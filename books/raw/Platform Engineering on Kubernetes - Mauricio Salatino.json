{
  "metadata": {
    "title": "Platform Engineering on Kubernetes - Mauricio Salatino",
    "author": "Mauricio Salatino",
    "publisher": "Unknown Publisher",
    "edition": "1st Edition",
    "isbn": "",
    "total_pages": 312,
    "conversion_date": "2025-12-19T17:41:23.075898",
    "conversion_method": "PyMuPDF + OCR fallback",
    "source_pdf": "Platform Engineering on Kubernetes - Mauricio Salatino.pdf",
    "extraction_method": "PyMuPDF_fallback (Unstructured failed)"
  },
  "chapters": [
    {
      "number": 1,
      "title": "Segment 1 (pages 1-8)",
      "start_page": 1,
      "end_page": 8,
      "detection_method": "topic_boundary",
      "content": "M A N N I N G\nMauricio Salatino\nForeword by Jared Watts\n\n\nM A N N I N G\nShelter ISland\nPlatform Engineering \non Kubernetes\nMAURICIO SALATINO \n\n\nFor online information and ordering of this and other Manning books, please visit www.manning.com. \nThe publisher offers discounts on this book when ordered in quantity.\nFor more information, please contact\nSpecial Sales Department\nManning Publications Co.\n20 Baldwin Road\nPO Box 761\nShelter Island, NY 11964\nEmail: orders@manning.com\n© 2024 by Manning Publications Co. All rights Reserved.\nNo part of this publication may be reproduced, stored in a retrieval system, or transmitted, in any form \nor by means electronic, mechanical, photocopying, or otherwise, without prior written permission of the \npublisher.\nMany of the designations used by manufacturers and sellers to distinguish their products are claimed \nas trademarks. Where those designations appear in the book, and Manning Publications was aware of a \ntrademark claim, the designations have been printed in initial caps or all caps.\nRecognizing the importance of preserving what has been written, it is Manning’s policy to have the books \nwe publish printed on acid-­free paper, and we exert our best efforts to that end. Recognizing also our \nresponsibility to conserve the resources of our planet, Manning books are printed on paper that is at \nleast 15 percent recycled and processed without the use of elemental chlorine.\n∞\n\t\nManning Publications Co. \n20 Baldwin Road\nPO Box 761 \nShelter Island, NY 11964\nISBN 9781617299322\nPrinted in the United States of America\nThe author and publisher have made every effort to ensure that the information in this book was correct \nat press time. The author and publisher do not assume and hereby disclaim any liability to any party for \nany loss, damage, or disruption caused by errors or omissions, whether such errors or omissions result \nfrom negligence, accident, or any other cause, or from any usage of the information herein.\n\t\nDevelopment editor: \t Ian Hough\n\t\nTechnical development editor: \t Raphael Villela\n\t\nReview editor: \t Dunja NikitoviÊ\n\t\nProduction editor: \t Aleksandar DragosavljeviÊ\n\t\nCopy editor: \t Katie Petito\n\t\nTechnical proofreader: \t Werner Dijkerman\n\t\nTypesetter:\t Tamara ŠveliÊ SabljiÊ\n\t\nCover designer: \t Marija Tudor\n\n\nFirst and foremost, this book is dedicated to my wife and family, who  \nhelped and supported me throughout writing this book. Without their help  \nand support, this would have been impossible.\nThis book is dedicated to all cloud-native practitioners, communities, and \norganizations that are invested in using open-source and cloud-native projects to \ndesign, build and deliver better software for their customers.\n\n\niv\ncontents\nforeword\t\nix\npreface\t\nxi\nacknowledgments\t\nxii\nabout this book\t\nxiv\nabout the author\t\nxvii\nabout the cover illustration\t\nxviii\n\t\n1\n\t\n(The rise of) platforms on top of Kubernetes  1\n\t 1.1\t\nWhat is a platform, and why do I need one?  2\nCloud services and domain-specific needs  3  ■  Your job as an \norganization  4  ■  Working with cloud platforms  6 \nGCP dashboard, CLIs, and APIs  8  ■  Why do cloud providers \nwork?  10\n\t 1.2\t\nPlatforms built on top of Kubernetes  11\nThe Kubernetes adoption journey  12  ■  The CNCF Landscape \npuzzle  14\n\t 1.3\t\nPlatform engineering  16\nWhy can’t I just buy a platform?  17\n\t 1.4\t\nThe need for a walking skeleton  18\nBuilding a Conference application  19  ■  Differences between \na monolith and a distributed set of services  22  ■  Our walking \nskeleton and building platforms  24\n\n\n\t\nv\ncontents\n\t\nv\n\t\n2\n\t\nCloud-native application challenges  27\n\t 2.1\t\nRunning our cloud-native applications  28\nChoosing the best Kubernetes environment for you  28 \nInstalling the walking skeleton  30\n\t 2.2\t\nInstalling the Conference application with a single \ncommand  34\nVerifying that the application is up and running  35 \nInteracting with your application  36\n\t 2.3\t\nInspecting the walking skeleton  41\nKubernetes deployments basics  41  ■  Exploring deployments  42 \nReplicaSets  43  ■  Connecting services  46  ■  Exploring \nservices  46  ■  Service discovery in Kubernetes  47 \nTroubleshooting internal services  48\n\t 2.4\t\nCloud-native application challenges  49\nDowntime is not allowed  50  ■  Service’s resilience built-in  53 \nDealing with the application state is not trivial  55  ■  Dealing \nwith inconsistent data  58  ■  Understanding how the \napplication is working  58  ■  Application security and identity \nmanagement  60  ■  Other challenges  61\n\t 2.5\t\nLinking back to platform engineering  62\n\t\n3\n\t\nService pipelines: Building cloud-native applications   66\n\t 3.1\t\nWhat does it take to deliver cloud-native applications \ncontinuously?  67\n\t 3.2\t\nService pipelines  70\n\t 3.3\t\nConventions that will save you time  71\n\t 3.4\t\nService pipeline structure  72\nService pipeline in real life  75  ■  Service pipeline \nrequirements  76  ■  Opinions, limitations, and compromises \naround service pipelines   78\n\t 3.5\t\nService pipelines in action  79\nTekton in action  79  ■  Pipelines in Tekton  82  ■  Tekton \nadvantages and extras  86  ■  Dagger in action  88 \nShould I use Tekton, Dagger, or GitHub Actions?  93\n\t 3.6\t\nLinking back to platform engineering  94\n\n\nvivi\ncontents\n\t\n4\n\t\nEnvironment pipelines: Deploying cloud-native \t\t\n\t\n\t\n\t\n\t\napplications  98\n\t 4.1\t\nEnvironment pipelines  99\nHow did this work in the past, and what has changed lately?  100 \nWhat is GitOps, and how does it relate to environment \npipelines?  102  ■  Steps involved in an environment \npipeline  105  ■  Environment pipeline requirements and different \napproaches  107\n\t 4.2\t\nEnvironment pipelines in action  110\nCreating an Argo CD application  111  ■  Dealing with changes \nthe GitOps way  115\n\t 4.3\t\nService + environment pipelines  117\n\t 4.4\t\nLinking back to platform engineering  119\n\t\n5\n\t\nMulti-cloud (app) infrastructure  122\n\t 5.1\t\nThe challenges of managing infrastructure in \nKubernetes  123\nManaging your application infrastructure  124  ■  Connecting \nour services to the newly provisioned infrastructure  127 \nI’ve heard about Kubernetes operators. Should I use them?  128\n\t 5.2\t\nDeclarative infrastructure using Crossplane  130\nCrossplane providers  131  ■  Crossplane compositions  132 \nCrossplane components and requirements  134  ■  Crossplane \nbehaviors  136\n\t 5.3\t\nInfrastructure for our walking skeleton  138\nConnecting our services with the new provisioned \ninfrastructure  148\n\t 5.4\t\nLinking back to platform engineering  152\n\t\n6\n\t\nLet’s build a platform on top of Kubernetes  155\n\t 6.1\t\nThe importance of the platform APIs  156\nRequesting development environments  157\n\t 6.2\t\nPlatform architecture  160\nPlatform challenges  163  ■  Managing more than one \ncluster  163  ■  Isolation and multi-tenancy  164\n\n\n\t\nvii\ncontents\n\t\nvii\n\t 6.3\t\nOur platform walking skeleton  166\nvcluster for virtual Kubernetes clusters  169  ■  The platform \nexperience  170\n\t 6.4\t\nLinking back to platform engineering  173\n\t\n7\n\t\nPlatform capabilities I: Shared application concerns  178\n\t 7.1\t\nWhat are most applications doing 95% of the time?  179\nThe challenges of coupling application and infrastructure  180 \nService-to-service interaction challenges  181  ■  Storing/\nreading state challenges  184  ■  Asynchronous messaging \nchallenges  186  ■  Dealing with edge cases (the remaining \n5%)  188\n\t 7.2\t\nStandard APIs to separate applications from \ninfrastructure  189\nExposing platform capabilities challenges  191\n\t 7.3\t\nProviding application-level platform capabilities  192\nDapr in action  192  ■  Dapr in Kubernetes  193  ■  Dapr and \nyour applications  196  ■  Feature flags in action  197 \nUpdating our Conference application to consume application-level \nplatform capabilities  199\n\t 7.4\t\nLinking back to platform engineering  205\n\t\n8\n\t\nPlatform capabilities II: Enabling teams to experiment   209\n\t 8.1\t\nRelease strategies fundamentals  211\nCanary releases  211  ■  Blue/green deployments  212 \nA/B testing  213  ■  Limitations and complexities of using built-in \nKubernetes building blocks  215\n\t 8.2\t\nKnative Serving: Advanced traffic management and release \nstrategies  216\nKnative Services: Containers-as-a-Service  216  ■  Advanced \ntraffic-splitting features  220\n\t 8.3\t\nArgo Rollouts: Release strategies automated with GitOps  228\nArgo Rollouts canary rollouts  229  ■  Argo Rollouts blue/green \ndeployments   236  ■  Argo Rollouts analysis for progressive \ndelivery  242  ■  Argo Rollouts and traffic management  245\n\t 8.4\t\nLinking back to platform engineering  247\n",
      "page_number": 1
    },
    {
      "number": 2,
      "title": "Segment 2 (pages 9-16)",
      "start_page": 9,
      "end_page": 16,
      "detection_method": "topic_boundary",
      "content": "viii\ncontents\nviii\n\t\n9\n\t\nMeasuring your platforms  251\n\t 9.1\t\nWhat to measure: DORA metrics and high-performant \nteams  252\nThe integration problem  254\n\t 9.2\t\nHow to measure our platform: CloudEvents and \nCDEvents  255\nCloudEvents for continuous delivery: CDEvents  256 \nBuilding a CloudEvents-based metrics collection pipeline  259 \nData collection from event sources  260  ■  Knative Eventing event \nsources  260  ■  Data transformation to CDEvents  262 \nMetrics calculation  264  ■  Working example  266\n\t 9.3\t\nKeptn Lifecycle Toolkit  272\n\t 9.4\t\nWhat’s next on the platform engineering journey?  276\n\t 9.5\t\nFinal thoughts  279\n\t \t\nindex  281\n\n\nix\nforeword\nThe cloud native landscape has matured to a point where we can finally start building \npractical solutions. A plethora of projects have emerged, each with a unique focus on \nsolving a portion of the grander vision. We now find ourselves struggling to cobble \ntogether these disparate projects into an end-to-end product. How can we manage the \ninherent complexity that this litany of tools brings and construct a complete solution?\nPlatform Engineering on Kubernetes by Mauricio Salatino offers a comprehensive answer \nto this question in the form of platform engineering. The discipline of platform engi-\nneering is positioned to make cloud-native development accessible to application devel-\nopers through highly productive and reliable delivery of their software to production \nenvironments. I consider platform engineering to be the crucial modern discipline that \nwill tame complexity and deliver the tantalizing promises made long ago when Kuber-\nnetes first made cloud-native technology available for the masses.\n This book provides much needed insight into how modern platforms can be archi-\ntected to effectively integrate the most useful cloud-native technologies from the ecosys-\ntem and solve real problems for the application developer customers of your platform. \nIt efficiently provides practical guidance, learned through hands-on exercises and \nexamples, to instill real skills for building a meaningful platform solution. The valuable \ninformation contained within these pages will enable platform teams to build a self-ser-\nvice developer platform as their product, allowing developers to deliver their applica-\ntions to production with greater speed and reliability than they’ve ever seen before.\nI’ve personally met a wealth of amazing individuals within the cloud-native ecosys-\ntem from my time as a co-creator, maintainer, and steering committee member on two \nseparate projects in the Cloud Native Computing Foundation. From my experience, \nMauricio is uniquely positioned to author this beneficial book that walks you through \nintegrating all of these projects into a complete platform, as he has consistently been an \n\n\nx\nforeword\nx\nintegrator within the ecosystem himself by bringing together people, communities, and \ntechnology on numerous occasions. Mauricio has demonstrated an uncanny ability to \nidentify shared interests across project visions, to bring the right people together, and \nfind common ground that unifies the efforts into a cohesive approach. He has shown \na consistent dedication to his rare gift of finding paths that make us better together \nthrough our collaboration and synergy rather than competition or duplication.\nIn the same way that Mauricio brings together people and technology, he has \nbrought together many projects into a valuable whole within these pages. I expect that \nlessons learned within this book will be some of the most rewarding steps you take in \nrealizing your platform engineering vision. Please enjoy the journey!\n—Jared Watts\nFounding Engineer, Upbound\n\n\nxi\npreface\nI started working on this book more than two years ago. After working for the cloud-na-\ntive communities for more than four years, I’ve learned many lessons I’d like to share \nwith teams to speed up their Kubernetes adoption journey. Because I contributed to \nseveral open-source projects (most included in this book), creating a table of content \nfor a book idea wasn’t that difficult. On the other hand, writing a book about a for-\never-changing ecosystem proved challenging. But as you will find out when reading \nthis book, platform engineering is all about managing the complexities of constantly \nevolving projects and requirements from different teams that need the right tools to \ndo their job. \nThis book has allowed me to meet and work with the best people in the industry from \ndifferent backgrounds and communities who share my passions: open source, cloud \nnative, and knowledge sharing. I’ve toured the world, presenting at conferences in the \ncloud-native space, always gathering feedback from community members, developers, \nand teams struggling to keep up with the amazing amount of open-source projects cre-\nated daily. I hope this book helps you and your team to evaluate, integrate, and build \nplatforms on top of Kubernetes. \n\n\nxii\nacknowledgments\nI would like to give special thanks to everyone who contributed to the examples pro-\nvided in this book (both the original repository at https://github.com/salaboy/from \n-monolith-to-k8s/ and the new one at https://github.com/salaboy/platforms-on \n-k8s/). This book was written for and by the community of the projects mentioned. \nSpecial thanks to my brother Ezequiel Salatino (https://salatino.me/), who \ndesigned and built the frontend applications so readers can experience a website \ninstead of a bunch of REST endpoints. I will be forever grateful to Matheus Cruz and \nAsare Nkansah, who helped me build big chunks of the examples without expecting \nanything in return. Finally, thank you to my friend Thomas Vitale for sharing thorough \nreviews of multiple editions of the drafts; all your comments made the content of this \nbook more accurate and focused. \nI couldn’t have done this book without all the support provided by the Manning \nteam. I want to thank development editor, Ian Hough, for the countless hours spent \non the manuscript. Acquisitions editor, Michael Stephens, for strongly believing in the \nbook idea since day one, Raphael Villela as technical editor for all the technical advice \nprovided, and Werner Dijkerman as technical proofer for his comments and ensuring \nthat all of the code is in good working order.\nTo all the reviewers: Alain Lompo, Alexander Schwartz, Andres Sacco, Carlos Panato, \nClifford Thurber, Conor Redmond, Ernesto Cárdenas Cangahuala, Evan Anderson, \nGiuseppe Catalano, Gregory A. Lussier, Harinath Mallepally, John Guthrie, Jonathan \nBlair, Kent Spillner, Lucian Torje, Michael Bright, Mladen Knezic, Philippe Van Ber-\ngen, Prashant Dwivedi, Richard Meinsen, Roman Levchenko, Roman Zhuzha, Sachin \nRastogi, Simeon Leyzerzon, Simone Sguazza, Stanley Anozie, Theo Despoudis, Vidhya \nVinay, Vivek Krishnan, Werner Dijkerman, WIlliam Jamir, Zoheb Ainapore, your sug-\ngestions helped make this a better book.\nProject-specific thanks: \n\n\n\t\nxiii\nacknowledgments\n\t\nxiii\n¡ Argo Project (https://argoproj.github.io/ )—I want to thank Dan Garfield from \nCodefresh for his continuous support of the book and his contributions to the \nOpenGitOps (https://opengitops.dev/) initiative.\n¡ Crossplane (https://crossplane.io )—I want to thank Jared Watts for his constant \nwillingness to help and push things forward. Also, I want to thank Viktor Farcic \nand Stefan Schimanski for always supporting the Crossplane community. The \nCrossplane community has taught me many valuable lessons that shaped my \ncareer. \n¡ Dagger (https://dagger.io )—I want to thank Marcos Nils and Julian Cruciani \nfor their help with the Dagger examples and their willingness to improve things \nwhen time can be saved for developers. \n¡ Dapr (https://dapr.io )—Big thanks and appreciation to both Yaron Schneider \nand Mark Fussel for their constant support to get this book out of the door and to \nthe entire Diagrid (https://diagrid.io )—team, who is building amazing products \non top of Dapr.\n¡ Keptn (https://keptn.sh )—Big thanks to Giovanni Liva and Andreas Grabner for \ntheir speedy response and the amazing work that they have done in the Keptn \nand OpenFeature communities.\n¡ Knative (https://knative.dev )—The entire Knative community is awesome, but \nspecial thanks to Lance Ball, who led the Knative Functions working group to \nbuild something amazing. \n¡ Kratix (https://kratix.io )—Special thanks to Abby Bangser for sharing her plat-\nform insights and reviewing key chapters in the book. All your comments and \nremarks made this book way more valuable. \n¡ OpenFeature (https://openfeature.dev )—I wanted to thank James Milligan for his \nhelp in getting the OpenFeature and flagd examples working. \n¡ Tekton (https://tekton.dev )—Big thanks to Andrea Fritolli for his amazing work \non the Tekton community and for always answering my Slack messages. \n¡ Vcluster (https://vcluster.com )—Both Ishan Khare and Fabian Kramm had \nbeen instrumental to the work that I’ve done for this book. Their willingness \nto get things working had gone above and beyond. Big thanks for creating and \nmaintaining the vcluster, Devspace (https://www.devspace.sh/), and DevPod \n(https://devpod.sh/) projects.\n\n\nxiv\nabout this book\nPlatform Engineering on Kubernetes was written to help teams going through a Kuber-\nnetes adoption journey. The book uses a developer-centric approach to cover build-\ning, packaging, and deploying cloud-native applications to Kubernetes clusters, but \nit doesn’t stop there. Once you and your teams understand how to use Kubernetes \nfor your applications, you face new challenges related to managing Kubernetes exten-\nsions, multi-tenancy, and multi-cluster setups. \nPlatforms on top of Kubernetes need to integrate a wide range of tools to enable spe-\ncialized teams to perform their daily tasks while at the same time preventing them from \nlearning how all these tools work. Platform teams are in charge of learning, curating, \nand integrating tools to make the life of development teams, data scientists, operations \nteams, testing teams, product teams, and everyone involved with the software delivery \nprocess of your organization easier.\nMost of the content is focused around Kubernetes and built to be agnostic of the \ntechnology stack used for application-specific features. If you are getting started with \nKubernetes or you are a cloud-native practitioner, this book can help you to understand \nhow multiple projects can be combined to build team-specific experiences and reduce \nthe cognitive load involved in their day-to-day jobs, no matter the programming lan-\nguage you and your teams are using.\nHow this book is organized: a roadmap\nThis book is organized into nine chapters, and it uses the concept of a “walking skel-\neton” to build a platform to support the teams in building a Conference application. \nThe flow of the book goes as follows: \nChapter 1 introduces what platforms are, why you need one, and how the platforms \nwe will cover in this book compare to what cloud providers offer. This chapter intro-\nduces the business use case for the Conference application that further chapters will \nexplore.\n\n\n\t\nxv\nabout this book\n\t\nxv\nChapter 2 evaluates the challenges of building cloud native and distributed applica-\ntions that run on Kubernetes. This chapter encourages the reader to deploy the Con-\nference application and explore its design by changing its configuration and testing \ndifferent scenarios. By looking at the challenges teams will face when deploying and \nrunning applications on top of Kubernetes and providing a playground to experiment \nby using the walking skeleton, the book aims to enable readers with enough experience \nto tackle bigger challenges. \nChapter 3 focuses on all the extra steps needed to build, package, and distribute \nartifacts to run our applications in different cloud providers. This chapter introduces \nthe concept of service pipeline and explores two different but complementary projects: \nTekton and Dagger. \nOnce our artifacts are ready to be deployed, chapter 4 is centered around the con-\ncept of the environment pipeline. By defining our environment pipelines and by using \na GitOps approach, teams can manage the configuration of multiple environments \nusing a declarative approach. This chapter explores Argo CD as a tool to configure and \nmanage your environments. \nApplications can’t work on their own. Most applications require infrastructural com-\nponents such as databases, message brokers, and identity providers, among others, to \nwork. Chapter 5 covers a Kubernetes-native approach to provision application infra-\nstructure components across cloud providers using a project called Crossplane. \nOnce we have taken care of building, packaging, and deploying our applications and \nother components that our applications need to run, chapter 6 proposes the reader \nbuild a platform on top of Kubernetes using all that we have learned so far but focusing \nonly on a simple use case: creating development environments. \nPlatforms are not only about creating environments, managing clusters, and deploy-\ning applications. Platforms should provide customized workflows for teams to be pro-\nductive. Chapter 7 focuses on enabling development teams with application-level APIs \nthat platform teams can decide how to wire to available resources. This chapter evalu-\nates tools like Dapr and OpenFeature to enable teams with more than clusters and a \nplace to run their applications.\nWhile enabling developers to be more efficient will improve software delivery times, \nif new releases are blocked and not deployed in front of customers, all the effort will \nbe wasted. Chapter 8 focuses on showing techniques, more precisely release strategies, \nthat can be used to experiment with new releases before fully committing to them. This \nchapter evaluates Knative Serving and Argo Rollouts to implement different release \nstrategies that your teams can use to experiment with new features in a controlled way.\nBecause platforms are software, we need to measure how effective we are when evolv-\ning them. Chapter 9 evaluates two approaches to tap into the tools we are using to build \nour platform and calculate key metrics that allow the platform engineering team to \nevaluate their platform initiatives. This chapter looks into CloudEvents, CDEvents, and \nthe Keptn Lifecycle Toolkit as options to gather events, store them, and aggregate them \nto calculate meaningful metrics. \n",
      "page_number": 9
    },
    {
      "number": 3,
      "title": "Segment 3 (pages 17-27)",
      "start_page": 17,
      "end_page": 27,
      "detection_method": "topic_boundary",
      "content": "xvi\nabout this book\nxvi\nBy the end of the book, the reader ends up with a clear picture and hands-on experi-\nence of how platforms are built on top of Kubernetes, what the priorities of the platform \nengineering teams are, and why learning and keeping up to date with the cloud-native \nspace is so important to be successful.\nAbout the code \nThis book contains many examples of source code both in numbered listings \nand in line with normal text. In both cases, source code is formatted in a fixed \n-width font like this to separate it from ordinary text. Sometimes code is also in \nbold to highlight code that has changed from previous steps in the chapter, such as \nwhen a new feature adds to an existing line of code.\nIn many cases, the original source code has been reformatted; we’ve added line \nbreaks and reworked indentation to accommodate the available page space in the \nbook. In rare cases, even this was not enough, and listings include line-continuation \nmarkers (➥). Additionally, comments in the source code have often been removed \nfrom the listings when the code is described in the text. Code annotations accompany \nmany of the listings, highlighting important concepts.\nYou can get executable snippets of code from the liveBook (online) version of this \nbook at https://livebook.manning.com/book/platform-engineering-on-kubernetes. The \ncom­plete code for the examples in the book is available for download from the Manning \nwebsite at https://www.manning.com/books/platform-engineering-on-kubernetes.\nEach chapter links to step-by-step tutorials where readers are encouraged to get their \nhands dirty with the tools and projects running in their environments. You can find \nall the source code and step-by-step tutorials on the following GitHub repository at \nhttps://github.com/salaboy/platforms-on-k8s/.\nliveBook discussion forum\nPurchase of Platform Engineering on Kubernetes includes free access to liveBook, Man-\nning’s online reading platform. Using liveBook’s exclusive discussion features, you \ncan attach comments to the book globally or to specific sections or paragraphs. It’s a \nsnap to make notes for yourself, ask and answer technical questions, and receive help \nfrom the author and other users. To access the forum, go to https://livebook.manning \n.com/book/platform-engineering-on-kubernetes/discussion. You can also learn more \nabout Manning’s forums and the rules of conduct at https://livebook.manning.com/\ndiscussion.\nManning’s commitment to our readers is to provide a venue where a meaningful dia-\nlogue between individual readers and between readers and the author can take place. It \nis not a commitment to any specific amount of participation on the part of the author, \nwhose contribution to the forum remains voluntary (and unpaid). We suggest you try \nasking the author some challenging questions lest his interest stray! The forum and the \narchives of previous discussions will be accessible from the publisher’s website as long as \nthe book is in print.\n\n\nxvii\nabout the author\nMauricio Salatino works for Diagrid (https://diagrid \n.io) as an Open Source Software Engineer. He is currently \na Dapr OSS Contributor and Knative Steering Committee \nmember. Before working at Diagrid, Mauricio spent the \nlast 10 years building tools for Cloud-Native developers \nat companies such as Red Hat and VMware. When he is \nnot writing tools for developers or contributing to Open \nSource projects in the Cloud Native space, he teaches \nabout Kubernetes and Cloud-Native via his Blog https://\nsalaboy.com and/or LearnK8s (https://learnk8s.io).\n\n\nxviii\nabout the cover illustration\nThe figure on the cover of Platform Engineering on Kubernetes is “Femme des Isles d’Ar-\ngentiere et de Milo,” or “A Woman from the Isles of Argentiera and Milos,” taken from \na collection by Jacques Grasset de Saint-Sauveur, published in 1788. Each illustration is \nfinely drawn and colored by hand. \nIn those days, it was easy to identify where people lived and what their trade or station \nin life was just by their dress. Manning celebrates the inventiveness and initiative of the \ncomputer business with book covers based on the rich diversity of regional culture cen-\nturies ago, brought back to life by pictures from collections such as this one.\n\n\n1\n1\n(The rise of) platforms \non top of Kubernetes\nThis chapter covers\n¡ Understanding platforms and why we need \t\n\t them\n¡ Building a platform on top of Kubernetes\n¡ Introducing a “walking skeleton” application\nPlatform engineering is not a new term in the tech industry. But it is quite new in \nthe cloud-native space and the context of Kubernetes. We were not using the term \nin the cloud-native communities when I started writing this book back in 2020. How-\never, by the time of writing this book (2023), platform engineering had become the \nnew hot topic in cloud-native and Kubernetes communities. This book aims to go \non a journey to explore what platforms are and why you would use Kubernetes, and \nmore specifically, the Kubernetes APIs at the core, to build a platform and enable \nyour internal teams to deliver software more efficiently. \nTo understand why platform engineering became a trend in the industry, you first \nneed to understand the cloud native and Kubernetes ecosystems. Because this book \nassumes that you are already familiar with Kubernetes, containers, and cloud-native \napplications, we will focus on describing the challenges you will face when archi-\ntecting, building, and running these applications on top of Kubernetes and cloud \n\n\n2\nChapter 1  (The rise of) platforms on top of Kubernetes \nproviders. We will take a developer-focused approach, meaning that most of the topics \ncovered are tackled in a way that relates to developers’ day-to-day tasks and how a myr-\niad of tools and frameworks in the cloud-native space will affect them. \nThe ultimate goal for every software development team is to deliver new features \nand bug/security fixes to their customers. New features and more stable applications \ntranslate directly to competitive business advantages and happy customers. To deliver \nmore software efficiently, development teams must have access to the tools they need \nto do their work. The main objective of the platform and platform engineering teams is \nto enable developers to deliver software more efficiently. This requires a different tech-\nnological approach and a cultural shift towards treating development teams as internal \ncustomers of the platforms we will be building. \nWe will use a simple application (composed of multiple services) as an example \nthroughout the chapters to build a platform that supports the teams building, releas-\ning, and managing this application by using all open source tools in the cloud-native \nspace. \n1.1\t\nWhat is a platform, and why do I need one?\nPlatforms are a collection of services that help companies get their software running \nin front of their customers (internal or external). Platforms aim to be a one-stop shop \nfor teams to have all the tools that they need to be productive and continuously deliver \nbusiness value—with the rise in popularity and with the growing demand to improve \ndevelopment cycles, platforms that once used to provide us only with computing \nresources had leveled up the stack to provide more and more services. \nPlatforms are not new, and neither are cloud platforms. Cloud providers like AWS, \nGoogle, Microsoft, Alibaba, and IBM have provided us platforms for years. These cloud \nproviders offer teams many tools to build, run, and monitor their business-critical appli-\ncations using a pay-as-you-go model. From a business agility perspective, these platforms \noffered by cloud providers have fundamentally shifted the expectations for teams con-\nsuming their services. This allows companies and teams to start fast and create applica-\ntions that can scale globally without a significant initial investment. If no one uses the \napplications they are building, their bills will not be large at the end of the month. On \nthe other side of the spectrum, if you are successful and your applications are popular, \nyou must get ready for a large bill at the end of the month. The more resources (stor-\nage, network traffic, services, etc.) you use, the more you pay. Another aspect to con-\nsider is that if you rely on the tools provided by your cloud provider, it is harder to move \naway from them as your entire organization gets used to that cloud provider’s tools, \nworkflows, and services. It becomes a painful experience to plan and migrate applica-\ntions across different providers. \nIn the following sections, we will cover the current state of cloud platforms and what \nkind of platforms we will discuss in this book. Lately, as always happens in our industry, \n\n\n\t\n3\nWhat is a platform, and why do I need one?\nterms that can be useful to describe very concrete tools and practices tend to be abused \nby marketing teams and become buzzwords. We must set the context for the rest of the \nbook to avoid confusion.\n1.1.1\t\nCloud services and domain-specific needs\nWe can organize cloud services into different layers, something that we need to do to \nunderstand where the industry is today and where it is heading. The following diagram \nshows a set of categories of the services provided by cloud providers, starting from \nlow-level infrastructure services, such as provisioning hardware on demand to high-\nlevel application services, where developers can interact with machine-learning mod-\nels without worrying where these models are running. Figure 1.1 shows these layers, \nstarting at the bottom with low-level computing resources and going up the stack with \napplication-level and industry-specific services. \nApplication Services & Industry specific Services\n(AI & ML, Voice recognition, Text recognition, etc.)\nDevelopment tools \n(SDKs, Libraries/Frameworks, Debuggers, etc.)\nApplication Infrastructure \n(Databases, Message Brokers, Identity management, \nSecrets management, etc.)\nOperating System and Base Software\n(Operating System, Patches, Kernel Modules, etc.)\nOperational tools \n(Monitoring tools, Metrics dashboards, Cost \nmanagement, etc.)\nInfrastructure & Computing Resources \n(Hardware, Networking, power, etc.)\nHigh Level Application ($$$)\nLow-Level Infrastructure ($)\nApplication \nDevelopment\nOperations\nFigure 1.1    Cloud provider’s services categories\nThe higher the category, the more you will need to pay for the service, because these \nservices usually take care of all the underlying layers and operational costs for you. For \nexample, suppose you provision a new highly available PostgreSQL database in a man-\naged service offered by a cloud provider. Figure 1.2 shows an example of a relational \ndatabase such as PostgreSQL.\n\n\n4\nChapter 1  (The rise of) platforms on top of Kubernetes \nApplication Infrastructure \n(Databases, Message Brokers, Identity management, \nSecrets management, etc.)\nOperating System and Base Software\n(Operating System, Patches, Kernel Modules, etc.)\nOperational tools \n(Monitoring tools, Metrics dashboards, Cost \nmanagement, etc.)\nInfrastructure & Computing Resources \n(Hardware, Networking, power, etc.)\nApplication Infrastructure ($$)\nOperations\nLow-Level Infrastructure ($)\nPostgreSQL\nFigure 1.2    Provisioning a PostgreSQL database instance in the cloud\nIn that case, the service cost includes the cost and management of the database soft-\nware needed, the operating system where the database runs, and the hardware needed \nto run it. Because you might want to monitor and get metrics on how the database \nperforms when your application is under heavy load, the cloud provider also wires up \nall the monitoring tools available for the service. Then it is up to you to do the math: is \nit worth paying a cloud provider to make all these decisions for us, or can you build an \ninternal team with enough knowledge to run and operate all these software and hard-\nware on-premises? Sometimes, money is not a problem; you must deal with company \nor industry policies and regulations. In such cases, can you run your workloads and \nhost your data in a cloud provider? \n1.1.2\t\nYour job as an organization\nKeeping up to date with all the provided services, libraries, frameworks, and tools is a \nfull-time job. Operating and maintaining the wide range of software and hardware that \ncompanies need to run their applications requires you to have the right teams in place, \nand at the end of the day, if you are not a large and mature organization in terms of \nyour software delivery practices, or if you are not getting any competitive advantage by \nmanaging your own hardware/software stack, adopting a cloud provider is usually the \nright way to go.  \nIt is still the job of each company and developer to look at the available services and \nchoose what they will use and how they will mix and match these services to build new \nfeatures. It is common to find cloud architects (experts on a specific cloud provider, \nor on-premises experts) in each organization defining how and which services will be \nused to build core applications. It is also common to engage with the cloud provider’s \nconsulting services to get advice and guidance on specific use cases and best practices. \nCloud providers might suggest tools and workflows to create applications. Still, each \norganization needs to go through a learning curve and mature its practices around \napplying these tools to solve its specific challenges. Staffing cloud provider experts is \n\n\n\t\n5\nWhat is a platform, and why do I need one?\nalways a good idea, because they bring knowledge from previous experiences, saving \ntime for less-experienced teams. \nIn this book, we will focus on organization-specific platforms, not generic cloud plat-\nforms that you can buy off the shelf, like those offered by cloud providers. We also want \nto focus on platforms that can work on-premises on our organization’s hardware. This is \nimportant for more regulated industries that cannot run on public clouds. This forces \nus to have a broader view of tools, standards, and workflows that can be applied outside \nthe realm of a cloud provider. Consuming services from more than one cloud provider \nis also becoming increasingly popular. This can result from working for a company that \nacquired or became acquired by another company using a different provider, ending \nup in a situation where multiple providers must coexist, and there should be a shared \nstrategy for both. In other situations, in more regulated industries, organizations are \nforced to run workloads on different providers (including on-prem workloads) to guar-\nantee resiliency in situations where an entire cloud provider can go down.\nThe kind of platforms we will be looking at extends the layers of customer behavior \nmentioned before to include company-specific services, company-specific standards, \nand developer experiences that allow the organization’s development teams to build \ncomplex systems for the organization and their customers. Figure 1.3 shows how, no \nmatter whether we are consuming cloud services, third-party services, or internal ser-\nvices, organizations must mix and match these services by building layers on top that \nare focused on solving business-specific challenges.\nOrganization Specific\nServices\nData Sources\nTools\nEvent Sources\nApplication Services & Industry specific Services\nDevelopment tools\nApplication Infrastructure\nOperational tools\nOperating System and Base Software\nInfrastructure & Computing Resources\nCloud Provider (Generic)\nThird-Party \nServices\nFigure 1.3    Organization-specific layers\n\n\n6\nChapter 1  (The rise of) platforms on top of Kubernetes \nThese extra layers are, most of the time, “glue” between existing services, data, and \nevent sources combined to solve particular challenges the business faces or to imple-\nment new features for their customers. It is common to rely on third-party service pro-\nviders for more business-specific tools, for example, industry-specific or generic CRM \n(Customer Relationship Management) systems, such as Salesforce. \nFor the customers, the platform, the cloud provider, and where the services are run-\nning are entirely irrelevant. Internally, for development teams, the platform acts as an \nenabler for development teams to do their work. Platforms are not static, and their \nmain objective is to help the organization improve and excel at continuously delivering \nhigh-quality software to its customers. \nNo matter the industry where your company operates and whether you choose to use \na cloud provider, your company’s combinations of tools and workflows to deliver new \nfeatures to its customers can be described as your platform. Technically, platforms are \nall about system integrations, best practices, and composable services that we can com-\nbine to build more complex systems. This book will look at standard practices, tools, \nand behaviors that make platforms successful and how you can build your cloud-native \nplatforms, whether running on one or more cloud providers or on-premises. \nWe will use cloud providers as a reference to compare the services and tools they \nprovide and learn how we can achieve similar results in a multi-cloud provider and \non-premises way by using open-source tools. But before looking into concrete tools, it is \nessential to understand what kind of experiences we can get from cloud providers. \n1.1.3\t\nWorking with cloud platforms\nOne common denominator between all cloud providers is that they provide services \nusing an API-first approach. This means that to access any of their services, an API will \nbe available to the users to request and interact with this service. These APIs expose all \nthe service functionality, such as which resources can be created, with which configu-\nration parameters, where (in which region of the world) we want the resource to run, \netc. Another important aspect of these APIs is that they require a team to own these \nAPI definitions; this means that a team will be in charge of identifying how these APIs \nare going to be used and how they are going to evolve and have clear definitions of \nwhat these APIs are not responsible for. \nEach cloud provider can be analyzed by looking at their APIs, because there will \nusually be one API for each offered service. It is common to see services in the beta or \nalpha stage only offered through the APIs for early users to experiment, test, and pro-\nvide feedback before the service is officially announced. While the structure, format, \nand style tend to be similar for all the services provided by a cloud provider, there are \nno standards across cloud providers to define how these services should be exposed and \nwhich features they need to support.  \nManually crafting complex requests against the cloud provider services, APIs is com-\nplex and error prone. It is a common practice by cloud providers to simplify the devel-\noper’s life by providing SDKs (software development kits) that consume the services \n\n\n\t\n7\nWhat is a platform, and why do I need one?\nAPIs implemented in different programming languages. This means developers can \nprogrammatically connect and use a cloud provider’s services by including a depen-\ndency (library, the cloud provider SDK) for their applications. While this is handy, it \nintroduces some strong dependencies between the application’s code and the cloud \nprovider, sometimes requiring us to release our application code to upgrade these \ndependencies. \nIn the same way that with APIs, with SDKs, there are no standards, and each SDK \nheavily depends on the programming language ecosystem’s best practices and tools. \nThere are cases where the SDKs don’t play nice with frameworks or tools that are pop-\nular in the programming language that you are using. Examples where SDKs/Clients \ncan go wrong, include database drivers that don’t align with the version provided by \nthe cloud provider or languages and ecosystems that the Cloud Provider does not yet \nsupport. In such cases, going directly to the API is possible but hard and usually discour-\naged, because your teams will maintain all the code required to connect to the cloud \nprovider services. \nCloud providers also provide CLIs (command-line interfaces), tools for operations \nteams and some developers’ workflows. CLIs are binaries you can download, install, \nand use from your operating system terminal. CLIs interact directly with the cloud pro-\nviders’ APIs but don’t require you to know how to create a new application to interact \nwith the services as with SDKs. CLIs are particularly useful for continuous integration \nand automation pipelines, where resources might need to be created on demand, for \nexample, to run our integration tests.\nFigure 1.4 shows applications and automation such as CI/CD pipelines and inte-\ngration tests consuming the same APIs but using different tools designed by the cloud \nprovider to simplify these scenarios. The figure also shows the Dashboard component, \nusually running inside the cloud provider, which provides visual access to all the ser-\nvices and resources being created.\nApplications\nCI/CD Pipelines\nIntegration Tests\nScripts\nSDKs\nCLIs\nCloud Provider\nServices APIs\nDashboards\nFigure 1.4    Cloud providers’ SDKs, CLIs, and Dashboard clients \nFinally, due to the number of services provided and the interconnections between the \nservices, cloud providers offer dashboards and user interfaces to access and interact \nwith all the offered services. These dashboards also offer reporting, billing, and other \n\n\n8\nChapter 1  (The rise of) platforms on top of Kubernetes \nfunctions that are hard to visualize using the CLIs or directly via the APIs. By using \nthese dashboards, users can access most of the standard features provided by the ser-\nvices and real-time access to see what is being created inside the cloud provider. \nAs mentioned, dashboards, CLIs, and SDKs require your teams to learn about many \ncloud provider-specific flows, tools, and nomenclature. Because of the number of ser-\nvices provided by each cloud provider, it is no wonder why finding experts that can \ncover more than a single provider is challenging. \nBecause this is a Kubernetes-focused book, I wanted to show the experience pro-\nvided by a cloud provider to create a Kubernetes cluster, which demonstrates the dash-\nboard, CLI, and API exposed by the Google Cloud Platform. Some cloud providers \nprovide a better experience than others, but overall, you should be able to achieve the \nsame with all the major ones. \n1.1.4\t\nGCP dashboard, CLIs, and APIs\nLook at the Google Kubernetes Engine dashboard in figure 1.5 to create new Kuber-\nnetes clusters. As soon as you click Create a New Cluster, you are presented with a form \nasking you to fill in a few required fields, such as the name of the cluster. \nFigure 1.5    Google Kubernetes Engine creation form\nCloud providers do a fantastic job at having sensible defaults to avoid asking you to \nfill in 200 parameters before creating the needed resource. Once you have filled in all \nthe required fields, the form offers a quick way to start the provisioning process by just \n",
      "page_number": 17
    },
    {
      "number": 4,
      "title": "Segment 4 (pages 28-37)",
      "start_page": 28,
      "end_page": 37,
      "detection_method": "topic_boundary",
      "content": "\t\n9\nWhat is a platform, and why do I need one?\nclicking the Create button down the bottom. It is pretty interesting to see that, in this \ncase, the Google Cloud Platform offers you an estimated cost per hour of the resource \nthat you have configured. This highlights the difference between providing features \nfor technical teams and providing a full service, covering the needs of technical teams \nand clarifying how these decisions can affect the business as a whole. You can start \ntweaking parameters to see how this cost changes (usually, it goes up). \nFigure 1.6    Create via a dashboard, REST, or using a Command Line Interface (CLI) tool\nAs shown in figure 1.6, right beside the Create button, you can see the REST option. \nThe cloud provider here helps you by crafting the REST request to their APIs needed \nto create the resource you can configure using the forms. This is quite handy if you \ndon’t want to spend hours looking at their API documents to find the shape of the pay-\nload and properties needed to create the request; see figure 1.7. \nFigure 1.7    Create via Kubernetes cluster using a REST request\nFinally, the CLI command option, using the cloud provider CLI, in this case, gcloud, \nis once again crafted to contain all the parameters the CLI command needs based on \nwhat you have configured in the form, as shown in figure 1.8. \n\n\n10\nChapter 1  (The rise of) platforms on top of Kubernetes \nFigure 1.8    Create via Kubernetes cluster using the gcloud CLI\nNotice the horizontal scroll in figure 1.8; this command can become extremely com-\nplex. The Google Cloud Platform’s user experience team has done a wonderful job \nsimplifying how teams can set all these parameters by relying on sensible defaults. \nThere are no differences between these approaches regarding the expected behav-\nior, but you need to consider that when you use the cloud provider’s dashboard, your \naccount credentials are being used from your current session. If you are crafting a \nrequest or using the CLI from outside the cloud provider’s network, you must first \nauthenticate with the cloud provider before issuing the request or executing the com-\nmand to create the resource(s). It is essential to notice that these interactions will dif-\nfer from cloud provider to cloud provider. You cannot expect the commands to be \nsimilar in AWS or Azure, the dashboard interactions, or how the security mechanism \nworks to authenticate the CLIs or REST requests.  \n1.1.5\t\nWhy do cloud providers work?\nWhile one can argue that dashboards, CLIs, APIs, and SDKs are the primary artifacts \nwe will consume from cloud providers, but the big question is: how will we combine \nthese tools to deliver software? Suppose you analyze why organizations worldwide trust \nAWS, Google Cloud Platform, and Microsoft Azure. You will likely find that by adopt-\ning an API-first approach and offering dashboards, CLIs, SDKs, and a myriad of ser-\nvices, these platforms provide teams with three main features that define platforms \ntoday (figure 1.9):\n\n\n\t\n11\nPlatforms built on top of Kubernetes\n¡ APIs (contracts): No matter which tools you use, the platform must expose a set of \nAPIs enabling teams to consume or provision the resources needed to do their \nwork. These APIs are the responsibility of the platform engineering teams to \nmaintain and evolve \n¡ Golden paths to production: The platform codifies and automates workflows \nrequired by teams to get their changes into production environments where live \ncustomers/users can access them. \n¡ Visibility: At all times, by looking at the cloud provider dashboard, the organiza-\ntion can monitor which resources are being used, how much each service costs, \ndeal with incidents, and have a complete picture of how the organization delivers \nsoftware.\nCloud Provider\nApplication Services and \nTools Using an API-First \napproach\nEnable us to build our \ngolden paths to production \nusing Automation \nServices and Tools\nVisibility on operations, \ncost and efficiency\nFigure 1.9    Cloud provider platforms’ advantages\nThese key features are provided using a competitive pay-as-you-go model that heavily \nrelies on demand (traffic), at a global scale (not for all services), allowing the organiza-\ntion to externalize all the operation and infrastructure costs.  \nWhile cloud providers are going higher and higher up the stack (providing high-\nlevel services, not just provisioning hardware and application infrastructure such as \ndatabases), your teams still need to learn and glue these services together to solve their \nbusiness challenges.\nThis is where Kubernetes and the CNCF landscape (Cloud-Native Computing Foun-\ndation, https://www.cncf.io/) become key areas to explore for learning how to build \nplatforms that are cloud-provider agnostic and allow us to pick and choose from a big \npool of vibrant projects. Let’s move on to that next.\n1.2\t\nPlatforms built on top of Kubernetes\nWe have briefly discussed what platforms are and how cloud providers are driving the \nway forward to define what these platforms can do for organizations and development \nteams in charge of delivering software. But how does this map to Kubernetes? Isn’t \nKubernetes a platform? \nKubernetes was designed to be a declarative system for our cloud-native applica-\ntions. Kubernetes defines a set of building blocks that allows us to run and deploy our \nworkloads. Nowadays, every major cloud provider offers Kubernetes-managed services, \n\n\n12\nChapter 1  (The rise of) platforms on top of Kubernetes \nwhich enables us with a standardized way of packaging (containers) and deploying \nworkloads across cloud providers. Because Kubernetes comes with its tools and ecosys-\ntem (the CNCF landscape, https://landscape.cncf.io/), you can create cloud-agnostic \nworkflows to build, run, and monitor your applications. But learning Kubernetes is just \nthe starting point, because the building blocks provided by Kubernetes are very low \nlevel and designed to be composed to build tools and systems that solve more concrete \nscenarios. Combining these low-level building blocks provided by Kubernetes to build \nmore complex tools to solve more specific challenges is a natural evolutionary step. \nWhile Kubernetes provides us with APIs (the Kubernetes APIs), a CLI (kubectl), \nand a dashboard (Kubernetes Dashboard, https://kubernetes.io/docs/tasks/access \n-application-cluster/web-ui-dashboard/), Kubernetes is not a platform. Kubernetes is \na meta-platform or a platform to build platforms, because it provides all the building \nblocks you need to build concrete platforms that will solve domain-specific challenges.\nFigure 1.10 shows how Kubernetes tools and components map to what we have dis-\ncussed about platforms and cloud providers. \n`kubectl` CLI\nKubernetes SDKs\n<HTTP requests>\nKubernetes APIs\nKubernetes Dashboard\nKubernetes Cluster\nFigure 1.10    Kubernetes offer us a CLI, SDKs and dashboards, is it a platform? \nKubernetes can be extended, and that’s why this book will look into specific projects \nusing the Kubernetes APIs, tools, or internal mechanisms to solve generic challenges \nlike continuous integration, continuous delivery, provisioning cloud resources, moni-\ntoring and observability, and developer experience, among others. \n1.2.1\t\nThe Kubernetes adoption journey\nIt is fundamental that, no matter which tools platform teams choose, we abstract all the \ncomplexity and all the glue code we write to make these tools work together from the \nteams consuming these tools. Remember that application development teams, testing \nteams, and operations teams, among others, have different priorities and concerns. As \npart of the Kubernetes adoption journey, we must be we must be aware that not all the \nteams consuming these tools to be experts on Kubernetes. \nExtending Kubernetes with your custom extensions is one way to make Kubernetes \nwork for your organization-specific challenges. Remember that no matter which tools \nyou write or install in your Kubernetes clusters, the operations teams will need to run \nthem in your production environments and keep them running at scale. Each new tool \nor extension you write will require training the consumer teams to understand how \nthese tools work and for which scenarios they were designed. It is quite easy to end up \n\n\n\t\n13\nPlatforms built on top of Kubernetes\nin a situation where you have chosen 10 different tools that need to be integrated, and \nglue code needs to be written. Platform teams always evaluate the trade-offs between \nwriting glue code, rewriting a more tailored solution for their use case, or extending \nexisting tools. I strongly recommend you get familiar with the tools in the CNCF land-\nscape (https://landscape.cncf.io) to avoid going in a direction where every tool you \nuse is custom-made for your organization, meaning that you will need to maintain inter-\nnally all these tools in the long run.\nAbstracting away complexity is a key part of building platforms. A clear contract with \nyour teams specifying what the platform can do for them is crucial to successful plat-\nform engineering initiatives. These contracts are exposed as APIs that teams can inter-\nact with programmatically, using a dashboard, or via automation. \nFigure 1.11 shows a typical Kubernetes adoption journey toward platform engineer-\ning. The journey starts by adopting Kubernetes as the target platform to run your work-\nloads, followed by researching and selecting tools, usually from the CNCF Landscape. \nWhen initial tools are selected, your platform starts to shape up, and some investment \nis needed to configure and make these tools work for your teams. Finally, all these con-\nfigurations and tools selected can be hidden behind a friendlier platform API, allowing \nend users to focus on their workflows instead of trying to understand every detail about \nthe tools and glue code forming the platform. \nKubernetes\nCNCF \nLandscape\nTools and \nFrameworks\nYour Platform \nChoices\nYour Platform \nGlue Code\nTools and \nFrameworks\nYour Platform \nAPIs\nApplication \nDevelopment Teams\nPlatform Engineering Team\nFigure 1.11    Platform journey on Kubernetes\nGoing through this journey, we can define platforms as how we encode the knowledge \nit takes to provide our development teams with all the workflows they need to be pro-\nductive. The operational knowledge and the decisions on the tools used to implement \nthese workflows are encapsulated behind a contract materialized as the platform APIs. \nThese APIs can use the Kubernetes APIs to provide a declarative approach, but this \nis optional. Some platforms hide that the platform uses Kubernetes, which can also \nreduce the cognitive load from teams interacting with it.  \n\n\n14\nChapter 1  (The rise of) platforms on top of Kubernetes \nWhile I’ve tried to cover from a very high level what a platform is, I prefer to delegate \nall the formal definitions to working groups in the cloud-native space that are in charge \nof defining and keeping terms updated. I strongly suggest you check the App Delivery \nTAG - Platform Working Group from the CNCF white paper on platforms (https://\ntag-app-delivery.cncf.io/whitepapers/platforms/), which takes on the work of trying to \ndefine what platforms are.\nTheir current definition, at the time of writing this book, reads as follows: “A plat-\nform for cloud-native computing is an integrated collection of capabilities defined and \npresented according to the needs of the platform’s users. It is a cross-cutting layer that \nensures a consistent experience for acquiring and integrating typical capabilities and \nservices for a broad set of applications and use cases. A good platform provides consis-\ntent user experiences for using and managing its capabilities and services, such as web \nportals, project templates, and self-service APIs.”\nIn this book, we will embark on this journey of building an example platform by look-\ning at the available cloud-native tools to see how they can provide different platform \ncapabilities. But where do we find these tools? Do these tools work together? How do we \nchoose between different alternatives? Let’s take a quick look at the CNCF Landscape.\n1.2.2\t\nThe CNCF Landscape puzzle\nKeeping up with cloud provider services is a full-time job, and each cloud provider \nhosts a yearly conference and minor events to announce what is new and shiny. In the \nKubernetes and cloud native space, you can expect the same. The CNCF landscape is \ncontinuously expanding and evolving. As you can see in figure 1.12, the landscape is \nhuge and very difficult to read at first sight.\nFigure 1.12    The CNCF landscape (Source: https://landscape.cncf.io)\n\n\n\t\n15\nPlatforms built on top of Kubernetes\nA significant difference compared to cloud provider-offered services is the public and \ncommunity-driven maturity model that each project in the CNCF must follow to obtain \nthe graduated status. Each project’s maturity journey is independent of any cloud pro-\nvider, and you, as an individual or as an organization, can influence where the project \nis going or how fast it gets there.\nWhile cloud providers have defined the cloud’s shape, most are now involved in \nCNCF projects pushing for these open initiatives to succeed. They are working on tools \nthat can be used across cloud providers, removing barriers and allowing innovation in \nthe open instead of behind each cloud provider’s door. Figure 1.13 shows how Kuber-\nnetes enabled the cloud native innovation ecosystem to flourish outside cloud provid-\ners. Cloud providers haven’t stopped offering new, more specialized services, but in the \nlast five years, we have seen a shift toward improved collaborations across cloud provid-\ners and software vendors to develop new tools and innovation in the open.\nCNCF Ecosystem\nCI/CD Tools\nObservability Tools\nOperations Tools\nMachine Learning \nTools\nServerless Tools\nSecurity Tools\nStorage Tools\nMicrosoft Azure\nAmazon AWS\nGoogle Cloud \nPlatform\nAlibaba Cloud\nIBM Cloud\nKubernetes\nBuilding Blocks to run workloads\nServices, Deployments, Ingress, Jobs, NetworkPolicies, etc\nCommunity Driven \nEcosystem\nVendor Driven \nServices\nFigure 1.13    Kubernetes enabling a multi-cloud cloud-native ecosystem\nA common denominator from most CNCF-hosted projects is that they all work with \nKubernetes, extending it and solving high-level challenges closer to development \nteams. The CNCF has reached a point where more and more tools are being created to \nsimplify development tools and workflows. Interestingly, most of these tools don’t focus \njust on developers. They also enable operation teams and system integrators to glue \nprojects together and define new developer experiences native to Kubernetes. Devel-\nopment teams don’t need to worry about the tooling and integrations required for \ntheir day-to-day workflows. The increased maturity level of the communities involved \n\n\n16\nChapter 1  (The rise of) platforms on top of Kubernetes \nin the CNCF landscape and this push to simplify how development teams interact with \nall these tools gave birth to the conversations around platform engineering. The next \nsection will explore these conversations, why you can’t buy a platform, and how we will \nexplore this large ecosystem in the rest of this book.  \n1.3\t\nPlatform engineering\nIn the same way that cloud providers have internal teams defining which new services \nwill be offered, how these services are going to scale, and which tools and APIs need to \nbe exposed to their customers, it became clear that organizations can benefit from hav-\ning their internal platform engineering teams. These teams help enable development \nteams by deciding the tool selection that makes sense to best solve software delivery \nproblems and speed up the process. \nA common trend is having a dedicated platform engineering team to define these \nAPIs and make platform-wide decisions. The platform team collaborates with devel-\nopment teams, operations teams, and cloud provider experts to implement tools that \nmeet the needs of the workflows application teams. Besides having a dedicated plat-\nform engineering team, a key cultural change promoted by the book Team Topologies \n(https://teamtopologies.com/) is to treat the platform itself as an internal product \nand your development teams as customers. This is not new, but it pushes the platform \nteam to focus on these internal development teams’ satisfaction while using the plat-\nform’s tools. \nFigure 1.14 shows how application development teams (App Dev Teams) can focus \non working on new features using their preferred tools while the Platform Team creates \nGolden Paths (to production), which all the work produced by these teams to validate \nthe functionality and deliver these changes to our organization customers/end users. \nPlatform Team\nPlatform\nApp Dev \nTeams\nWork\nTools\nWork\nFeatures\nGolden \nPaths\nProduction \nEnvironment\nCustomer / \nEnd User\nFigure 1.14    Platform teams take the work done by developers safely to production.\n\n\n\t\n17\nPlatform engineering\nThis relationship between the platform and development teams creates synergy, focus-\ning on improving the entire organization’s software delivery practices. By creating \nGolden Paths, the platform doesn’t stop on the day-to-day development tasks. Still, it \nalso aims to automate how the changes made by development teams reach our organi-\nzation’s end customers/consumers. \nBy adding visibility to the whole process, you can help the entire organization under-\nstand and see how teams produce new features and when those features will be available \nto our end users. This can be very valuable business decisions, marketing, and for plan-\nning in general. \n1.3.1\t\nWhy can’t I just buy a platform?\nUnfortunately, you can’t buy an off-the-shelf platform to solve all your organization’s \nneeds. As we discussed, you can buy one or more cloud provider services, but your \ninternal teams will need to figure out which services and how they must be combined \nto solve specific problems. The exercise of figuring out which tools and services fit your \norganization’s needs and compliance requirements and how to encapsulate these deci-\nsions behind interfaces that teams can consume using a self-service approach is usually \nsomething you can’t buy. \nThere are tools designed with this situation in mind that try to enable platform teams \nto do less gluing by implementing a set of out-of-the-box workflows or having a very \nopinionated set of tools they support. Tools in this category that are also heavily using \nand extending Kubernetes are Red Hat OpenShift (https://www.redhat.com/en/ \ntechnologies/cloud-computing/openshift) and VMware Tanzu (https://tanzu.vmware \n.com/tanzu). These tools are very attractive to Chief Technology Officers (CTOs) and \narchitects because they cover most topics they need solutions for, such as CI/CD, oper-\nations, developer tooling, and frameworks. Based on my experience, while these tools \nare helpful in many scenarios, platform teams require flexibility in their chosen tools to \nfit their existing practices. At the end of the day, if you buy these tools, your teams will \nalso need to spend time learning them, which is why these tools like Red Hat OpenShift \nand VMware Tanzu are sold with consulting services, which is another cost to factor \ninto the equation. For medium and large organizations, adopting and adapting these \nopinionated off-the-shelf tools might require changes in well-defined workflows and \npractices that are already well-known to your teams. For smaller and less-mature organi-\nzations, these tools can save a lot of time by reducing the number of choices that teams \nwill face when getting started with new initiatives, but the cost of these tools and services \nmight be too high for a young organization.\nFigure 1.15 shows how the journey changes depending on which tools the platform \nteam chooses. These Kubernetes distributions (OpenShift, Tanzu, among others) can \nlimit the number of choices the platform teams can make, but they can also save time \nand come with services such as training and consulting that your teams can rely on.\n\n\n18\nChapter 1  (The rise of) platforms on top of Kubernetes \nKubernetes\nCNCF \nLandscape\nKubernetes \nDistribution\nYour Platform \nChoices\nYour Platform \nAPIs\nTools and \nFrameworks\nTools and \nFrameworks\nKubernetes \nDistribution Provider\nYour Platform Glue \nCode\nPlatform Engineering \nTeam\nKubernetes \nDistribution\nTools and \nFrameworks\nFigure 1.15    Building platforms on top of Kubernetes distributions\nNo matter if you are already a customer of these tools, you will still be in charge of \nbuilding a platform on top of these tools. If you have Red Hat OpenShift or VMware \nTanzu available to your teams, I strongly encourage you to familiarize yourself with the \ntools they support and their design choices and decisions. Aligning with the tools you \nhave and consulting with their architects might help you find shortcuts to build your \nlayers on top of these tools. \nA word of caution: It is crucial to notice that these tools can be considered Kubernetes \ndistributions. Distributions in the same sense as Linux distributions mean that I expect \nmore and more distributions to appear, tackling different challenges and use cases. \nTools like K0s and MicroK8s for IoT and edge cases are other examples. While you can \nadopt any of these distributions, ensure they align with your organization’s goals. \nBecause I want to keep this book as practical as possible, we will look at a simple \napplication we will use to go on our journey in the next section. We will not build a \ngeneric platform for a generic use case. We will build an example platform demonstrat-\ning the concepts covered in the previous sections. Having a concrete example you can \nrun, experiment with, and change should help you map the topics discussed to your \nday-to-day challenges. The application introduced in the next section highlights the \nchallenges you will face while creating, building, and maintaining distributed applica-\ntions in most business domains. Hence, the example platform we will build to support \nthis application should map to the challenges you will face in your business domain.\n1.4\t\nThe need for a walking skeleton\nIn the Kubernetes ecosystem, it is common to need to integrate at least 10 or more \nprojects or frameworks to deliver a simple PoC (proof of concept). This work can cover \ntopics such as building projects into containers that can run inside Kubernetes and \nrouting traffic to the REST endpoints provided by each service. If you want to exper-\niment with new projects to see if they fit into your ecosystem, build a PoC to validate \nyour understanding of how this new project/framework works and how it will save you \nand your team time. \nFor this book, I have created a simple “walking skeleton.” This cloud-native appli-\ncation goes beyond being a simple PoC and allows you to explore how different \n",
      "page_number": 28
    },
    {
      "number": 5,
      "title": "Segment 5 (pages 38-45)",
      "start_page": 38,
      "end_page": 45,
      "detection_method": "topic_boundary",
      "content": "\t\n19\nThe need for a walking skeleton\narchitectural patterns can be applied. It also lets you test how different tools and frame-\nworks can be integrated without changing your projects for experimentation. I’ve pre-\nferred the term “walking skeleton” instead of “proof of concept” or “demo application”, \nas the term walking skeleton reflects more closely the intention of the application intro-\nduced in this section.\nThe primary purpose of this walking skeleton is to highlight how to solve very spe-\ncific challenges from an architectural point of view, the requirements that your applica-\ntions will need, and the delivery practices’ angle. You should be able to map how these \nchallenges are solved in the sample cloud-native application to your specific domain. \nChallenges will not always be the same, but I want to highlight the principles behind \neach proposed solution and the approach taken to guide your decisions.\nWith this walking skeleton, you can also figure out the minimum viable product you \nneed and deploy it quickly to a production environment where you can improve it. \nBy taking the walking skeleton to a production environment, you can gain valuable \ninsights into what you will need for other services and from an infrastructure perspec-\ntive. It can also help your teams understand what it takes to work with these projects and \nhow and where things can go wrong. \nThe technology stack used to build the walking skeleton is unimportant. It is more \nimportant to understand how the pieces fit together and what tools and practices can \nenable each team behind a service (or a set of services) to evolve safely and efficiently.  \n1.4.1\t\nBuilding a Conference application\nThroughout this book, you will be working with a Conference application. This Confer-\nence application can be deployed in different environments to serve different events. \nThis application relies on containers, Kubernetes, and tools that will work across any \nmajor cloud providers and on-prem Kubernetes installations. \nFigure 1.16 shows what the application’s main page looks like.\nFigure 1.16    Conference application home page\n\n\n20\nChapter 1  (The rise of) platforms on top of Kubernetes \nThe Conference application allows users to manage conference events, and it provides \na basic landing page, an Agenda page where all the approved talks will be listed, and a \nCall for Proposals form where potential speakers can submit their talk proposals. The \napplication also allows conference organizers to do admin tasks, such as reviewing sub-\nmitted proposals and approving or rejecting them (see figure 1.17). \nFigure 1.17    Conference application Back Office page\nThis application is composed of a set of services that have different responsibilities. \nFigure 1.18 shows the main components of the application that you control—in other \nwords, the services that you and your team will be changing and delivering. \nEnd User\nFrontend\nNextJS\nFrontend(Backend)\nAgenda Service\nC4P Service\nNotifications \nService\nFigure 1.18    Conference application services. The end user interacts with the frontend that routes \nrequests to all the backend services.\nThe team has created these services to implement a basic walking skeleton with func-\ntionality that demonstrates business value. Here is a brief description of each service:\n¡ Frontend: This service is the main entry point for your users to access the applica-\ntion. For this reason, the service hosts a NextJS application (HTML, JavaScript, \nand CSS files) that the client’s browser will download. The client-side application \n\n\n\t\n21\nThe need for a walking skeleton\ninteracts with a backend service that accepts the requests from the browser and \nroutes each request to one or more backend services. \n¡ Agenda service: This service deals with listing all the talks that were approved for \nthe conference. This service needs to be highly available during the conference \ndates, because the attendees will be hitting this service several times during the \nday to move between sessions. \n¡ Call for Proposals (C4P): This service contains the logic to deal with Call for Pro-\nposals use case (C4P for short) when the conference is being organized. This \nfunctionality allows potential speakers to submit talk proposals that the confer-\nence organizers will review and decide which ones to include in the conference \nagenda.\n¡ Notifications service: This service enables the conference organizers to send notifi-\ncations to attendees and speakers. \nFigure 1.19 shows the Call for Proposals flow that was selected by the team to build \nthe walking skeleton and validate their assumptions about how the Conference appli-\ncation will work. By implementing this use case end to end, the team can validate its \nchosen technology stack and architectural assumptions. \nConference \nOrganizer\nPotential \nSpeaker\nMain Site\nBack Office\nC4P Service\nNotifications \nService\nAgenda Service\n#1 A potential \nspeaker submits a \nnew Proposal from \nthe Conference Site\n#2 A conference organizer \nreview the proposal in the \nConference Back Office and \ndecides to approve or reject it\n#3 An automated \nnotification is sent to the \npotential speaker about \nthe decision made by \nthe organizers\n#4 Only if the proposal is \napproved is automatically \nadded to the Conference \nAgenda page\nFrontend\nFigure 1.19    Call for Proposals use case\nAfter implementing the basics of the Call for Proposals use case, the team can decide \nwhat use case to implement next. Do the conference organizers need to manage spon-\nsors? Do the speakers need a dedicated profile page? Adding new features or services \nshould be straightforward because the base building blocks are in place.\nWhile looking at how these use cases are implemented, you need to consider also \nhow to coordinate across teams when new use cases will be implemented or when \nchanges need to be introduced. To improve collaboration, you need visibility, and you \nneed to understand how the application is working.\n\n\n22\nChapter 1  (The rise of) platforms on top of Kubernetes \nYou also need to consider the operation side of this cloud-native application. You \ncan imagine there will be a period when the application will open the Call for Proposals \nrequest for potential speakers to submit proposals, then closer to the conference date, \nopen the attendee registration page, etc. \nThroughout this book, I will encourage you to experiment by adding new services \nand implementing new use cases. In chapter 2, when you deploy the application to a \nKubernetes cluster, you will inspect how these services are configured to work, how the \ndata flows between the different services, and how to scale the services. \nBy playing around with a fictional application, you are free to change each service’s \ninternals, use different tools and compare results or even have different versions of \neach service to try in parallel. Each service provides all the resources needed to deploy \nthese services to your environment. In chapters 3 and 4, we will go deeper into each \nservice to understand how to build and deploy each service so teams can change the \ncurrent behavior and create and deploy new releases.\nBefore deploying this cloud-native conference application, it is important to men-\ntion some of the main differences with bundling all these functionalities in a single \nmonolithic application. \nBut what about if the Conference application was created using a monolith \napproach? Let’s briefly discuss what the main differences would be.  \n1.4.2\t\nDifferences between a monolith and a distributed set of services\nUnderstanding the differences between having a single monolithic application and a \nfully distributed set of services is critical to grasping why the increased complexity is \nworth the effort. If you are still working with monolithic applications that you want to \nsplit up to use a distributed approach, this section highlights the main differences you \nwill encounter. \nFigure 1.20 shows a monolithic application implementing the same use case dis-\ncussed before, but in this scenario, different teams working on different features will \nshare the same codebase. There are no explicit requirements for strong interfaces \nbetween internal services when developing a monolithic application. It’s optional to \nseparate the logic of different functionalities in well-encapsulated modules. The lack \nof interfaces and overlap between functionality pushes the teams making changes on \nthe application to have complex coordination strategies to ensure that features don’t \nconflict and that changes can be merged in the codebase.\nConference Application\nFrontend\nC4P Service\nAgenda Service\nNotifications \nService\nFigure 1.20    In a monolith application, all the logic to implement different use cases are bundled \ntogether. This push different teams to work on the same codebase and requires them to have complex \ncoordination practices to avoid conflicting changes.\n\n\n\t\n23\nThe need for a walking skeleton\nFunctionally wise, they are the same and you can do the same amount of use cases, but \nthe monolith application presented some drawbacks that you might be experiencing \nwith your monolith applications already. The following points highlight the benefits of \nthe cloud-native application that we will use in this book and some disadvantages asso-\nciated with a parallel-universe alternative monolithic implementation: \n¡ Now services can evolve independently, teams are empowered to go faster, and there is no \nbottleneck at the codebase level: In the monolithic application, there is a single source \ncode repository for different teams to work on, there was a single continuous \nintegration pipeline for the project which was slow, and teams were using feature \nbranches that caused problems with complex merges. \n¡ Now the application can scale differently for different scenarios: From a scalability \nperspective, each service can be scaled depending on the load level it experi-\nences. With the monolith application, the operations team can only create new \ninstances of the entire application if it need to scale just a single functionality. \nFine-grained control over how different functionalities are scaled can be a signifi-\ncant differentiator for your use case, but you must do your due diligence. \n¡ The cloud-native version is much more complex, because it is a distributed system: It \nuses the flexibility and characteristics of the cloud infrastructure much better, \nallowing the operation teams to use tools to manage this complexity and the \nday-to-day operations. Creating your in-house mechanism to operate large appli-\ncations was much more common when building monolithic applications. In \ncloud-native environments, there are a lot of tools provided by cloud providers \nand open-source projects that can be used to operate and monitor cloud-native \napplications. \n¡ Welcome polyglotism: Each service can be built using a different programming lan-\nguage or different frameworks. With the monolith, application developers were \nstuck in old versions of libraries, because changing or upgrading a library usu-\nally involved large refactoring, and the whole application needed to be tested \nto guarantee that the application will not break. In a cloud-native approach, ser-\nvices are not forced to use a single technology stack. This allowed teams to be \nmore autonomous in choosing their tools, which can speed up delivery times in \nsome situations. \n¡ All or nothing with the monolith: If the monolith application went down, the entire \napplication is down, and users couldn’t access anything. With the cloud-native \nversion, users can still access the application even if services are down. The exam-\nple walking skeleton shows how to support degraded services by adopting popu-\nlar tools. By using Kubernetes, which was designed to monitor your services and \ntake action in case a service is misbehaving, the platform will try to self-heal your \napplications. \n¡ Each conference event required a different version of the monolith: When dealing with \ndifferent events, each conference required a version of the monolith slightly dif-\nferent from the other events. This causes divergent codebases and duplication \n\n\n24\nChapter 1  (The rise of) platforms on top of Kubernetes \nof the entire project. Most of the changes done for a conference were lost when \nthe event was done. In the cloud-native approach, we promote reusability by hav-\ning fine-grained services that can be swapped, avoiding duplication of the whole \napplication. \nWhile the monolith application is much more straightforward to operate and develop \nthan the cloud-native application, the remainder of the book focuses on understand-\ning and reducing the complexity of building a distributed application. We’ll do that by \nadopting the right tools and practices, which will unlock your teams to be more inde-\npendent and efficient while promoting resiliency and robustness to your applications. \nIf you are currently working with a monolith application, I hope this book helps you \nto compare different approaches and introduces you to the tools and practices that are \nrequired for building distributed applications.  \n1.4.3\t\nOur walking skeleton and building platforms\nNow that we have a simple application that our customers will be using, we can focus \non understanding all the tools our teams will need to improve these services continu-\nously. The platforms we will cover in this book are those organizations that will build \nfor domain-specific purposes, not generic ones. By creating our walking skeleton for \na specific scenario, we can mimic a platform that optimizes tools and workflows to \nimprove how software gets delivered for those teams. Our walking skeleton is not a \nsimple “Hello World” application, so it allows for more experimentation, writing more \ncomplex features, and using tools to make the application more robust. \nWe will now embark on a cloud-native journey. First, we will look into how distributed \napplications run on top of Kubernetes, what Kubernetes provides, and its challenges. \nRight after that, we will start looking into tools that will extend the basic Kubernetes \nfeatures to assist us in building, deploying, and running our cloud-native applications.\nLater on, in chapter 6, after evaluating some of the challenges of building and deliv-\nering distributed applications, we will build our platform walking skeleton that will help \nteams create new features to work with the existing application in a safe environment, \nwhere they can do their day-to-day work without conflicting with other teams. Once we \nhave our platform walking skeleton, we will build and offer higher-level platform capa-\nbilities to enable our teams to be more productive and reduce their need to understand \nthe complexity of Kubernetes and all the tools we will discuss in this book. \nFinally, to close the book, we will look at how to measure how good the platforms that \nwe are building are. As with any software, we need to measure it to ensure that new tools \nor changes we introduce make things better and not worse.\nThis journey will push us to make hard decisions and choices that will become critical \nfor our platform engineering practices. The following list covers the main milestones in \nthis journey without going into the details of the specific tools covered in each chapter.\n¡ Chapter 2: Cloud-native application challenges: After getting the Conference applica-\ntion up and running in a Kubernetes cluster, we will analyze the main and most \ncommon challenges you will face when working on and running cloud-native \n\n\n\t\n25\nThe need for a walking skeleton\napplications on top of Kubernetes. In this chapter, you will inspect the applica-\ntion from a runtime perspective and try to break it in different ways to see how it \nbehaves when things go wrong.\n¡ Chapter 3: Service pipelines: Building cloud-native applications: Once the applica-\ntion is up and running, you and your teams will change the application’s ser-\nvices to add new features or fix bugs. This chapter covers what it takes to build \nthese application services, including the latest changes using service pipelines \nto create a release of the artifacts needed to deploy these new versions into live \nenvironments.\n¡ Chapter 4: Environment pipelines: Deploying cloud-native applications: If we sort out \nhow to package and release new versions of our services, then we need to have a \nclear strategy on how to promote these new versions to different environments so \nthey can be tested and validated before facing real customers. This chapter cov-\ners the concept of environment pipelines and a popular trend in the cloud-native \ncommunity called GitOps to configure and deploy applications across different \nenvironments. \n¡ Chapter 5: Multi-cloud (app) infrastructure: Your applications can’t run in isolation. \nApplication services need application infrastructure components, such as data-\nbases, message brokers, identity services, etc., to work. This chapter focuses on \nhow to provision the components that our application’s services need using a \nmulti-cloud and Kubernetes-native approach.\n¡ Chapter 6: Let’s build a platform on top of Kubernetes: Once we understand how the \napplication runs, how it is built and deployed, and how it connects to cloud \ninfrastructure, we will focus our attention on abstracting the complexity intro-\nduced by all the tools that we are using from the teams making changes to the \napplication. We don’t want our development teams to get distracted setting up \ncloud-provider accounts, configuring the servers where the build pipelines will \nrun, or worrying about where their environment is running. Welcome to the plat-\nform engineering team!\n¡ Chapter 7: Platform capabilities I: Shared application concerns: How can we reduce \nfriction and dependencies between application and operation teams? How can \nwe decouple even further the logic of our applications from the components that \nthese applications need to run? This chapter covers a set of platform capabilities \nthat enable application developers to focus on writing code. The platform team \ncan concentrate on deciding how to wire all the components required by the \napplication and then expose simple and standardized APIs that developers can \nconsume. \n¡ Chapter 8: Platform capabilities II: Enabling teams to experiment: Now that we have a \nplatform that takes care of provisioning environments for our teams to do their \nwork, what else can the platform do for the application development teams? If \nyou enable your teams to run more than a single version of your application’s \nservices simultaneously, new features or fixes can be rolled out incrementally. \n\n\n26\nChapter 1  (The rise of) platforms on top of Kubernetes \nHaving room for experimentation allows the organization to find issues sooner \nand reduces each release’s associated stress. This chapter covers how to imple-\nment different release strategies for your cloud-native applications. \n¡ Chapter 9: Measuring your platforms: Platforms are as good as the improvements \nthey bring to the organization. We need to measure our platform performance \nto see how well it’s doing, because we should use a continuous improvement \napproach to ensure that the tools we use are helping our teams deliver faster and \nmore efficiently. This chapter focuses on using the DORA metrics to understand \nhow well the organization is delivering software and how platform changes can \nimprove the throughput of our delivery pipelines. \nNow that you know what is coming, let’s deploy our cloud-native Conference \napplication.  \nSummary\n¡ (Cloud) platforms provide a set of services for teams to build their domain-spe-\ncific applications.\n¡ Platforms usually offer three main features: APIs, dashboards, and SDKs for dif-\nferent teams to use whatever fits their workflows. \n¡ Cloud platforms provide a pay-as-you-go model to consume hardware and soft-\nware. The higher you go up the stack, the more expensive the service will be. \n¡ Kubernetes offers the basic building blocks to build platforms on top in a way \nthat we can remain independent of the underlying cloud provider and even \ndeploy our platforms on-premises.\n¡ The Cloud Native and Computing Foundation promotes and fosters collabora-\ntions between open-source projects in the cloud-native space. Keeping track of \nwhat is going on in these communities is a full-time job.\n¡ Platform engineering on Kubernetes (specifically for this book) helps manage \nthe complexity of choosing which tools and practices teams need to adopt to be \nmore efficient at delivering software that will run on top of Kubernetes.\n",
      "page_number": 38
    },
    {
      "number": 6,
      "title": "Segment 6 (pages 46-55)",
      "start_page": 46,
      "end_page": 55,
      "detection_method": "topic_boundary",
      "content": "27\n2\nCloud-native \napplication challenges\nThis chapter covers\n¡ Working with a cloud-native application running \t\n\t in a Kubernetes cluster\n¡ Choosing between local and remote  \n\t Kubernetes clusters\n¡ Understanding the main components and  \n\t Kubernetes resources\n¡ Understanding the challenges of working with \t\n\t cloud-native applications\nWhen I want to try something new, a framework, a new tool, or just a new applica-\ntion, I tend to be impatient; I want to see it running immediately. Then, when it is \nrunning, I want to dig deeper and understand how it works. I break things to exper-\niment and validate that I understand how these tools, frameworks, or applications \nwork internally. That is the sort of approach we’ll take in this chapter! \nTo have a cloud-native application up and running, you will need a Kubernetes \ncluster. In this chapter, you will work with a local Kubernetes cluster using a project \ncalled KinD (Kubernetes in Docker, https://kind.sigs.k8s.io/). This local cluster will \nallow you to deploy applications locally for development and experimentation. To \n\n\n28\nChapter 2  Cloud-native application challenges \ninstall a set of microservices, you will use Helm, a project that helps package, deploy, \nand distribute Kubernetes applications. You will install the walking skeleton services \nintroduced in chapter 1, which implements a Conference application. \nOnce the services for the Conference application are up and running, you will \ninspect its Kubernetes resources to understand how the application was architected \nand its inner workings by using kubectl. Once you get an overview of the main pieces \ninside the application, you will jump ahead to try to break the application, finding com-\nmon challenges and pitfalls that your cloud-native applications can face. This chapter \ncovers the basics of running cloud-native applications in a modern technology stack \nbased on Kubernetes, highlighting the good and the bad that come with developing, \ndeploying, and maintaining distributed applications. The following chapters tackle \nthese associated challenges by looking into projects whose main focus is to speed up \nand make more efficient the delivery of your projects.\n2.1\t\nRunning our cloud-native applications\nTo understand the innate challenges of cloud-native applications, we need to be able \nto experiment with a simple example that we can control, configure, and break for \neducational purposes. In the context of cloud-native applications, “simple” cannot be \na single service, so for simple applications we will need to deal with the complexities of \ndistributed applications such as networking latency, resilience to failure on some of the \napplications’ services, and eventual inconsistencies. To run a cloud-native application, \nin this case, the walking skeleton introduced in chapter 1, you need a Kubernetes clus-\nter. Where this cluster is going to be installed and who will be responsible for setting it \nup are the first questions that developers will have. It is quite common for developers \nto want to run things locally, on their laptop or workstation, and with Kubernetes, this \nis possible—but is it optimal? Let’s analyze the advantages and disadvantages of run-\nning a local cluster against other options.\n2.1.1\t\nChoosing the best Kubernetes environment for you\nThis section doesn’t cover a comprehensive list of all the available Kubernetes flavors, \nbut it focuses on common patterns in how Kubernetes clusters can be provisioned \nand managed. There are three possible alternatives—all of them with advantages and \ndrawbacks:\n¡ Local Kubernetes in your laptop/desktop computer: I tend to discourage people from \nrunning Kubernetes on their laptops. As you will see in the rest of the book, \nrunning your software in similar environments to production is highly recom-\nmended to avoid problems that can be summed up as “but it works on my laptop.” \nThese problems are mostly caused by the fact that when you run Kubernetes on \nyour laptop, you are not running on top of a real cluster of machines. Hence, \nthere are no network round-trips and no real load balancing. \n–\t Pros: Lightweight, fast to get started, good for testing, experimenting, and \nlocal development. Good for running small applications.\n\n\n\t\n29\nRunning our cloud-native applications\n–\t Cons: Not a real cluster, it behaves differently, and has reduced hardware to \nrun workloads. You will not be able to run a large application on your laptop. \n¡ On-premise Kubernetes in your data center: This is a typical option for companies with \nprivate clouds. This approach requires the company to have a dedicated team \nand hardware to create, maintain, and operate these clusters. If your company is \nmature enough, it might have a self-service platform that allows users to request \nnew Kubernetes clusters on demand. \n–\t Pros: A real cluster on top of real hardware will behave closer to how a produc-\ntion cluster will work. You will have a clear picture of which features are avail-\nable for your applications to use in your environments. \n–\t Cons: It requires a mature operation team to set up clusters and give creden-\ntials to users, and it requires dedicated hardware for developers to work on \ntheir experiments.\n¡ Managed service Kubernetes offering in a cloud provider: I tend to be in favor of this \napproach, because using a cloud provider service allows you to pay for what you \nuse, and services like Google Kubernetes Engine (GKE), Azure AKS, and AWS \nEKS are all built with a self-service approach in mind, enabling developers to spin \nup new Kubernetes clusters quickly. There are two primary considerations:\n1\t You need to choose one cloud provider and have an account with a big credit \ncard to pay for what your teams will consume. This might involve setting up \nsome caps in the budget and defining who has access. By selecting a cloud \nprovider, you might be in a vendor lock-in situation if you are not careful. \n2\t Everything is remote, and for developers and other teams that are used to \nwork locally, this is too big of a change. It takes time for developers to adapt, \nbecause the tools and most of the workloads will run remotely. This is also an \nadvantage, because the environments used by your developers and the appli-\ncations that they are deploying are going to behave as if they were running in \na production environment.\n–\t Pros: You are working with real (fully fledged) clusters. You can define how \nmany resources you need for your tasks, and when you are done, you can \ndelete them to release resources. You don’t need to invest in hardware up \nfront.\n–\t Cons: You need a potentially big credit card, and you need your developers to \nwork against remote clusters and services.\nA final recommendation is to check the following repository, which contains free \nKubernetes credits in major cloud providers: https://github.com/learnk8s/free \n-kubernetes. I’ve created this repository to keep an updated list of these free trials that \nyou can use to get all the examples in the book up and running on top of real infra-\nstructure. Figure 2.1 summarizes the information contained in the previous bullet \npoints.\n\n\n30\nChapter 2  Cloud-native application challenges \nDevelopers are \nused to work locally.\nThese are in-house \nclusters but they feel \nremote to developers.\nThese are fully remote \nsetups, developers need to \nget used to new workflows.\nLocal\nPros\n•  Lightweight\n•  Fast to get started\n•  Good for local development\n•  Good for testing (CI)\n•  Good for small applications\nCons\n•  Limited capacity\n•  It doesn’t behave as a real  \n \n \ncluster\n•  Good network bandwidth is   \n \nrequired to download containers  \n \nto your laptop\nOn Premises\nPros\n•  Real cluster on top of real  \n \n \nmachines\n•  It behaves closer to a Production  \n \nEnvironment\n•  Provide a remote environment  \n \nfor development teams to work\nCons\n•  Requires you to have and  \n \n \nmaintain dedicated hardware\n•  Requires a mature team to  \n \n \nprovision the cluster and  \n \n \ndistribute credentials\n•  It might lack integrations and   \n \nextra features provided by cloud  \n \nproviders\n•  Difficult to scale up if you require  \n \na large number of clusters\nCloud Provider\nPros\n•  Fully fledged managed clusters\n•  You don’t need to deal with  \n \n \nhardware\n•  Easy to scale and manage\n•  Extra services provided (backup,  \n \napp infrastructure, security, etc.)\n•  Pay-as-you-go model\nCons\n•  Difficult to estimate costs, you  \n \nmight need a big credit card to  \n \npay for what you use\n•  Possible vendor lock-in\n•  Cloud-Provider specific expertise  \n \nrequired\nFigure 2.1    Kubernetes cluster Local vs. Remote setups. \nWhile these three options are all valid and have drawbacks, in the next sections, you will \nuse Kubernetes KinD (Kubernetes in Docker, https://kind.sigs.k8s.io/) to deploy the \nwalking skeleton introduced in chapter 1 in a local Kubernetes environment running on \nyour laptop/pc. Check the step-by-step tutorial located at https://github.com/salaboy/ \nplatforms-on-k8s/tree/main/chapter-2#creating-a-local-cluster-with-kubernetes-kind \nto create your local KinD cluster that we will use to deploy our walking skeleton, the \nConference application. \nNotice that the tutorial creates a local KinD cluster that simulates having three nodes \nand a special port mapping to allow our Ingress controller to route incoming traffic \nthat we will send to http://localhost.\n2.1.2\t\nInstalling the walking skeleton\nTo run containerized applications on top of Kubernetes, you will need to have each \nof the services packaged as a container image, plus you will need to define how these \ncontainers will be configured to run in your Kubernetes cluster. To do so, Kubernetes \nallows you to define different kinds of resources (using YAML format) to configure \nhow your containers will run and communicate with each other. The most common \nkinds of resources are: \n¡ Deployments: Declaratively define how many replicas of your container need to be \nup for your application to work correctly. Deployments also allow us to choose \nwhich container (or containers) we want to run and how these containers must \nbe configured (using environment variables). \n\n\n\t\n31\nRunning our cloud-native applications\n¡ Services: Declaratively define a high-level abstraction to route traffic to the con-\ntainers created by your deployments. It also acts as a load balancer between the \nreplicas inside your deployments. Services enable other services and applications \ninside the cluster to use the service name instead of the physical IP address of the \ncontainers to communicate, providing what is known as service discovery. \n¡ Ingress: Declaratively define a route for routing traffic from outside the cluster to \nservices inside the cluster. Using Ingress definitions, we can expose the services \nthat are required by client applications running outside the cluster. \n¡ ConfigMap/secrets: Declaratively define and store configuration objects to set up \nour service instances. Secrets are considered sensitive information that should \nhave protected access. \nThese YAML files will be complex and hard to manage if you have large applications \nwith tens or hundreds of services. Keeping track of the changes and deploying appli-\ncations by applying these files using kubectl becomes a complex job. It is beyond the \nscope of this book to cover a detailed view of these resources, and other resources \nare available such as the official Kubernetes documentation page (https://kubernetes \n.io/docs/concepts/workloads/). In this book, we will concentrate on how to deal with \nthese resources for large applications and the tools that can help us with that task. The \nfollowing section provides an overview of the tools to package and install components \ninto your Kubernetes cluster. \nPackaging and installing Kubernetes applications\nThere are different tools to package and manage your Kubernetes applications. Most \nof the time, we can separate these tools into two main categories: templating engines \nand package managers. You will probably need both kinds of tools for real-life scenar-\nios to get things done. Let’s discuss these two kinds of tools: why would you need a tem-\nplating engine? What kind of packages do you want to manage? \nA templating engine allows you to reuse the same resource definitions in different \nenvironments where applications might require slightly different parameters. The text-\nbook example of the need to template your resources is database URLs. If your service \nneeds to connect to different database instances in different environments, such as the \ntesting database in the testing environment and the production database in the produc-\ntion environment, you want to avoid maintaining two copies of the same YAML file but \nwith different URLs. Figure 2.2 shows how you can now add variables to the YAML files, \nand the engine will then find and replace these variables with different values depend-\ning on where you want to use the f﻿iinal (rendered) resource. \n\n\n32\nChapter 2  Cloud-native application challenges \nservice.yaml\nmyservice:\n   dbURL: {{dbURL}}\ndev.yaml\n  dbURL: dev.db.endpoint\ntest.yaml\n  dbURL: test.db.endpoint\nTemplating Engine\n            service.yaml\nmyservice:\n   dbURL: dev.db.endpoint\n             service.yaml\nmyservice:\n   dbURL: test.db.endpoint\nDev\nTest\nFigure 2.2    Templating engines render YAML resources by replacing variables.\nUsing a templating engine can save you a lot of time maintaining different copies of \nthe same file, because when files start to pile up, maintaining them becomes a full-time \njob. There are several tools in the community to deal with templating Kubernetes files. \nSome tools just deal with YAML files, and some other tools are more targeted to Kuber-\nnetes resources specifically. Some projects that you should check out are: \n¡ Kustomize: https://kustomize.io/\n¡ Carvel YTT: https://carvel.dev/ytt/ \n¡ Helm Templates: https://helm.sh/docs/chart_best_practices/templates/#helm \nNow, what do you do with all these files? It is quite a natural urge to organize these files \nin logical packages. If you are building an application that is composed of different ser-\nvices, it might make sense to group all the resources related to a service inside the same \ndirectory or even in the same repository that contains the source code for that service. \nYou also want to make sure that you can distribute these files to the teams deploying \nthese services to different environments, and you quickly realize that you need to ver-\nsion these files in some way. This versioning might be related to the version of your \nservice itself or with a high-level logical aggregation that makes sense for your appli-\ncation. When we talk about grouping, versioning, and distributing these resources, \nwe are describing the responsibility of a package manager. Developers and operations \nteams are already used to working with package managers no matter the technology \nstack they use. Maven/Gradle for Java, NPM for NodeJS, APT-GET for Linux/Debian/\nUbuntu packages, and more recently, containers and container registries for cloud-na-\ntive applications. So, what does a package manager for YAML files look like? What are \nthe package manager’s main responsibilities? \nAs a user, a package manager allows you to browse available packages and their meta-\ndata to decide which package you want to install. Once you have decided which package \nyou want to use, you should be able to download it and then install it. Once the package \nis installed, you would expect, as a user, to be able to upgrade to a newer version of the \npackage when it becomes available. Upgrading/updating a package requires manual \n\n\n\t\n33\nRunning our cloud-native applications\nintervention, meaning that as a user, you will explicitly tell the package manager to \nupgrade the installation of a certain package to a newer (or latest) version.\nFrom a package provider’s point of view, a package manager should offer a conven-\ntion and structure to create packages and a tool to package the files you want to distrib-\nute. Package managers deal with versions and dependencies, meaning that if you create \na package, you must associate a version number with it. Some package managers use the \nsemver (semantic versioning) approach, which uses three numbers to describe the pack-\nage maturity (1.0.1 where these numbers represent the major, minor, and patch ver-\nsions). A package manager doesn’t need to provide a centralized package repository, \nbut they often do. This package repository is in charge of hosting packages for users to \nconsume. Central repositories are useful because they provide access to developers with \nthousands of packages ready to be used. Some examples of these central repositories \nare Maven Central, NPM, Docker Hub, GitHub Container Registry, etc. These repos-\nitories are in charge of indexing the package’s metadata (which can include versions, \nlabels, dependencies, and short descriptions) to make them searchable by users. These \nrepositories also deal with access control to have public and private packages, but at the \nend of the day, the main responsibility of the package repository is to allow package pro-\nducers to upload packages and package consumers to download packages from them \n(see figure 2.3). \nPackage Manager\nYour Package \n0.1.0\nPackage \nRepository\nservice.yaml\ndeployment.yaml\ningress.yaml\nBuild \nand add \nmetadata\nDistribute\nSearch and \nConsume\nFigure 2.3    Package Managers’ responsibilities: build, package, and distribute\nWhen we talk about Kubernetes, Helm is a very popular tool that provides both a pack-\nage manager and a templating engine. But there are others worth looking into, such \nas: \n¡ Imgpkg (https://carvel.dev/imgpkg/), which uses Container registries to store \nthe packages.\n¡ Kapp (https://carvel.dev/kapp/), which provides higher-level abstractions to \ngroup resources as applications.\n¡ Tools like Terraform and Pulumi that allow you to manage infrastructure as code. \nIn the following section, we will look at using Helm (http://helm.sh) to install the \nConference application into our Kubernetes cluster.\n\n\n34\nChapter 2  Cloud-native application challenges \n2.2\t\nInstalling the Conference application with a single command\nLet’s install the Conference application introduced in chapter 1, section 1.4 into our \nKubernetes cluster using Helm. This Conference application allows conference orga-\nnizers to receive proposals from potential speakers, evaluate these proposals, and keep \nan updated agenda with the approved submissions for the event. We will use this appli-\ncation throughout the book to exemplify the challenges that you will face while build-\ning real-life applications. \nNOTE    For the complete list of steps, follow the step-by-step tutorial located at \nhttps://github.com/salaboy/platforms-on-k8s/tree/main/chapter-2. It includes \nall the prerequisites to run the commands described in this section, such as creating \na cluster and installing the command-line tools needed for the examples to work. \nThis application was built as a walking skeleton, which means it is not a complete appli-\ncation but has all the pieces required for the “Call for Proposals” flow to work. These \nservices can be iterated further to support other flows and real-life scenarios. In the \nfollowing sections, you will install the application into the cluster and interact with it to \nsee how it behaves when it runs on top of Kubernetes. Let’s install the application with \nthe following line:\nhelm install conference oci://docker.io/salaboy/conference-app --version \nv1.0.0\nYou should see the output similar to listing 2.1. \nListing 2.1    Helm installed the chart conference-app version 1.0.0\n> helm install conference oci://docker.io/salaboy/conference-app --version \n➥v1.0.0 \nPulled: registry-1.docker.io/salaboy/conference-app:v1.0.0\nDigest: \nsha256:e5dd1a87a867fd7d6c6caecef3914234a12f23581c5137edf63bfd9add7d5459\nNAME: conference\nLAST DEPLOYED: Mon Jun 26 08:19:15 2023\nNAMESPACE: default\nSTATUS: deployed\nREVISION: 1\nTEST SUITE: None\nNOTES:\nCloud-Native Conference Application v1.0.0\nChart Deployed: conference-app - v1.0.0\nRelease Name: conference\nFor more information visit: https://github.com/salaboy/platforms-on-k8s\nAccess the Conference Application Frontend by running \n➥'kubectl port-forward svc/frontend -n default 8080:80'\nNOTE    Since Helm 3.7+ you can package and distribute Helm Charts as OCI con-\ntainer images, the URL for the Helm Chart contains oci:// because this chart \nis hosted in Docker Hub, where the application containers are stored. Before \nHelm supported OCI images, you needed to manually add and fetch packages \nfrom a Helm Chart Repository, which used tar files to distribute these charts. \n\n\n\t\n35\nInstalling the Conference application with a single command\nhelm install creates a Helm release, which means that you have created an appli-\ncation instance, in this case, the instance is called conference. With Helm, you can \ndeploy multiple instances of the application if you want to. You can list Helm releases \nby running:\nhelm list\nThe output should look like figure 2.4. \nFigure 2.4    List Helm releases\nNOTE    If instead of using helm install you run helm template oci://\ndocker.io/salaboy/conference-app --version v1.0.0. Helm will output \nthe YAML files, which will apply against the cluster. There are situations where \nyou might want to do that instead of helm install, for example, if you want to \noverride values that the Helm Charts don’t allow you to parameterize or apply \nany other transformations before sending the request to Kubernetes. \n2.2.1\t\nVerifying that the application is up and running\nOnce the application is deployed, containers will be downloaded to run on your lap-\ntop, which can take a while. Depending on your internet connection, the process \ncan take up to 10 minutes because Kafka, PostgreSQL, and Redis will be downloaded \nalongside the application’s containers. The RESTARTS columns show how often the \ncontainer has been restarted due to an error. In distributed applications, this is nor-\nmal, as components might depend on each other, and when they are started at the \nsame time, connections can fail. By design, applications should be able to recover from \nproblems, and Kubernetes will automatically restart a failing container. \nYou can monitor the progress by listing all the pods running in your cluster, once \nagain, using the -owide flag to get more information:\nkubectl get pods -owide\nThe output should look like figure 2.5. \nListing 2.5    Listing application pods\n\n\n36\nChapter 2  Cloud-native application challenges \nSomething that you might notice in the list of pods is that we are not only running the \napplication’s services, but we are also running Redis, PostgreSQL, and Kafka, because \nthe C4P (Call for Proposals) and Agenda services need persistent storage. The applica-\ntion will be using Kafka to exchange asynchronous messages between services. Besides \nthe services, we will have these two databases and a message broker (Kafka) running \ninside our Kubernetes cluster. \nIn the output shown in figure 2.5 you need to pay attention to the READY and STA-\nTUS columns, where 1/1 in the READY column means that one replica of the container \nis running, and one is expected to be running. As you can see the RESTART column \nis showing 7 for the Call for Proposals Service (conference-c4p-service). This is \nbecause the service depends on Redis to be up and running for the service to be able to \nconnect to it. While Redis is bootstrapping the application will try to connect, and if it \nfails, it will try to keep reconnecting. As soon as Redis is up, the service will connect to it. \nThe same applies to Kafka and PostgreSQL. To quickly recap, our application services, \nthe databases, and the message broker that we are running are shown in figure 2.6. \nFrontend\nCall For Proposals \n(C4P) Service\nAgenda Service\nNotifications \nService\nKafka\nPostgreSQL\nRedis\nFigure 2.6    Application services, databases, and message broker\nNotice that Pods can be scheduled in different nodes. You can check this in the NODE \ncolumn; this is Kubernetes efficiently using the cluster resources. If all the Pods are \nup and running, you’ve made it! The application is now up and running, and you can \naccess it by pointing your favorite browser to http://localhost.\nIf you are interested in Helm and building your own Conference application Helm \nChart, I recommend you to check the source code provided with the tutorials: https://\ngithub.com/salaboy/platforms-on-k8s/tree/main/conference-application/helm/\nconference-app. \n2.2.2\t\nInteracting with your application\nIn the previous section, we installed the application into our local Kubernetes cluster. \nIn this section, we will quickly interact with the application to understand how the \nservices interact to accomplish a simple use case: Receiving and approving proposals. \nRemember that you can access the application by pointing your browser to http://\nlocalhost. The Conference application should look like figure 2.7. \n",
      "page_number": 46
    },
    {
      "number": 7,
      "title": "Segment 7 (pages 56-64)",
      "start_page": 56,
      "end_page": 64,
      "detection_method": "topic_boundary",
      "content": "\t\n37\nInstalling the Conference application with a single command\nFigure 2.7    \nConference \nlanding page\nIf you switch to the Agenda section now, you should see something like figure 2.8. \nFigure 2.8    \nConference empty \nAgenda when we \nfirst install the \napplication\nThe application’s Agenda page lists all the talks scheduled for the conference. Poten-\ntial speakers can submit proposals that the conference organizers will review. When \nyou start the application for the first time, there will be no talks on the agenda, but you \ncan now go ahead and submit a proposal from the Call from Proposals section. Check \nfigure 2.9.\nFigure 2.9    \nSubmitting a \nproposal for \norganizers to \nreview\n\n\n38\nChapter 2  Cloud-native application challenges \nNotice that there are four fields (Title, Description, Author, and Email) in the form to \nsubmit a proposal. Fill in all the fields and submit by clicking the Submit Proposal but-\nton at the bottom of the form. The organizers will use this information to evaluate your \nproposal and get in touch with you via email if your proposal gets approved or rejected. \nOnce the proposal is submitted, you can go to the Back Office (click the arrow point-\ning to the right at the top menu) and check the Review Proposals tab, where you can \nApprove or Reject submitted proposals. You will be acting as a conference organizer on \nthis screen; see figure 2.10. \nFigure 2.10    Conference organizers can Accept or Reject incoming proposals\nApproved proposals will appear on the Main Agenda page. Attendees who visit the \npage at this stage can glance at the conference’s main speakers. Figure 2.11 shows our \nfreshly approved proposal in the Agenda section of the main conference page.\nFigure 2.11    Your proposal is now live on the agenda! \n\n\n\t\n39\nInstalling the Conference application with a single command\nAt this stage, the potential speaker should have received an email about the approval \nor rejection of their proposal. You can check this by looking at the notification service \nlogs, using kubectl from your terminal; see figure 2.12 for the output of the command:\nkubectl logs -f conference-notifications-service -deployment-<POD_ID>\nFigure 2.12    Notifications service logs (emails and events) \nThese logs show two important aspects of the application. First, notifications are sent \nvia emails to potential speakers. The organizers need to keep track of these communi-\ncations. On the conference Back Office page, you can find the Notifications tab, where \nthe content of the notifications is shown to the organizers (see figure 2.13). \nFigure 2.13    Notifications displayed in the Back Office\n\n\n40\nChapter 2  Cloud-native application challenges \nThe second aspect displayed here is Events. All services from this application are emit-\nting events when relevant actions are performed. The notification service is emitting \nan event, in this case to Kafka, for every notification that is being sent. This allows other \nservices and applications to integrate with the application services asynchronously. Fig-\nure 2.14 shows the Events section of the Back Office. \nFigure 2.14    All service events in the Back Office\nFigure 2.14 shows all events emitted by the application services; notice that you can see \nall the meaningful operations being performed by the services to fulfill the Call for \nProposals flow (New Proposal > New Agenda Item > Proposal Approved > Notification \nSent).\nIf you made it so far, congrats, the Conference application is working as expected. \nI encourage you to submit another proposal and reject it, to validate that the correct \nnotification and events are sent to the potential speaker. \nIn this section, you installed the Conference application using Helm. Then we ver-\nified that the application is up and running and that potential speakers can submit \nproposals, while conference organizers can approve or reject these proposals. The deci-\nsions will send notifications to potential speakers via email. \nThis simple application allows us to demonstrate a basic use case that we can now \nexpand and improve to support real users. We have seen that installing a new instance \nof the application is quite simple. We used Helm to install a set of services that are con-\nnected as well as some infrastructural components such as Redis, PostgreSQL, and in \nthe next section, we will go deeper into understanding what we have installed and how \nthe application is working. \n\n\n\t\n41\nInspecting the walking skeleton\n2.3\t\nInspecting the walking skeleton\nIf you have been using Kubernetes for a while, you probably know all about kubectl. \nBecause this application version uses native Kubernetes deployments and services, you \ncan inspect and troubleshoot these Kubernetes resources using kubectl.\nUsually, instead of just looking at the pods running (with kubectl get pods), to \nunderstand and operate the application, you will be looking at services and deploy-\nments. Let’s explore the deployment resources first. \n2.3.1\t\nKubernetes deployments basics\nLet’s start with deployments. Deployments in Kubernetes are in charge of containing \nthe recipe for running our containers. Deployments are also in charge of defining how \ncontainers will run and how they will be upgraded to newer versions when needed. By \nlooking at the deployment details, you can get very useful information, such as:\n¡ The container that this deployment is using. Notice that this is just a simple Docker \ncontainer, meaning that you can even run this container locally if you want to \nwith docker run. This is fundamental to troubleshooting problems. \n¡ The number of replicas required by the deployment. For this example, it is set to \n1, but you will change this in the next section. More replicas add more resiliency \nto the application, because these replicas can go down. Kubernetes will spawn \nnew instances to keep the number of desired replicas up at all times.\n¡ The resource allocation for the container. Depending on the load and the technol-\nogy stack that you used to build your service, you will need to fine-tune how many \nresources Kubernetes you allow your container to use.\n¡ The status of the readiness and liveness probes. Kubernetes, by default, will monitor \nthe health of your container. It does that by executing two probes: 1) The “readi-\nness probe” checks if the container is ready to answer requests, and 2) The “live-\nness probe” checks if the main process of the container is running. \n¡ The rolling updates strategy defines how our Pods will be updated to avoid down-\ntime for our users. With the RollingUpdateStrategy, you can define how \nmany replicas are allowed while triggering and updating to a newer version. \nFirst, let’s list all the available deployments with: \nkubectl get deployments\nThe output should look like listing 2.2. \nListing 2.2    Listing your application’s deployments\nNAME                                          READY   UP-TO-DATE   AVAILABLE   \nconference-agenda-service-deployment          1/1     1            1           \nconference-c4p-service-deployment             1/1     1            1           \nconference-frontend-deployment                1/1     1            1           \nconference-notifications-service-deployment   1/1     1            1           \n\n\n42\nChapter 2  Cloud-native application challenges \n2.3.2\t\nExploring deployments\nIn the following example, you will describe the Frontend deployment. You can describe \neach deployment in more detail with kubectl describe deploy conference-fron-\ntend-deployment (see listing 2.3).\nListing 2.3    Describing a deployment to see its details\n> kubectl describe deploy conference-frontend-deployment \nName:                   conference-frontend-deployment\nNamespace:              default\nCreationTimestamp:      Tue, 27 Jun 2023 08:21:21 +0100\nLabels:                 app.kubernetes.io/managed-by=Helm\nAnnotations:            deployment.kubernetes.io/revision: 1\n                        meta.helm.sh/release-name: conference\n                        meta.helm.sh/release-namespace: default\nSelector:               app=frontend\nReplicas:               1 desired | 1 updated | 1 total | 1 available \nStrategyType:           RollingUpdate\nMinReadySeconds:        0\nRollingUpdateStrategy:  25% max unavailable, 25% max surge\nPod Template:\n  Labels:  app=frontend\n  Containers:\n   frontend:\n    Image:      salaboy/frontend-go...\n    Port:       8080/TCP\n    Host Port:  0/TCP\n    ...\n    ...\n    Environment: \n      AGENDA_SERVICE_URL:         agenda-service.default.svc.cluster.local\n      C4P_SERVICE_URL:            c4p-service.default.svc.cluster.local\n      NOTIFICATIONS_SERVICE_URL:  notifications-service.default.svc.cluster.\nlocal\n      KAFKA_URL:                  conference-kafka.default.svc.cluster.local\n      POD_NODENAME:                (v1:spec.nodeName)\n      POD_NAME:                    (v1:metadata.name)\n      POD_NAMESPACE:               (v1:metadata.namespace)\n      POD_IP:                      (v1:status.podIP)\n      POD_SERVICE_ACCOUNT:         (v1:spec.serviceAccountName)\n    Mounts:                       <none>\n  Volumes:                        <none>\nConditions:\n  Type           Status  Reason\n  ----           ------  ------\n  Available      True    MinimumReplicasAvailable\n  Progressing    True    NewReplicaSetAvailable\nOldReplicaSets:  <none>\nNewReplicaSet:   conference-frontend-deployment-<ID> (1/1 replicas created)\nShows the replicas available for this \ndeployment. This gives you a quick indication \nabout the state of your deployment.\nThe container image, including the name and tag used for this service.\nThe environment variables used to configure this container.\n\n\n\t\n43\nInspecting the walking skeleton\nEvents: \n  Type    Reason             Age   From                   Message\n  ----    ------             ----  ----                   -------\n  Normal  ScalingReplicaSet  48m   deployment-controller  Scaled up replica \n➥set conference-frontend-deployment-59d988899 to 1\nListing 2.3 shows that describing deployments in this way is very helpful if for some rea-\nson the deployment is not working as expected. For example, if the number of replicas \nrequired is not met, describing the resource will give you insights into where the prob-\nlem might be. Always check at the bottom for the events associated with the resource to \nget more insights about the resource status. In this case, the deployment was scaled to \nhave one replica 48 minutes ago. \nAs mentioned before, deployments are also responsible for coordinating version or \nconfiguration upgrades and rollbacks. The deployment update strategy is set by default \nto “Rolling ,” which means that the deployment will incrementally upgrade pods one \nafter the other to minimize downtime. An alternative strategy called Recreate can be \nset, which will shut down all the pods and create new ones. \nIn contrast with pods, deployments are not ephemeral; hence, if you create a \nDeployment, it will be there for you to query no matter if the containers under the hood \nare failing. By default, when you create a deployment resource, Kubernetes creates an \nintermediate resource for handling and checking the deployment–requested replicas. \n2.3.3\t\nReplicaSets\nHaving multiple replicas of your containers is an important feature to scale your appli-\ncations. If your application is experiencing loads of traffic from your users, you can eas-\nily scale up the number of replicas of your services to accommodate all the incoming \nrequests. Similarly, if your application is not experiencing a large number of requests, \nthese replicas can be scaled down to save resources. The object created by Kubernetes \nis called ReplicaSet, and it can be queried by running:\nkubectl get replicaset\nThe output should look like listing 2.4. \nListing 2.4    Listing the deployment’s ReplicaSets\n> kubectl get replicasets\nNAME                                              DESIRED   CURRENT   READY\nconference-agenda-service-deployment-7cc9f58875        1       1         1\nconference-c4p-service-deployment-76dfc94444           1       1         1\nconference-frontend-deployment-59d988899               1       1         1\nconference-notifications-service-deployment-7cbcb8677b 1       1         1\nEvents shows us relevant information \nabout our Kubernetes resources—in this \ncase, when the replica was created.\n\n\n44\nChapter 2  Cloud-native application challenges \nThese ReplicaSet objects are fully managed by the deployment’s resource, and usu-\nally, you shouldn’t need to deal with them. ReplicaSets are also essential when dealing \nwith rolling updates, and you can find more information about this topic at https://\nkubernetes.io/docs/tutorials/kubernetes-basics/update/update-intro/. You will be \nperforming updates to the application with Helm in later chapters, where these mech-\nanisms will kick in. \nIf you want to change the number of replicas for a deployment, you once again can \nuse kubectl to do so: \n> kubectl scale --replicas=2 deployments/<DEPLOYMENT_ID>\nYou can try this out with the Frontend deployment: \n> kubectl scale --replicas=2 deployments/conference-frontend-deployment\nIf we now list the application pods, we will see that there are two replicas for the fron-\ntend service:\nconference-frontend-deployment-<ID>-8gpgn  1/1     Running   7 (53m ago)   59m\nconference-frontend-deployment-<ID>-z4c5c  1/1     Running   0             13s\nThis command changes the deployment resource in Kubernetes and triggers the cre-\nation of a second replica for the Frontend deployment. Increasing the number of rep-\nlicas of your user-facing services is quite common because it is the service that all users \nwill hit when visiting the conference page. \nIf we access the application right now, as end users we will not notice any difference, \nbut every time we refresh, a different replica might serve us. To make this more evident, \nwe can turn on a feature that is built into the Frontend service, which shows us more \ninformation about the application containers. You can enable this feature by setting an \nenvironment variable: \nkubectl set env deployment/conference-frontend-deployment  \n➥FEATURE_DEBUG_ENABLED=true\nNotice that when you change the deployment object configuration (anything inside \nspec.template.spec block) the rolling update mechanism of the Deployment \nresource will kick in. All the existing pods managed by this deployment will be upgraded \nto have the new specification(in this example to include the new FEATURE_DEBUG_\nENABLED environment variable). This upgrade, by default, will start a new pod with the \nnew specification and wait for it to be ready before terminating the old version of the \npod. This process will be repeated until all the pods (replicas for the deployment) are \nusing the new configuration. \nIf you access the application again in your browser (you might need to access using \nIncognito Mode if the browser cached the website), in the Back Office section, there is a \nnew Debug tab. You can see the Pod Name, Pod IP, the Namespace, and the Node name \nwhere the Pod is running for all services (figure 2.15).\n\n\n\t\n45\nInspecting the walking skeleton\nFigure 2.15    First replica of the Frontend answering your request (running on Node Name: dev-worker)\nIf you wait for 3 seconds, the page will automatically refresh, and you should see the \nsecond replica answering this time, if not wait for the next cycle (figure 2.16). \nFigure 2.16    Second replica of the Frontend answering your request (running on Node Name: dev-   \t\n\t\n\t\n       worker3)\nBy default, Kubernetes will load-balance the requests between the replicas. Being able \nto scale by just changing the number of replicas, there is no need to deploy anything \nnew, Kubernetes will provision a new pod (with a new container in it) to deal with more \ntraffic. Kubernetes will also make sure that there is the amount of desired replicas at \nall times. You can test this by deleting one pod and watching how Kubernetes recreates \nit automatically. For this scenario, you need to be careful, because the web application \nfrontend is executing several requests to fetch the HTML, CSS, and JavaScript librar-\nies; hence, each of these requests can land in a different replica. \n",
      "page_number": 56
    },
    {
      "number": 8,
      "title": "Segment 8 (pages 65-76)",
      "start_page": 65,
      "end_page": 76,
      "detection_method": "topic_boundary",
      "content": "46\nChapter 2  Cloud-native application challenges \n2.3.4\t\nConnecting services\nWe have looked at deployments, which are in charge of getting our containers up and \nrunning and keeping them that way, but so far, these containers can only be accessed \ninside the Kubernetes cluster. If we want other services to interact with these contain-\ners, we need to look at another Kubernetes resource called Service. Kubernetes pro-\nvides an advanced service-discovery mechanism that allows services to communicate \nwith each other by just knowing their names. This is essential for connecting many \nservices without knowing IP addresses of Kubernetes pods that can change over time, \nas they can be upgraded, rescheduled to a different node, or just restarted with a new \nIP address when something goes wrong.\n2.3.5\t\nExploring services\nTo expose your containers to other services, you need to use a Kubernetes Service \nresource. Each application service defines this Service resource, so other services and \nclients can connect to them. In Kubernetes, services will be in charge of routing traffic \nto your application containers. These services represent a logical name that you can \nuse to abstract where your containers run. If you have multiple replicas of your con-\ntainers, the service resource will be in charge of load balancing the traffic among all \nthe replicas. You can list all the services by running:\nkubectl get services\nAfter running the command, you should see something like listing 2.5.\nListing 2.5    Listing application’s services\nNAME                        TYPE        CLUSTER-IP      PORT(S)\nagenda-service              ClusterIP   10.96.90.100    80/TCP\nc4p-service                 ClusterIP   10.96.179.86    80/TCP\nconference-kafka            ClusterIP   10.96.67.2      9092/TCP\nconference-kafka-headless   ClusterIP   None     9092/TCP,9094/TCP,9093/TCP\nconference-postgresql       ClusterIP   10.96.121.167   5432/TCP\nconference-postgresql-hl    ClusterIP   None            5432/TCP\nconference-redis-headless   ClusterIP   None            6379/TCP\nconference-redis-master     ClusterIP   10.96.225.138   6379/TCP\nfrontend                    ClusterIP   10.96.60.237    80/TCP\nkubernetes                  ClusterIP   10.96.0.1       443/TCP\nnotifications-service       ClusterIP   10.96.65.248    80/TCP\nAnd you can also describe a service to see more information about it with:\nkubectl describe service frontend\nThis should give you something like we see in listing 2.6. Services and deployments are \nlinked by the Selector property, highlighted in the following image. In other words, \nthe service will route traffic to all the pods created by a deployment containing the \nlabel app=frontend.\n\n\n\t\n47\nInspecting the walking skeleton\nListing 2.6    Describing the Frontend service\nName:              frontend\nNamespace:         default\nLabels:            app.kubernetes.io/managed-by=Helm\nAnnotations:       meta.helm.sh/release-name: conference\n                   meta.helm.sh/release-namespace: default\nSelector:          app=frontend\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                10.96.60.237\nIPs:               10.96.60.237\nPort:              <unset>  80/TCP\nTargetPort:        8080/TCP\nEndpoints:         10.244.1.6:8080,10.244.2.9:8080\nSession Affinity:  None\nEvents:            <none>\n2.3.6\t\nService discovery in Kubernetes\nBy using services, if your application service needs to send a request to any other ser-\nvice, it can use the Kubernetes service’s name and port; in most cases, you can use port \n80 if you are using HTTP requests, so you only need to use the service name. If you \nlook at the source code of the services, you will see that HTTP requests are created \nagainst the service name; no IP addresses or Ports are needed.\nFinally, if you want to expose your services outside the Kubernetes cluster, you need \nan Ingress resource. As the name represents, this Kubernetes resource is in charge of \nrouting traffic from outside the cluster to services that are inside the cluster. Usually, \nyou will not expose multiple services, limiting the entry points for your applications.\nYou can get all the available Ingress resources by running the following command:\nkubectl get ingress\nThe output should look like listing 2.7.\nListing 2.7    Listing the application’s Ingress resources\nNAME                          CLASS   HOSTS   ADDRESS     PORTS   AGE\nconference-frontend-ingress   nginx   *       localhost   80      84m\nAnd then you can describe the Ingress resource in the same way as you did with other \nresource types to get more information about it:\nkubectl describe ingress conference-frontend-ingress\nYou should expect the output to look like listing 2.8. \nThe selector used to match a \nservice and a deployment.\n\n\n48\nChapter 2  Cloud-native application challenges \nListing 2.8    Describing the Ingress resource\nName:             conference-frontend-ingress\nLabels:           app.kubernetes.io/managed-by=Helm\nNamespace:        default\nAddress:          localhost\nIngress Class:    nginx\nDefault backend:  <default>\nRules:\n  Host        Path  Backends\n  ----        ----  --------\n  *           \n              /   frontend:80 (10.244.1.6:8080,10.244.2.9:8080) \nAnnotations:  meta.helm.sh/release-name: conference\n              meta.helm.sh/release-namespace: default\n              nginx.ingress.kubernetes.io/rewrite-target: /\nEvents:       <none>\nAs you can see, Ingress also uses the service’s name to route traffic. For this to work, \nyou need an Ingress controller, like we installed when we created the KinD cluster. If \nyou are running in a cloud provider, you might need to install an Ingress controller. \nThe following spreadsheet is a community resource created to keep track of the \ndifferent options of Ingress controllers that are available for you to use: http://mng \n.bz/K9Bn. \nWith Ingresses, you can configure a single entry-point and use path-based routing to \nredirect traffic to each service you need to expose. The previous Ingress resource in list-\ning 2.8 routes all the traffic sent to / to the frontend service. Notice that Ingress rules \nare pretty simple, and you shouldn’t add any business logic routing at this level.\n2.3.7\t\nTroubleshooting internal services\nSometimes, it is important to access internal services to debug or troubleshoot services \nthat are not working. For such situations, you can use the kubectl port-forward \ncommand to temporarily access services that are not exposed outside of the cluster \nusing an Ingress resource. For example, to access the Agenda service without going \nthrough the Frontend you can use the following command: \nkubectl port-forward svc/agenda-service 8080:80 \nYou should see the following output (listing 2.9) and make sure that you don’t kill the \ncommand.\nListing 2.9    kubectl port-forward allows you to expose a service for debugging purposes\nForwarding from 127.0.0.1:8080 -> 8080\nForwarding from [::1]:8080 -> 8080\nAnd then using your browser, use curl in a different tab or any other tool to point to \nhttp://localhost:8080/service/info to access the exposed Agenda service. The \nAll traffic going to '/' will go to \nthe frontend:80 service.\n\n\n\t\n49\nCloud-native application challenges\nfollowing listing shows how you can curl the Agenda service info endpoint and print \na pretty/colorful JSON payload with the help of jq, which you must install separately. \nListing 2.10    curl localhost:8080 to access Agenda service using port-forward\n> curl -s localhost:8080/service/info | jq --color-output\n{\n  \"Name\": \"AGENDA\",\n  \"Version\": \"1.0.0\",\n  \"Source\": \"https://github.com/salaboy/platforms-on-k8s/tree/main/    \t\n\t\n            conference-application/agenda-service\",\n  \"PodName\": \"conference-agenda-service-deployment-7cc9f58875-28wrt\",\n  \"PodNamespace\": \"default\",\n  \"PodNodeName\": \"dev-worker3\",\n  \"PodIp\": \"10.244.2.2\",\n  \"PodServiceAccount\": \"default\"\n}\nIn this section, you have inspected the main Kubernetes resources that were created to \nrun your application’s containers inside Kubernetes. By looking at these resources and \ntheir relationships, you can troubleshoot problems when they arise. \nFor everyday operations, the kubectl command line tool might not be optimal, and \ndifferent dashboards can be used to explore and manage your Kubernetes workloads, \nsuch as k9s (https://k9scli.io/), the Kubernetes dashboard (https://kubernetes.io/\ndocs/tasks/access-application-cluster/web-ui-dashboard/) and Skooner (https://\ngithub.com/skooner-k8s/skooner). \n2.4\t\nCloud-native application challenges\nIn contrast to a monolithic application, which will go down entirely if something goes \nwrong, cloud-native applications shouldn’t crash if a service goes down. Cloud-native \napplications are designed for failure and should keep providing valuable functionality \nin the case of errors. A degraded service while fixing problems is better than having \nno access to the application. In this section, you will change some of the service con-\nfigurations in Kubernetes to understand how the application will behave in different \nsituations. \nIn some cases, application/service developers will need to make sure that they \nbuild their services to be resilient and Kubernetes or the infrastructure will solve some \nconcerns. \nThis section covers some of the most common challenges associated with cloud-na-\ntive applications. I find it useful to know what are the things that are going to go wrong \nin advance rather than when I am already building and delivering the application. This \nis not an extensive list; it is just the beginning to make sure that you don’t get stuck with \nproblems that are widely known. The following sections will exemplify and highlight \nthese challenges with the Conference application: \n\n\n50\nChapter 2  Cloud-native application challenges \n¡ Downtime is not allowed: If you are building and running a cloud-native applica-\ntion on top of Kubernetes, and you are still suffering from application downtime, \nthen you are not capitalizing on the advantages of the technology stack that you \nare using. \n¡ Service’s built-in resiliency: Downstream services will go down, and you need to \nensure that your services are prepared for that. Kubernetes helps with dynamic \nservice discovery, but that is not enough for your application to be resilient. \n¡ Dealing with the application state is not trivial: We must understand each service’s \ninfrastructural requirements to allow Kubernetes to scale up and down our ser-\nvices efficiently. \n¡ Inconsistent data: A common problem of working with distributed applications is \nthat data is not stored in a single place and tends to be distributed. The applica-\ntion will need to be ready to deal with cases where different services have differ-\nent views of the state of the world.\n¡ Understanding how the application is working (monitoring, tracing, and telemetry): Hav-\ning a clear understanding of how the application is performing and that it is \ndoing what it is supposed to be doing is essential for quickly finding problems \nwhen things go wrong. \n¡ Application security and identity management: Dealing with users and security is \nalways an afterthought. For distributed applications, having these aspects clearly \ndocumented and implemented early on will help you to refine the application \nrequirements by defining “who can do what and when.” \nLet’s start with the first of the challenges: Downtime is not allowed.\n2.4.1\t\nDowntime is not allowed\nWhen using Kubernetes, we can easily scale up and down our services’ replicas. This \nis a great feature when your services were designed based on the assumption that the \nplatform will scale them by creating new copies of the containers running the service. \nSo, what happens when the service is not ready to handle replication or when no repli-\ncas are available for a given service? \nLet’s scale up the Frontend service to have two replicas running. To achieve this, you \ncan run the following command: \nkubectl scale --replicas=2 deployments/conference-frontend-deployment\nIf one of the replicas stops running or breaks for any reason, Kubernetes will try to start \nanother one to ensure that two replicas are up all the time. Figure 2.17 shows two Fron-\ntend replicas serving traffic to the user.\n\n\n\t\n51\nCloud-native application challenges\nFrontend <Service>\nUser\nFrontend \n<Pod>\nFrontend \n<Pod>\nAgenda Service \n<Service>\nC4P Service \n<Service>\nNotifications \nService \n<Service>\nFigure 2.17    By having two replicas of the Frontend container running, we allow the application to \ntolerate failures and also to increase the number of concurrent requests that the application can handle.\nYou can quickly try this self-healing feature of Kubernetes by killing one of the two pods \nof the application Frontend. You can do this by running the following commands, as \nshown in listings 2.11 and 2.12.\nListing 2.11    Checking that the two replicas are up and running\n> kubectl get pods \nNAME                                             READY   STATUS    RESTARTS      AGE\nconference-agenda-service-deployment-<ID>        1/1     Running   7 (92m ago)   100m\nconference-c4p-service-deployment-<ID>           1/1     Running   7 (92m ago)   100m\nconference-frontend-deployment-<ID>              1/1     Running   0             25m\nconference-frontend-deployment-<ID>              1/1     Running   0             25m\nconference-kafka-0                               1/1     Running   0             100m\nconference-notifications-service-deployment-<ID> 1/1     Running   7 (91m ago)   100m\nconference-postgresql-0                          1/1     Running   0             100m\nconference-redis-master-0                        1/1     Running   0             100m\nNow, copy one of the two Pods Id and delete it: \n> kubectl delete pod conference-frontend-deployment-c46dbbb9-ltrgs\nThen list the pods again (listing 2.12).\nListing 2.12    A new replica is automatically created as soon as one goes down\n> kubectl get pods\nNAME                                             READY   STATUS    RESTARTS      AGE\nconference-agenda-service-deployment-<ID>        1/1     Running   7 (92m ago)   100m\nconference-c4p-service-deployment-<ID>           1/1     Running   7 (92m ago)   100m\nconference-frontend-deployment-<NEW ID>          0/1     ContainerCreating 0     1s\nconference-frontend-deployment-<ID>              1/1     Running   0             25m\nconference-kafka-0                               1/1     Running   0             100m\nconference-notifications-service-deployment-<ID> 1/1     Running   7 (91m ago)   100m\nconference-postgresql-0                          1/1     Running   0             100m\nconference-redis-master-0                        1/1     Running   0             100m\n\n\n52\nChapter 2  Cloud-native application challenges \nYou can see how Kubernetes (the ReplicaSet, more specifically) immediately creates \na new pod when it detects only one running. While this new pod is being created and \nstarted, you have a single replica answering your requests until the second one is up \nand running. This mechanism ensures that at least two replicas answer your users’ \nrequests. Figure 2.18 shows that the application still works, because we still have one \npod serving requests.\nFrontend <Service>\nUser\nFrontend \n<Pod>\nFrontend \n<Pod>\nAgenda Service \n<Service>\nC4P Service \n<Service>\nNotifications \nService \n<Service>\nFigure 2.18    If one \nof the instances \nfails, Kubernetes will \nautomatically kill \nand recreate that \ninstance. But at least \nthe other running \ncontainer can keep \nanswering requests.\nIf you have a single replica and kill the running pod, you will have downtime in your \napplication until the new container is created and ready to serve requests. You can \nrevert to a single replica with the following:\n> kubectl scale --replicas=1 deployments/conference-frontend-deployment\nGo ahead and try this out. Delete only the replica available for the Frontend pod:\n> kubectl delete pod <POD_ID>\nFigure 2.19 shows the application is not working anymore, because there are no Fron-\ntend pods to serve incoming requests from users.\nFrontend <Service>\nUser\nFrontend \n<Pod>\nAgenda Service \n<Service>\nC4P Service \n<Service>\nNotifications \nService \n<Service>\nFigure 2.19    With a \nsingle replica being \nrestarted, there is no \nbackup to answer user \nrequests. If there is \nno replica available \nto serve your users’ \nrequests, you will \nexperience downtime. \nThis is exactly what we \nwant to avoid.\n\n\n\t\n53\nCloud-native application challenges\nAfter killing the pod, try to access the application by refreshing your browser (http://\nlocalhost). You should see “503 Service Temporarily Unavailable” in your browser, \nbecause the Ingress controller (not shown in the previous figure for simplicity) cannot \nfind a replica running behind the Frontend service. If you wait for a bit, you will see \nthe application come back up. Figure 2.20 shows the 503 “Service Temporarily Unavail-\nable” being returned by the NGINX Ingress controller component that was in charge \nof routing traffic to the Frontend service.\nService Downtime\nFigure 2.20    With a single replica being restarted, there is no backup to answer user requests\nThis error message is quite tricky, because the application takes about a second to get \nrestarted and to be fully functional, so if you didn’t manage to see it, you can try to \ndownscale the frontend service to zero replicas with kubectl scale --replicas=0 \ndeployments/conference-frontend-deployment to simulate downtime.\nThis behavior is expected, because the Frontend service is a user-facing service. If it \ngoes down, users will not be able to access any functionality, so having multiple replicas \nis recommended. From this perspective, the Frontend service is the most important \nservice of the entire application, since our primary goal for our applications is to avoid \ndowntime. \nIn summary, pay special attention to user-facing services exposed outside of your \ncluster. Whether they are user interfaces or just APIs, ensure you have as many replicas \nas needed to deal with incoming requests. Having a single replica should be avoided for \nmost use cases besides development.  \n2.4.2\t\nService’s resilience built-in\nBut now, what happens if the other services go down? For example, the Agenda service, \nis just in charge of listing all the accepted proposals to the conference attendees. This \nservice is also critical, because the Agenda List is right there on the main page of the \napplication. So, let’s scale the service down: \nkubectl scale --replicas=0 deployments/conference-agenda-service-deployment\nFigure 2.21 shows how the application can keep working, even if one of the services is \nmisbehaving.\n\n\n54\nChapter 2  Cloud-native application challenges \nUser\nFrontend <Service>\nAgenda Service \n<Service>\nC4P Service \n<Service>\nNotifications \nService \n<Service>\nAgenda Service \n<Pod>\nFigure 2.21    No pods for the Agenda service. If a service is failing, the user should be able to keep using \nthe application with limited functionality. \nRight after running this command, the container will be killed, and the service will \nnot have any container answering its requests. Try refreshing the application in your \nbrowser, you should see a cached response as shown in figure 2.22.\nFigure 2.22    If the Agenda service has no replica running, the Frontend is wise enough to show the user \nsome cached entries.\nAs you can see, the application is still running, but the Agenda service is not available \nright now. Check the Debug tab in the Back Office section, which should show that the \nAgenda service is unhealthy (figure 2.23). \n\n\n\t\n55\nCloud-native application challenges\nFigure 2.23    If in Debug mode, the Back Office should show the unhealthy services.\nYou can prepare your application for such scenarios; in this case, the Frontend has a \ncached response to at least show something to the user. If, for some reason, the Agenda \nservice is down, at least the user will be able to access other services and other sections \nof the application. From the application perspective, it is important not to propagate \nthe error back to the user. The user should be able to keep using other application \nservices, for example, the Call for Proposals form, until the Agenda service is restored. \nYou need to pay special attention when developing services that will run in Kuberne-\ntes, as now your service is responsible for dealing with errors generated by downstream \nservices. This is important to ensure that errors or services going down don’t bring \nyour entire application down. Simple mechanisms such as cached responses will make \nyour applications more resilient and allow you to incrementally upgrade these services \nwithout worrying about bringing everything down. For our conference scenario, having \na CronJob that periodically caches the agenda entries might be enough. Remember, \ndowntime is not allowed.  \nLet’s now switch to talking about dealing with the state in our applications and how \nit is critical to understand how our application’s services handle the state from a scal-\nability point of view. Since we will be talking about scalability, data consistency is the \nchallenge we will try to solve next.\n2.4.3\t\nDealing with the application state is not trivial\nLet’s scale up the agenda service again to have a single replica: \n> kubectl scale --replicas=1 deployments/conference-agenda-service-deployment\nIf you have created proposals before, you will notice that as soon as the Agenda service \ngoes back up, you see the accepted proposals again on the Agenda page. This works \nonly because both the Agenda service and C4P Service store all the proposals and \nagenda items in external databases (PostgreSQL and Redis). In this context, external \nmeans outside of the pod memory. What will happen if we scale the Agenda service up \nto two replicas? See listing 2.13.\n\n\n56\nChapter 2  Cloud-native application challenges \nListing 2.13    Running with two replicas of the Agenda service\n> kubectl scale --replicas=2 deployments/conference-agenda-service-deployment\nNAME                                                    READY   STATUS          AGE\nconference-agenda-service-deployment-<ID>               1/1     Running         2m30s\nconference-agenda-service-deployment-<ID>               1/1     Running         22s\nconference-c4p-service-deployment-<ID>                  1/1     Running         150m\nconference-frontend-deployment-<ID>                     1/1     Running         8m55s\nconference-kafka-0                                      1/1     Running         150m\nconference-notifications-service-deployment-<ID>        1/1     Running         150m\nconference-postgresql-0                                 1/1     Running         150m\nconference-redis-master-0                               1/1     Running         150m\nFigure 2.24 shows the Agenda service running two replicas of the service concurrently. \nUser\nFrontend <Service>\nAgenda Service <Service>\nFrontend \n<Pod>\nAgenda Service \n<Pod>\nAgenda Service \n<Pod>\nFigure 2.24     \nTwo replicas can \nnow deal with more \ntraffic. The requests \nbeing forwarded by \nthe Frontend can be \nanswered by the two \navailable replicas, \nallowing the application \nto handle more load. \nWith two replicas dealing with your user requests, now the Frontend will have two \ninstances to query. Kubernetes will do the load balancing between the two replicas, but \nyour application will have no control over which replica the request hits. Because we \nare using a database to back up the data outside of the pod’s context, we can scale the \nreplicas to many pods dealing with the application demand. Figure 2.25 shows how the \nAgenda service relies on Redis to store the application state, while the Call for Propos-\nals uses PostgreSQL to do the same. \nUser\nFrontend <Service>\nAgenda Service \n<Service>\nC4P Service\n<Service>\nNotifications \nService\n<Service>\nAgenda Service\n<Pod>\nC4P Service\n<Pod>\nRedis\nPostgreSQL\nFigure 2.25    Both \ndata-sensitive services \nuse persistent stores. \nDelegating state \nstorage to external \ncomponents, make \nyour service stateless \nand easier to scale. \n\n\n\t\n57\nCloud-native application challenges\nOne of the limitations of this approach is the number of database connections that your \ndatabase supports in its default configuration. If you keep scaling up the replicas, always \nconsider reviewing the database connection pool settings to ensure that your database \ncan handle all the connections created by all the replicas. But for the sake of learning, \nlet’s imagine that we don’t have a database, and our Agenda service keeps all the agenda \nitems in memory. How would the application behave if we started scaling up the Agenda \nservice pods? Figure 2.26 shows the hypothetical case of having in-memory data inside \nour applications. \nUser\nFrontend \n<Service>\nAgenda Service <Service>\nAgenda Service\nAgenda Service \n<Pod>\nIn Memory State\nFigure 2.26     \nWhat would happen \nif the Agenda service \nkeeps the state in-\nmemory? If state is \nkept in memory it is \nquite hard to share \nacross replicas. This \nmakes scaling the \nservice much harder.\nBy scaling these services up, we have found a problem with the design of one of the \napplication services. The Agenda service is keeping the state in-memory, and that will \naffect the scaling capabilities from Kubernetes. For this kind of scenario, when Kuber-\nnetes balances the requests across different replicas, the Frontend service will receive \ndifferent data depending on which replica processed the request. \nWhen running existing applications in Kubernetes, you will need to deeply under-\nstand how much data they are keeping in-memory because this will affect how you can \nscale them up. For web applications that keep HTTP sessions and require sticky sessions \n(subsequent requests going to the same replica), you need to set up HTTP session repli-\ncation to get this working with multiple replicas. This might require more components \nbeing configured at the infrastructure level, such as a cache.  \nUnderstanding your service requirements will help you plan and automate your \ninfrastructural requirements, such as databases, caches, message brokers, etc. The \nmore complex the application gets, the more dependencies on these infrastructural \ncomponents it will have. \nAs we have seen before, we have installed Redis and PostgreSQL as part of the appli-\ncation Helm Chart. This is usually not a good idea because databases and tools like \nmessage brokers will need special care from the operation team, who can choose not to \nrun these services inside Kubernetes. We will expand on this topic in chapter 4 where \nwe go deeper into how to deal with infrastructure when working with Kubernetes and \ncloud providers. \n",
      "page_number": 65
    },
    {
      "number": 9,
      "title": "Segment 9 (pages 77-84)",
      "start_page": 77,
      "end_page": 84,
      "detection_method": "topic_boundary",
      "content": "58\nChapter 2  Cloud-native application challenges \n2.4.4\t\nDealing with inconsistent data\nHaving stored data in a relational data store like PostgreSQL or a NoSQL approach \nlike Redis doesn’t solve the problem of having inconsistent data across different stores. \nBecause these stores should be hidden away by the service API, you will need to have \nmechanisms to check that the data that the services are handling is consistent. In dis-\ntributed systems, it is quite common to talk about “eventual consistency,” meaning that \neventually the system will be consistent. Having eventual consistency is better than not \nhaving consistency at all. For this example, we can build a simple check mechanism \nthat once in a while (imagine once a day) checks for the accepted talks in the Agenda \nservice to see if they have been approved in the Call for Proposals service. If there is an \nentry that the Call hasn’t approved for the Proposal Service (C4P), then we can raise \nsome alerts or send an email to the conference organizers (figure 2.27). \nNotifications\n<Service>\nAgenda\n<Service>\nAgenda\n<Pod>\nCall for Proposals\n<Service>\nCall for Proposals\n<Pod>\nNotifications\n<Pod>\nConsistency Checker\n<Pod>\n1\n2\n3\n4\nFigure 2.27    Consistency checks can run as CronJobs. We can execute checks against the application \nservices on fixed intervals to make sure that the state is consistent. For example: (1) every day at \nmidnight we query the Agenda Service (2) to verify that the published sessions are approved in the \n(3) Call For Proposals Service and a corresponding notification has been sent by the (4) Notifications \nService.\nIn figure 2.27, we can see how a CronJob (1) will be executed every X period, depend-\ning on how important it is for us to fix consistency problems. Then it will query the \nAgenda service public APIs (2) to check which accepted proposals are being listed and \ncompare that with the Call for Proposals service approved list (3). Finally, if any incon-\nsistency is found, an email can be sent using the Notifications service public APIs (4). \nThink of the simple use case this application was designed for; what other checks \nwould you need? One that immediately comes to mind is verifying that emails were \nsent correctly for Rejected and Approved proposals. For this use case, emails are really \nimportant, and we need to ensure those emails are sent to our accepted and rejected \nspeakers. \n2.4.5\t\nUnderstanding how the application is working\nDistributed systems are complex beasts, and fully understanding how they work from \nday one can help you save time when things go wrong. This has pushed the monitor-\ning, tracing, and telemetry communities hard to develop solutions that help us under-\nstand how things are working at any given time. \n\n\n\t\n59\nCloud-native application challenges\nThe https://opentelemetry.io/ OpenTelemetry community has evolved alongside \nKubernetes, and it can now provide most of the tools you will need to monitor how your \nservices are working. As stated on their website, “You can use it to instrument, generate, \ncollect, and export telemetry data (metrics, logs, and traces) for analysis to understand \nyour software’s performance and behavior.” Figure 2.28 shows a common use case \nwhere services all push metrics, traces, and logs to a centralized place that stores and \naggregates the information so it can be displayed in dashboards or used by other tools. \nFrontend\nCall For Proposals \n(C4P) Service\nAgenda Service\nNotifications \nService\nDashboard\nOperator\nTraces\nMetrics\nLogs\nFigure 2.28    Aggregating observability from all our services in a single place reduces the cognitive load \non the teams responsible for keeping the application up and running.\nIt is important to notice that OpenTelemetry focuses on both the behavior and perfor-\nmance of your software, because they will both affect your users and user experience. \nFrom the behavior point of view, you want to make sure that the application is doing \nwhat it is supposed to do, and by that, you will need to understand which services are \ncalling which other services or infrastructure to perform tasks. \nUsing Prometheus and Grafana allows us to see the service telemetry and build \ndomain-specific dashboards to highlight certain application-level metrics, for example, \nthe amount of Approved vs. Rejected proposals over time, as shown in figure 2.29. \nFigure 2.29    Monitoring telemetry data with Prometheus and Grafana\n\n\n60\nChapter 2  Cloud-native application challenges \nFrom the performance point of view, you need to ensure that services are respecting \ntheir Service Level Agreements (SLAs), which means that they are taking only a short \ntime to answer requests. If one of your services misbehaves and takes more than usual, \nyou want to know. \nFor tracing, you must modify your services to understand the internal operations and \ntheir performance. OpenTelemetry provides drop-in instrumentation libraries in most \nlanguages to externalize service metrics and traces. Figure 2.30 shows the OpenTeleme-\ntry architecture, where you can see the OpenTelemetry collector receiving information \nfrom each application agent, but also from shared infrastructure components.\nFigure 2.30    OpenTelemetry architecture and library (Source: https://opentelemetry.io/docs/)\nThe recommendation here is if you are creating a walking skeleton, ensure it has Open-\nTelemetry built-in. If you push monitoring to later stages of the project, it will be too \nlate, things will go wrong, and finding out who is responsible will take too much time. \n2.4.6\t\nApplication security and identity management\nIf you have ever built a web application, you know that providing identity management \n(user accounts and user identity) plus authentication and authorization is quite an \nendeavor. A simple way to break any application (cloud-native or not) is to perform \nactions you are not supposed to do, such as deleting all the proposed presentations \nunless you are a conference organizer. \nThis also becomes challenging in distributed systems, because authorization and \nuser identity must be propagated across different services. In distributed architectures, \nit is quite common to have a component that generates requests on behalf of a user \ninstead of exposing all the services for the user to interact directly. In our example, the \nFrontend service is this component. Most of the time, you can use this external-facing \ncomponent as the barrier between external and internal services. For this reason, it is \n\n\n\t\n61\nCloud-native application challenges\nquite common to configure the Frontend service to connect with an authorization and \nauthentication provider commonly using the OAuth2 protocol. Figure 2.31 shows the \nFrontend service interacting with an identity management service, which is responsible \nfor connecting to an Identity Provider (Google, GitHub, your internal LDAP server) \nto validate the user credentials as well as to provide roles or group memberships that \ndefine what the user can and can’t do in different services. The Frontend service han-\ndles the login flow (authentication and authorization), but only the context is propa-\ngated to the backend services once that is done. \nFrontend\nCall For Proposals \n(C4P) Service\nAgenda Service\nNotifications \nService\nIdentity \nManagement\nService\nIdentity \nProviders\nAuthentication and Authorization Flow\nUser\nFigure 2.31    Identity management: The Role/Group is propagated to the backend services. \nOn the identity management front, you have seen that the application doesn’t handle \nusers or their data, which is good for regulations such as GDPR. We might want to \nallow users to use their social media accounts to log in to our applications without the \nneed for them to create separate accounts. This is usually known as social login. \nSome popular solutions bring both OAuth2 and identity management together, \nsuch as Keycloak (https://www.keycloak.org/) and Zitadel (https://zitadel.com/\nopensource). These open-source projects provide a one-stop-shop for single sign-on \nsolutions and advanced identity management. In the case of Zitadel, it also provides a \nmanaged service that you can use if you don’t want to install and maintain an SSO and \nidentity management component inside your infrastructure. \nThe same is true with tracing and monitoring. If you are planning to have users (and \nyou will probably do, sooner or later), including single sign-on and identity manage-\nment into the walking skeleton will push you to think about the specifics of “who will be \nable to do what,” refining your use case even more. \n2.4.7\t\nOther challenges\nIn the previous sections, we have covered a few common challenges you will face while \nbuilding cloud-native applications, but these are not all. Can you think of other ways of \nbreaking this first version of the application? \nNotice that tackling the challenges discussed in this chapter will help, but there are \nother challenges related to how we deliver a continuously evolving application com-\nposed of a growing number of services. \n\n\n62\nChapter 2  Cloud-native application challenges \n2.5\t\nLinking back to platform engineering\nIn previous sections, we have covered many topics. We reviewed options for packaging \nand distributing Kubernetes applications, and then installing our walking skeleton in a \nKubernetes cluster using Helm. We tested the application functionality by interacting \nwith it, and finally, we jumped into analyzing common cloud-native challenges that \nteams will face when building distributed applications. \nBut you might be wondering how all these topics relate to the title of this book, con-\ntinuous delivery, and platform engineering in general. In this section, we will make \nmore explicit connections to the topics introduced in chapter 1. \nFirst, the intention behind creating a Kubernetes cluster and running an application \non top of it was to ensure we cover Kubernetes built-in mechanisms for resilience and \nscaling up our application services. Kubernetes provides the building blocks to run our \napplications with zero downtime, even when we are constantly updating them. This \nallows us, Kubernetes users, to release new versions of our components more frequently, \nbecause we are not supposed to stop the entire application from updating one of its \nparts. In chapter 8 we will see how Kubernetes’ built-in mechanisms can be extended to \nimplement different release strategies. \nIf you are not using the capabilities offered by Kubernetes to keep releasing software \nin front of your customers, then you need to raise a red flag. Quite often, this can be \ndue to old practices from before Kubernetes that are getting in the way, lack of auto-\nmation, or not having clearly defined contracts between services that block dependent \nservices from being released independently. We will touch on this topic several times \nin future chapters because this is a fundamental principle when trying to improve your \ncontinuous delivery practice and something that the platform engineering team needs \nto prioritize.\nIn this chapter, we have also seen how to install a cloud-native application using \na package manager that encapsulates the configuration files required to deploy our \napplication. These configuration files (Kubernetes resources expressed as YAML files) \ndescribe our application topology and contain links to the containers used by each \napplication’s service. These YAML files also contain configuration for each service, \nsuch as the environment variables to configure each service. Packaging and versioning \nthese configuration files allows us to easily create new application instances in different \nenvironments, which we will cover in chapter 4. \nI highly recommend the book Grokking Continuous Delivery by Christie Wilson (Man-\nning Publications, 2018) if you want to get more insights into the continuous delivery \naspects of how configuration as code can help you deliver more software reliably. \nBecause I wanted to make sure that you have an application to play around with and \nbecause we needed to cover Kubernetes built-in mechanisms, I’ve made a conscious \ndecision to start with an already packaged application that can be easily deployed into \nany Kubernetes cluster (no matter if it is running locally or in a cloud provider). We can \nidentify two different phases. One we haven’t covered yet is how to produce these pack-\nages that can be deployed to any Kubernetes cluster, and the second, which we started \nplaying with, is when we run this application in a concrete cluster (we can consider this \ncluster an environment, maybe a development environment), as shown in figure 2.32. \n\n\n\t\n63\nLinking back to platform engineering\nLocal Environment\n Application\n Container \nRegistry\n Install using \nPackage \nManager\n Users can deploy new \ninstances of the \napplication to their local \nor remote environments\nFigure 2.32    \nApplications’ lifecycle \nfrom building and \npackaging to running \ninside an environment\nIt is important to understand that the steps executed for our local environment will \nwork for any Kubernetes cluster, no matter the cluster size and location. While each \ncloud provider will have its own security and identity mechanisms, the Kubernetes APIs \nand resources we created when we installed our application Helm Chart to the cluster \nwill be the same. If you now use Helm templating capabilities to fine-tune your applica-\ntion (for example, resource consumptions and network configurations) for the target \nenvironment, you can easily automate these deployments to any Kubernetes cluster. \nBefore moving on, let’s be clear that pushing developers to configure application \ninstances might not be the best use of their time. A developer accessing the production \nenvironment that users/customers are accessing might also not be optimal. We want to \nensure that developers are focused on building new features and improving our appli-\ncation. Figure 2.33 shows how we should be automating all the steps involved in build-\ning, publishing, and deploying the artifacts that developers are creating, making sure \nthat they can focus on adding features to the application instead of manually dealing \nwith packaging, distributing, and deploying new versions when they are ready. This is \nthe primary focus of this chapter. \nAgenda Service  \nSource Code \nRepository\nFrontend Source \nCode Repository\nC4P Service \nSource Code \nRepository\nNotifications \nService Source \nCode Repository\nTest & Build\nTest & Build\nTest & Build\nTest & Build\nPackage & \nPublish\nPackage & \nPublish\nPackage & \nPublish\nPackage & \nPublish\nDeploy into an \nEnvironment\nDeploy into an \nEnvironment\nDeploy into an \nEnvironment\nDeploy into an \nEnvironment\nEnvironment\nApplication\nFrontend\nAgenda \nService\nC4P Service\nNotifications \nService\nDatabases\nMessage \nBrokers\nInfrastructure\nDevelopers \nchange the \nservices’ source \ncode.\nAutomated tests \nand builds needs \nto be configured\nPackaging, \nversioning and \npublishing the \ngenerated \nartifacts needs to \nbe pain free, and \ntransparent for \ndevelopers.\nDeploying new \nartifacts into a \nsafe environment \nhelp teams to \nvalidate that their \nchanges are \nworking as \nintended\nFigure 2.33    Developers can focus on building features, but the platform team needs to automate the entire \nprocess after changes are made.\n\n\n64\nChapter 2  Cloud-native application challenges \nUnderstanding the tools we can use to automate the path from source code changes \nto running software in a Kubernetes cluster is fundamental to enabling developers to \nfocus on what they do best “code new features.” Another big difference we will tackle \nis that cloud-native applications are not static. As you can see in the previous diagram, \nwe will not install a static application definition. We want to release and deploy new \nversions of the services as they become available. \nManually installing applications is error-prone; manually changing configurations \nin our Kubernetes clusters can make us end up in situations where we don’t know how \nto replicate the current state of our application in a different environment. Hence \nin chapters 3 and 4, we will talk about automation using what is commonly known as \npipelines. \nIn the next chapter, we will cover a more dynamic aspect of our distributed applica-\ntion with pipelines to deliver new versions of our services. Chapter 4 will explore how we \ncan manage our environments using Kubernetes-based GitOps tools.\nSummary\n¡ Choosing between local and remote Kubernetes clusters requires serious \nconsiderations:\n–\t You can use Kubernetes KinD to bootstrap a local Kubernetes cluster to \ndevelop your application. The main drawback is that your cluster is limited by \nyour local resources (CPU and memory) and is not a real cluster of machines. \n–\t You can have an account in a cloud provider and do all development against \na remote cluster. The main drawback of this approach is that most developers \nare not used to working remotely all the time and that someone needs to pay \nfor the remote resources. \n¡ Package managers, like Helm, help you to package, distribute, and install your \nKubernetes applications. In this chapter, you installed an application into a \nKubernetes cluster with a single command line.\n¡ Understanding which Kubernetes resources are created by your application \ngives you an idea about how the application will behave when things go wrong \nand what extra considerations are needed in real-life scenarios.\n¡ Even with very simple applications, you will face challenges that you will have to \ntackle one at a time. Knowing these challenges ahead of time helps you to plan \nand architect your services with the right mindset. \n¡ Having a walking skeleton helps you to try different scenarios and technologies \nin a controlled environment. In this chapter, you have experimented with: \n–\t Scaling up and down your services to see first-hand how the application \nbehaves when things go wrong.\n–\t Keeping state is hard, and we will need dedicated components to do this \nefficiently.\n\n\n\t\n65\nSummary\n–\t Having at least two replicas for our services minimizes downtime. Making sure \nthat the user-facing components are always up and running guarantees that \neven when things go wrong, the user will be able to interact with parts of the \napplication.\n–\t Having fallbacks and built-in mechanisms to deal with problems when they \narise makes your application more resilient. \n¡ If you have followed the linked step-by-step tutorial, you now have hands-on \nexperience creating a local Kubernetes cluster, installing an application, scaling \nup and down services, and, most importantly, checking that the application is \nrunning as expected.\n",
      "page_number": 77
    },
    {
      "number": 10,
      "title": "Segment 10 (pages 85-95)",
      "start_page": 85,
      "end_page": 95,
      "detection_method": "topic_boundary",
      "content": "66\n3\nService pipelines: Building \ncloud-native applications \nThis chapter covers\n¡ Discovering the components for delivering \t\t\n\t cloud-native applications\n¡ Learning the advantages of creating and  \n\t standardizing service pipelines\n¡ Using Tekton, Dagger, and GitHub Actions to \t\n\t build cloud-native applications\nIn the previous chapter, you installed and interacted with a simple distributed Con-\nference application composed of four services. This chapter covers what it takes to \ncontinuously deliver each component using the pipeline concept as a delivery mech-\nanism. This chapter describes and shows in practice how each of these services can \nbe built, packaged, released, and published so they can run in your organization’s \nenvironments. \nThis chapter introduces the concept of service pipelines. The service pipeline takes \nall the steps to build your software from source code until the artifacts are ready to \nrun. This chapter is divided into two main sections: \n\n\n\t\n67\nWhat does it take to deliver cloud-native applications continuously?\n¡ What does it take to deliver a cloud-native applications continuously? \n¡ Service pipelines\n–\t What is a service pipeline?\n–\t Service pipelines in action using: \n¡ Tekton, a Kubernetes native pipeline engine\n¡ Dagger to code your pipelines, and then run everywhere\n¡ Should I use Tekton, Dagger, or GitHub Actions? \n3.1\t\nWhat does it take to deliver cloud-native applications continuously?\nWhen working with Kubernetes, teams are now responsible for more moving pieces \nand tasks involving containers and how to run them in Kubernetes. These extra tasks \ndon’t come for free. Teams must learn to automate and optimize the steps required to \nkeep each service running. Tasks that were the responsibility of the operations teams \nare now becoming more and more the responsibility of the teams in charge of devel-\noping each of the individual services. New tools and new approaches give develop-\ners the power to develop, run, and maintain the services they produce. The tools that \nwe will look at in this chapter are designed to automate all the tasks involved to go \nfrom source code to a service that is up and running inside a Kubernetes cluster. This \nchapter describes the mechanisms to deliver software components (our application \nservices) to multiple environments where these services will run. But before jumping \ninto the tools, let’s take a quick look at the challenges that we are facing. \nBuilding and delivering cloud-native applications present significant challenges that \nteams must tackle:\n¡ Dealing with different team interactions when building different pieces of the applica-\ntion: This requires coordination between teams and ensuring that services are \ndesigned so that the team responsible for a service is not blocking other teams’ \nprogress or their ability to keep improving their services.\n¡ We need to support upgrading a service without breaking or stopping all the other running \nservices: If we want to achieve continuous delivery, services should be upgraded \nindependently without the fear of bringing down the entire application. This \nteams to think about how backward compatible the new version is and whether \nthe new version can run alongside the old version to avoid big bang upgrades.\n¡ Storing and publishing several artifacts per service that can be accessed/downloaded from \ndifferent environments, which might be in different regions: If we are working in a cloud \nenvironment, all servers are remote, and all produced artifacts need to be acces-\nsible for each of these servers to fetch. If you are working on an on-premise setup, \nall the repositories for storing these artifacts must be provisioned, configured, \nand maintained in-house. \n\n\n68\nChapter 3  Service pipelines: Building cloud-native applications  \n¡ Managing and provisioning different environments for various purposes such as devel-\nopment, testing, Q&A, and production: If you want to speed up your development \nand testing initiatives, developers and teams should be able to provision these \nenvironments on demand. Having environments configured as close as possible \nto the real production environment will save you a lot of time catching errors \nbefore they hit your live users. \nAs we saw in the previous chapter, the main paradigm shift when working with cloud-na-\ntive applications is that our application has no single code base. Teams can work inde-\npendently on their services, but this requires new approaches to compensate for the \ncomplexities of working with a distributed system. If teams worry and waste time every \ntime a new service needs to be added to the system, we are doing things wrong. End-to-\nend automation is necessary for teams to feel comfortable adding or refactoring ser-\nvices. This automation is usually performed by what is commonly known as pipelines. \nAs shown in figure 3.1, these pipelines describe what needs to be done to build and run \nour services, and usually, they can be executed without human intervention. \nPipeline\nService Source \nCode\n(in Git)\nEnvironment (Staging)\nService \nRunning\nFigure 3.1    We use the concept of a pipeline to transform source code into an artifact that can run \ninside an environment.\nYou can even have pipelines to automate the creation of a new service or add new users \nto your identity management solution. But what are these pipelines doing exactly? Do \nwe need to create our pipelines from scratch? How do we implement these pipelines in \nour projects? Do we need one or more pipelines to achieve this? \nSection 3.2 is focused on using pipelines to build solutions that can be copied, \nshared, and executed multiple times to produce the same results. Pipelines can be cre-\nated for different purposes, and it is common to define them as a set of steps (one after \nthe other in sequence) that produce a set of expected outputs. Based on these outputs, \nthese pipelines can be classified into different groups. \nMost pipeline tools allow you to define pipelines as a collection of tasks (also known \nas steps or jobs) that will run a specific job or script to perform a concrete action. These \nsteps can be anything, from running tests, copying code from one place to another, \ndeploying software, provisioning virtual machines, creating users, etc. \nPipeline definitions can be executed by a component known as the pipeline engine, \nwhich is responsible for picking up the pipeline definition to create a new pipeline \ninstance that runs each task. The tasks will be executed one after the other in sequence, \n\n\n\t\n69\nWhat does it take to deliver cloud-native applications continuously?\nand each task execution might generate data that can be shared with the following task. \nIf there is an error in any of the steps involved with the pipeline, the pipeline stops, and \nthe pipeline state will be marked as an error (failed). If there are no errors, the pipeline \nexecution (also known as pipeline instance) can be marked as successful. Depending \non the pipeline definition and whether the execution was successful, we should verify \nthat the expected outputs were generated or produced. \nIn figure 3.2, we can see the pipeline engine picking up our pipeline definition and \ncreating different instances that can be parameterized differently for different outputs. \nFor example, Pipeline Instance 1 finished correctly, while Pipeline Instance 2 failed to \nexecute all the tasks included in the definition. Pipeline Instance 3, in this case, is still \nrunning.\nPipeline Definition\nOK\nOK\nOK\nOK\nOK\nOK\nTask\nTask\nTask\nTask\nTask\nTask\nTask\nTask\nTask\nTask\nTask\nTask\nPipeline Instance 1\nPipeline Instance 2\nPipeline Instance 3\nPipeline Engine\nSuccessful\nFailed\nRunning\nFigure 3.2    A pipeline definition can be instantiated by a pipeline engine multiple times, and it describes \nwhat needs to be done. The pipeline engine creates pipeline Instances, which run the tasks included \nin the pipeline definition. These pipeline instances can fail or run for longer periods of time depending \non the tasks that they are performing. As a user, you can always ask the pipeline engine the status of a \nparticular pipeline instance and its tasks.\nAs expected, with these pipeline definitions we can create loads of different automa-\ntion solutions, and it is common to find tools that build more specific solutions on top \nof a pipeline engine or even hide the complexity of dealing with a pipeline engine to \nsimplify the user experience. In the following sections, we will look for examples of \ndifferent tools, some more low-level and flexible, and some higher level, more opin-\nionated, and designed to solve a very concrete scenario. \nBut how do these concepts and tools apply to delivering cloud-native applications? \nFor cloud-native applications, we have very concrete expectations about how to build, \npackage, release, and publish our software components (services) and where these \nshould be deployed. In the context of delivering cloud-native applications, we can \ndefine two main kinds of pipelines:\n¡ Service pipelines: These take care of the building, unit testing, packaging, and dis-\ntributing (usually to an artifact repository) of our software artifacts.\n\n\n70\nChapter 3  Service pipelines: Building cloud-native applications  \n¡ Environment pipelines: These take care of deploying and updating all the services \nin a given environment, such as staging, testing, production, etc., usually con-\nsuming what needs to be deployed from a source of truth. \nChapter 3 focuses on service pipelines, while chapter 4 focuses on tools that help us \nto define environment pipelines using a more declarative approach known as GitOps.\nBy separating the build process (service pipeline) and the deployment process (envi-\nronment pipeline), we give more control to the teams responsible for promoting new \nversions in front of our customers. Service and environment pipelines are executed \non top of different resources and with different expectations. The following section \ngoes into more detail about the steps that we commonly define in our service pipelines. \nChapter 4 covers what is expected of environment pipelines.  \n3.2\t\nService pipelines\nA service pipeline defines and executes all the steps required to build, package, and \ndistribute a service artifact so it can be deployed into an environment. A service pipe-\nline is not responsible for deploying the newly created service artifact, but it can be \nresponsible for notifying interested parties that there is a new version available for the \nservice. \nYou can share the same pipeline definition for different services if you standardize \nhow your services must be built, packaged, and released. Try to avoid pushing each of \nyour teams to define a completely different pipeline for each service, because they will \nprobably reinvent something that has already been defined, tested, and improved by \nother teams. A considerable amount of tasks need to be performed, and a set of conven-\ntions that, when followed, can reduce the time required to perform the whole process. \nThe name service pipeline refers to the fact that each of our application’s services will \nhave a pipeline that describes the tasks required for that particular service. If the ser-\nvices are similar and they are using a similar technology stack, it makes sense for the \npipelines to look quite similar. One of the main objectives of these service pipelines is to \ncontain enough detail to run without any human intervention, automating all the tasks \nin the pipeline end to end. \nService pipelines can be used as a mechanism to improve the communication \nbetween the development team that is creating a service and the operations team that \nis running that service in production. Development teams expect these pipelines to \nrun and notify them if there is any problem with the code they are trying to build. If \nthere are no errors, they will expect one or more artifacts to be produced as part of \nthe pipeline execution. Operations teams can add all the checks to these pipelines to \nensure the produced artifacts are production ready. These checks can include policy \nand conformance checks, signing, security scanning, and other requirements that vali-\ndate that the produced artifacts are up to the standards expected to run in the produc-\ntion environment. \n\n\n\t\n71\nConventions that will save you time\nNOTE    It is tempting to think about creating a single pipeline for the entire \napplication (collection of services), as we did with monolith applications. How-\never, that defeats the purpose of independently updating each service at its own \npace. You should avoid situations with a single pipeline defined for a set of ser-\nvices, because it will block your ability to release services independently. \n3.3\t\nConventions that will save you time\nService pipelines can be more opinionated on their structure and reach. By following \nsome of these strong opinions and conventions, you can avoid pushing your teams to \ndefine every little detail and discover these conventions by trial and error. The follow-\ning approaches have been proven to work: \n¡ Trunk-based development: The idea here is to ensure that what you have in the \nmain branch of your source code repository is always ready to be released. You \ndon’t merge changes that break this branch’s build and release process. You only \nmerge if the changes you are merging are ready to be released. This approach \nalso includes using feature branches, which allow developers to work on features \nwithout breaking the main branch. When the features are done and tested, devel-\nopers can send pull requests (change requests) for other developers to review \nand merge. This also means that when you merge something to the main branch, \nyou can automatically create a new release of your service (and all the related \nartifacts). This creates a continuous stream of releases generated after each new \nfeature is merged into the main branch. Because each release is consistent and \nhas been tested, you can then deploy this new release to an environment that \ncontains all the other services of your application. This approach enables the \nteam behind the service to move forward and keep releasing without worrying \nabout other services. \n¡ Source code and configuration management: There are different approaches to deal-\ning with software and the configuration needed to run the software we are pro-\nducing. When we talk about services and distributed applications, there are two \ndifferent schools of thought: \n–\t One service/one repository/one pipeline: You keep your service source code and all \nthe configurations that need to be built, packaged, released, and deployed in \nthe same repository. This allows the team behind the service to push changes \nat any pace they want without worrying about other services’ source code. It \nis a common practice to have the source code in the same repository where \nyou have the Dockerfile describing how the Docker image should be created \nand the Kubernetes manifest required to deploy the service into a Kubernetes \ncluster. These configurations should include the pipeline definition that will \nbe used to build and package your service. \n–\t Mono repository: Alternatively, use a mono repository approach where a sin-\ngle repository is used, and different pipelines are configured for different \n\n\n72\nChapter 3  Service pipelines: Building cloud-native applications  \ndirectories inside the repository. While this approach can work, you need to \nensure that your teams are not blocking each other by waiting for each other’s \npull requests to merge.  \n¡ Consumer-driven contract testing: Your service uses contracts to run tests against \nother services. Unit testing an individual service shouldn’t require having other \nservices up and running. By creating consumer-driven contracts, each service \ncan test its functionality against other APIs. If any downstream service is released, \na new contract is shared with all the upstream services so they can run their tests \nagainst the new version. \nThere are two books that I strongly recommend:\n¡ Continuous Delivery: Reliable Software Releases through Build, Test, and Deployment \nAutomation by Jez Humble and David Farley (Addison-Wesley Professional, 2010) \n¡ Grokking Continuous Delivery by Christie Wilson (Manning Publications, 2022)\nMost of the tools mentioned in these books allow you to implement these practices \nfor efficient delivery. If we take these practices and conventions into account, we can \ndefine the responsibility of a service pipeline as follows: A service pipeline transforms \nsource code to one or a set of artifacts that can be deployed in an environment. \n3.4\t\nService pipeline structure\nWith this definition in mind, let’s take a look at what tasks are included in service pipe-\nlines for cloud-native applications that will run on Kubernetes: \n¡ Register to receive notifications about changes in the source code repository main branch: \n(Source version control system, nowadays a Git repository.) If the source code \nchanges, we need to create a new release. We create a new release by triggering \nthe service pipeline. This is usually implemented using webhooks or a pull-based \nmechanism that checks if new changes were submitted.\n¡ Clone the source code from the repository: To build the service, we need to clone the \nsource code into a machine that has the tools to build/compile the source code \ninto a binary format that can be executed.\n¡ Create a new tag for the new version to be released: Based on trunk-based development, \na new release can be created every time a change happens. This will help us to \nunderstand what is being deployed and what changes were included in each new \nrelease. \n¡ Build and test the source code:\n–\t As part of the build process, most projects will execute unit tests and break the \nbuild if there are any failures.\n–\t Depending on our technology stack, we will need tools available for this step, \nfor example, compilers, dependencies, linters (static source code analyzers), \netc.\n\n\n\t\n73\nService pipeline structure\n–\t Tools like CodeCov, which measures how much of the code is being covered \nby tests, are used to block changes from being merged if a coverage threshold \nis not met. \n–\t Security scanners are also used to evaluate vulnerabilities on our application \ndependencies. If a new CVE (Common Vulnerabilities and Exposures) is \nfound, the change can be blocked too.\n¡ Publish the binary artifacts into an artifact repository: We need to make sure that these \nbinaries are available for other systems to consume, including the next steps in \nthe pipeline. This step involves copying the binary artifact to a different location \nover the network. This artifact will share the same version of the tag created in \nthe repository, providing us with traceability from the binary to the source code \nused to produce it. \n¡ Building a container image: If we are building cloud-native services, we must build \na container image. The most common way of doing this today is using Docker \nor other container alternatives. This step requires the source code repository to \nhave, for example, a Dockerfile defining how this container image needs to be \nbuilt and the mechanism to build (builder) the container image. Some tools like \nCNCF Buildpacks (https://buildpacks.io) save us from having a Dockerfile and \ncan automate the container-building process. Having the right tools for the job \nis essential, because multiple container images might need to be generated for \ndifferent platforms. For a released service, we might have more than one con-\ntainer image, for example, one for amd64 and one for arm64 platforms. All the \nexamples in this book are built for these two platforms.\n¡ Publish the container image into a container registry: In the same way that we pub-\nlished the binary artifacts generated when building our service source code, we \nneed to publish our container image into a centralized location where others can \naccess it. This container image will have the same version as the tag created in the \nrepository and the binary published. This helps us see which source code will run \nwhen you run the container image. \n¡ Lint, verify, and optionally package YAML files for Kubernetes deployments (Helm can \nbe used here): If you are running these containers inside Kubernetes, you need \nto manage, store, and version a Kubernetes manifest that defines how the con-\ntainers are going to be deployed into a Kubernetes cluster. If you use a package \nmanager such as Helm, you can version the package with the same version used \nfor the binaries and the container image. My rule for packaging YAML files goes \nas follows: “If you have enough people trying to install your services (open-source \nproject or very large globally distributed organization), you might want to pack-\nage and version your YAML files. If you only have a few teams and environments \nto handle, you can probably distribute the YAML files without using a packaging \ntool.” \n¡ (Optional) Publish these Kubernetes manifests to a centralized location: If you are using \nHelm, it makes sense to push these Helm packages (called Charts) to a centralized \n\n\n74\nChapter 3  Service pipelines: Building cloud-native applications  \nlocation. This will allow other tools to fetch these Charts so they can be deployed \nin any number of Kubernetes clusters. As we saw in chapter 2, these Helm Charts \ncan now be distributed as OCI container images to a container registry.\n¡ Notify interested parties about the new version of the service: If we are trying to automate \nfrom a source to a service running, the service pipeline can send notifications to \nall the interested services that might be waiting for new versions to be deployed. \nThese notifications can be pull requests to other repositories, events to an event \nbus, emails to the teams interested in these releases, etc. A pull-based approach \ncan also work, where an agent constantly monitors the artifact repository (or con-\ntainer registry) to see if new versions are available for a given artifact.\nFigure 3.3 shows the steps described in the previous bullet points as a sequence of \nsteps. Most pipeline tools will have a visual representation that allows you to see which \nsteps will be executed.\nClone \nSource \nCode\nBuild & \nTest\nPush to \nrepository\nBuild \nContainer\nPush to \nContainer \nRegistry\nVerify (lint) \nKubernetes \nYAML files \nor Helm \nPackage\nPush \nChart to \nRepository\nNotify new \nversion \navailable\nChange \nin Git\nPipeline Instance\nCreate a Pipeline Instance\nFigure 3.3    Service pipelines automate all the steps required to produce artifacts that can run in \nmultiple environments. Service pipelines are often triggered by changes in source code, but are not in \ncharge of deploying the created artifacts in a specific environment. They can notify other components \nabout these new versions. \nThe outcome of this pipeline is a set of artifacts that can be deployed to an environ-\nment to have the service up and running. The service needs to be built and packaged \nin a way that does not depend on any specific environment. The service can depend \non other services to work in the environment, such as infrastructural components like \ndatabases, message brokers, or other downstream services. \nNo matter the tool that you choose to use to implement these pipelines, you should \nbe looking at the following characteristics: \n\n\n\t\n75\nService pipeline structure\n¡ Pipelines run automatically based on changes (if you follow trunk-based develop-\nment, one pipeline instance is created for every change in the repository’s main \nbranch). \n¡ Pipelines executions will notify about the success or failure state with clear mes-\nsages. This includes having easy ways to find, for example, the why and where the \npipeline failed or how much time it takes to execute each step. \n¡ Each pipeline execution has a unique id that we can use to access the log and \nthe parameters that were used to run the pipeline, so we can reproduce the setup \nthat was used to troubleshoot problems. Using this unique id, we can also access \nthe logs created by all the steps in the pipeline. By looking at the pipeline exe-\ncution, we should also be able to find all the produced artifacts and where those \nwere published. \n¡ Pipelines can also be triggered manually and configured with different parame-\nters for special situations. For example, to test a work-in-progress feature branch. \nLet’s now deep dive into the concrete details of what a service pipeline will look like in \nreal life. \n3.4.1\t\nService pipeline in real life\nIn real life, a service pipeline will run every time you merge changes to the main branch \nof your repository. This is how it should work if you follow a trunk-based development \napproach: \n¡ When you merge changes to your main branch, this service pipeline runs and \ncreates a set of artifacts using the latest code base. If the service pipeline succeeds, \nour artifacts will be releasable. We want to ensure that our main branch is always \nin a releasable state, so the service pipeline that runs on top of the main branch \nmust always succeed. If, for some reason, this pipeline is failing, the team behind \nthe service needs to switch the focus to fixing the problem as soon as possible. In \nother words, teams shouldn’t merge code into your main branch that breaks its \nservice pipeline. We must also run a pipeline in our feature branches to do that. \n¡ For each of your feature branches, a very similar pipeline should run to verify \nthat the changes in the branch can be built, tested, and released against the main \nbranch. In modern environments, the concept of GitHub pull requests is used to \nrun these pipelines to make sure that before merging any pull request, a pipeline \nvalidates the changes. \n¡ It is common that after merging a set of features to the main branch, and because \nwe know that the main branch is releasable at all times, the team in charge of \nthe service decides to tag a new release. In Git, a new tag (a pointer to a specific \ncommit) is created based on the main branch. The tag name is commonly used \nto represent the version of the artifact that the pipeline will create. \nFigure 3.4 shows the pipelines configured for the main branch and a generic pipeline \nto validate feature branches only when pull requests are created. Multiple instances of \nthese pipelines can be triggered to validate new changes continuously. \n\n\n76\nChapter 3  Service pipelines: Building cloud-native applications  \nService Pipeline (main branch)\nService Pipeline (feature branch)\nThis pipeline creates \nreleases that can be \ndeployed by other teams.\nGit\nmain\nfeature X\nThis pipeline creates \nartifacts that can be used \nfor integration testing \nbefore creating releases.\nFigure 3.4    Service pipelines for main branch and feature branches\nThe service pipeline shown in figure 3.4 represents the most common steps you must \nexecute every time you merge something to the main branch. Still, there are also some \nvariations of this pipeline that you might need to run under different circumstances. \nDifferent events can kick off a pipeline execution, and we can have slightly different \npipelines for different purposes, such as: \n¡ Validate a change in a feature branch: This pipeline can execute the same steps as \nthe pipeline in the main branch, but the artifacts generated should include the \nbranch name, maybe as a version or as part of the artifact name. Running a pipe-\nline after every change might be too expensive and not needed all the time, so \nyou should decide based on your needs. \n¡ Validate a pull request (PR)/change request: The pipeline will validate that the pull \nrequest/change request changes are valid and that artifacts can be produced \nwith the recent changes. Usually, the result of the pipeline can be notified back \nto the user in charge of merging the PR and also block the merging options if the \npipeline is failing. This pipeline is used to validate that whatever is merged into \nthe main branch is valid and can be released. Validating pull requests and change \nrequests can be an excellent option to avoid running pipelines for every change \nin the feature branches. When the developer(s) is ready to get feedback from the \nbuild system, it can create a PR that will trigger the pipeline. The pipeline would \nbe retriggered if developers made changes on top of the pull request. \nDespite minor differences and optimizations that can be added to these pipelines, \nthe behavior and produced artifacts are mostly the same. These conventions and \napproaches rely on the pipelines executing enough tests to validate that the produced \nservice can be deployed to an environment. \n3.4.2\t\nService pipeline requirements\nThis section covers the infrastructural requirements for service pipelines to work and \nthe contents of the source repository required for the pipeline to do its work.\nLet’s start with the infrastructural requirements that a service pipeline needs to work: \n",
      "page_number": 85
    },
    {
      "number": 11,
      "title": "Segment 11 (pages 96-108)",
      "start_page": 96,
      "end_page": 108,
      "detection_method": "topic_boundary",
      "content": "\t\n77\nService pipeline structure\n¡ Webhooks for source code change notifications: First, it needs access to register web-\nhooks to the Git repository with the service’s source code, so a pipeline instance \ncan be created when a new change is merged into the main branch. \n¡ Artifact repository available and valid credentials to push the binary artifacts: Once the \nsource code is built, we need to push the newly created artifact to the artifact \nrepository where all artifacts are stored. This requires configuring an artifact \nrepository with valid credentials to push new artifacts. \n¡ Container registry and valid credentials to push new container images: In the same way \nas we need to push binary artifacts, we need to distribute our docker contain-\ners, so Kubernetes clusters can fetch the images when we want to provision a \nnew instance of a service. A container registry with valid credentials is needed to \naccomplish this step. \n¡ Helm Chart repository and valid credentials: Kubernetes manifest can be packaged \nand distributed as Helm Charts. If you are using Helm, you must have a Helm \nChart repository and valid credentials to push these packages.\nFigure 3.5 shows the most common external systems a pipeline instance will interact \nwith. From a Git repository to artifact repositories and container registries, the team \nmaintaining these pipelines must ensure that the right credentials are in place and \nthat these components are reachable (from a network perspective) from where the \npipelines are running. \nGit Repository\nClone \nSource \nCode\nBuild & \nTest\nPush to \nrepository\nBuild \nContainer\nPush to \nContainer \nRegistry\nVerify (lint) \nKubernetes \nYAML files \nor Helm \nPackage\nPush \nChart to \nRepository\nPipeline Instance\nArtifact \nRepository\nDocker Registry\nHelm Chart \nRepository\n<Registered Webhooks>\n<Valid Credentials>\n<Valid Credentials>\n<Valid Credentials>\nFigure 3.5    Running pipelines requires a lot of infrastructure to be in place. This includes maintaining services and \nrepositories, creating users and credentials, and making sure that these services (repositories) are accessible from \nremote locations. \nFor service pipelines to do their job, the repository containing the service’s source \ncode also needs to have a Dockerfile or the ways to produce a container image and the \nnecessary Kubernetes manifest to deploy the service into Kubernetes. \nFigure 3.6 shows a possible directory layout of our service source code repository, \nwhich includes the source (src) directory containing all the files that will be compiled \n\n\n78\nChapter 3  Service pipelines: Building cloud-native applications  \ninto binary format. The Dockerfile is used to build our container image for the service, \nand the Helm Chart directory contains all the files to create a Helm chart that can be \ndistributed to install the service into a Kubernetes cluster. You can decide between hav-\ning a Helm Chart per service or a single Helm Chart for all the application services.\nFigure 3.6 shows the service layout, including the Helm Chart definition. This can \nhelp to package and distribute services independently. If we include everything needed \nto build, package, and run our service into a Kubernetes cluster, the service pipeline \nneeds to run after every change in the main branch to create a new service release. \nHelm Chart Directory: contains all the \nKubernetes YAML ﬁles that we need to \ndeploy our service to Kubernetes\nDockerﬁle: deﬁnes how to create a \ncontainer for our service\nService Pipeline: contains the tasks to \nbuild the contents of this repository\nService’s Source Code: contains the \nsource code from our Service\nFigure 3.6    The service source code repository needs to have all the configurations for the service \npipeline to work.\nIn summary, service pipelines are responsible for building our source and related \nartifacts to be deployed into an environment. As mentioned, service pipelines are not \nresponsible for deploying the produced service into a live environment. The environ-\nment pipeline’s responsibility is covered in the next chapter. \n3.4.3\t\nOpinions, limitations, and compromises around service pipelines \nNo “one size fits all” solution exists for creating our service pipelines. In real life, you \nmust make compromises depending on your requirements. Before looking at tools like \nTekton, Dagger, and GitHub Actions, let me quickly touch on some practical aspects \nI’ve seen teams fighting with. Here is a short and non-comprehensive list of things to \nconsider when designing your service pipelines: \n¡ Avoid strict rules and opinions to define where service pipelines start and end: For \nexample, your services might not need to be packaged as Helm Charts, as men-\ntioned in the previous sections. If there are not enough cases when you want to \ninstall an isolated service—for example, your service depends heavily on other \nservices—removing that step from the service pipeline and the chart definition \nfrom the service repository might make a lot of sense.\n¡ Understand the lifecycle of your components and artifacts: Depending on how often ser-\nvices change and their dependencies, service pipelines can be linked together to \n\n\n\t\n79\nService pipelines in action\nbuild a set of services together. Mapping these relationships and understanding \nthe needs of the teams operating these services will give you the right granular-\nity to create your service pipelines. For example, you can enable your teams to \nkeep releasing new container images for new versions of the services that they are \nworking on, but a different team controls the cadence and release of the Helm \nCharts that bundle all the application services together.\n¡ Find what works best for your organization: Optimize end-to-end automation based \non business priorities. If a critical service is causing delays to be released and \ndeployed, focus on having the service pipeline ready and fully functional before \ntrying to cover other services. There is no point in creating generic solutions that \nmight take a while to figure out that your organization suffers 80% of the cases \nwith a single service.\n¡ Do not create unnecessary steps until they are required: I’ve heavily mentioned tools like \nHelm in this book to package and distribute Kubernetes manifest, but I am not \nsuggesting that is the way to go. I’ve used Helm as an example tool that is widely \nadopted, but you might be in a situation where you don’t need to package your \nKubernetes manifest for distribution. Your service pipeline shouldn’t have that \nstep if that’s the case. If the need arises later, you can extend your service pipe-\nlines to include more steps. \nLet’s now jump to see some tools in this space.\n3.5\t\nService pipelines in action\nThere are several pipeline engines out there, even fully managed services like GitHub \nActions (https://github.com/features/actions) and several well-known CI (continu-\nous integration) managed services that will provide loads of integrations for you to \nbuild and package your application’s services. \nIn the following sections, we will examine two projects: Tekton and Dagger. These \nprojects provide you with the tools to work with cloud-native applications and, as we will \nsee in chapter 6, enable platform teams to package, distribute, and reuse the organi-\nzation’s specific knowledge built over time. Tekton (https://tekton.dev) was designed \nas a pipeline engine for Kubernetes. Because Tekton is a generic pipeline engine, you \ncan create any pipeline with it. On the other hand, a much newer project called Dagger \n(https://dagger.io) was designed to run everywhere. We will contrast Tekton and Dag-\nger with GitHub actions.\n3.5.1\t\nTekton in action\nTekton was initially created as part of the Knative project (https://knative.dev) from \nGoogle. (We will look more into Knative in chapter 8). Tekton was initially called Kna-\ntive Build, and later separated from Knative to be an independent project. Tekton’s \nmain characteristic is that it is a cloud-native pipeline engine designed for Kubernetes. \nThis section will look into how to use Tekton to define service pipelines. \n\n\n80\nChapter 3  Service pipelines: Building cloud-native applications  \nIn Tekton, you have two main concepts: tasks and pipelines. In Tekton, the pipeline \nengine is a set of components that understand how to execute Tasks and Pipelines \nKubernetes resources. Tekton, like most of the Kubernetes projects covered in this \nbook, can be installed into your Kubernetes cluster. I strongly recommend you check \ntheir official documentation page, which explains the value of using a tool like Tekton \nat https://tekton.dev/docs/concepts/overview/. \nNOTE    I’ve included a set of step-by-step tutorials in this repository. You can \nstart by looking at how to install Tekton in your cluster and the tekton/hello \n-world/ example at https://github.com/salaboy/platforms-on-k8s/tree/main/ \nchapter-3/tekton.\nWhen you install Tekton, you install a set of custom resource definitions, which are \nextensions to the Kubernetes APIs, that define tasks and pipelines. Tekton also installs \nthe pipeline engine that knows how to deal with Tasks and Pipelines resources. \nNotice that after installing Tekton, you can also install the Tekton Dashboard and the \ntkn command-line interface tool.\nOnce you install the Tekton release, you will see a new namespace called tekton \n-pipelines, which contains the pipeline controller (the pipeline engine), and the \npipeline webhook listener, which is used to listen for events coming from external \nsources, such as git repositories. \nA task in Tekton will look like a normal Kubernetes resource, as shown in listing 3.1.\nListing 3.1    Simple Tekton task definition\napiVersion: tekton.dev/v1\nkind: Task\nmetadata:\n name: hello-world-task\nspec:\n  params:\n   - name: name\n     type: string\n     description: who do you want to welcome?\n     default: tekton user\n steps:\n   - name: echo\n     image: ubuntu\n     command:\n       - echo\n     args:\n       - \"Hello World: $(params.name)\" \nThe name of the resource defined \nin metadata.name represents the \ntask definition name.\nWe can use the \nparams section to \ndefine which \nparameters can be \nconfigured for our \ntask definition.\nThe Docker image \ncalled Ubuntu is \ngoing to be used for \nthis task.\nThe command \narguments (args) \nin this case are \njust a “Hello \nWorld” string; \nnotice that you \ncan send a list of \narguments for \nmore complex \ncommands.\nThe command arguments (args) in this case\n are just a “Hello World: $(params.name)” \nstring, which will use the Task parameter.\n\n\n\t\n81\nService pipelines in action\nYou can find the task definition in this repository, alongside a step-by-step tutorial to \nrun it in your cluster: https://github.com/salaboy/platforms-on-k8s/blob/main/\nchapter-3/tekton/hello-world/hello-world-task.yaml. \nDerived from this example, you can create a task for whatever you want, because you \nhave the flexibility to define which container to use and which commands to run. Once \nyou have the task definition, you need to make that available to Tekton by applying this \nfile to the cluster with kubectl apply -f task.yaml. By applying the file into Kuber-\nnetes, we are only making the definition available to the Tekton components in the \ncluster, but the task will not run. \nIf you want to run this task, a task can be executed multiple times. Tekton requires \nyou to create a TaskRun resource like the following listing.\nListing 3.2    A task run represents an instance of our task definition\napiVersion: tekton.dev/v1\nkind: TaskRun\nmetadata:\n  name: hello-world-task-run-1\nspec:\n  params: \n  - name: name\n    value: \"Building Platforms on top of Kubernetes reader!\" \n  taskRef:\n    name: hello-world-task\nThe TaskRun resource can be found at https://github.com/salaboy/platforms-on \n-k8s/blob/main/chapter-3/tekton/hello-world/task-run.yaml. \nIf you apply this TaskRun to the cluster (kubectl apply -f taskrun.yaml), the \npipeline engine will execute this task. You can take a look at the Tekton task in action by \nlooking at the TaskRun resources in listing 3.3. \nListing 3.3    Get all TaskRun instances\n> kubectl get taskrun\nNAME                             SUCCEEDED       STARTTIME   COMPLETIONTIME\nhello-world-task-run-1           True            66s         7s\nIf you list all the running pods, you will notice that each task creates a pod, as shown in \nlisting 3.4. \nWe can define specific \nparameter values for \nthis TaskRun.\nWe need to reference the name of \nthe task definition that we want to \nrun. Notice that this name is unique \nper task resource that we define.\n\n\n82\nChapter 3  Service pipelines: Building cloud-native applications  \nListing 3.4    List all the pods associated to TaskRuns\n> kubectl get pods \nNAME                                     READY   STATUS   AGE\nhello-world-task-run-1-pod               0/1     Init:0/1 2s\nAnd because you have a pod, you can tail the logs to see what the task is doing as in \nlisting 3.5. \nListing 3.5    Accessing the TaskRun logs using the pod name\n> kubectl logs -f hello-world-task-run-1-pod  \nDefaulted container \"step-echo\" out of: step-echo, prepare (init) \nHello World: Building Platforms on top of Kubernetes reader!\nYou just executed your first Tekton TaskRun. Congrats! But a single task is not interest-\ning at all. If we can sequence multiple tasks together, we can create our service pipe-\nlines. Let’s look at how we can build Tekton pipelines from this simple task example. \n3.5.2\t\nPipelines in Tekton\nA task can be helpful, but Tekton becomes interesting when you create sequences of \nthese tasks using pipelines. \nA pipeline is a collection of these tasks in a concrete sequence. The following pipe-\nline uses the task definition that we defined earlier. It prints a message, fetches a file \nfrom a URL, and then reads its content, which is forwarded to our Hello World task, \nwhich prints a message. \nFigure 3.7 shows a simple Tekton pipeline comprising three Tekton tasks. \n'wget'\n'cat'\nHello World!\nDownload a file \nfrom a 'url'\nReads the file that was \ndownloaded and set \nthe content in \n'results.message'\nPrints “Hello World:” \nappending the content of \n'results.message'\nFigure 3.7    Simple Tekton pipeline using our Hello World task\nIn this simple pipeline, we are using an existing task definition (wget) from the Tekton \nHub, which is a community repository hosting generic tasks, and then we are defining \nthe cat task inline inside the pipeline to showcase Tekton flexibility, to finally use the \nHello World task that we defined in the previous section.\nLet’s look at a simple service pipeline defined in Tekton (hello-world-pipeline \n.yaml). Don’t be scared. This is a lot of YAML, I warned you. See listing 3.6. \n\n\n\t\n83\nService pipelines in action\nListing 3.6    Pipeline definition\napiVersion: tekton.dev/v1\nkind: Pipeline\nmetadata:\n  name: hello-world-pipeline\n  annotations:\n    description: |\n      Fetch resource from internet, cat content and then say hello\nspec:\n  results:  \n  - name: message\n    type: string\n    value: $(tasks.cat.results.messageFromFile)\n  params: \n  - name: url\n    description: resource that we want to fetch\n    type: string\n    default: \"\"\n  workspaces: \n  - name: files\n  tasks:\n  - name: wget\n    taskRef: \n      name: wget\n    params:\n    - name: url\n      value: \"$(params.url)\"\n    - name: diroptions\n      value:\n        - \"-P\"  \n    workspaces:\n    - name: wget-workspace\n      workspace: files\n  - name: cat\n    runAfter: [wget]\n    workspaces:\n    - name: wget-workspace\n      workspace: files\n    taskSpec:  \n      workspaces:\n      - name: wget-workspace\n      results: \n        - name: messageFromFile\n          description: the message obtained from the file\n      steps:\nPipeline resources can define an array of \nresults that are expected from the pipeline \nwhen they are executed. Tasks can set these \nresults values when they are executed.\nIn the same way as \ntasks, we can define \nwhich parameters can \nbe set by the user \nwhen running this \npipeline. These \npipeline parameters \ncan be forwarded to \nindividual tasks if \nneeded.\nPipelines and tasks allow \nthe use of Tekton \nWorkspaces to store \npersistent information. \nThis can be used to share \ninformation between \ntasks. As each task is \nexecuted in its container, \nusing persistent storage \nto share information is \neasy to set up.\nWe use a task \nreference to a task we \ndidn’t create. We need \nto make sure to install \nthis task definition \nbefore creating a \nPipelineRun for this \npipeline.\nWe can define tasks inline the pipeline if we want to. \nThis makes the pipeline file more complicated, but \nsometimes it is useful to have a task that just glues \nother tasks together, as is shown in this case. The only \npurpose of this task is to read the content of the \ndownloaded file and make it available as a String for \nour Hello World task that doesn’t accept a file. \n\n\n84\nChapter 3  Service pipelines: Building cloud-native applications  \n      - name: cat\n        image: bash:latest\n        script: |\n          #!/usr/bin/env bash\n          cat $(workspaces.wget-workspace.path)/welcome.md |  \n➥tee /tekton/results/messageFromFile\n  - name: hello-world\n    runAfter: [cat]\n    taskRef:\n      name: hello-world-task  \n    params:\n      - name: name\n        value: \"$(tasks.cat.results.messageFromFile)\"  \nYou can find the full pipeline definition at https://github.com/salaboy/platforms \n-on-k8s/blob/main/chapter-3/tekton/hello-world/hello-world-pipeline.yaml. \nBefore applying the pipeline definition, you need to install the wget Tekton task that \nwas created and maintained by the Tekton community: \nkubectl apply -f\n➥https://raw.githubusercontent.com/tektoncd/catalog/main/task/wget/0.1/wget.yaml\nOnce again, you must apply this pipeline resource to your cluster for Tekton to know \nabout: kubectl apply -f hello-world-pipeline.yaml.\nAs you can see in the pipeline definition, the spec.tasks field contains an array of \ntasks. These tasks need to be already deployed into the cluster, and the pipeline defini-\ntion defines the sequence in which these tasks will be executed. These task references \ncan be your tasks, or as in the example, they can come from the Tekton catalog, a repos-\nitory containing community-maintained task definitions that you can reuse. \nIn the same way, because tasks need TaskRuns for the executions, you will need to \ncreate a PipelineRun for every time you want to execute your pipeline, as shown in the \nfollowing listing. \nListing 3.7    PipelineRun represent an instance (execution) of our pipelines\napiVersion: tekton.dev/v1\nkind: PipelineRun\nmetadata:\n  name: hello-world-pipeline-run-1\nspec:\n  workspaces: \n    - name: files\n      volumeClaimTemplate: \n        spec:\nThis also requires installing the “hello-world-\ntask” definition in the cluster. Remember \nthat you can always run “kubectl get tasks” \nto see which tasks are available.\nWe can use Tekton’s powerful templating mechanism \nto provide the value for Hello World task. We are using \na reference to the “cat” task results.\nWhen we create a PipelineRun, we need to \nbound the workspaces defined in the \npipeline definition to real storage. In this \ncase a VolumeClaim is created requesting 1 \nMb of storage for the PipelineRun to use. \n\n\n\t\n85\nService pipelines in action\n          accessModes:\n          - ReadWriteOnce\n          resources:\n            requests:\n              storage: 1M \n  params: \n  - name: url\n    value: \n➥\"https://raw.githubusercontent.com/salaboy/salaboy/main/welcome.md\"\n  pipelineRef:\n    name: hello-world-pipeline\nYou can find the PipelineRun resource at https://github.com/salaboy/platforms-on \n-k8s/blob/main/chapter-3/tekton/hello-world/pipeline-run.yaml. \nWhen you apply this file to the cluster kubectl apply -f pipeline-run.yaml, Tek-\nton will execute the pipeline by running all the tasks defined in the pipeline definition. \nWhen running this pipeline, Tekton will create one pod per task and three TaskRun \nresources. A pipeline is just orchestrating tasks, or in other words creating TaskRuns. \nTo check that the TaskRuns were created and that the pipeline executed successfully, \nsee listing 3.8. \nListing 3.8    Getting task runs from the pipeline execution\n> kubectl get taskrun\nNAME                                   SUCCEEDED  STARTTIME  COMPLETIONTIME\nhello-world-pipeline-run-1-cat         True       109s       104s\nhello-world-pipeline-run-1-hello-world True       103s       98s\nhello-world-pipeline-run-1-wget        True       117s       109s\nFor each TaskRun, Tekton created a pod (listing 3.9).\nListing 3.9    Checking that all TaskRuns belonging to the pipeline have finished\n> kubectl get pods\nNAME                                         READY   STATUS         AGE\nhello-world-pipeline-run-1-cat-pod           0/1     Completed      11s\nhello-world-pipeline-run-1-hello-world-pod   0/1     Completed      5s\nhello-world-pipeline-run-1-wget-pod          0/1     Completed      19s\nReview the logs from the hello-world-pipeline-run-1-hello-world-pod to see \nwhat the task printed, as shown in listing 3.10. \nListing 3.10    Getting the logs from the last task\n> kubectl logs hello-world-pipeline-run-1-hello-world-pod\nDefaulted container \"step-echo\" out of: step-echo, prepare (init)\nHello World: Welcome, Internet traveler! Do you want to learn more about \nPlatforms on top of Kubernetes? Check this repository: https://github.com/\nsalaboy/platforms-on-k8s\nThe pipeline parameter “url” can be any \nURL that you want as soon because it is \naccessible from the PipelineRun context \n(meaning that it can reach the URL, and \nit is not behind a firewall). \nAs with tasks, we need to provide the \nname of the pipeline definition that \nwe want to use for this PipelineRun.\n\n\n86\nChapter 3  Service pipelines: Building cloud-native applications  \nYou can always look at Tasks, TaskRuns, Pipelines, and PipelineRuns in the Tekton \ndashboard. To access the Tekton dashboard, if you installed it in your cluster, you need \nto first run: \n> kubectl port-forward -n tekton-pipelines \n➥services/tekton-dashboard 9097:9097\nFigure 3.8 shows the Tekton dashboard user interface, where we can explore our task \nand pipeline definitions as well as trigger new task and pipeline runs and explore the \nlogs that each task outputs.\nFigure 3.8    Our PipelineRun execution in the Tekton dashboard\nIf required, you can find a step-by-step tutorial on how to install Tekton in your Kuber-\nnetes cluster and how to run the service pipeline at the following repository: https://\ngithub.com/salaboy/platforms-on-k8s/blob/main/chapter-3/tekton/hello-world/\nREADME.md. \nAt the end of the tutorial, you will find links to more complex pipelines I’ve defined \nfor each Conference application service. These pipelines are more complex because \nthey require access to external services, credentials to publish artifacts and container \nimages, and the rights to do some privileged actions inside the cluster. Check this sec-\ntion of the tutorial if you are interested in more details: https://github.com/salaboy/\nplatforms-on-k8s/tree/main/chapter-3/tekton#tekton-for-service-pipelines. \n3.5.3\t\nTekton advantages and extras\nAs we have seen, Tekton is super flexible and allows you to create advanced pipelines, \nand it includes other features, such as: \n¡ Input and output mappings to share data between tasks\n¡ Event triggers that allow you to listen for events that will trigger pipelines or tasks\n¡ A command-line tool to easily interact with tasks and pipelines from your terminal\n¡ A simple dashboard to monitor your pipelines and task executions (figure 3.9)\n\n\n\t\n87\nService pipelines in action\nFigure 3.9    Tekton dashboard—a user interface for monitoring your pipelines\nFigure 3.9 shows the community-driven Tekton dashboard, which you can use to visu-\nalize the execution of your pipelines. Remember that because Tekton was built to work \non top of Kubernetes, you can monitor your pipelines using kubectl as with any other \nKubernetes resource. Still, nothing beats a user interface for less technical users. \nBut now, if you want to implement a service pipeline with Tekton, you will spend \nquite a bit of time defining tasks, the pipeline, how to map inputs and outputs, defin-\ning the right events listener for your Git repositories, and then going more low-level \ninto defining which docker images you will use for each task. Creating and maintaining \nthese pipelines and their associated resources can become a full-time job, and for that, \nTekton launched an initiative to define a catalog where tasks (pipelines and resources \nare planned for future releases) can be shared. The Tekton catalog is available at \nhttps://github.com/tektoncd/catalog. \nWith the help of the Tekton catalog, we can create pipelines that reference tasks \ndefined in the catalog. In the previous section, we used the wget task downloaded from \nthis catalog; you can find a full description of the wget task at https://hub.tekton.dev/\ntekton/task/wget. Hence, we don’t need to worry about defining them. You can also \nvisit https://hub.tekton.dev, which allows you to search for task definitions and pro-\nvides detailed documentation about installing and using these tasks in your pipelines \n(figure 3.10).\nTekton Hub and the Tekton catalog allow you to reuse tasks and pipelines created by \na large community of users and companies. I strongly recommend you check out the \nTekton Overview page, which summarizes the advantages of using Tekton, including \nwho should use Tekton and why: https://tekton.dev/docs/concepts/overview/. \n\n\n88\nChapter 3  Service pipelines: Building cloud-native applications  \nFigure 3.10    Tekton Hub is a portal to share and reuse tasks and pipeline definitions\nTekton is quite a mature project in the cloud-native space, but it also presents some \nchallenges:\n¡ You need to install and maintain Tekton running inside a Kubernetes cluster. You \ndon’t want your pipelines running right beside your application workloads, so \nyou might need a separate cluster.\n¡ There is no easy way to run a Tekton pipeline locally. For development purposes, \nyou rely on having access to a Kubernetes cluster to run a pipeline manually.\n¡ You need to know Kubernetes to define and create tasks and pipelines.\n¡ While Tekton provides some conditional logic, it is limited by what you can do in \nYAML and using a declarative approach of Kubernetes.\nWe will now jump into a project called Dagger that was created to mitigate some of \nthese points, not to replace Tekton but to provide a different approach to solving \neveryday challenges when building complex pipelines. \n3.5.4\t\nDagger in action\nDagger (https://dagger.io) was born with one objective: “to enable developers to build \npipelines using their favorite programming language that they can run everywhere.” \nDagger only relies on a container runtime to run pipelines that can be defined using \ncode that every developer can write. Dagger currently supports Go, Python, Type-\nScript, and JavaScript SDKs, but the team behind Dagger is quickly expanding to new \nlanguages. \nDagger is not focused on Kubernetes only. Platform teams must ensure that while \nteams use Kubernetes’ powerful and declarative nature, also development teams can \n\n\n\t\n89\nService pipelines in action\nbe productive and use the appropriate tool for the job. This short section will examine \nhow Dagger compares with Tekton, where it can fit better, and where it can comple-\nment other tools. \nIf you are interested in getting started with Dagger, you can check these resources: \n¡ Dagger docs: https://docs.dagger.io \n¡ Dagger Quickstart: https://docs.dagger.io/648215/quickstart/ \n¡ Dagger GraphQL playground: https://play.dagger.cloud\nDagger, like Tekton, also has a pipeline engine, but this engine can work both locally \nand remotely, providing a unified runtime across environments. Dagger doesn’t \ndirectly integrate with Kubernetes. This means that there are no Kubernetes CRDs or \nYAML involved. This can be important depending on the skills and preferences of the \nteams in charge of creating and maintaining these pipelines.\nIn Dagger, we define pipelines by writing code. Because pipelines are just code, these \npipelines can be distributed using any code packaging tools. For example, if our pipe-\nlines are written in Go, we can use Go modules to import pipelines or tasks written by \nother teams. If we use Java, we can use Maven or Gradle to package and distribute our \npipeline libraries to promote reuse.\nFigure 3.11 shows how development teams can write pipelines using the Dagger \nSDKs and then use the Dagger engine to execute these pipelines using any OCI Con-\ntainer Runtime such as Docker or PodMan. It doesn’t matter if you want to run your \npipelines in your local development environment (your laptop with Docker for Mac \nor Windows), your continuous integration environment, or even inside Kubernetes. \nThese pipelines will behave in the same way.\nFigure 3.11    Using your preferred programming language and its tools to write pipelines (Source: dagger.io)\nThe Dagger pipeline engine is then in charge of orchestrating the tasks defined in the \npipelines and optimizing what is requested by the container runtime used to execute \neach task. A significant advantage of the Dagger pipeline engine is that it was designed \n",
      "page_number": 96
    },
    {
      "number": 12,
      "title": "Segment 12 (pages 109-140)",
      "start_page": 109,
      "end_page": 140,
      "detection_method": "topic_boundary",
      "content": "90\nChapter 3  Service pipelines: Building cloud-native applications  \nfrom the ground up to optimize how pipelines run. Imagine that you are building tons \nof services multiple times a day. You will not only keep your CPUs hot, but the amount \nof traffic downloading artifacts, again and again, becomes expensive—more if you are \nrunning on top of a cloud provider, which charges you based on consumption. \nDagger, similar to Tekton, uses containers to execute each task (step) in the pipeline. \nThe pipeline engine optimizes the resource consumption by caching the results of pre-\nvious executions, preventing you from re-executing tasks that were already executed \nusing the same inputs. In addition, you can run the Dagger engine locally on your lap-\ntop/workstation or remotely, even inside a Kubernetes cluster. \nWhen I compare Dagger to something like Tekton, with my developer background, \nI tend to like the flexibility of coding pipelines using a programming language I am \nfamiliar with. For developers to create, version and share code is easy, because I don’t \nneed to learn any new tools. \nInstead of looking at a Hello World example, I wanted to show how a service pipe-\nline would look in Dagger. So, let’s look at how a service pipeline is defined using the \nDagger Go SDK. The following code snippet shows a service pipeline defining the \nmain goals we want to execute for each service. Take a look at the buildService, test \nService, and publishService functions. These functions codify what it means to \nbuild, test, and publish each service. These functions use the Dagger client to execute \nactions inside containers that Dagger will orchestrate, as shown in listing 3.11.\nListing 3.11    Go application defining tasks using Dagger\nfunc main() {\n  var err error\n  ctx := context.Background()\n  if len(os.Args) < 2 {\n    ...)\n  }\n  client := getDaggerClient(ctx)\n  defer client.Close()\n  switch os.Args[1] {\n    case \"build\":\n      if len(os.Args) < 3 {\n        panic(...)\n      }\n      _, err = buildService(ctx, client, os.Args[2])\n      \n    case \"test\":\n      err = testService(ctx, client, os.Args[2])\n    case \"publish\":\n      pv, err := buildService(ctx, client, os.Args[2])\n     \n      err = publishService(ctx, client, os.Args[2], pv, os.Args[3])\n    case \"all\":\n      pv, err := buildService(ctx, client, os.Args[2])\n      err = testService(ctx, client, os.Args[2])\n\n\n\t\n91\nService pipelines in action\n      err = publishService(ctx, client, os.Args[2], pv, os.Args[3])\n   default:\n     log.Fatalln(\"invalid command specified\")\n}\nYou can find the service-pipeline.go definition at https://github.com/salaboy/\nplatforms-on-k8s/blob/main/conference-application/service-pipeline.go. \nBy running go run service-pipeline.go build notifications-service \nDagger will use containers to build our Go application source code and then build a \ncontainer ready to be pushed to a container registry. If you look at the buildService \nfunction in listing 3.12, you will notice that it builds our service source code, in this \ncase, looping over a list of target platforms (amd64 and arm64) to produce binaries for \neach of them. Once the binaries are produced, a container is created using the Dagger \nclient client.Container function. Because we are defining each step programmati-\ncally, we can also define what needs to be cached for subsequent builds (using client.\nCacheVolume). \nListing 3.12    Tasks: Go code that uses Dagger built-in functions\nfunc buildService(ctx context.Context, \n                  client *dagger.Client, \n                  dir string) ([]*dagger.Container, error) {\n  srcDir := client.Host().Directory(dir)\n  platformVariants := make([]*dagger.Container, 0, len(platforms))\n  for _, platform := range platforms {\n    ctr := client.Container()\n    ctr = ctr.From(\"golang:1.20-alpine\")\n    // mount in our source code\n    ctr = ctr.WithDirectory(\"/src\", srcDir)\n    ctr = ctr.WithMountedCache(\"/go/pkg/mod\", client.CacheVolume(\"go-mod\"))\n    ctr = ctr.WithMountedCache(\"/root/.cache/go-build\", \n    ➥ client.CacheVolume(\"go-build\"))\n    // mount in an empty dir to put the built binary\n    ctr = ctr.WithDirectory(\"/output\", client.Directory())\n    // ensure the binary will be statically linked and thus executable\n    // in the final image\n    ctr = ctr.WithEnvVariable(\"CGO_ENABLED\", \"0\")\n    // configure go to support different architectures\n    ctr = ctr.WithEnvVariable(\"GOOS\", \"linux\")\n    ctr = ctr.WithEnvVariable(\"GOARCH\", architecture(platform))\n    // build the binary and put the result at the mounted output directory\n    ctr = ctr.WithWorkdir(\"/src\")\n    ctr = ctr.WithExec([]string{\"go\", \"build\",\"-o\", \"/output/app\",\".\",})\n    // select the output directory\n    outputDir := ctr.Directory(\"/output\")\n\n\n92\nChapter 3  Service pipelines: Building cloud-native applications  \n    // create a new container with the output and the platform label\n    binaryCtr := client.Container(dagger.ContainerOpts{Platform: platform}).\n                        WithEntrypoint([]string{\"./app\"}).\n                        WithRootfs(outputDir)\n    platformVariants = append(platformVariants, binaryCtr)\n  }\n  return platformVariants, nil\n}\nThese pipelines are written in Go and build Go applications, but nothing stops you \nfrom building other languages and using the necessary tools. Each task is just a con-\ntainer. Dagger and the open-source community will create all the basic building blocks, \nbut each organization has to create domain-specific libraries to integrate with third-\nparty or in-house/legacy systems. By focusing on enabling developers, Dagger lets you \nchoose the right tool(s) to create these integrations. There is no need to write plugins, \njust code that can be distributed as any other library. \nTry running the pipeline for one of the services or follow the step-by-step tutorial that \nyou can find at https://github.com/salaboy/platforms-on-k8s/blob/main/chapter-3/ \ndagger/README.md. If you run the pipeline twice, the second run will be almost \ninstant since most steps are cached. \nIn contrast with Tekton, we are running the Dagger pipeline locally, not in a Kuber-\nnetes cluster, which has advantages. For example, we don’t need a Kubernetes cluster to \nrun and test this pipeline, and we don’t need to wait for remote feedback. Developers \ncan run these pipelinesby using a local container runtime (like Docker or Podman), \nincluding integration tests, before pushing any changes to the Git repository. Having \nfast feedback allows them to go faster.\nBut now, how does this translate to a remote environment? What if we want to run this \npipeline remotely on a Kubernetes cluster? The good news is that it works the same: it is \njust a remote Dagger pipeline engine that will execute our pipelines. No matter where \nthis remote pipeline engine is, running inside Kubernetes or as a managed service, our \npipeline behavior and the caching mechanisms provided by the pipeline engine will \nbehave the same way. Figure 3.12 shows how the execution will go if we install the Dag-\nger pipeline engine inside Kubernetes and run the same pipelines.\nDagger Go SDK\nGo\npipeline.go\nKubernetes Cluster\nDagger Pipeline \nEngine\nContainer Runtime\nCache\nFigure 3.12    When configured against a remote Dagger Pipeline Engine, the Dagger SDK will collect and \nsend the context for the pipeline to be executed remotely.\n\n\n\t\n93\nService pipelines in action\nWhen the Dagger Pipeline Engine is installed in a remote environment such as a \nKubernetes Cluster, virtual machine, or any other computing resource, we can connect \nand run our pipelines against it. The Dagger Go SDK takes all the context needed \nfrom the local environment and sends it to the Dagger Pipeline Engine to execute the \ntasks remotely. We don’t need to worry about publishing our application source code \nonline for the pipeline. \nCheck this step-by-step tutorial on how to run your Dagger pipelines on Kubernetes: \nhttps://github.com/salaboy/platforms-on-k8s/blob/main/chapter-3/dagger/\nREADME.md#running-your-pipelines-remotely-on-kubernetes. \nAs you can see, Dagger will use persistent storage (Cache) to cache all the builds \nand tasks to optimize performance and reduce pipeline running times. The operations \nteam in charge of deploying and running Dagger inside Kubernetes will need to track \nhow much storage is needed based on the pipelines the organization is running. \nIn this short section, we have seen how to use Dagger to create our service pipelines. \nWe have seen that Dagger is very different from Tekton: you don’t need to write your \npipelines using YAML, you can write your pipelines in any supported programming lan-\nguage, you can run your pipelines locally or remotely using the same code, and you can \ndistribute your pipelines using the same tools that you are using for your applications. \nFrom a Kubernetes point of view, when you use a tool like Dagger, you lose the Kuber-\nnetes native approach of managing your pipelines as you manage your other Kuber-\nnetes resources. I see the Dagger community expanding in that direction if they get \nenough feedback and requests for that. \nFrom a platform engineering perspective, you can create and distribute complex \npipelines (and tasks) for your teams to use and extend using tools they already know. \nThese pipelines will run the same way no matter where they are executed, making it an \nextremely flexible solution. Platform teams can take this flexibility to decide where to \nrun these pipelines more efficiently (based on costs and resources) without complicat-\ning developers’ lives, as they will always be able to run their pipelines locally for devel-\nopment purposes. \n3.5.5\t\nShould I use Tekton, Dagger, or GitHub Actions?\nAs you have seen, Tekton and Dagger provide us with the basic building blocks to con-\nstruct unopinionated pipelines. In other words, we can use Tekton and Dagger to build \nservice pipelines and almost every imaginable pipeline. With Tekton, we use the Kuber-\nnetes resource-based approach, scalability, and self-healing features. Using Kuberne-\ntes-native resources can be very helpful in integrating Tekton with other Kubernetes \ntools, such as managing and monitoring Kubernetes resources. Using the Kubernetes \nresource model, you can treat your Tekton pipelines and PipelineRuns as any other \nKubernetes resource and reuse all the existing tooling.\nWith Dagger, we can define our pipelines using well-known programming languages \nand tools and run these pipelines everywhere (locally in our workstations in the same \nway as if we were running them remotely). This makes Tekton and Dagger perfect tools \n\n\n94\nChapter 3  Service pipelines: Building cloud-native applications  \nthat platform builders can use to build more opinionated pipelines that development \nteams can use. \nOn the other hand, you can use a managed service such as GitHub Actions. You can \nlook at how the service pipelines are configured using GitHub actions for all the proj-\nects mentioned here. For example, you can check the service pipeline for the notifi-\ncations service at https://github.com/salaboy/platforms-on-k8s/blob/main/.github/\nworkflows/notifications-service-service-pipelines.yaml. \nThis GitHub Action pipeline uses ko-build to build the service and then pushes \nthe new container image to Docker Hub. Notice that this pipeline doesn’t run any \ntests, and it uses a custom step (https://github.com/salaboy/platforms-on-k8s/blob/\nmain/.github/workflows/notifications-service-service-pipelines.yaml#L17) to check if \nthe code for the service was changed; only run the build and push to Docker Hub if \nthere were changes to the service source code. \nThe advantage of using GitHub Actions is that you don’t need to maintain the infra-\nstructure running them or pay for the machines that run these pipelines (if your vol-\nume is small enough). But if you are running loads of pipelines and these pipelines are \ndata-intensive, GitHub Actions will be costly.\nFor cost-related reasons or because you cannot run your pipelines in the cloud due \nto industry regulations, Tekton and Dagger shine in providing you with all the building \nblocks to compose and run complex pipelines. While Dagger is already focused on cost \nand runtime optimization, this is coming for Tekton and other pipeline engines. \nIt is important to note that you can integrate Tekton and Dagger with GitHub. For \nexample, use Tekton Triggers (https://github.com/tektoncd/triggers/blob/main/\ndocs/getting-started/README.md) to react to commits into a GitHub repository. You \ncan also run Dagger inside a GitHub Action, enabling developers to run the same pipe-\nline locally executed in GitHub Actions, which cannot be done easily out of the box.\nNow that we have our artifacts and configurations ready to be deployed to multiple \nenvironments, let’s look at what is commonly known as the GitOps approach for contin-\nuous deployment through environment pipelines.  \n3.6\t\nLinking back to platform engineering\nAs part of your platform initiatives, you will need to help teams build their services in \nan automated way. Most of the time, a decision must be made to standardize how the \nservices will be built and packaged across teams. If the platform team can provide a \nsolution that is accessible to teams to try out locally or have the right environments \nto test before pushing changes to a Git repository, this will increase the velocity and \nfeedback loop that these teams need to move with confidence. A separate setup might \nbe needed to validate pull requests and alert teams if their repositories’ main branch \nis unreleasable.\nWhile GitHub Actions (and other managed services) are a popular solution, plat-\nform engineering teams might choose different tools or services based on their budgets \nand other platform-wide decisions (such as aligning with the Kubernetes APIs). \n\n\n\t\n95\nLinking back to platform engineering\nI’ve made conscious choices for this book’s demos and step-by-step tutorials (https://\ngithub.com/salaboy/platforms-on-k8s/tree/main/chapter-3) that might differ greatly \nfrom your projects. First, because the complexity of the projects presented in this book \nis quite low, but also because to keep the resources organized and versioned to support \nfuture revisions, all the application service’s source code is kept under a simple direc-\ntory structure. This decision to have all the service’s source code together in the same \nrepository influences the shape of our service pipelines. \nThe service pipelines provided (both using Tekton and Dagger) receive as a param-\neter the directory of the repository that the user wants to build. If you set up webhooks \nto trigger pipelines on pull requests, you must filter where the changes are to see which \nservice pipeline to run. This adds to the complexity of the entire setup. As suggested \nin previous sections, an alternative approach is to have one repository per service. This \nenables you to have custom service pipeline definitions per service (which can reuse \ngeneric tasks) and simple webhook definitions, as you know exactly what to run when \nchanges are made. The main problem with having one repository per service is dealing \nwith users and access, because adding new services will force you to create new reposito-\nries and ensure that developers have access to it. \nAnother big decision the platform team will need to make concerning service pipe-\nlines is where they start and end. For the examples provided here, the service pipelines \nstart when a change is submitted and end after publishing the container images for \neach service. Service Pipelines for the walking skeleton services don’t package and pub-\nlish individual services Helm Charts. Figure 3.13 shows the responsibility of the service \npipelines defined by the examples.\nnotifications-service/\nagenda-service/\nfrontend/\nc4p-service/\nhelm/conference-app/\nConference Application Repository\nContainer Registry\nService Pipelines\n(build, test, \npackage, publish)\nApplication Pipeline\n(package, publish)\nFigure 3.13    The service pipelines and the application pipeline have different lifecycles.\nYou need to ask yourself if having Helm Charts per service is a good idea or an overkill. \nYou should have a clear understanding of who will consume these artifacts. Try answer-\ning questions to find a strategy that will work for your teams: \n¡ Will you deploy your services individually, or will they always be deployed as a set?\n¡ How often does your services change? Do you have services that change more \noften? \n\n\n96\nChapter 3  Service pipelines: Building cloud-native applications  \n¡ How many teams are going to deploy these services? \n¡ Are you creating an artifact that an open-source community will consume with \nmany users deploying the services individually? \nFor the examples provided for this chapter, a separate application-level pipeline is pro-\nvided to package and publish the Conference application Helm Chart. \nThe reason behind this decision was simple: every reader will install the application \nin a cluster, and I needed a simple way to enable that. If readers don’t want to use Helm \nto install the application in their clusters, they can export the output of running the \nhelm template command and apply the output using kubectl. Another important \nfactor behind that decision is the lifecycle of the Helm Chart and the application’s ser-\nvices. The shape of the application doesn’t change much. The Helm Chart definition \nmight only change if we need to add or remove a service. The service’s code, however, \nchanges a lot, and we want to enable the teams working on these services to keep adding \nchanges to them. \nFigure 3.14 shows two complementary approaches for service pipelines. The ser-\nvices running in the developer’s environment provide fast feedback loops, and those \nrunning remotely produce artifacts that teams will use to deploy the same application \nacross different environments. \nWhen developers push application changes \nto Git a Service, pipelines automate the \ncreation of the artifacts needed to deploy our \napplication to different environments.\nDevelopers have local tools to get fast \nfeedback to validate that their changes are \ncorrect before pushing them to Git.\nDeveloper \nInner-Loop \nTools\nChanges\nContainer \nRegistry\nGit \nRepository\nApplication\nEnvironment\nService Pipeline\nFigure 3.14    Local vs. remote service pipelines\nFinally, none of the examples in this book provide configurations to tap into webhooks \nfrom the Git repositories besides those linked using GitHub actions. Pushing readers \nto get the right tokens and configuring this with multiple Git providers is not com-\nplex, but it would take me many pages to explain. Teams consuming these mechanisms \nwouldn’t need to worry about dealing with the credentials needed for your service \npipelines. As a platform team, automating access to credentials for development (and \nother) teams to just connect to services is fundamental to speed up their workflows. \n\n\n\t\n97\nSummary\nSummary\n¡ Service pipelines define how to go from source code to artifacts that can be \ndeployed in multiple environments. Following trunk-based development and \none service = one repository practices helps your teams standardize building and \nreleasing software artifacts more efficiently. \n¡ You need to find what works for your teams and applications. There is no one-\nsize-fits-all solution, and compromises must be made. How often do your appli-\ncation’s services change, and how do you deploy them into environments? \nAnswering these questions can help you to define where your service pipelines \nstart and end. \n¡ Tekton is a pipeline engine designed for Kubernetes. You can use Tekton to \ndesign your custom pipelines and use all the shared tasks and pipelines openly \navailable in the Tekton catalog. You can now install Tekton in your cluster and \nstart creating pipelines. \n¡ Dagger allows you to write and distribute pipelines using your favorite program-\nming language. These pipelines can be executed in any environment, including \nyour developer’s laptops. \n¡ Tools like GitHub Actions are very useful but can be expensive. Platform builders \nmust look for tools that provide enough flexibility to build and distribute tasks \nthat other teams can reuse and follow company guidelines. Enabling teams to \nrun their pipelines locally is a big plus as it will improve their developer experi-\nence and their feedback times. \n¡ If you followed the step-by-step tutorials, you gained hands-on experience in \nusing Tekton and Dagger to create and run your service pipelines.\n\n\n98\n4\nEnvironment pipelines: Deploying \ncloud-native applications\nThis chapter covers\n¡ Deploying produced artifacts into environments\n¡ Using environment pipelines and GitOps to \t\n\t manage environments\n¡ Using Argo CD with Helm to deliver software \t\n\t efficiently\nThis chapter introduces the concept of environment pipelines. We cover the steps \nrequired to deploy the artifacts created by service pipelines into concrete running \nenvironments all the way to production. We will look into a common practice that \nhas emerged in the cloud-native space called GitOps, which allows us to define and \nconfigure our environments using a Git repository. Finally, we will look at a project \ncalled Argo CD, which implements a GitOps approach for managing applications \non top of Kubernetes. This chapter is divided into three main sections: \n¡ Environment pipelines\n¡ Environment pipelines in action using Argo CD\n¡ Service + environment pipelines working together\n\n\n\t\n99\nEnvironment pipelines\n4.1\t\nEnvironment pipelines\nWe can build as many services as we want and produce new versions, but if these ver-\nsions cannot flow freely across different environments to be tested and finally used by \nour customers, our organization will struggle to have a smooth end-to-end software \ndelivery practice. Environment pipelines are in charge of configuring and maintaining \nour environments. \nIt is quite common for companies to have different environments for different pur-\nposes, for example, a staging environment where developers can deploy their latest \nversions of the services or a quality assurance (QA) environment where manual testing \nhappens and one or more production environments, which are where the real users \ninteract with our applications. These (staging, QA, and production) are just examples. \nThere shouldn’t be any hard limit on how many environments we can have. Figure 4.1 \nshows how a single release flows throughout different environments until it reaches \nproduction, where it is going to be live in front of our application’s users.\nThe Service \nv1.1.2 was \nreleased \nsuccessfully\nDevelopment\nStaging\nQuality Assurance\nProduction\nService v1.1.2\nService v1.1.2\nService v1.1.2\nService v1.1.2\nFigure 4.1    Released service moving throughout different environments\nEach environment (development, staging, QA, and production) will have one envi-\nronment pipeline. These pipelines will be responsible for keeping the environment \nconfiguration in sync with the hardware running the live version of the environment. \nThese environment pipelines use as the source of truth a repository that contains the \nenvironment configurations, including which services and which version of each ser-\nvice needs to be deployed (figure 4.2). \nService v1.1.2 works \nfine in Development \nlet’s promote it to \nStaging.\nService v1.1.2 \nis ready for the \nprime time.\nService v1.1.2 \nwas released \nsuccessfully.\nDevelopment\nService v1.1.2\nStaging\nProduction\nConfiguration\nConfiguration\nConfiguration\nService v1.1.2\nService v1.1.2\nEnvironment \nPipeline\nEnvironment \nPipeline\nEnvironment \nPipeline\nFigure 4.2    Promoting services to different environments means updating environment configurations\n\n\n100\nChapter 4  Environment pipelines: Deploying cloud-native applications\nIf you are using this approach, each environment will have its configuration repository. \nPromoting a newly released version means changing the environment configuration \nrepository to add a new service or updating the configuration to point to the newly \nreleased version. Some organizations keep all sensitive environment configurations all \ntogether in a single repository; this helps with centralizing the credentials required to \nread and modify these configurations.\nThese configuration changes can be automated or require manual intervention. For \nmore sensitive environments, such as the production environment, you might require \ndifferent stakeholders to sign off before adding or updating a service.\nBut where do environment pipelines come from? And why wouldn’t you have heard \nof them before? Before jumping into the details about what an environment pipeline \nwould look like, we need to get a bit of background on why this matters in the first place. \n4.1.1\t\nHow did this work in the past, and what has changed lately?\nTraditionally, creating new environments was hard and costly. Creating new environ-\nments on demand wasn’t a thing for these two reasons. First, the differences between \nthe environment that a developer used to create an application and where the applica-\ntion ran for end users were completely different. These differences, not only in com-\nputing power, caused huge stress on operations teams responsible for running these \napplications. Depending on the environment’s capabilities, they needed to fine-tune \nthe application’s configurations (that they didn’t design). Second, tools for automat-\ning the provisioning and configuration of complex setups have become mainstream. \nWith the help of containers and Kubernetes, there has been a standardization around \nhow these tools are designed and work across cloud providers. These tools had reached \na point where developers can codify infrastructure using their programming language \nof choice or rely on the Kubernetes API to create these definitions.\nBefore the rise of cloud–native applications, deploying a new application or a new ver-\nsion of an application required shutting down the server, running some scripts, copying \nsome binaries, and then starting the server again with the new version running. After the \nserver starts again, the application could fail to start. Hence more configuration tuning \nmight be needed. Most of these configurations were done manually in the server itself, \nmaking it difficult to remember and keep track of what was changed and why. \nAs part of automating these processes, tools like Jenkins (https://www.jenkins.io/, a \nvery popular pipeline engine) and/or scripts were used to simplify deploying new bina-\nries. So instead of manually stopping servers and copying binaries, an operator can run \na Jenkins Job defining which versions of the artifacts they wanted to deploy, and Jenkins \nwill run the job notifying the operator about the output. This approach had two main \nadvantages: \n¡ Tools like Jenkins can have access to the environment’s credentials, avoiding \nmanual access to the servers by the operators. \n¡ Tools like Jenkins log every job execution and the parameters, allowing us to \nkeep track of what was done and the result of the execution.\n\n\n\t\n101\nEnvironment pipelines\nWhile automating with tools like Jenkins was a big improvement compared to manually \ndeploying new versions, there were still some problems, such as having fixed environ-\nments completely different from where the software was being developed and tested. \nWe needed to specify how the environment is created and configured to the operat-\ning system’s version and the software installed into the machines or virtual machines \nto reduce the difference between different environments. Virtual machines helped \ngreatly with this task, because we can easily create two or more virtual machines config-\nured similarly. \nWe can even give our developers these virtual machines to work. But now we have a \nnew problem. We will need new tools to manage, run, maintain, and store our virtual \nmachines. If we have multiple physical machines where we want to run virtual machines, \nwe don’t want our operations team to start these VMs in each server manually. Hence, \nwe will need a hypervisor to monitor and run VMs in a cluster of physical computers. \nUsing tools like Jenkins and virtual machines (with hypervisors) were a huge \nimprovement. Because we implemented some automation, operators didn’t need to \naccess servers or VMs to change configurations manually, and our environments were \ncreated using a configuration predefined in a fixed virtual machine configuration. \nTools like Ansible (https://www.ansible.com/) and Puppet (https://www.puppet \n.com/) are built on top of these concepts.\nFigure 4.3 shows Jenkins Jobs configured to create virtual machines that host our \napplications. But beware, these virtual machines host an entire operating system. All \nthe tools bundled with that operating system will run beside your applications! \nJenkins Job #1\nJenkins Job #2\nVirtual Machine #1\nVirtual Machine #2\nApplication\nApplication\nFigure 4.3    Jenkins Jobs or scripts encapsulated the operational knowledge of how to do deployments in \nan imperative way, defining step-by-step what needs to be done. This is a complex task, hard to maintain \nand modify, and very specific to the tool we're using. On the other hand, virtual machines are resource-\nintensive and not portable across cloud providers.\nWhile this approach is still common in the industry, there is a lot of room for improve-\nment, for example, in the following areas: \n¡ Jenkins Jobs and scripts are imperative by nature, meaning they specify step-by-\nstep what needs to be done. This has a great disadvantage, because if something \nchanges—let’s say a server is no longer there or requires more data to authen-\nticate against a service—the logic of the pipeline will fail, and it will need to be \nmanually updated.\n\n\n102\nChapter 4  Environment pipelines: Deploying cloud-native applications\n¡ Virtual machines are heavy. Every time you start a virtual machine, you start a \ncomplete instance of an operating system. Running the operating system pro-\ncesses does not add any business value; the larger the cluster, the bigger the oper-\nating system overhead. On the VM’s requirements, running VMs in developers’ \nenvironments may not be possible.\n¡ Environments’ configurations are hidden and not versioned. Most of the envi-\nronment configurations and how the deployments are done are encoded inside \ntools like Jenkins, where complex pipelines tend to grow out of control, making \nthe changes very risky and migration to newer tools and stacks very difficult. \n¡ Each cloud provider has a non-standard way of creating virtual machines. This \ncan push us into a vendor lock-in situation. If we created VMs for Amazon Web \nServices, we could not run these VMs into the Google Cloud Platform or Micro-\nsoft Azure. \nHow are teams approaching this with modern tooling? That is an easy question. We \nnow have Kubernetes and containers that aim to solve the overhead caused by VMs and \nthe cloud-provider portability by relying on containers and the widely adopted Kuber-\nnetes APIs. Kubernetes also provides the building blocks to ensure we don’t need to \nshut down our servers to deploy new applications or change their configurations. If we \ndo things in the Kubernetes way, we shouldn’t have any downtime in our applications. \nBut Kubernetes alone doesn’t solve the process of configuring the clusters them-\nselves. How we apply changes to their configurations, or the process and tooling \ninvolved into deploying applications to these clusters, also matter. That’s why you might \nhave heard about GitOps.\nWhat is GitOps, and how does it relate to our environment pipelines? We’ll answer \nthat question next.\n4.1.2\t\nWhat is GitOps, and how does it relate to environment pipelines?\nIf we don’t want to encode all of our operational knowledge in a tool like Jenkins, where \nit is difficult to maintain, change, and keep track of it, we need a different approach. \nThe term GitOps, defined by the CNCF’s GitOps Working Group (https:// \nopengitops.dev/), defines the process of creating, maintaining, and applying the con-\nfiguration of our environments and applications declaratively using Git as the source of \ntruth. OpenGitOps defines four core principles that we need to consider when we talk \nabout GitOps: \n1\t Declarative: A system (https://github.com/open-gitops/documents/blob/v1.0.0/ \nGLOSSARY.md#software-system) managed by GitOps must have its desired state \nexpressed declaratively (https://github.com/open-gitops/documents/blob/\nv1.0.0/GLOSSARY.md#declarative-description). We have this covered if we use \nKubernetes manifest, because we define what needs to be deployed and how that \nneeds to be configured using declarative resources that Kubernetes will reconcile. \n2\t Versioned and immutable: The desired state is stored (https://github.com/open \n-gitops/documents/blob/v1.0.0/GLOSSARY.md#state-store) in a way that enforces \n\n\n\t\n103\nEnvironment pipelines\nimmutability and versioning and retains a complete version history. The Open \nGitOps initiative doesn’t enforce the use of Git. As soon as our definitions are \nstored, versioned, and immutable, we can consider it as GitOps. This opens the \ndoor to storing files in, for example, S3 buckets, which are also versioned and \nimmutable. \n3\t Pulled automatically: Software agents automatically pull the desired state declara-\ntions from the source. The GitOps software pulls the changes from the source \nperiodically in an automated way. Users shouldn’t worry about when the changes \nare pulled. \n4\t Continuously reconciled: Software agents continuously (https://github.com/open \n-gitops/documents/blob/v1.0.0/GLOSSARY.md#continuous) observe the sys-\ntem state and attempt to apply (https://github.com/open-gitops/documents/\nblob/v1.0.0/GLOSSARY.md#reconciliation) the desired state. This continuous \nreconciliation helps us to build resilience in our environments and the entire \ndelivery process, because we have components that are in charge of applying the \ndesired state and monitoring our environments from configuration drifts. If the \nreconciliation fails, GitOps tools will notify us about the problems and keep try-\ning to apply the changes until the desired state is achieved. \nBy storing the configuration of our environments and applications in a Git repository, \nwe can track and version the changes we make. By relying on Git, we can easily roll \nback changes if these changes don’t work as expected. GitOps covers the configuration \nstorage and how these configurations are applied to the computing resources where \nthe applications run. \nGitOps was coined in the context of Kubernetes, but this approach is not new, \nbecause configuration management tools have existed for a long time. Instead, GitOps \nrepresents a refinement of these tried and tested approaches that can be applied to any \nsoftware operation, not just Kubernetes. With the rise in popularity of cloud provid-\ners’ tools for managing Infrastructure as Code, tools like Chef (https://www.chef.io/), \nAnsible (https://www.ansible.com/), Terraform (https://www.terraform.io/), and \nPulumi (https://www.pulumi.com/) are loved by operations teams, because these tools \nallow them to define how to configure cloud resources and configure them together in \na reproducible way. If you need a new environment, you just run this Terraform script \nor Pulumi app, and then voila, the environment is up and running. These tools are also \nequipped to communicate with the cloud provider’s APIs to create Kubernetes clusters \nso that we can automate the creation of these clusters. \nWith GitOps, we manage configuration and rely on the Kubernetes APIs as the stan-\ndard way to deploy our applications to Kubernetes clusters. With GitOps, we use a Git \nrepository as the source of truth for our environment’s internal configurations (Kuber-\nnetes YAML files) while removing the need to interact manually with the Kubernetes \nclusters to avoid configuration drifts and security problems. When using GitOps tools, \n\n\n104\nChapter 4  Environment pipelines: Deploying cloud-native applications\nwe can expect to have software agents in charge of pulling from the source of truth (Git \nrepository in this example) periodically and constantly monitoring the environment to \nprovide a continuous reconciliation loop. This ensures that the GitOps tool will do its \nbest to ensure that the desired state expressed in the repository is what we have in our \nlive environments.\nWe can reconfigure any Kubernetes cluster to have the same configuration stored \nin our Git repository by running an environment pipeline. Figure 4.4 shows how these \npieces fit together. On the left, we have Infrastructure as Code tools that can create \ncloud resources, including Kubernetes clusters and application infrastructure for \nour environments. Once the environment is set up, an environment pipeline using a \nGitOps approach can sync all the configurations for our environment into the target \nKubernetes cluster, regularly checking that the configuration stored in Git is in sync \nwith the cluster.\n“Infrastructure as \nCode” Tool\n(Terraform, Pulumi, Ansible, Chef)\n<create, update>\n<periodically pull>\n<continuous \nreconciliation>\nKubernetes \nCluster\nEnvironment\nGitOps Tool\nApplication #1\nEnvironment \nPipeline\nApplication #2\nGit \nrepository\nGit \nrepository\nFigure 4.4    Infrastructure as Code, GitOps, and environment pipelines working together. Infrastructure \nas code tools run scripts to create cloud resources in a reproducible way. We can create our Kubernetes \nclusters to be all the same using these tools. GitOps tools run environment pipelines to continuously \nreconcile declarative configuration, which is stored in a versioned and immutable repository.\nBy separating the infrastructure and application concerns, our environment pipelines \nallow us to ensure that our environments are easy to reproduce and update whenever \nneeded. By relying on Git as the source of truth, we can roll back our infrastructural \nand application changes as needed. It is also important to understand that because \nwe are working with the Kubernetes APIs, our environment’s definitions are now \nexpressed in a declarative way, supporting changes in the context where these config-\nurations are applied and letting Kubernetes deal with how to achieve the desired state \nexpressed by these configurations. \nFigure 4.5 shows these interactions, where operation teams only make changes to \nthe Git repository that contains our environment configuration, and then a pipeline \n(a set of steps) is executed to ensure that this configuration is in sync with the target \nenvironment. \n\n\n\t\n105\nEnvironment pipelines\nChanges\nPipeline\nGit Repository\nEnvironment \nConfiguration\nService A v1.2\nService B v2.13\n<sync/apply>\nFigure 4.5    Defining the state of the cluster using the configuration in Git (GitOps). Environment \npipelines monitor configuration changes on a Git repository and apply those changes to the infrastructure \n(Kubernetes cluster) whenever a new change is detected. Following this approach allows us to roll back \nchanges in the infrastructure by reverting commits on Git. We can also replicate the exact environment \nconfiguration by just running the same pipeline against another cluster.  \nWhen you start using environment pipelines, you aim to stop interacting, changing, \nor modifying the environment’s configuration manually, and all interactions are done \nexclusively by these pipelines. To give a very concrete example, instead of executing \nkubectl apply -f or helm install into our Kubernetes cluster, an operator will be \nin charge of running these commands based on the contents of a Git repository that \nhas the definitions and configurations of what needs to be installed in the cluster. \nIn theory, an operator that monitors a Git repository and reacts to changes is all you \nneed, but in practice, a set of steps is needed to ensure we have full control of what is \ndeployed to our environments. Hence, thinking about GitOps as a pipeline helps us \nunderstand that for some scenarios, we will need to add extra steps to these pipelines \ntriggered every time an environment configuration is changed. \nLet’s look at these steps with more concrete tools commonly found in real-life \nscenarios. \n4.1.3\t\nSteps involved in an environment pipeline\nNo matter what kind of applications you are deploying to different environments, \nenvironment pipelines usually include a set of predefined steps. Figure 4.6 shows \nthese steps as a sequence, as most of the time these steps are defined inside scripts or \nencoded in tools that are in charge of checking that each step was executed correctly. \nLet’s dig deeper into the details of these steps:\n¡ Reacting to changes in the configuration: This can be done by polling or pushing: \n–\t Polling for changes: A component can pull the repository and check if there \nhave been new commits since the last time it checked. If new changes are \ndetected, a new environment pipeline instance is created.\n–\t Pushing changes using webhooks: If the repository supports webhooks, the repos-\nitory can notify our environment pipelines that there are new changes to sync. \n\n\n106\nChapter 4  Environment pipelines: Deploying cloud-native applications\nRemember, the GitOps principles state “pulled automatically,” which means \nwe can use webhooks, but we should not rely entirely on them for getting con-\nfig change updates. \nChange\nin Git\nVerify/Validate \nConfiguration\nClone \nConfiguration\nApply \nConfiguration\nValidate \nRuntime\nPipeline Instance\nCreate a Pipeline Instance\nFigure 4.6    Environment pipeline for a Kubernetes environment\n¡ Clone the source code from the repository, which contains the desired state for our environ-\nment: This step fetches the configuration from a remote Git repository that con-\ntains the environment configurations. Tools like Git fetch only the delta between \nthe remote repository and what we have locally.\n¡ Apply the desired state to a live environment: This usually includes doing a kubectl \napply -f or a helm install command to install new versions of the artifacts. \nNotice that with both kubectl and helm, Kubernetes is smart enough to recog-\nnize where the changes are and only apply the differences. Once the pipeline \nhas all the configurations locally accessible, it will use a set of credentials to apply \nthese changes to a Kubernetes cluster. Notice that we can fine-tune the access \nrights that the pipelines have to the cluster to ensure they are not exploited from \na security point of view. This also allows you to remove access from individual \nteam members to the clusters where the services are deployed. \n¡ Verify that the changes are applied and that the state matches what is described inside the \nGit repository (deal with configuration drift): Once the changes are applied to the live \ncluster, checking that the new versions of services are up and running is needed \nto identify if we need to revert to a previous version. It is quite simple if we need \nto revert changes, because all the history is stored in Git. Applying the previous \nversion is just looking at the previous commit in the repository.\n¡ Validate that your workloads are working as expected: Once the configurations are \napplied correctly, we need to validate that the applications deployed are working \nas expected and doing what they are supposed to do. \n\n\n\t\n107\nEnvironment pipelines\nFor the environment pipeline to work, a component that can apply the changes to the \nenvironment is needed, and it needs to be configured accordingly with the right access \ncredentials. The main idea behind this component is to make sure that nobody will \nchange the environment configuration by manually interacting with the cluster. This \ncomponent is the only one allowed to change the environment configuration, deploy \nnew services, upgrade versions, or remove services from the environment. For an envi-\nronment pipeline to work, the following two considerations need to be met:\n¡ The repository containing the desired state for the environment must have all the \nnecessary configurations to create and configure the environment successfully.\n¡ The Kubernetes cluster where the environment will run needs to be configured \nwith the correct credentials for allowing the state to be changed by the pipelines. \nThe term environment pipeline refers to the fact that each environment will have a pipe-\nline associated with it. Because multiple environments are usually required (develop-\nment, staging, production) for delivering applications, each will have a pipeline in \ncharge of deploying and upgrading the components running in them. By using this \napproach, promoting services between different environments is achieved by send-\ning pull requests/change requests to the environment’s repository. The pipeline will \nreflect the changes in the target cluster. \n4.1.4\t\nEnvironment pipeline requirements and different approaches\nSo, what are the contents of these environment’s repositories? As you will see in figure \n4.7, the contents of the environment repository are just the definition of which services \nneed to be present in the environment. The environment pipeline then can just apply \nthese Kubernetes manifests to the target cluster. \nGit Repository\nstaging/Chart.yaml\n       /values.yaml\nGit Repository\nstaging/apps.yaml\nGit Repository\nstaging/helmfile\nContains the reference to one \nor more Helm Charts that will \nbe installed in the target \nKubernetes cluster. You can \nparameterize these charts \nusing a `values.yaml` file.\nContains all the Kubernetes \nresources needed to deploy \nthe application’s services. You \ncan have one or more files \nthat will be applied to the \ntarget Kubernetes cluster.\nTools like `helmfile` allows \nyou to define environments \ndeclaratively using Helm \nReleases.\nFigure 4.7    Environment configuration options\n\n\n108\nChapter 4  Environment pipelines: Deploying cloud-native applications\nThe first option (simple layout) is to store all the Kubernetes YAML files in a Git repos-\nitory, and then the environment pipeline will just use kubectl apply -f * against \nthe configured cluster. While this approach is simple, there is one big drawback: if you \nhave your Kubernetes YAML files for each service in the service repository, then the \nenvironment repository will have these files duplicated, and they can go out of sync. \nImagine if you have several environments, you must maintain all the copies in sync, \nwhich might become challenging. \nThe second option (using Helm Charts) is a bit more elaborate now that we are \nusing Helm to define the state of the cluster. You can use Helm dependencies to create \na parent chart that will include as dependencies all the services that should be present \nin the environment. If you do so, the environment pipeline can use helm update . to \napply the chart into a cluster. Something I don’t like about this approach is that you cre-\nate one Helm release per change, and there are no separate releases for each service. \nThis approach uses Helm dependencies to fetch each service definition, so a prerequi-\nsite for this approach is to have every service package as a Helm Chart. \nThe third option is to use a project called helmfile (https://github.com/helmfile/\nhelmfile), designed for this very specific purpose, to define environment configura-\ntions. A helmfile allows you to declaratively define what Helm releases need to be pres-\nent in our cluster. These Helm releases will be created when we run helmfile sync, \nhaving defined a helmfile containing the helm releases we want in the cluster. \nWhether you use any of these approaches or other tools to do this, the expectation is \nclear. You have a repository with the configuration (one repository per environment or \na directory per environment), and a pipeline is in charge of picking up the configura-\ntion and using a tool to apply it to a cluster. \nIt is common to have several environments (staging, QA, production), even allowing \nteams to create on-demand environments for running tests or day-to-day development \ntasks. If you use the “one environment per namespace” approach, as shown in figure \n4.8, it is common to have a separate Git repository for each environment, because it \nhelps keep access to environments isolated and secure. This approach is simple, but \nit doesn’t provide enough isolation on the Kubernetes cluster, because Kubernetes \nNamespaces were designed for logical partitioning of the cluster. In this case, the stag-\ning environment will share with the production environment the cluster resources. \nPipeline\nProduction Environment \nConfiguration\nPipeline\nStaging Environment \nConfiguration\nStaging Namespace\nProduction Namespace\nGit Repository\nKubernetes Cluster\n<sync>\n<sync>\nGit Repository\nFigure 4.8    One environment per Kubernetes namespace approach. One strategy is to use namespaces \nfor different environments. While this simplifies the configurations required for the pipelines to deploy \nservices to different environments, namespaces don’t provide strong isolation guarantees.\n\n\n\t\n109\nEnvironment pipelines\nAn alternative approach can be to use an entirely new cluster for each environment. \nThe main difference is isolation and access control. By having a cluster per environ-\nment, you can be stricter in defining who and which components can deploy and \nupgrade things in these environments and have different hardware configurations for \neach cluster, such as multi-region setups and other scalability concerns that might not \nmake sense to have in your staging and testing environments. Using different clusters, \nyou can also aim for a multi-cloud setup, where different cloud providers can host dif-\nferent environments. \nFigure 4.9 shows how you can use the namespace approach for development envi-\nronments, which will be created by different teams and then have separated clusters \nfor staging and production. The idea here is to have the staging and production clus-\nter configured as similarly as possible, so applications deployed onto different environ-\nments behave the same. \nEnv Configuration \nTeam A\nEnv Pipeline\nEnv Pipeline\nEnv Pipeline\nEnv Pipeline\nEnv Configuration \nTeam B\nEnv Configuration \nStaging\nEnv Configuration \nProduction\nGit Repository\nNamespace\nNamespace\nStaging Cluster\nProduction Clusters\nDev Cluster\nGit Repository\nGit Repository\nFigure 4.9    Different environment configurations, based on requirements. A more realistic approach \ncan use the same cluster for multiple teams doing day-to-day work, while more sensitive environments \nlike staging and production are separated on their own clusters and Git repositories to store their \nconfigurations. For a service to be promoted to a new environment, a pull request needs to be submitted \nto the corresponding Git repository.\nOkay, but how can we implement these pipelines? Should we implement these pipe-\nlines using Tekton? In the next section, we will look at Argo CD (https://argo-cd \n.readthedocs.io/en/stable/), a tool that has encoded the environment pipeline logic \nand best practices into a very specific tool for continuous deployment.  \n\n\n110\nChapter 4  Environment pipelines: Deploying cloud-native applications\n4.2\t\nEnvironment pipelines in action\nYou can implement an environment pipeline as described in the previous section using \nTekton or Dagger. This has been done in projects like Jenkins X (https://jenkins-x \n.io), but nowadays, the steps for an environment pipeline are encoded in specialized \ntools for continuous deployment like Argo CD (https://argo-cd.readthedocs.io/en/\nstable/). \nIn contrast with service pipelines, where we might need specialized tools to build \nour artifacts depending on which technology stack we use, environment pipelines for \nKubernetes are well-standardized today under the GitOps umbrella. Considering that \nall our artifacts are being built and published by our service pipelines, we first need to \ncreate our environment Git repository, which will contain the environment configura-\ntion, including the services deployed to that environment. \nArgo CD provides a very opinionated but flexible GitOps implementation. We will \ndelegate all the steps required to deploy software into our environments to Argo CD. \nArgo CD can out-of-the-box monitor a Git repository that contains our environment(s) \nconfiguration and periodically apply the configuration to a live cluster. This enables us \nto remove manual interactions with the target clusters, which reduces configuration \ndrifts as Git becomes our source of truth. \nUsing tools like Argo CD allows us to declaratively define what we want to install in \nour environments, while Argo CD is in charge of notifying us when something goes \nwrong or our clusters are out of sync. Argo CD is not limited to a single cluster, mean-\ning our environment can live in separate clusters, even in different cloud providers. \nFigure 4.10 shows Argo CD managing different environments on different clusters, \nusing different Git repositories as the source of truth to keep the configuration of each \nenvironment.\nQA Environment\nDevelopment \nEnvironment #1\nDevelopment \nEnvironment #2\nProduction \nEnvironment\nKubernetes Cluster\nKubernetes Cluster\nArgoCD\nGit\nGit\nKubernetes Cluster\nFigure 4.10    Argo CD will sync environments, configurations from Git to live clusters\n\n\n\t\n111\nEnvironment pipelines in action\nIn the same way that we now have separate service pipelines for each service, we can \nhave separate repositories, branches, or directories to configure our environments. \nArgo CD can monitor repositories or directories inside repositories for changes to sync \nour environments configurations. \nWe will install Argo CD in our Kubernetes cluster for this example and configure our \nstaging environment using a GitOps approach. For that, we need a Git repository that \nserves as our source of truth. You can follow a step-by-step tutorial located at https://\ngithub.com/salaboy/platforms-on-k8s/blob/main/chapter-4/README.md. \nFor installing Argo CD, I recommend you check their Getting Started guide that you \ncan find at https://argo-cd.readthedocs.io/en/stable/getting_started/. This guide \ninstalls all the components required for Argo CD to work, so after finishing this guide, \nwe should have all we need to get our staging environment going. It also guides you \nthrough the installation of the argocd CLI (Command-Line Interface), which some-\ntimes is very handy. In the following sections, we will focus on the user interface, but you \ncan access the same functionality using the CLI. Argo CD comes with a very useful user \ninterface that lets you monitor how your environments and applications are doing and \nquickly find out if there are any problems. \nThe main objective of this section is to replicate what we did in section 2.1.3 in chap-\nter 2, where we installed and interacted with the application, but here we aim to fully \nautomate the process for an environment that will be configured using a git repository. \nOnce again, we will use Helm to define the environment configuration as Argo CD pro-\nvides an out-of-the-box Helm integration. \nNOTE    Argo CD used a different nomenclature than the one we used here. In \nArgo CD you configure applications instead of environments. In the following \nscreenshots, you will see that we will be configuring an Argo CD application to \nrepresent our staging environment. As there are no restrictions on what you can \ninclude in a Helm Chart, we will be using a Helm Chart to configure our Confer-\nence application into this environment. \n4.2.1\t\nCreating an Argo CD application\nIf you access the Argo CD user interface, you will see right in the top left corner of the \nscreen the + New App button (figure 4.11). \nFigure 4.11    \nArgo CD user \ninterface—new \napplication \ncreation\n\n\n112\nChapter 4  Environment pipelines: Deploying cloud-native applications\nGo ahead and hit that button to see the application creation form. Besides adding a \nname and selecting a Project where our Argo CD application will live (we will select \nthe default project), we will check the Auto-Create Namespace option, as shown in \nfigure 4.12. \nFigure 4.12    New application parameters, manual sync, and auto-create namespace\nBy associating our environment with a new namespace in our cluster, we can only use \nthe Kubernetes RBAC mechanism to allow administrators to modify the Kubernetes \nresources in that namespace. Remember that by using Argo CD, we want to ensure that \ndevelopers don’t accidentally change the application configuration or manually apply \nconfiguration changes to the cluster. Argo CD will sync the resources defined in a Git \nrepository. So where is that Git repository? That’s exactly what we need to configure \nnext (figure 4.13). \nFigure 4.13    Argo CD application’s configuration repository, revision, and path\nAs mentioned, we will use a directory inside the https://github.com/salaboy/platforms \n-on-k8s/ repository to define our staging environment. You should fork this reposi-\ntory (and then use your fork URL) to make any changes you want to the environment \nconfiguration. The directory that contains the environment configuration can be \nfound under chapter-4/argo-cd/staging/. As shown in figure 4.14, you can also select \nbetween different branches and tags, allowing you to have fine-grain control of where \nthe configuration is coming from and how that configuration evolves. \n\n\n\t\n113\nEnvironment pipelines in action\nFigure 4.14    Configuration destination, for this example, is the cluster where Argo CD is installed\nThe next step is to define where Argo CD will apply this environment configuration. \nWe can use Argo CD to install and sync environments in different clusters, but for this \nexample, we will be using the same Kubernetes cluster where we installed Argo CD and \nthe staging namespace. There is an option for Argo CD to create this namespace for \nyou, or you can create it manually when setting up the cluster and the permissions for \ndifferent namespaces. \nFinally, because it makes sense to reuse the same configuration for similar environ-\nments, Argo CD enables us to configure different parameters specific to this installa-\ntion. Since we are using Helm and the Argo CD user interface is smart enough to scan \nthe content of the repository/path we have entered, it knows it is dealing with a Helm \nChart. If we were not using a Helm Chart, Argo CD allows us to set up environment vari-\nables as parameters for our configuration scripts (figure 4.15). \nFigure 4.15    Helm configuration parameters for the staging environment\nAs you can see in the previous image, Argo CD also identified an empty values.yaml file \ninside the repository path that we have provided. If the values.yaml file had any param-\neters, the user interface will parse them and show them for you to validate. We can add \nmore parameters to the VALUES text box to override any other chart (or sub-charts) \nconfigurations. \nAfter we provide all this configuration, we are ready to hit the Create button at the \ntop of the form. Argo CD will create the application and automatically sync the changes, \nas we selected the Automatic Sync option (figure 4.16). \n\n\n114\nChapter 4  Environment pipelines: Deploying cloud-native applications\nFigure 4.16    \nApplication \ncreated and \nautomatically \nsynced\nIf you click into the application, you will drill down to the application’s full view, which \nshows you the state of all the resources associated with the application, as shown in \nfigure 4.17. \nFigure 4.17    Our staging environment is healthy, and all the services are running.\nIf you are creating the environment in a local cluster or a real Kubernetes cluster, you \nshould access the application and interact with it. Let’s recap what we have achieved: \n¡ We have installed Argo CD into our Kubernetes cluster. Using the provided Argo \nCD Dashboard (user interface), we have created a new Argo CD application for \nour staging environment. \n¡ We have created our staging environment configuration in a Git repository \nhosted in GitHub, which uses a Helm Chart definition to configure our Con-\nference application services and their dependencies (Redis, PostgreSQL, and \nKafka). \n\n\n\t\n115\nEnvironment pipelines in action\n¡ We have synced the configuration to a namespace (staging) in the same cluster \nwhere we installed Argo CD.\n¡ Most importantly, we have removed the need for manual interaction against the \ntarget cluster. Theoretically, there will be no need to execute kubectl against the \nstaging namespace. \nFor this setup to work, we need to make sure that the artifacts that the Helm Charts \n(and the Kubernetes resources inside them) are available for the target cluster to pull. I \nstrongly recommend you follow the step-by-step tutorial (https://github.com/salaboy/ \nplatforms-on-k8s/tree/main/chapter-4) to get hands-on with Argo CD to understand \nhow this tool works and how it can help your teams to continuously deploy their appli-\ncations to multiple environments. \n4.2.2\t\nDealing with changes the GitOps way\nImagine now that the team in charge of developing the user interface (frontend) \ndecides to introduce a new feature. They create a pull request to the frontend repos-\nitory. Once this pull request is merged with the main, the team can decide to create a \nnew release for the service. The release process should include the creation of tagged \nartifacts using the release number. The creation of these artifacts is the responsibility \nof the service pipeline, as we saw in previous sections. Figure 4.18 shows how Argo CD, \nin this case, syncs the configuration changes from the staging configuration repository. \nStaging Configuration \nRepository\nDeveloper\nOperator\nContainer Registry\nHelm Repository\nKubernetes Cluster\nStaging\nfrontend 0.1.0\nagenda-service 0.1.0\nc4p-service 0.1.0\nnotifications-service 0.1.0\nArgo CD\nWeb Browser\nUser\nSend \nchange \nupdate\nFigure 4.18    Components to set up the staging environment with Argo CD\n\n\n116\nChapter 4  Environment pipelines: Deploying cloud-native applications\nOnce we have the released artifacts, we can now update the environment. We can \nupdate the staging environment by submitting a pull request to our GitHub reposi-\ntory that can be reviewed before merging to the main branch, the branch we used to \nconfigure our Argo CD application. The changes in the environment configuration \nrepository are going to be usually about: \n¡ Bumping up or reverting a service version: For our example, this is as simple as chang-\ning the version of the chart of one or more services. Rolling back one of the \nservices to the previous is as simple as reverting the version number in the envi-\nronment chart or even reverting the commit that increased the version in the \nfirst place. Notice that reverting commits is always recommended, as rolling back \nto a previous version might also include configuration changes to the services \nthat, if they are not applied, old versions might not work. \n¡ Adding or removing a service: Adding a new service is a bit more complicated, \nbecause you will need to add both the chart reference and the service configura-\ntion parameters. For this to work, the chart definition needs to be reachable by \nthe Argo CD installation. Suppose the service(s)’ chart(s) are available, and the \nconfiguration parameters are valid. In that case, the next time we sync our Argo \nCD application, the new service(s) will be deployed to the environment. Remov-\ning services is more straightforward, because the moment you remove the depen-\ndency from the environment Helm Chart, the service will be removed from the \nenvironment. \n¡ Tweaking charts parameters: Sometimes, we don’t want to change any service ver-\nsion, and we might be trying to fine-tune the application parameters to accom-\nmodate performance or scalability requirements, monitoring configurations, or \nthe log level for a set of services. These changes are also versioned and should be \ntreated as new features and bug fixes. \nWe will quickly notice the differences if we compare this with manually installing Helm \nto install the application into the cluster. First, a developer might have the environ-\nment configuration on their laptop, making the environment very difficult to repli-\ncate from a different location. Changes to the environment configuration that are not \ntracked using a version control system will be lost, and we will not have any way to ver-\nify whether these changes are working in a live cluster. Configuration drifts are much \nmore difficult to track down and troubleshoot. \nThis automated approach with Argo CD can open the door to more advanced sce-\nnarios. For example, we can create preview environments (figure 4.19) for our pull \nrequests to test changes before they get merged and artifacts are released. \n\n\n\t\n117\nService + environment pipelines\nOpen Pull \nRequest #3\nGit \nRepository\nPreview Environment\nService v0.1.0-pr-3\nAnother developer, \nin charge of \nreviewing the Pull \nRequest code can \nvalidate the changes \nlive in the Preview \nEnvironment.\nA Preview Environment \nPipeline creates a new \nPreview Environment to \nrun the service with the \nchanges introduced in the \nPull Request.\nA Developer \ncreates a new \nPull Request #3.\nFigure 4.19    Preview environments for faster iterations\nUsing preview environments can help iterate faster and enable teams to validate \nchanges before merging them into the project’s main branch. Preview environments \ncan also be notified when the pull request is merged, making an automated clean-up \nmechanism straightforward to implement.  \nNOTE     Another important detail to mention when using Argo CD and Helm is \nthat compared with using Helm Charts manually, where Helm will create release \nresources every time we update a chart in our cluster, Argo CD will not use this \nHelm feature. Argo CD takes the approach of using a Helm template to render \nthe Kubernetes resources YAML, and then it applies the output using kubectl \napply. This approach relies on the fact that everything is versioned in Git and \nallows the unification of different templating engines for YAML. In addition to \nsome security benefits, this is key to enabling diffing in Argo CD, which allows us \nto specify which resources should be managed by Argo CD and which elements \nmay be managed by different controllers.\nFinally, to tie things together, let’s see how service and environment pipelines interact \nto provide end-to-end automation, from code changes to deploying new versions into \nmultiple environments. \n4.3\t\nService + environment pipelines\nLet’s look at how service pipelines and environment pipeline connect. The connec-\ntion between these two pipelines happens via pull/change requests to Git repositories, \nbecause the pipelines will be triggered when changes are submitted and merged (fig-\nure 4.20). \n\n\n118\nChapter 4  Environment pipelines: Deploying cloud-native applications\nWhen configuration \nchanges are merged the \nEnvironment Pipeline \nsync them to the live \nenvironment.\nService\nGit Repository\nA change triggers a \nService Pipeline \ninstance.\nSend automated pull \nrequests to \nenvironments \nrepositories.\nAll artifacts are \npublished and ready \nto be deployed.\nSend \nNotifications\nEnvironment\nGit Repository\nEnvironment\nService\nService Pipeline\nEnvironment Pipeline\nFigure 4.20    A service pipeline can trigger an environment pipeline via a pull request.\nDevelopers, when they finish a new feature, create a pull/change request to the repos-\nitory’s main branch. This pull/change request can be reviewed and built by a spe-\ncialized service pipeline. When this new feature is merged into the repository’s main \nbranch, a new instance of the service pipeline is triggered. This instance creates a new \nrelease and all the artifacts needed to deploy the service’s new version into a Kuber-\nnetes cluster. As we saw in chapter 3, this includes a binary with the compiled source \ncode, a container image, and Kubernetes Manifests that can be packaged using tools \nlike Helm. \nAs the last step of the service pipeline, you can include a notification step that can \nnotify the interested environments that there is a new version of a service that they are \nrunning available. This notification is usually an automated pull/change request into \nthe environment’s repository. Alternatively, you monitor (or subscribe to notifications) \nyour artifact repositories, and when a new version is detected, a pull/change request is \ncreated to the configured environments. \nThe pull/change requests created to environment repositories can be automatically \ntested by a specialized environment pipeline. In the same way as we did with service \npipelines, and for low-risk environments, these pull/change requests can be automati-\ncally merged without any human intervention. \nBy implementing this flow, we can enable developers to focus on fixing bugs and \ncreating new features that will be automatically released and promoted to low-risk envi-\nronments. Once the new versions are tested in environments like staging, and we know \nthat these new versions or configurations are not causing any problems, a pull/change \nrequest can be created for the repository that contains the production environment \nconfiguration. \n\n\n\t\n119\nLinking back to platform engineering\nThe more sensitive the environments are, the more required checks and validations. \nIn this case, as shown in figure 4.21, to promote a new service version to the production \nenvironment, a new test environment will be created to validate and test the changes \nintroduced in the pull/change request submitted. Once those validations are done, \na manual sign-off is required to merge the pull request and trigger the environment \npipeline synchronization. \nA new version (Service A v1.1.2) \nis available. This needs \nvalidation and manual approval \nto be promoted to the \nproduction environment.\nProduction\nValidations (automated and manual)\nProduction-like Test \nEnvironment\nPull Request\nOK to merge!\nService A v1.1.2\nManual Sign off\nPerformance/Regression \nTest Suite\nService v1.1.2\nService Y v1.2.3\nService Z v4.2.4\nConfiguration\nEnvironment \nPipeline\nFigure 4.21    Promoting changes to the production environment\nEnvironment pipelines are the mechanism you use to encode your organization’s \nrequirements to release and promote software to different environments. We have \nseen in this chapter what a tool like Argo CD can do for us. Next, we need to evaluate \nif a single Argo CD installation would be enough and who will manage it and keep it \nsecure. Do you need to extend Argo CD with custom hook points? Do you need to inte-\ngrate it with other tools? We will explore these questions in chapter 6, so before closing \nthis chapter, let’s look at how environment pipelines and tools like Argo CD fit into the \nplatform engineering story. \n4.4\t\nLinking back to platform engineering\nFrom a platform engineering perspective, providing a GitOps approach is becoming \nincreasingly popular for teams to configure different environments. With the popular-\nity of tools like Argo CD, more people feel comfortable storing and manipulating envi-\nronment configurations on version control systems like Git. As a platform engineering \nteam, you can enable your teams to use this approach without pushing them to learn \nhow to install, maintain, and configure these tools. \nPlatforms can automate the creation of environment repositories and make sure \nthat the right teams have access to read and write configurations to promote services. \n\n\n120\nChapter 4  Environment pipelines: Deploying cloud-native applications\nConsumers of these platforms are expected to know how to interact with their environ-\nments, but not how the tools provided by the platform work or how they are configured. \nThere are cases, for example, in development environments, where using a GitOps \napproach might not work, because some development teams will want direct access to \nclusters, and your platform should be flexible enough to allow this access when needed. \nAs discussed in section 4.3, service and environment pipelines work hand in hand \nto produce software artifacts and move them between environments. Both service and \nenvironment pipelines are key mechanisms to get in place to implement what is known \nas golden paths. The more mature your platform becomes, the coordination between \nenvironment pipelines becomes essential to automate how your new software releases \ngo from source to production environments and are validated by your end users (cus-\ntomers). These golden paths are automated workflows to move the changes that our \nteams are producing to our production environments where customers will be able to \naccess them. Figure 4.22 shows from a high level what a golden path looks like for our \napplications.\nProduction Clusters\nGolden Path (from Source to Production)\nDev Cluster\nNamespace\nStaging Cluster\nQuality \nAssurance\nDevs\nCustomers\nOK!\nFigure 4.22    What does it take to promote new releases to our production environments?\nThink about how many service and environment pipelines will need to be executed \nto take the software produced in our development environments to our production \nclusters, where customers can access the release of a single service. How are these pipe-\nlines coordinated and wired to ensure our deployments work as expected? How many \nmanual verifications do you need in this whole process? And most importantly, what \ncan you automate for your teams not to worry about all these complex interactions?\nSo far, we have covered how to install an application into a Kubernetes cluster, build \nand package the application services into containers, and package and distribute the \nconfiguration files needed to deploy these services into a Kubernetes cluster. This chap-\nter adds to the picture of how to manage different environments where this application \nwill run using a GitOps approach. Figure 4.23 shows all the pieces together.\n\n\n\t\n121\nSummary\nChanges to our environments \nnow happen by submitting \nchanges to a Git repository that \ncontains the configuration of \nwhich services and versions \nneeds to be deployed for each \nenvironment.\nEnvironments \nConfiguration \nRepository\nContainer \nRegistry\nService Pipeline\n(Per Service)\nEnvironment\nEnvironment\nEnvironment\nApplication\nApplication\nApplication\nGitOps Sync\nFigure 4.23    Adding GitOps to manage multiple environments\nBefore digging deeper into golden paths (in chapter 6), we must explore one more \nchallenge we face when we deploy our applications to different environments: applica-\ntion infrastructure, in the next chapter.\nSummary\n¡ Environment pipelines are responsible for deploying software artifacts to live \nenvironments. Environment pipelines avoid teams interacting directly with the \ncluster where the applications run, reducing errors and misconfigurations. Envi-\nronment pipelines should check that environments are fully operational after \nupdating their configuration.\n¡ Using tools like Argo CD, you can define the content of each environment into a \nGit repository that is used as the source of truth for what the environment config-\nuration should look like. Argo CD will keep track of the state of the cluster where \nthe environment is running and ensure no drift in the configuration applied in \nthe cluster. \n¡ Teams can upgrade or downgrade the versions of the services running in an envi-\nronment by submitting pull/change requests to the repository where the envi-\nronment configuration is stored. A team or an automated process can validate \nthese changes, and when approved and merged, these changes will be reflected \nin the live environment. Changes can be rolled back if things go wrong by revert-\ning commits to the git repository.\n¡ If you followed the step-by-step tutorial, you got hands-on experience on how to \ndeploy application workloads following a GitOps approach by using Argo CD.\n",
      "page_number": 109
    },
    {
      "number": 13,
      "title": "Segment 13 (pages 141-148)",
      "start_page": 141,
      "end_page": 148,
      "detection_method": "topic_boundary",
      "content": "122\n5\nMulti-cloud (app) \ninfrastructure\nThis chapter covers\n¡ Defining and managing the infrastructure for \t\n\t your cloud-native applications\n¡ Identifying the challenges of managing  \n\t infrastructure components\n¡ Learning how Crossplane is the Kubernetes way \t\n\t to deal with infrastructure\nIn previous chapters, we installed a walking skeleton, and we learned how to build \neach separate component using service pipelines and then how to deploy them into \ndifferent environments using environment pipelines. We now face a big challenge: \ndealing with our application infrastructure, meaning running and maintaining not \nonly our application services but also the components that our services need to run. \nThese services expect other components to work correctly, such as databases, mes-\nsage brokers, identity management solutions, email servers, etc. While several tools \nexist to automate the installation (for on-premises setups) or provisioning of these \ncomponents in different cloud providers, this chapter will focus on just one that \ndoes it in a Kubernetes way. This chapter has three main sections: \n\n\n\t\n123\nThe challenges of managing infrastructure in Kubernetes\n¡ The challenges of dealing with infrastructure\n¡ How to deal with infrastructure using Kubernetes constructs\n¡ How to provision infrastructure for our walking skeleton using Crossplane\nLet’s get started. Why is it so difficult to manage our application infrastructure?\n5.1\t\nThe challenges of managing infrastructure in Kubernetes\nWhen you design applications like the walking skeleton introduced in chapter 1, you \nface specific challenges that are not core to achieving your business goals. Installing, \nconfiguring, and maintaining application infrastructure components that support our \napplication’s services is a big task that needs to be planned carefully by the right teams \nwith the right expertise. \nThese components are classified as application infrastructure, which usually involves \nthird-party components not developed in-house, such as databases, message brokers, \nidentity management solutions, etc. A big reason behind the success of modern cloud \nproviders is that they are great at providing and maintaining these components and \nallow your development teams to focus on building the core features of applications, \nwhich brings value to the business. \nIt is essential to distinguish between application infrastructure and hardware infra-\nstructure, because this book is not concerned with hardware provisioning, the reminder \nof content focus on the application space. I assume that for public cloud offerings, the \nprovider solves all hardware-related topics. For on-prem scenarios, you likely have a spe-\ncialized team taking care of the hardware (removing, adding, and maintaining hard-\nware as needed).\nIt is common to rely on cloud provider services to provision application infrastruc-\nture. There are a lot of advantages to doing so, such as pay-as-you-use services, easy \nprovisioning at scale, and automated maintenance. But at that point, you heavily rely \non provider-specific ways of doing things and their tools. The moment you create a \ndatabase or a message broker in a cloud provider, you are jumping outside the realms of \nKubernetes. Now you depend on their tools and automation mechanisms, and you are \ncreating a strong dependency between your business and the cloud provider. \nLet’s look at the challenges associated with provisioning and maintaining applica-\ntion infrastructure, so your teams can plan and choose the right tool for the job:\n¡ Configuring components to scale: Each component requires different expertise to \nbe configured (database administrators for databases, message broker experts, \nmachine learning experts, etc.) and a deep understanding of how our applica-\ntion’s services will use it, as well as the hardware available. These configurations \nneed to be versioned and monitored closely, so new environments can be created \nquickly to reproduce problems or test new versions of our application. \n¡ Maintaining components in the long run: Databases and message brokers are con-\nstantly released and patched to improve performance and security. This constant \n\n\n124\nChapter 5  Multi-cloud (app) infrastructure \nchange pushes the operations teams to ensure they can upgrade to newer ver-\nsions and keep all the data safe without bringing down the entire application. All \nthis complexity requires a lot of coordination and impact analysis between the \nteams providing and consuming these components. \n¡ Cloud provider services affect our multi-cloud strategy: If we rely on cloud-specific \napplication infrastructure and tools, we need to find a way to enable develop-\ners to create and provision their components for developing and testing their \nservices. We need a way to abstract how infrastructure is provisioned to enable \napplications to define what infrastructure they need without relying directly on \ncloud-specific tools. \nInterestingly, we had these challenges even before having distributed applications, and \nconfiguration and provisioning architectural components have always been hard and \nusually far away from developers. Cloud providers are doing a fantastic job by bringing \nthese topics closer to developers so they can be more autonomous and iterate faster. \nUnfortunately, when working with Kubernetes, we have more options that we need to \nconsider carefully to ensure we understand the tradeoffs. The following section covers \nhow we can manage our application infrastructure inside Kubernetes. While this is \nusually not recommended, it can be practical and cheaper for some scenarios.  \n5.1.1\t\nManaging your application infrastructure\nApplication infrastructure has become an exciting arena. With the rise of containers, \nevery developer can bootstrap a database or message broker with a couple of com-\nmands, which is usually enough for development purposes. In the Kubernetes world, \nthis translates to Helm Charts, which uses containers to configure and provision data-\nbases (relational and NoSQL), message brokers, identity management solutions, etc. \nAs we saw in chapter 2, you installed the walking skeleton application containing four \nservices, two databases (Redis and PostgreSQL), and a message broker (Kafka) with a \nsingle command. \nFor our walking skeleton, we are provisioning an instance of a Redis NoSQL database \nfor the Agenda service, an instance of a PostgreSQL database for the Call for Proposals \n(C4P) service, and an instance of a Kafka cluster, all using Helm Charts. The number of \nHelm charts available today is impressive, and it is pretty easy to think that installing a \nHelm Chart will be the way to go. The Helm charts used in the example application can \nall be found in the Bitnami Helm Chart repositories at https://bitnami.com/stacks/\nhelm.\nAs discussed in chapter 2, if we want to scale our services that keep state, we must \nprovision specialized components such as databases. Application developers will define \nwhich kind of database will suit them best depending on the data they need to store and \nhow that data will be structured. Figure 5.1 shows the dependency of the application \nservices on some of the application infrastructure components that we have identified \nfor our walking skeleton. \n\n\n\t\n125\nThe challenges of managing infrastructure in Kubernetes\nCall For Proposals \n(C4P) Service\nFrontend\nAgenda Service\nNotifications \nService\nKafka\nPostgreSQL\nKafka\nFigure 5.1    Services and their dependencies on application infrastructure components\nThe process of setting up these (PostgreSQL, Redis, and Kafka) components inside \nyour Kubernetes cluster involves the following steps: \n¡ Finding or creating a suitable Helm Chart for the component you want to boot-\nstrap. For the walking skeleton, PostgreSQL (https://bitnami.com/stack/\npostgresql/helm), Redis (https://bitnami.com/stack/redis/helm), and Kafka \n(https://bitnami.com/stack/kafka/helm) can be found in the Bitnami Helm \nChart repository. If you cannot find a Helm Chart but have a Docker container \nfor the component you want to provision, you can create your chart after you \ndefine the basic Kubernetes constructs needed for the deployment. \n¡ Research the chart configurations and parameters you must set up to accommo-\ndate your requirements. Each chart exposes a set of parameters that you can tune \nfor different use cases. Check the chart website to understand what is available. \nInclude your operations teams and DBAs to check the optimal database config-\nurations for your use case; this is not something that a developer can do. This \nanalysis also requires Kubernetes expertise to ensure the components can work \nin HA (high availability) mode inside Kubernetes.\n¡ Install the chart into your Kubernetes cluster using helm install. By running \nhelm install, you are downloading a set of Kubernetes manifest (YAML files) \nthat describe how these components need to be deployed. Helm will then pro-\nceed to apply these YAML files to your cluster. For our Conference application \nHelm Chart that we installed in chapter 2 (section 2.1.3), all the application \ninfrastructure components are added as a dependency to the chart.\n¡ Configure your service to connect to the newly provisioned components. You can \nachieve this by giving the service the new provisioned instance URL and creden-\ntials to connect. For a database, it will be the database URL serving requests and \npossibly a username and password. An interesting detail to notice here is that \nyour application will need some kind of driver to connect to the target database. \nMore on this in chapter 8.\n¡ Maintain these components in the long run, doing backups and ensuring the \nfail-over mechanisms work as expected.\n\n\n126\nChapter 5  Multi-cloud (app) infrastructure \nFigure 5.2 shows the steps involved in installing and wiring up these application infra-\nstructure components to our application’s services.\nPostgreSQL\nHelm Chart\nPostgreSQL\nService A\nKubernetes Cluster\nNamespace A \n#1\n#2\n#3\n`helm install`\nFigure 5.2    Provisioning a new PostgreSQL instance using the PostgreSQL Helm Chart. #1 Install a helm \nchart into a Namespace inside a Kubernetes Cluster; #2 The chart creates Kubernetes resources such \nas StatefulSets and Deployments to provision a PostgreSQL instance; #3 A Service needs to connect \nto the newly created instance, this can be done manually or by referencing a Kubernetes Secret that \ncontains the credentials and details on how to connect.\nIf you are working with Helm Charts, there are a couple of caveats and tricks that you \nneed to be aware of: \n¡ If the chart doesn’t allow you to configure a parameter that you are interested \nin changing, you can always use helm template, then modify the output to add \nor change the parameters that you need to finally install the components using \nkubectl apply -f. Alternatively, you can submit a pull request to the chart \nrepository. It is a common practice not to expose all possible parameters and wait \nfor community members to suggest more parameters to be exposed by the chart. \nDon’t be shy and contact the maintainers if that is the case. Whatever modifica-\ntion you do, the chart content must be maintained and documented. By using \nhelm template, you lose the Helm release management features, allowing you \nto upgrade a chart when a new version is available. \n¡ Most charts have a default configuration designed to scale, meaning that the \ndefault deployment will target high-availability scenarios. This results in charts \nthat, when installed, consume a lot of resources (CPU and memory) that might \nnot be available if you use Kubernetes KinD or Minikube on your laptop. Once \nagain, chart documentation usually includes special configurations for develop-\nment and resource-constrained environments.\n¡ If you are installing a database inside your Kubernetes cluster, each database \ncontainer (pod) must have access to storage from the underlying Kubernetes \nnode. For databases, you might need a special kind of storage to enable the data-\nbase to scale elastically, which might require advanced configurations outside of \nKubernetes. \n\n\n\t\n127\nThe challenges of managing infrastructure in Kubernetes\nFor our walking skeleton, for example, we set up the Redis chart to use the architec-\nture parameter to standalone, (as you can see in the environment pipeline configu-\nrations and in the Agenda service Helm Chart values.yaml file) to make it easier to run \non environments where you might have limited resources, such as your laptop/work-\nstation. This affects Redis’s availability to tolerate failure, because it will only run a sin-\ngle replica in contrast with the default setup where a master and two slaves are created. \n5.1.2\t\nConnecting our services to the newly provisioned infrastructure\nInstalling the charts will not make our application services automatically connect to \nthe Redis, PostgreSQL, or Kafka instances. We need to provide the services the con-\nfigurations need to connect while also being conscious of the time needed by these \ncomponents, such as databases, to start.\nFigure 5.3 shows how the wiring usually happens, as most charts automatically create \na Kubernetes secret hosting all the details that application’s services need to connect.\n#1\nPostgreSQL\nKubernetes Cluster\nNamespace A\nDeployment\nSecret\nName: postgresql-secret\nURL: postgresql\nPassword: admin\n#3\nPod\nEnv:\nfromSecret: postgresql-secret\n#2\nFigure 5.3    Connecting a service to a provisioned resource using secrets. #1 A Kubernetes deployment \nis created to run one of your services, and the pod template contains the environment variables to \nconfigure the pods that this deployment will create; #2 The pod is created using the template specified \nin the deployment resource, which points to a secret that contains the details to connect to the db \ninstance; #3 The container, which is running inside the pod needs to be prepared to consume the \nenvironment variables to connect to the db instance.\nA common practice is to use Kubernetes secrets to store the credentials for these appli-\ncation infrastructure components. The Helm Chart for Redis and PostgreSQL that \nwe are using for our walking skeleton creates a new Kubernetes secret containing the \ndetails required to connect. These Helm Charts also create a Kubernetes service to be \nused as the location (URL) where the instance will run. \nTo connect the Call for Proposals (C4P) service to the PostgreSQL instance, you \nneed to make sure that the Kubernetes Deployment for the C4P service (conference \n-c4p-service-deployment) has the right environment variables (listing 5.1). \n\n\n128\nChapter 5  Multi-cloud (app) infrastructure \nListing 5.1    Environment variables to connect to application infrastructure (PostgreSQL)\n- name: KAFKA_URL\n  value: <KAFKA SERVICE URL>\n- name: POSTGRES_HOST\n  valueFrom:\n    secretKeyRef:\n      name: <POSTGRESQL SECRET NAME>\n      key: postgres-url\n- name: POSTGRES_PASSWORD\n  valueFrom:\n    secretKeyRef:\n      name: <POSTGRESQL SECRET NAME>\n      key: postgres-password\nThe bold highlights how we can consume the dynamically generated password when \nwe install the chart and the DB endpoint URL, which is the PostgreSQL Kubernetes \nservice, also created by the chart. The DB endpoint will be different if you used a differ-\nent chart release name. \nA similar configuration applies to the Agenda service (conference-agenda-service \n-deployment) and Redis (listing 5.2).\nListing 5.2    Environment variables to connect to application infrastructure (Redis) \n- name: KAFKA_URL\n  value: <KAFKA SERVICE URL>\n- name: REDIS_HOST\n  valueFrom:\n    secretKeyRef:\n      name: <REDIS SECRET NAME>\n      key: redis-url\n- name: REDIS_PASSWORD\n  valueFrom:\n    secretKeyRef:\n      name: <REDIS SECRET NAME>\n      key: redis-password\nAs before, we extract the password from a Kubernetes secret that will be generated \nwhen installing the Redis Helm Chart. The secret name will be derived from the name \nof the Helm Chart release that we use. The REDIS_HOST is obtained from the name \nof the Kubernetes service that is created by the chart, which depends on the helm \nrelease name that you used.  For all the services of the application we will need to \nset up the KAFKA_URL environment variable so that the services can connect to Kafka. \nConfiguring different instances for the application infrastructure components opens \nthe door for us to delegate the provisioning and maintenance to other teams and even \ncloud providers. \n5.1.3\t\nI’ve heard about Kubernetes operators. Should I use them?\nNow you have four application services, two databases, and a message broker inside \nyour Kubernetes cluster. Believe it or not, now you are in charge of seven components \nto maintain and scale depending on the application’s needs. The team that built the \n\n\n\t\n129\nThe challenges of managing infrastructure in Kubernetes\nservices will know exactly how to maintain and upgrade each service, but they are not \nexperts in maintaining and scaling databases or message brokers. \nYou might need help with these databases and message brokers depending on how \ndemanding the services are. Imagine you have too many requests on the Agenda ser-\nvice, so you decide to scale up the number of replicas of the agenda deployment to 200. \nAt that point, Redis must have enough resources to deal with 200 pods connecting to \nthe Redis cluster. The advantage of using Redis for this scenario, where we might get a \nlot of reads while the conference is ongoing, is that the Redis cluster allows us to read \ndata from the replicas so the load can be distributed.\nFigure 5.4 shows a typical case of high demand, where we are tempted to increase \nthe number of replicas of our application’s services, without checking or changing the \nconfiguration of our PostgreSQL instance. In these scenarios, even if the application’s \nservices can scale, the PostgreSQL instance will be the bottleneck if not configured \naccordingly (to support 200+ concurrent connections).\nPod #113\nPod #1\nPod #2\nPod #200\nPod #56\nPostgreSQL\nDeployment\nReplicas: 200\nKubernetes Cluster\nNamespace A\n#1\n#2\nReplicaSet\nFigure 5.4    Application infrastructure needs to be configured according to how our services will be \nscaled. #1 If you noticed a surge in demand for one of your services, you might be tempted to increase \nthe number of replicas, and the deployment using the ReplicaSet will not complain about it. If the cluster \nhas enough resources, the replicas will be created; #2 If the application infrastructure is not correctly \nconfigured, you might encounter a lot of issues, such as exhausting the database connection pool or \noverloading the database pods, as they are not scaled when you scale up your deployments.\nIf you are installing your application infrastructure with Helm, notice that Helm will \nnot check for the health of these components—it is just doing the installation. It is \nquite common nowadays to find another alternative to install components in a Kuber-\nnetes cluster called Operators. Usually associated with application infrastructure, you \ncan find more active components that will install and monitor the installed compo-\nnents. One example of these operators is the Zalando PostgreSQL Operator, which \nyou can find at https://github.com/zalando/postgres-operator. While these operators \nare focused on allowing you to provision new instances of PostgreSQL databases, they \nalso implement other features focused on maintenance, for example: \n",
      "page_number": 141
    },
    {
      "number": 14,
      "title": "Segment 14 (pages 149-156)",
      "start_page": 149,
      "end_page": 156,
      "detection_method": "topic_boundary",
      "content": "130\nChapter 5  Multi-cloud (app) infrastructure \n¡ Rolling updates on Postgres cluster changes, including quick minor version \nupdates\n¡ Live volume resize without pod restarts (AWS EBS, PVC)\n¡ Database connection pooling with PGBouncer\n¡ Supporting fast, in-place major version upgrades\nIn general, Kubernetes operators try to encapsulate the operational tasks associated \nwith a specific component, in this case, PostgreSQL. While using operators might add \nmore features on top of installing a given component, you still need to maintain the \ncomponent and the operator itself now. Each operator comes with a very opinionated \nflow that your teams will need to research and learn to manage. Take this into consid-\neration when researching and deciding which operator to use. \nRegarding the application infrastructure you and your teams decide to use if you \nplan to run these components inside your cluster, plan accordingly to have the right \nin-house expertise to manage, maintain, and scale these extra components.  \nIn the following section, we will look at how we can tackle these challenges by looking \nat an open-source project that aims to simplify the provisioning of cloud and on-prem \nresources for application infrastructure components using a declarative approach. \n5.2\t\nDeclarative infrastructure using Crossplane\nUsing Helm to install application infrastructure components inside Kubernetes is far \nfrom ideal for large applications and user-facing environments, because maintaining \nthese components and their requirements, such as advanced storage configurations, \nmight become too complex to handle for your teams. \nCloud providers do a fantastic job at allowing us to provision infrastructure, but they \nall rely on cloud provider-specific tools that are outside of the realm of Kubernetes. \nIn this section, we will look at an alternative tool—a CNCF project called Crossplane \n(https://crossplane.io), which uses the Kubernetes APIs and extension points to \nenable users to provision real infrastructure in a declarative way, using the Kubernetes \nAPIs. Crossplane relies on the Kubernetes APIs to support multiple cloud providers; \nthis also means that it integrates nicely with all the existing Kubernetes tooling. \nBy understanding how Crossplane works and how it can be extended, you can build \na multi-cloud approach and run your cloud-native applications and their dependencies \nwith different providers without worrying about getting locked in on a single vendor. \nBecause Crossplane uses the same declarative approach as Kubernetes, you can create \nhigh-level abstractions about the applications you are trying to deploy and maintain. \nTo use Crossplane, you must first install its control plane in a Kubernetes cluster. You \ncan follow the official documentation (https://docs.crossplane.io/) or the step-by-step \ntutorial introduced in section 5.3. \nThe core Crossplane components alone will not do much for you. Depending on \nyour cloud provider(s), you will install and configure one or more Crossplane providers. \nLet’s take a look at what Crossplane providers have to offer us. \n\n\n\t\n131\nDeclarative infrastructure using Crossplane\n5.2.1\t\nCrossplane providers\nCrossplane extends Kubernetes by installing a set of components called Crossplane \nproviders (https://docs.crossplane.io/v1.12/concepts/providers/) in charge of \nunderstanding and interacting with cloud provider-specific services to provision cloud \nresources on our behalf. Figure 5.5 shows how by installing the GCP provider and the \nAWS provider, our Crossplane installation can provision resources on both clouds.\nKubernetes Cluster\nKubernetes API\nCrossplane \nAWS Provider\nCrossplane \nGCP Provider\nGCP Account\nAWS Account\n> kubectl apply -f \nresource.yaml\nFigure 5.5    Crossplane installed with GCP and AWS providers\nBy installing Crossplane providers, you are extending the Kubernetes API’s function-\nality to provision external resources such as databases, message brokers, buckets, and \nother cloud resources that will live outside your Kubernetes cluster but inside the \ncloud provider realm. There are several Crossplane providers that cover the major \ncloud providers such as GCP, AWS, and Azure. You can find these Crossplane providers \nin the Crossplane GitHub’s organization: https://docs.crossplane.io/latest/concepts/\nproviders/.\nOnce a Crossplane Provider is installed, you can create provider-specific resources \nin a declarative way, which means that you can create a Kubernetes Resource, apply it \nwith kubectl apply -f, package these definitions in Helm Charts or use environment \npipelines storing these resources in a Git repository.\nFor example, creating a bucket in Google Cloud using the Crossplane GCP provider \nlooks like listing 5.4. \n\n\n132\nChapter 5  Multi-cloud (app) infrastructure \nListing 5.4    Google Cloud Platform bucket resource definition\ncat <<EOF | kubectl create -f -\napiVersion: storage.gcp.upbound.io/v1beta1\nkind: Bucket\nmetadata:\n  generateName: crossplane-bucket-\n  labels:\n    docs.crossplane.io/example: provider-gcp \nspec: \n  forProvider:\n    location: US\n  providerConfigRef:\n    name: default\nEOF\nProvisioning cloud-specific resources relying on the Kubernetes APIs is a big step for-\nward, but Crossplane doesn’t stop there. If you look at what it takes to provision a \ndatabase in any major cloud provider, you will realize that provisioning the compo-\nnent is just one of the tasks involved in getting the component ready to be used. You \nneed extra network and security configurations, user credentials, and other cloud \nprovider-specific configurations to connect to these provisioned resources. Welcome \nCrossplane compositions!  \n5.2.2\t\nCrossplane compositions\nCrossplane aims to serve two different personas: platform teams and application teams. \nWhile platform teams are cloud provider experts who understand how to provision \ncloud provider-specific components, application teams know the application require-\nments and understand what is required from the application infrastructure perspec-\ntive. The interesting thing about this approach is that when using Crossplane, platform \nteams can define these complex configurations for a specific cloud provider and \nexpose simplified interfaces for application teams. \nIn real-life scenarios, it is rare to create a single component. For example, if we want \nto provision a database instance, application teams will also require the correct network \nand security configurations to be able to access the newly created instance. Being able \nto compose and wire together several components is a very convenient feature, and to \nachieve these abstractions and simplified interfaces, Crossplane introduced two con-\ncepts, Composite Resource Definitions (XRDs) and Composite Resources (XRs). \nFigure 5.6 shows how you can use Crossplane XRD to define abstractions for differ-\nent cloud providers. The platform team might be very knowledgeable in Google Cloud \nor Azure, so they will be in charge of defining which Resources they want to wire up \ntogether for a specific application. The application team has a simple resource inter-\nface to request the resource they are interested in. But as usual, abstractions are compli-\ncated and good to show who is responsible for what, but let’s look at a concrete example \nto understand the power of Crossplane compositions.\nBoth apiVersion and \nkind are defined by the \nCrossplane GCP \nprovider. You can find \nall the supported types \nof resources in the \nCrossplane provider \ndocumentation.\nBy creating a bucket resource in \nour Kubernetes cluster where \nCrossplane is installed, you are \ncreating a request for Crossplane \nto provision and monitor this \nresource on your behalf.\nFor each resource type, you \nhave a set of parameters to \nconfigure the resource. In \nthis case, we want the \nbucket to be in the US. \nDifferent resources will \nexpose different \nconfiguration parameters.\n\n\n\t\n133\nDeclarative infrastructure using Crossplane\nPlatform Teams define \n“CompositeResourcesDefinitions” \nto configure cloud resources. These \nresources will managed by Crossplane.\nManaged Resource\nApplication Teams create \nClaims to access Managed \nResources by Crossplane.\nPlatform Teams\nResource\nResource Claim\nCompositeResource\nDefinition\nApplication Teams\nFigure 5.6    Resource composition abstractions by Crossplane composite resources\nFigure 5.7 shows how the application team can create a simple PostgreSQL resource to \na provision in Google Cloud a CloudSQLInstance plus a network configuration and a \nbucket. The application team is interested in something other than what resources are \ncreated or even in which cloud provider they were created. They are only interested in \nhaving a PostgreSQL instance to connect their applications to.  \nApplication Teams \ncreate simple Claim \nresources to request \naccess to Managed \nResources. These \nclaims enable teams to \naccess instances by \ncreating a Secret that \ncontains credentials \nand services URLs to \nconnect. \nGCP CloudSQLInstance\nPostgreSQL\nPlatform Teams understand \nCloud Provider Resources \nand how they need to be \nwired up together.\nPlatform Teams\nApplication \nTeams\nPostgreSQL \nCredentials\n<Secret>\nBucket\nNetwork\nPostgreSQL\nManaged Resource\nPostgreSQL Resource Claim\nPostgreSQL\n<CompositeResource\nDefinition>\nApplication\n<POD>\nFigure 5.7    Provisioning a PostgreSQL instance in Google Cloud with Crossplane compositions\n\n\n134\nChapter 5  Multi-cloud (app) infrastructure \nThis takes us to the Secret box in the figure, representing a Kubernetes secret that \nCrossplane will create for our application/services pods to connect to the provisioned \nresources. Crossplane creates this Kubernetes secret with all the details our applica-\ntions require to connect to the newly created resources (or just with the one relevant \nto the application). This secret typically contains URLs, usernames, passwords, certif-\nicates, or anything required for your applications to connect. Platform teams define \nwhat will be included in the secret when defining the CompositeResources. In the fol-\nlowing sections, when we add real infrastructure to our Conference application, we will \nexplore how these CompositeResourceDefinitions look and how they can be applied \nto create all the components our applications need. \n5.2.3\t\nCrossplane components and requirements\nTo work with Crossplane providers and CompositeResourceDefinitions we need to \nunderstand how Crossplane components will work together to provision and manage \nthese components inside different cloud providers. \nThis section covers what Crossplane needs to work and how Crossplane components \nwill manage our CompositeResources. First, it is important to understand that you \nmust install Crossplane in a Kubernetes cluster. This can be the cluster where your \napplications run or a separate cluster where Crossplane will run. This cluster will have \nsome Crossplane components that will understand our CompositeResourceDefini-\ntions and have enough permissions on the cloud platform to provision resources on \nour behalf. \nKubernetes Cluster\nKubernetes API\nCrossplane \nGCP Provider\nGCP Account\n> kubectl apply -f \ndatabase.yaml\nFigure 5.8    Crossplane in Google Cloud Platform\nFigure 5.8 shows Crossplane installed inside a Kubernetes cluster, with the Crossplane \nGCP provider installed and configured to use a Google Cloud Platform account with \nenough rights to provision PostgreSQL and Redis instances. This means having, in \nsome cases, admin access to create resources on the cloud provider. \n\n\n\t\n135\nDeclarative infrastructure using Crossplane\nFor figure 5.8 to work in GCP, you need the following configurations on the cloud \nprovider: \n¡ For creating a Redis instance in GCP.\n–\t Your GCP project needs to have the redis.googleapis.com APIs enabled.\n–\t You also need to have admin rights on the Redis resources roles/redis \n.admin.\n¡ For creating a PostgreSQL instance in GCP: \n–\t Your GCP project needs to have the sqladmin.googleapis.com APIs \nenabled.\n–\t You also need to have admin rights on the SQL resources roles/cloudsql \n.admin. \nEach Crossplane provider available requires a specific security configuration to work \nand an account inside the cloud provider where we want to create resources. Once a \nCrossplane provider is installed and configured (in this case, the GCP provider) we can \nstart creating resources managed by this provider. You can find the resources offered \nby each provider on the following documentation site: https://doc.crds.dev/github \n.com/crossplane/provider-gcp (figure 5.9).\nFigure 5.9    Crossplane GCP–supported resources\nAs you can see in the previous figure, the GCP provider version 0.22.0 supports 29 \ndifferent CRDs (Custom Resource Definitions) for creating resources in the Google \nCloud Platform. Crossplane defines each of these resources as managed resources. \nEach of these managed resources will need to be enabled for the Crossplane provider \nto have access to the list, create, and modify these resources.  \nIn section 5.3, we will look at how to provision cloud or local resources for our appli-\ncations using different Crossplane providers and Crossplane compositions. Before \njumping into the technical aspects, let’s look at Crossplane core behaviors that you \nshould look for when working with tools in the Kubernetes space.\n\n\n136\nChapter 5  Multi-cloud (app) infrastructure \n5.2.4\t\nCrossplane behaviors\nIn contrast to installing Helm components in our Kubernetes clusters, we use \nCrossplane to interact with the cloud provider-specific APIs to provision resources \ninside the cloud infrastructure. This should simplify the maintenance tasks and costs \nrelated to these resources. Another important difference is that the Crossplane pro-\nvider (GCP provider in this case) will observe the created managed resources for \nus. These managed resources offer some advantages compared with just installed \nresources using Helm. Managed resources have very well-defined behaviors. Here is a \nsummary of what to expect from a Crossplane managed resource:\n¡ Visible as any other Kubernetes resource: Crossplane managed resources are just \nKubernetes resources. This means that we can use any Kubernetes tool to moni-\ntor and query the state of these resources. \n¡ Continuous reconciliation: When a managed resource is created, the provider will \ncontinuously monitor the resource to ensure it exists and is working and report \nback the status to the Kubernetes resource. The parameters defined inside \nthe managed resource are considered the desired state (source of truth) and \nCrossplane providers will work to apply these configurations to the cloud pro-\nvider resources. Once again, we can use standard Kubernetes tools to monitor \nchanges in state and trigger remediation flows. \n¡ Immutable propertiesProviders are in charge of reporting back if a user manually \nchanges properties in the cloud provider. The idea here is to avoid configuration \ndrifts from what was defined to what is running in the cloud provider. If so, the \nstate is reported back to the managed resource. Crossplane will not delete the \ncloud provider resource but will notify back so actions can be taken. Other tools \nlike Terraform (https://www.terraform.io) will automatically delete the remote \nresources to recreate them. \n¡ Late initialization: Some properties in the managed resources can be optional, \nmeaning each provider will select the default values for these properties. When \nthis happens, Crossplane creates the resource with the default values and then \nsets the selected values into the managed resource. This simplifies the configura-\ntion needed to create resources and reuse the sensible defaults defined by cloud \nproviders, usually in their user interfaces.\n¡ Deletion: When deleting a managed resource, the cloud provider immediately \ntriggers the action. However, the managed resource is kept until the resource is \nfully removed from the cloud provider. Errors that might happen during dele-\ntion on the cloud provider will be added to the managed resource status field. \n¡ Importing existing resources: Crossplane doesn’t necessarily need to create the \nresources to manage them. You can create managed resources that start moni-\ntoring components created before Crossplane was installed. You can achieve this \nusing a specific Crossplane annotation on the managed resource: crossplane \n.io/external-name.\n\n\n\t\n137\nDeclarative infrastructure using Crossplane\nTo summarize the interactions between Crossplane, the Crossplane GCP provider, and \nour managed resources, let’s look at figure 5.10. \nKubernetes Cluster\nKubernetes API\nCrossplane \nGCP Provider\nGCP Account\n1\n2\n6\n3\n4\n5\n> kubectl apply -f \ndatabase.yaml\nManaged \nResource\nSecret\nFigure 5.10    Lifecycle of managed resources with Crossplane\nThe following points indicate the sequence observed in figure 5.10:\n1\t First, we need to create a resource. We can use any tool to create Kubernetes \nresources; kubectl here is just an example. \n2\t If the created resource is a Crossplane managed resource, let’s imagine a \nCloudSQLInstance resource the GCP Crossplane provider will pick up and \nmanage.\n3\t The first step to execute when managing a resource will be checking if it exists \nin the infrastructure (that is, in the configured GCP account). If it doesn’t exist, \nthe provider will request that the resource be created in the infrastructure. The \nappropriate SQL database will be provisioned depending on the properties set \non the resource, such as which kind of SQL database is required. Imagine that we \nhave chosen a PostgreSQL database for the sake of the example. \n4\t The cloud provider, after receiving the request, if the resources are enabled, will \ncreate a new PostgreSQL instance with the configured parameters in the man-\naged resource. \n5\t The status of the PostgreSQL will be reported back to the managed resource, \nwhich means that we can use kubectl or any other tool to monitor the status of \nthe provisioned resources. Crossplane providers will keep these in sync. \n6\t When the database is up and running, the Crossplane provider will create a secret \nto store the credentials and properties that our applications will need to connect \nto the newly created instance.\nCrossplane will regularly check the status of the PostgreSQL instance and update the \nmanaged resource. \n",
      "page_number": 149
    },
    {
      "number": 15,
      "title": "Segment 15 (pages 157-170)",
      "start_page": 157,
      "end_page": 170,
      "detection_method": "topic_boundary",
      "content": "138\nChapter 5  Multi-cloud (app) infrastructure \nBy following Kubernetes design patterns, Crossplane uses the reconciliation cycle \nimplemented by controllers to keep track of external resources.  Let’s see this in action! \nThe following section will examine how we can use Crossplane with our walking skele-\nton application.  \n5.3\t\nInfrastructure for our walking skeleton\nIn this section, we will use Crossplane to abstract away how we provision infrastructure \nfor our Conference application. Because you might not have access to a cloud provider \nlike GCP, AWS, or Azure, we will work with a special provider called the Crossplane \nHelm provider. This Crossplane Helm provider allows us to manage Helm Charts as \ncloud resources. The idea here is to show how using Crossplane—more specifically, \nusing Crossplane compositions—we can enable users to request resources using a sim-\nplified Kubernetes resource to provision local or different cloud resources (hosted in \ndifferent cloud providers). \nFor our Conference application, we need Redis, PostgreSQL, and Kafka instances. \nFrom the application perspective, as soon as these three components are available, we \ncan connect to them, and we are good to go. How these components are configured is \nthe responsibility of the operations teams. \nThe conference application helm chart that we installed in chapter 2 included the \ninstallation of Redis, PostgreSQL, and Kafka as Helm dependencies using a condi-\ntional value that can be set at installation time. Let’s take a quick look at how this was \nwired up for our Helm Chart: https://github.com/salaboy/platforms-on-k8s/blob/ \nmain/conference-application/helm/conference-app/Chart.yaml#L13. \nThe Conference Helm Chart includes the Redis, PostgreSQL, and Kafka charts \ndependencies, as shown in listing 5.5.\nListing 5.5    Conference application with Helm Chart dependencies\napiVersion: v2\ndescription: A Helm chart for the Conference App\nname: conference-app\nversion: v1.0.0\ntype: application\nicon: https://www.salaboy.com/content/images/2023/06/avatar-new.png\nappVersion: v1.0.0\nhome: http://github.com/salaboy/platforms-on-k8s\ndependencies: \n- name: redis\n  version: 17.11.3 \n  repository: https://charts.bitnami.com/bitnami\n  condition: install.infrastructure\nYou can include any number of dependencies to \nyour Helm Charts. This allows complex compositions.\nEach dependency \nrequires the chart \nname, the repository \nwhere it is hosted \n(notice that you can use \noci:// references here \ntoo), and the version of \nthe chart that you want \nto install. \nCustom conditions can be defined to \ndecide if this dependency is injected \nwhen we install the chart.\n\n\n\t\n139\nInfrastructure for our walking skeleton\n- name: postgresql\n  version: 12.5.7 \n  repository: https://charts.bitnami.com/bitnami\n  condition: install.infrastructure\n- name: kafka\n  version: 22.1.5\n  repository: https://charts.bitnami.com/bitnami\n  condition: install.infrastructure \nFor this example, all the application infrastructure dependencies are defined at the \napplication level (dependencies section in the Chart.yaml file), but there is nothing \nstopping you from having one Helm Chart per service, which internally defines its own \ndependencies.\nThis kind of chart dependency works for development teams that want to install the \nentire application with all the components needed with a single command. Still, we \nwant to decouple all the application infrastructural concerns from application services \nfor larger scenarios. Luckily, the Conference application Helm Chart allows us to turn \noff these component dependencies, allowing us to plug in Redis, PostgreSQL, and \nKafka instances hosted and managed by different teams (figure 5.11). \nConference Application Helm Chart\ninstall.infrastructure: true\nRedis Helm Chart\nVersion: 17.11.3\nPostgresql Helm Chart\nVersion: 12.5.7\nKafka Helm Chart\nVersion: 22.1.5\nUsers install this top \nlevel chart\nFigure 5.11    Using Helm Chart dependencies for application infrastructure\nBy separating who requests and who provisions the application’s infrastructure com-\nponents, we enable different teams to control and manage when these components \nare updated, backed up, or how they need to be restored in case of failure. By using \nCrossplane, we can enable teams to request these databases on demand, which then \ncan be connected to our application’s services. One important aspect of the mecha-\nnisms we will use in the next sections is that the components we request can be pro-\nvisioned locally (using the Crossplane Helm provider) or remotely using Crossplane \ncloud providers. Let’s see what this would look like. You can follow a step-by-step tuto-\nrial to install, configure, and create your Crossplane compositions: https://github \n.com/salaboy/platforms-on-k8s/tree/main/chapter-5. \nIn this example, we will create a KinD cluster and configure Crossplane to allow \nteams to request application infrastructure on demand using the Crossplane Helm \nprovider for development purposes. In production the same requests will be satisfied \n\n\n140\nChapter 5  Multi-cloud (app) infrastructure \nvia scalable cloud resources. More specifically, we enable teams to request Redis, Post-\ngreSQL, and Kafka instances this way using a simplified interface.\nFor our Conference application example, the platform team decided to create two \ndifferent concepts: \n¡ Databases: NoSQL and SQL databases such as Redis and PostgreSQL. \n¡ Message brokers: For managed and unmanaged message brokers such as Kafka. \nAfter having Crossplane and the Crossplane Helm provider installed, the platform \nteam needs to define two Kubernetes resources: \n¡ Crossplane Composite Resource Definitions (XRDs): Defines the resources we want \nto expose to our teams—in this example, Database and MessageBroker. These \nComposite Resource Definitions define an interface that multiple Compositions \ncan implement.\n¡ Crossplane composition: The Crossplane composition allows us to define a set of \nresource manifests. We can link a composition to a Composite Resource Defini-\ntion and implement that XRD. By doing so, when the user requests new resources \nfrom the XRD–defined resource, all the composed resource manifests in the \ncomposition will be created in the cluster. We can provide multiple compositions \n(for example for different cloud providers), all implementing the same XRD, \nand then use labels in our resources to choose which composition should kick in.\nI know this might sound confusing at first, so let’s see these concepts in action. Let’s \nlook at the database Crossplane Composite Resource Definition (https://github.com/\nsalaboy/platforms-on-k8s/blob/main/chapter-5/resources/app-database-resource \n.yaml) in listing 5.6.\nListing 5.6    Database Composite Resource Definition\napiVersion: apiextensions.crossplane.io/v1\nkind: CompositeResourceDefinition\nmetadata:\n  name: databases.salaboy.com\nspec:\n  group: salaboy.com \n  names:\n    kind: Database\n    plural: databases\n    shortNames:\n      - \"db\"\n      - \"dbs\"\n  versions:\n  - additionalPrinterColumns:\n    - jsonPath: .spec.parameters.size\n      name: SIZE\n      type: string\nAs with every Kubernetes resource, \nthe CompositeResourceDefinition \nneeds a unique name.\nThis CompositeResourceDefinition \ndefines a new type of resource that \nneeds to have a group and a kind.\nOur new resource type that users can \nrequest is Database, because we want to \nenable them to request new databases.\n\n\n\t\n141\nInfrastructure for our walking skeleton\n    - jsonPath: .spec.parameters.mockData\n      name: MOCKDATA\n      type: boolean  \n    - jsonPath: .spec.compositionSelector.matchLabels.kind\n      name: KIND\n      type: string\n    name: v1alpha1\n    served: true\n    referenceable: true\n    schema: \n      openAPIV3Schema:\n        type: object\n        properties:\n          spec:\n            type: object\n            properties:\n              parameters: \n                type: object\n                properties:\n                  size:\n                    type: string \n                  mockData: \n                    type: boolean\n                required:   \n                - size\n            required: \n            - parameters \nWe have defined a new type of resource called a Database, which contains two param-\neters that we can set, size and mockData. Users can define how many resources are \nallocated for that instance by setting up the size parameter. Instead of worrying about \nhow much storage they will need or how many replicas they need for the database \ninstances, they can simply specify a size from a list of possible values (small, medium, \nor large). Using the mockData parameters, you can implement a mechanism to inject \ndata into the instance when needed. This is just an example of what can be done, but it \nis up to you to define these interfaces and what parameters make sense to your teams. \nLet’s see what the Crossplane composition looks like that will implement this XRD, \nin listing 5.7. \nListing 5.7    Key/value Database Crossplane composition\napiVersion: apiextensions.crossplane.io/v1\nkind: Composition\nmetadata:\n  name: keyvalue.db.local.salaboy.com\n  labels: \n    type: dev\n    provider: local\n    kind: keyvalue\nspec:\n  writeConnectionSecretsToNamespace: crossplane-system\nThe new resource we are \ndefining can also define custom \nparameters. For this example, \nand only for demonstration \npurposes, we are defining only \ntwo: size and mockData.\nBecause the Kubernetes API server can \nvalidate all resources, we can define which \nparameters are required and their types and \nother validations. The Kubernetes API server \nwill reject our resource request if these \nparameters are not provided or invalid.\nThe composition resource also \nneeds a unique name.\nFor each composition, we can also define labels. We \nwill then use these to match compositions with the \nrequested Database resources.\n\n\n142\nChapter 5  Multi-cloud (app) infrastructure \n  compositeTypeRef: \n    apiVersion: salaboy.com/v1alpha1\n    kind: Database\n  resources:\n    - name: redis-helm-release\n      base:\n        apiVersion: helm.crossplane.io/v1beta1\n        kind: Release\n        metadata:\n          annotations:\n            crossplane.io/external-name: # patched\n        spec:\n          rollbackLimit: 3\n          forProvider:\n            namespace: default\n            chart: \n              name: redis\n              repository: https://charts.bitnami.com/bitnami\n              version: \"17.8.0\"\n            values:\n              architecture: standalone\n          providerConfigRef: \n            name: default\n      patches: \n        - fromFieldPath: metadata.name\n          toFieldPath: metadata.annotations[crossplane.io/external-name]\n          policy:\n            fromFieldPath: Required\n        - fromFieldPath: metadata.name\n          toFieldPath: metadata.name\n          transforms:\n            - type: string\n              string:\n                fmt: \"%s-redis\"         \n      readinessChecks: \n      - type: MatchString\n        fieldPath: status.atProvider.state\n        matchString: deployed\nUsing the compositeTypeRef property, we are linking \nDatabase CompositeResourceDefinition to this composition.\nInside the resources array, we \ncan define all the resources this \ncomposition will provision. It is \nquite common to have more \nthan one resource here. For \nthis example, we are \nconfiguring a single resource of \ntype Release defined in the \nCrossplane Helm provider.\nWe need to provide the values \ndefined for the Release \nresource, in this case, the Helm \nChart details that we want to \ninstall using the Crossplane \nHelm provider. As you can see, \nwe are pointing to the Redis \nHelm Chart hosted by Bitnami.\nUsing the providerConfigRef, \nwe can target different \nCrossplane Helm provider \nconfigurations. This means \nwe can have different Helm \nproviders pointing to \ndifferent target clusters, and \nthis composition can select \nwhich one to use. For the \nsake of simplicity, this \ncomposition uses the default \nconfiguration for the local \nHelm provider installation.\nBecause we are wiring multiple \nresources, we can patch resources to \nconfigure them to work together or to \napply the parameters of the requested \nresource. Check the Crossplane \ndocumentation for more details on what \ncan be achieved with these mechanisms.\nFor each composition, we can define a condition to flag the \nresource status. For this example, we will mark the \ncomposition as ready when the Helm Release resource status \n.atProvider.state property is set to deployed. If you are \nprovisioning multiple resources, you, as the person defining \nthe composition, will need to define what this condition is.\n\n\n\t\n143\nInfrastructure for our walking skeleton\nWith this composition, we link our Database claim with a set of resources, in this case, \ninstalling the Redis Helm Chart using the default Helm provider we installed with \nCrossplane in our Kubernetes cluster. Figure 5.12 shows two user requests for the same \ndatabase type. \nUsers request as \nmany Database \nresources as \nthey want\nkeyvalue.db.local.salaboy.com\n<Composition>\ndatabases.salaboy.com\n<Composite Resource \nDefinition>\nmy-db\n<Database>\nmy-db-2\n<Database>\nRedis Helm Chart\nVersion: 17.6.0\nInstall using the \nHelm Provider\nFigure 5.12    Crossplane composition and Composite Resource Definition working together\nIt is important to note that this Helm Chart will be installed in the same Kubernetes \ncluster where Crossplane is installed. Still, nothing stops us from configuring the Helm \nprovider to have the right credentials to install charts to a completely different cluster.\nIn the step-by-step tutorial (https://github.com/salaboy/platforms-on-k8s/tree/\nmain/chapter-5), you will install the three Composite Resource Definitions and three \ncompositions. Once these are installed, as shown in figure 5.12, you can request new \ndatabases and message brokers, and for every request, all the resources defined in the \ncomposition will be provisioned. For the sake of simplicity, the key-value database com-\nposition just installs Redis, but there are no limits on how many resources you can cre-\nate (except for the available hardware or quotas you have). \nA Database resource is just another Kubernetes resource that now our cluster \nunderstands, and it looks like listing 5.8. \nListing 5.8    Teams create database resources to request new database instances\napiVersion: salaboy.com/v1alpha1\nkind: Database\nmetadata:.  name: my-db-keyavalue\nspec:\n  compositionSelector:\n    matchLabels: \n      provider: local\n      type: dev\n      kind: keyvalue\n  parameters: \n    size: small\n    mockData: false\n    \nThe unique name \nfor the resource\nWe use matchLabels to select \nthe appropriate composition.\nWe need to set the parameters that are \nrequired by our Database resource claim.\n\n\n144\nChapter 5  Multi-cloud (app) infrastructure \nThe schema for this Database resource is defined inside the Crossplane Composite \nResourceDefinition. Notice that the spec.compositionSelector.matchLabels \nmatches with the labels used for the composition. We can use this mechanism to select \na different composition for the same Database definition. \nIf you are following the step-by-step tutorial, try to create multiple resources and look \nat the Crossplane official documentation to understand how to implement parameters \nlike small or mockData because these values are not being used yet and only serve for \ndemonstration purposes.\nThe real power of these mechanisms comes when you have different compositions \n(implementations) for the same interface (Composite Resource Definition). For exam-\nple, we can now create another composition to provision PostgreSQL instances for the \nCall for Proposals service, as shown in listing 5.9. The PostgreSQL composition will look \nsimilar to the one for Redis, but it will install the PostgreSQL helm chart instead. \nListing 5.9    SQL Database Crossplane Composition\napiVersion: apiextensions.crossplane.io/v1\nkind: Composition\nmetadata:\n  name: sql.db.local.salaboy.com \n  labels:\n    type: dev\n    provider: local\n    kind: sql \nspec:\n  ...\n  compositeTypeRef:\n    apiVersion: salaboy.com/v1alpha1\n    kind: Database\n  resources:\n    - name: postgresql-helm-release\n      base:\n        apiVersion: helm.crossplane.io/v1beta1\n        kind: Release\n        spec:\n          forProvider:\n            chart: \n              name: postgresql\n              repository: https://charts.bitnami.com/bitnami\n              version: \"12.2.7\"\n          providerConfigRef:\n            name: default \n          …\nLet’s look at how to create a PostgreSQL instance using this composition. Creating a \nPostgreSQL instance will look pretty similar to what we did before for Redis, as shown \nin listing 5.10. \nWe need a \nunique name for \nour composition, \nso we can \ndifferentiate it \nfrom the \nkeyvalue \ncomposition that \nwe used for \nRedis.\nWe use a different \nlabel to describe this \ncomposition, notice \nthat the provider is the \nsame as before.\nWe want to install the \nPostgreSQL Helm Chart \nhosted by Bitnami.\n\n\n\t\n145\nInfrastructure for our walking skeleton\nListing 5.10    Database resource with kind: sql label to select implementation\napiVersion: salaboy.com/v1alpha1\nkind: Database\nmetadata:\n  name: my-db-sql\nspec:\n  compositionSelector:\n    matchLabels:\n      provider: local\n      type: dev\n      kind: sql\n  parameters: \n    size: small\n    mockData: false\nWe are just using labels to select which composition will be triggered for our Database \nresource. Figure 5.13 shows these concepts in action. Notice how labels select the right \ncomposition based on the kind label value. \nRedis Helm Chart\nPostgreSQL Helm Chart\nkeyvalue.db.local.salaboy.com\n<Composition>\nLabels: \nkind: keyvalue\nprovider: local\nmy-db-kv\n<Database>\nLabels: \nkind: keyvalue\nprovider: local\ndatabases.salaboy.com\n<Composite Resource \nDefinition>\nmy-db-sql\n<Database>\nLabels: \nkind: sql\nprovider: local\nsql.db.local.salaboy.com\n<Composition>\nLabels: \nkind: sql\nprovider: local\nFigure 5.13    Selecting compositions using labels\nHooray! We can create databases! But of course, this doesn’t stop here. If you have \naccess to a cloud provider, you can provide compositions that create database instances \ninside the cloud provider, and this is where Crossplane shines.  \nIf we use the Google Cloud Platform (GCP) as an example, for compositions that \nuse cloud resources from GCP, you will need to install the Crossplane GCP provider \nand configure it accordingly, as explained in the official Crossplane documentation: \nhttps://docs.crossplane.io/latest/getting-started/provider-gcp/. \nThe unique name used for the \nPostgreSQL database.\nWe use the “sql” label to match the \npreviously defined composition.\n\n\n146\nChapter 5  Multi-cloud (app) infrastructure \nmy-db-kv\n<Database>\nLabels: \nkind: keyvalue\nprovider: local\nmy-db-cloud-kv\n<Database>\nLabels: \nkind: keyvalue\nprovider: cloud\ndatabases.salaboy.com\n<Composite Resource \nDefinition>\nkeyvalue.db.local.salaboy.com\n<Composition>\nLabels: \nkind: keyvalue\nprovider: local\nkeyvalue.db.cloud.salaboy.com\n<Composition>\nLabels: \nkind: keyvalue\nprovider: cloud\nRedis Helm Chart\nGCP MemoryStore (Redis)\nCrossplane will \nuse the \nconfigured GCP \nProvider\nFigure 5.14    Selecting compositions using different providers, still using labels\nWe can still select different providers by matching labels with our desired composition. \nBy changing a label in figure 5.14, we can use the local Helm Provider or the GCP pro-\nvider to instantiate a Redis Instance.\nNOTE  Check the community–contributed AWS compositions for this example \nusing the Crossplane AWS Provider at https://github.com/salaboy/platforms \n-on-k8s/tree/main/chapter-5/aws. \nThen, creating new database resources that will be provisioned in the Google Cloud \nPlatform will look like listing 5.11. \nListing 5.11    Requesting a new SQL database\napiVersion: salaboy.com/v1alpha1\nkind: Database\nmetadata:\n  name: my-db-cloud-sql\nspec:\n  compositionSelector:\n    matchLabels:\n      provider: gcp\n      type: dev\n      kind: sql\n  parameters: \n    size: small\n    mockData: false\nNo matter where our databases or other application infrastructure components are \nprovisioned, we can connect our application’s services by following some conven-\ntions. We can use the resource name (for example, my-db-cloud-sql) to know which \nKubernetes service will be used for service discovery. We can also use the created secret \nto obtain the credentials that we will need to connect.  \nThe unique name for our \nresource needs to be different \nfrom all the ones used before.\nThe provider label selects the composition labeled with \nprovider: gcp. In other words, with this label, we select \nwhere the database will be provisioned.\nThe kind label allows us to select which \nkind of database we want to provision.\n\n\n\t\n147\nInfrastructure for our walking skeleton\nThe step-by-step tutorial also provides a CompositeResourceDefinition for mes-\nsage brokers and a composition that installs the Kafka Helm chart that you can find at \nhttps://github.com/salaboy/platforms-on-k8s/blob/main/chapter-5/resources/app \n-messagebroker-kafka.yaml. \nOne really important thing to consider for this example is that Google Cloud Plat-\nform doesn’t provide a managed Kafka service. This pushes your team to decide to \nreplace Kafka when the application is going to be deployed on Google Cloud Platform, \ninstall and manage Kafka on Google Cloud compute or hire a third-party service. In the \nAWS example, we have a Kafka–managed service that we can use, so there is no need to \nchange our application code. But still, wouldn’t it be nice to abstract away how we con-\nnect to these infrastructure services? More on this in chapter 7.\nFigure 5.15 shows how easy it is to provide a Composite Resource Definition for key/\nvalue databases that can be provisioned locally using Helm or managed by a cloud pro-\nvider. But in the case of Kafka, it gets a bit trickier because you might need to inte-\ngrate with a third-party service or take the lead in having a team to manage the Kafka \ninstance(s).\nkeyvalue.db.local.salaboy.com\n<Composition>\nkeyvalue.db.cloud.salaboy.com\n<Composition>\nkafka.mb.local.salaboy.com\n<Composition>\n???.mb.cloud.salaboy.com\n<Composition>\ndatabases.salaboy.com\n<Composite Resource \nDefinition>\nmessagebrokers.salaboy.com\n<Composite Resource \nDefinition>\nmy-db\n<Database>\nmy-mb\n<MessageBroker>\nRedis Helm Chart\nGCP MemoryStore (Redis)\nKafka Helm Chart\nCloud Service\nFigure 5.15    Compositions push teams to define which Cloud services are available for our applications \nto use.\nBesides Kafka and Google Cloud Platform, your teams will need a strategy to deal with \ninfrastructure across cloud providers, or at least make conscious choices about how to \ndeal with situations like this. From the application’s services perspective, would you \n\n\n148\nChapter 5  Multi-cloud (app) infrastructure \nmaintain two copies of the same service if you decide to swap Kafka and use Google \nPubSub instead? One includes the Kafka dependencies, and the other includes the \nGoogle GCP SDKs to connect to Google PubSub. If you only use Google PubSub, you \nlose the ability to run the application outside Google Cloud. \n5.3.1\t\nConnecting our services with the new provisioned infrastructure\nWhen we create new database or message broker resources, Crossplane will monitor \nthe status of these Kubernetes resources against the status of the provisioned compo-\nnents inside the specific cloud provider, keeping them in sync and ensuring that the \ndesired configurations are applied. This means that Crossplane will make sure that our \ndatabases and message brokers are up and running. If for some reason that changes, \nCrossplane will try to reapply the configurations that we requested until what we \nrequested is up and running. \nIf we don’t have the application deployed in our KinD cluster, we can deploy it with-\nout installing PostgreSQL, Redis, and Kafka. As we have seen in chapter 2, this can be \ndisabled by setting one flag: install.infrastructure=false:\n> helm install conference oci://docker.io/salaboy/conference-app  \n➥--version v1.0.0 --set install.infrastructure=false\nI strongly recommend you check out the step-by-step tutorial that you can find at \nhttps://github.com/salaboy/platforms-on-k8s/tree/main/chapter-5 to get your hands \ndirty with Crossplane and the Conference application. The best way to learn is by \ndoing!\nIf we just run this command, no components (Redis, PostgreSQL, or Kafka) will be \nprovisioned by Helm. Still, the application’s services will not know where to connect to \nthe Redis, PostgreSQL, and Kafka instances we created using our Crossplane composi-\ntions. We need to add more parameters to the application chart, so the services know \nwhere to connect. First, check which databases you have available in your cluster as in \nlisting 5.12. \nListing 5.12    Listing all database resources\n> kubectl get dbs\nNAME              SIZE     KIND       SYNCED   READY   COMPOSITION                     \nmy-db-keyavalue   small    keyvalue   True     True    keyvalue.db.local.salaboy.com   \nmy-db-sql         small    sql        True     True    sql.db.local.salaboy.com        \nThe tutorial also guides you to create a MessageBroker and checks that you have one \ninstance of that too, as in listing 5.13. \nListing 5.13    Listing all MessageBroker resources\n> kubectl get mbs\nNAME          SIZE    KIND    SYNCED   READY   COMPOSITION                  \nmy-mb-kafka   small   kafka   True     True    kafka.mb.local.salaboy.com   \nListing 5.14 shows the Kubernetes pods for our database instances and our message \nbroker.\n\n\n\t\n149\nInfrastructure for our walking skeleton\nListing 5.14    Pods for our application infrastructure\n> kubectl get pods\nNAME                             READY   STATUS    RESTARTS   AGE\nmy-db-keyavalue-redis-master-0   1/1     Running   0          25m\nmy-db-sql-postgresql-0           1/1     Running   0          25m\nmy-mb-kafka-0                    1/1     Running   0          25m\nAlong with the pods, four Kubernetes secrets were created: two to store the Helm \nreleases used by our Crossplane compositions and two containing our new databases \npasswords that our applications will need to use to connect (see listing 5.15).\nListing 5.15    Kubernetes secrets containing credentials to connect to our Databases\n> kubectl get secret\nNAME                                    TYPE                 DATA   AGE\nmy-db-keyavalue-redis                   Opaque               1      26m\nmy-db-sql-postgresql                    Opaque               1      25m\nsh.helm.release.v1.my-db-keyavalue.v1   helm.sh/release.v1   1      26m\nsh.helm.release.v1.my-db-sql.v1         helm.sh/release.v1   1      25m\nsh.helm.release.v1.my-mb-kafka.v1       helm.sh/release.v1   1      25m\nTake a look at the services available in the default namespace after we provisioned our \ndatabases, see Listing 5.16: \nListing 5.16    Custom values.yaml file to connect with new infrastructure\n> kubectl get services\nNAME                           TYPE        CLUSTER-IP       PORT(S)\nkubernetes                     ClusterIP   10.96.0.1        443/TCP\nmy-db-keyavalue-redis-headless ClusterIP   None             6379/TCP\nmy-db-keyavalue-redis-master   ClusterIP   10.96.49.121     6379/TCP\nmy-db-sql-postgresql           ClusterIP   10.96.129.115    5432/TCP\nmy-db-sql-postgresql-hl        ClusterIP   None             5432/TCP\nmy-mb-kafka                    ClusterIP   10.96.239.45     9092/TCP\nmy-mb-kafka-headless           ClusterIP   None             9092/TCP\nWith the database and message broker service names and secrets, we can configure our \nconference application chart to not only not deploy Redis, PostgreSQL, and Kafka but \nalso to connect to the right instances by running the following command:\n> helm install conference oci://docker.io/salaboy/conference-app  \n➥--version v1.0.0 -f app-values.yaml\nInstead of setting all the parameters in the command, we are using a file for the values \nto be applied to the chart. For this example, the app-values.yaml file looks like listing \n5.17. \n\n\n150\nChapter 5  Multi-cloud (app) infrastructure \nListing 5.17    Helm Chart customized values.yaml file\ninstall:\n  infrastructure: false\nfrontend:\n  kafka:\n    url: my-mb-kafka.default.svc.cluster.local\nagenda:\n  kafka:\n    url: my-mb-kafka.default.svc.cluster.local\n  redis:\n    host: my-db-keyavalue-redis-master.default.svc.cluster.local\n    secretName: my-db-keyavalue-redis\nc4p:\n  kafka:\n    url: my-mb-kafka.default.svc.cluster.local\n  postgresql:\n    host: my-db-sql-postgresql.default.svc.cluster.local\n    secretName: my-db-sql-postgresql\nnotifications:\n  kafka:\n    url: my-mb-kafka.default.svc.cluster.local\nIn this app-values.yaml file, we are not only turning off the Helm dependencies for \nPostgreSQL, Redis, and Kafka, but we are also configuring the variables needed for \nthe services to connect to our newly provisioned databases. Notice that if the data-\nbases were created in a different namespace or with a different name, the kafka.\nurl, postgresql.host and redis.host should contain the appropriate name-\nspace in the fully qualified name of the service, for example, my-db-sql-postgresql \n.default.svc.cluster.local (where default is the namespace). \nFigure 5.16 shows the Conference application services connecting to the application \ninfrastructure that was created with Crossplane. The boundaries between the developer \nrealm and the platform team become more defined now, as developers interested in \ngetting the infrastructure that they need have a set of options that are carefully selected \nby the platform team and exposed to developers using simpler interfaces.\nWe disable the Redis, PostgreSQL, and Kafka Helm \ndependencies. These components will not be \ninstalled when we install the application.\nWe use the Kubernetes \nservice created for our \nKafka cluster to \nconnect all the \napplication services to \nthe created instance. \nThe same approach is \nused for Redis and \nPostgreSQL.\nFor both Redis and PostgreSQL, \na Kubernetes secret is created \nby the composite resource. Our \nHelm Chart understands how to \nget the credentials from the \nsecret, so we only need to \nspecify the secret name.\n\n\n\t\n151\nInfrastructure for our walking skeleton\nkeyvalue.db.local.salaboy.com\n<Composition>\nLabels: \nkind: keyvalue\nprovider: local\nkeyvalue.db.cloud.salaboy.com\n<Composition>\nLabels: \nkind: keyvalue\nprovider: cloud\nkafka.mb.local.salaboy.com\n<Composition>\ndatabases.salaboy.com\n<Composite Resource \nDefinition>\nmessagebroker.\nsalaboy.com\n<Composite Resource \nDefinition>\nmy-db-keyvalue\n<Database>\nmy-db-sql\n<Database>\nmy-mb-kafka\n<MessageBroker>\nCall for Proposals Service\nAgenda Service\nNotifications Service\nRedis Helm Chart\nGCP MemoryStore (Redis)\nKafka Helm Chart\nPlatform \nEngineer\nDevelopers\nFigure 5.16    Enabling different teams to work together and focus on their tasks at hand\nAll this effort enables us to split the responsibility of defining, configuring, and run-\nning all the application infrastructure to another team not responsible for working \non the application’s services. Services can be released independently without worrying \nabout which databases are being used or when they need to be upgraded. Developers \nshouldn’t be worrying about cloud provider accounts or if they have access to create \ndifferent resources. Hence, another team with a completely different set of skills can \ntake care of creating Crossplane compositions and configuring Crossplane providers. \nWe have also enabled teams to request application infrastructure components by \nusing Kubernetes resources. This enables them to create their setups for experimen-\ntation and testing or to set up new instances of the application quickly. This is a major \nshift in how we (as developers) were used to doing things, because before this, cloud \nproviders and most companies must have access to a database and a ticketing system to \nrequest another team to provision that resource for you, which can take weeks! \nTo summarize what we have achieved so far, we can say that:\n¡ We abstracted how to provision local- and cloud-specific components such as \nPostgreSQL and Redis databases and message brokers such as Kafka and all the \nconfigurations needed to access these new instances. \n¡ We exposed a simplified interface for the application teams that is cloud-pro-\nvider independent because it relies on the Kubernetes API. \n¡ Finally, we connected our application service to the newly provisioned instances \nby relying on Kubernetes Secrets created by Crossplane, containing all the details \nrequired to connect to the newly created instances. \n",
      "page_number": 157
    },
    {
      "number": 16,
      "title": "Segment 16 (pages 171-178)",
      "start_page": 171,
      "end_page": 178,
      "detection_method": "topic_boundary",
      "content": "152\nChapter 5  Multi-cloud (app) infrastructure \nIf you use mechanisms like Crossplane compositions to create higher-level abstrac-\ntions, you will create domain-specific concepts that your teams can consume using a \nself-service approach. We have created our database and message broker concept by \ncreating a Crossplane Composite Resource that uses Crossplane compositions that \nknows which resources to provision (and in which cloud provider). \nNOTE    You can follow a step-by-step tutorial that covers all the steps described \nin this section at https://github.com/salaboy/platforms-on-k8s/tree/main/\nchapter-5. \n5.4\t\nLinking back to platform engineering\nWe need to be cautious. We cannot expect every developer to understand or be willing \nto use tools like the ones we have discussed (Crossplane, ArgoCD, Tekton, etc.). We \nneed a way to reduce the complexity these tools introduce. Platforms are meant to \nreduce the cognitive load of their users, as described in chapter 1 when we looked at \nGoogle Cloud Platform and how it enables teams to create a Kubernetes cluster with a \nfew clicks. For GCP and other platforms, the users interacting with the platform don’t \nneed to understand what is going on under the covers, what tools are being used, or \nthe design of the entire platform to use it. \nCrossplane was created to serve both platform teams and development teams (or \nconsumers), which have different priorities, interests, and skills. By creating the right \nabstractions (XRDs) the platform team can expose simple resources that development \nteams can configure according to their needs, while behind the covers, a complex \ncomposition is being set up to create and wire together a group of cloud resources. \nWe have also seen how by using labels and selectors, we can choose between different \ncompositions, enabling the creation of infrastructure in different cloud providers but \nkeeping the same user experience for the teams creating the requests. Crossplane, by \nextending the Kubernetes APIs, unifies how we manage our workloads and how we can \nmanage application infrastructure across cloud providers. In other words, if we install \nCrossplane into a Kubernetes cluster, we cannot only deploy and run our clusters but \nalso provision and manage cloud resources by using the same tooling that we use for \nour workloads. \nWith all the goodies that Crossplane brings, you must also be ready for some draw-\nbacks and challenges. Platform teams looking into Crossplane have other more popu-\nlar options available to provision cloud resources, such as Hashicorp’s Terraform and \nPulumi. Crossplane is much more recent than Terraform, and because Crossplane is \nfocused on Kubernetes, it requires platform teams to be fully invested in Kubernetes. \nTeams not used to managing Kubernetes clusters will find tools like Crossplane chal-\nlenging at first, so you need to level up your Kubernetes skills to run and maintain a tool \nlike Crossplane. \nPlatform teams will be forced to make a decision about using Crossplane or tools like \nTerraform, and my recommendation is to think about how much you want to align the \n\n\n\t\n153\nLinking back to platform engineering\ntools that you are using with the Kubernetes APIs. Being able to manage infrastructure \n(cloud resources) in the same way that we manage our applications makes a lot of sense \nin theory. Still, it also needs to make sense to the teams managing and maintaining \nthese components up and running. In the last couple of years, there has been a huge \nincrease in maturity around observability, security, and operations in the cloud-native \nspace. More and more teams are feeling comfortable with managing and operating \nKubernetes at scale. For those teams, Crossplane can be a great addition, because it is \ngoing to work with all their existing Kubernetes observability stacks, policy enforcers, \nand dashboards. \nWhen having tools as flexible as Crossplane, you open the door to new possibilities \nthat can span across cloud providers. Platform teams now have more options available, \nand that can be counterproductive, but one thing is clear. If you use the right abstrac-\ntions, the platform can be flexible, as consumer interfaces will not change. At the same \ntime, the platform team can iterate on their previous decisions and provide new imple-\nmentations behind the covers. \nFigure 5.17 shows how by using Crossplane, we can provide self-service abstractions \nfor development teams to consume. They can request databases, message brokers, \nidentity services, and any other internal or external services they might need for their \napplications. But what do they need from an application perspective? Think about the \nKafka example provided before. What needs to change in your applications if you move \nfrom Kafka to Google PubSub?\nWhat do I need in \nmy applications to \nconsume these \nservices?\nDevelopers\nPlatform \nEngineer\nImplementations\nApplications\nDatabases as a \nService\nMessage Brokers as a \nService\nIdentity as a Service\nX as a Service\nFigure 5.17    What do developers need to consume all these Platform services?\nWe have covered a lot of ground so far, from installing a simple application into a clus-\nter to building services and deploying them using a GitOps approach and now provi-\nsioning application infrastructure declaratively. Figure 5.18 shows how using a GitOps \napproach we can define not only which services/applications should be running inside \nan environment, but also which cloud resources need to be provisioned and wired to \nour application services.\n\n\n154\nChapter 5  Multi-cloud (app) infrastructure \nEnvironments \nConfiguration \nRepository\nEnvironment configurations \ncan include definitions to \nprovision cloud resources \nand how to wire them to our \napplication’s services.\nGitOps Sync\nProvisioning \nCloud Resources\nEnvironment\nApplication\nDatabases\nMessage Brokers\nMessage Broker\nDatabase\nCloud Provider\nFigure 5.18    Provisioning application infrastructure using a declarative GitOps approach\nIt is time to put everything together into a platform, because it doesn’t make too much \nsense to have our applications running in the same cluster where our pipelines and \nother tools are running. What would a platform on top of Kubernetes look like? What \nare the main challenges that your teams will face when trying to build one? There is \nonly one way to find out: Let’s build a platform on top of Kubernetes! \nSummary\n¡ Cloud-native applications depend on application infrastructure to run, as each \nservice might require different persistent storages, a message broker to send mes-\nsages, and other components to work.\n¡ Creating application infrastructure inside cloud providers is easy and can save us \na lot of time, but then we rely on their tools and ecosystem.\n¡ Provisioning infrastructure in a cloud-agnostic way can be achieved by relying \non the Kubernetes API and tools like Crossplane, which abstracts the underly-\ning cloud provider and lets us define which resources must be provisioned using \nCrossplane compositions.\n¡ Crossplane provides support for major cloud providers. It can be extended for \nother service providers, including third-party tools that might not be running \non cloud providers (for example, legacy systems we want to manage using the \nKubernetes APIs). \n¡ By using Crossplane Composite Resource Definitions, we create an interface \nthat application teams can use to request cloud resources using a self-service \napproach.\n¡ If you followed the step-by-step tutorial, you got hands-on experience on how \nto provision application infrastructure using a multi-cloud approach using \nCrossplane.\n\n\n155\n6\nLet’s build a platform \non top of Kubernetes\nThis chapter covers\n¡ Identifying features that platforms should  \n\t provide on Kubernetes\n¡ Learning the challenges with multi-cluster and \t\n\t multi-tenant setups\n¡ Seeing what a platform on top of Kubernetes \t\n\t looks like\nSo far, we have looked at what platform engineering is, why we need to think about \nplatforms in the context of Kubernetes, and how teams must choose the tools they \ncan use from the CNCF landscape (chapter 1). Then we jumped into figuring out \nhow our applications would run on top of Kubernetes (chapter 2), and how to build, \npackage, and deploy (chapters 3 and 4), and connect these applications to other \nservices that they need to work (chapter 5). This chapter puts all the pieces together \nto create a walking skeleton for our platform. We will use some of the open-source \nprojects introduced in the previous chapters and new tools to solve some of the \nchallenges we will face when creating the first iteration of our platform. This chap-\nter is divided into three main sections: \n\n\n156\nChapter 6  Let’s build a platform on top of Kubernetes \n¡ The importance of the platform APIs\n¡ Kubernetes platform architecture and how we can architect a scalable platform \ndespite multi-tenancy and multi-cluster challenges \n¡ Introducing our platform walking skeleton and learning how to build a platform \non top of Kubernetes\nLet’s start by considering why defining the platform APIs is the first step to platform \nbuilding. \n6.1\t\nThe importance of the platform APIs\nIn chapter 1, we looked at existing platforms, such as Google Cloud Platform, to under-\nstand what key features they offer to teams building and running cloud applications. \nWe now need to compare this to the platforms that we are building on top of Kuberne-\ntes, because these platforms share some common goals and features with cloud provid-\ners while at the same time being closer to our organizations’ domains. \nPlatforms are nothing other than software that we will design, create, and maintain. \nAs with any good software, our platform will evolve to help teams with new scenarios, \nmake our teams more efficient by providing automation, and give us the tools to make \nthe business more successful. As with any other software, we will start by looking at the \nplatform APIs, which will provide us with a manageable scope to start with and define \nthe contracts and behaviors our platform will provide its users. \nFigure 6.1 shows how the platform APIs are the main entry point for consumers of \nthe platform—in this case, developers. These APIs should hide away the complexity of \nthe tools, decisions, supported workflows, and golden paths that the platform provides \nto its users while at the same time offering a self-service place for teams to get what they \nneed.\nPlatform APIs\nOur Platform V1.2\nPlatform \nEngineer\nTools, Decisions, Supported \nWorkflows, Golden Paths\nDevelopers\nFigure 6.1    The platform engineering team is responsible for platform APIs.\n\n\n\t\n157\nThe importance of the platform APIs\nOur platform APIs are important, because good APIs can simplify the life of develop-\nment teams wanting to consume services from our platform. If our platform APIs are \nwell designed, more tailored tools like CLIs, SDKs, or even user interfaces can be cre-\nated to assist users in consuming our platform services. \nIf we build custom and more domain-specific APIs for our platform, we can start by \ntackling one problem at a time and then expand these APIs/interfaces to cover more \nand more workflows, even for different teams. Once we understand which workflows we \nwant to cover and have an initial platform API dashboard, more tooling can be created \nto help teams adopt the platform.  \nLet’s use an example to make it more concrete. I hope you can translate the example \nI am showing here into more concrete examples inside your organization. All the mech-\nanisms should apply in the same way. Let’s enable our development teams to request \nnew development environments. \n6.1.1\t\nRequesting development environments\nA common scenario where a platform can help teams get up to speed when they start \nworking on new features is provisioning them with all they need to do their work. To \nachieve this task, the platform engineering team must understand what they will work \non, what tools they need, and which other services must be available to succeed. \nOnce the platform engineering team understands what development teams require, \nthey can define an API to provision new development environments on demand. \nBehind these APIs, the platform has the mechanisms to create, configure, and provide \naccess for the requesting team to connect. \nFor our Conference application example, if a development team is extending the \napplication, we (the platform engineering team) must ensure they have a running ver-\nsion to work against and test changes. This isolated application instance will also need \nits databases and other infrastructural components to work. More advanced use cases \ninclude loading the application with mock data, allowing teams to test their changes \nwith pre-populated data, and having the right tools to verify the changes. The inter-\nactions between the application development team and the platform should look like \nfigure 6.2. \nApp Dev Team\nPlatform\nDevelopment \nEnvironment\nAPIs\n1\n2\n3\nFigure 6.2    Application development team interactions with the platform . #1 App dev teams can \nrequest as many Development Environments as they need to the platform APIs; #2 The platform has \nencoded how to provision all the components and tools needed for the app dev team to work; #3 The \nplatform needs to give access to the app dev team to use the newly provisioned environment.\n\n\n158\nChapter 6  Let’s build a platform on top of Kubernetes \nAs mentioned before, development environments are just an example. You must ask \nyourself what tools your teams need to do their work. A development environment \nmight not be the best way to expose tools to a team of data scientists, for example, \nbecause they might need other tools to gather and process data or train machine learn-\ning models. \nImplementing this simple flow in Kubernetes is not an easy task. To implement this \nscenario, we need to: \n¡ Create new APIs that understand development environment requests.\n¡ Have the mechanisms to encode what a development environment means for \nour teams.\n¡ Have the mechanisms to provision and configure components and tools.\n¡ Have the mechanisms to enable teams to connect to the newly provisioned \nenvironments.\nThere are several options for implementing this scenario, including creating custom \nKubernetes extensions or using more specialized tools for development environments. \nBut before diving into implementation details, let’s define what our platform API \nwould look like for this scenario.\nAs with object-oriented programming (OOP), our APIs are Interfaces that can \nbe implemented by different Classes, which finally provide concrete behavior. For \nprovisioning development environments, we can define a very simple interface called \nEnvironment. Development teams requesting a new development environment can \ncreate new requests to the platform by creating new environment resources. The Envi-\nronment interface represents a contract between the user and the platform. This con-\ntract can include parameters to define the type of environment the team is requesting \nor options and parameters they need to tune for their specific request. \nFigure 6.3 shows the simplest environment definition, which includes a name for \nthe environment and the kind of environment that we want to create (we might enable \nteams to request different setups, and for this example, we want a new development \nenvironment). The environment definition also includes custom configurations that \nmake sense for the consuming team to parameterize. In this case, because we will install \nthe Conference application, we want to enable teams to decide if the infrastructure \ncomponents need to be installed or not. \nEnvironment\nName: team-a-env\nParameters:\n • Type: development\n • InstallInfra: true\nPlatform APIs\nMechanisms to \nunderstand \nEnvironments\nFigure 6.3    Environment resource defined by the Platform API\n\n\n\t\n159\nThe importance of the platform APIs\nIt is important to note that the Environment interface shouldn’t include (or leak) \nany implementation details about our environments. These resources (environments \nin this case) serve as our abstraction layer to hide complexity from our platform users \nabout how these environments will be created. The simpler these resources are, the \nbetter for the platform users. In this example, the platform can use the Environment \nType parameter to decide which environment to create, and we can plug in new types \nas we evolve our platform mechanisms. \nOnce we recognize which interfaces we need, we can slowly add parameters that \nteams can configure. For our example, it might make sense to parameterize some fea-\ntures for the services we want to deploy in our environment if we also want the appli-\ncation infrastructure to be created or to connect our services to existing components. \nFigure 6.4 shows the definition of an environment that requires the platform to install \nthe application infrastructure that the services need. We also want to enable some \ndebug features on our Frontend service. The possibilities here are endless, depending \non what makes sense for your teams to parameterize. The platform team can control \nwhat is possible and what is not. Expanding the environment interface to cover more \nuse cases can look like f﻿iigure 6.4. \nEnvironment\nName: team-a-env\nParameters\n • Type: development\n • InstallInfra: true\n • Frontend: \n        Debug: enabled\nPlatform API\no\nFigure 6.4    Extended environment resource to enable/disable the application’s services.\nEncoding this environment resource into a format like JSON or YAML to implement \nthe platform API is straightforward, as shown in listing 6.1. \nListing 6.1    Environment definition in JSON format\n{\n  \"name\": \"my-dev-env\",\n  \"parameters\":{\n    \"type\": \"development\",\n    \"installInfra\": true,\n    \"frontend\": {\n      \"debug\": \"true\",\n    }\n  }\n}\nOnce the interface is defined, the next logical step is to provide one implementation \nto provision these environments for our platform users. Before jumping into imple-\nmentation details, we need to cover two of the main challenges you will face when \ndeciding where the mechanisms for implementing these environments will reside. \n",
      "page_number": 171
    },
    {
      "number": 17,
      "title": "Segment 17 (pages 179-192)",
      "start_page": 179,
      "end_page": 192,
      "detection_method": "topic_boundary",
      "content": "160\nChapter 6  Let’s build a platform on top of Kubernetes \nNOTE   When building these interfaces, we are designing user experiences. \nFrom a platform engineering perspective, consider these interfaces as layers \nwe are building to simplify how teams interact with our platform. But it is also \nimportant to recognize that we are not trying to build a black-box approach \nwhere this interface is the only way of interacting with our platform. If teams \nhave the technical experience to interact with the underlying layers and tools, \nthey should be able to do so.\n6.2\t\nPlatform architecture\nThis section discusses how we’ll architect our platform. On the technical side of build-\ning platforms, we will encounter challenges requiring the platform team to make some \nhard choices. In this section, we will talk about how we can architect a platform that \nallows us to encapsulate a set of tools behind our platform APIs and enable develop-\nment teams to perform their tasks without worrying about which tools are being used \nby the platform to provision and wire up complex resources. \nBecause we are already using Kubernetes to deploy our workloads in the Confer-\nence application, it also makes sense to run the platform services on top of Kubernetes, \nright? But would you run the platform services and components right beside your work-\nloads? Probably not. Let’s step back a bit.\nIf your organization adopts Kubernetes, you will likely already deal with multiple \nKubernetes clusters. As discussed in chapter 4, your organization probably has produc-\ntion, staging, or QA environments already in place. If you want your application devel-\nopment teams to work on environments that feel like the production environment, you \nmust enable them with Kubernetes clusters. \nFigure 6.5 shows a typical distribution of Kubernetes clusters inside an organization, \nwhere tons of small clusters might be created for short periods for development pur-\nposes. One or more mid-size clusters can be used for staging and testing purposes; these \nclusters tend to stay the same as they might be purposefully created to run performance \ntests or a large set of integration tests. Finally, one or more large clusters are created for \nrunning our production workloads. Depending on how many regions we want to cover, \nwe might need multiple production clusters that are geographically distributed. The \nconfiguration of these clusters is static and does not change. In contrast with develop-\nment and testing clusters, production clusters are the responsibility of Site Reliability \nEngineering teams, ensuring that these clusters and the applications running on them \nare up and running 24/7.\nDevelopment \nClusters\nStaging/QA Clusters\nProduction Clusters\nFigure 6.5    \nEnvironment \nclusters, in case \nyou want to enable \ndevelopers to \nhave their own \nenvironments.\n\n\n\t\n161\nPlatform architecture\nWhile the production cluster(s) and staging/QA cluster(s) should be handled care-\nfully and hardened to serve real-life traffic, development environments tend to be \nmore ephemeral and sometimes even run on the development team laptops. Certainly, \nyou don’t want to run any platform-related tools in any of these environments. The \nreason is simple: tools like Crossplane, ArgoCD, or Tekton shouldn’t be competing for \nresources with our application’s workloads. Security considerations might apply too; \nwe don’t want our application’s security compromised due to a vulnerability in our \nplatform tools.\nWhen looking at building platforms on top of Kubernetes, teams tend to create one \nor more special clusters to run platform-specific tools. The terms still need to be stan-\ndardized, but creating a platform or management cluster to install platform-wide tools \nis becoming increasingly popular. \nFigure 6.6 shows how by having separate platform cluster(s), you can install the tools \nthat you need to implement your platform capabilities while at the same time building a \nset of management tools to control environments where your workloads run.\nPlatform\nEnvironment\nEnvironment\nApp \nDev\n<manage>\n<manage>\nFigure 6.6    Platform cluster with platform tools managing environments\nNow that you have a separate place to install these tools, you can also host the platform \nAPI on this cluster, once again, to not overload your workload clusters with platform \ncomponents. Wouldn’t it be great to reuse or extend the Kubernetes API to serve also \nas our platform API? There are pros and cons to this approach. For example, sup-\npose we want our platform API to follow Kubernetes conventions and behaviors. In \nthat case, our platform will use the declarative nature of Kubernetes and promote all \nthe best practices followed by the Kubernetes APIs, such as versioning, the resource \nmodel, etc. This API might be too complex for non-Kubernetes users, or the organi-\nzation might follow other standards when creating new APIs that do not match the \nKubernetes style. If we reuse the Kubernetes APIs for our platform APIs, all the CNCF tools \ndesigned to work with these APIs will automatically work with our platform. Our platform auto-\nmatically becomes part of the ecosystem. In the last couple of years, I’ve seen a trend \naround teams adopting the Kubernetes APIs as their platform APIs. How much you \n\n\n162\nChapter 6  Let’s build a platform on top of Kubernetes \nlean on the Kubernetes APIs is a decision that platform engineering teams will need to \nmake, and there are always tradeoffs.\nFigure 6.7 shows the relationship between having the Kubernetes APIs to use the CNCF \nand cloud-native ecosystem while at the same time exposing an organization-specific API \nthat follows company standards on how APIs should be created. To make sure that the \nmessage is clear, these are not exclusive, and as we will see in section 6.3, it makes a lot \nof sense to have both.\nPlatform\nCompany-specific \ntooling and \nconformance\nCompany Standards \nPlatform API\nKubernetes-based \nPlatform API\nPlatform Internals\nCNCF / \nCloud Native \nEcosystem\nFigure 6.7    \nKubernetes-based \nplatform APIs \ncomplemented by \ncompany-specific \nAPIs\nAdopting the Kubernetes APIs for your platform API doesn’t stop you from building a \nlayer on top for other tools to consume or to follow the company’s standards. By hav-\ning a Kubernetes-based API layer, you can access all the amazing tools created in the \nCNCF and cloud-native space. On top of the Kubernetes-based APIs, another layer can \nfollow company standards and conformance checks, enabling easier integrations with \nother existing systems. \nFollowing our previous example, we can extend Kubernetes to understand our envi-\nronment requests and provide the mechanisms to define how these environments will \nbe provisioned. \nFigure 6.8 shows a Kubernetes resource used to define our environments. This \nresource can be sent to a Kubernetes API server with an installed set of extensions to \nunderstand what to do when a new environment definition arrives. \nKubernetes \nextension to \nunderstand \nEnvironments\nPlatform\nEnvironment\nName: team-a-env\nFigure 6.8    \nExtending \nKubernetes \nto understand \nenvironments \nand serve as our \nplatform APIs\n\n\n\t\n163\nPlatform architecture\nIn principle, this looks good and doable. Still, before implementing these Kubernetes \nextensions to serve as our platform API and central hub of platform tooling, we need \nto understand the questions that our platform implementation will try to answer. Let’s \nlook at the main platform challenges that teams in these scenarios will face. \n6.2.1\t\nPlatform challenges\nSooner or later, if you are dealing with multiple Kubernetes clusters, you must manage \nthem and all the resources related to these clusters. What does it take to manage all \nthese resources? The first step to understanding the underlying problems is to under-\nstand who the users of our platforms are. Are we building a platform for external cus-\ntomers or internal teams? What are their needs and the level of isolation that they need \nto operate autonomously without bothering their neighbors? What guardrails do they \nneed to be successful? \nWhile I cannot answer these questions for all use cases, one thing is clear—plat-\nform tools and workloads need to be separated. We need to encode in our platform \nour tenant boundaries based on each tenant’s expectations. No matter if these ten-\nants are customers or internal teams. We must set clear expectations about our tenancy \nmodel and guarantees for our platform users, so they understand the limitations of the \nresources the platform gives them to do their work. \nThe platform we will build needs to encode all these decisions. In the following two \nsections, we will look at the two most common decisions that platform teams will need \nto make early in their journey: (1) managing more than one cluster and (2) isolation \nand multi-tenancy. \n6.2.2\t\nManaging more than one cluster\nThe platform we will build needs to manage and understand which environments are \navailable for teams. More importantly, it should enable the team to request their own \nenvironments whenever needed. \nUsing the Kubernetes APIs as our platform API to request environments, we can use \ntools like ArgoCD (covered in chapter 4) to persist and sync our environment configu-\nrations to live Kubernetes clusters. Managing our clusters and environments becomes \njust managing Kubernetes resources that must be synced to our platform cluster(s). \nFigure 6.9 shows using two tools that we have already used (Crossplane and ArgoCD) \nfor our Conference application but use now in the context of managing platform-wide \nresources. \nBy combining tools like ArgoCD and Crossplane inside our platform clusters, we \npromote the techniques we discussed in chapter 4 for environment pipelines, which \nsync application-level components which we now use for managing high-level platform \nconcerns. In this case, tools like Crossplane can help us provision full-fledged environ-\nments on cloud providers. \n\n\n164\nChapter 6  Let’s build a platform on top of Kubernetes \nPlatform\nGit\nTeam C \nEnvironment\nTeam B \nEnvironment\nTeam A \nEnvironment\nFigure 6.9    \nCombining GitOps \nand Crossplane \nfor managing \nenvironments and \nclusters\nAs you can see in the previous figure, our platform configuration itself will become \nmore complex, because it will need to have its source of truth (Git repository) to store \nthe environment and resources that the platform manages. It will also need to have \naccess to a secret store, such as HashiCorp Vault, to enable Crossplane to connect and \ncreate resources in different cloud providers. In other words, you now have two extra \nconcerns. First, you will need to define, configure, and give access to one or more Git \nrepositories to contain the configurations for the resources created in the platform. \nSecond, you must manage a set of cloud provider accounts and their credentials so the \nplatform cluster(s) can access and use these accounts. \nIf you can manage all the platform resources like your workloads (using a GitOps \napproach, managing credentials and users, and exposing the right abstractions/APIs), \nthe platform artifacts become just an extension of your development and continuous \ndelivery practices. \nWhile the example in section 6.3 doesn’t focus on configuring all these concerns, it \nprovides a nice playground to build on top and experiment with more advanced setups \ndepending on your teams’ requirements. \nI recommend prioritizing which configurations make sense to understand what your \nteams or tenants will do with the resources, expectations, and requirements. Let’s dig a \nbit more into that space. \n6.2.3\t\nIsolation and multi-tenancy\nDepending on your tenants’ (teams, internal or external customers) requirements, \nyou might need to create different isolation levels, so they don’t disturb each other \nwhen working under the same platform roof. \nMulti-tenancy is a complicated topic in the Kubernetes ecosystem. Using Kubernetes \nRBAC (role-based access control), Kubernetes Namespaces, and multiple Kubernetes \ncontrollers that might have been designed with different tenancy models makes it hard \nto define isolation levels between tenants inside the same cluster.\n\n\n\t\n165\nPlatform architecture\nCompanies embarking on adopting Kubernetes tend to take one of the following \napproaches for isolation: \n¡ Kubernetes Namespaces:\n–\t Pros: \n¡ Creating namespaces is very easy, and it has almost zero overhead.\n¡ Creating namespaces is cheap, because it is just a logical boundary that \nKubernetes uses to separate resources inside the cluster.\n–\t Cons: \n¡ Isolation between namespaces is very basic, and it will require RBAC roles \nto limit users’ visibility outside the namespaces they have been assigned. \nResource quotas must also be defined to ensure that a single namespace is \nnot consuming all the cluster resources.\n¡ Providing access to a single namespace requires sharing access to the same \nKubernetes APIs endpoints that admins and all the other tenants are using. \nThis limits the operations clients can execute on the cluster, such as install-\ning cluster-wide resources.\n¡ All the tenants will be interacting against the same Kubernetes API server, \nwhich might cause problems depending on the scale and the needs of each \nof the tenants. \n¡ Sharing the same Kubernetes API server limits the cluster-wide resources \nthat can be installed in the cluster. For example, installing two different \nversions of the same extensions is not possible. \n¡ Kubernetes clusters: \n–\t Pros: \n¡ Users interacting with different clusters can have full admin capabilities \nenabling them to install as many tools as they need. \n¡ You have full isolation between clusters, and tenants connecting to differ-\nent clusters will not share the same Kubernetes API server endpoints. Each \ncluster can have different configurations for how scalable and resilient they \nare. This allows you to define different tenants’ categories based on their \nrequirements. \n–\t Cons: \n¡ This approach is expensive, as you will be paying for computing resources \nto run Kubernetes. The more clusters you create, the more money you will \nspend running Kubernetes.\n¡ Managing multiple Kubernetes clusters becomes complex if you enable \nteams to create (or request) their own. Zombie clusters (clusters nobody \nuses and are abandoned) start to pop up, wasting valuable resources. \n¡ Sharing resources, installing, and maintaining tools across a fleet of differ-\nent Kubernetes clusters is challenging and a full-time job.\n\n\n166\nChapter 6  Let’s build a platform on top of Kubernetes \nBased on my experience, teams will create isolated Kubernetes clusters for sensitive \nenvironments such as production environments and performance testing. These sen-\nsitive environments tend to stay the same and are only managed by operation and site \nreliability teams. Using a big cluster with namespaces is a common practice when you \nshift towards development teams and more ephemeral environments for testing or \nday-to-day development tasks.\nChoosing between these two options is hard, but what is important is not to overcom-\nmit to just a single option. Different teams might have different requirements, so in the \nnext section, we will look at how the platform can abstract these decisions, enabling \nteams to access different setups depending on their needs.  \nMy recommendation for platform teams making these decisions is to build and have \npractices in place that enable you to pivot from one solution to another. Starting with \nsimple solutions such as namespace isolation is quite common, but after a while, when \nhaving a single cluster with tons of namespaces is not enough, you need a more robust \nplan. To make this decision easier, ask yourself if your consumers need access to the \nKubernetes APIs. If they don’t, you might want to evaluate following an approach sim-\nilar to Google Cloud Run (https://cloud.google.com/run), Azure Container Apps \n(https://azure.microsoft.com/en-us/products/container-apps ), or AWS App Runner \n(https://aws.amazon.com/apprunner/), which enables teams to run containers with-\nout the need of accessing the orchestrator APIs.\n6.3\t\nOur platform walking skeleton\nThis section looks into creating a simple platform allowing internal teams to create \ndevelopment environments. Because our teams are deploying the conference appli-\ncation to Kubernetes clusters, we want to offer them the same developer experience.\nNOTE    You can follow a step-by-step tutorial, where you will install and inter-\nact with the platform walking skeleton at https://github.com/salaboy/\nplatforms-on-k8s/tree/main/chapter-6. \nTo achieve this, we will use some tools that we used before, like Crossplane, to extend \nKubernetes to understand development environments. Then, we will use a project \ncalled vcluster (https://vcluster.com) to provision small Kubernetes clusters for our \nteams. These clusters are isolated, allowing teams to install extra tools without worrying \nabout what other teams are doing. Because teams will have access to the Kubernetes \nAPIs, they can do whatever they need with the cluster without requesting complicated \npermissions to debug their workloads. \nFigure 6.10 shows how the process works. Teams can request new environments by \ncreating environment Kubernetes resources. The platform will take these resources \nand provision small Kubernetes clusters with vcluster for them to use. We will keep \nthings simple for the walking skeleton, but the platforms are complicated.\n\n\n\t\n167\nOur platform walking skeleton\nPlatform\nDevelopment \nEnvironments\nEnvironment\nName: team-a-env\nFigure 6.10    \nBuilding a \nplatform \nprototype \nto provision \ndevelopment \nenvironments\nI can’t stress enough the importance that this example, on purpose, is using existing \ntools instead of creating our custom Kubernetes extensions. If you create custom con-\ntrollers to manage environments, you create a complex component that will require \nmaintenance and probably overlaps 95% with the mechanisms shown in this example. \nIn other words, no custom Kubernetes controllers have been created while building \nthis example. \nIn the same way that we started this chapter talking about our platform APIs, let’s \nlook at how we can build these APIs without creating custom Kubernetes extensions \nthat we will need to test, maintain, and release. We will use Crossplane compositions as \nwe did for our databases and message brokers in chapter 5, but now we will implement \nour environment custom Crossplane Composition Resource Definition. We can keep \nthe environment resource simple and use Kubernetes label matches and selectors to \nmatch a resource with one of the possible compositions we can create to provision our \nenvironments. \nFigure 6.11 shows how changing a property/label from our environment helps \nCrossplane to pick the right composition for our team. \nPlatform API\nEnv Composition\ntype: development\nEnv Composition\ntype: testing\nEnvironment\nName: team-a-env\nLabels:\n • type: development\nFigure 6.11    Mapping environment resources to Crossplane compositions\nCrossplane compositions offer the flexibility to use different providers to provision \nand configure resources together, and as we saw in chapter 5, multiple compositions \n(implementations) can be provided for different kinds of environments. For this \nexample, we want each environment to be isolated from the other to avoid teams unin-\ntentionally deleting others’ team resources. The two most intuitive ways of creating \nisolated environments would be to create a new namespace per environment or a full-\nblown Kubernetes cluster for each environment. \n\n\n168\nChapter 6  Let’s build a platform on top of Kubernetes \nFigure 6.12 shows how another Crossplane provider (called Kubernetes provider) \ncan be used to create Kubernetes resources such as Namespaces. This compares against \nusing a cloud-provider Crossplane provider that enables us to create a full-blown clus-\nter, in this case in Google Cloud Platform (GCP). Once we have a cluster, we can install \nour Conference application Helm Chart.\nEnv Composition\ntype: development\nEnv Composition\ntype: testing\nCrossplane \nKubernetes Provider\nConference \n`Helm Chart`\nConference \n`Helm Chart`\nCrossplane GCP \nProvider\nCrossplane Helm \nProvider\nCrossplane Helm \nProvider\nKubernetes `Namespace`\n`GKECluster`\nFigure 6.12    Different environment compositions, Namespace, and GKECluster\nWhile creating a fully-fledged Kubernetes cluster might be overkill for every develop-\nment team, a Kubernetes Namespace might not provide enough isolation for your use \ncase, because all teams will interact with the same Kubernetes API server. For this rea-\nson, we will use vcluster in conjunction with the Crossplane Helm provider, which \ngives us the best of both worlds without the costs of creating new clusters. Figure 6.13 \nshows how we can reuse the Crossplane Helm provider to create vclusters. \nEnv Composition\ntype: development\nCrossplane Helm \nProvider\nCrossplane Helm \nProvider\nvcluster\n`Helm Chart`\nConference \n`Helm Chart`\nFigure 6.13    Using vcluster to create isolated environments\nYou might be wondering: what is a vcluster? And why are we using the Crossplane \nHelm provider to create one? While vcluster is just another option that you can use \nto build your platforms, I consider it a key tool in every platform engineer toolbox. \n\n\n\t\n169\nOur platform walking skeleton\n6.3.1\t\nvcluster for virtual Kubernetes clusters\nI am a big fan of the vcluster project. If you are discussing multi-tenancy on top of \nKubernetes, vcluster tends to pop up in the conversation, because it offers a really \nnice alternative to the Kubernetes Namespaces vs. Kubernetes clusters discussions. \nvcluster focuses on providing Kubernetes API server isolation between differ-\nent tenants by creating virtual clusters inside your existing Kubernetes cluster (host \ncluster). Figure 6.14 shows how vcluster works inside an existing Kubernetes cluster \n(HOST).\nK8s API Server\nK8s API Server\nK8s API Server\nK8s Scheduler\nK8s API Server\nKubernetes Cluster (HOST)\nvcluster A\nvcluster B\nvcluster C\nFigure 6.14    vcluster provides isolation at the Kubernetes (K8s) API server\nBy creating new virtual clusters, we can share an isolated API server with tenants where \nthey can do whatever they need without worrying about what other tenants are doing \nor installing. For scenarios where you want each tenant to have cluster-wide access and \nfull control of the Kubernetes API server, vcluster provides a simple alternative to \nimplement this. If you don’t need to provide your teams with access to the Kubernetes \nAPIs, I recommend using the namespace approach mentioned before.\nCreating a vcluster is easy: you can create a new vcluster by installing the \nvcluster Helm Chart. Alternatively, you can use the vcluster CLI to create one and \nconnect to it. \nFinally, a great table comparing vcluster, Kubernetes Namespaces and Kubernetes \nclusters can be found in their documentation. If you are already having these conver-\nsations with your teams, this table explains the advantages and tradeoffs in crystal clear \nlanguage (figure 6.15). \nFigure 6.15    \nPros and cons \nof Kubernetes \nNamespaces \nvs. vcluster vs. \nKubernetes cluster \ntenants\n\n\n170\nChapter 6  Let’s build a platform on top of Kubernetes \nI strongly recommend checking their website (https://vcluster.com) and the blog post \navailable at https://www.salaboy.com/2023/06/19/cost-effective-multi-tenancy-on \n-kubernetes/ to learn more about this project and how it can help your teams provi-\nsion cost-effective clusters.\nNext, let’s see what our platform walking skeleton looks like for teams that want to \ncreate, connect, and work against new environments that use vcluster. \n6.3.2\t\nThe platform experience\nThe platform walking skeleton implemented in the GitHub repository at https://\ngithub.com/salaboy/platforms-on-k8s/tree/main/chapter-6 allows teams connected \nto the platform API to create new environment resources and submit a request for the \nplatform to provision it for them.\nFigure 6.16 shows the architecture for our platform walking skeleton. First, applica-\ntion development teams can create requests to the platform APIs for new development \nenvironments. The platform will provision a new environment—in this case, following a \nCrossplane composition that uses the Crossplane Helm provider to create a new virtual \ncluster (using vcluster)—and then install the Conference application Helm Chart \nfor development teams to do their work. Second, application development teams can \nconnect to this new isolated environment without fearing breaking other teams’ setups.\nEnv Composition\ntype: development\nEnvironment\nName: team-a-env\nParameters:\n • type: development\nCrossplane Helm \nProvider\nCrossplane Helm \nProvider\nvcluster\n`Helm Chart`\nApp Dev\n1\n2\nConference \n`Helm Chart`\nPlatform\nEnvironment\nFigure 6.16    Using Crossplane and vcluster to create isolated environments for application development teams\nNOTE    It makes a lot of sense to have a large cluster to host all the ephemeral \ndevelopment environment clusters. The tools we used for building the platform \nwalking skeleton can be easily configured to implement that setup, but it is quite \nhard to demonstrate running on a single and local KinD cluster.\nThe platform cluster uses Crossplane and Crossplane compositions to define how to \nprovision the environment. To run the Crossplane composition in a local Kuberne-\ntes cluster (and not require access to a specific cloud provider), the walking skeleton \n\n\n\t\n171\nOur platform walking skeleton\nuses vcluster to provision each environment on its own (virtual) Kubernetes cluster. \nHaving separate Kubernetes clusters enables teams to connect to these environments \nand do the work they need to do with our Conference application, which is by default \ninstalled when the environment is created. \nApplication teams need to be connected to the platform API (Kubernetes clusters \nhosting the platform tools—in this case, Crossplane and the vcluster configurations) \nto request new environments using tools like kubectl. For the walking skeleton, send-\ning an environment resource to the platform APIs will result in the platform provi-\nsioning a new vcluster that the team can connect to. See listing 6.2, which shows an \nenvironment resource def﻿iinition that we can send to the Kubernetes API server.\nListing 6.2    Environment definition as a Kubernetes resource\napiVersion: salaboy.com/v1alpha1\nkind: Environment\nmetadata:\n  name: team-a-dev-env\nspec:\n  compositionSelector:\n    matchLabels:\n      type: development\n    parameters: \n      installInfra: true\nBecause these are Kubernetes resources, teams can query these resources using \nkubectl, as shown in listing 6.3.\nListing 6.3    Listing environment resources\n> kubect get environments\nNAME           CONNECT-TO           TYPE        INFRA READY\nteam-a-dev-env team-a-dev-env-jp7j4 development true  True  \nOnce the environment is ready, teams will be able to connect to it. Because we are \nusing vcluster, connecting to it is just like connecting to any other Kubernetes clus-\nter. Luckily, vcluster makes our life easier, and we can use their CLI to configure the \naccess tokens for us. \nRunning the following command will connect you to the vcluster instance that \nhas been just created and host the Conference application installed by the Crossplane \ncomposition:\nvcluster connect team-a-dev-env-jp7j4 --server https://localhost:8443 -- zsh\nThe name for the environment \nthat we want to create\nThe type of \nenvironment \nwe want is \ndefined using \nlabels\nParameters are custom to your specific use case. Depending \non what you want to enable teams to configure, you can \niteratively define more and more parameters for them to \nfine-tune when requesting environments.\n\n\n172\nChapter 6  Let’s build a platform on top of Kubernetes \nNOTE    When running vcluster connect, you are now connected to a new \ncluster context, meaning that if you list all the pods and Namespaces, you will \nonly see the resources that are available in this new cluster. You shouldn’t see any \nCrossplane resources, for example. \nA natural extension to the walking skeleton would be to use Crossplane compositions \nto create environments spawning Kubernetes clusters on a cloud provider. Managing \nthese environment resources inside a Git repository using ArgoCD is also a natural step \nforward. In such cases and in contrast to requiring application development teams to \nconnect directly with the platform APIs, teams can request new environments by send-\ning a pull request to a repository that can be validated and automatically merged.\nThe step-by-step tutorial (https://github.com/salaboy/platforms-on-k8s/tree/\nmain/chapter-6) finishes by deploying a custom Platform Admin User Interface applica-\ntion. This Platform Admin application enables teams to consume the platform features \nwithout connecting to the Kubernetes platform APIs, commonly called “Click Ops,” \nbecause we are trying to avoid teams writing complex YAML files or long commands \nlike cloud providers do. This application exposes REST endpoints and the functionality \nprovided by the user interface to reduce the cognitive load from application teams who \nneed to know how the platform is operating behind the covers. Figure 6.17 shows the \nPlatform Portal admin interface (this is not part of the Conference application).\nFigure 6.17    Platform Admin user interface allows teams to create and manage environments without \nconnecting to the platform’s Kubernetes APIs.\nThis Platform Admin application also exposes REST endpoints to perform all the \nactions by sending REST requests, which can be used for further automation and inte-\ngrations with existing systems. \nTo recap, the walking skeleton offers the platform users different ways of interac-\ntion. First, it extends the Kubernetes APIs to enable platform workflows such as creating \n\n\n\t\n173\nLinking back to platform engineering\ndevelopment environments using Crossplane. Then it provides a user interface and \nsimplified REST endpoints for teams that don’t want or can’t use the extended Kuber-\nnetes APIs. These simplified REST APIs, SDKs, and CLIs can be created for teams to \nmanage their environments. \nThere is value in having both options always available. It’s good to use the power of \nthe Kubernetes APIs and the cloud-native ecosystem, when possible, but it’s also import-\nant to have a simplified option for reducing the cognitive load and following company \nAPI standards when needed.\nBefore closing this chapter, let’s bring back all the topics and projects we have seen \ntogether. How are all these tools and configurations related to platform engineering? \nWho is responsible for which component? And what comes next? \n6.4\t\nLinking back to platform engineering\nSo far, we have explored open-source projects that tackle different challenges we face \nwhen building distributed applications. Most of these tools are not focused on appli-\ncation developers, requiring skills and knowledge that are usually not needed to build \nbusiness applications and features. The common denominator across all tools has \nbeen Kubernetes, and in most cases, projects have extended Kubernetes to perform \ntasks besides running our workloads. In this short section, I want to recap how all these \nprojects fit together to delineate responsibilities, contracts, and expectations. \nIf we look at all these examples from a distance, there are two kinds of teams: plat-\nform and application development teams. These two teams have different responsibili-\nties and require different tools to do their job. From what we have seen so far: \n¡ Platform teams are responsible for the following: \n–\t Understanding the needs of different teams related to IT services, cloud \nresources, and tools.\n–\t Facilitating access to credentials and to different resources.\n–\t Creating automation for other teams to get what they need.\n¡ Application development teams are responsible for the following: \n–\t Defining the customer-facing architecture and tech stack.\n–\t Creating customer-facing features.\n–\t Releasing new versions to continuously improve how the business operates.\nThese responsibilities materialize in software artifacts that can be managed similarly. \nFigure 6.18 shows the artifacts we have used for the platform walking skeleton. The \ntools not included in the step-by-step tutorial are drawn with dashed lines.\n",
      "page_number": 179
    },
    {
      "number": 18,
      "title": "Segment 18 (pages 193-201)",
      "start_page": 193,
      "end_page": 201,
      "detection_method": "topic_boundary",
      "content": "174\nChapter 6  Let’s build a platform on top of Kubernetes \nTekton Service Pipelines\nPlatform (Walking Skeleton)\nPlatform Admin User \nInterface\nTekton Management\nArgo CD Management\nArgo CD Application \nConfiguration\n`vcluster` \nconfigurations\nContainer Registry\nCrossplane Management\nCrossplane Composite \nResource Definitions \n(XRD)\nEnvironments \nGit Repositories\nAccess Configurations \nand Credentials\nCrossplane \nCompositions\nPlatform Admin REST \nendpoints\nExtended Kubernetes APIs\nFigure 6.18    Platform walking skeleton tools, configurations, and services\nAs you can see, even for a very simple platform, the platform team is managing and \nadministrating different tools that need to be highly available for our application \ndevelopment teams to consume. I haven’t focused on managing credentials or secrets, \nbut this is something that the platform team will face early on in their journey. Using \ntools like the external-secrets project (https://github.com/external-secrets/external \n-secrets) and/or tools like Vault by HashiCorp (https://www.vaultproject.io/) would \nmake managing and storing credentials much easier and more centralized. This level \nof complexity has historically led to two implementation scenarios:\n1\t Purchase a solution that provides fantastic application developer experience \nbut limited platform engineering customization or operability (e.g., Heroku, \nCloudFoundry)\n2\t Build a solution from a set of primitives, including scripting languages (BASH, \nPython, etc.), declarative infrastructure languages (Crossplane, Terraform, Chef, \nAnsible), and workflow engines (ArgoCD Workflows, CircleCI, GitHub Actions).\nRecently there has been an explosion of new tools that enable the first scenario (e.g., \nVercel, Fly.io). However, for many organizations, these solutions have needed help \n\n\n\t\n175\nLinking back to platform engineering\nmanaging their business process and compliance requirements fully. To address this \nchallenge, there is more focus on lowering the cost of building bespoke internal offer-\nings. For example, a project called Kratix (https://kratix.io/), which is a framework \nthat optimizes the definition and implementation of experiences as a service to other \ninternal teams.\nKratix is centered around the platform-building experience instead of the appli-\ncation user experience. A framework like Kratix can enable an internal marketplace \nwhere specialists can offer capabilities as a service while maintaining consistency across \nofferings, similar to what we explored with Crossplane compositions. \nWhether you use an external tool or build your own, the platform engineering team \nmust build a knowledge base about the projects they are using to build the platform and \nhave a release process to manage changes when the tools are online for other teams to \nuse. \nSimilar to this book’s examples repository at https://github.com/salaboy/platforms \n-on-k8s/, the platform engineering team will need to manage all the configuration files \nto install and recreate all the tools and resources the platform needs to work. \nNOTE    Ideally, as with Kubernetes, if the control plane (tools we installed) is \ndown, our teams should be able to keep working. We (as platform engineer-\ning teams) need to build resilient platforms and ensure that if something goes \nwrong, we don’t block teams and the important work they are doing. While the \nplatform we build should speed up software delivery, it shouldn’t be on the crit-\nical path for the teams’ success. In other words, there should always be a way \naround the platform, meaning that if teams want to directly access some of the \ntools that the platform is using, they should be able to do so. \nThe walking skeleton we built in this chapter offers different layers for different users \nto work and integrate with. If your team understands the platform’s tools, they can \naccess the Kubernetes APIs of the platform cluster for full flexibility and control. If \nthey choose, they can also use the provided user interface and REST endpoints to inte-\ngrate with other systems. Figure 6.19 shows our platform walking skeleton, how it pro-\nvides teams with predefined workflows exposed by the platform APIs, and the tools and \nbehaviors implemented under the hood by the platform team. \nI strongly recommend platform teams document their journey with each of the tools \nthat they are planning to use as part of their platform initiatives, because bringing team \nmembers up to speed on these decisions is usually the most challenging aspect of main-\ntaining a platform like the one described here. \n\n\n176\nChapter 6  Let’s build a platform on top of Kubernetes \nTeams interact with the \nPlatform APIs, without \nthe need to know which \ntools are used or how \ntools are configured.\nThe Platform Team owns the definition \nof the Platform APIs and the decisions \non which tools are used to implement \nthe platform provided workflows.\nOur Platform\nPlatform APIs\nEnvironments \nConfiguration \nRepository\nGitOps Sync\nProvisioning \nCloud Resources\nService Pipelines\nManages\nManages\nContainer \nRegistry\nApplication\nInfrastructure\nApplication\nInfrastructure\nEnvironment\nEnvironment\nCloud Resources\nCloud Resources\nCloud Provider\nCloud Provider\nFigure 6.19    Platform responsibilities and boundaries\nIn the next couple of chapters, we will explore some core capabilities the platform \nshould provide when creating environments for teams. Which functionalities can be \nprovided to the application development teams so they can be more efficient when \ndelivering software? Chapter 7 covers release strategies and why they are important \nto enable teams to experiment and release more software. Chapter 8 covers shared \nconcerns that you will need to provide to all services of your applications and different \napproaches to facilitate these mechanisms to your developers.\nSummary\n¡ Building platforms on top of Kubernetes is a complex task that involves combin-\ning different tools to serve teams with different requirements.\n¡ Platforms are software projects as your business applications. Starting by under-\nstanding who the main users will be and defining clear APIs is the key to prioritiz-\ning tasks on how to build your platform. \n¡ Managing multiple Kubernetes clusters and dealing with tenant isolations are \ntwo main challenges that platform teams face early on in their platform-building \njourney.\n\n\n\t\n177\nSummary\n¡ Having a platform walking skeleton can help you to demonstrate to internal \nteams what can be built to speed up their cloud-native journey.\n¡ Using tools like Crossplane, ArgoCD, vcluster, and others can help you pro-\nmote cloud-native best practices at the platform level but, most importantly, \navoid the urge to create your custom tools and ways to provision and maintain \ncomplex configurations of cloud-native resources.\n¡ If you followed the step-by-step tutorial, you got hands-on experience using \ntools like Crossplane and vcluster to provision on-demand development envi-\nronments. You also interacted with a simplified API that reduces the cognitive \nload for teams that don’t want or can’t interact with a full-blown Kubernetes API \nserver.\n\n\n178\n7\nPlatform capabilities I: \nShared application concerns\nThis chapter covers\n¡ Learning requirements of 95% of cloud-native \t\n\t applications\n¡ Reducing friction between application and \t\n\t infrastructure\n¡ Addressing shared concerns with standard APIs \t\n\t and components\nIn chapter 5 we created abstractions such as databases and message brokers to pro-\nvision and configure all the components required by our application’s services. In \nchapter 6, we extended these mechanisms to build our platform walking skeleton.\nThis platform enables teams to request new development environments that not \nonly create isolated environments but also install an instance of the Conference \napplication (and all the components required by the application) so teams can do \ntheir work. By going through the process of building a platform, we defined the \nresponsibilities of a platform team and where each tool belongs and why. We ended \nchapter 6 with clear guidelines for where tools like Crossplane, Argo CD, and Tek-\nton would run to manage and enable different environments with capabilities that \nteams will need to deliver more software in front of customers. \n\n\n\t\n179\nWhat are most applications doing 95% of the time?\nSo far, we have given developers Kubernetes clusters with an instance of their appli-\ncation running. This chapter looks at mechanisms to provide developers with capabili-\nties closer to their application needs. Most of these capabilities will be accessed by APIs \nthat abstract away the application’s infrastructure needs, allowing the platform team \nto evolve (update, reconfigure, change) infrastructural components without updating \nany application code. At the same time, developers will interact with these platform \ncapabilities without knowing how they are implemented and without bloating their \napplications with a load of dependencies. This chapter is divided into three sections: \n¡ What are most applications doing 95% of the time? \n¡ Standard APIs and abstractions to separate application code from infrastructure.\n¡ Updating our Conference application with Dapr (Distributed Application Run-\ntime), a CNCF and open-source project created to provide solutions to distrib-\nuted application challenges. \nLet’s start by analyzing what most applications are doing. Don’t worry; we will also \ncover edge cases. \n7.1\t\nWhat are most applications doing 95% of the time?\nWe have worked with our walking skeleton Conference applications for seven chapters. \nWe have learned how to run it on top of Kubernetes and how to connect the services to \ndatabases, key-value stores, and message brokers. There was a good reason to go over \nthose steps and include those behaviors in the walking skeleton. Most applications, like \nthe Conference application, will need the following functionality: \n¡ Call other services to send or receive information: Application services don’t exist on \ntheir own. They need to call and be called by other services. Services can be \nlocal or remote, and you can use different protocols, most commonly HTTP and \nGRPC. We use HTTP calls between services for the conference application walk-\ning skeleton.\n¡ Store and read data from persistent storage: This can be a database, a key-value store, a \nblob store like S3 buckets, or even writing and reading from files. For the confer-\nence application, we are using Redis and PostgreSQL. \n¡ Emit and consume events or messages asynchronously: Using asynchronous messaging \nfor communicating systems implementing an event-driven architecture is a com-\nmon practice in distributed systems. Using tools like Kafka, RabbitMQ, or even \ncloud-provider messaging systems is common. Each service in the Conference \napplication is emitting or consuming events using Kafka. \n¡ Accessing credentials to connect to services: When connecting to an application’s \ninfrastructure components, whether local or remote, most services will need cre-\ndentials to authenticate to other systems. In this book I’ve only mentioned tools \nlike external-secrets (https://github.com/external-secrets/external-secrets) or \nHashiCorp’s Vault (https://www.vaultproject.io/), but we haven’t dug deeper \ninto it. \n\n\n180\nChapter 7  Platform capabilities I: Shared application concerns \nWhether we are building business applications or machine learning tools, most appli-\ncations will benefit from having these capabilities easily available to consume. And \nwhile complex applications require much more than that, there is always a way to sepa-\nrate the complex part from the generic parts. \nFigure 7.1 shows several example service interactions with each other and available \ninfrastructure. Service A is calling Service B using HTTP (for this topic, GRPC would fit \nsimilarly). Service B stores and reads data from a database and will need the right cre-\ndentials to connect. Service A also connects to a message broker and places messages \ninto it. Service C can pick messages from the message broker and, using some creden-\ntials, connect to a Bucket to store some calculations based on the messages it receives. \nI need \ncredentials to \nconnect.\nI need \ncredentials to \nconnect.\nService A\nService B\nService C\nMessage \nBroker\nBucket\nDatabase\nAMQP / Proprietary\nAMQP / Proprietary\nHTTP/GRPC\nFigure 7.1    Common communication patterns in distributed applications\nNo matter what logic these services are implementing, we can extract some constant \nbehaviors and enable development teams to consume without the hassle of dealing \nwith the low-level details or pushing them to make decisions around cross-cutting con-\ncerns that can be solved at the platform level. \nTo understand how this can work, we must look closely at what is happening inside \nthese services. As you might know already, the devil is in the details. While from a high-\nlevel perspective, we are used to dealing with services doing what is described in figure \n7.1, if we want to unlock an increased velocity in our software delivery pipelines, we \nneed to go one level down to understand the intricate relationships between the com-\nponents of our applications. Let’s take a quick look at the challenges the application \nteams face when trying to change different services and infrastructure that our services \nrequire. \n7.1.1\t\nThe challenges of coupling application and infrastructure\nFortunately, this is not a programming language competition, independent of your \nprogramming language of choice. If you want to connect to a database or message \nbroker, you must add some dependencies to your application code. While this is a com-\nmon practice in the software development industry, it is also one of the reasons why \ndelivery speed is slower than it should be.  \n\n\n\t\n181\nWhat are most applications doing 95% of the time?\nCoordination between different teams is the reason behind most blockers when \nreleasing software. We have created architectures and adopted Kubernetes because we \nwant to go faster. By using containers, we have adopted an easier and more standard \nway to run our applications. No matter in which language the application is written or \nwhich tech stack is used, if you give me a container with the application inside, I can \nrun it. We have removed the application dependencies on the operating system and the \nsoftware that we need to have installed in a machine (or virtual machine) to run your \napplication, which is now encapsulated inside a container. \nUnfortunately, we haven’t tackled the relationships and integration points between \ncontainers (our application’s services). We also haven’t solved how these containers will \ninteract with application infrastructure components that can be local (self-hosted) or \nmanaged by a cloud provider. \nLet’s take a closer look at where these applications heavily rely on other services and \ncan block teams from making changes, pushing them for complicated coordination \nthat can end up causing downtime to our users. We will start by splitting up the previous \nexample into the specifics of each interaction. \n7.1.2\t\nService-to-service interaction challenges\nTo send data from one service to another, you must know where the other service is \nrunning and which protocol it uses to receive information. Because we are dealing with \ndistributed systems, we also need to ensure that the requests between services arrive at \nthe other service and have mechanisms to deal with unexpected network problems or \nsituations where the other services might fail. In other words, we need to build resil-\nience in our services. We cannot always trust the network or other services to behave as \nexpected. \nLet’s use Service A and Service B as examples to go deeper into the details. In figure \n7.2, Service A needs to send a request to Service B. \nService A\nService B\nHTTP/GRPC\nThis looks really \nsimple, what can go \nwrong here?\nFigure 7.2    \nService-to-service \ninteraction \nchallenges\nBut let’s dig deeper into the mechanisms services can use internally. Suppose we leave \nthe fact that Service A depends on the Service B contract (API) to be stable and not \nchange for this to work on the side. What else can go wrong here? As mentioned, devel-\nopment teams should add a resiliency layer inside their services to ensure that Service \nA requests reach Service B. One way to do this is to use a framework to retry the request \nif it fails automatically. Frameworks implementing this functionality are available for \nall programming languages. Tools like go-retryablehttp (https://github.com/\nhashicorp/go-retryablehttp) or Spring Retry for Spring Boot (https://github.com/\nspring-projects/spring-retry) add resiliency to your service-to-service interactions. \n\n\n182\nChapter 7  Platform capabilities I: Shared application concerns \nSome of these mechanisms also include exponential backoff functionality to avoid \noverloading services and the network when things are going wrong. \nUnfortunately, there is no standard library shared across tech stacks that can provide \nthe same behavior and functionality for all your applications, so even if you configure \nboth Spring Retry and go-retryablehttp with similar parameters, it is quite hard to \nguarantee that they will behave in the same way when services start failing. \nService B\nRetry 3 times \nevery 3 seconds.\nService A v0.1.0 \n(Java)\nRetry 5 times with \nexponential backoff.\nService C v2.0.6\n(Go)\ngo-retryablehttp\nv0.7.2\nSpring Retry \nv3.1.0\nHTTP\nFigure 7.3    \nService-to-service \ninteractions retry \nmechanisms\nFigure 7.3 shows Service A written in Java using the Spring Retry library to retry three \ntimes with a wait time of 3 seconds between each request when the request fails to \nbe acknowledged by Service B. Service C, written in Go using the go-retryable \nhttp library, is configured to retry five times but using an exponential backoff (the \nretry period between requests is not fixed; this can provide time for the other service to \nrecover and not be flooded with retries) mechanism when things go wrong. \nEven if the applications are written in the same language and using the same frame-\nworks, both services (A and B) must have compatible versions of their dependencies \nand configurations. If we push both Service A and Service B to have the versions of \nthe frameworks, we are coupling them together, meaning we will need to coordinate \nthe update of the other service whenever any of these internal dependency versions \nchange. This can cause even more slowdowns and increase the complexity of coordina-\ntion efforts.\nNOTE    In this section, I’ve used retrying mechanisms as an example, but think \nabout other cross-cutting concerns that you might want to include for these ser-\nvice-to-service interactions, like circuit breakers (also for resiliency) rate limiting \nand observability. Consider the frameworks and libraries you will need to add to \ninstrument your application code to get metrics from it.\nOn the other hand, using different frameworks (and versions) for each service will \ncomplicate troubleshooting these services for our operations teams. Wouldn’t it be \n",
      "page_number": 193
    },
    {
      "number": 19,
      "title": "Segment 19 (pages 202-224)",
      "start_page": 202,
      "end_page": 224,
      "detection_method": "topic_boundary",
      "content": "\t\n183\nWhat are most applications doing 95% of the time?\ngreat to have a way to add resiliency to our applications without modifying them? \nBefore answering this question, what else can go wrong? \nSomething that developers often overlook relates to the security aspect of these com-\nmunications. Service A and Service B don’t live in a vacuum, meaning other services \nsurround them. If any of these services is compromised by a bad actor, having a free-for-\nall service-to-service invocation between all the services makes our entire system inse-\ncure. This is where having service identity and the right security mechanisms to ensure \nthat, for this example, Service A can only call Service B is extremely important, as shown \nin figure 7.4. \nIf Service A is compromised, it \ncan affect the entire system.\nService A\nService B\nService C\nService D\nService E\nFigure 7.4    \nIf a service is \ncompromised, \nit can affect the \nentire system.\nHaving a mechanism that allows us to define our service’s identity, we can define which \nservice-to-service invocations are allowed and which protocols and ports are allowed \nfor the communications to happen. Figure 7.5 shows how we can reduce the blast \nradius (how many services are affected if a security breach happens) by defining rules \nthat enforce which services are allowed in our system and how they are supposed to \ninteract. \nService E\nBy having service identity \nwe can enforce rules to \nreduce the blast radius a \nservice gets compromised.\nService A\nService C\nService B\nService D\nAllowed Services:\n • Service A\n • Service B\n • Service C\n • Service D\nAllowed invocations:\n • Service A to    \n \nService B \n \n(HTTPS)\nHTTPS\nFigure 7.5    \nReducing the \nblast radius by \ndefining system-\nlevel rules\nHaving the right mechanisms to define and validate these rules cannot be easily built \ninside each service. Hence developers tend to assume that an external mechanism will \nbe in charge of performing these checks.  \nAs we will see in the following sections, service identity is something that we need \nacross the board and not only for service-to-service interactions. Wouldn’t it be great to \n\n\n184\nChapter 7  Platform capabilities I: Shared application concerns \nhave a simple way to add service identity to our system without changing our applica-\ntion’s services?\nBefore answering this question, let’s look at other challenges teams face when archi-\ntecting distributed applications. Let’s talk about storing and reading state, which most \napplications do. \n7.1.3\t\nStoring/reading state challenges\nOur application needs to store or read state from persistent storage. That is quite a \ncommon requirement, right? You need data to do some calculations, then store the \nresults somewhere so they don’t get lost if your application goes down. In our example, \nfigure 7.6, Service B needed to connect to a database or persistent storage to read and \nwrite data. \nWhat can go \nwrong here? \nService B \nDatabase \nFigure 7.6    \nStoring/reading \nstate challenges\nWhat can go wrong here? Developers are used to connecting to different kinds of \ndatabases (relational, NoSQL, files, buckets) and interacting with them. But two main \nfriction points slow teams from moving their services forward: dependencies and \ncredentials. \nLet’s start by looking at dependencies. What kind of dependencies does Service B \nneed to connect to a database? Figure 7.7 shows Service B connecting to both a rela-\ntional database and a NoSQL database. To achieve these connections, Service B needs \nto include a driver and a client library, plus the configuration needed to fine-tune how \nthe application will connect to these two databases. These configurations define the \nsize of the connection pool (how many application threads can connect concurrently \nto the database), buffers, health checks, and other important details that can change \nhow the application behaves. \nconfig\nconfig\nService B v0.1.6\nDriver v1.0.1\nClient v2.2.3\nRelational \nDatabase\nv1.x\nNoSQL 2.x\nFigure 7.7    \nDatabases \ndependencies and \nclient versions\nBesides the configuration of the driver and the client, their versions need to be com-\npatible with the version of the databases we are running, and this is where the chal-\nlenges begin. \n\n\n\t\n185\nWhat are most applications doing 95% of the time?\nNOTE    It is important to notice that each driver/client is specific to the database \n(relational or NoSQL) that you are connecting to. This section assumes you used \na specific database because it meets your application’s requirements. Each data-\nbase vendor has unique features optimized for different use cases. In this chap-\nter, we are more interested in 95% of the cases that do not use vendor-specific \nfeatures.\nOnce the application’s service is connected to the database using the client APIs, \nit should be fairly easy to interact with it. Whether by sending SQL queries or com-\nmands to fetch data or using a key-value API to read keys and values from the database \ninstance, developers should know the basics to start reading and writing data. \nDo you have more than one service interacting with the same database instance? \nAre they both using the same library and the same version? Are these services written \nusing the same programming language and frameworks? Even if you manage to control \nall these dependencies, there is still a coupling that will slow you down. Whenever the \noperations teams decide to upgrade the database version, each service connecting to \nthis instance might or might not need to upgrade its dependencies and configuration \nparameters. Would you upgrade the database first or the dependencies? \nFor credentials, we face a similar problem. It is quite common to consume creden-\ntials from a credential store like HashiCorp’s Vault (https://www.vaultproject.io/). If \nnot provided by the platform and not managed in Kubernetes, application services can \ninclude a dependency to consume credentials from their application’s code easily. Fig-\nure 7.8 shows Service B connecting to a credential store, using a specific client library, \nto get a token to connect to a database. \nToken\nService B v0.4.6\nDriver\nClient v4.4.1\nDatabase\nCredential \nStore\nFigure 7.8    \nCredentials store \ndependencies\nIn chapters 2 and 5, we connected the Conference services to different components \nusing Kubernetes Secrets. By using Kubernetes Secrets, we were removing the need for \napplication developers to worry about where to get these credentials from. \nOtherwise, if your service connects to other services or components that might \nrequire dependencies in this way, the service will need to be upgraded for any change \nin any of the components. This coupling between the service code and dependencies \ncreates the need for complex coordination between application development teams, \nthe platform team, and the operations teams in charge of keeping these components \nup and running. \n\n\n186\nChapter 7  Platform capabilities I: Shared application concerns \nCan we get rid of some of these dependencies? Can we push some of these concerns \ndown to the platform team, so we remove the hassle of keeping them updated from \ndevelopers? If we decouple these services with a clean interface, then the infrastructure \nand applications can be updated independently. \nBefore jumping into the next topic, I wanted to briefly talk about why having ser-\nvice identity at this level can also help reduce security problems when interacting with \napplication infrastructure components. Figure 7.9 shows how similar service identity \nrules can be applied to validate who can interact with infrastructure components. Once \nagain, the system will limit the blast radius if a service is compromised.\nService identity help \nus to enforce which \nservices can interact \nwith the infrastructure \ncomponents.\nService B\nService C\nDatabase\nAllowed Services:\n • Service B\n • Service C\nCan connect to \nDatabase:\n • Service B\nFigure 7.9    \nEnforcing rules \nbased on service \nidentity\nBut what about asynchronous interactions? Let’s look at how these challenges relate to \nasynchronous messaging before jumping into the solutions space. \n7.1.4\t\nAsynchronous messaging challenges\nWith asynchronous messaging, you want to decouple the producer from the consumer. \nWhen using HTTP or GRPC, Service A needs to know about Service B, and both ser-\nvices need to be up to exchange information. When using asynchronous messaging, \nService A doesn’t know anything about Service C. You can take it even further, where \nService C might not even be running when Service A places a message into the mes-\nsage broker. Figure 7.10 shows Service A placing a message into the message broker; at \na later point in time, Service C can connect to the message broker and fetch messages \nfrom it. \nI also need \ncredentials to \nconnect.\nI also need \ncredentials to \nconnect.\nService A\nMessage \nBroker\nService C\nAMQP / Proprietary\nAMQP / Proprietary\nFigure 7.10    Asynchronous messaging interactions\n\n\n\t\n187\nWhat are most applications doing 95% of the time?\nSimilar to HTTP/GRPC service-to-service interactions, when using a message broker, \nwe need to know where the message broker is to send messages to or to subscribe to get \nmessages from. Message brokers also provide isolation to enable applications to group \nmessages together using the concept of topics. Services can be connected to the same \nmessage broker instance but send and consume messages from different topics. \nWhen using message brokers, we face the same problems described with databases. \nWe need to add a dependency to our applications depending on which message bro-\nker we decide to use, its version, and the programming language that we have cho-\nsen. Message brokers will use different protocols to receive and send information. A \nstandard increasingly adopted in this space is the CloudEvent specification (https://\ncloudevents.io/) from the CNCF. While CloudEvents is a great step forward, it doesn’t \nsave your application developers from adding dependencies to connect and interact \nwith your message brokers. \nFigure 7.11 shows Service A, which includes the Kafka client library to connect to \nKafka and send messages. Besides the URL, port, and credentials to connect to the \nKafka instance, the Kafka client also receives configurations on how the client will \nbehave when connecting to the broker, similar to databases. Service C uses the same \nclient, but with different versions, to connect to the same broker. \nKafka Client v3.4.3\nKafka Client v3.3.0\nService A\nService C\nKafka 3.x\nFigure 7.11    \nDependencies \nand API \nchallenges\nMessage brokers face the same problem as with databases and persistent storage. But \nunfortunately, with message brokers, developers will need to learn specific APIs that \nmight not be that easy initially. Sending and consuming messages using different pro-\ngramming languages present more challenges and cognitive load on teams without \nexperience with the specifics of the message broker at hand. \nSame as with databases, if you have chosen Kafka, for example, it means that Kafka \nfits your application requirements. You might want to use advanced Kafka features that \nother message brokers don’t provide. However, let me repeat it here: we are interested \nin 95% of the cases where application services want to exchange messages to external-\nize the state and let other interested parties know. For those cases, we want to remove \nthe cognitive load from our application teams and let them emit and consume mes-\nsages without the hassle of learning all the specifics of the selected message broker. By \nreducing the cognitive load required on developers to learn specific technologies, you \ncan onboard less experienced developers and let experts take care of the details. Simi-\nlar to databases, we can use service identity to control which services can connect, read, \nand write messages from a message broker. The same principles apply. \n\n\n188\nChapter 7  Platform capabilities I: Shared application concerns \n7.1.5\t\nDealing with edge cases (the remaining 5%)\nThere is always more than one good reason to add libraries to your application’s ser-\nvices. Sometimes these libraries will give you the ultimate control over how to con-\nnect to vendor-specific components and functionalities. Other times, we add libraries \nbecause it is the easiest way to get started or because we are instructed to do so. Some-\none in the organization decided to use PostgreSQL, and the fastest way to connect and \nuse it is to add the PostgreSQL driver to our application code. We usually don’t realize \nthat we are coupling our application to that specific PostgreSQL version. For edge \ncases, or to be more specific, scenarios where you need to use some vendor-specific \nfunctionality, consider wrapping up that specific functionality as a separate unit from \nall the generic functionality you might consume from a database or message broker. \nService A\nService A\nKafka Client v3.4.3\nHTTP/GRPC\nMessaging API\nKafka 3.x\n95%\n5%\nFigure 7.12    \nCommon vs. \nedge cases \nencapsulation\nI’ve chosen to use async messaging as an example in figure 7.12, but the same applies to \ndatabases and credential stores. If we can decouple 95% of our services to use generic \ncapabilities to do their work and encapsulate edge cases as separate units, we reduce \nthe coupling and the cognitive load on new team members tasked to modify these \nservices. Service A in figure 7.12 is consuming a message API provided by the platform \nteam to consume and emit messages asynchronously. We will look deeper into this \napproach in the next section. But more importantly, the edge cases, where we need \nto use some Kafka-specific features, for example, are extracted into a separate service \nthat Service A can still interact with using HTTP or GRPC. Notice that the messaging \nAPI also uses Kafka to move information around. Still, for Service A, that is no longer \nrelevant, because a simplified API is exposed as a platform capability. \nWhen we need to change these services, 95% of the time, we don’t need team mem-\nbers to worry about Kafka. The messaging API removes that concern from our applica-\ntion development teams. For modifying Service Y, you will need Kafka experts, and the \nService Y code will need to be upgraded if Kafka is upgraded because it directly depends \non the Kafka client. For this book, platform engineering teams should focus on trying \nto reduce the cognitive load on teams for the most common cases while at the same \ntime allowing teams to choose the appropriate tool for edge cases and specific scenarios \nthat don’t fit the common solutions. \nThe following section will look at some approaches to address some of the challenges \nwe have been discussing. However, keep in mind that these are generic solutions, and \nfurther steps may be required within your own specific context.\n\n\n\t\n189\nStandard APIs to separate applications from infrastructure\n7.2\t\nStandard APIs to separate applications from infrastructure\nWhat about if we encapsulate all these common functionalities (storing and reading \ndata, messaging, credential stores, resiliency policies) into APIs that developers can \nuse from within their applications to solve common challenges while, at the same time, \nenabling the platform team to wire infrastructure in a way that doesn’t require the \napplication’s code to change? In figure 7.13 we can see the same services, but instead of \nadding dependencies to interact with infrastructure, they use HTTP/GRPC requests.\nCredentials \nStore API\nService A\nService B\nResiliency \nPolicies\nPubSub API\nService C\nStatestore \nAPI\nStatestore \nAPI\nHTTP/GRPC\nCloudEvents\nCloudEvents\nFigure 7.13    Platform \ncapabilities as APIs\nSuppose we expose a set of HTTP/GRPC APIs that our applications services can con-\nsume. In that case, we can remove vendor-specific dependencies from our application \ncode and consume these services using standard HTTP or GRPC calls. \nThis separation between application services and platform capabilities enables sepa-\nrate teams to handle different responsibilities. The platform can evolve independently \nfrom applications, and application code will now only depend on the platform capabil-\nities interfaces but not the version of the components running under the hood. Figure \n7.14 shows the separation between application code (our three services) managed by \napplication development teams and platform capabilities that are managed by the plat-\nform team.\nCredentials \nStore API\nPubSub API\nResiliency \nPolicies\nStatestore \nAPI\nMessage Broker\nService A\nService B\nService C\nPlatform Capabilities\nApp Dev Teams\nPlatform Team\nFigure 7.14    Decoupling responsibilities from app dev teams and platform capabilities\n\n\n190\nChapter 7  Platform capabilities I: Shared application concerns \nWhen using an approach like the one suggested here, the platform team can expand \nthe platform capabilities, introducing new services for application development teams. \nMore importantly, they can do so without affecting the existing applications or forc-\ning them to release new versions. This enables teams to decide when to release new \nversions of their services based on their features and the capabilities that they want to \nconsume. \nBy following this approach, the platform team can make new capabilities available \nfor services to use and promote best practices. Because these platform capabilities are \naccessible to all services, they can promote standardization and implement best prac-\ntices behind the covers. Each team can decide which capabilities are needed to solve \ntheir specific problems based on the available ones. If capabilities are correctly ver-\nsioned, teams can decide how and when to upgrade to the latest version, allowing teams \nto move at their own pace without the platform pushing every team to upgrade when-\never a new version is available. \nFor the sake of argument, imagine that the platform team decides to expose a consis-\ntent feature flagging capability to all the services. Using this capability, all services can \nconsistently define and use feature flags without adding anything to their code except \nthe feature flag conditional checks. Teams then can manage, visualize, and toggle on \nand off all their flags consistently. A capability like feature flags introduced and man-\naged by the platform team directly affects developers’ performance, because they don’t \nneed to worry about defining how feature flags will be handled under the hood (per-\nsistence, refresh, consistency, etc.), and they know for sure that they are doing things \naligned with other services. \nFigure 7.15 shows how the platform team can add extra capabilities, like, for exam-\nple, feature flags, directly enabling teams to use this new capability uniformly in all the \nservices. No new dependencies are needed.\nApp Dev Teams\nPlatform Team\nRelease Manager \nTeam\nCredentials \nStore API\nPubSub API\nStatestore \nAPI\nFeature \nFlags API\nFeature Flags \nDashboard\nService A\nService B\nService C\nPlatform Capabilities\nFigure 7.15    Enabling teams by providing consistent and unified capabilities such as feature flags\n\n\n\t\n191\nStandard APIs to separate applications from infrastructure\nBefore moving forward, here’s a word of caution. Let’s look at some challenges that \nyou will face when externalizing capabilities like APIs, as suggested in the previous \nfigure. \n7.2.1\t\nExposing platform capabilities challenges\nExternalizing APIs for teams to use will require, first of all, stable (and versioned) \ncontracts that application teams can trust. When these APIs change, all applications \nconsuming those APIs will break and must be updated. Platform teams can adopt a \nnon-breaking changes policy that guarantees backward compatibility to teams and \ntheir applications. Adopting such policies makes your platform easier to consume, \nbecause the platform APIs and contracts are reliable for teams to use.\nOne of the main advantages of adding dependencies to your application code and, \nfor example, using containers is that for local development, you can always start a Post-\ngreSQL instance using Docker or Docker Compose and connect your application \nlocally to it. If you move toward platform-provided capabilities, you must ensure that \nyou can provide a local development experience for your teams unless your organiza-\ntion is mature enough to always work against remote services. \nAnother big difference is that the connection between your services and the platform \nprovided APIs will introduce latency and require security by default. Before, calling the \nPostgreSQL driver APIs was a local call in the same process as your application. HTTPS, \nor a secure protocol, established the connection to the database itself, but setting that \nsecure channel between your application and the database was the responsibility of the \noperations team. \nIt is also essential to recognize all the edge cases we can find when applying this \napproach to real-life projects. If you want to build these platform capabilities and push \nfor your teams to consume them, you need to make sure that there is always a door \nopen for edge cases so that teams (or even the platform team) aren’t forced to make \ncommon cases more complex to account for an obscure feature that will be used only \n1% of the time. Figure 7.16 shows Services A, B, and C using the capabilities exposed \nby the platform via the capabilities APIs. Service Y, on the other hand, has very specific \nrequirements for how to connect to the database, and the team maintaining the service \nhas decided to bypass the platform capabilities APIs to connect directly to the database \nusing the database client.\nTreating edge cases separately allows Services A, B, and C to evolve separately from \nthe platform components (database, message brokers, credential stores), while Service \nY is now heavily dependent on the database that is connecting to and requires a specific \nversion of the client. While this sounds bad, in practice, it is acceptable and should be \nconsidered a platform feature. Teams that cannot solve their business problems with \nthe exposed APIs will hate the platform and silently find workarounds. Good platforms \n(and platform teams) will promote APIs that cover a wide range of use cases, solving \nand facilitating the implementation of common functionality for application develop-\ners. If these APIs are not enough for all teams, documenting and deeply understand-\ning the edge cases leads to new APIs and platform features that the platform team can \nimplement in future versions.\n\n\n192\nChapter 7  Platform capabilities I: Shared application concerns \nStatestore \nAPI\nPubSub API\nResiliency \nPolicies\nCredentials \nStore API\nMessage Broker\nService A\nService B\nService C\nPlatform Capabilities\nService Y\nService C\nDependency\nFigure 7.16    Handling edge cases; do not ignore them\nThe following section will examine a couple of CNCF initiatives that took these ideas \nforward and helped us implement the platform capabilities that most of our applica-\ntions require. \n7.3\t\nProviding application-level platform capabilities\nIn this section, we will look at two projects that can save development teams time in \nstandardizing these generic APIs that most of our applications will need. We will start \nby looking at the Dapr project (https://dapr.io/), what it is, how it works, and what it \ncan do for our development and platform teams. Then we will look into OpenFeature \n(https://openfeature.dev/), a CNCF initiative that provides our applications with the \nright abstractions to define and use feature flags without being tied to a specific feature \nflag provider. \nOnce we get a bit of an understanding of how these two projects work and comple-\nment each other by helping us to provide application-level platform capabilities, we \nwill look into how these projects can be applied to our Conference application, what \nchanges are needed, the advantages of following this approach, and some examples \nshowing edge cases. Let’s start with Dapr, our Distributed Application Runtime. \n7.3.1\t\nDapr in action\nDapr provides a set of consistent APIs to solve common and recurrent distributed \napplication challenges. The Dapr project has spent the last four years implementing a \nset of APIs (called Building Block APIs) to abstract away common challenges and best \npractices that distributed applications will need 95% of the time. Created by Microsoft \nin 2019 and donated to the CNCF in 2021, the Dapr project has a large community \n\n\n\t\n193\nProviding application-level platform capabilities\ncontributing with extensions and improvements to the project APIs, making it the 10th \nfastest-growing project in the CNCF of 2023. \nDapr defines a set of building blocks that provide concrete APIs to solve distributed \napplication challenges and swappable implementations that the platform team can \nconfigure. If you visit the https://dapr.io website, you will see the list of Building Block \nAPIs, including Service Invocation, State Management, Publish & Subscribe, Secrets \nStore, Input/Output Bindings, Actors, Configurations Management, and, more \nrecently Workflows. Figure 7.17 shows the Dapr official website describing the current \nDapr Building Block APIs that teams can use to build their distributed applications. \nCheck the Dapr Overview page at https://docs.dapr.io/concepts/overview/ for more \ninformation about the Dapr project.\nFigure 7.17    Dapr components for building distributed applications\nWhile Dapr does much more than just expose APIs, in this chapter, I wanted to focus \non the APIs provided by the project and the mechanisms used by the project to enable \napplications/services to consume these APIs. \nBecause this is a Kubernetes book, we will look at Dapr in the context of Kubernetes, \nbut the project can also be used outside of Kubernetes clusters, making Dapr a generic \ntool to build distributed applications no matter where you are running them. As a side \nnote, Dapr is currently part of Azure Container Apps service (https://azure.microsoft \n.com/en-us/products/container-apps), where it is configured with another CNCF \nproject KEDA (https://keda.sh/) for autoscaling your distributed applications. \n7.3.2\t\nDapr in Kubernetes\nDapr works as a Kubernetes extension or add-on. You must install a set of Dapr control-\nlers (a Dapr control plane) on your Kubernetes clusters. Figure 7.15 shows Service A \ndeployed in a Kubernetes cluster with Dapr installed. Service A needs to be annotated \nwith two annotations: dapr.io/enabled: \"true\" for the Dapr control plane to be \naware of the application and dapr.io/appid: \"service-a\" to use Dapr service iden-\ntity features. \n\n\n194\nChapter 7  Platform capabilities I: Shared application concerns \nOnce Dapr is installed in your clusters, your applications deployed in the cluster \ncan start using the Dapr APIs by adding a set of annotations to your deployments. This \nenables the Dapr control plane services to understand that your application wants to \nuse the Dapr APIs, as shown in figure 7.18. \nKubernetes Cluster\nDapr Control Plane\nKubernetes Cluster\nDapr\nFigure 7.18   \nThe Dapr \ncontrol plane \nmonitor for \napplications \nwith Dapr \nannotations\nBy default, Dapr will make all the Dapr APIs available to your applications/services \nas a sidecar (daprd is the container that will run beside your applications/services) \nthat runs beside your application’s containers. Using the sidecar pattern, we enable \nour application to interact with a co-located (localhost) API that runs very close to \nthe application’s container and avoids network round trips. Figure 7.19 shows how \nthe Dapr control plane injects the daprd sidecar into the application annotated with \nthe Dapr annotations. This enables the application to access the configured Dapr \ncomponents. \nKubernetes Cluster\nDapr Control Plane\nDapr\nKubernetes Pod\n`daprd`\nService A\nDapr \nComponents\n<injects>\nHTTP/GRPC\nFigure 7.19    \nDapr sidecars \n(daprd) give your \napplications local \naccess to Dapr \ncomponents.\nOnce the Dapr sidecar is running beside your applications/service container, it can \nuse the Dapr APIs by sending requests (using HTTP or GRPC) to localhost, because \nthe daprd sidecar runs inside the same pod as the application, sharing the same net-\nworking space. \nNow for the Dapr APIs to be of some use, the platform team needs to configure \nthe implementation (or backing mechanisms named Dapr components) for these APIs \nto work. For example, if you want to use the Statestore Dapr APIs (https://docs.dapr \n.io/operations/components/setup-state-store/) from your applications/services, you \nmust define and configure a Statestore component.\n\n\n\t\n195\nProviding application-level platform capabilities\nWhen working with Dapr on Kubernetes, you configure a Dapr component spec-\nification using a Kubernetes resource. For example, you can configure a Statestore \nDapr component to use Redis. See listing 7.1 for an example Dapr component resource \ndefinition.\nListing 7.1    Dapr Statestore component definition \napiVersion: dapr.io/v1alpha1\nkind: Component\nmetadata:\n  name: statestore\nspec:\n  type: state.redis\n  version: v1\n  metadata:\n  - name: keyPrefix\n    value: name\n  - name: redisHost\n    value: redis-master:6379\n  - name: redisPassword\n    secretKeyRef:\n      name: redis\n      key: redis-password\nauth:\n  secretStore: kubernetes\nIf the component resource is available in the Kubernetes cluster, the daprd sidecar can \nread its configurations and connect to the Redis instance for this example. From the \napplication perspective, there is no need to know if Redis is being used or if any other \nimplementation for the Statestore component. Figure 7.20 shows how Dapr compo-\nnents are wired so Service A can use the Statestore component APIs. For this example, \nby calling a local API, Service A will be able to store and read data from the Redis \ninstance.\nDapr\nKubernetes Pod\n`daprd`\nService A\n<injects>\nHTTP/GRPC\nKubernetes Cluster\nDapr Control Plane\nStatestore\nComponent\nStatestore\nComponent\nRedis\nFigure 7.20    \nDapr sidecars \nuse component \nconfigurations \nto connect to \nthe component’s \ninfrastructure.\nDapr makes it easy to build your application using a local/self-hosted Redis instance \nbut then move it to the cloud where a managed Redis service can be used. No code or \ndependencies changes are needed, just a different Dapr component configuration. \nThe Statestore component APIs support different \nimplementations that you can find at https://docs.dapr.io/\nreference/components-reference/supported-state-stores/. \nFor this example, we are setting up the state.redis \nimplementation. \nBy setting the redisHost, the platform team can define \nwhere the Redis instance is located. There is no need for \nthis instance to be inside the Kubernetes cluster; it can be \nany accessible Redis instance.\nThe redisPassword property (required by \nthe state.redis implementation) can use, \nas shown in this example, a Kubernetes \nSecret reference to fetch the password.\n\n\n196\nChapter 7  Platform capabilities I: Shared application concerns \nDo you want to emit and consume messages between different applications? You \njust need to configure a Dapr PubSub component (https://docs.dapr.io/operations/ \ncomponents/setup-pubsub/) and its implementation. Now your service can use a \nlocal API to emit asynchronous messages. Do you want to make all service interactions \n(including infrastructure) calls resilient? You can use Dapr resiliency policies (https://\ndocs.dapr.io/operations/resiliency/policies/) to avoid writing custom logic inside \nyour application code. \nFigure 7.21 shows how Service A and Service B can send requests to each other using \nthe Service Invocation APIs, in contrast to calling the other service directly. Using these \nAPIs (that send traffic through the daprd sidecar) enables the platform team to config-\nure resiliency policies at the platform level, uniformly without adding any dependen-\ncies or changing the application code. \n<read>\nDapr\nKubernetes Pod\n`daprd`\nService A\nHTTP/GRPC\nDapr\nKubernetes Pod\n`daprd`\nService B\nHTTP/GRPC\nKubernetes Cluster\n<read>\nResiliency \nPolicies\nFigure 7.21    \nDapr-enabled \nservices can use \nservice-to-service \ncommunications \nand resiliency \npolicies.\nOK, so the Dapr control plane will inject the Dapr sidecars (daprd) to the applications \nthat are interested in using Dapr components. But how does this look from the appli-\ncation point of view? \n7.3.3\t\nDapr and your applications\nIf we go back to the example introduced in the previous section where Service A wants \nto use the Statestore component to store/read some data from persistent storage like \nRedis, the application code is straightforward. No matter which programming lan-\nguage you use, as soon as you know how to create HTTP or GRPC requests, you have all \nyou need to work with Dapr. \nFor example, to store data using the Statestore APIs your application code needs to \nsend an HTTP/GRPC request to the following endpoint:\nhttp://localhost:<DAPR_HTTP_PORT>/v1.0/state/<STATESTORE_NAME>\nUsing curl, the request will look like this, where -d shows the data we want to per-\nsist and 3500 is the default DAPR_HTTP_PORT and our Statestore component is called \nstatestore:\n> curl -X POST -H \"Content-Type: application/json\"  \n➥-d '[{ \"key\": \"name\", \"value\": \"Bruce Wayne\"}]'  \n➥http://localhost:3500/v1.0/state/statestore\n\n\n\t\n197\nProviding application-level platform capabilities\nTo read the data that we have persisted, instead of sending a POST request, we just \nwrite a GET request. With curl, it would look like this: \ncurl http://localhost:3500/v1.0/state/statestore/name \nUsually, you will not be using curl from inside your applications. You will use your \nprogramming language tools to write these requests. So, if you use Python, Go, Java, \n.NET, or JavaScript, you can find tutorials online on using popular libraries or built-in \nmechanisms to write these requests.\nAnother option is to use one of the Dapr SDKs (Software Development Kits) avail-\nable for different programming languages. Adding the Dapr SDK to your application \nas a dependency allows you to make your developers’ lives easier, so they don’t need to \ncraft HTTP or GRCP requests manually. It is crucial to notice that while you are now \nadding a new dependency to your application, this dependency is optional and only \nused as a helper to speed things up, because this dependency is not tied to any of the \ninfrastructural components that the Dapr APIs are interacting with. \nCheck the Dapr website for examples of how your code will look if you use the Dapr \nSDK. For example, for a multi-programming language example on how to use the Sta-\ntestore component using the SDKs, you can visit https://docs.dapr.io/getting-started/\nquickstarts/statemanagement-quickstart/. \nWhile I decided to focus on Dapr for API abstractions, Dapr offers much more.  By \nallowing platform teams to swap Dapr components implementations, applications \ncan be moved across cloud providers without needing to change any application \ncode. By default, the entire system is observable (https://docs.dapr.io/operations/ \nobservability/), secure (https://docs.dapr.io/operations/security/), and resilient \n(https://docs.dapr.io/operations/resiliency/), as Dapr sidecars will enforce service \nidentity and the rules specified by the platform team, while at the same time extracting \nmetrics from all the Dapr-enabled applications and components. I recommend plat-\nform teams familiarize themselves with the Dapr Project, as the project was built to solve \ncommon challenges that teams will face when working with distributed applications. \nCheck section 7.3.5 of this chapter to see how we can make our Conference application \nDapr-enabled. Now let’s talk a bit about feature flags.\n7.3.4\t\nFeature flags in action\nFeature flags enable teams to release software that includes new features without mak-\ning those features available immediately. New features can be hidden behind feature \nflags that can be enabled later. In other words, feature flags allow teams to keep deploy-\ning new versions of their services or applications, and once these applications are run-\nning, features can be turned on or off based on the company’s needs. \nCompared to application-level APIs, which directly enabled developers with out-of-\nthe-box behaviors to implement complex features, feature flags can enable other teams \nthat make business-related decisions on when features should be enabled to customers. \nWhile most companies might build mechanisms to implement feature flags, it is \na well-recognized pattern to be encapsulated into a specialized service or library. In \nthe Kubernetes world, you can consider using ConfigMaps as the simplest way to \n\n\n198\nChapter 7  Platform capabilities I: Shared application concerns \nparameterize your containers. As soon as your container can read environment vari-\nables to turn on and off features, you are ready to go. We used this approach in chapter \n2 with the FEATURE_DEBUG_ENABLED=true environment variable.\nUnfortunately, this approach is too simplistic and doesn’t work for real-world sce-\nnarios. First, one of the main reasons is that your containers will need to be restarted \nto reread the content of the ConfigMap if it changes. Second, you might need many \nflags for your different services, so you might need multiple ConfigMaps to manage \nyour feature flags. Third, if you use environment variables, you will need to develop a \nconvention to define each flag’s status, default values, and type, because you cannot get \naway with just defining variables as plain strings. \nBecause this is a well-understood problem, several companies have come up with \ntools and managed services like LaunchDarkly (https://launchdarkly.com/) and Split \n(https://www.split.io/product/feature-flags/), among others, which enable teams to \nhost their feature flags in a remote service that offers simplified access to view and mod-\nify feature flags without the need for technical knowledge. For each of these services, to \nfetch and evaluate complex feature flags, you will need to download and add a depen-\ndency to your applications. As each feature flag provider will offer different functional-\nities, switching between providers would require many changes.\nOpenFeature (https://openfeature.dev/) is a CNCF initiative to unify how feature \nflags can be consumed and evaluated in cloud-native applications. In the same way that \nDapr is abstracting how to interact with Statestores (storing and reading state) or Pub-\nSub (async message brokers) components, OpenFeature provides a consistent API to \nconsume and evaluate feature flags no matter which features flag provider we use. \nIn this short section, we will look at a simple example using a ConfigMap to hold a \nset of feature flag definitions. We will also be using the flagd implementation provided \nby OpenFeature, but the beauty of this approach is that you can then swap the provider \nwhere the feature flags are stored without changing any single line of code in your \napplication. \nFigure 7.22 shows a simple application including the OpenFeature SDK that is con-\nfigured to connect to an OpenFeature provider—in this case, flagd, which is in charge \nof hosting our feature flag definitions. \nOpenFeature SDK\nKubernetes Pod\nApp\n`flagd` Service\n`ConfigMap`\nOpenFeature \nSpec\nFigure 7.22    \nConsuming and \nevaluating feature \nflags from our \napplication services\n\n\n\t\n199\nProviding application-level platform capabilities\nFor this simple example, our app is written in Go and uses the OpenFeature Go SDK \nto fetch feature flags from the flagd service. The flagd service for this example is con-\nfigured to watch a Kubernetes ConfigMap that contains some complex feature flags \ndefinitions.\nWhile this is a simple example, it allows us to see how a service like flagd can allow us \nto abstract away all the complexities of the storage and implementation of the mecha-\nnisms needed to provide a feature flag capability as part of our platform. \nIn contrast with Dapr, the OpenFeature SDK is needed because we are not only \nfetching the feature flag definitions but also performing evaluations that can involve \ncomplex feature flags. \nYou can hook every service in your application to connect to an OpenFeature pro-\nvider to perform feature flag evaluations. An important difference with just using plain \nConfigMaps is that by using OpenFeature, containers don’t need to be restarted to fetch \nvalues if they change; that is now the responsibility of the OpenFeature flag provider.\nIn the next section, we look at how to apply both Dapr and OpenFeature to the Con-\nference application walking skeleton. \n7.3.5\t\nUpdating our Conference application to consume application-level platform \ncapabilities\nConceptually and from a platform perspective, it will be great to consume all these \ncapabilities without the platform leaking which tools are used to implement different \nbehaviors. This would enable the platform team to change/swap implementations and \nreduce the cognitive load from teams using these capabilities. But as we discussed with \nKubernetes, understanding how these tools work, their behaviors, and how their func-\ntionalities were designed influences how we architect our applications and services. In \nthis last section of the chapter, I wanted to show how tools like Dapr and OpenFeature \ncan influence your application architecture and, at the same time, show how these \ntools offer building blocks to create higher-level abstractions to reduce consumers’ \ncognitive load. \nFor our Conference application, we can use the following Dapr components, so let’s \nfocus on these: \n¡ Dapr Statestore component: Using the Statestore component APIs enables us to \nremove the Redis dependency from the Agenda service included in the Con-\nference application. If, for some reason, we want to swap Redis for another per-\nsistent store, we will be able to do so without changing any of the application \ncode.\n¡ Dapr PubSub component: For emitting events, we can replace the Kafka client from \nall the services to use the PubSub component APIs, allowing us to test different \n\n\n200\nChapter 7  Platform capabilities I: Shared application concerns \nimplementations, such as RabbitMQ or a cloud provider service to exchange \nasynchronous messages between applications. \n¡ Dapr service-to-service invocations and Dapr resiliency policies: If we use the ser-\nvice-to-service invocation APIs, we can configure resiliency policies between \nthe services without adding a library or custom code to our services code. By \ndefault, all services have resiliency policies defined if no custom configuration is \nprovided.\nWhile we can choose to use the Statestore component APIs also to remove the Post-\ngreSQL dependency in our Call for Proposals service, I have chosen not to do so to \nsupport the use of SQL and PostgreSQL features that the team needed for this service. \nWhen adopting Dapr, you must avoid pushing for an “all or nothing” approach. \nLet’s look at how the application will change if we decide to use Dapr. Figure 7.23 \nshows the application services using Dapr components, because all the services are \nannotated to use Dapr, and the daprd sidecar has been injected all services. Once the \nPubSub and Statestore components have been configured, they can be accessed by the \nCall for Proposals service, Agenda service, and Notifications service. Finally, a Dapr Sub-\nscription pushes events to the Frontend application. \nDapr\nDapr\nDapr\nDapr\n`daprd`\n`daprd`\n`daprd`\n`daprd`\nFrontend\nC4P Service\nPostgreSQL\nNotifications \nService\nAgenda \nService\nSubscription\nKafka\nPubSub Component\nStatestore Component\nRedis\nKubernetes Pod\nKubernetes Pod\nKubernetes Pod\nKubernetes Pod\nFigure 7.23    Using Dapr components for our walking skeleton / Conference application\nResiliency policies can also be configured and defined for the Call for Proposals ser-\nvice to interact with the agenda and notifications services, as shown in figure 7.24.\n\n\n\t\n201\nProviding application-level platform capabilities\nDapr\nDapr\n`daprd`\n`daprd`\n`daprd`\nKubernetes Pod\nKubernetes Pod\nKubernetes Pod\nC4P Service\nDapr\nNotifications \nService\nAgenda \nService\nResiliency Policies\nFigure 7.24    Service-to-service interactions can be handled by the daprd sidecar, allowing platform \nteams to define different resiliency policies. \nDapr applies default resiliency policies if we don’t configure any. These resiliency \npolicies also apply to, for our example, contacting the statestore and pubsub com-\nponents. This means that not only our service-to-service invocations are resilient, but \nevery time our application code wants to interact with infrastructure components such \nas databases, caches and message brokers, the resiliency policies will kick in. \nThe application code needs to change slightly, because when services want to talk to \neach other, they need to use the Dapr API to use resiliency policies. \nFinally, because we wanted to enable all the services to use feature flags, each service \nnow includes the OpenFeature SDK, which allows the platform team to define which \nfeature flag implementation all services will use. \nIn figure 7.25 each service has included the OpenFeature SDK library and is con-\nfigured to point to the flagd service that enables the platform team to configure the \nmechanism used to store, fetch, and manage all the feature flags used by all the services.\nOpenFeature SDK\nNotifications Service\nOpenFeature SDK\nOpenFeature SDK\nOpenFeature SDK\nAgenda Service\nC4P Service\nFrontend\nKubernetes Pod\nKubernetes Pod\nKubernetes Pod\nKubernetes Pod\n`flagd` Service\nConfigMap\nFigure 7.25    Services using the flagd feature flag provider.\n\n\n202\nChapter 7  Platform capabilities I: Shared application concerns \nUsing the OpenFeature SDK, we can change the feature flag provider without chang-\ning our application code. The OpenFeature SDK now standardizes all the feature flag \nconsumption and evaluation of our service code. \nWhile in Dapr, using the SDK is optional (because you can always craft your HTTP \nor GRPC requests by hand), in OpenFeature, the scenario is a bit more complicated. \nbecause the SDKs provide some of the evaluation logic to understand which type each \nflag is and if it is on or off. \nThe step-by-step tutorial (https://github.com/salaboy/platforms-on-k8s/tree/\nv2.0.0/chapter-7) deploys version v2.0.0 of the conference application that uses Dapr \nand OpenFeature flags to enable application teams to keep evolving the application \nservices. Version v2.0.0 of the application services doesn’t include the Kafka or Redis \nclient to interact with infrastructure. These services can be deployed in different envi-\nronments (including cloud providers) and wired against different implementations of \nthese standard APIs. Figure 7.26 shows the dependencies that we managed to remove \nfor version v2.0.0 of the application using the Dapr component APIs.\nDapr\nDapr\nDapr\nDapr\nSubscription\nKafka\nPubSub Component\n/api/new-events/\nFrontend\nC4P Service\nAgenda Service\nKafka Client\nStatestore Component\nPostgreSQL\nRedis\nNotifications \nService\nKafka Client\nPostgreSQL \nDriver\nKafka Client\nKafka Client\nKafka Client\nFigure 7.26    Kafka and Redis client removed from services’ dependencies.\nFrom a platform perspective, three Kubernetes resources are defined by the Dapr Sta-\ntestore component, the Dapr PubSub component, and the Dapr Subscription.\nWe’ve already seen in section 7.3.1 how a Dapr Statestore component is defined. In \nlisting 7.2, we can see how a PubSub component is defined, in this case selecting the \ntype to be pubsub.kafka, which uses the Kafka instance installed using Helm. \n\n\n\t\n203\nProviding application-level platform capabilities\nListing 7.2    Dapr PubSub component definition \napiVersion: dapr.io/v1alpha1\nkind: Component\nmetadata:\n  name: conference-pubsub\nspec:\n  type: pubsub.kafka\n  version: v1\n  metadata:\n  - name: brokers\n    value:  kafka.default.svc.cluster.local:9092\n  - name: authType\n    value: \"none\" \nYou can find all the supported PubSub implementations on the official Dapr website \n(https://docs.dapr.io/reference/components-reference/supported-pubsub/). Finally, \nthe Dapr Subscription resources allow us to declaratively configure subscriptions to \nPubSub components and route events to the application’s endpoints, as shown in list-\ning 7.3. \nListing 7.3    Dapr Subscription definition\napiVersion: dapr.io/v1alpha1\nkind: Subscription\nmetadata:\n  name: frontend-subscription\nspec:\n  pubsubname: conference-pubsub\n  topic: events-topic \n  route: /api/new-events/ \nscopes: \n- frontend \nFrom an application developer perspective, the changes in v2.0.0 use the Dapr Go SDK \nto call the Dapr components API. For example, to read the state from the Statestore \ncomponent, the Agenda service performs the call shown in listing 7.4. \nListing 7.4    Getting state from a Statestore using the Dapr SDK\ns.APIClient.GetState(ctx, \nSTATESTORE_NAME, \nKEY, \nnil) \nWe need to specify \nthe Kafka brokers \navailable for the \nPubSub component \nto connect to. \nBy default, the Kafka \nHelm Chart provided by \nBitnami doesn’t require \nauthentication. \nThe PubSub \ncomponent where \nwe want to register \nthe subscription\nThe topic inside the \nPubSub component \nthat the subscription \nwill listen to\nThe route where the events \nreceived in the topic will be \nforwarded to by Dapr\nscopes allows us to define which Dapr applications are allowed to receive events \nfrom this subscription. In this case the only consumer is the frontend \napplication. Scopes heavily relies on service identity to block messages from \nbeing forwarded to unauthorized services.\nTo store state, you only need to \nprovide the Statestore component \nname configured in Dapr. \nYou also need to provide the \nkey that you want to retrieve \nfrom the Statestore.\n\n\n204\nChapter 7  Platform capabilities I: Shared application concerns \nThe APIClient instance here is just a Dapr client that provides helpers to interact with \nthe DAPR HTTP and GRPC APIs. Similarly, to store state, you can use the SaveState \nmethod; see listing 7.5.\nListing 7.5    Saving state from a Statestore using the Dapr SDK\ns.APIClient.SaveState(ctx, \nSTATESTORE_NAME, \nKEY, \njsonData, \nnil)\nFinally, and following exactly the same approach, applications can publish events to \nthe PubSub component by using the API shown in listing 7.6. \nListing 7.6    Publishing an event using the Dapr SDK\ns.APIClient.PublishEvent(ctx, \nPUBSUB_NAME,  \nPUBSUB_TOPIC, \neventJson) \nOn the OpenFeature side, the feature flag configurations are defined inside a ConfigMap \n(https://github.com/salaboy/platforms-on-k8s/blob/v2.0.0/conference-application \n/helm/conference-app/templates/openfeature.yaml#L49). The tutorial shows three \ndifferent feature flags added to the Conference application to control frontend and \nbackend features. By modifying the ConfigMap that contains the flag definitions, we \ncan change the application behavior without the need to restart any container. The \neventsEnabled feature flag in listing 7.7 shows a feature flag of type Object that con-\ntains properties for each of the services. By defining different variants, we can codify \nprofiles, allowing us to define complex scenarios.\nListing 7.7    Feature flag definitions, including variants\n      \"eventsEnabled\": {\n      \"state\": \"ENABLED\",\n      \"variants\": {\n        \"all\": {\n          \"agenda-service\": true,\n          \"notifications-service\": true,\n          \"c4p-service\": true\nSame as before, we need to provide the Statestore \ncomponent name. Notice that applications can have access \nto multiple Statestore components for different purposes.\nThe KEY will be used \nto store the payload, \nso it can then be \nretrieved by calling \nGetState method.\nThe state is sent to the APIs \nas a JSON payload.\nTo publish an event, we need to specify the Dapr PubSub \ncomponent that we want to use as well as the topic. \nThe topic allows us to divide the \nPubSub component into different \nlogical buckets that the \napplication can use to exchange \nevents and messages.\nThe event payload is \nexpressed as JSON.\n\n\n\t\n205\nLinking back to platform engineering\n        },\n        \"decisions-only\": {\n           \"agenda-service\": false,\n           \"notifications-service\": false,\n           \"c4p-service\": true\n         },\n         \"none\": {\n           \"agenda-service\": false,\n            \"notifications-service\": false,\n            \"c4p-service\": false\n          }\n        },\n        \"defaultVariant\": \"all\"\nListing 7.7 shows an Object feature flag that defines three variants: all, deci-\nsions-only, and none. By changing the defaultVariant property, we can change \nwhich profile is selected, in this case to enable and disable which services will emit \nevents. Inside the Agenda service source code, we use the OpenFeature GO SDK to \nfetch and evaluate the flag, as shown in the following listing.\nListing 7.8    Feature flag evaluation using OpenFeature SDK\ns.FeatureClient.ObjectValue(ctx, \"eventsEnabled\", \nEventsEnabled{},\nopenfeature.EvaluationContext{})\nListing 7.8 shows using the OpenFeature client to fetch the eventsEnabled feature. \nThe EventsEnabled{} struct is the default value that should return in case there is \na problem fetching the feature flag. Finally, the EvaluationContext struct allows \nyou to add extra parameters for OpenFeature to evaluate the flag for more complex \nscenarios.\nYou can find the differences between v1.0.0 and v2.0.0 by comparing the main \nbranch and the v2.0.0 branch in the application repository at https://github.com/\nsalaboy/platforms-on-k8s/compare/v2.0.0. At the same time, the platform team is free \nto configure and wire up application infrastructure and define all the backing mecha-\nnisms and implementations for feature flags, storage, messaging, configuration, man-\naging credentials, resiliency, and other common challenges they don’t want to expose \ndirectly to developers.  \n7.4\t\nLinking back to platform engineering\nIn this chapter, we have seen how to enable teams with platform-wide capabilities in \nthe form of APIs. We aim to speed up their process of writing and delivering complex \nsoftware by providing teams with common and standard APIs to solve everyday chal-\nlenges when creating distributed applications and mechanisms such as feature flags. \nBy separating application infrastructure from the application’s code, we not only \nremove dependencies from our services, but we also enable the platform team to \ndecide how to configure application infrastructure components and how the services \nwill connect to them. If different environments require different implementations, the \n",
      "page_number": 202
    },
    {
      "number": 20,
      "title": "Segment 20 (pages 225-233)",
      "start_page": 225,
      "end_page": 233,
      "detection_method": "topic_boundary",
      "content": "206\nChapter 7  Platform capabilities I: Shared application concerns \nplatform team can work behind the APIs to provide different configurations for differ-\nent scenarios. \nFigure 7.27 shows how we can reduce friction and dependencies related to the appli-\ncation infrastructure. This allows our application’s services to work in various environ-\nments the platform team can control. Using projects like Dapr, you also gain portability \nof your applications across cloud providers, consistent APIs that can be used from any \nprogramming language, and you enable teams to bring their applications from a local \ndevelopment environment to production environments, allowing the platform team to \nwire up the infrastructure that your application needs to work. With feature flags, we \nenable developers to keep releasing software by masking features behind feature flags \nthat can be turned on and off, enabling other teams closer to customers (like product \nteams) to decide when these features should be exposed. \nCloud Resources\nPlatform Teams can \nconfigure and wire these \nApplication-Level APIs with \ndifferent infrastructure \ncomponents depending on \nthe available resources.\nDevelopers work on \nimplementing features \nconsuming Application-Level \nAPIs provided by the \nplatform.\nProduct Teams can make \nuse of the Feature Flags \nDashboard to turn on and \noff features when the \nbusiness needs it.\nOur Platform\nPlatform APIs\nCloud Provider\nApplication\nApplication-Level \nAPIs\nInfrastructure\nEnvironments \nConfiguration \nRepository\nContainer \nRegistry\nGitOps Sync\nProvisioning Cloud \nResources\nService Pipelines\nFeature Flags \nDashboard\nManages\nEnvironment\nFigure 7.27    Consistent capabilities across environments enable smoother paths to production.\nBy providing consistent capabilities across environments, we enable easier paths to \nproduction, because we can control which features are exposed to customers after \nreleasing the new version to production. Developers can keep building features rely-\ning on platform-provided application-level APIs without knowing where the available \n\n\n\t\n207\nLinking back to platform engineering\ninfrastructure is or which versions of databases and message brokers are used in the \nproduction environment. \nFor the sake of space, topics such as observability, metrics, and logs, service meshes \nhaven’t been covered in these sections, because these capabilities are currently more \nmature and more operations-focused. I’ve decided to focus on capabilities that build \non top of the operation and infrastructure teams to speed up development teams and \nsolve everyday challenges. Platform teams will define which observability stack they will \nuse across environments early and how this data can be available to developers trou-\nbleshooting problems. Service meshes and certificate rotation tools for mutual TLS \n(encryption between services) are often discussed in these conversations because these \nare topics that development teams will not want to spend time on and should be pro-\nvided at the platform level. Figure 7.28 shows how our platform is responsible for defin-\ning, fetching, and aggregating data from the tools available inside each environment. \nOur platform should provide a single entry point to understand what is happening in \ndifferent environments and provide teams with enough information to troubleshoot \nproblems and access the tools the organization needs to deliver software to customers.\nTools to fetch and aggregate data to \nmonitor and manage Environments\nPlatform Provided API\nPlatform\nEnvironment\nConference Application\nObservability \n(Otel)\nMutual TLS & \nCertificates\nDapr\nOpenFeature\nCloud Provider \nStack or Self \nManaged\nDatabases / \nMessage Brokers / \nIdentity / \nCredentials\nManaged \nFeature Flag \nProvider\nFigure 7.28    The platform that we build needs to define, manage, and monitor the tools available in each \nenvironment.\nThe next chapter will explore tools to enable teams to experiment while releasing soft-\nware. Along the same lines of using feature flags, we will dig deeper into how to use \ndifferent release strategies to catch problems earlier in the release process and enable \nstakeholders to try different approaches simultaneously. \n\n\n208\nChapter 7  Platform capabilities I: Shared application concerns \nSummary\n¡ Moving dependencies to application infrastructure enables application code to \nstay agnostic to platform-wide upgrades. Separating the lifecycle of the applica-\ntions and the infrastructure enables teams to rely on stable APIs instead of deal-\ning with provider-specific clients and drivers for everyday use cases. \n¡ Treating edge cases separately allows experts to make more conscious cases \nbased on their application requirements. This also allows common scenarios to \nbe handled by less experienced team members, who don’t need to understand \nthe specifics of tools like vendor-specific database features or low-level message \nbroker configurations when they only want to store or read data or emit events \nfrom their application’s code. \n¡ Dapr solves common and shared concerns when building distributed applica-\ntions. Developers that can write HTTP/GRPC requests can interact with infra-\nstructure that the platform team will wire up. \n¡ Feature flags enable developers to keep releasing software by masking new fea-\ntures behind feature flags that can be turned on and off.\n¡ OpenFeature standardizes the way applications consume and evaluate feature \nflags. Relying on OpenFeature abstractions allows platform teams to decide \nwhere feature flags are stored and how they are managed. Different providers \ncan offer non-technical people dashboards where they can see and manipulate \nflags. \n¡ If you followed the step-by-step tutorial, you gained hands-on experience in using \ntools like Dapr and OpenFeature in the context of a cloud-native application \ncomposed of four services that interact with SQL and NoSQL databases and a \nmessage broker like Kafka. You also modified feature flags on a running applica-\ntion to change its behavior without restarting any of its components.\n\n\n209\n8\nPlatform capabilities II: \nEnabling teams to experiment \nThis chapter covers\n¡ Enabling teams by providing release strategies \t\n\t capabilities\n¡ Identifying the challenges of using Kubernetes \t\n\t built-in mechanisms to implement release \t\n\t strategies\n¡ Using Knative Serving advanced traffic  \n\t management to release our cloud-native \t \t\n\t applications\n¡ Leveraging Argo Rollouts out-of-the-box release \t\n\t strategies\nIn chapter 7, we looked at how enabling development teams with application-level \nAPIs can reduce the cognitive load on developers to solve common distributed \napplication challenges while at the same time enabling platform teams to wire and \nconfigure these components to be accessible for applications to consume. We also \nevaluated using feature flags to enable developers to keep releasing new features \nand enable other teams closer to the business to decide when these new features are \nexposed to customers. \n\n\n210\nChapter 8  Platform capabilities II: Enabling teams to experiment  \nIn this chapter, we will look at how introducing different release strategies can \nhelp the organization catch errors earlier in the process, validate assumptions, and \nenable teams to experiment with different versions of the same application running \nsimultaneously. \nWe want to avoid teams being worried about deploying a new version of your ser-\nvices, as this slows down your release cadence and causes stress to everyone involved in \nthe release process. Reducing risk and having the proper mechanisms to deploy new \nversions drastically improves confidence in the system. It also reduces the time from a \nrequested change until it is live in front of your users. New releases with fixes and new \nfeatures directly correlate to business value, because software is not valuable unless it \nserves our company’s users. \nWhile Kubernetes built-in resources such as deployments, services, and ingresses \nprovide us with the basic building blocks to deploy and expose our services to our users, \na lot of manual and error-prone work must happen to implement well-known release \nstrategies. For these reasons, the cloud-native communities have created specialized \ntools to help teams be more productive by providing mechanisms to implement the \nmost common release strategy patterns we will discuss in this chapter. This chapter is \ndivided into three main sections: \n¡ Release strategies fundamentals:\n–\t Canary releases, blue/green deployments, and A/B testing\n–\t Limitations and complexities of using Kubernetes built-in mechanisms\n¡ Knative Serving: Autoscaling, advanced traffic management, and release \nstrategies\n–\t Introduction to Knative Serving \n–\t Release strategies in action with Knative Serving and the Conference \napplication\n¡ Argo Rollouts: Release strategies automated with GitOps\n–\t Introducing Argo Rollouts\n–\t Argo Rollouts and progressive delivery\nThe first section of this chapter covers the most common and well-documented release \nstrategies from a high level, and we’ll quickly look at why implementing these release \nstrategies with Kubernetes building blocks can be challenging. Section 8.2 looks at \nKnative Serving, which provides higher-level building blocks that highly simplify how \nto implement these release strategies while at the same time providing advanced traffic \nmanagement and dynamic autoscaling for our workloads. Section 8.3 introduces Argo \nRollouts, another project from the Argo family that focuses on enabling teams with \nout-of-the-box release strategies and progressive delivery. Let’s start covering the fun-\ndamentals of release strategies.\n\n\n\t\n211\nRelease strategies fundamentals\n8.1\t\nRelease strategies fundamentals\nIf you look for the most common release strategies teams implement to promote ser-\nvices to sensitive environments, you will find canary releases, blue/green deployments, \nand A/B testing. Each release strategy has a different purpose and can be applied to \nvarious scenarios. In the following short sections, we will look at what is expected for \neach release strategy, the expected benefits of having these mechanisms in place, and \nhow they relate to Kubernetes. Let’s start by looking into canary releases. \n8.1.1\t\nCanary releases\nWith canary releases, we want to enable teams to deploy a new version of a service and \nhave full control over how much live traffic is routed to this new version. This allows \nteams to slowly route traffic to the new version to validate that no problems were intro-\nduced before routing all the production traffic to it. \nFigure 8.1 shows users accessing our software, where 95% of the requests are for-\nwarded to the service that we know is stable and only 5% are forwarded to the new ver-\nsion of the service. \nService \n(New Version)\nService\n(Stable)\nRouter\nUsers\n95%\n5%\nFigure 8.1    Releasing a new version (canary) of the service with 5% traffic routed to it\nThe term canary release comes from coal miners who used canary birds to alert them \nwhen toxic gasses reached dangerous levels. In this case, our canary release can help us \nidentify problems or regressions introduced by the new version early on, where rolling \nback 100% of the traffic to the stable version doesn’t include a full deployment.\nIn the context of Kubernetes, and as shown in figure 8.2, you can implement a sort of \ncanary release by using two Kubernetes deployments resources (one with the stable ver-\nsion and one with the new version) and a single Kubernetes service that matches these \ntwo deployments. If each deployment has a single replica, there will be a 50% and 50% \ntraffic split. Adding more replicas to each version creates a different percentage traffic \nsplit (for example, three replicas for the stable version and only one replica for the new \nversion will give you a 75% to 25% traffic split ratio), as the Kubernetes service route \nrequests using a round-robin fashion to all pods matching the service label.\n\n\n212\nChapter 8  Platform capabilities II: Enabling teams to experiment  \nService\nmatchLabel: app\nDeployment\n(Stable)\nlabel: app\nDeployment\n(New Version)\nlabel: app\nPod\nPod\nPod\nPod\n75%\n25%\nFigure 8.2    Canary release in Kubernetes using two deployments and one service.\nTools like Istio (https://istio.io/) or Linkerd (https://linkerd.io/) service meshes can \ngive you finer-grained control of how traffic gets routed to each service. I strongly rec-\nommend you check Martin Fowler’s website, which explains this release strategy in \nmore detail at https://martinfowler.com/bliki/CanaryRelease.html. \n8.1.2\t\nBlue/green deployments\nWith blue/green deployments, we aim to enable teams to switch between two versions \nof their services or applications that are running parallel. This parallel version can \nact as a staging instance for testing, and when the team is confident enough, they can \nswitch traffic to this parallel instance. This approach gives the team the safety of having \nanother instance ready if the new version starts experiencing problems. This approach \nrequires having enough resources to run both versions simultaneously, which can be \nexpensive, but it gives your teams the freedom to experiment with an instance that is \nrunning with the same resources as your production workloads. \nFigure 8.3 shows internal teams testing a production-like setup of the service’s new \nversion. Whenever this new version is ready, the team can decide to switch production \ntraffic to the new version while still having the stable version to rollback if things go \nwrong.\nBlue\nGreen\nInternal Testing\nUsers\nRouter\nService (Stable)\nService(New \nVersion)\nFigure 8.3    Blue/green deployments run in parallel with production-grade setups, allowing teams to \nswitch traffic when they feel confident in the new version.\n\n\n\t\n213\nRelease strategies fundamentals\nIn the Kubernetes context, you can implement blue/green deployments by using two \nKubernetes deployment resources and a Kubernetes service, but in this case, the ser-\nvice should only match the pods of a single deployment. Updating the service config-\nuration to match the green deployment label(s) will automatically switch the traffic to \nthe new version. \nFigure 8.4 shows how by changing the matchLabel of the service to “green,” the \ntraffic will be automatically routed to the new version of the service. In the mean-\ntime, for testing, internal teams can use a different service to match the new version’s \ndeployment.\nChanging the Active Service \nmatchLabel to “green” will \nswitch traffic to the new version\nActive Service\nmatchLabel: \nblue\nDeployment \n(Stable)\nlabel: blue\nPreview Service\nmatchLabel: \ngreen\nDeployment\n(New Version)\nlabel: green\nBlue\nGreen\nInternal Testing\nFigure 8.4    Blue/green deployments run in parallel. The service matchLabel is used to define where to \nroute requests. \nOnce again, I strongly recommend you check Martin Fowler’s website (https:// \nmartinfowler.com/bliki/BlueGreenDeployment.html) on blue/green deployments, \nbecause there are links and more context that you might find useful. \n8.1.3\t\nA/B testing\nA/B testing is different from canary releases and blue/green deployments because it \nfocuses more on end users than internal teams. With A/B testing, we want to enable \nother teams closer to the business to try different approaches to solve a business prob-\nlem. Examples are having two different page layouts to see which one works better for \nthe users or having different registration flows to validate which one takes users less \ntime and causes less frustration. As discussed in chapter 7 with feature flags, we want \nto enable other teams and not only developers to experiment, in this case by providing \ndifferent groups of users access to different versions of the application. These teams \ncan then validate how effective each feature is and then decide which one to keep. \nFigure 8.5 shows two different service implementations providing alternative regis-\ntration flows for users. Using A/B testing, we can run both in parallel and collect data to \nenable business teams to decide which option works better.\n\n\n214\nChapter 8  Platform capabilities II: Enabling teams to experiment  \nService (stable)\nRegistration \nFlow A\nUsers\n50%\n50%\nService (stable)\nRegistration \nFlow B\nRouter\nWhich one \nworks \nbetter for \nour users?\nStakeholders\nFigure 8.5    A/B testing enables teams closer to the business to evaluate different approaches and \ngather data to make decisions to improve business outcomes.\nBecause A/B testing is not a technical release strategy, it can be implemented in dif-\nferent ways depending on the application’s requirements. Having two separate Kuber-\nnetes services and deployments would make sense to run and access two different \nversions of the same application. Figure 8.6 shows the use of two Kubernetes services \nand two deployments to route users to different versions of the same functionality. It \nalso shows that an application-level router will be needed to define the rules on how \nusers are routed to each of the alternatives.\nAn application level \nrouter is needed to \ndefine the rules for \nrouting users to one of \nthe available options\nLogical \nRouter\nService\nService\nDeployment \nRegistration \nFlow A\nDeployment\nRegistration \nFlow B\nFigure 8.6    A/B testing requires some business and application-level rules to define how to route users \nto different options.\nA/B testing can be implemented using similar mechanisms as canary releases, and we \nwill look at several options in the following sections. Continuous Delivery by Jez Humble \nand David Farley (Addison-Wesley Professional, 2010) covers these release strategies in \ndetail, so I strongly recommend you check that book.  \n",
      "page_number": 225
    },
    {
      "number": 21,
      "title": "Segment 21 (pages 234-264)",
      "start_page": 234,
      "end_page": 264,
      "detection_method": "topic_boundary",
      "content": "\t\n215\nRelease strategies fundamentals\n8.1.4\t\nLimitations and complexities of using built-in Kubernetes building blocks\nCanary releases, blue/green deployments, and A/B testing can be implemented using \nbuilt-in Kubernetes resources. But as you have seen, this requires creating different \ndeployments, changing labels, and calculating the number of replicas needed to \nachieve percentage-based distribution of the requests is quite a major and error-prone \ntask. Even if you use a GitOps approach, as shown with ArgoCD or other similar tools \nin chapter 4, creating the required resources with the right configurations is quite \nhard and takes a lot of effort.\nWe can summarize the drawbacks of implementing these patterns using Kubernetes \nbuilding blocks as follows: \n¡ Manual creation of more Kubernetes resources, such as deployments, services, \nand ingress rules, to implement these different strategies can be error-prone and \ncumbersome. The team implementing the release strategies must understand \nhow Kubernetes behaves to achieve the desired output.\n¡ No automated mechanisms are provided out of the box to coordinate and imple-\nment the resources required by each release strategy.\n¡ They can be error-prone, because multiple changes need to be applied at the \nsame time in different resources for everything to work as expected.\n¡ Suppose we notice a demand increase or decrease in our services. In that case, we \nneed to manually change the number of replicas for our deployments or install \nand configure a custom auto scaler (more on this later in this chapter). Unfor-\ntunately, if you set the number of replicas to 0, there will not be any instance to \nanswer requests, requiring you to have at least one replica running all the time. \nOut of the box, Kubernetes doesn’t include any mechanism to automate or facilitate \nthese release strategies, which becomes a problem quite quickly if you are dealing with \nmany services that depend on each other.  \nNOTE    One thing is clear: your teams need to be aware of the implicit con-\ntracts imposed by Kubernetes regarding 12-factor apps and how their services \nAPIs evolve to avoid downtime. Your developers need to know how Kubernetes’ \nbuilt-in mechanisms work to have more control over how your applications are \nupgraded.\nIf we want to reduce the risk of releasing new versions, we want to empower our devel-\nopers to have these release strategies available for their daily experimentation. \nIn the next sections, we will look at Knative Serving and Argo Rollouts, tools and \nmechanisms built on top of Kubernetes to simplify all the manual work and limitations \nthat we will find when trying to set up Kubernetes building blocks to enable teams with \ndifferent release mechanisms. Let’s start first with Knative Serving, which extends our \nKubernetes clusters with a set of building blocks that simplifies the implementation of \nthe release strategies described before. \n\n\n216\nChapter 8  Platform capabilities II: Enabling teams to experiment  \n8.2\t\nKnative Serving: Advanced traffic management and release \nstrategies\nKnative is one of these technologies that are hard not to use when you learn what it \ncan do for you. After working with the project for almost three years and observing the \nevolution of some of its components, every Kubernetes cluster should have Knative \nServing installed; your teams will appreciate it. Knative Serving is a Kubernetes exten-\nsion that provides higher-level abstractions on top of Kubernetes built-in resources to \nimplement good practices and common patterns that enable your teams to go faster \nand have more control over their services.\nWhile this chapter focuses on release strategies, you should look into Knative Serving \nif you are interested in the following topics: \n¡ Providing a containers-as-a-service approach for your teams to use.\n¡ Dynamic autoscaling for your workloads to provide a functions-as-a-service \napproach for your teams. Knative Serving installs its own autoscaler, which is \nautomatically available for all Knative Services.\n¡ Advanced and fine-grained traffic management for your services.\nAs the title of this section specifies, the following sections focus on a subset of the \nfunctionality provided by Knative, called Knative Serving. Knative Serving allows you \nto define Knative Services, which dramatically simplifies implementing the release strat-\negies exemplified in the previous sections. Knative Services will create Kubernetes \nbuilt-in resources for you and keep track of their changes and versions, enabling sce-\nnarios that require multiple versions to be present simultaneously. Knative Services \nalso provides advanced traffic handling and autoscaling to scale down to zero replicas \nfor a serverless approach. \nNOTE  A step-by-step tutorial on how to use Knative Serving with the Con-\nference application to implement different release strategies can be found at \nhttps://github.com/salaboy/platforms-on-k8s/blob/main/chapter-8/knative/\nREADME.md. \nIt is outside of the scope of this book to explain how Knative Serving components and \nresources work; my recommendation is that if I manage to get your attention with the \nexamples in the following sections, you should check out Knative in Action by Jacques \nChester (Manning Publications, 2021). \n8.2.1\t\nKnative Services: Containers-as-a-Service\nOnce you have Knative Serving installed, you can create Knative Services. I can hear \nyou thinking: “But we already have Kubernetes services. Why do we need Knative \nServices?” Believe me, I had the same feeling when I saw the same name, but follow \nalong—it does make sense. \n\n\n\t\n217\nKnative Serving: Advanced traffic management and release strategies\nWhen we deployed our walking skeleton in chapter 2 (the Conference application), \nwe created at least two Kubernetes resources: a Kubernetes deployment and a Kuber-\nnetes service. As we discussed in chapter 2, by using ReplicaSets, a deployment can per-\nform rolling updates by keeping track of the configuration changes in the deployment \nresources. We also discussed in chapter 2 the need for creating an ingress resource to \nroute traffic from outside the cluster. Usually, you only create an ingress resource to \nmap the publicly available services, such as the Frontend of the Conference application \nor the Conference Admin Portal. \nNOTE    The Ingress resource that we created routes all the traffic straight to \nthe in-cluster Kubernetes service, and the ingress controller used in the tuto-\nrials works as a simple reverse proxy. It doesn’t have any advanced capability to \nsplit traffic, rate limit, or inspect the request headers to make dynamic decisions \nabout it. \nYou can follow a step-by-step tutorial to create a cluster, install Knative Serving, and \ndeploy the application services at https://github.com/salaboy/platforms-on-k8s/\nblob/main/chapter-8/knative/README.md#installation. \nKnative Services are built on top of these resources (services, deployments, Replica-\nSets) to simplify how we define and manage the lifecycle of our application’s services. \nWhile it simplifies the task and reduces the amount of YAML that we need to maintain, \nit also adds some exciting features. Before jumping into the features, let’s look at how a \nKnative Service looks in action. \nKnative Services expose a simplified contract to its users that resembles a contain-\ner-as-a-service interface such as AWS App Runner and Azure Container Apps. In fact, \nKnative Services share the interface used by Google Cloud Run to enable users to run \ncontainers on-demand without the need to understand Kubernetes. \nBecause Knative Serving installs its own autoscaler, Knative Services are automati-\ncally configured to scale based on demand. This makes Knative Serving a very good way \nto implement a function-as-a-service platform, because workloads that are not being used \nwill be automatically downscaled to zero.\nLet’s see these features in action, beginning with the Knative Service Kubernetes \nresource. We will start simple and use the notification service from the Conference \napplication to demonstrate how Knative Services work. Check the notifications-service.\nyaml resource definition (available at https://github.com/salaboy/platforms-on-k8s/\nblob/main/chapter-8/knative/notifications-service.yaml), as shown in the following \nlisting. \n\n\n218\nChapter 8  Platform capabilities II: Enabling teams to experiment  \nListing 8.1    Knative Service definition\napiVersion: serving.knative.dev/v1\nkind: Service\nmetadata:\n  name: notifications-service\nspec:\n  template:\n    spec:\n      containers:\n        - image: salaboy/notifications-service:v1.0.0 \n          Env:  \n          - name: KAFKA_URL\n            value: <URL> \n  \nIn the same way as a deployment will pick the spec.template.spec field to cookie-cut \npods, a Knative Service defines the configuration for creating other resources using \nthe same field. \nNothing too strange so far, but how is this different from a Kubernetes Service? If you \ncreate this resource using kubectl apply -f, you can start exploring the differences. \nNOTE    All the examples in this section are based on running the step-by-step tuto-\nrial on a KinD cluster. Outputs will be different if you run in a cloud provider. See \nhttps://github.com/salaboy/platforms-on-k8s/blob/main/chapter-8/knative/ \nREADME.md#knative-services-quick-intro.\nYou can also list all Knative Services using kubectl get ksvc (ksvc stands for Knative \nService), and you should see your newly created Knative Service there: \n​NAME                   URL                             LATEST CREATED               READY \nnotifications-service  http://notificationsl-service...notifications-service-00001  True \nThere are a couple of details to notice right here; first, there is a URL that you can copy \ninto your browser and access the service. If you were running in a cloud provider and \nconfigured DNS while installing Knative, this URL should be accessible immediately. \nThe LASTCREATED column shows the name of the latest Knative Revision of the Ser-\nvice. Knative Revisions are pointers to the specific configuration of our service, mean-\ning that we can route traffic to them. \nYou can go ahead and test the Knative Service URL by using curl or by pointing your \nbrowser to http://notifications-service.default.127.0.0.1.sslip.io/service/info. Notice \nthat we are using jq (https://jqlang.github.io/jq/download/), a very popular JSON \nutility, to pretty-print the output. You should see the output in listing 8.2.\nYou need to specify a name for the resource, \nas with any other Kubernetes resource.\nYou need to \nspecify which \ncontainer \nimage you \nwant to run.\nYou can parameterize \nyour containers using \nenvironment variables.\n\n\n\t\n219\nKnative Serving: Advanced traffic management and release strategies\nListing 8.2    Interacting with our newly created Knative Service\ncurl http://notifications-service.default.127.0.0.1.sslip.io/service/info \n{\n   \"name\" : \"NOTIFICATIONS\",\n   \"podIp\" : \"10.244.0.18\",\n   \"podName\" : \"notifications-service-00001-deployment-74cf6f5f7f-h8kct\",\n   \"podNamespace\" : \"default\",\n   \"podNodeName\" : \"dev-control-plane\",\n   \"podServiceAccount\" : \"default\",\n   \"source\" : \"https://github.com/salaboy/platforms-on-k8s/tree/main/         \n     conference-application/notifications-service\",\n   \"version\" : \"1.0.0\"\n}\nAs with any other Kubernetes resource, you can also use kubectl describe ksvc \nnotifications-service to get a more detailed description of the resource. If you list \nother well-known resources such as deployment, services, and pods, you will find out \nthat Knative Serving is creating them for you and managing them. Because these are \nmanaged resources now, it is usually not recommended to change them manually. If \nyou want to change your application configurations, you should edit the Knative Ser-\nvice resource. \nA Knative Service, as we applied it before to our cluster, by default behaves differ-\nently from creating a service, a deployment, and an ingress manually. A Knative Service \nby default: \n¡ Is accessible: It exposes itself under a public URL so you can access it from out-\nside the cluster. It doesn’t create an ingress resource, because it uses the avail-\nable Knative Networking stack that you installed previously. Because Knative has \nmore control over the network stack and manages deployments and services, it \nknows when the service is ready to serve requests, reducing configuration errors \nbetween services and deployments. \n¡ Manages Kubernetes resources: It creates two services and a deployment. Knative \nServing allows us to run multiple versions of the same service simultaneously. \nHence, it will create a new Kubernetes service for each version (which in Knative \nServing is called  a revision).\n¡ Collects service usage: It creates a pod with the specified user-container and a \nsidecar container called queue-proxy. \n¡ Scales-up and down based on demand: It automatically downscales itself to zero if no \nrequests are hitting the service (by default after 90 seconds): \n–\t It achieves this by downscaling the Deployment replicas to 0 using the data \ncollected by the queue-proxy.\n–\t If a request arrives and there is no replica available, it scales up while queuing \nthe request, so it doesn’t get lost. \n\n\n220\nChapter 8  Platform capabilities II: Enabling teams to experiment  \n–\t Our notification service has set a minimum number of replicas to 1 to be kept \nrunning at all times.\n¡ Configuration changes history is managed by Knative Serving: If you change the Kna-\ntive Service configuration, a new Revision will be created. By default, all traffic will \nbe routed to the latest revision.\nOf course, these are the defaults, but you can fine-tune each of your Knative Services \nto serve your purpose and, for example, implement the previously described release \nstrategies.  \nIn the next section, we will look at how Knative Serving advanced traffic-handling \nfeatures can be used to implement canary releases, blue/green deployments, A/B test-\ning, and header-based routing. \n8.2.2\t\nAdvanced traffic-splitting features\nLet’s start by looking at how you can implement a canary release for one of our appli-\ncation’s services with a Knative Service. This section starts by looking into doing canary \nreleases using percentage-based traffic splitting. Then it goes into A/B testing by using \ntag-based and header-based traffic splitting.\nCanary releases using percentage-based traffic splitting\nIf you get the Knative Service resource (with kubectl get ksvc notifications \n-service -oyaml), you will notice that the spec section now also contains a spec.\ntraffic section (as shown in listing 8.3) that was created by default, because we didn’t \nspecify anything. By default, 100% of the traffic is being routed to the latest Knative \nRevision of the service.\nListing 8.3    The Knative Service allows us to set traffic rules\n traffic:\n  - latestRevision: true\n    percent: 100\nNow imagine that you made a change in your service to improve how emails are sent, \nbut your team is not sure how well it will be received by people, and we want to avoid \nhaving any backlash from people not wanting to sign into our conference because of \nthe website. Hence, we can run both versions side-by-side and control how much of the \ntraffic is being routed to each version (Revision in Knative terms).\nLet’s edit (kubectl edit ksvc notifications-service) the Knative Service and \napply the changes, as shown in listing 8.4.\nListing 8.4    Changing our Knative Service\napiVersion: serving.knative.dev/v1\nkind: Service\nmetadata:\n  name: notifications-service \nspec:\n\n\n\t\n221\nKnative Serving: Advanced traffic management and release strategies\n  template:\n    spec:\n      containers:\n        - image: salaboy/image: salaboy/notifications-service-0e27884e01429ab7\ne350cb5dff61b525:v1.1.0 \n          env:\nname: KAFKA_URL \nvalue: <URL>\n  traffic: \n  - percent: 50\n    revisionName: notifications-service-00001\n  - latestRevision: true\n    percent: 50\nIf you try now with curl, you should be able to see the traffic split in action. \nListing 8.5    New requests hitting different versions that are running parallel\ncurl http://notifications-service.default.127.0.0.1.sslip.io/service/info \n{\n  \"name\":\"NOTIFICATIONS-IMPROVED\", \n  \"version\":\"1.1.0\", \n  …\n} \ncurl http://notifications-service.default.127.0.0.1.sslip.io/service/info \n{\n  \"name\":\"NOTIFICATIONS\",\n  \"version\":\"1.0.0\", \n  …\n}\ncurl http://notifications-service.default.127.0.0.1.sslip.io/service/info \n{\n  \"name\":\"NOTIFICATIONS-IMPROVED\", \n  \"version\":\"1.1.0\", \n  …\n} \ncurl http://notifications-service.default.127.0.0.1.sslip.io/service/info \n{\n  \"name\":\"NOTIFICATIONS\",\n  \"version\":\"1.0.0\", \n  …\n}\nOnce you have validated that the new version of your service is working correctly, you \ncan start sending more traffic until you feel confident to move 100% of the traffic to it. \nIf things go wrong, you can revert the traffic split to the stable version. \nYou have updated the container \nimage that the service will use from \n“notifications-service-0e27884e0142\n9ab7e350cb5dff61b525:v1.0.0” to \n“notifications-service-0e27884e0142\n9ab7e350cb5dff61b525:v1.1.0”.\nYou have created a 50% / 50% traffic split where 50% of \nthe traffic will keep going to your stable version and 50% \nto the newest version that you just updated.\nOne in five requests will go to the new \n“NOTIFICATIONS-IMPROVED” version. \nNotice that this can take a while until the \nnew Knative Revision is running.\n\n\n222\nChapter 8  Platform capabilities II: Enabling teams to experiment  \nNotice that you are not limited to just two service revisions; you can create as many as \nyou want as long as the traffic percentage sum of all the revisions is 100%. Knative will \nfollow these rules and scale up the required revisions of your services to serve requests. \nYou don’t need to create any new Kubernetes resources, as Knative will create those for \nyou, reducing the likelihood of errors that come with modifying multiple resources \nsimultaneously. \nFigure 8.7 shows some challenges that you will face when using this feature. By using \npercentages, you don’t have control over where subsequent requests will land. Knative \nwill just make sure to maintain a fair distribution based on the percentages that you \nhave specified. This can become a problem if, for example, you have a user interface \ninstead of a simple REST endpoint. \nPercentage-based Traffic \nsplit works when clients \nmake isolated requests and \nthey don’t mind getting \nanswers from different \nversions of the service.\nThis doesn’t work well \nwhen the client makes \nmultiple correlated requests \nand expect all to land in the \nsame version. This is a \ncommon scenarios with \nUser Interfaces and Web \nBrowsers.\n50%\n50%\n50%\n50%\nNotifications \nService\nv1.0.0\nNotifications \nService\nv1.1.0\nFrontend\nv1.0.0\nFrontend\nv1.1.0\nKnative Service\nKnative Service\nClient\nBrowser\nFigure 8.7    Percentage-based traffic split scenarios and challenges\nUser interfaces are complex because a browser will perform several correlated GET \nrequests to render the page HTML, CSS, images, and so forth. You can quickly end \nup in a situation where each request hits a different version of your application. Let’s \nlook at a different approach that might be better suited for testing user interfaces or \nscenarios when we need to ensure that several requests end up in the correct version of \nour application.  \nA/B testing with tag-based routing\nIf you want to perform A/B testing of different versions of the user interface included \nwith the Conference application, you will need to give Knative some way to differenti-\nate where to send the requests. You have two options. First, you can point to a special \nURL for the service you want to try out, and the second is to use a request header to \ndifferentiate where to send the request. Let’s look at these two alternatives in action. \n\n\n\t\n223\nKnative Serving: Advanced traffic management and release strategies\nThe step-by-step tutorial (https://github.com/salaboy/platforms-on-k8s/tree/main/\nchapter-8/knative#run-the-conference-application-with-knative-services) defines all the \nConference application services to be Knative Services and deploys them to the cluster. \nThe Frontend Knative Services looks like listing 8.6.\nListing 8.6    Knative Service definition for the Frontend application\napiVersion: serving.knative.dev/v1\nkind: Service\nmetadata:\n  name: frontend\nspec:\n  template:\n    metadata:\n      annotations:\n        autoscaling.knative.dev/min-scale: \"1\" \n    spec:\n      containers:\n      - image: salaboy/frontend-go-1739aa83b5e69d4ccb8a5615830ae66c:v1.0.0\n        env:\n        - name: KAFKA_URL\n          value: kafka.default.svc.cluster.local\n       …\nOnce again, we have just created a Knative Service, but we cannot specify percent-\nage-based routing rules because this container image contains a web application com-\nposed of HTML, CSS, images, and JavaScript files. Knative will not stop you from doing \nso. Still, you will notice requests going to different versions and errors popping up \nbecause a given image is not in one of the versions, or you end up with the wrong \nstylesheet (CSS) coming from the wrong version of the application. \nLet’s start by defining a Tag that you can use to test a new stylesheet and also \ninclude the Debug tab in the Back Office section. You can do that by modifying the \nKnative Service resource as we did before. First, change the image to salaboy/fron-\ntend-go-1739aa83b5e69d4ccb8a5615830ae66c:v1.1.0, add the FEATURE_DEBUG_\nENABLED environment variable with value true and then create some new traffic rules \nusing the traffic.tag property:\n traffic:\n - percent: 100 \n   revisionName: frontend-00001\n - latestRevision: true\n   tag: version110\nYou need to specify a \nname for this service.\nWe don’t want Knative \nServing to downscale the \nFrontend service if nobody \nis using it. We want to \nkeep at least one instance \nrunning all the time.\nYou now define the Frontend container image, because we are \ngoing to test multiple requests going to the same version.\n100% of the traffic will go to \nour stable version, and no \nrequest will be sent to our \nnewly updated revision with \nversion v1.1.0.\nWe created a new tag called “color”; you \ncan find the URL for this new tag by \ndescribing the Knative Service resource.\n\n\n224\nChapter 8  Platform capabilities II: Enabling teams to experiment  \nAs shown in listing 8.7, if you describe the Knative Service (kubectl describe ksvc \nfrontend) you will find the URL for the tag that we just created, as shown in the fol-\nlowing listing. \nListing 8.7    Traffic rules when using tags\n Traffic:\n    Latest Revision:  false\n    Percent:          100\n    Revision Name:    frontend-00001\n    Latest Revision:  true\n    Percent:          0\n    Revision Name:    frontend-00001\n    Tag:              version110\n    URL:              http://version110-frontend.default.127.0.0.1.sslip.io\nFigure 8.8 shows how the Knative Service will route 100% of the traffic to version v1.0.0 \nwhen no tags are specified. If the tag ”version110” is specified, the Knative Service will \nroute traffic to the version v1.1.0.\nClient\nKnative Service\nFrontend\nv1.0.0\nFrontend\nv1.1.0\n100%\nOnly Tag: \nversion110\nFigure 8.8    Knative Serving tag-based routing for version v1.1.0.\nUsing a web browser, check that you can consistently access version v1.1.0 by using \nthe following URL (http://version110-frontend.default.127.0.0.1.sslip.io) and version \nv.1.0.0 using the original service URL (http://frontend.default.127.0.0.1.sslip.io). Fig-\nure 8.9 shows both side by side using a different color palette. \nv1.0.0 - 100% traffic\nv1.1.0 - Tag based traffic\nFigure 8.9    A/B testing with tag-based routing\nYou can find the tag and its generated \nURL in the ksvc traffic section.\n\n\n\t\n225\nKnative Serving: Advanced traffic management and release strategies\nUsing tags guarantees that all requests are hitting the URL to the correct version of \nyour service. One more option avoids you pointing to a different URL for doing A/B \ntesting, and it might be useful for debugging purposes. The next section looks at tag-\nbased routing using HTTP headers instead of different URLs. \nA/B testing with header-based routing\nFinally, let’s look at a Knative Serving feature (https://knative.dev/docs/serving/\nconfiguration/feature-flags/#tag-header-based-routing) that allows you to use HTTP \nheaders to route requests. This feature also uses tags to know where to route traffic, \nbut instead of using a different URL to access a specific revision, you can add an HTTP \nheader that will do the trick. \nImagine that you want to enable developers to access a debugging version of the \napplication. Application developers can set a special header in their browsers and then \naccess a specific revision. \nTo enable this experimental feature, you or the administrator that installs Knative \nneeds to patch a ConfigMap inside the knative-serving namespace: \nkubectl patch cm config-features -n knative-serving  \n➥-p ‘{\"data\":{\"tag-header-based-routing\":\"Enabled\"}}’\nOnce the feature is enabled, you can test this by using the tag version110 that we cre-\nated before. Listing 8.8 shows the traffic rules that we have defined. The tag name that \nwe want to target using HTTP header-based routing is highlighted.\nListing 8.8    HTTP headers-based routing using the name of the tag \n traffic:\n - percent: 100 \n   revisionName: frontend-00001\n - latestRevision: true\n   tag: version110\nIf you point your browser to the Knative Service URL (kubectl get ksvc), you will \nsee the same application as always, as shown in figure 8.10, but if you use a tool like \nModHeader extension (https://chrome.google.com/webstore/detail/modheader/\nidgpnmonknjnojddfkpgkljpfnnfcklj?hl=en) for Chrome, you can set your custom \nHTTP headers that will be included in every request that the browser produces. For \nthis example, and because the tag that you created is called version110, you need to \nset the following HTTP header: Knative-Serving-Tag: version110. As soon as the \nHTTP header is present, Knative Serving will route the incoming request to the ver-\nsion110 tag. \nFigure 8.10 shows how Knative Serving routes the request to our version110 tag by \nusing an HTTP header set using ModHeader. Notice that we are using the default ser-\nvice URL http://frontend.default.127.0.0.1.sslip.io.\n\n\n226\nChapter 8  Platform capabilities II: Enabling teams to experiment  \nFigure 8.10    Using ModHeader Chrome extension to set custom HTTP headers for header-based routing.\nBoth tag and header-based routing are designed to ensure that all requests will be \nrouted to the same revision if you hit a specific URL (created for the tag) or if one par-\nticular header is present. Finally, let’s look at how to do blue/green deployments with \nKnative Serving. \nBlue/green deployments\nFor situations where we need to change from one version to the next at a very specific \npoint in time, because there is no backward compatibility, we can still use tag-based \nrouting with percentages. Instead of going gradually from one version to the next, we \nuse percentages as a switch from 0 to 100 on the new version and from 100 to 0 on the \nold version. \nMost blue/green deployment scenarios require coordination between different \nteams and services to make sure that both the service and the clients are updated at the \nsame time. Knative Serving allows you to declaratively define when to switch from one \nversion to the next in a controller way. Figure 8.11 shows the scenario where we want to \ndeploy a new version of the notifications service v2.0.0 that is not backward compati-\nble with v1.x versions. This means that this upgrade will require changes to the clients. \nBy using Knative Serving traffic rules and tags, we can decide when the switch happens. \nTeams responsible for the clients and the upgrade of the notification service v2.0.0 \nwill need to coordinate the upgrade. \n\n\n\t\n227\nKnative Serving: Advanced traffic management and release strategies\nUpdate to v2.0.0 and update \ntraffic rules\n \nv2.0.0 is not \nbackward \ncompatible\nWhen teams are \ncomfortable with v2.0.0, \nthey will need to \ncoordinate the update of \nthe clients (v2.0.0) and \nswitch 100% of the traffic \nto the `green` tag.\n0% Tag: green\n100% Tag: green\n100%\n0%\nblue\ngreen\nKnative Service\nblue\ngreen\nClient\nClient \nv2.0.0\nKnative Service\nNotifications \nService\nv1.0.0\nNotifications \nService\nv2.0.0\nNotifications \nService\nv1.0.0\nNotifications \nService\nv2.0.0\nFor situations where v2.0.0\nis not backward compatible\nwith v1.0.0, we can use\n a Tag for internal teams \nto test v2.0.0. \nFigure 8.11    Blue/green deployments using Knative Serving tag-based routing\nTo achieve the scenario described in figure 8.11, we can create the “green” tag for the \nnew version inside our Knative Service, as shown in listing 8.9. \nListing 8.9    Using tags to define blue and green revisions\n...\ntraffic:\n    - revisionName: <blue-revision-name>\n      percent: 100 # All traffic is still being routed to the first revision\n    - revisionName: <green-revision-name>\n      percent: 0 # 0% of traffic routed to the second revision\n      tag: green # A named route\nBy creating a new tag (called “green”), we will now have a new URL to access the new \nversion for testing. This is particularly useful for testing new versions of the clients, \nbecause if the Service API is changing with a non-backward compatible change, clients \nmight need to be updated as well. Once all tests are performed, we can safely switch \nall traffic to the “green” revision of our service, as shown in listing 8.10. Notice that we \nremoved the tag from the \"green\" revision and created a new tag for the \"blue\" revision.\nListing 8.10    Switching traffic using the Knative declarative approach\n...\ntraffic:\n    - revisionName: <first-revision-name>\n      percent: 0 # All traffic is still being routed to the first revision\n\n\n228\nChapter 8  Platform capabilities II: Enabling teams to experiment  \n      tag: blue # A named route\n    - revisionName: <second-revision-name>\n      percent: 100 # 100% of traffic routed to the second revision\nNotice that the “blue” original version before the update is now accessible using \nheader–or tag–based routing and is receiving all the traffic sent to the service.\nGenerally, we cannot progressively move traffic from one version to the next, because \nthe client consuming the service will need to understand that requests might land in \ndifferent (and non-compatible) versions of the service.  \nIn the previous sections, we have been looking into how Knative Serving simplifies \nthe implementation of different release strategies for your teams to deliver features \nand new versions of your services continuously. Knative Serving reduces the need to \ncreate several Kubernetes built-in resources to manually implement the release strat-\negies described in this chapter. It provides high-level abstractions such as Knative Ser-\nvices, which creates and manages Kubernetes built-in resources and a network stack for \nadvanced traffic management. \nLet’s switch to another alternative for managing release strategies in Kubernetes \nwith Argo Rollouts. \n8.3\t\nArgo Rollouts: Release strategies automated with GitOps\nIn most cases you will see Argo Rollouts working hand in hand with ArgoCD. This \nmakes sense because we want to enable a delivery pipeline that removes the need \nto interact with our environments to apply configuration changes manually. For the \nexamples in the following sections, we will focus only on Argo Rollouts, but in real-life \nscenarios, you shouldn’t apply resources to the environments using kubectl, because \nArgo CD will do it for you. \nAs defined on the website, Argo Rollouts is “a Kubernetes controller and set of CRDs \nwhich provide advanced deployment capabilities such as blue-green, canary, canary \nanalysis, experimentation, and progressive delivery features to Kubernetes.” As we have \nseen with other projects, Argo Rollouts extend Kubernetes with the concepts of Roll-\nouts, Analysis, and Experimentations to enable progressive delivery features. The \nmain idea with Argo Rollouts is to use the Kubernetes built-in blocks without the need \nto manually modify and keep track of deployment and services resources. \nArgo Rollouts is composed of two big parts: the Kubernetes controller that imple-\nments the logic to deal with our rollouts, definitions (also analysis and experimenta-\ntions) and a kubectl plugin that allows you to control how these rollouts progress, \nenabling manual promotions and rollbacks. Using the kubectl Argo Rollouts plugin, \nyou can also install the Argo Rollouts Dashboard and run it locally. \nNOTE     You can follow a tutorial on how to install Argo Rollouts on a local Kuber-\nnetes KinD cluster at https://github.com/salaboy/platforms-on-k8s/blob/ \nmain/chapter-8/argo-rollouts/README.md. Notice that this tutorial requires \ncreating a different KinD cluster than the one we used for Knative Serving. \n\n\n\t\n229\nArgo Rollouts: Release strategies automated with GitOps\nLet’s start by looking at how we can implement canary releases with Argo Rollouts to \nsee how it compares with using plain Kubernetes resources or Knative Services. \n8.3.1\t\nArgo Rollouts canary rollouts\nWe’ll begin by creating our first Rollout resource. With Argo Rollouts, we will be not \ndefining deployments, because we will delegate this responsibility to the Argo Rollouts \ncontroller. Instead, we define an Argo Rollouts resource that also provides our pod \nspecification (PodSpec in the same way that a Deployment defines how pods need to \nbe created). \nFor these examples, we will use only the notifications service from the Conference \nplatform application, and we will not use Helm. When using Argo Rollouts, we need to \ndeal with a different resource type currently not included in the Conference applica-\ntion Helm charts. Argo Rollouts can work perfectly fine with Helm, but we will create \nfiles to test how Argo Rollouts behave for these examples. You can take a look at an Argo \nRollouts example using Helm at https://argoproj.github.io/argo-rollouts/features/\nhelm/. Let’s start by creating an Argo Rollouts resource for the notifications service in \nlisting 8.11. \nListing 8.11    Argo Rollouts resource definition\napiVersion: argoproj.io/v1alpha1\nkind: Rollout\nmetadata:\n  name: notifications-service-canary\nspec:\n  replicas: 3\n  strategy:\n    canary: \n      steps: \n      - setWeight: 25\n      - pause: {}\n      - setWeight: 75\n      - pause: {duration: 10}\n  revisionHistoryLimit: 2\n  selector:\n    matchLabels:\n      app: notifications-service\n  template:\n    metadata:\n      labels:\n        app: notifications-service\n    spec:\n      containers:\n      - name: notifications-service\n        image: salaboy/notifications-service-<HASH>:v1.0.0\n        env: \n          - name: KAFKA_URL\n            value: kafka.default.svc.cluster.local\n          ... \nThe Rollouts resource definition \nallows us to configure our workloads \nto use different releases.\nNotice that as \nwith \ndeployments, we \ncan set up the \nnumber of \nreplicas that we \nwant for our \nnotification \nservice.\nThis example sets the \nspec.strategy property \nto canary, which \nrequires a set of \nspecific steps to \nconfigure how the \ncanary release will \nbehave for this specific \nservice.\nThe steps defined will be executed in sequence when \nwe make any update on our service. For this example, \nthe canary will start with 25% of the traffic and wait \nfor manual promotion and then switch to 75%, wait \nfor 10 seconds, and finally move to 100%.\n\n\n230\nChapter 8  Platform capabilities II: Enabling teams to experiment  \nNOTE    You can find the full file at https://github.com/salaboy/platforms-on \n-k8s/blob/main/chapter-8/argo-rollouts/canary-release/rollout.yaml. \nThis Rollout resource manages the creation of Pods using what we define inside the \nspec.template and spec.replicas fields. But it adds the spec.strategy section, \nwhich for this case is set to canary and defines the steps (amount traffic (weight) that \nwill be sent to the canary) in which the rollout will happen. As you can see, you can also \ndefine a pause between each step. The duration is expressed in seconds and allows \nus to have a fine-grain control of how the traffic is shifted to the canary version. If you \ndon’t specify the duration parameter, the rollout will wait there until manual inter-\nvention happens. Let’s see how this rollout works in action. \nLet’s apply the Rollout resource to our Kubernetes cluster (check the step-by-step tuto-\nrial available at https://github.com/salaboy/platforms-on-k8s/tree/main/chapter-8/ \nargo-rollouts#canary-releases for all the steps): \n> kubectl apply -f argo-rollouts/canary-release/ \nNOTE    This command will also create a Kubernetes service and a Kubernetes \ningress resource. \nRemember, if you are using ArgoCD, instead of manually applying the resource, \nyou will push this resource to your Git repository that Argo CD is monitoring. Once \nthe resource is applied, we can see that a new Rollout resource is available by using \nkubectl, as shown in listing 8.12.\nListing 8.12    Getting all Argo Rollouts resources\n> kubectl get rollouts.argoproj.io \nNAME                           DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   \nnotifications-service-canary   3         3         3            3                     \nThis looks pretty much like a normal Kubernetes deployment, but it is not. If you use \nkubectl get deployments, you shouldn’t see any deployment resource available \nfor our email-service. Argo Rollouts replace the use of Kubernetes deployments \nby using Rollouts resources, which are in charge of creating and manipulating replica \nsets, we can check using kubectl get rs that our Rollout has created a new Replica-\nSet. See listing 8.13. \nListing 8.13    Getting the ReplicaSet created by our Rollout \n> kubectl get rs\nNAME                                    DESIRED   CURRENT   READY   \nnotifications-service-canary-7f6b88b5fb   3          3         3             \n\n\n\t\n231\nArgo Rollouts: Release strategies automated with GitOps\nArgo Rollouts will create and manage these replica sets that we used to manage with \ndeployment resources, but in a way that enables us to smoothly perform canary \nreleases. \nIf you have installed the Argo Rollouts Dashboard, you should see our Rollout on the \nmain page (see figure 8.12).\nFigure 8.12    \nArgo Rollouts \nDashboard\nAs with deployments, we still need a service and an ingress to route traffic to our ser-\nvice from outside the cluster; these resources are included in the step-by-step tutorial \n(https://github.com/salaboy/platforms-on-k8s/tree/main/chapter-8/argo-rollouts/\ncanary-release). If you create the following resources, you can start interacting with the \nstable service and with the canary, as shown in figure 8.13.\nRollout\nStrategy: Canary\nSteps: 25%, Wait \nfor Manual \nPromotion, 75% \nPod #1\nApprox. Weight 75%\nApprox. Weight 25%\nReplica Set #1\n(Stable)\nService\nIngress\nReplica Set #2\n(canary)\nPod #2\nPod #3\nPod #4\nFigure 8.13    Argo Rollouts canary release Kubernetes resources. The Rollout controls the ReplicaSets \nand manage the approximate weights based on the number of pods in each ReplicaSet.\nIf you create a service and an ingress, you should be able to query the notifications ser-\nvice service/info endpoint by using the following curl command:\n> curl localhost/service/info | jq\nThe output should look like listing 8.14. \n\n\n232\nChapter 8  Platform capabilities II: Enabling teams to experiment  \nListing 8.14    Interacting with version v1.0.0 of the notification service\n{\n  \"name\": \"NOTIFICATIONS\",\n  \"version\": \"1.0.0\",\n  \"source\": \"https://github.com/salaboy/platforms-on-k8s/tree/main/ \n➥conference-application/notifications-service\",\n  \"podName\": \"notifications-service-canary-7f6b88b5fb-fq8mm\",\n  \"podNamespace\": \"default\",\n  \"podNodeName\": \"dev-worker2\",\n  \"podIp\": \"10.244.1.5\",\n  \"podServiceAccount\": \"default\"\n}\nThe request shows the output of the service/info endpoint of our notifications \nservice. Because we have just created this Rollout resource, the Rollout canary strat-\negy mechanism didn’t kick in just yet. Now if we want to update the Rollout spec \n.template section with a new container image reference or change environment vari-\nables, a new revision will be created, and the canary strategy will kick in. \nIn a new terminal, we can watch the Rollout status before doing any modification, so \nwe can see the Rollout mechanism in action when we change the Rollout specification. \nIf we want to watch how the rollout progresses after we make some changes, you can run \nthe following command in a separate terminal: \n> kubectl argo rollouts get rollout notifications-service-canary --watch\nYou should see something like figure 8.14.\nFigure 8.14    Rollout details using the argo plugin for kubectl\n\n\n\t\n233\nArgo Rollouts: Release strategies automated with GitOps\nLet’s modify our notification-service-canary rollout by running the following \ncommand: \n> kubectl argo rollouts set image notifications-service-canary notifications-\nservice=salaboy/notifications-service-0e27884e01429ab7e350cb5dff61b525:v1.1.0\nAs soon as we replace the container image used by the Rollout, the rollout strategy will \nkick in. If you go back to the terminal where you are watching the rollout, you should \nsee that a new # revision: 2 was created; see figure 8.15.\nFigure 8.15    Rollout progress after updating the service\nYou can see that revision 2 is labeled as the “canary” and the status of the rollout is “॥ \nPaused” and only one pod is created for the canary. So far, the rollout has only exe-\ncuted the first step, as in listing 8.15.\nListing 8.15    Steps definition in our Rollout\nstrategy:\n   canary:\n     steps:\n     - setWeight: 25\n     - pause: {}\nYou can also check the status of the canary Rollout in the dashboard, as shown in figure \n8.16.\n\n\n234\nChapter 8  Platform capabilities II: Enabling teams to experiment  \nFigure 8.16     \nA canary release \nhas been created \nwith approximately \n20% of the traffic \nbeing routed to it.\nThe Rollout is currently paused waiting for manual intervention. We can now test that \nour canary is receiving traffic to see if we are happy with how the canary is working \nbefore continuing the rollout process. To do that, we can query the “service/info” end-\npoint again to see that approximately 25% of the time we hit the canary, as in listing \n8.16.\nListing 8.16    Example output hitting version v1.1.10 from our notification service\n> curl localhost/service/info | jq\n{\n  \"name\":\"NOTIFICATIONS-IMPROVED\",\n  \"version\":\"1.1.0\",\n  …\n}\nWe can see that one request hit our stable version and one went to the canary. \nArgo Rollouts is not dealing with traffic management; in this case, the Rollout \nresource is only dealing with the underlying ReplicaSet objects and their replicas. You \ncan check the ReplicaSets by running kubectl get rs, as in listing 8.17.\nListing 8.17    Checking the ReplicaSets associated to our Rollout\n> kubectl get rs\nNAME                                      DESIRED   CURRENT  READY   AGE\nnotifications-service-canary-68fd6b4ff9   1         1        1       12s\nnotifications-service-canary-7f6b88b5fb      3          3         3        17m\nThe traffic management between these different pods (canary and stable pods) \nis being managed by the Kubernetes Service resource, so to see our request hitting \nboth the canary and the stable version pods, we need to go through the Kubernetes \nservice. I am only mentioning this because if you use kubectl port-forward svc/ \nnotifications-service 8080:80, for example, you might be tempted to think that \n\n\n\t\n235\nArgo Rollouts: Release strategies automated with GitOps\ntraffic is being forwarded to the Kubernetes service (because we are using svc/noti-\nfications-service), but kubectl port-forward resolves to a pod instance and \nconnects to a single pod, allowing you only to hit the canary or a stable pod. For this \nreason, we have used an ingress, which will use the service to load balance traffic and \nhit all the pods that are matching to the service selector.  \nIf we are happy with the results, we can continue the rollout process by executing the \nfollowing command, which promotes the canary to be the stable version: \n> kubectl argo rollouts promote notifications-service-canary\nAlthough we have just manually promoted the rollout, the best practice would be uti-\nlizing Argo Rollouts automated analysis steps, which we will dig into in section 8.3.2.\nIf you look at the Argo Rollouts Dashboard, you will notice that you can also promote \nthe rollout to move forward using the Button Promote in the Rollout. Promotion in this \ncontext only means that the rollout can continue to execute the next steps defined in \nthe spec.strategy section, as shown in listing 8.18.\nListing 8.18    Rollouts steps definition with 10 seconds pause\n strategy:\n   canary:\n     steps:\n     - setWeight: 25\n     - pause: {}\n     - setWeight: 75\n     - pause: {duration: 10}\nAfter the manual promotion, the weight is going to be set to 75%, followed by a pause \nof 10 seconds, to finally set the wait to 100%. At that point, you should see that revision \n1 is being downscaled while progressively revision 2 is being upscaled to take all the \ntraffic. See figure 8.17, which shows the final state of the rollout. \nFigure 8.17    Rollout finished with all the traffic shifted to revision 2\n\n\n236\nChapter 8  Platform capabilities II: Enabling teams to experiment  \nYou can see this rollout progression live in the dashboard as well in figure 8.18.\nFigure 8.18    \nThe canary \nrevision is \npromoted to \nbe the stable \nversion.\nAs you can see, revision 1 was downscaled to have zero pods, and revision 2 is now \nmarked as the stable version. If you check the ReplicaSets, you will see the same out-\nput, as shown in listing 8.19. \nListing 8.19    The ReplicaSet responsible for revision 1 is downscaled to 0\n> kubectl get rs\nNAME                                      DESIRED   CURRENT   READY   \nnotifications-service-canary-68fd6b4ff9   3         3         3       \nnotifications-service-canary-7f6b88b5fb      0          0          0       \nWe have successfully created, tested, and promoted a canary release with Argo Rollouts! \nCompared to what we have seen in section 8.1 for canary releases, using two deploy-\nment resources to implement the same pattern with Argo Rollouts, you have full con-\ntrol over how your canary release is promoted, how much time you want to wait before \nshifting more traffic to the canary and how many manual interventions steps do you \nwant to add. Let’s now see how a blue/green deployment works with Argo Rollouts.\n8.3.2\t\nArgo Rollouts blue/green deployments \nIn section 8.1 we covered the advantages and the reasons why you would be interested \nin doing blue/green deployments using Kubernetes basic building blocks. We have \nalso seen how manual the process is and how these manual steps can open the door for \nsilly mistakes that can bring our services down. In this section, we will look at how Argo \nRollouts allows us to implement blue/green deployments following the same approach \nwe previously used for canary deployments. Check the step-by-step tutorial for Argo \nRollouts blue/green deployments at https://github.com/salaboy/platforms-on-k8s/\ntree/main/chapter-8/argo-rollouts#bluegreen-deployments. Let’s look at what our \nRollout with a BlueGreen strategy looks like in listing 8.20. \n\n\n\t\n237\nArgo Rollouts: Release strategies automated with GitOps\nListing 8.20    Rollout defining a BlueGreen strategy\napiVersion: argoproj.io/v1alpha1\nkind: Rollout\nmetadata:\n  name: notifications-service-bluegreen\nspec:\n  replicas: 2\n  revisionHistoryLimit: 2\n  selector:\n    matchLabels:\n      app: notifications-service\n  template:\n    metadata:\n      labels:\n        app: notifications-service\n    spec:\n      containers:\n      - name: notifications-service\n        image: salaboy/notifications-service-<HASH>:v1.0.0\n        env: \n          - name: KAFKA_URL\n            value: kafka.default.svc.cluster.local\n          ..\n  strategy:\n    blueGreen: \n      activeService: notifications-service-blue\n      previewService: notifications-service-green\n      autoPromotionEnabled: false\nNOTE    You can find the full file at https://github.com/salaboy/platforms-on \n-k8s/blob/main/chapter-8/argo-rollouts/blue-green/rollout.yaml. \nLet’s apply the resources for this Rollout resource to work (two Kubernetes services \nand an ingress):\n> kubectl apply -f argo-rollouts/blue-green/\nWe are using the same spec.template as before, but now we are setting the strategy of \nthe rollout to be blueGreen, and because of that, we need to configure the reference \nto two Kubernetes services. One service will be the Active service (Blue), which is serv-\ning production traffic, and the other one is the Green service that we want to preview \nbut without routing production traffic to it. The autoPromotionEnabled: false is \nrequired to allow for manual intervention for the promotion to happen. By default, \nthe rollout will be automatically promoted as soon as the new ReplicaSet is ready/\navailable. You can watch the rollout running the following command or in the Argo \nRollouts Dashboard:\n> kubectl argo rollouts get rollout notifications-service-bluegreen --watch\nIn the following figure, you should see output similar to the output we saw for the \ncanary release.\n\n\n238\nChapter 8  Platform capabilities II: Enabling teams to experiment  \nFigure 8.19    Checking the state of our BlueGreen Rollout\nAnd in the dashboard, see figure 8.20. \nFigure 8.20    \nBlue/green \ndeployment in \nthe Argo Rollouts \nDashboard.\nWe can interact with revision #1 using an ingress to the service and then send a request \nlike listing 8.21. \nListing 8.21    Hitting revision 1 of our service\n> curl localhost/service/info\n{\n  \"name\":\"NOTIFICATIONS\",\n  \"version\":\"1.0.0\",\n  …\n}\nIf we now make changes to our Rollout spec.template the blueGreen strategy will \nkick in. For this example, the expected result that we want to see is that the preview \nService is now routing traffic to the second revision that is created when we make \nchanges to the rollout: \n> kubectl argo rollouts set image notifications-service-bluegreen   \n➥notifications-service=salaboy/notifications-service-<HASH>:v1.1.0\n\n\n\t\n239\nArgo Rollouts: Release strategies automated with GitOps\nThe rollout mechanism will kick in, and it will automatically create a new ReplicaSet \nwith revision 2 that includes our changes. Argo Rollouts for blue/green deployments \nwill use selectors to route traffic to our new revision by modifying the previewService \nthat we referenced in our Rollout definition. \nIf you describe the notifications-service-green Kubernetes service, you will \nnotice that a new selector was added, as in listing 8.22. \nListing 8.22    Kubernetes service selectors managed by Argo Rollouts\n> kubectl describe svc notifications-service-green\nName:              notifications-service-green\nNamespace:         default\nLabels:            <none>\nAnnotations:       argo-rollouts.argoproj.io/managed-by-rollouts: \nnotifications-service-bluegreen\nSelector:          app=notifications-service,rollouts-pod-template-\nhash=645d484596\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                10.96.198.251\nIPs:               10.96.198.251\nPort:              http  80/TCP\nTargetPort:        http/TCP\nEndpoints:         10.244.2.5:8080,10.244.3.6:8080\nSession Affinity:  None\nEvents:            <none>\nThis selector matches with the revision 2 ReplicaSet that was created when we made \nthe changes, as shown in listing 8.23. \nListing 8.23    The ReplicaSet uses the same labels to match the service definition\n> kubectl describe rs notifications-service-bluegreen-645d484596\nName:           notifications-service-bluegreen-645d484596\nNamespace:      default\nSelector:       app=notifications-service,rollouts-pod-template-\nhash=645d484596\nLabels:         app=notifications-service\n                rollouts-pod-template-hash=645d484596\nAnnotations:    rollout.argoproj.io/desired-replicas: 2\n                rollout.argoproj.io/revision: 2\nControlled By:  Rollout/notifications-service-bluegreen\nReplicas:       2 current / 2 desired\nPods Status:    2 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=notifications-service\n           rollouts-pod-template-hash=645d484596\n\n\n240\nChapter 8  Platform capabilities II: Enabling teams to experiment  \nBy using the selector and labels, the Rollout with the blueGreen strategy is handling \nthese links automatically for us. This avoids the need to create these labels manually \nand makes sure they match. As shown in figure 8.21, you can check now that there are \ntwo revisions (and ReplicaSets) with two pods each.\nFigure 8.21    Both Blue and Green services have the same amount of replicas running\nIn the Argo Rollouts Dashboard you should see the same information as in figure 8.22.\nFigure 8.22    \nArgo Rollouts \nDashboard \nBlue and Green \nrevisions are up\nWe can now interact with the Green service (revision #2) using a different path in our \nIngress in the following listing.\n\n\n\t\n241\nArgo Rollouts: Release strategies automated with GitOps\nListing 8.24    interacting with revision 2 (our Green service)\n> curl localhost/green/service/info | jq                        \n{\n  \"name\": \"NOTIFICATIONS-IMPROVED\",\n  \"version\": \"1.1.0\",\n  \"source\": \"https://github.com/salaboy/platforms-on-k8s/tree/v1.1.0/ \n➥conference-application/notifications-service\",\n  \"podName\": \"notifications-service-bluegreen-645d484596-rsj6z\",\n  \"podNamespace\": \"default\",\n  \"podNodeName\": \"dev-worker\",\n  \"podIp\": \"10.244.2.5\",\n  \"podServiceAccount\": \"default\"\n}\nOnce we have the Green service running, the Rollout is in a Paused state until we decide \nto promote it to be the stable service. Figure 8.23 shows how the Rollout resource will \norchestrate the many replicas the Green and Blue services will have depending on the \nprogress of the rollout. \nThe Rollout update \nthe Services with the \ncorrect labels to \nmatch the Pods \ncreated by the \ndifferent Replica Sets.\nThe Rollout creates \nand manage Replica \nSets, when new \nchanges are detected \nin the spec.template \nsection of the Rollout.\nRollout\nStrategy: BlueGreen\n-     blueService\n-     greenService\nReplica Set #1\n(active)\nReplica Set #2\n(preview)\nIngress\nService\n(blue)\nService\n(green)\nPod #1\nPod #2\nPod #3\nPod #4\nFigure 8.23    Blue/green deployment with Kubernetes resources\nBecause we now have two services, we can access both at the same time and make sure \nthat our Green (green-service) is working as expected before promoting it to be our \nmain (blue) service. While the service is in preview, other services in the cluster can start \nrouting traffic to it for testing purposes, but to route all the traffic and replace our Blue \nservice with our Green service, we can use once again the Argo Rollouts promotion \nmechanism from the terminal using the CLI or from the Argo Rollouts Dashboard. Try \nto promote the Rollout using the Dashboard now instead of using kubectl. Remember \nthat the command for promoting the rollout from the terminal looks like this: \n>kubectl argo rollouts promote notifications-service-bluegreen\n\n\n242\nChapter 8  Platform capabilities II: Enabling teams to experiment  \nNotice that a 30-second delay is added by default before the scaling down of our revi-\nsion #1 (this can be controlled using the property called scaleDownDelaySeconds), \nbut the promotion (switching labels to the services) happens the moment we hit the \nPROMOTE button, as shown in figure 8.24.\nFigure 8.24    \nGreen service \npromotion using \nthe Argo Rollouts \nDashboard\nThis promotion only switches labels to the services’ resources, which automatically \nchanges the routing tables to now forward all the traffic from the Active service to our \nGreen service. If we make more changes to our Rollout, the process will start again, and \nthe preview service will point to a new revision which will include these changes. Now \nthat we have seen the basics of canary releases and blue/green deployments with Argo \nRollouts, let’s take a look at more advanced mechanisms provided by Argo Rollouts.  \n8.3.3\t\nArgo Rollouts analysis for progressive delivery\nSo far, we have managed to have more control over our different release strategies, but \nArgo Rollouts shine by providing the AnalysisTemplate CRD, which lets us ensure that \nour canary and Green services are working as expected when progressing through our \nrollouts. These analyses are automated and serve as gates for our Rollouts not to prog-\nress unless the analysis probes are successful. \nThese analyses can use different providers to run the probes, ranging from Pro-\nmetheus, Datadog (https://www.datadoghq.com/), New Relic (https://newrelic \n.com/), and Dynatrace (https://www.dynatrace.com/), among others, providing maxi-\nmum flexibility to define these automated tests against the new revisions of our services. \nFigure 8.25 shows how AnalysisTemplates allows Argo Rollouts to create \nAnalysisRuns to validate that the new version that is rolled out is behaving as expected \nby looking at service metrics. AnalysisRuns will probe the service for metrics and only \nproceed with the Rollout steps if the metrics match the success conditions defined in \nthe AnalysisTemplate.\n\n\n\t\n243\nArgo Rollouts: Release strategies automated with GitOps\nAnalysisTemplate\nsuccessCondition: result[0] >= 0.95\nproviderPrometheus: <query>\nRollout\nStrategy: Canary\nSteps: 25%, Wait for Manual \nPromotion, 75%\nAnalysisTemplate\nService\nAnalysisRun #1\nPause\nOK?\nRollout before manual promotion\nRollout if Analysis is successful\nReplica Set #1\n(Stable)\nReplica Set #2\n(Canary)\nReplica Set #1\n(Stable)\nReplica Set #2\n(Canary)\nPod #1\nPod #2\nPod #3\nPod #4\nPod #3\nPod #4\nPod #5\nPod #6\n<create>\n<probe>\n<continue>\nFigure 8.25    Argo Rollouts \nand analysis working \ntogether to make sure that \nour new revisions are sound \nbefore shifting more traffic \nto them. When receiving \nthe signal to move forward \nto the next step of the \nRollout, an AnalysisRun \nis created to probe the \nservice by running a \nquery defined in the \nAnalysisTemplate. The \nAnalysisRun result \naffect if the Rollout’s \nupdate will continue, abort, \nor pause.\nFor canary release, the analysis can be triggered as part of the step definitions, mean-\ning between arbitrary steps, to start at a predefined step or for every step defined in the \nRollout. An AnalysisTemplate using the Prometheus provider definition looks like \nlisting 8.25. \nListing 8.25    AnalysisTemplate resource provided by Argo Rollouts\napiVersion: argoproj.io/v1alpha1\nkind: AnalysisTemplate\nmetadata:\n  name: success-rate\nspec:\n  args:\n  - name: service-name\n  metrics:\n  - name: success-rate\n    interval: 5m\n    # NOTE: prometheus queries return results in the form of a vector.\n    # It is common to access the index 0 to obtain the value\n    successCondition: result[0] >= 0.95\n    failureLimit: 3\n    provider:\n      prometheus:\n        address: http://prometheus.example.com:9090\n        query: <Prometheus Query here>\nThen in our Rollout, we can refer to this template and define when a new AnalysisRun \nwill be created, for example, if we want to run the first analysis after step 2 (listing \n8.26).\n\n\n244\nChapter 8  Platform capabilities II: Enabling teams to experiment  \nListing 8.26    Selecting analysis template when defining canary release\nstrategy:\n    canary:\n      analysis:\n        templates:\n        - templateName: success-rate\n        startingStep: 2 # delay starting analysis run until setWeight: 40%\n        args:\n        - name: service-name\n          value: notifications-service-canary.default.svc.cluster.local\nAs mentioned before, the analysis can also be defined as part of the steps. In that case, \nour steps definition will look like listing 8.27. \nListing 8.27    Using AnalysisTemplate reference as a step in the rollout\nstrategy:\n    canary:\n      steps:\n      - setWeight: 20\n      - pause: {duration: 5m}\n      - analysis:\n          templates:\n          - templateName: success-rate\n          args:\n          - name: service-name\n            value: notifications-service-canary.default.svc.cluster.local \nFor rollouts using a BlueGreen strategy, we can trigger Analysis runs pre- and post-pro-\nmotion. Figure 8.26 shows the PrePromotionAnalysis step by running the SmokeTest-\nTemplate. This will gate the rollout to switch traffic to the Green service if the \nAnalysisRun fails. \nRollout\nStrategy: BlueGreen\n-     activeService\n-     previewService\nPrePromotionAnalysis: \n - SmokeTestsTemplate\n<promote only if `AnalysisRun` succeed>\nAnalysisTemplate\nSmokeTestsTemplate\nAnalysisRun\nSmokeTests\nReplica Set #2\n(preview)\nReplica Set #1\n(active)\nService\n(active)\nService\n(preview)\nIngress\nPod #1\nPod #2\nPod #3\nPod #4\n<linked to>\n<creates>\n<test>\nFigure 8.26    Argo Rollouts with blueGreen deployments and PrePromotionAnalysis in action. When the \npromotion is triggered on the Rollout it will create a new `AnalysisRun` using the `SmokeTestsTemplate` \nbefore switching the labels to route traffic to the Preview Service. Only if the `AnalysisRun` is successful \nthe preview service becomes the new Active Service.\n\n\n\t\n245\nArgo Rollouts: Release strategies automated with GitOps\nHere is an example of PrePromotionAnalysis configured in our Rollout in listing 8.28.\nListing 8.28    Defining a PrePromotionAnalysis as part of a BlueGreen rollout\napiVersion: argoproj.io/v1alpha1\nkind: Rollout\nmetadata:\n  name: notifications-service-rollout\nspec:\n...\n  strategy:\n    blueGreen:\n      activeService: notifications-service-blue\n      previewService: notifications-service-green\n      prePromotionAnalysis:\n        templates:\n        - templateName: smoke-tests\n        args:\n        - name: service-name\n          value: notifications-service-preview.default.svc.cluster.local\nFor PrePromotion tests, run a new AnalysisRun test before switching traffic to the \nGreen service, and only if the test is successful will the labels be updated. For Post-\nPromotion, the test will run after the labels were switched to the Green service, and \nif the AnalysisRun fails, the rollout can automatically revert the labels to the previous \nversion. This is possible because the Blue service will not be downscaled until the Anal-\nysisRun finishes.\nI recommend you check the Analysis section of the official documentation as it con-\ntains a detailed explanation of all the providers and knobs that you can use to make sure \nthat your Rollouts go smoothly: https://argoproj.github.io/argo-rollouts/features/\nanalysis/. \n8.3.4\t\nArgo Rollouts and traffic management\nFinally, it is worth mentioning that Rollouts used the number of pods available to \napproximate the weights we define for canary releases. While this is a good start and \na simple mechanism, sometimes we need more control over how traffic is routed to \ndifferent revisions. We can use the power of service meshes and load balancers to write \nmore precise rules about which traffic is routed to our canary releases. \nArgo Rollouts can be configured with different trafficRouting rules, depending on \nwhich traffic management tool we have available in our Kubernetes cluster. Argo Roll-\nouts today supports: Istio, AWS ALB Ingress Controller, Ambassador Edge Stack, Nginx \nIngress Controller, Service Mesh Interface (SMI), and Traefik Proxy, among others. As \ndescribed in the documentation, if we have more advanced traffic management capa-\nbilities, we can implement techniques like:\n",
      "page_number": 234
    },
    {
      "number": 22,
      "title": "Segment 22 (pages 265-273)",
      "start_page": 265,
      "end_page": 273,
      "detection_method": "topic_boundary",
      "content": "246\nChapter 8  Platform capabilities II: Enabling teams to experiment  \n¡ Raw percentages (i.e., 5% of traffic should go to the new version while the rest \ngoes to the stable version)\n¡ Header-based routing (i.e., send requests with a specific header to the new \nversion)\n¡ Mirrored traffic where all the traffic is copied and sent to the new version in par-\nallel (but the response is ignored)\nBy using tools like Istio in conjunction with Argo Rollouts, we can enable developers to \ntest features that are only available by setting specific headers or to forward copies of \nthe production traffic to the canaries to validate that they are behaving as they should. \nHere is an example of configuring a Rollout to mirror 35% of the traffic to the canary \nrelease, which has a 25% weight. This means that 35% of the traffic routed to the stable \nservice will be copied and forwarded to the canary. By using this technique, we don’t \nrisk any of the production traffic, because Istio is copying requests for testing purposes, \nas shown in listing 8.29.\nListing 8.29    Using Istio for advanced (weight-based) traffic split \napiVersion: argoproj.io/v1alpha1\nkind: Rollout\nspec:\n  ...\n  strategy:\n    canary:\n      canaryService: notifications-service-canary\n      stableService: notifications-service-stable\n      trafficRouting:\n        managedRoutes:\n          - name: mirror-route\n        istio:\n          virtualService:\n            name: notifications-service-vsvc\n      steps:\n        - setCanaryScale:\n            weight: 25\n      - setMirrorRoute:\n          name: mirror-route\n          percentage: 35\n          match:\n            - method:\n                exact: GET\n              path:\n                prefix: /\n      - pause:\n          duration: 10m\n      - setMirrorRoute:\n          name: \"mirror-route\" # removes mirror based traffic route\n\n\n\t\n247\nLinking back to platform engineering\nAs you can see, this simple example already requires knowledge of Istio Virtual Services \nand a more advanced configuration that is out of the scope of this section. I strongly \nrecommend checking Istio in Action by Christian Posta and Rinor Maloku (Manning \nPublications, 2022) if you want to learn about Istio. Figure 8.27 shows Rollouts config-\nured to use Istio traffic management capabilities to do weight-based routing. \nRollout\nStrategy: Canary\ntrafficRouting:\nistio: \nmirrorRoute\nIstio\nService\nReplica Set #1\n(Stable)\nReplica Set #2\n(canary)\nPod #1\nPod #3\nPod #2\nPod #5\n<configures>\n<controls how traffic \nis delivered to the \nService>\nWeight 100%\nWeight 25%\n<mirrored traffic>\nPod #4\nFigure 8.27    Traffic mirroring to canary release using Istio. Using tools like Istio to set \ntrafficRouting enables our canary workloads to experience real life traffic that the stable service \nis receiving. The Rollout Controller is in charge of configuring Istio Virtual Services to do the work for us \nand has a fine-grained control about which traffic is delivered to the Service.\nWhen using “trafficManagement” features, the Rollout canary strategy will behave dif-\nferently than when we are not using any rules. More specifically, the Stable version of \nthe service will not be downscaled when going through a canary release rollout. This \nensures that the Stable service can handle 100% of the traffic. The usual calculations \napply to the canary replica count.  \nI strongly recommend checking the official documentation (https://argoproj \n.github.io/argo-rollouts/features/traffic-management/) and following the examples \nthere, because the rollouts need to be configured differently depending on the service \nmesh that you have available. \n8.4\t\nLinking back to platform engineering\nIn this chapter, we have seen what can be achieved with basic Kubernetes building \nblocks and how tools like Argo Rollouts or Knative Serving simplify the life of teams by \nreleasing new versions of their applications to Kubernetes. \n\n\n248\nChapter 8  Platform capabilities II: Enabling teams to experiment  \nIt is unfortunate that as of today, in 2023, Argo Rollouts and Knative Serving hav-\nen’t been integrated yet (https://github.com/argoproj/argo-rollouts/issues/2186), \nbecause both communities would benefit from a consolidated way of defining release \nstrategies instead of duplicating functionality. I like the Knative Serving building blocks \nthat facilitate implementing these release strategies. On the other hand, I like how \nArgo Rollouts takes things to the next level with the concepts of AnalysisTemplates \nto ensure we can automatically test and validate new releases. The future is promising, \nbecause both projects are looking for further integrations with the Gateway API stan-\ndard (https://gateway-api.sigs.k8s.io/) to unify how advanced traffic routing capabil-\nities are managed in Kubernetes. Tools like Istio, Knative Serving, and Argo Rollouts \nhave active initiatives to support this new standard.\nI firmly believe that you will face delivery challenges sooner or later in your Kuber-\nnetes journey, and having these mechanisms available inside your clusters will increase \nyour confidence to release more software faster. Hence, I don’t take the evaluation \nof these tools lightly. Make sure you plan time for your teams to research and choose \nwhich tools they will use to implement these release strategies; many software vendors \ncan assist you and provide recommendations too.\nFrom a platform engineering perspective, we have looked into how to enable devel-\nopers to be more efficient by providing them application-level APIs that they can con-\nsume no matter their language. We have enabled other teams, like product managers \nor more business-focused teams, to decide when certain features are enabled and how \nto perform different release strategies depending on their needs. We enabled opera-\ntions teams to define the rules safely to validate that new Rollouts are safe and working \nas expected.\nWhile the focus of this chapter wasn’t analyzing tools like Knative Serving in detail, it \nis important to mention containers-as-a-service and function-as-a-service features when \nbuilding platforms, because these represent common traits that platform teams might \nwant to expose to their users. I would also recommend checking Knative Functions \n(https://knative.dev/docs/functions/), now an official Knative module, because the \nproject highlights the importance of building a function-based development workflow \nbased on Knative and leveraging the polyglot approach of Kubernetes.\nFigure 8.28 shows tools like Knative Serving provide basic building blocks for plat-\nform teams to expose different ways to deploy and run different teams’ workloads. By \nadding advanced traffic management, teams can implement more complex release \nstrategies. Argo Rollouts and Knative Serving work with Istio Service Mesh, which will \ncover other important aspects, such as mTLS for encryption and observability. Tools \nlike Dapr and OpenFeature fit perfectly in this picture by providing standard interfaces \nfor teams to use while at the same time enabling platform teams to define the backing \nimplementations without committing to a single solution.\n\n\n\t\n249\nLinking back to platform engineering\nStandard Application-level APIs\nEnvironment\nTransparent Security and Observability\nContainers-as-a- \nService\nFunctions-as-a- \nService\nRelease Strategies\nInfrastructure \nProvisioning\nFeature Flags \nDashboards\nRelease Gates and \nMonitoring\nPipelines\nSecurity\nIdentity \nManagement\nObservability\nPlatform\n<manage>\nFigure 8.28    Platform capabilities defined to manage environments.\nI do see tools like Knative, Argo Rollouts, Dapr, Istio, and OpenFeature leading the \nway in this space, and still, even if teams need to figure out all the details of each of \nthese tools, patterns are emerging. These tools have been around for over three years, \nand you can notice the maturity of their features, roadmaps, and the people involved. \nWith some of these projects graduating from the incubation process at the CNCF, I \nexpect more integrations to help users with common workflows that most companies \nare implementing by hand today.\nFinally, to recap our journey so far, figure 8.29 shows how release strategies fit into \nour platform walking skeleton and how teams closer to the business (product teams, \nstakeholders) can use these mechanisms to validate new versions before fully moving all \ncustomers to the latest version.\nThe Platform provides tools \nand mechanisms to enable \nteams to experiment with \nnew versions in a safe way. \nOur Platform\nPlatform APIs\nEnvironment\nApplication-Level APIs\nApplication V1\nApplication V2\nObservability\nInfrastructure\nGitOps Sync\nProvisioning \nCloud Resources\nService Pipelines\nFeature Flags \nDashboard\nRelease \nStrategies\nEnvironments \nConfiguration \nRepository\nContainer \nRegistry\nManages\nFigure 8.29    Environments that enable teams to experiment with new versions \n\n\n250\nChapter 8  Platform capabilities II: Enabling teams to experiment  \nIn the next chapter, to close the book, I’ve decided to talk about how we can mea-\nsure the platforms we are building on top of Kubernetes. The platform capabilities \ndescribed in these last two chapters and the combinations of tools described in this \nbook are good because we are improving our team’s velocity for delivering software. \nTherefore, using metrics that focus on how efficient our teams are in delivering soft-\nware directly correlates with the tools offered by the platform for these teams to use. \nSummary\n¡ Implementing common release strategies such as canary releases, blue/green \ndeployments, and A/B testing can be challenging using Kubernetes built-in \nresources. \n¡ Knative Serving introduces an advanced networking layer that gives us fine-grain \ncontrol over how traffic is routed to different versions of our services that can \nbe deployed simultaneously. This feature is implemented on top of Knative Ser-\nvices and reduces the manual work of creating several Kubernetes resources for \nimplementing canary releases, blue/green deployments, and A/B testing release \nstrategies. Knative Serving simplifies the operational burden of moving traffic to \nnew versions and, with the help of the Knative autoscaler, can scale up and down \nbased on demand. \n¡ Argo Rollouts integrates with ArgoCD (discussed in chapter 4) and provides an \nalternative to implement release strategies using the concept of Rollouts. Argo \nRollouts also include features to automate testing new releases to ensure we \nmove safely between versions (AnalysisTemplates and AnalysisRuns). \n¡ Platform teams must enable stakeholders (business, product managers, oper-\nations) to experiment by providing flexible mechanisms and workflows that \nreduce the risk of releasing new versions of the applications that they are working \nwith. \n¡ Following the step-by-step tutorials, you gain hands-on experience using Knative \nServices and different patterns to route traffic to the Conference application. \nYou also gained experience using Argo Rollouts to implement canary releases \nand blue/green deployments.\n\n\n251\n9\nMeasuring your platforms\nThis chapter covers\n¡ Learning the importance of measuring platform \t\n\t performance\n¡ Implementing DORA metrics and learning the \t\n\t secret continuous improvement \n¡ Using tools and standards to collect and  \n\t calculate metrics\nIn chapter 8, we covered the principles of how to build a platform that helps you \ndeliver software and enables your teams to have the tools they need when needed. \nThis last chapter is all about making sure that the platform is working, not only for \napplication development teams, but for the entire organization. To understand how \nthe platform is performing, we need to be able to measure it. There are different \nways of taking measurements on the software we run. Still, in this chapter, we will \nfocus on the DORA (DevOps Research and Assessment) metrics, which provide a \ngood foundation for understanding our organization’s software delivery speed and \nhow good we are at recovering from failures when they happen. \nThis chapter is divided into two main sections:\n\n\n252\nChapter 9  Measuring your platforms\n¡ What to measure: DORA metrics and high-performant teams\n¡ How to measure our platform initiatives: \n–\t CloudEvents and CDEvents to the rescue\n–\t Keptn Lifecycle Toolkit\nLet’s get started by understanding what we should be measuring, and for that, we will \nneed to look at the DORA metrics. \n9.1\t\nWhat to measure: DORA metrics and high-performant teams\nAfter performing thorough research in the industry, the DevOps Research and Assess-\nment (DORA) team has identified five key metrics that highlight the performance of \nsoftware development teams delivering software. Initially, in 2020, only four keys were \ndefined so that you might find references to the “DORA four keys”’ metrics. After sur-\nveying hundreds of teams, DORA discovered which indicators and metrics separated \nhigh-performant/elite teams from the rest, and the numbers were quite shocking. \nDORA used the following four keys to rank teams and their practices: \n¡ Deployment frequency: How often an organization successfully releases software in \nfront of their customers\n¡ Lead time for change: The time that it takes a change produced by an application \nteam to reach live customers\n¡ Change failure rate: The number of problems that are created by new changes \nbeing introduced to our production environments\n¡ Time to restore service: How long it takes to recover from a problem in our produc-\ntion environments\nFigure 9.1 shows the DORA metrics by category, where the first two are associated with \nteams’ velocity. The second two, change failure rate and time to restore service, indi-\ncate how likely we are as an organization to recover from failure. \nDeployment \nFrequency\nLead Time for \nChange\nChange Failure \nRate\nTime to Restore \nService\nVelocity Metrics\nRecovery Metrics\nFigure 9.1    \nDORA metrics \nby category\nIn 2022, a fifth key metric focused on reliability was added to cover operational per-\nformance. We will only discuss on the four software delivery metrics, because this book \nfocuses on application development teams and not operation teams.\n\n\n\t\n253\nWhat to measure: DORA metrics and high-performant teams\nThese five key metrics, as shown in the reports, establish a clear correlation between \nhigh-performing teams and their velocity expressed by these metrics. If you manage \nyour teams to reduce their deployment frequency (that is, how often they deploy new \nversions in front of your users) and reduce the time caused by incidents, your software \ndelivery performance will increase. \nIn this chapter, we will look at how to calculate these metrics for the platforms we are \nbuilding to ensure that these platforms are improving our continuous delivery prac-\ntices. To collect data and calculate these metrics, you will need to tap into different \nsystems that your teams are using to deliver software. For example, if you want to calcu-\nlate deployment frequency, you will need access to data from the production environment \nevery time a new release is deployed (see figure 9.2). Another option would be to use \ndata from the environment pipelines performing the releases to our production envi-\nronment. Figure 9.2 shows how we can observe our CI/CD pipelines and the produc-\ntion environment to calculate a metric like deployment frequency.\nApplication\nProduction \nEnvironment\nDeployment \nFrequency\nCI/CD Pipelines\nFigure 9.2    \nDeployment \nfrequency data \nsources.\nIf you want to calculate lead time for change, you will need to aggregate data coming from \nyour source code version control system like GitHub/GitLab/BitBucket and have a \nway to correlate this information with the artifacts that are being deployed into pro-\nduction (figure 9.3). \nProduction \nEnvironment\nCI Pipelines\nCD Pipelines\nLead Time for \nChange\nApplication\nGit\nArtifact \nRepository\nFigure 9.3    \nLead time for \nchange data \nsources\nSuppose you have a straightforward way to correlate commits to artifacts and later to \ndeployments. In that case, you can rely on a few sources, but if you want to have a more \ndetailed understanding of where the bottlenecks are, you might choose to aggregate \nmore data to be able to see where time is being spent. \nYou might need to tap into incident management and monitoring tools to calculate \nchange failure rate and time to restore service, as in figure 9.4. \n\n\n254\nChapter 9  Measuring your platforms\nCD Pipelines\nApplication\nProduction \nEnvironment\nIncident \nManagement\nMonitoring\nChange Failure \nRate\nTime to Restore \nService\nFigure 9.4    \nRecovery \nmetrics data \nsources\nFor recovery metrics (change failure rate and time to restore service), data collection \ncan be more challenging, because we need to find a way to measure the time when the \napplication performance is degraded or there is downtime. This might involve reports \nfrom actual users experiencing problems with our applications. \n9.1.1\t\nThe integration problem\nThis quickly becomes a system integration challenge. In general terms, we need to \nobserve the systems involved in our software delivery process, capture relevant data, \nand then have the mechanisms to aggregate this information. Once this information \nis available, we can use these metrics to optimize our delivery processes and find and \nsolve bottlenecks.\nWhile some projects already provide DORA metrics out of the box, you must evalu-\nate if they are flexible enough to plug your systems into them. The Four Keys project by \nGoogle provides an out-of-the-box experience to calculate these metrics based on exter-\nnal outputs. You can read more about it at https://cloud.google.com/blog/products/\ndevops-sre/using-the-four-keys-to-measure-your-devops-performance. \nUnfortunately, the Four Keys project requires you to run on the Google Cloud Plat-\nform because it uses BigData and Google Cloud run to do the calculations. Following \nthe principles of this book, we need a solution that works across cloud providers and uses \nKubernetes as the baseline. Other tools like LinearB (https://linearb.io/) offer a SaaS \nsolution to track different tools. I also recommend a blog post by Codefresh (https:// \ncodefresh.io/learn/software-deployment/dora-metrics-4-key-metrics-for-improving \n-devops-performance/) that explains the challenges of calculating these metrics and \nthe data points that you will need to do so.\nTo have a Kubernetes-native way to calculate these metrics, we need to standardize \nthe way we consume information from different systems, transform this information \ninto a model that we can use to calculate these metrics, and make sure that different \norganizations can extend this model with their metrics and their very diverse sources \nof information. In the next section, we will look at two standards that can help us with \nthis mission: CloudEvents (https://cloudevents.io/) and CDEvents (https://cdevents \n.dev/).\n",
      "page_number": 265
    },
    {
      "number": 23,
      "title": "Segment 23 (pages 274-286)",
      "start_page": 274,
      "end_page": 286,
      "detection_method": "topic_boundary",
      "content": "\t\n255\nHow to measure our platform: CloudEvents and CDEvents\n9.2\t\nHow to measure our platform: CloudEvents and CDEvents\nMore and more tools and service providers are adopting CloudEvents (https://\ncloudevents.io) as a standard way to wrap event data. In this book, we have covered \nTekton (https://tekton.dev) and Dapr PubSub (https://dapr.io), but if you look on \nthe official CloudEvents website (go to https://cloudevents.io and scroll to the Cloud \nEvents Adopters section), you can find all the projects that already support the stan-\ndard. In that list, you will find Argo Events (https://argoproj.github.io/argo-events/) \nand Knative Eventing (https://knative.dev/docs/eventing/), projects that we haven’t \ncovered but that work very well with the tools described in previous chapters. I find \nit interesting to see cloud provider services such as GoogleCloud Eventarc (https:// \ncloud.google.com/eventarc/docs) and Alibaba Cloud EventBridge (https://www \n.alibabacloud.com/help/en/eventbridge) in the list, which indicates that CloudE-\nvents are here to stay. \nWhile seeing more adoption is an excellent indicator, much work remains when you \nreceive or want to emit a CloudEvent. CloudEvents are simple and thin envelopes for \nour events data. Figure 9.5 shows the very simple structure of a CloudEvent. The specifi-\ncation defines the CloudEvent required metadata and verifies that the CloudEvent will \nhave a Payload that contains the event data that we want to send to other systems.\nCloudEvent Metadata\n(id, type, source, specversion)\nCloudEvent Payload\nCloudEvent\nStandard fields and \nextensions\nThis is where our event \ndata goes. \nFigure 9.5    CloudEvents, a simple envelope to wrap our events data\nUsing CloudEvents, developers emit and consume events by relying on the Cloud­\nEvents specification to know at least what the events are about. Because the Cloud­\nEvents specification is not transport-specific, we can use different transports to move \nCloudEvents around. The specification includes the definition of bindings for proto-\ncols such as AMQP, HTTP, AVRO, KAFKA, NATS, MQQT, JSON, XML, websockets, and \nwebhooks. You can find the full list at https://github.com/cloudevents/spec/tree/\nmain#cloudevents-documents. \nWhen we used Dapr PubSub in chapter 7, we used the CloudEvents SDK to verify \nthe type of the event and get the CloudEvent payload (https://github.com/salaboy/ \nplatforms-on-k8s/blob/v2.0.0/conference-application/frontend-go/frontend \n.go#L118). Projects like Tekton, Knative Eventing, and Argo Events already produce \nand provide CloudEvents sources that we can consume. For example, Knative Eventing \n\n\n256\nChapter 9  Measuring your platforms\nprovides sources for GitHub, GitLab, the Kubernetes API Server, Kafka, RabbitMQ, \netc. (https://knative.dev/docs/eventing/sources/#knative-sources). Argo Events adds \nto the list Slack and Stripe, but it gives us 20+ out-of-the-box event sources (https:// \nargoproj.github.io/argo-events/concepts/event_source/). While projects like Tek-\nton provide us with internal events for their own managed resources such as pipelines, \ntasks, pipelineRuns and taskRuns, it would be great to collect events about other tools \nin a unified way. \nIf we want to measure how the tools we include in our platform are helping our teams \nto release more software, we need to tap into these event sources to collect data, aggre-\ngate data, and extract meaningful metrics. Figure 9.6 shows different events sources \nthat we can tap into to measure how tools are helping teams to deliver more software, \nbut if we want to calculate metrics, we will need to store these events somewhere for \nfurther processing.\nApplication \nInfrastructure\nInternal \nServices\nArtifact \nRepositories\nEvents \nStore\nEvent Sources\nRepositories\nEnvironments\nServices\nPipelines\nFigure 9.6    Event sources and event store\nIf we want to use these events to calculate metrics, we will need to open the envelope, \nread the data, and based on that, aggregate and correlate these events together.\nThis has proven challenging, as each tool that generates CloudEvents can define its \nschemas for the CloudEvent payload. We would need to understand how each system \nis encoding the payload to extract the data we need to calculate our metrics. Wouldn’t \nit be great to have some standard model to quickly filter and consume these events \nbased on what they mean for our software delivery needs? Welcome CDEvents (https:// \ncdevents.dev).\n9.2.1\t\nCloudEvents for continuous delivery: CDEvents\nCDEvents is just CloudEvents but with a more specific purpose. They map to different \nphases of our continuous delivery practices. CDEvents is an initiative that the Contin-\nuous Delivery Foundation (https://cd.foundation) drives, and as its website defines, \nthey focus on enabling interoperability across different tools that are related to con-\ntinuous delivery: “CDEvents is a common specification for Continuous Delivery events, \nenabling interoperability in the complete software production ecosystem” (https://\ncdevents.dev).\n\n\n\t\n257\nHow to measure our platform: CloudEvents and CDEvents\nTo provide interoperability, the CDEvents specification defines four stages (https://\ngithub.com/cdevents/spec/blob/v0.3.0/spec.md#vocabulary-stages). These stages \nare used to group events that are conceptually related to different phases and tools in \nour software delivery ecosystem:\n¡ Core: Events related to the orchestration of tasks usually come from pipeline \nengines. Here you will find the specification of the events around the subjects \n“taskRun” and “pipelineRun.” Events like “PipelineRun started” or “TaskRun \nqueued” can be found at this stage.\n¡ Source code version control: Events related to changes associated with your source \ncode. The specification focuses on covering the subjects: “repository,” “branch,” \nand “change.” Events like “Change created” or “Change Merged” can be found \nat this stage.\n¡ Continuous integration: Events related to building software, producing artifacts, \nand running tests. This stage covers the subjects “artifact,” “build,” “testCase,” \nand “testSuite.” Events like “Artifact published” or “Build finished” can be found \nat this stage.\n¡ Continuous deployment: Events related to deploying software in different envi-\nronments. The subjects covered in this stage are “services” and “environments.” \nEvents like “service deployed” or “environment modified” can be found at this \nstage.\n¡ Continuous operations: Events related to the incidents related to our running \nservices.\nFigure 9.7 shows these categories and some example events for each.\nPipelineRun Started\nCore\nSource Code Version \nControl\nContinuous \nIntegration\nContinuous \nDeployment\nContinuous \nOperations\nTaskRun Queued\nPipelineRun Finished\nRepository Created\nBranch Deleted\nChange Merged\nArtifact Published\nBuild Finished\nTest Suite Started\nService Deployed\nEnvironment Created\nService Updated\nIncident Detected\nIncident Reported\nIncident Resolved\nFigure 9.7     \nThe four stages \ndefined by \nthe CDEvents \nspecification\n\n\n258\nChapter 9  Measuring your platforms\nWe can easily use CDEvents to calculate our software delivery metrics, because they \nalready cover the subjects that these metrics are interested in. For example, we can use \nevents from the continuous deployment stage to calculate the deployment frequency met-\nric. We can combine continuous deployment events and source code version control \nevents to calculate lead time for change. \nThe question then becomes, where do we get CDEvents from? CDEvents is a much \nnewer specification that is currently being incubated at the CDFoundation, and it is my \nfirm belief that as part of the interoperability story, this specification can serve as a hook \nmechanism for different tools and implementations to map their tools to a standard \nmodel that we can use to calculate all these metrics while allowing legacy systems (and \ntools that are not emitting cloud events) to benefit from them too. \nThis chapter will use the CDEvents specification to define our standardized data \nmodel. We will collect information from various systems using CloudEvents and rely on \nCDEvents to map the incoming events into the different stages of our software delivery \npractice. Figure 9.8 shows the most common sources of events that can be related to \nsoftware delivery. \nSource Version Control\nYour Custom Source\nCloud Provider Service\nPipelines\nReporting Tools\nEnvironments\nMonitoring Tools\nCDevents\nFigure 9.8    CDEvents are more specialized CloudEvents for continuous delivery.\nTools like Tekton are already providing experimental support for CDEvents (https://\nwww.youtube.com/watch?v=GAm6JzTW4nc), and as we will see in the next section, \nwe can transform CloudEvents into CDEvents using functions. More importantly, the \nCDEvents Working Group is also focused on providing software development kits \n(SDKs) in different languages so you can build your applications that consume and \nemit CDEvents no matter the programming language you are using. \nThe next section will examine how a Kubernetes-based solution for calculat-\ning DORA metrics can be built and extended to support different metrics and event \nsources. This is important to ensure that different platforms using different tools can \nuse their performance and detect early bottlenecks and improvement points. Notice \nthat this is just an example of how different tools can be wired together in the context of \nprojects related to Kubernetes. \n\n\n\t\n259\nHow to measure our platform: CloudEvents and CDEvents\n9.2.2\t\nBuilding a CloudEvents-based metrics collection pipeline\nTo calculate the metrics proposed by the DORA team (deployment frequency, lead \ntime for change, change failure rate, and time to restore service), we need to collect \ndata. Once we have the data coming from different systems, we need to transform the \ndata into a standardized model that we can use to calculate the metrics. Then we need \nto process the data to calculate the values for each metric. We need to store the results \nof these calculations, and then we need to make them available to everyone interested, \nprobably using a graphical dashboard that summarizes the data collected and the cal-\nculated metrics.\nDifferent tools can be used to build this data collection, transformation, and aggre-\ngation pipeline. Still, to build a simple yet extensible solution, we will use some of the \ntools covered in the previous chapters, such as Knative Serving to build our aggrega-\ntion and transformation functions, CloudEvents, and CDEvents. We will also use Kna-\ntive Eventing event sources, but this demo can be easily extended to support any other \nCloudEvent source, such as Argo Events. This section is divided into three subsections: \n¡ Data collection from event sources\n¡ Data transformation to CDEvents\n¡ Metrics calculations\nThese sections map one to one with the proposed architecture that, from a high level, \nlooks like figure 9.9. \nEvent \nSources\nData \nTransformation\nDatabase\nDatabase\nDatabase\nMetrics \nCalculation\nData Collection\nFigure 9.9    Collecting and transforming data to calculate DORA metrics\nFrom a high-level perspective, we need to architect our data collection and transfor-\nmation pipeline to support any number of event sources, because different companies \nand implementations will collect data from systems that we cannot anticipate. We are \nimposing the data to be in the form of CloudEvents before it enters our system. If you \nhave event sources not following the CloudEvents specification, you must adapt their \ndata to follow the specification. This can be easily achieved using the CloudEvents \nSDKs (https://cloudevents.io/ > SDKs section) to wrap your existing events to follow \nthe specification.\nOnce the data enters our system, we will store it in persistent storage. In this case, \nwe have used a PostgreSQL database to store all the incoming data and calculations. \n\n\n260\nChapter 9  Measuring your platforms\nComponents don’t directly call the next stage (data transformation). Instead, each \ncomponent periodically fetches data from the database and processes all the data \nthat hasn’t been processed yet. This stage (data transformation) transforms incoming \nCloudEvents already stored in the database into CDEvents structures that will be used \nto calculate the metrics. Once the transformation to the CDEvents structure happens, \nthe result is stored in a separate table in our PostgreSQL database. Finally, the “metrics \ncalculation” stage periodically reads from the database all new CDEvents that haven’t \nbeen processed and calculates the metrics we have defined.\nThis simple architecture allows us to plug in new data sources, new transformation \nlogic depending on the data we receive, and finally, new metrics calculation logic for \nyour domain-specific metrics (not only DORA metrics). It is also important to notice \nthat as soon as we guarantee that the incoming data is correctly stored, all the trans-\nformations and calculations can be recalculated if the metrics data is lost. Let’s look \ndeeper at the stages required to calculate the simplest DORA four key metrics, “deploy-\nment frequency.” \n9.2.3\t\nData collection from event sources\nAs shown in figure 9.9, we want to consume data from multiple sources, but we have \nset CloudEvents as the standard input format. While CloudEvents has been widely \nadopted, many systems still don’t support the standard. This section will look into Kna-\ntive Sources as a mechanism that can declaratively define our event sources and trans-\nform non-CloudEvent data into CloudEvents.\nThe proposed solution then exposes a REST Endpoint to receive incoming Cloud­\nEvents. Once we have CloudEvents, we will validate the data and store it in a Post-\ngreSQL table called cloudevents_raw. Let’s look at Knative Eventing event sources, \nbecause we can just install and configure these event sources to produce events for us \nautomatically.\n9.2.4\t\nKnative Eventing event sources\nWith Knative Eventing event sources, you can install existing or create new event \nsources. Figure 9.10 shows some of the event sources provided out of the box and \nhow these events will be routed to the data collection step of our data transformation \npipeline. \nREST\nKubernetes \nAPI Server\nGitHub\nRabbitMQ\nYour Source\nData \nCollection\nDatabase\nEvent Sources\nFigure 9.10    \nKnative \nSources and \ndata collection\n\n\n\t\n261\nHow to measure our platform: CloudEvents and CDEvents\nSeveral Knative Eventing event sources are provided out of the box by the Knative com-\nmunity and different software vendors. The following list is not exhaustive, but it cov-\ners some of the sources that you might want to use to calculate your metrics: \n¡ APIServerSource\n¡ PingSource\n¡ GitHubSource\n¡ GitLabSource\n¡ RabbitMQSource\n¡ KafkaSource\nCheck the complete list of third-party sources at https://knative.dev/docs/eventing/\nsources/#third-party-sources. These sources transform events, for example, from the \nKubernetes API Server, GitHub, or RabbitMQ AMQP messages into CloudEvents.\nIf you want to use one of the available Knative Sources, for example, the APIServer-\nSource, you just need to ensure that the source is installed in your cluster and then \nconfigure the source according to your needs(see listing 9.1). For calculating the \ndeployment frequency metric, we will tap into Kubernetes Events related to deploy-\nments. You can declaratively configure the source and where the events will be sent by \ndefining an APIServerSource resource. \nListing 9.1    Knative Source APIServerSource definition\napiVersion: sources.knative.dev/v1\nkind: ApiServerSource\nmetadata:\n name: main-api-server-source \nspec:\n serviceAccountName: api-server-source-sa\n mode: Resource\n resources:\n   - apiVersion: v1\n     kind: Event\nApiServerSource is the resource type that we use to configure the \nKnative ApiServerSource component that reads from the Kubernetes \nEvent stream (https://www.cncf.io/blog/2021/12/21/extracting-value \n-from-the-kubernetes-events-feed/), transforms these events to \nCloudEvents, and sends them to a sink (target destination). \nAs with every \nKubernetes resource, \nwe need to define a \nname for this resource. \nWe can configure as \nmany ApiServerSources \nas we want.\nBecause we are reading events from the \nKubernetes API server, we need to have access. \nHence, a ServiceAccount needs to exist to enable \nthe ApiServerSource components to read from \nthe internal event stream. You can check the \nServiceAccount, Role, and RoleBinding \nresources that are needed for this \nApiServerSource resource to work at https://\ngithub.com/salaboy/platforms-on-k8s/blob/\nmain/chapter-9/dora-cloudevents/ \napi-serversource-deployments.yaml.\nAs defined before, this source is \ninterested in resources of type Event. \n\n\n262\nChapter 9  Measuring your platforms\n sink: \n   ref:\n     apiVersion: v1\n     kind: Service\n     name: cloudevents-raw-service\n     namespace: dora-cloudevents\nAs you can imagine, the ApiServerSource will generate tons of events, which are sent \nto cloudevents-raw-service and stored in the PostgreSQL database. More complex \nrouting and filtering can be configured only to forward events that interest us, but we \ncan also apply filtering in the next stages, allowing for an approach that can enable \nus to add more metrics as we evolve our data collection process. With this source, we \nwill receive one or more CloudEvents and store them in the database whenever a new \ndeployment resource is created, modified, or deleted. \nIf you have a system already producing events but need CloudEvents, you can \ncreate your own Custom Knative Eventing event source. Look at the following tuto-\nrial for more information on how to do this: https://knative.dev/docs/eventing/\ncustom-event-source/custom-event-source/. \nThe big advantage of declaring and managing your event sources using Knative \nEventing event sources is that you can query your sources as any other Kubernetes \nresource, monitor and manage their state, and troubleshoot when problems arise using \nall the tools available in the Kubernetes ecosystem. Once CloudEvents are stored in our \ndatabase, we can analyze them and map them into CDEvents for further calculations. \n9.2.5\t\nData transformation to CDEvents\nNow that we have CloudEvents in our PostgreSQL database, we have validated that \nthey are valid CloudEvents. We want to transform some of these very generic Cloud \nEvents into CDEvents, which we will use to calculate our metrics. \nAs explained in the introduction, these transformations will depend on what kind of \nmetrics you are trying to calculate. For this example, we will look into internal Kuberne-\ntes events related to deployment resources to calculate the deployment frequency met-\nric, but completely different approaches can be used. For example, instead of looking \ninto Kubernetes internal events, you can look into ArgoCD events or Tekton Pipeline \nevents to monitor when deployments are triggered but from outside the cluster. Fig-\nure 9.11 shows the mapping and transformation process that needs to happen to map \nCloudEvent to CDEvents.\nIn the sink section, we define where we want to send the CloudEvents generated from this \nsource. In this case, we use a service reference to a Kubernetes Service named \ncloudevents-raw-service, which lives in the four-keys namespace. Knative Sources, when \nreferencing other Kubernetes resources, will check that these resources exist and only be \nready when the target service is found. Alternatively, we can point to a URI if the service \ndoesn’t live in the Kubernetes API context, but we lose this valuable check that can help us \nto troubleshoot scenarios where we are sending events to a non-existing endpoint.\n\n\n\t\n263\nHow to measure our platform: CloudEvents and CDEvents\nData \nTransformation\nDatabase\nDatabase\nFigure 9.11    \nMapping and \ntransforming from \nCloudEvents to \nCDEvents\nWe need a way to map a very generic CloudEvent to a concrete CDEvent that indi-\ncates that a service deployment has happened or has been updated. This mapping and \ntransformation logic can be written in any programming language as we only deal with \nCloudEvents and CDEvents. Because of the volume of events we might be receiving, it \nis essential not to block and process all the events as they arrive. For this reason, a more \nasynchronous approach has been chosen here. The data transformation logic is sched-\nuled at fixed periods, which can be configured depending on how often we want/can \nprocess the incoming events. \nFor this example, we will map and translate incoming events with type equal to \ndev.knative.apiserver.resource.add and data.InvolvedObject.Kind equal to \nDeployment to CDEvents of the type dev.cdevents.service.deployed.0.1.0. This \ntransformation is particular to our needs because it correlates events from the Knative \nAPIServerSource to those defined in the CDEvents specification, as shown in figure \n9.12. \nType = \"dev.knative.apiserver.resource.add\"\nData Transformation\nType = dev.cdevents.service.deployed.0.1.0\ndata.InvolvedObject.Kind = \"Deployment\"\nFigure 9.12    Concrete mapping and CDEvent creation for deployments\nTo calculate different metrics, we will need more of these transformations. One option \nwould be to add all the transformation logic into a single container. This approach \nwould allow us to version all the transformations together as a single unit, but at the \nsame time, it can complicate or limit teams writing new transformations, because they \nhave a single place to change code. An alternative that we can take is to use a func-\ntion-based approach, we can promote the creation of single-purpose functions to do \nthese transformations. By using functions, only functions that are currently transform-\ning events will be running. All the ones that are not being used can be downscaled. If \nwe have too many events to process, functions can be upscaled on demand based on \ntraffic.\n\n\n264\nChapter 9  Measuring your platforms\nDeployment Transformation Function\ndev.cdevents.service.deployed.0.1.0\nPipeline Finished Function\ndev.cdevents.pipelinerun.finished.0.1.0\nChange Transformation Function\ndev.cdevents.change.created.0.1.1\nCDEvents \nEndpoint\nDB \nDB \nData \nTransformation \nRouter\nFigure 9.13    Using functions to map CloudEvents to CDEvents\nAs shown in figure 9.13, a new component is needed to route the CloudEvents being \nread from the database to concrete functions. Each transformation function can trans-\nform the incoming CloudEvent by inspecting its payload, enriching the content with \nan external data source, or simply wrapping the entire CloudEvent into a CDEvent. \nThe data transformation router component must be flexible enough to allow new \ntransformation functions to be plugged into the system and multiple functions to pro-\ncess the same event (the same CloudEvent being sent to one or more transformation \nfunctions). \nTransformation and mapping functions don’t need to care about how the CDEvents \nwill be persisted. This allows us to keep these functions simple and focused on transfor-\nmations only. Once the transformation is done and a new CDEvent is produced, the \nfunction will send the event to the CDEvents endpoint component, which stores the \nCDEvent in our database.  \nBy the end of the transformations, we will have zero or more CDEvents stored in our \ndatabase. These CDEvents can be used by the metric calculation functions that we will \nlook at in the following section.  \n9.2.6\t\nMetrics calculation\nTo calculate our metrics (DORA or custom metrics), we will use the same func-\ntion-based approach we used for the CDEvents transformation and mapping. In \nthis case, we will write functions to calculate different metrics. Because each metric \nrequires aggregating data from different events and maybe systems, each metric cal-\nculation function can implement a different logic, see figure 9.14. The mechanisms \nused to calculate a metric are up to the developers who write the code to perform the \ncalculation.\n\n\n\t\n265\nHow to measure our platform: CloudEvents and CDEvents\nTime To Restore Service\nFunction\nChange Failure Rate\nFunction\nLead Time for Change\nFunction\nDeployment Frequency \nFunction\nDB\nDB\nFigure 9.14    Using functions to calculate DORA metrics\nTo calculate metrics, each function can be configured to fetch very specific CDEvents \nfrom the database and with different periods depending on how often we need to get \nupdates for a particular metric. The metric result can be stored in the database or sent \nto an external system, depending on what you want to do with the calculated data. \nIf we look at calculating the deployment frequency metric for a more concrete exam-\nple, we need to implement a couple of custom mechanisms and data structures to keep \ntrack of the metric, as in figure 9.15.\nselect from \n`cdevents_raw` where \ntype=’dev.cdevents.\nservice\n.deployed.0.1.0’\nCreate Deployments \nstructure Function\ninsert into \ndeployments …\nselect from \ndeployments \n(by day and service)\nGet Deployment \nFrequency Function\nCustom Metric calculation functions\nDB\nDB\nDB\nDashboard\n#1\n#2\n#3\nFigure 9.15    Deployment frequency calculation flow\nA simplified flow for calculating the deployment frequency metric is shown in figure \n9.15 where step #1 is to get CDEvents related to deployments from the cdevents_\nraw table. The Create Deployments structure function is in charge of reading \nCDEvents with type dev.cdevents.service.deployed.0.1.0, inspecting the pay-\nload and metadata, and creating a new structure that can be later queried. Step #2 \nis responsible for persisting this new structure in our database. The main reason for \nthis structure is to make our data easier and more performant to query for the metric \n\n\n266\nChapter 9  Measuring your platforms\nwe are implementing. In this case, a new deployment structure (and table) is created \nto record data we want to use to calculate our deployment frequency metric. For this \nsimple example, the deployment structure contains the service’s name, the timestamp, \nand the deployment’s name. In step #3 we can use this data to get our deployment \nfrequency by service and display this information per day, week, or month. These func-\ntions need to be idempotent, meaning that we can retrigger the calculation of the met-\nrics again using the same CDEvents as input, and we should obtain the same results.\nOptimizations can be added to this flow; for example, a custom mechanism can be \ncreated to avoid reprocessing CDEvents that have already been processed. These cus-\ntomizations can be treated as internal mechanisms for each metric, and developers \nshould be able to add integration with other systems and tools as needed. For the sake \nof the example, the Get Deployment Frequency Function can fetch the metrics from \nthe database. Still, in a more realistic scenario, you can have a dashboard directly que-\nrying the database where the simplified structures are stored, because many dashboard \nsolutions provide an SQL connector out of the box. \nNow that we have covered the flow to calculate the deployment frequency metric \nlet’s look at a working example where we will install all the components required for \ndata collection, data transformation, and metrics calculation.\n9.2.7\t\nWorking example\nThis section will look at a working example, showing how we can combine data col-\nlection, data transformation to CDEvents, and metrics calculation for our Kuberne-\ntes-based platforms. It covers a very basic example and a step-by-step tutorial on how to \ninstall and how to run the components needed to calculate the deployment frequency \nmetric of our deployments (https://github.com/salaboy/platforms-on-k8s/blob/\nmain/chapter-9/dora-cloudevents/README.md).\nThe architecture implemented in this example puts together the stages defined in \nthe previous sections: data collection, data transformation, and metrics calculation. \nOne of the main aspects covered by this architecture is the extensibility and pluggabil-\nity of components for data transformation and metrics calculation. This architecture \nassumes that we will collect data as CloudEvents, so the user is responsible for trans-\nforming their event sources to CloudEvents to use this architecture.\nFigure 9.16 shows how all the components are tied together to provide the function-\nality of deciding which events we want to collect and how to transform them into CDE-\nvents so we can calculate DORA metrics with them. \n\n\n\t\n267\nHow to measure our platform: CloudEvents and CDEvents\nCloudEvent to \nCDEvent Transformer\n<Function>\nTimer \nbased\nprotected\nTimer \nbased\nregistry/ \nmapping\nRouter\n* Allows for custom mechanism to keep \ntrack and optimize metrics calculation\nCloudEvent Source\n(GitHub)\nCloudEvent Source\n(Tekton)\nCloudEvent Source\n(Kubernetes)\nCDEvents Endpoint\nCloudEvents Endpoint\nMetrics Endpoints\nDashboard\nGet Metric*\n<Function>\nMetric Calculation\n<Function>\n**Metrics**\ncdevents_raw \nTable\ncloudevents_raw \nTable\nFigure 9.16    Example architecture for capturing and calculating DORA metrics\nWhile the architecture might look complicated initially, it was designed to allow custom \nextensions and mappings necessary to collect and process events from various sources. \nFollowing the step-by-step tutorial, you will create a new Kubernetes cluster to install \nall the components needed to collect CloudEvents and calculate the metrics. Still, the \narchitecture is in no way limited by a single cluster. After you create and connect to \na cluster, you will install tools such as Knative Serving for our function’s runtime and \nKnative Eventing only for our event sources. Once the cluster is ready, you will create a \nnew namespace to host all the components actively processing the data collected and \nan instance of PostgreSQL to store our events.\nStoring events and metrics\nOnce we have our database to store events and metrics information, we need to create \nthe tables for our components to store and read events. For this example, we will create \nthe following tables: cloudevents_raw, cdevents_raw, and deployments, as shown \nin figure 9.17.\n",
      "page_number": 274
    },
    {
      "number": 24,
      "title": "Segment 24 (pages 287-295)",
      "start_page": 287,
      "end_page": 295,
      "detection_method": "topic_boundary",
      "content": "268\nChapter 9  Measuring your platforms\n`cloudevents_raw`\n`cdevents_raw`\n`deployments`\n`event_timestamp` TIMESTAMP NOT NULL\n`cd_subject_id` varchar(255) NOT NULL\n`event_id` serial NOT NULL\n`content` json NOT NULL\n`deploy_id` varchar(255) NOT NULL\n`time_created` TIMESTAMP NOT NULL\n`deploy_name` varchar(255) NOT NULL\n`cd_type` varchar(255) NOT NULL\n`cd_timestamp` TIMESTAMP NOT NULL\n`cd_source` varchar(255) NOT NULL\n`cd_id` varchar(255) NOT NULL\n`cd_subject_source` varchar(255)\n`content` json NOT nuLL\nFigure 9.17    Tables, CloudEvents, CDEvents, and metrics calculations\nLet’s look at what information we are going to be storing in these three tables. The \ncloudevents_raw table stores all the incoming CloudEvents from different sources. \nThe main purpose of this table is data collection:\n¡ The schema of this table is very simple and only has three columns:\n–\t event_id: This value is generated by the database.\n–\t event_timestamp: Stores the timestamp of when the event is received. This \ncan be later used to order events for reprocessing.\n–\t content: Stores the serialized JSON version of the CloudEvent in a JSON \ncolumn.\n¡ This table is kept as simple as possible because we don’t know what kind of cloud \nevents we are getting, and at this point, we don’t want to unmarshal and read the \npayload, because this can be done in the data transformation stage.\nThe cdevents_raw table stores all the CDEvents we are interested in storing after fil-\ntering and transforming all the incoming CloudEvents. Because CDEvents are more \nspecific, and we have more metadata about these events, this table has more columns: \n¡ cd_id: Stores the CloudEvent ID from the original CloudEvent.\n¡ cd_timestamp: Stores the timestamp of when the original CloudEvent was \nreceived.\n¡ cd_source: Stores the source where the original CloudEvent was generated.\n¡ cd_type: Stores and allows us to filter by different CDEvents types. The types of \nCDEvents stored in this table are defined by the transformation functions run-\nning in our setup. \n¡ cd_subject_id: Stores the ID of the entity associated with this CDEvent. This \ninformation is obtained when our transformation functions analyze the content \nof the original CloudEvent.\n¡ cd_subject_source: Stores the source of the entity associated with this \nCDEvent. \n¡ content: The JSON serialized version of our CDEvent, which includes the origi-\nnal CloudEvent as a payload.\n\n\n\t\n269\nHow to measure our platform: CloudEvents and CDEvents\nThe deployments table is custom to calculate the deployment frequency metric. There \nare no rules to what you store in these custom tables that are used to calculate different \nmetrics. For the sake of simplicity, this table only has three columns:\n¡ deploy_id: The id used to identify a service deployment.\n¡ time_created: When the deployment was created or updated.\n¡ deploy_name: The deployment name used to calculate the metrics.\nOnce we have the tables ready to store our events and metrics data, we need to have \nevents flowing into our components, and for that, we will need to configure event \nsources.\nConfiguring event sources\nFinally, before installing the data transformation or metrics calculation functions, we \nwill configure the Kubernetes API Server event source from Knative Eventing to detect \nwhen new deployments are being created. See figure 9.18.\nKnative Eventing \nAPI Server Source\nKubernetes Cluster\nKubernetes \nEvent Stream\nDeployment\nDeployment\nDeployment\nWorkloads\nFigure 9.18    Example using the Knative Eventing API server source. We can tap into Kubernetes \nEvent Stream by using the Knative Eventing API Server Source, which transforms internal events into \nCloudEvents that can be routed to different systems for filtering and processing.\nHere, you can use any CloudEvent-enabled data source. The Knative API server source \nis an example of how easy it is to consume and route events for further processing. \nCheck projects like Argo Events (https://argoproj.github.io/argo-events/) and \nother Knative Eventing sources (https://knative.dev/docs/eventing/sources/) to \nfamiliarize yourself with what is available out of the box. Also, check the CloudEvents \nspecification adopters list (https://cloudevents.io/), because all these tools are already \ngenerating CloudEvents that you can consume and map to calculate metrics.\nDeploying data transformation and metrics calculation components\nNow that we have a place to store our events and metrics data, and event sources are con-\nfigured and ready to emit events when users interact with our cluster, we can deploy the \ncomponents that will take these events, filter them, and transform them to calculate our \ndeployment frequency metric. The step-by-step tutorial deploys the following components:\n\n\n270\nChapter 9  Measuring your platforms\n¡ CloudEvents endpoint: Exposes an HTTP endpoint to receive CloudEvents and \nconnects to the database to store them.\n¡ CDEvents endpoint: Exposes an HTTP endpoint to receive CDEvents and connects \nto the database to store them.\n¡ CloudEvents router: Reads CloudEvents from the database and routes them to the \nconfigured transformation functions. This component allows users to plug their \ntransformation functions to transform a CloudEvent into a CDEvent for further \nprocessing. The CloudEvents router runs periodically by fetching unprocessed \nevents from the database.\n¡ (CDEvents) transformation function: Users can define transformation functions and \nmap CloudEvents to CDEvents. The idea here is to enable users to add as many \nfunctions as needed to calculate DORA and other metrics.\n¡ (Deployment frequency) calculation function: Metrics calculation functions provide a \nway to calculate different metrics by reading CDEvents from the database. These \nfunctions can store the calculated metrics in custom database tables if needed.\n¡ (Deployment frequency)  metric endpoint: These metric endpoints can be optionally \nexposed for applications to consume the calculated metrics. Alternatively, dash-\nboards can query the data directly from the database.\nFigure 9.19 shows how CloudEvents flows throughout the different components that \nwe have installed.\nCloudEvents Endpoint\nHTTP\nHTTP\nHTTP\nMetrics \nConsumer\nCloudEvents Router\nTransformation Function\nCDEvents Endpoint\nCalculation Function\nMetric Endpoint\nCloudEvents\nData Sources\nDB\nDB\nDB\nFigure 9.19    Data flows from Data Sources producing CloudEvents to the CloudEvents endpoint whose \nonly mission is to store these events into the Event Store. From there, the CloudEvents Router have the \nlogic to decide where to route events to transformation functions, which allows us to map CloudEvents \nto CDEvents for further processing. Once we have CDEvents, the Calculation Functions can read these \nevents to aggregate data and produce metrics. Metrics consumers can get the metrics by interacting \nwith the Metric Endpoint, which will fetch the calculated metrics from the metrics database.\n\n\n\t\n271\nHow to measure our platform: CloudEvents and CDEvents\nAs soon as we have our components up and running, we can start using our cluster to \ngenerate events filtered and processed by these components to produce the deploy-\nment frequency metric.\nDeployment frequency metric for your deployments\nWe need to deploy new workloads to our cluster to calculate the deployment frequency \nmetric. The tutorial includes all the transformation and metric calculation functions \nto monitor events coming from deployment resources. \nWhile development teams can create and update their existing deployments, the \nplatform team can transparently monitor how efficient the platform is to enable teams \nto perform their work. Figure 9.20 shows the teams involved and how the metrics are \ncalculated for this example.\nI have all the tools \nto efficiently deploy  \nmy workloads\nI can monitor \nhow much \nimpact new \ntools have on \ndifferent teams’ \nproductivity.\nApp Dev \nTeams\nPlatform \nTeam\nKnative Eventing \nAPI Server Source\nKubernetes \nEvent Stream\nDeployment\nWorkloads\nFour Keys\nMetrics Endpoint\nCloudEvents Endpoint\nKubernetes Cluster\nFigure 9.20    Components and data flow to measure performance metrics\nFinally, you can curl the following endpoint if you are running the example on KinD: \n> curl http://dora-frequency-endpoint.dora-cloudevents.127.0.0.1.sslip.io/ \n➥deploy-frequency/day | jq\nYou should see something like the following listing.\nListing 9.2    Getting deployment frequency metrics\n[\n   {\n      \"DeployName\":\"nginx-deployment-1\",\n      \"Deployments\":3,\n      \"Time\":\"2022-11-19T00:00:00Z\"\n   },\n   {\n      \"DeployName\":\"nginx-deployment-3\",\n      \"Deployments\":1,\n      \"Time\":\"2022-11-19T00:00:00Z\"\n   }\n]\n\n\n272\nChapter 9  Measuring your platforms\nTransformation and metrics calculation functions are scheduled to run every minute. \nHence, these metrics will be only returned after the functions have been executed. \nAlternatively, you can use a dashboard solution like Grafana to connect to our Post-\ngreSQL database and configure the metrics. Dashboard tools can be focused on the \ntables that store data about particular metrics. For our deployment frequency exam-\nple, the deployments table is the only one relevant for displaying the metrics. \nI strongly recommend you check the example and try to run it locally, follow the \nstep-by-step tutorial, and get in touch if you have questions or want to help improve \nit. Modifying the example to calculate the metrics differently or adding your custom \nmetrics will give you a good overview of how complex these metrics calculations are but, \nat the same time, how important it is to have this information available to our applica-\ntion development and operations teams so they can understand how things are going \nalmost in real-time.  \nIn the next section, we will look at the Keptn Lifecycle Toolkit (https://keptn.sh), \nan open-source and CNCF project that built different mechanisms not only to moni-\ntor, observe, and calculate metrics about our cloud-native applications, but also to take \nactions when things are not going as expected or with integrations with other systems \nare needed. \n9.3\t\nKeptn Lifecycle Toolkit\nThe Keptn Lifecycle Toolkit (KLT) is a cloud-native lifecycle orchestration toolkit. KLT \nfocuses on deployment observability, deployment data access, and deployment check \norchestration. Keptn is not only all about monitoring and observing what is going on \nwith our workloads, but it also provides the mechanisms to check and act when things \ngo wrong.\nAs we saw in the previous section, getting basic metrics such as deployment frequency \ncan be very useful in measuring teams’ performance. While deployment frequency is \njust one metric, we can use that to start measuring our early platform initiatives. In this \nshort section, I wanted to show how KLT can help you with this task by following a differ-\nent but complementary approach to the one discussed in section 9.2.\nKeptn extends the Kubernetes Scheduler component (which decides where our \nworkloads will run on our clusters) to monitor and extract information about our \nworkloads, as in figure 9.21. This mechanism enables teams to set up custom pre/post-­\ndeployment tasks by providing Keptn Task Definitions resources. Keptn is planning to \nuse Kubernetes built-in scheduling gates, a feature that, at the time of writing, is being \nproposed to the Kubernetes community (http://mng.bz/PRW2). \nNOTE  You can follow a step-by-step tutorial to see Keptn in action by following \nthis link: https://github.com/salaboy/platforms-on-k8s/blob/main/chapter-9/ \nkeptn/README.md.\n\n\n\t\n273\nKeptn Lifecycle Toolkit\nGrafana Dashboards\nKeptn Task \nDefinition\nMetrics\nTraces\nPrometheus\nJaeger\nKeptn\nDeployment\nDeployment\nDeployment\nObservability\nKubernetes \nScheduler\nPre/Post Hooks\nFigure 9.21    \nKeptn architecture \nproviding \nout-of-the-box \nobservability \nand application \nlifecycle hooks.\nKeptn uses standard Kubernetes annotations to identify which applications are inter-\nested in being monitored and managed. I have included the following annotations \nfor the Conference application to make Keptn aware of our services. The Agenda ser-\nvice deployment resource includes the following annotations, as shown in listing 9.3 \n(https://github.com/salaboy/platforms-on-k8s/blob/main/conference-application/\nhelm/conference-app/templates/agenda-service.yaml#L14).\nListing 9.3    Kubernetes standard application annotations\napp.kubernetes.io/name: agenda-service\napp.kubernetes.io/part-of: agenda-service\napp.kubernetes.io/version: v1.0.0\nKeptn is now aware of the Agenda service and can monitor and execute actions related \nto this service lifecycle. Notice the part-of annotation, which allows us to monitor sin-\ngle services and group a set of services under the same logical application. This group-\ning allows Keptn to execute pre/post-deployment actions for each service and the \nlogical application (a group of services sharing the same value for the app.kubernetes \n.io/part-of annotation. This example doesn’t use that feature because I want to \nkeep things simple and focused on single services. \nThe step-by-step tutorial installs Keptn, Prometheus, Grafana, and Jaeger so we can \nunderstand what Keptn is doing. Once Keptn is installed in your cluster, you need to \nlet Keptn know which namespaces should be monitored, by annotating the namespace \nresources with a Keptn annotation. You can do that by running the following command \nto enable Keptn in the default namespace: \nkubectl annotate ns default keptn.sh/lifecycle-toolkit=\"enabled\"\nOnce Keptn starts monitoring a specific namespace, it will look for annotated deploy-\nments to start getting metrics that the Keptn Applications Grafana dashboards can \nconsume, as shown in figure 9.22.\n\n\n274\nChapter 9  Measuring your platforms\nFigure 9.22    \nKeptn Application \nGrafana \ndashboard for \nthe notifications \nservice\nThis dashboard shows us our deployment frequency for the annotated deployments \n(all the Conference application’s services) running in the default namespace. In the \nstep-by-step tutorial, we make changes to the notification service deployment so Keptn \ncan detect the change and show the new version in the dashboard. As shown in figure \n9.22, the average time between deployments is 5.83 minutes. On the side, you can see \nexactly how long it took to deploy v1.0.0 and v1.10. Having these dashboards avail-\nable to the teams responsible for each service can help provide visibility on the whole \nprocess of releasing new versions. Having this information available from day one can \nshow progress on how teams improve their workflows or find bottlenecks and recur-\nring problems that can be easily fixed. \nBesides gaining all this information and out-of-the-box metrics, as mentioned before, \nKLT goes one step further by providing hook points to execute pre-/post-­deployment \ntasks. We can use these tasks to validate the environment’s state before performing \na release, send notifications to the teams on call, or just audit the process. After the \ndeployment, we can use post-deployment hooks to run validation tests, send automated \nnotifications to customers about the update, or just congratulate the team for their \namazing work. \nKeptn introduces the KeptnTaskDefinitions resource, which supports Deno \n(https://deno.land/), Python3, or any container image reference (https://lifecycle \n.keptn.sh/docs/yaml-crd-ref/taskdefinition/) to define what the task behavior. The \nKeptnTaskDefinition resource used by the step-by-step tutorial is quite simple, and it \nlooks like listing 9.4. \n\n\n\t\n275\nKeptn Lifecycle Toolkit\nListing 9.4    Keptn TaskDefinition using Deno\napiVersion: lifecycle.keptn.sh/v1alpha3\nkind: KeptnTaskDefinition\nmetadata:\n  name: stdout-notification\nspec:\n  function:\n    inline:\n      code: |\n        let context = Deno.env.get(\"CONTEXT\"); \n        console.log(\"Keptn Task Executed with context: \\n\");\n        console.log(context);\nTo bind a task definition with one of our services, we use a Keptn-specific annotation in \nour deployments: \n keptn.sh/post-deployment-tasks: stdout-notification\nThis annotation will configure Keptn to execute this task after the notification ser-\nvice deployment is changed and the new version is deployed. Keptn will create a new \nKubernetes Job to run the KeptnTaskDefinition. This means you can query all the \npre-/post-deployment task definition executions by looking at the job executions in \nthe default namespace. \nBy using annotations and KeptnTaskDefinitions, the platform engineering team can \ncreate a library of shared tasks that teams can reuse in their workloads, or even better, \nthey can use mutation webhooks or a policy engine like OPA to automatically mutate \nthe deployment resources to add the Keptn annotation. \nIf you change the notification service deployment and then tail the logs, you should \nsee the following (listing 9.5). \nListing 9.5    Expected output from the TaskDefinition execution\nKeptn Task Executed with context: \n{\n  \"workloadName\":\"notifications-service-notifications-service\",\n  \"appName\":\"notifications-service\",\n  \"appVersion\":\"\",\n  \"workloadVersion\":\"v1.1.0\",\n  \"taskType\":\"post\",\n  \"objectType\":\"Workload\"\n}\nThe team will use this resource \nname to define where this task \nwill be executed. This is a \nreusable task definition, so this \ncan be called from different \nservices’ lifecycle hooks.\nWe can access the context of the task that is being executed \nby calling Deno.env.get(\"CONTEXT\"). This provides us with \nall the details used to create the task, such as which \nworkload requests this task to be executed.\n\n\n276\nChapter 9  Measuring your platforms\nIf you look at Jaeger in figure 9.23, you can see all the steps involved in deploying a new \nversion of our notification service by looking at the Keptn Lifecycle Operator traces.\nFigure 9.23    Keptn Lifecycle Operator traces for service updates\nIf you run the step-by-step tutorial on your environment, you can see that the post-de-\nployment hook is being scheduled after the new version of the service is up and \nrunning. \nIn this short section, we have learned the basics of what the Keptn Lifecycle Toolkit \ncan do for us, how we can benefit from having these metrics from day one, and how we \ncan have more control over the lifecycle of our services by adding pre-/post-deployment \ntasks using a declarative way. \nI strongly recommend you check the Keptn website and other more advanced \nmechanisms that they provide, such as Evaluations (https://lifecycle.keptn.sh/ \ndocs-klt-v0.8.1/concepts/evaluations/), which allows us to make decisions and even \ngate deployments that are not meeting certain requirements, such as increased mem-\nory consumption or too much CPU usage. \nWhile Keptn uses a completely different approach from the one described in section \n9.2, I strongly believe these approaches are complementary. I hope to see further inte-\ngrations between Keptn and CloudEvents. If this topic interests you, I encourage you to \njoin the conversation at https://github.com/keptn/lifecycle-toolkit/issues/1841. \n9.4\t\nWhat’s next on the platform engineering journey?\nThe examples covered in this chapter highlighted the importance of measuring \nour technical decisions. In a good or bad way, each decision will affect all the teams \ninvolved in delivering software. \nThese metrics built into our platforms can help us measure improvement and justify \ninvesting in tools that facilitate our software delivery practices. If we want to include a \n",
      "page_number": 287
    },
    {
      "number": 25,
      "title": "Segment 25 (pages 296-303)",
      "start_page": 296,
      "end_page": 303,
      "detection_method": "topic_boundary",
      "content": "\t\n277\nWhat’s next on the platform engineering journey?\nnew tool in our platform, you can test your assumptions and measure the effect of each \ntool or adopted methodology. It is quite a common practice to have these metrics acces-\nsible and visible for all your teams, so when things go wrong or a tool is not working as \nexpected, you will have hard evidence to back up your claims.\nFrom a platform engineering perspective, I strongly recommend not leaving this \ntopic until the end (as I did with this chapter in the book). Using tools like KLT, you \ncan gain insights with a small investment and use standard monitoring techniques that \nare well-understood in the industry. Looking into CloudEvents and CDEvents is worth \nit, not only from a monitoring and metrics calculation perspective, but also for event-\ndriven integrations with other tools and systems. Figure 9.24 shows that by tapping into \nevent sources from the tools that we are using in our golden paths, we can keep our \nteams informed about their decisions affect the entire software delivery chain.\nTapping into events from \nGolden Paths or standard \nworkflows provided by the \nplatform gives teams great \ninsights about where \nbottlenecks are and how \nthese can be improved. \nProduction Environment\nStandard Application-level APIs\nTransparent Security and Observability\nContainers-as-a- \nService\nFunctions-as-a- \nService\nMetrics and Release \nDashboards\nObservability\nRelease Gates and \nMonitoring\nSource \nCode\nContainer \nRegistry\nChecks & \nVerification\nGolden Paths\nPlatform\nPipelines\nFigure 9.24    Golden paths and workflows provided by our platform are the best source of raw information for \ncalculating the team’s performance metrics.\nEnsuring that the basic metrics for your platform can be calculated will help your \nteams to think about end-to-end flows for each release—where the bottlenecks are and \nwhere they spend or waste most of their time. If the DORA metrics are too hard for \nyour organization to implement, you can focus on measuring your platform’s golden \npaths or main workflows. For example, based on the examples provided in chapter 6, \nyou can measure how much time it takes to provision a development environment, \nwhich capabilities are provided, and how often the team requests new instances, as \nshown in figure 9.25. \n\n\n278\nChapter 9  Measuring your platforms\nPlatform\nMetrics and Release \nDashboards\nRelease Gates and \nMonitoring\nObservability\nDevelopment Environment \nGolden Path\n \nDevelopment Environment\nConference Application\nDevelopment \nTeam\nHow often do teams request\nnew environments? How long \ndo they need to wait for the\nenvironment to be ready? \nHow long are these\nenvironment up and running?     \nFigure 9.25    Platform and application walking skeleton metrics\nBy collecting metrics, not only from customer applications but also from platform-spe-\ncific workflows, like creating development environments, your teams will have full visi-\nbility of the tools they are using and how the changes in the tool affect and unlock the \nvelocity of software delivery. Figure 9.26 shows a recap of our platform journey and \nhow important these metrics are for our platform teams. Remember, if you are measur-\ning your platform initiatives, your platforms will get better.\nEnvironments \nConfiguration \nRepository\nContainer \nRegistry\nOur Platform\nPlatform APIs\nMetrics Dashboard\nEvery platform component can contribute with \ndata to calculate platform metrics that enable \nthe platform team to measure the success of \ndifferent platform initiatives and workflows.\nGitOps Sync\nProvisioning \nCloud Resources\nService Pipelines\nRelease \nStrategies\nFeature Flags \nDashboard\nEnvironment\nApplication-Level \nAPIs\nApplication V1\nManages\nFigure 9.26    \nTapping into \nplatform \ncomponents \nto collect data \nand calculate \nmetrics\n\n\n\t\n279\nFinal thoughts\n9.5\t\nFinal thoughts\nI hope that going through the examples of this book has given you enough hands-on \nexperience to tackle real-life challenges. While the examples covered here are not \nexhaustive or deep in detail, the intention is to show a wide range of topics that plat-\nform engineering teams must deal with. The cloud-native space is constantly evolving, \nand the tools I evaluated when I started writing this book have completely changed in \ntwo years, pushing teams worldwide to be very flexible about their decisions. Making \nmistakes and reviewing decisions is part of the day-to-day work that platform engineers \nmust do for small and large organizations. \nGoing back to the beginning of this book, platform engineers must encapsulate all \nthese decisions behind platform APIs that they can maintain and evolve, so understand-\ning the capabilities needed by different teams is key to having a successful platform \nengineering journey. Providing self-service capabilities and focusing on what your \nteams need should be heavy influencers on the platform engineers’ priority lists. \nUnfortunately, I don’t have an unlimited number of pages or unlimited time to keep \nadding content to this book, but I did my best to include the topics and challenges I’ve \nseen organizations and communities facing while working in the cloud-native space. \nWe have reached a point in the Kubernetes ecosystem where tools are maturing, and \nmore projects are graduating, indicating that more and more companies are reusing \ntools instead of building their own. \nI’ve intentionally omitted topics such as extending Kubernetes with custom control-\nlers, because balancing what is built in-house for your platforms needs to be carefully \ndefined by platform engineering teams. Creating and maintaining your extensions \nshould be left to very special cases where no tools exist to solve a problem you are try-\ning to solve. For the most common cases, as we have seen in this book, CI/CD, GitOps, \ninfrastructure provisioning in the cloud, developer tools, platform-building tools, and \nother tools are mature enough for you to use and extend if necessary.\nIt was quite hard to leave topics such as service meshes, policy engines, observability, \nincident management, operations tools, and cloud development environments out of \nthis book. There are wonderful projects that would require entire chapters to cover. But \nas a platform engineer, you must keep researching and keeping an eye on the cloud-na-\ntive communities to see where new developments and projects can help your organiza-\ntion’s teams. \nI strongly recommend you engage with your local Kubernetes communities and be \nactive in the open-source ecosystem. This not only gives you a great playground to learn, \nbut it also helps you to make the right informed decisions about which technologies to \nadopt. Understanding how strong the communities behind these projects are is key \nto validating that they are solving a problem that first needs a solution and is common \nenough to be solved in a generic (non-organization) specific way. Tools like OSS Insight \n(https://ossinsight.io/) provide enormous value for decision-making and ensure that \nif you invest time and resources in an open-source project, an active community will \nmaintain your changes and improvements. \n\n\n280\nChapter 9  Measuring your platforms\nFinally, keep an eye on my blog (https://salaboy.com), because further articles \nrelated to the book will be published to explore other topics that I consider important \nfor platform engineering teams. If you are interested in contributing to open-source, \nexpanding or fixing the examples provided in the book is a great way to get hands-on \nexperience with all the tools most open-source projects use.  \nSummary\n¡ Using DORA metrics gives you a clear picture of how the organization delivers \nsoftware in front of your customers. This can be used to understand bottlenecks \nresulting in improvements on the platforms we are building. Using the team’s \nperformance metrics based on our software delivery practices will help you \nunderstand how your platform initiatives affect how teams’ work and the benefits \nto the overall organization. \n¡ CloudEvents standardize how we consume and emit events. Over the last couple \nof years, we have seen a rise in the adoption of CloudEvents by different projects \nin the CNCF landscape. This adoption allows us to rely on CloudEvents to get \ninformation about components and other systems that we can aggregate and col-\nlect helpful information that can be used for decision-making. \n¡ CDEvents provides a CloudEvents extension, a set of more specific CloudEvents \nrelated to continuous delivery software practices. While I expect the adoption of \nCDEvents to grow over time, we have seen how to map CloudEvents to CDEvents \nto calculate the DORA metrics. By using CDEvents as the base model to calculate \nthese metrics, we can map any event source to contribute to the calculations of \nthese metrics. \n¡ If we can measure our platform, we will know what needs improvement and \nwhere the organization struggles with its delivery practices. This feedback loop \nprovided by the metrics gives valuable information to platform teams in charge \nof continuously improving the tools and processes our teams use daily. \n¡ If you followed this chapter’s step-by-step tutorials, you gained hands-on experi-\nence with setting CloudEvent sources, monitoring deployments, and how CDE-\nvents can help standardize information about our software delivery lifecycle. You \nalso installed Keptn as a different approach to monitor your workloads and exe-\ncute pre-/post-deployment tasks to validate that newer versions are working as \nexpected. \n\n\n281\nindex\nA\nabstracting complexity  25\nof storage and \nimplementation  200\nwhile building platforms  13\nabstractions\nachieving by Crossplane \ncompositions  133\ndefining for cloud \nproviders  133\nhigher-level, creating  153, 200\nhigher-level, providing  217\nself-service  154\nA/B testing\ndrawbacks of installing using \nbuilt-in Kubernetes \nresources  216\nof user interfaces  223\noverview  214–215\nvs. canary releases and blue/\ngreen deployments  214\nwith header-based \nrouting  226–227\nwith tag-based routing  223\nAgenda page\nempty  37\nwith cache entry  54\nwith proposals  38\nAgenda service\naccessing  48\nacessing Dapr components  201\nConference application  21\nno pods for  54\nNoSQL database for  125\npersistent storage, need for  36\nscaling up  55\ntoo many requests  130\nAnalysisTemplates  244\nAPI-first approach\nadvantages of  10\nexplained  6\napplication development teams \n(App Dev Teams). See also \nsoftware development \nteams\nconnected to platform API  172\ninteracting with platforms  158\nresponsibilities  174\nrole of  133\nseparating responsibilities from \nplatform engineering \nteams  190\nusefulness of platforms for  26\nworking on new features  16\napplication infrastructure\nappropriate configuration, need \nfor  130\nchallenges  124–125\ncomponents  124\ncomponents, installing and \nconnecting with \nservices  127\ndeveloping independently of \nservices  152\non demand  140\nmanaging  125–128\nprovisioning using GitOps \napproach  155\nseparating from application \ncode  206\nvs. hardware infrastructure  124\nApplication Programming \nInterfaces (APIs). See also \nKubernetes APIs; platform \nAPIs\nREST request  9\nusefulness  6\napplication services\ncalling other services  180\nconnecting with infrastructure \ncomponents  128, 151\nmaintaining and \nupgrading  129\nseparated from platform \ncapabilities  190\nusing Dapr components  201\napplication state\ndealing with  55–57\n\n\n282\nindex\nproblems if kept in memory  57\nstored externally  56\nArgo CD\nadvantages of  111\nconfiguring parameters specific \nto installation  114\ndescribed  111\ninstalling  112\nsummarized  122\nsyncing\nconfiguration changes  116\nenvironment \nconfigurations  111\nuser interface  112\nusing  231\nusing with Helm  118\nArgo CD application\nconfigured in main \nbranch  117\ncreating  112–116\nfine-tuning parameters  117\nsyncing  114, 117\nArgo Rollouts\nanalysis  244\nautomated analysis steps  236\nblue/green deployments  238–\n243\ndashboard  231, 236, 242, 243\ndefined  229\nintroduction  229\nReplicaSets, dealing with  236\nresource, creating  230\nsummarized  251\nusefulness  249\ntraffic management  247–249\nvs. Kubernetes \ndeployments  231\nartifact repository  78. See also \nrepositories\nasynchronous\napproach to data \ntransformation  265\nintegration with application \nservices  40\nmessages exchanging between \nservices  36\nauthentication  60\nand authorization flow  61\ncredentials needed for  180\nneed for  10\nautomated\napproach with Argo CD  117\nclean-up mechanism  118\ncreation of environment \nrepositories  120\nPull/Change requests  119\npulling changes in \ndeclarations  104, 107\ntests  244\nautomating\ncontainer building process  74\nentire process of building \nplatforms  63\ninfrastructural \nrequirements  57\nKubernetes deployments  63\nlack of  62\nsoftware releases flow between \nenvironments  121\nwith Jenkins  102\nautomation\ndifferent solutions, creating  70\nend-to-end  69\noptimizing end-to-end  80\npipelines  7\nB\nBack Office page  38. See also \nConference application\nDebug tab  224\nfailed services on  55\nnotifications on  39\nservice events on  40\nbackward compatibility  227\nblue/green deployments\nArgo Rollouts  238–243\ncoordination between \nteams  227\ndrawbacks of installing using \nbuilt-in Kubernetes \nresources  216\nimplementing in \nKubernetes  214\noverview  213–214\npromotion analysis  246\nrunning in parallel  214\nwith Knative Services  227–229\nwith Kubernetes resources  243\nbottlenecks  130, 255, 260\nbranches\nmain  117\nmain and feature  72, 76\nselecting  113\nseparate  112\nbrowser\nproblems with GET \nrequests  223\nrefreshing  53\nusing  36, 44, 48\nbuilding blocks\nAPIs defined in Dapr \nproject  194\nKubernetes  11, 103, 216\nproviding basic  93, 250\nbuilding platforms. See also \nKubernetes; platforms\nabstracting complexity  12, 13\nexample  18\non top of Kubernetes  13, 25, \n162\nC\nCall for Proposals (C4P) service\nacessing Dapr components  201\nConference application  21\nconnecting to PostgreSQL \ninstance  128\nflow  40\npersistent storage, need for  36\nPostgreSQL database for  125\nstored externally  56\nuse case  21\ncanary releases\nanalysis  244\ndrawbacks of installing using \nbuilt-in Kubernetes \nresources  216\nimplemented with Argo \nRollouts  230\nin Kubernetes  213\noverview  212–213\nrevision promoted to stable \nversion  237\nrouting traffic to  235\nterm, explained  212\ntraffic mirroring  248\ntraffic splitting, percentage-\nbased  221–223\n\n\n\t\n283\nindex\nusing deployment resources vs. \nArgo Rollouts  237\nCDEvents\navoiding reprocessing  268\ndescribed  258\nendpoint  272\noverview  258\nspecification  259\nstored  270\nsummarized  282\nusefulness  279\ncentral repositories  33. See also \nrepositories\nchange failure rate\ncalculating  255\nDORA metrics  254\ncloud architects, role of  4\nCloudEvents\ndefined  257\nendpoint  272\nsources  257\nmetrics collection pipeline, \nbuilding of  261–262\noverview  257–258\nspecification  257\nstandard input format  262\nsummarized  282\ntransforming to CDEvents, \nfunctions for  265–266\nusefulness  279\ncloud-native applications\nadvantages over monolith \napplications  23–24\nchallenges  25, 49, 61, 68–69\ncontinuous delivering  68– 71\ndynamic  64\nKubernetes as declarative system \nfor  11\nmain paradigm shift  69\nrunning locally or otherwise  28\ntasks expected in service \npipelines  73–75\ntools for operating and \nmonitoring  23\nvs. monolith applications  49\nwalking skeleton  18\nCloud-Native Computing \nFoundation (CNCF)  11. \nSee also CNCF\nCrossplane project  131\ncloud-native ecosystems  1\ncomputing platform for, \ndefinition  14\noutside cloud providers, enabled \nby Kubernetes  15–16\nusing  163\ncloud platforms. See also platforms\nand pay-as-you-go model  26\nthree main features of  10\nworking with  6–8\ncloud providers\nadvantages  10–11\nAPI-first approach  6\nconfigurations needed for \nGoogle Cloud Platform \n(GCP)  136\nKubernetes managed services \nand  11\nmain benefits of  2, 4\nportability  103\nREST request  9\nSDKs, CLIs, and Dashboard \nclients  7\nsupporting multiple  131\nusing more than one  5\ncloud services\nadvantages and \ndisadvantages  124\nAPIs not standardized  6\nbuying  17\ncategories  3\ncost  4\norganizing into layers  3\nCNCF-hosted projects, common \ndenominator  15\nCNCF Landscape  11\noverview  14–16\nresearching and selecting \ntools  13\nvs. cloud provider offered \nservices  15\nCNCF white paper on \nplatforms  14\ncommand line interfaces (CLIs)\ndefinition  7\ntools  81, 87\ncomplexity\nabstracting  25\nhiding from platform \nusers  160\nmanaging  23\nof pipeline service setup  96\nof using Kubernetes built-in \nresources  216\nreducing, need for  153\nConference application\nannotations for  275\nBack Office page  20\ncloud-native, overview  19–22\ncomplex pipelines for  87\nconfiguring services and \ndependencies  115\ndiagram  36\nessential functionalities  180\nHelm Chart \ndependencies  139–140\nHelm Chart, installing  169\nhome page  19, 37\nhosting  172\ninfrastructure components, \nadding  126\ninfrastructure for  139\ninstalling  34–35\ninteracting with  36–40\nlist of challenges  49\nmonolith, overview  22–24\nNotifications service  218, 230\nrepository  96\nrequirements  158\nrestarting  36\nservices   20\nsubmitting proposals  37\nusing Dapr components  200\nverifying  35–36\nConfigMap  199, 200\nmodifying  205\npatching  226\nConfigMap/secrets, Kubernetes \nresources  31\nconfiguration drifts\navoiding  104, 137\ndealing with  107\ndifficult to track  117\nmonitoring environments  104\nconfiguration files\ndefinition  62\npackaging and distributing  121\nconfiguration management  72\nconfiguration parameters  6\n\n\n284\nindex\nconnection pool  185\ncontainer image  119\nbuilding  74\ncontaining web \napplication  224\nOCI  75\npublishing to centralized \nlocation  74\npushing to Docker Hub  95\nreplacing by rollouts  234\ncontainer registry  75, 78, 96\ncontainers\nbenefits of using  182\nparameterizing  199\nresource allocation for  41\nrunning inside Kubernetes  74\nrunning on demand  218\nsimple docker  41\ncontainers-as-a-service\nimportance of  249\ninterface  218\ncontinuous delivery. See CDEvents\nContinuous Delivery: Reliable Software \nReleases through Build, Test, \nand Deployment Automation, \nbook  73\nContinuous Delivery, book  215\ncontinuous reconciliation\nimportance of  104\nwith Crossplane managed \nresources  137\ncontracts\nbetween services  62\nbetween users and \nplatforms  159\nconsumer-driven  73\nexposed as platform APIs  11, \n13\nconventions that save time\nconsumer-driven contract \ntesting  73\nsource code and configuration \nmanagement  72–73\ntrunk-based development  72\ncredentials\naccessing  180\nproblem with  186\nCronJob, executing \nperiodically  58\nCrossplane\nadvantages, summarized  155\nbehaviors  137\ncomponents and \nrequirements  135–136\ndescribed  131\ndrawbacks and challenges  153\nGCP supported resources  136\nHelm provider  139, 140\ninstalled with two \nproviders  132\ninstalling in Kubernetes \ncluster  135\nisolated environments, \ncreating  171\nKubernetes secrets, \ncreating  135\nmanaged resources, \nadvantages  137\nofficial documentation  146\nproviders  132–133\ninstalled and \nconfigured  135\nsyncing resource \nstatuses  138, 149\nusing  169\nCrossplane Composite Resource \nDefinitions (XRDs)  133\ncreating  153\ndescribed  141\nimplementing  142\nCrossplane Composite Resources \n(XRs)  133\nCrossplane compositions\nadding parameters  149\nconfiguring and creating  140\ndescribed  141\nexample  134\nexamples for different database \nresources  142–146\nmapping environment resources \nto  168\noverview  133–134\nrunning in local Kubernetes \ncluster  171\nselecting different \nproviders  147\nselecting using labels  145, 147\nusing  139\nD\nDagger\npurpose of  89\nsummarized  98\nvs. Tekton  90, 91, 93\nwriting pipelines in any \nsupported language  90\nDapr\nannotations  195\napplications and  197–198\nCNCF project  193\ncontrol plane  195\nin Kubernetes  194–197\noverview  193–194\nresiliency policies  201\nservice-to-service \ninvocations  201\nsoftware development kits \n(SDKs)  198, 204\nSubscription resources  204\nsummarized  209\nusefulness  250\nDapr components\naccessing configured  195\nconfiguring  196\nfor building distributed \napplications  194\nPubSub  197, 199, 200, 203\nStatestore  196, 197, 199, 200\nused for Conference \napplication  201\ndashboards\nArgo Rollouts  229, 231, 236\nbuilding domain-specific  59\ncomponent  7\nfor managing Kubernetes \nworkloads  49\nfor monitoring pipelines  88\nKeptn application  276\nquerying databases \ndirectly  268\nTekton  87\nusefulness  7\ndata collection\nevents routed to  262\nfor recovery metrics  256\nfrom event sources  261, 262\ndata transformation\nasynchronous approach  265\n",
      "page_number": 296
    },
    {
      "number": 26,
      "title": "Segment 26 (pages 304-311)",
      "start_page": 304,
      "end_page": 311,
      "detection_method": "topic_boundary",
      "content": "\t\n285\nindex\ndescribed  262\ndifferent approaches  265\nfunctions for  272, 274\nto CDEvents  261, 264–266\ndeclarative definition, enabled by \nArgo CD  111\ndeclarative description, \nimportance of  103\ndependencies\nadding\nand removing  181\nDapr SDK  198\nto application code  192\nbenefits and problems with  7\ncompatible versions of  183\nHelm  109\nkinds of  185\nof services  79\non infrastructural \ncomponents  57, 126\nreducing between teams  25\nremoving from services  203, \n206\nupgrading  186\nvendor-specific  190\ndeployment frequency\ncalculating metrics  255, 260, \n263\nworking example  268–274\ncalculation flow  267\ncalculation function  272\nDORA metrics  254\nmetrics endpoint  272\ndeployments\nautomating  63\nbasics  41\nblue/green  213–214, 227–229, \n238–243\ndefault  127\ndescribing  43\nexploring  42–43\nfrontend service  42, 44\nKubernetes resources  30, 211\nlist of available  41\nmanaged by Knative  220\nmanaging ReplicaSet \nobjects  44\nperforming rolling \nupdates  218\ndevelopment environments  108\nbuilding platform prototype \nfor  168\nclusters  162\nGitOps approach, \nunusable  121\nnamespace approach  110\non demand  158\nprovisioning  159\nDevOps Research and Assessment \n(DORA). See DORA \nmetrics\ndistributed applications\ncommon communication \npatterns  181\ncomplexities  28\nDapr components for  194\nmono repository  72\none service/one repository/one \npipeline  72\nproblem with inconsistent \ndata  50\nreducing complexity  24\nsecurity and identity \nmanagement  50\ndistributed approach, vs. monolith \napproach  22–24\ndistributed systems\nauthorization, problem of  60\nevent-driven architecture  180\neventual consistency, \nmeaning  58\nDockerfile\nneed for  78\nusage  79\ndomain-specific libraries, creating, \nneed for  93\nDORA metrics\narchitecture, example  269\nby category  254\ncollecting and transforming data \nfor  261\nhard to implement  279\nout of the box  256\nsummarized  282\nusing functions for \ncalculating  267\ndowntime\nminimizing  65, 103\nnot allowed  50–53, 55\nsimulating  53\nE\nedge cases\ndocumenting  192\nhandling  193\noverview  189\nrecognizing all  192\nenvironment clusters  161\nenvironment configurations\nbased on requirements  110\ndefining with helmfile  109\nsynced by Argo CD  111\nupdating  100\nenvironment pipelines\naccess rights, fine-tuning  107\ncoordination between  121\ndeploying cloud-native \napplications  25\ndifferent approaches  108–110\nexplained  71\nfor Kubernetes \nenvironment  107\nfor storing Kubernetes \nresources  132\nimplementing using \nArgoCD  111\ninteracting with service \npipelines  118, 120–121\noverview  100–101\nresponsibilities of  100\nstandardized for \nKubernetes  111\nsteps involved in  107\nsummarized  122\nusing GitOps approach  105\nvital conditions for \nworking  108\nenvironments\nconfiguration options  108\nconsistent capabilities \nacross  207\ncreating new, brief history \nof  101\ndefinition in JSON format  160\ndeploying same application \nacross different  97\nexpanding resources  160\ninternal configurations  104\n\n\n286\nindex\nisolated  169\nlive  107\nlow-risk  119\nmanaging  250\nmanaging and provisioning \ndifferent  69\nmulti-cloud setup  110\nmultiple  95, 108, 109, 122\nnew cluster for each  110\non-demand  109\nrepositories  108, 119, 120\nright for testing  95\nsensitive  167, 212\nsharing Kubernetes \nresources  109\nsimple definition  159\ntesting new versions  119\nunified runtime across  90\nusing one per namespace  109\nenvironment variables  128, 199\nevents\nassociated with resources  43\ncategories and examples \nof  259–260\ncoming from external \nsources  81\nemitted by application \nservices  40\nemitting and consuming  180, \n257\nin notification service logs  39\nKnative sources  262\nlistener  88\nsources  258, 260\nstore  258\nstoring and reading  269\ntapping into sources  279\ntriggers  87\nEvent Sources, configuring  271\nextending\nexisting tools  13\nKubernetes  12, 15, 17, 163\nKubernetes APIs  81, 132\nF\nfeature flags  191\nconsuming and evaluating  199\ndescribed  198\nhosting in remote services  199\noverview  198–200\nproviders  199, 203\nsummarized  209\nusefulness  207\nfifth key metric, described  254\nfrontend service\nConference application  20\ndebug features  160\ndeployment  42\ndownscaling  53\ninteracting with identity \nmanagement service  61\nreplicas  45, 50\nscaling up  50\nfunction-as-a-service\nimportance of  249\nplatform  218\nG\nGitHub, pull requests concept  76\nGitHub Actions\nadvantage of using  95\nfor building service \npipelines  95\nsummarized  98\nGitOps\napproach  95, 154\ndealing with changes  116–118\ndefinition  103\nimplementation  111\nmanaging multiple \nenvironments  122\noverview  103–106\nviewed as pipelines  106\nGit repository  73, 78, 81\nas source of truth  104, 112\nhistory stored in  107\nmanaging environment \nresources  173\nmonitored by Argo CD  231\nmonitoring  106, 111\nremote  107\nseparate for each \nenvironment  109\nstoring configurations in  104\nglue code\nabstracting  12\nvs. rewriting more tailored \nsolution or extending \nexisting tools  13\ngolden paths to production  279\ncreated by platform team  16\ndefinition  121\nenabled by cloud providers  11\nGoogle Cloud Platform (GCP)\ncreating full-blown cluster \nin  169\ndashboard, CLIs and \nAPIs  8–10\nsimplifying user jobs  10\nusing with Crossplane \ncompositions  146\nvs. platforms built on top of \nKubernetes  157\nGoogle Kubernetes Engine\nadvantages of  29\ncreating new clusters  8\nGrokking Continuous Delivery, \nbook  62, 73\nH\nheader-based routing  226–227, \n247\nHelm\nas package manager  74\nconfiguration prameters  114\ndependencies, turning off  151\ndescribed  28, 34\none release per change  109\ntemplating capabilities  63\ntutorial  36\nupdating applications  44\nwhen inappropriate  80\nHelm Chart  74, 79\ncaveats and tricks  127–128\nfinding or creating \nsuitable  126\nper service, good or bad?  79, \n96\nrepository  78\nusing definition  115\nusing manually  118\nhigh-performing teams  254\nHTTP headers\ncustom  226\nfor routing requests  226\n\n\n\t\n287\nindex\nI\nidentity management service  60–\n61\ndiagram  61\nrole of  61\nidentity provider, role of  61\nimmutability\nimportance of  104\nwith Crossplane managed \nresources  137\ninconsistent data\naccross different stores  58\ndealing with  58\nproblem with  50\ninfrastructural requirements\nautomating  57\nfor service pipelines  77\ninfrastructure\nas code tools  104–105\nchecking resources  138\ndeclarative  131–139\nmanaging in Kubernetes  124–\n131\nmulti-cloud  123\nprovisioning in cloud-agnostic \nway  155\nseparating applications \nfrom  190–191\ningress\ncontroller  30, 48, 53\nfor routing traffic  232\nKubernetes resources  31, 47, \n211, 218\nintegration tests  7, 161\ninternal services  5\naccessing  48\ninternal teams  1, 4, 16, 17, 167, \n176\ntesting deployments  214\nisolation\nbetween environments  168\ninsufficient  169\nKubernetes clusters, pros and \ncons  166–167\nKubernetes namespaces, pros \nand cons  166\nprovided by vcluster  170\nIstio in Action, book  248\nJ\nJenkins, advantages of  101\nJenkins Jobs\ndescribed  102\nimprovements  102\nK\nKafka\nHelm Chart  140\nprovisioning instance of  125\nusage  36\nKeptn Lifecycle Toolkit (KLT)\nannotated deployments  275\ndescribed  274\nTaskDefinition  276\nusefulness  278\nKnative Eventing\nAPI server source  271\nevent sources  262\nKnative In Action, book  217\nKnative Revisions, defined  219\nKnative Services\nbuilt on top of Kubernetes \nresources  218\nchanging configuration  221\ndefault characteristics  220–221\nfrontend  223\nhow they work  218\nmodifying resource  224\nrole of  217\nKnative Serving\ndefined  217\nsummarized  251\nswitching traffic  228\ntag-based routing  225\ntraffic rules and tags  227\nusefulness  249\nKnative Sources, described  262\nKratix, framework  176\nKubernetes\nadvantages when using \nTekton  94\nannotations  275\napplications, packaging and \nmanaging  31–33\nautomating deployments  63\nbuilt-in mechanisms, summary \nof  62\nbuilt-in resources  211\nchoosing the best environment \nfor using  28–30\nclusters on demand  29\nconnecting services  46\nDapr installed in  194–197\ndefinition  12\ndeployments  41–43\ndistribution of clusters in \norganizations  161\ndistributions  18\necosystem  1, 12\nenabling multi-cloud cloud-\nnative ecosystem  15–16\nin cloud provider setup, pros \nand cons  29\nin shared infrastructure  60\ninstalling application using \nHelm  34\ninternal events  264\nload balancing  45, 56\nlocal setup, pros and cons  28\nlocal vs. remote setup  29, 64\nlow-level building blocks  12\nmanaging infrastructure  124–\n131\nmanifest  72, 74, 78, 103\nmisbehaving platform services \nand  23\nnamespaces  109, 166\non-premise setup, pros and \ncons  29\noperators  130\nplatforms built on top of  11–\n16, 25\nproblems with using Tekton  89\npublishing manifests to \ncentralized location  74\nresources  30, 46, 141, 203\nrestarting failing container  35\nscaling services replicas  50\nsecrets  128, 135, 186\nservice selectors  240\nsetting up PostgreSQL, Redis, \nand Kafka  126\ntasks expected in service \npipelines  73–75\ntypical adoption journey  13\nusing gcloud CLI  10\nusing REST request  9\nwriting custom extensions \nfor  12\n\n\n288\nindex\nKubernetes APIs\nrelying on  103, 104\nusefulness  105\nKubernetes in Docker \n(KinD)  219\ndescribed  27\nlimited resources  127\nL\nlayers\napplication-level services  3\ncross-cutting  14\nextending with custom \nbehavior  5\nindustry-specific services  3\nKubernetes-based API  163\nof cloud services  3\norganization-specific  5\nlead time for change\ncalculating metrics  255, 260\nDORA metrics  254\nlifecycles\napplications’ diagram  63\nof Agenda service  275\nof Helm Chart and application \nservices  97\nof managed resources with \nCrossplane  138–139\nof service components and \nartifacts  79\nof service pipelines and \napplication pipeline  96\nliveness probe  41\nload balancing\nnot performed  28\nrequests between replicas  45, \n56\ntraffic  236\ntraffic among replicas  46\nlocal Kubernetes setup, pros and \ncons  28\nM\nmanaged resources. See \nCrossplane, managed \nresources\nmeasuring platforms\ndifferent approaches to  279\nDORA metrics  26, 254\nimportance of  280\nsummarized  282\nmessage broker (Kafka)  36, 141, \n188\nmetrics. See also DORA metrics\nbuilt into platforms  278\ncalculations  261\nfunctions for  266, 274\noverview  266–268\nteams involved in  273\ncustom  274\ndomain-specific  262\nmicroservices, installing sets \nof  28. See also \nOpenTelemetry.\nmirrored traffic  247, 248\nmonolith applications, \ndrawbacks  23–24\nmonolith approach, vs. distributed \napproach  22–24\nmono repository, described  72\nmulti-cloud infrastructure  123\nneed for components  25\nmulti-tenancy  166\non top of Kubernetes  170\nN\nnotifications\nabout changes in source \ncode  73\nabout new versions of \nservices  119\non Back Office page  39\nsent by pipeline services  75\nsubscribing to  119\nnotification service logs\nchecking status of proposals  39\nemails and events  39\ntailing  277\nNotifications service\nacessing Dapr components  201\nblue/green deployment  239\nConference application  21\ndashboard for  276\ndeploying new versions  227\nquerying  232\nO\none repository per service, main \nproblem  96\non-premise Kubernetes setup, pros \nand cons  29\nOpenFeature\ndescribed  199\nproviders  200\nSDK  199, 202\nsummarized  209\nusefulness  250\nOpenGitOps, four core \nprinciples  103\nOpenShift  17\nOpenTelemetry\narchitecture and library  60\ncommunity  59\noperation teams\ncollaborating with other \nteams  16\npriorities different from other \nteams  12\nreducing frictions between \nteams  25\nresponsibilities of  139\nsimplifying work with CNCF \ntools  15, 23\ntools preferred by  104\nusing tools from cloud \nproviders  7\norganizations\nmain jobs of  4–6\nP\npackage managers\nmain responsibilities  32\nusefulness  64\nusing semver approach  33\npercentage-based routing  247\npersistent storage\nDagger and  93\nfor Agenda and C4P \nservices  36\nfor sharing information  83\nfor storing and reading \ndata  179, 184, 196, 260\npipeline definitions\ncustom per service  96\ndefining tasks  85\n\n\n\t\n289\nindex\nexecuted by pipeline \nengine  69\nfor creating automation \nsolutions  70\nsharing  71\npipeline engines  80\nadvantages of Dagger  90\nexecuting pipeline \ndefinitions  70\nJenkins  101\nrole of  69\nTekton  80\npipelines\nautomation performed by  69\nCI/CD  255\nfor data collection, \ntransformation, and \naggregation  261, 262\ntwo main kinds  70\nusage  69\nPlatform Admin application  173\nplatform APIs\nbenefits of using Kubernetes \nAPIs as  162\nbuilding without creating \ncustom Kubernetes \nextensions  168\ndomain-specific  158\nhosting on platform \nclusters  162\nimplementing  160\nimportance of  157–158\nresponsibility of platform \nengineering teams  157\nplatform capabilities. See also \nshared application \nconcerns\naccessed by APIs  180\napplication-level  193–206\nas APIs  190\navailable for services  191\nconsistent across \nenvironments  207\nenabling teams to \nexperiment  26, 213\nfeature flags  191\nfor managing \nenvironments  250\ngeneric  189\nseparated from application \nservices  190\nplatform engineering\nintroduction  1\non Kubernetes, usefulness  26\nreducing complexity  153\nsuccessful initiatives  13\nview of complex pipelines  94\nplatform engineering teams\nAPIs as responsibilities of  11\nautomating entire process of \nbuilding platforms  63\nchoosing tools or services  95\ncreating library of shared \ntasks  277\ndedicated  16\npriorities  62\nreducing cognitive load on \nteams  189\nresponsibilities  174, 176\nresponsible for platform \nAPIs  157\nrole of  133\nsuggestions for  281–282\nunderstanding requirements of \ndevelopment teams  158\nplatforms\narchitecture  161\nauthor’s definition of  13\nautomating creation of \nenvironmental \nrepositories  120\nchallenges  164\nisolation and multi-\ntenancy  165–167\nmanaging more than one \ncluster  164–167\nclusters  162\ncurrent CNCF definition of  14\ndefining, fetching and \naggregating data for \nmanaging \nenvironments  208\ndescribed  2\ndesired properties  14\nevolving independently from \napplications  190\nmain objective  6\nmetrics built into  278\norganization-specific  5\nrelationship with development \nteams  17\ntools, configurations, and \nservices  175\nwalking skeleton, example  167\nworking on-premises  5\nplatform services. See also \nindividual services\nfine-grained  24\nneeded for application \ndevelopment  154\npods\ncanary and stable, traffic \nmanagement  236\ndealing with large number \nof  130\nlist of  35, 82\nmanaged resources  220\nscheduled in different \nnodes  36\nupdating  41\nupgrading  44\npolling, vs. pushing  106\npolyglotism, advantages of  23\nPostgreSQL\ndownside of installing  57\nfor C4P service  125\nHelm Chart  140\nofferd by cloud provider  3\nstoring C4P  56\nstoring proposals in  55\nusage  36\npreview environments\nfor faster iterations  118\nfor pull requests  117\nproduction environments  108, \n121\nclusters  162\ndescribed  100\nseparated clusters for  110\nwith isolated Kubernetes \nclusters  167\nproof of concept (PoC), \nbuilding  18\npull requests\ncreating  116\nsending  108\nsubmitting  117, 127\nQ\nquality assurance (QA) \nenvironments\n\n\n290\nindex\nclusters  162\ndescribed  100\nR\nreadiness probe  41\nreconciliation\ncontinuous  137\ncycle used by Crossplane  139\nRed Hat OpenShift, tool  17\nRedis\nadvantage of using  130\ndownside of installing  57\nHelm Chart  140\nNoSQL database  125\nservice dependent on  36\nstoring application state  56\nstoring proposals in  55\nusage  36\nrelease strategies\nA/B testing  214–215\nArgo Rollouts  229\nblue/green deployments  213–\n214, 227–229\ncanary releases  212–213\noverview  211\nreplicas\nchanging number of  44\ndownscaling  220\nincreasing number of  130, 212\nmultiple recommended  53\nnumber of  41, 241\nnumber of running  36\nrunning concurrently  56\nReplicaSets  43–45, 218\ncreating new  231\ncreating new pod  52\nrepositories. See also individual \nrepositories; service \npipelines\ncentral  33\nfrontend  116\npackage  33\nseparate  112\nsource code main branch  73\ntags created in  74\nusage  29\nwith environment \nconfigurations  100\nwith pipeline service's source \ncode  78\nresiliency. See services, built-in \nresilience\nREST endpoint  223, 262\nREST request\nusefulness  9\nusing  9, 173\nreusability, in cloud-native \napproach  24\nrouting. See  header-based routing; \ntag-based routing; traffic \nsplitting\nrouting rules, percentage-\nbased  224, 227\nS\nscaling\naffected by amount of data kept \nin memory  57\napplications  43\napplication services  64\nbased on demand  218, 220\nby changing number of \nreplicas  45\ndatabases, elastically  127\nservices  23, 50, 125\nSelector property  46\nservice pipelines\nbuilding cloud-native \napplications  25\nbuilding with Tekton, Dagger or \nGitHub Action  94–95\ncharacteristics  75\nconventions that save time  72–\n73\ndescribed  71– 2\ndetermining start and end \nof  96\nexplained  70\nfailing  76\nfailing logic  102\nfor improving communication \nbetween teams  71\nfor main and feature \nbranches  77\nin Dagger  91\nin real life  76–77\ninfrastructural \nrequirements  77–79\ninteracting with environment \npipelines  118–121\nrecommendations for \ndesigning  79\nrequired infrastructure, \ndiagram  78\nresponibility of  73\nresponsibilities, \nsummarized  79\nrunning locally  89, 90, 94\nrunning remotely  93, 97\nsending notifications  75\nseparate for each service  112\nsource code repository  79\nstructure  73–76\nsummarized  98\ntasks for cloud-native \napplications  73–75\ntriggering  73\ntriggering environment \npipelines  119\nvariations depending on \ncircumstances  77\nService Revisions  222\nservices\naccessing/downloading items \nfrom different \nenvironments  68\nadding libraries  189\nadding or removing  117\nbarrier between external and \ninternal  60\nbuilt-in resilience  50, 53–55, \n182\nchecking data consistency  58\ncompromised  184\nconnecting  46\ncoordination between \nteams  68\nexploring  46–47\nfrontend  44\nidentity  184, 187, 188\nindependent of \nenvironments  75\ninteracting  36\niteration of  34\nKubernetes resources  31, 211\nlarge numbers of  31\nmanaged by Knative  220\n\n\n\t\n291\nindex\nmonitoring with \nOpenTelemetry  59\nnew versions, testing  213\nparameterizing features  160\nreleasing independently  72\nreleasing independently of \napplication \ninfrastructure  152\nreverting versions  117\nrouting traffic to  213, 232\nscaling  43, 64\nsource code  47\nsystem-level rules  184\ntroubleshooting  48–49\nupdating  234\nupgrading independently, need \nfor  68\nservice-to-service\ncommunications and resiliency \npolicies  197\ninteractions  183, 202\ninvocations  184\nshared application concerns  20\nchallenges\nasynchronous \nmessaging  187–188\ncoordination between \nteams  182\nedge cases  189–189\nseparating applications from \ninfrastructure  190–191\nservice-to service \ninteractions  182–184\nstoring/reading state  185–\n187\noverview  180–181\nsocial login, definition  61\nsoftware development kits (SDKs)\nnot standardized  7\nproviding by cloud providers  6\nsoftware development teams\navoiding distractions  25\nfocusing on building platform \nfeatures  63\nnew responsibilities  68\npriorities different from other \nteams  12\nranking with DORA \nmetrics  254\nsimplified interaction with \ntools  16\ntreated as customers  16\nultimate goal  2\nusing platforms  11\nworking with platform \nengineering teams  152\nsource code\nand configuration \nmanagement  72\nbuilding and testing  73\ncloning  73, 107\nrepository  79\nSpring Retry, library  183\nstaging environments  108\nclusters  162\ndefining  113\ndescribed  100\nHelm configuration \nparameters  114\nseparated clusters for  110\nsetting up with ArgoCD  116\nstate of  115\nsticky sessions  57\nT\ntag-based routing  223–226\ntags\nfor routing requests  224\nfor routing traffic  227\nTanzu  17\ntask definitions, searching for  88\nTaskRun resource, creating  82\ntasks, executing remotely  94\nTeam Topologies, book with different \nview on platforms  16\nTekton\nadvantages and extras  87–89\ncatalog  88\nchallenges, list of  89\ndashboard user interface  87, \n88\nexecuting pipelines  86\nHub  89\ninstalling  81\ninstalling in Kubernetes  87\npipelines in  83\nsummarized  98\ntasks and pipelines  81\nwriting pipelines in any \nsupported language  94\ntelemetry\ndata (metrics, logs, traces)  59\nmonitoring data  59\ntemplating engines\nunification  118\nusage  31\nthird-party\ncomponents  124\nservices  5, 148\nsources  263\ntools  155\nticketing system  152\ntime to restore service\ncalculating  255\nDORA metrics  254\ntraffic rules  226\ncreating by Knative \nServices  221, 224\nmore precise  247\nupdating  227\ntraffic splitting\npercentage-based  221, 223\nweight-based  247\ntroubleshooting\ninternal services  48–49\nproblems in pipelines  76\nproviding enough information \nfor  208\ntrunk-based development  76\ncreating new releases  73\ndescribed  72\nU\nuse case\nbasic  40\nmore advanced  158\nreceiving and approving \nproposals  36\nV\nvalidating\nby end users  121\nchange in feature branch  77\nchanges  118\nCloudEvents  264\nenvironment's state  276\n\n\n292\nindex\nif applications are working as \nexpected  107\npull request/change \nrequest  77\nvcluster\ncreating  170\noverview  170–171\nusefulness  172\nvs. Kubernetes namespaces vs. \nKubernetes clusters  170\nversioning, importance of  104\nvirtual machines, benefits and \ndownsides  102–103\nvisibility\nof Crossplane managed \nresources  137\nof tools  280\non operations, cost and \nefficiency  11\nusefulness  17, 21\nVMware Tanzu, tool  17\nW\nwalking skeleton\napplication built as  34\narchitecture  171\nbuilding platforms and  24–26\nchallenges  124\ninfrastructure for  139\ninspecting  41–49\ninstalling  30\nintroduction  18–19\nmetrics  280\nnatural extension  173\nOpenTelemetry built-in  60\nprimary purpose  19\nrelease strategies for, \nsummarized  250\nservices  96\nselecting  21\nsupporting degraded  23\nusefulness  64\nusing Dapr components  201\nwebhooks\nlistener  81\nmutation  277\nregister  78\nsmple definitions  96\nsupported by repository  106\nworkflows\ncloud-agnostic  12\ncodifying and automating  11\nfocusing on  13\nimplementing out-of-the \nbox  17\noptimizing  24\nplatform-specific  280\npredefined  176\nteams for implementing  16\nworkloads\ndownscaling  218\nmanaging  153\nmonitoring and observing with \nKLT  274\nrunning and deploying  11, 122\nseparated from platform \ntools  164\nY\nYAML files  35. See also \nconfiguration files\nadding variables  31\ncomplexity  31\ndownloading and applying  126\nfor Kubernetes \ndeployments  74\norganizing, versioning, and \ndistributing  32\nrule for packaging  74\nstoring in Git repository  109\n",
      "page_number": 304
    },
    {
      "number": 27,
      "title": "Segment 27 (pages 312-312)",
      "start_page": 312,
      "end_page": 312,
      "detection_method": "topic_boundary",
      "content": "Mauricio Salatino ● Foreword by Jared Watts\nISBN-13: 978-1-61729-932-2 \nK\nubernetes is an amazing orchestration tool, but it’s just \nthe start of your journey to the cloud. To effi  ciently \ndeliver cloud-native software, your team needs a solid \nbuild pipeline, an effi  cient package manager and distribution \nmechanism, and APIs that reduce your team’s cognitive load. \nTh is book will show you how to build custom platforms on \ntop of Kubernetes—all with open-source tools such as Dapr, \nKnative, Argo CD and Rollouts, and Tekton.\nPlatform Engineering on Kubernetes starts by clearly defi ning \nthe elements of a great Kubernetes-based platform. Th en, it \nsystematically introduces the tools you’ll need to build a plat-\nform that exactly matches your organization’s requirements. \nHands-on examples and detailed code guide you through each \nstep. By the end, you’ll be able to create a complete platform \nto effi  ciently deliver cloud-native software without being tied \nto a specifi c cloud provider or vendor. \nWhat’s Inside\n● Package, version, distribute, and deploy with Helm, \n   Tekton, Dagger and Argo CD\n● Implement a multi-cloud infrastructure strategy \n   using Crossplane\n● Progressive upgrades with Knative Serving and Argo \n   Rollouts\n● Enable development teams with standard application-level \n   APIs with Dapr\nFor developers and software architects familiar with the basics \nof containers and Kubernetes.\nMauricio Salatino is currently a Dapr OSS Contributor, a Kna-\ntive Steering Committee member, and co-lead of the Knative \nFunctions working group.\nFor print book owners, all ebook formats are free:\nhttps://www.manning.com/freebook\nPlatform Engineering on Kubernetes\nOPERATIONS & CLOUD\nM A N N I N G\n“\nAn engaging and \ncaptivating hands-on \nexploration of the CNCF land-\nscape through the prism of \nplatform engineering.”\n—Viktor Farcic\nUpbound/@DevOpsToolkit \n“\nTh e book is a refl ection \nof a mountain of personal \nexperience and the author’s \nown journey on the windy \n paths of cloud native.”\n—Andreas Grabner, Dynatrace \n“\nBrims with Mauricio’s \nunique experience, insights, \n and deep understanding.”\n—Th omas Vitale, Systematic \n“\nFor anyone looking to \nbuild a modern, cloud \nnative development platform \non Kubernetes. \nAn indispensable guide.”\n—Lance Ball, Red Hat\n“\nA comprehensive exploration \nof platform engineering.”\n—Carlos Santana, AWS\nSee first page\n",
      "page_number": 312
    }
  ],
  "pages": [
    {
      "page_number": 1,
      "content": "M A N N I N G\nMauricio Salatino\nForeword by Jared Watts\n",
      "content_length": 56,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 2,
      "content": "M A N N I N G\nShelter ISland\nPlatform Engineering \non Kubernetes\nMAURICIO SALATINO \n",
      "content_length": 84,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 3,
      "content": "For online information and ordering of this and other Manning books, please visit www.manning.com. \nThe publisher offers discounts on this book when ordered in quantity.\nFor more information, please contact\nSpecial Sales Department\nManning Publications Co.\n20 Baldwin Road\nPO Box 761\nShelter Island, NY 11964\nEmail: orders@manning.com\n© 2024 by Manning Publications Co. All rights Reserved.\nNo part of this publication may be reproduced, stored in a retrieval system, or transmitted, in any form \nor by means electronic, mechanical, photocopying, or otherwise, without prior written permission of the \npublisher.\nMany of the designations used by manufacturers and sellers to distinguish their products are claimed \nas trademarks. Where those designations appear in the book, and Manning Publications was aware of a \ntrademark claim, the designations have been printed in initial caps or all caps.\nRecognizing the importance of preserving what has been written, it is Manning’s policy to have the books \nwe publish printed on acid-­free paper, and we exert our best efforts to that end. Recognizing also our \nresponsibility to conserve the resources of our planet, Manning books are printed on paper that is at \nleast 15 percent recycled and processed without the use of elemental chlorine.\n∞\n\t\nManning Publications Co. \n20 Baldwin Road\nPO Box 761 \nShelter Island, NY 11964\nISBN 9781617299322\nPrinted in the United States of America\nThe author and publisher have made every effort to ensure that the information in this book was correct \nat press time. The author and publisher do not assume and hereby disclaim any liability to any party for \nany loss, damage, or disruption caused by errors or omissions, whether such errors or omissions result \nfrom negligence, accident, or any other cause, or from any usage of the information herein.\n\t\nDevelopment editor: \t Ian Hough\n\t\nTechnical development editor: \t Raphael Villela\n\t\nReview editor: \t Dunja NikitoviÊ\n\t\nProduction editor: \t Aleksandar DragosavljeviÊ\n\t\nCopy editor: \t Katie Petito\n\t\nTechnical proofreader: \t Werner Dijkerman\n\t\nTypesetter:\t Tamara ŠveliÊ SabljiÊ\n\t\nCover designer: \t Marija Tudor\n",
      "content_length": 2151,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 4,
      "content": "First and foremost, this book is dedicated to my wife and family, who  \nhelped and supported me throughout writing this book. Without their help  \nand support, this would have been impossible.\nThis book is dedicated to all cloud-native practitioners, communities, and \norganizations that are invested in using open-source and cloud-native projects to \ndesign, build and deliver better software for their customers.\n",
      "content_length": 415,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 5,
      "content": "iv\ncontents\nforeword\t\nix\npreface\t\nxi\nacknowledgments\t\nxii\nabout this book\t\nxiv\nabout the author\t\nxvii\nabout the cover illustration\t\nxviii\n\t\n1\n\t\n(The rise of) platforms on top of Kubernetes  1\n\t 1.1\t\nWhat is a platform, and why do I need one?  2\nCloud services and domain-specific needs  3  ■  Your job as an \norganization  4  ■  Working with cloud platforms  6 \nGCP dashboard, CLIs, and APIs  8  ■  Why do cloud providers \nwork?  10\n\t 1.2\t\nPlatforms built on top of Kubernetes  11\nThe Kubernetes adoption journey  12  ■  The CNCF Landscape \npuzzle  14\n\t 1.3\t\nPlatform engineering  16\nWhy can’t I just buy a platform?  17\n\t 1.4\t\nThe need for a walking skeleton  18\nBuilding a Conference application  19  ■  Differences between \na monolith and a distributed set of services  22  ■  Our walking \nskeleton and building platforms  24\n",
      "content_length": 829,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 6,
      "content": "\t\nv\ncontents\n\t\nv\n\t\n2\n\t\nCloud-native application challenges  27\n\t 2.1\t\nRunning our cloud-native applications  28\nChoosing the best Kubernetes environment for you  28 \nInstalling the walking skeleton  30\n\t 2.2\t\nInstalling the Conference application with a single \ncommand  34\nVerifying that the application is up and running  35 \nInteracting with your application  36\n\t 2.3\t\nInspecting the walking skeleton  41\nKubernetes deployments basics  41  ■  Exploring deployments  42 \nReplicaSets  43  ■  Connecting services  46  ■  Exploring \nservices  46  ■  Service discovery in Kubernetes  47 \nTroubleshooting internal services  48\n\t 2.4\t\nCloud-native application challenges  49\nDowntime is not allowed  50  ■  Service’s resilience built-in  53 \nDealing with the application state is not trivial  55  ■  Dealing \nwith inconsistent data  58  ■  Understanding how the \napplication is working  58  ■  Application security and identity \nmanagement  60  ■  Other challenges  61\n\t 2.5\t\nLinking back to platform engineering  62\n\t\n3\n\t\nService pipelines: Building cloud-native applications   66\n\t 3.1\t\nWhat does it take to deliver cloud-native applications \ncontinuously?  67\n\t 3.2\t\nService pipelines  70\n\t 3.3\t\nConventions that will save you time  71\n\t 3.4\t\nService pipeline structure  72\nService pipeline in real life  75  ■  Service pipeline \nrequirements  76  ■  Opinions, limitations, and compromises \naround service pipelines   78\n\t 3.5\t\nService pipelines in action  79\nTekton in action  79  ■  Pipelines in Tekton  82  ■  Tekton \nadvantages and extras  86  ■  Dagger in action  88 \nShould I use Tekton, Dagger, or GitHub Actions?  93\n\t 3.6\t\nLinking back to platform engineering  94\n",
      "content_length": 1673,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 7,
      "content": "vivi\ncontents\n\t\n4\n\t\nEnvironment pipelines: Deploying cloud-native \t\t\n\t\n\t\n\t\n\t\napplications  98\n\t 4.1\t\nEnvironment pipelines  99\nHow did this work in the past, and what has changed lately?  100 \nWhat is GitOps, and how does it relate to environment \npipelines?  102  ■  Steps involved in an environment \npipeline  105  ■  Environment pipeline requirements and different \napproaches  107\n\t 4.2\t\nEnvironment pipelines in action  110\nCreating an Argo CD application  111  ■  Dealing with changes \nthe GitOps way  115\n\t 4.3\t\nService + environment pipelines  117\n\t 4.4\t\nLinking back to platform engineering  119\n\t\n5\n\t\nMulti-cloud (app) infrastructure  122\n\t 5.1\t\nThe challenges of managing infrastructure in \nKubernetes  123\nManaging your application infrastructure  124  ■  Connecting \nour services to the newly provisioned infrastructure  127 \nI’ve heard about Kubernetes operators. Should I use them?  128\n\t 5.2\t\nDeclarative infrastructure using Crossplane  130\nCrossplane providers  131  ■  Crossplane compositions  132 \nCrossplane components and requirements  134  ■  Crossplane \nbehaviors  136\n\t 5.3\t\nInfrastructure for our walking skeleton  138\nConnecting our services with the new provisioned \ninfrastructure  148\n\t 5.4\t\nLinking back to platform engineering  152\n\t\n6\n\t\nLet’s build a platform on top of Kubernetes  155\n\t 6.1\t\nThe importance of the platform APIs  156\nRequesting development environments  157\n\t 6.2\t\nPlatform architecture  160\nPlatform challenges  163  ■  Managing more than one \ncluster  163  ■  Isolation and multi-tenancy  164\n",
      "content_length": 1545,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 8,
      "content": "\t\nvii\ncontents\n\t\nvii\n\t 6.3\t\nOur platform walking skeleton  166\nvcluster for virtual Kubernetes clusters  169  ■  The platform \nexperience  170\n\t 6.4\t\nLinking back to platform engineering  173\n\t\n7\n\t\nPlatform capabilities I: Shared application concerns  178\n\t 7.1\t\nWhat are most applications doing 95% of the time?  179\nThe challenges of coupling application and infrastructure  180 \nService-to-service interaction challenges  181  ■  Storing/\nreading state challenges  184  ■  Asynchronous messaging \nchallenges  186  ■  Dealing with edge cases (the remaining \n5%)  188\n\t 7.2\t\nStandard APIs to separate applications from \ninfrastructure  189\nExposing platform capabilities challenges  191\n\t 7.3\t\nProviding application-level platform capabilities  192\nDapr in action  192  ■  Dapr in Kubernetes  193  ■  Dapr and \nyour applications  196  ■  Feature flags in action  197 \nUpdating our Conference application to consume application-level \nplatform capabilities  199\n\t 7.4\t\nLinking back to platform engineering  205\n\t\n8\n\t\nPlatform capabilities II: Enabling teams to experiment   209\n\t 8.1\t\nRelease strategies fundamentals  211\nCanary releases  211  ■  Blue/green deployments  212 \nA/B testing  213  ■  Limitations and complexities of using built-in \nKubernetes building blocks  215\n\t 8.2\t\nKnative Serving: Advanced traffic management and release \nstrategies  216\nKnative Services: Containers-as-a-Service  216  ■  Advanced \ntraffic-splitting features  220\n\t 8.3\t\nArgo Rollouts: Release strategies automated with GitOps  228\nArgo Rollouts canary rollouts  229  ■  Argo Rollouts blue/green \ndeployments   236  ■  Argo Rollouts analysis for progressive \ndelivery  242  ■  Argo Rollouts and traffic management  245\n\t 8.4\t\nLinking back to platform engineering  247\n",
      "content_length": 1755,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 9,
      "content": "viii\ncontents\nviii\n\t\n9\n\t\nMeasuring your platforms  251\n\t 9.1\t\nWhat to measure: DORA metrics and high-performant \nteams  252\nThe integration problem  254\n\t 9.2\t\nHow to measure our platform: CloudEvents and \nCDEvents  255\nCloudEvents for continuous delivery: CDEvents  256 \nBuilding a CloudEvents-based metrics collection pipeline  259 \nData collection from event sources  260  ■  Knative Eventing event \nsources  260  ■  Data transformation to CDEvents  262 \nMetrics calculation  264  ■  Working example  266\n\t 9.3\t\nKeptn Lifecycle Toolkit  272\n\t 9.4\t\nWhat’s next on the platform engineering journey?  276\n\t 9.5\t\nFinal thoughts  279\n\t \t\nindex  281\n",
      "content_length": 647,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 10,
      "content": "ix\nforeword\nThe cloud native landscape has matured to a point where we can finally start building \npractical solutions. A plethora of projects have emerged, each with a unique focus on \nsolving a portion of the grander vision. We now find ourselves struggling to cobble \ntogether these disparate projects into an end-to-end product. How can we manage the \ninherent complexity that this litany of tools brings and construct a complete solution?\nPlatform Engineering on Kubernetes by Mauricio Salatino offers a comprehensive answer \nto this question in the form of platform engineering. The discipline of platform engi-\nneering is positioned to make cloud-native development accessible to application devel-\nopers through highly productive and reliable delivery of their software to production \nenvironments. I consider platform engineering to be the crucial modern discipline that \nwill tame complexity and deliver the tantalizing promises made long ago when Kuber-\nnetes first made cloud-native technology available for the masses.\n This book provides much needed insight into how modern platforms can be archi-\ntected to effectively integrate the most useful cloud-native technologies from the ecosys-\ntem and solve real problems for the application developer customers of your platform. \nIt efficiently provides practical guidance, learned through hands-on exercises and \nexamples, to instill real skills for building a meaningful platform solution. The valuable \ninformation contained within these pages will enable platform teams to build a self-ser-\nvice developer platform as their product, allowing developers to deliver their applica-\ntions to production with greater speed and reliability than they’ve ever seen before.\nI’ve personally met a wealth of amazing individuals within the cloud-native ecosys-\ntem from my time as a co-creator, maintainer, and steering committee member on two \nseparate projects in the Cloud Native Computing Foundation. From my experience, \nMauricio is uniquely positioned to author this beneficial book that walks you through \nintegrating all of these projects into a complete platform, as he has consistently been an \n",
      "content_length": 2157,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 11,
      "content": "x\nforeword\nx\nintegrator within the ecosystem himself by bringing together people, communities, and \ntechnology on numerous occasions. Mauricio has demonstrated an uncanny ability to \nidentify shared interests across project visions, to bring the right people together, and \nfind common ground that unifies the efforts into a cohesive approach. He has shown \na consistent dedication to his rare gift of finding paths that make us better together \nthrough our collaboration and synergy rather than competition or duplication.\nIn the same way that Mauricio brings together people and technology, he has \nbrought together many projects into a valuable whole within these pages. I expect that \nlessons learned within this book will be some of the most rewarding steps you take in \nrealizing your platform engineering vision. Please enjoy the journey!\n—Jared Watts\nFounding Engineer, Upbound\n",
      "content_length": 886,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 12,
      "content": "xi\npreface\nI started working on this book more than two years ago. After working for the cloud-na-\ntive communities for more than four years, I’ve learned many lessons I’d like to share \nwith teams to speed up their Kubernetes adoption journey. Because I contributed to \nseveral open-source projects (most included in this book), creating a table of content \nfor a book idea wasn’t that difficult. On the other hand, writing a book about a for-\never-changing ecosystem proved challenging. But as you will find out when reading \nthis book, platform engineering is all about managing the complexities of constantly \nevolving projects and requirements from different teams that need the right tools to \ndo their job. \nThis book has allowed me to meet and work with the best people in the industry from \ndifferent backgrounds and communities who share my passions: open source, cloud \nnative, and knowledge sharing. I’ve toured the world, presenting at conferences in the \ncloud-native space, always gathering feedback from community members, developers, \nand teams struggling to keep up with the amazing amount of open-source projects cre-\nated daily. I hope this book helps you and your team to evaluate, integrate, and build \nplatforms on top of Kubernetes. \n",
      "content_length": 1258,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 13,
      "content": "xii\nacknowledgments\nI would like to give special thanks to everyone who contributed to the examples pro-\nvided in this book (both the original repository at https://github.com/salaboy/from \n-monolith-to-k8s/ and the new one at https://github.com/salaboy/platforms-on \n-k8s/). This book was written for and by the community of the projects mentioned. \nSpecial thanks to my brother Ezequiel Salatino (https://salatino.me/), who \ndesigned and built the frontend applications so readers can experience a website \ninstead of a bunch of REST endpoints. I will be forever grateful to Matheus Cruz and \nAsare Nkansah, who helped me build big chunks of the examples without expecting \nanything in return. Finally, thank you to my friend Thomas Vitale for sharing thorough \nreviews of multiple editions of the drafts; all your comments made the content of this \nbook more accurate and focused. \nI couldn’t have done this book without all the support provided by the Manning \nteam. I want to thank development editor, Ian Hough, for the countless hours spent \non the manuscript. Acquisitions editor, Michael Stephens, for strongly believing in the \nbook idea since day one, Raphael Villela as technical editor for all the technical advice \nprovided, and Werner Dijkerman as technical proofer for his comments and ensuring \nthat all of the code is in good working order.\nTo all the reviewers: Alain Lompo, Alexander Schwartz, Andres Sacco, Carlos Panato, \nClifford Thurber, Conor Redmond, Ernesto Cárdenas Cangahuala, Evan Anderson, \nGiuseppe Catalano, Gregory A. Lussier, Harinath Mallepally, John Guthrie, Jonathan \nBlair, Kent Spillner, Lucian Torje, Michael Bright, Mladen Knezic, Philippe Van Ber-\ngen, Prashant Dwivedi, Richard Meinsen, Roman Levchenko, Roman Zhuzha, Sachin \nRastogi, Simeon Leyzerzon, Simone Sguazza, Stanley Anozie, Theo Despoudis, Vidhya \nVinay, Vivek Krishnan, Werner Dijkerman, WIlliam Jamir, Zoheb Ainapore, your sug-\ngestions helped make this a better book.\nProject-specific thanks: \n",
      "content_length": 2002,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 14,
      "content": "\t\nxiii\nacknowledgments\n\t\nxiii\n¡ Argo Project (https://argoproj.github.io/ )—I want to thank Dan Garfield from \nCodefresh for his continuous support of the book and his contributions to the \nOpenGitOps (https://opengitops.dev/) initiative.\n¡ Crossplane (https://crossplane.io )—I want to thank Jared Watts for his constant \nwillingness to help and push things forward. Also, I want to thank Viktor Farcic \nand Stefan Schimanski for always supporting the Crossplane community. The \nCrossplane community has taught me many valuable lessons that shaped my \ncareer. \n¡ Dagger (https://dagger.io )—I want to thank Marcos Nils and Julian Cruciani \nfor their help with the Dagger examples and their willingness to improve things \nwhen time can be saved for developers. \n¡ Dapr (https://dapr.io )—Big thanks and appreciation to both Yaron Schneider \nand Mark Fussel for their constant support to get this book out of the door and to \nthe entire Diagrid (https://diagrid.io )—team, who is building amazing products \non top of Dapr.\n¡ Keptn (https://keptn.sh )—Big thanks to Giovanni Liva and Andreas Grabner for \ntheir speedy response and the amazing work that they have done in the Keptn \nand OpenFeature communities.\n¡ Knative (https://knative.dev )—The entire Knative community is awesome, but \nspecial thanks to Lance Ball, who led the Knative Functions working group to \nbuild something amazing. \n¡ Kratix (https://kratix.io )—Special thanks to Abby Bangser for sharing her plat-\nform insights and reviewing key chapters in the book. All your comments and \nremarks made this book way more valuable. \n¡ OpenFeature (https://openfeature.dev )—I wanted to thank James Milligan for his \nhelp in getting the OpenFeature and flagd examples working. \n¡ Tekton (https://tekton.dev )—Big thanks to Andrea Fritolli for his amazing work \non the Tekton community and for always answering my Slack messages. \n¡ Vcluster (https://vcluster.com )—Both Ishan Khare and Fabian Kramm had \nbeen instrumental to the work that I’ve done for this book. Their willingness \nto get things working had gone above and beyond. Big thanks for creating and \nmaintaining the vcluster, Devspace (https://www.devspace.sh/), and DevPod \n(https://devpod.sh/) projects.\n",
      "content_length": 2228,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 15,
      "content": "xiv\nabout this book\nPlatform Engineering on Kubernetes was written to help teams going through a Kuber-\nnetes adoption journey. The book uses a developer-centric approach to cover build-\ning, packaging, and deploying cloud-native applications to Kubernetes clusters, but \nit doesn’t stop there. Once you and your teams understand how to use Kubernetes \nfor your applications, you face new challenges related to managing Kubernetes exten-\nsions, multi-tenancy, and multi-cluster setups. \nPlatforms on top of Kubernetes need to integrate a wide range of tools to enable spe-\ncialized teams to perform their daily tasks while at the same time preventing them from \nlearning how all these tools work. Platform teams are in charge of learning, curating, \nand integrating tools to make the life of development teams, data scientists, operations \nteams, testing teams, product teams, and everyone involved with the software delivery \nprocess of your organization easier.\nMost of the content is focused around Kubernetes and built to be agnostic of the \ntechnology stack used for application-specific features. If you are getting started with \nKubernetes or you are a cloud-native practitioner, this book can help you to understand \nhow multiple projects can be combined to build team-specific experiences and reduce \nthe cognitive load involved in their day-to-day jobs, no matter the programming lan-\nguage you and your teams are using.\nHow this book is organized: a roadmap\nThis book is organized into nine chapters, and it uses the concept of a “walking skel-\neton” to build a platform to support the teams in building a Conference application. \nThe flow of the book goes as follows: \nChapter 1 introduces what platforms are, why you need one, and how the platforms \nwe will cover in this book compare to what cloud providers offer. This chapter intro-\nduces the business use case for the Conference application that further chapters will \nexplore.\n",
      "content_length": 1945,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 16,
      "content": "\t\nxv\nabout this book\n\t\nxv\nChapter 2 evaluates the challenges of building cloud native and distributed applica-\ntions that run on Kubernetes. This chapter encourages the reader to deploy the Con-\nference application and explore its design by changing its configuration and testing \ndifferent scenarios. By looking at the challenges teams will face when deploying and \nrunning applications on top of Kubernetes and providing a playground to experiment \nby using the walking skeleton, the book aims to enable readers with enough experience \nto tackle bigger challenges. \nChapter 3 focuses on all the extra steps needed to build, package, and distribute \nartifacts to run our applications in different cloud providers. This chapter introduces \nthe concept of service pipeline and explores two different but complementary projects: \nTekton and Dagger. \nOnce our artifacts are ready to be deployed, chapter 4 is centered around the con-\ncept of the environment pipeline. By defining our environment pipelines and by using \na GitOps approach, teams can manage the configuration of multiple environments \nusing a declarative approach. This chapter explores Argo CD as a tool to configure and \nmanage your environments. \nApplications can’t work on their own. Most applications require infrastructural com-\nponents such as databases, message brokers, and identity providers, among others, to \nwork. Chapter 5 covers a Kubernetes-native approach to provision application infra-\nstructure components across cloud providers using a project called Crossplane. \nOnce we have taken care of building, packaging, and deploying our applications and \nother components that our applications need to run, chapter 6 proposes the reader \nbuild a platform on top of Kubernetes using all that we have learned so far but focusing \nonly on a simple use case: creating development environments. \nPlatforms are not only about creating environments, managing clusters, and deploy-\ning applications. Platforms should provide customized workflows for teams to be pro-\nductive. Chapter 7 focuses on enabling development teams with application-level APIs \nthat platform teams can decide how to wire to available resources. This chapter evalu-\nates tools like Dapr and OpenFeature to enable teams with more than clusters and a \nplace to run their applications.\nWhile enabling developers to be more efficient will improve software delivery times, \nif new releases are blocked and not deployed in front of customers, all the effort will \nbe wasted. Chapter 8 focuses on showing techniques, more precisely release strategies, \nthat can be used to experiment with new releases before fully committing to them. This \nchapter evaluates Knative Serving and Argo Rollouts to implement different release \nstrategies that your teams can use to experiment with new features in a controlled way.\nBecause platforms are software, we need to measure how effective we are when evolv-\ning them. Chapter 9 evaluates two approaches to tap into the tools we are using to build \nour platform and calculate key metrics that allow the platform engineering team to \nevaluate their platform initiatives. This chapter looks into CloudEvents, CDEvents, and \nthe Keptn Lifecycle Toolkit as options to gather events, store them, and aggregate them \nto calculate meaningful metrics. \n",
      "content_length": 3318,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 17,
      "content": "xvi\nabout this book\nxvi\nBy the end of the book, the reader ends up with a clear picture and hands-on experi-\nence of how platforms are built on top of Kubernetes, what the priorities of the platform \nengineering teams are, and why learning and keeping up to date with the cloud-native \nspace is so important to be successful.\nAbout the code \nThis book contains many examples of source code both in numbered listings \nand in line with normal text. In both cases, source code is formatted in a fixed \n-width font like this to separate it from ordinary text. Sometimes code is also in \nbold to highlight code that has changed from previous steps in the chapter, such as \nwhen a new feature adds to an existing line of code.\nIn many cases, the original source code has been reformatted; we’ve added line \nbreaks and reworked indentation to accommodate the available page space in the \nbook. In rare cases, even this was not enough, and listings include line-continuation \nmarkers (➥). Additionally, comments in the source code have often been removed \nfrom the listings when the code is described in the text. Code annotations accompany \nmany of the listings, highlighting important concepts.\nYou can get executable snippets of code from the liveBook (online) version of this \nbook at https://livebook.manning.com/book/platform-engineering-on-kubernetes. The \ncom­plete code for the examples in the book is available for download from the Manning \nwebsite at https://www.manning.com/books/platform-engineering-on-kubernetes.\nEach chapter links to step-by-step tutorials where readers are encouraged to get their \nhands dirty with the tools and projects running in their environments. You can find \nall the source code and step-by-step tutorials on the following GitHub repository at \nhttps://github.com/salaboy/platforms-on-k8s/.\nliveBook discussion forum\nPurchase of Platform Engineering on Kubernetes includes free access to liveBook, Man-\nning’s online reading platform. Using liveBook’s exclusive discussion features, you \ncan attach comments to the book globally or to specific sections or paragraphs. It’s a \nsnap to make notes for yourself, ask and answer technical questions, and receive help \nfrom the author and other users. To access the forum, go to https://livebook.manning \n.com/book/platform-engineering-on-kubernetes/discussion. You can also learn more \nabout Manning’s forums and the rules of conduct at https://livebook.manning.com/\ndiscussion.\nManning’s commitment to our readers is to provide a venue where a meaningful dia-\nlogue between individual readers and between readers and the author can take place. It \nis not a commitment to any specific amount of participation on the part of the author, \nwhose contribution to the forum remains voluntary (and unpaid). We suggest you try \nasking the author some challenging questions lest his interest stray! The forum and the \narchives of previous discussions will be accessible from the publisher’s website as long as \nthe book is in print.\n",
      "content_length": 3005,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 18,
      "content": "xvii\nabout the author\nMauricio Salatino works for Diagrid (https://diagrid \n.io) as an Open Source Software Engineer. He is currently \na Dapr OSS Contributor and Knative Steering Committee \nmember. Before working at Diagrid, Mauricio spent the \nlast 10 years building tools for Cloud-Native developers \nat companies such as Red Hat and VMware. When he is \nnot writing tools for developers or contributing to Open \nSource projects in the Cloud Native space, he teaches \nabout Kubernetes and Cloud-Native via his Blog https://\nsalaboy.com and/or LearnK8s (https://learnk8s.io).\n",
      "content_length": 576,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 19,
      "content": "xviii\nabout the cover illustration\nThe figure on the cover of Platform Engineering on Kubernetes is “Femme des Isles d’Ar-\ngentiere et de Milo,” or “A Woman from the Isles of Argentiera and Milos,” taken from \na collection by Jacques Grasset de Saint-Sauveur, published in 1788. Each illustration is \nfinely drawn and colored by hand. \nIn those days, it was easy to identify where people lived and what their trade or station \nin life was just by their dress. Manning celebrates the inventiveness and initiative of the \ncomputer business with book covers based on the rich diversity of regional culture cen-\nturies ago, brought back to life by pictures from collections such as this one.\n",
      "content_length": 688,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 20,
      "content": "1\n1\n(The rise of) platforms \non top of Kubernetes\nThis chapter covers\n¡ Understanding platforms and why we need \t\n\t them\n¡ Building a platform on top of Kubernetes\n¡ Introducing a “walking skeleton” application\nPlatform engineering is not a new term in the tech industry. But it is quite new in \nthe cloud-native space and the context of Kubernetes. We were not using the term \nin the cloud-native communities when I started writing this book back in 2020. How-\never, by the time of writing this book (2023), platform engineering had become the \nnew hot topic in cloud-native and Kubernetes communities. This book aims to go \non a journey to explore what platforms are and why you would use Kubernetes, and \nmore specifically, the Kubernetes APIs at the core, to build a platform and enable \nyour internal teams to deliver software more efficiently. \nTo understand why platform engineering became a trend in the industry, you first \nneed to understand the cloud native and Kubernetes ecosystems. Because this book \nassumes that you are already familiar with Kubernetes, containers, and cloud-native \napplications, we will focus on describing the challenges you will face when archi-\ntecting, building, and running these applications on top of Kubernetes and cloud \n",
      "content_length": 1265,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 21,
      "content": "2\nChapter 1  (The rise of) platforms on top of Kubernetes \nproviders. We will take a developer-focused approach, meaning that most of the topics \ncovered are tackled in a way that relates to developers’ day-to-day tasks and how a myr-\niad of tools and frameworks in the cloud-native space will affect them. \nThe ultimate goal for every software development team is to deliver new features \nand bug/security fixes to their customers. New features and more stable applications \ntranslate directly to competitive business advantages and happy customers. To deliver \nmore software efficiently, development teams must have access to the tools they need \nto do their work. The main objective of the platform and platform engineering teams is \nto enable developers to deliver software more efficiently. This requires a different tech-\nnological approach and a cultural shift towards treating development teams as internal \ncustomers of the platforms we will be building. \nWe will use a simple application (composed of multiple services) as an example \nthroughout the chapters to build a platform that supports the teams building, releas-\ning, and managing this application by using all open source tools in the cloud-native \nspace. \n1.1\t\nWhat is a platform, and why do I need one?\nPlatforms are a collection of services that help companies get their software running \nin front of their customers (internal or external). Platforms aim to be a one-stop shop \nfor teams to have all the tools that they need to be productive and continuously deliver \nbusiness value—with the rise in popularity and with the growing demand to improve \ndevelopment cycles, platforms that once used to provide us only with computing \nresources had leveled up the stack to provide more and more services. \nPlatforms are not new, and neither are cloud platforms. Cloud providers like AWS, \nGoogle, Microsoft, Alibaba, and IBM have provided us platforms for years. These cloud \nproviders offer teams many tools to build, run, and monitor their business-critical appli-\ncations using a pay-as-you-go model. From a business agility perspective, these platforms \noffered by cloud providers have fundamentally shifted the expectations for teams con-\nsuming their services. This allows companies and teams to start fast and create applica-\ntions that can scale globally without a significant initial investment. If no one uses the \napplications they are building, their bills will not be large at the end of the month. On \nthe other side of the spectrum, if you are successful and your applications are popular, \nyou must get ready for a large bill at the end of the month. The more resources (stor-\nage, network traffic, services, etc.) you use, the more you pay. Another aspect to con-\nsider is that if you rely on the tools provided by your cloud provider, it is harder to move \naway from them as your entire organization gets used to that cloud provider’s tools, \nworkflows, and services. It becomes a painful experience to plan and migrate applica-\ntions across different providers. \nIn the following sections, we will cover the current state of cloud platforms and what \nkind of platforms we will discuss in this book. Lately, as always happens in our industry, \n",
      "content_length": 3230,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 22,
      "content": "\t\n3\nWhat is a platform, and why do I need one?\nterms that can be useful to describe very concrete tools and practices tend to be abused \nby marketing teams and become buzzwords. We must set the context for the rest of the \nbook to avoid confusion.\n1.1.1\t\nCloud services and domain-specific needs\nWe can organize cloud services into different layers, something that we need to do to \nunderstand where the industry is today and where it is heading. The following diagram \nshows a set of categories of the services provided by cloud providers, starting from \nlow-level infrastructure services, such as provisioning hardware on demand to high-\nlevel application services, where developers can interact with machine-learning mod-\nels without worrying where these models are running. Figure 1.1 shows these layers, \nstarting at the bottom with low-level computing resources and going up the stack with \napplication-level and industry-specific services. \nApplication Services & Industry specific Services\n(AI & ML, Voice recognition, Text recognition, etc.)\nDevelopment tools \n(SDKs, Libraries/Frameworks, Debuggers, etc.)\nApplication Infrastructure \n(Databases, Message Brokers, Identity management, \nSecrets management, etc.)\nOperating System and Base Software\n(Operating System, Patches, Kernel Modules, etc.)\nOperational tools \n(Monitoring tools, Metrics dashboards, Cost \nmanagement, etc.)\nInfrastructure & Computing Resources \n(Hardware, Networking, power, etc.)\nHigh Level Application ($$$)\nLow-Level Infrastructure ($)\nApplication \nDevelopment\nOperations\nFigure 1.1    Cloud provider’s services categories\nThe higher the category, the more you will need to pay for the service, because these \nservices usually take care of all the underlying layers and operational costs for you. For \nexample, suppose you provision a new highly available PostgreSQL database in a man-\naged service offered by a cloud provider. Figure 1.2 shows an example of a relational \ndatabase such as PostgreSQL.\n",
      "content_length": 1986,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 23,
      "content": "4\nChapter 1  (The rise of) platforms on top of Kubernetes \nApplication Infrastructure \n(Databases, Message Brokers, Identity management, \nSecrets management, etc.)\nOperating System and Base Software\n(Operating System, Patches, Kernel Modules, etc.)\nOperational tools \n(Monitoring tools, Metrics dashboards, Cost \nmanagement, etc.)\nInfrastructure & Computing Resources \n(Hardware, Networking, power, etc.)\nApplication Infrastructure ($$)\nOperations\nLow-Level Infrastructure ($)\nPostgreSQL\nFigure 1.2    Provisioning a PostgreSQL database instance in the cloud\nIn that case, the service cost includes the cost and management of the database soft-\nware needed, the operating system where the database runs, and the hardware needed \nto run it. Because you might want to monitor and get metrics on how the database \nperforms when your application is under heavy load, the cloud provider also wires up \nall the monitoring tools available for the service. Then it is up to you to do the math: is \nit worth paying a cloud provider to make all these decisions for us, or can you build an \ninternal team with enough knowledge to run and operate all these software and hard-\nware on-premises? Sometimes, money is not a problem; you must deal with company \nor industry policies and regulations. In such cases, can you run your workloads and \nhost your data in a cloud provider? \n1.1.2\t\nYour job as an organization\nKeeping up to date with all the provided services, libraries, frameworks, and tools is a \nfull-time job. Operating and maintaining the wide range of software and hardware that \ncompanies need to run their applications requires you to have the right teams in place, \nand at the end of the day, if you are not a large and mature organization in terms of \nyour software delivery practices, or if you are not getting any competitive advantage by \nmanaging your own hardware/software stack, adopting a cloud provider is usually the \nright way to go.  \nIt is still the job of each company and developer to look at the available services and \nchoose what they will use and how they will mix and match these services to build new \nfeatures. It is common to find cloud architects (experts on a specific cloud provider, \nor on-premises experts) in each organization defining how and which services will be \nused to build core applications. It is also common to engage with the cloud provider’s \nconsulting services to get advice and guidance on specific use cases and best practices. \nCloud providers might suggest tools and workflows to create applications. Still, each \norganization needs to go through a learning curve and mature its practices around \napplying these tools to solve its specific challenges. Staffing cloud provider experts is \n",
      "content_length": 2738,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 24,
      "content": "\t\n5\nWhat is a platform, and why do I need one?\nalways a good idea, because they bring knowledge from previous experiences, saving \ntime for less-experienced teams. \nIn this book, we will focus on organization-specific platforms, not generic cloud plat-\nforms that you can buy off the shelf, like those offered by cloud providers. We also want \nto focus on platforms that can work on-premises on our organization’s hardware. This is \nimportant for more regulated industries that cannot run on public clouds. This forces \nus to have a broader view of tools, standards, and workflows that can be applied outside \nthe realm of a cloud provider. Consuming services from more than one cloud provider \nis also becoming increasingly popular. This can result from working for a company that \nacquired or became acquired by another company using a different provider, ending \nup in a situation where multiple providers must coexist, and there should be a shared \nstrategy for both. In other situations, in more regulated industries, organizations are \nforced to run workloads on different providers (including on-prem workloads) to guar-\nantee resiliency in situations where an entire cloud provider can go down.\nThe kind of platforms we will be looking at extends the layers of customer behavior \nmentioned before to include company-specific services, company-specific standards, \nand developer experiences that allow the organization’s development teams to build \ncomplex systems for the organization and their customers. Figure 1.3 shows how, no \nmatter whether we are consuming cloud services, third-party services, or internal ser-\nvices, organizations must mix and match these services by building layers on top that \nare focused on solving business-specific challenges.\nOrganization Specific\nServices\nData Sources\nTools\nEvent Sources\nApplication Services & Industry specific Services\nDevelopment tools\nApplication Infrastructure\nOperational tools\nOperating System and Base Software\nInfrastructure & Computing Resources\nCloud Provider (Generic)\nThird-Party \nServices\nFigure 1.3    Organization-specific layers\n",
      "content_length": 2106,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 25,
      "content": "6\nChapter 1  (The rise of) platforms on top of Kubernetes \nThese extra layers are, most of the time, “glue” between existing services, data, and \nevent sources combined to solve particular challenges the business faces or to imple-\nment new features for their customers. It is common to rely on third-party service pro-\nviders for more business-specific tools, for example, industry-specific or generic CRM \n(Customer Relationship Management) systems, such as Salesforce. \nFor the customers, the platform, the cloud provider, and where the services are run-\nning are entirely irrelevant. Internally, for development teams, the platform acts as an \nenabler for development teams to do their work. Platforms are not static, and their \nmain objective is to help the organization improve and excel at continuously delivering \nhigh-quality software to its customers. \nNo matter the industry where your company operates and whether you choose to use \na cloud provider, your company’s combinations of tools and workflows to deliver new \nfeatures to its customers can be described as your platform. Technically, platforms are \nall about system integrations, best practices, and composable services that we can com-\nbine to build more complex systems. This book will look at standard practices, tools, \nand behaviors that make platforms successful and how you can build your cloud-native \nplatforms, whether running on one or more cloud providers or on-premises. \nWe will use cloud providers as a reference to compare the services and tools they \nprovide and learn how we can achieve similar results in a multi-cloud provider and \non-premises way by using open-source tools. But before looking into concrete tools, it is \nessential to understand what kind of experiences we can get from cloud providers. \n1.1.3\t\nWorking with cloud platforms\nOne common denominator between all cloud providers is that they provide services \nusing an API-first approach. This means that to access any of their services, an API will \nbe available to the users to request and interact with this service. These APIs expose all \nthe service functionality, such as which resources can be created, with which configu-\nration parameters, where (in which region of the world) we want the resource to run, \netc. Another important aspect of these APIs is that they require a team to own these \nAPI definitions; this means that a team will be in charge of identifying how these APIs \nare going to be used and how they are going to evolve and have clear definitions of \nwhat these APIs are not responsible for. \nEach cloud provider can be analyzed by looking at their APIs, because there will \nusually be one API for each offered service. It is common to see services in the beta or \nalpha stage only offered through the APIs for early users to experiment, test, and pro-\nvide feedback before the service is officially announced. While the structure, format, \nand style tend to be similar for all the services provided by a cloud provider, there are \nno standards across cloud providers to define how these services should be exposed and \nwhich features they need to support.  \nManually crafting complex requests against the cloud provider services, APIs is com-\nplex and error prone. It is a common practice by cloud providers to simplify the devel-\noper’s life by providing SDKs (software development kits) that consume the services \n",
      "content_length": 3396,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 26,
      "content": "\t\n7\nWhat is a platform, and why do I need one?\nAPIs implemented in different programming languages. This means developers can \nprogrammatically connect and use a cloud provider’s services by including a depen-\ndency (library, the cloud provider SDK) for their applications. While this is handy, it \nintroduces some strong dependencies between the application’s code and the cloud \nprovider, sometimes requiring us to release our application code to upgrade these \ndependencies. \nIn the same way that with APIs, with SDKs, there are no standards, and each SDK \nheavily depends on the programming language ecosystem’s best practices and tools. \nThere are cases where the SDKs don’t play nice with frameworks or tools that are pop-\nular in the programming language that you are using. Examples where SDKs/Clients \ncan go wrong, include database drivers that don’t align with the version provided by \nthe cloud provider or languages and ecosystems that the Cloud Provider does not yet \nsupport. In such cases, going directly to the API is possible but hard and usually discour-\naged, because your teams will maintain all the code required to connect to the cloud \nprovider services. \nCloud providers also provide CLIs (command-line interfaces), tools for operations \nteams and some developers’ workflows. CLIs are binaries you can download, install, \nand use from your operating system terminal. CLIs interact directly with the cloud pro-\nviders’ APIs but don’t require you to know how to create a new application to interact \nwith the services as with SDKs. CLIs are particularly useful for continuous integration \nand automation pipelines, where resources might need to be created on demand, for \nexample, to run our integration tests.\nFigure 1.4 shows applications and automation such as CI/CD pipelines and inte-\ngration tests consuming the same APIs but using different tools designed by the cloud \nprovider to simplify these scenarios. The figure also shows the Dashboard component, \nusually running inside the cloud provider, which provides visual access to all the ser-\nvices and resources being created.\nApplications\nCI/CD Pipelines\nIntegration Tests\nScripts\nSDKs\nCLIs\nCloud Provider\nServices APIs\nDashboards\nFigure 1.4    Cloud providers’ SDKs, CLIs, and Dashboard clients \nFinally, due to the number of services provided and the interconnections between the \nservices, cloud providers offer dashboards and user interfaces to access and interact \nwith all the offered services. These dashboards also offer reporting, billing, and other \n",
      "content_length": 2543,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 27,
      "content": "8\nChapter 1  (The rise of) platforms on top of Kubernetes \nfunctions that are hard to visualize using the CLIs or directly via the APIs. By using \nthese dashboards, users can access most of the standard features provided by the ser-\nvices and real-time access to see what is being created inside the cloud provider. \nAs mentioned, dashboards, CLIs, and SDKs require your teams to learn about many \ncloud provider-specific flows, tools, and nomenclature. Because of the number of ser-\nvices provided by each cloud provider, it is no wonder why finding experts that can \ncover more than a single provider is challenging. \nBecause this is a Kubernetes-focused book, I wanted to show the experience pro-\nvided by a cloud provider to create a Kubernetes cluster, which demonstrates the dash-\nboard, CLI, and API exposed by the Google Cloud Platform. Some cloud providers \nprovide a better experience than others, but overall, you should be able to achieve the \nsame with all the major ones. \n1.1.4\t\nGCP dashboard, CLIs, and APIs\nLook at the Google Kubernetes Engine dashboard in figure 1.5 to create new Kuber-\nnetes clusters. As soon as you click Create a New Cluster, you are presented with a form \nasking you to fill in a few required fields, such as the name of the cluster. \nFigure 1.5    Google Kubernetes Engine creation form\nCloud providers do a fantastic job at having sensible defaults to avoid asking you to \nfill in 200 parameters before creating the needed resource. Once you have filled in all \nthe required fields, the form offers a quick way to start the provisioning process by just \n",
      "content_length": 1596,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 28,
      "content": "\t\n9\nWhat is a platform, and why do I need one?\nclicking the Create button down the bottom. It is pretty interesting to see that, in this \ncase, the Google Cloud Platform offers you an estimated cost per hour of the resource \nthat you have configured. This highlights the difference between providing features \nfor technical teams and providing a full service, covering the needs of technical teams \nand clarifying how these decisions can affect the business as a whole. You can start \ntweaking parameters to see how this cost changes (usually, it goes up). \nFigure 1.6    Create via a dashboard, REST, or using a Command Line Interface (CLI) tool\nAs shown in figure 1.6, right beside the Create button, you can see the REST option. \nThe cloud provider here helps you by crafting the REST request to their APIs needed \nto create the resource you can configure using the forms. This is quite handy if you \ndon’t want to spend hours looking at their API documents to find the shape of the pay-\nload and properties needed to create the request; see figure 1.7. \nFigure 1.7    Create via Kubernetes cluster using a REST request\nFinally, the CLI command option, using the cloud provider CLI, in this case, gcloud, \nis once again crafted to contain all the parameters the CLI command needs based on \nwhat you have configured in the form, as shown in figure 1.8. \n",
      "content_length": 1356,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 29,
      "content": "10\nChapter 1  (The rise of) platforms on top of Kubernetes \nFigure 1.8    Create via Kubernetes cluster using the gcloud CLI\nNotice the horizontal scroll in figure 1.8; this command can become extremely com-\nplex. The Google Cloud Platform’s user experience team has done a wonderful job \nsimplifying how teams can set all these parameters by relying on sensible defaults. \nThere are no differences between these approaches regarding the expected behav-\nior, but you need to consider that when you use the cloud provider’s dashboard, your \naccount credentials are being used from your current session. If you are crafting a \nrequest or using the CLI from outside the cloud provider’s network, you must first \nauthenticate with the cloud provider before issuing the request or executing the com-\nmand to create the resource(s). It is essential to notice that these interactions will dif-\nfer from cloud provider to cloud provider. You cannot expect the commands to be \nsimilar in AWS or Azure, the dashboard interactions, or how the security mechanism \nworks to authenticate the CLIs or REST requests.  \n1.1.5\t\nWhy do cloud providers work?\nWhile one can argue that dashboards, CLIs, APIs, and SDKs are the primary artifacts \nwe will consume from cloud providers, but the big question is: how will we combine \nthese tools to deliver software? Suppose you analyze why organizations worldwide trust \nAWS, Google Cloud Platform, and Microsoft Azure. You will likely find that by adopt-\ning an API-first approach and offering dashboards, CLIs, SDKs, and a myriad of ser-\nvices, these platforms provide teams with three main features that define platforms \ntoday (figure 1.9):\n",
      "content_length": 1670,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 30,
      "content": "\t\n11\nPlatforms built on top of Kubernetes\n¡ APIs (contracts): No matter which tools you use, the platform must expose a set of \nAPIs enabling teams to consume or provision the resources needed to do their \nwork. These APIs are the responsibility of the platform engineering teams to \nmaintain and evolve \n¡ Golden paths to production: The platform codifies and automates workflows \nrequired by teams to get their changes into production environments where live \ncustomers/users can access them. \n¡ Visibility: At all times, by looking at the cloud provider dashboard, the organiza-\ntion can monitor which resources are being used, how much each service costs, \ndeal with incidents, and have a complete picture of how the organization delivers \nsoftware.\nCloud Provider\nApplication Services and \nTools Using an API-First \napproach\nEnable us to build our \ngolden paths to production \nusing Automation \nServices and Tools\nVisibility on operations, \ncost and efficiency\nFigure 1.9    Cloud provider platforms’ advantages\nThese key features are provided using a competitive pay-as-you-go model that heavily \nrelies on demand (traffic), at a global scale (not for all services), allowing the organiza-\ntion to externalize all the operation and infrastructure costs.  \nWhile cloud providers are going higher and higher up the stack (providing high-\nlevel services, not just provisioning hardware and application infrastructure such as \ndatabases), your teams still need to learn and glue these services together to solve their \nbusiness challenges.\nThis is where Kubernetes and the CNCF landscape (Cloud-Native Computing Foun-\ndation, https://www.cncf.io/) become key areas to explore for learning how to build \nplatforms that are cloud-provider agnostic and allow us to pick and choose from a big \npool of vibrant projects. Let’s move on to that next.\n1.2\t\nPlatforms built on top of Kubernetes\nWe have briefly discussed what platforms are and how cloud providers are driving the \nway forward to define what these platforms can do for organizations and development \nteams in charge of delivering software. But how does this map to Kubernetes? Isn’t \nKubernetes a platform? \nKubernetes was designed to be a declarative system for our cloud-native applica-\ntions. Kubernetes defines a set of building blocks that allows us to run and deploy our \nworkloads. Nowadays, every major cloud provider offers Kubernetes-managed services, \n",
      "content_length": 2422,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 31,
      "content": "12\nChapter 1  (The rise of) platforms on top of Kubernetes \nwhich enables us with a standardized way of packaging (containers) and deploying \nworkloads across cloud providers. Because Kubernetes comes with its tools and ecosys-\ntem (the CNCF landscape, https://landscape.cncf.io/), you can create cloud-agnostic \nworkflows to build, run, and monitor your applications. But learning Kubernetes is just \nthe starting point, because the building blocks provided by Kubernetes are very low \nlevel and designed to be composed to build tools and systems that solve more concrete \nscenarios. Combining these low-level building blocks provided by Kubernetes to build \nmore complex tools to solve more specific challenges is a natural evolutionary step. \nWhile Kubernetes provides us with APIs (the Kubernetes APIs), a CLI (kubectl), \nand a dashboard (Kubernetes Dashboard, https://kubernetes.io/docs/tasks/access \n-application-cluster/web-ui-dashboard/), Kubernetes is not a platform. Kubernetes is \na meta-platform or a platform to build platforms, because it provides all the building \nblocks you need to build concrete platforms that will solve domain-specific challenges.\nFigure 1.10 shows how Kubernetes tools and components map to what we have dis-\ncussed about platforms and cloud providers. \n`kubectl` CLI\nKubernetes SDKs\n<HTTP requests>\nKubernetes APIs\nKubernetes Dashboard\nKubernetes Cluster\nFigure 1.10    Kubernetes offer us a CLI, SDKs and dashboards, is it a platform? \nKubernetes can be extended, and that’s why this book will look into specific projects \nusing the Kubernetes APIs, tools, or internal mechanisms to solve generic challenges \nlike continuous integration, continuous delivery, provisioning cloud resources, moni-\ntoring and observability, and developer experience, among others. \n1.2.1\t\nThe Kubernetes adoption journey\nIt is fundamental that, no matter which tools platform teams choose, we abstract all the \ncomplexity and all the glue code we write to make these tools work together from the \nteams consuming these tools. Remember that application development teams, testing \nteams, and operations teams, among others, have different priorities and concerns. As \npart of the Kubernetes adoption journey, we must be we must be aware that not all the \nteams consuming these tools to be experts on Kubernetes. \nExtending Kubernetes with your custom extensions is one way to make Kubernetes \nwork for your organization-specific challenges. Remember that no matter which tools \nyou write or install in your Kubernetes clusters, the operations teams will need to run \nthem in your production environments and keep them running at scale. Each new tool \nor extension you write will require training the consumer teams to understand how \nthese tools work and for which scenarios they were designed. It is quite easy to end up \n",
      "content_length": 2842,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 32,
      "content": "\t\n13\nPlatforms built on top of Kubernetes\nin a situation where you have chosen 10 different tools that need to be integrated, and \nglue code needs to be written. Platform teams always evaluate the trade-offs between \nwriting glue code, rewriting a more tailored solution for their use case, or extending \nexisting tools. I strongly recommend you get familiar with the tools in the CNCF land-\nscape (https://landscape.cncf.io) to avoid going in a direction where every tool you \nuse is custom-made for your organization, meaning that you will need to maintain inter-\nnally all these tools in the long run.\nAbstracting away complexity is a key part of building platforms. A clear contract with \nyour teams specifying what the platform can do for them is crucial to successful plat-\nform engineering initiatives. These contracts are exposed as APIs that teams can inter-\nact with programmatically, using a dashboard, or via automation. \nFigure 1.11 shows a typical Kubernetes adoption journey toward platform engineer-\ning. The journey starts by adopting Kubernetes as the target platform to run your work-\nloads, followed by researching and selecting tools, usually from the CNCF Landscape. \nWhen initial tools are selected, your platform starts to shape up, and some investment \nis needed to configure and make these tools work for your teams. Finally, all these con-\nfigurations and tools selected can be hidden behind a friendlier platform API, allowing \nend users to focus on their workflows instead of trying to understand every detail about \nthe tools and glue code forming the platform. \nKubernetes\nCNCF \nLandscape\nTools and \nFrameworks\nYour Platform \nChoices\nYour Platform \nGlue Code\nTools and \nFrameworks\nYour Platform \nAPIs\nApplication \nDevelopment Teams\nPlatform Engineering Team\nFigure 1.11    Platform journey on Kubernetes\nGoing through this journey, we can define platforms as how we encode the knowledge \nit takes to provide our development teams with all the workflows they need to be pro-\nductive. The operational knowledge and the decisions on the tools used to implement \nthese workflows are encapsulated behind a contract materialized as the platform APIs. \nThese APIs can use the Kubernetes APIs to provide a declarative approach, but this \nis optional. Some platforms hide that the platform uses Kubernetes, which can also \nreduce the cognitive load from teams interacting with it.  \n",
      "content_length": 2405,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 33,
      "content": "14\nChapter 1  (The rise of) platforms on top of Kubernetes \nWhile I’ve tried to cover from a very high level what a platform is, I prefer to delegate \nall the formal definitions to working groups in the cloud-native space that are in charge \nof defining and keeping terms updated. I strongly suggest you check the App Delivery \nTAG - Platform Working Group from the CNCF white paper on platforms (https://\ntag-app-delivery.cncf.io/whitepapers/platforms/), which takes on the work of trying to \ndefine what platforms are.\nTheir current definition, at the time of writing this book, reads as follows: “A plat-\nform for cloud-native computing is an integrated collection of capabilities defined and \npresented according to the needs of the platform’s users. It is a cross-cutting layer that \nensures a consistent experience for acquiring and integrating typical capabilities and \nservices for a broad set of applications and use cases. A good platform provides consis-\ntent user experiences for using and managing its capabilities and services, such as web \nportals, project templates, and self-service APIs.”\nIn this book, we will embark on this journey of building an example platform by look-\ning at the available cloud-native tools to see how they can provide different platform \ncapabilities. But where do we find these tools? Do these tools work together? How do we \nchoose between different alternatives? Let’s take a quick look at the CNCF Landscape.\n1.2.2\t\nThe CNCF Landscape puzzle\nKeeping up with cloud provider services is a full-time job, and each cloud provider \nhosts a yearly conference and minor events to announce what is new and shiny. In the \nKubernetes and cloud native space, you can expect the same. The CNCF landscape is \ncontinuously expanding and evolving. As you can see in figure 1.12, the landscape is \nhuge and very difficult to read at first sight.\nFigure 1.12    The CNCF landscape (Source: https://landscape.cncf.io)\n",
      "content_length": 1947,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 34,
      "content": "\t\n15\nPlatforms built on top of Kubernetes\nA significant difference compared to cloud provider-offered services is the public and \ncommunity-driven maturity model that each project in the CNCF must follow to obtain \nthe graduated status. Each project’s maturity journey is independent of any cloud pro-\nvider, and you, as an individual or as an organization, can influence where the project \nis going or how fast it gets there.\nWhile cloud providers have defined the cloud’s shape, most are now involved in \nCNCF projects pushing for these open initiatives to succeed. They are working on tools \nthat can be used across cloud providers, removing barriers and allowing innovation in \nthe open instead of behind each cloud provider’s door. Figure 1.13 shows how Kuber-\nnetes enabled the cloud native innovation ecosystem to flourish outside cloud provid-\ners. Cloud providers haven’t stopped offering new, more specialized services, but in the \nlast five years, we have seen a shift toward improved collaborations across cloud provid-\ners and software vendors to develop new tools and innovation in the open.\nCNCF Ecosystem\nCI/CD Tools\nObservability Tools\nOperations Tools\nMachine Learning \nTools\nServerless Tools\nSecurity Tools\nStorage Tools\nMicrosoft Azure\nAmazon AWS\nGoogle Cloud \nPlatform\nAlibaba Cloud\nIBM Cloud\nKubernetes\nBuilding Blocks to run workloads\nServices, Deployments, Ingress, Jobs, NetworkPolicies, etc\nCommunity Driven \nEcosystem\nVendor Driven \nServices\nFigure 1.13    Kubernetes enabling a multi-cloud cloud-native ecosystem\nA common denominator from most CNCF-hosted projects is that they all work with \nKubernetes, extending it and solving high-level challenges closer to development \nteams. The CNCF has reached a point where more and more tools are being created to \nsimplify development tools and workflows. Interestingly, most of these tools don’t focus \njust on developers. They also enable operation teams and system integrators to glue \nprojects together and define new developer experiences native to Kubernetes. Devel-\nopment teams don’t need to worry about the tooling and integrations required for \ntheir day-to-day workflows. The increased maturity level of the communities involved \n",
      "content_length": 2214,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 35,
      "content": "16\nChapter 1  (The rise of) platforms on top of Kubernetes \nin the CNCF landscape and this push to simplify how development teams interact with \nall these tools gave birth to the conversations around platform engineering. The next \nsection will explore these conversations, why you can’t buy a platform, and how we will \nexplore this large ecosystem in the rest of this book.  \n1.3\t\nPlatform engineering\nIn the same way that cloud providers have internal teams defining which new services \nwill be offered, how these services are going to scale, and which tools and APIs need to \nbe exposed to their customers, it became clear that organizations can benefit from hav-\ning their internal platform engineering teams. These teams help enable development \nteams by deciding the tool selection that makes sense to best solve software delivery \nproblems and speed up the process. \nA common trend is having a dedicated platform engineering team to define these \nAPIs and make platform-wide decisions. The platform team collaborates with devel-\nopment teams, operations teams, and cloud provider experts to implement tools that \nmeet the needs of the workflows application teams. Besides having a dedicated plat-\nform engineering team, a key cultural change promoted by the book Team Topologies \n(https://teamtopologies.com/) is to treat the platform itself as an internal product \nand your development teams as customers. This is not new, but it pushes the platform \nteam to focus on these internal development teams’ satisfaction while using the plat-\nform’s tools. \nFigure 1.14 shows how application development teams (App Dev Teams) can focus \non working on new features using their preferred tools while the Platform Team creates \nGolden Paths (to production), which all the work produced by these teams to validate \nthe functionality and deliver these changes to our organization customers/end users. \nPlatform Team\nPlatform\nApp Dev \nTeams\nWork\nTools\nWork\nFeatures\nGolden \nPaths\nProduction \nEnvironment\nCustomer / \nEnd User\nFigure 1.14    Platform teams take the work done by developers safely to production.\n",
      "content_length": 2107,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 36,
      "content": "\t\n17\nPlatform engineering\nThis relationship between the platform and development teams creates synergy, focus-\ning on improving the entire organization’s software delivery practices. By creating \nGolden Paths, the platform doesn’t stop on the day-to-day development tasks. Still, it \nalso aims to automate how the changes made by development teams reach our organi-\nzation’s end customers/consumers. \nBy adding visibility to the whole process, you can help the entire organization under-\nstand and see how teams produce new features and when those features will be available \nto our end users. This can be very valuable business decisions, marketing, and for plan-\nning in general. \n1.3.1\t\nWhy can’t I just buy a platform?\nUnfortunately, you can’t buy an off-the-shelf platform to solve all your organization’s \nneeds. As we discussed, you can buy one or more cloud provider services, but your \ninternal teams will need to figure out which services and how they must be combined \nto solve specific problems. The exercise of figuring out which tools and services fit your \norganization’s needs and compliance requirements and how to encapsulate these deci-\nsions behind interfaces that teams can consume using a self-service approach is usually \nsomething you can’t buy. \nThere are tools designed with this situation in mind that try to enable platform teams \nto do less gluing by implementing a set of out-of-the-box workflows or having a very \nopinionated set of tools they support. Tools in this category that are also heavily using \nand extending Kubernetes are Red Hat OpenShift (https://www.redhat.com/en/ \ntechnologies/cloud-computing/openshift) and VMware Tanzu (https://tanzu.vmware \n.com/tanzu). These tools are very attractive to Chief Technology Officers (CTOs) and \narchitects because they cover most topics they need solutions for, such as CI/CD, oper-\nations, developer tooling, and frameworks. Based on my experience, while these tools \nare helpful in many scenarios, platform teams require flexibility in their chosen tools to \nfit their existing practices. At the end of the day, if you buy these tools, your teams will \nalso need to spend time learning them, which is why these tools like Red Hat OpenShift \nand VMware Tanzu are sold with consulting services, which is another cost to factor \ninto the equation. For medium and large organizations, adopting and adapting these \nopinionated off-the-shelf tools might require changes in well-defined workflows and \npractices that are already well-known to your teams. For smaller and less-mature organi-\nzations, these tools can save a lot of time by reducing the number of choices that teams \nwill face when getting started with new initiatives, but the cost of these tools and services \nmight be too high for a young organization.\nFigure 1.15 shows how the journey changes depending on which tools the platform \nteam chooses. These Kubernetes distributions (OpenShift, Tanzu, among others) can \nlimit the number of choices the platform teams can make, but they can also save time \nand come with services such as training and consulting that your teams can rely on.\n",
      "content_length": 3132,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 37,
      "content": "18\nChapter 1  (The rise of) platforms on top of Kubernetes \nKubernetes\nCNCF \nLandscape\nKubernetes \nDistribution\nYour Platform \nChoices\nYour Platform \nAPIs\nTools and \nFrameworks\nTools and \nFrameworks\nKubernetes \nDistribution Provider\nYour Platform Glue \nCode\nPlatform Engineering \nTeam\nKubernetes \nDistribution\nTools and \nFrameworks\nFigure 1.15    Building platforms on top of Kubernetes distributions\nNo matter if you are already a customer of these tools, you will still be in charge of \nbuilding a platform on top of these tools. If you have Red Hat OpenShift or VMware \nTanzu available to your teams, I strongly encourage you to familiarize yourself with the \ntools they support and their design choices and decisions. Aligning with the tools you \nhave and consulting with their architects might help you find shortcuts to build your \nlayers on top of these tools. \nA word of caution: It is crucial to notice that these tools can be considered Kubernetes \ndistributions. Distributions in the same sense as Linux distributions mean that I expect \nmore and more distributions to appear, tackling different challenges and use cases. \nTools like K0s and MicroK8s for IoT and edge cases are other examples. While you can \nadopt any of these distributions, ensure they align with your organization’s goals. \nBecause I want to keep this book as practical as possible, we will look at a simple \napplication we will use to go on our journey in the next section. We will not build a \ngeneric platform for a generic use case. We will build an example platform demonstrat-\ning the concepts covered in the previous sections. Having a concrete example you can \nrun, experiment with, and change should help you map the topics discussed to your \nday-to-day challenges. The application introduced in the next section highlights the \nchallenges you will face while creating, building, and maintaining distributed applica-\ntions in most business domains. Hence, the example platform we will build to support \nthis application should map to the challenges you will face in your business domain.\n1.4\t\nThe need for a walking skeleton\nIn the Kubernetes ecosystem, it is common to need to integrate at least 10 or more \nprojects or frameworks to deliver a simple PoC (proof of concept). This work can cover \ntopics such as building projects into containers that can run inside Kubernetes and \nrouting traffic to the REST endpoints provided by each service. If you want to exper-\niment with new projects to see if they fit into your ecosystem, build a PoC to validate \nyour understanding of how this new project/framework works and how it will save you \nand your team time. \nFor this book, I have created a simple “walking skeleton.” This cloud-native appli-\ncation goes beyond being a simple PoC and allows you to explore how different \n",
      "content_length": 2816,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 38,
      "content": "\t\n19\nThe need for a walking skeleton\narchitectural patterns can be applied. It also lets you test how different tools and frame-\nworks can be integrated without changing your projects for experimentation. I’ve pre-\nferred the term “walking skeleton” instead of “proof of concept” or “demo application”, \nas the term walking skeleton reflects more closely the intention of the application intro-\nduced in this section.\nThe primary purpose of this walking skeleton is to highlight how to solve very spe-\ncific challenges from an architectural point of view, the requirements that your applica-\ntions will need, and the delivery practices’ angle. You should be able to map how these \nchallenges are solved in the sample cloud-native application to your specific domain. \nChallenges will not always be the same, but I want to highlight the principles behind \neach proposed solution and the approach taken to guide your decisions.\nWith this walking skeleton, you can also figure out the minimum viable product you \nneed and deploy it quickly to a production environment where you can improve it. \nBy taking the walking skeleton to a production environment, you can gain valuable \ninsights into what you will need for other services and from an infrastructure perspec-\ntive. It can also help your teams understand what it takes to work with these projects and \nhow and where things can go wrong. \nThe technology stack used to build the walking skeleton is unimportant. It is more \nimportant to understand how the pieces fit together and what tools and practices can \nenable each team behind a service (or a set of services) to evolve safely and efficiently.  \n1.4.1\t\nBuilding a Conference application\nThroughout this book, you will be working with a Conference application. This Confer-\nence application can be deployed in different environments to serve different events. \nThis application relies on containers, Kubernetes, and tools that will work across any \nmajor cloud providers and on-prem Kubernetes installations. \nFigure 1.16 shows what the application’s main page looks like.\nFigure 1.16    Conference application home page\n",
      "content_length": 2128,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 39,
      "content": "20\nChapter 1  (The rise of) platforms on top of Kubernetes \nThe Conference application allows users to manage conference events, and it provides \na basic landing page, an Agenda page where all the approved talks will be listed, and a \nCall for Proposals form where potential speakers can submit their talk proposals. The \napplication also allows conference organizers to do admin tasks, such as reviewing sub-\nmitted proposals and approving or rejecting them (see figure 1.17). \nFigure 1.17    Conference application Back Office page\nThis application is composed of a set of services that have different responsibilities. \nFigure 1.18 shows the main components of the application that you control—in other \nwords, the services that you and your team will be changing and delivering. \nEnd User\nFrontend\nNextJS\nFrontend(Backend)\nAgenda Service\nC4P Service\nNotifications \nService\nFigure 1.18    Conference application services. The end user interacts with the frontend that routes \nrequests to all the backend services.\nThe team has created these services to implement a basic walking skeleton with func-\ntionality that demonstrates business value. Here is a brief description of each service:\n¡ Frontend: This service is the main entry point for your users to access the applica-\ntion. For this reason, the service hosts a NextJS application (HTML, JavaScript, \nand CSS files) that the client’s browser will download. The client-side application \n",
      "content_length": 1445,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 40,
      "content": "\t\n21\nThe need for a walking skeleton\ninteracts with a backend service that accepts the requests from the browser and \nroutes each request to one or more backend services. \n¡ Agenda service: This service deals with listing all the talks that were approved for \nthe conference. This service needs to be highly available during the conference \ndates, because the attendees will be hitting this service several times during the \nday to move between sessions. \n¡ Call for Proposals (C4P): This service contains the logic to deal with Call for Pro-\nposals use case (C4P for short) when the conference is being organized. This \nfunctionality allows potential speakers to submit talk proposals that the confer-\nence organizers will review and decide which ones to include in the conference \nagenda.\n¡ Notifications service: This service enables the conference organizers to send notifi-\ncations to attendees and speakers. \nFigure 1.19 shows the Call for Proposals flow that was selected by the team to build \nthe walking skeleton and validate their assumptions about how the Conference appli-\ncation will work. By implementing this use case end to end, the team can validate its \nchosen technology stack and architectural assumptions. \nConference \nOrganizer\nPotential \nSpeaker\nMain Site\nBack Office\nC4P Service\nNotifications \nService\nAgenda Service\n#1 A potential \nspeaker submits a \nnew Proposal from \nthe Conference Site\n#2 A conference organizer \nreview the proposal in the \nConference Back Office and \ndecides to approve or reject it\n#3 An automated \nnotification is sent to the \npotential speaker about \nthe decision made by \nthe organizers\n#4 Only if the proposal is \napproved is automatically \nadded to the Conference \nAgenda page\nFrontend\nFigure 1.19    Call for Proposals use case\nAfter implementing the basics of the Call for Proposals use case, the team can decide \nwhat use case to implement next. Do the conference organizers need to manage spon-\nsors? Do the speakers need a dedicated profile page? Adding new features or services \nshould be straightforward because the base building blocks are in place.\nWhile looking at how these use cases are implemented, you need to consider also \nhow to coordinate across teams when new use cases will be implemented or when \nchanges need to be introduced. To improve collaboration, you need visibility, and you \nneed to understand how the application is working.\n",
      "content_length": 2409,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 41,
      "content": "22\nChapter 1  (The rise of) platforms on top of Kubernetes \nYou also need to consider the operation side of this cloud-native application. You \ncan imagine there will be a period when the application will open the Call for Proposals \nrequest for potential speakers to submit proposals, then closer to the conference date, \nopen the attendee registration page, etc. \nThroughout this book, I will encourage you to experiment by adding new services \nand implementing new use cases. In chapter 2, when you deploy the application to a \nKubernetes cluster, you will inspect how these services are configured to work, how the \ndata flows between the different services, and how to scale the services. \nBy playing around with a fictional application, you are free to change each service’s \ninternals, use different tools and compare results or even have different versions of \neach service to try in parallel. Each service provides all the resources needed to deploy \nthese services to your environment. In chapters 3 and 4, we will go deeper into each \nservice to understand how to build and deploy each service so teams can change the \ncurrent behavior and create and deploy new releases.\nBefore deploying this cloud-native conference application, it is important to men-\ntion some of the main differences with bundling all these functionalities in a single \nmonolithic application. \nBut what about if the Conference application was created using a monolith \napproach? Let’s briefly discuss what the main differences would be.  \n1.4.2\t\nDifferences between a monolith and a distributed set of services\nUnderstanding the differences between having a single monolithic application and a \nfully distributed set of services is critical to grasping why the increased complexity is \nworth the effort. If you are still working with monolithic applications that you want to \nsplit up to use a distributed approach, this section highlights the main differences you \nwill encounter. \nFigure 1.20 shows a monolithic application implementing the same use case dis-\ncussed before, but in this scenario, different teams working on different features will \nshare the same codebase. There are no explicit requirements for strong interfaces \nbetween internal services when developing a monolithic application. It’s optional to \nseparate the logic of different functionalities in well-encapsulated modules. The lack \nof interfaces and overlap between functionality pushes the teams making changes on \nthe application to have complex coordination strategies to ensure that features don’t \nconflict and that changes can be merged in the codebase.\nConference Application\nFrontend\nC4P Service\nAgenda Service\nNotifications \nService\nFigure 1.20    In a monolith application, all the logic to implement different use cases are bundled \ntogether. This push different teams to work on the same codebase and requires them to have complex \ncoordination practices to avoid conflicting changes.\n",
      "content_length": 2957,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 42,
      "content": "\t\n23\nThe need for a walking skeleton\nFunctionally wise, they are the same and you can do the same amount of use cases, but \nthe monolith application presented some drawbacks that you might be experiencing \nwith your monolith applications already. The following points highlight the benefits of \nthe cloud-native application that we will use in this book and some disadvantages asso-\nciated with a parallel-universe alternative monolithic implementation: \n¡ Now services can evolve independently, teams are empowered to go faster, and there is no \nbottleneck at the codebase level: In the monolithic application, there is a single source \ncode repository for different teams to work on, there was a single continuous \nintegration pipeline for the project which was slow, and teams were using feature \nbranches that caused problems with complex merges. \n¡ Now the application can scale differently for different scenarios: From a scalability \nperspective, each service can be scaled depending on the load level it experi-\nences. With the monolith application, the operations team can only create new \ninstances of the entire application if it need to scale just a single functionality. \nFine-grained control over how different functionalities are scaled can be a signifi-\ncant differentiator for your use case, but you must do your due diligence. \n¡ The cloud-native version is much more complex, because it is a distributed system: It \nuses the flexibility and characteristics of the cloud infrastructure much better, \nallowing the operation teams to use tools to manage this complexity and the \nday-to-day operations. Creating your in-house mechanism to operate large appli-\ncations was much more common when building monolithic applications. In \ncloud-native environments, there are a lot of tools provided by cloud providers \nand open-source projects that can be used to operate and monitor cloud-native \napplications. \n¡ Welcome polyglotism: Each service can be built using a different programming lan-\nguage or different frameworks. With the monolith, application developers were \nstuck in old versions of libraries, because changing or upgrading a library usu-\nally involved large refactoring, and the whole application needed to be tested \nto guarantee that the application will not break. In a cloud-native approach, ser-\nvices are not forced to use a single technology stack. This allowed teams to be \nmore autonomous in choosing their tools, which can speed up delivery times in \nsome situations. \n¡ All or nothing with the monolith: If the monolith application went down, the entire \napplication is down, and users couldn’t access anything. With the cloud-native \nversion, users can still access the application even if services are down. The exam-\nple walking skeleton shows how to support degraded services by adopting popu-\nlar tools. By using Kubernetes, which was designed to monitor your services and \ntake action in case a service is misbehaving, the platform will try to self-heal your \napplications. \n¡ Each conference event required a different version of the monolith: When dealing with \ndifferent events, each conference required a version of the monolith slightly dif-\nferent from the other events. This causes divergent codebases and duplication \n",
      "content_length": 3271,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 43,
      "content": "24\nChapter 1  (The rise of) platforms on top of Kubernetes \nof the entire project. Most of the changes done for a conference were lost when \nthe event was done. In the cloud-native approach, we promote reusability by hav-\ning fine-grained services that can be swapped, avoiding duplication of the whole \napplication. \nWhile the monolith application is much more straightforward to operate and develop \nthan the cloud-native application, the remainder of the book focuses on understand-\ning and reducing the complexity of building a distributed application. We’ll do that by \nadopting the right tools and practices, which will unlock your teams to be more inde-\npendent and efficient while promoting resiliency and robustness to your applications. \nIf you are currently working with a monolith application, I hope this book helps you \nto compare different approaches and introduces you to the tools and practices that are \nrequired for building distributed applications.  \n1.4.3\t\nOur walking skeleton and building platforms\nNow that we have a simple application that our customers will be using, we can focus \non understanding all the tools our teams will need to improve these services continu-\nously. The platforms we will cover in this book are those organizations that will build \nfor domain-specific purposes, not generic ones. By creating our walking skeleton for \na specific scenario, we can mimic a platform that optimizes tools and workflows to \nimprove how software gets delivered for those teams. Our walking skeleton is not a \nsimple “Hello World” application, so it allows for more experimentation, writing more \ncomplex features, and using tools to make the application more robust. \nWe will now embark on a cloud-native journey. First, we will look into how distributed \napplications run on top of Kubernetes, what Kubernetes provides, and its challenges. \nRight after that, we will start looking into tools that will extend the basic Kubernetes \nfeatures to assist us in building, deploying, and running our cloud-native applications.\nLater on, in chapter 6, after evaluating some of the challenges of building and deliv-\nering distributed applications, we will build our platform walking skeleton that will help \nteams create new features to work with the existing application in a safe environment, \nwhere they can do their day-to-day work without conflicting with other teams. Once we \nhave our platform walking skeleton, we will build and offer higher-level platform capa-\nbilities to enable our teams to be more productive and reduce their need to understand \nthe complexity of Kubernetes and all the tools we will discuss in this book. \nFinally, to close the book, we will look at how to measure how good the platforms that \nwe are building are. As with any software, we need to measure it to ensure that new tools \nor changes we introduce make things better and not worse.\nThis journey will push us to make hard decisions and choices that will become critical \nfor our platform engineering practices. The following list covers the main milestones in \nthis journey without going into the details of the specific tools covered in each chapter.\n¡ Chapter 2: Cloud-native application challenges: After getting the Conference applica-\ntion up and running in a Kubernetes cluster, we will analyze the main and most \ncommon challenges you will face when working on and running cloud-native \n",
      "content_length": 3406,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 44,
      "content": "\t\n25\nThe need for a walking skeleton\napplications on top of Kubernetes. In this chapter, you will inspect the applica-\ntion from a runtime perspective and try to break it in different ways to see how it \nbehaves when things go wrong.\n¡ Chapter 3: Service pipelines: Building cloud-native applications: Once the applica-\ntion is up and running, you and your teams will change the application’s ser-\nvices to add new features or fix bugs. This chapter covers what it takes to build \nthese application services, including the latest changes using service pipelines \nto create a release of the artifacts needed to deploy these new versions into live \nenvironments.\n¡ Chapter 4: Environment pipelines: Deploying cloud-native applications: If we sort out \nhow to package and release new versions of our services, then we need to have a \nclear strategy on how to promote these new versions to different environments so \nthey can be tested and validated before facing real customers. This chapter cov-\ners the concept of environment pipelines and a popular trend in the cloud-native \ncommunity called GitOps to configure and deploy applications across different \nenvironments. \n¡ Chapter 5: Multi-cloud (app) infrastructure: Your applications can’t run in isolation. \nApplication services need application infrastructure components, such as data-\nbases, message brokers, identity services, etc., to work. This chapter focuses on \nhow to provision the components that our application’s services need using a \nmulti-cloud and Kubernetes-native approach.\n¡ Chapter 6: Let’s build a platform on top of Kubernetes: Once we understand how the \napplication runs, how it is built and deployed, and how it connects to cloud \ninfrastructure, we will focus our attention on abstracting the complexity intro-\nduced by all the tools that we are using from the teams making changes to the \napplication. We don’t want our development teams to get distracted setting up \ncloud-provider accounts, configuring the servers where the build pipelines will \nrun, or worrying about where their environment is running. Welcome to the plat-\nform engineering team!\n¡ Chapter 7: Platform capabilities I: Shared application concerns: How can we reduce \nfriction and dependencies between application and operation teams? How can \nwe decouple even further the logic of our applications from the components that \nthese applications need to run? This chapter covers a set of platform capabilities \nthat enable application developers to focus on writing code. The platform team \ncan concentrate on deciding how to wire all the components required by the \napplication and then expose simple and standardized APIs that developers can \nconsume. \n¡ Chapter 8: Platform capabilities II: Enabling teams to experiment: Now that we have a \nplatform that takes care of provisioning environments for our teams to do their \nwork, what else can the platform do for the application development teams? If \nyou enable your teams to run more than a single version of your application’s \nservices simultaneously, new features or fixes can be rolled out incrementally. \n",
      "content_length": 3111,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 45,
      "content": "26\nChapter 1  (The rise of) platforms on top of Kubernetes \nHaving room for experimentation allows the organization to find issues sooner \nand reduces each release’s associated stress. This chapter covers how to imple-\nment different release strategies for your cloud-native applications. \n¡ Chapter 9: Measuring your platforms: Platforms are as good as the improvements \nthey bring to the organization. We need to measure our platform performance \nto see how well it’s doing, because we should use a continuous improvement \napproach to ensure that the tools we use are helping our teams deliver faster and \nmore efficiently. This chapter focuses on using the DORA metrics to understand \nhow well the organization is delivering software and how platform changes can \nimprove the throughput of our delivery pipelines. \nNow that you know what is coming, let’s deploy our cloud-native Conference \napplication.  \nSummary\n¡ (Cloud) platforms provide a set of services for teams to build their domain-spe-\ncific applications.\n¡ Platforms usually offer three main features: APIs, dashboards, and SDKs for dif-\nferent teams to use whatever fits their workflows. \n¡ Cloud platforms provide a pay-as-you-go model to consume hardware and soft-\nware. The higher you go up the stack, the more expensive the service will be. \n¡ Kubernetes offers the basic building blocks to build platforms on top in a way \nthat we can remain independent of the underlying cloud provider and even \ndeploy our platforms on-premises.\n¡ The Cloud Native and Computing Foundation promotes and fosters collabora-\ntions between open-source projects in the cloud-native space. Keeping track of \nwhat is going on in these communities is a full-time job.\n¡ Platform engineering on Kubernetes (specifically for this book) helps manage \nthe complexity of choosing which tools and practices teams need to adopt to be \nmore efficient at delivering software that will run on top of Kubernetes.\n",
      "content_length": 1950,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 46,
      "content": "27\n2\nCloud-native \napplication challenges\nThis chapter covers\n¡ Working with a cloud-native application running \t\n\t in a Kubernetes cluster\n¡ Choosing between local and remote  \n\t Kubernetes clusters\n¡ Understanding the main components and  \n\t Kubernetes resources\n¡ Understanding the challenges of working with \t\n\t cloud-native applications\nWhen I want to try something new, a framework, a new tool, or just a new applica-\ntion, I tend to be impatient; I want to see it running immediately. Then, when it is \nrunning, I want to dig deeper and understand how it works. I break things to exper-\niment and validate that I understand how these tools, frameworks, or applications \nwork internally. That is the sort of approach we’ll take in this chapter! \nTo have a cloud-native application up and running, you will need a Kubernetes \ncluster. In this chapter, you will work with a local Kubernetes cluster using a project \ncalled KinD (Kubernetes in Docker, https://kind.sigs.k8s.io/). This local cluster will \nallow you to deploy applications locally for development and experimentation. To \n",
      "content_length": 1090,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 47,
      "content": "28\nChapter 2  Cloud-native application challenges \ninstall a set of microservices, you will use Helm, a project that helps package, deploy, \nand distribute Kubernetes applications. You will install the walking skeleton services \nintroduced in chapter 1, which implements a Conference application. \nOnce the services for the Conference application are up and running, you will \ninspect its Kubernetes resources to understand how the application was architected \nand its inner workings by using kubectl. Once you get an overview of the main pieces \ninside the application, you will jump ahead to try to break the application, finding com-\nmon challenges and pitfalls that your cloud-native applications can face. This chapter \ncovers the basics of running cloud-native applications in a modern technology stack \nbased on Kubernetes, highlighting the good and the bad that come with developing, \ndeploying, and maintaining distributed applications. The following chapters tackle \nthese associated challenges by looking into projects whose main focus is to speed up \nand make more efficient the delivery of your projects.\n2.1\t\nRunning our cloud-native applications\nTo understand the innate challenges of cloud-native applications, we need to be able \nto experiment with a simple example that we can control, configure, and break for \neducational purposes. In the context of cloud-native applications, “simple” cannot be \na single service, so for simple applications we will need to deal with the complexities of \ndistributed applications such as networking latency, resilience to failure on some of the \napplications’ services, and eventual inconsistencies. To run a cloud-native application, \nin this case, the walking skeleton introduced in chapter 1, you need a Kubernetes clus-\nter. Where this cluster is going to be installed and who will be responsible for setting it \nup are the first questions that developers will have. It is quite common for developers \nto want to run things locally, on their laptop or workstation, and with Kubernetes, this \nis possible—but is it optimal? Let’s analyze the advantages and disadvantages of run-\nning a local cluster against other options.\n2.1.1\t\nChoosing the best Kubernetes environment for you\nThis section doesn’t cover a comprehensive list of all the available Kubernetes flavors, \nbut it focuses on common patterns in how Kubernetes clusters can be provisioned \nand managed. There are three possible alternatives—all of them with advantages and \ndrawbacks:\n¡ Local Kubernetes in your laptop/desktop computer: I tend to discourage people from \nrunning Kubernetes on their laptops. As you will see in the rest of the book, \nrunning your software in similar environments to production is highly recom-\nmended to avoid problems that can be summed up as “but it works on my laptop.” \nThese problems are mostly caused by the fact that when you run Kubernetes on \nyour laptop, you are not running on top of a real cluster of machines. Hence, \nthere are no network round-trips and no real load balancing. \n–\t Pros: Lightweight, fast to get started, good for testing, experimenting, and \nlocal development. Good for running small applications.\n",
      "content_length": 3180,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 48,
      "content": "\t\n29\nRunning our cloud-native applications\n–\t Cons: Not a real cluster, it behaves differently, and has reduced hardware to \nrun workloads. You will not be able to run a large application on your laptop. \n¡ On-premise Kubernetes in your data center: This is a typical option for companies with \nprivate clouds. This approach requires the company to have a dedicated team \nand hardware to create, maintain, and operate these clusters. If your company is \nmature enough, it might have a self-service platform that allows users to request \nnew Kubernetes clusters on demand. \n–\t Pros: A real cluster on top of real hardware will behave closer to how a produc-\ntion cluster will work. You will have a clear picture of which features are avail-\nable for your applications to use in your environments. \n–\t Cons: It requires a mature operation team to set up clusters and give creden-\ntials to users, and it requires dedicated hardware for developers to work on \ntheir experiments.\n¡ Managed service Kubernetes offering in a cloud provider: I tend to be in favor of this \napproach, because using a cloud provider service allows you to pay for what you \nuse, and services like Google Kubernetes Engine (GKE), Azure AKS, and AWS \nEKS are all built with a self-service approach in mind, enabling developers to spin \nup new Kubernetes clusters quickly. There are two primary considerations:\n1\t You need to choose one cloud provider and have an account with a big credit \ncard to pay for what your teams will consume. This might involve setting up \nsome caps in the budget and defining who has access. By selecting a cloud \nprovider, you might be in a vendor lock-in situation if you are not careful. \n2\t Everything is remote, and for developers and other teams that are used to \nwork locally, this is too big of a change. It takes time for developers to adapt, \nbecause the tools and most of the workloads will run remotely. This is also an \nadvantage, because the environments used by your developers and the appli-\ncations that they are deploying are going to behave as if they were running in \na production environment.\n–\t Pros: You are working with real (fully fledged) clusters. You can define how \nmany resources you need for your tasks, and when you are done, you can \ndelete them to release resources. You don’t need to invest in hardware up \nfront.\n–\t Cons: You need a potentially big credit card, and you need your developers to \nwork against remote clusters and services.\nA final recommendation is to check the following repository, which contains free \nKubernetes credits in major cloud providers: https://github.com/learnk8s/free \n-kubernetes. I’ve created this repository to keep an updated list of these free trials that \nyou can use to get all the examples in the book up and running on top of real infra-\nstructure. Figure 2.1 summarizes the information contained in the previous bullet \npoints.\n",
      "content_length": 2902,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 49,
      "content": "30\nChapter 2  Cloud-native application challenges \nDevelopers are \nused to work locally.\nThese are in-house \nclusters but they feel \nremote to developers.\nThese are fully remote \nsetups, developers need to \nget used to new workflows.\nLocal\nPros\n•  Lightweight\n•  Fast to get started\n•  Good for local development\n•  Good for testing (CI)\n•  Good for small applications\nCons\n•  Limited capacity\n•  It doesn’t behave as a real  \n \n \ncluster\n•  Good network bandwidth is   \n \nrequired to download containers  \n \nto your laptop\nOn Premises\nPros\n•  Real cluster on top of real  \n \n \nmachines\n•  It behaves closer to a Production  \n \nEnvironment\n•  Provide a remote environment  \n \nfor development teams to work\nCons\n•  Requires you to have and  \n \n \nmaintain dedicated hardware\n•  Requires a mature team to  \n \n \nprovision the cluster and  \n \n \ndistribute credentials\n•  It might lack integrations and   \n \nextra features provided by cloud  \n \nproviders\n•  Difficult to scale up if you require  \n \na large number of clusters\nCloud Provider\nPros\n•  Fully fledged managed clusters\n•  You don’t need to deal with  \n \n \nhardware\n•  Easy to scale and manage\n•  Extra services provided (backup,  \n \napp infrastructure, security, etc.)\n•  Pay-as-you-go model\nCons\n•  Difficult to estimate costs, you  \n \nmight need a big credit card to  \n \npay for what you use\n•  Possible vendor lock-in\n•  Cloud-Provider specific expertise  \n \nrequired\nFigure 2.1    Kubernetes cluster Local vs. Remote setups. \nWhile these three options are all valid and have drawbacks, in the next sections, you will \nuse Kubernetes KinD (Kubernetes in Docker, https://kind.sigs.k8s.io/) to deploy the \nwalking skeleton introduced in chapter 1 in a local Kubernetes environment running on \nyour laptop/pc. Check the step-by-step tutorial located at https://github.com/salaboy/ \nplatforms-on-k8s/tree/main/chapter-2#creating-a-local-cluster-with-kubernetes-kind \nto create your local KinD cluster that we will use to deploy our walking skeleton, the \nConference application. \nNotice that the tutorial creates a local KinD cluster that simulates having three nodes \nand a special port mapping to allow our Ingress controller to route incoming traffic \nthat we will send to http://localhost.\n2.1.2\t\nInstalling the walking skeleton\nTo run containerized applications on top of Kubernetes, you will need to have each \nof the services packaged as a container image, plus you will need to define how these \ncontainers will be configured to run in your Kubernetes cluster. To do so, Kubernetes \nallows you to define different kinds of resources (using YAML format) to configure \nhow your containers will run and communicate with each other. The most common \nkinds of resources are: \n¡ Deployments: Declaratively define how many replicas of your container need to be \nup for your application to work correctly. Deployments also allow us to choose \nwhich container (or containers) we want to run and how these containers must \nbe configured (using environment variables). \n",
      "content_length": 3021,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 50,
      "content": "\t\n31\nRunning our cloud-native applications\n¡ Services: Declaratively define a high-level abstraction to route traffic to the con-\ntainers created by your deployments. It also acts as a load balancer between the \nreplicas inside your deployments. Services enable other services and applications \ninside the cluster to use the service name instead of the physical IP address of the \ncontainers to communicate, providing what is known as service discovery. \n¡ Ingress: Declaratively define a route for routing traffic from outside the cluster to \nservices inside the cluster. Using Ingress definitions, we can expose the services \nthat are required by client applications running outside the cluster. \n¡ ConfigMap/secrets: Declaratively define and store configuration objects to set up \nour service instances. Secrets are considered sensitive information that should \nhave protected access. \nThese YAML files will be complex and hard to manage if you have large applications \nwith tens or hundreds of services. Keeping track of the changes and deploying appli-\ncations by applying these files using kubectl becomes a complex job. It is beyond the \nscope of this book to cover a detailed view of these resources, and other resources \nare available such as the official Kubernetes documentation page (https://kubernetes \n.io/docs/concepts/workloads/). In this book, we will concentrate on how to deal with \nthese resources for large applications and the tools that can help us with that task. The \nfollowing section provides an overview of the tools to package and install components \ninto your Kubernetes cluster. \nPackaging and installing Kubernetes applications\nThere are different tools to package and manage your Kubernetes applications. Most \nof the time, we can separate these tools into two main categories: templating engines \nand package managers. You will probably need both kinds of tools for real-life scenar-\nios to get things done. Let’s discuss these two kinds of tools: why would you need a tem-\nplating engine? What kind of packages do you want to manage? \nA templating engine allows you to reuse the same resource definitions in different \nenvironments where applications might require slightly different parameters. The text-\nbook example of the need to template your resources is database URLs. If your service \nneeds to connect to different database instances in different environments, such as the \ntesting database in the testing environment and the production database in the produc-\ntion environment, you want to avoid maintaining two copies of the same YAML file but \nwith different URLs. Figure 2.2 shows how you can now add variables to the YAML files, \nand the engine will then find and replace these variables with different values depend-\ning on where you want to use the f﻿iinal (rendered) resource. \n",
      "content_length": 2829,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 51,
      "content": "32\nChapter 2  Cloud-native application challenges \nservice.yaml\nmyservice:\n   dbURL: {{dbURL}}\ndev.yaml\n  dbURL: dev.db.endpoint\ntest.yaml\n  dbURL: test.db.endpoint\nTemplating Engine\n            service.yaml\nmyservice:\n   dbURL: dev.db.endpoint\n             service.yaml\nmyservice:\n   dbURL: test.db.endpoint\nDev\nTest\nFigure 2.2    Templating engines render YAML resources by replacing variables.\nUsing a templating engine can save you a lot of time maintaining different copies of \nthe same file, because when files start to pile up, maintaining them becomes a full-time \njob. There are several tools in the community to deal with templating Kubernetes files. \nSome tools just deal with YAML files, and some other tools are more targeted to Kuber-\nnetes resources specifically. Some projects that you should check out are: \n¡ Kustomize: https://kustomize.io/\n¡ Carvel YTT: https://carvel.dev/ytt/ \n¡ Helm Templates: https://helm.sh/docs/chart_best_practices/templates/#helm \nNow, what do you do with all these files? It is quite a natural urge to organize these files \nin logical packages. If you are building an application that is composed of different ser-\nvices, it might make sense to group all the resources related to a service inside the same \ndirectory or even in the same repository that contains the source code for that service. \nYou also want to make sure that you can distribute these files to the teams deploying \nthese services to different environments, and you quickly realize that you need to ver-\nsion these files in some way. This versioning might be related to the version of your \nservice itself or with a high-level logical aggregation that makes sense for your appli-\ncation. When we talk about grouping, versioning, and distributing these resources, \nwe are describing the responsibility of a package manager. Developers and operations \nteams are already used to working with package managers no matter the technology \nstack they use. Maven/Gradle for Java, NPM for NodeJS, APT-GET for Linux/Debian/\nUbuntu packages, and more recently, containers and container registries for cloud-na-\ntive applications. So, what does a package manager for YAML files look like? What are \nthe package manager’s main responsibilities? \nAs a user, a package manager allows you to browse available packages and their meta-\ndata to decide which package you want to install. Once you have decided which package \nyou want to use, you should be able to download it and then install it. Once the package \nis installed, you would expect, as a user, to be able to upgrade to a newer version of the \npackage when it becomes available. Upgrading/updating a package requires manual \n",
      "content_length": 2681,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 52,
      "content": "\t\n33\nRunning our cloud-native applications\nintervention, meaning that as a user, you will explicitly tell the package manager to \nupgrade the installation of a certain package to a newer (or latest) version.\nFrom a package provider’s point of view, a package manager should offer a conven-\ntion and structure to create packages and a tool to package the files you want to distrib-\nute. Package managers deal with versions and dependencies, meaning that if you create \na package, you must associate a version number with it. Some package managers use the \nsemver (semantic versioning) approach, which uses three numbers to describe the pack-\nage maturity (1.0.1 where these numbers represent the major, minor, and patch ver-\nsions). A package manager doesn’t need to provide a centralized package repository, \nbut they often do. This package repository is in charge of hosting packages for users to \nconsume. Central repositories are useful because they provide access to developers with \nthousands of packages ready to be used. Some examples of these central repositories \nare Maven Central, NPM, Docker Hub, GitHub Container Registry, etc. These repos-\nitories are in charge of indexing the package’s metadata (which can include versions, \nlabels, dependencies, and short descriptions) to make them searchable by users. These \nrepositories also deal with access control to have public and private packages, but at the \nend of the day, the main responsibility of the package repository is to allow package pro-\nducers to upload packages and package consumers to download packages from them \n(see figure 2.3). \nPackage Manager\nYour Package \n0.1.0\nPackage \nRepository\nservice.yaml\ndeployment.yaml\ningress.yaml\nBuild \nand add \nmetadata\nDistribute\nSearch and \nConsume\nFigure 2.3    Package Managers’ responsibilities: build, package, and distribute\nWhen we talk about Kubernetes, Helm is a very popular tool that provides both a pack-\nage manager and a templating engine. But there are others worth looking into, such \nas: \n¡ Imgpkg (https://carvel.dev/imgpkg/), which uses Container registries to store \nthe packages.\n¡ Kapp (https://carvel.dev/kapp/), which provides higher-level abstractions to \ngroup resources as applications.\n¡ Tools like Terraform and Pulumi that allow you to manage infrastructure as code. \nIn the following section, we will look at using Helm (http://helm.sh) to install the \nConference application into our Kubernetes cluster.\n",
      "content_length": 2450,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 53,
      "content": "34\nChapter 2  Cloud-native application challenges \n2.2\t\nInstalling the Conference application with a single command\nLet’s install the Conference application introduced in chapter 1, section 1.4 into our \nKubernetes cluster using Helm. This Conference application allows conference orga-\nnizers to receive proposals from potential speakers, evaluate these proposals, and keep \nan updated agenda with the approved submissions for the event. We will use this appli-\ncation throughout the book to exemplify the challenges that you will face while build-\ning real-life applications. \nNOTE    For the complete list of steps, follow the step-by-step tutorial located at \nhttps://github.com/salaboy/platforms-on-k8s/tree/main/chapter-2. It includes \nall the prerequisites to run the commands described in this section, such as creating \na cluster and installing the command-line tools needed for the examples to work. \nThis application was built as a walking skeleton, which means it is not a complete appli-\ncation but has all the pieces required for the “Call for Proposals” flow to work. These \nservices can be iterated further to support other flows and real-life scenarios. In the \nfollowing sections, you will install the application into the cluster and interact with it to \nsee how it behaves when it runs on top of Kubernetes. Let’s install the application with \nthe following line:\nhelm install conference oci://docker.io/salaboy/conference-app --version \nv1.0.0\nYou should see the output similar to listing 2.1. \nListing 2.1    Helm installed the chart conference-app version 1.0.0\n> helm install conference oci://docker.io/salaboy/conference-app --version \n➥v1.0.0 \nPulled: registry-1.docker.io/salaboy/conference-app:v1.0.0\nDigest: \nsha256:e5dd1a87a867fd7d6c6caecef3914234a12f23581c5137edf63bfd9add7d5459\nNAME: conference\nLAST DEPLOYED: Mon Jun 26 08:19:15 2023\nNAMESPACE: default\nSTATUS: deployed\nREVISION: 1\nTEST SUITE: None\nNOTES:\nCloud-Native Conference Application v1.0.0\nChart Deployed: conference-app - v1.0.0\nRelease Name: conference\nFor more information visit: https://github.com/salaboy/platforms-on-k8s\nAccess the Conference Application Frontend by running \n➥'kubectl port-forward svc/frontend -n default 8080:80'\nNOTE    Since Helm 3.7+ you can package and distribute Helm Charts as OCI con-\ntainer images, the URL for the Helm Chart contains oci:// because this chart \nis hosted in Docker Hub, where the application containers are stored. Before \nHelm supported OCI images, you needed to manually add and fetch packages \nfrom a Helm Chart Repository, which used tar files to distribute these charts. \n",
      "content_length": 2619,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 54,
      "content": "\t\n35\nInstalling the Conference application with a single command\nhelm install creates a Helm release, which means that you have created an appli-\ncation instance, in this case, the instance is called conference. With Helm, you can \ndeploy multiple instances of the application if you want to. You can list Helm releases \nby running:\nhelm list\nThe output should look like figure 2.4. \nFigure 2.4    List Helm releases\nNOTE    If instead of using helm install you run helm template oci://\ndocker.io/salaboy/conference-app --version v1.0.0. Helm will output \nthe YAML files, which will apply against the cluster. There are situations where \nyou might want to do that instead of helm install, for example, if you want to \noverride values that the Helm Charts don’t allow you to parameterize or apply \nany other transformations before sending the request to Kubernetes. \n2.2.1\t\nVerifying that the application is up and running\nOnce the application is deployed, containers will be downloaded to run on your lap-\ntop, which can take a while. Depending on your internet connection, the process \ncan take up to 10 minutes because Kafka, PostgreSQL, and Redis will be downloaded \nalongside the application’s containers. The RESTARTS columns show how often the \ncontainer has been restarted due to an error. In distributed applications, this is nor-\nmal, as components might depend on each other, and when they are started at the \nsame time, connections can fail. By design, applications should be able to recover from \nproblems, and Kubernetes will automatically restart a failing container. \nYou can monitor the progress by listing all the pods running in your cluster, once \nagain, using the -owide flag to get more information:\nkubectl get pods -owide\nThe output should look like figure 2.5. \nListing 2.5    Listing application pods\n",
      "content_length": 1826,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 55,
      "content": "36\nChapter 2  Cloud-native application challenges \nSomething that you might notice in the list of pods is that we are not only running the \napplication’s services, but we are also running Redis, PostgreSQL, and Kafka, because \nthe C4P (Call for Proposals) and Agenda services need persistent storage. The applica-\ntion will be using Kafka to exchange asynchronous messages between services. Besides \nthe services, we will have these two databases and a message broker (Kafka) running \ninside our Kubernetes cluster. \nIn the output shown in figure 2.5 you need to pay attention to the READY and STA-\nTUS columns, where 1/1 in the READY column means that one replica of the container \nis running, and one is expected to be running. As you can see the RESTART column \nis showing 7 for the Call for Proposals Service (conference-c4p-service). This is \nbecause the service depends on Redis to be up and running for the service to be able to \nconnect to it. While Redis is bootstrapping the application will try to connect, and if it \nfails, it will try to keep reconnecting. As soon as Redis is up, the service will connect to it. \nThe same applies to Kafka and PostgreSQL. To quickly recap, our application services, \nthe databases, and the message broker that we are running are shown in figure 2.6. \nFrontend\nCall For Proposals \n(C4P) Service\nAgenda Service\nNotifications \nService\nKafka\nPostgreSQL\nRedis\nFigure 2.6    Application services, databases, and message broker\nNotice that Pods can be scheduled in different nodes. You can check this in the NODE \ncolumn; this is Kubernetes efficiently using the cluster resources. If all the Pods are \nup and running, you’ve made it! The application is now up and running, and you can \naccess it by pointing your favorite browser to http://localhost.\nIf you are interested in Helm and building your own Conference application Helm \nChart, I recommend you to check the source code provided with the tutorials: https://\ngithub.com/salaboy/platforms-on-k8s/tree/main/conference-application/helm/\nconference-app. \n2.2.2\t\nInteracting with your application\nIn the previous section, we installed the application into our local Kubernetes cluster. \nIn this section, we will quickly interact with the application to understand how the \nservices interact to accomplish a simple use case: Receiving and approving proposals. \nRemember that you can access the application by pointing your browser to http://\nlocalhost. The Conference application should look like figure 2.7. \n",
      "content_length": 2504,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 56,
      "content": "\t\n37\nInstalling the Conference application with a single command\nFigure 2.7    \nConference \nlanding page\nIf you switch to the Agenda section now, you should see something like figure 2.8. \nFigure 2.8    \nConference empty \nAgenda when we \nfirst install the \napplication\nThe application’s Agenda page lists all the talks scheduled for the conference. Poten-\ntial speakers can submit proposals that the conference organizers will review. When \nyou start the application for the first time, there will be no talks on the agenda, but you \ncan now go ahead and submit a proposal from the Call from Proposals section. Check \nfigure 2.9.\nFigure 2.9    \nSubmitting a \nproposal for \norganizers to \nreview\n",
      "content_length": 695,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 57,
      "content": "38\nChapter 2  Cloud-native application challenges \nNotice that there are four fields (Title, Description, Author, and Email) in the form to \nsubmit a proposal. Fill in all the fields and submit by clicking the Submit Proposal but-\nton at the bottom of the form. The organizers will use this information to evaluate your \nproposal and get in touch with you via email if your proposal gets approved or rejected. \nOnce the proposal is submitted, you can go to the Back Office (click the arrow point-\ning to the right at the top menu) and check the Review Proposals tab, where you can \nApprove or Reject submitted proposals. You will be acting as a conference organizer on \nthis screen; see figure 2.10. \nFigure 2.10    Conference organizers can Accept or Reject incoming proposals\nApproved proposals will appear on the Main Agenda page. Attendees who visit the \npage at this stage can glance at the conference’s main speakers. Figure 2.11 shows our \nfreshly approved proposal in the Agenda section of the main conference page.\nFigure 2.11    Your proposal is now live on the agenda! \n",
      "content_length": 1081,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 58,
      "content": "\t\n39\nInstalling the Conference application with a single command\nAt this stage, the potential speaker should have received an email about the approval \nor rejection of their proposal. You can check this by looking at the notification service \nlogs, using kubectl from your terminal; see figure 2.12 for the output of the command:\nkubectl logs -f conference-notifications-service -deployment-<POD_ID>\nFigure 2.12    Notifications service logs (emails and events) \nThese logs show two important aspects of the application. First, notifications are sent \nvia emails to potential speakers. The organizers need to keep track of these communi-\ncations. On the conference Back Office page, you can find the Notifications tab, where \nthe content of the notifications is shown to the organizers (see figure 2.13). \nFigure 2.13    Notifications displayed in the Back Office\n",
      "content_length": 864,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 59,
      "content": "40\nChapter 2  Cloud-native application challenges \nThe second aspect displayed here is Events. All services from this application are emit-\nting events when relevant actions are performed. The notification service is emitting \nan event, in this case to Kafka, for every notification that is being sent. This allows other \nservices and applications to integrate with the application services asynchronously. Fig-\nure 2.14 shows the Events section of the Back Office. \nFigure 2.14    All service events in the Back Office\nFigure 2.14 shows all events emitted by the application services; notice that you can see \nall the meaningful operations being performed by the services to fulfill the Call for \nProposals flow (New Proposal > New Agenda Item > Proposal Approved > Notification \nSent).\nIf you made it so far, congrats, the Conference application is working as expected. \nI encourage you to submit another proposal and reject it, to validate that the correct \nnotification and events are sent to the potential speaker. \nIn this section, you installed the Conference application using Helm. Then we ver-\nified that the application is up and running and that potential speakers can submit \nproposals, while conference organizers can approve or reject these proposals. The deci-\nsions will send notifications to potential speakers via email. \nThis simple application allows us to demonstrate a basic use case that we can now \nexpand and improve to support real users. We have seen that installing a new instance \nof the application is quite simple. We used Helm to install a set of services that are con-\nnected as well as some infrastructural components such as Redis, PostgreSQL, and in \nthe next section, we will go deeper into understanding what we have installed and how \nthe application is working. \n",
      "content_length": 1804,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 60,
      "content": "\t\n41\nInspecting the walking skeleton\n2.3\t\nInspecting the walking skeleton\nIf you have been using Kubernetes for a while, you probably know all about kubectl. \nBecause this application version uses native Kubernetes deployments and services, you \ncan inspect and troubleshoot these Kubernetes resources using kubectl.\nUsually, instead of just looking at the pods running (with kubectl get pods), to \nunderstand and operate the application, you will be looking at services and deploy-\nments. Let’s explore the deployment resources first. \n2.3.1\t\nKubernetes deployments basics\nLet’s start with deployments. Deployments in Kubernetes are in charge of containing \nthe recipe for running our containers. Deployments are also in charge of defining how \ncontainers will run and how they will be upgraded to newer versions when needed. By \nlooking at the deployment details, you can get very useful information, such as:\n¡ The container that this deployment is using. Notice that this is just a simple Docker \ncontainer, meaning that you can even run this container locally if you want to \nwith docker run. This is fundamental to troubleshooting problems. \n¡ The number of replicas required by the deployment. For this example, it is set to \n1, but you will change this in the next section. More replicas add more resiliency \nto the application, because these replicas can go down. Kubernetes will spawn \nnew instances to keep the number of desired replicas up at all times.\n¡ The resource allocation for the container. Depending on the load and the technol-\nogy stack that you used to build your service, you will need to fine-tune how many \nresources Kubernetes you allow your container to use.\n¡ The status of the readiness and liveness probes. Kubernetes, by default, will monitor \nthe health of your container. It does that by executing two probes: 1) The “readi-\nness probe” checks if the container is ready to answer requests, and 2) The “live-\nness probe” checks if the main process of the container is running. \n¡ The rolling updates strategy defines how our Pods will be updated to avoid down-\ntime for our users. With the RollingUpdateStrategy, you can define how \nmany replicas are allowed while triggering and updating to a newer version. \nFirst, let’s list all the available deployments with: \nkubectl get deployments\nThe output should look like listing 2.2. \nListing 2.2    Listing your application’s deployments\nNAME                                          READY   UP-TO-DATE   AVAILABLE   \nconference-agenda-service-deployment          1/1     1            1           \nconference-c4p-service-deployment             1/1     1            1           \nconference-frontend-deployment                1/1     1            1           \nconference-notifications-service-deployment   1/1     1            1           \n",
      "content_length": 2819,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 61,
      "content": "42\nChapter 2  Cloud-native application challenges \n2.3.2\t\nExploring deployments\nIn the following example, you will describe the Frontend deployment. You can describe \neach deployment in more detail with kubectl describe deploy conference-fron-\ntend-deployment (see listing 2.3).\nListing 2.3    Describing a deployment to see its details\n> kubectl describe deploy conference-frontend-deployment \nName:                   conference-frontend-deployment\nNamespace:              default\nCreationTimestamp:      Tue, 27 Jun 2023 08:21:21 +0100\nLabels:                 app.kubernetes.io/managed-by=Helm\nAnnotations:            deployment.kubernetes.io/revision: 1\n                        meta.helm.sh/release-name: conference\n                        meta.helm.sh/release-namespace: default\nSelector:               app=frontend\nReplicas:               1 desired | 1 updated | 1 total | 1 available \nStrategyType:           RollingUpdate\nMinReadySeconds:        0\nRollingUpdateStrategy:  25% max unavailable, 25% max surge\nPod Template:\n  Labels:  app=frontend\n  Containers:\n   frontend:\n    Image:      salaboy/frontend-go...\n    Port:       8080/TCP\n    Host Port:  0/TCP\n    ...\n    ...\n    Environment: \n      AGENDA_SERVICE_URL:         agenda-service.default.svc.cluster.local\n      C4P_SERVICE_URL:            c4p-service.default.svc.cluster.local\n      NOTIFICATIONS_SERVICE_URL:  notifications-service.default.svc.cluster.\nlocal\n      KAFKA_URL:                  conference-kafka.default.svc.cluster.local\n      POD_NODENAME:                (v1:spec.nodeName)\n      POD_NAME:                    (v1:metadata.name)\n      POD_NAMESPACE:               (v1:metadata.namespace)\n      POD_IP:                      (v1:status.podIP)\n      POD_SERVICE_ACCOUNT:         (v1:spec.serviceAccountName)\n    Mounts:                       <none>\n  Volumes:                        <none>\nConditions:\n  Type           Status  Reason\n  ----           ------  ------\n  Available      True    MinimumReplicasAvailable\n  Progressing    True    NewReplicaSetAvailable\nOldReplicaSets:  <none>\nNewReplicaSet:   conference-frontend-deployment-<ID> (1/1 replicas created)\nShows the replicas available for this \ndeployment. This gives you a quick indication \nabout the state of your deployment.\nThe container image, including the name and tag used for this service.\nThe environment variables used to configure this container.\n",
      "content_length": 2399,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 62,
      "content": "\t\n43\nInspecting the walking skeleton\nEvents: \n  Type    Reason             Age   From                   Message\n  ----    ------             ----  ----                   -------\n  Normal  ScalingReplicaSet  48m   deployment-controller  Scaled up replica \n➥set conference-frontend-deployment-59d988899 to 1\nListing 2.3 shows that describing deployments in this way is very helpful if for some rea-\nson the deployment is not working as expected. For example, if the number of replicas \nrequired is not met, describing the resource will give you insights into where the prob-\nlem might be. Always check at the bottom for the events associated with the resource to \nget more insights about the resource status. In this case, the deployment was scaled to \nhave one replica 48 minutes ago. \nAs mentioned before, deployments are also responsible for coordinating version or \nconfiguration upgrades and rollbacks. The deployment update strategy is set by default \nto “Rolling ,” which means that the deployment will incrementally upgrade pods one \nafter the other to minimize downtime. An alternative strategy called Recreate can be \nset, which will shut down all the pods and create new ones. \nIn contrast with pods, deployments are not ephemeral; hence, if you create a \nDeployment, it will be there for you to query no matter if the containers under the hood \nare failing. By default, when you create a deployment resource, Kubernetes creates an \nintermediate resource for handling and checking the deployment–requested replicas. \n2.3.3\t\nReplicaSets\nHaving multiple replicas of your containers is an important feature to scale your appli-\ncations. If your application is experiencing loads of traffic from your users, you can eas-\nily scale up the number of replicas of your services to accommodate all the incoming \nrequests. Similarly, if your application is not experiencing a large number of requests, \nthese replicas can be scaled down to save resources. The object created by Kubernetes \nis called ReplicaSet, and it can be queried by running:\nkubectl get replicaset\nThe output should look like listing 2.4. \nListing 2.4    Listing the deployment’s ReplicaSets\n> kubectl get replicasets\nNAME                                              DESIRED   CURRENT   READY\nconference-agenda-service-deployment-7cc9f58875        1       1         1\nconference-c4p-service-deployment-76dfc94444           1       1         1\nconference-frontend-deployment-59d988899               1       1         1\nconference-notifications-service-deployment-7cbcb8677b 1       1         1\nEvents shows us relevant information \nabout our Kubernetes resources—in this \ncase, when the replica was created.\n",
      "content_length": 2678,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 63,
      "content": "44\nChapter 2  Cloud-native application challenges \nThese ReplicaSet objects are fully managed by the deployment’s resource, and usu-\nally, you shouldn’t need to deal with them. ReplicaSets are also essential when dealing \nwith rolling updates, and you can find more information about this topic at https://\nkubernetes.io/docs/tutorials/kubernetes-basics/update/update-intro/. You will be \nperforming updates to the application with Helm in later chapters, where these mech-\nanisms will kick in. \nIf you want to change the number of replicas for a deployment, you once again can \nuse kubectl to do so: \n> kubectl scale --replicas=2 deployments/<DEPLOYMENT_ID>\nYou can try this out with the Frontend deployment: \n> kubectl scale --replicas=2 deployments/conference-frontend-deployment\nIf we now list the application pods, we will see that there are two replicas for the fron-\ntend service:\nconference-frontend-deployment-<ID>-8gpgn  1/1     Running   7 (53m ago)   59m\nconference-frontend-deployment-<ID>-z4c5c  1/1     Running   0             13s\nThis command changes the deployment resource in Kubernetes and triggers the cre-\nation of a second replica for the Frontend deployment. Increasing the number of rep-\nlicas of your user-facing services is quite common because it is the service that all users \nwill hit when visiting the conference page. \nIf we access the application right now, as end users we will not notice any difference, \nbut every time we refresh, a different replica might serve us. To make this more evident, \nwe can turn on a feature that is built into the Frontend service, which shows us more \ninformation about the application containers. You can enable this feature by setting an \nenvironment variable: \nkubectl set env deployment/conference-frontend-deployment  \n➥FEATURE_DEBUG_ENABLED=true\nNotice that when you change the deployment object configuration (anything inside \nspec.template.spec block) the rolling update mechanism of the Deployment \nresource will kick in. All the existing pods managed by this deployment will be upgraded \nto have the new specification(in this example to include the new FEATURE_DEBUG_\nENABLED environment variable). This upgrade, by default, will start a new pod with the \nnew specification and wait for it to be ready before terminating the old version of the \npod. This process will be repeated until all the pods (replicas for the deployment) are \nusing the new configuration. \nIf you access the application again in your browser (you might need to access using \nIncognito Mode if the browser cached the website), in the Back Office section, there is a \nnew Debug tab. You can see the Pod Name, Pod IP, the Namespace, and the Node name \nwhere the Pod is running for all services (figure 2.15).\n",
      "content_length": 2755,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 64,
      "content": "\t\n45\nInspecting the walking skeleton\nFigure 2.15    First replica of the Frontend answering your request (running on Node Name: dev-worker)\nIf you wait for 3 seconds, the page will automatically refresh, and you should see the \nsecond replica answering this time, if not wait for the next cycle (figure 2.16). \nFigure 2.16    Second replica of the Frontend answering your request (running on Node Name: dev-   \t\n\t\n\t\n       worker3)\nBy default, Kubernetes will load-balance the requests between the replicas. Being able \nto scale by just changing the number of replicas, there is no need to deploy anything \nnew, Kubernetes will provision a new pod (with a new container in it) to deal with more \ntraffic. Kubernetes will also make sure that there is the amount of desired replicas at \nall times. You can test this by deleting one pod and watching how Kubernetes recreates \nit automatically. For this scenario, you need to be careful, because the web application \nfrontend is executing several requests to fetch the HTML, CSS, and JavaScript librar-\nies; hence, each of these requests can land in a different replica. \n",
      "content_length": 1118,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 65,
      "content": "46\nChapter 2  Cloud-native application challenges \n2.3.4\t\nConnecting services\nWe have looked at deployments, which are in charge of getting our containers up and \nrunning and keeping them that way, but so far, these containers can only be accessed \ninside the Kubernetes cluster. If we want other services to interact with these contain-\ners, we need to look at another Kubernetes resource called Service. Kubernetes pro-\nvides an advanced service-discovery mechanism that allows services to communicate \nwith each other by just knowing their names. This is essential for connecting many \nservices without knowing IP addresses of Kubernetes pods that can change over time, \nas they can be upgraded, rescheduled to a different node, or just restarted with a new \nIP address when something goes wrong.\n2.3.5\t\nExploring services\nTo expose your containers to other services, you need to use a Kubernetes Service \nresource. Each application service defines this Service resource, so other services and \nclients can connect to them. In Kubernetes, services will be in charge of routing traffic \nto your application containers. These services represent a logical name that you can \nuse to abstract where your containers run. If you have multiple replicas of your con-\ntainers, the service resource will be in charge of load balancing the traffic among all \nthe replicas. You can list all the services by running:\nkubectl get services\nAfter running the command, you should see something like listing 2.5.\nListing 2.5    Listing application’s services\nNAME                        TYPE        CLUSTER-IP      PORT(S)\nagenda-service              ClusterIP   10.96.90.100    80/TCP\nc4p-service                 ClusterIP   10.96.179.86    80/TCP\nconference-kafka            ClusterIP   10.96.67.2      9092/TCP\nconference-kafka-headless   ClusterIP   None     9092/TCP,9094/TCP,9093/TCP\nconference-postgresql       ClusterIP   10.96.121.167   5432/TCP\nconference-postgresql-hl    ClusterIP   None            5432/TCP\nconference-redis-headless   ClusterIP   None            6379/TCP\nconference-redis-master     ClusterIP   10.96.225.138   6379/TCP\nfrontend                    ClusterIP   10.96.60.237    80/TCP\nkubernetes                  ClusterIP   10.96.0.1       443/TCP\nnotifications-service       ClusterIP   10.96.65.248    80/TCP\nAnd you can also describe a service to see more information about it with:\nkubectl describe service frontend\nThis should give you something like we see in listing 2.6. Services and deployments are \nlinked by the Selector property, highlighted in the following image. In other words, \nthe service will route traffic to all the pods created by a deployment containing the \nlabel app=frontend.\n",
      "content_length": 2715,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 66,
      "content": "\t\n47\nInspecting the walking skeleton\nListing 2.6    Describing the Frontend service\nName:              frontend\nNamespace:         default\nLabels:            app.kubernetes.io/managed-by=Helm\nAnnotations:       meta.helm.sh/release-name: conference\n                   meta.helm.sh/release-namespace: default\nSelector:          app=frontend\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                10.96.60.237\nIPs:               10.96.60.237\nPort:              <unset>  80/TCP\nTargetPort:        8080/TCP\nEndpoints:         10.244.1.6:8080,10.244.2.9:8080\nSession Affinity:  None\nEvents:            <none>\n2.3.6\t\nService discovery in Kubernetes\nBy using services, if your application service needs to send a request to any other ser-\nvice, it can use the Kubernetes service’s name and port; in most cases, you can use port \n80 if you are using HTTP requests, so you only need to use the service name. If you \nlook at the source code of the services, you will see that HTTP requests are created \nagainst the service name; no IP addresses or Ports are needed.\nFinally, if you want to expose your services outside the Kubernetes cluster, you need \nan Ingress resource. As the name represents, this Kubernetes resource is in charge of \nrouting traffic from outside the cluster to services that are inside the cluster. Usually, \nyou will not expose multiple services, limiting the entry points for your applications.\nYou can get all the available Ingress resources by running the following command:\nkubectl get ingress\nThe output should look like listing 2.7.\nListing 2.7    Listing the application’s Ingress resources\nNAME                          CLASS   HOSTS   ADDRESS     PORTS   AGE\nconference-frontend-ingress   nginx   *       localhost   80      84m\nAnd then you can describe the Ingress resource in the same way as you did with other \nresource types to get more information about it:\nkubectl describe ingress conference-frontend-ingress\nYou should expect the output to look like listing 2.8. \nThe selector used to match a \nservice and a deployment.\n",
      "content_length": 2100,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 67,
      "content": "48\nChapter 2  Cloud-native application challenges \nListing 2.8    Describing the Ingress resource\nName:             conference-frontend-ingress\nLabels:           app.kubernetes.io/managed-by=Helm\nNamespace:        default\nAddress:          localhost\nIngress Class:    nginx\nDefault backend:  <default>\nRules:\n  Host        Path  Backends\n  ----        ----  --------\n  *           \n              /   frontend:80 (10.244.1.6:8080,10.244.2.9:8080) \nAnnotations:  meta.helm.sh/release-name: conference\n              meta.helm.sh/release-namespace: default\n              nginx.ingress.kubernetes.io/rewrite-target: /\nEvents:       <none>\nAs you can see, Ingress also uses the service’s name to route traffic. For this to work, \nyou need an Ingress controller, like we installed when we created the KinD cluster. If \nyou are running in a cloud provider, you might need to install an Ingress controller. \nThe following spreadsheet is a community resource created to keep track of the \ndifferent options of Ingress controllers that are available for you to use: http://mng \n.bz/K9Bn. \nWith Ingresses, you can configure a single entry-point and use path-based routing to \nredirect traffic to each service you need to expose. The previous Ingress resource in list-\ning 2.8 routes all the traffic sent to / to the frontend service. Notice that Ingress rules \nare pretty simple, and you shouldn’t add any business logic routing at this level.\n2.3.7\t\nTroubleshooting internal services\nSometimes, it is important to access internal services to debug or troubleshoot services \nthat are not working. For such situations, you can use the kubectl port-forward \ncommand to temporarily access services that are not exposed outside of the cluster \nusing an Ingress resource. For example, to access the Agenda service without going \nthrough the Frontend you can use the following command: \nkubectl port-forward svc/agenda-service 8080:80 \nYou should see the following output (listing 2.9) and make sure that you don’t kill the \ncommand.\nListing 2.9    kubectl port-forward allows you to expose a service for debugging purposes\nForwarding from 127.0.0.1:8080 -> 8080\nForwarding from [::1]:8080 -> 8080\nAnd then using your browser, use curl in a different tab or any other tool to point to \nhttp://localhost:8080/service/info to access the exposed Agenda service. The \nAll traffic going to '/' will go to \nthe frontend:80 service.\n",
      "content_length": 2408,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 68,
      "content": "\t\n49\nCloud-native application challenges\nfollowing listing shows how you can curl the Agenda service info endpoint and print \na pretty/colorful JSON payload with the help of jq, which you must install separately. \nListing 2.10    curl localhost:8080 to access Agenda service using port-forward\n> curl -s localhost:8080/service/info | jq --color-output\n{\n  \"Name\": \"AGENDA\",\n  \"Version\": \"1.0.0\",\n  \"Source\": \"https://github.com/salaboy/platforms-on-k8s/tree/main/    \t\n\t\n            conference-application/agenda-service\",\n  \"PodName\": \"conference-agenda-service-deployment-7cc9f58875-28wrt\",\n  \"PodNamespace\": \"default\",\n  \"PodNodeName\": \"dev-worker3\",\n  \"PodIp\": \"10.244.2.2\",\n  \"PodServiceAccount\": \"default\"\n}\nIn this section, you have inspected the main Kubernetes resources that were created to \nrun your application’s containers inside Kubernetes. By looking at these resources and \ntheir relationships, you can troubleshoot problems when they arise. \nFor everyday operations, the kubectl command line tool might not be optimal, and \ndifferent dashboards can be used to explore and manage your Kubernetes workloads, \nsuch as k9s (https://k9scli.io/), the Kubernetes dashboard (https://kubernetes.io/\ndocs/tasks/access-application-cluster/web-ui-dashboard/) and Skooner (https://\ngithub.com/skooner-k8s/skooner). \n2.4\t\nCloud-native application challenges\nIn contrast to a monolithic application, which will go down entirely if something goes \nwrong, cloud-native applications shouldn’t crash if a service goes down. Cloud-native \napplications are designed for failure and should keep providing valuable functionality \nin the case of errors. A degraded service while fixing problems is better than having \nno access to the application. In this section, you will change some of the service con-\nfigurations in Kubernetes to understand how the application will behave in different \nsituations. \nIn some cases, application/service developers will need to make sure that they \nbuild their services to be resilient and Kubernetes or the infrastructure will solve some \nconcerns. \nThis section covers some of the most common challenges associated with cloud-na-\ntive applications. I find it useful to know what are the things that are going to go wrong \nin advance rather than when I am already building and delivering the application. This \nis not an extensive list; it is just the beginning to make sure that you don’t get stuck with \nproblems that are widely known. The following sections will exemplify and highlight \nthese challenges with the Conference application: \n",
      "content_length": 2572,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 69,
      "content": "50\nChapter 2  Cloud-native application challenges \n¡ Downtime is not allowed: If you are building and running a cloud-native applica-\ntion on top of Kubernetes, and you are still suffering from application downtime, \nthen you are not capitalizing on the advantages of the technology stack that you \nare using. \n¡ Service’s built-in resiliency: Downstream services will go down, and you need to \nensure that your services are prepared for that. Kubernetes helps with dynamic \nservice discovery, but that is not enough for your application to be resilient. \n¡ Dealing with the application state is not trivial: We must understand each service’s \ninfrastructural requirements to allow Kubernetes to scale up and down our ser-\nvices efficiently. \n¡ Inconsistent data: A common problem of working with distributed applications is \nthat data is not stored in a single place and tends to be distributed. The applica-\ntion will need to be ready to deal with cases where different services have differ-\nent views of the state of the world.\n¡ Understanding how the application is working (monitoring, tracing, and telemetry): Hav-\ning a clear understanding of how the application is performing and that it is \ndoing what it is supposed to be doing is essential for quickly finding problems \nwhen things go wrong. \n¡ Application security and identity management: Dealing with users and security is \nalways an afterthought. For distributed applications, having these aspects clearly \ndocumented and implemented early on will help you to refine the application \nrequirements by defining “who can do what and when.” \nLet’s start with the first of the challenges: Downtime is not allowed.\n2.4.1\t\nDowntime is not allowed\nWhen using Kubernetes, we can easily scale up and down our services’ replicas. This \nis a great feature when your services were designed based on the assumption that the \nplatform will scale them by creating new copies of the containers running the service. \nSo, what happens when the service is not ready to handle replication or when no repli-\ncas are available for a given service? \nLet’s scale up the Frontend service to have two replicas running. To achieve this, you \ncan run the following command: \nkubectl scale --replicas=2 deployments/conference-frontend-deployment\nIf one of the replicas stops running or breaks for any reason, Kubernetes will try to start \nanother one to ensure that two replicas are up all the time. Figure 2.17 shows two Fron-\ntend replicas serving traffic to the user.\n",
      "content_length": 2506,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 70,
      "content": "\t\n51\nCloud-native application challenges\nFrontend <Service>\nUser\nFrontend \n<Pod>\nFrontend \n<Pod>\nAgenda Service \n<Service>\nC4P Service \n<Service>\nNotifications \nService \n<Service>\nFigure 2.17    By having two replicas of the Frontend container running, we allow the application to \ntolerate failures and also to increase the number of concurrent requests that the application can handle.\nYou can quickly try this self-healing feature of Kubernetes by killing one of the two pods \nof the application Frontend. You can do this by running the following commands, as \nshown in listings 2.11 and 2.12.\nListing 2.11    Checking that the two replicas are up and running\n> kubectl get pods \nNAME                                             READY   STATUS    RESTARTS      AGE\nconference-agenda-service-deployment-<ID>        1/1     Running   7 (92m ago)   100m\nconference-c4p-service-deployment-<ID>           1/1     Running   7 (92m ago)   100m\nconference-frontend-deployment-<ID>              1/1     Running   0             25m\nconference-frontend-deployment-<ID>              1/1     Running   0             25m\nconference-kafka-0                               1/1     Running   0             100m\nconference-notifications-service-deployment-<ID> 1/1     Running   7 (91m ago)   100m\nconference-postgresql-0                          1/1     Running   0             100m\nconference-redis-master-0                        1/1     Running   0             100m\nNow, copy one of the two Pods Id and delete it: \n> kubectl delete pod conference-frontend-deployment-c46dbbb9-ltrgs\nThen list the pods again (listing 2.12).\nListing 2.12    A new replica is automatically created as soon as one goes down\n> kubectl get pods\nNAME                                             READY   STATUS    RESTARTS      AGE\nconference-agenda-service-deployment-<ID>        1/1     Running   7 (92m ago)   100m\nconference-c4p-service-deployment-<ID>           1/1     Running   7 (92m ago)   100m\nconference-frontend-deployment-<NEW ID>          0/1     ContainerCreating 0     1s\nconference-frontend-deployment-<ID>              1/1     Running   0             25m\nconference-kafka-0                               1/1     Running   0             100m\nconference-notifications-service-deployment-<ID> 1/1     Running   7 (91m ago)   100m\nconference-postgresql-0                          1/1     Running   0             100m\nconference-redis-master-0                        1/1     Running   0             100m\n",
      "content_length": 2480,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 71,
      "content": "52\nChapter 2  Cloud-native application challenges \nYou can see how Kubernetes (the ReplicaSet, more specifically) immediately creates \na new pod when it detects only one running. While this new pod is being created and \nstarted, you have a single replica answering your requests until the second one is up \nand running. This mechanism ensures that at least two replicas answer your users’ \nrequests. Figure 2.18 shows that the application still works, because we still have one \npod serving requests.\nFrontend <Service>\nUser\nFrontend \n<Pod>\nFrontend \n<Pod>\nAgenda Service \n<Service>\nC4P Service \n<Service>\nNotifications \nService \n<Service>\nFigure 2.18    If one \nof the instances \nfails, Kubernetes will \nautomatically kill \nand recreate that \ninstance. But at least \nthe other running \ncontainer can keep \nanswering requests.\nIf you have a single replica and kill the running pod, you will have downtime in your \napplication until the new container is created and ready to serve requests. You can \nrevert to a single replica with the following:\n> kubectl scale --replicas=1 deployments/conference-frontend-deployment\nGo ahead and try this out. Delete only the replica available for the Frontend pod:\n> kubectl delete pod <POD_ID>\nFigure 2.19 shows the application is not working anymore, because there are no Fron-\ntend pods to serve incoming requests from users.\nFrontend <Service>\nUser\nFrontend \n<Pod>\nAgenda Service \n<Service>\nC4P Service \n<Service>\nNotifications \nService \n<Service>\nFigure 2.19    With a \nsingle replica being \nrestarted, there is no \nbackup to answer user \nrequests. If there is \nno replica available \nto serve your users’ \nrequests, you will \nexperience downtime. \nThis is exactly what we \nwant to avoid.\n",
      "content_length": 1729,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 72,
      "content": "\t\n53\nCloud-native application challenges\nAfter killing the pod, try to access the application by refreshing your browser (http://\nlocalhost). You should see “503 Service Temporarily Unavailable” in your browser, \nbecause the Ingress controller (not shown in the previous figure for simplicity) cannot \nfind a replica running behind the Frontend service. If you wait for a bit, you will see \nthe application come back up. Figure 2.20 shows the 503 “Service Temporarily Unavail-\nable” being returned by the NGINX Ingress controller component that was in charge \nof routing traffic to the Frontend service.\nService Downtime\nFigure 2.20    With a single replica being restarted, there is no backup to answer user requests\nThis error message is quite tricky, because the application takes about a second to get \nrestarted and to be fully functional, so if you didn’t manage to see it, you can try to \ndownscale the frontend service to zero replicas with kubectl scale --replicas=0 \ndeployments/conference-frontend-deployment to simulate downtime.\nThis behavior is expected, because the Frontend service is a user-facing service. If it \ngoes down, users will not be able to access any functionality, so having multiple replicas \nis recommended. From this perspective, the Frontend service is the most important \nservice of the entire application, since our primary goal for our applications is to avoid \ndowntime. \nIn summary, pay special attention to user-facing services exposed outside of your \ncluster. Whether they are user interfaces or just APIs, ensure you have as many replicas \nas needed to deal with incoming requests. Having a single replica should be avoided for \nmost use cases besides development.  \n2.4.2\t\nService’s resilience built-in\nBut now, what happens if the other services go down? For example, the Agenda service, \nis just in charge of listing all the accepted proposals to the conference attendees. This \nservice is also critical, because the Agenda List is right there on the main page of the \napplication. So, let’s scale the service down: \nkubectl scale --replicas=0 deployments/conference-agenda-service-deployment\nFigure 2.21 shows how the application can keep working, even if one of the services is \nmisbehaving.\n",
      "content_length": 2239,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 73,
      "content": "54\nChapter 2  Cloud-native application challenges \nUser\nFrontend <Service>\nAgenda Service \n<Service>\nC4P Service \n<Service>\nNotifications \nService \n<Service>\nAgenda Service \n<Pod>\nFigure 2.21    No pods for the Agenda service. If a service is failing, the user should be able to keep using \nthe application with limited functionality. \nRight after running this command, the container will be killed, and the service will \nnot have any container answering its requests. Try refreshing the application in your \nbrowser, you should see a cached response as shown in figure 2.22.\nFigure 2.22    If the Agenda service has no replica running, the Frontend is wise enough to show the user \nsome cached entries.\nAs you can see, the application is still running, but the Agenda service is not available \nright now. Check the Debug tab in the Back Office section, which should show that the \nAgenda service is unhealthy (figure 2.23). \n",
      "content_length": 926,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 74,
      "content": "\t\n55\nCloud-native application challenges\nFigure 2.23    If in Debug mode, the Back Office should show the unhealthy services.\nYou can prepare your application for such scenarios; in this case, the Frontend has a \ncached response to at least show something to the user. If, for some reason, the Agenda \nservice is down, at least the user will be able to access other services and other sections \nof the application. From the application perspective, it is important not to propagate \nthe error back to the user. The user should be able to keep using other application \nservices, for example, the Call for Proposals form, until the Agenda service is restored. \nYou need to pay special attention when developing services that will run in Kuberne-\ntes, as now your service is responsible for dealing with errors generated by downstream \nservices. This is important to ensure that errors or services going down don’t bring \nyour entire application down. Simple mechanisms such as cached responses will make \nyour applications more resilient and allow you to incrementally upgrade these services \nwithout worrying about bringing everything down. For our conference scenario, having \na CronJob that periodically caches the agenda entries might be enough. Remember, \ndowntime is not allowed.  \nLet’s now switch to talking about dealing with the state in our applications and how \nit is critical to understand how our application’s services handle the state from a scal-\nability point of view. Since we will be talking about scalability, data consistency is the \nchallenge we will try to solve next.\n2.4.3\t\nDealing with the application state is not trivial\nLet’s scale up the agenda service again to have a single replica: \n> kubectl scale --replicas=1 deployments/conference-agenda-service-deployment\nIf you have created proposals before, you will notice that as soon as the Agenda service \ngoes back up, you see the accepted proposals again on the Agenda page. This works \nonly because both the Agenda service and C4P Service store all the proposals and \nagenda items in external databases (PostgreSQL and Redis). In this context, external \nmeans outside of the pod memory. What will happen if we scale the Agenda service up \nto two replicas? See listing 2.13.\n",
      "content_length": 2254,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 75,
      "content": "56\nChapter 2  Cloud-native application challenges \nListing 2.13    Running with two replicas of the Agenda service\n> kubectl scale --replicas=2 deployments/conference-agenda-service-deployment\nNAME                                                    READY   STATUS          AGE\nconference-agenda-service-deployment-<ID>               1/1     Running         2m30s\nconference-agenda-service-deployment-<ID>               1/1     Running         22s\nconference-c4p-service-deployment-<ID>                  1/1     Running         150m\nconference-frontend-deployment-<ID>                     1/1     Running         8m55s\nconference-kafka-0                                      1/1     Running         150m\nconference-notifications-service-deployment-<ID>        1/1     Running         150m\nconference-postgresql-0                                 1/1     Running         150m\nconference-redis-master-0                               1/1     Running         150m\nFigure 2.24 shows the Agenda service running two replicas of the service concurrently. \nUser\nFrontend <Service>\nAgenda Service <Service>\nFrontend \n<Pod>\nAgenda Service \n<Pod>\nAgenda Service \n<Pod>\nFigure 2.24     \nTwo replicas can \nnow deal with more \ntraffic. The requests \nbeing forwarded by \nthe Frontend can be \nanswered by the two \navailable replicas, \nallowing the application \nto handle more load. \nWith two replicas dealing with your user requests, now the Frontend will have two \ninstances to query. Kubernetes will do the load balancing between the two replicas, but \nyour application will have no control over which replica the request hits. Because we \nare using a database to back up the data outside of the pod’s context, we can scale the \nreplicas to many pods dealing with the application demand. Figure 2.25 shows how the \nAgenda service relies on Redis to store the application state, while the Call for Propos-\nals uses PostgreSQL to do the same. \nUser\nFrontend <Service>\nAgenda Service \n<Service>\nC4P Service\n<Service>\nNotifications \nService\n<Service>\nAgenda Service\n<Pod>\nC4P Service\n<Pod>\nRedis\nPostgreSQL\nFigure 2.25    Both \ndata-sensitive services \nuse persistent stores. \nDelegating state \nstorage to external \ncomponents, make \nyour service stateless \nand easier to scale. \n",
      "content_length": 2259,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 76,
      "content": "\t\n57\nCloud-native application challenges\nOne of the limitations of this approach is the number of database connections that your \ndatabase supports in its default configuration. If you keep scaling up the replicas, always \nconsider reviewing the database connection pool settings to ensure that your database \ncan handle all the connections created by all the replicas. But for the sake of learning, \nlet’s imagine that we don’t have a database, and our Agenda service keeps all the agenda \nitems in memory. How would the application behave if we started scaling up the Agenda \nservice pods? Figure 2.26 shows the hypothetical case of having in-memory data inside \nour applications. \nUser\nFrontend \n<Service>\nAgenda Service <Service>\nAgenda Service\nAgenda Service \n<Pod>\nIn Memory State\nFigure 2.26     \nWhat would happen \nif the Agenda service \nkeeps the state in-\nmemory? If state is \nkept in memory it is \nquite hard to share \nacross replicas. This \nmakes scaling the \nservice much harder.\nBy scaling these services up, we have found a problem with the design of one of the \napplication services. The Agenda service is keeping the state in-memory, and that will \naffect the scaling capabilities from Kubernetes. For this kind of scenario, when Kuber-\nnetes balances the requests across different replicas, the Frontend service will receive \ndifferent data depending on which replica processed the request. \nWhen running existing applications in Kubernetes, you will need to deeply under-\nstand how much data they are keeping in-memory because this will affect how you can \nscale them up. For web applications that keep HTTP sessions and require sticky sessions \n(subsequent requests going to the same replica), you need to set up HTTP session repli-\ncation to get this working with multiple replicas. This might require more components \nbeing configured at the infrastructure level, such as a cache.  \nUnderstanding your service requirements will help you plan and automate your \ninfrastructural requirements, such as databases, caches, message brokers, etc. The \nmore complex the application gets, the more dependencies on these infrastructural \ncomponents it will have. \nAs we have seen before, we have installed Redis and PostgreSQL as part of the appli-\ncation Helm Chart. This is usually not a good idea because databases and tools like \nmessage brokers will need special care from the operation team, who can choose not to \nrun these services inside Kubernetes. We will expand on this topic in chapter 4 where \nwe go deeper into how to deal with infrastructure when working with Kubernetes and \ncloud providers. \n",
      "content_length": 2622,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 77,
      "content": "58\nChapter 2  Cloud-native application challenges \n2.4.4\t\nDealing with inconsistent data\nHaving stored data in a relational data store like PostgreSQL or a NoSQL approach \nlike Redis doesn’t solve the problem of having inconsistent data across different stores. \nBecause these stores should be hidden away by the service API, you will need to have \nmechanisms to check that the data that the services are handling is consistent. In dis-\ntributed systems, it is quite common to talk about “eventual consistency,” meaning that \neventually the system will be consistent. Having eventual consistency is better than not \nhaving consistency at all. For this example, we can build a simple check mechanism \nthat once in a while (imagine once a day) checks for the accepted talks in the Agenda \nservice to see if they have been approved in the Call for Proposals service. If there is an \nentry that the Call hasn’t approved for the Proposal Service (C4P), then we can raise \nsome alerts or send an email to the conference organizers (figure 2.27). \nNotifications\n<Service>\nAgenda\n<Service>\nAgenda\n<Pod>\nCall for Proposals\n<Service>\nCall for Proposals\n<Pod>\nNotifications\n<Pod>\nConsistency Checker\n<Pod>\n1\n2\n3\n4\nFigure 2.27    Consistency checks can run as CronJobs. We can execute checks against the application \nservices on fixed intervals to make sure that the state is consistent. For example: (1) every day at \nmidnight we query the Agenda Service (2) to verify that the published sessions are approved in the \n(3) Call For Proposals Service and a corresponding notification has been sent by the (4) Notifications \nService.\nIn figure 2.27, we can see how a CronJob (1) will be executed every X period, depend-\ning on how important it is for us to fix consistency problems. Then it will query the \nAgenda service public APIs (2) to check which accepted proposals are being listed and \ncompare that with the Call for Proposals service approved list (3). Finally, if any incon-\nsistency is found, an email can be sent using the Notifications service public APIs (4). \nThink of the simple use case this application was designed for; what other checks \nwould you need? One that immediately comes to mind is verifying that emails were \nsent correctly for Rejected and Approved proposals. For this use case, emails are really \nimportant, and we need to ensure those emails are sent to our accepted and rejected \nspeakers. \n2.4.5\t\nUnderstanding how the application is working\nDistributed systems are complex beasts, and fully understanding how they work from \nday one can help you save time when things go wrong. This has pushed the monitor-\ning, tracing, and telemetry communities hard to develop solutions that help us under-\nstand how things are working at any given time. \n",
      "content_length": 2765,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 78,
      "content": "\t\n59\nCloud-native application challenges\nThe https://opentelemetry.io/ OpenTelemetry community has evolved alongside \nKubernetes, and it can now provide most of the tools you will need to monitor how your \nservices are working. As stated on their website, “You can use it to instrument, generate, \ncollect, and export telemetry data (metrics, logs, and traces) for analysis to understand \nyour software’s performance and behavior.” Figure 2.28 shows a common use case \nwhere services all push metrics, traces, and logs to a centralized place that stores and \naggregates the information so it can be displayed in dashboards or used by other tools. \nFrontend\nCall For Proposals \n(C4P) Service\nAgenda Service\nNotifications \nService\nDashboard\nOperator\nTraces\nMetrics\nLogs\nFigure 2.28    Aggregating observability from all our services in a single place reduces the cognitive load \non the teams responsible for keeping the application up and running.\nIt is important to notice that OpenTelemetry focuses on both the behavior and perfor-\nmance of your software, because they will both affect your users and user experience. \nFrom the behavior point of view, you want to make sure that the application is doing \nwhat it is supposed to do, and by that, you will need to understand which services are \ncalling which other services or infrastructure to perform tasks. \nUsing Prometheus and Grafana allows us to see the service telemetry and build \ndomain-specific dashboards to highlight certain application-level metrics, for example, \nthe amount of Approved vs. Rejected proposals over time, as shown in figure 2.29. \nFigure 2.29    Monitoring telemetry data with Prometheus and Grafana\n",
      "content_length": 1679,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 79,
      "content": "60\nChapter 2  Cloud-native application challenges \nFrom the performance point of view, you need to ensure that services are respecting \ntheir Service Level Agreements (SLAs), which means that they are taking only a short \ntime to answer requests. If one of your services misbehaves and takes more than usual, \nyou want to know. \nFor tracing, you must modify your services to understand the internal operations and \ntheir performance. OpenTelemetry provides drop-in instrumentation libraries in most \nlanguages to externalize service metrics and traces. Figure 2.30 shows the OpenTeleme-\ntry architecture, where you can see the OpenTelemetry collector receiving information \nfrom each application agent, but also from shared infrastructure components.\nFigure 2.30    OpenTelemetry architecture and library (Source: https://opentelemetry.io/docs/)\nThe recommendation here is if you are creating a walking skeleton, ensure it has Open-\nTelemetry built-in. If you push monitoring to later stages of the project, it will be too \nlate, things will go wrong, and finding out who is responsible will take too much time. \n2.4.6\t\nApplication security and identity management\nIf you have ever built a web application, you know that providing identity management \n(user accounts and user identity) plus authentication and authorization is quite an \nendeavor. A simple way to break any application (cloud-native or not) is to perform \nactions you are not supposed to do, such as deleting all the proposed presentations \nunless you are a conference organizer. \nThis also becomes challenging in distributed systems, because authorization and \nuser identity must be propagated across different services. In distributed architectures, \nit is quite common to have a component that generates requests on behalf of a user \ninstead of exposing all the services for the user to interact directly. In our example, the \nFrontend service is this component. Most of the time, you can use this external-facing \ncomponent as the barrier between external and internal services. For this reason, it is \n",
      "content_length": 2073,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 80,
      "content": "\t\n61\nCloud-native application challenges\nquite common to configure the Frontend service to connect with an authorization and \nauthentication provider commonly using the OAuth2 protocol. Figure 2.31 shows the \nFrontend service interacting with an identity management service, which is responsible \nfor connecting to an Identity Provider (Google, GitHub, your internal LDAP server) \nto validate the user credentials as well as to provide roles or group memberships that \ndefine what the user can and can’t do in different services. The Frontend service han-\ndles the login flow (authentication and authorization), but only the context is propa-\ngated to the backend services once that is done. \nFrontend\nCall For Proposals \n(C4P) Service\nAgenda Service\nNotifications \nService\nIdentity \nManagement\nService\nIdentity \nProviders\nAuthentication and Authorization Flow\nUser\nFigure 2.31    Identity management: The Role/Group is propagated to the backend services. \nOn the identity management front, you have seen that the application doesn’t handle \nusers or their data, which is good for regulations such as GDPR. We might want to \nallow users to use their social media accounts to log in to our applications without the \nneed for them to create separate accounts. This is usually known as social login. \nSome popular solutions bring both OAuth2 and identity management together, \nsuch as Keycloak (https://www.keycloak.org/) and Zitadel (https://zitadel.com/\nopensource). These open-source projects provide a one-stop-shop for single sign-on \nsolutions and advanced identity management. In the case of Zitadel, it also provides a \nmanaged service that you can use if you don’t want to install and maintain an SSO and \nidentity management component inside your infrastructure. \nThe same is true with tracing and monitoring. If you are planning to have users (and \nyou will probably do, sooner or later), including single sign-on and identity manage-\nment into the walking skeleton will push you to think about the specifics of “who will be \nable to do what,” refining your use case even more. \n2.4.7\t\nOther challenges\nIn the previous sections, we have covered a few common challenges you will face while \nbuilding cloud-native applications, but these are not all. Can you think of other ways of \nbreaking this first version of the application? \nNotice that tackling the challenges discussed in this chapter will help, but there are \nother challenges related to how we deliver a continuously evolving application com-\nposed of a growing number of services. \n",
      "content_length": 2550,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 81,
      "content": "62\nChapter 2  Cloud-native application challenges \n2.5\t\nLinking back to platform engineering\nIn previous sections, we have covered many topics. We reviewed options for packaging \nand distributing Kubernetes applications, and then installing our walking skeleton in a \nKubernetes cluster using Helm. We tested the application functionality by interacting \nwith it, and finally, we jumped into analyzing common cloud-native challenges that \nteams will face when building distributed applications. \nBut you might be wondering how all these topics relate to the title of this book, con-\ntinuous delivery, and platform engineering in general. In this section, we will make \nmore explicit connections to the topics introduced in chapter 1. \nFirst, the intention behind creating a Kubernetes cluster and running an application \non top of it was to ensure we cover Kubernetes built-in mechanisms for resilience and \nscaling up our application services. Kubernetes provides the building blocks to run our \napplications with zero downtime, even when we are constantly updating them. This \nallows us, Kubernetes users, to release new versions of our components more frequently, \nbecause we are not supposed to stop the entire application from updating one of its \nparts. In chapter 8 we will see how Kubernetes’ built-in mechanisms can be extended to \nimplement different release strategies. \nIf you are not using the capabilities offered by Kubernetes to keep releasing software \nin front of your customers, then you need to raise a red flag. Quite often, this can be \ndue to old practices from before Kubernetes that are getting in the way, lack of auto-\nmation, or not having clearly defined contracts between services that block dependent \nservices from being released independently. We will touch on this topic several times \nin future chapters because this is a fundamental principle when trying to improve your \ncontinuous delivery practice and something that the platform engineering team needs \nto prioritize.\nIn this chapter, we have also seen how to install a cloud-native application using \na package manager that encapsulates the configuration files required to deploy our \napplication. These configuration files (Kubernetes resources expressed as YAML files) \ndescribe our application topology and contain links to the containers used by each \napplication’s service. These YAML files also contain configuration for each service, \nsuch as the environment variables to configure each service. Packaging and versioning \nthese configuration files allows us to easily create new application instances in different \nenvironments, which we will cover in chapter 4. \nI highly recommend the book Grokking Continuous Delivery by Christie Wilson (Man-\nning Publications, 2018) if you want to get more insights into the continuous delivery \naspects of how configuration as code can help you deliver more software reliably. \nBecause I wanted to make sure that you have an application to play around with and \nbecause we needed to cover Kubernetes built-in mechanisms, I’ve made a conscious \ndecision to start with an already packaged application that can be easily deployed into \nany Kubernetes cluster (no matter if it is running locally or in a cloud provider). We can \nidentify two different phases. One we haven’t covered yet is how to produce these pack-\nages that can be deployed to any Kubernetes cluster, and the second, which we started \nplaying with, is when we run this application in a concrete cluster (we can consider this \ncluster an environment, maybe a development environment), as shown in figure 2.32. \n",
      "content_length": 3612,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 82,
      "content": "\t\n63\nLinking back to platform engineering\nLocal Environment\n Application\n Container \nRegistry\n Install using \nPackage \nManager\n Users can deploy new \ninstances of the \napplication to their local \nor remote environments\nFigure 2.32    \nApplications’ lifecycle \nfrom building and \npackaging to running \ninside an environment\nIt is important to understand that the steps executed for our local environment will \nwork for any Kubernetes cluster, no matter the cluster size and location. While each \ncloud provider will have its own security and identity mechanisms, the Kubernetes APIs \nand resources we created when we installed our application Helm Chart to the cluster \nwill be the same. If you now use Helm templating capabilities to fine-tune your applica-\ntion (for example, resource consumptions and network configurations) for the target \nenvironment, you can easily automate these deployments to any Kubernetes cluster. \nBefore moving on, let’s be clear that pushing developers to configure application \ninstances might not be the best use of their time. A developer accessing the production \nenvironment that users/customers are accessing might also not be optimal. We want to \nensure that developers are focused on building new features and improving our appli-\ncation. Figure 2.33 shows how we should be automating all the steps involved in build-\ning, publishing, and deploying the artifacts that developers are creating, making sure \nthat they can focus on adding features to the application instead of manually dealing \nwith packaging, distributing, and deploying new versions when they are ready. This is \nthe primary focus of this chapter. \nAgenda Service  \nSource Code \nRepository\nFrontend Source \nCode Repository\nC4P Service \nSource Code \nRepository\nNotifications \nService Source \nCode Repository\nTest & Build\nTest & Build\nTest & Build\nTest & Build\nPackage & \nPublish\nPackage & \nPublish\nPackage & \nPublish\nPackage & \nPublish\nDeploy into an \nEnvironment\nDeploy into an \nEnvironment\nDeploy into an \nEnvironment\nDeploy into an \nEnvironment\nEnvironment\nApplication\nFrontend\nAgenda \nService\nC4P Service\nNotifications \nService\nDatabases\nMessage \nBrokers\nInfrastructure\nDevelopers \nchange the \nservices’ source \ncode.\nAutomated tests \nand builds needs \nto be configured\nPackaging, \nversioning and \npublishing the \ngenerated \nartifacts needs to \nbe pain free, and \ntransparent for \ndevelopers.\nDeploying new \nartifacts into a \nsafe environment \nhelp teams to \nvalidate that their \nchanges are \nworking as \nintended\nFigure 2.33    Developers can focus on building features, but the platform team needs to automate the entire \nprocess after changes are made.\n",
      "content_length": 2664,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 83,
      "content": "64\nChapter 2  Cloud-native application challenges \nUnderstanding the tools we can use to automate the path from source code changes \nto running software in a Kubernetes cluster is fundamental to enabling developers to \nfocus on what they do best “code new features.” Another big difference we will tackle \nis that cloud-native applications are not static. As you can see in the previous diagram, \nwe will not install a static application definition. We want to release and deploy new \nversions of the services as they become available. \nManually installing applications is error-prone; manually changing configurations \nin our Kubernetes clusters can make us end up in situations where we don’t know how \nto replicate the current state of our application in a different environment. Hence \nin chapters 3 and 4, we will talk about automation using what is commonly known as \npipelines. \nIn the next chapter, we will cover a more dynamic aspect of our distributed applica-\ntion with pipelines to deliver new versions of our services. Chapter 4 will explore how we \ncan manage our environments using Kubernetes-based GitOps tools.\nSummary\n¡ Choosing between local and remote Kubernetes clusters requires serious \nconsiderations:\n–\t You can use Kubernetes KinD to bootstrap a local Kubernetes cluster to \ndevelop your application. The main drawback is that your cluster is limited by \nyour local resources (CPU and memory) and is not a real cluster of machines. \n–\t You can have an account in a cloud provider and do all development against \na remote cluster. The main drawback of this approach is that most developers \nare not used to working remotely all the time and that someone needs to pay \nfor the remote resources. \n¡ Package managers, like Helm, help you to package, distribute, and install your \nKubernetes applications. In this chapter, you installed an application into a \nKubernetes cluster with a single command line.\n¡ Understanding which Kubernetes resources are created by your application \ngives you an idea about how the application will behave when things go wrong \nand what extra considerations are needed in real-life scenarios.\n¡ Even with very simple applications, you will face challenges that you will have to \ntackle one at a time. Knowing these challenges ahead of time helps you to plan \nand architect your services with the right mindset. \n¡ Having a walking skeleton helps you to try different scenarios and technologies \nin a controlled environment. In this chapter, you have experimented with: \n–\t Scaling up and down your services to see first-hand how the application \nbehaves when things go wrong.\n–\t Keeping state is hard, and we will need dedicated components to do this \nefficiently.\n",
      "content_length": 2719,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 84,
      "content": "\t\n65\nSummary\n–\t Having at least two replicas for our services minimizes downtime. Making sure \nthat the user-facing components are always up and running guarantees that \neven when things go wrong, the user will be able to interact with parts of the \napplication.\n–\t Having fallbacks and built-in mechanisms to deal with problems when they \narise makes your application more resilient. \n¡ If you have followed the linked step-by-step tutorial, you now have hands-on \nexperience creating a local Kubernetes cluster, installing an application, scaling \nup and down services, and, most importantly, checking that the application is \nrunning as expected.\n",
      "content_length": 650,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 85,
      "content": "66\n3\nService pipelines: Building \ncloud-native applications \nThis chapter covers\n¡ Discovering the components for delivering \t\t\n\t cloud-native applications\n¡ Learning the advantages of creating and  \n\t standardizing service pipelines\n¡ Using Tekton, Dagger, and GitHub Actions to \t\n\t build cloud-native applications\nIn the previous chapter, you installed and interacted with a simple distributed Con-\nference application composed of four services. This chapter covers what it takes to \ncontinuously deliver each component using the pipeline concept as a delivery mech-\nanism. This chapter describes and shows in practice how each of these services can \nbe built, packaged, released, and published so they can run in your organization’s \nenvironments. \nThis chapter introduces the concept of service pipelines. The service pipeline takes \nall the steps to build your software from source code until the artifacts are ready to \nrun. This chapter is divided into two main sections: \n",
      "content_length": 980,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 86,
      "content": "\t\n67\nWhat does it take to deliver cloud-native applications continuously?\n¡ What does it take to deliver a cloud-native applications continuously? \n¡ Service pipelines\n–\t What is a service pipeline?\n–\t Service pipelines in action using: \n¡ Tekton, a Kubernetes native pipeline engine\n¡ Dagger to code your pipelines, and then run everywhere\n¡ Should I use Tekton, Dagger, or GitHub Actions? \n3.1\t\nWhat does it take to deliver cloud-native applications continuously?\nWhen working with Kubernetes, teams are now responsible for more moving pieces \nand tasks involving containers and how to run them in Kubernetes. These extra tasks \ndon’t come for free. Teams must learn to automate and optimize the steps required to \nkeep each service running. Tasks that were the responsibility of the operations teams \nare now becoming more and more the responsibility of the teams in charge of devel-\noping each of the individual services. New tools and new approaches give develop-\ners the power to develop, run, and maintain the services they produce. The tools that \nwe will look at in this chapter are designed to automate all the tasks involved to go \nfrom source code to a service that is up and running inside a Kubernetes cluster. This \nchapter describes the mechanisms to deliver software components (our application \nservices) to multiple environments where these services will run. But before jumping \ninto the tools, let’s take a quick look at the challenges that we are facing. \nBuilding and delivering cloud-native applications present significant challenges that \nteams must tackle:\n¡ Dealing with different team interactions when building different pieces of the applica-\ntion: This requires coordination between teams and ensuring that services are \ndesigned so that the team responsible for a service is not blocking other teams’ \nprogress or their ability to keep improving their services.\n¡ We need to support upgrading a service without breaking or stopping all the other running \nservices: If we want to achieve continuous delivery, services should be upgraded \nindependently without the fear of bringing down the entire application. This \nteams to think about how backward compatible the new version is and whether \nthe new version can run alongside the old version to avoid big bang upgrades.\n¡ Storing and publishing several artifacts per service that can be accessed/downloaded from \ndifferent environments, which might be in different regions: If we are working in a cloud \nenvironment, all servers are remote, and all produced artifacts need to be acces-\nsible for each of these servers to fetch. If you are working on an on-premise setup, \nall the repositories for storing these artifacts must be provisioned, configured, \nand maintained in-house. \n",
      "content_length": 2764,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 87,
      "content": "68\nChapter 3  Service pipelines: Building cloud-native applications  \n¡ Managing and provisioning different environments for various purposes such as devel-\nopment, testing, Q&A, and production: If you want to speed up your development \nand testing initiatives, developers and teams should be able to provision these \nenvironments on demand. Having environments configured as close as possible \nto the real production environment will save you a lot of time catching errors \nbefore they hit your live users. \nAs we saw in the previous chapter, the main paradigm shift when working with cloud-na-\ntive applications is that our application has no single code base. Teams can work inde-\npendently on their services, but this requires new approaches to compensate for the \ncomplexities of working with a distributed system. If teams worry and waste time every \ntime a new service needs to be added to the system, we are doing things wrong. End-to-\nend automation is necessary for teams to feel comfortable adding or refactoring ser-\nvices. This automation is usually performed by what is commonly known as pipelines. \nAs shown in figure 3.1, these pipelines describe what needs to be done to build and run \nour services, and usually, they can be executed without human intervention. \nPipeline\nService Source \nCode\n(in Git)\nEnvironment (Staging)\nService \nRunning\nFigure 3.1    We use the concept of a pipeline to transform source code into an artifact that can run \ninside an environment.\nYou can even have pipelines to automate the creation of a new service or add new users \nto your identity management solution. But what are these pipelines doing exactly? Do \nwe need to create our pipelines from scratch? How do we implement these pipelines in \nour projects? Do we need one or more pipelines to achieve this? \nSection 3.2 is focused on using pipelines to build solutions that can be copied, \nshared, and executed multiple times to produce the same results. Pipelines can be cre-\nated for different purposes, and it is common to define them as a set of steps (one after \nthe other in sequence) that produce a set of expected outputs. Based on these outputs, \nthese pipelines can be classified into different groups. \nMost pipeline tools allow you to define pipelines as a collection of tasks (also known \nas steps or jobs) that will run a specific job or script to perform a concrete action. These \nsteps can be anything, from running tests, copying code from one place to another, \ndeploying software, provisioning virtual machines, creating users, etc. \nPipeline definitions can be executed by a component known as the pipeline engine, \nwhich is responsible for picking up the pipeline definition to create a new pipeline \ninstance that runs each task. The tasks will be executed one after the other in sequence, \n",
      "content_length": 2814,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 88,
      "content": "\t\n69\nWhat does it take to deliver cloud-native applications continuously?\nand each task execution might generate data that can be shared with the following task. \nIf there is an error in any of the steps involved with the pipeline, the pipeline stops, and \nthe pipeline state will be marked as an error (failed). If there are no errors, the pipeline \nexecution (also known as pipeline instance) can be marked as successful. Depending \non the pipeline definition and whether the execution was successful, we should verify \nthat the expected outputs were generated or produced. \nIn figure 3.2, we can see the pipeline engine picking up our pipeline definition and \ncreating different instances that can be parameterized differently for different outputs. \nFor example, Pipeline Instance 1 finished correctly, while Pipeline Instance 2 failed to \nexecute all the tasks included in the definition. Pipeline Instance 3, in this case, is still \nrunning.\nPipeline Definition\nOK\nOK\nOK\nOK\nOK\nOK\nTask\nTask\nTask\nTask\nTask\nTask\nTask\nTask\nTask\nTask\nTask\nTask\nPipeline Instance 1\nPipeline Instance 2\nPipeline Instance 3\nPipeline Engine\nSuccessful\nFailed\nRunning\nFigure 3.2    A pipeline definition can be instantiated by a pipeline engine multiple times, and it describes \nwhat needs to be done. The pipeline engine creates pipeline Instances, which run the tasks included \nin the pipeline definition. These pipeline instances can fail or run for longer periods of time depending \non the tasks that they are performing. As a user, you can always ask the pipeline engine the status of a \nparticular pipeline instance and its tasks.\nAs expected, with these pipeline definitions we can create loads of different automa-\ntion solutions, and it is common to find tools that build more specific solutions on top \nof a pipeline engine or even hide the complexity of dealing with a pipeline engine to \nsimplify the user experience. In the following sections, we will look for examples of \ndifferent tools, some more low-level and flexible, and some higher level, more opin-\nionated, and designed to solve a very concrete scenario. \nBut how do these concepts and tools apply to delivering cloud-native applications? \nFor cloud-native applications, we have very concrete expectations about how to build, \npackage, release, and publish our software components (services) and where these \nshould be deployed. In the context of delivering cloud-native applications, we can \ndefine two main kinds of pipelines:\n¡ Service pipelines: These take care of the building, unit testing, packaging, and dis-\ntributing (usually to an artifact repository) of our software artifacts.\n",
      "content_length": 2644,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 89,
      "content": "70\nChapter 3  Service pipelines: Building cloud-native applications  \n¡ Environment pipelines: These take care of deploying and updating all the services \nin a given environment, such as staging, testing, production, etc., usually con-\nsuming what needs to be deployed from a source of truth. \nChapter 3 focuses on service pipelines, while chapter 4 focuses on tools that help us \nto define environment pipelines using a more declarative approach known as GitOps.\nBy separating the build process (service pipeline) and the deployment process (envi-\nronment pipeline), we give more control to the teams responsible for promoting new \nversions in front of our customers. Service and environment pipelines are executed \non top of different resources and with different expectations. The following section \ngoes into more detail about the steps that we commonly define in our service pipelines. \nChapter 4 covers what is expected of environment pipelines.  \n3.2\t\nService pipelines\nA service pipeline defines and executes all the steps required to build, package, and \ndistribute a service artifact so it can be deployed into an environment. A service pipe-\nline is not responsible for deploying the newly created service artifact, but it can be \nresponsible for notifying interested parties that there is a new version available for the \nservice. \nYou can share the same pipeline definition for different services if you standardize \nhow your services must be built, packaged, and released. Try to avoid pushing each of \nyour teams to define a completely different pipeline for each service, because they will \nprobably reinvent something that has already been defined, tested, and improved by \nother teams. A considerable amount of tasks need to be performed, and a set of conven-\ntions that, when followed, can reduce the time required to perform the whole process. \nThe name service pipeline refers to the fact that each of our application’s services will \nhave a pipeline that describes the tasks required for that particular service. If the ser-\nvices are similar and they are using a similar technology stack, it makes sense for the \npipelines to look quite similar. One of the main objectives of these service pipelines is to \ncontain enough detail to run without any human intervention, automating all the tasks \nin the pipeline end to end. \nService pipelines can be used as a mechanism to improve the communication \nbetween the development team that is creating a service and the operations team that \nis running that service in production. Development teams expect these pipelines to \nrun and notify them if there is any problem with the code they are trying to build. If \nthere are no errors, they will expect one or more artifacts to be produced as part of \nthe pipeline execution. Operations teams can add all the checks to these pipelines to \nensure the produced artifacts are production ready. These checks can include policy \nand conformance checks, signing, security scanning, and other requirements that vali-\ndate that the produced artifacts are up to the standards expected to run in the produc-\ntion environment. \n",
      "content_length": 3131,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 90,
      "content": "\t\n71\nConventions that will save you time\nNOTE    It is tempting to think about creating a single pipeline for the entire \napplication (collection of services), as we did with monolith applications. How-\never, that defeats the purpose of independently updating each service at its own \npace. You should avoid situations with a single pipeline defined for a set of ser-\nvices, because it will block your ability to release services independently. \n3.3\t\nConventions that will save you time\nService pipelines can be more opinionated on their structure and reach. By following \nsome of these strong opinions and conventions, you can avoid pushing your teams to \ndefine every little detail and discover these conventions by trial and error. The follow-\ning approaches have been proven to work: \n¡ Trunk-based development: The idea here is to ensure that what you have in the \nmain branch of your source code repository is always ready to be released. You \ndon’t merge changes that break this branch’s build and release process. You only \nmerge if the changes you are merging are ready to be released. This approach \nalso includes using feature branches, which allow developers to work on features \nwithout breaking the main branch. When the features are done and tested, devel-\nopers can send pull requests (change requests) for other developers to review \nand merge. This also means that when you merge something to the main branch, \nyou can automatically create a new release of your service (and all the related \nartifacts). This creates a continuous stream of releases generated after each new \nfeature is merged into the main branch. Because each release is consistent and \nhas been tested, you can then deploy this new release to an environment that \ncontains all the other services of your application. This approach enables the \nteam behind the service to move forward and keep releasing without worrying \nabout other services. \n¡ Source code and configuration management: There are different approaches to deal-\ning with software and the configuration needed to run the software we are pro-\nducing. When we talk about services and distributed applications, there are two \ndifferent schools of thought: \n–\t One service/one repository/one pipeline: You keep your service source code and all \nthe configurations that need to be built, packaged, released, and deployed in \nthe same repository. This allows the team behind the service to push changes \nat any pace they want without worrying about other services’ source code. It \nis a common practice to have the source code in the same repository where \nyou have the Dockerfile describing how the Docker image should be created \nand the Kubernetes manifest required to deploy the service into a Kubernetes \ncluster. These configurations should include the pipeline definition that will \nbe used to build and package your service. \n–\t Mono repository: Alternatively, use a mono repository approach where a sin-\ngle repository is used, and different pipelines are configured for different \n",
      "content_length": 3037,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 91,
      "content": "72\nChapter 3  Service pipelines: Building cloud-native applications  \ndirectories inside the repository. While this approach can work, you need to \nensure that your teams are not blocking each other by waiting for each other’s \npull requests to merge.  \n¡ Consumer-driven contract testing: Your service uses contracts to run tests against \nother services. Unit testing an individual service shouldn’t require having other \nservices up and running. By creating consumer-driven contracts, each service \ncan test its functionality against other APIs. If any downstream service is released, \na new contract is shared with all the upstream services so they can run their tests \nagainst the new version. \nThere are two books that I strongly recommend:\n¡ Continuous Delivery: Reliable Software Releases through Build, Test, and Deployment \nAutomation by Jez Humble and David Farley (Addison-Wesley Professional, 2010) \n¡ Grokking Continuous Delivery by Christie Wilson (Manning Publications, 2022)\nMost of the tools mentioned in these books allow you to implement these practices \nfor efficient delivery. If we take these practices and conventions into account, we can \ndefine the responsibility of a service pipeline as follows: A service pipeline transforms \nsource code to one or a set of artifacts that can be deployed in an environment. \n3.4\t\nService pipeline structure\nWith this definition in mind, let’s take a look at what tasks are included in service pipe-\nlines for cloud-native applications that will run on Kubernetes: \n¡ Register to receive notifications about changes in the source code repository main branch: \n(Source version control system, nowadays a Git repository.) If the source code \nchanges, we need to create a new release. We create a new release by triggering \nthe service pipeline. This is usually implemented using webhooks or a pull-based \nmechanism that checks if new changes were submitted.\n¡ Clone the source code from the repository: To build the service, we need to clone the \nsource code into a machine that has the tools to build/compile the source code \ninto a binary format that can be executed.\n¡ Create a new tag for the new version to be released: Based on trunk-based development, \na new release can be created every time a change happens. This will help us to \nunderstand what is being deployed and what changes were included in each new \nrelease. \n¡ Build and test the source code:\n–\t As part of the build process, most projects will execute unit tests and break the \nbuild if there are any failures.\n–\t Depending on our technology stack, we will need tools available for this step, \nfor example, compilers, dependencies, linters (static source code analyzers), \netc.\n",
      "content_length": 2706,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 92,
      "content": "\t\n73\nService pipeline structure\n–\t Tools like CodeCov, which measures how much of the code is being covered \nby tests, are used to block changes from being merged if a coverage threshold \nis not met. \n–\t Security scanners are also used to evaluate vulnerabilities on our application \ndependencies. If a new CVE (Common Vulnerabilities and Exposures) is \nfound, the change can be blocked too.\n¡ Publish the binary artifacts into an artifact repository: We need to make sure that these \nbinaries are available for other systems to consume, including the next steps in \nthe pipeline. This step involves copying the binary artifact to a different location \nover the network. This artifact will share the same version of the tag created in \nthe repository, providing us with traceability from the binary to the source code \nused to produce it. \n¡ Building a container image: If we are building cloud-native services, we must build \na container image. The most common way of doing this today is using Docker \nor other container alternatives. This step requires the source code repository to \nhave, for example, a Dockerfile defining how this container image needs to be \nbuilt and the mechanism to build (builder) the container image. Some tools like \nCNCF Buildpacks (https://buildpacks.io) save us from having a Dockerfile and \ncan automate the container-building process. Having the right tools for the job \nis essential, because multiple container images might need to be generated for \ndifferent platforms. For a released service, we might have more than one con-\ntainer image, for example, one for amd64 and one for arm64 platforms. All the \nexamples in this book are built for these two platforms.\n¡ Publish the container image into a container registry: In the same way that we pub-\nlished the binary artifacts generated when building our service source code, we \nneed to publish our container image into a centralized location where others can \naccess it. This container image will have the same version as the tag created in the \nrepository and the binary published. This helps us see which source code will run \nwhen you run the container image. \n¡ Lint, verify, and optionally package YAML files for Kubernetes deployments (Helm can \nbe used here): If you are running these containers inside Kubernetes, you need \nto manage, store, and version a Kubernetes manifest that defines how the con-\ntainers are going to be deployed into a Kubernetes cluster. If you use a package \nmanager such as Helm, you can version the package with the same version used \nfor the binaries and the container image. My rule for packaging YAML files goes \nas follows: “If you have enough people trying to install your services (open-source \nproject or very large globally distributed organization), you might want to pack-\nage and version your YAML files. If you only have a few teams and environments \nto handle, you can probably distribute the YAML files without using a packaging \ntool.” \n¡ (Optional) Publish these Kubernetes manifests to a centralized location: If you are using \nHelm, it makes sense to push these Helm packages (called Charts) to a centralized \n",
      "content_length": 3151,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 93,
      "content": "74\nChapter 3  Service pipelines: Building cloud-native applications  \nlocation. This will allow other tools to fetch these Charts so they can be deployed \nin any number of Kubernetes clusters. As we saw in chapter 2, these Helm Charts \ncan now be distributed as OCI container images to a container registry.\n¡ Notify interested parties about the new version of the service: If we are trying to automate \nfrom a source to a service running, the service pipeline can send notifications to \nall the interested services that might be waiting for new versions to be deployed. \nThese notifications can be pull requests to other repositories, events to an event \nbus, emails to the teams interested in these releases, etc. A pull-based approach \ncan also work, where an agent constantly monitors the artifact repository (or con-\ntainer registry) to see if new versions are available for a given artifact.\nFigure 3.3 shows the steps described in the previous bullet points as a sequence of \nsteps. Most pipeline tools will have a visual representation that allows you to see which \nsteps will be executed.\nClone \nSource \nCode\nBuild & \nTest\nPush to \nrepository\nBuild \nContainer\nPush to \nContainer \nRegistry\nVerify (lint) \nKubernetes \nYAML files \nor Helm \nPackage\nPush \nChart to \nRepository\nNotify new \nversion \navailable\nChange \nin Git\nPipeline Instance\nCreate a Pipeline Instance\nFigure 3.3    Service pipelines automate all the steps required to produce artifacts that can run in \nmultiple environments. Service pipelines are often triggered by changes in source code, but are not in \ncharge of deploying the created artifacts in a specific environment. They can notify other components \nabout these new versions. \nThe outcome of this pipeline is a set of artifacts that can be deployed to an environ-\nment to have the service up and running. The service needs to be built and packaged \nin a way that does not depend on any specific environment. The service can depend \non other services to work in the environment, such as infrastructural components like \ndatabases, message brokers, or other downstream services. \nNo matter the tool that you choose to use to implement these pipelines, you should \nbe looking at the following characteristics: \n",
      "content_length": 2239,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 94,
      "content": "\t\n75\nService pipeline structure\n¡ Pipelines run automatically based on changes (if you follow trunk-based develop-\nment, one pipeline instance is created for every change in the repository’s main \nbranch). \n¡ Pipelines executions will notify about the success or failure state with clear mes-\nsages. This includes having easy ways to find, for example, the why and where the \npipeline failed or how much time it takes to execute each step. \n¡ Each pipeline execution has a unique id that we can use to access the log and \nthe parameters that were used to run the pipeline, so we can reproduce the setup \nthat was used to troubleshoot problems. Using this unique id, we can also access \nthe logs created by all the steps in the pipeline. By looking at the pipeline exe-\ncution, we should also be able to find all the produced artifacts and where those \nwere published. \n¡ Pipelines can also be triggered manually and configured with different parame-\nters for special situations. For example, to test a work-in-progress feature branch. \nLet’s now deep dive into the concrete details of what a service pipeline will look like in \nreal life. \n3.4.1\t\nService pipeline in real life\nIn real life, a service pipeline will run every time you merge changes to the main branch \nof your repository. This is how it should work if you follow a trunk-based development \napproach: \n¡ When you merge changes to your main branch, this service pipeline runs and \ncreates a set of artifacts using the latest code base. If the service pipeline succeeds, \nour artifacts will be releasable. We want to ensure that our main branch is always \nin a releasable state, so the service pipeline that runs on top of the main branch \nmust always succeed. If, for some reason, this pipeline is failing, the team behind \nthe service needs to switch the focus to fixing the problem as soon as possible. In \nother words, teams shouldn’t merge code into your main branch that breaks its \nservice pipeline. We must also run a pipeline in our feature branches to do that. \n¡ For each of your feature branches, a very similar pipeline should run to verify \nthat the changes in the branch can be built, tested, and released against the main \nbranch. In modern environments, the concept of GitHub pull requests is used to \nrun these pipelines to make sure that before merging any pull request, a pipeline \nvalidates the changes. \n¡ It is common that after merging a set of features to the main branch, and because \nwe know that the main branch is releasable at all times, the team in charge of \nthe service decides to tag a new release. In Git, a new tag (a pointer to a specific \ncommit) is created based on the main branch. The tag name is commonly used \nto represent the version of the artifact that the pipeline will create. \nFigure 3.4 shows the pipelines configured for the main branch and a generic pipeline \nto validate feature branches only when pull requests are created. Multiple instances of \nthese pipelines can be triggered to validate new changes continuously. \n",
      "content_length": 3036,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 95,
      "content": "76\nChapter 3  Service pipelines: Building cloud-native applications  \nService Pipeline (main branch)\nService Pipeline (feature branch)\nThis pipeline creates \nreleases that can be \ndeployed by other teams.\nGit\nmain\nfeature X\nThis pipeline creates \nartifacts that can be used \nfor integration testing \nbefore creating releases.\nFigure 3.4    Service pipelines for main branch and feature branches\nThe service pipeline shown in figure 3.4 represents the most common steps you must \nexecute every time you merge something to the main branch. Still, there are also some \nvariations of this pipeline that you might need to run under different circumstances. \nDifferent events can kick off a pipeline execution, and we can have slightly different \npipelines for different purposes, such as: \n¡ Validate a change in a feature branch: This pipeline can execute the same steps as \nthe pipeline in the main branch, but the artifacts generated should include the \nbranch name, maybe as a version or as part of the artifact name. Running a pipe-\nline after every change might be too expensive and not needed all the time, so \nyou should decide based on your needs. \n¡ Validate a pull request (PR)/change request: The pipeline will validate that the pull \nrequest/change request changes are valid and that artifacts can be produced \nwith the recent changes. Usually, the result of the pipeline can be notified back \nto the user in charge of merging the PR and also block the merging options if the \npipeline is failing. This pipeline is used to validate that whatever is merged into \nthe main branch is valid and can be released. Validating pull requests and change \nrequests can be an excellent option to avoid running pipelines for every change \nin the feature branches. When the developer(s) is ready to get feedback from the \nbuild system, it can create a PR that will trigger the pipeline. The pipeline would \nbe retriggered if developers made changes on top of the pull request. \nDespite minor differences and optimizations that can be added to these pipelines, \nthe behavior and produced artifacts are mostly the same. These conventions and \napproaches rely on the pipelines executing enough tests to validate that the produced \nservice can be deployed to an environment. \n3.4.2\t\nService pipeline requirements\nThis section covers the infrastructural requirements for service pipelines to work and \nthe contents of the source repository required for the pipeline to do its work.\nLet’s start with the infrastructural requirements that a service pipeline needs to work: \n",
      "content_length": 2561,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 96,
      "content": "\t\n77\nService pipeline structure\n¡ Webhooks for source code change notifications: First, it needs access to register web-\nhooks to the Git repository with the service’s source code, so a pipeline instance \ncan be created when a new change is merged into the main branch. \n¡ Artifact repository available and valid credentials to push the binary artifacts: Once the \nsource code is built, we need to push the newly created artifact to the artifact \nrepository where all artifacts are stored. This requires configuring an artifact \nrepository with valid credentials to push new artifacts. \n¡ Container registry and valid credentials to push new container images: In the same way \nas we need to push binary artifacts, we need to distribute our docker contain-\ners, so Kubernetes clusters can fetch the images when we want to provision a \nnew instance of a service. A container registry with valid credentials is needed to \naccomplish this step. \n¡ Helm Chart repository and valid credentials: Kubernetes manifest can be packaged \nand distributed as Helm Charts. If you are using Helm, you must have a Helm \nChart repository and valid credentials to push these packages.\nFigure 3.5 shows the most common external systems a pipeline instance will interact \nwith. From a Git repository to artifact repositories and container registries, the team \nmaintaining these pipelines must ensure that the right credentials are in place and \nthat these components are reachable (from a network perspective) from where the \npipelines are running. \nGit Repository\nClone \nSource \nCode\nBuild & \nTest\nPush to \nrepository\nBuild \nContainer\nPush to \nContainer \nRegistry\nVerify (lint) \nKubernetes \nYAML files \nor Helm \nPackage\nPush \nChart to \nRepository\nPipeline Instance\nArtifact \nRepository\nDocker Registry\nHelm Chart \nRepository\n<Registered Webhooks>\n<Valid Credentials>\n<Valid Credentials>\n<Valid Credentials>\nFigure 3.5    Running pipelines requires a lot of infrastructure to be in place. This includes maintaining services and \nrepositories, creating users and credentials, and making sure that these services (repositories) are accessible from \nremote locations. \nFor service pipelines to do their job, the repository containing the service’s source \ncode also needs to have a Dockerfile or the ways to produce a container image and the \nnecessary Kubernetes manifest to deploy the service into Kubernetes. \nFigure 3.6 shows a possible directory layout of our service source code repository, \nwhich includes the source (src) directory containing all the files that will be compiled \n",
      "content_length": 2565,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 97,
      "content": "78\nChapter 3  Service pipelines: Building cloud-native applications  \ninto binary format. The Dockerfile is used to build our container image for the service, \nand the Helm Chart directory contains all the files to create a Helm chart that can be \ndistributed to install the service into a Kubernetes cluster. You can decide between hav-\ning a Helm Chart per service or a single Helm Chart for all the application services.\nFigure 3.6 shows the service layout, including the Helm Chart definition. This can \nhelp to package and distribute services independently. If we include everything needed \nto build, package, and run our service into a Kubernetes cluster, the service pipeline \nneeds to run after every change in the main branch to create a new service release. \nHelm Chart Directory: contains all the \nKubernetes YAML ﬁles that we need to \ndeploy our service to Kubernetes\nDockerﬁle: deﬁnes how to create a \ncontainer for our service\nService Pipeline: contains the tasks to \nbuild the contents of this repository\nService’s Source Code: contains the \nsource code from our Service\nFigure 3.6    The service source code repository needs to have all the configurations for the service \npipeline to work.\nIn summary, service pipelines are responsible for building our source and related \nartifacts to be deployed into an environment. As mentioned, service pipelines are not \nresponsible for deploying the produced service into a live environment. The environ-\nment pipeline’s responsibility is covered in the next chapter. \n3.4.3\t\nOpinions, limitations, and compromises around service pipelines \nNo “one size fits all” solution exists for creating our service pipelines. In real life, you \nmust make compromises depending on your requirements. Before looking at tools like \nTekton, Dagger, and GitHub Actions, let me quickly touch on some practical aspects \nI’ve seen teams fighting with. Here is a short and non-comprehensive list of things to \nconsider when designing your service pipelines: \n¡ Avoid strict rules and opinions to define where service pipelines start and end: For \nexample, your services might not need to be packaged as Helm Charts, as men-\ntioned in the previous sections. If there are not enough cases when you want to \ninstall an isolated service—for example, your service depends heavily on other \nservices—removing that step from the service pipeline and the chart definition \nfrom the service repository might make a lot of sense.\n¡ Understand the lifecycle of your components and artifacts: Depending on how often ser-\nvices change and their dependencies, service pipelines can be linked together to \n",
      "content_length": 2629,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 98,
      "content": "\t\n79\nService pipelines in action\nbuild a set of services together. Mapping these relationships and understanding \nthe needs of the teams operating these services will give you the right granular-\nity to create your service pipelines. For example, you can enable your teams to \nkeep releasing new container images for new versions of the services that they are \nworking on, but a different team controls the cadence and release of the Helm \nCharts that bundle all the application services together.\n¡ Find what works best for your organization: Optimize end-to-end automation based \non business priorities. If a critical service is causing delays to be released and \ndeployed, focus on having the service pipeline ready and fully functional before \ntrying to cover other services. There is no point in creating generic solutions that \nmight take a while to figure out that your organization suffers 80% of the cases \nwith a single service.\n¡ Do not create unnecessary steps until they are required: I’ve heavily mentioned tools like \nHelm in this book to package and distribute Kubernetes manifest, but I am not \nsuggesting that is the way to go. I’ve used Helm as an example tool that is widely \nadopted, but you might be in a situation where you don’t need to package your \nKubernetes manifest for distribution. Your service pipeline shouldn’t have that \nstep if that’s the case. If the need arises later, you can extend your service pipe-\nlines to include more steps. \nLet’s now jump to see some tools in this space.\n3.5\t\nService pipelines in action\nThere are several pipeline engines out there, even fully managed services like GitHub \nActions (https://github.com/features/actions) and several well-known CI (continu-\nous integration) managed services that will provide loads of integrations for you to \nbuild and package your application’s services. \nIn the following sections, we will examine two projects: Tekton and Dagger. These \nprojects provide you with the tools to work with cloud-native applications and, as we will \nsee in chapter 6, enable platform teams to package, distribute, and reuse the organi-\nzation’s specific knowledge built over time. Tekton (https://tekton.dev) was designed \nas a pipeline engine for Kubernetes. Because Tekton is a generic pipeline engine, you \ncan create any pipeline with it. On the other hand, a much newer project called Dagger \n(https://dagger.io) was designed to run everywhere. We will contrast Tekton and Dag-\nger with GitHub actions.\n3.5.1\t\nTekton in action\nTekton was initially created as part of the Knative project (https://knative.dev) from \nGoogle. (We will look more into Knative in chapter 8). Tekton was initially called Kna-\ntive Build, and later separated from Knative to be an independent project. Tekton’s \nmain characteristic is that it is a cloud-native pipeline engine designed for Kubernetes. \nThis section will look into how to use Tekton to define service pipelines. \n",
      "content_length": 2940,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 99,
      "content": "80\nChapter 3  Service pipelines: Building cloud-native applications  \nIn Tekton, you have two main concepts: tasks and pipelines. In Tekton, the pipeline \nengine is a set of components that understand how to execute Tasks and Pipelines \nKubernetes resources. Tekton, like most of the Kubernetes projects covered in this \nbook, can be installed into your Kubernetes cluster. I strongly recommend you check \ntheir official documentation page, which explains the value of using a tool like Tekton \nat https://tekton.dev/docs/concepts/overview/. \nNOTE    I’ve included a set of step-by-step tutorials in this repository. You can \nstart by looking at how to install Tekton in your cluster and the tekton/hello \n-world/ example at https://github.com/salaboy/platforms-on-k8s/tree/main/ \nchapter-3/tekton.\nWhen you install Tekton, you install a set of custom resource definitions, which are \nextensions to the Kubernetes APIs, that define tasks and pipelines. Tekton also installs \nthe pipeline engine that knows how to deal with Tasks and Pipelines resources. \nNotice that after installing Tekton, you can also install the Tekton Dashboard and the \ntkn command-line interface tool.\nOnce you install the Tekton release, you will see a new namespace called tekton \n-pipelines, which contains the pipeline controller (the pipeline engine), and the \npipeline webhook listener, which is used to listen for events coming from external \nsources, such as git repositories. \nA task in Tekton will look like a normal Kubernetes resource, as shown in listing 3.1.\nListing 3.1    Simple Tekton task definition\napiVersion: tekton.dev/v1\nkind: Task\nmetadata:\n name: hello-world-task\nspec:\n  params:\n   - name: name\n     type: string\n     description: who do you want to welcome?\n     default: tekton user\n steps:\n   - name: echo\n     image: ubuntu\n     command:\n       - echo\n     args:\n       - \"Hello World: $(params.name)\" \nThe name of the resource defined \nin metadata.name represents the \ntask definition name.\nWe can use the \nparams section to \ndefine which \nparameters can be \nconfigured for our \ntask definition.\nThe Docker image \ncalled Ubuntu is \ngoing to be used for \nthis task.\nThe command \narguments (args) \nin this case are \njust a “Hello \nWorld” string; \nnotice that you \ncan send a list of \narguments for \nmore complex \ncommands.\nThe command arguments (args) in this case\n are just a “Hello World: $(params.name)” \nstring, which will use the Task parameter.\n",
      "content_length": 2454,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 100,
      "content": "\t\n81\nService pipelines in action\nYou can find the task definition in this repository, alongside a step-by-step tutorial to \nrun it in your cluster: https://github.com/salaboy/platforms-on-k8s/blob/main/\nchapter-3/tekton/hello-world/hello-world-task.yaml. \nDerived from this example, you can create a task for whatever you want, because you \nhave the flexibility to define which container to use and which commands to run. Once \nyou have the task definition, you need to make that available to Tekton by applying this \nfile to the cluster with kubectl apply -f task.yaml. By applying the file into Kuber-\nnetes, we are only making the definition available to the Tekton components in the \ncluster, but the task will not run. \nIf you want to run this task, a task can be executed multiple times. Tekton requires \nyou to create a TaskRun resource like the following listing.\nListing 3.2    A task run represents an instance of our task definition\napiVersion: tekton.dev/v1\nkind: TaskRun\nmetadata:\n  name: hello-world-task-run-1\nspec:\n  params: \n  - name: name\n    value: \"Building Platforms on top of Kubernetes reader!\" \n  taskRef:\n    name: hello-world-task\nThe TaskRun resource can be found at https://github.com/salaboy/platforms-on \n-k8s/blob/main/chapter-3/tekton/hello-world/task-run.yaml. \nIf you apply this TaskRun to the cluster (kubectl apply -f taskrun.yaml), the \npipeline engine will execute this task. You can take a look at the Tekton task in action by \nlooking at the TaskRun resources in listing 3.3. \nListing 3.3    Get all TaskRun instances\n> kubectl get taskrun\nNAME                             SUCCEEDED       STARTTIME   COMPLETIONTIME\nhello-world-task-run-1           True            66s         7s\nIf you list all the running pods, you will notice that each task creates a pod, as shown in \nlisting 3.4. \nWe can define specific \nparameter values for \nthis TaskRun.\nWe need to reference the name of \nthe task definition that we want to \nrun. Notice that this name is unique \nper task resource that we define.\n",
      "content_length": 2030,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 101,
      "content": "82\nChapter 3  Service pipelines: Building cloud-native applications  \nListing 3.4    List all the pods associated to TaskRuns\n> kubectl get pods \nNAME                                     READY   STATUS   AGE\nhello-world-task-run-1-pod               0/1     Init:0/1 2s\nAnd because you have a pod, you can tail the logs to see what the task is doing as in \nlisting 3.5. \nListing 3.5    Accessing the TaskRun logs using the pod name\n> kubectl logs -f hello-world-task-run-1-pod  \nDefaulted container \"step-echo\" out of: step-echo, prepare (init) \nHello World: Building Platforms on top of Kubernetes reader!\nYou just executed your first Tekton TaskRun. Congrats! But a single task is not interest-\ning at all. If we can sequence multiple tasks together, we can create our service pipe-\nlines. Let’s look at how we can build Tekton pipelines from this simple task example. \n3.5.2\t\nPipelines in Tekton\nA task can be helpful, but Tekton becomes interesting when you create sequences of \nthese tasks using pipelines. \nA pipeline is a collection of these tasks in a concrete sequence. The following pipe-\nline uses the task definition that we defined earlier. It prints a message, fetches a file \nfrom a URL, and then reads its content, which is forwarded to our Hello World task, \nwhich prints a message. \nFigure 3.7 shows a simple Tekton pipeline comprising three Tekton tasks. \n'wget'\n'cat'\nHello World!\nDownload a file \nfrom a 'url'\nReads the file that was \ndownloaded and set \nthe content in \n'results.message'\nPrints “Hello World:” \nappending the content of \n'results.message'\nFigure 3.7    Simple Tekton pipeline using our Hello World task\nIn this simple pipeline, we are using an existing task definition (wget) from the Tekton \nHub, which is a community repository hosting generic tasks, and then we are defining \nthe cat task inline inside the pipeline to showcase Tekton flexibility, to finally use the \nHello World task that we defined in the previous section.\nLet’s look at a simple service pipeline defined in Tekton (hello-world-pipeline \n.yaml). Don’t be scared. This is a lot of YAML, I warned you. See listing 3.6. \n",
      "content_length": 2127,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 102,
      "content": "\t\n83\nService pipelines in action\nListing 3.6    Pipeline definition\napiVersion: tekton.dev/v1\nkind: Pipeline\nmetadata:\n  name: hello-world-pipeline\n  annotations:\n    description: |\n      Fetch resource from internet, cat content and then say hello\nspec:\n  results:  \n  - name: message\n    type: string\n    value: $(tasks.cat.results.messageFromFile)\n  params: \n  - name: url\n    description: resource that we want to fetch\n    type: string\n    default: \"\"\n  workspaces: \n  - name: files\n  tasks:\n  - name: wget\n    taskRef: \n      name: wget\n    params:\n    - name: url\n      value: \"$(params.url)\"\n    - name: diroptions\n      value:\n        - \"-P\"  \n    workspaces:\n    - name: wget-workspace\n      workspace: files\n  - name: cat\n    runAfter: [wget]\n    workspaces:\n    - name: wget-workspace\n      workspace: files\n    taskSpec:  \n      workspaces:\n      - name: wget-workspace\n      results: \n        - name: messageFromFile\n          description: the message obtained from the file\n      steps:\nPipeline resources can define an array of \nresults that are expected from the pipeline \nwhen they are executed. Tasks can set these \nresults values when they are executed.\nIn the same way as \ntasks, we can define \nwhich parameters can \nbe set by the user \nwhen running this \npipeline. These \npipeline parameters \ncan be forwarded to \nindividual tasks if \nneeded.\nPipelines and tasks allow \nthe use of Tekton \nWorkspaces to store \npersistent information. \nThis can be used to share \ninformation between \ntasks. As each task is \nexecuted in its container, \nusing persistent storage \nto share information is \neasy to set up.\nWe use a task \nreference to a task we \ndidn’t create. We need \nto make sure to install \nthis task definition \nbefore creating a \nPipelineRun for this \npipeline.\nWe can define tasks inline the pipeline if we want to. \nThis makes the pipeline file more complicated, but \nsometimes it is useful to have a task that just glues \nother tasks together, as is shown in this case. The only \npurpose of this task is to read the content of the \ndownloaded file and make it available as a String for \nour Hello World task that doesn’t accept a file. \n",
      "content_length": 2163,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 103,
      "content": "84\nChapter 3  Service pipelines: Building cloud-native applications  \n      - name: cat\n        image: bash:latest\n        script: |\n          #!/usr/bin/env bash\n          cat $(workspaces.wget-workspace.path)/welcome.md |  \n➥tee /tekton/results/messageFromFile\n  - name: hello-world\n    runAfter: [cat]\n    taskRef:\n      name: hello-world-task  \n    params:\n      - name: name\n        value: \"$(tasks.cat.results.messageFromFile)\"  \nYou can find the full pipeline definition at https://github.com/salaboy/platforms \n-on-k8s/blob/main/chapter-3/tekton/hello-world/hello-world-pipeline.yaml. \nBefore applying the pipeline definition, you need to install the wget Tekton task that \nwas created and maintained by the Tekton community: \nkubectl apply -f\n➥https://raw.githubusercontent.com/tektoncd/catalog/main/task/wget/0.1/wget.yaml\nOnce again, you must apply this pipeline resource to your cluster for Tekton to know \nabout: kubectl apply -f hello-world-pipeline.yaml.\nAs you can see in the pipeline definition, the spec.tasks field contains an array of \ntasks. These tasks need to be already deployed into the cluster, and the pipeline defini-\ntion defines the sequence in which these tasks will be executed. These task references \ncan be your tasks, or as in the example, they can come from the Tekton catalog, a repos-\nitory containing community-maintained task definitions that you can reuse. \nIn the same way, because tasks need TaskRuns for the executions, you will need to \ncreate a PipelineRun for every time you want to execute your pipeline, as shown in the \nfollowing listing. \nListing 3.7    PipelineRun represent an instance (execution) of our pipelines\napiVersion: tekton.dev/v1\nkind: PipelineRun\nmetadata:\n  name: hello-world-pipeline-run-1\nspec:\n  workspaces: \n    - name: files\n      volumeClaimTemplate: \n        spec:\nThis also requires installing the “hello-world-\ntask” definition in the cluster. Remember \nthat you can always run “kubectl get tasks” \nto see which tasks are available.\nWe can use Tekton’s powerful templating mechanism \nto provide the value for Hello World task. We are using \na reference to the “cat” task results.\nWhen we create a PipelineRun, we need to \nbound the workspaces defined in the \npipeline definition to real storage. In this \ncase a VolumeClaim is created requesting 1 \nMb of storage for the PipelineRun to use. \n",
      "content_length": 2367,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 104,
      "content": "\t\n85\nService pipelines in action\n          accessModes:\n          - ReadWriteOnce\n          resources:\n            requests:\n              storage: 1M \n  params: \n  - name: url\n    value: \n➥\"https://raw.githubusercontent.com/salaboy/salaboy/main/welcome.md\"\n  pipelineRef:\n    name: hello-world-pipeline\nYou can find the PipelineRun resource at https://github.com/salaboy/platforms-on \n-k8s/blob/main/chapter-3/tekton/hello-world/pipeline-run.yaml. \nWhen you apply this file to the cluster kubectl apply -f pipeline-run.yaml, Tek-\nton will execute the pipeline by running all the tasks defined in the pipeline definition. \nWhen running this pipeline, Tekton will create one pod per task and three TaskRun \nresources. A pipeline is just orchestrating tasks, or in other words creating TaskRuns. \nTo check that the TaskRuns were created and that the pipeline executed successfully, \nsee listing 3.8. \nListing 3.8    Getting task runs from the pipeline execution\n> kubectl get taskrun\nNAME                                   SUCCEEDED  STARTTIME  COMPLETIONTIME\nhello-world-pipeline-run-1-cat         True       109s       104s\nhello-world-pipeline-run-1-hello-world True       103s       98s\nhello-world-pipeline-run-1-wget        True       117s       109s\nFor each TaskRun, Tekton created a pod (listing 3.9).\nListing 3.9    Checking that all TaskRuns belonging to the pipeline have finished\n> kubectl get pods\nNAME                                         READY   STATUS         AGE\nhello-world-pipeline-run-1-cat-pod           0/1     Completed      11s\nhello-world-pipeline-run-1-hello-world-pod   0/1     Completed      5s\nhello-world-pipeline-run-1-wget-pod          0/1     Completed      19s\nReview the logs from the hello-world-pipeline-run-1-hello-world-pod to see \nwhat the task printed, as shown in listing 3.10. \nListing 3.10    Getting the logs from the last task\n> kubectl logs hello-world-pipeline-run-1-hello-world-pod\nDefaulted container \"step-echo\" out of: step-echo, prepare (init)\nHello World: Welcome, Internet traveler! Do you want to learn more about \nPlatforms on top of Kubernetes? Check this repository: https://github.com/\nsalaboy/platforms-on-k8s\nThe pipeline parameter “url” can be any \nURL that you want as soon because it is \naccessible from the PipelineRun context \n(meaning that it can reach the URL, and \nit is not behind a firewall). \nAs with tasks, we need to provide the \nname of the pipeline definition that \nwe want to use for this PipelineRun.\n",
      "content_length": 2482,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 105,
      "content": "86\nChapter 3  Service pipelines: Building cloud-native applications  \nYou can always look at Tasks, TaskRuns, Pipelines, and PipelineRuns in the Tekton \ndashboard. To access the Tekton dashboard, if you installed it in your cluster, you need \nto first run: \n> kubectl port-forward -n tekton-pipelines \n➥services/tekton-dashboard 9097:9097\nFigure 3.8 shows the Tekton dashboard user interface, where we can explore our task \nand pipeline definitions as well as trigger new task and pipeline runs and explore the \nlogs that each task outputs.\nFigure 3.8    Our PipelineRun execution in the Tekton dashboard\nIf required, you can find a step-by-step tutorial on how to install Tekton in your Kuber-\nnetes cluster and how to run the service pipeline at the following repository: https://\ngithub.com/salaboy/platforms-on-k8s/blob/main/chapter-3/tekton/hello-world/\nREADME.md. \nAt the end of the tutorial, you will find links to more complex pipelines I’ve defined \nfor each Conference application service. These pipelines are more complex because \nthey require access to external services, credentials to publish artifacts and container \nimages, and the rights to do some privileged actions inside the cluster. Check this sec-\ntion of the tutorial if you are interested in more details: https://github.com/salaboy/\nplatforms-on-k8s/tree/main/chapter-3/tekton#tekton-for-service-pipelines. \n3.5.3\t\nTekton advantages and extras\nAs we have seen, Tekton is super flexible and allows you to create advanced pipelines, \nand it includes other features, such as: \n¡ Input and output mappings to share data between tasks\n¡ Event triggers that allow you to listen for events that will trigger pipelines or tasks\n¡ A command-line tool to easily interact with tasks and pipelines from your terminal\n¡ A simple dashboard to monitor your pipelines and task executions (figure 3.9)\n",
      "content_length": 1861,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 106,
      "content": "\t\n87\nService pipelines in action\nFigure 3.9    Tekton dashboard—a user interface for monitoring your pipelines\nFigure 3.9 shows the community-driven Tekton dashboard, which you can use to visu-\nalize the execution of your pipelines. Remember that because Tekton was built to work \non top of Kubernetes, you can monitor your pipelines using kubectl as with any other \nKubernetes resource. Still, nothing beats a user interface for less technical users. \nBut now, if you want to implement a service pipeline with Tekton, you will spend \nquite a bit of time defining tasks, the pipeline, how to map inputs and outputs, defin-\ning the right events listener for your Git repositories, and then going more low-level \ninto defining which docker images you will use for each task. Creating and maintaining \nthese pipelines and their associated resources can become a full-time job, and for that, \nTekton launched an initiative to define a catalog where tasks (pipelines and resources \nare planned for future releases) can be shared. The Tekton catalog is available at \nhttps://github.com/tektoncd/catalog. \nWith the help of the Tekton catalog, we can create pipelines that reference tasks \ndefined in the catalog. In the previous section, we used the wget task downloaded from \nthis catalog; you can find a full description of the wget task at https://hub.tekton.dev/\ntekton/task/wget. Hence, we don’t need to worry about defining them. You can also \nvisit https://hub.tekton.dev, which allows you to search for task definitions and pro-\nvides detailed documentation about installing and using these tasks in your pipelines \n(figure 3.10).\nTekton Hub and the Tekton catalog allow you to reuse tasks and pipelines created by \na large community of users and companies. I strongly recommend you check out the \nTekton Overview page, which summarizes the advantages of using Tekton, including \nwho should use Tekton and why: https://tekton.dev/docs/concepts/overview/. \n",
      "content_length": 1957,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 107,
      "content": "88\nChapter 3  Service pipelines: Building cloud-native applications  \nFigure 3.10    Tekton Hub is a portal to share and reuse tasks and pipeline definitions\nTekton is quite a mature project in the cloud-native space, but it also presents some \nchallenges:\n¡ You need to install and maintain Tekton running inside a Kubernetes cluster. You \ndon’t want your pipelines running right beside your application workloads, so \nyou might need a separate cluster.\n¡ There is no easy way to run a Tekton pipeline locally. For development purposes, \nyou rely on having access to a Kubernetes cluster to run a pipeline manually.\n¡ You need to know Kubernetes to define and create tasks and pipelines.\n¡ While Tekton provides some conditional logic, it is limited by what you can do in \nYAML and using a declarative approach of Kubernetes.\nWe will now jump into a project called Dagger that was created to mitigate some of \nthese points, not to replace Tekton but to provide a different approach to solving \neveryday challenges when building complex pipelines. \n3.5.4\t\nDagger in action\nDagger (https://dagger.io) was born with one objective: “to enable developers to build \npipelines using their favorite programming language that they can run everywhere.” \nDagger only relies on a container runtime to run pipelines that can be defined using \ncode that every developer can write. Dagger currently supports Go, Python, Type-\nScript, and JavaScript SDKs, but the team behind Dagger is quickly expanding to new \nlanguages. \nDagger is not focused on Kubernetes only. Platform teams must ensure that while \nteams use Kubernetes’ powerful and declarative nature, also development teams can \n",
      "content_length": 1673,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 108,
      "content": "\t\n89\nService pipelines in action\nbe productive and use the appropriate tool for the job. This short section will examine \nhow Dagger compares with Tekton, where it can fit better, and where it can comple-\nment other tools. \nIf you are interested in getting started with Dagger, you can check these resources: \n¡ Dagger docs: https://docs.dagger.io \n¡ Dagger Quickstart: https://docs.dagger.io/648215/quickstart/ \n¡ Dagger GraphQL playground: https://play.dagger.cloud\nDagger, like Tekton, also has a pipeline engine, but this engine can work both locally \nand remotely, providing a unified runtime across environments. Dagger doesn’t \ndirectly integrate with Kubernetes. This means that there are no Kubernetes CRDs or \nYAML involved. This can be important depending on the skills and preferences of the \nteams in charge of creating and maintaining these pipelines.\nIn Dagger, we define pipelines by writing code. Because pipelines are just code, these \npipelines can be distributed using any code packaging tools. For example, if our pipe-\nlines are written in Go, we can use Go modules to import pipelines or tasks written by \nother teams. If we use Java, we can use Maven or Gradle to package and distribute our \npipeline libraries to promote reuse.\nFigure 3.11 shows how development teams can write pipelines using the Dagger \nSDKs and then use the Dagger engine to execute these pipelines using any OCI Con-\ntainer Runtime such as Docker or PodMan. It doesn’t matter if you want to run your \npipelines in your local development environment (your laptop with Docker for Mac \nor Windows), your continuous integration environment, or even inside Kubernetes. \nThese pipelines will behave in the same way.\nFigure 3.11    Using your preferred programming language and its tools to write pipelines (Source: dagger.io)\nThe Dagger pipeline engine is then in charge of orchestrating the tasks defined in the \npipelines and optimizing what is requested by the container runtime used to execute \neach task. A significant advantage of the Dagger pipeline engine is that it was designed \n",
      "content_length": 2079,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 109,
      "content": "90\nChapter 3  Service pipelines: Building cloud-native applications  \nfrom the ground up to optimize how pipelines run. Imagine that you are building tons \nof services multiple times a day. You will not only keep your CPUs hot, but the amount \nof traffic downloading artifacts, again and again, becomes expensive—more if you are \nrunning on top of a cloud provider, which charges you based on consumption. \nDagger, similar to Tekton, uses containers to execute each task (step) in the pipeline. \nThe pipeline engine optimizes the resource consumption by caching the results of pre-\nvious executions, preventing you from re-executing tasks that were already executed \nusing the same inputs. In addition, you can run the Dagger engine locally on your lap-\ntop/workstation or remotely, even inside a Kubernetes cluster. \nWhen I compare Dagger to something like Tekton, with my developer background, \nI tend to like the flexibility of coding pipelines using a programming language I am \nfamiliar with. For developers to create, version and share code is easy, because I don’t \nneed to learn any new tools. \nInstead of looking at a Hello World example, I wanted to show how a service pipe-\nline would look in Dagger. So, let’s look at how a service pipeline is defined using the \nDagger Go SDK. The following code snippet shows a service pipeline defining the \nmain goals we want to execute for each service. Take a look at the buildService, test \nService, and publishService functions. These functions codify what it means to \nbuild, test, and publish each service. These functions use the Dagger client to execute \nactions inside containers that Dagger will orchestrate, as shown in listing 3.11.\nListing 3.11    Go application defining tasks using Dagger\nfunc main() {\n  var err error\n  ctx := context.Background()\n  if len(os.Args) < 2 {\n    ...)\n  }\n  client := getDaggerClient(ctx)\n  defer client.Close()\n  switch os.Args[1] {\n    case \"build\":\n      if len(os.Args) < 3 {\n        panic(...)\n      }\n      _, err = buildService(ctx, client, os.Args[2])\n      \n    case \"test\":\n      err = testService(ctx, client, os.Args[2])\n    case \"publish\":\n      pv, err := buildService(ctx, client, os.Args[2])\n     \n      err = publishService(ctx, client, os.Args[2], pv, os.Args[3])\n    case \"all\":\n      pv, err := buildService(ctx, client, os.Args[2])\n      err = testService(ctx, client, os.Args[2])\n",
      "content_length": 2396,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 110,
      "content": "\t\n91\nService pipelines in action\n      err = publishService(ctx, client, os.Args[2], pv, os.Args[3])\n   default:\n     log.Fatalln(\"invalid command specified\")\n}\nYou can find the service-pipeline.go definition at https://github.com/salaboy/\nplatforms-on-k8s/blob/main/conference-application/service-pipeline.go. \nBy running go run service-pipeline.go build notifications-service \nDagger will use containers to build our Go application source code and then build a \ncontainer ready to be pushed to a container registry. If you look at the buildService \nfunction in listing 3.12, you will notice that it builds our service source code, in this \ncase, looping over a list of target platforms (amd64 and arm64) to produce binaries for \neach of them. Once the binaries are produced, a container is created using the Dagger \nclient client.Container function. Because we are defining each step programmati-\ncally, we can also define what needs to be cached for subsequent builds (using client.\nCacheVolume). \nListing 3.12    Tasks: Go code that uses Dagger built-in functions\nfunc buildService(ctx context.Context, \n                  client *dagger.Client, \n                  dir string) ([]*dagger.Container, error) {\n  srcDir := client.Host().Directory(dir)\n  platformVariants := make([]*dagger.Container, 0, len(platforms))\n  for _, platform := range platforms {\n    ctr := client.Container()\n    ctr = ctr.From(\"golang:1.20-alpine\")\n    // mount in our source code\n    ctr = ctr.WithDirectory(\"/src\", srcDir)\n    ctr = ctr.WithMountedCache(\"/go/pkg/mod\", client.CacheVolume(\"go-mod\"))\n    ctr = ctr.WithMountedCache(\"/root/.cache/go-build\", \n    ➥ client.CacheVolume(\"go-build\"))\n    // mount in an empty dir to put the built binary\n    ctr = ctr.WithDirectory(\"/output\", client.Directory())\n    // ensure the binary will be statically linked and thus executable\n    // in the final image\n    ctr = ctr.WithEnvVariable(\"CGO_ENABLED\", \"0\")\n    // configure go to support different architectures\n    ctr = ctr.WithEnvVariable(\"GOOS\", \"linux\")\n    ctr = ctr.WithEnvVariable(\"GOARCH\", architecture(platform))\n    // build the binary and put the result at the mounted output directory\n    ctr = ctr.WithWorkdir(\"/src\")\n    ctr = ctr.WithExec([]string{\"go\", \"build\",\"-o\", \"/output/app\",\".\",})\n    // select the output directory\n    outputDir := ctr.Directory(\"/output\")\n",
      "content_length": 2360,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 111,
      "content": "92\nChapter 3  Service pipelines: Building cloud-native applications  \n    // create a new container with the output and the platform label\n    binaryCtr := client.Container(dagger.ContainerOpts{Platform: platform}).\n                        WithEntrypoint([]string{\"./app\"}).\n                        WithRootfs(outputDir)\n    platformVariants = append(platformVariants, binaryCtr)\n  }\n  return platformVariants, nil\n}\nThese pipelines are written in Go and build Go applications, but nothing stops you \nfrom building other languages and using the necessary tools. Each task is just a con-\ntainer. Dagger and the open-source community will create all the basic building blocks, \nbut each organization has to create domain-specific libraries to integrate with third-\nparty or in-house/legacy systems. By focusing on enabling developers, Dagger lets you \nchoose the right tool(s) to create these integrations. There is no need to write plugins, \njust code that can be distributed as any other library. \nTry running the pipeline for one of the services or follow the step-by-step tutorial that \nyou can find at https://github.com/salaboy/platforms-on-k8s/blob/main/chapter-3/ \ndagger/README.md. If you run the pipeline twice, the second run will be almost \ninstant since most steps are cached. \nIn contrast with Tekton, we are running the Dagger pipeline locally, not in a Kuber-\nnetes cluster, which has advantages. For example, we don’t need a Kubernetes cluster to \nrun and test this pipeline, and we don’t need to wait for remote feedback. Developers \ncan run these pipelinesby using a local container runtime (like Docker or Podman), \nincluding integration tests, before pushing any changes to the Git repository. Having \nfast feedback allows them to go faster.\nBut now, how does this translate to a remote environment? What if we want to run this \npipeline remotely on a Kubernetes cluster? The good news is that it works the same: it is \njust a remote Dagger pipeline engine that will execute our pipelines. No matter where \nthis remote pipeline engine is, running inside Kubernetes or as a managed service, our \npipeline behavior and the caching mechanisms provided by the pipeline engine will \nbehave the same way. Figure 3.12 shows how the execution will go if we install the Dag-\nger pipeline engine inside Kubernetes and run the same pipelines.\nDagger Go SDK\nGo\npipeline.go\nKubernetes Cluster\nDagger Pipeline \nEngine\nContainer Runtime\nCache\nFigure 3.12    When configured against a remote Dagger Pipeline Engine, the Dagger SDK will collect and \nsend the context for the pipeline to be executed remotely.\n",
      "content_length": 2611,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 112,
      "content": "\t\n93\nService pipelines in action\nWhen the Dagger Pipeline Engine is installed in a remote environment such as a \nKubernetes Cluster, virtual machine, or any other computing resource, we can connect \nand run our pipelines against it. The Dagger Go SDK takes all the context needed \nfrom the local environment and sends it to the Dagger Pipeline Engine to execute the \ntasks remotely. We don’t need to worry about publishing our application source code \nonline for the pipeline. \nCheck this step-by-step tutorial on how to run your Dagger pipelines on Kubernetes: \nhttps://github.com/salaboy/platforms-on-k8s/blob/main/chapter-3/dagger/\nREADME.md#running-your-pipelines-remotely-on-kubernetes. \nAs you can see, Dagger will use persistent storage (Cache) to cache all the builds \nand tasks to optimize performance and reduce pipeline running times. The operations \nteam in charge of deploying and running Dagger inside Kubernetes will need to track \nhow much storage is needed based on the pipelines the organization is running. \nIn this short section, we have seen how to use Dagger to create our service pipelines. \nWe have seen that Dagger is very different from Tekton: you don’t need to write your \npipelines using YAML, you can write your pipelines in any supported programming lan-\nguage, you can run your pipelines locally or remotely using the same code, and you can \ndistribute your pipelines using the same tools that you are using for your applications. \nFrom a Kubernetes point of view, when you use a tool like Dagger, you lose the Kuber-\nnetes native approach of managing your pipelines as you manage your other Kuber-\nnetes resources. I see the Dagger community expanding in that direction if they get \nenough feedback and requests for that. \nFrom a platform engineering perspective, you can create and distribute complex \npipelines (and tasks) for your teams to use and extend using tools they already know. \nThese pipelines will run the same way no matter where they are executed, making it an \nextremely flexible solution. Platform teams can take this flexibility to decide where to \nrun these pipelines more efficiently (based on costs and resources) without complicat-\ning developers’ lives, as they will always be able to run their pipelines locally for devel-\nopment purposes. \n3.5.5\t\nShould I use Tekton, Dagger, or GitHub Actions?\nAs you have seen, Tekton and Dagger provide us with the basic building blocks to con-\nstruct unopinionated pipelines. In other words, we can use Tekton and Dagger to build \nservice pipelines and almost every imaginable pipeline. With Tekton, we use the Kuber-\nnetes resource-based approach, scalability, and self-healing features. Using Kuberne-\ntes-native resources can be very helpful in integrating Tekton with other Kubernetes \ntools, such as managing and monitoring Kubernetes resources. Using the Kubernetes \nresource model, you can treat your Tekton pipelines and PipelineRuns as any other \nKubernetes resource and reuse all the existing tooling.\nWith Dagger, we can define our pipelines using well-known programming languages \nand tools and run these pipelines everywhere (locally in our workstations in the same \nway as if we were running them remotely). This makes Tekton and Dagger perfect tools \n",
      "content_length": 3261,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 113,
      "content": "94\nChapter 3  Service pipelines: Building cloud-native applications  \nthat platform builders can use to build more opinionated pipelines that development \nteams can use. \nOn the other hand, you can use a managed service such as GitHub Actions. You can \nlook at how the service pipelines are configured using GitHub actions for all the proj-\nects mentioned here. For example, you can check the service pipeline for the notifi-\ncations service at https://github.com/salaboy/platforms-on-k8s/blob/main/.github/\nworkflows/notifications-service-service-pipelines.yaml. \nThis GitHub Action pipeline uses ko-build to build the service and then pushes \nthe new container image to Docker Hub. Notice that this pipeline doesn’t run any \ntests, and it uses a custom step (https://github.com/salaboy/platforms-on-k8s/blob/\nmain/.github/workflows/notifications-service-service-pipelines.yaml#L17) to check if \nthe code for the service was changed; only run the build and push to Docker Hub if \nthere were changes to the service source code. \nThe advantage of using GitHub Actions is that you don’t need to maintain the infra-\nstructure running them or pay for the machines that run these pipelines (if your vol-\nume is small enough). But if you are running loads of pipelines and these pipelines are \ndata-intensive, GitHub Actions will be costly.\nFor cost-related reasons or because you cannot run your pipelines in the cloud due \nto industry regulations, Tekton and Dagger shine in providing you with all the building \nblocks to compose and run complex pipelines. While Dagger is already focused on cost \nand runtime optimization, this is coming for Tekton and other pipeline engines. \nIt is important to note that you can integrate Tekton and Dagger with GitHub. For \nexample, use Tekton Triggers (https://github.com/tektoncd/triggers/blob/main/\ndocs/getting-started/README.md) to react to commits into a GitHub repository. You \ncan also run Dagger inside a GitHub Action, enabling developers to run the same pipe-\nline locally executed in GitHub Actions, which cannot be done easily out of the box.\nNow that we have our artifacts and configurations ready to be deployed to multiple \nenvironments, let’s look at what is commonly known as the GitOps approach for contin-\nuous deployment through environment pipelines.  \n3.6\t\nLinking back to platform engineering\nAs part of your platform initiatives, you will need to help teams build their services in \nan automated way. Most of the time, a decision must be made to standardize how the \nservices will be built and packaged across teams. If the platform team can provide a \nsolution that is accessible to teams to try out locally or have the right environments \nto test before pushing changes to a Git repository, this will increase the velocity and \nfeedback loop that these teams need to move with confidence. A separate setup might \nbe needed to validate pull requests and alert teams if their repositories’ main branch \nis unreleasable.\nWhile GitHub Actions (and other managed services) are a popular solution, plat-\nform engineering teams might choose different tools or services based on their budgets \nand other platform-wide decisions (such as aligning with the Kubernetes APIs). \n",
      "content_length": 3227,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 114,
      "content": "\t\n95\nLinking back to platform engineering\nI’ve made conscious choices for this book’s demos and step-by-step tutorials (https://\ngithub.com/salaboy/platforms-on-k8s/tree/main/chapter-3) that might differ greatly \nfrom your projects. First, because the complexity of the projects presented in this book \nis quite low, but also because to keep the resources organized and versioned to support \nfuture revisions, all the application service’s source code is kept under a simple direc-\ntory structure. This decision to have all the service’s source code together in the same \nrepository influences the shape of our service pipelines. \nThe service pipelines provided (both using Tekton and Dagger) receive as a param-\neter the directory of the repository that the user wants to build. If you set up webhooks \nto trigger pipelines on pull requests, you must filter where the changes are to see which \nservice pipeline to run. This adds to the complexity of the entire setup. As suggested \nin previous sections, an alternative approach is to have one repository per service. This \nenables you to have custom service pipeline definitions per service (which can reuse \ngeneric tasks) and simple webhook definitions, as you know exactly what to run when \nchanges are made. The main problem with having one repository per service is dealing \nwith users and access, because adding new services will force you to create new reposito-\nries and ensure that developers have access to it. \nAnother big decision the platform team will need to make concerning service pipe-\nlines is where they start and end. For the examples provided here, the service pipelines \nstart when a change is submitted and end after publishing the container images for \neach service. Service Pipelines for the walking skeleton services don’t package and pub-\nlish individual services Helm Charts. Figure 3.13 shows the responsibility of the service \npipelines defined by the examples.\nnotifications-service/\nagenda-service/\nfrontend/\nc4p-service/\nhelm/conference-app/\nConference Application Repository\nContainer Registry\nService Pipelines\n(build, test, \npackage, publish)\nApplication Pipeline\n(package, publish)\nFigure 3.13    The service pipelines and the application pipeline have different lifecycles.\nYou need to ask yourself if having Helm Charts per service is a good idea or an overkill. \nYou should have a clear understanding of who will consume these artifacts. Try answer-\ning questions to find a strategy that will work for your teams: \n¡ Will you deploy your services individually, or will they always be deployed as a set?\n¡ How often does your services change? Do you have services that change more \noften? \n",
      "content_length": 2681,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 115,
      "content": "96\nChapter 3  Service pipelines: Building cloud-native applications  \n¡ How many teams are going to deploy these services? \n¡ Are you creating an artifact that an open-source community will consume with \nmany users deploying the services individually? \nFor the examples provided for this chapter, a separate application-level pipeline is pro-\nvided to package and publish the Conference application Helm Chart. \nThe reason behind this decision was simple: every reader will install the application \nin a cluster, and I needed a simple way to enable that. If readers don’t want to use Helm \nto install the application in their clusters, they can export the output of running the \nhelm template command and apply the output using kubectl. Another important \nfactor behind that decision is the lifecycle of the Helm Chart and the application’s ser-\nvices. The shape of the application doesn’t change much. The Helm Chart definition \nmight only change if we need to add or remove a service. The service’s code, however, \nchanges a lot, and we want to enable the teams working on these services to keep adding \nchanges to them. \nFigure 3.14 shows two complementary approaches for service pipelines. The ser-\nvices running in the developer’s environment provide fast feedback loops, and those \nrunning remotely produce artifacts that teams will use to deploy the same application \nacross different environments. \nWhen developers push application changes \nto Git a Service, pipelines automate the \ncreation of the artifacts needed to deploy our \napplication to different environments.\nDevelopers have local tools to get fast \nfeedback to validate that their changes are \ncorrect before pushing them to Git.\nDeveloper \nInner-Loop \nTools\nChanges\nContainer \nRegistry\nGit \nRepository\nApplication\nEnvironment\nService Pipeline\nFigure 3.14    Local vs. remote service pipelines\nFinally, none of the examples in this book provide configurations to tap into webhooks \nfrom the Git repositories besides those linked using GitHub actions. Pushing readers \nto get the right tokens and configuring this with multiple Git providers is not com-\nplex, but it would take me many pages to explain. Teams consuming these mechanisms \nwouldn’t need to worry about dealing with the credentials needed for your service \npipelines. As a platform team, automating access to credentials for development (and \nother) teams to just connect to services is fundamental to speed up their workflows. \n",
      "content_length": 2462,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 116,
      "content": "\t\n97\nSummary\nSummary\n¡ Service pipelines define how to go from source code to artifacts that can be \ndeployed in multiple environments. Following trunk-based development and \none service = one repository practices helps your teams standardize building and \nreleasing software artifacts more efficiently. \n¡ You need to find what works for your teams and applications. There is no one-\nsize-fits-all solution, and compromises must be made. How often do your appli-\ncation’s services change, and how do you deploy them into environments? \nAnswering these questions can help you to define where your service pipelines \nstart and end. \n¡ Tekton is a pipeline engine designed for Kubernetes. You can use Tekton to \ndesign your custom pipelines and use all the shared tasks and pipelines openly \navailable in the Tekton catalog. You can now install Tekton in your cluster and \nstart creating pipelines. \n¡ Dagger allows you to write and distribute pipelines using your favorite program-\nming language. These pipelines can be executed in any environment, including \nyour developer’s laptops. \n¡ Tools like GitHub Actions are very useful but can be expensive. Platform builders \nmust look for tools that provide enough flexibility to build and distribute tasks \nthat other teams can reuse and follow company guidelines. Enabling teams to \nrun their pipelines locally is a big plus as it will improve their developer experi-\nence and their feedback times. \n¡ If you followed the step-by-step tutorials, you gained hands-on experience in \nusing Tekton and Dagger to create and run your service pipelines.\n",
      "content_length": 1595,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 117,
      "content": "98\n4\nEnvironment pipelines: Deploying \ncloud-native applications\nThis chapter covers\n¡ Deploying produced artifacts into environments\n¡ Using environment pipelines and GitOps to \t\n\t manage environments\n¡ Using Argo CD with Helm to deliver software \t\n\t efficiently\nThis chapter introduces the concept of environment pipelines. We cover the steps \nrequired to deploy the artifacts created by service pipelines into concrete running \nenvironments all the way to production. We will look into a common practice that \nhas emerged in the cloud-native space called GitOps, which allows us to define and \nconfigure our environments using a Git repository. Finally, we will look at a project \ncalled Argo CD, which implements a GitOps approach for managing applications \non top of Kubernetes. This chapter is divided into three main sections: \n¡ Environment pipelines\n¡ Environment pipelines in action using Argo CD\n¡ Service + environment pipelines working together\n",
      "content_length": 958,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 118,
      "content": "\t\n99\nEnvironment pipelines\n4.1\t\nEnvironment pipelines\nWe can build as many services as we want and produce new versions, but if these ver-\nsions cannot flow freely across different environments to be tested and finally used by \nour customers, our organization will struggle to have a smooth end-to-end software \ndelivery practice. Environment pipelines are in charge of configuring and maintaining \nour environments. \nIt is quite common for companies to have different environments for different pur-\nposes, for example, a staging environment where developers can deploy their latest \nversions of the services or a quality assurance (QA) environment where manual testing \nhappens and one or more production environments, which are where the real users \ninteract with our applications. These (staging, QA, and production) are just examples. \nThere shouldn’t be any hard limit on how many environments we can have. Figure 4.1 \nshows how a single release flows throughout different environments until it reaches \nproduction, where it is going to be live in front of our application’s users.\nThe Service \nv1.1.2 was \nreleased \nsuccessfully\nDevelopment\nStaging\nQuality Assurance\nProduction\nService v1.1.2\nService v1.1.2\nService v1.1.2\nService v1.1.2\nFigure 4.1    Released service moving throughout different environments\nEach environment (development, staging, QA, and production) will have one envi-\nronment pipeline. These pipelines will be responsible for keeping the environment \nconfiguration in sync with the hardware running the live version of the environment. \nThese environment pipelines use as the source of truth a repository that contains the \nenvironment configurations, including which services and which version of each ser-\nvice needs to be deployed (figure 4.2). \nService v1.1.2 works \nfine in Development \nlet’s promote it to \nStaging.\nService v1.1.2 \nis ready for the \nprime time.\nService v1.1.2 \nwas released \nsuccessfully.\nDevelopment\nService v1.1.2\nStaging\nProduction\nConfiguration\nConfiguration\nConfiguration\nService v1.1.2\nService v1.1.2\nEnvironment \nPipeline\nEnvironment \nPipeline\nEnvironment \nPipeline\nFigure 4.2    Promoting services to different environments means updating environment configurations\n",
      "content_length": 2226,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 119,
      "content": "100\nChapter 4  Environment pipelines: Deploying cloud-native applications\nIf you are using this approach, each environment will have its configuration repository. \nPromoting a newly released version means changing the environment configuration \nrepository to add a new service or updating the configuration to point to the newly \nreleased version. Some organizations keep all sensitive environment configurations all \ntogether in a single repository; this helps with centralizing the credentials required to \nread and modify these configurations.\nThese configuration changes can be automated or require manual intervention. For \nmore sensitive environments, such as the production environment, you might require \ndifferent stakeholders to sign off before adding or updating a service.\nBut where do environment pipelines come from? And why wouldn’t you have heard \nof them before? Before jumping into the details about what an environment pipeline \nwould look like, we need to get a bit of background on why this matters in the first place. \n4.1.1\t\nHow did this work in the past, and what has changed lately?\nTraditionally, creating new environments was hard and costly. Creating new environ-\nments on demand wasn’t a thing for these two reasons. First, the differences between \nthe environment that a developer used to create an application and where the applica-\ntion ran for end users were completely different. These differences, not only in com-\nputing power, caused huge stress on operations teams responsible for running these \napplications. Depending on the environment’s capabilities, they needed to fine-tune \nthe application’s configurations (that they didn’t design). Second, tools for automat-\ning the provisioning and configuration of complex setups have become mainstream. \nWith the help of containers and Kubernetes, there has been a standardization around \nhow these tools are designed and work across cloud providers. These tools had reached \na point where developers can codify infrastructure using their programming language \nof choice or rely on the Kubernetes API to create these definitions.\nBefore the rise of cloud–native applications, deploying a new application or a new ver-\nsion of an application required shutting down the server, running some scripts, copying \nsome binaries, and then starting the server again with the new version running. After the \nserver starts again, the application could fail to start. Hence more configuration tuning \nmight be needed. Most of these configurations were done manually in the server itself, \nmaking it difficult to remember and keep track of what was changed and why. \nAs part of automating these processes, tools like Jenkins (https://www.jenkins.io/, a \nvery popular pipeline engine) and/or scripts were used to simplify deploying new bina-\nries. So instead of manually stopping servers and copying binaries, an operator can run \na Jenkins Job defining which versions of the artifacts they wanted to deploy, and Jenkins \nwill run the job notifying the operator about the output. This approach had two main \nadvantages: \n¡ Tools like Jenkins can have access to the environment’s credentials, avoiding \nmanual access to the servers by the operators. \n¡ Tools like Jenkins log every job execution and the parameters, allowing us to \nkeep track of what was done and the result of the execution.\n",
      "content_length": 3362,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 120,
      "content": "\t\n101\nEnvironment pipelines\nWhile automating with tools like Jenkins was a big improvement compared to manually \ndeploying new versions, there were still some problems, such as having fixed environ-\nments completely different from where the software was being developed and tested. \nWe needed to specify how the environment is created and configured to the operat-\ning system’s version and the software installed into the machines or virtual machines \nto reduce the difference between different environments. Virtual machines helped \ngreatly with this task, because we can easily create two or more virtual machines config-\nured similarly. \nWe can even give our developers these virtual machines to work. But now we have a \nnew problem. We will need new tools to manage, run, maintain, and store our virtual \nmachines. If we have multiple physical machines where we want to run virtual machines, \nwe don’t want our operations team to start these VMs in each server manually. Hence, \nwe will need a hypervisor to monitor and run VMs in a cluster of physical computers. \nUsing tools like Jenkins and virtual machines (with hypervisors) were a huge \nimprovement. Because we implemented some automation, operators didn’t need to \naccess servers or VMs to change configurations manually, and our environments were \ncreated using a configuration predefined in a fixed virtual machine configuration. \nTools like Ansible (https://www.ansible.com/) and Puppet (https://www.puppet \n.com/) are built on top of these concepts.\nFigure 4.3 shows Jenkins Jobs configured to create virtual machines that host our \napplications. But beware, these virtual machines host an entire operating system. All \nthe tools bundled with that operating system will run beside your applications! \nJenkins Job #1\nJenkins Job #2\nVirtual Machine #1\nVirtual Machine #2\nApplication\nApplication\nFigure 4.3    Jenkins Jobs or scripts encapsulated the operational knowledge of how to do deployments in \nan imperative way, defining step-by-step what needs to be done. This is a complex task, hard to maintain \nand modify, and very specific to the tool we're using. On the other hand, virtual machines are resource-\nintensive and not portable across cloud providers.\nWhile this approach is still common in the industry, there is a lot of room for improve-\nment, for example, in the following areas: \n¡ Jenkins Jobs and scripts are imperative by nature, meaning they specify step-by-\nstep what needs to be done. This has a great disadvantage, because if something \nchanges—let’s say a server is no longer there or requires more data to authen-\nticate against a service—the logic of the pipeline will fail, and it will need to be \nmanually updated.\n",
      "content_length": 2706,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 121,
      "content": "102\nChapter 4  Environment pipelines: Deploying cloud-native applications\n¡ Virtual machines are heavy. Every time you start a virtual machine, you start a \ncomplete instance of an operating system. Running the operating system pro-\ncesses does not add any business value; the larger the cluster, the bigger the oper-\nating system overhead. On the VM’s requirements, running VMs in developers’ \nenvironments may not be possible.\n¡ Environments’ configurations are hidden and not versioned. Most of the envi-\nronment configurations and how the deployments are done are encoded inside \ntools like Jenkins, where complex pipelines tend to grow out of control, making \nthe changes very risky and migration to newer tools and stacks very difficult. \n¡ Each cloud provider has a non-standard way of creating virtual machines. This \ncan push us into a vendor lock-in situation. If we created VMs for Amazon Web \nServices, we could not run these VMs into the Google Cloud Platform or Micro-\nsoft Azure. \nHow are teams approaching this with modern tooling? That is an easy question. We \nnow have Kubernetes and containers that aim to solve the overhead caused by VMs and \nthe cloud-provider portability by relying on containers and the widely adopted Kuber-\nnetes APIs. Kubernetes also provides the building blocks to ensure we don’t need to \nshut down our servers to deploy new applications or change their configurations. If we \ndo things in the Kubernetes way, we shouldn’t have any downtime in our applications. \nBut Kubernetes alone doesn’t solve the process of configuring the clusters them-\nselves. How we apply changes to their configurations, or the process and tooling \ninvolved into deploying applications to these clusters, also matter. That’s why you might \nhave heard about GitOps.\nWhat is GitOps, and how does it relate to our environment pipelines? We’ll answer \nthat question next.\n4.1.2\t\nWhat is GitOps, and how does it relate to environment pipelines?\nIf we don’t want to encode all of our operational knowledge in a tool like Jenkins, where \nit is difficult to maintain, change, and keep track of it, we need a different approach. \nThe term GitOps, defined by the CNCF’s GitOps Working Group (https:// \nopengitops.dev/), defines the process of creating, maintaining, and applying the con-\nfiguration of our environments and applications declaratively using Git as the source of \ntruth. OpenGitOps defines four core principles that we need to consider when we talk \nabout GitOps: \n1\t Declarative: A system (https://github.com/open-gitops/documents/blob/v1.0.0/ \nGLOSSARY.md#software-system) managed by GitOps must have its desired state \nexpressed declaratively (https://github.com/open-gitops/documents/blob/\nv1.0.0/GLOSSARY.md#declarative-description). We have this covered if we use \nKubernetes manifest, because we define what needs to be deployed and how that \nneeds to be configured using declarative resources that Kubernetes will reconcile. \n2\t Versioned and immutable: The desired state is stored (https://github.com/open \n-gitops/documents/blob/v1.0.0/GLOSSARY.md#state-store) in a way that enforces \n",
      "content_length": 3121,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 122,
      "content": "\t\n103\nEnvironment pipelines\nimmutability and versioning and retains a complete version history. The Open \nGitOps initiative doesn’t enforce the use of Git. As soon as our definitions are \nstored, versioned, and immutable, we can consider it as GitOps. This opens the \ndoor to storing files in, for example, S3 buckets, which are also versioned and \nimmutable. \n3\t Pulled automatically: Software agents automatically pull the desired state declara-\ntions from the source. The GitOps software pulls the changes from the source \nperiodically in an automated way. Users shouldn’t worry about when the changes \nare pulled. \n4\t Continuously reconciled: Software agents continuously (https://github.com/open \n-gitops/documents/blob/v1.0.0/GLOSSARY.md#continuous) observe the sys-\ntem state and attempt to apply (https://github.com/open-gitops/documents/\nblob/v1.0.0/GLOSSARY.md#reconciliation) the desired state. This continuous \nreconciliation helps us to build resilience in our environments and the entire \ndelivery process, because we have components that are in charge of applying the \ndesired state and monitoring our environments from configuration drifts. If the \nreconciliation fails, GitOps tools will notify us about the problems and keep try-\ning to apply the changes until the desired state is achieved. \nBy storing the configuration of our environments and applications in a Git repository, \nwe can track and version the changes we make. By relying on Git, we can easily roll \nback changes if these changes don’t work as expected. GitOps covers the configuration \nstorage and how these configurations are applied to the computing resources where \nthe applications run. \nGitOps was coined in the context of Kubernetes, but this approach is not new, \nbecause configuration management tools have existed for a long time. Instead, GitOps \nrepresents a refinement of these tried and tested approaches that can be applied to any \nsoftware operation, not just Kubernetes. With the rise in popularity of cloud provid-\ners’ tools for managing Infrastructure as Code, tools like Chef (https://www.chef.io/), \nAnsible (https://www.ansible.com/), Terraform (https://www.terraform.io/), and \nPulumi (https://www.pulumi.com/) are loved by operations teams, because these tools \nallow them to define how to configure cloud resources and configure them together in \na reproducible way. If you need a new environment, you just run this Terraform script \nor Pulumi app, and then voila, the environment is up and running. These tools are also \nequipped to communicate with the cloud provider’s APIs to create Kubernetes clusters \nso that we can automate the creation of these clusters. \nWith GitOps, we manage configuration and rely on the Kubernetes APIs as the stan-\ndard way to deploy our applications to Kubernetes clusters. With GitOps, we use a Git \nrepository as the source of truth for our environment’s internal configurations (Kuber-\nnetes YAML files) while removing the need to interact manually with the Kubernetes \nclusters to avoid configuration drifts and security problems. When using GitOps tools, \n",
      "content_length": 3104,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 123,
      "content": "104\nChapter 4  Environment pipelines: Deploying cloud-native applications\nwe can expect to have software agents in charge of pulling from the source of truth (Git \nrepository in this example) periodically and constantly monitoring the environment to \nprovide a continuous reconciliation loop. This ensures that the GitOps tool will do its \nbest to ensure that the desired state expressed in the repository is what we have in our \nlive environments.\nWe can reconfigure any Kubernetes cluster to have the same configuration stored \nin our Git repository by running an environment pipeline. Figure 4.4 shows how these \npieces fit together. On the left, we have Infrastructure as Code tools that can create \ncloud resources, including Kubernetes clusters and application infrastructure for \nour environments. Once the environment is set up, an environment pipeline using a \nGitOps approach can sync all the configurations for our environment into the target \nKubernetes cluster, regularly checking that the configuration stored in Git is in sync \nwith the cluster.\n“Infrastructure as \nCode” Tool\n(Terraform, Pulumi, Ansible, Chef)\n<create, update>\n<periodically pull>\n<continuous \nreconciliation>\nKubernetes \nCluster\nEnvironment\nGitOps Tool\nApplication #1\nEnvironment \nPipeline\nApplication #2\nGit \nrepository\nGit \nrepository\nFigure 4.4    Infrastructure as Code, GitOps, and environment pipelines working together. Infrastructure \nas code tools run scripts to create cloud resources in a reproducible way. We can create our Kubernetes \nclusters to be all the same using these tools. GitOps tools run environment pipelines to continuously \nreconcile declarative configuration, which is stored in a versioned and immutable repository.\nBy separating the infrastructure and application concerns, our environment pipelines \nallow us to ensure that our environments are easy to reproduce and update whenever \nneeded. By relying on Git as the source of truth, we can roll back our infrastructural \nand application changes as needed. It is also important to understand that because \nwe are working with the Kubernetes APIs, our environment’s definitions are now \nexpressed in a declarative way, supporting changes in the context where these config-\nurations are applied and letting Kubernetes deal with how to achieve the desired state \nexpressed by these configurations. \nFigure 4.5 shows these interactions, where operation teams only make changes to \nthe Git repository that contains our environment configuration, and then a pipeline \n(a set of steps) is executed to ensure that this configuration is in sync with the target \nenvironment. \n",
      "content_length": 2632,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 124,
      "content": "\t\n105\nEnvironment pipelines\nChanges\nPipeline\nGit Repository\nEnvironment \nConfiguration\nService A v1.2\nService B v2.13\n<sync/apply>\nFigure 4.5    Defining the state of the cluster using the configuration in Git (GitOps). Environment \npipelines monitor configuration changes on a Git repository and apply those changes to the infrastructure \n(Kubernetes cluster) whenever a new change is detected. Following this approach allows us to roll back \nchanges in the infrastructure by reverting commits on Git. We can also replicate the exact environment \nconfiguration by just running the same pipeline against another cluster.  \nWhen you start using environment pipelines, you aim to stop interacting, changing, \nor modifying the environment’s configuration manually, and all interactions are done \nexclusively by these pipelines. To give a very concrete example, instead of executing \nkubectl apply -f or helm install into our Kubernetes cluster, an operator will be \nin charge of running these commands based on the contents of a Git repository that \nhas the definitions and configurations of what needs to be installed in the cluster. \nIn theory, an operator that monitors a Git repository and reacts to changes is all you \nneed, but in practice, a set of steps is needed to ensure we have full control of what is \ndeployed to our environments. Hence, thinking about GitOps as a pipeline helps us \nunderstand that for some scenarios, we will need to add extra steps to these pipelines \ntriggered every time an environment configuration is changed. \nLet’s look at these steps with more concrete tools commonly found in real-life \nscenarios. \n4.1.3\t\nSteps involved in an environment pipeline\nNo matter what kind of applications you are deploying to different environments, \nenvironment pipelines usually include a set of predefined steps. Figure 4.6 shows \nthese steps as a sequence, as most of the time these steps are defined inside scripts or \nencoded in tools that are in charge of checking that each step was executed correctly. \nLet’s dig deeper into the details of these steps:\n¡ Reacting to changes in the configuration: This can be done by polling or pushing: \n–\t Polling for changes: A component can pull the repository and check if there \nhave been new commits since the last time it checked. If new changes are \ndetected, a new environment pipeline instance is created.\n–\t Pushing changes using webhooks: If the repository supports webhooks, the repos-\nitory can notify our environment pipelines that there are new changes to sync. \n",
      "content_length": 2540,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 125,
      "content": "106\nChapter 4  Environment pipelines: Deploying cloud-native applications\nRemember, the GitOps principles state “pulled automatically,” which means \nwe can use webhooks, but we should not rely entirely on them for getting con-\nfig change updates. \nChange\nin Git\nVerify/Validate \nConfiguration\nClone \nConfiguration\nApply \nConfiguration\nValidate \nRuntime\nPipeline Instance\nCreate a Pipeline Instance\nFigure 4.6    Environment pipeline for a Kubernetes environment\n¡ Clone the source code from the repository, which contains the desired state for our environ-\nment: This step fetches the configuration from a remote Git repository that con-\ntains the environment configurations. Tools like Git fetch only the delta between \nthe remote repository and what we have locally.\n¡ Apply the desired state to a live environment: This usually includes doing a kubectl \napply -f or a helm install command to install new versions of the artifacts. \nNotice that with both kubectl and helm, Kubernetes is smart enough to recog-\nnize where the changes are and only apply the differences. Once the pipeline \nhas all the configurations locally accessible, it will use a set of credentials to apply \nthese changes to a Kubernetes cluster. Notice that we can fine-tune the access \nrights that the pipelines have to the cluster to ensure they are not exploited from \na security point of view. This also allows you to remove access from individual \nteam members to the clusters where the services are deployed. \n¡ Verify that the changes are applied and that the state matches what is described inside the \nGit repository (deal with configuration drift): Once the changes are applied to the live \ncluster, checking that the new versions of services are up and running is needed \nto identify if we need to revert to a previous version. It is quite simple if we need \nto revert changes, because all the history is stored in Git. Applying the previous \nversion is just looking at the previous commit in the repository.\n¡ Validate that your workloads are working as expected: Once the configurations are \napplied correctly, we need to validate that the applications deployed are working \nas expected and doing what they are supposed to do. \n",
      "content_length": 2214,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 126,
      "content": "\t\n107\nEnvironment pipelines\nFor the environment pipeline to work, a component that can apply the changes to the \nenvironment is needed, and it needs to be configured accordingly with the right access \ncredentials. The main idea behind this component is to make sure that nobody will \nchange the environment configuration by manually interacting with the cluster. This \ncomponent is the only one allowed to change the environment configuration, deploy \nnew services, upgrade versions, or remove services from the environment. For an envi-\nronment pipeline to work, the following two considerations need to be met:\n¡ The repository containing the desired state for the environment must have all the \nnecessary configurations to create and configure the environment successfully.\n¡ The Kubernetes cluster where the environment will run needs to be configured \nwith the correct credentials for allowing the state to be changed by the pipelines. \nThe term environment pipeline refers to the fact that each environment will have a pipe-\nline associated with it. Because multiple environments are usually required (develop-\nment, staging, production) for delivering applications, each will have a pipeline in \ncharge of deploying and upgrading the components running in them. By using this \napproach, promoting services between different environments is achieved by send-\ning pull requests/change requests to the environment’s repository. The pipeline will \nreflect the changes in the target cluster. \n4.1.4\t\nEnvironment pipeline requirements and different approaches\nSo, what are the contents of these environment’s repositories? As you will see in figure \n4.7, the contents of the environment repository are just the definition of which services \nneed to be present in the environment. The environment pipeline then can just apply \nthese Kubernetes manifests to the target cluster. \nGit Repository\nstaging/Chart.yaml\n       /values.yaml\nGit Repository\nstaging/apps.yaml\nGit Repository\nstaging/helmfile\nContains the reference to one \nor more Helm Charts that will \nbe installed in the target \nKubernetes cluster. You can \nparameterize these charts \nusing a `values.yaml` file.\nContains all the Kubernetes \nresources needed to deploy \nthe application’s services. You \ncan have one or more files \nthat will be applied to the \ntarget Kubernetes cluster.\nTools like `helmfile` allows \nyou to define environments \ndeclaratively using Helm \nReleases.\nFigure 4.7    Environment configuration options\n",
      "content_length": 2487,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 127,
      "content": "108\nChapter 4  Environment pipelines: Deploying cloud-native applications\nThe first option (simple layout) is to store all the Kubernetes YAML files in a Git repos-\nitory, and then the environment pipeline will just use kubectl apply -f * against \nthe configured cluster. While this approach is simple, there is one big drawback: if you \nhave your Kubernetes YAML files for each service in the service repository, then the \nenvironment repository will have these files duplicated, and they can go out of sync. \nImagine if you have several environments, you must maintain all the copies in sync, \nwhich might become challenging. \nThe second option (using Helm Charts) is a bit more elaborate now that we are \nusing Helm to define the state of the cluster. You can use Helm dependencies to create \na parent chart that will include as dependencies all the services that should be present \nin the environment. If you do so, the environment pipeline can use helm update . to \napply the chart into a cluster. Something I don’t like about this approach is that you cre-\nate one Helm release per change, and there are no separate releases for each service. \nThis approach uses Helm dependencies to fetch each service definition, so a prerequi-\nsite for this approach is to have every service package as a Helm Chart. \nThe third option is to use a project called helmfile (https://github.com/helmfile/\nhelmfile), designed for this very specific purpose, to define environment configura-\ntions. A helmfile allows you to declaratively define what Helm releases need to be pres-\nent in our cluster. These Helm releases will be created when we run helmfile sync, \nhaving defined a helmfile containing the helm releases we want in the cluster. \nWhether you use any of these approaches or other tools to do this, the expectation is \nclear. You have a repository with the configuration (one repository per environment or \na directory per environment), and a pipeline is in charge of picking up the configura-\ntion and using a tool to apply it to a cluster. \nIt is common to have several environments (staging, QA, production), even allowing \nteams to create on-demand environments for running tests or day-to-day development \ntasks. If you use the “one environment per namespace” approach, as shown in figure \n4.8, it is common to have a separate Git repository for each environment, because it \nhelps keep access to environments isolated and secure. This approach is simple, but \nit doesn’t provide enough isolation on the Kubernetes cluster, because Kubernetes \nNamespaces were designed for logical partitioning of the cluster. In this case, the stag-\ning environment will share with the production environment the cluster resources. \nPipeline\nProduction Environment \nConfiguration\nPipeline\nStaging Environment \nConfiguration\nStaging Namespace\nProduction Namespace\nGit Repository\nKubernetes Cluster\n<sync>\n<sync>\nGit Repository\nFigure 4.8    One environment per Kubernetes namespace approach. One strategy is to use namespaces \nfor different environments. While this simplifies the configurations required for the pipelines to deploy \nservices to different environments, namespaces don’t provide strong isolation guarantees.\n",
      "content_length": 3211,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 128,
      "content": "\t\n109\nEnvironment pipelines\nAn alternative approach can be to use an entirely new cluster for each environment. \nThe main difference is isolation and access control. By having a cluster per environ-\nment, you can be stricter in defining who and which components can deploy and \nupgrade things in these environments and have different hardware configurations for \neach cluster, such as multi-region setups and other scalability concerns that might not \nmake sense to have in your staging and testing environments. Using different clusters, \nyou can also aim for a multi-cloud setup, where different cloud providers can host dif-\nferent environments. \nFigure 4.9 shows how you can use the namespace approach for development envi-\nronments, which will be created by different teams and then have separated clusters \nfor staging and production. The idea here is to have the staging and production clus-\nter configured as similarly as possible, so applications deployed onto different environ-\nments behave the same. \nEnv Configuration \nTeam A\nEnv Pipeline\nEnv Pipeline\nEnv Pipeline\nEnv Pipeline\nEnv Configuration \nTeam B\nEnv Configuration \nStaging\nEnv Configuration \nProduction\nGit Repository\nNamespace\nNamespace\nStaging Cluster\nProduction Clusters\nDev Cluster\nGit Repository\nGit Repository\nFigure 4.9    Different environment configurations, based on requirements. A more realistic approach \ncan use the same cluster for multiple teams doing day-to-day work, while more sensitive environments \nlike staging and production are separated on their own clusters and Git repositories to store their \nconfigurations. For a service to be promoted to a new environment, a pull request needs to be submitted \nto the corresponding Git repository.\nOkay, but how can we implement these pipelines? Should we implement these pipe-\nlines using Tekton? In the next section, we will look at Argo CD (https://argo-cd \n.readthedocs.io/en/stable/), a tool that has encoded the environment pipeline logic \nand best practices into a very specific tool for continuous deployment.  \n",
      "content_length": 2056,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 129,
      "content": "110\nChapter 4  Environment pipelines: Deploying cloud-native applications\n4.2\t\nEnvironment pipelines in action\nYou can implement an environment pipeline as described in the previous section using \nTekton or Dagger. This has been done in projects like Jenkins X (https://jenkins-x \n.io), but nowadays, the steps for an environment pipeline are encoded in specialized \ntools for continuous deployment like Argo CD (https://argo-cd.readthedocs.io/en/\nstable/). \nIn contrast with service pipelines, where we might need specialized tools to build \nour artifacts depending on which technology stack we use, environment pipelines for \nKubernetes are well-standardized today under the GitOps umbrella. Considering that \nall our artifacts are being built and published by our service pipelines, we first need to \ncreate our environment Git repository, which will contain the environment configura-\ntion, including the services deployed to that environment. \nArgo CD provides a very opinionated but flexible GitOps implementation. We will \ndelegate all the steps required to deploy software into our environments to Argo CD. \nArgo CD can out-of-the-box monitor a Git repository that contains our environment(s) \nconfiguration and periodically apply the configuration to a live cluster. This enables us \nto remove manual interactions with the target clusters, which reduces configuration \ndrifts as Git becomes our source of truth. \nUsing tools like Argo CD allows us to declaratively define what we want to install in \nour environments, while Argo CD is in charge of notifying us when something goes \nwrong or our clusters are out of sync. Argo CD is not limited to a single cluster, mean-\ning our environment can live in separate clusters, even in different cloud providers. \nFigure 4.10 shows Argo CD managing different environments on different clusters, \nusing different Git repositories as the source of truth to keep the configuration of each \nenvironment.\nQA Environment\nDevelopment \nEnvironment #1\nDevelopment \nEnvironment #2\nProduction \nEnvironment\nKubernetes Cluster\nKubernetes Cluster\nArgoCD\nGit\nGit\nKubernetes Cluster\nFigure 4.10    Argo CD will sync environments, configurations from Git to live clusters\n",
      "content_length": 2208,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 130,
      "content": "\t\n111\nEnvironment pipelines in action\nIn the same way that we now have separate service pipelines for each service, we can \nhave separate repositories, branches, or directories to configure our environments. \nArgo CD can monitor repositories or directories inside repositories for changes to sync \nour environments configurations. \nWe will install Argo CD in our Kubernetes cluster for this example and configure our \nstaging environment using a GitOps approach. For that, we need a Git repository that \nserves as our source of truth. You can follow a step-by-step tutorial located at https://\ngithub.com/salaboy/platforms-on-k8s/blob/main/chapter-4/README.md. \nFor installing Argo CD, I recommend you check their Getting Started guide that you \ncan find at https://argo-cd.readthedocs.io/en/stable/getting_started/. This guide \ninstalls all the components required for Argo CD to work, so after finishing this guide, \nwe should have all we need to get our staging environment going. It also guides you \nthrough the installation of the argocd CLI (Command-Line Interface), which some-\ntimes is very handy. In the following sections, we will focus on the user interface, but you \ncan access the same functionality using the CLI. Argo CD comes with a very useful user \ninterface that lets you monitor how your environments and applications are doing and \nquickly find out if there are any problems. \nThe main objective of this section is to replicate what we did in section 2.1.3 in chap-\nter 2, where we installed and interacted with the application, but here we aim to fully \nautomate the process for an environment that will be configured using a git repository. \nOnce again, we will use Helm to define the environment configuration as Argo CD pro-\nvides an out-of-the-box Helm integration. \nNOTE    Argo CD used a different nomenclature than the one we used here. In \nArgo CD you configure applications instead of environments. In the following \nscreenshots, you will see that we will be configuring an Argo CD application to \nrepresent our staging environment. As there are no restrictions on what you can \ninclude in a Helm Chart, we will be using a Helm Chart to configure our Confer-\nence application into this environment. \n4.2.1\t\nCreating an Argo CD application\nIf you access the Argo CD user interface, you will see right in the top left corner of the \nscreen the + New App button (figure 4.11). \nFigure 4.11    \nArgo CD user \ninterface—new \napplication \ncreation\n",
      "content_length": 2473,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 131,
      "content": "112\nChapter 4  Environment pipelines: Deploying cloud-native applications\nGo ahead and hit that button to see the application creation form. Besides adding a \nname and selecting a Project where our Argo CD application will live (we will select \nthe default project), we will check the Auto-Create Namespace option, as shown in \nfigure 4.12. \nFigure 4.12    New application parameters, manual sync, and auto-create namespace\nBy associating our environment with a new namespace in our cluster, we can only use \nthe Kubernetes RBAC mechanism to allow administrators to modify the Kubernetes \nresources in that namespace. Remember that by using Argo CD, we want to ensure that \ndevelopers don’t accidentally change the application configuration or manually apply \nconfiguration changes to the cluster. Argo CD will sync the resources defined in a Git \nrepository. So where is that Git repository? That’s exactly what we need to configure \nnext (figure 4.13). \nFigure 4.13    Argo CD application’s configuration repository, revision, and path\nAs mentioned, we will use a directory inside the https://github.com/salaboy/platforms \n-on-k8s/ repository to define our staging environment. You should fork this reposi-\ntory (and then use your fork URL) to make any changes you want to the environment \nconfiguration. The directory that contains the environment configuration can be \nfound under chapter-4/argo-cd/staging/. As shown in figure 4.14, you can also select \nbetween different branches and tags, allowing you to have fine-grain control of where \nthe configuration is coming from and how that configuration evolves. \n",
      "content_length": 1616,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 132,
      "content": "\t\n113\nEnvironment pipelines in action\nFigure 4.14    Configuration destination, for this example, is the cluster where Argo CD is installed\nThe next step is to define where Argo CD will apply this environment configuration. \nWe can use Argo CD to install and sync environments in different clusters, but for this \nexample, we will be using the same Kubernetes cluster where we installed Argo CD and \nthe staging namespace. There is an option for Argo CD to create this namespace for \nyou, or you can create it manually when setting up the cluster and the permissions for \ndifferent namespaces. \nFinally, because it makes sense to reuse the same configuration for similar environ-\nments, Argo CD enables us to configure different parameters specific to this installa-\ntion. Since we are using Helm and the Argo CD user interface is smart enough to scan \nthe content of the repository/path we have entered, it knows it is dealing with a Helm \nChart. If we were not using a Helm Chart, Argo CD allows us to set up environment vari-\nables as parameters for our configuration scripts (figure 4.15). \nFigure 4.15    Helm configuration parameters for the staging environment\nAs you can see in the previous image, Argo CD also identified an empty values.yaml file \ninside the repository path that we have provided. If the values.yaml file had any param-\neters, the user interface will parse them and show them for you to validate. We can add \nmore parameters to the VALUES text box to override any other chart (or sub-charts) \nconfigurations. \nAfter we provide all this configuration, we are ready to hit the Create button at the \ntop of the form. Argo CD will create the application and automatically sync the changes, \nas we selected the Automatic Sync option (figure 4.16). \n",
      "content_length": 1770,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 133,
      "content": "114\nChapter 4  Environment pipelines: Deploying cloud-native applications\nFigure 4.16    \nApplication \ncreated and \nautomatically \nsynced\nIf you click into the application, you will drill down to the application’s full view, which \nshows you the state of all the resources associated with the application, as shown in \nfigure 4.17. \nFigure 4.17    Our staging environment is healthy, and all the services are running.\nIf you are creating the environment in a local cluster or a real Kubernetes cluster, you \nshould access the application and interact with it. Let’s recap what we have achieved: \n¡ We have installed Argo CD into our Kubernetes cluster. Using the provided Argo \nCD Dashboard (user interface), we have created a new Argo CD application for \nour staging environment. \n¡ We have created our staging environment configuration in a Git repository \nhosted in GitHub, which uses a Helm Chart definition to configure our Con-\nference application services and their dependencies (Redis, PostgreSQL, and \nKafka). \n",
      "content_length": 1020,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 134,
      "content": "\t\n115\nEnvironment pipelines in action\n¡ We have synced the configuration to a namespace (staging) in the same cluster \nwhere we installed Argo CD.\n¡ Most importantly, we have removed the need for manual interaction against the \ntarget cluster. Theoretically, there will be no need to execute kubectl against the \nstaging namespace. \nFor this setup to work, we need to make sure that the artifacts that the Helm Charts \n(and the Kubernetes resources inside them) are available for the target cluster to pull. I \nstrongly recommend you follow the step-by-step tutorial (https://github.com/salaboy/ \nplatforms-on-k8s/tree/main/chapter-4) to get hands-on with Argo CD to understand \nhow this tool works and how it can help your teams to continuously deploy their appli-\ncations to multiple environments. \n4.2.2\t\nDealing with changes the GitOps way\nImagine now that the team in charge of developing the user interface (frontend) \ndecides to introduce a new feature. They create a pull request to the frontend repos-\nitory. Once this pull request is merged with the main, the team can decide to create a \nnew release for the service. The release process should include the creation of tagged \nartifacts using the release number. The creation of these artifacts is the responsibility \nof the service pipeline, as we saw in previous sections. Figure 4.18 shows how Argo CD, \nin this case, syncs the configuration changes from the staging configuration repository. \nStaging Configuration \nRepository\nDeveloper\nOperator\nContainer Registry\nHelm Repository\nKubernetes Cluster\nStaging\nfrontend 0.1.0\nagenda-service 0.1.0\nc4p-service 0.1.0\nnotifications-service 0.1.0\nArgo CD\nWeb Browser\nUser\nSend \nchange \nupdate\nFigure 4.18    Components to set up the staging environment with Argo CD\n",
      "content_length": 1773,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 135,
      "content": "116\nChapter 4  Environment pipelines: Deploying cloud-native applications\nOnce we have the released artifacts, we can now update the environment. We can \nupdate the staging environment by submitting a pull request to our GitHub reposi-\ntory that can be reviewed before merging to the main branch, the branch we used to \nconfigure our Argo CD application. The changes in the environment configuration \nrepository are going to be usually about: \n¡ Bumping up or reverting a service version: For our example, this is as simple as chang-\ning the version of the chart of one or more services. Rolling back one of the \nservices to the previous is as simple as reverting the version number in the envi-\nronment chart or even reverting the commit that increased the version in the \nfirst place. Notice that reverting commits is always recommended, as rolling back \nto a previous version might also include configuration changes to the services \nthat, if they are not applied, old versions might not work. \n¡ Adding or removing a service: Adding a new service is a bit more complicated, \nbecause you will need to add both the chart reference and the service configura-\ntion parameters. For this to work, the chart definition needs to be reachable by \nthe Argo CD installation. Suppose the service(s)’ chart(s) are available, and the \nconfiguration parameters are valid. In that case, the next time we sync our Argo \nCD application, the new service(s) will be deployed to the environment. Remov-\ning services is more straightforward, because the moment you remove the depen-\ndency from the environment Helm Chart, the service will be removed from the \nenvironment. \n¡ Tweaking charts parameters: Sometimes, we don’t want to change any service ver-\nsion, and we might be trying to fine-tune the application parameters to accom-\nmodate performance or scalability requirements, monitoring configurations, or \nthe log level for a set of services. These changes are also versioned and should be \ntreated as new features and bug fixes. \nWe will quickly notice the differences if we compare this with manually installing Helm \nto install the application into the cluster. First, a developer might have the environ-\nment configuration on their laptop, making the environment very difficult to repli-\ncate from a different location. Changes to the environment configuration that are not \ntracked using a version control system will be lost, and we will not have any way to ver-\nify whether these changes are working in a live cluster. Configuration drifts are much \nmore difficult to track down and troubleshoot. \nThis automated approach with Argo CD can open the door to more advanced sce-\nnarios. For example, we can create preview environments (figure 4.19) for our pull \nrequests to test changes before they get merged and artifacts are released. \n",
      "content_length": 2833,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 136,
      "content": "\t\n117\nService + environment pipelines\nOpen Pull \nRequest #3\nGit \nRepository\nPreview Environment\nService v0.1.0-pr-3\nAnother developer, \nin charge of \nreviewing the Pull \nRequest code can \nvalidate the changes \nlive in the Preview \nEnvironment.\nA Preview Environment \nPipeline creates a new \nPreview Environment to \nrun the service with the \nchanges introduced in the \nPull Request.\nA Developer \ncreates a new \nPull Request #3.\nFigure 4.19    Preview environments for faster iterations\nUsing preview environments can help iterate faster and enable teams to validate \nchanges before merging them into the project’s main branch. Preview environments \ncan also be notified when the pull request is merged, making an automated clean-up \nmechanism straightforward to implement.  \nNOTE     Another important detail to mention when using Argo CD and Helm is \nthat compared with using Helm Charts manually, where Helm will create release \nresources every time we update a chart in our cluster, Argo CD will not use this \nHelm feature. Argo CD takes the approach of using a Helm template to render \nthe Kubernetes resources YAML, and then it applies the output using kubectl \napply. This approach relies on the fact that everything is versioned in Git and \nallows the unification of different templating engines for YAML. In addition to \nsome security benefits, this is key to enabling diffing in Argo CD, which allows us \nto specify which resources should be managed by Argo CD and which elements \nmay be managed by different controllers.\nFinally, to tie things together, let’s see how service and environment pipelines interact \nto provide end-to-end automation, from code changes to deploying new versions into \nmultiple environments. \n4.3\t\nService + environment pipelines\nLet’s look at how service pipelines and environment pipeline connect. The connec-\ntion between these two pipelines happens via pull/change requests to Git repositories, \nbecause the pipelines will be triggered when changes are submitted and merged (fig-\nure 4.20). \n",
      "content_length": 2032,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 137,
      "content": "118\nChapter 4  Environment pipelines: Deploying cloud-native applications\nWhen configuration \nchanges are merged the \nEnvironment Pipeline \nsync them to the live \nenvironment.\nService\nGit Repository\nA change triggers a \nService Pipeline \ninstance.\nSend automated pull \nrequests to \nenvironments \nrepositories.\nAll artifacts are \npublished and ready \nto be deployed.\nSend \nNotifications\nEnvironment\nGit Repository\nEnvironment\nService\nService Pipeline\nEnvironment Pipeline\nFigure 4.20    A service pipeline can trigger an environment pipeline via a pull request.\nDevelopers, when they finish a new feature, create a pull/change request to the repos-\nitory’s main branch. This pull/change request can be reviewed and built by a spe-\ncialized service pipeline. When this new feature is merged into the repository’s main \nbranch, a new instance of the service pipeline is triggered. This instance creates a new \nrelease and all the artifacts needed to deploy the service’s new version into a Kuber-\nnetes cluster. As we saw in chapter 3, this includes a binary with the compiled source \ncode, a container image, and Kubernetes Manifests that can be packaged using tools \nlike Helm. \nAs the last step of the service pipeline, you can include a notification step that can \nnotify the interested environments that there is a new version of a service that they are \nrunning available. This notification is usually an automated pull/change request into \nthe environment’s repository. Alternatively, you monitor (or subscribe to notifications) \nyour artifact repositories, and when a new version is detected, a pull/change request is \ncreated to the configured environments. \nThe pull/change requests created to environment repositories can be automatically \ntested by a specialized environment pipeline. In the same way as we did with service \npipelines, and for low-risk environments, these pull/change requests can be automati-\ncally merged without any human intervention. \nBy implementing this flow, we can enable developers to focus on fixing bugs and \ncreating new features that will be automatically released and promoted to low-risk envi-\nronments. Once the new versions are tested in environments like staging, and we know \nthat these new versions or configurations are not causing any problems, a pull/change \nrequest can be created for the repository that contains the production environment \nconfiguration. \n",
      "content_length": 2409,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 138,
      "content": "\t\n119\nLinking back to platform engineering\nThe more sensitive the environments are, the more required checks and validations. \nIn this case, as shown in figure 4.21, to promote a new service version to the production \nenvironment, a new test environment will be created to validate and test the changes \nintroduced in the pull/change request submitted. Once those validations are done, \na manual sign-off is required to merge the pull request and trigger the environment \npipeline synchronization. \nA new version (Service A v1.1.2) \nis available. This needs \nvalidation and manual approval \nto be promoted to the \nproduction environment.\nProduction\nValidations (automated and manual)\nProduction-like Test \nEnvironment\nPull Request\nOK to merge!\nService A v1.1.2\nManual Sign off\nPerformance/Regression \nTest Suite\nService v1.1.2\nService Y v1.2.3\nService Z v4.2.4\nConfiguration\nEnvironment \nPipeline\nFigure 4.21    Promoting changes to the production environment\nEnvironment pipelines are the mechanism you use to encode your organization’s \nrequirements to release and promote software to different environments. We have \nseen in this chapter what a tool like Argo CD can do for us. Next, we need to evaluate \nif a single Argo CD installation would be enough and who will manage it and keep it \nsecure. Do you need to extend Argo CD with custom hook points? Do you need to inte-\ngrate it with other tools? We will explore these questions in chapter 6, so before closing \nthis chapter, let’s look at how environment pipelines and tools like Argo CD fit into the \nplatform engineering story. \n4.4\t\nLinking back to platform engineering\nFrom a platform engineering perspective, providing a GitOps approach is becoming \nincreasingly popular for teams to configure different environments. With the popular-\nity of tools like Argo CD, more people feel comfortable storing and manipulating envi-\nronment configurations on version control systems like Git. As a platform engineering \nteam, you can enable your teams to use this approach without pushing them to learn \nhow to install, maintain, and configure these tools. \nPlatforms can automate the creation of environment repositories and make sure \nthat the right teams have access to read and write configurations to promote services. \n",
      "content_length": 2278,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 139,
      "content": "120\nChapter 4  Environment pipelines: Deploying cloud-native applications\nConsumers of these platforms are expected to know how to interact with their environ-\nments, but not how the tools provided by the platform work or how they are configured. \nThere are cases, for example, in development environments, where using a GitOps \napproach might not work, because some development teams will want direct access to \nclusters, and your platform should be flexible enough to allow this access when needed. \nAs discussed in section 4.3, service and environment pipelines work hand in hand \nto produce software artifacts and move them between environments. Both service and \nenvironment pipelines are key mechanisms to get in place to implement what is known \nas golden paths. The more mature your platform becomes, the coordination between \nenvironment pipelines becomes essential to automate how your new software releases \ngo from source to production environments and are validated by your end users (cus-\ntomers). These golden paths are automated workflows to move the changes that our \nteams are producing to our production environments where customers will be able to \naccess them. Figure 4.22 shows from a high level what a golden path looks like for our \napplications.\nProduction Clusters\nGolden Path (from Source to Production)\nDev Cluster\nNamespace\nStaging Cluster\nQuality \nAssurance\nDevs\nCustomers\nOK!\nFigure 4.22    What does it take to promote new releases to our production environments?\nThink about how many service and environment pipelines will need to be executed \nto take the software produced in our development environments to our production \nclusters, where customers can access the release of a single service. How are these pipe-\nlines coordinated and wired to ensure our deployments work as expected? How many \nmanual verifications do you need in this whole process? And most importantly, what \ncan you automate for your teams not to worry about all these complex interactions?\nSo far, we have covered how to install an application into a Kubernetes cluster, build \nand package the application services into containers, and package and distribute the \nconfiguration files needed to deploy these services into a Kubernetes cluster. This chap-\nter adds to the picture of how to manage different environments where this application \nwill run using a GitOps approach. Figure 4.23 shows all the pieces together.\n",
      "content_length": 2426,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 140,
      "content": "\t\n121\nSummary\nChanges to our environments \nnow happen by submitting \nchanges to a Git repository that \ncontains the configuration of \nwhich services and versions \nneeds to be deployed for each \nenvironment.\nEnvironments \nConfiguration \nRepository\nContainer \nRegistry\nService Pipeline\n(Per Service)\nEnvironment\nEnvironment\nEnvironment\nApplication\nApplication\nApplication\nGitOps Sync\nFigure 4.23    Adding GitOps to manage multiple environments\nBefore digging deeper into golden paths (in chapter 6), we must explore one more \nchallenge we face when we deploy our applications to different environments: applica-\ntion infrastructure, in the next chapter.\nSummary\n¡ Environment pipelines are responsible for deploying software artifacts to live \nenvironments. Environment pipelines avoid teams interacting directly with the \ncluster where the applications run, reducing errors and misconfigurations. Envi-\nronment pipelines should check that environments are fully operational after \nupdating their configuration.\n¡ Using tools like Argo CD, you can define the content of each environment into a \nGit repository that is used as the source of truth for what the environment config-\nuration should look like. Argo CD will keep track of the state of the cluster where \nthe environment is running and ensure no drift in the configuration applied in \nthe cluster. \n¡ Teams can upgrade or downgrade the versions of the services running in an envi-\nronment by submitting pull/change requests to the repository where the envi-\nronment configuration is stored. A team or an automated process can validate \nthese changes, and when approved and merged, these changes will be reflected \nin the live environment. Changes can be rolled back if things go wrong by revert-\ning commits to the git repository.\n¡ If you followed the step-by-step tutorial, you got hands-on experience on how to \ndeploy application workloads following a GitOps approach by using Argo CD.\n",
      "content_length": 1948,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 141,
      "content": "122\n5\nMulti-cloud (app) \ninfrastructure\nThis chapter covers\n¡ Defining and managing the infrastructure for \t\n\t your cloud-native applications\n¡ Identifying the challenges of managing  \n\t infrastructure components\n¡ Learning how Crossplane is the Kubernetes way \t\n\t to deal with infrastructure\nIn previous chapters, we installed a walking skeleton, and we learned how to build \neach separate component using service pipelines and then how to deploy them into \ndifferent environments using environment pipelines. We now face a big challenge: \ndealing with our application infrastructure, meaning running and maintaining not \nonly our application services but also the components that our services need to run. \nThese services expect other components to work correctly, such as databases, mes-\nsage brokers, identity management solutions, email servers, etc. While several tools \nexist to automate the installation (for on-premises setups) or provisioning of these \ncomponents in different cloud providers, this chapter will focus on just one that \ndoes it in a Kubernetes way. This chapter has three main sections: \n",
      "content_length": 1114,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 142,
      "content": "\t\n123\nThe challenges of managing infrastructure in Kubernetes\n¡ The challenges of dealing with infrastructure\n¡ How to deal with infrastructure using Kubernetes constructs\n¡ How to provision infrastructure for our walking skeleton using Crossplane\nLet’s get started. Why is it so difficult to manage our application infrastructure?\n5.1\t\nThe challenges of managing infrastructure in Kubernetes\nWhen you design applications like the walking skeleton introduced in chapter 1, you \nface specific challenges that are not core to achieving your business goals. Installing, \nconfiguring, and maintaining application infrastructure components that support our \napplication’s services is a big task that needs to be planned carefully by the right teams \nwith the right expertise. \nThese components are classified as application infrastructure, which usually involves \nthird-party components not developed in-house, such as databases, message brokers, \nidentity management solutions, etc. A big reason behind the success of modern cloud \nproviders is that they are great at providing and maintaining these components and \nallow your development teams to focus on building the core features of applications, \nwhich brings value to the business. \nIt is essential to distinguish between application infrastructure and hardware infra-\nstructure, because this book is not concerned with hardware provisioning, the reminder \nof content focus on the application space. I assume that for public cloud offerings, the \nprovider solves all hardware-related topics. For on-prem scenarios, you likely have a spe-\ncialized team taking care of the hardware (removing, adding, and maintaining hard-\nware as needed).\nIt is common to rely on cloud provider services to provision application infrastruc-\nture. There are a lot of advantages to doing so, such as pay-as-you-use services, easy \nprovisioning at scale, and automated maintenance. But at that point, you heavily rely \non provider-specific ways of doing things and their tools. The moment you create a \ndatabase or a message broker in a cloud provider, you are jumping outside the realms of \nKubernetes. Now you depend on their tools and automation mechanisms, and you are \ncreating a strong dependency between your business and the cloud provider. \nLet’s look at the challenges associated with provisioning and maintaining applica-\ntion infrastructure, so your teams can plan and choose the right tool for the job:\n¡ Configuring components to scale: Each component requires different expertise to \nbe configured (database administrators for databases, message broker experts, \nmachine learning experts, etc.) and a deep understanding of how our applica-\ntion’s services will use it, as well as the hardware available. These configurations \nneed to be versioned and monitored closely, so new environments can be created \nquickly to reproduce problems or test new versions of our application. \n¡ Maintaining components in the long run: Databases and message brokers are con-\nstantly released and patched to improve performance and security. This constant \n",
      "content_length": 3086,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 143,
      "content": "124\nChapter 5  Multi-cloud (app) infrastructure \nchange pushes the operations teams to ensure they can upgrade to newer ver-\nsions and keep all the data safe without bringing down the entire application. All \nthis complexity requires a lot of coordination and impact analysis between the \nteams providing and consuming these components. \n¡ Cloud provider services affect our multi-cloud strategy: If we rely on cloud-specific \napplication infrastructure and tools, we need to find a way to enable develop-\ners to create and provision their components for developing and testing their \nservices. We need a way to abstract how infrastructure is provisioned to enable \napplications to define what infrastructure they need without relying directly on \ncloud-specific tools. \nInterestingly, we had these challenges even before having distributed applications, and \nconfiguration and provisioning architectural components have always been hard and \nusually far away from developers. Cloud providers are doing a fantastic job by bringing \nthese topics closer to developers so they can be more autonomous and iterate faster. \nUnfortunately, when working with Kubernetes, we have more options that we need to \nconsider carefully to ensure we understand the tradeoffs. The following section covers \nhow we can manage our application infrastructure inside Kubernetes. While this is \nusually not recommended, it can be practical and cheaper for some scenarios.  \n5.1.1\t\nManaging your application infrastructure\nApplication infrastructure has become an exciting arena. With the rise of containers, \nevery developer can bootstrap a database or message broker with a couple of com-\nmands, which is usually enough for development purposes. In the Kubernetes world, \nthis translates to Helm Charts, which uses containers to configure and provision data-\nbases (relational and NoSQL), message brokers, identity management solutions, etc. \nAs we saw in chapter 2, you installed the walking skeleton application containing four \nservices, two databases (Redis and PostgreSQL), and a message broker (Kafka) with a \nsingle command. \nFor our walking skeleton, we are provisioning an instance of a Redis NoSQL database \nfor the Agenda service, an instance of a PostgreSQL database for the Call for Proposals \n(C4P) service, and an instance of a Kafka cluster, all using Helm Charts. The number of \nHelm charts available today is impressive, and it is pretty easy to think that installing a \nHelm Chart will be the way to go. The Helm charts used in the example application can \nall be found in the Bitnami Helm Chart repositories at https://bitnami.com/stacks/\nhelm.\nAs discussed in chapter 2, if we want to scale our services that keep state, we must \nprovision specialized components such as databases. Application developers will define \nwhich kind of database will suit them best depending on the data they need to store and \nhow that data will be structured. Figure 5.1 shows the dependency of the application \nservices on some of the application infrastructure components that we have identified \nfor our walking skeleton. \n",
      "content_length": 3106,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 144,
      "content": "\t\n125\nThe challenges of managing infrastructure in Kubernetes\nCall For Proposals \n(C4P) Service\nFrontend\nAgenda Service\nNotifications \nService\nKafka\nPostgreSQL\nKafka\nFigure 5.1    Services and their dependencies on application infrastructure components\nThe process of setting up these (PostgreSQL, Redis, and Kafka) components inside \nyour Kubernetes cluster involves the following steps: \n¡ Finding or creating a suitable Helm Chart for the component you want to boot-\nstrap. For the walking skeleton, PostgreSQL (https://bitnami.com/stack/\npostgresql/helm), Redis (https://bitnami.com/stack/redis/helm), and Kafka \n(https://bitnami.com/stack/kafka/helm) can be found in the Bitnami Helm \nChart repository. If you cannot find a Helm Chart but have a Docker container \nfor the component you want to provision, you can create your chart after you \ndefine the basic Kubernetes constructs needed for the deployment. \n¡ Research the chart configurations and parameters you must set up to accommo-\ndate your requirements. Each chart exposes a set of parameters that you can tune \nfor different use cases. Check the chart website to understand what is available. \nInclude your operations teams and DBAs to check the optimal database config-\nurations for your use case; this is not something that a developer can do. This \nanalysis also requires Kubernetes expertise to ensure the components can work \nin HA (high availability) mode inside Kubernetes.\n¡ Install the chart into your Kubernetes cluster using helm install. By running \nhelm install, you are downloading a set of Kubernetes manifest (YAML files) \nthat describe how these components need to be deployed. Helm will then pro-\nceed to apply these YAML files to your cluster. For our Conference application \nHelm Chart that we installed in chapter 2 (section 2.1.3), all the application \ninfrastructure components are added as a dependency to the chart.\n¡ Configure your service to connect to the newly provisioned components. You can \nachieve this by giving the service the new provisioned instance URL and creden-\ntials to connect. For a database, it will be the database URL serving requests and \npossibly a username and password. An interesting detail to notice here is that \nyour application will need some kind of driver to connect to the target database. \nMore on this in chapter 8.\n¡ Maintain these components in the long run, doing backups and ensuring the \nfail-over mechanisms work as expected.\n",
      "content_length": 2457,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 145,
      "content": "126\nChapter 5  Multi-cloud (app) infrastructure \nFigure 5.2 shows the steps involved in installing and wiring up these application infra-\nstructure components to our application’s services.\nPostgreSQL\nHelm Chart\nPostgreSQL\nService A\nKubernetes Cluster\nNamespace A \n#1\n#2\n#3\n`helm install`\nFigure 5.2    Provisioning a new PostgreSQL instance using the PostgreSQL Helm Chart. #1 Install a helm \nchart into a Namespace inside a Kubernetes Cluster; #2 The chart creates Kubernetes resources such \nas StatefulSets and Deployments to provision a PostgreSQL instance; #3 A Service needs to connect \nto the newly created instance, this can be done manually or by referencing a Kubernetes Secret that \ncontains the credentials and details on how to connect.\nIf you are working with Helm Charts, there are a couple of caveats and tricks that you \nneed to be aware of: \n¡ If the chart doesn’t allow you to configure a parameter that you are interested \nin changing, you can always use helm template, then modify the output to add \nor change the parameters that you need to finally install the components using \nkubectl apply -f. Alternatively, you can submit a pull request to the chart \nrepository. It is a common practice not to expose all possible parameters and wait \nfor community members to suggest more parameters to be exposed by the chart. \nDon’t be shy and contact the maintainers if that is the case. Whatever modifica-\ntion you do, the chart content must be maintained and documented. By using \nhelm template, you lose the Helm release management features, allowing you \nto upgrade a chart when a new version is available. \n¡ Most charts have a default configuration designed to scale, meaning that the \ndefault deployment will target high-availability scenarios. This results in charts \nthat, when installed, consume a lot of resources (CPU and memory) that might \nnot be available if you use Kubernetes KinD or Minikube on your laptop. Once \nagain, chart documentation usually includes special configurations for develop-\nment and resource-constrained environments.\n¡ If you are installing a database inside your Kubernetes cluster, each database \ncontainer (pod) must have access to storage from the underlying Kubernetes \nnode. For databases, you might need a special kind of storage to enable the data-\nbase to scale elastically, which might require advanced configurations outside of \nKubernetes. \n",
      "content_length": 2406,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 146,
      "content": "\t\n127\nThe challenges of managing infrastructure in Kubernetes\nFor our walking skeleton, for example, we set up the Redis chart to use the architec-\nture parameter to standalone, (as you can see in the environment pipeline configu-\nrations and in the Agenda service Helm Chart values.yaml file) to make it easier to run \non environments where you might have limited resources, such as your laptop/work-\nstation. This affects Redis’s availability to tolerate failure, because it will only run a sin-\ngle replica in contrast with the default setup where a master and two slaves are created. \n5.1.2\t\nConnecting our services to the newly provisioned infrastructure\nInstalling the charts will not make our application services automatically connect to \nthe Redis, PostgreSQL, or Kafka instances. We need to provide the services the con-\nfigurations need to connect while also being conscious of the time needed by these \ncomponents, such as databases, to start.\nFigure 5.3 shows how the wiring usually happens, as most charts automatically create \na Kubernetes secret hosting all the details that application’s services need to connect.\n#1\nPostgreSQL\nKubernetes Cluster\nNamespace A\nDeployment\nSecret\nName: postgresql-secret\nURL: postgresql\nPassword: admin\n#3\nPod\nEnv:\nfromSecret: postgresql-secret\n#2\nFigure 5.3    Connecting a service to a provisioned resource using secrets. #1 A Kubernetes deployment \nis created to run one of your services, and the pod template contains the environment variables to \nconfigure the pods that this deployment will create; #2 The pod is created using the template specified \nin the deployment resource, which points to a secret that contains the details to connect to the db \ninstance; #3 The container, which is running inside the pod needs to be prepared to consume the \nenvironment variables to connect to the db instance.\nA common practice is to use Kubernetes secrets to store the credentials for these appli-\ncation infrastructure components. The Helm Chart for Redis and PostgreSQL that \nwe are using for our walking skeleton creates a new Kubernetes secret containing the \ndetails required to connect. These Helm Charts also create a Kubernetes service to be \nused as the location (URL) where the instance will run. \nTo connect the Call for Proposals (C4P) service to the PostgreSQL instance, you \nneed to make sure that the Kubernetes Deployment for the C4P service (conference \n-c4p-service-deployment) has the right environment variables (listing 5.1). \n",
      "content_length": 2494,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 147,
      "content": "128\nChapter 5  Multi-cloud (app) infrastructure \nListing 5.1    Environment variables to connect to application infrastructure (PostgreSQL)\n- name: KAFKA_URL\n  value: <KAFKA SERVICE URL>\n- name: POSTGRES_HOST\n  valueFrom:\n    secretKeyRef:\n      name: <POSTGRESQL SECRET NAME>\n      key: postgres-url\n- name: POSTGRES_PASSWORD\n  valueFrom:\n    secretKeyRef:\n      name: <POSTGRESQL SECRET NAME>\n      key: postgres-password\nThe bold highlights how we can consume the dynamically generated password when \nwe install the chart and the DB endpoint URL, which is the PostgreSQL Kubernetes \nservice, also created by the chart. The DB endpoint will be different if you used a differ-\nent chart release name. \nA similar configuration applies to the Agenda service (conference-agenda-service \n-deployment) and Redis (listing 5.2).\nListing 5.2    Environment variables to connect to application infrastructure (Redis) \n- name: KAFKA_URL\n  value: <KAFKA SERVICE URL>\n- name: REDIS_HOST\n  valueFrom:\n    secretKeyRef:\n      name: <REDIS SECRET NAME>\n      key: redis-url\n- name: REDIS_PASSWORD\n  valueFrom:\n    secretKeyRef:\n      name: <REDIS SECRET NAME>\n      key: redis-password\nAs before, we extract the password from a Kubernetes secret that will be generated \nwhen installing the Redis Helm Chart. The secret name will be derived from the name \nof the Helm Chart release that we use. The REDIS_HOST is obtained from the name \nof the Kubernetes service that is created by the chart, which depends on the helm \nrelease name that you used.  For all the services of the application we will need to \nset up the KAFKA_URL environment variable so that the services can connect to Kafka. \nConfiguring different instances for the application infrastructure components opens \nthe door for us to delegate the provisioning and maintenance to other teams and even \ncloud providers. \n5.1.3\t\nI’ve heard about Kubernetes operators. Should I use them?\nNow you have four application services, two databases, and a message broker inside \nyour Kubernetes cluster. Believe it or not, now you are in charge of seven components \nto maintain and scale depending on the application’s needs. The team that built the \n",
      "content_length": 2187,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 148,
      "content": "\t\n129\nThe challenges of managing infrastructure in Kubernetes\nservices will know exactly how to maintain and upgrade each service, but they are not \nexperts in maintaining and scaling databases or message brokers. \nYou might need help with these databases and message brokers depending on how \ndemanding the services are. Imagine you have too many requests on the Agenda ser-\nvice, so you decide to scale up the number of replicas of the agenda deployment to 200. \nAt that point, Redis must have enough resources to deal with 200 pods connecting to \nthe Redis cluster. The advantage of using Redis for this scenario, where we might get a \nlot of reads while the conference is ongoing, is that the Redis cluster allows us to read \ndata from the replicas so the load can be distributed.\nFigure 5.4 shows a typical case of high demand, where we are tempted to increase \nthe number of replicas of our application’s services, without checking or changing the \nconfiguration of our PostgreSQL instance. In these scenarios, even if the application’s \nservices can scale, the PostgreSQL instance will be the bottleneck if not configured \naccordingly (to support 200+ concurrent connections).\nPod #113\nPod #1\nPod #2\nPod #200\nPod #56\nPostgreSQL\nDeployment\nReplicas: 200\nKubernetes Cluster\nNamespace A\n#1\n#2\nReplicaSet\nFigure 5.4    Application infrastructure needs to be configured according to how our services will be \nscaled. #1 If you noticed a surge in demand for one of your services, you might be tempted to increase \nthe number of replicas, and the deployment using the ReplicaSet will not complain about it. If the cluster \nhas enough resources, the replicas will be created; #2 If the application infrastructure is not correctly \nconfigured, you might encounter a lot of issues, such as exhausting the database connection pool or \noverloading the database pods, as they are not scaled when you scale up your deployments.\nIf you are installing your application infrastructure with Helm, notice that Helm will \nnot check for the health of these components—it is just doing the installation. It is \nquite common nowadays to find another alternative to install components in a Kuber-\nnetes cluster called Operators. Usually associated with application infrastructure, you \ncan find more active components that will install and monitor the installed compo-\nnents. One example of these operators is the Zalando PostgreSQL Operator, which \nyou can find at https://github.com/zalando/postgres-operator. While these operators \nare focused on allowing you to provision new instances of PostgreSQL databases, they \nalso implement other features focused on maintenance, for example: \n",
      "content_length": 2672,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 149,
      "content": "130\nChapter 5  Multi-cloud (app) infrastructure \n¡ Rolling updates on Postgres cluster changes, including quick minor version \nupdates\n¡ Live volume resize without pod restarts (AWS EBS, PVC)\n¡ Database connection pooling with PGBouncer\n¡ Supporting fast, in-place major version upgrades\nIn general, Kubernetes operators try to encapsulate the operational tasks associated \nwith a specific component, in this case, PostgreSQL. While using operators might add \nmore features on top of installing a given component, you still need to maintain the \ncomponent and the operator itself now. Each operator comes with a very opinionated \nflow that your teams will need to research and learn to manage. Take this into consid-\neration when researching and deciding which operator to use. \nRegarding the application infrastructure you and your teams decide to use if you \nplan to run these components inside your cluster, plan accordingly to have the right \nin-house expertise to manage, maintain, and scale these extra components.  \nIn the following section, we will look at how we can tackle these challenges by looking \nat an open-source project that aims to simplify the provisioning of cloud and on-prem \nresources for application infrastructure components using a declarative approach. \n5.2\t\nDeclarative infrastructure using Crossplane\nUsing Helm to install application infrastructure components inside Kubernetes is far \nfrom ideal for large applications and user-facing environments, because maintaining \nthese components and their requirements, such as advanced storage configurations, \nmight become too complex to handle for your teams. \nCloud providers do a fantastic job at allowing us to provision infrastructure, but they \nall rely on cloud provider-specific tools that are outside of the realm of Kubernetes. \nIn this section, we will look at an alternative tool—a CNCF project called Crossplane \n(https://crossplane.io), which uses the Kubernetes APIs and extension points to \nenable users to provision real infrastructure in a declarative way, using the Kubernetes \nAPIs. Crossplane relies on the Kubernetes APIs to support multiple cloud providers; \nthis also means that it integrates nicely with all the existing Kubernetes tooling. \nBy understanding how Crossplane works and how it can be extended, you can build \na multi-cloud approach and run your cloud-native applications and their dependencies \nwith different providers without worrying about getting locked in on a single vendor. \nBecause Crossplane uses the same declarative approach as Kubernetes, you can create \nhigh-level abstractions about the applications you are trying to deploy and maintain. \nTo use Crossplane, you must first install its control plane in a Kubernetes cluster. You \ncan follow the official documentation (https://docs.crossplane.io/) or the step-by-step \ntutorial introduced in section 5.3. \nThe core Crossplane components alone will not do much for you. Depending on \nyour cloud provider(s), you will install and configure one or more Crossplane providers. \nLet’s take a look at what Crossplane providers have to offer us. \n",
      "content_length": 3117,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 150,
      "content": "\t\n131\nDeclarative infrastructure using Crossplane\n5.2.1\t\nCrossplane providers\nCrossplane extends Kubernetes by installing a set of components called Crossplane \nproviders (https://docs.crossplane.io/v1.12/concepts/providers/) in charge of \nunderstanding and interacting with cloud provider-specific services to provision cloud \nresources on our behalf. Figure 5.5 shows how by installing the GCP provider and the \nAWS provider, our Crossplane installation can provision resources on both clouds.\nKubernetes Cluster\nKubernetes API\nCrossplane \nAWS Provider\nCrossplane \nGCP Provider\nGCP Account\nAWS Account\n> kubectl apply -f \nresource.yaml\nFigure 5.5    Crossplane installed with GCP and AWS providers\nBy installing Crossplane providers, you are extending the Kubernetes API’s function-\nality to provision external resources such as databases, message brokers, buckets, and \nother cloud resources that will live outside your Kubernetes cluster but inside the \ncloud provider realm. There are several Crossplane providers that cover the major \ncloud providers such as GCP, AWS, and Azure. You can find these Crossplane providers \nin the Crossplane GitHub’s organization: https://docs.crossplane.io/latest/concepts/\nproviders/.\nOnce a Crossplane Provider is installed, you can create provider-specific resources \nin a declarative way, which means that you can create a Kubernetes Resource, apply it \nwith kubectl apply -f, package these definitions in Helm Charts or use environment \npipelines storing these resources in a Git repository.\nFor example, creating a bucket in Google Cloud using the Crossplane GCP provider \nlooks like listing 5.4. \n",
      "content_length": 1642,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 151,
      "content": "132\nChapter 5  Multi-cloud (app) infrastructure \nListing 5.4    Google Cloud Platform bucket resource definition\ncat <<EOF | kubectl create -f -\napiVersion: storage.gcp.upbound.io/v1beta1\nkind: Bucket\nmetadata:\n  generateName: crossplane-bucket-\n  labels:\n    docs.crossplane.io/example: provider-gcp \nspec: \n  forProvider:\n    location: US\n  providerConfigRef:\n    name: default\nEOF\nProvisioning cloud-specific resources relying on the Kubernetes APIs is a big step for-\nward, but Crossplane doesn’t stop there. If you look at what it takes to provision a \ndatabase in any major cloud provider, you will realize that provisioning the compo-\nnent is just one of the tasks involved in getting the component ready to be used. You \nneed extra network and security configurations, user credentials, and other cloud \nprovider-specific configurations to connect to these provisioned resources. Welcome \nCrossplane compositions!  \n5.2.2\t\nCrossplane compositions\nCrossplane aims to serve two different personas: platform teams and application teams. \nWhile platform teams are cloud provider experts who understand how to provision \ncloud provider-specific components, application teams know the application require-\nments and understand what is required from the application infrastructure perspec-\ntive. The interesting thing about this approach is that when using Crossplane, platform \nteams can define these complex configurations for a specific cloud provider and \nexpose simplified interfaces for application teams. \nIn real-life scenarios, it is rare to create a single component. For example, if we want \nto provision a database instance, application teams will also require the correct network \nand security configurations to be able to access the newly created instance. Being able \nto compose and wire together several components is a very convenient feature, and to \nachieve these abstractions and simplified interfaces, Crossplane introduced two con-\ncepts, Composite Resource Definitions (XRDs) and Composite Resources (XRs). \nFigure 5.6 shows how you can use Crossplane XRD to define abstractions for differ-\nent cloud providers. The platform team might be very knowledgeable in Google Cloud \nor Azure, so they will be in charge of defining which Resources they want to wire up \ntogether for a specific application. The application team has a simple resource inter-\nface to request the resource they are interested in. But as usual, abstractions are compli-\ncated and good to show who is responsible for what, but let’s look at a concrete example \nto understand the power of Crossplane compositions.\nBoth apiVersion and \nkind are defined by the \nCrossplane GCP \nprovider. You can find \nall the supported types \nof resources in the \nCrossplane provider \ndocumentation.\nBy creating a bucket resource in \nour Kubernetes cluster where \nCrossplane is installed, you are \ncreating a request for Crossplane \nto provision and monitor this \nresource on your behalf.\nFor each resource type, you \nhave a set of parameters to \nconfigure the resource. In \nthis case, we want the \nbucket to be in the US. \nDifferent resources will \nexpose different \nconfiguration parameters.\n",
      "content_length": 3168,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 152,
      "content": "\t\n133\nDeclarative infrastructure using Crossplane\nPlatform Teams define \n“CompositeResourcesDefinitions” \nto configure cloud resources. These \nresources will managed by Crossplane.\nManaged Resource\nApplication Teams create \nClaims to access Managed \nResources by Crossplane.\nPlatform Teams\nResource\nResource Claim\nCompositeResource\nDefinition\nApplication Teams\nFigure 5.6    Resource composition abstractions by Crossplane composite resources\nFigure 5.7 shows how the application team can create a simple PostgreSQL resource to \na provision in Google Cloud a CloudSQLInstance plus a network configuration and a \nbucket. The application team is interested in something other than what resources are \ncreated or even in which cloud provider they were created. They are only interested in \nhaving a PostgreSQL instance to connect their applications to.  \nApplication Teams \ncreate simple Claim \nresources to request \naccess to Managed \nResources. These \nclaims enable teams to \naccess instances by \ncreating a Secret that \ncontains credentials \nand services URLs to \nconnect. \nGCP CloudSQLInstance\nPostgreSQL\nPlatform Teams understand \nCloud Provider Resources \nand how they need to be \nwired up together.\nPlatform Teams\nApplication \nTeams\nPostgreSQL \nCredentials\n<Secret>\nBucket\nNetwork\nPostgreSQL\nManaged Resource\nPostgreSQL Resource Claim\nPostgreSQL\n<CompositeResource\nDefinition>\nApplication\n<POD>\nFigure 5.7    Provisioning a PostgreSQL instance in Google Cloud with Crossplane compositions\n",
      "content_length": 1493,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 153,
      "content": "134\nChapter 5  Multi-cloud (app) infrastructure \nThis takes us to the Secret box in the figure, representing a Kubernetes secret that \nCrossplane will create for our application/services pods to connect to the provisioned \nresources. Crossplane creates this Kubernetes secret with all the details our applica-\ntions require to connect to the newly created resources (or just with the one relevant \nto the application). This secret typically contains URLs, usernames, passwords, certif-\nicates, or anything required for your applications to connect. Platform teams define \nwhat will be included in the secret when defining the CompositeResources. In the fol-\nlowing sections, when we add real infrastructure to our Conference application, we will \nexplore how these CompositeResourceDefinitions look and how they can be applied \nto create all the components our applications need. \n5.2.3\t\nCrossplane components and requirements\nTo work with Crossplane providers and CompositeResourceDefinitions we need to \nunderstand how Crossplane components will work together to provision and manage \nthese components inside different cloud providers. \nThis section covers what Crossplane needs to work and how Crossplane components \nwill manage our CompositeResources. First, it is important to understand that you \nmust install Crossplane in a Kubernetes cluster. This can be the cluster where your \napplications run or a separate cluster where Crossplane will run. This cluster will have \nsome Crossplane components that will understand our CompositeResourceDefini-\ntions and have enough permissions on the cloud platform to provision resources on \nour behalf. \nKubernetes Cluster\nKubernetes API\nCrossplane \nGCP Provider\nGCP Account\n> kubectl apply -f \ndatabase.yaml\nFigure 5.8    Crossplane in Google Cloud Platform\nFigure 5.8 shows Crossplane installed inside a Kubernetes cluster, with the Crossplane \nGCP provider installed and configured to use a Google Cloud Platform account with \nenough rights to provision PostgreSQL and Redis instances. This means having, in \nsome cases, admin access to create resources on the cloud provider. \n",
      "content_length": 2128,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 154,
      "content": "\t\n135\nDeclarative infrastructure using Crossplane\nFor figure 5.8 to work in GCP, you need the following configurations on the cloud \nprovider: \n¡ For creating a Redis instance in GCP.\n–\t Your GCP project needs to have the redis.googleapis.com APIs enabled.\n–\t You also need to have admin rights on the Redis resources roles/redis \n.admin.\n¡ For creating a PostgreSQL instance in GCP: \n–\t Your GCP project needs to have the sqladmin.googleapis.com APIs \nenabled.\n–\t You also need to have admin rights on the SQL resources roles/cloudsql \n.admin. \nEach Crossplane provider available requires a specific security configuration to work \nand an account inside the cloud provider where we want to create resources. Once a \nCrossplane provider is installed and configured (in this case, the GCP provider) we can \nstart creating resources managed by this provider. You can find the resources offered \nby each provider on the following documentation site: https://doc.crds.dev/github \n.com/crossplane/provider-gcp (figure 5.9).\nFigure 5.9    Crossplane GCP–supported resources\nAs you can see in the previous figure, the GCP provider version 0.22.0 supports 29 \ndifferent CRDs (Custom Resource Definitions) for creating resources in the Google \nCloud Platform. Crossplane defines each of these resources as managed resources. \nEach of these managed resources will need to be enabled for the Crossplane provider \nto have access to the list, create, and modify these resources.  \nIn section 5.3, we will look at how to provision cloud or local resources for our appli-\ncations using different Crossplane providers and Crossplane compositions. Before \njumping into the technical aspects, let’s look at Crossplane core behaviors that you \nshould look for when working with tools in the Kubernetes space.\n",
      "content_length": 1790,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 155,
      "content": "136\nChapter 5  Multi-cloud (app) infrastructure \n5.2.4\t\nCrossplane behaviors\nIn contrast to installing Helm components in our Kubernetes clusters, we use \nCrossplane to interact with the cloud provider-specific APIs to provision resources \ninside the cloud infrastructure. This should simplify the maintenance tasks and costs \nrelated to these resources. Another important difference is that the Crossplane pro-\nvider (GCP provider in this case) will observe the created managed resources for \nus. These managed resources offer some advantages compared with just installed \nresources using Helm. Managed resources have very well-defined behaviors. Here is a \nsummary of what to expect from a Crossplane managed resource:\n¡ Visible as any other Kubernetes resource: Crossplane managed resources are just \nKubernetes resources. This means that we can use any Kubernetes tool to moni-\ntor and query the state of these resources. \n¡ Continuous reconciliation: When a managed resource is created, the provider will \ncontinuously monitor the resource to ensure it exists and is working and report \nback the status to the Kubernetes resource. The parameters defined inside \nthe managed resource are considered the desired state (source of truth) and \nCrossplane providers will work to apply these configurations to the cloud pro-\nvider resources. Once again, we can use standard Kubernetes tools to monitor \nchanges in state and trigger remediation flows. \n¡ Immutable propertiesProviders are in charge of reporting back if a user manually \nchanges properties in the cloud provider. The idea here is to avoid configuration \ndrifts from what was defined to what is running in the cloud provider. If so, the \nstate is reported back to the managed resource. Crossplane will not delete the \ncloud provider resource but will notify back so actions can be taken. Other tools \nlike Terraform (https://www.terraform.io) will automatically delete the remote \nresources to recreate them. \n¡ Late initialization: Some properties in the managed resources can be optional, \nmeaning each provider will select the default values for these properties. When \nthis happens, Crossplane creates the resource with the default values and then \nsets the selected values into the managed resource. This simplifies the configura-\ntion needed to create resources and reuse the sensible defaults defined by cloud \nproviders, usually in their user interfaces.\n¡ Deletion: When deleting a managed resource, the cloud provider immediately \ntriggers the action. However, the managed resource is kept until the resource is \nfully removed from the cloud provider. Errors that might happen during dele-\ntion on the cloud provider will be added to the managed resource status field. \n¡ Importing existing resources: Crossplane doesn’t necessarily need to create the \nresources to manage them. You can create managed resources that start moni-\ntoring components created before Crossplane was installed. You can achieve this \nusing a specific Crossplane annotation on the managed resource: crossplane \n.io/external-name.\n",
      "content_length": 3077,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 156,
      "content": "\t\n137\nDeclarative infrastructure using Crossplane\nTo summarize the interactions between Crossplane, the Crossplane GCP provider, and \nour managed resources, let’s look at figure 5.10. \nKubernetes Cluster\nKubernetes API\nCrossplane \nGCP Provider\nGCP Account\n1\n2\n6\n3\n4\n5\n> kubectl apply -f \ndatabase.yaml\nManaged \nResource\nSecret\nFigure 5.10    Lifecycle of managed resources with Crossplane\nThe following points indicate the sequence observed in figure 5.10:\n1\t First, we need to create a resource. We can use any tool to create Kubernetes \nresources; kubectl here is just an example. \n2\t If the created resource is a Crossplane managed resource, let’s imagine a \nCloudSQLInstance resource the GCP Crossplane provider will pick up and \nmanage.\n3\t The first step to execute when managing a resource will be checking if it exists \nin the infrastructure (that is, in the configured GCP account). If it doesn’t exist, \nthe provider will request that the resource be created in the infrastructure. The \nappropriate SQL database will be provisioned depending on the properties set \non the resource, such as which kind of SQL database is required. Imagine that we \nhave chosen a PostgreSQL database for the sake of the example. \n4\t The cloud provider, after receiving the request, if the resources are enabled, will \ncreate a new PostgreSQL instance with the configured parameters in the man-\naged resource. \n5\t The status of the PostgreSQL will be reported back to the managed resource, \nwhich means that we can use kubectl or any other tool to monitor the status of \nthe provisioned resources. Crossplane providers will keep these in sync. \n6\t When the database is up and running, the Crossplane provider will create a secret \nto store the credentials and properties that our applications will need to connect \nto the newly created instance.\nCrossplane will regularly check the status of the PostgreSQL instance and update the \nmanaged resource. \n",
      "content_length": 1940,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 157,
      "content": "138\nChapter 5  Multi-cloud (app) infrastructure \nBy following Kubernetes design patterns, Crossplane uses the reconciliation cycle \nimplemented by controllers to keep track of external resources.  Let’s see this in action! \nThe following section will examine how we can use Crossplane with our walking skele-\nton application.  \n5.3\t\nInfrastructure for our walking skeleton\nIn this section, we will use Crossplane to abstract away how we provision infrastructure \nfor our Conference application. Because you might not have access to a cloud provider \nlike GCP, AWS, or Azure, we will work with a special provider called the Crossplane \nHelm provider. This Crossplane Helm provider allows us to manage Helm Charts as \ncloud resources. The idea here is to show how using Crossplane—more specifically, \nusing Crossplane compositions—we can enable users to request resources using a sim-\nplified Kubernetes resource to provision local or different cloud resources (hosted in \ndifferent cloud providers). \nFor our Conference application, we need Redis, PostgreSQL, and Kafka instances. \nFrom the application perspective, as soon as these three components are available, we \ncan connect to them, and we are good to go. How these components are configured is \nthe responsibility of the operations teams. \nThe conference application helm chart that we installed in chapter 2 included the \ninstallation of Redis, PostgreSQL, and Kafka as Helm dependencies using a condi-\ntional value that can be set at installation time. Let’s take a quick look at how this was \nwired up for our Helm Chart: https://github.com/salaboy/platforms-on-k8s/blob/ \nmain/conference-application/helm/conference-app/Chart.yaml#L13. \nThe Conference Helm Chart includes the Redis, PostgreSQL, and Kafka charts \ndependencies, as shown in listing 5.5.\nListing 5.5    Conference application with Helm Chart dependencies\napiVersion: v2\ndescription: A Helm chart for the Conference App\nname: conference-app\nversion: v1.0.0\ntype: application\nicon: https://www.salaboy.com/content/images/2023/06/avatar-new.png\nappVersion: v1.0.0\nhome: http://github.com/salaboy/platforms-on-k8s\ndependencies: \n- name: redis\n  version: 17.11.3 \n  repository: https://charts.bitnami.com/bitnami\n  condition: install.infrastructure\nYou can include any number of dependencies to \nyour Helm Charts. This allows complex compositions.\nEach dependency \nrequires the chart \nname, the repository \nwhere it is hosted \n(notice that you can use \noci:// references here \ntoo), and the version of \nthe chart that you want \nto install. \nCustom conditions can be defined to \ndecide if this dependency is injected \nwhen we install the chart.\n",
      "content_length": 2664,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 158,
      "content": "\t\n139\nInfrastructure for our walking skeleton\n- name: postgresql\n  version: 12.5.7 \n  repository: https://charts.bitnami.com/bitnami\n  condition: install.infrastructure\n- name: kafka\n  version: 22.1.5\n  repository: https://charts.bitnami.com/bitnami\n  condition: install.infrastructure \nFor this example, all the application infrastructure dependencies are defined at the \napplication level (dependencies section in the Chart.yaml file), but there is nothing \nstopping you from having one Helm Chart per service, which internally defines its own \ndependencies.\nThis kind of chart dependency works for development teams that want to install the \nentire application with all the components needed with a single command. Still, we \nwant to decouple all the application infrastructural concerns from application services \nfor larger scenarios. Luckily, the Conference application Helm Chart allows us to turn \noff these component dependencies, allowing us to plug in Redis, PostgreSQL, and \nKafka instances hosted and managed by different teams (figure 5.11). \nConference Application Helm Chart\ninstall.infrastructure: true\nRedis Helm Chart\nVersion: 17.11.3\nPostgresql Helm Chart\nVersion: 12.5.7\nKafka Helm Chart\nVersion: 22.1.5\nUsers install this top \nlevel chart\nFigure 5.11    Using Helm Chart dependencies for application infrastructure\nBy separating who requests and who provisions the application’s infrastructure com-\nponents, we enable different teams to control and manage when these components \nare updated, backed up, or how they need to be restored in case of failure. By using \nCrossplane, we can enable teams to request these databases on demand, which then \ncan be connected to our application’s services. One important aspect of the mecha-\nnisms we will use in the next sections is that the components we request can be pro-\nvisioned locally (using the Crossplane Helm provider) or remotely using Crossplane \ncloud providers. Let’s see what this would look like. You can follow a step-by-step tuto-\nrial to install, configure, and create your Crossplane compositions: https://github \n.com/salaboy/platforms-on-k8s/tree/main/chapter-5. \nIn this example, we will create a KinD cluster and configure Crossplane to allow \nteams to request application infrastructure on demand using the Crossplane Helm \nprovider for development purposes. In production the same requests will be satisfied \n",
      "content_length": 2397,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 159,
      "content": "140\nChapter 5  Multi-cloud (app) infrastructure \nvia scalable cloud resources. More specifically, we enable teams to request Redis, Post-\ngreSQL, and Kafka instances this way using a simplified interface.\nFor our Conference application example, the platform team decided to create two \ndifferent concepts: \n¡ Databases: NoSQL and SQL databases such as Redis and PostgreSQL. \n¡ Message brokers: For managed and unmanaged message brokers such as Kafka. \nAfter having Crossplane and the Crossplane Helm provider installed, the platform \nteam needs to define two Kubernetes resources: \n¡ Crossplane Composite Resource Definitions (XRDs): Defines the resources we want \nto expose to our teams—in this example, Database and MessageBroker. These \nComposite Resource Definitions define an interface that multiple Compositions \ncan implement.\n¡ Crossplane composition: The Crossplane composition allows us to define a set of \nresource manifests. We can link a composition to a Composite Resource Defini-\ntion and implement that XRD. By doing so, when the user requests new resources \nfrom the XRD–defined resource, all the composed resource manifests in the \ncomposition will be created in the cluster. We can provide multiple compositions \n(for example for different cloud providers), all implementing the same XRD, \nand then use labels in our resources to choose which composition should kick in.\nI know this might sound confusing at first, so let’s see these concepts in action. Let’s \nlook at the database Crossplane Composite Resource Definition (https://github.com/\nsalaboy/platforms-on-k8s/blob/main/chapter-5/resources/app-database-resource \n.yaml) in listing 5.6.\nListing 5.6    Database Composite Resource Definition\napiVersion: apiextensions.crossplane.io/v1\nkind: CompositeResourceDefinition\nmetadata:\n  name: databases.salaboy.com\nspec:\n  group: salaboy.com \n  names:\n    kind: Database\n    plural: databases\n    shortNames:\n      - \"db\"\n      - \"dbs\"\n  versions:\n  - additionalPrinterColumns:\n    - jsonPath: .spec.parameters.size\n      name: SIZE\n      type: string\nAs with every Kubernetes resource, \nthe CompositeResourceDefinition \nneeds a unique name.\nThis CompositeResourceDefinition \ndefines a new type of resource that \nneeds to have a group and a kind.\nOur new resource type that users can \nrequest is Database, because we want to \nenable them to request new databases.\n",
      "content_length": 2384,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 160,
      "content": "\t\n141\nInfrastructure for our walking skeleton\n    - jsonPath: .spec.parameters.mockData\n      name: MOCKDATA\n      type: boolean  \n    - jsonPath: .spec.compositionSelector.matchLabels.kind\n      name: KIND\n      type: string\n    name: v1alpha1\n    served: true\n    referenceable: true\n    schema: \n      openAPIV3Schema:\n        type: object\n        properties:\n          spec:\n            type: object\n            properties:\n              parameters: \n                type: object\n                properties:\n                  size:\n                    type: string \n                  mockData: \n                    type: boolean\n                required:   \n                - size\n            required: \n            - parameters \nWe have defined a new type of resource called a Database, which contains two param-\neters that we can set, size and mockData. Users can define how many resources are \nallocated for that instance by setting up the size parameter. Instead of worrying about \nhow much storage they will need or how many replicas they need for the database \ninstances, they can simply specify a size from a list of possible values (small, medium, \nor large). Using the mockData parameters, you can implement a mechanism to inject \ndata into the instance when needed. This is just an example of what can be done, but it \nis up to you to define these interfaces and what parameters make sense to your teams. \nLet’s see what the Crossplane composition looks like that will implement this XRD, \nin listing 5.7. \nListing 5.7    Key/value Database Crossplane composition\napiVersion: apiextensions.crossplane.io/v1\nkind: Composition\nmetadata:\n  name: keyvalue.db.local.salaboy.com\n  labels: \n    type: dev\n    provider: local\n    kind: keyvalue\nspec:\n  writeConnectionSecretsToNamespace: crossplane-system\nThe new resource we are \ndefining can also define custom \nparameters. For this example, \nand only for demonstration \npurposes, we are defining only \ntwo: size and mockData.\nBecause the Kubernetes API server can \nvalidate all resources, we can define which \nparameters are required and their types and \nother validations. The Kubernetes API server \nwill reject our resource request if these \nparameters are not provided or invalid.\nThe composition resource also \nneeds a unique name.\nFor each composition, we can also define labels. We \nwill then use these to match compositions with the \nrequested Database resources.\n",
      "content_length": 2430,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 161,
      "content": "142\nChapter 5  Multi-cloud (app) infrastructure \n  compositeTypeRef: \n    apiVersion: salaboy.com/v1alpha1\n    kind: Database\n  resources:\n    - name: redis-helm-release\n      base:\n        apiVersion: helm.crossplane.io/v1beta1\n        kind: Release\n        metadata:\n          annotations:\n            crossplane.io/external-name: # patched\n        spec:\n          rollbackLimit: 3\n          forProvider:\n            namespace: default\n            chart: \n              name: redis\n              repository: https://charts.bitnami.com/bitnami\n              version: \"17.8.0\"\n            values:\n              architecture: standalone\n          providerConfigRef: \n            name: default\n      patches: \n        - fromFieldPath: metadata.name\n          toFieldPath: metadata.annotations[crossplane.io/external-name]\n          policy:\n            fromFieldPath: Required\n        - fromFieldPath: metadata.name\n          toFieldPath: metadata.name\n          transforms:\n            - type: string\n              string:\n                fmt: \"%s-redis\"         \n      readinessChecks: \n      - type: MatchString\n        fieldPath: status.atProvider.state\n        matchString: deployed\nUsing the compositeTypeRef property, we are linking \nDatabase CompositeResourceDefinition to this composition.\nInside the resources array, we \ncan define all the resources this \ncomposition will provision. It is \nquite common to have more \nthan one resource here. For \nthis example, we are \nconfiguring a single resource of \ntype Release defined in the \nCrossplane Helm provider.\nWe need to provide the values \ndefined for the Release \nresource, in this case, the Helm \nChart details that we want to \ninstall using the Crossplane \nHelm provider. As you can see, \nwe are pointing to the Redis \nHelm Chart hosted by Bitnami.\nUsing the providerConfigRef, \nwe can target different \nCrossplane Helm provider \nconfigurations. This means \nwe can have different Helm \nproviders pointing to \ndifferent target clusters, and \nthis composition can select \nwhich one to use. For the \nsake of simplicity, this \ncomposition uses the default \nconfiguration for the local \nHelm provider installation.\nBecause we are wiring multiple \nresources, we can patch resources to \nconfigure them to work together or to \napply the parameters of the requested \nresource. Check the Crossplane \ndocumentation for more details on what \ncan be achieved with these mechanisms.\nFor each composition, we can define a condition to flag the \nresource status. For this example, we will mark the \ncomposition as ready when the Helm Release resource status \n.atProvider.state property is set to deployed. If you are \nprovisioning multiple resources, you, as the person defining \nthe composition, will need to define what this condition is.\n",
      "content_length": 2784,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 162,
      "content": "\t\n143\nInfrastructure for our walking skeleton\nWith this composition, we link our Database claim with a set of resources, in this case, \ninstalling the Redis Helm Chart using the default Helm provider we installed with \nCrossplane in our Kubernetes cluster. Figure 5.12 shows two user requests for the same \ndatabase type. \nUsers request as \nmany Database \nresources as \nthey want\nkeyvalue.db.local.salaboy.com\n<Composition>\ndatabases.salaboy.com\n<Composite Resource \nDefinition>\nmy-db\n<Database>\nmy-db-2\n<Database>\nRedis Helm Chart\nVersion: 17.6.0\nInstall using the \nHelm Provider\nFigure 5.12    Crossplane composition and Composite Resource Definition working together\nIt is important to note that this Helm Chart will be installed in the same Kubernetes \ncluster where Crossplane is installed. Still, nothing stops us from configuring the Helm \nprovider to have the right credentials to install charts to a completely different cluster.\nIn the step-by-step tutorial (https://github.com/salaboy/platforms-on-k8s/tree/\nmain/chapter-5), you will install the three Composite Resource Definitions and three \ncompositions. Once these are installed, as shown in figure 5.12, you can request new \ndatabases and message brokers, and for every request, all the resources defined in the \ncomposition will be provisioned. For the sake of simplicity, the key-value database com-\nposition just installs Redis, but there are no limits on how many resources you can cre-\nate (except for the available hardware or quotas you have). \nA Database resource is just another Kubernetes resource that now our cluster \nunderstands, and it looks like listing 5.8. \nListing 5.8    Teams create database resources to request new database instances\napiVersion: salaboy.com/v1alpha1\nkind: Database\nmetadata:.  name: my-db-keyavalue\nspec:\n  compositionSelector:\n    matchLabels: \n      provider: local\n      type: dev\n      kind: keyvalue\n  parameters: \n    size: small\n    mockData: false\n    \nThe unique name \nfor the resource\nWe use matchLabels to select \nthe appropriate composition.\nWe need to set the parameters that are \nrequired by our Database resource claim.\n",
      "content_length": 2140,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 163,
      "content": "144\nChapter 5  Multi-cloud (app) infrastructure \nThe schema for this Database resource is defined inside the Crossplane Composite \nResourceDefinition. Notice that the spec.compositionSelector.matchLabels \nmatches with the labels used for the composition. We can use this mechanism to select \na different composition for the same Database definition. \nIf you are following the step-by-step tutorial, try to create multiple resources and look \nat the Crossplane official documentation to understand how to implement parameters \nlike small or mockData because these values are not being used yet and only serve for \ndemonstration purposes.\nThe real power of these mechanisms comes when you have different compositions \n(implementations) for the same interface (Composite Resource Definition). For exam-\nple, we can now create another composition to provision PostgreSQL instances for the \nCall for Proposals service, as shown in listing 5.9. The PostgreSQL composition will look \nsimilar to the one for Redis, but it will install the PostgreSQL helm chart instead. \nListing 5.9    SQL Database Crossplane Composition\napiVersion: apiextensions.crossplane.io/v1\nkind: Composition\nmetadata:\n  name: sql.db.local.salaboy.com \n  labels:\n    type: dev\n    provider: local\n    kind: sql \nspec:\n  ...\n  compositeTypeRef:\n    apiVersion: salaboy.com/v1alpha1\n    kind: Database\n  resources:\n    - name: postgresql-helm-release\n      base:\n        apiVersion: helm.crossplane.io/v1beta1\n        kind: Release\n        spec:\n          forProvider:\n            chart: \n              name: postgresql\n              repository: https://charts.bitnami.com/bitnami\n              version: \"12.2.7\"\n          providerConfigRef:\n            name: default \n          …\nLet’s look at how to create a PostgreSQL instance using this composition. Creating a \nPostgreSQL instance will look pretty similar to what we did before for Redis, as shown \nin listing 5.10. \nWe need a \nunique name for \nour composition, \nso we can \ndifferentiate it \nfrom the \nkeyvalue \ncomposition that \nwe used for \nRedis.\nWe use a different \nlabel to describe this \ncomposition, notice \nthat the provider is the \nsame as before.\nWe want to install the \nPostgreSQL Helm Chart \nhosted by Bitnami.\n",
      "content_length": 2243,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 164,
      "content": "\t\n145\nInfrastructure for our walking skeleton\nListing 5.10    Database resource with kind: sql label to select implementation\napiVersion: salaboy.com/v1alpha1\nkind: Database\nmetadata:\n  name: my-db-sql\nspec:\n  compositionSelector:\n    matchLabels:\n      provider: local\n      type: dev\n      kind: sql\n  parameters: \n    size: small\n    mockData: false\nWe are just using labels to select which composition will be triggered for our Database \nresource. Figure 5.13 shows these concepts in action. Notice how labels select the right \ncomposition based on the kind label value. \nRedis Helm Chart\nPostgreSQL Helm Chart\nkeyvalue.db.local.salaboy.com\n<Composition>\nLabels: \nkind: keyvalue\nprovider: local\nmy-db-kv\n<Database>\nLabels: \nkind: keyvalue\nprovider: local\ndatabases.salaboy.com\n<Composite Resource \nDefinition>\nmy-db-sql\n<Database>\nLabels: \nkind: sql\nprovider: local\nsql.db.local.salaboy.com\n<Composition>\nLabels: \nkind: sql\nprovider: local\nFigure 5.13    Selecting compositions using labels\nHooray! We can create databases! But of course, this doesn’t stop here. If you have \naccess to a cloud provider, you can provide compositions that create database instances \ninside the cloud provider, and this is where Crossplane shines.  \nIf we use the Google Cloud Platform (GCP) as an example, for compositions that \nuse cloud resources from GCP, you will need to install the Crossplane GCP provider \nand configure it accordingly, as explained in the official Crossplane documentation: \nhttps://docs.crossplane.io/latest/getting-started/provider-gcp/. \nThe unique name used for the \nPostgreSQL database.\nWe use the “sql” label to match the \npreviously defined composition.\n",
      "content_length": 1671,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 165,
      "content": "146\nChapter 5  Multi-cloud (app) infrastructure \nmy-db-kv\n<Database>\nLabels: \nkind: keyvalue\nprovider: local\nmy-db-cloud-kv\n<Database>\nLabels: \nkind: keyvalue\nprovider: cloud\ndatabases.salaboy.com\n<Composite Resource \nDefinition>\nkeyvalue.db.local.salaboy.com\n<Composition>\nLabels: \nkind: keyvalue\nprovider: local\nkeyvalue.db.cloud.salaboy.com\n<Composition>\nLabels: \nkind: keyvalue\nprovider: cloud\nRedis Helm Chart\nGCP MemoryStore (Redis)\nCrossplane will \nuse the \nconfigured GCP \nProvider\nFigure 5.14    Selecting compositions using different providers, still using labels\nWe can still select different providers by matching labels with our desired composition. \nBy changing a label in figure 5.14, we can use the local Helm Provider or the GCP pro-\nvider to instantiate a Redis Instance.\nNOTE  Check the community–contributed AWS compositions for this example \nusing the Crossplane AWS Provider at https://github.com/salaboy/platforms \n-on-k8s/tree/main/chapter-5/aws. \nThen, creating new database resources that will be provisioned in the Google Cloud \nPlatform will look like listing 5.11. \nListing 5.11    Requesting a new SQL database\napiVersion: salaboy.com/v1alpha1\nkind: Database\nmetadata:\n  name: my-db-cloud-sql\nspec:\n  compositionSelector:\n    matchLabels:\n      provider: gcp\n      type: dev\n      kind: sql\n  parameters: \n    size: small\n    mockData: false\nNo matter where our databases or other application infrastructure components are \nprovisioned, we can connect our application’s services by following some conven-\ntions. We can use the resource name (for example, my-db-cloud-sql) to know which \nKubernetes service will be used for service discovery. We can also use the created secret \nto obtain the credentials that we will need to connect.  \nThe unique name for our \nresource needs to be different \nfrom all the ones used before.\nThe provider label selects the composition labeled with \nprovider: gcp. In other words, with this label, we select \nwhere the database will be provisioned.\nThe kind label allows us to select which \nkind of database we want to provision.\n",
      "content_length": 2091,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 166,
      "content": "\t\n147\nInfrastructure for our walking skeleton\nThe step-by-step tutorial also provides a CompositeResourceDefinition for mes-\nsage brokers and a composition that installs the Kafka Helm chart that you can find at \nhttps://github.com/salaboy/platforms-on-k8s/blob/main/chapter-5/resources/app \n-messagebroker-kafka.yaml. \nOne really important thing to consider for this example is that Google Cloud Plat-\nform doesn’t provide a managed Kafka service. This pushes your team to decide to \nreplace Kafka when the application is going to be deployed on Google Cloud Platform, \ninstall and manage Kafka on Google Cloud compute or hire a third-party service. In the \nAWS example, we have a Kafka–managed service that we can use, so there is no need to \nchange our application code. But still, wouldn’t it be nice to abstract away how we con-\nnect to these infrastructure services? More on this in chapter 7.\nFigure 5.15 shows how easy it is to provide a Composite Resource Definition for key/\nvalue databases that can be provisioned locally using Helm or managed by a cloud pro-\nvider. But in the case of Kafka, it gets a bit trickier because you might need to inte-\ngrate with a third-party service or take the lead in having a team to manage the Kafka \ninstance(s).\nkeyvalue.db.local.salaboy.com\n<Composition>\nkeyvalue.db.cloud.salaboy.com\n<Composition>\nkafka.mb.local.salaboy.com\n<Composition>\n???.mb.cloud.salaboy.com\n<Composition>\ndatabases.salaboy.com\n<Composite Resource \nDefinition>\nmessagebrokers.salaboy.com\n<Composite Resource \nDefinition>\nmy-db\n<Database>\nmy-mb\n<MessageBroker>\nRedis Helm Chart\nGCP MemoryStore (Redis)\nKafka Helm Chart\nCloud Service\nFigure 5.15    Compositions push teams to define which Cloud services are available for our applications \nto use.\nBesides Kafka and Google Cloud Platform, your teams will need a strategy to deal with \ninfrastructure across cloud providers, or at least make conscious choices about how to \ndeal with situations like this. From the application’s services perspective, would you \n",
      "content_length": 2031,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 167,
      "content": "148\nChapter 5  Multi-cloud (app) infrastructure \nmaintain two copies of the same service if you decide to swap Kafka and use Google \nPubSub instead? One includes the Kafka dependencies, and the other includes the \nGoogle GCP SDKs to connect to Google PubSub. If you only use Google PubSub, you \nlose the ability to run the application outside Google Cloud. \n5.3.1\t\nConnecting our services with the new provisioned infrastructure\nWhen we create new database or message broker resources, Crossplane will monitor \nthe status of these Kubernetes resources against the status of the provisioned compo-\nnents inside the specific cloud provider, keeping them in sync and ensuring that the \ndesired configurations are applied. This means that Crossplane will make sure that our \ndatabases and message brokers are up and running. If for some reason that changes, \nCrossplane will try to reapply the configurations that we requested until what we \nrequested is up and running. \nIf we don’t have the application deployed in our KinD cluster, we can deploy it with-\nout installing PostgreSQL, Redis, and Kafka. As we have seen in chapter 2, this can be \ndisabled by setting one flag: install.infrastructure=false:\n> helm install conference oci://docker.io/salaboy/conference-app  \n➥--version v1.0.0 --set install.infrastructure=false\nI strongly recommend you check out the step-by-step tutorial that you can find at \nhttps://github.com/salaboy/platforms-on-k8s/tree/main/chapter-5 to get your hands \ndirty with Crossplane and the Conference application. The best way to learn is by \ndoing!\nIf we just run this command, no components (Redis, PostgreSQL, or Kafka) will be \nprovisioned by Helm. Still, the application’s services will not know where to connect to \nthe Redis, PostgreSQL, and Kafka instances we created using our Crossplane composi-\ntions. We need to add more parameters to the application chart, so the services know \nwhere to connect. First, check which databases you have available in your cluster as in \nlisting 5.12. \nListing 5.12    Listing all database resources\n> kubectl get dbs\nNAME              SIZE     KIND       SYNCED   READY   COMPOSITION                     \nmy-db-keyavalue   small    keyvalue   True     True    keyvalue.db.local.salaboy.com   \nmy-db-sql         small    sql        True     True    sql.db.local.salaboy.com        \nThe tutorial also guides you to create a MessageBroker and checks that you have one \ninstance of that too, as in listing 5.13. \nListing 5.13    Listing all MessageBroker resources\n> kubectl get mbs\nNAME          SIZE    KIND    SYNCED   READY   COMPOSITION                  \nmy-mb-kafka   small   kafka   True     True    kafka.mb.local.salaboy.com   \nListing 5.14 shows the Kubernetes pods for our database instances and our message \nbroker.\n",
      "content_length": 2796,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 168,
      "content": "\t\n149\nInfrastructure for our walking skeleton\nListing 5.14    Pods for our application infrastructure\n> kubectl get pods\nNAME                             READY   STATUS    RESTARTS   AGE\nmy-db-keyavalue-redis-master-0   1/1     Running   0          25m\nmy-db-sql-postgresql-0           1/1     Running   0          25m\nmy-mb-kafka-0                    1/1     Running   0          25m\nAlong with the pods, four Kubernetes secrets were created: two to store the Helm \nreleases used by our Crossplane compositions and two containing our new databases \npasswords that our applications will need to use to connect (see listing 5.15).\nListing 5.15    Kubernetes secrets containing credentials to connect to our Databases\n> kubectl get secret\nNAME                                    TYPE                 DATA   AGE\nmy-db-keyavalue-redis                   Opaque               1      26m\nmy-db-sql-postgresql                    Opaque               1      25m\nsh.helm.release.v1.my-db-keyavalue.v1   helm.sh/release.v1   1      26m\nsh.helm.release.v1.my-db-sql.v1         helm.sh/release.v1   1      25m\nsh.helm.release.v1.my-mb-kafka.v1       helm.sh/release.v1   1      25m\nTake a look at the services available in the default namespace after we provisioned our \ndatabases, see Listing 5.16: \nListing 5.16    Custom values.yaml file to connect with new infrastructure\n> kubectl get services\nNAME                           TYPE        CLUSTER-IP       PORT(S)\nkubernetes                     ClusterIP   10.96.0.1        443/TCP\nmy-db-keyavalue-redis-headless ClusterIP   None             6379/TCP\nmy-db-keyavalue-redis-master   ClusterIP   10.96.49.121     6379/TCP\nmy-db-sql-postgresql           ClusterIP   10.96.129.115    5432/TCP\nmy-db-sql-postgresql-hl        ClusterIP   None             5432/TCP\nmy-mb-kafka                    ClusterIP   10.96.239.45     9092/TCP\nmy-mb-kafka-headless           ClusterIP   None             9092/TCP\nWith the database and message broker service names and secrets, we can configure our \nconference application chart to not only not deploy Redis, PostgreSQL, and Kafka but \nalso to connect to the right instances by running the following command:\n> helm install conference oci://docker.io/salaboy/conference-app  \n➥--version v1.0.0 -f app-values.yaml\nInstead of setting all the parameters in the command, we are using a file for the values \nto be applied to the chart. For this example, the app-values.yaml file looks like listing \n5.17. \n",
      "content_length": 2473,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 169,
      "content": "150\nChapter 5  Multi-cloud (app) infrastructure \nListing 5.17    Helm Chart customized values.yaml file\ninstall:\n  infrastructure: false\nfrontend:\n  kafka:\n    url: my-mb-kafka.default.svc.cluster.local\nagenda:\n  kafka:\n    url: my-mb-kafka.default.svc.cluster.local\n  redis:\n    host: my-db-keyavalue-redis-master.default.svc.cluster.local\n    secretName: my-db-keyavalue-redis\nc4p:\n  kafka:\n    url: my-mb-kafka.default.svc.cluster.local\n  postgresql:\n    host: my-db-sql-postgresql.default.svc.cluster.local\n    secretName: my-db-sql-postgresql\nnotifications:\n  kafka:\n    url: my-mb-kafka.default.svc.cluster.local\nIn this app-values.yaml file, we are not only turning off the Helm dependencies for \nPostgreSQL, Redis, and Kafka, but we are also configuring the variables needed for \nthe services to connect to our newly provisioned databases. Notice that if the data-\nbases were created in a different namespace or with a different name, the kafka.\nurl, postgresql.host and redis.host should contain the appropriate name-\nspace in the fully qualified name of the service, for example, my-db-sql-postgresql \n.default.svc.cluster.local (where default is the namespace). \nFigure 5.16 shows the Conference application services connecting to the application \ninfrastructure that was created with Crossplane. The boundaries between the developer \nrealm and the platform team become more defined now, as developers interested in \ngetting the infrastructure that they need have a set of options that are carefully selected \nby the platform team and exposed to developers using simpler interfaces.\nWe disable the Redis, PostgreSQL, and Kafka Helm \ndependencies. These components will not be \ninstalled when we install the application.\nWe use the Kubernetes \nservice created for our \nKafka cluster to \nconnect all the \napplication services to \nthe created instance. \nThe same approach is \nused for Redis and \nPostgreSQL.\nFor both Redis and PostgreSQL, \na Kubernetes secret is created \nby the composite resource. Our \nHelm Chart understands how to \nget the credentials from the \nsecret, so we only need to \nspecify the secret name.\n",
      "content_length": 2126,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 170,
      "content": "\t\n151\nInfrastructure for our walking skeleton\nkeyvalue.db.local.salaboy.com\n<Composition>\nLabels: \nkind: keyvalue\nprovider: local\nkeyvalue.db.cloud.salaboy.com\n<Composition>\nLabels: \nkind: keyvalue\nprovider: cloud\nkafka.mb.local.salaboy.com\n<Composition>\ndatabases.salaboy.com\n<Composite Resource \nDefinition>\nmessagebroker.\nsalaboy.com\n<Composite Resource \nDefinition>\nmy-db-keyvalue\n<Database>\nmy-db-sql\n<Database>\nmy-mb-kafka\n<MessageBroker>\nCall for Proposals Service\nAgenda Service\nNotifications Service\nRedis Helm Chart\nGCP MemoryStore (Redis)\nKafka Helm Chart\nPlatform \nEngineer\nDevelopers\nFigure 5.16    Enabling different teams to work together and focus on their tasks at hand\nAll this effort enables us to split the responsibility of defining, configuring, and run-\nning all the application infrastructure to another team not responsible for working \non the application’s services. Services can be released independently without worrying \nabout which databases are being used or when they need to be upgraded. Developers \nshouldn’t be worrying about cloud provider accounts or if they have access to create \ndifferent resources. Hence, another team with a completely different set of skills can \ntake care of creating Crossplane compositions and configuring Crossplane providers. \nWe have also enabled teams to request application infrastructure components by \nusing Kubernetes resources. This enables them to create their setups for experimen-\ntation and testing or to set up new instances of the application quickly. This is a major \nshift in how we (as developers) were used to doing things, because before this, cloud \nproviders and most companies must have access to a database and a ticketing system to \nrequest another team to provision that resource for you, which can take weeks! \nTo summarize what we have achieved so far, we can say that:\n¡ We abstracted how to provision local- and cloud-specific components such as \nPostgreSQL and Redis databases and message brokers such as Kafka and all the \nconfigurations needed to access these new instances. \n¡ We exposed a simplified interface for the application teams that is cloud-pro-\nvider independent because it relies on the Kubernetes API. \n¡ Finally, we connected our application service to the newly provisioned instances \nby relying on Kubernetes Secrets created by Crossplane, containing all the details \nrequired to connect to the newly created instances. \n",
      "content_length": 2434,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 171,
      "content": "152\nChapter 5  Multi-cloud (app) infrastructure \nIf you use mechanisms like Crossplane compositions to create higher-level abstrac-\ntions, you will create domain-specific concepts that your teams can consume using a \nself-service approach. We have created our database and message broker concept by \ncreating a Crossplane Composite Resource that uses Crossplane compositions that \nknows which resources to provision (and in which cloud provider). \nNOTE    You can follow a step-by-step tutorial that covers all the steps described \nin this section at https://github.com/salaboy/platforms-on-k8s/tree/main/\nchapter-5. \n5.4\t\nLinking back to platform engineering\nWe need to be cautious. We cannot expect every developer to understand or be willing \nto use tools like the ones we have discussed (Crossplane, ArgoCD, Tekton, etc.). We \nneed a way to reduce the complexity these tools introduce. Platforms are meant to \nreduce the cognitive load of their users, as described in chapter 1 when we looked at \nGoogle Cloud Platform and how it enables teams to create a Kubernetes cluster with a \nfew clicks. For GCP and other platforms, the users interacting with the platform don’t \nneed to understand what is going on under the covers, what tools are being used, or \nthe design of the entire platform to use it. \nCrossplane was created to serve both platform teams and development teams (or \nconsumers), which have different priorities, interests, and skills. By creating the right \nabstractions (XRDs) the platform team can expose simple resources that development \nteams can configure according to their needs, while behind the covers, a complex \ncomposition is being set up to create and wire together a group of cloud resources. \nWe have also seen how by using labels and selectors, we can choose between different \ncompositions, enabling the creation of infrastructure in different cloud providers but \nkeeping the same user experience for the teams creating the requests. Crossplane, by \nextending the Kubernetes APIs, unifies how we manage our workloads and how we can \nmanage application infrastructure across cloud providers. In other words, if we install \nCrossplane into a Kubernetes cluster, we cannot only deploy and run our clusters but \nalso provision and manage cloud resources by using the same tooling that we use for \nour workloads. \nWith all the goodies that Crossplane brings, you must also be ready for some draw-\nbacks and challenges. Platform teams looking into Crossplane have other more popu-\nlar options available to provision cloud resources, such as Hashicorp’s Terraform and \nPulumi. Crossplane is much more recent than Terraform, and because Crossplane is \nfocused on Kubernetes, it requires platform teams to be fully invested in Kubernetes. \nTeams not used to managing Kubernetes clusters will find tools like Crossplane chal-\nlenging at first, so you need to level up your Kubernetes skills to run and maintain a tool \nlike Crossplane. \nPlatform teams will be forced to make a decision about using Crossplane or tools like \nTerraform, and my recommendation is to think about how much you want to align the \n",
      "content_length": 3134,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 172,
      "content": "\t\n153\nLinking back to platform engineering\ntools that you are using with the Kubernetes APIs. Being able to manage infrastructure \n(cloud resources) in the same way that we manage our applications makes a lot of sense \nin theory. Still, it also needs to make sense to the teams managing and maintaining \nthese components up and running. In the last couple of years, there has been a huge \nincrease in maturity around observability, security, and operations in the cloud-native \nspace. More and more teams are feeling comfortable with managing and operating \nKubernetes at scale. For those teams, Crossplane can be a great addition, because it is \ngoing to work with all their existing Kubernetes observability stacks, policy enforcers, \nand dashboards. \nWhen having tools as flexible as Crossplane, you open the door to new possibilities \nthat can span across cloud providers. Platform teams now have more options available, \nand that can be counterproductive, but one thing is clear. If you use the right abstrac-\ntions, the platform can be flexible, as consumer interfaces will not change. At the same \ntime, the platform team can iterate on their previous decisions and provide new imple-\nmentations behind the covers. \nFigure 5.17 shows how by using Crossplane, we can provide self-service abstractions \nfor development teams to consume. They can request databases, message brokers, \nidentity services, and any other internal or external services they might need for their \napplications. But what do they need from an application perspective? Think about the \nKafka example provided before. What needs to change in your applications if you move \nfrom Kafka to Google PubSub?\nWhat do I need in \nmy applications to \nconsume these \nservices?\nDevelopers\nPlatform \nEngineer\nImplementations\nApplications\nDatabases as a \nService\nMessage Brokers as a \nService\nIdentity as a Service\nX as a Service\nFigure 5.17    What do developers need to consume all these Platform services?\nWe have covered a lot of ground so far, from installing a simple application into a clus-\nter to building services and deploying them using a GitOps approach and now provi-\nsioning application infrastructure declaratively. Figure 5.18 shows how using a GitOps \napproach we can define not only which services/applications should be running inside \nan environment, but also which cloud resources need to be provisioned and wired to \nour application services.\n",
      "content_length": 2429,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 173,
      "content": "154\nChapter 5  Multi-cloud (app) infrastructure \nEnvironments \nConfiguration \nRepository\nEnvironment configurations \ncan include definitions to \nprovision cloud resources \nand how to wire them to our \napplication’s services.\nGitOps Sync\nProvisioning \nCloud Resources\nEnvironment\nApplication\nDatabases\nMessage Brokers\nMessage Broker\nDatabase\nCloud Provider\nFigure 5.18    Provisioning application infrastructure using a declarative GitOps approach\nIt is time to put everything together into a platform, because it doesn’t make too much \nsense to have our applications running in the same cluster where our pipelines and \nother tools are running. What would a platform on top of Kubernetes look like? What \nare the main challenges that your teams will face when trying to build one? There is \nonly one way to find out: Let’s build a platform on top of Kubernetes! \nSummary\n¡ Cloud-native applications depend on application infrastructure to run, as each \nservice might require different persistent storages, a message broker to send mes-\nsages, and other components to work.\n¡ Creating application infrastructure inside cloud providers is easy and can save us \na lot of time, but then we rely on their tools and ecosystem.\n¡ Provisioning infrastructure in a cloud-agnostic way can be achieved by relying \non the Kubernetes API and tools like Crossplane, which abstracts the underly-\ning cloud provider and lets us define which resources must be provisioned using \nCrossplane compositions.\n¡ Crossplane provides support for major cloud providers. It can be extended for \nother service providers, including third-party tools that might not be running \non cloud providers (for example, legacy systems we want to manage using the \nKubernetes APIs). \n¡ By using Crossplane Composite Resource Definitions, we create an interface \nthat application teams can use to request cloud resources using a self-service \napproach.\n¡ If you followed the step-by-step tutorial, you got hands-on experience on how \nto provision application infrastructure using a multi-cloud approach using \nCrossplane.\n",
      "content_length": 2081,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 174,
      "content": "155\n6\nLet’s build a platform \non top of Kubernetes\nThis chapter covers\n¡ Identifying features that platforms should  \n\t provide on Kubernetes\n¡ Learning the challenges with multi-cluster and \t\n\t multi-tenant setups\n¡ Seeing what a platform on top of Kubernetes \t\n\t looks like\nSo far, we have looked at what platform engineering is, why we need to think about \nplatforms in the context of Kubernetes, and how teams must choose the tools they \ncan use from the CNCF landscape (chapter 1). Then we jumped into figuring out \nhow our applications would run on top of Kubernetes (chapter 2), and how to build, \npackage, and deploy (chapters 3 and 4), and connect these applications to other \nservices that they need to work (chapter 5). This chapter puts all the pieces together \nto create a walking skeleton for our platform. We will use some of the open-source \nprojects introduced in the previous chapters and new tools to solve some of the \nchallenges we will face when creating the first iteration of our platform. This chap-\nter is divided into three main sections: \n",
      "content_length": 1067,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 175,
      "content": "156\nChapter 6  Let’s build a platform on top of Kubernetes \n¡ The importance of the platform APIs\n¡ Kubernetes platform architecture and how we can architect a scalable platform \ndespite multi-tenancy and multi-cluster challenges \n¡ Introducing our platform walking skeleton and learning how to build a platform \non top of Kubernetes\nLet’s start by considering why defining the platform APIs is the first step to platform \nbuilding. \n6.1\t\nThe importance of the platform APIs\nIn chapter 1, we looked at existing platforms, such as Google Cloud Platform, to under-\nstand what key features they offer to teams building and running cloud applications. \nWe now need to compare this to the platforms that we are building on top of Kuberne-\ntes, because these platforms share some common goals and features with cloud provid-\ners while at the same time being closer to our organizations’ domains. \nPlatforms are nothing other than software that we will design, create, and maintain. \nAs with any good software, our platform will evolve to help teams with new scenarios, \nmake our teams more efficient by providing automation, and give us the tools to make \nthe business more successful. As with any other software, we will start by looking at the \nplatform APIs, which will provide us with a manageable scope to start with and define \nthe contracts and behaviors our platform will provide its users. \nFigure 6.1 shows how the platform APIs are the main entry point for consumers of \nthe platform—in this case, developers. These APIs should hide away the complexity of \nthe tools, decisions, supported workflows, and golden paths that the platform provides \nto its users while at the same time offering a self-service place for teams to get what they \nneed.\nPlatform APIs\nOur Platform V1.2\nPlatform \nEngineer\nTools, Decisions, Supported \nWorkflows, Golden Paths\nDevelopers\nFigure 6.1    The platform engineering team is responsible for platform APIs.\n",
      "content_length": 1943,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 176,
      "content": "\t\n157\nThe importance of the platform APIs\nOur platform APIs are important, because good APIs can simplify the life of develop-\nment teams wanting to consume services from our platform. If our platform APIs are \nwell designed, more tailored tools like CLIs, SDKs, or even user interfaces can be cre-\nated to assist users in consuming our platform services. \nIf we build custom and more domain-specific APIs for our platform, we can start by \ntackling one problem at a time and then expand these APIs/interfaces to cover more \nand more workflows, even for different teams. Once we understand which workflows we \nwant to cover and have an initial platform API dashboard, more tooling can be created \nto help teams adopt the platform.  \nLet’s use an example to make it more concrete. I hope you can translate the example \nI am showing here into more concrete examples inside your organization. All the mech-\nanisms should apply in the same way. Let’s enable our development teams to request \nnew development environments. \n6.1.1\t\nRequesting development environments\nA common scenario where a platform can help teams get up to speed when they start \nworking on new features is provisioning them with all they need to do their work. To \nachieve this task, the platform engineering team must understand what they will work \non, what tools they need, and which other services must be available to succeed. \nOnce the platform engineering team understands what development teams require, \nthey can define an API to provision new development environments on demand. \nBehind these APIs, the platform has the mechanisms to create, configure, and provide \naccess for the requesting team to connect. \nFor our Conference application example, if a development team is extending the \napplication, we (the platform engineering team) must ensure they have a running ver-\nsion to work against and test changes. This isolated application instance will also need \nits databases and other infrastructural components to work. More advanced use cases \ninclude loading the application with mock data, allowing teams to test their changes \nwith pre-populated data, and having the right tools to verify the changes. The inter-\nactions between the application development team and the platform should look like \nfigure 6.2. \nApp Dev Team\nPlatform\nDevelopment \nEnvironment\nAPIs\n1\n2\n3\nFigure 6.2    Application development team interactions with the platform . #1 App dev teams can \nrequest as many Development Environments as they need to the platform APIs; #2 The platform has \nencoded how to provision all the components and tools needed for the app dev team to work; #3 The \nplatform needs to give access to the app dev team to use the newly provisioned environment.\n",
      "content_length": 2739,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 177,
      "content": "158\nChapter 6  Let’s build a platform on top of Kubernetes \nAs mentioned before, development environments are just an example. You must ask \nyourself what tools your teams need to do their work. A development environment \nmight not be the best way to expose tools to a team of data scientists, for example, \nbecause they might need other tools to gather and process data or train machine learn-\ning models. \nImplementing this simple flow in Kubernetes is not an easy task. To implement this \nscenario, we need to: \n¡ Create new APIs that understand development environment requests.\n¡ Have the mechanisms to encode what a development environment means for \nour teams.\n¡ Have the mechanisms to provision and configure components and tools.\n¡ Have the mechanisms to enable teams to connect to the newly provisioned \nenvironments.\nThere are several options for implementing this scenario, including creating custom \nKubernetes extensions or using more specialized tools for development environments. \nBut before diving into implementation details, let’s define what our platform API \nwould look like for this scenario.\nAs with object-oriented programming (OOP), our APIs are Interfaces that can \nbe implemented by different Classes, which finally provide concrete behavior. For \nprovisioning development environments, we can define a very simple interface called \nEnvironment. Development teams requesting a new development environment can \ncreate new requests to the platform by creating new environment resources. The Envi-\nronment interface represents a contract between the user and the platform. This con-\ntract can include parameters to define the type of environment the team is requesting \nor options and parameters they need to tune for their specific request. \nFigure 6.3 shows the simplest environment definition, which includes a name for \nthe environment and the kind of environment that we want to create (we might enable \nteams to request different setups, and for this example, we want a new development \nenvironment). The environment definition also includes custom configurations that \nmake sense for the consuming team to parameterize. In this case, because we will install \nthe Conference application, we want to enable teams to decide if the infrastructure \ncomponents need to be installed or not. \nEnvironment\nName: team-a-env\nParameters:\n • Type: development\n • InstallInfra: true\nPlatform APIs\nMechanisms to \nunderstand \nEnvironments\nFigure 6.3    Environment resource defined by the Platform API\n",
      "content_length": 2518,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 178,
      "content": "\t\n159\nThe importance of the platform APIs\nIt is important to note that the Environment interface shouldn’t include (or leak) \nany implementation details about our environments. These resources (environments \nin this case) serve as our abstraction layer to hide complexity from our platform users \nabout how these environments will be created. The simpler these resources are, the \nbetter for the platform users. In this example, the platform can use the Environment \nType parameter to decide which environment to create, and we can plug in new types \nas we evolve our platform mechanisms. \nOnce we recognize which interfaces we need, we can slowly add parameters that \nteams can configure. For our example, it might make sense to parameterize some fea-\ntures for the services we want to deploy in our environment if we also want the appli-\ncation infrastructure to be created or to connect our services to existing components. \nFigure 6.4 shows the definition of an environment that requires the platform to install \nthe application infrastructure that the services need. We also want to enable some \ndebug features on our Frontend service. The possibilities here are endless, depending \non what makes sense for your teams to parameterize. The platform team can control \nwhat is possible and what is not. Expanding the environment interface to cover more \nuse cases can look like f﻿iigure 6.4. \nEnvironment\nName: team-a-env\nParameters\n • Type: development\n • InstallInfra: true\n • Frontend: \n        Debug: enabled\nPlatform API\no\nFigure 6.4    Extended environment resource to enable/disable the application’s services.\nEncoding this environment resource into a format like JSON or YAML to implement \nthe platform API is straightforward, as shown in listing 6.1. \nListing 6.1    Environment definition in JSON format\n{\n  \"name\": \"my-dev-env\",\n  \"parameters\":{\n    \"type\": \"development\",\n    \"installInfra\": true,\n    \"frontend\": {\n      \"debug\": \"true\",\n    }\n  }\n}\nOnce the interface is defined, the next logical step is to provide one implementation \nto provision these environments for our platform users. Before jumping into imple-\nmentation details, we need to cover two of the main challenges you will face when \ndeciding where the mechanisms for implementing these environments will reside. \n",
      "content_length": 2299,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 179,
      "content": "160\nChapter 6  Let’s build a platform on top of Kubernetes \nNOTE   When building these interfaces, we are designing user experiences. \nFrom a platform engineering perspective, consider these interfaces as layers \nwe are building to simplify how teams interact with our platform. But it is also \nimportant to recognize that we are not trying to build a black-box approach \nwhere this interface is the only way of interacting with our platform. If teams \nhave the technical experience to interact with the underlying layers and tools, \nthey should be able to do so.\n6.2\t\nPlatform architecture\nThis section discusses how we’ll architect our platform. On the technical side of build-\ning platforms, we will encounter challenges requiring the platform team to make some \nhard choices. In this section, we will talk about how we can architect a platform that \nallows us to encapsulate a set of tools behind our platform APIs and enable develop-\nment teams to perform their tasks without worrying about which tools are being used \nby the platform to provision and wire up complex resources. \nBecause we are already using Kubernetes to deploy our workloads in the Confer-\nence application, it also makes sense to run the platform services on top of Kubernetes, \nright? But would you run the platform services and components right beside your work-\nloads? Probably not. Let’s step back a bit.\nIf your organization adopts Kubernetes, you will likely already deal with multiple \nKubernetes clusters. As discussed in chapter 4, your organization probably has produc-\ntion, staging, or QA environments already in place. If you want your application devel-\nopment teams to work on environments that feel like the production environment, you \nmust enable them with Kubernetes clusters. \nFigure 6.5 shows a typical distribution of Kubernetes clusters inside an organization, \nwhere tons of small clusters might be created for short periods for development pur-\nposes. One or more mid-size clusters can be used for staging and testing purposes; these \nclusters tend to stay the same as they might be purposefully created to run performance \ntests or a large set of integration tests. Finally, one or more large clusters are created for \nrunning our production workloads. Depending on how many regions we want to cover, \nwe might need multiple production clusters that are geographically distributed. The \nconfiguration of these clusters is static and does not change. In contrast with develop-\nment and testing clusters, production clusters are the responsibility of Site Reliability \nEngineering teams, ensuring that these clusters and the applications running on them \nare up and running 24/7.\nDevelopment \nClusters\nStaging/QA Clusters\nProduction Clusters\nFigure 6.5    \nEnvironment \nclusters, in case \nyou want to enable \ndevelopers to \nhave their own \nenvironments.\n",
      "content_length": 2853,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 180,
      "content": "\t\n161\nPlatform architecture\nWhile the production cluster(s) and staging/QA cluster(s) should be handled care-\nfully and hardened to serve real-life traffic, development environments tend to be \nmore ephemeral and sometimes even run on the development team laptops. Certainly, \nyou don’t want to run any platform-related tools in any of these environments. The \nreason is simple: tools like Crossplane, ArgoCD, or Tekton shouldn’t be competing for \nresources with our application’s workloads. Security considerations might apply too; \nwe don’t want our application’s security compromised due to a vulnerability in our \nplatform tools.\nWhen looking at building platforms on top of Kubernetes, teams tend to create one \nor more special clusters to run platform-specific tools. The terms still need to be stan-\ndardized, but creating a platform or management cluster to install platform-wide tools \nis becoming increasingly popular. \nFigure 6.6 shows how by having separate platform cluster(s), you can install the tools \nthat you need to implement your platform capabilities while at the same time building a \nset of management tools to control environments where your workloads run.\nPlatform\nEnvironment\nEnvironment\nApp \nDev\n<manage>\n<manage>\nFigure 6.6    Platform cluster with platform tools managing environments\nNow that you have a separate place to install these tools, you can also host the platform \nAPI on this cluster, once again, to not overload your workload clusters with platform \ncomponents. Wouldn’t it be great to reuse or extend the Kubernetes API to serve also \nas our platform API? There are pros and cons to this approach. For example, sup-\npose we want our platform API to follow Kubernetes conventions and behaviors. In \nthat case, our platform will use the declarative nature of Kubernetes and promote all \nthe best practices followed by the Kubernetes APIs, such as versioning, the resource \nmodel, etc. This API might be too complex for non-Kubernetes users, or the organi-\nzation might follow other standards when creating new APIs that do not match the \nKubernetes style. If we reuse the Kubernetes APIs for our platform APIs, all the CNCF tools \ndesigned to work with these APIs will automatically work with our platform. Our platform auto-\nmatically becomes part of the ecosystem. In the last couple of years, I’ve seen a trend \naround teams adopting the Kubernetes APIs as their platform APIs. How much you \n",
      "content_length": 2436,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 181,
      "content": "162\nChapter 6  Let’s build a platform on top of Kubernetes \nlean on the Kubernetes APIs is a decision that platform engineering teams will need to \nmake, and there are always tradeoffs.\nFigure 6.7 shows the relationship between having the Kubernetes APIs to use the CNCF \nand cloud-native ecosystem while at the same time exposing an organization-specific API \nthat follows company standards on how APIs should be created. To make sure that the \nmessage is clear, these are not exclusive, and as we will see in section 6.3, it makes a lot \nof sense to have both.\nPlatform\nCompany-specific \ntooling and \nconformance\nCompany Standards \nPlatform API\nKubernetes-based \nPlatform API\nPlatform Internals\nCNCF / \nCloud Native \nEcosystem\nFigure 6.7    \nKubernetes-based \nplatform APIs \ncomplemented by \ncompany-specific \nAPIs\nAdopting the Kubernetes APIs for your platform API doesn’t stop you from building a \nlayer on top for other tools to consume or to follow the company’s standards. By hav-\ning a Kubernetes-based API layer, you can access all the amazing tools created in the \nCNCF and cloud-native space. On top of the Kubernetes-based APIs, another layer can \nfollow company standards and conformance checks, enabling easier integrations with \nother existing systems. \nFollowing our previous example, we can extend Kubernetes to understand our envi-\nronment requests and provide the mechanisms to define how these environments will \nbe provisioned. \nFigure 6.8 shows a Kubernetes resource used to define our environments. This \nresource can be sent to a Kubernetes API server with an installed set of extensions to \nunderstand what to do when a new environment definition arrives. \nKubernetes \nextension to \nunderstand \nEnvironments\nPlatform\nEnvironment\nName: team-a-env\nFigure 6.8    \nExtending \nKubernetes \nto understand \nenvironments \nand serve as our \nplatform APIs\n",
      "content_length": 1870,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 182,
      "content": "\t\n163\nPlatform architecture\nIn principle, this looks good and doable. Still, before implementing these Kubernetes \nextensions to serve as our platform API and central hub of platform tooling, we need \nto understand the questions that our platform implementation will try to answer. Let’s \nlook at the main platform challenges that teams in these scenarios will face. \n6.2.1\t\nPlatform challenges\nSooner or later, if you are dealing with multiple Kubernetes clusters, you must manage \nthem and all the resources related to these clusters. What does it take to manage all \nthese resources? The first step to understanding the underlying problems is to under-\nstand who the users of our platforms are. Are we building a platform for external cus-\ntomers or internal teams? What are their needs and the level of isolation that they need \nto operate autonomously without bothering their neighbors? What guardrails do they \nneed to be successful? \nWhile I cannot answer these questions for all use cases, one thing is clear—plat-\nform tools and workloads need to be separated. We need to encode in our platform \nour tenant boundaries based on each tenant’s expectations. No matter if these ten-\nants are customers or internal teams. We must set clear expectations about our tenancy \nmodel and guarantees for our platform users, so they understand the limitations of the \nresources the platform gives them to do their work. \nThe platform we will build needs to encode all these decisions. In the following two \nsections, we will look at the two most common decisions that platform teams will need \nto make early in their journey: (1) managing more than one cluster and (2) isolation \nand multi-tenancy. \n6.2.2\t\nManaging more than one cluster\nThe platform we will build needs to manage and understand which environments are \navailable for teams. More importantly, it should enable the team to request their own \nenvironments whenever needed. \nUsing the Kubernetes APIs as our platform API to request environments, we can use \ntools like ArgoCD (covered in chapter 4) to persist and sync our environment configu-\nrations to live Kubernetes clusters. Managing our clusters and environments becomes \njust managing Kubernetes resources that must be synced to our platform cluster(s). \nFigure 6.9 shows using two tools that we have already used (Crossplane and ArgoCD) \nfor our Conference application but use now in the context of managing platform-wide \nresources. \nBy combining tools like ArgoCD and Crossplane inside our platform clusters, we \npromote the techniques we discussed in chapter 4 for environment pipelines, which \nsync application-level components which we now use for managing high-level platform \nconcerns. In this case, tools like Crossplane can help us provision full-fledged environ-\nments on cloud providers. \n",
      "content_length": 2818,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 183,
      "content": "164\nChapter 6  Let’s build a platform on top of Kubernetes \nPlatform\nGit\nTeam C \nEnvironment\nTeam B \nEnvironment\nTeam A \nEnvironment\nFigure 6.9    \nCombining GitOps \nand Crossplane \nfor managing \nenvironments and \nclusters\nAs you can see in the previous figure, our platform configuration itself will become \nmore complex, because it will need to have its source of truth (Git repository) to store \nthe environment and resources that the platform manages. It will also need to have \naccess to a secret store, such as HashiCorp Vault, to enable Crossplane to connect and \ncreate resources in different cloud providers. In other words, you now have two extra \nconcerns. First, you will need to define, configure, and give access to one or more Git \nrepositories to contain the configurations for the resources created in the platform. \nSecond, you must manage a set of cloud provider accounts and their credentials so the \nplatform cluster(s) can access and use these accounts. \nIf you can manage all the platform resources like your workloads (using a GitOps \napproach, managing credentials and users, and exposing the right abstractions/APIs), \nthe platform artifacts become just an extension of your development and continuous \ndelivery practices. \nWhile the example in section 6.3 doesn’t focus on configuring all these concerns, it \nprovides a nice playground to build on top and experiment with more advanced setups \ndepending on your teams’ requirements. \nI recommend prioritizing which configurations make sense to understand what your \nteams or tenants will do with the resources, expectations, and requirements. Let’s dig a \nbit more into that space. \n6.2.3\t\nIsolation and multi-tenancy\nDepending on your tenants’ (teams, internal or external customers) requirements, \nyou might need to create different isolation levels, so they don’t disturb each other \nwhen working under the same platform roof. \nMulti-tenancy is a complicated topic in the Kubernetes ecosystem. Using Kubernetes \nRBAC (role-based access control), Kubernetes Namespaces, and multiple Kubernetes \ncontrollers that might have been designed with different tenancy models makes it hard \nto define isolation levels between tenants inside the same cluster.\n",
      "content_length": 2229,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 184,
      "content": "\t\n165\nPlatform architecture\nCompanies embarking on adopting Kubernetes tend to take one of the following \napproaches for isolation: \n¡ Kubernetes Namespaces:\n–\t Pros: \n¡ Creating namespaces is very easy, and it has almost zero overhead.\n¡ Creating namespaces is cheap, because it is just a logical boundary that \nKubernetes uses to separate resources inside the cluster.\n–\t Cons: \n¡ Isolation between namespaces is very basic, and it will require RBAC roles \nto limit users’ visibility outside the namespaces they have been assigned. \nResource quotas must also be defined to ensure that a single namespace is \nnot consuming all the cluster resources.\n¡ Providing access to a single namespace requires sharing access to the same \nKubernetes APIs endpoints that admins and all the other tenants are using. \nThis limits the operations clients can execute on the cluster, such as install-\ning cluster-wide resources.\n¡ All the tenants will be interacting against the same Kubernetes API server, \nwhich might cause problems depending on the scale and the needs of each \nof the tenants. \n¡ Sharing the same Kubernetes API server limits the cluster-wide resources \nthat can be installed in the cluster. For example, installing two different \nversions of the same extensions is not possible. \n¡ Kubernetes clusters: \n–\t Pros: \n¡ Users interacting with different clusters can have full admin capabilities \nenabling them to install as many tools as they need. \n¡ You have full isolation between clusters, and tenants connecting to differ-\nent clusters will not share the same Kubernetes API server endpoints. Each \ncluster can have different configurations for how scalable and resilient they \nare. This allows you to define different tenants’ categories based on their \nrequirements. \n–\t Cons: \n¡ This approach is expensive, as you will be paying for computing resources \nto run Kubernetes. The more clusters you create, the more money you will \nspend running Kubernetes.\n¡ Managing multiple Kubernetes clusters becomes complex if you enable \nteams to create (or request) their own. Zombie clusters (clusters nobody \nuses and are abandoned) start to pop up, wasting valuable resources. \n¡ Sharing resources, installing, and maintaining tools across a fleet of differ-\nent Kubernetes clusters is challenging and a full-time job.\n",
      "content_length": 2319,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 185,
      "content": "166\nChapter 6  Let’s build a platform on top of Kubernetes \nBased on my experience, teams will create isolated Kubernetes clusters for sensitive \nenvironments such as production environments and performance testing. These sen-\nsitive environments tend to stay the same and are only managed by operation and site \nreliability teams. Using a big cluster with namespaces is a common practice when you \nshift towards development teams and more ephemeral environments for testing or \nday-to-day development tasks.\nChoosing between these two options is hard, but what is important is not to overcom-\nmit to just a single option. Different teams might have different requirements, so in the \nnext section, we will look at how the platform can abstract these decisions, enabling \nteams to access different setups depending on their needs.  \nMy recommendation for platform teams making these decisions is to build and have \npractices in place that enable you to pivot from one solution to another. Starting with \nsimple solutions such as namespace isolation is quite common, but after a while, when \nhaving a single cluster with tons of namespaces is not enough, you need a more robust \nplan. To make this decision easier, ask yourself if your consumers need access to the \nKubernetes APIs. If they don’t, you might want to evaluate following an approach sim-\nilar to Google Cloud Run (https://cloud.google.com/run), Azure Container Apps \n(https://azure.microsoft.com/en-us/products/container-apps ), or AWS App Runner \n(https://aws.amazon.com/apprunner/), which enables teams to run containers with-\nout the need of accessing the orchestrator APIs.\n6.3\t\nOur platform walking skeleton\nThis section looks into creating a simple platform allowing internal teams to create \ndevelopment environments. Because our teams are deploying the conference appli-\ncation to Kubernetes clusters, we want to offer them the same developer experience.\nNOTE    You can follow a step-by-step tutorial, where you will install and inter-\nact with the platform walking skeleton at https://github.com/salaboy/\nplatforms-on-k8s/tree/main/chapter-6. \nTo achieve this, we will use some tools that we used before, like Crossplane, to extend \nKubernetes to understand development environments. Then, we will use a project \ncalled vcluster (https://vcluster.com) to provision small Kubernetes clusters for our \nteams. These clusters are isolated, allowing teams to install extra tools without worrying \nabout what other teams are doing. Because teams will have access to the Kubernetes \nAPIs, they can do whatever they need with the cluster without requesting complicated \npermissions to debug their workloads. \nFigure 6.10 shows how the process works. Teams can request new environments by \ncreating environment Kubernetes resources. The platform will take these resources \nand provision small Kubernetes clusters with vcluster for them to use. We will keep \nthings simple for the walking skeleton, but the platforms are complicated.\n",
      "content_length": 2997,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 186,
      "content": "\t\n167\nOur platform walking skeleton\nPlatform\nDevelopment \nEnvironments\nEnvironment\nName: team-a-env\nFigure 6.10    \nBuilding a \nplatform \nprototype \nto provision \ndevelopment \nenvironments\nI can’t stress enough the importance that this example, on purpose, is using existing \ntools instead of creating our custom Kubernetes extensions. If you create custom con-\ntrollers to manage environments, you create a complex component that will require \nmaintenance and probably overlaps 95% with the mechanisms shown in this example. \nIn other words, no custom Kubernetes controllers have been created while building \nthis example. \nIn the same way that we started this chapter talking about our platform APIs, let’s \nlook at how we can build these APIs without creating custom Kubernetes extensions \nthat we will need to test, maintain, and release. We will use Crossplane compositions as \nwe did for our databases and message brokers in chapter 5, but now we will implement \nour environment custom Crossplane Composition Resource Definition. We can keep \nthe environment resource simple and use Kubernetes label matches and selectors to \nmatch a resource with one of the possible compositions we can create to provision our \nenvironments. \nFigure 6.11 shows how changing a property/label from our environment helps \nCrossplane to pick the right composition for our team. \nPlatform API\nEnv Composition\ntype: development\nEnv Composition\ntype: testing\nEnvironment\nName: team-a-env\nLabels:\n • type: development\nFigure 6.11    Mapping environment resources to Crossplane compositions\nCrossplane compositions offer the flexibility to use different providers to provision \nand configure resources together, and as we saw in chapter 5, multiple compositions \n(implementations) can be provided for different kinds of environments. For this \nexample, we want each environment to be isolated from the other to avoid teams unin-\ntentionally deleting others’ team resources. The two most intuitive ways of creating \nisolated environments would be to create a new namespace per environment or a full-\nblown Kubernetes cluster for each environment. \n",
      "content_length": 2129,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 187,
      "content": "168\nChapter 6  Let’s build a platform on top of Kubernetes \nFigure 6.12 shows how another Crossplane provider (called Kubernetes provider) \ncan be used to create Kubernetes resources such as Namespaces. This compares against \nusing a cloud-provider Crossplane provider that enables us to create a full-blown clus-\nter, in this case in Google Cloud Platform (GCP). Once we have a cluster, we can install \nour Conference application Helm Chart.\nEnv Composition\ntype: development\nEnv Composition\ntype: testing\nCrossplane \nKubernetes Provider\nConference \n`Helm Chart`\nConference \n`Helm Chart`\nCrossplane GCP \nProvider\nCrossplane Helm \nProvider\nCrossplane Helm \nProvider\nKubernetes `Namespace`\n`GKECluster`\nFigure 6.12    Different environment compositions, Namespace, and GKECluster\nWhile creating a fully-fledged Kubernetes cluster might be overkill for every develop-\nment team, a Kubernetes Namespace might not provide enough isolation for your use \ncase, because all teams will interact with the same Kubernetes API server. For this rea-\nson, we will use vcluster in conjunction with the Crossplane Helm provider, which \ngives us the best of both worlds without the costs of creating new clusters. Figure 6.13 \nshows how we can reuse the Crossplane Helm provider to create vclusters. \nEnv Composition\ntype: development\nCrossplane Helm \nProvider\nCrossplane Helm \nProvider\nvcluster\n`Helm Chart`\nConference \n`Helm Chart`\nFigure 6.13    Using vcluster to create isolated environments\nYou might be wondering: what is a vcluster? And why are we using the Crossplane \nHelm provider to create one? While vcluster is just another option that you can use \nto build your platforms, I consider it a key tool in every platform engineer toolbox. \n",
      "content_length": 1733,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 188,
      "content": "\t\n169\nOur platform walking skeleton\n6.3.1\t\nvcluster for virtual Kubernetes clusters\nI am a big fan of the vcluster project. If you are discussing multi-tenancy on top of \nKubernetes, vcluster tends to pop up in the conversation, because it offers a really \nnice alternative to the Kubernetes Namespaces vs. Kubernetes clusters discussions. \nvcluster focuses on providing Kubernetes API server isolation between differ-\nent tenants by creating virtual clusters inside your existing Kubernetes cluster (host \ncluster). Figure 6.14 shows how vcluster works inside an existing Kubernetes cluster \n(HOST).\nK8s API Server\nK8s API Server\nK8s API Server\nK8s Scheduler\nK8s API Server\nKubernetes Cluster (HOST)\nvcluster A\nvcluster B\nvcluster C\nFigure 6.14    vcluster provides isolation at the Kubernetes (K8s) API server\nBy creating new virtual clusters, we can share an isolated API server with tenants where \nthey can do whatever they need without worrying about what other tenants are doing \nor installing. For scenarios where you want each tenant to have cluster-wide access and \nfull control of the Kubernetes API server, vcluster provides a simple alternative to \nimplement this. If you don’t need to provide your teams with access to the Kubernetes \nAPIs, I recommend using the namespace approach mentioned before.\nCreating a vcluster is easy: you can create a new vcluster by installing the \nvcluster Helm Chart. Alternatively, you can use the vcluster CLI to create one and \nconnect to it. \nFinally, a great table comparing vcluster, Kubernetes Namespaces and Kubernetes \nclusters can be found in their documentation. If you are already having these conver-\nsations with your teams, this table explains the advantages and tradeoffs in crystal clear \nlanguage (figure 6.15). \nFigure 6.15    \nPros and cons \nof Kubernetes \nNamespaces \nvs. vcluster vs. \nKubernetes cluster \ntenants\n",
      "content_length": 1879,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 189,
      "content": "170\nChapter 6  Let’s build a platform on top of Kubernetes \nI strongly recommend checking their website (https://vcluster.com) and the blog post \navailable at https://www.salaboy.com/2023/06/19/cost-effective-multi-tenancy-on \n-kubernetes/ to learn more about this project and how it can help your teams provi-\nsion cost-effective clusters.\nNext, let’s see what our platform walking skeleton looks like for teams that want to \ncreate, connect, and work against new environments that use vcluster. \n6.3.2\t\nThe platform experience\nThe platform walking skeleton implemented in the GitHub repository at https://\ngithub.com/salaboy/platforms-on-k8s/tree/main/chapter-6 allows teams connected \nto the platform API to create new environment resources and submit a request for the \nplatform to provision it for them.\nFigure 6.16 shows the architecture for our platform walking skeleton. First, applica-\ntion development teams can create requests to the platform APIs for new development \nenvironments. The platform will provision a new environment—in this case, following a \nCrossplane composition that uses the Crossplane Helm provider to create a new virtual \ncluster (using vcluster)—and then install the Conference application Helm Chart \nfor development teams to do their work. Second, application development teams can \nconnect to this new isolated environment without fearing breaking other teams’ setups.\nEnv Composition\ntype: development\nEnvironment\nName: team-a-env\nParameters:\n • type: development\nCrossplane Helm \nProvider\nCrossplane Helm \nProvider\nvcluster\n`Helm Chart`\nApp Dev\n1\n2\nConference \n`Helm Chart`\nPlatform\nEnvironment\nFigure 6.16    Using Crossplane and vcluster to create isolated environments for application development teams\nNOTE    It makes a lot of sense to have a large cluster to host all the ephemeral \ndevelopment environment clusters. The tools we used for building the platform \nwalking skeleton can be easily configured to implement that setup, but it is quite \nhard to demonstrate running on a single and local KinD cluster.\nThe platform cluster uses Crossplane and Crossplane compositions to define how to \nprovision the environment. To run the Crossplane composition in a local Kuberne-\ntes cluster (and not require access to a specific cloud provider), the walking skeleton \n",
      "content_length": 2307,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 190,
      "content": "\t\n171\nOur platform walking skeleton\nuses vcluster to provision each environment on its own (virtual) Kubernetes cluster. \nHaving separate Kubernetes clusters enables teams to connect to these environments \nand do the work they need to do with our Conference application, which is by default \ninstalled when the environment is created. \nApplication teams need to be connected to the platform API (Kubernetes clusters \nhosting the platform tools—in this case, Crossplane and the vcluster configurations) \nto request new environments using tools like kubectl. For the walking skeleton, send-\ning an environment resource to the platform APIs will result in the platform provi-\nsioning a new vcluster that the team can connect to. See listing 6.2, which shows an \nenvironment resource def﻿iinition that we can send to the Kubernetes API server.\nListing 6.2    Environment definition as a Kubernetes resource\napiVersion: salaboy.com/v1alpha1\nkind: Environment\nmetadata:\n  name: team-a-dev-env\nspec:\n  compositionSelector:\n    matchLabels:\n      type: development\n    parameters: \n      installInfra: true\nBecause these are Kubernetes resources, teams can query these resources using \nkubectl, as shown in listing 6.3.\nListing 6.3    Listing environment resources\n> kubect get environments\nNAME           CONNECT-TO           TYPE        INFRA READY\nteam-a-dev-env team-a-dev-env-jp7j4 development true  True  \nOnce the environment is ready, teams will be able to connect to it. Because we are \nusing vcluster, connecting to it is just like connecting to any other Kubernetes clus-\nter. Luckily, vcluster makes our life easier, and we can use their CLI to configure the \naccess tokens for us. \nRunning the following command will connect you to the vcluster instance that \nhas been just created and host the Conference application installed by the Crossplane \ncomposition:\nvcluster connect team-a-dev-env-jp7j4 --server https://localhost:8443 -- zsh\nThe name for the environment \nthat we want to create\nThe type of \nenvironment \nwe want is \ndefined using \nlabels\nParameters are custom to your specific use case. Depending \non what you want to enable teams to configure, you can \niteratively define more and more parameters for them to \nfine-tune when requesting environments.\n",
      "content_length": 2268,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 191,
      "content": "172\nChapter 6  Let’s build a platform on top of Kubernetes \nNOTE    When running vcluster connect, you are now connected to a new \ncluster context, meaning that if you list all the pods and Namespaces, you will \nonly see the resources that are available in this new cluster. You shouldn’t see any \nCrossplane resources, for example. \nA natural extension to the walking skeleton would be to use Crossplane compositions \nto create environments spawning Kubernetes clusters on a cloud provider. Managing \nthese environment resources inside a Git repository using ArgoCD is also a natural step \nforward. In such cases and in contrast to requiring application development teams to \nconnect directly with the platform APIs, teams can request new environments by send-\ning a pull request to a repository that can be validated and automatically merged.\nThe step-by-step tutorial (https://github.com/salaboy/platforms-on-k8s/tree/\nmain/chapter-6) finishes by deploying a custom Platform Admin User Interface applica-\ntion. This Platform Admin application enables teams to consume the platform features \nwithout connecting to the Kubernetes platform APIs, commonly called “Click Ops,” \nbecause we are trying to avoid teams writing complex YAML files or long commands \nlike cloud providers do. This application exposes REST endpoints and the functionality \nprovided by the user interface to reduce the cognitive load from application teams who \nneed to know how the platform is operating behind the covers. Figure 6.17 shows the \nPlatform Portal admin interface (this is not part of the Conference application).\nFigure 6.17    Platform Admin user interface allows teams to create and manage environments without \nconnecting to the platform’s Kubernetes APIs.\nThis Platform Admin application also exposes REST endpoints to perform all the \nactions by sending REST requests, which can be used for further automation and inte-\ngrations with existing systems. \nTo recap, the walking skeleton offers the platform users different ways of interac-\ntion. First, it extends the Kubernetes APIs to enable platform workflows such as creating \n",
      "content_length": 2121,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 192,
      "content": "\t\n173\nLinking back to platform engineering\ndevelopment environments using Crossplane. Then it provides a user interface and \nsimplified REST endpoints for teams that don’t want or can’t use the extended Kuber-\nnetes APIs. These simplified REST APIs, SDKs, and CLIs can be created for teams to \nmanage their environments. \nThere is value in having both options always available. It’s good to use the power of \nthe Kubernetes APIs and the cloud-native ecosystem, when possible, but it’s also import-\nant to have a simplified option for reducing the cognitive load and following company \nAPI standards when needed.\nBefore closing this chapter, let’s bring back all the topics and projects we have seen \ntogether. How are all these tools and configurations related to platform engineering? \nWho is responsible for which component? And what comes next? \n6.4\t\nLinking back to platform engineering\nSo far, we have explored open-source projects that tackle different challenges we face \nwhen building distributed applications. Most of these tools are not focused on appli-\ncation developers, requiring skills and knowledge that are usually not needed to build \nbusiness applications and features. The common denominator across all tools has \nbeen Kubernetes, and in most cases, projects have extended Kubernetes to perform \ntasks besides running our workloads. In this short section, I want to recap how all these \nprojects fit together to delineate responsibilities, contracts, and expectations. \nIf we look at all these examples from a distance, there are two kinds of teams: plat-\nform and application development teams. These two teams have different responsibili-\nties and require different tools to do their job. From what we have seen so far: \n¡ Platform teams are responsible for the following: \n–\t Understanding the needs of different teams related to IT services, cloud \nresources, and tools.\n–\t Facilitating access to credentials and to different resources.\n–\t Creating automation for other teams to get what they need.\n¡ Application development teams are responsible for the following: \n–\t Defining the customer-facing architecture and tech stack.\n–\t Creating customer-facing features.\n–\t Releasing new versions to continuously improve how the business operates.\nThese responsibilities materialize in software artifacts that can be managed similarly. \nFigure 6.18 shows the artifacts we have used for the platform walking skeleton. The \ntools not included in the step-by-step tutorial are drawn with dashed lines.\n",
      "content_length": 2518,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 193,
      "content": "174\nChapter 6  Let’s build a platform on top of Kubernetes \nTekton Service Pipelines\nPlatform (Walking Skeleton)\nPlatform Admin User \nInterface\nTekton Management\nArgo CD Management\nArgo CD Application \nConfiguration\n`vcluster` \nconfigurations\nContainer Registry\nCrossplane Management\nCrossplane Composite \nResource Definitions \n(XRD)\nEnvironments \nGit Repositories\nAccess Configurations \nand Credentials\nCrossplane \nCompositions\nPlatform Admin REST \nendpoints\nExtended Kubernetes APIs\nFigure 6.18    Platform walking skeleton tools, configurations, and services\nAs you can see, even for a very simple platform, the platform team is managing and \nadministrating different tools that need to be highly available for our application \ndevelopment teams to consume. I haven’t focused on managing credentials or secrets, \nbut this is something that the platform team will face early on in their journey. Using \ntools like the external-secrets project (https://github.com/external-secrets/external \n-secrets) and/or tools like Vault by HashiCorp (https://www.vaultproject.io/) would \nmake managing and storing credentials much easier and more centralized. This level \nof complexity has historically led to two implementation scenarios:\n1\t Purchase a solution that provides fantastic application developer experience \nbut limited platform engineering customization or operability (e.g., Heroku, \nCloudFoundry)\n2\t Build a solution from a set of primitives, including scripting languages (BASH, \nPython, etc.), declarative infrastructure languages (Crossplane, Terraform, Chef, \nAnsible), and workflow engines (ArgoCD Workflows, CircleCI, GitHub Actions).\nRecently there has been an explosion of new tools that enable the first scenario (e.g., \nVercel, Fly.io). However, for many organizations, these solutions have needed help \n",
      "content_length": 1819,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 194,
      "content": "\t\n175\nLinking back to platform engineering\nmanaging their business process and compliance requirements fully. To address this \nchallenge, there is more focus on lowering the cost of building bespoke internal offer-\nings. For example, a project called Kratix (https://kratix.io/), which is a framework \nthat optimizes the definition and implementation of experiences as a service to other \ninternal teams.\nKratix is centered around the platform-building experience instead of the appli-\ncation user experience. A framework like Kratix can enable an internal marketplace \nwhere specialists can offer capabilities as a service while maintaining consistency across \nofferings, similar to what we explored with Crossplane compositions. \nWhether you use an external tool or build your own, the platform engineering team \nmust build a knowledge base about the projects they are using to build the platform and \nhave a release process to manage changes when the tools are online for other teams to \nuse. \nSimilar to this book’s examples repository at https://github.com/salaboy/platforms \n-on-k8s/, the platform engineering team will need to manage all the configuration files \nto install and recreate all the tools and resources the platform needs to work. \nNOTE    Ideally, as with Kubernetes, if the control plane (tools we installed) is \ndown, our teams should be able to keep working. We (as platform engineer-\ning teams) need to build resilient platforms and ensure that if something goes \nwrong, we don’t block teams and the important work they are doing. While the \nplatform we build should speed up software delivery, it shouldn’t be on the crit-\nical path for the teams’ success. In other words, there should always be a way \naround the platform, meaning that if teams want to directly access some of the \ntools that the platform is using, they should be able to do so. \nThe walking skeleton we built in this chapter offers different layers for different users \nto work and integrate with. If your team understands the platform’s tools, they can \naccess the Kubernetes APIs of the platform cluster for full flexibility and control. If \nthey choose, they can also use the provided user interface and REST endpoints to inte-\ngrate with other systems. Figure 6.19 shows our platform walking skeleton, how it pro-\nvides teams with predefined workflows exposed by the platform APIs, and the tools and \nbehaviors implemented under the hood by the platform team. \nI strongly recommend platform teams document their journey with each of the tools \nthat they are planning to use as part of their platform initiatives, because bringing team \nmembers up to speed on these decisions is usually the most challenging aspect of main-\ntaining a platform like the one described here. \n",
      "content_length": 2770,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 195,
      "content": "176\nChapter 6  Let’s build a platform on top of Kubernetes \nTeams interact with the \nPlatform APIs, without \nthe need to know which \ntools are used or how \ntools are configured.\nThe Platform Team owns the definition \nof the Platform APIs and the decisions \non which tools are used to implement \nthe platform provided workflows.\nOur Platform\nPlatform APIs\nEnvironments \nConfiguration \nRepository\nGitOps Sync\nProvisioning \nCloud Resources\nService Pipelines\nManages\nManages\nContainer \nRegistry\nApplication\nInfrastructure\nApplication\nInfrastructure\nEnvironment\nEnvironment\nCloud Resources\nCloud Resources\nCloud Provider\nCloud Provider\nFigure 6.19    Platform responsibilities and boundaries\nIn the next couple of chapters, we will explore some core capabilities the platform \nshould provide when creating environments for teams. Which functionalities can be \nprovided to the application development teams so they can be more efficient when \ndelivering software? Chapter 7 covers release strategies and why they are important \nto enable teams to experiment and release more software. Chapter 8 covers shared \nconcerns that you will need to provide to all services of your applications and different \napproaches to facilitate these mechanisms to your developers.\nSummary\n¡ Building platforms on top of Kubernetes is a complex task that involves combin-\ning different tools to serve teams with different requirements.\n¡ Platforms are software projects as your business applications. Starting by under-\nstanding who the main users will be and defining clear APIs is the key to prioritiz-\ning tasks on how to build your platform. \n¡ Managing multiple Kubernetes clusters and dealing with tenant isolations are \ntwo main challenges that platform teams face early on in their platform-building \njourney.\n",
      "content_length": 1793,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 196,
      "content": "\t\n177\nSummary\n¡ Having a platform walking skeleton can help you to demonstrate to internal \nteams what can be built to speed up their cloud-native journey.\n¡ Using tools like Crossplane, ArgoCD, vcluster, and others can help you pro-\nmote cloud-native best practices at the platform level but, most importantly, \navoid the urge to create your custom tools and ways to provision and maintain \ncomplex configurations of cloud-native resources.\n¡ If you followed the step-by-step tutorial, you got hands-on experience using \ntools like Crossplane and vcluster to provision on-demand development envi-\nronments. You also interacted with a simplified API that reduces the cognitive \nload for teams that don’t want or can’t interact with a full-blown Kubernetes API \nserver.\n",
      "content_length": 769,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 197,
      "content": "178\n7\nPlatform capabilities I: \nShared application concerns\nThis chapter covers\n¡ Learning requirements of 95% of cloud-native \t\n\t applications\n¡ Reducing friction between application and \t\n\t infrastructure\n¡ Addressing shared concerns with standard APIs \t\n\t and components\nIn chapter 5 we created abstractions such as databases and message brokers to pro-\nvision and configure all the components required by our application’s services. In \nchapter 6, we extended these mechanisms to build our platform walking skeleton.\nThis platform enables teams to request new development environments that not \nonly create isolated environments but also install an instance of the Conference \napplication (and all the components required by the application) so teams can do \ntheir work. By going through the process of building a platform, we defined the \nresponsibilities of a platform team and where each tool belongs and why. We ended \nchapter 6 with clear guidelines for where tools like Crossplane, Argo CD, and Tek-\nton would run to manage and enable different environments with capabilities that \nteams will need to deliver more software in front of customers. \n",
      "content_length": 1157,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 198,
      "content": "\t\n179\nWhat are most applications doing 95% of the time?\nSo far, we have given developers Kubernetes clusters with an instance of their appli-\ncation running. This chapter looks at mechanisms to provide developers with capabili-\nties closer to their application needs. Most of these capabilities will be accessed by APIs \nthat abstract away the application’s infrastructure needs, allowing the platform team \nto evolve (update, reconfigure, change) infrastructural components without updating \nany application code. At the same time, developers will interact with these platform \ncapabilities without knowing how they are implemented and without bloating their \napplications with a load of dependencies. This chapter is divided into three sections: \n¡ What are most applications doing 95% of the time? \n¡ Standard APIs and abstractions to separate application code from infrastructure.\n¡ Updating our Conference application with Dapr (Distributed Application Run-\ntime), a CNCF and open-source project created to provide solutions to distrib-\nuted application challenges. \nLet’s start by analyzing what most applications are doing. Don’t worry; we will also \ncover edge cases. \n7.1\t\nWhat are most applications doing 95% of the time?\nWe have worked with our walking skeleton Conference applications for seven chapters. \nWe have learned how to run it on top of Kubernetes and how to connect the services to \ndatabases, key-value stores, and message brokers. There was a good reason to go over \nthose steps and include those behaviors in the walking skeleton. Most applications, like \nthe Conference application, will need the following functionality: \n¡ Call other services to send or receive information: Application services don’t exist on \ntheir own. They need to call and be called by other services. Services can be \nlocal or remote, and you can use different protocols, most commonly HTTP and \nGRPC. We use HTTP calls between services for the conference application walk-\ning skeleton.\n¡ Store and read data from persistent storage: This can be a database, a key-value store, a \nblob store like S3 buckets, or even writing and reading from files. For the confer-\nence application, we are using Redis and PostgreSQL. \n¡ Emit and consume events or messages asynchronously: Using asynchronous messaging \nfor communicating systems implementing an event-driven architecture is a com-\nmon practice in distributed systems. Using tools like Kafka, RabbitMQ, or even \ncloud-provider messaging systems is common. Each service in the Conference \napplication is emitting or consuming events using Kafka. \n¡ Accessing credentials to connect to services: When connecting to an application’s \ninfrastructure components, whether local or remote, most services will need cre-\ndentials to authenticate to other systems. In this book I’ve only mentioned tools \nlike external-secrets (https://github.com/external-secrets/external-secrets) or \nHashiCorp’s Vault (https://www.vaultproject.io/), but we haven’t dug deeper \ninto it. \n",
      "content_length": 3013,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 199,
      "content": "180\nChapter 7  Platform capabilities I: Shared application concerns \nWhether we are building business applications or machine learning tools, most appli-\ncations will benefit from having these capabilities easily available to consume. And \nwhile complex applications require much more than that, there is always a way to sepa-\nrate the complex part from the generic parts. \nFigure 7.1 shows several example service interactions with each other and available \ninfrastructure. Service A is calling Service B using HTTP (for this topic, GRPC would fit \nsimilarly). Service B stores and reads data from a database and will need the right cre-\ndentials to connect. Service A also connects to a message broker and places messages \ninto it. Service C can pick messages from the message broker and, using some creden-\ntials, connect to a Bucket to store some calculations based on the messages it receives. \nI need \ncredentials to \nconnect.\nI need \ncredentials to \nconnect.\nService A\nService B\nService C\nMessage \nBroker\nBucket\nDatabase\nAMQP / Proprietary\nAMQP / Proprietary\nHTTP/GRPC\nFigure 7.1    Common communication patterns in distributed applications\nNo matter what logic these services are implementing, we can extract some constant \nbehaviors and enable development teams to consume without the hassle of dealing \nwith the low-level details or pushing them to make decisions around cross-cutting con-\ncerns that can be solved at the platform level. \nTo understand how this can work, we must look closely at what is happening inside \nthese services. As you might know already, the devil is in the details. While from a high-\nlevel perspective, we are used to dealing with services doing what is described in figure \n7.1, if we want to unlock an increased velocity in our software delivery pipelines, we \nneed to go one level down to understand the intricate relationships between the com-\nponents of our applications. Let’s take a quick look at the challenges the application \nteams face when trying to change different services and infrastructure that our services \nrequire. \n7.1.1\t\nThe challenges of coupling application and infrastructure\nFortunately, this is not a programming language competition, independent of your \nprogramming language of choice. If you want to connect to a database or message \nbroker, you must add some dependencies to your application code. While this is a com-\nmon practice in the software development industry, it is also one of the reasons why \ndelivery speed is slower than it should be.  \n",
      "content_length": 2521,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 200,
      "content": "\t\n181\nWhat are most applications doing 95% of the time?\nCoordination between different teams is the reason behind most blockers when \nreleasing software. We have created architectures and adopted Kubernetes because we \nwant to go faster. By using containers, we have adopted an easier and more standard \nway to run our applications. No matter in which language the application is written or \nwhich tech stack is used, if you give me a container with the application inside, I can \nrun it. We have removed the application dependencies on the operating system and the \nsoftware that we need to have installed in a machine (or virtual machine) to run your \napplication, which is now encapsulated inside a container. \nUnfortunately, we haven’t tackled the relationships and integration points between \ncontainers (our application’s services). We also haven’t solved how these containers will \ninteract with application infrastructure components that can be local (self-hosted) or \nmanaged by a cloud provider. \nLet’s take a closer look at where these applications heavily rely on other services and \ncan block teams from making changes, pushing them for complicated coordination \nthat can end up causing downtime to our users. We will start by splitting up the previous \nexample into the specifics of each interaction. \n7.1.2\t\nService-to-service interaction challenges\nTo send data from one service to another, you must know where the other service is \nrunning and which protocol it uses to receive information. Because we are dealing with \ndistributed systems, we also need to ensure that the requests between services arrive at \nthe other service and have mechanisms to deal with unexpected network problems or \nsituations where the other services might fail. In other words, we need to build resil-\nience in our services. We cannot always trust the network or other services to behave as \nexpected. \nLet’s use Service A and Service B as examples to go deeper into the details. In figure \n7.2, Service A needs to send a request to Service B. \nService A\nService B\nHTTP/GRPC\nThis looks really \nsimple, what can go \nwrong here?\nFigure 7.2    \nService-to-service \ninteraction \nchallenges\nBut let’s dig deeper into the mechanisms services can use internally. Suppose we leave \nthe fact that Service A depends on the Service B contract (API) to be stable and not \nchange for this to work on the side. What else can go wrong here? As mentioned, devel-\nopment teams should add a resiliency layer inside their services to ensure that Service \nA requests reach Service B. One way to do this is to use a framework to retry the request \nif it fails automatically. Frameworks implementing this functionality are available for \nall programming languages. Tools like go-retryablehttp (https://github.com/\nhashicorp/go-retryablehttp) or Spring Retry for Spring Boot (https://github.com/\nspring-projects/spring-retry) add resiliency to your service-to-service interactions. \n",
      "content_length": 2956,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 201,
      "content": "182\nChapter 7  Platform capabilities I: Shared application concerns \nSome of these mechanisms also include exponential backoff functionality to avoid \noverloading services and the network when things are going wrong. \nUnfortunately, there is no standard library shared across tech stacks that can provide \nthe same behavior and functionality for all your applications, so even if you configure \nboth Spring Retry and go-retryablehttp with similar parameters, it is quite hard to \nguarantee that they will behave in the same way when services start failing. \nService B\nRetry 3 times \nevery 3 seconds.\nService A v0.1.0 \n(Java)\nRetry 5 times with \nexponential backoff.\nService C v2.0.6\n(Go)\ngo-retryablehttp\nv0.7.2\nSpring Retry \nv3.1.0\nHTTP\nFigure 7.3    \nService-to-service \ninteractions retry \nmechanisms\nFigure 7.3 shows Service A written in Java using the Spring Retry library to retry three \ntimes with a wait time of 3 seconds between each request when the request fails to \nbe acknowledged by Service B. Service C, written in Go using the go-retryable \nhttp library, is configured to retry five times but using an exponential backoff (the \nretry period between requests is not fixed; this can provide time for the other service to \nrecover and not be flooded with retries) mechanism when things go wrong. \nEven if the applications are written in the same language and using the same frame-\nworks, both services (A and B) must have compatible versions of their dependencies \nand configurations. If we push both Service A and Service B to have the versions of \nthe frameworks, we are coupling them together, meaning we will need to coordinate \nthe update of the other service whenever any of these internal dependency versions \nchange. This can cause even more slowdowns and increase the complexity of coordina-\ntion efforts.\nNOTE    In this section, I’ve used retrying mechanisms as an example, but think \nabout other cross-cutting concerns that you might want to include for these ser-\nvice-to-service interactions, like circuit breakers (also for resiliency) rate limiting \nand observability. Consider the frameworks and libraries you will need to add to \ninstrument your application code to get metrics from it.\nOn the other hand, using different frameworks (and versions) for each service will \ncomplicate troubleshooting these services for our operations teams. Wouldn’t it be \n",
      "content_length": 2386,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 202,
      "content": "\t\n183\nWhat are most applications doing 95% of the time?\ngreat to have a way to add resiliency to our applications without modifying them? \nBefore answering this question, what else can go wrong? \nSomething that developers often overlook relates to the security aspect of these com-\nmunications. Service A and Service B don’t live in a vacuum, meaning other services \nsurround them. If any of these services is compromised by a bad actor, having a free-for-\nall service-to-service invocation between all the services makes our entire system inse-\ncure. This is where having service identity and the right security mechanisms to ensure \nthat, for this example, Service A can only call Service B is extremely important, as shown \nin figure 7.4. \nIf Service A is compromised, it \ncan affect the entire system.\nService A\nService B\nService C\nService D\nService E\nFigure 7.4    \nIf a service is \ncompromised, \nit can affect the \nentire system.\nHaving a mechanism that allows us to define our service’s identity, we can define which \nservice-to-service invocations are allowed and which protocols and ports are allowed \nfor the communications to happen. Figure 7.5 shows how we can reduce the blast \nradius (how many services are affected if a security breach happens) by defining rules \nthat enforce which services are allowed in our system and how they are supposed to \ninteract. \nService E\nBy having service identity \nwe can enforce rules to \nreduce the blast radius a \nservice gets compromised.\nService A\nService C\nService B\nService D\nAllowed Services:\n • Service A\n • Service B\n • Service C\n • Service D\nAllowed invocations:\n • Service A to    \n \nService B \n \n(HTTPS)\nHTTPS\nFigure 7.5    \nReducing the \nblast radius by \ndefining system-\nlevel rules\nHaving the right mechanisms to define and validate these rules cannot be easily built \ninside each service. Hence developers tend to assume that an external mechanism will \nbe in charge of performing these checks.  \nAs we will see in the following sections, service identity is something that we need \nacross the board and not only for service-to-service interactions. Wouldn’t it be great to \n",
      "content_length": 2139,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 203,
      "content": "184\nChapter 7  Platform capabilities I: Shared application concerns \nhave a simple way to add service identity to our system without changing our applica-\ntion’s services?\nBefore answering this question, let’s look at other challenges teams face when archi-\ntecting distributed applications. Let’s talk about storing and reading state, which most \napplications do. \n7.1.3\t\nStoring/reading state challenges\nOur application needs to store or read state from persistent storage. That is quite a \ncommon requirement, right? You need data to do some calculations, then store the \nresults somewhere so they don’t get lost if your application goes down. In our example, \nfigure 7.6, Service B needed to connect to a database or persistent storage to read and \nwrite data. \nWhat can go \nwrong here? \nService B \nDatabase \nFigure 7.6    \nStoring/reading \nstate challenges\nWhat can go wrong here? Developers are used to connecting to different kinds of \ndatabases (relational, NoSQL, files, buckets) and interacting with them. But two main \nfriction points slow teams from moving their services forward: dependencies and \ncredentials. \nLet’s start by looking at dependencies. What kind of dependencies does Service B \nneed to connect to a database? Figure 7.7 shows Service B connecting to both a rela-\ntional database and a NoSQL database. To achieve these connections, Service B needs \nto include a driver and a client library, plus the configuration needed to fine-tune how \nthe application will connect to these two databases. These configurations define the \nsize of the connection pool (how many application threads can connect concurrently \nto the database), buffers, health checks, and other important details that can change \nhow the application behaves. \nconfig\nconfig\nService B v0.1.6\nDriver v1.0.1\nClient v2.2.3\nRelational \nDatabase\nv1.x\nNoSQL 2.x\nFigure 7.7    \nDatabases \ndependencies and \nclient versions\nBesides the configuration of the driver and the client, their versions need to be com-\npatible with the version of the databases we are running, and this is where the chal-\nlenges begin. \n",
      "content_length": 2097,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 204,
      "content": "\t\n185\nWhat are most applications doing 95% of the time?\nNOTE    It is important to notice that each driver/client is specific to the database \n(relational or NoSQL) that you are connecting to. This section assumes you used \na specific database because it meets your application’s requirements. Each data-\nbase vendor has unique features optimized for different use cases. In this chap-\nter, we are more interested in 95% of the cases that do not use vendor-specific \nfeatures.\nOnce the application’s service is connected to the database using the client APIs, \nit should be fairly easy to interact with it. Whether by sending SQL queries or com-\nmands to fetch data or using a key-value API to read keys and values from the database \ninstance, developers should know the basics to start reading and writing data. \nDo you have more than one service interacting with the same database instance? \nAre they both using the same library and the same version? Are these services written \nusing the same programming language and frameworks? Even if you manage to control \nall these dependencies, there is still a coupling that will slow you down. Whenever the \noperations teams decide to upgrade the database version, each service connecting to \nthis instance might or might not need to upgrade its dependencies and configuration \nparameters. Would you upgrade the database first or the dependencies? \nFor credentials, we face a similar problem. It is quite common to consume creden-\ntials from a credential store like HashiCorp’s Vault (https://www.vaultproject.io/). If \nnot provided by the platform and not managed in Kubernetes, application services can \ninclude a dependency to consume credentials from their application’s code easily. Fig-\nure 7.8 shows Service B connecting to a credential store, using a specific client library, \nto get a token to connect to a database. \nToken\nService B v0.4.6\nDriver\nClient v4.4.1\nDatabase\nCredential \nStore\nFigure 7.8    \nCredentials store \ndependencies\nIn chapters 2 and 5, we connected the Conference services to different components \nusing Kubernetes Secrets. By using Kubernetes Secrets, we were removing the need for \napplication developers to worry about where to get these credentials from. \nOtherwise, if your service connects to other services or components that might \nrequire dependencies in this way, the service will need to be upgraded for any change \nin any of the components. This coupling between the service code and dependencies \ncreates the need for complex coordination between application development teams, \nthe platform team, and the operations teams in charge of keeping these components \nup and running. \n",
      "content_length": 2667,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 205,
      "content": "186\nChapter 7  Platform capabilities I: Shared application concerns \nCan we get rid of some of these dependencies? Can we push some of these concerns \ndown to the platform team, so we remove the hassle of keeping them updated from \ndevelopers? If we decouple these services with a clean interface, then the infrastructure \nand applications can be updated independently. \nBefore jumping into the next topic, I wanted to briefly talk about why having ser-\nvice identity at this level can also help reduce security problems when interacting with \napplication infrastructure components. Figure 7.9 shows how similar service identity \nrules can be applied to validate who can interact with infrastructure components. Once \nagain, the system will limit the blast radius if a service is compromised.\nService identity help \nus to enforce which \nservices can interact \nwith the infrastructure \ncomponents.\nService B\nService C\nDatabase\nAllowed Services:\n • Service B\n • Service C\nCan connect to \nDatabase:\n • Service B\nFigure 7.9    \nEnforcing rules \nbased on service \nidentity\nBut what about asynchronous interactions? Let’s look at how these challenges relate to \nasynchronous messaging before jumping into the solutions space. \n7.1.4\t\nAsynchronous messaging challenges\nWith asynchronous messaging, you want to decouple the producer from the consumer. \nWhen using HTTP or GRPC, Service A needs to know about Service B, and both ser-\nvices need to be up to exchange information. When using asynchronous messaging, \nService A doesn’t know anything about Service C. You can take it even further, where \nService C might not even be running when Service A places a message into the mes-\nsage broker. Figure 7.10 shows Service A placing a message into the message broker; at \na later point in time, Service C can connect to the message broker and fetch messages \nfrom it. \nI also need \ncredentials to \nconnect.\nI also need \ncredentials to \nconnect.\nService A\nMessage \nBroker\nService C\nAMQP / Proprietary\nAMQP / Proprietary\nFigure 7.10    Asynchronous messaging interactions\n",
      "content_length": 2060,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 206,
      "content": "\t\n187\nWhat are most applications doing 95% of the time?\nSimilar to HTTP/GRPC service-to-service interactions, when using a message broker, \nwe need to know where the message broker is to send messages to or to subscribe to get \nmessages from. Message brokers also provide isolation to enable applications to group \nmessages together using the concept of topics. Services can be connected to the same \nmessage broker instance but send and consume messages from different topics. \nWhen using message brokers, we face the same problems described with databases. \nWe need to add a dependency to our applications depending on which message bro-\nker we decide to use, its version, and the programming language that we have cho-\nsen. Message brokers will use different protocols to receive and send information. A \nstandard increasingly adopted in this space is the CloudEvent specification (https://\ncloudevents.io/) from the CNCF. While CloudEvents is a great step forward, it doesn’t \nsave your application developers from adding dependencies to connect and interact \nwith your message brokers. \nFigure 7.11 shows Service A, which includes the Kafka client library to connect to \nKafka and send messages. Besides the URL, port, and credentials to connect to the \nKafka instance, the Kafka client also receives configurations on how the client will \nbehave when connecting to the broker, similar to databases. Service C uses the same \nclient, but with different versions, to connect to the same broker. \nKafka Client v3.4.3\nKafka Client v3.3.0\nService A\nService C\nKafka 3.x\nFigure 7.11    \nDependencies \nand API \nchallenges\nMessage brokers face the same problem as with databases and persistent storage. But \nunfortunately, with message brokers, developers will need to learn specific APIs that \nmight not be that easy initially. Sending and consuming messages using different pro-\ngramming languages present more challenges and cognitive load on teams without \nexperience with the specifics of the message broker at hand. \nSame as with databases, if you have chosen Kafka, for example, it means that Kafka \nfits your application requirements. You might want to use advanced Kafka features that \nother message brokers don’t provide. However, let me repeat it here: we are interested \nin 95% of the cases where application services want to exchange messages to external-\nize the state and let other interested parties know. For those cases, we want to remove \nthe cognitive load from our application teams and let them emit and consume mes-\nsages without the hassle of learning all the specifics of the selected message broker. By \nreducing the cognitive load required on developers to learn specific technologies, you \ncan onboard less experienced developers and let experts take care of the details. Simi-\nlar to databases, we can use service identity to control which services can connect, read, \nand write messages from a message broker. The same principles apply. \n",
      "content_length": 2964,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 207,
      "content": "188\nChapter 7  Platform capabilities I: Shared application concerns \n7.1.5\t\nDealing with edge cases (the remaining 5%)\nThere is always more than one good reason to add libraries to your application’s ser-\nvices. Sometimes these libraries will give you the ultimate control over how to con-\nnect to vendor-specific components and functionalities. Other times, we add libraries \nbecause it is the easiest way to get started or because we are instructed to do so. Some-\none in the organization decided to use PostgreSQL, and the fastest way to connect and \nuse it is to add the PostgreSQL driver to our application code. We usually don’t realize \nthat we are coupling our application to that specific PostgreSQL version. For edge \ncases, or to be more specific, scenarios where you need to use some vendor-specific \nfunctionality, consider wrapping up that specific functionality as a separate unit from \nall the generic functionality you might consume from a database or message broker. \nService A\nService A\nKafka Client v3.4.3\nHTTP/GRPC\nMessaging API\nKafka 3.x\n95%\n5%\nFigure 7.12    \nCommon vs. \nedge cases \nencapsulation\nI’ve chosen to use async messaging as an example in figure 7.12, but the same applies to \ndatabases and credential stores. If we can decouple 95% of our services to use generic \ncapabilities to do their work and encapsulate edge cases as separate units, we reduce \nthe coupling and the cognitive load on new team members tasked to modify these \nservices. Service A in figure 7.12 is consuming a message API provided by the platform \nteam to consume and emit messages asynchronously. We will look deeper into this \napproach in the next section. But more importantly, the edge cases, where we need \nto use some Kafka-specific features, for example, are extracted into a separate service \nthat Service A can still interact with using HTTP or GRPC. Notice that the messaging \nAPI also uses Kafka to move information around. Still, for Service A, that is no longer \nrelevant, because a simplified API is exposed as a platform capability. \nWhen we need to change these services, 95% of the time, we don’t need team mem-\nbers to worry about Kafka. The messaging API removes that concern from our applica-\ntion development teams. For modifying Service Y, you will need Kafka experts, and the \nService Y code will need to be upgraded if Kafka is upgraded because it directly depends \non the Kafka client. For this book, platform engineering teams should focus on trying \nto reduce the cognitive load on teams for the most common cases while at the same \ntime allowing teams to choose the appropriate tool for edge cases and specific scenarios \nthat don’t fit the common solutions. \nThe following section will look at some approaches to address some of the challenges \nwe have been discussing. However, keep in mind that these are generic solutions, and \nfurther steps may be required within your own specific context.\n",
      "content_length": 2930,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 208,
      "content": "\t\n189\nStandard APIs to separate applications from infrastructure\n7.2\t\nStandard APIs to separate applications from infrastructure\nWhat about if we encapsulate all these common functionalities (storing and reading \ndata, messaging, credential stores, resiliency policies) into APIs that developers can \nuse from within their applications to solve common challenges while, at the same time, \nenabling the platform team to wire infrastructure in a way that doesn’t require the \napplication’s code to change? In figure 7.13 we can see the same services, but instead of \nadding dependencies to interact with infrastructure, they use HTTP/GRPC requests.\nCredentials \nStore API\nService A\nService B\nResiliency \nPolicies\nPubSub API\nService C\nStatestore \nAPI\nStatestore \nAPI\nHTTP/GRPC\nCloudEvents\nCloudEvents\nFigure 7.13    Platform \ncapabilities as APIs\nSuppose we expose a set of HTTP/GRPC APIs that our applications services can con-\nsume. In that case, we can remove vendor-specific dependencies from our application \ncode and consume these services using standard HTTP or GRPC calls. \nThis separation between application services and platform capabilities enables sepa-\nrate teams to handle different responsibilities. The platform can evolve independently \nfrom applications, and application code will now only depend on the platform capabil-\nities interfaces but not the version of the components running under the hood. Figure \n7.14 shows the separation between application code (our three services) managed by \napplication development teams and platform capabilities that are managed by the plat-\nform team.\nCredentials \nStore API\nPubSub API\nResiliency \nPolicies\nStatestore \nAPI\nMessage Broker\nService A\nService B\nService C\nPlatform Capabilities\nApp Dev Teams\nPlatform Team\nFigure 7.14    Decoupling responsibilities from app dev teams and platform capabilities\n",
      "content_length": 1860,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 209,
      "content": "190\nChapter 7  Platform capabilities I: Shared application concerns \nWhen using an approach like the one suggested here, the platform team can expand \nthe platform capabilities, introducing new services for application development teams. \nMore importantly, they can do so without affecting the existing applications or forc-\ning them to release new versions. This enables teams to decide when to release new \nversions of their services based on their features and the capabilities that they want to \nconsume. \nBy following this approach, the platform team can make new capabilities available \nfor services to use and promote best practices. Because these platform capabilities are \naccessible to all services, they can promote standardization and implement best prac-\ntices behind the covers. Each team can decide which capabilities are needed to solve \ntheir specific problems based on the available ones. If capabilities are correctly ver-\nsioned, teams can decide how and when to upgrade to the latest version, allowing teams \nto move at their own pace without the platform pushing every team to upgrade when-\never a new version is available. \nFor the sake of argument, imagine that the platform team decides to expose a consis-\ntent feature flagging capability to all the services. Using this capability, all services can \nconsistently define and use feature flags without adding anything to their code except \nthe feature flag conditional checks. Teams then can manage, visualize, and toggle on \nand off all their flags consistently. A capability like feature flags introduced and man-\naged by the platform team directly affects developers’ performance, because they don’t \nneed to worry about defining how feature flags will be handled under the hood (per-\nsistence, refresh, consistency, etc.), and they know for sure that they are doing things \naligned with other services. \nFigure 7.15 shows how the platform team can add extra capabilities, like, for exam-\nple, feature flags, directly enabling teams to use this new capability uniformly in all the \nservices. No new dependencies are needed.\nApp Dev Teams\nPlatform Team\nRelease Manager \nTeam\nCredentials \nStore API\nPubSub API\nStatestore \nAPI\nFeature \nFlags API\nFeature Flags \nDashboard\nService A\nService B\nService C\nPlatform Capabilities\nFigure 7.15    Enabling teams by providing consistent and unified capabilities such as feature flags\n",
      "content_length": 2399,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 210,
      "content": "\t\n191\nStandard APIs to separate applications from infrastructure\nBefore moving forward, here’s a word of caution. Let’s look at some challenges that \nyou will face when externalizing capabilities like APIs, as suggested in the previous \nfigure. \n7.2.1\t\nExposing platform capabilities challenges\nExternalizing APIs for teams to use will require, first of all, stable (and versioned) \ncontracts that application teams can trust. When these APIs change, all applications \nconsuming those APIs will break and must be updated. Platform teams can adopt a \nnon-breaking changes policy that guarantees backward compatibility to teams and \ntheir applications. Adopting such policies makes your platform easier to consume, \nbecause the platform APIs and contracts are reliable for teams to use.\nOne of the main advantages of adding dependencies to your application code and, \nfor example, using containers is that for local development, you can always start a Post-\ngreSQL instance using Docker or Docker Compose and connect your application \nlocally to it. If you move toward platform-provided capabilities, you must ensure that \nyou can provide a local development experience for your teams unless your organiza-\ntion is mature enough to always work against remote services. \nAnother big difference is that the connection between your services and the platform \nprovided APIs will introduce latency and require security by default. Before, calling the \nPostgreSQL driver APIs was a local call in the same process as your application. HTTPS, \nor a secure protocol, established the connection to the database itself, but setting that \nsecure channel between your application and the database was the responsibility of the \noperations team. \nIt is also essential to recognize all the edge cases we can find when applying this \napproach to real-life projects. If you want to build these platform capabilities and push \nfor your teams to consume them, you need to make sure that there is always a door \nopen for edge cases so that teams (or even the platform team) aren’t forced to make \ncommon cases more complex to account for an obscure feature that will be used only \n1% of the time. Figure 7.16 shows Services A, B, and C using the capabilities exposed \nby the platform via the capabilities APIs. Service Y, on the other hand, has very specific \nrequirements for how to connect to the database, and the team maintaining the service \nhas decided to bypass the platform capabilities APIs to connect directly to the database \nusing the database client.\nTreating edge cases separately allows Services A, B, and C to evolve separately from \nthe platform components (database, message brokers, credential stores), while Service \nY is now heavily dependent on the database that is connecting to and requires a specific \nversion of the client. While this sounds bad, in practice, it is acceptable and should be \nconsidered a platform feature. Teams that cannot solve their business problems with \nthe exposed APIs will hate the platform and silently find workarounds. Good platforms \n(and platform teams) will promote APIs that cover a wide range of use cases, solving \nand facilitating the implementation of common functionality for application develop-\ners. If these APIs are not enough for all teams, documenting and deeply understand-\ning the edge cases leads to new APIs and platform features that the platform team can \nimplement in future versions.\n",
      "content_length": 3440,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 211,
      "content": "192\nChapter 7  Platform capabilities I: Shared application concerns \nStatestore \nAPI\nPubSub API\nResiliency \nPolicies\nCredentials \nStore API\nMessage Broker\nService A\nService B\nService C\nPlatform Capabilities\nService Y\nService C\nDependency\nFigure 7.16    Handling edge cases; do not ignore them\nThe following section will examine a couple of CNCF initiatives that took these ideas \nforward and helped us implement the platform capabilities that most of our applica-\ntions require. \n7.3\t\nProviding application-level platform capabilities\nIn this section, we will look at two projects that can save development teams time in \nstandardizing these generic APIs that most of our applications will need. We will start \nby looking at the Dapr project (https://dapr.io/), what it is, how it works, and what it \ncan do for our development and platform teams. Then we will look into OpenFeature \n(https://openfeature.dev/), a CNCF initiative that provides our applications with the \nright abstractions to define and use feature flags without being tied to a specific feature \nflag provider. \nOnce we get a bit of an understanding of how these two projects work and comple-\nment each other by helping us to provide application-level platform capabilities, we \nwill look into how these projects can be applied to our Conference application, what \nchanges are needed, the advantages of following this approach, and some examples \nshowing edge cases. Let’s start with Dapr, our Distributed Application Runtime. \n7.3.1\t\nDapr in action\nDapr provides a set of consistent APIs to solve common and recurrent distributed \napplication challenges. The Dapr project has spent the last four years implementing a \nset of APIs (called Building Block APIs) to abstract away common challenges and best \npractices that distributed applications will need 95% of the time. Created by Microsoft \nin 2019 and donated to the CNCF in 2021, the Dapr project has a large community \n",
      "content_length": 1943,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 212,
      "content": "\t\n193\nProviding application-level platform capabilities\ncontributing with extensions and improvements to the project APIs, making it the 10th \nfastest-growing project in the CNCF of 2023. \nDapr defines a set of building blocks that provide concrete APIs to solve distributed \napplication challenges and swappable implementations that the platform team can \nconfigure. If you visit the https://dapr.io website, you will see the list of Building Block \nAPIs, including Service Invocation, State Management, Publish & Subscribe, Secrets \nStore, Input/Output Bindings, Actors, Configurations Management, and, more \nrecently Workflows. Figure 7.17 shows the Dapr official website describing the current \nDapr Building Block APIs that teams can use to build their distributed applications. \nCheck the Dapr Overview page at https://docs.dapr.io/concepts/overview/ for more \ninformation about the Dapr project.\nFigure 7.17    Dapr components for building distributed applications\nWhile Dapr does much more than just expose APIs, in this chapter, I wanted to focus \non the APIs provided by the project and the mechanisms used by the project to enable \napplications/services to consume these APIs. \nBecause this is a Kubernetes book, we will look at Dapr in the context of Kubernetes, \nbut the project can also be used outside of Kubernetes clusters, making Dapr a generic \ntool to build distributed applications no matter where you are running them. As a side \nnote, Dapr is currently part of Azure Container Apps service (https://azure.microsoft \n.com/en-us/products/container-apps), where it is configured with another CNCF \nproject KEDA (https://keda.sh/) for autoscaling your distributed applications. \n7.3.2\t\nDapr in Kubernetes\nDapr works as a Kubernetes extension or add-on. You must install a set of Dapr control-\nlers (a Dapr control plane) on your Kubernetes clusters. Figure 7.15 shows Service A \ndeployed in a Kubernetes cluster with Dapr installed. Service A needs to be annotated \nwith two annotations: dapr.io/enabled: \"true\" for the Dapr control plane to be \naware of the application and dapr.io/appid: \"service-a\" to use Dapr service iden-\ntity features. \n",
      "content_length": 2163,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 213,
      "content": "194\nChapter 7  Platform capabilities I: Shared application concerns \nOnce Dapr is installed in your clusters, your applications deployed in the cluster \ncan start using the Dapr APIs by adding a set of annotations to your deployments. This \nenables the Dapr control plane services to understand that your application wants to \nuse the Dapr APIs, as shown in figure 7.18. \nKubernetes Cluster\nDapr Control Plane\nKubernetes Cluster\nDapr\nFigure 7.18   \nThe Dapr \ncontrol plane \nmonitor for \napplications \nwith Dapr \nannotations\nBy default, Dapr will make all the Dapr APIs available to your applications/services \nas a sidecar (daprd is the container that will run beside your applications/services) \nthat runs beside your application’s containers. Using the sidecar pattern, we enable \nour application to interact with a co-located (localhost) API that runs very close to \nthe application’s container and avoids network round trips. Figure 7.19 shows how \nthe Dapr control plane injects the daprd sidecar into the application annotated with \nthe Dapr annotations. This enables the application to access the configured Dapr \ncomponents. \nKubernetes Cluster\nDapr Control Plane\nDapr\nKubernetes Pod\n`daprd`\nService A\nDapr \nComponents\n<injects>\nHTTP/GRPC\nFigure 7.19    \nDapr sidecars \n(daprd) give your \napplications local \naccess to Dapr \ncomponents.\nOnce the Dapr sidecar is running beside your applications/service container, it can \nuse the Dapr APIs by sending requests (using HTTP or GRPC) to localhost, because \nthe daprd sidecar runs inside the same pod as the application, sharing the same net-\nworking space. \nNow for the Dapr APIs to be of some use, the platform team needs to configure \nthe implementation (or backing mechanisms named Dapr components) for these APIs \nto work. For example, if you want to use the Statestore Dapr APIs (https://docs.dapr \n.io/operations/components/setup-state-store/) from your applications/services, you \nmust define and configure a Statestore component.\n",
      "content_length": 1993,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 214,
      "content": "\t\n195\nProviding application-level platform capabilities\nWhen working with Dapr on Kubernetes, you configure a Dapr component spec-\nification using a Kubernetes resource. For example, you can configure a Statestore \nDapr component to use Redis. See listing 7.1 for an example Dapr component resource \ndefinition.\nListing 7.1    Dapr Statestore component definition \napiVersion: dapr.io/v1alpha1\nkind: Component\nmetadata:\n  name: statestore\nspec:\n  type: state.redis\n  version: v1\n  metadata:\n  - name: keyPrefix\n    value: name\n  - name: redisHost\n    value: redis-master:6379\n  - name: redisPassword\n    secretKeyRef:\n      name: redis\n      key: redis-password\nauth:\n  secretStore: kubernetes\nIf the component resource is available in the Kubernetes cluster, the daprd sidecar can \nread its configurations and connect to the Redis instance for this example. From the \napplication perspective, there is no need to know if Redis is being used or if any other \nimplementation for the Statestore component. Figure 7.20 shows how Dapr compo-\nnents are wired so Service A can use the Statestore component APIs. For this example, \nby calling a local API, Service A will be able to store and read data from the Redis \ninstance.\nDapr\nKubernetes Pod\n`daprd`\nService A\n<injects>\nHTTP/GRPC\nKubernetes Cluster\nDapr Control Plane\nStatestore\nComponent\nStatestore\nComponent\nRedis\nFigure 7.20    \nDapr sidecars \nuse component \nconfigurations \nto connect to \nthe component’s \ninfrastructure.\nDapr makes it easy to build your application using a local/self-hosted Redis instance \nbut then move it to the cloud where a managed Redis service can be used. No code or \ndependencies changes are needed, just a different Dapr component configuration. \nThe Statestore component APIs support different \nimplementations that you can find at https://docs.dapr.io/\nreference/components-reference/supported-state-stores/. \nFor this example, we are setting up the state.redis \nimplementation. \nBy setting the redisHost, the platform team can define \nwhere the Redis instance is located. There is no need for \nthis instance to be inside the Kubernetes cluster; it can be \nany accessible Redis instance.\nThe redisPassword property (required by \nthe state.redis implementation) can use, \nas shown in this example, a Kubernetes \nSecret reference to fetch the password.\n",
      "content_length": 2334,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 215,
      "content": "196\nChapter 7  Platform capabilities I: Shared application concerns \nDo you want to emit and consume messages between different applications? You \njust need to configure a Dapr PubSub component (https://docs.dapr.io/operations/ \ncomponents/setup-pubsub/) and its implementation. Now your service can use a \nlocal API to emit asynchronous messages. Do you want to make all service interactions \n(including infrastructure) calls resilient? You can use Dapr resiliency policies (https://\ndocs.dapr.io/operations/resiliency/policies/) to avoid writing custom logic inside \nyour application code. \nFigure 7.21 shows how Service A and Service B can send requests to each other using \nthe Service Invocation APIs, in contrast to calling the other service directly. Using these \nAPIs (that send traffic through the daprd sidecar) enables the platform team to config-\nure resiliency policies at the platform level, uniformly without adding any dependen-\ncies or changing the application code. \n<read>\nDapr\nKubernetes Pod\n`daprd`\nService A\nHTTP/GRPC\nDapr\nKubernetes Pod\n`daprd`\nService B\nHTTP/GRPC\nKubernetes Cluster\n<read>\nResiliency \nPolicies\nFigure 7.21    \nDapr-enabled \nservices can use \nservice-to-service \ncommunications \nand resiliency \npolicies.\nOK, so the Dapr control plane will inject the Dapr sidecars (daprd) to the applications \nthat are interested in using Dapr components. But how does this look from the appli-\ncation point of view? \n7.3.3\t\nDapr and your applications\nIf we go back to the example introduced in the previous section where Service A wants \nto use the Statestore component to store/read some data from persistent storage like \nRedis, the application code is straightforward. No matter which programming lan-\nguage you use, as soon as you know how to create HTTP or GRPC requests, you have all \nyou need to work with Dapr. \nFor example, to store data using the Statestore APIs your application code needs to \nsend an HTTP/GRPC request to the following endpoint:\nhttp://localhost:<DAPR_HTTP_PORT>/v1.0/state/<STATESTORE_NAME>\nUsing curl, the request will look like this, where -d shows the data we want to per-\nsist and 3500 is the default DAPR_HTTP_PORT and our Statestore component is called \nstatestore:\n> curl -X POST -H \"Content-Type: application/json\"  \n➥-d '[{ \"key\": \"name\", \"value\": \"Bruce Wayne\"}]'  \n➥http://localhost:3500/v1.0/state/statestore\n",
      "content_length": 2376,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 216,
      "content": "\t\n197\nProviding application-level platform capabilities\nTo read the data that we have persisted, instead of sending a POST request, we just \nwrite a GET request. With curl, it would look like this: \ncurl http://localhost:3500/v1.0/state/statestore/name \nUsually, you will not be using curl from inside your applications. You will use your \nprogramming language tools to write these requests. So, if you use Python, Go, Java, \n.NET, or JavaScript, you can find tutorials online on using popular libraries or built-in \nmechanisms to write these requests.\nAnother option is to use one of the Dapr SDKs (Software Development Kits) avail-\nable for different programming languages. Adding the Dapr SDK to your application \nas a dependency allows you to make your developers’ lives easier, so they don’t need to \ncraft HTTP or GRCP requests manually. It is crucial to notice that while you are now \nadding a new dependency to your application, this dependency is optional and only \nused as a helper to speed things up, because this dependency is not tied to any of the \ninfrastructural components that the Dapr APIs are interacting with. \nCheck the Dapr website for examples of how your code will look if you use the Dapr \nSDK. For example, for a multi-programming language example on how to use the Sta-\ntestore component using the SDKs, you can visit https://docs.dapr.io/getting-started/\nquickstarts/statemanagement-quickstart/. \nWhile I decided to focus on Dapr for API abstractions, Dapr offers much more.  By \nallowing platform teams to swap Dapr components implementations, applications \ncan be moved across cloud providers without needing to change any application \ncode. By default, the entire system is observable (https://docs.dapr.io/operations/ \nobservability/), secure (https://docs.dapr.io/operations/security/), and resilient \n(https://docs.dapr.io/operations/resiliency/), as Dapr sidecars will enforce service \nidentity and the rules specified by the platform team, while at the same time extracting \nmetrics from all the Dapr-enabled applications and components. I recommend plat-\nform teams familiarize themselves with the Dapr Project, as the project was built to solve \ncommon challenges that teams will face when working with distributed applications. \nCheck section 7.3.5 of this chapter to see how we can make our Conference application \nDapr-enabled. Now let’s talk a bit about feature flags.\n7.3.4\t\nFeature flags in action\nFeature flags enable teams to release software that includes new features without mak-\ning those features available immediately. New features can be hidden behind feature \nflags that can be enabled later. In other words, feature flags allow teams to keep deploy-\ning new versions of their services or applications, and once these applications are run-\nning, features can be turned on or off based on the company’s needs. \nCompared to application-level APIs, which directly enabled developers with out-of-\nthe-box behaviors to implement complex features, feature flags can enable other teams \nthat make business-related decisions on when features should be enabled to customers. \nWhile most companies might build mechanisms to implement feature flags, it is \na well-recognized pattern to be encapsulated into a specialized service or library. In \nthe Kubernetes world, you can consider using ConfigMaps as the simplest way to \n",
      "content_length": 3369,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 217,
      "content": "198\nChapter 7  Platform capabilities I: Shared application concerns \nparameterize your containers. As soon as your container can read environment vari-\nables to turn on and off features, you are ready to go. We used this approach in chapter \n2 with the FEATURE_DEBUG_ENABLED=true environment variable.\nUnfortunately, this approach is too simplistic and doesn’t work for real-world sce-\nnarios. First, one of the main reasons is that your containers will need to be restarted \nto reread the content of the ConfigMap if it changes. Second, you might need many \nflags for your different services, so you might need multiple ConfigMaps to manage \nyour feature flags. Third, if you use environment variables, you will need to develop a \nconvention to define each flag’s status, default values, and type, because you cannot get \naway with just defining variables as plain strings. \nBecause this is a well-understood problem, several companies have come up with \ntools and managed services like LaunchDarkly (https://launchdarkly.com/) and Split \n(https://www.split.io/product/feature-flags/), among others, which enable teams to \nhost their feature flags in a remote service that offers simplified access to view and mod-\nify feature flags without the need for technical knowledge. For each of these services, to \nfetch and evaluate complex feature flags, you will need to download and add a depen-\ndency to your applications. As each feature flag provider will offer different functional-\nities, switching between providers would require many changes.\nOpenFeature (https://openfeature.dev/) is a CNCF initiative to unify how feature \nflags can be consumed and evaluated in cloud-native applications. In the same way that \nDapr is abstracting how to interact with Statestores (storing and reading state) or Pub-\nSub (async message brokers) components, OpenFeature provides a consistent API to \nconsume and evaluate feature flags no matter which features flag provider we use. \nIn this short section, we will look at a simple example using a ConfigMap to hold a \nset of feature flag definitions. We will also be using the flagd implementation provided \nby OpenFeature, but the beauty of this approach is that you can then swap the provider \nwhere the feature flags are stored without changing any single line of code in your \napplication. \nFigure 7.22 shows a simple application including the OpenFeature SDK that is con-\nfigured to connect to an OpenFeature provider—in this case, flagd, which is in charge \nof hosting our feature flag definitions. \nOpenFeature SDK\nKubernetes Pod\nApp\n`flagd` Service\n`ConfigMap`\nOpenFeature \nSpec\nFigure 7.22    \nConsuming and \nevaluating feature \nflags from our \napplication services\n",
      "content_length": 2713,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 218,
      "content": "\t\n199\nProviding application-level platform capabilities\nFor this simple example, our app is written in Go and uses the OpenFeature Go SDK \nto fetch feature flags from the flagd service. The flagd service for this example is con-\nfigured to watch a Kubernetes ConfigMap that contains some complex feature flags \ndefinitions.\nWhile this is a simple example, it allows us to see how a service like flagd can allow us \nto abstract away all the complexities of the storage and implementation of the mecha-\nnisms needed to provide a feature flag capability as part of our platform. \nIn contrast with Dapr, the OpenFeature SDK is needed because we are not only \nfetching the feature flag definitions but also performing evaluations that can involve \ncomplex feature flags. \nYou can hook every service in your application to connect to an OpenFeature pro-\nvider to perform feature flag evaluations. An important difference with just using plain \nConfigMaps is that by using OpenFeature, containers don’t need to be restarted to fetch \nvalues if they change; that is now the responsibility of the OpenFeature flag provider.\nIn the next section, we look at how to apply both Dapr and OpenFeature to the Con-\nference application walking skeleton. \n7.3.5\t\nUpdating our Conference application to consume application-level platform \ncapabilities\nConceptually and from a platform perspective, it will be great to consume all these \ncapabilities without the platform leaking which tools are used to implement different \nbehaviors. This would enable the platform team to change/swap implementations and \nreduce the cognitive load from teams using these capabilities. But as we discussed with \nKubernetes, understanding how these tools work, their behaviors, and how their func-\ntionalities were designed influences how we architect our applications and services. In \nthis last section of the chapter, I wanted to show how tools like Dapr and OpenFeature \ncan influence your application architecture and, at the same time, show how these \ntools offer building blocks to create higher-level abstractions to reduce consumers’ \ncognitive load. \nFor our Conference application, we can use the following Dapr components, so let’s \nfocus on these: \n¡ Dapr Statestore component: Using the Statestore component APIs enables us to \nremove the Redis dependency from the Agenda service included in the Con-\nference application. If, for some reason, we want to swap Redis for another per-\nsistent store, we will be able to do so without changing any of the application \ncode.\n¡ Dapr PubSub component: For emitting events, we can replace the Kafka client from \nall the services to use the PubSub component APIs, allowing us to test different \n",
      "content_length": 2712,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 219,
      "content": "200\nChapter 7  Platform capabilities I: Shared application concerns \nimplementations, such as RabbitMQ or a cloud provider service to exchange \nasynchronous messages between applications. \n¡ Dapr service-to-service invocations and Dapr resiliency policies: If we use the ser-\nvice-to-service invocation APIs, we can configure resiliency policies between \nthe services without adding a library or custom code to our services code. By \ndefault, all services have resiliency policies defined if no custom configuration is \nprovided.\nWhile we can choose to use the Statestore component APIs also to remove the Post-\ngreSQL dependency in our Call for Proposals service, I have chosen not to do so to \nsupport the use of SQL and PostgreSQL features that the team needed for this service. \nWhen adopting Dapr, you must avoid pushing for an “all or nothing” approach. \nLet’s look at how the application will change if we decide to use Dapr. Figure 7.23 \nshows the application services using Dapr components, because all the services are \nannotated to use Dapr, and the daprd sidecar has been injected all services. Once the \nPubSub and Statestore components have been configured, they can be accessed by the \nCall for Proposals service, Agenda service, and Notifications service. Finally, a Dapr Sub-\nscription pushes events to the Frontend application. \nDapr\nDapr\nDapr\nDapr\n`daprd`\n`daprd`\n`daprd`\n`daprd`\nFrontend\nC4P Service\nPostgreSQL\nNotifications \nService\nAgenda \nService\nSubscription\nKafka\nPubSub Component\nStatestore Component\nRedis\nKubernetes Pod\nKubernetes Pod\nKubernetes Pod\nKubernetes Pod\nFigure 7.23    Using Dapr components for our walking skeleton / Conference application\nResiliency policies can also be configured and defined for the Call for Proposals ser-\nvice to interact with the agenda and notifications services, as shown in figure 7.24.\n",
      "content_length": 1853,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 220,
      "content": "\t\n201\nProviding application-level platform capabilities\nDapr\nDapr\n`daprd`\n`daprd`\n`daprd`\nKubernetes Pod\nKubernetes Pod\nKubernetes Pod\nC4P Service\nDapr\nNotifications \nService\nAgenda \nService\nResiliency Policies\nFigure 7.24    Service-to-service interactions can be handled by the daprd sidecar, allowing platform \nteams to define different resiliency policies. \nDapr applies default resiliency policies if we don’t configure any. These resiliency \npolicies also apply to, for our example, contacting the statestore and pubsub com-\nponents. This means that not only our service-to-service invocations are resilient, but \nevery time our application code wants to interact with infrastructure components such \nas databases, caches and message brokers, the resiliency policies will kick in. \nThe application code needs to change slightly, because when services want to talk to \neach other, they need to use the Dapr API to use resiliency policies. \nFinally, because we wanted to enable all the services to use feature flags, each service \nnow includes the OpenFeature SDK, which allows the platform team to define which \nfeature flag implementation all services will use. \nIn figure 7.25 each service has included the OpenFeature SDK library and is con-\nfigured to point to the flagd service that enables the platform team to configure the \nmechanism used to store, fetch, and manage all the feature flags used by all the services.\nOpenFeature SDK\nNotifications Service\nOpenFeature SDK\nOpenFeature SDK\nOpenFeature SDK\nAgenda Service\nC4P Service\nFrontend\nKubernetes Pod\nKubernetes Pod\nKubernetes Pod\nKubernetes Pod\n`flagd` Service\nConfigMap\nFigure 7.25    Services using the flagd feature flag provider.\n",
      "content_length": 1699,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 221,
      "content": "202\nChapter 7  Platform capabilities I: Shared application concerns \nUsing the OpenFeature SDK, we can change the feature flag provider without chang-\ning our application code. The OpenFeature SDK now standardizes all the feature flag \nconsumption and evaluation of our service code. \nWhile in Dapr, using the SDK is optional (because you can always craft your HTTP \nor GRPC requests by hand), in OpenFeature, the scenario is a bit more complicated. \nbecause the SDKs provide some of the evaluation logic to understand which type each \nflag is and if it is on or off. \nThe step-by-step tutorial (https://github.com/salaboy/platforms-on-k8s/tree/\nv2.0.0/chapter-7) deploys version v2.0.0 of the conference application that uses Dapr \nand OpenFeature flags to enable application teams to keep evolving the application \nservices. Version v2.0.0 of the application services doesn’t include the Kafka or Redis \nclient to interact with infrastructure. These services can be deployed in different envi-\nronments (including cloud providers) and wired against different implementations of \nthese standard APIs. Figure 7.26 shows the dependencies that we managed to remove \nfor version v2.0.0 of the application using the Dapr component APIs.\nDapr\nDapr\nDapr\nDapr\nSubscription\nKafka\nPubSub Component\n/api/new-events/\nFrontend\nC4P Service\nAgenda Service\nKafka Client\nStatestore Component\nPostgreSQL\nRedis\nNotifications \nService\nKafka Client\nPostgreSQL \nDriver\nKafka Client\nKafka Client\nKafka Client\nFigure 7.26    Kafka and Redis client removed from services’ dependencies.\nFrom a platform perspective, three Kubernetes resources are defined by the Dapr Sta-\ntestore component, the Dapr PubSub component, and the Dapr Subscription.\nWe’ve already seen in section 7.3.1 how a Dapr Statestore component is defined. In \nlisting 7.2, we can see how a PubSub component is defined, in this case selecting the \ntype to be pubsub.kafka, which uses the Kafka instance installed using Helm. \n",
      "content_length": 1969,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 222,
      "content": "\t\n203\nProviding application-level platform capabilities\nListing 7.2    Dapr PubSub component definition \napiVersion: dapr.io/v1alpha1\nkind: Component\nmetadata:\n  name: conference-pubsub\nspec:\n  type: pubsub.kafka\n  version: v1\n  metadata:\n  - name: brokers\n    value:  kafka.default.svc.cluster.local:9092\n  - name: authType\n    value: \"none\" \nYou can find all the supported PubSub implementations on the official Dapr website \n(https://docs.dapr.io/reference/components-reference/supported-pubsub/). Finally, \nthe Dapr Subscription resources allow us to declaratively configure subscriptions to \nPubSub components and route events to the application’s endpoints, as shown in list-\ning 7.3. \nListing 7.3    Dapr Subscription definition\napiVersion: dapr.io/v1alpha1\nkind: Subscription\nmetadata:\n  name: frontend-subscription\nspec:\n  pubsubname: conference-pubsub\n  topic: events-topic \n  route: /api/new-events/ \nscopes: \n- frontend \nFrom an application developer perspective, the changes in v2.0.0 use the Dapr Go SDK \nto call the Dapr components API. For example, to read the state from the Statestore \ncomponent, the Agenda service performs the call shown in listing 7.4. \nListing 7.4    Getting state from a Statestore using the Dapr SDK\ns.APIClient.GetState(ctx, \nSTATESTORE_NAME, \nKEY, \nnil) \nWe need to specify \nthe Kafka brokers \navailable for the \nPubSub component \nto connect to. \nBy default, the Kafka \nHelm Chart provided by \nBitnami doesn’t require \nauthentication. \nThe PubSub \ncomponent where \nwe want to register \nthe subscription\nThe topic inside the \nPubSub component \nthat the subscription \nwill listen to\nThe route where the events \nreceived in the topic will be \nforwarded to by Dapr\nscopes allows us to define which Dapr applications are allowed to receive events \nfrom this subscription. In this case the only consumer is the frontend \napplication. Scopes heavily relies on service identity to block messages from \nbeing forwarded to unauthorized services.\nTo store state, you only need to \nprovide the Statestore component \nname configured in Dapr. \nYou also need to provide the \nkey that you want to retrieve \nfrom the Statestore.\n",
      "content_length": 2155,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 223,
      "content": "204\nChapter 7  Platform capabilities I: Shared application concerns \nThe APIClient instance here is just a Dapr client that provides helpers to interact with \nthe DAPR HTTP and GRPC APIs. Similarly, to store state, you can use the SaveState \nmethod; see listing 7.5.\nListing 7.5    Saving state from a Statestore using the Dapr SDK\ns.APIClient.SaveState(ctx, \nSTATESTORE_NAME, \nKEY, \njsonData, \nnil)\nFinally, and following exactly the same approach, applications can publish events to \nthe PubSub component by using the API shown in listing 7.6. \nListing 7.6    Publishing an event using the Dapr SDK\ns.APIClient.PublishEvent(ctx, \nPUBSUB_NAME,  \nPUBSUB_TOPIC, \neventJson) \nOn the OpenFeature side, the feature flag configurations are defined inside a ConfigMap \n(https://github.com/salaboy/platforms-on-k8s/blob/v2.0.0/conference-application \n/helm/conference-app/templates/openfeature.yaml#L49). The tutorial shows three \ndifferent feature flags added to the Conference application to control frontend and \nbackend features. By modifying the ConfigMap that contains the flag definitions, we \ncan change the application behavior without the need to restart any container. The \neventsEnabled feature flag in listing 7.7 shows a feature flag of type Object that con-\ntains properties for each of the services. By defining different variants, we can codify \nprofiles, allowing us to define complex scenarios.\nListing 7.7    Feature flag definitions, including variants\n      \"eventsEnabled\": {\n      \"state\": \"ENABLED\",\n      \"variants\": {\n        \"all\": {\n          \"agenda-service\": true,\n          \"notifications-service\": true,\n          \"c4p-service\": true\nSame as before, we need to provide the Statestore \ncomponent name. Notice that applications can have access \nto multiple Statestore components for different purposes.\nThe KEY will be used \nto store the payload, \nso it can then be \nretrieved by calling \nGetState method.\nThe state is sent to the APIs \nas a JSON payload.\nTo publish an event, we need to specify the Dapr PubSub \ncomponent that we want to use as well as the topic. \nThe topic allows us to divide the \nPubSub component into different \nlogical buckets that the \napplication can use to exchange \nevents and messages.\nThe event payload is \nexpressed as JSON.\n",
      "content_length": 2279,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 224,
      "content": "\t\n205\nLinking back to platform engineering\n        },\n        \"decisions-only\": {\n           \"agenda-service\": false,\n           \"notifications-service\": false,\n           \"c4p-service\": true\n         },\n         \"none\": {\n           \"agenda-service\": false,\n            \"notifications-service\": false,\n            \"c4p-service\": false\n          }\n        },\n        \"defaultVariant\": \"all\"\nListing 7.7 shows an Object feature flag that defines three variants: all, deci-\nsions-only, and none. By changing the defaultVariant property, we can change \nwhich profile is selected, in this case to enable and disable which services will emit \nevents. Inside the Agenda service source code, we use the OpenFeature GO SDK to \nfetch and evaluate the flag, as shown in the following listing.\nListing 7.8    Feature flag evaluation using OpenFeature SDK\ns.FeatureClient.ObjectValue(ctx, \"eventsEnabled\", \nEventsEnabled{},\nopenfeature.EvaluationContext{})\nListing 7.8 shows using the OpenFeature client to fetch the eventsEnabled feature. \nThe EventsEnabled{} struct is the default value that should return in case there is \na problem fetching the feature flag. Finally, the EvaluationContext struct allows \nyou to add extra parameters for OpenFeature to evaluate the flag for more complex \nscenarios.\nYou can find the differences between v1.0.0 and v2.0.0 by comparing the main \nbranch and the v2.0.0 branch in the application repository at https://github.com/\nsalaboy/platforms-on-k8s/compare/v2.0.0. At the same time, the platform team is free \nto configure and wire up application infrastructure and define all the backing mecha-\nnisms and implementations for feature flags, storage, messaging, configuration, man-\naging credentials, resiliency, and other common challenges they don’t want to expose \ndirectly to developers.  \n7.4\t\nLinking back to platform engineering\nIn this chapter, we have seen how to enable teams with platform-wide capabilities in \nthe form of APIs. We aim to speed up their process of writing and delivering complex \nsoftware by providing teams with common and standard APIs to solve everyday chal-\nlenges when creating distributed applications and mechanisms such as feature flags. \nBy separating application infrastructure from the application’s code, we not only \nremove dependencies from our services, but we also enable the platform team to \ndecide how to configure application infrastructure components and how the services \nwill connect to them. If different environments require different implementations, the \n",
      "content_length": 2536,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 225,
      "content": "206\nChapter 7  Platform capabilities I: Shared application concerns \nplatform team can work behind the APIs to provide different configurations for differ-\nent scenarios. \nFigure 7.27 shows how we can reduce friction and dependencies related to the appli-\ncation infrastructure. This allows our application’s services to work in various environ-\nments the platform team can control. Using projects like Dapr, you also gain portability \nof your applications across cloud providers, consistent APIs that can be used from any \nprogramming language, and you enable teams to bring their applications from a local \ndevelopment environment to production environments, allowing the platform team to \nwire up the infrastructure that your application needs to work. With feature flags, we \nenable developers to keep releasing software by masking features behind feature flags \nthat can be turned on and off, enabling other teams closer to customers (like product \nteams) to decide when these features should be exposed. \nCloud Resources\nPlatform Teams can \nconfigure and wire these \nApplication-Level APIs with \ndifferent infrastructure \ncomponents depending on \nthe available resources.\nDevelopers work on \nimplementing features \nconsuming Application-Level \nAPIs provided by the \nplatform.\nProduct Teams can make \nuse of the Feature Flags \nDashboard to turn on and \noff features when the \nbusiness needs it.\nOur Platform\nPlatform APIs\nCloud Provider\nApplication\nApplication-Level \nAPIs\nInfrastructure\nEnvironments \nConfiguration \nRepository\nContainer \nRegistry\nGitOps Sync\nProvisioning Cloud \nResources\nService Pipelines\nFeature Flags \nDashboard\nManages\nEnvironment\nFigure 7.27    Consistent capabilities across environments enable smoother paths to production.\nBy providing consistent capabilities across environments, we enable easier paths to \nproduction, because we can control which features are exposed to customers after \nreleasing the new version to production. Developers can keep building features rely-\ning on platform-provided application-level APIs without knowing where the available \n",
      "content_length": 2091,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 226,
      "content": "\t\n207\nLinking back to platform engineering\ninfrastructure is or which versions of databases and message brokers are used in the \nproduction environment. \nFor the sake of space, topics such as observability, metrics, and logs, service meshes \nhaven’t been covered in these sections, because these capabilities are currently more \nmature and more operations-focused. I’ve decided to focus on capabilities that build \non top of the operation and infrastructure teams to speed up development teams and \nsolve everyday challenges. Platform teams will define which observability stack they will \nuse across environments early and how this data can be available to developers trou-\nbleshooting problems. Service meshes and certificate rotation tools for mutual TLS \n(encryption between services) are often discussed in these conversations because these \nare topics that development teams will not want to spend time on and should be pro-\nvided at the platform level. Figure 7.28 shows how our platform is responsible for defin-\ning, fetching, and aggregating data from the tools available inside each environment. \nOur platform should provide a single entry point to understand what is happening in \ndifferent environments and provide teams with enough information to troubleshoot \nproblems and access the tools the organization needs to deliver software to customers.\nTools to fetch and aggregate data to \nmonitor and manage Environments\nPlatform Provided API\nPlatform\nEnvironment\nConference Application\nObservability \n(Otel)\nMutual TLS & \nCertificates\nDapr\nOpenFeature\nCloud Provider \nStack or Self \nManaged\nDatabases / \nMessage Brokers / \nIdentity / \nCredentials\nManaged \nFeature Flag \nProvider\nFigure 7.28    The platform that we build needs to define, manage, and monitor the tools available in each \nenvironment.\nThe next chapter will explore tools to enable teams to experiment while releasing soft-\nware. Along the same lines of using feature flags, we will dig deeper into how to use \ndifferent release strategies to catch problems earlier in the release process and enable \nstakeholders to try different approaches simultaneously. \n",
      "content_length": 2135,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 227,
      "content": "208\nChapter 7  Platform capabilities I: Shared application concerns \nSummary\n¡ Moving dependencies to application infrastructure enables application code to \nstay agnostic to platform-wide upgrades. Separating the lifecycle of the applica-\ntions and the infrastructure enables teams to rely on stable APIs instead of deal-\ning with provider-specific clients and drivers for everyday use cases. \n¡ Treating edge cases separately allows experts to make more conscious cases \nbased on their application requirements. This also allows common scenarios to \nbe handled by less experienced team members, who don’t need to understand \nthe specifics of tools like vendor-specific database features or low-level message \nbroker configurations when they only want to store or read data or emit events \nfrom their application’s code. \n¡ Dapr solves common and shared concerns when building distributed applica-\ntions. Developers that can write HTTP/GRPC requests can interact with infra-\nstructure that the platform team will wire up. \n¡ Feature flags enable developers to keep releasing software by masking new fea-\ntures behind feature flags that can be turned on and off.\n¡ OpenFeature standardizes the way applications consume and evaluate feature \nflags. Relying on OpenFeature abstractions allows platform teams to decide \nwhere feature flags are stored and how they are managed. Different providers \ncan offer non-technical people dashboards where they can see and manipulate \nflags. \n¡ If you followed the step-by-step tutorial, you gained hands-on experience in using \ntools like Dapr and OpenFeature in the context of a cloud-native application \ncomposed of four services that interact with SQL and NoSQL databases and a \nmessage broker like Kafka. You also modified feature flags on a running applica-\ntion to change its behavior without restarting any of its components.\n",
      "content_length": 1871,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 228,
      "content": "209\n8\nPlatform capabilities II: \nEnabling teams to experiment \nThis chapter covers\n¡ Enabling teams by providing release strategies \t\n\t capabilities\n¡ Identifying the challenges of using Kubernetes \t\n\t built-in mechanisms to implement release \t\n\t strategies\n¡ Using Knative Serving advanced traffic  \n\t management to release our cloud-native \t \t\n\t applications\n¡ Leveraging Argo Rollouts out-of-the-box release \t\n\t strategies\nIn chapter 7, we looked at how enabling development teams with application-level \nAPIs can reduce the cognitive load on developers to solve common distributed \napplication challenges while at the same time enabling platform teams to wire and \nconfigure these components to be accessible for applications to consume. We also \nevaluated using feature flags to enable developers to keep releasing new features \nand enable other teams closer to the business to decide when these new features are \nexposed to customers. \n",
      "content_length": 942,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 229,
      "content": "210\nChapter 8  Platform capabilities II: Enabling teams to experiment  \nIn this chapter, we will look at how introducing different release strategies can \nhelp the organization catch errors earlier in the process, validate assumptions, and \nenable teams to experiment with different versions of the same application running \nsimultaneously. \nWe want to avoid teams being worried about deploying a new version of your ser-\nvices, as this slows down your release cadence and causes stress to everyone involved in \nthe release process. Reducing risk and having the proper mechanisms to deploy new \nversions drastically improves confidence in the system. It also reduces the time from a \nrequested change until it is live in front of your users. New releases with fixes and new \nfeatures directly correlate to business value, because software is not valuable unless it \nserves our company’s users. \nWhile Kubernetes built-in resources such as deployments, services, and ingresses \nprovide us with the basic building blocks to deploy and expose our services to our users, \na lot of manual and error-prone work must happen to implement well-known release \nstrategies. For these reasons, the cloud-native communities have created specialized \ntools to help teams be more productive by providing mechanisms to implement the \nmost common release strategy patterns we will discuss in this chapter. This chapter is \ndivided into three main sections: \n¡ Release strategies fundamentals:\n–\t Canary releases, blue/green deployments, and A/B testing\n–\t Limitations and complexities of using Kubernetes built-in mechanisms\n¡ Knative Serving: Autoscaling, advanced traffic management, and release \nstrategies\n–\t Introduction to Knative Serving \n–\t Release strategies in action with Knative Serving and the Conference \napplication\n¡ Argo Rollouts: Release strategies automated with GitOps\n–\t Introducing Argo Rollouts\n–\t Argo Rollouts and progressive delivery\nThe first section of this chapter covers the most common and well-documented release \nstrategies from a high level, and we’ll quickly look at why implementing these release \nstrategies with Kubernetes building blocks can be challenging. Section 8.2 looks at \nKnative Serving, which provides higher-level building blocks that highly simplify how \nto implement these release strategies while at the same time providing advanced traffic \nmanagement and dynamic autoscaling for our workloads. Section 8.3 introduces Argo \nRollouts, another project from the Argo family that focuses on enabling teams with \nout-of-the-box release strategies and progressive delivery. Let’s start covering the fun-\ndamentals of release strategies.\n",
      "content_length": 2667,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 230,
      "content": "\t\n211\nRelease strategies fundamentals\n8.1\t\nRelease strategies fundamentals\nIf you look for the most common release strategies teams implement to promote ser-\nvices to sensitive environments, you will find canary releases, blue/green deployments, \nand A/B testing. Each release strategy has a different purpose and can be applied to \nvarious scenarios. In the following short sections, we will look at what is expected for \neach release strategy, the expected benefits of having these mechanisms in place, and \nhow they relate to Kubernetes. Let’s start by looking into canary releases. \n8.1.1\t\nCanary releases\nWith canary releases, we want to enable teams to deploy a new version of a service and \nhave full control over how much live traffic is routed to this new version. This allows \nteams to slowly route traffic to the new version to validate that no problems were intro-\nduced before routing all the production traffic to it. \nFigure 8.1 shows users accessing our software, where 95% of the requests are for-\nwarded to the service that we know is stable and only 5% are forwarded to the new ver-\nsion of the service. \nService \n(New Version)\nService\n(Stable)\nRouter\nUsers\n95%\n5%\nFigure 8.1    Releasing a new version (canary) of the service with 5% traffic routed to it\nThe term canary release comes from coal miners who used canary birds to alert them \nwhen toxic gasses reached dangerous levels. In this case, our canary release can help us \nidentify problems or regressions introduced by the new version early on, where rolling \nback 100% of the traffic to the stable version doesn’t include a full deployment.\nIn the context of Kubernetes, and as shown in figure 8.2, you can implement a sort of \ncanary release by using two Kubernetes deployments resources (one with the stable ver-\nsion and one with the new version) and a single Kubernetes service that matches these \ntwo deployments. If each deployment has a single replica, there will be a 50% and 50% \ntraffic split. Adding more replicas to each version creates a different percentage traffic \nsplit (for example, three replicas for the stable version and only one replica for the new \nversion will give you a 75% to 25% traffic split ratio), as the Kubernetes service route \nrequests using a round-robin fashion to all pods matching the service label.\n",
      "content_length": 2318,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 231,
      "content": "212\nChapter 8  Platform capabilities II: Enabling teams to experiment  \nService\nmatchLabel: app\nDeployment\n(Stable)\nlabel: app\nDeployment\n(New Version)\nlabel: app\nPod\nPod\nPod\nPod\n75%\n25%\nFigure 8.2    Canary release in Kubernetes using two deployments and one service.\nTools like Istio (https://istio.io/) or Linkerd (https://linkerd.io/) service meshes can \ngive you finer-grained control of how traffic gets routed to each service. I strongly rec-\nommend you check Martin Fowler’s website, which explains this release strategy in \nmore detail at https://martinfowler.com/bliki/CanaryRelease.html. \n8.1.2\t\nBlue/green deployments\nWith blue/green deployments, we aim to enable teams to switch between two versions \nof their services or applications that are running parallel. This parallel version can \nact as a staging instance for testing, and when the team is confident enough, they can \nswitch traffic to this parallel instance. This approach gives the team the safety of having \nanother instance ready if the new version starts experiencing problems. This approach \nrequires having enough resources to run both versions simultaneously, which can be \nexpensive, but it gives your teams the freedom to experiment with an instance that is \nrunning with the same resources as your production workloads. \nFigure 8.3 shows internal teams testing a production-like setup of the service’s new \nversion. Whenever this new version is ready, the team can decide to switch production \ntraffic to the new version while still having the stable version to rollback if things go \nwrong.\nBlue\nGreen\nInternal Testing\nUsers\nRouter\nService (Stable)\nService(New \nVersion)\nFigure 8.3    Blue/green deployments run in parallel with production-grade setups, allowing teams to \nswitch traffic when they feel confident in the new version.\n",
      "content_length": 1817,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 232,
      "content": "\t\n213\nRelease strategies fundamentals\nIn the Kubernetes context, you can implement blue/green deployments by using two \nKubernetes deployment resources and a Kubernetes service, but in this case, the ser-\nvice should only match the pods of a single deployment. Updating the service config-\nuration to match the green deployment label(s) will automatically switch the traffic to \nthe new version. \nFigure 8.4 shows how by changing the matchLabel of the service to “green,” the \ntraffic will be automatically routed to the new version of the service. In the mean-\ntime, for testing, internal teams can use a different service to match the new version’s \ndeployment.\nChanging the Active Service \nmatchLabel to “green” will \nswitch traffic to the new version\nActive Service\nmatchLabel: \nblue\nDeployment \n(Stable)\nlabel: blue\nPreview Service\nmatchLabel: \ngreen\nDeployment\n(New Version)\nlabel: green\nBlue\nGreen\nInternal Testing\nFigure 8.4    Blue/green deployments run in parallel. The service matchLabel is used to define where to \nroute requests. \nOnce again, I strongly recommend you check Martin Fowler’s website (https:// \nmartinfowler.com/bliki/BlueGreenDeployment.html) on blue/green deployments, \nbecause there are links and more context that you might find useful. \n8.1.3\t\nA/B testing\nA/B testing is different from canary releases and blue/green deployments because it \nfocuses more on end users than internal teams. With A/B testing, we want to enable \nother teams closer to the business to try different approaches to solve a business prob-\nlem. Examples are having two different page layouts to see which one works better for \nthe users or having different registration flows to validate which one takes users less \ntime and causes less frustration. As discussed in chapter 7 with feature flags, we want \nto enable other teams and not only developers to experiment, in this case by providing \ndifferent groups of users access to different versions of the application. These teams \ncan then validate how effective each feature is and then decide which one to keep. \nFigure 8.5 shows two different service implementations providing alternative regis-\ntration flows for users. Using A/B testing, we can run both in parallel and collect data to \nenable business teams to decide which option works better.\n",
      "content_length": 2307,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 233,
      "content": "214\nChapter 8  Platform capabilities II: Enabling teams to experiment  \nService (stable)\nRegistration \nFlow A\nUsers\n50%\n50%\nService (stable)\nRegistration \nFlow B\nRouter\nWhich one \nworks \nbetter for \nour users?\nStakeholders\nFigure 8.5    A/B testing enables teams closer to the business to evaluate different approaches and \ngather data to make decisions to improve business outcomes.\nBecause A/B testing is not a technical release strategy, it can be implemented in dif-\nferent ways depending on the application’s requirements. Having two separate Kuber-\nnetes services and deployments would make sense to run and access two different \nversions of the same application. Figure 8.6 shows the use of two Kubernetes services \nand two deployments to route users to different versions of the same functionality. It \nalso shows that an application-level router will be needed to define the rules on how \nusers are routed to each of the alternatives.\nAn application level \nrouter is needed to \ndefine the rules for \nrouting users to one of \nthe available options\nLogical \nRouter\nService\nService\nDeployment \nRegistration \nFlow A\nDeployment\nRegistration \nFlow B\nFigure 8.6    A/B testing requires some business and application-level rules to define how to route users \nto different options.\nA/B testing can be implemented using similar mechanisms as canary releases, and we \nwill look at several options in the following sections. Continuous Delivery by Jez Humble \nand David Farley (Addison-Wesley Professional, 2010) covers these release strategies in \ndetail, so I strongly recommend you check that book.  \n",
      "content_length": 1601,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 234,
      "content": "\t\n215\nRelease strategies fundamentals\n8.1.4\t\nLimitations and complexities of using built-in Kubernetes building blocks\nCanary releases, blue/green deployments, and A/B testing can be implemented using \nbuilt-in Kubernetes resources. But as you have seen, this requires creating different \ndeployments, changing labels, and calculating the number of replicas needed to \nachieve percentage-based distribution of the requests is quite a major and error-prone \ntask. Even if you use a GitOps approach, as shown with ArgoCD or other similar tools \nin chapter 4, creating the required resources with the right configurations is quite \nhard and takes a lot of effort.\nWe can summarize the drawbacks of implementing these patterns using Kubernetes \nbuilding blocks as follows: \n¡ Manual creation of more Kubernetes resources, such as deployments, services, \nand ingress rules, to implement these different strategies can be error-prone and \ncumbersome. The team implementing the release strategies must understand \nhow Kubernetes behaves to achieve the desired output.\n¡ No automated mechanisms are provided out of the box to coordinate and imple-\nment the resources required by each release strategy.\n¡ They can be error-prone, because multiple changes need to be applied at the \nsame time in different resources for everything to work as expected.\n¡ Suppose we notice a demand increase or decrease in our services. In that case, we \nneed to manually change the number of replicas for our deployments or install \nand configure a custom auto scaler (more on this later in this chapter). Unfor-\ntunately, if you set the number of replicas to 0, there will not be any instance to \nanswer requests, requiring you to have at least one replica running all the time. \nOut of the box, Kubernetes doesn’t include any mechanism to automate or facilitate \nthese release strategies, which becomes a problem quite quickly if you are dealing with \nmany services that depend on each other.  \nNOTE    One thing is clear: your teams need to be aware of the implicit con-\ntracts imposed by Kubernetes regarding 12-factor apps and how their services \nAPIs evolve to avoid downtime. Your developers need to know how Kubernetes’ \nbuilt-in mechanisms work to have more control over how your applications are \nupgraded.\nIf we want to reduce the risk of releasing new versions, we want to empower our devel-\nopers to have these release strategies available for their daily experimentation. \nIn the next sections, we will look at Knative Serving and Argo Rollouts, tools and \nmechanisms built on top of Kubernetes to simplify all the manual work and limitations \nthat we will find when trying to set up Kubernetes building blocks to enable teams with \ndifferent release mechanisms. Let’s start first with Knative Serving, which extends our \nKubernetes clusters with a set of building blocks that simplifies the implementation of \nthe release strategies described before. \n",
      "content_length": 2940,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 235,
      "content": "216\nChapter 8  Platform capabilities II: Enabling teams to experiment  \n8.2\t\nKnative Serving: Advanced traffic management and release \nstrategies\nKnative is one of these technologies that are hard not to use when you learn what it \ncan do for you. After working with the project for almost three years and observing the \nevolution of some of its components, every Kubernetes cluster should have Knative \nServing installed; your teams will appreciate it. Knative Serving is a Kubernetes exten-\nsion that provides higher-level abstractions on top of Kubernetes built-in resources to \nimplement good practices and common patterns that enable your teams to go faster \nand have more control over their services.\nWhile this chapter focuses on release strategies, you should look into Knative Serving \nif you are interested in the following topics: \n¡ Providing a containers-as-a-service approach for your teams to use.\n¡ Dynamic autoscaling for your workloads to provide a functions-as-a-service \napproach for your teams. Knative Serving installs its own autoscaler, which is \nautomatically available for all Knative Services.\n¡ Advanced and fine-grained traffic management for your services.\nAs the title of this section specifies, the following sections focus on a subset of the \nfunctionality provided by Knative, called Knative Serving. Knative Serving allows you \nto define Knative Services, which dramatically simplifies implementing the release strat-\negies exemplified in the previous sections. Knative Services will create Kubernetes \nbuilt-in resources for you and keep track of their changes and versions, enabling sce-\nnarios that require multiple versions to be present simultaneously. Knative Services \nalso provides advanced traffic handling and autoscaling to scale down to zero replicas \nfor a serverless approach. \nNOTE  A step-by-step tutorial on how to use Knative Serving with the Con-\nference application to implement different release strategies can be found at \nhttps://github.com/salaboy/platforms-on-k8s/blob/main/chapter-8/knative/\nREADME.md. \nIt is outside of the scope of this book to explain how Knative Serving components and \nresources work; my recommendation is that if I manage to get your attention with the \nexamples in the following sections, you should check out Knative in Action by Jacques \nChester (Manning Publications, 2021). \n8.2.1\t\nKnative Services: Containers-as-a-Service\nOnce you have Knative Serving installed, you can create Knative Services. I can hear \nyou thinking: “But we already have Kubernetes services. Why do we need Knative \nServices?” Believe me, I had the same feeling when I saw the same name, but follow \nalong—it does make sense. \n",
      "content_length": 2690,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 236,
      "content": "\t\n217\nKnative Serving: Advanced traffic management and release strategies\nWhen we deployed our walking skeleton in chapter 2 (the Conference application), \nwe created at least two Kubernetes resources: a Kubernetes deployment and a Kuber-\nnetes service. As we discussed in chapter 2, by using ReplicaSets, a deployment can per-\nform rolling updates by keeping track of the configuration changes in the deployment \nresources. We also discussed in chapter 2 the need for creating an ingress resource to \nroute traffic from outside the cluster. Usually, you only create an ingress resource to \nmap the publicly available services, such as the Frontend of the Conference application \nor the Conference Admin Portal. \nNOTE    The Ingress resource that we created routes all the traffic straight to \nthe in-cluster Kubernetes service, and the ingress controller used in the tuto-\nrials works as a simple reverse proxy. It doesn’t have any advanced capability to \nsplit traffic, rate limit, or inspect the request headers to make dynamic decisions \nabout it. \nYou can follow a step-by-step tutorial to create a cluster, install Knative Serving, and \ndeploy the application services at https://github.com/salaboy/platforms-on-k8s/\nblob/main/chapter-8/knative/README.md#installation. \nKnative Services are built on top of these resources (services, deployments, Replica-\nSets) to simplify how we define and manage the lifecycle of our application’s services. \nWhile it simplifies the task and reduces the amount of YAML that we need to maintain, \nit also adds some exciting features. Before jumping into the features, let’s look at how a \nKnative Service looks in action. \nKnative Services expose a simplified contract to its users that resembles a contain-\ner-as-a-service interface such as AWS App Runner and Azure Container Apps. In fact, \nKnative Services share the interface used by Google Cloud Run to enable users to run \ncontainers on-demand without the need to understand Kubernetes. \nBecause Knative Serving installs its own autoscaler, Knative Services are automati-\ncally configured to scale based on demand. This makes Knative Serving a very good way \nto implement a function-as-a-service platform, because workloads that are not being used \nwill be automatically downscaled to zero.\nLet’s see these features in action, beginning with the Knative Service Kubernetes \nresource. We will start simple and use the notification service from the Conference \napplication to demonstrate how Knative Services work. Check the notifications-service.\nyaml resource definition (available at https://github.com/salaboy/platforms-on-k8s/\nblob/main/chapter-8/knative/notifications-service.yaml), as shown in the following \nlisting. \n",
      "content_length": 2721,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 237,
      "content": "218\nChapter 8  Platform capabilities II: Enabling teams to experiment  \nListing 8.1    Knative Service definition\napiVersion: serving.knative.dev/v1\nkind: Service\nmetadata:\n  name: notifications-service\nspec:\n  template:\n    spec:\n      containers:\n        - image: salaboy/notifications-service:v1.0.0 \n          Env:  \n          - name: KAFKA_URL\n            value: <URL> \n  \nIn the same way as a deployment will pick the spec.template.spec field to cookie-cut \npods, a Knative Service defines the configuration for creating other resources using \nthe same field. \nNothing too strange so far, but how is this different from a Kubernetes Service? If you \ncreate this resource using kubectl apply -f, you can start exploring the differences. \nNOTE    All the examples in this section are based on running the step-by-step tuto-\nrial on a KinD cluster. Outputs will be different if you run in a cloud provider. See \nhttps://github.com/salaboy/platforms-on-k8s/blob/main/chapter-8/knative/ \nREADME.md#knative-services-quick-intro.\nYou can also list all Knative Services using kubectl get ksvc (ksvc stands for Knative \nService), and you should see your newly created Knative Service there: \n​NAME                   URL                             LATEST CREATED               READY \nnotifications-service  http://notificationsl-service...notifications-service-00001  True \nThere are a couple of details to notice right here; first, there is a URL that you can copy \ninto your browser and access the service. If you were running in a cloud provider and \nconfigured DNS while installing Knative, this URL should be accessible immediately. \nThe LASTCREATED column shows the name of the latest Knative Revision of the Ser-\nvice. Knative Revisions are pointers to the specific configuration of our service, mean-\ning that we can route traffic to them. \nYou can go ahead and test the Knative Service URL by using curl or by pointing your \nbrowser to http://notifications-service.default.127.0.0.1.sslip.io/service/info. Notice \nthat we are using jq (https://jqlang.github.io/jq/download/), a very popular JSON \nutility, to pretty-print the output. You should see the output in listing 8.2.\nYou need to specify a name for the resource, \nas with any other Kubernetes resource.\nYou need to \nspecify which \ncontainer \nimage you \nwant to run.\nYou can parameterize \nyour containers using \nenvironment variables.\n",
      "content_length": 2398,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 238,
      "content": "\t\n219\nKnative Serving: Advanced traffic management and release strategies\nListing 8.2    Interacting with our newly created Knative Service\ncurl http://notifications-service.default.127.0.0.1.sslip.io/service/info \n{\n   \"name\" : \"NOTIFICATIONS\",\n   \"podIp\" : \"10.244.0.18\",\n   \"podName\" : \"notifications-service-00001-deployment-74cf6f5f7f-h8kct\",\n   \"podNamespace\" : \"default\",\n   \"podNodeName\" : \"dev-control-plane\",\n   \"podServiceAccount\" : \"default\",\n   \"source\" : \"https://github.com/salaboy/platforms-on-k8s/tree/main/         \n     conference-application/notifications-service\",\n   \"version\" : \"1.0.0\"\n}\nAs with any other Kubernetes resource, you can also use kubectl describe ksvc \nnotifications-service to get a more detailed description of the resource. If you list \nother well-known resources such as deployment, services, and pods, you will find out \nthat Knative Serving is creating them for you and managing them. Because these are \nmanaged resources now, it is usually not recommended to change them manually. If \nyou want to change your application configurations, you should edit the Knative Ser-\nvice resource. \nA Knative Service, as we applied it before to our cluster, by default behaves differ-\nently from creating a service, a deployment, and an ingress manually. A Knative Service \nby default: \n¡ Is accessible: It exposes itself under a public URL so you can access it from out-\nside the cluster. It doesn’t create an ingress resource, because it uses the avail-\nable Knative Networking stack that you installed previously. Because Knative has \nmore control over the network stack and manages deployments and services, it \nknows when the service is ready to serve requests, reducing configuration errors \nbetween services and deployments. \n¡ Manages Kubernetes resources: It creates two services and a deployment. Knative \nServing allows us to run multiple versions of the same service simultaneously. \nHence, it will create a new Kubernetes service for each version (which in Knative \nServing is called  a revision).\n¡ Collects service usage: It creates a pod with the specified user-container and a \nsidecar container called queue-proxy. \n¡ Scales-up and down based on demand: It automatically downscales itself to zero if no \nrequests are hitting the service (by default after 90 seconds): \n–\t It achieves this by downscaling the Deployment replicas to 0 using the data \ncollected by the queue-proxy.\n–\t If a request arrives and there is no replica available, it scales up while queuing \nthe request, so it doesn’t get lost. \n",
      "content_length": 2553,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 239,
      "content": "220\nChapter 8  Platform capabilities II: Enabling teams to experiment  \n–\t Our notification service has set a minimum number of replicas to 1 to be kept \nrunning at all times.\n¡ Configuration changes history is managed by Knative Serving: If you change the Kna-\ntive Service configuration, a new Revision will be created. By default, all traffic will \nbe routed to the latest revision.\nOf course, these are the defaults, but you can fine-tune each of your Knative Services \nto serve your purpose and, for example, implement the previously described release \nstrategies.  \nIn the next section, we will look at how Knative Serving advanced traffic-handling \nfeatures can be used to implement canary releases, blue/green deployments, A/B test-\ning, and header-based routing. \n8.2.2\t\nAdvanced traffic-splitting features\nLet’s start by looking at how you can implement a canary release for one of our appli-\ncation’s services with a Knative Service. This section starts by looking into doing canary \nreleases using percentage-based traffic splitting. Then it goes into A/B testing by using \ntag-based and header-based traffic splitting.\nCanary releases using percentage-based traffic splitting\nIf you get the Knative Service resource (with kubectl get ksvc notifications \n-service -oyaml), you will notice that the spec section now also contains a spec.\ntraffic section (as shown in listing 8.3) that was created by default, because we didn’t \nspecify anything. By default, 100% of the traffic is being routed to the latest Knative \nRevision of the service.\nListing 8.3    The Knative Service allows us to set traffic rules\n traffic:\n  - latestRevision: true\n    percent: 100\nNow imagine that you made a change in your service to improve how emails are sent, \nbut your team is not sure how well it will be received by people, and we want to avoid \nhaving any backlash from people not wanting to sign into our conference because of \nthe website. Hence, we can run both versions side-by-side and control how much of the \ntraffic is being routed to each version (Revision in Knative terms).\nLet’s edit (kubectl edit ksvc notifications-service) the Knative Service and \napply the changes, as shown in listing 8.4.\nListing 8.4    Changing our Knative Service\napiVersion: serving.knative.dev/v1\nkind: Service\nmetadata:\n  name: notifications-service \nspec:\n",
      "content_length": 2345,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 240,
      "content": "\t\n221\nKnative Serving: Advanced traffic management and release strategies\n  template:\n    spec:\n      containers:\n        - image: salaboy/image: salaboy/notifications-service-0e27884e01429ab7\ne350cb5dff61b525:v1.1.0 \n          env:\nname: KAFKA_URL \nvalue: <URL>\n  traffic: \n  - percent: 50\n    revisionName: notifications-service-00001\n  - latestRevision: true\n    percent: 50\nIf you try now with curl, you should be able to see the traffic split in action. \nListing 8.5    New requests hitting different versions that are running parallel\ncurl http://notifications-service.default.127.0.0.1.sslip.io/service/info \n{\n  \"name\":\"NOTIFICATIONS-IMPROVED\", \n  \"version\":\"1.1.0\", \n  …\n} \ncurl http://notifications-service.default.127.0.0.1.sslip.io/service/info \n{\n  \"name\":\"NOTIFICATIONS\",\n  \"version\":\"1.0.0\", \n  …\n}\ncurl http://notifications-service.default.127.0.0.1.sslip.io/service/info \n{\n  \"name\":\"NOTIFICATIONS-IMPROVED\", \n  \"version\":\"1.1.0\", \n  …\n} \ncurl http://notifications-service.default.127.0.0.1.sslip.io/service/info \n{\n  \"name\":\"NOTIFICATIONS\",\n  \"version\":\"1.0.0\", \n  …\n}\nOnce you have validated that the new version of your service is working correctly, you \ncan start sending more traffic until you feel confident to move 100% of the traffic to it. \nIf things go wrong, you can revert the traffic split to the stable version. \nYou have updated the container \nimage that the service will use from \n“notifications-service-0e27884e0142\n9ab7e350cb5dff61b525:v1.0.0” to \n“notifications-service-0e27884e0142\n9ab7e350cb5dff61b525:v1.1.0”.\nYou have created a 50% / 50% traffic split where 50% of \nthe traffic will keep going to your stable version and 50% \nto the newest version that you just updated.\nOne in five requests will go to the new \n“NOTIFICATIONS-IMPROVED” version. \nNotice that this can take a while until the \nnew Knative Revision is running.\n",
      "content_length": 1865,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 241,
      "content": "222\nChapter 8  Platform capabilities II: Enabling teams to experiment  \nNotice that you are not limited to just two service revisions; you can create as many as \nyou want as long as the traffic percentage sum of all the revisions is 100%. Knative will \nfollow these rules and scale up the required revisions of your services to serve requests. \nYou don’t need to create any new Kubernetes resources, as Knative will create those for \nyou, reducing the likelihood of errors that come with modifying multiple resources \nsimultaneously. \nFigure 8.7 shows some challenges that you will face when using this feature. By using \npercentages, you don’t have control over where subsequent requests will land. Knative \nwill just make sure to maintain a fair distribution based on the percentages that you \nhave specified. This can become a problem if, for example, you have a user interface \ninstead of a simple REST endpoint. \nPercentage-based Traffic \nsplit works when clients \nmake isolated requests and \nthey don’t mind getting \nanswers from different \nversions of the service.\nThis doesn’t work well \nwhen the client makes \nmultiple correlated requests \nand expect all to land in the \nsame version. This is a \ncommon scenarios with \nUser Interfaces and Web \nBrowsers.\n50%\n50%\n50%\n50%\nNotifications \nService\nv1.0.0\nNotifications \nService\nv1.1.0\nFrontend\nv1.0.0\nFrontend\nv1.1.0\nKnative Service\nKnative Service\nClient\nBrowser\nFigure 8.7    Percentage-based traffic split scenarios and challenges\nUser interfaces are complex because a browser will perform several correlated GET \nrequests to render the page HTML, CSS, images, and so forth. You can quickly end \nup in a situation where each request hits a different version of your application. Let’s \nlook at a different approach that might be better suited for testing user interfaces or \nscenarios when we need to ensure that several requests end up in the correct version of \nour application.  \nA/B testing with tag-based routing\nIf you want to perform A/B testing of different versions of the user interface included \nwith the Conference application, you will need to give Knative some way to differenti-\nate where to send the requests. You have two options. First, you can point to a special \nURL for the service you want to try out, and the second is to use a request header to \ndifferentiate where to send the request. Let’s look at these two alternatives in action. \n",
      "content_length": 2417,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 242,
      "content": "\t\n223\nKnative Serving: Advanced traffic management and release strategies\nThe step-by-step tutorial (https://github.com/salaboy/platforms-on-k8s/tree/main/\nchapter-8/knative#run-the-conference-application-with-knative-services) defines all the \nConference application services to be Knative Services and deploys them to the cluster. \nThe Frontend Knative Services looks like listing 8.6.\nListing 8.6    Knative Service definition for the Frontend application\napiVersion: serving.knative.dev/v1\nkind: Service\nmetadata:\n  name: frontend\nspec:\n  template:\n    metadata:\n      annotations:\n        autoscaling.knative.dev/min-scale: \"1\" \n    spec:\n      containers:\n      - image: salaboy/frontend-go-1739aa83b5e69d4ccb8a5615830ae66c:v1.0.0\n        env:\n        - name: KAFKA_URL\n          value: kafka.default.svc.cluster.local\n       …\nOnce again, we have just created a Knative Service, but we cannot specify percent-\nage-based routing rules because this container image contains a web application com-\nposed of HTML, CSS, images, and JavaScript files. Knative will not stop you from doing \nso. Still, you will notice requests going to different versions and errors popping up \nbecause a given image is not in one of the versions, or you end up with the wrong \nstylesheet (CSS) coming from the wrong version of the application. \nLet’s start by defining a Tag that you can use to test a new stylesheet and also \ninclude the Debug tab in the Back Office section. You can do that by modifying the \nKnative Service resource as we did before. First, change the image to salaboy/fron-\ntend-go-1739aa83b5e69d4ccb8a5615830ae66c:v1.1.0, add the FEATURE_DEBUG_\nENABLED environment variable with value true and then create some new traffic rules \nusing the traffic.tag property:\n traffic:\n - percent: 100 \n   revisionName: frontend-00001\n - latestRevision: true\n   tag: version110\nYou need to specify a \nname for this service.\nWe don’t want Knative \nServing to downscale the \nFrontend service if nobody \nis using it. We want to \nkeep at least one instance \nrunning all the time.\nYou now define the Frontend container image, because we are \ngoing to test multiple requests going to the same version.\n100% of the traffic will go to \nour stable version, and no \nrequest will be sent to our \nnewly updated revision with \nversion v1.1.0.\nWe created a new tag called “color”; you \ncan find the URL for this new tag by \ndescribing the Knative Service resource.\n",
      "content_length": 2442,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 243,
      "content": "224\nChapter 8  Platform capabilities II: Enabling teams to experiment  \nAs shown in listing 8.7, if you describe the Knative Service (kubectl describe ksvc \nfrontend) you will find the URL for the tag that we just created, as shown in the fol-\nlowing listing. \nListing 8.7    Traffic rules when using tags\n Traffic:\n    Latest Revision:  false\n    Percent:          100\n    Revision Name:    frontend-00001\n    Latest Revision:  true\n    Percent:          0\n    Revision Name:    frontend-00001\n    Tag:              version110\n    URL:              http://version110-frontend.default.127.0.0.1.sslip.io\nFigure 8.8 shows how the Knative Service will route 100% of the traffic to version v1.0.0 \nwhen no tags are specified. If the tag ”version110” is specified, the Knative Service will \nroute traffic to the version v1.1.0.\nClient\nKnative Service\nFrontend\nv1.0.0\nFrontend\nv1.1.0\n100%\nOnly Tag: \nversion110\nFigure 8.8    Knative Serving tag-based routing for version v1.1.0.\nUsing a web browser, check that you can consistently access version v1.1.0 by using \nthe following URL (http://version110-frontend.default.127.0.0.1.sslip.io) and version \nv.1.0.0 using the original service URL (http://frontend.default.127.0.0.1.sslip.io). Fig-\nure 8.9 shows both side by side using a different color palette. \nv1.0.0 - 100% traffic\nv1.1.0 - Tag based traffic\nFigure 8.9    A/B testing with tag-based routing\nYou can find the tag and its generated \nURL in the ksvc traffic section.\n",
      "content_length": 1473,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 244,
      "content": "\t\n225\nKnative Serving: Advanced traffic management and release strategies\nUsing tags guarantees that all requests are hitting the URL to the correct version of \nyour service. One more option avoids you pointing to a different URL for doing A/B \ntesting, and it might be useful for debugging purposes. The next section looks at tag-\nbased routing using HTTP headers instead of different URLs. \nA/B testing with header-based routing\nFinally, let’s look at a Knative Serving feature (https://knative.dev/docs/serving/\nconfiguration/feature-flags/#tag-header-based-routing) that allows you to use HTTP \nheaders to route requests. This feature also uses tags to know where to route traffic, \nbut instead of using a different URL to access a specific revision, you can add an HTTP \nheader that will do the trick. \nImagine that you want to enable developers to access a debugging version of the \napplication. Application developers can set a special header in their browsers and then \naccess a specific revision. \nTo enable this experimental feature, you or the administrator that installs Knative \nneeds to patch a ConfigMap inside the knative-serving namespace: \nkubectl patch cm config-features -n knative-serving  \n➥-p ‘{\"data\":{\"tag-header-based-routing\":\"Enabled\"}}’\nOnce the feature is enabled, you can test this by using the tag version110 that we cre-\nated before. Listing 8.8 shows the traffic rules that we have defined. The tag name that \nwe want to target using HTTP header-based routing is highlighted.\nListing 8.8    HTTP headers-based routing using the name of the tag \n traffic:\n - percent: 100 \n   revisionName: frontend-00001\n - latestRevision: true\n   tag: version110\nIf you point your browser to the Knative Service URL (kubectl get ksvc), you will \nsee the same application as always, as shown in figure 8.10, but if you use a tool like \nModHeader extension (https://chrome.google.com/webstore/detail/modheader/\nidgpnmonknjnojddfkpgkljpfnnfcklj?hl=en) for Chrome, you can set your custom \nHTTP headers that will be included in every request that the browser produces. For \nthis example, and because the tag that you created is called version110, you need to \nset the following HTTP header: Knative-Serving-Tag: version110. As soon as the \nHTTP header is present, Knative Serving will route the incoming request to the ver-\nsion110 tag. \nFigure 8.10 shows how Knative Serving routes the request to our version110 tag by \nusing an HTTP header set using ModHeader. Notice that we are using the default ser-\nvice URL http://frontend.default.127.0.0.1.sslip.io.\n",
      "content_length": 2572,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 245,
      "content": "226\nChapter 8  Platform capabilities II: Enabling teams to experiment  \nFigure 8.10    Using ModHeader Chrome extension to set custom HTTP headers for header-based routing.\nBoth tag and header-based routing are designed to ensure that all requests will be \nrouted to the same revision if you hit a specific URL (created for the tag) or if one par-\nticular header is present. Finally, let’s look at how to do blue/green deployments with \nKnative Serving. \nBlue/green deployments\nFor situations where we need to change from one version to the next at a very specific \npoint in time, because there is no backward compatibility, we can still use tag-based \nrouting with percentages. Instead of going gradually from one version to the next, we \nuse percentages as a switch from 0 to 100 on the new version and from 100 to 0 on the \nold version. \nMost blue/green deployment scenarios require coordination between different \nteams and services to make sure that both the service and the clients are updated at the \nsame time. Knative Serving allows you to declaratively define when to switch from one \nversion to the next in a controller way. Figure 8.11 shows the scenario where we want to \ndeploy a new version of the notifications service v2.0.0 that is not backward compati-\nble with v1.x versions. This means that this upgrade will require changes to the clients. \nBy using Knative Serving traffic rules and tags, we can decide when the switch happens. \nTeams responsible for the clients and the upgrade of the notification service v2.0.0 \nwill need to coordinate the upgrade. \n",
      "content_length": 1576,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 246,
      "content": "\t\n227\nKnative Serving: Advanced traffic management and release strategies\nUpdate to v2.0.0 and update \ntraffic rules\n \nv2.0.0 is not \nbackward \ncompatible\nWhen teams are \ncomfortable with v2.0.0, \nthey will need to \ncoordinate the update of \nthe clients (v2.0.0) and \nswitch 100% of the traffic \nto the `green` tag.\n0% Tag: green\n100% Tag: green\n100%\n0%\nblue\ngreen\nKnative Service\nblue\ngreen\nClient\nClient \nv2.0.0\nKnative Service\nNotifications \nService\nv1.0.0\nNotifications \nService\nv2.0.0\nNotifications \nService\nv1.0.0\nNotifications \nService\nv2.0.0\nFor situations where v2.0.0\nis not backward compatible\nwith v1.0.0, we can use\n a Tag for internal teams \nto test v2.0.0. \nFigure 8.11    Blue/green deployments using Knative Serving tag-based routing\nTo achieve the scenario described in figure 8.11, we can create the “green” tag for the \nnew version inside our Knative Service, as shown in listing 8.9. \nListing 8.9    Using tags to define blue and green revisions\n...\ntraffic:\n    - revisionName: <blue-revision-name>\n      percent: 100 # All traffic is still being routed to the first revision\n    - revisionName: <green-revision-name>\n      percent: 0 # 0% of traffic routed to the second revision\n      tag: green # A named route\nBy creating a new tag (called “green”), we will now have a new URL to access the new \nversion for testing. This is particularly useful for testing new versions of the clients, \nbecause if the Service API is changing with a non-backward compatible change, clients \nmight need to be updated as well. Once all tests are performed, we can safely switch \nall traffic to the “green” revision of our service, as shown in listing 8.10. Notice that we \nremoved the tag from the \"green\" revision and created a new tag for the \"blue\" revision.\nListing 8.10    Switching traffic using the Knative declarative approach\n...\ntraffic:\n    - revisionName: <first-revision-name>\n      percent: 0 # All traffic is still being routed to the first revision\n",
      "content_length": 1972,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 247,
      "content": "228\nChapter 8  Platform capabilities II: Enabling teams to experiment  \n      tag: blue # A named route\n    - revisionName: <second-revision-name>\n      percent: 100 # 100% of traffic routed to the second revision\nNotice that the “blue” original version before the update is now accessible using \nheader–or tag–based routing and is receiving all the traffic sent to the service.\nGenerally, we cannot progressively move traffic from one version to the next, because \nthe client consuming the service will need to understand that requests might land in \ndifferent (and non-compatible) versions of the service.  \nIn the previous sections, we have been looking into how Knative Serving simplifies \nthe implementation of different release strategies for your teams to deliver features \nand new versions of your services continuously. Knative Serving reduces the need to \ncreate several Kubernetes built-in resources to manually implement the release strat-\negies described in this chapter. It provides high-level abstractions such as Knative Ser-\nvices, which creates and manages Kubernetes built-in resources and a network stack for \nadvanced traffic management. \nLet’s switch to another alternative for managing release strategies in Kubernetes \nwith Argo Rollouts. \n8.3\t\nArgo Rollouts: Release strategies automated with GitOps\nIn most cases you will see Argo Rollouts working hand in hand with ArgoCD. This \nmakes sense because we want to enable a delivery pipeline that removes the need \nto interact with our environments to apply configuration changes manually. For the \nexamples in the following sections, we will focus only on Argo Rollouts, but in real-life \nscenarios, you shouldn’t apply resources to the environments using kubectl, because \nArgo CD will do it for you. \nAs defined on the website, Argo Rollouts is “a Kubernetes controller and set of CRDs \nwhich provide advanced deployment capabilities such as blue-green, canary, canary \nanalysis, experimentation, and progressive delivery features to Kubernetes.” As we have \nseen with other projects, Argo Rollouts extend Kubernetes with the concepts of Roll-\nouts, Analysis, and Experimentations to enable progressive delivery features. The \nmain idea with Argo Rollouts is to use the Kubernetes built-in blocks without the need \nto manually modify and keep track of deployment and services resources. \nArgo Rollouts is composed of two big parts: the Kubernetes controller that imple-\nments the logic to deal with our rollouts, definitions (also analysis and experimenta-\ntions) and a kubectl plugin that allows you to control how these rollouts progress, \nenabling manual promotions and rollbacks. Using the kubectl Argo Rollouts plugin, \nyou can also install the Argo Rollouts Dashboard and run it locally. \nNOTE     You can follow a tutorial on how to install Argo Rollouts on a local Kuber-\nnetes KinD cluster at https://github.com/salaboy/platforms-on-k8s/blob/ \nmain/chapter-8/argo-rollouts/README.md. Notice that this tutorial requires \ncreating a different KinD cluster than the one we used for Knative Serving. \n",
      "content_length": 3081,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 248,
      "content": "\t\n229\nArgo Rollouts: Release strategies automated with GitOps\nLet’s start by looking at how we can implement canary releases with Argo Rollouts to \nsee how it compares with using plain Kubernetes resources or Knative Services. \n8.3.1\t\nArgo Rollouts canary rollouts\nWe’ll begin by creating our first Rollout resource. With Argo Rollouts, we will be not \ndefining deployments, because we will delegate this responsibility to the Argo Rollouts \ncontroller. Instead, we define an Argo Rollouts resource that also provides our pod \nspecification (PodSpec in the same way that a Deployment defines how pods need to \nbe created). \nFor these examples, we will use only the notifications service from the Conference \nplatform application, and we will not use Helm. When using Argo Rollouts, we need to \ndeal with a different resource type currently not included in the Conference applica-\ntion Helm charts. Argo Rollouts can work perfectly fine with Helm, but we will create \nfiles to test how Argo Rollouts behave for these examples. You can take a look at an Argo \nRollouts example using Helm at https://argoproj.github.io/argo-rollouts/features/\nhelm/. Let’s start by creating an Argo Rollouts resource for the notifications service in \nlisting 8.11. \nListing 8.11    Argo Rollouts resource definition\napiVersion: argoproj.io/v1alpha1\nkind: Rollout\nmetadata:\n  name: notifications-service-canary\nspec:\n  replicas: 3\n  strategy:\n    canary: \n      steps: \n      - setWeight: 25\n      - pause: {}\n      - setWeight: 75\n      - pause: {duration: 10}\n  revisionHistoryLimit: 2\n  selector:\n    matchLabels:\n      app: notifications-service\n  template:\n    metadata:\n      labels:\n        app: notifications-service\n    spec:\n      containers:\n      - name: notifications-service\n        image: salaboy/notifications-service-<HASH>:v1.0.0\n        env: \n          - name: KAFKA_URL\n            value: kafka.default.svc.cluster.local\n          ... \nThe Rollouts resource definition \nallows us to configure our workloads \nto use different releases.\nNotice that as \nwith \ndeployments, we \ncan set up the \nnumber of \nreplicas that we \nwant for our \nnotification \nservice.\nThis example sets the \nspec.strategy property \nto canary, which \nrequires a set of \nspecific steps to \nconfigure how the \ncanary release will \nbehave for this specific \nservice.\nThe steps defined will be executed in sequence when \nwe make any update on our service. For this example, \nthe canary will start with 25% of the traffic and wait \nfor manual promotion and then switch to 75%, wait \nfor 10 seconds, and finally move to 100%.\n",
      "content_length": 2589,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 249,
      "content": "230\nChapter 8  Platform capabilities II: Enabling teams to experiment  \nNOTE    You can find the full file at https://github.com/salaboy/platforms-on \n-k8s/blob/main/chapter-8/argo-rollouts/canary-release/rollout.yaml. \nThis Rollout resource manages the creation of Pods using what we define inside the \nspec.template and spec.replicas fields. But it adds the spec.strategy section, \nwhich for this case is set to canary and defines the steps (amount traffic (weight) that \nwill be sent to the canary) in which the rollout will happen. As you can see, you can also \ndefine a pause between each step. The duration is expressed in seconds and allows \nus to have a fine-grain control of how the traffic is shifted to the canary version. If you \ndon’t specify the duration parameter, the rollout will wait there until manual inter-\nvention happens. Let’s see how this rollout works in action. \nLet’s apply the Rollout resource to our Kubernetes cluster (check the step-by-step tuto-\nrial available at https://github.com/salaboy/platforms-on-k8s/tree/main/chapter-8/ \nargo-rollouts#canary-releases for all the steps): \n> kubectl apply -f argo-rollouts/canary-release/ \nNOTE    This command will also create a Kubernetes service and a Kubernetes \ningress resource. \nRemember, if you are using ArgoCD, instead of manually applying the resource, \nyou will push this resource to your Git repository that Argo CD is monitoring. Once \nthe resource is applied, we can see that a new Rollout resource is available by using \nkubectl, as shown in listing 8.12.\nListing 8.12    Getting all Argo Rollouts resources\n> kubectl get rollouts.argoproj.io \nNAME                           DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   \nnotifications-service-canary   3         3         3            3                     \nThis looks pretty much like a normal Kubernetes deployment, but it is not. If you use \nkubectl get deployments, you shouldn’t see any deployment resource available \nfor our email-service. Argo Rollouts replace the use of Kubernetes deployments \nby using Rollouts resources, which are in charge of creating and manipulating replica \nsets, we can check using kubectl get rs that our Rollout has created a new Replica-\nSet. See listing 8.13. \nListing 8.13    Getting the ReplicaSet created by our Rollout \n> kubectl get rs\nNAME                                    DESIRED   CURRENT   READY   \nnotifications-service-canary-7f6b88b5fb   3          3         3             \n",
      "content_length": 2465,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 250,
      "content": "\t\n231\nArgo Rollouts: Release strategies automated with GitOps\nArgo Rollouts will create and manage these replica sets that we used to manage with \ndeployment resources, but in a way that enables us to smoothly perform canary \nreleases. \nIf you have installed the Argo Rollouts Dashboard, you should see our Rollout on the \nmain page (see figure 8.12).\nFigure 8.12    \nArgo Rollouts \nDashboard\nAs with deployments, we still need a service and an ingress to route traffic to our ser-\nvice from outside the cluster; these resources are included in the step-by-step tutorial \n(https://github.com/salaboy/platforms-on-k8s/tree/main/chapter-8/argo-rollouts/\ncanary-release). If you create the following resources, you can start interacting with the \nstable service and with the canary, as shown in figure 8.13.\nRollout\nStrategy: Canary\nSteps: 25%, Wait \nfor Manual \nPromotion, 75% \nPod #1\nApprox. Weight 75%\nApprox. Weight 25%\nReplica Set #1\n(Stable)\nService\nIngress\nReplica Set #2\n(canary)\nPod #2\nPod #3\nPod #4\nFigure 8.13    Argo Rollouts canary release Kubernetes resources. The Rollout controls the ReplicaSets \nand manage the approximate weights based on the number of pods in each ReplicaSet.\nIf you create a service and an ingress, you should be able to query the notifications ser-\nvice service/info endpoint by using the following curl command:\n> curl localhost/service/info | jq\nThe output should look like listing 8.14. \n",
      "content_length": 1426,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 251,
      "content": "232\nChapter 8  Platform capabilities II: Enabling teams to experiment  \nListing 8.14    Interacting with version v1.0.0 of the notification service\n{\n  \"name\": \"NOTIFICATIONS\",\n  \"version\": \"1.0.0\",\n  \"source\": \"https://github.com/salaboy/platforms-on-k8s/tree/main/ \n➥conference-application/notifications-service\",\n  \"podName\": \"notifications-service-canary-7f6b88b5fb-fq8mm\",\n  \"podNamespace\": \"default\",\n  \"podNodeName\": \"dev-worker2\",\n  \"podIp\": \"10.244.1.5\",\n  \"podServiceAccount\": \"default\"\n}\nThe request shows the output of the service/info endpoint of our notifications \nservice. Because we have just created this Rollout resource, the Rollout canary strat-\negy mechanism didn’t kick in just yet. Now if we want to update the Rollout spec \n.template section with a new container image reference or change environment vari-\nables, a new revision will be created, and the canary strategy will kick in. \nIn a new terminal, we can watch the Rollout status before doing any modification, so \nwe can see the Rollout mechanism in action when we change the Rollout specification. \nIf we want to watch how the rollout progresses after we make some changes, you can run \nthe following command in a separate terminal: \n> kubectl argo rollouts get rollout notifications-service-canary --watch\nYou should see something like figure 8.14.\nFigure 8.14    Rollout details using the argo plugin for kubectl\n",
      "content_length": 1397,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 252,
      "content": "\t\n233\nArgo Rollouts: Release strategies automated with GitOps\nLet’s modify our notification-service-canary rollout by running the following \ncommand: \n> kubectl argo rollouts set image notifications-service-canary notifications-\nservice=salaboy/notifications-service-0e27884e01429ab7e350cb5dff61b525:v1.1.0\nAs soon as we replace the container image used by the Rollout, the rollout strategy will \nkick in. If you go back to the terminal where you are watching the rollout, you should \nsee that a new # revision: 2 was created; see figure 8.15.\nFigure 8.15    Rollout progress after updating the service\nYou can see that revision 2 is labeled as the “canary” and the status of the rollout is “॥ \nPaused” and only one pod is created for the canary. So far, the rollout has only exe-\ncuted the first step, as in listing 8.15.\nListing 8.15    Steps definition in our Rollout\nstrategy:\n   canary:\n     steps:\n     - setWeight: 25\n     - pause: {}\nYou can also check the status of the canary Rollout in the dashboard, as shown in figure \n8.16.\n",
      "content_length": 1038,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 253,
      "content": "234\nChapter 8  Platform capabilities II: Enabling teams to experiment  \nFigure 8.16     \nA canary release \nhas been created \nwith approximately \n20% of the traffic \nbeing routed to it.\nThe Rollout is currently paused waiting for manual intervention. We can now test that \nour canary is receiving traffic to see if we are happy with how the canary is working \nbefore continuing the rollout process. To do that, we can query the “service/info” end-\npoint again to see that approximately 25% of the time we hit the canary, as in listing \n8.16.\nListing 8.16    Example output hitting version v1.1.10 from our notification service\n> curl localhost/service/info | jq\n{\n  \"name\":\"NOTIFICATIONS-IMPROVED\",\n  \"version\":\"1.1.0\",\n  …\n}\nWe can see that one request hit our stable version and one went to the canary. \nArgo Rollouts is not dealing with traffic management; in this case, the Rollout \nresource is only dealing with the underlying ReplicaSet objects and their replicas. You \ncan check the ReplicaSets by running kubectl get rs, as in listing 8.17.\nListing 8.17    Checking the ReplicaSets associated to our Rollout\n> kubectl get rs\nNAME                                      DESIRED   CURRENT  READY   AGE\nnotifications-service-canary-68fd6b4ff9   1         1        1       12s\nnotifications-service-canary-7f6b88b5fb      3          3         3        17m\nThe traffic management between these different pods (canary and stable pods) \nis being managed by the Kubernetes Service resource, so to see our request hitting \nboth the canary and the stable version pods, we need to go through the Kubernetes \nservice. I am only mentioning this because if you use kubectl port-forward svc/ \nnotifications-service 8080:80, for example, you might be tempted to think that \n",
      "content_length": 1763,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 254,
      "content": "\t\n235\nArgo Rollouts: Release strategies automated with GitOps\ntraffic is being forwarded to the Kubernetes service (because we are using svc/noti-\nfications-service), but kubectl port-forward resolves to a pod instance and \nconnects to a single pod, allowing you only to hit the canary or a stable pod. For this \nreason, we have used an ingress, which will use the service to load balance traffic and \nhit all the pods that are matching to the service selector.  \nIf we are happy with the results, we can continue the rollout process by executing the \nfollowing command, which promotes the canary to be the stable version: \n> kubectl argo rollouts promote notifications-service-canary\nAlthough we have just manually promoted the rollout, the best practice would be uti-\nlizing Argo Rollouts automated analysis steps, which we will dig into in section 8.3.2.\nIf you look at the Argo Rollouts Dashboard, you will notice that you can also promote \nthe rollout to move forward using the Button Promote in the Rollout. Promotion in this \ncontext only means that the rollout can continue to execute the next steps defined in \nthe spec.strategy section, as shown in listing 8.18.\nListing 8.18    Rollouts steps definition with 10 seconds pause\n strategy:\n   canary:\n     steps:\n     - setWeight: 25\n     - pause: {}\n     - setWeight: 75\n     - pause: {duration: 10}\nAfter the manual promotion, the weight is going to be set to 75%, followed by a pause \nof 10 seconds, to finally set the wait to 100%. At that point, you should see that revision \n1 is being downscaled while progressively revision 2 is being upscaled to take all the \ntraffic. See figure 8.17, which shows the final state of the rollout. \nFigure 8.17    Rollout finished with all the traffic shifted to revision 2\n",
      "content_length": 1773,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 255,
      "content": "236\nChapter 8  Platform capabilities II: Enabling teams to experiment  \nYou can see this rollout progression live in the dashboard as well in figure 8.18.\nFigure 8.18    \nThe canary \nrevision is \npromoted to \nbe the stable \nversion.\nAs you can see, revision 1 was downscaled to have zero pods, and revision 2 is now \nmarked as the stable version. If you check the ReplicaSets, you will see the same out-\nput, as shown in listing 8.19. \nListing 8.19    The ReplicaSet responsible for revision 1 is downscaled to 0\n> kubectl get rs\nNAME                                      DESIRED   CURRENT   READY   \nnotifications-service-canary-68fd6b4ff9   3         3         3       \nnotifications-service-canary-7f6b88b5fb      0          0          0       \nWe have successfully created, tested, and promoted a canary release with Argo Rollouts! \nCompared to what we have seen in section 8.1 for canary releases, using two deploy-\nment resources to implement the same pattern with Argo Rollouts, you have full con-\ntrol over how your canary release is promoted, how much time you want to wait before \nshifting more traffic to the canary and how many manual interventions steps do you \nwant to add. Let’s now see how a blue/green deployment works with Argo Rollouts.\n8.3.2\t\nArgo Rollouts blue/green deployments \nIn section 8.1 we covered the advantages and the reasons why you would be interested \nin doing blue/green deployments using Kubernetes basic building blocks. We have \nalso seen how manual the process is and how these manual steps can open the door for \nsilly mistakes that can bring our services down. In this section, we will look at how Argo \nRollouts allows us to implement blue/green deployments following the same approach \nwe previously used for canary deployments. Check the step-by-step tutorial for Argo \nRollouts blue/green deployments at https://github.com/salaboy/platforms-on-k8s/\ntree/main/chapter-8/argo-rollouts#bluegreen-deployments. Let’s look at what our \nRollout with a BlueGreen strategy looks like in listing 8.20. \n",
      "content_length": 2039,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 256,
      "content": "\t\n237\nArgo Rollouts: Release strategies automated with GitOps\nListing 8.20    Rollout defining a BlueGreen strategy\napiVersion: argoproj.io/v1alpha1\nkind: Rollout\nmetadata:\n  name: notifications-service-bluegreen\nspec:\n  replicas: 2\n  revisionHistoryLimit: 2\n  selector:\n    matchLabels:\n      app: notifications-service\n  template:\n    metadata:\n      labels:\n        app: notifications-service\n    spec:\n      containers:\n      - name: notifications-service\n        image: salaboy/notifications-service-<HASH>:v1.0.0\n        env: \n          - name: KAFKA_URL\n            value: kafka.default.svc.cluster.local\n          ..\n  strategy:\n    blueGreen: \n      activeService: notifications-service-blue\n      previewService: notifications-service-green\n      autoPromotionEnabled: false\nNOTE    You can find the full file at https://github.com/salaboy/platforms-on \n-k8s/blob/main/chapter-8/argo-rollouts/blue-green/rollout.yaml. \nLet’s apply the resources for this Rollout resource to work (two Kubernetes services \nand an ingress):\n> kubectl apply -f argo-rollouts/blue-green/\nWe are using the same spec.template as before, but now we are setting the strategy of \nthe rollout to be blueGreen, and because of that, we need to configure the reference \nto two Kubernetes services. One service will be the Active service (Blue), which is serv-\ning production traffic, and the other one is the Green service that we want to preview \nbut without routing production traffic to it. The autoPromotionEnabled: false is \nrequired to allow for manual intervention for the promotion to happen. By default, \nthe rollout will be automatically promoted as soon as the new ReplicaSet is ready/\navailable. You can watch the rollout running the following command or in the Argo \nRollouts Dashboard:\n> kubectl argo rollouts get rollout notifications-service-bluegreen --watch\nIn the following figure, you should see output similar to the output we saw for the \ncanary release.\n",
      "content_length": 1957,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 257,
      "content": "238\nChapter 8  Platform capabilities II: Enabling teams to experiment  \nFigure 8.19    Checking the state of our BlueGreen Rollout\nAnd in the dashboard, see figure 8.20. \nFigure 8.20    \nBlue/green \ndeployment in \nthe Argo Rollouts \nDashboard.\nWe can interact with revision #1 using an ingress to the service and then send a request \nlike listing 8.21. \nListing 8.21    Hitting revision 1 of our service\n> curl localhost/service/info\n{\n  \"name\":\"NOTIFICATIONS\",\n  \"version\":\"1.0.0\",\n  …\n}\nIf we now make changes to our Rollout spec.template the blueGreen strategy will \nkick in. For this example, the expected result that we want to see is that the preview \nService is now routing traffic to the second revision that is created when we make \nchanges to the rollout: \n> kubectl argo rollouts set image notifications-service-bluegreen   \n➥notifications-service=salaboy/notifications-service-<HASH>:v1.1.0\n",
      "content_length": 903,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 258,
      "content": "\t\n239\nArgo Rollouts: Release strategies automated with GitOps\nThe rollout mechanism will kick in, and it will automatically create a new ReplicaSet \nwith revision 2 that includes our changes. Argo Rollouts for blue/green deployments \nwill use selectors to route traffic to our new revision by modifying the previewService \nthat we referenced in our Rollout definition. \nIf you describe the notifications-service-green Kubernetes service, you will \nnotice that a new selector was added, as in listing 8.22. \nListing 8.22    Kubernetes service selectors managed by Argo Rollouts\n> kubectl describe svc notifications-service-green\nName:              notifications-service-green\nNamespace:         default\nLabels:            <none>\nAnnotations:       argo-rollouts.argoproj.io/managed-by-rollouts: \nnotifications-service-bluegreen\nSelector:          app=notifications-service,rollouts-pod-template-\nhash=645d484596\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                10.96.198.251\nIPs:               10.96.198.251\nPort:              http  80/TCP\nTargetPort:        http/TCP\nEndpoints:         10.244.2.5:8080,10.244.3.6:8080\nSession Affinity:  None\nEvents:            <none>\nThis selector matches with the revision 2 ReplicaSet that was created when we made \nthe changes, as shown in listing 8.23. \nListing 8.23    The ReplicaSet uses the same labels to match the service definition\n> kubectl describe rs notifications-service-bluegreen-645d484596\nName:           notifications-service-bluegreen-645d484596\nNamespace:      default\nSelector:       app=notifications-service,rollouts-pod-template-\nhash=645d484596\nLabels:         app=notifications-service\n                rollouts-pod-template-hash=645d484596\nAnnotations:    rollout.argoproj.io/desired-replicas: 2\n                rollout.argoproj.io/revision: 2\nControlled By:  Rollout/notifications-service-bluegreen\nReplicas:       2 current / 2 desired\nPods Status:    2 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=notifications-service\n           rollouts-pod-template-hash=645d484596\n",
      "content_length": 2116,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 259,
      "content": "240\nChapter 8  Platform capabilities II: Enabling teams to experiment  \nBy using the selector and labels, the Rollout with the blueGreen strategy is handling \nthese links automatically for us. This avoids the need to create these labels manually \nand makes sure they match. As shown in figure 8.21, you can check now that there are \ntwo revisions (and ReplicaSets) with two pods each.\nFigure 8.21    Both Blue and Green services have the same amount of replicas running\nIn the Argo Rollouts Dashboard you should see the same information as in figure 8.22.\nFigure 8.22    \nArgo Rollouts \nDashboard \nBlue and Green \nrevisions are up\nWe can now interact with the Green service (revision #2) using a different path in our \nIngress in the following listing.\n",
      "content_length": 753,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 260,
      "content": "\t\n241\nArgo Rollouts: Release strategies automated with GitOps\nListing 8.24    interacting with revision 2 (our Green service)\n> curl localhost/green/service/info | jq                        \n{\n  \"name\": \"NOTIFICATIONS-IMPROVED\",\n  \"version\": \"1.1.0\",\n  \"source\": \"https://github.com/salaboy/platforms-on-k8s/tree/v1.1.0/ \n➥conference-application/notifications-service\",\n  \"podName\": \"notifications-service-bluegreen-645d484596-rsj6z\",\n  \"podNamespace\": \"default\",\n  \"podNodeName\": \"dev-worker\",\n  \"podIp\": \"10.244.2.5\",\n  \"podServiceAccount\": \"default\"\n}\nOnce we have the Green service running, the Rollout is in a Paused state until we decide \nto promote it to be the stable service. Figure 8.23 shows how the Rollout resource will \norchestrate the many replicas the Green and Blue services will have depending on the \nprogress of the rollout. \nThe Rollout update \nthe Services with the \ncorrect labels to \nmatch the Pods \ncreated by the \ndifferent Replica Sets.\nThe Rollout creates \nand manage Replica \nSets, when new \nchanges are detected \nin the spec.template \nsection of the Rollout.\nRollout\nStrategy: BlueGreen\n-     blueService\n-     greenService\nReplica Set #1\n(active)\nReplica Set #2\n(preview)\nIngress\nService\n(blue)\nService\n(green)\nPod #1\nPod #2\nPod #3\nPod #4\nFigure 8.23    Blue/green deployment with Kubernetes resources\nBecause we now have two services, we can access both at the same time and make sure \nthat our Green (green-service) is working as expected before promoting it to be our \nmain (blue) service. While the service is in preview, other services in the cluster can start \nrouting traffic to it for testing purposes, but to route all the traffic and replace our Blue \nservice with our Green service, we can use once again the Argo Rollouts promotion \nmechanism from the terminal using the CLI or from the Argo Rollouts Dashboard. Try \nto promote the Rollout using the Dashboard now instead of using kubectl. Remember \nthat the command for promoting the rollout from the terminal looks like this: \n>kubectl argo rollouts promote notifications-service-bluegreen\n",
      "content_length": 2085,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 261,
      "content": "242\nChapter 8  Platform capabilities II: Enabling teams to experiment  \nNotice that a 30-second delay is added by default before the scaling down of our revi-\nsion #1 (this can be controlled using the property called scaleDownDelaySeconds), \nbut the promotion (switching labels to the services) happens the moment we hit the \nPROMOTE button, as shown in figure 8.24.\nFigure 8.24    \nGreen service \npromotion using \nthe Argo Rollouts \nDashboard\nThis promotion only switches labels to the services’ resources, which automatically \nchanges the routing tables to now forward all the traffic from the Active service to our \nGreen service. If we make more changes to our Rollout, the process will start again, and \nthe preview service will point to a new revision which will include these changes. Now \nthat we have seen the basics of canary releases and blue/green deployments with Argo \nRollouts, let’s take a look at more advanced mechanisms provided by Argo Rollouts.  \n8.3.3\t\nArgo Rollouts analysis for progressive delivery\nSo far, we have managed to have more control over our different release strategies, but \nArgo Rollouts shine by providing the AnalysisTemplate CRD, which lets us ensure that \nour canary and Green services are working as expected when progressing through our \nrollouts. These analyses are automated and serve as gates for our Rollouts not to prog-\nress unless the analysis probes are successful. \nThese analyses can use different providers to run the probes, ranging from Pro-\nmetheus, Datadog (https://www.datadoghq.com/), New Relic (https://newrelic \n.com/), and Dynatrace (https://www.dynatrace.com/), among others, providing maxi-\nmum flexibility to define these automated tests against the new revisions of our services. \nFigure 8.25 shows how AnalysisTemplates allows Argo Rollouts to create \nAnalysisRuns to validate that the new version that is rolled out is behaving as expected \nby looking at service metrics. AnalysisRuns will probe the service for metrics and only \nproceed with the Rollout steps if the metrics match the success conditions defined in \nthe AnalysisTemplate.\n",
      "content_length": 2109,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 262,
      "content": "\t\n243\nArgo Rollouts: Release strategies automated with GitOps\nAnalysisTemplate\nsuccessCondition: result[0] >= 0.95\nproviderPrometheus: <query>\nRollout\nStrategy: Canary\nSteps: 25%, Wait for Manual \nPromotion, 75%\nAnalysisTemplate\nService\nAnalysisRun #1\nPause\nOK?\nRollout before manual promotion\nRollout if Analysis is successful\nReplica Set #1\n(Stable)\nReplica Set #2\n(Canary)\nReplica Set #1\n(Stable)\nReplica Set #2\n(Canary)\nPod #1\nPod #2\nPod #3\nPod #4\nPod #3\nPod #4\nPod #5\nPod #6\n<create>\n<probe>\n<continue>\nFigure 8.25    Argo Rollouts \nand analysis working \ntogether to make sure that \nour new revisions are sound \nbefore shifting more traffic \nto them. When receiving \nthe signal to move forward \nto the next step of the \nRollout, an AnalysisRun \nis created to probe the \nservice by running a \nquery defined in the \nAnalysisTemplate. The \nAnalysisRun result \naffect if the Rollout’s \nupdate will continue, abort, \nor pause.\nFor canary release, the analysis can be triggered as part of the step definitions, mean-\ning between arbitrary steps, to start at a predefined step or for every step defined in the \nRollout. An AnalysisTemplate using the Prometheus provider definition looks like \nlisting 8.25. \nListing 8.25    AnalysisTemplate resource provided by Argo Rollouts\napiVersion: argoproj.io/v1alpha1\nkind: AnalysisTemplate\nmetadata:\n  name: success-rate\nspec:\n  args:\n  - name: service-name\n  metrics:\n  - name: success-rate\n    interval: 5m\n    # NOTE: prometheus queries return results in the form of a vector.\n    # It is common to access the index 0 to obtain the value\n    successCondition: result[0] >= 0.95\n    failureLimit: 3\n    provider:\n      prometheus:\n        address: http://prometheus.example.com:9090\n        query: <Prometheus Query here>\nThen in our Rollout, we can refer to this template and define when a new AnalysisRun \nwill be created, for example, if we want to run the first analysis after step 2 (listing \n8.26).\n",
      "content_length": 1947,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 263,
      "content": "244\nChapter 8  Platform capabilities II: Enabling teams to experiment  \nListing 8.26    Selecting analysis template when defining canary release\nstrategy:\n    canary:\n      analysis:\n        templates:\n        - templateName: success-rate\n        startingStep: 2 # delay starting analysis run until setWeight: 40%\n        args:\n        - name: service-name\n          value: notifications-service-canary.default.svc.cluster.local\nAs mentioned before, the analysis can also be defined as part of the steps. In that case, \nour steps definition will look like listing 8.27. \nListing 8.27    Using AnalysisTemplate reference as a step in the rollout\nstrategy:\n    canary:\n      steps:\n      - setWeight: 20\n      - pause: {duration: 5m}\n      - analysis:\n          templates:\n          - templateName: success-rate\n          args:\n          - name: service-name\n            value: notifications-service-canary.default.svc.cluster.local \nFor rollouts using a BlueGreen strategy, we can trigger Analysis runs pre- and post-pro-\nmotion. Figure 8.26 shows the PrePromotionAnalysis step by running the SmokeTest-\nTemplate. This will gate the rollout to switch traffic to the Green service if the \nAnalysisRun fails. \nRollout\nStrategy: BlueGreen\n-     activeService\n-     previewService\nPrePromotionAnalysis: \n - SmokeTestsTemplate\n<promote only if `AnalysisRun` succeed>\nAnalysisTemplate\nSmokeTestsTemplate\nAnalysisRun\nSmokeTests\nReplica Set #2\n(preview)\nReplica Set #1\n(active)\nService\n(active)\nService\n(preview)\nIngress\nPod #1\nPod #2\nPod #3\nPod #4\n<linked to>\n<creates>\n<test>\nFigure 8.26    Argo Rollouts with blueGreen deployments and PrePromotionAnalysis in action. When the \npromotion is triggered on the Rollout it will create a new `AnalysisRun` using the `SmokeTestsTemplate` \nbefore switching the labels to route traffic to the Preview Service. Only if the `AnalysisRun` is successful \nthe preview service becomes the new Active Service.\n",
      "content_length": 1938,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 264,
      "content": "\t\n245\nArgo Rollouts: Release strategies automated with GitOps\nHere is an example of PrePromotionAnalysis configured in our Rollout in listing 8.28.\nListing 8.28    Defining a PrePromotionAnalysis as part of a BlueGreen rollout\napiVersion: argoproj.io/v1alpha1\nkind: Rollout\nmetadata:\n  name: notifications-service-rollout\nspec:\n...\n  strategy:\n    blueGreen:\n      activeService: notifications-service-blue\n      previewService: notifications-service-green\n      prePromotionAnalysis:\n        templates:\n        - templateName: smoke-tests\n        args:\n        - name: service-name\n          value: notifications-service-preview.default.svc.cluster.local\nFor PrePromotion tests, run a new AnalysisRun test before switching traffic to the \nGreen service, and only if the test is successful will the labels be updated. For Post-\nPromotion, the test will run after the labels were switched to the Green service, and \nif the AnalysisRun fails, the rollout can automatically revert the labels to the previous \nversion. This is possible because the Blue service will not be downscaled until the Anal-\nysisRun finishes.\nI recommend you check the Analysis section of the official documentation as it con-\ntains a detailed explanation of all the providers and knobs that you can use to make sure \nthat your Rollouts go smoothly: https://argoproj.github.io/argo-rollouts/features/\nanalysis/. \n8.3.4\t\nArgo Rollouts and traffic management\nFinally, it is worth mentioning that Rollouts used the number of pods available to \napproximate the weights we define for canary releases. While this is a good start and \na simple mechanism, sometimes we need more control over how traffic is routed to \ndifferent revisions. We can use the power of service meshes and load balancers to write \nmore precise rules about which traffic is routed to our canary releases. \nArgo Rollouts can be configured with different trafficRouting rules, depending on \nwhich traffic management tool we have available in our Kubernetes cluster. Argo Roll-\nouts today supports: Istio, AWS ALB Ingress Controller, Ambassador Edge Stack, Nginx \nIngress Controller, Service Mesh Interface (SMI), and Traefik Proxy, among others. As \ndescribed in the documentation, if we have more advanced traffic management capa-\nbilities, we can implement techniques like:\n",
      "content_length": 2312,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 265,
      "content": "246\nChapter 8  Platform capabilities II: Enabling teams to experiment  \n¡ Raw percentages (i.e., 5% of traffic should go to the new version while the rest \ngoes to the stable version)\n¡ Header-based routing (i.e., send requests with a specific header to the new \nversion)\n¡ Mirrored traffic where all the traffic is copied and sent to the new version in par-\nallel (but the response is ignored)\nBy using tools like Istio in conjunction with Argo Rollouts, we can enable developers to \ntest features that are only available by setting specific headers or to forward copies of \nthe production traffic to the canaries to validate that they are behaving as they should. \nHere is an example of configuring a Rollout to mirror 35% of the traffic to the canary \nrelease, which has a 25% weight. This means that 35% of the traffic routed to the stable \nservice will be copied and forwarded to the canary. By using this technique, we don’t \nrisk any of the production traffic, because Istio is copying requests for testing purposes, \nas shown in listing 8.29.\nListing 8.29    Using Istio for advanced (weight-based) traffic split \napiVersion: argoproj.io/v1alpha1\nkind: Rollout\nspec:\n  ...\n  strategy:\n    canary:\n      canaryService: notifications-service-canary\n      stableService: notifications-service-stable\n      trafficRouting:\n        managedRoutes:\n          - name: mirror-route\n        istio:\n          virtualService:\n            name: notifications-service-vsvc\n      steps:\n        - setCanaryScale:\n            weight: 25\n      - setMirrorRoute:\n          name: mirror-route\n          percentage: 35\n          match:\n            - method:\n                exact: GET\n              path:\n                prefix: /\n      - pause:\n          duration: 10m\n      - setMirrorRoute:\n          name: \"mirror-route\" # removes mirror based traffic route\n",
      "content_length": 1850,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 266,
      "content": "\t\n247\nLinking back to platform engineering\nAs you can see, this simple example already requires knowledge of Istio Virtual Services \nand a more advanced configuration that is out of the scope of this section. I strongly \nrecommend checking Istio in Action by Christian Posta and Rinor Maloku (Manning \nPublications, 2022) if you want to learn about Istio. Figure 8.27 shows Rollouts config-\nured to use Istio traffic management capabilities to do weight-based routing. \nRollout\nStrategy: Canary\ntrafficRouting:\nistio: \nmirrorRoute\nIstio\nService\nReplica Set #1\n(Stable)\nReplica Set #2\n(canary)\nPod #1\nPod #3\nPod #2\nPod #5\n<configures>\n<controls how traffic \nis delivered to the \nService>\nWeight 100%\nWeight 25%\n<mirrored traffic>\nPod #4\nFigure 8.27    Traffic mirroring to canary release using Istio. Using tools like Istio to set \ntrafficRouting enables our canary workloads to experience real life traffic that the stable service \nis receiving. The Rollout Controller is in charge of configuring Istio Virtual Services to do the work for us \nand has a fine-grained control about which traffic is delivered to the Service.\nWhen using “trafficManagement” features, the Rollout canary strategy will behave dif-\nferently than when we are not using any rules. More specifically, the Stable version of \nthe service will not be downscaled when going through a canary release rollout. This \nensures that the Stable service can handle 100% of the traffic. The usual calculations \napply to the canary replica count.  \nI strongly recommend checking the official documentation (https://argoproj \n.github.io/argo-rollouts/features/traffic-management/) and following the examples \nthere, because the rollouts need to be configured differently depending on the service \nmesh that you have available. \n8.4\t\nLinking back to platform engineering\nIn this chapter, we have seen what can be achieved with basic Kubernetes building \nblocks and how tools like Argo Rollouts or Knative Serving simplify the life of teams by \nreleasing new versions of their applications to Kubernetes. \n",
      "content_length": 2063,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 267,
      "content": "248\nChapter 8  Platform capabilities II: Enabling teams to experiment  \nIt is unfortunate that as of today, in 2023, Argo Rollouts and Knative Serving hav-\nen’t been integrated yet (https://github.com/argoproj/argo-rollouts/issues/2186), \nbecause both communities would benefit from a consolidated way of defining release \nstrategies instead of duplicating functionality. I like the Knative Serving building blocks \nthat facilitate implementing these release strategies. On the other hand, I like how \nArgo Rollouts takes things to the next level with the concepts of AnalysisTemplates \nto ensure we can automatically test and validate new releases. The future is promising, \nbecause both projects are looking for further integrations with the Gateway API stan-\ndard (https://gateway-api.sigs.k8s.io/) to unify how advanced traffic routing capabil-\nities are managed in Kubernetes. Tools like Istio, Knative Serving, and Argo Rollouts \nhave active initiatives to support this new standard.\nI firmly believe that you will face delivery challenges sooner or later in your Kuber-\nnetes journey, and having these mechanisms available inside your clusters will increase \nyour confidence to release more software faster. Hence, I don’t take the evaluation \nof these tools lightly. Make sure you plan time for your teams to research and choose \nwhich tools they will use to implement these release strategies; many software vendors \ncan assist you and provide recommendations too.\nFrom a platform engineering perspective, we have looked into how to enable devel-\nopers to be more efficient by providing them application-level APIs that they can con-\nsume no matter their language. We have enabled other teams, like product managers \nor more business-focused teams, to decide when certain features are enabled and how \nto perform different release strategies depending on their needs. We enabled opera-\ntions teams to define the rules safely to validate that new Rollouts are safe and working \nas expected.\nWhile the focus of this chapter wasn’t analyzing tools like Knative Serving in detail, it \nis important to mention containers-as-a-service and function-as-a-service features when \nbuilding platforms, because these represent common traits that platform teams might \nwant to expose to their users. I would also recommend checking Knative Functions \n(https://knative.dev/docs/functions/), now an official Knative module, because the \nproject highlights the importance of building a function-based development workflow \nbased on Knative and leveraging the polyglot approach of Kubernetes.\nFigure 8.28 shows tools like Knative Serving provide basic building blocks for plat-\nform teams to expose different ways to deploy and run different teams’ workloads. By \nadding advanced traffic management, teams can implement more complex release \nstrategies. Argo Rollouts and Knative Serving work with Istio Service Mesh, which will \ncover other important aspects, such as mTLS for encryption and observability. Tools \nlike Dapr and OpenFeature fit perfectly in this picture by providing standard interfaces \nfor teams to use while at the same time enabling platform teams to define the backing \nimplementations without committing to a single solution.\n",
      "content_length": 3240,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 268,
      "content": "\t\n249\nLinking back to platform engineering\nStandard Application-level APIs\nEnvironment\nTransparent Security and Observability\nContainers-as-a- \nService\nFunctions-as-a- \nService\nRelease Strategies\nInfrastructure \nProvisioning\nFeature Flags \nDashboards\nRelease Gates and \nMonitoring\nPipelines\nSecurity\nIdentity \nManagement\nObservability\nPlatform\n<manage>\nFigure 8.28    Platform capabilities defined to manage environments.\nI do see tools like Knative, Argo Rollouts, Dapr, Istio, and OpenFeature leading the \nway in this space, and still, even if teams need to figure out all the details of each of \nthese tools, patterns are emerging. These tools have been around for over three years, \nand you can notice the maturity of their features, roadmaps, and the people involved. \nWith some of these projects graduating from the incubation process at the CNCF, I \nexpect more integrations to help users with common workflows that most companies \nare implementing by hand today.\nFinally, to recap our journey so far, figure 8.29 shows how release strategies fit into \nour platform walking skeleton and how teams closer to the business (product teams, \nstakeholders) can use these mechanisms to validate new versions before fully moving all \ncustomers to the latest version.\nThe Platform provides tools \nand mechanisms to enable \nteams to experiment with \nnew versions in a safe way. \nOur Platform\nPlatform APIs\nEnvironment\nApplication-Level APIs\nApplication V1\nApplication V2\nObservability\nInfrastructure\nGitOps Sync\nProvisioning \nCloud Resources\nService Pipelines\nFeature Flags \nDashboard\nRelease \nStrategies\nEnvironments \nConfiguration \nRepository\nContainer \nRegistry\nManages\nFigure 8.29    Environments that enable teams to experiment with new versions \n",
      "content_length": 1749,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 269,
      "content": "250\nChapter 8  Platform capabilities II: Enabling teams to experiment  \nIn the next chapter, to close the book, I’ve decided to talk about how we can mea-\nsure the platforms we are building on top of Kubernetes. The platform capabilities \ndescribed in these last two chapters and the combinations of tools described in this \nbook are good because we are improving our team’s velocity for delivering software. \nTherefore, using metrics that focus on how efficient our teams are in delivering soft-\nware directly correlates with the tools offered by the platform for these teams to use. \nSummary\n¡ Implementing common release strategies such as canary releases, blue/green \ndeployments, and A/B testing can be challenging using Kubernetes built-in \nresources. \n¡ Knative Serving introduces an advanced networking layer that gives us fine-grain \ncontrol over how traffic is routed to different versions of our services that can \nbe deployed simultaneously. This feature is implemented on top of Knative Ser-\nvices and reduces the manual work of creating several Kubernetes resources for \nimplementing canary releases, blue/green deployments, and A/B testing release \nstrategies. Knative Serving simplifies the operational burden of moving traffic to \nnew versions and, with the help of the Knative autoscaler, can scale up and down \nbased on demand. \n¡ Argo Rollouts integrates with ArgoCD (discussed in chapter 4) and provides an \nalternative to implement release strategies using the concept of Rollouts. Argo \nRollouts also include features to automate testing new releases to ensure we \nmove safely between versions (AnalysisTemplates and AnalysisRuns). \n¡ Platform teams must enable stakeholders (business, product managers, oper-\nations) to experiment by providing flexible mechanisms and workflows that \nreduce the risk of releasing new versions of the applications that they are working \nwith. \n¡ Following the step-by-step tutorials, you gain hands-on experience using Knative \nServices and different patterns to route traffic to the Conference application. \nYou also gained experience using Argo Rollouts to implement canary releases \nand blue/green deployments.\n",
      "content_length": 2170,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 270,
      "content": "251\n9\nMeasuring your platforms\nThis chapter covers\n¡ Learning the importance of measuring platform \t\n\t performance\n¡ Implementing DORA metrics and learning the \t\n\t secret continuous improvement \n¡ Using tools and standards to collect and  \n\t calculate metrics\nIn chapter 8, we covered the principles of how to build a platform that helps you \ndeliver software and enables your teams to have the tools they need when needed. \nThis last chapter is all about making sure that the platform is working, not only for \napplication development teams, but for the entire organization. To understand how \nthe platform is performing, we need to be able to measure it. There are different \nways of taking measurements on the software we run. Still, in this chapter, we will \nfocus on the DORA (DevOps Research and Assessment) metrics, which provide a \ngood foundation for understanding our organization’s software delivery speed and \nhow good we are at recovering from failures when they happen. \nThis chapter is divided into two main sections:\n",
      "content_length": 1033,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 271,
      "content": "252\nChapter 9  Measuring your platforms\n¡ What to measure: DORA metrics and high-performant teams\n¡ How to measure our platform initiatives: \n–\t CloudEvents and CDEvents to the rescue\n–\t Keptn Lifecycle Toolkit\nLet’s get started by understanding what we should be measuring, and for that, we will \nneed to look at the DORA metrics. \n9.1\t\nWhat to measure: DORA metrics and high-performant teams\nAfter performing thorough research in the industry, the DevOps Research and Assess-\nment (DORA) team has identified five key metrics that highlight the performance of \nsoftware development teams delivering software. Initially, in 2020, only four keys were \ndefined so that you might find references to the “DORA four keys”’ metrics. After sur-\nveying hundreds of teams, DORA discovered which indicators and metrics separated \nhigh-performant/elite teams from the rest, and the numbers were quite shocking. \nDORA used the following four keys to rank teams and their practices: \n¡ Deployment frequency: How often an organization successfully releases software in \nfront of their customers\n¡ Lead time for change: The time that it takes a change produced by an application \nteam to reach live customers\n¡ Change failure rate: The number of problems that are created by new changes \nbeing introduced to our production environments\n¡ Time to restore service: How long it takes to recover from a problem in our produc-\ntion environments\nFigure 9.1 shows the DORA metrics by category, where the first two are associated with \nteams’ velocity. The second two, change failure rate and time to restore service, indi-\ncate how likely we are as an organization to recover from failure. \nDeployment \nFrequency\nLead Time for \nChange\nChange Failure \nRate\nTime to Restore \nService\nVelocity Metrics\nRecovery Metrics\nFigure 9.1    \nDORA metrics \nby category\nIn 2022, a fifth key metric focused on reliability was added to cover operational per-\nformance. We will only discuss on the four software delivery metrics, because this book \nfocuses on application development teams and not operation teams.\n",
      "content_length": 2076,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 272,
      "content": "\t\n253\nWhat to measure: DORA metrics and high-performant teams\nThese five key metrics, as shown in the reports, establish a clear correlation between \nhigh-performing teams and their velocity expressed by these metrics. If you manage \nyour teams to reduce their deployment frequency (that is, how often they deploy new \nversions in front of your users) and reduce the time caused by incidents, your software \ndelivery performance will increase. \nIn this chapter, we will look at how to calculate these metrics for the platforms we are \nbuilding to ensure that these platforms are improving our continuous delivery prac-\ntices. To collect data and calculate these metrics, you will need to tap into different \nsystems that your teams are using to deliver software. For example, if you want to calcu-\nlate deployment frequency, you will need access to data from the production environment \nevery time a new release is deployed (see figure 9.2). Another option would be to use \ndata from the environment pipelines performing the releases to our production envi-\nronment. Figure 9.2 shows how we can observe our CI/CD pipelines and the produc-\ntion environment to calculate a metric like deployment frequency.\nApplication\nProduction \nEnvironment\nDeployment \nFrequency\nCI/CD Pipelines\nFigure 9.2    \nDeployment \nfrequency data \nsources.\nIf you want to calculate lead time for change, you will need to aggregate data coming from \nyour source code version control system like GitHub/GitLab/BitBucket and have a \nway to correlate this information with the artifacts that are being deployed into pro-\nduction (figure 9.3). \nProduction \nEnvironment\nCI Pipelines\nCD Pipelines\nLead Time for \nChange\nApplication\nGit\nArtifact \nRepository\nFigure 9.3    \nLead time for \nchange data \nsources\nSuppose you have a straightforward way to correlate commits to artifacts and later to \ndeployments. In that case, you can rely on a few sources, but if you want to have a more \ndetailed understanding of where the bottlenecks are, you might choose to aggregate \nmore data to be able to see where time is being spent. \nYou might need to tap into incident management and monitoring tools to calculate \nchange failure rate and time to restore service, as in figure 9.4. \n",
      "content_length": 2241,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 273,
      "content": "254\nChapter 9  Measuring your platforms\nCD Pipelines\nApplication\nProduction \nEnvironment\nIncident \nManagement\nMonitoring\nChange Failure \nRate\nTime to Restore \nService\nFigure 9.4    \nRecovery \nmetrics data \nsources\nFor recovery metrics (change failure rate and time to restore service), data collection \ncan be more challenging, because we need to find a way to measure the time when the \napplication performance is degraded or there is downtime. This might involve reports \nfrom actual users experiencing problems with our applications. \n9.1.1\t\nThe integration problem\nThis quickly becomes a system integration challenge. In general terms, we need to \nobserve the systems involved in our software delivery process, capture relevant data, \nand then have the mechanisms to aggregate this information. Once this information \nis available, we can use these metrics to optimize our delivery processes and find and \nsolve bottlenecks.\nWhile some projects already provide DORA metrics out of the box, you must evalu-\nate if they are flexible enough to plug your systems into them. The Four Keys project by \nGoogle provides an out-of-the-box experience to calculate these metrics based on exter-\nnal outputs. You can read more about it at https://cloud.google.com/blog/products/\ndevops-sre/using-the-four-keys-to-measure-your-devops-performance. \nUnfortunately, the Four Keys project requires you to run on the Google Cloud Plat-\nform because it uses BigData and Google Cloud run to do the calculations. Following \nthe principles of this book, we need a solution that works across cloud providers and uses \nKubernetes as the baseline. Other tools like LinearB (https://linearb.io/) offer a SaaS \nsolution to track different tools. I also recommend a blog post by Codefresh (https:// \ncodefresh.io/learn/software-deployment/dora-metrics-4-key-metrics-for-improving \n-devops-performance/) that explains the challenges of calculating these metrics and \nthe data points that you will need to do so.\nTo have a Kubernetes-native way to calculate these metrics, we need to standardize \nthe way we consume information from different systems, transform this information \ninto a model that we can use to calculate these metrics, and make sure that different \norganizations can extend this model with their metrics and their very diverse sources \nof information. In the next section, we will look at two standards that can help us with \nthis mission: CloudEvents (https://cloudevents.io/) and CDEvents (https://cdevents \n.dev/).\n",
      "content_length": 2510,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 274,
      "content": "\t\n255\nHow to measure our platform: CloudEvents and CDEvents\n9.2\t\nHow to measure our platform: CloudEvents and CDEvents\nMore and more tools and service providers are adopting CloudEvents (https://\ncloudevents.io) as a standard way to wrap event data. In this book, we have covered \nTekton (https://tekton.dev) and Dapr PubSub (https://dapr.io), but if you look on \nthe official CloudEvents website (go to https://cloudevents.io and scroll to the Cloud \nEvents Adopters section), you can find all the projects that already support the stan-\ndard. In that list, you will find Argo Events (https://argoproj.github.io/argo-events/) \nand Knative Eventing (https://knative.dev/docs/eventing/), projects that we haven’t \ncovered but that work very well with the tools described in previous chapters. I find \nit interesting to see cloud provider services such as GoogleCloud Eventarc (https:// \ncloud.google.com/eventarc/docs) and Alibaba Cloud EventBridge (https://www \n.alibabacloud.com/help/en/eventbridge) in the list, which indicates that CloudE-\nvents are here to stay. \nWhile seeing more adoption is an excellent indicator, much work remains when you \nreceive or want to emit a CloudEvent. CloudEvents are simple and thin envelopes for \nour events data. Figure 9.5 shows the very simple structure of a CloudEvent. The specifi-\ncation defines the CloudEvent required metadata and verifies that the CloudEvent will \nhave a Payload that contains the event data that we want to send to other systems.\nCloudEvent Metadata\n(id, type, source, specversion)\nCloudEvent Payload\nCloudEvent\nStandard fields and \nextensions\nThis is where our event \ndata goes. \nFigure 9.5    CloudEvents, a simple envelope to wrap our events data\nUsing CloudEvents, developers emit and consume events by relying on the Cloud­\nEvents specification to know at least what the events are about. Because the Cloud­\nEvents specification is not transport-specific, we can use different transports to move \nCloudEvents around. The specification includes the definition of bindings for proto-\ncols such as AMQP, HTTP, AVRO, KAFKA, NATS, MQQT, JSON, XML, websockets, and \nwebhooks. You can find the full list at https://github.com/cloudevents/spec/tree/\nmain#cloudevents-documents. \nWhen we used Dapr PubSub in chapter 7, we used the CloudEvents SDK to verify \nthe type of the event and get the CloudEvent payload (https://github.com/salaboy/ \nplatforms-on-k8s/blob/v2.0.0/conference-application/frontend-go/frontend \n.go#L118). Projects like Tekton, Knative Eventing, and Argo Events already produce \nand provide CloudEvents sources that we can consume. For example, Knative Eventing \n",
      "content_length": 2644,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 275,
      "content": "256\nChapter 9  Measuring your platforms\nprovides sources for GitHub, GitLab, the Kubernetes API Server, Kafka, RabbitMQ, \netc. (https://knative.dev/docs/eventing/sources/#knative-sources). Argo Events adds \nto the list Slack and Stripe, but it gives us 20+ out-of-the-box event sources (https:// \nargoproj.github.io/argo-events/concepts/event_source/). While projects like Tek-\nton provide us with internal events for their own managed resources such as pipelines, \ntasks, pipelineRuns and taskRuns, it would be great to collect events about other tools \nin a unified way. \nIf we want to measure how the tools we include in our platform are helping our teams \nto release more software, we need to tap into these event sources to collect data, aggre-\ngate data, and extract meaningful metrics. Figure 9.6 shows different events sources \nthat we can tap into to measure how tools are helping teams to deliver more software, \nbut if we want to calculate metrics, we will need to store these events somewhere for \nfurther processing.\nApplication \nInfrastructure\nInternal \nServices\nArtifact \nRepositories\nEvents \nStore\nEvent Sources\nRepositories\nEnvironments\nServices\nPipelines\nFigure 9.6    Event sources and event store\nIf we want to use these events to calculate metrics, we will need to open the envelope, \nread the data, and based on that, aggregate and correlate these events together.\nThis has proven challenging, as each tool that generates CloudEvents can define its \nschemas for the CloudEvent payload. We would need to understand how each system \nis encoding the payload to extract the data we need to calculate our metrics. Wouldn’t \nit be great to have some standard model to quickly filter and consume these events \nbased on what they mean for our software delivery needs? Welcome CDEvents (https:// \ncdevents.dev).\n9.2.1\t\nCloudEvents for continuous delivery: CDEvents\nCDEvents is just CloudEvents but with a more specific purpose. They map to different \nphases of our continuous delivery practices. CDEvents is an initiative that the Contin-\nuous Delivery Foundation (https://cd.foundation) drives, and as its website defines, \nthey focus on enabling interoperability across different tools that are related to con-\ntinuous delivery: “CDEvents is a common specification for Continuous Delivery events, \nenabling interoperability in the complete software production ecosystem” (https://\ncdevents.dev).\n",
      "content_length": 2411,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 276,
      "content": "\t\n257\nHow to measure our platform: CloudEvents and CDEvents\nTo provide interoperability, the CDEvents specification defines four stages (https://\ngithub.com/cdevents/spec/blob/v0.3.0/spec.md#vocabulary-stages). These stages \nare used to group events that are conceptually related to different phases and tools in \nour software delivery ecosystem:\n¡ Core: Events related to the orchestration of tasks usually come from pipeline \nengines. Here you will find the specification of the events around the subjects \n“taskRun” and “pipelineRun.” Events like “PipelineRun started” or “TaskRun \nqueued” can be found at this stage.\n¡ Source code version control: Events related to changes associated with your source \ncode. The specification focuses on covering the subjects: “repository,” “branch,” \nand “change.” Events like “Change created” or “Change Merged” can be found \nat this stage.\n¡ Continuous integration: Events related to building software, producing artifacts, \nand running tests. This stage covers the subjects “artifact,” “build,” “testCase,” \nand “testSuite.” Events like “Artifact published” or “Build finished” can be found \nat this stage.\n¡ Continuous deployment: Events related to deploying software in different envi-\nronments. The subjects covered in this stage are “services” and “environments.” \nEvents like “service deployed” or “environment modified” can be found at this \nstage.\n¡ Continuous operations: Events related to the incidents related to our running \nservices.\nFigure 9.7 shows these categories and some example events for each.\nPipelineRun Started\nCore\nSource Code Version \nControl\nContinuous \nIntegration\nContinuous \nDeployment\nContinuous \nOperations\nTaskRun Queued\nPipelineRun Finished\nRepository Created\nBranch Deleted\nChange Merged\nArtifact Published\nBuild Finished\nTest Suite Started\nService Deployed\nEnvironment Created\nService Updated\nIncident Detected\nIncident Reported\nIncident Resolved\nFigure 9.7     \nThe four stages \ndefined by \nthe CDEvents \nspecification\n",
      "content_length": 1997,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 277,
      "content": "258\nChapter 9  Measuring your platforms\nWe can easily use CDEvents to calculate our software delivery metrics, because they \nalready cover the subjects that these metrics are interested in. For example, we can use \nevents from the continuous deployment stage to calculate the deployment frequency met-\nric. We can combine continuous deployment events and source code version control \nevents to calculate lead time for change. \nThe question then becomes, where do we get CDEvents from? CDEvents is a much \nnewer specification that is currently being incubated at the CDFoundation, and it is my \nfirm belief that as part of the interoperability story, this specification can serve as a hook \nmechanism for different tools and implementations to map their tools to a standard \nmodel that we can use to calculate all these metrics while allowing legacy systems (and \ntools that are not emitting cloud events) to benefit from them too. \nThis chapter will use the CDEvents specification to define our standardized data \nmodel. We will collect information from various systems using CloudEvents and rely on \nCDEvents to map the incoming events into the different stages of our software delivery \npractice. Figure 9.8 shows the most common sources of events that can be related to \nsoftware delivery. \nSource Version Control\nYour Custom Source\nCloud Provider Service\nPipelines\nReporting Tools\nEnvironments\nMonitoring Tools\nCDevents\nFigure 9.8    CDEvents are more specialized CloudEvents for continuous delivery.\nTools like Tekton are already providing experimental support for CDEvents (https://\nwww.youtube.com/watch?v=GAm6JzTW4nc), and as we will see in the next section, \nwe can transform CloudEvents into CDEvents using functions. More importantly, the \nCDEvents Working Group is also focused on providing software development kits \n(SDKs) in different languages so you can build your applications that consume and \nemit CDEvents no matter the programming language you are using. \nThe next section will examine how a Kubernetes-based solution for calculat-\ning DORA metrics can be built and extended to support different metrics and event \nsources. This is important to ensure that different platforms using different tools can \nuse their performance and detect early bottlenecks and improvement points. Notice \nthat this is just an example of how different tools can be wired together in the context of \nprojects related to Kubernetes. \n",
      "content_length": 2435,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 278,
      "content": "\t\n259\nHow to measure our platform: CloudEvents and CDEvents\n9.2.2\t\nBuilding a CloudEvents-based metrics collection pipeline\nTo calculate the metrics proposed by the DORA team (deployment frequency, lead \ntime for change, change failure rate, and time to restore service), we need to collect \ndata. Once we have the data coming from different systems, we need to transform the \ndata into a standardized model that we can use to calculate the metrics. Then we need \nto process the data to calculate the values for each metric. We need to store the results \nof these calculations, and then we need to make them available to everyone interested, \nprobably using a graphical dashboard that summarizes the data collected and the cal-\nculated metrics.\nDifferent tools can be used to build this data collection, transformation, and aggre-\ngation pipeline. Still, to build a simple yet extensible solution, we will use some of the \ntools covered in the previous chapters, such as Knative Serving to build our aggrega-\ntion and transformation functions, CloudEvents, and CDEvents. We will also use Kna-\ntive Eventing event sources, but this demo can be easily extended to support any other \nCloudEvent source, such as Argo Events. This section is divided into three subsections: \n¡ Data collection from event sources\n¡ Data transformation to CDEvents\n¡ Metrics calculations\nThese sections map one to one with the proposed architecture that, from a high level, \nlooks like figure 9.9. \nEvent \nSources\nData \nTransformation\nDatabase\nDatabase\nDatabase\nMetrics \nCalculation\nData Collection\nFigure 9.9    Collecting and transforming data to calculate DORA metrics\nFrom a high-level perspective, we need to architect our data collection and transfor-\nmation pipeline to support any number of event sources, because different companies \nand implementations will collect data from systems that we cannot anticipate. We are \nimposing the data to be in the form of CloudEvents before it enters our system. If you \nhave event sources not following the CloudEvents specification, you must adapt their \ndata to follow the specification. This can be easily achieved using the CloudEvents \nSDKs (https://cloudevents.io/ > SDKs section) to wrap your existing events to follow \nthe specification.\nOnce the data enters our system, we will store it in persistent storage. In this case, \nwe have used a PostgreSQL database to store all the incoming data and calculations. \n",
      "content_length": 2442,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 279,
      "content": "260\nChapter 9  Measuring your platforms\nComponents don’t directly call the next stage (data transformation). Instead, each \ncomponent periodically fetches data from the database and processes all the data \nthat hasn’t been processed yet. This stage (data transformation) transforms incoming \nCloudEvents already stored in the database into CDEvents structures that will be used \nto calculate the metrics. Once the transformation to the CDEvents structure happens, \nthe result is stored in a separate table in our PostgreSQL database. Finally, the “metrics \ncalculation” stage periodically reads from the database all new CDEvents that haven’t \nbeen processed and calculates the metrics we have defined.\nThis simple architecture allows us to plug in new data sources, new transformation \nlogic depending on the data we receive, and finally, new metrics calculation logic for \nyour domain-specific metrics (not only DORA metrics). It is also important to notice \nthat as soon as we guarantee that the incoming data is correctly stored, all the trans-\nformations and calculations can be recalculated if the metrics data is lost. Let’s look \ndeeper at the stages required to calculate the simplest DORA four key metrics, “deploy-\nment frequency.” \n9.2.3\t\nData collection from event sources\nAs shown in figure 9.9, we want to consume data from multiple sources, but we have \nset CloudEvents as the standard input format. While CloudEvents has been widely \nadopted, many systems still don’t support the standard. This section will look into Kna-\ntive Sources as a mechanism that can declaratively define our event sources and trans-\nform non-CloudEvent data into CloudEvents.\nThe proposed solution then exposes a REST Endpoint to receive incoming Cloud­\nEvents. Once we have CloudEvents, we will validate the data and store it in a Post-\ngreSQL table called cloudevents_raw. Let’s look at Knative Eventing event sources, \nbecause we can just install and configure these event sources to produce events for us \nautomatically.\n9.2.4\t\nKnative Eventing event sources\nWith Knative Eventing event sources, you can install existing or create new event \nsources. Figure 9.10 shows some of the event sources provided out of the box and \nhow these events will be routed to the data collection step of our data transformation \npipeline. \nREST\nKubernetes \nAPI Server\nGitHub\nRabbitMQ\nYour Source\nData \nCollection\nDatabase\nEvent Sources\nFigure 9.10    \nKnative \nSources and \ndata collection\n",
      "content_length": 2471,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 280,
      "content": "\t\n261\nHow to measure our platform: CloudEvents and CDEvents\nSeveral Knative Eventing event sources are provided out of the box by the Knative com-\nmunity and different software vendors. The following list is not exhaustive, but it cov-\ners some of the sources that you might want to use to calculate your metrics: \n¡ APIServerSource\n¡ PingSource\n¡ GitHubSource\n¡ GitLabSource\n¡ RabbitMQSource\n¡ KafkaSource\nCheck the complete list of third-party sources at https://knative.dev/docs/eventing/\nsources/#third-party-sources. These sources transform events, for example, from the \nKubernetes API Server, GitHub, or RabbitMQ AMQP messages into CloudEvents.\nIf you want to use one of the available Knative Sources, for example, the APIServer-\nSource, you just need to ensure that the source is installed in your cluster and then \nconfigure the source according to your needs(see listing 9.1). For calculating the \ndeployment frequency metric, we will tap into Kubernetes Events related to deploy-\nments. You can declaratively configure the source and where the events will be sent by \ndefining an APIServerSource resource. \nListing 9.1    Knative Source APIServerSource definition\napiVersion: sources.knative.dev/v1\nkind: ApiServerSource\nmetadata:\n name: main-api-server-source \nspec:\n serviceAccountName: api-server-source-sa\n mode: Resource\n resources:\n   - apiVersion: v1\n     kind: Event\nApiServerSource is the resource type that we use to configure the \nKnative ApiServerSource component that reads from the Kubernetes \nEvent stream (https://www.cncf.io/blog/2021/12/21/extracting-value \n-from-the-kubernetes-events-feed/), transforms these events to \nCloudEvents, and sends them to a sink (target destination). \nAs with every \nKubernetes resource, \nwe need to define a \nname for this resource. \nWe can configure as \nmany ApiServerSources \nas we want.\nBecause we are reading events from the \nKubernetes API server, we need to have access. \nHence, a ServiceAccount needs to exist to enable \nthe ApiServerSource components to read from \nthe internal event stream. You can check the \nServiceAccount, Role, and RoleBinding \nresources that are needed for this \nApiServerSource resource to work at https://\ngithub.com/salaboy/platforms-on-k8s/blob/\nmain/chapter-9/dora-cloudevents/ \napi-serversource-deployments.yaml.\nAs defined before, this source is \ninterested in resources of type Event. \n",
      "content_length": 2386,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 281,
      "content": "262\nChapter 9  Measuring your platforms\n sink: \n   ref:\n     apiVersion: v1\n     kind: Service\n     name: cloudevents-raw-service\n     namespace: dora-cloudevents\nAs you can imagine, the ApiServerSource will generate tons of events, which are sent \nto cloudevents-raw-service and stored in the PostgreSQL database. More complex \nrouting and filtering can be configured only to forward events that interest us, but we \ncan also apply filtering in the next stages, allowing for an approach that can enable \nus to add more metrics as we evolve our data collection process. With this source, we \nwill receive one or more CloudEvents and store them in the database whenever a new \ndeployment resource is created, modified, or deleted. \nIf you have a system already producing events but need CloudEvents, you can \ncreate your own Custom Knative Eventing event source. Look at the following tuto-\nrial for more information on how to do this: https://knative.dev/docs/eventing/\ncustom-event-source/custom-event-source/. \nThe big advantage of declaring and managing your event sources using Knative \nEventing event sources is that you can query your sources as any other Kubernetes \nresource, monitor and manage their state, and troubleshoot when problems arise using \nall the tools available in the Kubernetes ecosystem. Once CloudEvents are stored in our \ndatabase, we can analyze them and map them into CDEvents for further calculations. \n9.2.5\t\nData transformation to CDEvents\nNow that we have CloudEvents in our PostgreSQL database, we have validated that \nthey are valid CloudEvents. We want to transform some of these very generic Cloud \nEvents into CDEvents, which we will use to calculate our metrics. \nAs explained in the introduction, these transformations will depend on what kind of \nmetrics you are trying to calculate. For this example, we will look into internal Kuberne-\ntes events related to deployment resources to calculate the deployment frequency met-\nric, but completely different approaches can be used. For example, instead of looking \ninto Kubernetes internal events, you can look into ArgoCD events or Tekton Pipeline \nevents to monitor when deployments are triggered but from outside the cluster. Fig-\nure 9.11 shows the mapping and transformation process that needs to happen to map \nCloudEvent to CDEvents.\nIn the sink section, we define where we want to send the CloudEvents generated from this \nsource. In this case, we use a service reference to a Kubernetes Service named \ncloudevents-raw-service, which lives in the four-keys namespace. Knative Sources, when \nreferencing other Kubernetes resources, will check that these resources exist and only be \nready when the target service is found. Alternatively, we can point to a URI if the service \ndoesn’t live in the Kubernetes API context, but we lose this valuable check that can help us \nto troubleshoot scenarios where we are sending events to a non-existing endpoint.\n",
      "content_length": 2946,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 282,
      "content": "\t\n263\nHow to measure our platform: CloudEvents and CDEvents\nData \nTransformation\nDatabase\nDatabase\nFigure 9.11    \nMapping and \ntransforming from \nCloudEvents to \nCDEvents\nWe need a way to map a very generic CloudEvent to a concrete CDEvent that indi-\ncates that a service deployment has happened or has been updated. This mapping and \ntransformation logic can be written in any programming language as we only deal with \nCloudEvents and CDEvents. Because of the volume of events we might be receiving, it \nis essential not to block and process all the events as they arrive. For this reason, a more \nasynchronous approach has been chosen here. The data transformation logic is sched-\nuled at fixed periods, which can be configured depending on how often we want/can \nprocess the incoming events. \nFor this example, we will map and translate incoming events with type equal to \ndev.knative.apiserver.resource.add and data.InvolvedObject.Kind equal to \nDeployment to CDEvents of the type dev.cdevents.service.deployed.0.1.0. This \ntransformation is particular to our needs because it correlates events from the Knative \nAPIServerSource to those defined in the CDEvents specification, as shown in figure \n9.12. \nType = \"dev.knative.apiserver.resource.add\"\nData Transformation\nType = dev.cdevents.service.deployed.0.1.0\ndata.InvolvedObject.Kind = \"Deployment\"\nFigure 9.12    Concrete mapping and CDEvent creation for deployments\nTo calculate different metrics, we will need more of these transformations. One option \nwould be to add all the transformation logic into a single container. This approach \nwould allow us to version all the transformations together as a single unit, but at the \nsame time, it can complicate or limit teams writing new transformations, because they \nhave a single place to change code. An alternative that we can take is to use a func-\ntion-based approach, we can promote the creation of single-purpose functions to do \nthese transformations. By using functions, only functions that are currently transform-\ning events will be running. All the ones that are not being used can be downscaled. If \nwe have too many events to process, functions can be upscaled on demand based on \ntraffic.\n",
      "content_length": 2212,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 283,
      "content": "264\nChapter 9  Measuring your platforms\nDeployment Transformation Function\ndev.cdevents.service.deployed.0.1.0\nPipeline Finished Function\ndev.cdevents.pipelinerun.finished.0.1.0\nChange Transformation Function\ndev.cdevents.change.created.0.1.1\nCDEvents \nEndpoint\nDB \nDB \nData \nTransformation \nRouter\nFigure 9.13    Using functions to map CloudEvents to CDEvents\nAs shown in figure 9.13, a new component is needed to route the CloudEvents being \nread from the database to concrete functions. Each transformation function can trans-\nform the incoming CloudEvent by inspecting its payload, enriching the content with \nan external data source, or simply wrapping the entire CloudEvent into a CDEvent. \nThe data transformation router component must be flexible enough to allow new \ntransformation functions to be plugged into the system and multiple functions to pro-\ncess the same event (the same CloudEvent being sent to one or more transformation \nfunctions). \nTransformation and mapping functions don’t need to care about how the CDEvents \nwill be persisted. This allows us to keep these functions simple and focused on transfor-\nmations only. Once the transformation is done and a new CDEvent is produced, the \nfunction will send the event to the CDEvents endpoint component, which stores the \nCDEvent in our database.  \nBy the end of the transformations, we will have zero or more CDEvents stored in our \ndatabase. These CDEvents can be used by the metric calculation functions that we will \nlook at in the following section.  \n9.2.6\t\nMetrics calculation\nTo calculate our metrics (DORA or custom metrics), we will use the same func-\ntion-based approach we used for the CDEvents transformation and mapping. In \nthis case, we will write functions to calculate different metrics. Because each metric \nrequires aggregating data from different events and maybe systems, each metric cal-\nculation function can implement a different logic, see figure 9.14. The mechanisms \nused to calculate a metric are up to the developers who write the code to perform the \ncalculation.\n",
      "content_length": 2066,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 284,
      "content": "\t\n265\nHow to measure our platform: CloudEvents and CDEvents\nTime To Restore Service\nFunction\nChange Failure Rate\nFunction\nLead Time for Change\nFunction\nDeployment Frequency \nFunction\nDB\nDB\nFigure 9.14    Using functions to calculate DORA metrics\nTo calculate metrics, each function can be configured to fetch very specific CDEvents \nfrom the database and with different periods depending on how often we need to get \nupdates for a particular metric. The metric result can be stored in the database or sent \nto an external system, depending on what you want to do with the calculated data. \nIf we look at calculating the deployment frequency metric for a more concrete exam-\nple, we need to implement a couple of custom mechanisms and data structures to keep \ntrack of the metric, as in figure 9.15.\nselect from \n`cdevents_raw` where \ntype=’dev.cdevents.\nservice\n.deployed.0.1.0’\nCreate Deployments \nstructure Function\ninsert into \ndeployments …\nselect from \ndeployments \n(by day and service)\nGet Deployment \nFrequency Function\nCustom Metric calculation functions\nDB\nDB\nDB\nDashboard\n#1\n#2\n#3\nFigure 9.15    Deployment frequency calculation flow\nA simplified flow for calculating the deployment frequency metric is shown in figure \n9.15 where step #1 is to get CDEvents related to deployments from the cdevents_\nraw table. The Create Deployments structure function is in charge of reading \nCDEvents with type dev.cdevents.service.deployed.0.1.0, inspecting the pay-\nload and metadata, and creating a new structure that can be later queried. Step #2 \nis responsible for persisting this new structure in our database. The main reason for \nthis structure is to make our data easier and more performant to query for the metric \n",
      "content_length": 1722,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 285,
      "content": "266\nChapter 9  Measuring your platforms\nwe are implementing. In this case, a new deployment structure (and table) is created \nto record data we want to use to calculate our deployment frequency metric. For this \nsimple example, the deployment structure contains the service’s name, the timestamp, \nand the deployment’s name. In step #3 we can use this data to get our deployment \nfrequency by service and display this information per day, week, or month. These func-\ntions need to be idempotent, meaning that we can retrigger the calculation of the met-\nrics again using the same CDEvents as input, and we should obtain the same results.\nOptimizations can be added to this flow; for example, a custom mechanism can be \ncreated to avoid reprocessing CDEvents that have already been processed. These cus-\ntomizations can be treated as internal mechanisms for each metric, and developers \nshould be able to add integration with other systems and tools as needed. For the sake \nof the example, the Get Deployment Frequency Function can fetch the metrics from \nthe database. Still, in a more realistic scenario, you can have a dashboard directly que-\nrying the database where the simplified structures are stored, because many dashboard \nsolutions provide an SQL connector out of the box. \nNow that we have covered the flow to calculate the deployment frequency metric \nlet’s look at a working example where we will install all the components required for \ndata collection, data transformation, and metrics calculation.\n9.2.7\t\nWorking example\nThis section will look at a working example, showing how we can combine data col-\nlection, data transformation to CDEvents, and metrics calculation for our Kuberne-\ntes-based platforms. It covers a very basic example and a step-by-step tutorial on how to \ninstall and how to run the components needed to calculate the deployment frequency \nmetric of our deployments (https://github.com/salaboy/platforms-on-k8s/blob/\nmain/chapter-9/dora-cloudevents/README.md).\nThe architecture implemented in this example puts together the stages defined in \nthe previous sections: data collection, data transformation, and metrics calculation. \nOne of the main aspects covered by this architecture is the extensibility and pluggabil-\nity of components for data transformation and metrics calculation. This architecture \nassumes that we will collect data as CloudEvents, so the user is responsible for trans-\nforming their event sources to CloudEvents to use this architecture.\nFigure 9.16 shows how all the components are tied together to provide the function-\nality of deciding which events we want to collect and how to transform them into CDE-\nvents so we can calculate DORA metrics with them. \n",
      "content_length": 2721,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 286,
      "content": "\t\n267\nHow to measure our platform: CloudEvents and CDEvents\nCloudEvent to \nCDEvent Transformer\n<Function>\nTimer \nbased\nprotected\nTimer \nbased\nregistry/ \nmapping\nRouter\n* Allows for custom mechanism to keep \ntrack and optimize metrics calculation\nCloudEvent Source\n(GitHub)\nCloudEvent Source\n(Tekton)\nCloudEvent Source\n(Kubernetes)\nCDEvents Endpoint\nCloudEvents Endpoint\nMetrics Endpoints\nDashboard\nGet Metric*\n<Function>\nMetric Calculation\n<Function>\n**Metrics**\ncdevents_raw \nTable\ncloudevents_raw \nTable\nFigure 9.16    Example architecture for capturing and calculating DORA metrics\nWhile the architecture might look complicated initially, it was designed to allow custom \nextensions and mappings necessary to collect and process events from various sources. \nFollowing the step-by-step tutorial, you will create a new Kubernetes cluster to install \nall the components needed to collect CloudEvents and calculate the metrics. Still, the \narchitecture is in no way limited by a single cluster. After you create and connect to \na cluster, you will install tools such as Knative Serving for our function’s runtime and \nKnative Eventing only for our event sources. Once the cluster is ready, you will create a \nnew namespace to host all the components actively processing the data collected and \nan instance of PostgreSQL to store our events.\nStoring events and metrics\nOnce we have our database to store events and metrics information, we need to create \nthe tables for our components to store and read events. For this example, we will create \nthe following tables: cloudevents_raw, cdevents_raw, and deployments, as shown \nin figure 9.17.\n",
      "content_length": 1640,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 287,
      "content": "268\nChapter 9  Measuring your platforms\n`cloudevents_raw`\n`cdevents_raw`\n`deployments`\n`event_timestamp` TIMESTAMP NOT NULL\n`cd_subject_id` varchar(255) NOT NULL\n`event_id` serial NOT NULL\n`content` json NOT NULL\n`deploy_id` varchar(255) NOT NULL\n`time_created` TIMESTAMP NOT NULL\n`deploy_name` varchar(255) NOT NULL\n`cd_type` varchar(255) NOT NULL\n`cd_timestamp` TIMESTAMP NOT NULL\n`cd_source` varchar(255) NOT NULL\n`cd_id` varchar(255) NOT NULL\n`cd_subject_source` varchar(255)\n`content` json NOT nuLL\nFigure 9.17    Tables, CloudEvents, CDEvents, and metrics calculations\nLet’s look at what information we are going to be storing in these three tables. The \ncloudevents_raw table stores all the incoming CloudEvents from different sources. \nThe main purpose of this table is data collection:\n¡ The schema of this table is very simple and only has three columns:\n–\t event_id: This value is generated by the database.\n–\t event_timestamp: Stores the timestamp of when the event is received. This \ncan be later used to order events for reprocessing.\n–\t content: Stores the serialized JSON version of the CloudEvent in a JSON \ncolumn.\n¡ This table is kept as simple as possible because we don’t know what kind of cloud \nevents we are getting, and at this point, we don’t want to unmarshal and read the \npayload, because this can be done in the data transformation stage.\nThe cdevents_raw table stores all the CDEvents we are interested in storing after fil-\ntering and transforming all the incoming CloudEvents. Because CDEvents are more \nspecific, and we have more metadata about these events, this table has more columns: \n¡ cd_id: Stores the CloudEvent ID from the original CloudEvent.\n¡ cd_timestamp: Stores the timestamp of when the original CloudEvent was \nreceived.\n¡ cd_source: Stores the source where the original CloudEvent was generated.\n¡ cd_type: Stores and allows us to filter by different CDEvents types. The types of \nCDEvents stored in this table are defined by the transformation functions run-\nning in our setup. \n¡ cd_subject_id: Stores the ID of the entity associated with this CDEvent. This \ninformation is obtained when our transformation functions analyze the content \nof the original CloudEvent.\n¡ cd_subject_source: Stores the source of the entity associated with this \nCDEvent. \n¡ content: The JSON serialized version of our CDEvent, which includes the origi-\nnal CloudEvent as a payload.\n",
      "content_length": 2414,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 288,
      "content": "\t\n269\nHow to measure our platform: CloudEvents and CDEvents\nThe deployments table is custom to calculate the deployment frequency metric. There \nare no rules to what you store in these custom tables that are used to calculate different \nmetrics. For the sake of simplicity, this table only has three columns:\n¡ deploy_id: The id used to identify a service deployment.\n¡ time_created: When the deployment was created or updated.\n¡ deploy_name: The deployment name used to calculate the metrics.\nOnce we have the tables ready to store our events and metrics data, we need to have \nevents flowing into our components, and for that, we will need to configure event \nsources.\nConfiguring event sources\nFinally, before installing the data transformation or metrics calculation functions, we \nwill configure the Kubernetes API Server event source from Knative Eventing to detect \nwhen new deployments are being created. See figure 9.18.\nKnative Eventing \nAPI Server Source\nKubernetes Cluster\nKubernetes \nEvent Stream\nDeployment\nDeployment\nDeployment\nWorkloads\nFigure 9.18    Example using the Knative Eventing API server source. We can tap into Kubernetes \nEvent Stream by using the Knative Eventing API Server Source, which transforms internal events into \nCloudEvents that can be routed to different systems for filtering and processing.\nHere, you can use any CloudEvent-enabled data source. The Knative API server source \nis an example of how easy it is to consume and route events for further processing. \nCheck projects like Argo Events (https://argoproj.github.io/argo-events/) and \nother Knative Eventing sources (https://knative.dev/docs/eventing/sources/) to \nfamiliarize yourself with what is available out of the box. Also, check the CloudEvents \nspecification adopters list (https://cloudevents.io/), because all these tools are already \ngenerating CloudEvents that you can consume and map to calculate metrics.\nDeploying data transformation and metrics calculation components\nNow that we have a place to store our events and metrics data, and event sources are con-\nfigured and ready to emit events when users interact with our cluster, we can deploy the \ncomponents that will take these events, filter them, and transform them to calculate our \ndeployment frequency metric. The step-by-step tutorial deploys the following components:\n",
      "content_length": 2341,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 289,
      "content": "270\nChapter 9  Measuring your platforms\n¡ CloudEvents endpoint: Exposes an HTTP endpoint to receive CloudEvents and \nconnects to the database to store them.\n¡ CDEvents endpoint: Exposes an HTTP endpoint to receive CDEvents and connects \nto the database to store them.\n¡ CloudEvents router: Reads CloudEvents from the database and routes them to the \nconfigured transformation functions. This component allows users to plug their \ntransformation functions to transform a CloudEvent into a CDEvent for further \nprocessing. The CloudEvents router runs periodically by fetching unprocessed \nevents from the database.\n¡ (CDEvents) transformation function: Users can define transformation functions and \nmap CloudEvents to CDEvents. The idea here is to enable users to add as many \nfunctions as needed to calculate DORA and other metrics.\n¡ (Deployment frequency) calculation function: Metrics calculation functions provide a \nway to calculate different metrics by reading CDEvents from the database. These \nfunctions can store the calculated metrics in custom database tables if needed.\n¡ (Deployment frequency)  metric endpoint: These metric endpoints can be optionally \nexposed for applications to consume the calculated metrics. Alternatively, dash-\nboards can query the data directly from the database.\nFigure 9.19 shows how CloudEvents flows throughout the different components that \nwe have installed.\nCloudEvents Endpoint\nHTTP\nHTTP\nHTTP\nMetrics \nConsumer\nCloudEvents Router\nTransformation Function\nCDEvents Endpoint\nCalculation Function\nMetric Endpoint\nCloudEvents\nData Sources\nDB\nDB\nDB\nFigure 9.19    Data flows from Data Sources producing CloudEvents to the CloudEvents endpoint whose \nonly mission is to store these events into the Event Store. From there, the CloudEvents Router have the \nlogic to decide where to route events to transformation functions, which allows us to map CloudEvents \nto CDEvents for further processing. Once we have CDEvents, the Calculation Functions can read these \nevents to aggregate data and produce metrics. Metrics consumers can get the metrics by interacting \nwith the Metric Endpoint, which will fetch the calculated metrics from the metrics database.\n",
      "content_length": 2192,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 290,
      "content": "\t\n271\nHow to measure our platform: CloudEvents and CDEvents\nAs soon as we have our components up and running, we can start using our cluster to \ngenerate events filtered and processed by these components to produce the deploy-\nment frequency metric.\nDeployment frequency metric for your deployments\nWe need to deploy new workloads to our cluster to calculate the deployment frequency \nmetric. The tutorial includes all the transformation and metric calculation functions \nto monitor events coming from deployment resources. \nWhile development teams can create and update their existing deployments, the \nplatform team can transparently monitor how efficient the platform is to enable teams \nto perform their work. Figure 9.20 shows the teams involved and how the metrics are \ncalculated for this example.\nI have all the tools \nto efficiently deploy  \nmy workloads\nI can monitor \nhow much \nimpact new \ntools have on \ndifferent teams’ \nproductivity.\nApp Dev \nTeams\nPlatform \nTeam\nKnative Eventing \nAPI Server Source\nKubernetes \nEvent Stream\nDeployment\nWorkloads\nFour Keys\nMetrics Endpoint\nCloudEvents Endpoint\nKubernetes Cluster\nFigure 9.20    Components and data flow to measure performance metrics\nFinally, you can curl the following endpoint if you are running the example on KinD: \n> curl http://dora-frequency-endpoint.dora-cloudevents.127.0.0.1.sslip.io/ \n➥deploy-frequency/day | jq\nYou should see something like the following listing.\nListing 9.2    Getting deployment frequency metrics\n[\n   {\n      \"DeployName\":\"nginx-deployment-1\",\n      \"Deployments\":3,\n      \"Time\":\"2022-11-19T00:00:00Z\"\n   },\n   {\n      \"DeployName\":\"nginx-deployment-3\",\n      \"Deployments\":1,\n      \"Time\":\"2022-11-19T00:00:00Z\"\n   }\n]\n",
      "content_length": 1717,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 291,
      "content": "272\nChapter 9  Measuring your platforms\nTransformation and metrics calculation functions are scheduled to run every minute. \nHence, these metrics will be only returned after the functions have been executed. \nAlternatively, you can use a dashboard solution like Grafana to connect to our Post-\ngreSQL database and configure the metrics. Dashboard tools can be focused on the \ntables that store data about particular metrics. For our deployment frequency exam-\nple, the deployments table is the only one relevant for displaying the metrics. \nI strongly recommend you check the example and try to run it locally, follow the \nstep-by-step tutorial, and get in touch if you have questions or want to help improve \nit. Modifying the example to calculate the metrics differently or adding your custom \nmetrics will give you a good overview of how complex these metrics calculations are but, \nat the same time, how important it is to have this information available to our applica-\ntion development and operations teams so they can understand how things are going \nalmost in real-time.  \nIn the next section, we will look at the Keptn Lifecycle Toolkit (https://keptn.sh), \nan open-source and CNCF project that built different mechanisms not only to moni-\ntor, observe, and calculate metrics about our cloud-native applications, but also to take \nactions when things are not going as expected or with integrations with other systems \nare needed. \n9.3\t\nKeptn Lifecycle Toolkit\nThe Keptn Lifecycle Toolkit (KLT) is a cloud-native lifecycle orchestration toolkit. KLT \nfocuses on deployment observability, deployment data access, and deployment check \norchestration. Keptn is not only all about monitoring and observing what is going on \nwith our workloads, but it also provides the mechanisms to check and act when things \ngo wrong.\nAs we saw in the previous section, getting basic metrics such as deployment frequency \ncan be very useful in measuring teams’ performance. While deployment frequency is \njust one metric, we can use that to start measuring our early platform initiatives. In this \nshort section, I wanted to show how KLT can help you with this task by following a differ-\nent but complementary approach to the one discussed in section 9.2.\nKeptn extends the Kubernetes Scheduler component (which decides where our \nworkloads will run on our clusters) to monitor and extract information about our \nworkloads, as in figure 9.21. This mechanism enables teams to set up custom pre/post-­\ndeployment tasks by providing Keptn Task Definitions resources. Keptn is planning to \nuse Kubernetes built-in scheduling gates, a feature that, at the time of writing, is being \nproposed to the Kubernetes community (http://mng.bz/PRW2). \nNOTE  You can follow a step-by-step tutorial to see Keptn in action by following \nthis link: https://github.com/salaboy/platforms-on-k8s/blob/main/chapter-9/ \nkeptn/README.md.\n",
      "content_length": 2904,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 292,
      "content": "\t\n273\nKeptn Lifecycle Toolkit\nGrafana Dashboards\nKeptn Task \nDefinition\nMetrics\nTraces\nPrometheus\nJaeger\nKeptn\nDeployment\nDeployment\nDeployment\nObservability\nKubernetes \nScheduler\nPre/Post Hooks\nFigure 9.21    \nKeptn architecture \nproviding \nout-of-the-box \nobservability \nand application \nlifecycle hooks.\nKeptn uses standard Kubernetes annotations to identify which applications are inter-\nested in being monitored and managed. I have included the following annotations \nfor the Conference application to make Keptn aware of our services. The Agenda ser-\nvice deployment resource includes the following annotations, as shown in listing 9.3 \n(https://github.com/salaboy/platforms-on-k8s/blob/main/conference-application/\nhelm/conference-app/templates/agenda-service.yaml#L14).\nListing 9.3    Kubernetes standard application annotations\napp.kubernetes.io/name: agenda-service\napp.kubernetes.io/part-of: agenda-service\napp.kubernetes.io/version: v1.0.0\nKeptn is now aware of the Agenda service and can monitor and execute actions related \nto this service lifecycle. Notice the part-of annotation, which allows us to monitor sin-\ngle services and group a set of services under the same logical application. This group-\ning allows Keptn to execute pre/post-deployment actions for each service and the \nlogical application (a group of services sharing the same value for the app.kubernetes \n.io/part-of annotation. This example doesn’t use that feature because I want to \nkeep things simple and focused on single services. \nThe step-by-step tutorial installs Keptn, Prometheus, Grafana, and Jaeger so we can \nunderstand what Keptn is doing. Once Keptn is installed in your cluster, you need to \nlet Keptn know which namespaces should be monitored, by annotating the namespace \nresources with a Keptn annotation. You can do that by running the following command \nto enable Keptn in the default namespace: \nkubectl annotate ns default keptn.sh/lifecycle-toolkit=\"enabled\"\nOnce Keptn starts monitoring a specific namespace, it will look for annotated deploy-\nments to start getting metrics that the Keptn Applications Grafana dashboards can \nconsume, as shown in figure 9.22.\n",
      "content_length": 2169,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 293,
      "content": "274\nChapter 9  Measuring your platforms\nFigure 9.22    \nKeptn Application \nGrafana \ndashboard for \nthe notifications \nservice\nThis dashboard shows us our deployment frequency for the annotated deployments \n(all the Conference application’s services) running in the default namespace. In the \nstep-by-step tutorial, we make changes to the notification service deployment so Keptn \ncan detect the change and show the new version in the dashboard. As shown in figure \n9.22, the average time between deployments is 5.83 minutes. On the side, you can see \nexactly how long it took to deploy v1.0.0 and v1.10. Having these dashboards avail-\nable to the teams responsible for each service can help provide visibility on the whole \nprocess of releasing new versions. Having this information available from day one can \nshow progress on how teams improve their workflows or find bottlenecks and recur-\nring problems that can be easily fixed. \nBesides gaining all this information and out-of-the-box metrics, as mentioned before, \nKLT goes one step further by providing hook points to execute pre-/post-­deployment \ntasks. We can use these tasks to validate the environment’s state before performing \na release, send notifications to the teams on call, or just audit the process. After the \ndeployment, we can use post-deployment hooks to run validation tests, send automated \nnotifications to customers about the update, or just congratulate the team for their \namazing work. \nKeptn introduces the KeptnTaskDefinitions resource, which supports Deno \n(https://deno.land/), Python3, or any container image reference (https://lifecycle \n.keptn.sh/docs/yaml-crd-ref/taskdefinition/) to define what the task behavior. The \nKeptnTaskDefinition resource used by the step-by-step tutorial is quite simple, and it \nlooks like listing 9.4. \n",
      "content_length": 1822,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 294,
      "content": "\t\n275\nKeptn Lifecycle Toolkit\nListing 9.4    Keptn TaskDefinition using Deno\napiVersion: lifecycle.keptn.sh/v1alpha3\nkind: KeptnTaskDefinition\nmetadata:\n  name: stdout-notification\nspec:\n  function:\n    inline:\n      code: |\n        let context = Deno.env.get(\"CONTEXT\"); \n        console.log(\"Keptn Task Executed with context: \\n\");\n        console.log(context);\nTo bind a task definition with one of our services, we use a Keptn-specific annotation in \nour deployments: \n keptn.sh/post-deployment-tasks: stdout-notification\nThis annotation will configure Keptn to execute this task after the notification ser-\nvice deployment is changed and the new version is deployed. Keptn will create a new \nKubernetes Job to run the KeptnTaskDefinition. This means you can query all the \npre-/post-deployment task definition executions by looking at the job executions in \nthe default namespace. \nBy using annotations and KeptnTaskDefinitions, the platform engineering team can \ncreate a library of shared tasks that teams can reuse in their workloads, or even better, \nthey can use mutation webhooks or a policy engine like OPA to automatically mutate \nthe deployment resources to add the Keptn annotation. \nIf you change the notification service deployment and then tail the logs, you should \nsee the following (listing 9.5). \nListing 9.5    Expected output from the TaskDefinition execution\nKeptn Task Executed with context: \n{\n  \"workloadName\":\"notifications-service-notifications-service\",\n  \"appName\":\"notifications-service\",\n  \"appVersion\":\"\",\n  \"workloadVersion\":\"v1.1.0\",\n  \"taskType\":\"post\",\n  \"objectType\":\"Workload\"\n}\nThe team will use this resource \nname to define where this task \nwill be executed. This is a \nreusable task definition, so this \ncan be called from different \nservices’ lifecycle hooks.\nWe can access the context of the task that is being executed \nby calling Deno.env.get(\"CONTEXT\"). This provides us with \nall the details used to create the task, such as which \nworkload requests this task to be executed.\n",
      "content_length": 2027,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 295,
      "content": "276\nChapter 9  Measuring your platforms\nIf you look at Jaeger in figure 9.23, you can see all the steps involved in deploying a new \nversion of our notification service by looking at the Keptn Lifecycle Operator traces.\nFigure 9.23    Keptn Lifecycle Operator traces for service updates\nIf you run the step-by-step tutorial on your environment, you can see that the post-de-\nployment hook is being scheduled after the new version of the service is up and \nrunning. \nIn this short section, we have learned the basics of what the Keptn Lifecycle Toolkit \ncan do for us, how we can benefit from having these metrics from day one, and how we \ncan have more control over the lifecycle of our services by adding pre-/post-deployment \ntasks using a declarative way. \nI strongly recommend you check the Keptn website and other more advanced \nmechanisms that they provide, such as Evaluations (https://lifecycle.keptn.sh/ \ndocs-klt-v0.8.1/concepts/evaluations/), which allows us to make decisions and even \ngate deployments that are not meeting certain requirements, such as increased mem-\nory consumption or too much CPU usage. \nWhile Keptn uses a completely different approach from the one described in section \n9.2, I strongly believe these approaches are complementary. I hope to see further inte-\ngrations between Keptn and CloudEvents. If this topic interests you, I encourage you to \njoin the conversation at https://github.com/keptn/lifecycle-toolkit/issues/1841. \n9.4\t\nWhat’s next on the platform engineering journey?\nThe examples covered in this chapter highlighted the importance of measuring \nour technical decisions. In a good or bad way, each decision will affect all the teams \ninvolved in delivering software. \nThese metrics built into our platforms can help us measure improvement and justify \ninvesting in tools that facilitate our software delivery practices. If we want to include a \n",
      "content_length": 1895,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 296,
      "content": "\t\n277\nWhat’s next on the platform engineering journey?\nnew tool in our platform, you can test your assumptions and measure the effect of each \ntool or adopted methodology. It is quite a common practice to have these metrics acces-\nsible and visible for all your teams, so when things go wrong or a tool is not working as \nexpected, you will have hard evidence to back up your claims.\nFrom a platform engineering perspective, I strongly recommend not leaving this \ntopic until the end (as I did with this chapter in the book). Using tools like KLT, you \ncan gain insights with a small investment and use standard monitoring techniques that \nare well-understood in the industry. Looking into CloudEvents and CDEvents is worth \nit, not only from a monitoring and metrics calculation perspective, but also for event-\ndriven integrations with other tools and systems. Figure 9.24 shows that by tapping into \nevent sources from the tools that we are using in our golden paths, we can keep our \nteams informed about their decisions affect the entire software delivery chain.\nTapping into events from \nGolden Paths or standard \nworkflows provided by the \nplatform gives teams great \ninsights about where \nbottlenecks are and how \nthese can be improved. \nProduction Environment\nStandard Application-level APIs\nTransparent Security and Observability\nContainers-as-a- \nService\nFunctions-as-a- \nService\nMetrics and Release \nDashboards\nObservability\nRelease Gates and \nMonitoring\nSource \nCode\nContainer \nRegistry\nChecks & \nVerification\nGolden Paths\nPlatform\nPipelines\nFigure 9.24    Golden paths and workflows provided by our platform are the best source of raw information for \ncalculating the team’s performance metrics.\nEnsuring that the basic metrics for your platform can be calculated will help your \nteams to think about end-to-end flows for each release—where the bottlenecks are and \nwhere they spend or waste most of their time. If the DORA metrics are too hard for \nyour organization to implement, you can focus on measuring your platform’s golden \npaths or main workflows. For example, based on the examples provided in chapter 6, \nyou can measure how much time it takes to provision a development environment, \nwhich capabilities are provided, and how often the team requests new instances, as \nshown in figure 9.25. \n",
      "content_length": 2318,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 297,
      "content": "278\nChapter 9  Measuring your platforms\nPlatform\nMetrics and Release \nDashboards\nRelease Gates and \nMonitoring\nObservability\nDevelopment Environment \nGolden Path\n \nDevelopment Environment\nConference Application\nDevelopment \nTeam\nHow often do teams request\nnew environments? How long \ndo they need to wait for the\nenvironment to be ready? \nHow long are these\nenvironment up and running?     \nFigure 9.25    Platform and application walking skeleton metrics\nBy collecting metrics, not only from customer applications but also from platform-spe-\ncific workflows, like creating development environments, your teams will have full visi-\nbility of the tools they are using and how the changes in the tool affect and unlock the \nvelocity of software delivery. Figure 9.26 shows a recap of our platform journey and \nhow important these metrics are for our platform teams. Remember, if you are measur-\ning your platform initiatives, your platforms will get better.\nEnvironments \nConfiguration \nRepository\nContainer \nRegistry\nOur Platform\nPlatform APIs\nMetrics Dashboard\nEvery platform component can contribute with \ndata to calculate platform metrics that enable \nthe platform team to measure the success of \ndifferent platform initiatives and workflows.\nGitOps Sync\nProvisioning \nCloud Resources\nService Pipelines\nRelease \nStrategies\nFeature Flags \nDashboard\nEnvironment\nApplication-Level \nAPIs\nApplication V1\nManages\nFigure 9.26    \nTapping into \nplatform \ncomponents \nto collect data \nand calculate \nmetrics\n",
      "content_length": 1502,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 298,
      "content": "\t\n279\nFinal thoughts\n9.5\t\nFinal thoughts\nI hope that going through the examples of this book has given you enough hands-on \nexperience to tackle real-life challenges. While the examples covered here are not \nexhaustive or deep in detail, the intention is to show a wide range of topics that plat-\nform engineering teams must deal with. The cloud-native space is constantly evolving, \nand the tools I evaluated when I started writing this book have completely changed in \ntwo years, pushing teams worldwide to be very flexible about their decisions. Making \nmistakes and reviewing decisions is part of the day-to-day work that platform engineers \nmust do for small and large organizations. \nGoing back to the beginning of this book, platform engineers must encapsulate all \nthese decisions behind platform APIs that they can maintain and evolve, so understand-\ning the capabilities needed by different teams is key to having a successful platform \nengineering journey. Providing self-service capabilities and focusing on what your \nteams need should be heavy influencers on the platform engineers’ priority lists. \nUnfortunately, I don’t have an unlimited number of pages or unlimited time to keep \nadding content to this book, but I did my best to include the topics and challenges I’ve \nseen organizations and communities facing while working in the cloud-native space. \nWe have reached a point in the Kubernetes ecosystem where tools are maturing, and \nmore projects are graduating, indicating that more and more companies are reusing \ntools instead of building their own. \nI’ve intentionally omitted topics such as extending Kubernetes with custom control-\nlers, because balancing what is built in-house for your platforms needs to be carefully \ndefined by platform engineering teams. Creating and maintaining your extensions \nshould be left to very special cases where no tools exist to solve a problem you are try-\ning to solve. For the most common cases, as we have seen in this book, CI/CD, GitOps, \ninfrastructure provisioning in the cloud, developer tools, platform-building tools, and \nother tools are mature enough for you to use and extend if necessary.\nIt was quite hard to leave topics such as service meshes, policy engines, observability, \nincident management, operations tools, and cloud development environments out of \nthis book. There are wonderful projects that would require entire chapters to cover. But \nas a platform engineer, you must keep researching and keeping an eye on the cloud-na-\ntive communities to see where new developments and projects can help your organiza-\ntion’s teams. \nI strongly recommend you engage with your local Kubernetes communities and be \nactive in the open-source ecosystem. This not only gives you a great playground to learn, \nbut it also helps you to make the right informed decisions about which technologies to \nadopt. Understanding how strong the communities behind these projects are is key \nto validating that they are solving a problem that first needs a solution and is common \nenough to be solved in a generic (non-organization) specific way. Tools like OSS Insight \n(https://ossinsight.io/) provide enormous value for decision-making and ensure that \nif you invest time and resources in an open-source project, an active community will \nmaintain your changes and improvements. \n",
      "content_length": 3344,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 299,
      "content": "280\nChapter 9  Measuring your platforms\nFinally, keep an eye on my blog (https://salaboy.com), because further articles \nrelated to the book will be published to explore other topics that I consider important \nfor platform engineering teams. If you are interested in contributing to open-source, \nexpanding or fixing the examples provided in the book is a great way to get hands-on \nexperience with all the tools most open-source projects use.  \nSummary\n¡ Using DORA metrics gives you a clear picture of how the organization delivers \nsoftware in front of your customers. This can be used to understand bottlenecks \nresulting in improvements on the platforms we are building. Using the team’s \nperformance metrics based on our software delivery practices will help you \nunderstand how your platform initiatives affect how teams’ work and the benefits \nto the overall organization. \n¡ CloudEvents standardize how we consume and emit events. Over the last couple \nof years, we have seen a rise in the adoption of CloudEvents by different projects \nin the CNCF landscape. This adoption allows us to rely on CloudEvents to get \ninformation about components and other systems that we can aggregate and col-\nlect helpful information that can be used for decision-making. \n¡ CDEvents provides a CloudEvents extension, a set of more specific CloudEvents \nrelated to continuous delivery software practices. While I expect the adoption of \nCDEvents to grow over time, we have seen how to map CloudEvents to CDEvents \nto calculate the DORA metrics. By using CDEvents as the base model to calculate \nthese metrics, we can map any event source to contribute to the calculations of \nthese metrics. \n¡ If we can measure our platform, we will know what needs improvement and \nwhere the organization struggles with its delivery practices. This feedback loop \nprovided by the metrics gives valuable information to platform teams in charge \nof continuously improving the tools and processes our teams use daily. \n¡ If you followed this chapter’s step-by-step tutorials, you gained hands-on experi-\nence with setting CloudEvent sources, monitoring deployments, and how CDE-\nvents can help standardize information about our software delivery lifecycle. You \nalso installed Keptn as a different approach to monitor your workloads and exe-\ncute pre-/post-deployment tasks to validate that newer versions are working as \nexpected. \n",
      "content_length": 2408,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 300,
      "content": "281\nindex\nA\nabstracting complexity  25\nof storage and \nimplementation  200\nwhile building platforms  13\nabstractions\nachieving by Crossplane \ncompositions  133\ndefining for cloud \nproviders  133\nhigher-level, creating  153, 200\nhigher-level, providing  217\nself-service  154\nA/B testing\ndrawbacks of installing using \nbuilt-in Kubernetes \nresources  216\nof user interfaces  223\noverview  214–215\nvs. canary releases and blue/\ngreen deployments  214\nwith header-based \nrouting  226–227\nwith tag-based routing  223\nAgenda page\nempty  37\nwith cache entry  54\nwith proposals  38\nAgenda service\naccessing  48\nacessing Dapr components  201\nConference application  21\nno pods for  54\nNoSQL database for  125\npersistent storage, need for  36\nscaling up  55\ntoo many requests  130\nAnalysisTemplates  244\nAPI-first approach\nadvantages of  10\nexplained  6\napplication development teams \n(App Dev Teams). See also \nsoftware development \nteams\nconnected to platform API  172\ninteracting with platforms  158\nresponsibilities  174\nrole of  133\nseparating responsibilities from \nplatform engineering \nteams  190\nusefulness of platforms for  26\nworking on new features  16\napplication infrastructure\nappropriate configuration, need \nfor  130\nchallenges  124–125\ncomponents  124\ncomponents, installing and \nconnecting with \nservices  127\ndeveloping independently of \nservices  152\non demand  140\nmanaging  125–128\nprovisioning using GitOps \napproach  155\nseparating from application \ncode  206\nvs. hardware infrastructure  124\nApplication Programming \nInterfaces (APIs). See also \nKubernetes APIs; platform \nAPIs\nREST request  9\nusefulness  6\napplication services\ncalling other services  180\nconnecting with infrastructure \ncomponents  128, 151\nmaintaining and \nupgrading  129\nseparated from platform \ncapabilities  190\nusing Dapr components  201\napplication state\ndealing with  55–57\n",
      "content_length": 1867,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 301,
      "content": "282\nindex\nproblems if kept in memory  57\nstored externally  56\nArgo CD\nadvantages of  111\nconfiguring parameters specific \nto installation  114\ndescribed  111\ninstalling  112\nsummarized  122\nsyncing\nconfiguration changes  116\nenvironment \nconfigurations  111\nuser interface  112\nusing  231\nusing with Helm  118\nArgo CD application\nconfigured in main \nbranch  117\ncreating  112–116\nfine-tuning parameters  117\nsyncing  114, 117\nArgo Rollouts\nanalysis  244\nautomated analysis steps  236\nblue/green deployments  238–\n243\ndashboard  231, 236, 242, 243\ndefined  229\nintroduction  229\nReplicaSets, dealing with  236\nresource, creating  230\nsummarized  251\nusefulness  249\ntraffic management  247–249\nvs. Kubernetes \ndeployments  231\nartifact repository  78. See also \nrepositories\nasynchronous\napproach to data \ntransformation  265\nintegration with application \nservices  40\nmessages exchanging between \nservices  36\nauthentication  60\nand authorization flow  61\ncredentials needed for  180\nneed for  10\nautomated\napproach with Argo CD  117\nclean-up mechanism  118\ncreation of environment \nrepositories  120\nPull/Change requests  119\npulling changes in \ndeclarations  104, 107\ntests  244\nautomating\ncontainer building process  74\nentire process of building \nplatforms  63\ninfrastructural \nrequirements  57\nKubernetes deployments  63\nlack of  62\nsoftware releases flow between \nenvironments  121\nwith Jenkins  102\nautomation\ndifferent solutions, creating  70\nend-to-end  69\noptimizing end-to-end  80\npipelines  7\nB\nBack Office page  38. See also \nConference application\nDebug tab  224\nfailed services on  55\nnotifications on  39\nservice events on  40\nbackward compatibility  227\nblue/green deployments\nArgo Rollouts  238–243\ncoordination between \nteams  227\ndrawbacks of installing using \nbuilt-in Kubernetes \nresources  216\nimplementing in \nKubernetes  214\noverview  213–214\npromotion analysis  246\nrunning in parallel  214\nwith Knative Services  227–229\nwith Kubernetes resources  243\nbottlenecks  130, 255, 260\nbranches\nmain  117\nmain and feature  72, 76\nselecting  113\nseparate  112\nbrowser\nproblems with GET \nrequests  223\nrefreshing  53\nusing  36, 44, 48\nbuilding blocks\nAPIs defined in Dapr \nproject  194\nKubernetes  11, 103, 216\nproviding basic  93, 250\nbuilding platforms. See also \nKubernetes; platforms\nabstracting complexity  12, 13\nexample  18\non top of Kubernetes  13, 25, \n162\nC\nCall for Proposals (C4P) service\nacessing Dapr components  201\nConference application  21\nconnecting to PostgreSQL \ninstance  128\nflow  40\npersistent storage, need for  36\nPostgreSQL database for  125\nstored externally  56\nuse case  21\ncanary releases\nanalysis  244\ndrawbacks of installing using \nbuilt-in Kubernetes \nresources  216\nimplemented with Argo \nRollouts  230\nin Kubernetes  213\noverview  212–213\nrevision promoted to stable \nversion  237\nrouting traffic to  235\nterm, explained  212\ntraffic mirroring  248\ntraffic splitting, percentage-\nbased  221–223\n",
      "content_length": 2950,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 302,
      "content": "\t\n283\nindex\nusing deployment resources vs. \nArgo Rollouts  237\nCDEvents\navoiding reprocessing  268\ndescribed  258\nendpoint  272\noverview  258\nspecification  259\nstored  270\nsummarized  282\nusefulness  279\ncentral repositories  33. See also \nrepositories\nchange failure rate\ncalculating  255\nDORA metrics  254\ncloud architects, role of  4\nCloudEvents\ndefined  257\nendpoint  272\nsources  257\nmetrics collection pipeline, \nbuilding of  261–262\noverview  257–258\nspecification  257\nstandard input format  262\nsummarized  282\ntransforming to CDEvents, \nfunctions for  265–266\nusefulness  279\ncloud-native applications\nadvantages over monolith \napplications  23–24\nchallenges  25, 49, 61, 68–69\ncontinuous delivering  68– 71\ndynamic  64\nKubernetes as declarative system \nfor  11\nmain paradigm shift  69\nrunning locally or otherwise  28\ntasks expected in service \npipelines  73–75\ntools for operating and \nmonitoring  23\nvs. monolith applications  49\nwalking skeleton  18\nCloud-Native Computing \nFoundation (CNCF)  11. \nSee also CNCF\nCrossplane project  131\ncloud-native ecosystems  1\ncomputing platform for, \ndefinition  14\noutside cloud providers, enabled \nby Kubernetes  15–16\nusing  163\ncloud platforms. See also platforms\nand pay-as-you-go model  26\nthree main features of  10\nworking with  6–8\ncloud providers\nadvantages  10–11\nAPI-first approach  6\nconfigurations needed for \nGoogle Cloud Platform \n(GCP)  136\nKubernetes managed services \nand  11\nmain benefits of  2, 4\nportability  103\nREST request  9\nSDKs, CLIs, and Dashboard \nclients  7\nsupporting multiple  131\nusing more than one  5\ncloud services\nadvantages and \ndisadvantages  124\nAPIs not standardized  6\nbuying  17\ncategories  3\ncost  4\norganizing into layers  3\nCNCF-hosted projects, common \ndenominator  15\nCNCF Landscape  11\noverview  14–16\nresearching and selecting \ntools  13\nvs. cloud provider offered \nservices  15\nCNCF white paper on \nplatforms  14\ncommand line interfaces (CLIs)\ndefinition  7\ntools  81, 87\ncomplexity\nabstracting  25\nhiding from platform \nusers  160\nmanaging  23\nof pipeline service setup  96\nof using Kubernetes built-in \nresources  216\nreducing, need for  153\nConference application\nannotations for  275\nBack Office page  20\ncloud-native, overview  19–22\ncomplex pipelines for  87\nconfiguring services and \ndependencies  115\ndiagram  36\nessential functionalities  180\nHelm Chart \ndependencies  139–140\nHelm Chart, installing  169\nhome page  19, 37\nhosting  172\ninfrastructure components, \nadding  126\ninfrastructure for  139\ninstalling  34–35\ninteracting with  36–40\nlist of challenges  49\nmonolith, overview  22–24\nNotifications service  218, 230\nrepository  96\nrequirements  158\nrestarting  36\nservices   20\nsubmitting proposals  37\nusing Dapr components  200\nverifying  35–36\nConfigMap  199, 200\nmodifying  205\npatching  226\nConfigMap/secrets, Kubernetes \nresources  31\nconfiguration drifts\navoiding  104, 137\ndealing with  107\ndifficult to track  117\nmonitoring environments  104\nconfiguration files\ndefinition  62\npackaging and distributing  121\nconfiguration management  72\nconfiguration parameters  6\n",
      "content_length": 3096,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 303,
      "content": "284\nindex\nconnection pool  185\ncontainer image  119\nbuilding  74\ncontaining web \napplication  224\nOCI  75\npublishing to centralized \nlocation  74\npushing to Docker Hub  95\nreplacing by rollouts  234\ncontainer registry  75, 78, 96\ncontainers\nbenefits of using  182\nparameterizing  199\nresource allocation for  41\nrunning inside Kubernetes  74\nrunning on demand  218\nsimple docker  41\ncontainers-as-a-service\nimportance of  249\ninterface  218\ncontinuous delivery. See CDEvents\nContinuous Delivery: Reliable Software \nReleases through Build, Test, \nand Deployment Automation, \nbook  73\nContinuous Delivery, book  215\ncontinuous reconciliation\nimportance of  104\nwith Crossplane managed \nresources  137\ncontracts\nbetween services  62\nbetween users and \nplatforms  159\nconsumer-driven  73\nexposed as platform APIs  11, \n13\nconventions that save time\nconsumer-driven contract \ntesting  73\nsource code and configuration \nmanagement  72–73\ntrunk-based development  72\ncredentials\naccessing  180\nproblem with  186\nCronJob, executing \nperiodically  58\nCrossplane\nadvantages, summarized  155\nbehaviors  137\ncomponents and \nrequirements  135–136\ndescribed  131\ndrawbacks and challenges  153\nGCP supported resources  136\nHelm provider  139, 140\ninstalled with two \nproviders  132\ninstalling in Kubernetes \ncluster  135\nisolated environments, \ncreating  171\nKubernetes secrets, \ncreating  135\nmanaged resources, \nadvantages  137\nofficial documentation  146\nproviders  132–133\ninstalled and \nconfigured  135\nsyncing resource \nstatuses  138, 149\nusing  169\nCrossplane Composite Resource \nDefinitions (XRDs)  133\ncreating  153\ndescribed  141\nimplementing  142\nCrossplane Composite Resources \n(XRs)  133\nCrossplane compositions\nadding parameters  149\nconfiguring and creating  140\ndescribed  141\nexample  134\nexamples for different database \nresources  142–146\nmapping environment resources \nto  168\noverview  133–134\nrunning in local Kubernetes \ncluster  171\nselecting different \nproviders  147\nselecting using labels  145, 147\nusing  139\nD\nDagger\npurpose of  89\nsummarized  98\nvs. Tekton  90, 91, 93\nwriting pipelines in any \nsupported language  90\nDapr\nannotations  195\napplications and  197–198\nCNCF project  193\ncontrol plane  195\nin Kubernetes  194–197\noverview  193–194\nresiliency policies  201\nservice-to-service \ninvocations  201\nsoftware development kits \n(SDKs)  198, 204\nSubscription resources  204\nsummarized  209\nusefulness  250\nDapr components\naccessing configured  195\nconfiguring  196\nfor building distributed \napplications  194\nPubSub  197, 199, 200, 203\nStatestore  196, 197, 199, 200\nused for Conference \napplication  201\ndashboards\nArgo Rollouts  229, 231, 236\nbuilding domain-specific  59\ncomponent  7\nfor managing Kubernetes \nworkloads  49\nfor monitoring pipelines  88\nKeptn application  276\nquerying databases \ndirectly  268\nTekton  87\nusefulness  7\ndata collection\nevents routed to  262\nfor recovery metrics  256\nfrom event sources  261, 262\ndata transformation\nasynchronous approach  265\n",
      "content_length": 2996,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 304,
      "content": "\t\n285\nindex\ndescribed  262\ndifferent approaches  265\nfunctions for  272, 274\nto CDEvents  261, 264–266\ndeclarative definition, enabled by \nArgo CD  111\ndeclarative description, \nimportance of  103\ndependencies\nadding\nand removing  181\nDapr SDK  198\nto application code  192\nbenefits and problems with  7\ncompatible versions of  183\nHelm  109\nkinds of  185\nof services  79\non infrastructural \ncomponents  57, 126\nreducing between teams  25\nremoving from services  203, \n206\nupgrading  186\nvendor-specific  190\ndeployment frequency\ncalculating metrics  255, 260, \n263\nworking example  268–274\ncalculation flow  267\ncalculation function  272\nDORA metrics  254\nmetrics endpoint  272\ndeployments\nautomating  63\nbasics  41\nblue/green  213–214, 227–229, \n238–243\ndefault  127\ndescribing  43\nexploring  42–43\nfrontend service  42, 44\nKubernetes resources  30, 211\nlist of available  41\nmanaged by Knative  220\nmanaging ReplicaSet \nobjects  44\nperforming rolling \nupdates  218\ndevelopment environments  108\nbuilding platform prototype \nfor  168\nclusters  162\nGitOps approach, \nunusable  121\nnamespace approach  110\non demand  158\nprovisioning  159\nDevOps Research and Assessment \n(DORA). See DORA \nmetrics\ndistributed applications\ncommon communication \npatterns  181\ncomplexities  28\nDapr components for  194\nmono repository  72\none service/one repository/one \npipeline  72\nproblem with inconsistent \ndata  50\nreducing complexity  24\nsecurity and identity \nmanagement  50\ndistributed approach, vs. monolith \napproach  22–24\ndistributed systems\nauthorization, problem of  60\nevent-driven architecture  180\neventual consistency, \nmeaning  58\nDockerfile\nneed for  78\nusage  79\ndomain-specific libraries, creating, \nneed for  93\nDORA metrics\narchitecture, example  269\nby category  254\ncollecting and transforming data \nfor  261\nhard to implement  279\nout of the box  256\nsummarized  282\nusing functions for \ncalculating  267\ndowntime\nminimizing  65, 103\nnot allowed  50–53, 55\nsimulating  53\nE\nedge cases\ndocumenting  192\nhandling  193\noverview  189\nrecognizing all  192\nenvironment clusters  161\nenvironment configurations\nbased on requirements  110\ndefining with helmfile  109\nsynced by Argo CD  111\nupdating  100\nenvironment pipelines\naccess rights, fine-tuning  107\ncoordination between  121\ndeploying cloud-native \napplications  25\ndifferent approaches  108–110\nexplained  71\nfor Kubernetes \nenvironment  107\nfor storing Kubernetes \nresources  132\nimplementing using \nArgoCD  111\ninteracting with service \npipelines  118, 120–121\noverview  100–101\nresponsibilities of  100\nstandardized for \nKubernetes  111\nsteps involved in  107\nsummarized  122\nusing GitOps approach  105\nvital conditions for \nworking  108\nenvironments\nconfiguration options  108\nconsistent capabilities \nacross  207\ncreating new, brief history \nof  101\ndefinition in JSON format  160\ndeploying same application \nacross different  97\nexpanding resources  160\ninternal configurations  104\n",
      "content_length": 2949,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 305,
      "content": "286\nindex\nisolated  169\nlive  107\nlow-risk  119\nmanaging  250\nmanaging and provisioning \ndifferent  69\nmulti-cloud setup  110\nmultiple  95, 108, 109, 122\nnew cluster for each  110\non-demand  109\nrepositories  108, 119, 120\nright for testing  95\nsensitive  167, 212\nsharing Kubernetes \nresources  109\nsimple definition  159\ntesting new versions  119\nunified runtime across  90\nusing one per namespace  109\nenvironment variables  128, 199\nevents\nassociated with resources  43\ncategories and examples \nof  259–260\ncoming from external \nsources  81\nemitted by application \nservices  40\nemitting and consuming  180, \n257\nin notification service logs  39\nKnative sources  262\nlistener  88\nsources  258, 260\nstore  258\nstoring and reading  269\ntapping into sources  279\ntriggers  87\nEvent Sources, configuring  271\nextending\nexisting tools  13\nKubernetes  12, 15, 17, 163\nKubernetes APIs  81, 132\nF\nfeature flags  191\nconsuming and evaluating  199\ndescribed  198\nhosting in remote services  199\noverview  198–200\nproviders  199, 203\nsummarized  209\nusefulness  207\nfifth key metric, described  254\nfrontend service\nConference application  20\ndebug features  160\ndeployment  42\ndownscaling  53\ninteracting with identity \nmanagement service  61\nreplicas  45, 50\nscaling up  50\nfunction-as-a-service\nimportance of  249\nplatform  218\nG\nGitHub, pull requests concept  76\nGitHub Actions\nadvantage of using  95\nfor building service \npipelines  95\nsummarized  98\nGitOps\napproach  95, 154\ndealing with changes  116–118\ndefinition  103\nimplementation  111\nmanaging multiple \nenvironments  122\noverview  103–106\nviewed as pipelines  106\nGit repository  73, 78, 81\nas source of truth  104, 112\nhistory stored in  107\nmanaging environment \nresources  173\nmonitored by Argo CD  231\nmonitoring  106, 111\nremote  107\nseparate for each \nenvironment  109\nstoring configurations in  104\nglue code\nabstracting  12\nvs. rewriting more tailored \nsolution or extending \nexisting tools  13\ngolden paths to production  279\ncreated by platform team  16\ndefinition  121\nenabled by cloud providers  11\nGoogle Cloud Platform (GCP)\ncreating full-blown cluster \nin  169\ndashboard, CLIs and \nAPIs  8–10\nsimplifying user jobs  10\nusing with Crossplane \ncompositions  146\nvs. platforms built on top of \nKubernetes  157\nGoogle Kubernetes Engine\nadvantages of  29\ncreating new clusters  8\nGrokking Continuous Delivery, \nbook  62, 73\nH\nheader-based routing  226–227, \n247\nHelm\nas package manager  74\nconfiguration prameters  114\ndependencies, turning off  151\ndescribed  28, 34\none release per change  109\ntemplating capabilities  63\ntutorial  36\nupdating applications  44\nwhen inappropriate  80\nHelm Chart  74, 79\ncaveats and tricks  127–128\nfinding or creating \nsuitable  126\nper service, good or bad?  79, \n96\nrepository  78\nusing definition  115\nusing manually  118\nhigh-performing teams  254\nHTTP headers\ncustom  226\nfor routing requests  226\n",
      "content_length": 2903,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 306,
      "content": "\t\n287\nindex\nI\nidentity management service  60–\n61\ndiagram  61\nrole of  61\nidentity provider, role of  61\nimmutability\nimportance of  104\nwith Crossplane managed \nresources  137\ninconsistent data\naccross different stores  58\ndealing with  58\nproblem with  50\ninfrastructural requirements\nautomating  57\nfor service pipelines  77\ninfrastructure\nas code tools  104–105\nchecking resources  138\ndeclarative  131–139\nmanaging in Kubernetes  124–\n131\nmulti-cloud  123\nprovisioning in cloud-agnostic \nway  155\nseparating applications \nfrom  190–191\ningress\ncontroller  30, 48, 53\nfor routing traffic  232\nKubernetes resources  31, 47, \n211, 218\nintegration tests  7, 161\ninternal services  5\naccessing  48\ninternal teams  1, 4, 16, 17, 167, \n176\ntesting deployments  214\nisolation\nbetween environments  168\ninsufficient  169\nKubernetes clusters, pros and \ncons  166–167\nKubernetes namespaces, pros \nand cons  166\nprovided by vcluster  170\nIstio in Action, book  248\nJ\nJenkins, advantages of  101\nJenkins Jobs\ndescribed  102\nimprovements  102\nK\nKafka\nHelm Chart  140\nprovisioning instance of  125\nusage  36\nKeptn Lifecycle Toolkit (KLT)\nannotated deployments  275\ndescribed  274\nTaskDefinition  276\nusefulness  278\nKnative Eventing\nAPI server source  271\nevent sources  262\nKnative In Action, book  217\nKnative Revisions, defined  219\nKnative Services\nbuilt on top of Kubernetes \nresources  218\nchanging configuration  221\ndefault characteristics  220–221\nfrontend  223\nhow they work  218\nmodifying resource  224\nrole of  217\nKnative Serving\ndefined  217\nsummarized  251\nswitching traffic  228\ntag-based routing  225\ntraffic rules and tags  227\nusefulness  249\nKnative Sources, described  262\nKratix, framework  176\nKubernetes\nadvantages when using \nTekton  94\nannotations  275\napplications, packaging and \nmanaging  31–33\nautomating deployments  63\nbuilt-in mechanisms, summary \nof  62\nbuilt-in resources  211\nchoosing the best environment \nfor using  28–30\nclusters on demand  29\nconnecting services  46\nDapr installed in  194–197\ndefinition  12\ndeployments  41–43\ndistribution of clusters in \norganizations  161\ndistributions  18\necosystem  1, 12\nenabling multi-cloud cloud-\nnative ecosystem  15–16\nin cloud provider setup, pros \nand cons  29\nin shared infrastructure  60\ninstalling application using \nHelm  34\ninternal events  264\nload balancing  45, 56\nlocal setup, pros and cons  28\nlocal vs. remote setup  29, 64\nlow-level building blocks  12\nmanaging infrastructure  124–\n131\nmanifest  72, 74, 78, 103\nmisbehaving platform services \nand  23\nnamespaces  109, 166\non-premise setup, pros and \ncons  29\noperators  130\nplatforms built on top of  11–\n16, 25\nproblems with using Tekton  89\npublishing manifests to \ncentralized location  74\nresources  30, 46, 141, 203\nrestarting failing container  35\nscaling services replicas  50\nsecrets  128, 135, 186\nservice selectors  240\nsetting up PostgreSQL, Redis, \nand Kafka  126\ntasks expected in service \npipelines  73–75\ntypical adoption journey  13\nusing gcloud CLI  10\nusing REST request  9\nwriting custom extensions \nfor  12\n",
      "content_length": 3066,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 307,
      "content": "288\nindex\nKubernetes APIs\nrelying on  103, 104\nusefulness  105\nKubernetes in Docker \n(KinD)  219\ndescribed  27\nlimited resources  127\nL\nlayers\napplication-level services  3\ncross-cutting  14\nextending with custom \nbehavior  5\nindustry-specific services  3\nKubernetes-based API  163\nof cloud services  3\norganization-specific  5\nlead time for change\ncalculating metrics  255, 260\nDORA metrics  254\nlifecycles\napplications’ diagram  63\nof Agenda service  275\nof Helm Chart and application \nservices  97\nof managed resources with \nCrossplane  138–139\nof service components and \nartifacts  79\nof service pipelines and \napplication pipeline  96\nliveness probe  41\nload balancing\nnot performed  28\nrequests between replicas  45, \n56\ntraffic  236\ntraffic among replicas  46\nlocal Kubernetes setup, pros and \ncons  28\nM\nmanaged resources. See \nCrossplane, managed \nresources\nmeasuring platforms\ndifferent approaches to  279\nDORA metrics  26, 254\nimportance of  280\nsummarized  282\nmessage broker (Kafka)  36, 141, \n188\nmetrics. See also DORA metrics\nbuilt into platforms  278\ncalculations  261\nfunctions for  266, 274\noverview  266–268\nteams involved in  273\ncustom  274\ndomain-specific  262\nmicroservices, installing sets \nof  28. See also \nOpenTelemetry.\nmirrored traffic  247, 248\nmonolith applications, \ndrawbacks  23–24\nmonolith approach, vs. distributed \napproach  22–24\nmono repository, described  72\nmulti-cloud infrastructure  123\nneed for components  25\nmulti-tenancy  166\non top of Kubernetes  170\nN\nnotifications\nabout changes in source \ncode  73\nabout new versions of \nservices  119\non Back Office page  39\nsent by pipeline services  75\nsubscribing to  119\nnotification service logs\nchecking status of proposals  39\nemails and events  39\ntailing  277\nNotifications service\nacessing Dapr components  201\nblue/green deployment  239\nConference application  21\ndashboard for  276\ndeploying new versions  227\nquerying  232\nO\none repository per service, main \nproblem  96\non-premise Kubernetes setup, pros \nand cons  29\nOpenFeature\ndescribed  199\nproviders  200\nSDK  199, 202\nsummarized  209\nusefulness  250\nOpenGitOps, four core \nprinciples  103\nOpenShift  17\nOpenTelemetry\narchitecture and library  60\ncommunity  59\noperation teams\ncollaborating with other \nteams  16\npriorities different from other \nteams  12\nreducing frictions between \nteams  25\nresponsibilities of  139\nsimplifying work with CNCF \ntools  15, 23\ntools preferred by  104\nusing tools from cloud \nproviders  7\norganizations\nmain jobs of  4–6\nP\npackage managers\nmain responsibilities  32\nusefulness  64\nusing semver approach  33\npercentage-based routing  247\npersistent storage\nDagger and  93\nfor Agenda and C4P \nservices  36\nfor sharing information  83\nfor storing and reading \ndata  179, 184, 196, 260\npipeline definitions\ncustom per service  96\ndefining tasks  85\n",
      "content_length": 2834,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 308,
      "content": "\t\n289\nindex\nexecuted by pipeline \nengine  69\nfor creating automation \nsolutions  70\nsharing  71\npipeline engines  80\nadvantages of Dagger  90\nexecuting pipeline \ndefinitions  70\nJenkins  101\nrole of  69\nTekton  80\npipelines\nautomation performed by  69\nCI/CD  255\nfor data collection, \ntransformation, and \naggregation  261, 262\ntwo main kinds  70\nusage  69\nPlatform Admin application  173\nplatform APIs\nbenefits of using Kubernetes \nAPIs as  162\nbuilding without creating \ncustom Kubernetes \nextensions  168\ndomain-specific  158\nhosting on platform \nclusters  162\nimplementing  160\nimportance of  157–158\nresponsibility of platform \nengineering teams  157\nplatform capabilities. See also \nshared application \nconcerns\naccessed by APIs  180\napplication-level  193–206\nas APIs  190\navailable for services  191\nconsistent across \nenvironments  207\nenabling teams to \nexperiment  26, 213\nfeature flags  191\nfor managing \nenvironments  250\ngeneric  189\nseparated from application \nservices  190\nplatform engineering\nintroduction  1\non Kubernetes, usefulness  26\nreducing complexity  153\nsuccessful initiatives  13\nview of complex pipelines  94\nplatform engineering teams\nAPIs as responsibilities of  11\nautomating entire process of \nbuilding platforms  63\nchoosing tools or services  95\ncreating library of shared \ntasks  277\ndedicated  16\npriorities  62\nreducing cognitive load on \nteams  189\nresponsibilities  174, 176\nresponsible for platform \nAPIs  157\nrole of  133\nsuggestions for  281–282\nunderstanding requirements of \ndevelopment teams  158\nplatforms\narchitecture  161\nauthor’s definition of  13\nautomating creation of \nenvironmental \nrepositories  120\nchallenges  164\nisolation and multi-\ntenancy  165–167\nmanaging more than one \ncluster  164–167\nclusters  162\ncurrent CNCF definition of  14\ndefining, fetching and \naggregating data for \nmanaging \nenvironments  208\ndescribed  2\ndesired properties  14\nevolving independently from \napplications  190\nmain objective  6\nmetrics built into  278\norganization-specific  5\nrelationship with development \nteams  17\ntools, configurations, and \nservices  175\nwalking skeleton, example  167\nworking on-premises  5\nplatform services. See also \nindividual services\nfine-grained  24\nneeded for application \ndevelopment  154\npods\ncanary and stable, traffic \nmanagement  236\ndealing with large number \nof  130\nlist of  35, 82\nmanaged resources  220\nscheduled in different \nnodes  36\nupdating  41\nupgrading  44\npolling, vs. pushing  106\npolyglotism, advantages of  23\nPostgreSQL\ndownside of installing  57\nfor C4P service  125\nHelm Chart  140\nofferd by cloud provider  3\nstoring C4P  56\nstoring proposals in  55\nusage  36\npreview environments\nfor faster iterations  118\nfor pull requests  117\nproduction environments  108, \n121\nclusters  162\ndescribed  100\nseparated clusters for  110\nwith isolated Kubernetes \nclusters  167\nproof of concept (PoC), \nbuilding  18\npull requests\ncreating  116\nsending  108\nsubmitting  117, 127\nQ\nquality assurance (QA) \nenvironments\n",
      "content_length": 3001,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 309,
      "content": "290\nindex\nclusters  162\ndescribed  100\nR\nreadiness probe  41\nreconciliation\ncontinuous  137\ncycle used by Crossplane  139\nRed Hat OpenShift, tool  17\nRedis\nadvantage of using  130\ndownside of installing  57\nHelm Chart  140\nNoSQL database  125\nservice dependent on  36\nstoring application state  56\nstoring proposals in  55\nusage  36\nrelease strategies\nA/B testing  214–215\nArgo Rollouts  229\nblue/green deployments  213–\n214, 227–229\ncanary releases  212–213\noverview  211\nreplicas\nchanging number of  44\ndownscaling  220\nincreasing number of  130, 212\nmultiple recommended  53\nnumber of  41, 241\nnumber of running  36\nrunning concurrently  56\nReplicaSets  43–45, 218\ncreating new  231\ncreating new pod  52\nrepositories. See also individual \nrepositories; service \npipelines\ncentral  33\nfrontend  116\npackage  33\nseparate  112\nsource code main branch  73\ntags created in  74\nusage  29\nwith environment \nconfigurations  100\nwith pipeline service's source \ncode  78\nresiliency. See services, built-in \nresilience\nREST endpoint  223, 262\nREST request\nusefulness  9\nusing  9, 173\nreusability, in cloud-native \napproach  24\nrouting. See  header-based routing; \ntag-based routing; traffic \nsplitting\nrouting rules, percentage-\nbased  224, 227\nS\nscaling\naffected by amount of data kept \nin memory  57\napplications  43\napplication services  64\nbased on demand  218, 220\nby changing number of \nreplicas  45\ndatabases, elastically  127\nservices  23, 50, 125\nSelector property  46\nservice pipelines\nbuilding cloud-native \napplications  25\nbuilding with Tekton, Dagger or \nGitHub Action  94–95\ncharacteristics  75\nconventions that save time  72–\n73\ndescribed  71– 2\ndetermining start and end \nof  96\nexplained  70\nfailing  76\nfailing logic  102\nfor improving communication \nbetween teams  71\nfor main and feature \nbranches  77\nin Dagger  91\nin real life  76–77\ninfrastructural \nrequirements  77–79\ninteracting with environment \npipelines  118–121\nrecommendations for \ndesigning  79\nrequired infrastructure, \ndiagram  78\nresponibility of  73\nresponsibilities, \nsummarized  79\nrunning locally  89, 90, 94\nrunning remotely  93, 97\nsending notifications  75\nseparate for each service  112\nsource code repository  79\nstructure  73–76\nsummarized  98\ntasks for cloud-native \napplications  73–75\ntriggering  73\ntriggering environment \npipelines  119\nvariations depending on \ncircumstances  77\nService Revisions  222\nservices\naccessing/downloading items \nfrom different \nenvironments  68\nadding libraries  189\nadding or removing  117\nbarrier between external and \ninternal  60\nbuilt-in resilience  50, 53–55, \n182\nchecking data consistency  58\ncompromised  184\nconnecting  46\ncoordination between \nteams  68\nexploring  46–47\nfrontend  44\nidentity  184, 187, 188\nindependent of \nenvironments  75\ninteracting  36\niteration of  34\nKubernetes resources  31, 211\nlarge numbers of  31\nmanaged by Knative  220\n",
      "content_length": 2882,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 310,
      "content": "\t\n291\nindex\nmonitoring with \nOpenTelemetry  59\nnew versions, testing  213\nparameterizing features  160\nreleasing independently  72\nreleasing independently of \napplication \ninfrastructure  152\nreverting versions  117\nrouting traffic to  213, 232\nscaling  43, 64\nsource code  47\nsystem-level rules  184\ntroubleshooting  48–49\nupdating  234\nupgrading independently, need \nfor  68\nservice-to-service\ncommunications and resiliency \npolicies  197\ninteractions  183, 202\ninvocations  184\nshared application concerns  20\nchallenges\nasynchronous \nmessaging  187–188\ncoordination between \nteams  182\nedge cases  189–189\nseparating applications from \ninfrastructure  190–191\nservice-to service \ninteractions  182–184\nstoring/reading state  185–\n187\noverview  180–181\nsocial login, definition  61\nsoftware development kits (SDKs)\nnot standardized  7\nproviding by cloud providers  6\nsoftware development teams\navoiding distractions  25\nfocusing on building platform \nfeatures  63\nnew responsibilities  68\npriorities different from other \nteams  12\nranking with DORA \nmetrics  254\nsimplified interaction with \ntools  16\ntreated as customers  16\nultimate goal  2\nusing platforms  11\nworking with platform \nengineering teams  152\nsource code\nand configuration \nmanagement  72\nbuilding and testing  73\ncloning  73, 107\nrepository  79\nSpring Retry, library  183\nstaging environments  108\nclusters  162\ndefining  113\ndescribed  100\nHelm configuration \nparameters  114\nseparated clusters for  110\nsetting up with ArgoCD  116\nstate of  115\nsticky sessions  57\nT\ntag-based routing  223–226\ntags\nfor routing requests  224\nfor routing traffic  227\nTanzu  17\ntask definitions, searching for  88\nTaskRun resource, creating  82\ntasks, executing remotely  94\nTeam Topologies, book with different \nview on platforms  16\nTekton\nadvantages and extras  87–89\ncatalog  88\nchallenges, list of  89\ndashboard user interface  87, \n88\nexecuting pipelines  86\nHub  89\ninstalling  81\ninstalling in Kubernetes  87\npipelines in  83\nsummarized  98\ntasks and pipelines  81\nwriting pipelines in any \nsupported language  94\ntelemetry\ndata (metrics, logs, traces)  59\nmonitoring data  59\ntemplating engines\nunification  118\nusage  31\nthird-party\ncomponents  124\nservices  5, 148\nsources  263\ntools  155\nticketing system  152\ntime to restore service\ncalculating  255\nDORA metrics  254\ntraffic rules  226\ncreating by Knative \nServices  221, 224\nmore precise  247\nupdating  227\ntraffic splitting\npercentage-based  221, 223\nweight-based  247\ntroubleshooting\ninternal services  48–49\nproblems in pipelines  76\nproviding enough information \nfor  208\ntrunk-based development  76\ncreating new releases  73\ndescribed  72\nU\nuse case\nbasic  40\nmore advanced  158\nreceiving and approving \nproposals  36\nV\nvalidating\nby end users  121\nchange in feature branch  77\nchanges  118\nCloudEvents  264\nenvironment's state  276\n",
      "content_length": 2859,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 311,
      "content": "292\nindex\nif applications are working as \nexpected  107\npull request/change \nrequest  77\nvcluster\ncreating  170\noverview  170–171\nusefulness  172\nvs. Kubernetes namespaces vs. \nKubernetes clusters  170\nversioning, importance of  104\nvirtual machines, benefits and \ndownsides  102–103\nvisibility\nof Crossplane managed \nresources  137\nof tools  280\non operations, cost and \nefficiency  11\nusefulness  17, 21\nVMware Tanzu, tool  17\nW\nwalking skeleton\napplication built as  34\narchitecture  171\nbuilding platforms and  24–26\nchallenges  124\ninfrastructure for  139\ninspecting  41–49\ninstalling  30\nintroduction  18–19\nmetrics  280\nnatural extension  173\nOpenTelemetry built-in  60\nprimary purpose  19\nrelease strategies for, \nsummarized  250\nservices  96\nselecting  21\nsupporting degraded  23\nusefulness  64\nusing Dapr components  201\nwebhooks\nlistener  81\nmutation  277\nregister  78\nsmple definitions  96\nsupported by repository  106\nworkflows\ncloud-agnostic  12\ncodifying and automating  11\nfocusing on  13\nimplementing out-of-the \nbox  17\noptimizing  24\nplatform-specific  280\npredefined  176\nteams for implementing  16\nworkloads\ndownscaling  218\nmanaging  153\nmonitoring and observing with \nKLT  274\nrunning and deploying  11, 122\nseparated from platform \ntools  164\nY\nYAML files  35. See also \nconfiguration files\nadding variables  31\ncomplexity  31\ndownloading and applying  126\nfor Kubernetes \ndeployments  74\norganizing, versioning, and \ndistributing  32\nrule for packaging  74\nstoring in Git repository  109\n",
      "content_length": 1513,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 312,
      "content": "Mauricio Salatino ● Foreword by Jared Watts\nISBN-13: 978-1-61729-932-2 \nK\nubernetes is an amazing orchestration tool, but it’s just \nthe start of your journey to the cloud. To effi  ciently \ndeliver cloud-native software, your team needs a solid \nbuild pipeline, an effi  cient package manager and distribution \nmechanism, and APIs that reduce your team’s cognitive load. \nTh is book will show you how to build custom platforms on \ntop of Kubernetes—all with open-source tools such as Dapr, \nKnative, Argo CD and Rollouts, and Tekton.\nPlatform Engineering on Kubernetes starts by clearly defi ning \nthe elements of a great Kubernetes-based platform. Th en, it \nsystematically introduces the tools you’ll need to build a plat-\nform that exactly matches your organization’s requirements. \nHands-on examples and detailed code guide you through each \nstep. By the end, you’ll be able to create a complete platform \nto effi  ciently deliver cloud-native software without being tied \nto a specifi c cloud provider or vendor. \nWhat’s Inside\n● Package, version, distribute, and deploy with Helm, \n   Tekton, Dagger and Argo CD\n● Implement a multi-cloud infrastructure strategy \n   using Crossplane\n● Progressive upgrades with Knative Serving and Argo \n   Rollouts\n● Enable development teams with standard application-level \n   APIs with Dapr\nFor developers and software architects familiar with the basics \nof containers and Kubernetes.\nMauricio Salatino is currently a Dapr OSS Contributor, a Kna-\ntive Steering Committee member, and co-lead of the Knative \nFunctions working group.\nFor print book owners, all ebook formats are free:\nhttps://www.manning.com/freebook\nPlatform Engineering on Kubernetes\nOPERATIONS & CLOUD\nM A N N I N G\n“\nAn engaging and \ncaptivating hands-on \nexploration of the CNCF land-\nscape through the prism of \nplatform engineering.”\n—Viktor Farcic\nUpbound/@DevOpsToolkit \n“\nTh e book is a refl ection \nof a mountain of personal \nexperience and the author’s \nown journey on the windy \n paths of cloud native.”\n—Andreas Grabner, Dynatrace \n“\nBrims with Mauricio’s \nunique experience, insights, \n and deep understanding.”\n—Th omas Vitale, Systematic \n“\nFor anyone looking to \nbuild a modern, cloud \nnative development platform \non Kubernetes. \nAn indispensable guide.”\n—Lance Ball, Red Hat\n“\nA comprehensive exploration \nof platform engineering.”\n—Carlos Santana, AWS\nSee first page\n",
      "content_length": 2397,
      "extraction_method": "PyMuPDF_fallback"
    }
  ]
}