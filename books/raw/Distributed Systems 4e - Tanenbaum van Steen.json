{
  "metadata": {
    "title": "Distributed Systems 4e - Tanenbaum van Steen",
    "author": "Unknown Author",
    "publisher": "Unknown Publisher",
    "edition": "1st Edition",
    "isbn": "",
    "total_pages": 685,
    "conversion_date": "2025-12-19T17:27:35.288187",
    "conversion_method": "PyMuPDF + OCR fallback",
    "source_pdf": "Distributed Systems 4e - Tanenbaum van Steen.pdf",
    "extraction_method": "PyMuPDF_fallback (Unstructured failed)"
  },
  "chapters": [
    {
      "number": 1,
      "title": "Segment 1 (pages 1-11)",
      "start_page": 1,
      "end_page": 11,
      "detection_method": "topic_boundary",
      "content": "D IS TRI B U T ED\nSY ST E MS\nMAARTEN VAN STEEN\nANDREW S. TANENBAUM\n4TH EDITION\nVERSION 01\n\n\nCover art by Max van Steen\n\n\nDISTRIBUTED SYSTEMS\nFourth edition\nVersion 4.01\n(January 2023)\nMaarten van Steen\nAndrew S. Tanenbaum\n\n\nCopyright © 2023 Maarten van Steen and Andrew S. Tanenbaum\nPublished by Maarten van Steen\nThe first and second edition of this book were previously published by Pearson Education, Inc.\nISBN: 978-90-815406-3-6 (printed version)\nISBN: 978-90-815406-4-3 (digital version)\nEdition: 4. Version: 01 (January 2023)\nAll rights to text and illustrations are reserved by Maarten van Steen and Andrew S. Tanenbaum. This work may\nnot be copied, reproduced, or translated in whole or part without written permission of the publisher, except for\nbrief excerpts in reviews or scholarly analysis. Use with any form of information storage and retrieval, electronic\nadaptation or whatever, computer software, or by similar or dissimilar methods now known or developed in the\nfuture is strictly forbidden without written permission of the publisher.\n\n\nTo Mariëlle, Max, and Elke\n– MvS\nTo Suzanne, Barbara, Marvin, Aron, Nathan, Olivia, and Mirte\n– AST\n\n\nCONTENTS\nPreface\nxi\n1\nIntroduction\n1\n1.1\nFrom networked systems to distributed systems . . . . . . . . .\n3\n1.1.1\nDistributed versus decentralized systems . . . . . . . . .\n3\n1.1.2\nWhy making the distinction is relevant . . . . . . . . . .\n7\n1.1.3\nStudying distributed systems . . . . . . . . . . . . . . . .\n8\n1.2\nDesign goals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n10\n1.2.1\nResource sharing . . . . . . . . . . . . . . . . . . . . . . .\n10\n1.2.2\nDistribution transparency . . . . . . . . . . . . . . . . . .\n11\n1.2.3\nOpenness\n. . . . . . . . . . . . . . . . . . . . . . . . . . .\n15\n1.2.4\nDependability . . . . . . . . . . . . . . . . . . . . . . . . .\n18\n1.2.5\nSecurity\n. . . . . . . . . . . . . . . . . . . . . . . . . . . .\n21\n1.2.6\nScalability . . . . . . . . . . . . . . . . . . . . . . . . . . .\n24\n1.3\nA simple classification of distributed systems . . . . . . . . . . .\n32\n1.3.1\nHigh-performance distributed computing\n. . . . . . . .\n32\n1.3.2\nDistributed information systems . . . . . . . . . . . . . .\n37\n1.3.3\nPervasive systems\n. . . . . . . . . . . . . . . . . . . . . .\n43\n1.4\nPitfalls\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n52\n1.5\nSummary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n53\n2\nArchitectures\n55\n2.1\nArchitectural styles . . . . . . . . . . . . . . . . . . . . . . . . . .\n56\n2.1.1\nLayered architectures\n. . . . . . . . . . . . . . . . . . . .\n57\n2.1.2\nService-oriented architectures . . . . . . . . . . . . . . . .\n62\n2.1.3\nPublish-subscribe architectures . . . . . . . . . . . . . . .\n68\n2.2\nMiddleware and distributed systems . . . . . . . . . . . . . . . .\n73\n2.2.1\nMiddleware organization . . . . . . . . . . . . . . . . . .\n74\n2.2.2\nModifiable middleware\n. . . . . . . . . . . . . . . . . . .\n78\n2.3\nLayered-system architectures . . . . . . . . . . . . . . . . . . . .\n78\n2.3.1\nSimple client-server architecture . . . . . . . . . . . . . .\n79\n2.3.2\nMultitiered Architectures . . . . . . . . . . . . . . . . . .\n80\n2.3.3\nExample: The Network File System . . . . . . . . . . . .\n83\n2.3.4\nExample: The Web . . . . . . . . . . . . . . . . . . . . . .\n85\n2.4\nSymmetrically distributed system architectures\n. . . . . . . . .\n88\n2.4.1\nStructured peer-to-peer systems . . . . . . . . . . . . . .\n90\n2.4.2\nUnstructured peer-to-peer systems . . . . . . . . . . . . .\n92\nv\n\n\nvi\nCONTENTS\n2.4.3\nHierarchically organized peer-to-peer networks . . . . .\n95\n2.4.4\nExample: BitTorrent . . . . . . . . . . . . . . . . . . . . .\n96\n2.5\nHybrid system architectures . . . . . . . . . . . . . . . . . . . . .\n98\n2.5.1\nCloud computing . . . . . . . . . . . . . . . . . . . . . . .\n98\n2.5.2\nThe edge-cloud architecture . . . . . . . . . . . . . . . . . 100\n2.5.3\nBlockchain architectures . . . . . . . . . . . . . . . . . . . 104\n2.6\nSummary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 108\n3\nProcesses\n111\n3.1\nThreads . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 112\n3.1.1\nIntroduction to threads\n. . . . . . . . . . . . . . . . . . . 113\n3.1.2\nThreads in distributed systems . . . . . . . . . . . . . . . 122\n3.2\nVirtualization\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 127\n3.2.1\nPrinciple of virtualization . . . . . . . . . . . . . . . . . . 127\n3.2.2\nContainers . . . . . . . . . . . . . . . . . . . . . . . . . . . 133\n3.2.3\nComparing virtual machines and containers . . . . . . . 138\n3.2.4\nApplication of virtual machines to distributed systems . 139\n3.3\nClients\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 141\n3.3.1\nNetworked user interfaces\n. . . . . . . . . . . . . . . . . 141\n3.3.2\nVirtual desktop environment . . . . . . . . . . . . . . . . 144\n3.3.3\nClient-side software for distribution transparency . . . . 148\n3.4\nServers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 149\n3.4.1\nGeneral design issues\n. . . . . . . . . . . . . . . . . . . . 149\n3.4.2\nObject servers . . . . . . . . . . . . . . . . . . . . . . . . . 154\n3.4.3\nExample: The Apache Web server . . . . . . . . . . . . . 159\n3.4.4\nServer clusters\n. . . . . . . . . . . . . . . . . . . . . . . . 161\n3.5\nCode migration . . . . . . . . . . . . . . . . . . . . . . . . . . . . 167\n3.5.1\nReasons for migrating code . . . . . . . . . . . . . . . . . 167\n3.5.2\nModels for code migration\n. . . . . . . . . . . . . . . . . 171\n3.5.3\nMigration in heterogeneous systems . . . . . . . . . . . . 174\n3.6\nSummary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 177\n4\nCommunication\n181\n4.1\nFoundations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 183\n4.1.1\nLayered Protocols . . . . . . . . . . . . . . . . . . . . . . . 183\n4.1.2\nTypes of Communication\n. . . . . . . . . . . . . . . . . . 190\n4.2\nRemote procedure call . . . . . . . . . . . . . . . . . . . . . . . . 192\n4.2.1\nBasic RPC operation . . . . . . . . . . . . . . . . . . . . . 192\n4.2.2\nParameter passing . . . . . . . . . . . . . . . . . . . . . . 197\n4.2.3\nRPC-based application support . . . . . . . . . . . . . . . 201\n4.2.4\nVariations on RPC\n. . . . . . . . . . . . . . . . . . . . . . 205\n4.3\nMessage-oriented communication\n. . . . . . . . . . . . . . . . . 208\n4.3.1\nSimple transient messaging with sockets . . . . . . . . . 208\n4.3.2\nAdvanced transient messaging . . . . . . . . . . . . . . . 213\nDS 4.01\n \n\n\nCONTENTS\nvii\n4.3.3\nMessage-oriented persistent communication . . . . . . . 220\n4.3.4\nExample: Advanced Message Queuing Protocol (AMQP) 227\n4.4\nMulticast communication\n. . . . . . . . . . . . . . . . . . . . . . 232\n4.4.1\nApplication-level tree-based multicasting . . . . . . . . . 232\n4.4.2\nFlooding-based multicasting\n. . . . . . . . . . . . . . . . 236\n4.4.3\nGossip-based data dissemination . . . . . . . . . . . . . . 240\n4.5\nSummary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 245\n5\nCoordination\n247\n5.1\nClock synchronization . . . . . . . . . . . . . . . . . . . . . . . . 249\n5.1.1\nPhysical clocks\n. . . . . . . . . . . . . . . . . . . . . . . . 250\n5.1.2\nClock synchronization algorithms . . . . . . . . . . . . . 253\n5.2\nLogical clocks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 260\n5.2.1\nLamport’s logical clocks . . . . . . . . . . . . . . . . . . . 260\n5.2.2\nVector clocks\n. . . . . . . . . . . . . . . . . . . . . . . . . 266\n5.3\nMutual exclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . 272\n5.3.1\nOverview\n. . . . . . . . . . . . . . . . . . . . . . . . . . . 272\n5.3.2\nA centralized algorithm . . . . . . . . . . . . . . . . . . . 273\n5.3.3\nA distributed algorithm . . . . . . . . . . . . . . . . . . . 274\n5.3.4\nA token-ring algorithm\n. . . . . . . . . . . . . . . . . . . 276\n5.3.5\nA decentralized algorithm . . . . . . . . . . . . . . . . . . 277\n5.3.6\nExample: Simple locking with ZooKeeper\n. . . . . . . . 280\n5.4\nElection algorithms . . . . . . . . . . . . . . . . . . . . . . . . . . 283\n5.4.1\nThe bully algorithm\n. . . . . . . . . . . . . . . . . . . . . 283\n5.4.2\nA ring algorithm . . . . . . . . . . . . . . . . . . . . . . . 285\n5.4.3\nExample: Leader election in ZooKeeper . . . . . . . . . . 286\n5.4.4\nExample: Leader election in Raft . . . . . . . . . . . . . . 289\n5.4.5\nElections in large-scale systems . . . . . . . . . . . . . . . 290\n5.4.6\nElections in wireless environments . . . . . . . . . . . . . 294\n5.5\nGossip-based coordination . . . . . . . . . . . . . . . . . . . . . . 297\n5.5.1\nAggregation . . . . . . . . . . . . . . . . . . . . . . . . . . 297\n5.5.2\nA peer-sampling service . . . . . . . . . . . . . . . . . . . 298\n5.5.3\nGossip-based overlay construction . . . . . . . . . . . . . 299\n5.5.4\nSecure gossiping . . . . . . . . . . . . . . . . . . . . . . . 303\n5.6\nDistributed event matching . . . . . . . . . . . . . . . . . . . . . 306\n5.6.1\nCentralized implementations . . . . . . . . . . . . . . . . 307\n5.6.2\nSecure publish-subscribe solutions . . . . . . . . . . . . . 313\n5.7\nLocation systems . . . . . . . . . . . . . . . . . . . . . . . . . . . 315\n5.7.1\nGPS: Global Positioning System\n. . . . . . . . . . . . . . 315\n5.7.2\nWhen GPS is not an option . . . . . . . . . . . . . . . . . 317\n5.7.3\nLogical positioning of nodes\n. . . . . . . . . . . . . . . . 318\n5.8\nSummary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 322\n6\nNaming\n325\n \nDS 4.01\n\n\nviii\nCONTENTS\n6.1\nNames, identifiers, and addresses\n. . . . . . . . . . . . . . . . . 326\n6.2\nFlat naming\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 329\n6.2.1\nSimple solutions\n. . . . . . . . . . . . . . . . . . . . . . . 329\n6.2.2\nHome-based approaches . . . . . . . . . . . . . . . . . . . 331\n6.2.3\nDistributed hash tables\n. . . . . . . . . . . . . . . . . . . 333\n6.2.4\nHierarchical approaches . . . . . . . . . . . . . . . . . . . 338\n6.2.5\nSecure flat naming . . . . . . . . . . . . . . . . . . . . . . 343\n6.3\nStructured naming\n. . . . . . . . . . . . . . . . . . . . . . . . . . 344\n6.3.1\nName spaces\n. . . . . . . . . . . . . . . . . . . . . . . . . 344\n6.3.2\nName resolution . . . . . . . . . . . . . . . . . . . . . . . 347\n6.3.3\nThe implementation of a name space\n. . . . . . . . . . . 352\n6.3.4\nExample: The Domain Name System . . . . . . . . . . . 359\n6.3.5\nExample: The Network File System . . . . . . . . . . . . 369\n6.4\nAttribute-based naming\n. . . . . . . . . . . . . . . . . . . . . . . 375\n6.4.1\nDirectory services\n. . . . . . . . . . . . . . . . . . . . . . 375\n6.4.2\nHierarchical implementations: LDAP . . . . . . . . . . . 376\n6.4.3\nDecentralized implementations . . . . . . . . . . . . . . . 380\n6.5\nNamed-data networking . . . . . . . . . . . . . . . . . . . . . . . 385\n6.5.1\nBasics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 385\n6.5.2\nRouting\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . 387\n6.5.3\nSecurity in named-data networking . . . . . . . . . . . . 388\n6.6\nSummary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 389\n7\nConsistency and replication\n391\n7.1\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 392\n7.1.1\nReasons for replication . . . . . . . . . . . . . . . . . . . . 393\n7.1.2\nReplication as scaling technique . . . . . . . . . . . . . . 394\n7.2\nData-centric consistency models\n. . . . . . . . . . . . . . . . . . 395\n7.2.1\nConsistent ordering of operations . . . . . . . . . . . . . 396\n7.2.2\nEventual consistency . . . . . . . . . . . . . . . . . . . . . 406\n7.2.3\nContinuous consistency . . . . . . . . . . . . . . . . . . . 410\n7.3\nClient-centric consistency models . . . . . . . . . . . . . . . . . . 415\n7.3.1\nMonotonic reads . . . . . . . . . . . . . . . . . . . . . . . 417\n7.3.2\nMonotonic writes . . . . . . . . . . . . . . . . . . . . . . . 418\n7.3.3\nRead your writes . . . . . . . . . . . . . . . . . . . . . . . 420\n7.3.4\nWrites follow reads . . . . . . . . . . . . . . . . . . . . . . 421\n7.3.5\nExample: client-centric consistency in ZooKeeper . . . . 422\n7.4\nReplica management . . . . . . . . . . . . . . . . . . . . . . . . . 423\n7.4.1\nFinding the best server location\n. . . . . . . . . . . . . . 424\n7.4.2\nContent replication and placement . . . . . . . . . . . . . 426\n7.4.3\nContent distribution . . . . . . . . . . . . . . . . . . . . . 430\n7.4.4\nManaging replicated objects\n. . . . . . . . . . . . . . . . 434\n7.5\nConsistency protocols\n. . . . . . . . . . . . . . . . . . . . . . . . 437\n7.5.1\nSequential consistency: Primary-based protocols\n. . . . 438\nDS 4.01\n \n\n\nCONTENTS\nix\n7.5.2\nSequential consistency: Replicated-write protocols\n. . . 440\n7.5.3\nCache-coherence protocols\n. . . . . . . . . . . . . . . . . 443\n7.5.4\nImplementing continuous consistency . . . . . . . . . . . 446\n7.5.5\nImplementing client-centric consistency . . . . . . . . . . 448\n7.6\nExample: Caching and replication in the Web\n. . . . . . . . . . 451\n7.7\nSummary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 458\n8\nFault tolerance\n461\n8.1\nIntroduction to fault tolerance . . . . . . . . . . . . . . . . . . . . 462\n8.1.1\nBasic concepts . . . . . . . . . . . . . . . . . . . . . . . . . 463\n8.1.2\nFailure models\n. . . . . . . . . . . . . . . . . . . . . . . . 466\n8.1.3\nFailure masking by redundancy . . . . . . . . . . . . . . 470\n8.2\nProcess resilience . . . . . . . . . . . . . . . . . . . . . . . . . . . 471\n8.2.1\nResilience by process groups . . . . . . . . . . . . . . . . 472\n8.2.2\nFailure masking and replication . . . . . . . . . . . . . . 474\n8.2.3\nConsensus in faulty systems with crash failures . . . . . 475\n8.2.4\nExample: Paxos . . . . . . . . . . . . . . . . . . . . . . . . 479\n8.2.5\nConsensus in faulty systems with arbitrary failures . . . 491\n8.2.6\nConsensus in blockchain systems\n. . . . . . . . . . . . . 502\n8.2.7\nSome limitations on realizing fault tolerance . . . . . . . 503\n8.2.8\nFailure detection . . . . . . . . . . . . . . . . . . . . . . . 506\n8.3\nReliable client-server communication\n. . . . . . . . . . . . . . . 508\n8.3.1\nPoint-to-point communication\n. . . . . . . . . . . . . . . 508\n8.3.2\nRPC semantics in the presence of failures . . . . . . . . . 509\n8.4\nReliable group communication . . . . . . . . . . . . . . . . . . . 515\n8.4.1\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . 515\n8.4.2\nScalability in reliable multicasting . . . . . . . . . . . . . 518\n8.4.3\nAtomic multicast . . . . . . . . . . . . . . . . . . . . . . . 522\n8.5\nDistributed commit . . . . . . . . . . . . . . . . . . . . . . . . . . 528\n8.6\nRecovery . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 536\n8.6.1\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . 536\n8.6.2\nCheckpointing\n. . . . . . . . . . . . . . . . . . . . . . . . 538\n8.6.3\nMessage logging . . . . . . . . . . . . . . . . . . . . . . . 541\n8.7\nSummary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 543\n9\nSecurity\n545\n9.1\nIntroduction to security\n. . . . . . . . . . . . . . . . . . . . . . . 546\n9.1.1\nSecurity threats, policies, and mechanisms . . . . . . . . 547\n9.1.2\nDesign issues . . . . . . . . . . . . . . . . . . . . . . . . . 548\n9.2\nCryptography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 555\n9.2.1\nBasics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 555\n9.2.2\nSymmetric and asymmetric cryptosystems . . . . . . . . 557\n9.2.3\nHash functions . . . . . . . . . . . . . . . . . . . . . . . . 560\n9.2.4\nKey management . . . . . . . . . . . . . . . . . . . . . . . 562\n \nDS 4.01\n\n\nx\nCONTENTS\n9.3\nAuthentication . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 571\n9.3.1\nIntroduction to authentication\n. . . . . . . . . . . . . . . 571\n9.3.2\nAuthentication protocols . . . . . . . . . . . . . . . . . . . 572\n9.4\nTrust in distributed systems . . . . . . . . . . . . . . . . . . . . . 585\n9.4.1\nTrust in the face of Byzantine failures . . . . . . . . . . . 586\n9.4.2\nTrusting an identity\n. . . . . . . . . . . . . . . . . . . . . 586\n9.4.3\nTrusting a system . . . . . . . . . . . . . . . . . . . . . . . 591\n9.5\nAuthorization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 593\n9.5.1\nGeneral issues in access control\n. . . . . . . . . . . . . . 593\n9.5.2\nAttribute-based access control\n. . . . . . . . . . . . . . . 598\n9.5.3\nDelegation . . . . . . . . . . . . . . . . . . . . . . . . . . . 601\n9.5.4\nDecentralized authorization: an example . . . . . . . . . 605\n9.6\nMonitoring . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 609\n9.6.1\nFirewalls . . . . . . . . . . . . . . . . . . . . . . . . . . . . 609\n9.6.2\nIntrusion detection: basics . . . . . . . . . . . . . . . . . . 611\n9.6.3\nCollaborative intrusion detection . . . . . . . . . . . . . . 612\n9.7\nSummary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 613\nIndex\n615\nBibliography\n631\nGlossary\n665\nDS 4.01\n \n",
      "page_number": 1
    },
    {
      "number": 2,
      "title": "Segment 2 (pages 12-21)",
      "start_page": 12,
      "end_page": 21,
      "detection_method": "topic_boundary",
      "content": "PREFACE\nThis is the fourth edition of “Distributed Systems.” We have stayed close\nto the setup of the third edition, including examples of (part of) existing\ndistributed systems close to where general principles are discussed. For\nexample, we have included material on blockchain systems, and discuss their\nvarious components throughout the book. We have, again, used special boxed\nsections for material that can be skipped at first reading.\nThe text has been thoroughly reviewed, revised, and updated. In particular,\nall the Python code has been updated to Python3, while at the same time\nthe channel package has been almost completely revised and simplified. The\ncoding examples in the book leave out many details for readability, but\nthe complete examples are available through the book’s Website, hosted at\nwww.distributed-systems.net. We have made sure that virtually all examples\ncan be instantly executed through a simple script. However, it will be necessary\nto download and install special packages, such as Redis.\nAs before, the Website also contains slides in PDF and PPT, as well as the\nsources for producing slides using LATEX with the Beamer class. All figures,\nnow including those for tables and coding examples, are available in PDF and\nPNG formats.\nLike the previous edition, the book can be (freely) downloaded, making it\nmuch easier to use hyperlinks where appropriate. At the same time, we are\noffering a printed version through Amazon.com, available at minimal costs.\nThe book being fully digital allows us to incorporate updates when needed.\nWe plan to run updates on a yearly basis, while keeping previous versions\ndigitally available, as well as the original printed version. Running frequent\nupdates is not always the right thing to do from the perspective of teaching, but\nyearly updates and maintaining previous versions seems a good compromise.\nUpdates generally consist of small corrections, the kind that usually pop up\nin errata lists. Next to that, the book now also contains an index section, as\nwell as a glossary section. These are typically sections that generally take a\nhuge time to compile, but are also sections that typically grow as the book\nis being used. Likewise, we may find ways to improve how hyperlinks have\nbeen incorporated. Such matters do not affect the main text, while potentially\nimproving the usability of the digital version.\nxi\n\n\nxii\nPREFACE\nAcknowledgements\nMany teachers and students have helped with spotting the inevitable errors\nin the third edition, and we owe them many thanks, but in any case Michael\nMay, Linh Phan, Juan Abadie, and Christian Zirpins. For the fourth edition,\na handful of colleagues were so kind to review parts of the material. In\nparticular, we wish to thank Armin Stocker, Hermann de Meer, Pim Otte,\nJohan Pouwelse, Michael P. Anderson, Ivo Varenhorst, Aditya Pappu, and\nAlexander Iosup. A special thanks goes to Hein Meling of Stavanger University.\nNot only did he help us tremendously in understanding how Paxos works\n(already for the third edition), we have gratefully adopted, and adapted, his\nLATEX style file for generating message-sequence charts. These figures are now\nmuch more consistent. We thank Max van Steen for designing the cover.\nMaarten van Steen\nAndrew S. Tanenbaum\nDS 4.01\n \n\n\n01\nINTRODUCTION\n\n\n2\nCHAPTER 1. INTRODUCTION\nThe pace at which computer systems change was, is, and continues to be\noverwhelming. From 1945, when the modern computer era began, until about\n1985, computers were large and expensive. Moreover, lacking a way to connect\nthem, these computers operated independently of one another.\nStarting in the mid-1980s, however, two advances in technology began to\nchange that situation. The first was the development of powerful microproces-\nsors. Initially, these were 8-bit machines, but soon 16-, 32-, and 64-bit CPUs\nbecame common. With powerful multicore CPUs, we now are again facing\nthe challenge of adapting and developing programs to exploit parallelism. In\nany case, the current generation of machines have the computing power of the\nmainframes deployed 30 or 40 years ago, but for 1/1000th of the price or less.\nThe second development was the invention of high-speed computer net-\nworks. Local-area networks or LANs allow thousands of machines within a\nbuilding to be connected in such a way that small amounts of information can\nbe transferred in a few microseconds or so. Larger amounts of data can be\nmoved between machines at rates of billions of bits per second (bps). Wide-area\nnetwork or WANs allow hundreds of millions of machines all over the earth\nto be connected at speeds varying from tens of thousands to hundreds of\nmillions bps and more.\nParallel to the development of increasingly powerful and networked ma-\nchines, we have also been able to witness miniaturization of computer systems,\nwith perhaps the smartphone as the most impressive outcome. Packed with\nsensors, lots of memory, and a powerful multicore CPU, these devices are\nnothing less than full-fledged computers. Of course, they also have network-\ning capabilities. Along the same lines, so-called nano computers have become\nreadily available. These small, single-board computers, often the size of a\ncredit card, can easily offer near-desktop performance. Well-known examples\ninclude Raspberry Pi and Arduino systems.\nAnd the story continues. As digitalization of our society continues, we\nbecome increasingly aware of how many computers are actually being used,\nregularly embedded into other systems such as cars, airplanes, buildings,\nbridges, the power grid, and so on. This awareness is, unfortunately, increased\nwhen such systems suddenly turn out to be hackable.\nFor example, in\n2021, a fuel pipeline in the United States was effectively shut down by a\nransomware attack. In this case, the computer system consisted of a mix\nof sensors, actuators, controllers, embedded computers, servers, etc., all\nbrought together into a single system. What many of us do not realize, is that\nvital infrastructures, such as fuel pipelines, are monitored and controlled by\nnetworked computer systems. Along the same lines, it may be time to start\nrealizing that a modern car is actually an autonomously operating, mobile\nnetworked computer. In this case, instead of the mobile computer being\ncarried by a person, we need to deal with the mobile computer carrying\npeople.\nDS 4.01\n \n\n\n1.1. FROM NETWORKED SYSTEMS TO DISTRIBUTED SYSTEMS\n3\nThe size of a networked computer system may vary from a handful of\ndevices, to millions of computers. The interconnection network may be wired,\nwireless, or a combination of both. Moreover, these systems are often highly\ndynamic, in the sense that computers can join and leave, with the topology\nand performance of the underlying network almost continuously changing.\nIt is difficult to think of computer systems that are not networked. And\nas a matter of fact, most networked computer systems can be accessed from\nany place in the world because they are hooked up to the Internet. Studying\nto understand these systems can easily become exceedingly complex. In this\nchapter, we start with shedding some light on what needs to be understood\nto build up the bigger picture without getting lost.\n1.1\nFrom networked systems to distributed systems\nBefore we dive into various aspects of distributed systems, let us first consider\nwhat distribution, or decentralization, actually entails.\n1.1.1\nDistributed versus decentralized systems\nWhen considering various sources, there are quite a few opinions on dis-\ntributed versus decentralized systems. Often, the distinction is illustrated by\nthree different organizations of networked computer systems, as shown in\nFigure 1.1, where each node represents a computer system and an edge a\ncommunication link between two nodes.\nTo what extent such distinctions are useful remains to be seen, especially\nwhen discussions open on the pros and cons of each organization.\nFor\nexample, it is often stated that centralized organizations do not scale well.\nLikewise, distributed organizations are said to be more robust against failures.\nAs we shall see, none of these claims are generally true.\n(a)\n(b)\n(c)\nFigure 1.1: The organization of a (a) centralized, (b) decentralized, and\n(c) distributed system, according to various popular sources.\nWe take a\ndifferent approach, as figures such as these are really not that meaningful.\n \nDS 4.01\n\n\n4\nCHAPTER 1. INTRODUCTION\nWe take a different approach. If we think of a networked computer system\nas a collection of computers connected in a network, we can ask ourselves\nhow these computers even became connected to each other in the first place.\nThere are roughly two views that one can take.\nThe first, integrative view, is that there was a need to connect existing\n(networked) computer systems to each other. Typically, this happens when\nservices running on a system need to be made available to users and applica-\ntions that were not thought of before. This may happen, for example, when\nintegrating financial services with project management services, as is often the\ncase within a single organization. In the scientific-research domain, we have\nseen efforts to connect a myriad of often expensive resources (special-purpose\ncomputers, supercomputers, very large database systems, etc.) into what came\nto be known as a grid computer.\nThe second, expansive view is that an existing system required an exten-\nsion through additional computers. This view is the one most often related to\nthe field of distributed systems. It entails expanding a system with computers\nto hold resources close to where those resources are needed. An expansion\nmay also be driven by the need to improve dependability: if one computer\nfails, then there are others who can take over. An important type of expansion\nis when a service needs to be made available for remote users and applications,\nfor example, by offering a Web interface or a smartphone application. This\nlast example also shows that the distinction between an integrative and an\nexpansive view is not a clear-cut.\nIn both cases, we see that the networked system runs services, where each\nservice is implemented as a collection of processes and resources spread across\nmultiple computers. The two views lead to a natural distinction between two\ntypes of networked computer systems:\n• A decentralized system is a networked computer system in which pro-\ncesses and resources are necessarily spread across multiple computers.\n• A distributed system is a networked computer system in which pro-\ncesses and resources are sufficiently spread across multiple computers.\nBefore we discuss why this distinction is important, let us look at a few\nexamples of each type of system.\nDecentralized systems are mainly related to the integrative view of net-\nworked computer systems. They come to being because we want to con-\nnect systems, yet may be hindered by administrative boundaries. For exam-\nple, many applications in the artificial-intelligence domain require massive\namounts of data for building reliable predictive models. Normally, data is\nbrought to the high-performance computers that literally train models before\nthey can be used. But when data needs to stay within the perimeter of an\norganization (and there can be many reasons why this is necessary), we need\nto bring the training to the data. The result is known as federated learning,\nDS 4.01\n \n\n\n1.1. FROM NETWORKED SYSTEMS TO DISTRIBUTED SYSTEMS\n5\nand is implemented by a decentralized system, where the need for spreading\nprocesses and resources is dictated by administrative policies.\nAnother example of a decentralized system is that of distributed ledger,\nalso known as a blockchain. In this case, we need to deal with the situation\nthat participating parties do not trust each other enough to set up simple\nschemes for collaboration. Instead, what they do is essentially make transac-\ntions among each other fully public (and verifiable) by an extend-only ledger\nthat keeps records of those transactions. The ledger itself is fully spread across\nthe participants, and the participants are the ones who validate transactions\n(of others) before admitting them to the ledger. The result is a decentralized\nsystem in which processes and resources are, indeed, necessarily spread across\nmultiple computers, in this case due to lack of trust.\nAs a last example of a decentralized system, consider systems that are\nnaturally geographically dispersed. This occurs typically with systems in\nwhich an actual location needs to be monitored, for example, in the case of\na power plant, a building, a specific natural environment, and so on. The\nsystem, controlling the monitors and where decisions are made, may easily\nbe placed somewhere else than the location being monitored. One obvious\nexample is monitoring and controlling of satellites, but also more mundane\nsituations as monitoring and controlling traffic, trains, etc. In these examples,\nthe necessity for spreading processes and resources comes from a spatial\nargument.\nAs we mentioned, distributed systems are mainly related to the expansive\nview of networked computer systems. A well-known example is making use\nof e-mail services, such as Google Mail. What often happens is that a user logs\ninto the system through a Web interface to read and send mails. More often,\nhowever, is that users configure their personal computer (such as a laptop) to\nmake use of a specific mail client. To that end, they need to configure a few\nsettings, such as the incoming and outgoing server. In the case of Google Mail,\nthese are imap.gmail.com and smtp.gmail.com, respectively. Logically, it seems\nas if these two servers will handle all your mail. However, with an estimate\nof close to 2 billion users as of 2022, it is unlikely that only two computers\ncan handle all their e-mails (which was estimated to be more than 300 billion\nper year, that is, some 10,000 mails per second). Behind the scenes, of course,\nthe entire Google Mail service has been implemented and spread across many\ncomputers, jointly forming a distributed system. That system has been set\nup to make sure that so many users can process their mails (i.e., ensures\nscalability), but also that the risk of losing mail because of failures, is minimal\n(i.e., the system ensures fault tolerance). To the user, however, the image of\njust two servers is kept up (i.e., the distribution itself is highly transparent\nto the user). The distributed system implementing an e-mail service, such\nas Google Mail, typically expands (or shrinks) as dictated by dependability\nrequirements, in turn, dependent on the number of its users.\n \nDS 4.01\n\n\n6\nCHAPTER 1. INTRODUCTION\nAn entirely different type of distributed system is formed by the collection\nof so-called Content Delivery Networks, or CDNs for short. A well-known\nexample is Akamai with, in 2022, over 400,000 servers worldwide. We will\ndiscuss the principle working of CDNs later in Chapter 3. What it boils\ndown to, is that the content of an actual Website, is copied and spread across\nvarious servers of the CDN. When visiting a Website, the user is transparently\nredirected to a nearby server that holds all or part of the content of that Website.\nThe choice for which server to direct a user to may depend on many things,\nbut surely when dealing with streaming content, a server is selected for which\ngood performance in terms of latency and bandwidth can be guaranteed.\nThe CDN dynamically ensures that the selected server will have the required\ncontent readily available, as well as update that content when needed, or\nremove it from the server when there are no or very few users to service there.\nMeanwhile, the user knows nothing about what is going on behind the scenes\n(which, again, is a form of distribution transparency). We also see in this\nexample, that content is not copied to all servers, yet only to where it makes\nsense, that is, sufficiently, and for reasons of performance. CDNs also copy\ncontent to multiple servers to provide high levels of dependability.\nAs a final, much smaller distributed system, consider a setup based on a\nNetwork-Attached Storage device, also called a NAS. For domestic use, a\ntypical NAS consists of 2–4 slots for internal hard disks. The NAS operates\nas a file server: it is accessible through a (generally wireless) network for\nany authorized device, and as such can offer services like shared storage,\nautomated backups, streaming media, and so on. The NAS itself can best be\nseen as a single computer optimized for storing files, and offering the ability\nto easily share those files. The latter is important, and together with multiple\nusers, we essentially have a setup of a distributed system. The users will\nbe working with a set of files that are locally (i.e., from their laptop) easily\naccessible (in fact, seemingly integrated into the local file system), while also\ndirectly accessible by and for other users. Again, where and how the shared\nfiles are stored is hidden (i.e., the distribution is transparent). Assuming that\nsharing files is the goal, then we see that indeed a NAS can provide sufficient\nspreading of processes and resources.\nNote 1.1 (More information: Are centralized solutions bad?)\nThere appears to be a stubborn misconception that centralized solutions cannot\nscale. Moreover, they are almost always associated with introducing a single\npoint of failure. Both reasons are often seen to be enough to dismiss centralized\nsolutions as being a good choice when designing distributed systems.\nWhat many people forget is that a difference should be made between logical\nand physical designs. A logically centralized solution can be implemented in a\nhighly scalable distributed manner. An excellent example is the Domain Name\nSystem (DNS), which we discuss extensively in Chapter 6. Logically, DNS is\nDS 4.01\n \n\n\n1.1. FROM NETWORKED SYSTEMS TO DISTRIBUTED SYSTEMS\n7\norganized as a huge tree, where each path from the root to a leaf node represents\na fully qualified name, such as www.distributed-systems.net. It would be a\nmistake to think that the root node is implemented by just a single server. In\nfact, the root node is implemented by 13 different root servers, each server, in\nturn, implemented as a large cluster computer. The physical organization of DNS\nalso shows that the root is not a single point of failure. Being highly replicated, it\nwould take serious efforts to bring that root down and so far, all attempts to do\nso have failed.\nCentralized solutions are not bad just because they seem to be centralized.\nIn fact, as we shall encounter many times throughout this book, (logically, and\neven physically) centralized solutions are often much better than distributed\ncounterparts for the simple reason that there is a single point of failure. It makes\nthem much easier to manage, for example, and certainly in comparison where\nthere may be multiple points of failures. Moreover, that single point of failure\ncan be hardened against many kinds of failures as well as many kinds of security\nattacks. When it comes to being a performance bottleneck, we will also see\nthat many things can be done to ensure that even that cannot be held against\ncentralization.\nIn this sense, let us not forget that centralized solutions have even proven to\nbe extremely scalable and robust. They are called cloud-based solutions. Again,\ntheir implementations can make use of very sophisticated distributed solutions,\nyet even then, we shall see that even those solutions may sometimes need to rely\non a small set of physical machines, if only to guarantee performance.\n1.1.2\nWhy making the distinction is relevant\nWhy do we make this distinction between decentralized and distributed\nsystems? It is important to realize that centralized solutions are generally\nmuch simpler, and also simpler along different criteria. Decentralization,\nthat is, the act of spreading the implementation of a service across multiple\ncomputers because we believe it is necessary, is a decision that needs to be\nconsidered carefully. Indeed, distributed and decentralized solutions are\ninherently difficult:\n• There are many, often unexpected, dependencies that hinder understand-\ning the behavior of these systems.\n• Distributed and decentralized systems suffer almost continuously from\npartial failures: some process or resource, somewhere at one of the\nparticipating computers, is not operating according to expectations.\nDiscovering that failure may actually take some time, while also such\nfailures are preferably masked (i.e., they go unnoticed for users and\napplications), including the recovery from failures.\n \nDS 4.01\n\n\n8\nCHAPTER 1. INTRODUCTION\n• Much related to partial failures is the fact that in many networked\ncomputer systems, participating nodes, processes, resources, and so\non, come and go. This makes these systems highly dynamic, in turn\nrequiring forms of automated management and maintenance, in turn\nincreasing the complexity.\n• The fact that distributed and decentralized systems are networked, used\nby many users and applications, and often cross multiple administra-\ntive boundaries, make them particularly vulnerable to security attacks.\nTherefore, understanding these systems and their behavior, requires\nthat we understand how they can be, and are secured. Unfortunately,\nunderstanding security is not that easy.\nOur distinction is one between sufficiency and necessity for spreading processes\nand resources across multiple computers. Throughout this book, we take\nthe standpoint that decentralization can never be a goal in itself, and that it\nshould focus on the sufficiency for spreading processes and resources across\ncomputers. In principle, the less spreading, the better. Yet at the same time,\nwe need to realize that spreading is sometimes truly necessary, as illustrated\nby the examples of decentralized systems. From this point of sufficiency, the\nbook is truly about distributed systems and where appropriate, we shall speak\nof decentralized systems.\nAlong the same lines, considering that distributed and decentralized\nsystems are inherently complex, it is equally important to consider solutions\nthat are as simple as possible. Therefore, we shall hardly discuss optimizations\nto solutions, firmly believing that the impact of their negative contribution to\nincreased complexity outweighs the importance of their positive contribution\nto an increase of any type of performance.\n1.1.3\nStudying distributed systems\nConsidering that distributed systems are inherently difficult, it is important to\ntake a systematic approach toward studying them. One of our major concerns\nis that there are so many explicit and implicit dependencies in distributed\nsystems. For example, there is no such thing as a separate communication\nmodule, or a separate security module. Our approach is to take a look at\ndistributed systems from a limited number, yet different perspectives. Each\nperspective is considered in a separate chapter.\n• There are many ways in which distributed systems are organized. We\nstart our discussion by taking the architectural perspective: what are\ncommon organizations, what are common styles? The architectural\nperspective will help in getting a first grip on how various components\nof existing systems interact and depend on each other.\nDS 4.01\n \n",
      "page_number": 12
    },
    {
      "number": 3,
      "title": "Segment 3 (pages 22-32)",
      "start_page": 22,
      "end_page": 32,
      "detection_method": "topic_boundary",
      "content": "1.1. FROM NETWORKED SYSTEMS TO DISTRIBUTED SYSTEMS\n9\n• Distributed systems are all about processes. The process perspective is\nall about understanding the different forms of processes that occur in\ndistributed systems, be they threads, their virtualization of hardware\nprocesses, clients, servers, and so on.\nProcesses form the software\nbackbone of distributed systems, and their understanding is essential\nfor understanding distributed systems.\n• Obviously, with multiple computers at stake, communication between\nprocesses is essential. The communication perspective concerns the\nfacilities that distributed systems provide to exchange data between\nprocesses. It essentially entails mimicking procedure calls across mul-\ntiple computers, high-level message passing with a wealth of semantic\noptions, and various sorts of communication between sets of processes.\n• To make distributed systems work, what happens under the hood on top\nof which applications are executed, is that processes coordinate things.\nThey jointly coordinate, for example, to compensate for the lack of global\nclock, for realizing mutual exclusive access to shared resources, and so\non. The coordination perspective describes a number of fundamental\ncoordination tasks that need to be carried out as part of most distributed\nsystems.\n• To access processes and resources, we need naming.\nIn particular,\nwe need naming schemes that, when used, will lead to the process,\nresources, or whatever other type of entity that is being named. As\nsimple as this may seem, naming not only turns out to be crucial in\ndistributed systems, there are also many ways in which naming is\nsupported. The naming perspective focuses entirely on resolving a\nname to the access point of the named entity.\n• A critical aspect of distributed systems is that they perform well in terms\nof efficiency and in terms of dependability. The key instrument for both\naspects is replicating resources. The only problem with replication is\nthat updates may happen, implying that all copies of a resource need\nto be updated as well. It is here, that keeping up the appearance of a\nnondistributed system becomes challenging. The consistency and repli-\ncation perspective essentially concentrates on the trade-offs between\nconsistency, replication, and performance.\n• We already mentioned that distributed systems are subject to partial\nfailures. The perspective of fault tolerance dives into the means for\nmasking failures and their recovery. It has proven to be one of the\ntoughest perspectives for understanding distributed systems, mainly\nbecause there are so many trade-offs to be made, and also because\ncompletely masking failures and their recovery is provably impossible.\n \nDS 4.01\n\n\n10\nCHAPTER 1. INTRODUCTION\n• As also mentioned, there is no such thing as a nonsecured distributed\nsystem. The security perspective focuses on how to ensure authorized\naccess to resources. To that end, we need to discuss trust in distributed\nsystems, along with authentication, namely verifying a claimed identity.\nThe security perspective comes last, yet later in this chapter we shall\ndiscuss a few basic instruments that are needed to understand the role\nof security in the previous perspectives.\n1.2\nDesign goals\nJust because it is possible to build distributed systems does not necessarily\nmean that it is a good idea. In this section, we discuss four important goals\nthat should be met to make building a distributed system worth the effort. A\ndistributed system should make resources easily accessible; it should hide the\nfact that resources are distributed across a network; it should be open; and it\nshould be scalable.\n1.2.1\nResource sharing\nAn important goal of a distributed system is to make it easy for users (and\napplications) to access and share remote resources. Resources can be virtually\nanything, but typical examples include peripherals, storage facilities, data,\nfiles, services, and networks, to name just a few. There are many reasons for\nwanting to share resources. One obvious reason is that of economics. For\nexample, it is cheaper to have a single high-end reliable storage facility be\nshared than having to buy and maintain storage for each user separately.\nConnecting users and resources also makes it easier to collaborate and\nexchange information, as is illustrated by the success of the Internet with\nits simple protocols for exchanging files, mail, documents, audio, and video.\nThe connectivity of the Internet has allowed geographically widely dispersed\ngroups of people to work together by all kinds of groupware, that is, software\nfor collaborative editing, teleconferencing, and so on, as is illustrated by\nmultinational software-development companies that have outsourced much\nof their code production to Asia, but also the myriad of collaboration tools\nthat became (more easily) available due to the COVID-19 pandemic.\nResource sharing in distributed systems is also illustrated by the success\nof file-sharing peer-to-peer networks like BitTorrent. These distributed sys-\ntems make it simple for users to share files across the Internet. Peer-to-peer\nnetworks are often associated with distribution of media files such as au-\ndio and video. In other cases, the technology is used for distributing large\namounts of data, as in the case of software updates, backup services, and data\nsynchronization across multiple servers.\nSeamless integration of resource-sharing facilities in a networked environ-\nment is also now commonplace. A group of users can simply place files into a\nDS 4.01\n \n\n\n1.2. DESIGN GOALS\n11\nspecial shared folder that is maintained by a third party somewhere on the In-\nternet. Using special software, the shared folder is barely distinguishable from\nother folders on a user’s computer. In effect, these services replace the use of\na shared directory on a local distributed file system, making data available\nto users independent of the organization they belong to, and independent of\nwhere they are. The service is offered for different operating systems. Where\nexactly data are stored is completely hidden from the end user.\n1.2.2\nDistribution transparency\nAn important goal of a distributed system is to hide the fact that its processes\nand resources are physically distributed across multiple computers, possibly\nseparated by large distances. In other words, it tries to make the distribution\nof processes and resources transparent, that is, invisible, to end users and\napplications. As we shall discuss more extensively in Chapter 2, achieving\ndistribution transparency is realized through what is known as middleware,\nsketched in Figure 1.2 (see Gazis and Katsiri [2022] for a first introduction).\nIn essence, what applications get to see is the same interface everywhere,\nwhereas behind that interface, where and how processes and resources are\nand how they are accessed is kept transparent. There are different types of\ntransparency, which we discuss next.\nTypes of distribution transparency\nThe concept of transparency can be applied to several aspects of a distributed\nsystem, of which the most important ones are listed in Figure 1.3. We use the\nterm object to mean either a process or a resource.\nAccess transparency deals with hiding differences in data representation\nand the way that objects can be accessed. At a basic level, we want to hide\ndifferences in machine architectures, but more important is that we reach\nFigure 1.2: Realizing distribution transparency through a middleware layer.\n \nDS 4.01\n\n\n12\nCHAPTER 1. INTRODUCTION\nTransparency\nDescription\nAccess\nHide differences in data representation and how an object is\naccessed\nLocation\nHide where an object is located\nRelocation\nHide that an object may be moved to another location while\nin use\nMigration\nHide that an object may move to another location\nReplication\nHide that an object is replicated\nConcurrency\nHide that an object may be shared by several independent\nusers\nFailure\nHide the failure and recovery of an object\nFigure 1.3: Different forms of transparency in a distributed system (see ISO\n[1995]). An object can be a resource or a process.\nagreement on how data is to be represented by different machines and operat-\ning systems. For example, a distributed system may have computer systems\nthat run different operating systems, each having their own file-naming con-\nventions. Differences in naming conventions, differences in file operations, or\ndifferences in how low-level communication with other processes is to take\nplace, are examples of access issues that should preferably be hidden from\nusers and applications.\nAn important group of transparency types concerns the location of a\nprocess or resource.\nLocation transparency refers to the fact that users\ncannot tell where an object is physically located in the system. Naming\nplays an important role in achieving location transparency. In particular,\nlocation transparency can often be achieved by assigning only logical names\nto resources, that is, names in which the location of a resource is not secretly\nencoded. An example of a such a name is the uniform resource locator\n(URL) https://www.distributed-systems.net/, which gives no clue about\nthe actual location of the Web server where this book is offered. The URL also\ngives no clue whether files at that site have always been at their current location\nor were recently moved there. For example, the entire site may have been\nmoved from one data center to another, yet users should not notice. The latter\nis an example of relocation transparency, which is becoming increasingly\nimportant in the context of cloud computing: the phenomenon by which\nservices are provided by huge collections of remote servers. We return to\ncloud computing in subsequent chapters, and, in particular, in Chapter 2.\nWhere relocation transparency refers to being moved by the distributed\nsystem, migration transparency is offered by a distributed system when it\nsupports the mobility of processes and resources initiated by users, with-\nout affecting ongoing communication and operations. A typical example\nis communication between mobile phones: regardless whether two people\nDS 4.01\n \n\n\n1.2. DESIGN GOALS\n13\nare actually moving, mobile phones will allow them to continue their con-\nversation. Other examples that come to mind include online tracking and\ntracing of goods as they are being transported from one place to another,\nand teleconferencing (partly) using devices that are equipped with mobile\nInternet.\nAs we shall see, replication plays an important role in distributed systems.\nFor example, resources may be replicated to increase availability or to im-\nprove performance by placing a copy close to the place where it is accessed.\nReplication transparency deals with hiding the fact that several copies of a\nresource exist, or that several processes are operating in some form of lockstep\nmode so that one can take over when another fails. To hide replication from\nusers, it is necessary that all replicas have the same name. Consequently,\na system that supports replication transparency should generally support\nlocation transparency as well, because it would otherwise be impossible to\nrefer to replicas at different locations.\nWe already mentioned that an important goal of distributed systems is\nto allow sharing of resources. In many cases, sharing resources is done\ncooperatively, as in the case of communication channels. However, there are\nalso many examples of competitive sharing of resources. For example, two\nindependent users may each have stored their files on the same file server\nor may be accessing the same tables in a shared database. In such cases, it\nis important that each user does not notice that the other is making use of\nthe same resource. This phenomenon is called concurrency transparency.\nAn important issue is that concurrent access to a shared resource leaves that\nresource in a consistent state. Consistency can be achieved through locking\nmechanisms, by which users are, in turn, given exclusive access to the desired\nresource. A more refined mechanism is to make use of transactions, but these\nmay be difficult to implement in a distributed system, notably when scalability\nis an issue.\nLast, but certainly not least, it is important that a distributed system\nprovides failure transparency. This means that a user or application does not\nnotice that some piece of the system fails to work properly, and that the system\nsubsequently (and automatically) recovers from that failure. Masking failures\nis one of the hardest issues in distributed systems and is even impossible\nwhen certain apparently realistic assumptions are made, as we will discuss\nin Chapter 8. The main difficulty in masking and transparently recovering\nfrom failures lies in the inability to distinguish between a dead process and a\npainfully slowly responding one. For example, when contacting a busy Web\nserver, a browser will eventually time out and report that the Web page is\nunavailable. At that point, the user cannot tell whether the server is actually\ndown or that the network is badly congested.\n \nDS 4.01\n\n\n14\nCHAPTER 1. INTRODUCTION\nDegree of distribution transparency\nAlthough distribution transparency is generally considered preferable for any\ndistributed system, there are situations in which blindly attempting to hide\nall distribution aspects from users is not a good idea. A simple example is\nrequesting your electronic newspaper to appear in your mailbox before 7 AM\nlocal time, as usual, while you are currently at the other end of the world\nliving in a different time zone. Your morning paper will not be the morning\npaper you are used to.\nLikewise, a wide-area distributed system that connects a process in San\nFrancisco to a process in Amsterdam cannot be expected to hide the fact\nthat Mother Nature will not allow it to send a message from one process to\nthe other in less than approximately 35 milliseconds. Practice shows that it\nactually takes several hundred milliseconds using a computer network. Signal\ntransmission is not only limited by the speed of light, but also by limited\nprocessing capacities and delays in the intermediate switches.\nThere is also a trade-off between a high degree of transparency and the\nperformance of a system. For example, many Internet applications repeatedly\ntry to contact a server before finally giving up. Consequently, attempting to\nmask a transient server failure before trying another one may slow down the\nsystem as a whole. In such a case, it may have been better to give up earlier,\nor at least let the user cancel the attempts to make contact.\nAnother example is where we need to guarantee that several replicas,\nlocated on different continents, must be consistent all the time. In other words,\nif one copy is changed, that change should be propagated to all copies before\nallowing any other operation. A single update operation may now even take\nseconds to complete, something that cannot be hidden from users.\nFinally, there are situations in which it is not at all obvious that hiding\ndistribution is a good idea. As distributed systems are expanding to devices\nthat people carry around and where the very notion of location and context\nawareness is becoming increasingly important, it may be best to actually expose\ndistribution rather than trying to hide it. An obvious example is making use\nof location-based services, which can often be found on mobile phones, such\nas finding a nearest shop or any nearby friends.\nThere are other arguments against distribution transparency. Recognizing\nthat full distribution transparency is simply impossible, we should ask our-\nselves whether it is even wise to pretend that we can achieve it. It may be much\nbetter to make distribution explicit so that the user and application developer\nare never tricked into believing that there is such a thing as transparency. The\nresult will be that users will much better understand the (sometimes unex-\npected) behavior of a distributed system, and are thus much better prepared\nto deal with this behavior.\nThe conclusion is that aiming for distribution transparency may be a\nnice goal when designing and implementing distributed systems, but that\nDS 4.01\n \n\n\n1.2. DESIGN GOALS\n15\nit should be considered together with other issues such as performance\nand comprehensibility. The price for achieving full transparency may be\nsurprisingly high.\nNote 1.2 (Discussion: Against distribution transparency)\nSeveral researchers have argued that hiding distribution will lead to only further\ncomplicating the development of distributed systems, exactly for the reason that\nfull distribution transparency can never be achieved. A popular technique for\nachieving access transparency is to extend procedure calls to remote servers. How-\never, Waldo et al. [1997] already pointed out that attempting to hide distribution\nby such remote procedure calls can lead to poorly understood semantics, for\nthe simple reason that a procedure call does change when executed over a faulty\ncommunication link.\nAs an alternative, various researchers and practitioners are now arguing for\nless transparency, for example, by more explicitly using message-style commu-\nnication, or more explicitly posting requests to, and getting results from remote\nmachines, as is done on the Web when fetching pages. Such solutions will be\ndiscussed in detail in the next chapter.\nA somewhat radical standpoint was taken by Wams [2012] by stating that\npartial failures preclude relying on the successful execution of a remote service. If\nsuch reliability cannot be guaranteed, it is then best to always perform only local\nexecutions, leading to the copy-before-use principle. According to this principle,\ndata can be accessed only after they have been transferred to the machine of the\nprocess wanting that data. Moreover, modifying a data item should not be done.\nInstead, it can only be updated to a new version. It is not difficult to imagine\nthat many other problems will surface. However, Wams shows that many existing\napplications can be retrofitted to this alternative approach without sacrificing\nfunctionality.\n1.2.3\nOpenness\nAnother important goal of distributed systems is openness. An open dis-\ntributed system is essentially a system that offers components that can easily\nbe used by, or integrated into other systems. At the same time, an open\ndistributed system itself will often consist of components that originate from\nelsewhere.\nInteroperability, composability, and extensibility\nTo be open means that components should adhere to standard rules that\ndescribe the syntax and semantics of what those components have to offer (i.e.,\nwhich service they provide). A general approach is to define services through\ninterfaces using an Interface Definition Language (IDL). Interface definitions\nwritten in an IDL nearly always capture only the syntax of services. In other\nwords, they specify precisely the names of the functions that are available\n \nDS 4.01\n\n\n16\nCHAPTER 1. INTRODUCTION\ntogether with types of the parameters, return values, possible exceptions that\ncan be raised, and so on. The hard part is specifying precisely what those\nservices do, that is, the semantics of interfaces. In practice, such specifications\nare given in an informal way by natural language.\nIf properly specified, an interface definition allows an arbitrary process\nthat needs a certain interface, to talk to another process that provides that\ninterface. It also allows two independent parties to build entirely different\nimplementations of those interfaces, leading to two separate components that\noperate in exactly the same way.\nProper specifications are complete and neutral. Complete means that\neverything that is necessary to make an implementation has indeed been\nspecified. However, many interface definitions are not at all complete, so\nthat it is necessary for a developer to add implementation-specific details.\nJust as important is the fact that specifications do not prescribe what an\nimplementation should look like; they should be neutral.\nAs pointed out in Blair and Stefani [1998], completeness and neutrality are\nimportant for interoperability and portability. Interoperability characterizes\nthe extent by which two implementations of systems or components from\ndifferent manufacturers can co-exist and work together by merely relying\non each other’s services as specified by a common standard. Portability\ncharacterizes to what extent an application developed for a distributed system\nA can be executed, without modification, on a different distributed system B\nthat implements the same interfaces as A.\nAnother important goal for an open distributed system is that it should\nbe easy to configure the system out of different components (possibly from\ndifferent developers). Moreover, it should be easy to add new components or\nreplace existing ones without affecting those components that stay in place.\nIn other words, an open distributed system should also be extensible. For\nexample, in an extensible system, it should be relatively easy to add parts that\nrun on a different operating system, or even to replace an entire file system.\nRelatively simple examples of extensibility are plug-ins for Web browsers, but\nalso those for Websites, such as the ones used for WordPress.\nNote 1.3 (Discussion: Open systems in practice)\nOf course, what we have just described is an ideal situation. Practice shows that\nmany distributed systems are not as open as we would like, and that still a lot\nof effort is needed to put various bits and pieces together to make a distributed\nsystem. One way out of the lack of openness is to simply reveal all the gory\ndetails of a component and to provide developers with the actual source code.\nThis approach is becoming increasingly popular, leading to so-called open-source\nprojects, where large groups of people contribute to improving and debugging\nsystems. Admittedly, this is as open as a system can get, but whether it is the best\nway is questionable.\nDS 4.01\n \n\n\n1.2. DESIGN GOALS\n17\nSeparating policy from mechanism\nTo achieve flexibility in open distributed systems, it is crucial that the system\nbe organized as a collection of relatively small and easily replaceable or\nadaptable components. This implies that we should provide definitions of not\nonly the highest-level interfaces, that is, those seen by users and applications,\nbut also definitions for interfaces to internal parts of the system and describe\nhow those parts interact. This approach is relatively new. Many older and\neven contemporary systems are constructed using a monolithic approach\nin which components are only logically separated but implemented as one,\nhuge program. This approach makes it hard to replace or adapt a component\nwithout affecting the entire system. Monolithic systems thus tend to be closed\ninstead of open.\nThe need for changing a distributed system is often caused by a component\nthat does not provide the optimal policy for a specific user or application.\nAs an example, consider caching in Web browsers. There are many different\nparameters that need to be considered:\nStorage: Where is data to be cached? Typically, there will be an in-memory\ncache next to storage on disk. In the latter case, the exact position in the\nlocal file system needs to be considered.\nExemption: When the cache fills up, which data is to be removed so that\nnewly fetched pages can be stored?\nSharing: Does each browser make use of a private cache, or is a cache to be\nshared among browsers of different users?\nRefreshing: When does a browser check if cached data is still up-to-date?\nCaches are most effective when a browser can return pages without\nhaving to contact the original Website. However, this bears the risk of\nreturning stale data. Note also that refresh rates are highly dependent\non which data is actually cached: whereas timetables for trains hardly\nchange, this is not the case for Web pages showing current highway-\ntraffic conditions, or worse yet, stock prices.\nWhat we need is a separation between policy and mechanism. In the case\nof Web caching, for example, a browser should ideally provide facilities for\nonly storing documents (i.e., a mechanism) and at the same time allow users\nto decide which documents are stored and for how long (i.e., a policy). In\npractice, this can be implemented by offering a rich set of parameters that the\nuser can set (dynamically). When taking this a step further, a browser may\neven offer facilities for plugging in policies that a user has implemented as a\nseparate component.\n \nDS 4.01\n\n\n18\nCHAPTER 1. INTRODUCTION\nNote 1.4 (Discussion: Is a strict separation really what we need?)\nIn theory, strictly separating policies from mechanisms seems to be the way to go.\nHowever, there is an important trade-off to consider: the stricter the separation, the\nmore we need to make sure that we offer the appropriate collection of mechanisms.\nIn practice, this means that a rich set of features is offered, in turn leading to many\nconfiguration parameters. As an example, the popular Firefox browser comes\nwith a few hundred configuration parameters. Just imagine how the configuration\nspace explodes when considering large distributed systems consisting of many\ncomponents. In other words, strict separation of policies and mechanisms may\nlead to highly complex configuration problems.\nOne option to alleviate these problems is to provide reasonable defaults, and\nthis is what often happens in practice. An alternative approach is one in which\nthe system observes its own usage and dynamically changes parameter settings.\nThis leads to what are known as self-configurable systems. Nevertheless, the\nfact alone that many mechanisms need to be offered to support a wide range of\npolicies often makes coding distributed systems very complicated. Hard-coding\npolicies into a distributed system may reduce complexity considerably, but at the\nprice of less flexibility.\n1.2.4\nDependability\nAs its name suggests, dependability refers to the degree that a computer\nsystem can be relied upon to operate as expected. In contrast to single-\ncomputer systems, dependability in distributed systems can be rather intricate\ndue to partial failures: somewhere there is a component failing while the\nsystem as a whole still seems to be living up to expectations (up to a certain\npoint or moment). Although single-computer systems can also suffer from\nfailures that do not appear immediately, having a potentially large collection\nof networked computer systems complicates matters considerably. In fact, one\nshould assume that at any time, there are always partial failures occurring.\nAn important goal of distributed systems is to mask those failures, as well as\nmask the recovery from those failures. This masking is the essence of being\nable to tolerate faults, accordingly referred to as fault tolerance.\nBasic concepts\nDependability is a term that covers several useful requirements for distributed\nsystems, including the following [Kopetz and Verissimo, 1993]:\n• Availability\n• Reliability\n• Safety\n• Maintainability\nDS 4.01\n \n\n\n1.2. DESIGN GOALS\n19\nAvailability is defined as the property that a system is ready to be used\nimmediately. In general, it refers to the probability that the system is operating\ncorrectly at any given moment and is available to perform its functions on\nbehalf of its users. In other words, a highly available system is one that will\nmost likely be working at a given instant in time.\nReliability refers to the property that a system can run continuously\nwithout failure. In contrast to availability, reliability is defined in terms of a\ntime interval instead of an instant in time. A highly reliable system is one\nthat will most likely continue to work without interruption during a relatively\nlong period of time. This is a subtle but important difference when compared\nto availability. If a system goes down on average for one, seemingly random\nmillisecond every hour, it has an availability of more than 99.9999 percent,\nbut is still unreliable. Similarly, a system that never crashes but is shut down\nfor two specific weeks every August has high reliability but only 96 percent\navailability. The two are not the same.\nSafety refers to the situation that when a system temporarily fails to\noperate correctly, no catastrophic event happens. For example, many process-\ncontrol systems, such as those used for controlling nuclear power plants or\nsending people into space, are required to provide a high degree of safety. If\nsuch control systems temporarily fail for only a very brief moment, the effects\ncould be disastrous. Many examples from the past (and probably many more\nyet to come) show how hard it is to build safe systems.\nFinally, maintainability refers to how easily a failed system can be repaired.\nA highly maintainable system may also show a high degree of availability,\nespecially if failures can be detected and repaired automatically. However, as\nwe shall see, automatically recovering from failures is easier said than done.\nTraditionally, fault-tolerance has been related to the following three metrics:\n• Mean Time To Failure (MTTF): The average time until a component\nfails.\n• Mean Time To Repair (MTTR): The average time needed to repair a\ncomponent.\n• Mean Time Between Failures (MTBF): Simply MTTF + MTTR.\nNote that these metrics make sense only if we have an accurate notion of\nwhat a failure actually is. As we will encounter in Chapter 8, identifying the\noccurrence of a failure may actually not be so obvious.\nFaults, errors, failures\nA system is said to fail when it cannot meet its promises. In particular, if a\ndistributed system is designed to provide its users with several services, the\nsystem has failed when one or more of those services cannot be (completely)\nprovided. An error is a part of a system’s state that may lead to a failure. For\n \nDS 4.01\n",
      "page_number": 22
    },
    {
      "number": 4,
      "title": "Segment 4 (pages 33-42)",
      "start_page": 33,
      "end_page": 42,
      "detection_method": "topic_boundary",
      "content": "20\nCHAPTER 1. INTRODUCTION\nexample, when transmitting packets across a network, it is to be expected that\nsome packets have been damaged when they arrive at the receiver. Damaged\nin this context means that the receiver may incorrectly sense a bit value (e.g.,\nreading a 1 instead of a 0), or may even be unable to detect that something\nhas arrived.\nThe cause of an error is called a fault. Clearly, finding out what caused an\nerror is important. For example, a wrong or bad transmission medium may\neasily cause packets to be damaged. In this case, it is relatively easy to remove\nthe fault. However, transmission errors may also be caused by bad weather\nconditions, such as in wireless networks. Changing the weather to reduce or\nprevent errors is a bit trickier.\nAs another example, a crashed program is clearly a failure, which may\nhave happened because the program entered a branch of code containing\na programming bug (i.e., a programming error). The cause of that bug is\ntypically a programmer. In other words, the programmer is the cause of the\nerror (programming bug), in turn leading to a failure (a crashed program).\nBuilding dependable systems closely relates to controlling faults.\nAs\nexplained by Avizienis et al. [2004], a distinction can be made between pre-\nventing, tolerating, removing, and forecasting faults. For our purposes, the\nmost important issue is fault tolerance, meaning that a system can provide\nits services even in the presence of faults. For example, by applying error-\ncorrecting codes for transmitting packets, it is possible to tolerate, to a certain\nextent, relatively poor transmission lines and reducing the probability that an\nerror (a damaged packet) may lead to a failure.\nFaults are generally classified as transient, intermittent, or permanent.\nTransient faults occur once and then disappear. If the operation is repeated,\nthe fault goes away. A bird flying through the beam of a microwave transmitter\nmay cause lost bits on some network (not to mention a roasted bird). If the\ntransmission times out and is retried, it will probably work the second time.\nAn intermittent fault occurs, then vanishes on its own accord, then reap-\npears, and so on. A loose contact on a connector will often cause an inter-\nmittent fault. Intermittent faults cause a great deal of aggravation because\nthey are difficult to diagnose. Typically, when the fault doctor shows up, the\nsystem works fine.\nA permanent fault is one that continues to exist until the faulty compo-\nnent is replaced. Burnt-out chips, software bugs, and disk-head crashes are\nexamples of permanent faults.\nDependable systems are also required to provide security, especially in\nterms of confidentiality and integrity. Confidentiality is the property that\ninformation is disclosed only to authorized parties, while integrity relates to\nensuring that alterations to various assets can be made only in an authorized\nway. Indeed, can we speak of a dependable system when confidentiality and\nintegrity are not in place? We return to security next.\nDS 4.01\n \n\n\n1.2. DESIGN GOALS\n21\n1.2.5\nSecurity\nA distributed system that is not secure, is not dependable. As mentioned,\nspecial attention is needed to ensure confidentiality and integrity, both of\nwhich are directly coupled to authorized disclosure and access of information\nand resources. In any computer system, authorization is done by checking\nwhether an identified entity has proper access rights. In turn, this means\nthat the system should know it is indeed dealing with the proper entity. For\nthis reason, authentication is essential: verifying the correctness of a claimed\nidentity. Equally important is the notion of trust. If a system can positively\nauthenticate a person, what is that authentication worth if the person cannot\nbe trusted? For this reason alone, proper authorization is important, as it\nmay be used to limit any damage that a person, who could in hindsight not\nbe trusted, can cause. For example, in financial systems, authorization may\nlimit the amount of money a person is allowed to transfer between various\naccounts. We will discuss trust, authentication, and authorization at length in\nChapter 9.\nKey elements needed to understand security\nAn essential technique to making distributed systems secure is cryptography.\nThis is not the place in this book to extensively discuss cryptography (which\nwe also defer until Chapter 9), yet to understand how security fits into various\nperspectives in the following chapters, we informally introduce some of its\nbasic elements.\nKeeping matters simple, security in distributed systems is all about en-\ncrypting and decrypting data using security keys. The easiest way of consid-\nering a security key K is to see it as a function operating on some data data.\nWe use the notation K(data) to express the fact that the key K operates on\ndata.\nThere are two ways of encrypting and decrypting data. In a symmetric\ncryptosystem, encryption and decryption takes place with a single key. Denot-\ning by EK(data) the encryption of data using key EK, and likewise DK(data)\nfor decryption with key DK, then in a symmetric cryptosystem, the same key\nis used for encryption and decryption, i.e.,\nif data = DK(EK(data)) then DK = EK.\nNote that in a symmetric cryptosystem, the key will need to be kept secret by\nall parties that are authorized to encrypt or decrypt data. In an asymmetric\ncryptosystem, the keys used for encryption and decryption are different.\nIn particular, there is a public key PK that can be used by anyone, and a\nsecret key SK that is, as its name suggests, to be kept secret. Asymmetric\ncryptosystems are also called public-key systems.\n \nDS 4.01\n\n\n22\nCHAPTER 1. INTRODUCTION\nEncryption and decryption in public-key systems can be used in two,\nfundamentally different ways. First, if Alice wants to encrypt data that can\nbe decrypted only by Bob, she should use Bob’s public key, PKB, leading\nto the encrypted data PKB(data). Only the holder of the associated secret\nkey can decrypt this information, i.e., Bob, who will apply the operation\nSKB(PKB(data)), which returns data.\nA second, and widely applied use case, is that of realizing digital signa-\ntures. Suppose Alice makes some data available for which it is important that\nany party, but let us assume it is Bob, needs to know for sure that it comes\nfrom Alice. In that case, Alice can encrypt the data with her secret key SKA,\nleading to SKA(data). If it can be assured that the associated public key PKA\nindeed belongs to Alice, then successfully decrypting SKA(data) to data, is\nproof that Alice knows about data: she is the only one holding the secret key\nSKA. Of course, we need to make the assumption that Alice is indeed the only\none who holds SKA. We return to some of these assumptions in Chapter 9.\nAs it turns out, proving that an entity has seen, or knows about some\ndata, returns frequently in secured distributed systems. Practical placement\nof digital signatures is generally more efficient by a hash function. A hash\nfunction H has the property that when operating on some data, i.e., H(data),\nit returns a fixed-length string, regardless of the length of data. Any change\nof data to data∗will lead to a different hash value H(data∗). Moreover, given\na hash value h, it is computationally impossible in practice, to discover the\noriginal data. What this all means, is that for placing a digital signature, Alice\ncomputes sig = SKA(H(data)) as her signature, and tells Bob about data, H\nand sig. Bob, in turn, can then verify that signature by computing PKA(sig)\nand verifying that it matches the value H(data).\nUsing cryptography in distributed systems\nThe application of cryptography in distributed systems comes in many forms.\nBesides its general use for encryption and digital signatures, cryptography\nforms the basis for realizing a secure channel between two communicating\nparties. Such channels basically let two parties know for sure that they are\nindeed communicating to the entities that they expected to communicate with.\nIn other words, a communication channel that supports mutual authentication.\nA practical example of a secure channel is using https when accessing Websites.\nNow, many browsers demand that Websites support this protocol, and at\nthe very least will warn the user when this is not the case. In general, using\ncryptography is necessary to realize authentication (and authorization) in\ndistributed systems.\nCryptography is also used to realize secure distributed data structures.\nA well-known example is that of a blockchain, which is, literally, a chain of\nblocks. The basic idea is simple: hash the data in a block Bi, and place that\nhash value as part of the data in its succeeding block Bi+1. Any change in\nDS 4.01\n \n\n\n1.2. DESIGN GOALS\n23\nBi (for example, as the result of an attack), will require that the attacker also\nchanges the stored hash value in Bi+1. However, because the successor of\nBi+1 contains the hash computed over the data in Bi+1, and thus including\nthe original hash value of Bi, the attacker will also have to change the new has\nvalue of Bi as stored in Bi+1. Yet changing that value, also means changing the\nhash value of Bi+1, and thus the value stored in Bi+2, in turn, requiring that\na new hash value is to be computed for Bi+2, and so on. In other words, by\nsecurely linking blocks into a chain, any successful change to a block requires\nthat all successive blocks be modified as well. These modifications should go\nunnoticed, which is virtually impossible.\nCryptography is also used for another important mechanism in distributed\nsystems: delegating access rights. The basic idea is that Alice may want to\ndelegate some rights to Bob, who, in turn, may want to pass some of those\nrights on to Chuck. Using appropriate means (which we discuss in Chapter 9, a\nservice can securely check that Chuck has indeed been authorized to perform\ncertain operations, without the need for that service to check with Alice\nwhether the delegation is in place. Note that delegation is something we are\nnow used to: many of us delegate access rights that we have as a user to\nspecific applications, such as an e-mail client.\nAn upcoming distributed application of cryptography is so-called multi-\nparty computation: the means for two or three parties to compute a value\nfor which the data of those parties is needed, but without having to actually\nshare that data. An often-used example is computing the number of votes\nwithout having to know who voted for whom.\nWe will see many more examples of security in distributed systems in the\nfollowing chapters. With the brief explanations of the cryptographic basis,\nit should suffice to see how security is applied. We shall consistently use\nthe notations as shown in Figure 1.4. Alternatively, security examples can be\nskipped until having studied Chapter 9.\nNotation\nDescription\nKA,B\nSecret key shared by A and B\nPKA\nPublic key of A\nSKA\nPrivate (secret) key of A\nEK(data)\nEncryption of data using key EK (or key K)\nDK(data)\nDecryption of (encrypted) data using key DK (or key K)\nH(data)\nThe hash of data computed using function H\nFigure 1.4: Notations for cryptosystems used in this book.\n \nDS 4.01\n\n\n24\nCHAPTER 1. INTRODUCTION\n1.2.6\nScalability\nFor many of us, worldwide connectivity through the Internet is as common as\nbeing able to send a package to anyone anywhere around the world. Moreover,\nwhere until recently, we were used to having relatively powerful desktop\ncomputers for office applications and storage, we are now witnessing that\nsuch applications and services are being placed in what has been coined “the\ncloud,” in turn leading to an increase of much smaller networked devices such\nas tablet computers or even cloud-only laptops such as Google’s Chromebook.\nWith this in mind, scalability has become one of the most important design\ngoals for developers of distributed systems.\nScalability dimensions\nScalability of a system can be measured along at least three different dimen-\nsions (see [Neuman, 1994]):\nSize scalability: A system can be scalable regarding its size, meaning that\nwe can easily add more users and resources to the system without any\nnoticeable loss of performance.\nGeographical scalability: A geographically scalable system is one in which\nthe users and resources may lie far apart, but the fact that communication\ndelays may be significant is hardly noticed.\nAdministrative scalability: An administratively scalable system is one that\ncan still be easily managed even if it spans many independent adminis-\ntrative organizations.\nLet us take a closer look at each of these three scalability dimensions.\nSize scalability\nWhen a system needs to scale, very different types of prob-\nlems need to be solved. Let us first consider scaling regarding size. If more\nusers or resources need to be supported, we are often confronted with the\nlimitations of centralized services, although often for very different reasons.\nFor example, many services are centralized in the sense that they are imple-\nmented by a single server running on a specific machine in the distributed\nsystem. In a more modern setting, we may have a group of collaborating\nservers co-located on a cluster of tightly coupled machines physically placed\nat the same location. The problem with this scheme is obvious: the server, or\ngroup of servers, can simply become a bottleneck when it needs to process\nan increasing number of requests. To illustrate how this can happen, let us\nassume that a service is implemented on a single machine. In that case, there\nare essentially three root causes for becoming a bottleneck:\n• The computational capacity, limited by the CPUs\n• The storage capacity, including the I/O transfer rate\nDS 4.01\n \n\n\n1.2. DESIGN GOALS\n25\n• The network between the user and the centralized service\nLet us first consider the computational capacity. Just imagine a service for\ncomputing optimal routes taking real-time traffic information into account. It\nis not difficult to imagine that this may be primarily a compute-bound service,\nrequiring several (tens of) seconds to complete a request. If there is only a\nsingle machine available, then even a modern high-end system will eventually\nrun into problems if the number of requests increases beyond a certain point.\nLikewise, but for different reasons, we will run into problems when having\na service that is mainly I/O bound. A typical example is a poorly designed\ncentralized search engine. The problem with content-based search queries is\nthat we essentially need to match a query against an entire data set. Even\nwith advanced indexing techniques, we may still face the problem of having\nto process a huge amount of data exceeding the main-memory capacity of\nthe machine running the service. As a consequence, much of the processing\ntime will be determined by the relatively slow disk accesses and transfer of\ndata between disk and main memory. Simply adding more or higher-speed\ndisks will prove not to be a sustainable solution as the number of requests\ncontinues to increase.\nFinally, the network between the user and the service may also be the cause\nof poor scalability. Just imagine a video-on-demand service that needs to\nstream high-quality video to multiple users. A video stream can easily require\na bandwidth of 8 to 10 Mbps, meaning that if a service sets up point-to-point\nconnections with its customers, it may soon hit the limits of the network\ncapacity of its own outgoing transmission lines.\nThere are several solutions to attack size scalability, which we discuss\nbelow after having looked into geographical and administrative scalability.\nNote 1.5 (Advanced: Analyzing size scalability)\nFigure 1.5: A simple model of a service as a queuing system.\nSize scalability problems for centralized services can be formally analyzed\nusing queuing theory and making a few simplifying assumptions. At a conceptual\nlevel, a centralized service can be modeled as the simple queuing system shown\nin Figure 1.5: requests are submitted to the service, where they are queued until\nfurther notice. As soon as the process can handle a next request, it fetches it from\nthe queue, does its work, and produces a response. We largely follow Menasce\nand Almeida [2002] in explaining the performance of a centralized service.\n \nDS 4.01\n\n\n26\nCHAPTER 1. INTRODUCTION\nOften, we may assume that the queue has an infinite capacity, meaning that\nthere is no restriction on the number of requests that can be accepted for further\nprocessing. Strictly speaking, this means that the arrival rate of requests is not\ninfluenced by what is currently in the queue or being processed. Assuming that\nthe arrival rate of requests is λ requests per second, and that the processing\ncapacity of the service is µ requests per second, one can compute that the fraction\nof time pk that there are k requests in the system is equal to:\npk =\n\u00001 −λ\nµ\n\u0001\u0000 λ\nµ\n\u0001k\nIf we define the utilization U of a service as the fraction of time that it is busy,\nthen clearly,\nU = ∑\nk>0\npk = 1 −p0 = λ\nµ ⇒pk = (1 −U)Uk\nWe can then compute the average number N of requests in the system as\nN = ∑\nk≥0\nk · pk = ∑\nk≥0\nk · (1 −U)Uk = (1 −U) ∑\nk≥0\nk · Uk = (1 −U)U\n(1 −U)2 =\nU\n1 −U .\nWhat we are truly interested in, is the response time R: how long does it take\nbefore the service to process a request, including the time spent in the queue.\nTo that end, we need the average throughput X. Considering that the service is\n“busy” when at least one request is being processed, and that this then happens\nwith a throughput of µ requests per second, and during a fraction U of the total\ntime, we have:\nX =\nU · µ\n|{z}\nserver at work\n+ (1 −U) · 0\n|\n{z\n}\nserver idle\n= λ\nµ · µ = λ\nUsing Little’s formula [Trivedi, 2002], we can then derive the response time as\nR = N\nX =\nS\n1 −U ⇒R\nS =\n1\n1 −U\nwhere S =\n1\nµ, the actual service time. Note that if U is small, the response-\nto-service time ratio is close to 1, meaning that a request is virtually instantly\nprocessed, and at the maximum speed possible. However, as soon as the utilization\ncomes closer to 1, we see that the response-to-server time ratio quickly increases to\nvery high values, effectively meaning that the system is coming close to a grinding\nhalt. This is where we see scalability problems emerge. From this simple model,\nwe can see that the only solution is bringing down the service time S. We leave it\nas an exercise to the reader to explore how S may be decreased.\nGeographical scalability\nGeographical scalability has its own problems. One\nof the main reasons why it is still difficult to scale existing distributed systems\nDS 4.01\n \n\n\n1.2. DESIGN GOALS\n27\nthat were designed for local-area networks is that many of them are based\non synchronous communication. In this form of communication, a party\nrequesting a service, generally referred to as a client, blocks until a reply is\nsent back from the server implementing the service. More specifically, we often\nsee a communication pattern consisting of many client-server interactions, as\nmay be the case with database transactions. This approach generally works\nfine in LANs, where communication between two machines is often at worst\na few hundred microseconds. However, in a wide-area system, we need to\nconsider that interprocess communication may be hundreds of milliseconds,\nthree orders of magnitude slower. Building applications using synchronous\ncommunication in wide-area systems requires a great deal of care (and not\njust a little patience), notably with a rich interaction pattern between client\nand server.\nAnother problem that hinders geographical scalability is that communica-\ntion in wide-area networks is inherently much less reliable than in local-area\nnetworks. In addition, we generally also need to deal with limited bandwidth.\nThe effect is that solutions developed for local-area networks cannot always\nbe easily ported to a wide-area system. A typical example is streaming video.\nIn a home network, even when having only wireless links, ensuring a stable,\nfast stream of high-quality video frames from a media server to a display is\nquite simple. Simply placing that same server far away and using a standard\nTCP connection to the display will surely fail: bandwidth limitations will\ninstantly surface, but also maintaining the same level of reliability can easily\ncause headaches.\nYet another issue that pops up when components lie far apart is the\nfact that wide-area systems generally have only very limited facilities for\nmultipoint communication. In contrast, local-area networks often support\nefficient broadcasting mechanisms. Such mechanisms have proven to be\nextremely useful for discovering components and services, which is essential\nfrom a management perspective. In wide-area systems, we need to develop\nseparate services, such as naming and directory services, to which queries\ncan be sent. These support services, in turn, need to be scalable as well and\noften no obvious solutions exist as we will encounter in later chapters.\nAdministrative scalability\nFinally, a difficult, and often open, question is\nhow to scale a distributed system across multiple, independent administrative\ndomains. A major problem that needs to be solved is that of conflicting\npolicies regarding resource usage (and payment), management, and security.\nTo illustrate, for many years, scientists have been looking for solutions to share\ntheir (often expensive) equipment in what is known as a computational grid.\nIn these grids, a global decentralized system is constructed as a federation of\nlocal distributed systems, allowing a program running on a computer at an\norganization A to directly access resources at the organization B.\n \nDS 4.01\n\n\n28\nCHAPTER 1. INTRODUCTION\nMany components of a distributed system that reside within a single\ndomain can often be trusted by users that operate within that same domain. In\nsuch cases, system administration may have tested and certified applications,\nand may have taken special measures to ensure that such components cannot\nbe tampered with. In essence, the users trust their system administrators.\nHowever, this trust does not expand naturally across domain boundaries.\nIf a distributed system expands to another domain, two types of security\nmeasures need to be taken.\nFirst, the distributed system has to protect\nitself against malicious attacks from the new domain. For example, users\nfrom the new domain may have only read access to the file system in its\noriginal domain. Likewise, facilities such as expensive image setters or high-\nperformance computers may not be made available to unauthorized users.\nSecond, the new domain has to protect itself against malicious attacks from\nthe distributed system. A typical example is that of downloading programs,\nsuch as in the case of federated learning. Basically, the new domain does not\nknow what to expect from such foreign code. The problem, as we shall see in\nChapter 9, is how to enforce those limitations.\nAs a counterexample of distributed systems spanning multiple adminis-\ntrative domains that apparently do not suffer from administrative scalability\nproblems, consider modern file-sharing peer-to-peer networks. In these cases,\nend users simply install a program implementing distributed search and\ndownload functions and within minutes can start downloading files. Other ex-\namples include peer-to-peer applications for telephony over the Internet such\nas older Skype systems [Baset and Schulzrinne, 2006], and (again older) peer-\nassisted audio-streaming applications such as Spotify [Kreitz and Niemelä,\n2010]. A more modern application (that has yet to prove itself in terms of scal-\nability) are blockchains. What these decentralized systems have in common is\nthat end users, and not administrative entities, collaborate to keep the system\nup and running. At best, underlying administrative organizations such as\nInternet Service Providers (ISPs) can police the network traffic that these\npeer-to-peer systems cause.\nScaling techniques\nHaving discussed some scalability problems brings us to the question of how\nthose problems can generally be solved. In most cases, scalability problems\nin distributed systems appear as performance problems caused by limited\ncapacity of servers and network. Simply improving their capacity (e.g., by\nincreasing memory, upgrading CPUs, or replacing network modules) is often\na solution, referred to as scaling up. When it comes to scaling out, that is,\nexpanding the distributed system by essentially deploying more machines,\nthere are basically only three techniques we can apply: hiding communication\nlatencies, distribution of work, and replication (see also Neuman [1994]).\nDS 4.01\n \n\n\n1.2. DESIGN GOALS\n29\nM\nA\nA\nR\nT\nE\nN\nFIRST NAME\nLAST NAME\nE-MAIL\nServer\nClient\nCheck form\nProcess form\nMAARTEN\nMVS\nVAN-STEEN.NET\n@\nVAN STEEN\n(a)\nFIRST NAME\nLAST NAME\nE-MAIL\nServer\nClient\nCheck form\nProcess form\nMAARTEN\nMVS@VAN-STEEN.NET\nVAN STEEN\nMAARTEN\nVAN STEEN\nMVS@VAN-STEEN.NET\n(b)\nFigure 1.6: The difference between letting (a) a server or (b) a client check\nforms as they are being filled.\nHiding communication latencies\nHiding communication latencies is appli-\ncable in the case of geographical scalability. The basic idea is simple: try to\navoid waiting for responses to remote-service requests as much as possible.\nFor example, when a service has been requested at a remote machine, an\nalternative to waiting for a reply from the server is to do other useful work at\nthe requester’s side. Essentially, this means constructing the requesting appli-\ncation in such a way that it uses only asynchronous communication. When a\nreply comes in, the application is interrupted and a special handler is called\nto complete the previously issued request. Asynchronous communication\ncan often be used in batch-processing systems and parallel applications, in\nwhich independent tasks can be scheduled for execution while another task is\nwaiting for communication to complete. Alternatively, a new thread of control\ncan be started to perform the request. Although it blocks waiting for the reply,\nother threads in the process can continue.\nHowever, there are many applications that cannot make effective use of\nasynchronous communication. For example, in interactive applications when\na user sends a request, she will generally have nothing better to do than to\nwait for the answer. In such cases, a much better solution is to reduce the\noverall communication, for example, by moving part of the computation that\nis normally done at the server to the client process requesting the service. A\ntypical case where this approach works is accessing databases using forms.\nFilling in forms can be done by sending a separate message for each field and\nwaiting for an acknowledgment from the server, as shown in Figure 1.6(a). For\nexample, the server may check for syntactic errors before accepting an entry.\n \nDS 4.01\n",
      "page_number": 33
    },
    {
      "number": 5,
      "title": "Segment 5 (pages 43-51)",
      "start_page": 43,
      "end_page": 51,
      "detection_method": "topic_boundary",
      "content": "30\nCHAPTER 1. INTRODUCTION\nA much better solution is to ship the code for filling in the form, and possibly\nchecking the entries, to the client, and have the client return a completed\nform, as shown in Figure 1.6(b). This approach of shipping code is widely\nsupported by the Web through JavaScript.\nPartitioning and distribution\nAnother important scaling technique is parti-\ntioning and distribution, which involves taking a component or other resource,\nsplitting it into smaller parts, and subsequently spreading those parts across\nthe system. A good example of partitioning and distribution is the Internet\nDomain Name System (DNS). The DNS name space is hierarchically orga-\nnized into a tree of domains, which are divided into nonoverlapping zones,\nas shown for the original DNS in Figure 1.7. The names in each zone are\nhandled by a single name server. Without going into too many details now\n(we return to DNS extensively in Chapter 6), one can think of each path name\nbeing the name of a host on the Internet, and is thus associated with a network\naddress of that host. Basically, resolving a name means returning the network\naddress of the associated host. Consider, for example, the name flits.cs.vu.nl.\nTo resolve this name, it is first passed to the server of zone Z1 (see Figure 1.7)\nwhich returns the address of the server for zone Z2, to which the rest of the\nname, flits.cs.vu, can be handed. The server for Z2 will return the address of\nthe server for zone Z3, which is capable of handling the last part of the name,\nand will return the address of the associated host.\nint\ncom\nedu\ngov\nmil\norg\nnet\njp\nus\nnl\nsun\neng\nyale\neng\nai\nlinda\nrobot\nacm\njack\njill\nieee\nkeio\ncs\ncs\npc24\nco\nnec\ncsl\noce\nvu\ncs\nflits\nfluit\nac\nGeneric\nCountries\nZ1\nZ2\nZ3\nFigure 1.7: An example of dividing the (original) DNS name space into zones.\nThese examples illustrate how the naming service as provided by DNS, is\ndistributed across several machines, thus avoiding that a single server has to\ndeal with all requests for name resolution.\nAs another example, consider the World Wide Web. To most users, the Web\nappears to be an enormous document-based information system, in which\neach document has its own unique name in the form of a URL. Conceptually,\nDS 4.01\n \n\n\n1.2. DESIGN GOALS\n31\nit may even appear as if there is only a single server. However, the Web\nis physically partitioned and distributed across a few hundreds of millions of\nservers, each handling often a number of Websites, or parts of Websites. The\nname of the server handling a document is encoded into that document’s\nURL. It is only because of this distribution of documents that the Web has\nbeen capable of scaling to its current size. Yet, note that finding out how many\nservers provide Web-based services is virtually impossible: A Website today\nis so much more than a few static Web documents.\nReplication\nConsidering that scalability problems often appear in the form\nof performance degradation, it is generally a good idea to actually replicate\ncomponents or resources, etc., across a distributed system. Replication not\nonly increases availability, but also helps to balance the load between com-\nponents, leading to better performance. Moreover, in geographically widely\ndispersed systems, having a copy nearby can hide much of the communication\nlatency problems mentioned before.\nCaching is a special form of replication, although the distinction between\nthe two is often hard to make or even artificial. As in the case of replication,\ncaching results in making a copy of a resource, generally in the proximity of\nthe client accessing that resource. However, in contrast to replication, caching\nis a decision made by the client of a resource and not by the owner of a\nresource.\nThere is one serious drawback to caching and replication that may ad-\nversely affect scalability. Because we now have multiple copies of a resource,\nmodifying one copy makes that copy different from the others. Consequently,\ncaching and replication leads to consistency problems.\nTo what extent inconsistencies can be tolerated depends on the usage of a\nresource. For example, many Web users find it acceptable that their browser\nreturns a cached document of which the validity has not been checked for\nthe last few minutes. However, there are also many cases in which strong\nconsistency guarantees need to be met, such as in the case of electronic stock\nexchanges and auctions. The problem with strong consistency is that an\nupdate must be immediately propagated to all other copies. Moreover, if two\nupdates happen concurrently, it is often also required that updates are pro-\ncessed in the same order everywhere, introducing a global ordering problem.\nTo make things worse, combining consistency with desirable properties such\nas availability may simply be impossible, as we discuss in Chapter 8.\nReplication therefore often requires some global synchronization mecha-\nnism. Unfortunately, such mechanisms are extremely hard or even impossible\nto implement in a scalable way, if alone because network latencies have a nat-\nural lower bound. Consequently, scaling by replication may introduce other,\ninherently nonscalable solutions. We return to replication and consistency\nextensively in Chapter 7.\n \nDS 4.01\n\n\n32\nCHAPTER 1. INTRODUCTION\nDiscussion\nWhen considering these scaling techniques, one could argue that\nsize scalability is the least problematic from a technical perspective. Often,\nincreasing the capacity of a machine will save the day, although perhaps\nthere is a high monetary cost to pay. Geographical scalability is a much\ntougher problem, as network latencies are naturally bound from below. As\na consequence, we may be forced to copy data to locations close to where\nclients are, leading to problems of maintaining copies consistent. Practice\nshows that combining distribution, replication, and caching techniques with\ndifferent forms of consistency generally leads to acceptable solutions. Finally,\nadministrative scalability seems to be the most difficult problem to solve,\npartly because we need to deal with nontechnical issues, such as politics of or-\nganizations and human collaboration. The introduction and now widespread\nuse of peer-to-peer technology has successfully demonstrated what can be\nachieved if end users are put in control [Lua et al., 2005; Oram, 2001]. How-\never, peer-to-peer networks are obviously not the universal solution to all\nadministrative scalability problems.\n1.3\nA simple classification of distributed systems\nWe have discussed distributed versus decentralized systems, yet it is also use-\nful to classify distributed systems according to what they are being developed\nand used for. We make a distinction between systems that are developed for\n(high performance) computing, for general information processing, and those\nthat are developed for pervasive computing, i.e., for the “Internet of Things.”\nAs with many classifications, the boundaries between these three types are\nnot strict and combinations can easily be thought of.\n1.3.1\nHigh-performance distributed computing\nAn important class of distributed systems is the one used for high-performance\ncomputing tasks. Roughly speaking, one can make a distinction between two\nsubgroups. In cluster computing the underlying hardware consists of a\ncollection of similar compute nodes, interconnected by a high-speed network,\noften alongside a more common local-area network for controlling the nodes.\nIn addition, each node generally runs the same operating system.\nThe situation becomes very different in the case of grid computing. This\nsubgroup consists as decentralized systems that are often constructed as a\nfederation of computer systems, where each system may fall under a different\nadministrative domain, and may be very different when it comes to hardware,\nsoftware, and deployed network technology.\nDS 4.01\n \n\n\n1.3. A SIMPLE CLASSIFICATION OF DISTRIBUTED SYSTEMS\n33\nNote 1.6 (More information: Parallel processing)\nHigh-performance computing more or less started with the introduction of multi-\nprocessor machines. In this case, multiple CPUs are organized in such a way that\nthey all have access to the same physical memory, as shown in Figure 1.8(a). In\ncontrast, in a multicomputer system several computers are connected through\na network and there is no sharing of main memory, as shown in Figure 1.8(b).\nThe shared-memory model turned out to be highly convenient for improving the\nperformance of programs, and it was relatively easy to program.\n(a)\n(b)\nFigure 1.8: A comparison between (a) multiprocessor and (b) multicom-\nputer architectures.\nIts essence is that multiple threads of control are executing at the same time,\nwhile all threads have access to shared data. Access to that data is controlled\nthrough well-understood synchronization mechanisms like semaphores (see Ben-\nAri [2006] or Herlihy et al. [2021] for more information on developing parallel\nprograms). Unfortunately, the model does not easily scale: so far, machines have\nbeen developed in which only a few tens (and sometimes hundreds) of CPUs\nhave efficient access to shared memory. To a certain extent, we are seeing the\nsame limitations for multicore processors.\nTo overcome the limitations of shared-memory systems, high-performance\ncomputing moved to distributed-memory systems. This shift also meant that many\nprograms had to make use of message passing instead of modifying shared data as\na means of communication and synchronization between threads. Unfortunately,\nmessage-passing models have proven to be much more difficult and error-prone\ncompared to the shared-memory programming models. For this reason, there\nhas been significant research in attempting to build so-called distributed shared-\nmemory multicomputers, or simply DSM systems [Amza et al., 1996].\nIn essence, a DSM system allows a processor to address a memory location\nat another computer as if it were local memory. This can be achieved using\nexisting techniques available to the operating system, for example, by mapping\nall main-memory pages of the various processors into a single virtual address\nspace. Whenever a processor A addresses a page located at another processor B,\na page fault occurs at A allowing the operating system at A to fetch the content of\nthe referenced page at B in the same way that it would normally fetch it locally\nfrom disk. At the same time, the processor B would be informed that the page is\ncurrently not accessible.\n \nDS 4.01\n\n\n34\nCHAPTER 1. INTRODUCTION\nMimicking shared-memory systems using multicomputers eventually had to\nbe abandoned because performance could never meet the expectations of pro-\ngrammers, who would rather resort to far more intricate, yet better (predictably)\nperforming message-passing models. An important side effect of exploring the\nhardware-software boundaries of parallel processing is a thorough understanding\nof consistency models, to which we return extensively in Chapter 7.\nCluster computing\nCluster computing systems became popular when the price/performance\nratio of personal computers and workstations improved. At a certain point, it\nbecame financially and technically attractive to build a supercomputer using\noff-the-shelf technology by simply hooking up a collection of relatively simple\ncomputers in a high-speed network. In virtually all cases, cluster computing is\nused for parallel programming, in which a single (compute intensive) program\nis run in parallel on multiple machines. The principle of this organization is\nshown in Figure 1.9.\nThis type of high-performance computing has evolved considerably. As\ndiscussed extensively by Gerofi et al. [2019], the developments of supercom-\nputers organized as clusters have reached a point where we see clusters with\nmore than 100,000 CPUs, with each CPU having 8 or 16 cores. There are mul-\ntiple networks. Most important is a network formed by dedicated high-speed\ninterconnects between the various nodes (in other words, there is often no\nsuch thing as a shared high-speed network for computations). A separate\nmanagement network, as well as nodes, are used to monitor and control\nFigure 1.9: An example of a cluster computing system (adapted from [Gerofi\net al., 2019].)\nDS 4.01\n \n\n\n1.3. A SIMPLE CLASSIFICATION OF DISTRIBUTED SYSTEMS\n35\nthe organization and performance of the system as a whole. In addition, a\nspecial high-performance file system or database is used, again with its own\nlocal, dedicated network. Figure 1.9 does not show additional equipment,\nnotably high-speed I/O as well as networking facilities for remote access and\ncommunication.\nA management node is generally responsible for collecting jobs from users,\nto subsequently distribute the associated tasks among the various compute\nnodes. In practice, several management nodes are used when dealing with\nvery large clusters. As such, a management node actually runs the software\nneeded for the execution of programs and management of the cluster, while\nthe compute nodes are equipped with a standard operating system extended\nwith typical functions for communication, storage, fault tolerance, and so on.\nAn interesting development, as explained in Gerofi et al. [2019], is the\nrole of the operating system. There has been a clear trend to minimize the\noperating system to lightweight kernels, essentially ensuring the least possible\noverhead. A drawback is that such operating systems become highly spe-\ncialized and fine-tuned toward the underlying hardware. This specialization\naffects compatibility, or openness. To compensate, we are now gradually\nseeing so-called multikernel approaches, in which a full-fledged operating\nsystem operates next to a lightweight kernel, thus achieving the best of two\nworlds. This combination is also necessary given increasingly more often, a\nhigh-performance compute node is required to run multiple, independent\njobs simultaneously. At present, 95% of all high-performance computers run\nLinux-based systems; multikernel approaches are developed for multicore\nCPUs, with most cores running a lightweight kernel and the other running\na regular Linux system. In this way, new developments such as contain-\ners (which we discuss in Chapter 3) can also be supported. The effects for\ncomputing performance still needs to be seen.\nGrid computing\nA characteristic feature of traditional cluster computing is its homogeneity.\nIn most cases, the computers in a cluster are largely the same, have the\nsame operating system, and are all connected through the same network.\nHowever, as we just discussed, there is a continuous trend toward more\nhybrid architectures in which nodes are specifically configured for certain\ntasks. This diversity is even more prevalent in grid-computing systems: no\nassumptions are made concerning similarity of hardware, operating systems,\nnetworks, administrative domains, security policies, etc. [Rajaraman, 2016].\nA key issue in a grid-computing system is that resources from different\norganizations are brought together to allow the collaboration of a group of\npeople from different institutions, indeed forming a federation of systems.\nSuch a collaboration is realized in the form of a virtual organization. The\nprocesses belonging to the same virtual organization have access rights to the\n \nDS 4.01\n\n\n36\nCHAPTER 1. INTRODUCTION\nresources that are provided to that organization. Typically, resources consist of\ncompute servers (including supercomputers, possibly implemented as cluster\ncomputers), storage facilities, and databases. In addition, special networked\ndevices such as telescopes, sensors, etc., can be provided as well.\nGiven its nature, much of the software for realizing grid computing evolves\naround providing access to resources from different administrative domains,\nand to only those users and applications that belong to a specific virtual\norganization. For this reason, focus is often on architectural issues. An\narchitecture initially proposed by Foster et al. [2001] is shown in Figure 1.10,\nwhich still forms the basis for many grid computing systems.\nFigure 1.10: A layered architecture for grid computing systems.\nThe architecture consists of four layers. The lowest fabric layer provides\ninterfaces to local resources at a specific site. Note that these interfaces are\ntailored to allow sharing of resources within a virtual organization. Typically,\nthey will provide functions for querying the state and capabilities of a resource,\nalong with functions for actual resource management (e.g., locking resources).\nThe connectivity layer consists of communication protocols for supporting\ngrid transactions that span the usage of multiple resources. For example,\nprotocols are needed to transfer data between resources, or to simply access\na resource from a remote location. In addition, the connectivity layer will\ncontain security protocols to authenticate users and resources. Note that in\nmany cases, human users are not authenticated; instead, programs acting on\nbehalf of the users are authenticated. In this sense, delegating rights from\na user to programs is an important function that needs to be supported in\nthe connectivity layer. We return to delegation when discussing security in\ndistributed systems in Chapter 9.\nThe resource layer is responsible for managing a single resource. It uses the\nfunctions provided by the connectivity layer and calls directly the interfaces\nmade available by the fabric layer. For example, this layer will offer functions\nfor obtaining configuration information on a specific resource, or, in general,\nto perform specific operations such as creating a process or reading data. The\nDS 4.01\n \n\n\n1.3. A SIMPLE CLASSIFICATION OF DISTRIBUTED SYSTEMS\n37\nresource layer is thus seen to be responsible for access control, and hence will\nrely on the authentication performed as part of the connectivity layer.\nThe next layer in the hierarchy is the collective layer. It deals with handling\naccess to multiple resources and typically consists of services for resource\ndiscovery, allocation and scheduling of tasks onto multiple resources, data\nreplication, and so on.\nUnlike the connectivity and resource layer, each\nconsisting of a relatively small, standard collection of protocols, the collective\nlayer may consist of many protocols reflecting the broad spectrum of services\nit may offer to a virtual organization.\nFinally, the application layer consists of the applications that operate\nwithin a virtual organization and which make use of the grid computing\nenvironment.\nTypically, the collective, connectivity, and resource layer form the heart of\nwhat could be called a grid middleware layer. These layers jointly provide\naccess to and management of resources that are potentially dispersed across\nmultiple sites.\nAn important observation from a middleware perspective is that in grid\ncomputing, the notion of a site (or administrative unit) is common. This\nprevalence is emphasized by the gradual shift toward a service-oriented ar-\nchitecture in which sites offer access to the various layers through a collection\nof Web services [Joseph et al., 2004]. This, by now, has led to the definition of\nan alternative architecture known as the Open Grid Services Architecture\n(OGSA) [Foster et al., 2006]. OGSA is based upon the original ideas as for-\nmulated by Foster et al. [2001], yet having gone through a standardization\nprocess makes it complex, to say the least. OGSA implementations generally\nfollow Web service standards.\n1.3.2\nDistributed information systems\nAnother important class of distributed systems is found in organizations\nthat were confronted with a wealth of networked applications, but for which\ninteroperability turned out to be a painful experience. Many of the existing\nmiddleware solutions are the result of working with an infrastructure in which\nit was easier to integrate applications into an enterprise-wide information\nsystem [Alonso et al., 2004; Bernstein, 1996; Hohpe and Woolf, 2004].\nWe can distinguish several levels at which integration can take place. Often,\na networked application simply consists of a server running that application\n(often including a database) and making it available to remote programs,\ncalled clients. Such clients send a request to the server for executing a specific\noperation, after which a response is sent back. Integration at the lowest level\nallows clients to wrap several requests, possibly for different servers, into a\nsingle larger request and have it executed as a distributed transaction. The\nkey idea is that all, or none of the requests are executed.\n \nDS 4.01\n\n\n38\nCHAPTER 1. INTRODUCTION\nAs applications became more sophisticated and were gradually separated\ninto independent components (notably distinguishing database components\nfrom processing components), it became clear that integration should also\ntake place by letting applications communicate directly with each other. This\nhas now led to an industry on enterprise application integration (EAI).\nDistributed transaction processing\nTo clarify our discussion, we concentrate on database applications. In practice,\noperations on a database are carried out in the form of transactions. Pro-\ngramming using transactions requires special primitives that must either be\nsupplied by the underlying distributed system or by the language runtime\nsystem. Typical examples of transaction primitives are shown in Figure 1.11.\nThe exact list of primitives depends on what kinds of objects are being used\nin the transaction [Gray and Reuter, 1993; Bernstein and Newcomer, 2009]. In\na mail system, there might be primitives to send, receive, and forward mail.\nIn an accounting system, they might be quite different. READ and WRITE are\ntypical examples, however. Ordinary statements, procedure calls, and so on,\nare also allowed inside a transaction. In particular, remote procedure calls\n(RPC), that is, procedure calls to remote servers, are often also encapsulated\nin a transaction, leading to what is known as a transactional RPC. We discuss\nRPCs extensively in Section 4.2.\nPrimitive\nDescription\nBEGIN_TRANSACTION\nMark the start of a transaction\nEND_TRANSACTION\nTerminate the transaction and try to commit\nABORT_TRANSACTION\nKill the transaction and restore the old values\nREAD\nRead data from a file, a table, or otherwise\nWRITE\nWrite data to a file, a table, or otherwise\nFigure 1.11: Example primitives for transactions.\nBEGIN_TRANSACTION and END_TRANSACTION are used to delimit the\nscope of a transaction. The operations between them form the body of the\ntransaction. The characteristic feature of a transaction is either all of these\noperations are executed or none are executed. These may be system calls,\nlibrary procedures, or bracketing statements in a language, depending on the\nimplementation.\nThis all-or-nothing property of transactions is one of the four characteristic\nproperties that transactions have. More specifically, transactions adhere to the\nso-called ACID properties:\n• Atomic: To the outside world, the transaction happens indivisibly\n• Consistent: The transaction does not violate system invariants\nDS 4.01\n \n",
      "page_number": 43
    },
    {
      "number": 6,
      "title": "Segment 6 (pages 52-62)",
      "start_page": 52,
      "end_page": 62,
      "detection_method": "topic_boundary",
      "content": "1.3. A SIMPLE CLASSIFICATION OF DISTRIBUTED SYSTEMS\n39\n• Isolated: Concurrent transactions do not interfere with each other\n• Durable: Once a transaction commits, the changes are permanent\nIn distributed systems, transactions are often constructed as a number of\nsubtransactions, jointly forming a nested transaction as shown in Figure 1.12.\nThe top-level transaction may fork off children that run in parallel with one\nanother, on different machines, to gain performance or simplify programming.\nEach of these children may also execute one or more subtransactions, or fork\noff its own children.\nFigure 1.12: A nested transaction.\nSubtransactions give rise to a subtle, but important, problem. Imagine\nthat a transaction starts several subtransactions in parallel, and one of these\ncommits, making its results visible to the parent transaction. After further\ncomputation, the parent aborts, restoring the entire system to the state it\nhad before the top-level transaction started. Consequently, the results of\nthe subtransaction that committed must nevertheless be undone. Thus, the\npermanence referred to above applies only to top-level transactions.\nSince transactions can be nested arbitrarily deep, considerable administra-\ntion is needed to get everything right. The semantics are clear, however. When\nany transaction or subtransaction starts, it is conceptually given a private copy\nof all data in the entire system for it to manipulate as it wishes. If it aborts,\nits private universe just vanishes, as if it had never existed. If it commits,\nits private universe replaces the parent’s universe. Thus, if a subtransaction\ncommits and then later a new subtransaction is started, the second one sees\nthe results produced by the first one. Likewise, if an enclosing (higher level)\ntransaction aborts, all its underlying subtransactions have to be aborted as\nwell. And if several transactions are started concurrently, the result is as if\nthey ran sequentially in some unspecified order.\nNested transactions are important in distributed systems, for they provide\na natural way of distributing a transaction across multiple machines. They\nfollow a logical division of the work of the original transaction. For example,\na transaction for planning a trip by which three different flights need to be\n \nDS 4.01\n\n\n40\nCHAPTER 1. INTRODUCTION\nreserved can be logically split up into three subtransactions. Each of these\nsubtransactions can be managed separately and independently.\nTP monitor\nServer\nServer\nServer\nClient\napplication\nRequests\nReply\nRequest\nRequest\nRequest\nReply\nReply\nReply\nTransaction\nFigure 1.13: The role of a TP monitor in distributed systems.\nEver since the early days of enterprise middleware systems, the compo-\nnent that handles distributed (or nested) transactions belongs to the core for\nintegrating applications at the server or database level. This component is\ncalled a transaction-processing monitor or TP monitor for short. Its main\ntask is to allow an application to access multiple server/databases by offering\nit a transactional programming model, as shown in Figure 1.13. Essentially,\nthe TP monitor coordinates the commitment of subtransactions following a\nstandard protocol known as distributed commit, which we discuss in detail\nin Section 8.5.\nAn important observation is that applications wanting to coordinate sev-\neral subtransactions into a single transaction do not have to implement this\ncoordination themselves. By simply making use of a TP monitor, this coordi-\nnation is done for them. This is precisely where middleware comes into play:\nit implements services that are useful for many applications, avoiding that\nsuch services have to be reimplemented over and over again by application\ndevelopers.\nEnterprise application integration\nAs mentioned, the more applications became decoupled from the databases\nthey were built upon, the more evident it became that facilities were needed\nto integrate applications independently of their databases. In particular, appli-\ncation components should be able to communicate directly with each other\nand not merely by means of the request/reply behavior that was supported\nby transaction processing systems.\nThis need for interapplication communication led to many communication\nmodels. The main idea was that existing applications could directly exchange\ninformation, as shown in Figure 1.14.\nDS 4.01\n \n\n\n1.3. A SIMPLE CLASSIFICATION OF DISTRIBUTED SYSTEMS\n41\nFigure 1.14: Middleware as a communication facilitator in enterprise applica-\ntion integration.\nSeveral types of communication middleware exist. With remote procedure\ncalls (RPC), an application component can effectively send a request to another\napplication component by doing a local procedure call, which results in the\nrequest being packaged as a message and sent to the callee. Likewise, the\nresult will be sent back and returned to the application as the result of the\nprocedure call.\nAs the popularity of object technology increased, techniques were devel-\noped to allow calls to remote objects, leading to what is known as remote\nmethod invocations (RMI). An RMI is essentially the same as an RPC, except\nthat it operates on objects instead of functions.\nRPC and RMI have the disadvantage that the caller and callee both need\nto be up and running at the time of communication.\nIn addition, they\nneed to know exactly how to refer to each other. This tight coupling is\noften experienced as a serious drawback, and has led to what is known as\nmessage-oriented middleware, or simply MOM. In this case, applications\nsend messages to logical contact points, often described by a subject. Likewise,\napplications can indicate their interest for a specific type of message, after\nwhich the communication middleware will take care that those messages are\ndelivered to those applications. These so-called publish-subscribe systems\nform an important and expanding class of distributed systems.\nNote 1.7 (More information: On integrating applications)\nSupporting enterprise application integration is an important goal for many mid-\ndleware products. In general, there are four ways to integrate applications [Hohpe\nand Woolf, 2004]:\nFile transfer: The essence of integration through file transfer, is that an applica-\ntion produces a file containing shared data that is subsequently read by\n \nDS 4.01\n\n\n42\nCHAPTER 1. INTRODUCTION\nother applications. The approach is technically simple, making it appealing.\nThe drawback, however, is that there are numerous things that need to be\nagreed upon:\n• File format and layout: text, binary, its structure, and so on. Nowadays,\nthe extended markup language (XML) has become popular as its files\nare, in principle, self-describing.\n• File management: where are they stored, how are they named, who is\nresponsible for deleting files?\n• Update propagation: When an application produces a file, there may\nbe several applications that need to read that file to provide the view\nof a single coherent system. As a consequence, sometimes separate\nprograms need to be implemented that notify applications of file\nupdates.\nShared database: Many of the problems associated with integration through files\nare alleviated when using a shared database. All applications will have\naccess to the same data, and often through a high-level database language\nsuch as SQL. Furthermore, it is easy to notify applications when changes\noccur, as triggers are often part of modern databases. There are, however,\ntwo major drawbacks. First, there is still a need to design a common\ndata schema, which may be far from trivial if the set of applications that\nneed to be integrated is not completely known in advance. Second, when\nthere are many reads and updates, a shared database can easily become a\nperformance bottleneck.\nRemote procedure call: Integration through files or a database implicitly as-\nsumes that changes by one application can easily trigger other applications\nto act. However, practice shows that sometimes small changes should\nactually trigger many applications to take actions. In such cases, it is not\nreally the change of data that is important, but the execution of a series of\nactions.\nSeries of actions are best captured through the execution of a procedure\n(which may, in turn, lead to all kinds of changes in shared data). To prevent\nthat every application needs to know all the internals of those actions (as\nimplemented by another application), standard encapsulation techniques\nshould be used, as deployed with traditional procedure calls or object\ninvocations. For such situations, an application can best offer a procedure\nto other applications in the form of a remote procedure call, or RPC. In\nessence, an RPC allows an application A to make use of the information\navailable only to the application B, without giving A direct access to that\ninformation. There are many advantages and disadvantages to remote\nprocedure calls, which are discussed in depth in Chapter 4.\nMessaging: A main drawback of RPCs is that caller and callee need to be up\nand running at the same time in order for the call to succeed. However, in\nmany scenarios, this simultaneous activity is often difficult or impossible\nDS 4.01\n \n\n\n1.3. A SIMPLE CLASSIFICATION OF DISTRIBUTED SYSTEMS\n43\nto guarantee. In such cases, offering a messaging system carrying requests\nfrom the application A to perform an action at the application B, is what\nis needed. The messaging system ensures that eventually the request is\ndelivered, and if needed, that a response is eventually returned as well.\nObviously, messaging is not the panacea for application integration: it also\nintroduces problems concerning data formatting and layout, it requires an\napplication to know where to send a message to, there need to be scenarios\nfor dealing with lost messages, and so on. Like RPCs, we will be discussing\nthese issues extensively in Chapter 4.\nWhat these four approaches tell us, is that application integration will generally\nnot be simple. Middleware (in the form of a distributed system), however, can\nsignificantly help in integration by providing the right facilities such as support\nfor RPCs or messaging. As said, enterprise application integration is an important\ntarget field for many middleware products.\n1.3.3\nPervasive systems\nThe distributed systems discussed so far are largely characterized by their\nstability: nodes are fixed and have a more or less permanent and high-quality\nconnection to a network. To a certain extent, this stability is realized through\nthe various techniques for achieving distribution transparency. For example,\nthere are many ways how we can create the illusion that only occasionally\ncomponents may fail. Likewise, there are all kinds of means to hide the actual\nnetwork location of a node, effectively allowing users and applications to\nbelieve that nodes stay put.\nHowever, matters have changed since the introduction of mobile and\nembedded computing devices, leading to what are generally referred to as\npervasive systems. As its name suggests, pervasive systems are intended\nto blend into our environment naturally. Many of their components are\nnecessarily spread across multiple computers, making them arguably a type of\ndecentralized system in our view. At the same time, most pervasive systems\nhave many components that are sufficiently spread throughout the system, for\nexample, to handle failures and such. In this sense, they are also arguably\ndistributed systems. The seemingly strict separation between decentralized\nand distributed systems is thus seen to be less strict than one could initially\nimagine.\nWhat makes them unique, in comparison to the computing and infor-\nmation systems described so far, is that the separation between users and\nsystem components is much more blurred. There is often no single dedicated\ninterface, such as a screen/keyboard combination. Instead, a pervasive system\nis often equipped with many sensors that pick up various aspects of a user’s\nbehavior. Likewise, it may have a myriad of actuators to provide information\nand feedback, often even purposefully aiming to steer behavior.\n \nDS 4.01\n\n\n44\nCHAPTER 1. INTRODUCTION\nMany devices in pervasive systems are characterized by being small,\nbattery-powered, mobile, and having only a wireless connection, although\nnot all these characteristics apply to all devices. These are not necessarily\nrestrictive characteristics, as is illustrated by smartphones [Roussos et al., 2005]\nand their role in what is now coined as the Internet of Things [Mattern and\nFloerkemeier, 2010; Stankovic, 2014]. Nevertheless, notably, the fact that we\noften need to deal with the intricacies of wireless and mobile communication,\nwill require special solutions to make a pervasive system as transparent or\nunobtrusive as possible.\nIn the following, we make a distinction between three different types of\npervasive systems, although there is considerable overlap between the three\ntypes: ubiquitous computing systems, mobile systems, and sensor networks.\nThis distinction allows us to focus on different aspects of pervasive systems.\nUbiquitous computing systems\nSo far, we have been talking about pervasive systems to emphasize that\nits elements have spread through in many parts of our environment. In a\nubiquitous computing system, we go one step further: the system is pervasive\nand continuously present. The latter means that a user will be continuously\ninteracting with the system, often not even being aware that interaction is\ntaking place. Poslad [2009] describes the core requirements for a ubiquitous\ncomputing system roughly as follows:\n1. (Distribution) Devices are networked, distributed, and accessible trans-\nparently\n2. (Interaction) Interaction between users and devices is highly unobtrusive\n3. (Context awareness) The system is aware of a user’s context to optimize\ninteraction\n4. (Autonomy) Devices operate autonomously without human intervention,\nand are thus highly self-managed\n5. (Intelligence) The system as a whole can handle a wide range of dy-\nnamic actions and interactions\nLet us consider these requirements from a distributed-systems perspective.\nAd. 1: Distribution\nAs mentioned, a ubiquitous computing system is an\nexample of a distributed system: the devices and other computers forming\nthe nodes of a system are simply networked and work together to form\nthe illusion of a single, coherent system. Distribution also comes naturally:\nthere will be devices close to users (such as sensors and actuators), connected\nto computers hidden from view and perhaps even operating remotely in a\nDS 4.01\n \n\n\n1.3. A SIMPLE CLASSIFICATION OF DISTRIBUTED SYSTEMS\n45\ncloud. Most, if not all, of the requirements regarding distribution transparency\nmentioned in Section 1.2.2, should therefore hold.\nAd. 2: Interaction\nWhen it comes to interaction with users, ubiquitous\ncomputing systems differ a lot in comparison to the systems we have been\ndiscussing so far. End users play a prominent role in the design of ubiquitous\nsystems, meaning that special attention needs to be paid to how the interac-\ntion between users and core system takes place. For ubiquitous computing\nsystems, much of the interaction by humans will be implicit, with an implicit\naction being defined as one “that is not primarily aimed to interact with a com-\nputerized system but which such a system understands as input” [Schmidt,\n2000]. In other words, a user could be mostly unaware of the fact that input is\nbeing provided to a computer system. From a certain perspective, ubiquitous\ncomputing can be said to seemingly hide interfaces.\nA simple example is where the settings of a car’s driver’s seat, steering\nwheel, and mirrors are fully personalized. If Bob takes a seat, the system will\nrecognize that it is dealing with Bob and subsequently makes the appropriate\nadjustments. The same happens when Alice uses the car, while an unknown\nuser will be steered toward making his or her own adjustments (to be remem-\nbered for later). This example already illustrates an important role of sensors\nin ubiquitous computing, namely as input devices that are used to identify a\nsituation (a specific person apparently wanting to drive), whose input analysis\nleads to actions (making adjustments). In turn, the actions may lead to natural\nreactions, for example that Bob slightly changes the seat settings. The system\nwill have to take all (implicit and explicit) actions by the user into account\nand react accordingly.\nAd. 3: Context awareness\nReacting to the sensory input, but also the explicit\ninput from users, is more easily said than done. What a ubiquitous computing\nsystem needs to do, is to take the context in which interactions take place\ninto account. Context awareness also differentiates ubiquitous computing\nsystems from the more traditional systems we have been discussing before,\nand is described by Dey and Abowd [2000] as “any information that can be\nused to characterize the situation of entities (i.e., whether a person, place, or\nobject) that are considered relevant to the interaction between a user and an\napplication, including the user and the application themselves.” In practice,\ncontext is often characterized by location, identity, time, and activity: the where,\nwho, when, and what. A system will need to have the necessary (sensory) input\nto determine one or several of these context types. As discussed by Alegre\net al. [2016], developing context-aware systems is difficult, if only for the\nreason that the notion of context is difficult to grasp.\nWhat is important, from a distributed-systems perspective, is that raw\ndata as collected by various sensors is lifted to a level of abstraction that can\nbe used by applications. A concrete example is detecting where a person is,\n \nDS 4.01\n\n\n46\nCHAPTER 1. INTRODUCTION\nfor example in terms of GPS coordinates, and subsequently mapping that\ninformation to an actual location, such as the corner of a street, or a specific\nshop or other known facility. The question is where this processing of sensory\ninput takes place: is all data collected at a central server connected to a\ndatabase with detailed information on a city, or is it the user’s smartphone\nwhere the mapping is done? Clearly, there are trade-offs to be considered.\nDey [2010] discusses more general approaches toward building context-\naware applications. When it comes to combining flexibility and potential\ndistribution, so-called shared data spaces in which processes are decoupled\nin time and space are attractive, yet as we shall see in later chapters, suffer\nfrom scalability problems. A survey on context-awareness and its relation to\nmiddleware and distributed systems is provided by Baldauf et al. [2007].\nAd. 4: Autonomy\nAn important aspect of most ubiquitous computing sys-\ntems is that explicit systems management has been reduced to a minimum. In\na ubiquitous computing environment, there is simply no room for a systems\nadministrator to keep everything up and running. As a consequence, the\nsystem as a whole should be able to act autonomously, and automatically\nreact to changes. This requires a myriad of techniques, of which several will\nbe discussed throughout this book. To give a few simple examples, think of\nthe following:\nAddress allocation: In order for networked devices to communicate, they\nneed an IP address. Addresses can be allocated automatically using pro-\ntocols like the Dynamic Host Configuration Protocol (DHCP) [Droms,\n1997] (which requires a server) or Zeroconf [Guttman, 2001].\nAdding devices: It should be easy to add devices to an existing system. A\nstep towards automatic configuration is realized by the Universal Plug\nand Play protocol (UPnP) [UPnP Forum, 2008]. Using UPnP, devices can\ndiscover each other and make sure that they can set up communication\nchannels between them.\nAutomatic updates: Many devices in a ubiquitous computing system should\nbe able to regularly check through the Internet if their software should\nbe updated. If so, they can download new versions of their components\nand ideally continue where they left off.\nAdmittedly, these are simple examples, but the picture should be clear that\nmanual intervention is to be kept to a minimum. We will be discussing many\ntechniques related to self-management in detail throughout the book.\nAd. 5: Intelligence\nFinally, Poslad [2009] mentions that ubiquitous com-\nputing systems often use methods and techniques from the field of artificial\nDS 4.01\n \n\n\n1.3. A SIMPLE CLASSIFICATION OF DISTRIBUTED SYSTEMS\n47\nintelligence. What this means, is that often a wide range of advanced algo-\nrithms and models need to be deployed to handle incomplete input, quickly\nreact to a changing environment, handle unexpected events, and so on. The\nextent to which this can or should be done in a distributed fashion is cru-\ncial from the perspective of distributed systems. Unfortunately, distributed\nsolutions for many problems in the field of artificial intelligence are yet to\nbe found, meaning that there may be a natural tension between the first\nrequirement of networked and distributed devices, and advanced distributed\ninformation processing.\nMobile computing systems\nAs mentioned, mobility often forms an important component of pervasive\nsystems, and many, if not all aspects that we have just discussed also apply to\nmobile computing. There are several issues that set mobile computing aside\nto pervasive systems in general (see also Adelstein et al. [2005] and Tarkoma\nand Kangasharju [2009]).\nFirst, the devices that form part of a (distributed) mobile system may\nvary widely.\nTypically, mobile computing is done with devices such as\nsmartphones and tablet computers.\nHowever, entirely different types of\ndevices are now using the Internet Protocol (IP) to communicate, placing\nmobile computing in a different perspective. Such devices include remote\ncontrols, pagers, active badges, car equipment, various GPS-enabled devices,\nand so on. A characteristic feature of all these devices is that they use wireless\ncommunication. Mobile implies wireless, so it seems (although there are\nexceptions to the rules).\nSecond, in mobile computing, the location of a device is assumed to change\nover time. A changing location has its effects on many issues. For example, if\nthe location of a device changes regularly, so will perhaps the services that\nare locally available. As a consequence, we may need to pay special attention\nto dynamically discovering services, but also letting services announce their\npresence. In a similar vein, we often also want to know where a device actually\nis. This may mean that we need to know the actual geographical coordinates\nof a device such as in tracking and tracing applications, but it may also require\nthat we can simply detect its network position (as in mobile IP [Perkins, 2010;\nPerkins et al., 2011].\nChanging locations may also have a profound effect on communication.\nFor some time, researchers in mobile computing have been concentrating on\nwhat are known as mobile ad hoc networks, also known as MANETs. The\nbasic idea was that a group of local mobile computers would jointly set up a\nlocal, wireless network and to subsequently share resources and services. The\nidea never really became popular. Along the same lines, there are researchers\nwho believe that end users are willing to share their local resources for another\nuser’s compute, storage, or communication requirements (see, e.g., Ferrer\n \nDS 4.01\n\n\n48\nCHAPTER 1. INTRODUCTION\net al. [2019]). Practice has shown over and over again that voluntarily making\nresources available is not something users are willing to do, even if they have\nresources in abundance. The effect is that in the case of mobile computing,\nwe generally see single mobile devices setting up connections to stationary\nservers. Changing locations then simply means that those connections need\nto be handed over by routers on the path from the mobile device to the\nserver. Mobile computing is then brought back to its essence: a mobile device\nconnected to a server (and nothing else). In practice, this means that mobile\ncomputing is all about mobile devices making use of cloud-based services, as\nsketched in Figure 1.15(a).\n(a)\n(b)\nFigure 1.15: (a) Mobile Cloud Computing versus (b) Mobile Edge Computing.\nDespite the conceptual simplicity of this model of mobile computing, the\nmere fact that so many devices make use of remote services has led to what is\nknown as Mobile Edge Computing, or simply MEC [Abbas et al., 2018], in\ncontrast to Mobile Cloud Computing (MCC). As we shall discuss further in\nChapter 2, (mobile) edge computing, as sketched in Figure 1.15(b), is becoming\nincreasingly important in those cases where latency, but also computational\nissues play a role for the mobile device. Typical example applications that\nrequire short latencies and computational resources include augmented reality,\ninteractive gaming, real-time sports monitoring, and various health applica-\ntions [Dimou et al., 2022]. In these examples, the combination of monitoring,\nanalyses, and immediate feedback in general make it difficult to rely on\nservers that may be placed thousands of miles from the mobile devices.\nDS 4.01\n \n\n\n1.3. A SIMPLE CLASSIFICATION OF DISTRIBUTED SYSTEMS\n49\nSensor networks\nOur last example of pervasive systems is sensor networks. These networks\nin many cases form part of the enabling technology for pervasiveness, and\nwe see that many solutions for sensor networks return in pervasive applica-\ntions. What makes sensor networks interesting from a distributed system’s\nperspective is that they are more than just a collection of input devices. In-\nstead, as we shall see, sensor nodes often collaborate to process the sensed\ndata efficiently in an application-specific manner, making them very different\nfrom, for example, traditional computer networks. Akyildiz et al. [2002] and\nAkyildiz et al. [2005] provide an overview from a networking perspective. A\nmore systems-oriented introduction to sensor networks is given by Zhao and\nGuibas [2004], but also [Hahmy, 2021] will show to be useful.\nA sensor network generally consists of tens to hundreds or thousands of\nrelatively small nodes, each equipped with one or more sensing devices. In\naddition, nodes can often act as actuators [Akyildiz and Kasimoglu, 2004],\na typical example being the automatic activation of sprinklers when a fire\nhas been detected. Many sensor networks use wireless communication, and\nthe nodes are often battery powered.\nTheir limited resources, restricted\ncommunication capabilities, and constrained power consumption demand\nthat efficiency is high on the list of design criteria.\nWhen zooming into an individual node, we see that, conceptually, they\ndo not differ a lot from “normal” computers: above the hardware there is a\nsoftware layer akin to what traditional operating systems offer, including low-\nlevel network access, access to sensors and actuators, memory management,\nand so on.\nNormally, support for specific services is included, such as\nlocalization, local storage (think of additional flash devices), and convenient\ncommunication facilities such as messaging and routing. However, similar to\nother networked computer systems, additional support is needed to effectively\ndeploy sensor network applications. In distributed systems, this takes the form\nof middleware. For sensor networks, we can, in principle, follow a similar\napproach in those cases that sensor nodes are sufficiently powerful and that\nenergy consumption is not a hindrance for running a more elaborate software\nstack. Various approaches are possible (see also [Zhang et al., 2021b]).\nFrom a programming perspective, and extensively surveyed by Mottola\nand Picco [2011], it is important to take the scope of communication primitives\ninto account. This scope can vary between addressing the physical neighbor-\nhood of a node, and providing primitives for systemwide communication.\nIn addition, it may also be possible to address a specific group of nodes.\nLikewise, computations may be restricted to an individual node, a group\nof nodes, or affect all nodes. To illustrate, Welsh and Mainland [2004] use\nso-called abstract regions allowing a node to identify a neighborhood from\nwhere it can, for example, gather information:\n \nDS 4.01\n",
      "page_number": 52
    },
    {
      "number": 7,
      "title": "Segment 7 (pages 63-70)",
      "start_page": 63,
      "end_page": 70,
      "detection_method": "topic_boundary",
      "content": "50\nCHAPTER 1. INTRODUCTION\n1\nregion\n= k_nearest_region.create(8);\n2\nreading = get_sensor_reading();\n3\nregion.putvar(reading_key, reading);\n4\nmax_id\n= region.reduce(OP_MAXID, reading_key);\nIn line 1, a node first creates a region of its eight nearest neighbors, after which\nit fetches a value from its sensor(s). This reading is subsequently written to\nthe previously defined region to be defined using the key reading_key. In\nline 4, the node checks whose sensor reading in the defined region was the\nlargest, which is returned in the variable max_id.\nWhen considering that sensor networks produce data, one can also focus\non the data-access model. This can be done directly by sending messages to\nand between nodes, or either moving code between nodes to locally access\ndata. More advanced is to make remote data directly accessible, as if variables\nand such were available in a shared data space. Finally, and also quite popular,\nis to let the sensor network provide a view of a single database. Such a\nview is easy to understand when realizing that many sensor networks are\ndeployed for measurement and surveillance applications [Bonnet et al., 2002].\nIn these cases, an operator would like to extract information from (a part of)\nthe network by simply issuing queries such as “What is the northbound traffic\nload on highway 1 at Santa Cruz?” Such queries resemble those of traditional\ndatabases. In this case, the answer will probably need to be provided through\ncollaboration of many sensors along highway 1, while leaving other sensors\nuntouched.\nTo organize a sensor network as a distributed database, there are essentially\ntwo extremes, as shown in Figure 1.16. First, sensors do not cooperate but\nsimply send their data to a centralized database located at the operator’s site.\nThe other extreme is to forward queries to relevant sensors and to let each\ncompute an answer, requiring the operator to aggregate the responses.\nNeither of these solutions is very attractive. The first one requires that\nsensors send all their measured data through the network, which may waste\nnetwork resources and energy. The second solution may also be wasteful,\nas it discards the aggregation capabilities of sensors, which would allow\nmuch fewer data to be returned to the operator. What is needed are facilities\nfor in-network data processing, similar to the previous example of abstract\nregions.\nIn-network processing can be done in numerous ways. One obvious way\nis to forward a query to all sensor nodes along a tree encompassing all nodes\nand to subsequently aggregate the results as they are propagated back to the\nroot, where the initiator is located. Aggregation will take place where two\nor more branches of the tree come together. As simple as this scheme may\nsound, it introduces difficult questions:\n• How do we (dynamically) set up an efficient tree in a sensor network?\n• How does aggregation of results take place? Can it be controlled?\nDS 4.01\n \n\n\n1.3. A SIMPLE CLASSIFICATION OF DISTRIBUTED SYSTEMS\n51\n(a)\n(b)\nFigure 1.16: Organizing a sensor network database, while storing and process-\ning data (a) only at the operator’s site or (b) only at the sensors.\n• What happens when network links fail?\nThese questions have been partly addressed in TinyDB, which implements\na declarative (database) interface to wireless sensor networks [Madden et al.,\n2005]. In essence, TinyDB can use any tree-based routing algorithm. An\nintermediate node will collect and aggregate the results from its children,\nalong with its own findings, and send that toward the root. To make matters\nefficient, queries span a period of time, allowing for careful scheduling of\noperations so that network resources and energy are optimally consumed.\nHowever, when queries can be initiated from different points in the net-\nwork, using single-rooted trees such as in TinyDB may not be efficient enough.\nAs an alternative, sensor networks may be equipped with special nodes where\nresults are forwarded to, as well as the queries related to those results. To give\na simple example, queries and results related to temperature readings may be\ncollected at a different location than those related to humidity measurements.\nThis approach corresponds directly to the notion of publish-subscribe systems.\nThe interesting aspect of sensor networks, as discussed along these lines,\nis that we really need to concentrate on the organization of sensor nodes, and\nnot the sensors themselves. Likewise, many sensor nodes will be equipped\nwith actuators, i.e., devices that directly influence an environment. A typical\n \nDS 4.01\n\n\n52\nCHAPTER 1. INTRODUCTION\nFigure 1.17: A hierarchical view from clouds to devices (adapted from Yousef-\npour et al. [2019]).\nactuator is one that controls the temperature in a room, or switches devices\non or off. By viewing and organizing the network as a distributed system, an\noperator is provided with a higher level of abstraction to monitor and control\na situation.\nCloud, edge, things\nAs may have become clear by now, distributed systems span a huge range of\ndifferent networked computer systems. Many of such systems operate in a\nsetting in which the various computers are connected through a local-area\nnetwork. Yet with the growth of the Internet-of-Things and the connectivity\nwith remote services offered through cloud-based systems, new organizations\nacross wide-area networks are emerging. Figure 1.17 presents this more\nhierarchical approach.\nTypically, higher up the hierarchy we see that typical qualities of dis-\ntributed systems improve: they become more reliable, have more capacity,\nand, in general, perform better. Lower in the hierarchy, we see that location-\nrelated aspects are easier facilitated, as well as performance qualities related to\nlatencies. At the same time, the lower parts show in an increase in the number\nof devices and computers, whereas higher up, the number of computers\nbecomes less.\n1.4\nPitfalls\nIt should be clear by now that developing a distributed system is a formidable\ntask. As we will see many times throughout this book, there are so many\nissues to consider, while it seems that only complexity can be the result.\nDS 4.01\n \n\n\n1.5. SUMMARY\n53\nNevertheless, by following several design principles, distributed systems can\nbe developed that strongly adhere to the goals we set out in this chapter.\nDistributed systems differ from traditional software because components\nare dispersed across a network. Not taking this dispersion into account during\ndesign time is what makes so many systems needlessly complex and results in\nflaws that need to be patched later on. Peter Deutsch, at the time working at\nSun Microsystems, formulated these flaws as the following false assumptions\nthat many make when developing a distributed application for the first time:\n• The network is reliable\n• The network is secure\n• The network is homogeneous\n• The topology does not change\n• Latency is zero\n• Bandwidth is infinite\n• Transport cost is zero\n• There is one administrator\nNote how these assumptions relate to properties that are unique to dis-\ntributed systems: reliability, security, heterogeneity, and topology of the\nnetwork; latency and bandwidth; transport costs; and finally administrative\ndomains. When developing nondistributed applications, most of these issues\nwill most likely not show up.\nMost of the principles we discuss in this book relate immediately to these\nassumptions. In all cases, we will be discussing solutions to problems that\nare caused by the fact that one or more assumptions are false. For example,\nreliable networks simply do not exist and lead to the impossibility of achieving\nfailure transparency. We devote an entire chapter to deal with the fact that\nnetworked communication is inherently insecure. We have already argued\nthat distributed systems need to be open and take heterogeneity into account.\nLikewise, when discussing replication for solving scalability problems, we\nare essentially tackling latency and bandwidth problems. We will also touch\nupon management issues at various points throughout this book.\n1.5\nSummary\nA distributed system is a collection of networked computer systems in which\nprocesses and resources are spread across different computers. We make a\ndistinction between sufficiently and necessarily spread, where the latter relates\nto decentralized systems. This distinction is important to make, as spreading\nprocesses and resources cannot be considered to be a goal by itself. Instead,\n \nDS 4.01\n\n\n54\nCHAPTER 1. INTRODUCTION\nmost choices for coming to a distributed system come from the need to im-\nprove the performance of a single computer system in terms of, for example,\nreliability, scalability, and efficiency. However, considering that most cen-\ntralized systems are still much easier to manage and maintain, one should\nthink twice before deciding to spread processes and resources. There are also\ncases when there is simply no choice, for example when connecting systems\nbelonging to different organizations, or when computers simply operate from\ndifferent locations (as in mobile computing).\nDesign goals for distributed systems include sharing resources and ensur-\ning openness. Increasingly important is designing secure distributed systems.\nIn addition, designers aim at hiding many of the intricacies related to the\ndistribution of processes, data, and control. However, this distribution trans-\nparency not only comes at a performance price, in practical situations it can\nnever be fully achieved. The fact that trade-offs need to be made between\nachieving various forms of distribution transparency is inherent to the design\nof distributed systems, and can easily complicate their understanding. One\nspecific difficult design goal that does not always blend well with achieving\ndistribution transparency is scalability. This is particularly true for geographi-\ncal scalability, in which case hiding latencies and bandwidth restrictions can\nturn out to be difficult. Likewise, administrative scalability, by which a system\nis designed to span multiple administrative domains, may easily conflict with\ngoals for achieving distribution transparency.\nDifferent types of distributed systems exist which can be classified as\nbeing oriented toward supporting computations, information processing, and\npervasiveness. Distributed computing systems are typically deployed for\nhigh-performance applications, often originating from the field of parallel\ncomputing. A field that emerged from parallel processing was initially grid\ncomputing with a strong focus on worldwide sharing of resources, in turn\nleading to what is now known as cloud computing. Cloud computing goes\nbeyond high-performance computing and also supports distributed systems\nfound in traditional office environments, where we see databases playing\nan important role. Typically, transaction processing systems are deployed\nin these environments. Finally, an emerging class of distributed systems is\nwhere components are small, the system is composed in an ad hoc fashion,\nbut most of all is no longer managed through a system administrator. This last\nclass is typically represented by pervasive computing environments, including\nmobile-computing systems as well as sensor-rich environments.\nMatters are further complicated by the fact that many developers initially\nmake assumptions about the underlying network that are fundamentally\nwrong. Later, when assumptions are dropped, it may turn out to be difficult\nto mask unwanted behavior. A typical example is assuming that network\nlatency is not significant. Other pitfalls include assuming that the network is\nreliable, static, secure, and homogeneous.\nDS 4.01\n \n\n\n02\nARCHITECTURES\n\n\n56\nCHAPTER 2. ARCHITECTURES\nDistributed systems are often complex pieces of software, of which the\ncomponents are by definition dispersed across multiple machines. To master\ntheir complexity, it is crucial that these systems be properly organized. There\nare different ways on how to view the organization of a distributed system,\nbut an obvious one is to make a distinction between, on the one hand, the\nlogical organization of the collection of software components, and on the other\nhand the actual physical realization.\nThe organization of distributed systems is mostly about the software\ncomponents that constitute the system. These software architectures tell us\nhow the various software components are to be organized and how they\nshould interact. In this chapter, we will first pay attention to some commonly\napplied architectural styles toward organizing (distributed) computer systems.\nAn important goal of distributed systems is to separate applications from\nunderlying platforms by providing a so-called middleware layer. Adopting\nsuch a layer is an important architectural decision, and its main purpose is\nto provide distribution transparency. However, trade-offs need to be made\nto achieve transparency, which has led to various techniques to adjust the\nmiddleware to the needs of the applications that make use of it. We discuss\nsome of the more commonly applied techniques, as they affect the organization\nof the middleware itself.\nThe actual realization of a distributed system requires that we instantiate\nand place software components on real machines. There are many choices\nthat can be made in doing so. The final instantiation of a software architecture\nis also referred to as a system architecture. In this chapter, we will look into\ntraditional centralized architectures in which a single server implements most\nof the software components (and thus functionality), while remote clients\ncan access that server using simple communication means. In addition, we\nconsider decentralized peer-to-peer architectures in which all nodes more or\nless play equal roles. Many real-world distributed systems are often organized\nin a hybrid fashion, combining elements from centralized and decentralized\narchitectures. We discuss several examples that illustrate the complexity of\nmany real-world distributed systems.\n2.1\nArchitectural styles\nWe start our discussion on architectures by first considering the logical or-\nganization of a distributed system into software components, also referred\nto as its software architecture [Bass et al., 2021; Richards and Ford, 2020].\nResearch on software architectures has matured considerably, and it is now\ncommonly accepted that designing or adopting an architecture is crucial for\nthe successful development of large software systems.\nFor our discussion, the notion of an architectural style is important. Such\na style is formulated in terms of components, the way that components are\nDS 4.01\n \n\n\n2.1. ARCHITECTURAL STYLES\n57\nconnected to each other, the data exchanged between components, and finally,\nhow these elements are jointly configured into a system. A component is\na modular unit with well-defined required and provided interfaces that is\nreplaceable within its environment [OMG, 2004]. That a component can be\nreplaced, and, in particular, while a system continues to operate, is important.\nThis is because often it is not an option to shut down a system for maintenance.\nAt best, only parts of it may be put temporarily out of order. Replacing a\ncomponent can be done only if its interfaces remain untouched. In practice, we\nsee that replacing or updating a component means that a part of a system (such\nas a server), runs a regular update and switches to the refreshed components\nonce their installation has finished. Special measures may need to be taken\nwhen a part of the distributed system does need to be restarted to let the\nupdates take effect. Such measures may include having replicated standbys\nthat take over while the partial restart is taking place.\nA somewhat more difficult concept to grasp is that of a connector, which\nis generally described as a mechanism that mediates communication, coordi-\nnation, or cooperation among components [Bass et al., 2021]. For example, a\nconnector can be formed by the facilities for (remote) procedure calls, message\npassing, or streaming data. In other words, a connector allows for the flow of\ncontrol and data between components.\nUsing components and connectors, we can come to various configurations,\nwhich, in turn, have been classified into architectural styles. Several styles\nhave by now been identified, of which the most important ones for distributed\nsystems are:\n• Layered architectures\n• Service-oriented architectures\n• Publish-subscribe architectures\nIn the following, we discuss each of these styles separately. We note in ad-\nvance that in most real-world distributed systems, many styles are combined.\nNotably, following an approach by which a system is subdivided into several\n(logical) layers is such a universal principle that it is generally combined with\nmost other architectural styles.\n2.1.1\nLayered architectures\nThe basic idea for the layered style is simple: components are organized in\na layered fashion where a component at layer Lj can make a downcall to\na component at a lower-level layer Li (with i < j) and generally expects a\nresponse. Only in exceptional cases will an upcall be made to a higher-level\ncomponent. The three common cases are shown in Figure 2.1.\n \nDS 4.01\n",
      "page_number": 63
    },
    {
      "number": 8,
      "title": "Segment 8 (pages 71-78)",
      "start_page": 71,
      "end_page": 78,
      "detection_method": "topic_boundary",
      "content": "58\nCHAPTER 2. ARCHITECTURES\n(a)\n(b)\n(c)\nFigure 2.1: (a) Pure layered organization. (b) Mixed layered organization.\n(c) Layered organization with upcalls (adopted from [Krakowiak, 2009]).\nFigure 2.1(a) shows a standard organization in which only downcalls to\nthe next lower layer are made. This organization is commonly deployed in\nthe case of network communication.\nIn many situations, we also encounter the organization shown in Fig-\nure 2.1(b). Consider, for example, an application A that makes use of a library\nLOS to interface to an operating system. At the same time, the application uses\na specialized mathematical library Lmath that has been implemented by also\nmaking use of LOS. In this case, referring to Figure 2.1(b), A is implemented at\nlayer N −1, Lmath at layer N −2, and LOS which is common to both of them,\nat layer N −3.\nFinally, a special situation is shown in Figure 2.1(c). In some cases, it\nis convenient to have a lower layer do an upcall to its next higher layer. A\ntypical example is when an operating system signals the occurrence of an\nevent, to which end it calls a user-defined operation for which an application\nhad previously passed a reference (typically referred to as a handle).\nLayered communication protocols\nA well-known and ubiquitously applied layered architecture is that of commu-\nnication-protocol stacks. We will concentrate here on the global picture only\nand defer a detailed discussion to Section 4.1.1.\nIn communication-protocol stacks, each layer implements one or several,\ncommunication services allowing data to be sent from a destination to one\nor several targets. To this end, each layer offers an interface specifying the\nDS 4.01\n \n\n\n2.1. ARCHITECTURAL STYLES\n59\nFigure 2.2: A layered communication-protocol stack, showing the difference\nbetween a service, its interface, and the protocol it deploys.\nfunctions that can be called. In principle, the interface should completely hide\nthe actual implementation of a service. Another important concept in the case\nof communication is that of a (communication) protocol, which describes\nthe rules that parties will follow to exchange information. It is important to\nunderstand the difference between a service offered by a layer, the interface by\nwhich that service is made available, and the protocol that a layer implements\nto establish communication. This distinction is shown in Figure 2.2.\nTo make this distinction clear, consider a reliable, connection-oriented\nservice, which is provided by many communication systems. In this case,\na communicating party first needs to set up a connection to another party\nbefore the two can send and receive messages. Being reliable means that\nstrong guarantees will be given that sent messages will indeed be delivered to\nthe other side, even when there is a high risk that messages may be lost (as,\nfor example, may be the case when using a wireless medium). In addition,\nsuch services generally also ensure that messages are delivered in the same\norder as that they were sent.\nThis kind of service is realized in the Internet by the Transmission Control\nProtocol (TCP). The protocol specifies which messages are to be exchanged for\nsetting up or tearing down a connection, what needs to be done to preserve\nthe ordering of transferred data, and what both parties need to do to detect\nand correct data that was lost during transmission. The service is made\navailable in the form of a relatively simple programming interface, containing\ncalls to set up a connection, send and receive messages, and to tear down\nthe connection again. In fact, there are different interfaces available, often\ndependent on the operating system or programming language used. Likewise,\nthere are many implementations of the protocol and its interfaces. (All the\ngory details can be found in [Stevens, 1994; Wright and Stevens, 1995].)\n \nDS 4.01\n\n\n60\nCHAPTER 2. ARCHITECTURES\nNote 2.1 (Example: Two communicating parties)\nTo make this distinction between service, interface, and protocol more concrete,\nconsider the following two communicating parties, also known as a client and a\nserver, respectively, expressed in Python (note that some code has been removed\nfor clarity).\n1 from socket\nimport *\n2\n3 s = socket(AF_INET, SOCK_STREAM)\n4 (conn, addr) = s.accept()\n# returns new socket and addr. client\n5 while True:\n# forever\n6\ndata = conn.recv(1024)\n# receive data from client\n7\nif not data: break\n# stop if client stopped\n8\nmsg = data.decode()+\"*\"\n# process the incoming data into a response\n9\nconn.send(msg.encode())\n# return the response\n10 conn.close()\n# close the connection\n(a) A simple server\n1 from socket\nimport *\n2\n3 s = socket(AF_INET, SOCK_STREAM)\n4 s.connect((HOST, PORT)) # connect to server (block until accepted)\n5 msg = \"Hello World\"\n# compose a message\n6 s.send(msg.encode())\n# send the message\n7 data = s.recv(1024)\n# receive the response\n8 print(data.decode())\n# print the result\n9 s.close()\n# close the connection\n(b) A client\nFigure 2.3: Two communicating parties.\nIn this example, a server is created that makes use of a connection-oriented\nservice as offered by the socket library available in Python. This service allows\ntwo communicating parties to reliably send and receive data over a connection.\nThe main functions available in its interface are:\n• socket(): to create an object representing the connection\n• accept(): a blocking call to wait for incoming connection requests; if\nsuccessful, the call returns a new socket for a separate connection\n• connect(): to set up a connection to a specified party\n• close(): to tear down a connection\n• send(), recv(): to send and receive data over a connection, respectively\nThe combination of constants AF_INET and SOCK_STREAM is used to specify that\nthe TCP protocol should be used in the communication between the two parties.\nThese two constants can be seen as part of the interface, whereas making use of\nTCP is part of the offered service. How TCP is implemented, or for that matter, any\npart of the communication service, is hidden completely from the applications.\nDS 4.01\n \n\n\n2.1. ARCHITECTURAL STYLES\n61\nFinally, also note that these two programs implicitly adhere to an application-\nlevel protocol: apparently, if the client sends some data, the server will return it.\nIndeed, it operates as an echo server, where the server adds an asterisk to the data\nsent by the client.\nApplication layering\nLet us now turn our attention to the logical layering of applications. Consider-\ning that a large class of distributed applications is targeted toward supporting\nusers or applications access to databases, many people have advocated a\ndistinction between three logical levels, essentially following a layered archi-\ntectural style:\n• The application-interface level\n• The processing level\n• The data level\nIn line with this layering, we see that applications can often be constructed\nfrom roughly three different pieces: a part that handles interaction with a\nuser or some external application, a part that operates on a database or file\nsystem, and a middle part that generally contains the core functionality of the\napplication. This middle part is logically placed at the processing level. In\ncontrast to user interfaces and databases, there are not many aspects common\nto the processing level. Therefore, we shall give several examples to make this\nlevel clearer.\nAs a first example, consider a simple Internet search engine, for example\none dedicated to buying houses. Such search engines appear as seemingly\nsimple Websites through which someone can provide descriptors such as\na city or region, a price range, the type of house, etc. The back end con-\nsists of a huge database of houses currently for sale. The processing layer\ndoes nothing else but transform the provided descriptors into a collection of\ndatabase queries, retrieves the answers and post-processes these answers by,\nfor example, ranking the output by relevance and subsequently generating an\nHTML page. Figure 2.4 shows this organization.\nAs another example, consider the organization of this book’s Website, in\nparticular, the interface that allows someone to get a personalized digital\ncopy of the book in PDF. In this case, the interface consists of a WordPress-\nbased Web server that merely collects the user’s e-mail address (and some\ninformation on exactly which version of the book is being requested). This\ninformation is internally appended to a file requests.txt. The data layer is\nsimple: it merely consists of a collection of LATEX files and figures that jointly\nconstitute the entire book.\n \nDS 4.01\n\n\n62\nCHAPTER 2. ARCHITECTURES\nFigure 2.4: The simplified organization of an Internet search engine for\nhousing, into three different layers.\nMaking a personalized copy consists of embedding the user’s e-mail\naddress into each of the figures. To this end, once every five minutes a\nseparate process is started that takes the list of requests and one-by-one adds\nthe requester’s e-mail address into each bitmapped figure, generates a fresh\ncopy of the book, stores the generated PDF in a special location (accessible\nthrough a unique URL), and sends the requester an e-mail that the copy is\navailable for download. This process continues until all requests have been\nhandled. In this example, we thus see that the processing layer outweighs the\ndata layer or the application-interface layer in terms of computational efforts\nand actions to take.\n2.1.2\nService-oriented architectures\nAlthough the layered architectural style is popular, one of its major drawbacks\nis the often strong dependency between different layers. Good examples\nwhere these potential dependencies have been carefully considered are found\nin designing communication protocol stacks. Bad examples include applica-\ntions that have essentially been designed and developed as compositions of\nexisting components without much concern for the stability of interfaces or\nthe components themselves, let alone the overlap of functionality between\ndifferent components. (A compelling example is given by Kucharski [2020],\nwho describes the dependency on a simple component that pads a given\nstring with zeroes or spaces. The author withdrew the component from the\nNPM library, leaving thousands of programs affected.)\nSuch direct dependencies to specific components have led to an architec-\ntural style reflecting a more loose organization into a collection of separate,\nDS 4.01\n \n\n\n2.1. ARCHITECTURAL STYLES\n63\nindependent entities. Each entity encapsulates a service. Whether they are\ncalled services, objects, or microservices, they have in common that the ser-\nvice is executed as a separate process (or thread). Of course, running separate\nentities does not necessarily lower dependencies in comparison to a layered\narchitectural style.\nObject-based architectural style\nTaking the object-based approach as an example, we have a logical organiza-\ntion as shown in Figure 2.5. In essence, each object corresponds to what we\nhave defined as a component, and these components are connected through\na procedure-call mechanism. In the case of distributed systems, a procedure\ncall can also take place over a network, that is, the calling object need not be\nexecuted on the same machine as the called object. In fact, where exactly the\ncalled object is located can be transparent to the caller: the called object may\nequally well run as a separate process on the same machine.\nFigure 2.5: An object-based architectural style.\nObject-based architectures are attractive because they provide a natural\nway of encapsulating data (called an object’s state) and the operations that can\nbe performed on that data (which are referred to as an object’s methods) into\na single entity. The interface offered by an object conceals implementation\ndetails, essentially meaning that we, in principle, can consider an object\ncompletely independent of its environment. As with components, this also\nmeans that if the interface is clearly defined and left otherwise untouched, an\nobject should be replaceable with one having the same interface.\nThis separation between interfaces and the objects implementing these\ninterfaces allows us to place an interface at one machine, while the object itself\nresides on another machine. This organization, which is shown in Figure 2.6\nis commonly referred to as a distributed object, or every so often a remote\nobject.\nWhen a client binds to a distributed object, an implementation of the\nobject’s interface, called a proxy, is then loaded into the client’s address space.\nA proxy is analogous to a so-called client stub in RPC systems. The only thing\nit does is pack method invocations into messages and unpack reply messages\nto return the result of the method invocation to the client. The actual object\n \nDS 4.01\n\n\n64\nCHAPTER 2. ARCHITECTURES\nServer machine\nObject\nClient machine\nProxy\nSame\ninterface\nas object\nInterface\nState\nMethod\nClient\ninvokes\na method\nNetwork\nSkeleton\ninvokes\nsame method\nat object\nMarshalled invocation\nis passed across network\nClient OS\nServer OS\nServer\nSkeleton\nClient\nFigure 2.6: Common organization of a remote object with client-side proxy.\nresides at a server machine, where it offers the same interface as it does on the\nclient machine. Incoming invocation requests are first passed to a server stub,\nwhich unpacks them to make method invocations at the object’s interface at\nthe server. The server stub is also responsible for packing return values into a\nmessage, and forwarding these reply messages to the client-side proxy.\nThe server-side stub is often referred to as a skeleton as it provides the\nbare means for letting the server middleware access the user-defined objects.\nIn practice, it often contains incomplete code in the form of a language-specific\nclass that needs to be further specialized by the developer.\nA characteristic, but somewhat counterintuitive, feature of most distributed\nobjects is that their state is not distributed: it resides at a single machine. Only\nthe interfaces implemented by the object are made available on other machines.\nSuch objects are also referred to as remote objects. In a general distributed\nobject, the state itself may be physically distributed across multiple machines,\nbut this distribution is also hidden from clients behind the object’s interfaces.\nMicroservice architectural style\nOne could argue that object-based architectures form the foundation of encap-\nsulating services into independent units. Encapsulation is the keyword here:\nthe service as a whole is realized as a self-contained entity, although it can\npossibly make use of other services. By clearly separating various services\nsuch that they can operate independently, we are paving the road toward\nservice-oriented architectures, generally abbreviated as SOAs.\nStimulated by object-oriented designs and inspired by the Unix approach\nin which many, many small and mutually independent programs can be easily\nDS 4.01\n \n\n\n2.1. ARCHITECTURAL STYLES\n65\ncomposed to form larger programs, software architects have been working on\nwhat are called microservices. Essential is that each microservice runs as a\nseparate (network) process. The implementation of a microservice could be\nin the form of a remote object, but this is not a requirement. Furthermore,\ndespite that people speak of microservices, there is no common agreement on\nwhat the size of such a service should be. Most important, however, is that a\nmicroservice truly represents a separate, independent service. In other words,\nmodularization is key to designing microservices [Wolff, 2017].\nNevertheless, size does matter. By already stating that microservices run\nas separate networked processes, we are also given a choice where to place a\nmicroservice. As we shall see later in this chapter, in the advent of edge and\nfog infrastructures, discussions have started on the orchestration of deploying\ndistributed applications across different layers. In other words, where do we\nplace what.\nCoarse-grained service composition\nIn a service-oriented architecture, a distributed application or system is essen-\ntially constructed as a composition of many services. A difference (although\nnot strict) with microservices is that not all of these services may belong to the\nsame administrative organization. We already came across this phenomenon\nwhen discussing cloud computing: it may very well be that an organization\nrunning its business application makes use of storage services offered by a\ncloud provider. These storage services are logically completely encapsulated\ninto a single unit, of which an interface is made available to customers.\nOf course, storage is a rather basic service, but more sophisticated situa-\ntions easily come to mind. Consider, for example, a Web shop selling goods\nsuch as e-books. A simple implementation, following the application layering\nwe discussed previously, may consist of an application for processing orders,\nwhich, in turn, operates on a local database containing the e-books. Order\nprocessing typically involves selecting items, registering and checking the\ndelivery channel (perhaps by making use of e-mail), but also making sure that\na payment takes place. The latter can be handled by a separate service, run by\na different organization, to which a purchasing customer is redirected for the\npayment, after which the e-book organization is notified so that it can com-\nplete the transaction. This example also illustrates that where microservices\nare considered to be relatively small, a general service may be expected to\nbe relatively large. In fact, it is not uncommon to implement a service as a\ncollection of microservices.\nIn this way, we see that the problem of developing a distributed system is\npartly one of service composition, and making sure that those services operate\nin harmony. Indeed, this problem is completely analogous to the enterprise\napplication integration issues discussed in Section 1.3.2.\nCrucial is, and\nremains, that each service offers a well-defined (programming) interface. In\n \nDS 4.01\n",
      "page_number": 71
    },
    {
      "number": 9,
      "title": "Segment 9 (pages 79-86)",
      "start_page": 79,
      "end_page": 86,
      "detection_method": "topic_boundary",
      "content": "66\nCHAPTER 2. ARCHITECTURES\npractice, this also means that each service offers its own interface, in turn,\npossibly making the composition of services far from trivial.\nResource-based architectures\nAs an increasing number of services became available over the Web and the\ndevelopment of distributed systems through service composition became more\nimportant, researchers started to rethink the architecture of mostly Web-based\ndistributed systems. One of the problems with service composition is that\nconnecting various components can easily turn into an integration nightmare.\nAs an alternative, one can also view a distributed system as a huge collec-\ntion of resources that are individually managed by components. Resources\nmay be added or removed by (remote) applications, and likewise can be\nretrieved or modified. This approach has now been widely adopted for\nthe Web and is known as Representational State Transfer (REST) [Fielding,\n2000]. There are four key characteristics of what are known as RESTful\narchitectures [Pautasso et al., 2008]:\n1. Resources are identified through a single naming scheme\n2. All services offer the same interface, consisting of at most four operations,\nas shown in Figure 2.7\n3. Messages sent to or from a service are fully self-described\n4. After executing an operation at a service, that component forgets every-\nthing about the caller\nThe last property is also referred to as a stateless execution, a concept to\nwhich we return in Chapter 3.\nOperation\nDescription\nPUT\nModify a resource by transferring a new state\nPOST\nCreate a new resource\nGET\nRetrieve the state of a resource in some representation\nDELETE\nDelete a resource\nFigure 2.7: The four operations available in RESTful architectures.\nTo illustrate how RESTful can work in practice, consider a cloud storage\nservice, such as Amazon’s Simple Storage Service (Amazon S3). Amazon\nS3, described in [Murty, 2008] and more recently in [Culkin and Zazon, 2022],\nsupports two resources: objects, which are essentially the equivalent of files,\nand buckets, the equivalent of directories. There is no concept of placing\nbuckets into buckets. An object named ObjectName contained in a bucket\nBucketName is referred to by the following Uniform Resource Identifier (URI):\nDS 4.01\n \n\n\n2.1. ARCHITECTURAL STYLES\n67\nhttps://s3.amazonaws.com/BucketName/ObjectName\nTo create a bucket, or an object for that matter, an application would essentially\nsend a PUT request with the URI of the bucket/object. In principle, the protocol\nthat is used with the service is HTTP. In other words, it is just another HTTP\nrequest, which will subsequently be correctly interpreted by S3. If the bucket\nor object already exists, an HTTP error message is returned.\nSimilarly, to know which objects are contained in a bucket, an application\nwould send a GET request with the URI of that bucket. S3 will return a list of\nobject names, again as an ordinary HTTP response.\nThe RESTful architecture has become popular because of its simplicity.\nPautasso et al. [2008] have compared RESTful services to service-specific\ninterfaces, and, as to be expected, they both have their advantages and dis-\nadvantages. In particular, the simplicity of RESTful architectures can easily\nprohibit easy solutions to intricate communication schemes. One example is\nwhere distributed transactions are needed, which generally requires that ser-\nvices keep track of the state of execution. On the other hand, there are many\nexamples in which RESTful architectures match perfectly a simple integration\nscheme of services, yet where the myriad of service interfaces will complicate\nmatters.\nNote 2.2 (Advanced: On interfaces)\nClearly, a service cannot be made easier or more difficult just because of the\nparticular interface it offers. A service offers functionality, and at best the way\nthat the service is accessed is determined by the interface. Indeed, one could\nargue that the discussion on RESTful versus service-specific interfaces is much\nabout access transparency. To better appreciate why so many people are paying\nattention to this issue, let us zoom in on the Amazon S3 service, which offers a\nREST interface as well as a more traditional interface (referred to as the SOAP\ninterface). The fact that the latter has been deprecated out says a lot.\nBucket operations\nObject operations\nListAllMyBuckets\nPutObjectInline\nCreateBucket\nPutObject\nDeleteBucket\nCopyObject\nListBucket\nGetObject\nGetBucketAccessControlPolicy\nGetObjectExtended\nSetBucketAccessControlPolicy\nDeleteObject\nGetBucketLoggingStatus\nGetObjectAccessControlPolicy\nSetBucketLoggingStatus\nSetObjectAccessControlPolicy\nFigure 2.8: The operations in Amazon’s S3 SOAP interface, by now\ndeprecated.\nThe SOAP interface consists of approximately 16 operations, listed in Fig-\nure 2.8. However, if we were to access Amazon S3 using the Python boto3 library,\nwe would have more than 100 operations available. In contrast, the REST interface\n \nDS 4.01\n\n\n68\nCHAPTER 2. ARCHITECTURES\noffers only very few operations, essentially those listed in Figure 2.7. Where do\nthese differences come from? The answer is, of course, in the parameter space. In\nthe case of RESTful architectures, an application will need to provide all that it\nwants through the parameters it passes by one of the operations. In Amazon’s\nSOAP interface, the number of parameters per operation is generally limited, and\nthis is certainly the case if we were to use the Python boto3 library.\nSticking to principles (so that we can avoid the intricacies of real code), suppose\nthat we have an interface bucket that offers an operation create, requiring an\ninput string such as mybucket, for creating a bucket with name “mybucket.”\nNormally, the operation would be called roughly as follows:\nimport bucket\nbucket.create(\"mybucket\")\nHowever, in a RESTful architecture, the call would need to be essentially encoded\nas a single string, such as\nPUT \"https://mybucket.s3.amazonsws.com/\"\nThe difference is striking. For example, in the first case, many syntactical errors\ncan often already be caught during compile time, whereas in the second case,\nchecking needs to be deferred until runtime.\nSecondly, one can argue that\nspecifying the semantics of an operation is much easier with specific interfaces\nthan with ones that offer only generic operations. On the other hand, with generic\noperations, changes are much easier to accommodate, as they would generally\ninvolve changing the layout of strings that encode what is actually required.\n2.1.3\nPublish-subscribe architectures\nAs systems continue to grow and processes can more easily join or leave, it\nbecomes important to have an architecture in which dependencies between\nprocesses become as loose as possible. A large class of distributed systems\nhave adopted an architecture in which there is a strong separation between\nprocessing and coordination. The idea is to view a system as a collection of\nautonomously operating processes. In this model, coordination encompasses\nthe communication and cooperation between processes. It forms the glue\nthat binds the activities performed by processes into a whole [Gelernter and\nCarriero, 1992].\nCabri et al. [2000] provide a taxonomy of coordination models that can\nbe applied equally to many types of distributed systems. Slightly adapting\ntheir terminology, we make a distinction between models along two different\ndimensions, temporal and referential, as shown in Figure 2.9.\nWhen processes are temporally and referentially coupled, coordination\ntakes place directly, referred to as direct coordination. The referential coupling\ngenerally appears in the form of explicit referencing in communication. For\nexample, a process can communicate only if it knows the name or identifier of\nDS 4.01\n \n\n\n2.1. ARCHITECTURAL STYLES\n69\nTemporally\nTemporally\ncoupled\ndecoupled\nReferentially\nDirect\nMailbox\ncoupled\nReferentially\nEvent-\nShared\ndecoupled\nbased\ndata space\nFigure 2.9: Examples of different forms of coordination.\nthe other processes it wants to exchange information with. Temporal coupling\nmeans that processes that are communicating will both have to be up and\nrunning. In real life, talking over cell phones (and assuming that a cell phone\nhas only one owner), is an example of direct communication.\nA different type of coordination occurs when processes are temporally de-\ncoupled, but referentially coupled, which we refer to as mailbox coordination.\nIn this case, there is no need for two communicating processes to be active\nat the same time to let communication take place. Instead, communication\ntakes place by putting messages in a (possibly shared) mailbox. Because it is\nnecessary to explicitly address the mailbox that will hold the messages that\nare to be exchanged, there is a referential coupling.\nThe combination of referentially decoupled and temporally coupled sys-\ntems form the group of models for event-based coordination. In referentially\ndecoupled systems, processes do not know each other explicitly. The only\nthing a process can do is publish a notification describing the occurrence of an\nevent (e.g., that it wants to coordinate activities, or that it just produced some\ninteresting results). Assuming that notifications come in all sorts and kinds,\nprocesses may subscribe to a specific kind of notification (see also [Mühl et al.,\n2006]). In an ideal event-based coordination model, a published notification\nwill be delivered exactly to those processes that have subscribed to it. However,\nit is generally required that the subscriber is up-and-running at the time the\nnotification was published.\nA well-known coordination model is the combination of referentially and\ntemporally decoupled processes, leading to what is known as a shared data\nspace. The key idea is that processes communicate entirely through tuples,\nwhich are structured data records consisting of several fields, very similar to a\nrow in a database table. Processes can put any type of tuple into the shared\ndata space. To retrieve a tuple, a process provides a search pattern that is\nmatched against the tuples. Any tuple that matches is returned.\nShared data spaces are thus seen to implement an associative search\nmechanism for tuples. When a process wants to extract a tuple from the data\nspace, it specifies (some of) the values of the fields it is interested in. Any\ntuple that matches that specification is then removed from the data space and\npassed to the process.\n \nDS 4.01\n\n\n70\nCHAPTER 2. ARCHITECTURES\nShared data spaces are often combined with event-based coordination: a\nprocess subscribes to certain tuples by providing a search pattern; when a\nprocess inserts a tuple into the data space, matching subscribers are notified. In\nboth cases, we are dealing with a publish-subscribe architecture, and indeed,\nthe key characteristic feature is that processes have no explicit reference to\neach other. The difference between a pure event-based architectural style , and\nthat of a shared data space, is shown in Figure 2.10. We have also shown an\nabstraction of the mechanism by which publishers and subscribers are matched,\nknown as an event bus.\n(a)\n(b)\nFigure 2.10: The (a) event-based and (b) shared data-space architectural style.\nNote 2.3 (Example: Linda tuple spaces)\nTo make matters a bit more concrete, we take a closer look at Linda, a program-\nming model developed in the 1980s [Carriero and Gelernter, 1989]. The shared\ndata space in Linda is known as a tuple space, which supports three operations:\n• in(t): remove a tuple that matches the template t\n• rd(t): obtain a copy of a tuple that matches the template t\n• out(t): add the tuple t to the tuple space\nNote that if a process would call out(t) twice in a row, we would find that two\ncopies of tuple t would have been stored. Formally, a tuple space is therefore\nalways modeled as a multiset. Both in and rd are blocking operations: the caller\nwill be blocked until a matching tuple is found, or has become available.\nConsider a simple microblog application in which messages are tagged with\nthe name of its poster and a topic, followed by a short string. Each message\nis modeled as a tuple <string,string,string> where the first string names the\nposter, the second string represents the topic, and the third one is the actual\ncontent. Assuming that we have created a shared data space called MicroBlog,\nFigure 2.11 shows how Alice and Bob can post messages to that space, and how\nDS 4.01\n \n\n\n2.1. ARCHITECTURAL STYLES\n71\nChuck can pick a (randomly selected) message. We have omitted some code for\nclarity. Note that neither Alice nor Bob knows who will read their postings.\n1 blog = linda.universe._rd((\"MicroBlog\",linda.TupleSpace))[1]\n2\n3 blog._out((\"bob\",\"distsys\",\"I am studying chap 2\"))\n4 blog._out((\"bob\",\"distsys\",\"The linda example’s pretty simple\"))\n5 blog._out((\"bob\",\"gtcn\",\"Cool book!\"))\n(a) Bob’s code for creating a microblog and posting three messages.\n1 blog = linda.universe._rd((\"MicroBlog\",linda.TupleSpace))[1]\n2\n3 blog._out((\"alice\",\"gtcn\",\"This graph theory stuff is not easy\"))\n4 blog._out((\"alice\",\"distsys\",\"I like systems more than graphs\"))\n(b) Alice’s code for creating a microblog and posting two messages.\n1 blog = linda.universe._rd((\"MicroBlog\",linda.TupleSpace))[1]\n2\n3 t1 = blog._rd((\"bob\",\"distsys\",str))\n4 t2 = blog._rd((\"alice\",\"gtcn\",str))\n5 t3 = blog._rd((\"bob\",\"gtcn\",str))\n(c) Chuck reading a message from Bob’s and Alice’s microblog.\nFigure 2.11: A simple example of using a shared data space.\nIn the first line of each code fragment, a process looks up the tuple space\nnamed “MicroBlog.” Bob posts three messages: two on topic distsys, and one on\ngtcn. Alice posts two messages, one on each topic. Chuck, finally, reads three\nmessages: one from Bob on distsys and one on gtcn, and one from Alice on gtcn.\nObviously, there is much room for improvement. For example, we should\nensure that Alice cannot post messages under Bob’s name. However, the important\nissue to note now, is that by providing only tags, a reader such as Chuck will\nbe able to pick up messages without needing to directly reference the poster. In\nparticular, Chuck could also read a randomly selected message on topic distsys\nthrough the statement\nt = blog_rd((str,\"distsys\",str))\nWe leave it as an exercise to the reader to extend the code fragments such that a\nnext message will be selected instead of a random one.\nAn important aspect of publish-subscribe systems is that communication\ntakes place by describing the events that a subscriber is interested in. As a\nconsequence, naming plays a crucial role. We return to naming later, but for\nnow, the important issue is that often, data items are not explicitly identified\nby senders and receivers.\nLet us first assume that events are described by a series of attributes.\nA notification describing an event is said to be published when it is made\n \nDS 4.01\n\n\n72\nCHAPTER 2. ARCHITECTURES\navailable for other processes to read. To that end, a subscription needs to\nbe passed to the middleware, containing a description of the event that the\nsubscriber is interested in. Such a description typically consists of some\n(attribute, value) pairs, which is common for so-called topic-based publish-\nsubscribe systems.\nAs an alternative, in content-based publish-subscribe systems, a sub-\nscription may also consist of (attribute, range) pairs. In this case, the specified\nattribute is expected to take on values within a specified range. Descriptions\ncan sometimes be given using all kinds of predicates formulated over the\nattributes, very similar in nature to SQL-like queries in the case of relational\ndatabases. Obviously, the more expressive a description is allowed to be, the\nmore difficult it will be to test whether an event matches a description.\nWe are now confronted with a situation in which subscriptions need to be\nmatched against notifications, as shown in Figure 2.12. Often, an event actually\ncorresponds to data becoming available. In that case, when matching succeeds,\nthere are two possible scenarios. In the first case, the middleware may decide\nto forward the published notification, along with the associated data, to its\ncurrent set of subscribers, that is, processes with a matching subscription. As\nan alternative, the middleware can also forward only a notification, at which\npoint subscribers can execute a read operation to retrieve the data item.\nFigure 2.12: The principle of exchanging data items between publishers and\nsubscribers.\nIn those cases, in which data associated with an event are immediately\nforwarded to subscribers, the middleware will generally not offer storage\nof data.\nStorage is either explicitly handled by a separate service, or is\nthe responsibility of subscribers. In other words, we have a referentially\ndecoupled, but temporally coupled system.\nThis situation is different when notifications are sent so that subscribers\nneed to explicitly read the associated data. Necessarily, the middleware will\nhave to store data items. In these situations, there are additional operations\nfor data management. It is also possible to attach a lease to a data item such\nthat when the lease expires that the data item is automatically deleted.\nDS 4.01\n \n\n\n2.2. MIDDLEWARE AND DISTRIBUTED SYSTEMS\n73\nEvents can easily complicate the processing of subscriptions. To illustrate,\nconsider a subscription such as “notify when room ZI.1060 is unoccupied and\nthe door is unlocked.” Typically, a distributed system supporting such sub-\nscriptions can be implemented by placing independent sensors for monitoring\nroom occupancy (e.g., motion sensors) and those for registering the status\nof a door lock. Following the approach sketched so far, we would need to\ncompose such primitive events into a publishable data item, to which processes\ncan then subscribe. Event composition turns out to be a difficult task, notably\nwhen the primitive events are generated from sources dispersed across the\ndistributed system.\nClearly, in publish-subscribe systems such as these, the crucial issue is the\nefficient and scalable implementation of matching subscriptions to notifica-\ntions. From the outside, the publish-subscribe architecture provides lots of\npotential for building very large-scale distributed systems due to the strong\ndecoupling of processes. On the other hand, devising scalable implementa-\ntions without losing this independence is not a trivial exercise, notably in\nthe case of content-based publish-subscribe systems. In this sense, although\nmany claim that the publish-subscribe style offers the path toward scalable\narchitectures, the fact is that implementations may easily form a bottleneck,\ncertainly when security and privacy is at stake, as we will discuss in Chapter 9\nand later in Chapter 5.\n2.2\nMiddleware and distributed systems\nTo assist the development of distributed applications, distributed systems are\noften organized to have a separate layer of software that is logically placed on\ntop of the respective operating systems of the computers that are part of the\nFigure 2.13: A distributed system organized in a middleware layer, which\nextends over multiple machines, offering each application the same interface.\n \nDS 4.01\n",
      "page_number": 79
    },
    {
      "number": 10,
      "title": "Segment 10 (pages 87-94)",
      "start_page": 87,
      "end_page": 94,
      "detection_method": "topic_boundary",
      "content": "74\nCHAPTER 2. ARCHITECTURES\nsystem. This organization is shown in Figure 2.13, leading to what is known\nas middleware [Bernstein, 1996].\nFigure 2.13 shows four networked computers and three applications, of\nwhich application B is distributed across computers 2 and 3. Each application\nis offered the same interface. The distributed system provides the means for\ncomponents of a single distributed application to communicate with each\nother, but also to let different applications communicate. At the same time,\nit hides, as best and reasonably as possible, the differences in hardware and\noperating systems from each application.\nIn a sense, middleware is the same to a distributed system as what an\noperating system is to a computer: a manager of resources offering its ap-\nplications to efficiently share and deploy those resources across a network.\nNext to resource management, it offers services that can also be found in most\noperating systems, including:\n• Facilities for interapplication communication.\n• Security services.\n• Accounting services.\n• Masking of and recovery from failures.\nThe main difference with their operating-system equivalents, is that middle-\nware services are offered in a networked environment. Note also that most\nservices are useful to many applications. In this sense, middleware can also\nbe viewed as a container of commonly used components and functions that\nnow no longer have to be implemented by applications separately.\nNote 2.4 (Historical note: The term middleware)\nAlthough the term middleware became popular in the mid 1990s, it was most\nlikely mentioned for the first time in a report on a NATO software engineering\nconference, edited by Peter Naur and Brian Randell in October 1968 [Naur and\nRandell, 1968]. Indeed, middleware was placed precisely between applications\nand service routines (the equivalent of operating systems).\n2.2.1\nMiddleware organization\nLet us now zoom into the actual organization of middleware. There are two\nimportant types of design patterns that are often applied to the organization of\nmiddleware: wrappers and interceptors. Each targets different problems, yet\naddresses the same goal for middleware: achieving openness (as we discussed\nin Section 1.2.3).\nDS 4.01\n \n\n\n2.2. MIDDLEWARE AND DISTRIBUTED SYSTEMS\n75\nWrappers\nWhen building a distributed system out of existing components, we immedi-\nately bump into a fundamental problem: the interfaces offered by the legacy\ncomponent are most likely not suitable for all applications. In Section 1.3.2 we\ndiscussed how enterprise application integration could be established through\nmiddleware as a communication facilitator, but there we still implicitly as-\nsumed that, in the end, components could be accessed through their native\ninterfaces.\nA wrapper or adapter is a special component that offers an interface\nacceptable to a client application, of which the functions are transformed\ninto those available at the component. In essence, it solves the problem of\nincompatible interfaces (see also Gamma et al. [1994]).\nAlthough originally narrowly defined in the context of object-oriented\nprogramming, in the context of distributed systems wrappers are much more\nthan simple interface transformers. For example, an object adapter is a\ncomponent that allows applications to invoke remote objects, although those\nobjects may have been implemented as a combination of library functions\noperating on the tables of a relational database.\nAs another example, reconsider Amazon’s S3 storage service. As men-\ntioned, there are two types of interfaces available, one adhering to a RESTful\narchitecture, another following a more traditional approach. For the RESTful\ninterface, clients will be using the HTTP protocol, essentially communicating\nwith a traditional Web server which now acts as an adapter to the actual stor-\nage service, by partly dissecting incoming requests and subsequently handing\nthem off to specialized servers internal to S3.\nWrappers have always played an important role in extending systems with\nexisting components. Extensibility, which is crucial for achieving openness,\nused to be addressed by adding wrappers as needed. In other words, if\nan application A managed data that was needed by an application B, one\napproach would be to develop a wrapper specific for B so that it could\nhave access to A’s data. Clearly, this approach does not scale well: with N\napplications we would, in theory, need to develop N × (N −1) = O(N2)\nwrappers.\nAgain, facilitating a reduction of the number of wrappers is typically\ndone through middleware. One way of doing this is implementing a so-\ncalled broker, which is logically a centralized component that handles all\nthe accesses between different applications. An often-used type is a message\nbroker of which we discuss the technicalities in Section 4.3.3. In the case of a\nmessage broker, applications simply send requests to the broker containing\ninformation on what they need. The broker, having knowledge of all relevant\napplications, contacts the appropriate applications, possibly combines and\ntransforms the responses and returns the result to the initial application. In\nprinciple, because a broker offers a single interface to each application, we\n \nDS 4.01\n\n\n76\nCHAPTER 2. ARCHITECTURES\n(a)\n(b)\nFigure 2.14: (a) Requiring each application to have a wrapper for each other\napplication. (b) Reducing the number of wrappers by making use of a broker.\nnow need at most 2N = O(N) wrappers instead of O(N2). This situation is\nsketched in Figure 2.14.\nInterceptors\nConceptually, an interceptor is nothing but a software construct that will\nbreak the usual flow of control and allow other (application specific) code\nto be executed. Interceptors are a primary means for adapting middleware\nto the specific needs of an application. As such, they play an important role\nin making middleware open. To make interceptors generic may require a\nsubstantial implementation effort, as illustrated by Schmidt et al. [2000], and it\nis unclear whether in such cases generality should be preferred over restricted\napplicability and simplicity. Furthermore, often having only limited intercep-\ntion facilities will improve management of the software and the distributed\nsystem as a whole.\nTo make matters concrete, consider interception as supported in many\nobject-based distributed systems. The basic idea is simple: an object A can call\na method that belongs to an object B, while the latter resides on a different\nmachine than A. As we explain in detail later in the book, such a remote-object\ninvocation is carried out in three steps:\n1. Object A is offered a local interface that is the same as the interface\noffered by object B. A calls the method available in that interface.\n2. The call by A is transformed into a generic object invocation, made\npossible through a general object-invocation interface offered by the\nmiddleware at the machine where A resides.\n3. Finally, the generic object invocation is transformed into a message that\nis sent through the transport-level network interface as offered by A’s\nlocal operating system.\nDS 4.01\n \n\n\n2.2. MIDDLEWARE AND DISTRIBUTED SYSTEMS\n77\nFigure 2.15: Using interceptors to handle remote-object invocations.\nThis scheme is shown in Figure 2.15. After the first step, the call B.doit(val)\nis transformed into a generic call, such as invoke(B,&doit,val) with a ref-\nerence to B’s method and the parameters that go along with the call. Now\nimagine that object B is replicated. In that case, each replica should actu-\nally be invoked. This is a clear point where interception can help. What\nthe request-level interceptor will do, is simply call invoke(B,&doit,val) for\neach of the replicas. The beauty of this all is that the object A need not be\naware of the replication of B, but also the object middleware need not have\nspecial components that deal with this replicated call. Only the request-level\ninterceptor, which may be added to the middleware, needs to know about B’s\nreplication.\nIn the end, a call to a remote object will have to be sent over the network.\nIn practice, this means that the messaging interface as offered by the local\noperating system will need to be invoked. At that level, a message-level\ninterceptor may assist in transferring the invocation to the target object. For\nexample, imagine that the parameter val actually corresponds to a huge array\nof data. In that case, it may be wise to fragment the data into smaller parts to\nhave it assembled again at the destination. Such a fragmentation may improve\nperformance or reliability. Again, the middleware need not be aware of this\nfragmentation; the lower-level interceptor will transparently handle the rest of\nthe communication with the local operating system.\n \nDS 4.01\n\n\n78\nCHAPTER 2. ARCHITECTURES\n2.2.2\nModifiable middleware\nWhat wrappers and interceptors offer are means to extend and adapt the\nmiddleware. The need for adaptation comes from the fact that the environment\nin which distributed applications are executed changes continuously. Changes\ninclude those resulting from mobility, a strong variance in the quality-of-\nservice of networks, failing hardware, and battery drainage, among others.\nRather than making applications responsible for reacting to changes, this task\nis placed in the middleware. Moreover, as the size of a distributed system\nincreases, changing its parts can rarely be done by temporarily shutting it\ndown. What is needed is being able to make changes on-the-fly.\nThese strong influences from the environment have brought many de-\nsigners of middleware to consider the construction of adaptive software. We\nfollow Parlavantzas and Coulson [2007] in speaking of modifiable middle-\nware to express that middleware may not only need to be adaptive, but that\nwe should be able to purposefully modify it without bringing it down. In\nthis context, interceptors can be thought of offering a means to adapt the\nstandard flow of control. Replacing software components at runtime is an\nexample of modifying a system. And indeed, perhaps one of the most popular\napproaches toward modifiable middleware is that of dynamically constructing\nmiddleware from components.\nComponent-based design focuses on supporting modifiability through\ncomposition. A system may either be configured statically at design time,\nor dynamically at runtime.\nThe latter requires support for late binding,\na technique that has been successfully applied in programming language\nenvironments, but also for operating systems where modules can be loaded\nand unloaded at will. Automatically selecting the best implementation of\na component during runtime is by now well understood [Yellin, 2003] but\nagain, the process remains complex for distributed systems, especially when\nconsidering that replacement of one component requires to know exactly what\nthe effect of that replacement on other components will be. Often, components\nare less independent as one may think.\nThe bottom line is that to accommodate dynamic changes to the software\nthat makes up middleware, we need at least basic support to load and unload\ncomponents at runtime. In addition, for each component explicit specifications\nof the interfaces it offers, as well the interfaces it requires, are needed. If state\nis maintained between calls to a component, then further special measures\nare needed. By-and-large, it should be clear that organizing middleware to be\nmodifiable requires special attention.\n2.3\nLayered-system architectures\nLet us now take a look at how many distributed systems are actually organized\nby considering where software components are placed. Deciding on software\nDS 4.01\n \n\n\n2.3. LAYERED-SYSTEM ARCHITECTURES\n79\ncomponents, their interaction, and their placement leads to an instance of a\nsoftware architecture, also known as a system architecture [Bass et al., 2021].\nWe start with discussing layered architectures. Other forms follow later.\nDespite the lack of consensus on many distributed systems issues, there\nis one issue that many researchers and practitioners agree upon: thinking in\nterms of clients that request services from servers helps to understand and\nmanage the complexity of distributed systems [Saltzer and Kaashoek, 2009].\nIn the following, we first consider a simple layered organization, followed by\nlooking at multi-layered organizations.\n2.3.1\nSimple client-server architecture\nIn the basic client-server model, processes in a distributed system are divided\ninto two (possibly overlapping) groups. A server is a process implementing\na specific service, for example, a file system service or a database service. A\nclient is a process that requests a service from a server by sending it a request\nand subsequently waiting for the server’s reply. This client-server interaction,\nalso known as request-reply behavior is shown in Figure 2.16.\nFigure 2.16: General interaction between a client C and a server S. C sends\nthe operation oper and waits for the response from S.\nCommunication between a client and a server can be implemented by a\nsimple connectionless protocol when the underlying network is fairly reliable,\nas in many local-area networks. In these cases, when a client requests a service,\nit simply packages a message for the server, identifying the service it wants,\nalong with the necessary input data. The message is then sent to the server.\nThe latter, in turn, will always wait for an incoming request, subsequently\nprocess it, and package the results in a reply message that is then sent to the\nclient.\nUsing a connectionless protocol has the obvious advantage of being effi-\ncient. As long as messages do not get lost or corrupted, the request/reply\nprotocol just sketched works fine. Unfortunately, making the protocol resistant\nto occasional transmission failures is not trivial. The only thing we can do is\npossibly let the client resend the request when no reply message comes in. The\nproblem, however, is that the client cannot detect whether the original request\nmessage was lost, or that transmission of the reply failed. If the reply was lost,\nthen resending a request may result in performing the operation twice. If the\n \nDS 4.01\n\n\n80\nCHAPTER 2. ARCHITECTURES\noperation was something like “transfer $10,000 from my bank account,” then\nclearly, it would have been better that we simply reported an error instead.\nOn the other hand, if the operation was “tell me how much money I have left,”\nit would be perfectly acceptable to resend the request. When an operation\ncan be repeated multiple times without harm, it is said to be idempotent.\nSince some requests are idempotent and others are not, it should be clear that\nthere is no single solution for dealing with lost messages. We defer a detailed\ndiscussion on handling transmission failures to Section 8.3.\nAs an alternative, many client-server systems use a reliable connection-\noriented protocol. Although this solution is not entirely appropriate in a\nlocal-area network due to relatively low performance, it works perfectly fine\nin wide-area systems in which communication is inherently unreliable. For\nexample, virtually all Internet application protocols are based on reliable\nTCP/IP connections. In this case, whenever a client requests a service, it first\nsets up a connection to the server before sending the request. The server\ngenerally uses that same connection to send the reply message, after which\nthe connection is torn down. The trouble may be that setting up and tearing\ndown a connection is relatively costly, especially when the request and reply\nmessages are small.\nThe client-server model has been subject to many debates and controver-\nsies over the years. One of the main issues was how to draw a clear distinction\nbetween a client and a server. Not surprisingly, there is often no clear distinc-\ntion. For example, a server for a distributed database may continuously act as\na client because it is forwarding requests to different file servers responsible\nfor implementing the database tables. In such a case, the database server itself\nonly processes the queries.\n2.3.2\nMultitiered Architectures\nThe distinction into three logical levels, as discussed so far, suggests sev-\neral possibilities for physically distributing a client-server application across\nseveral machines. The simplest organization is to have only two types of\nmachines:\n1. A client machine containing only the programs implementing (part of)\nthe user-interface level\n2. A server machine containing the rest, that is, the programs implementing\nthe processing and data level\nIn this organization everything is handled by the server while the client is\nessentially no more than a dumb terminal, possibly with only a convenient\ngraphical interface. There are, however, many other possibilities. As explained\nin Section 2.1.1, many distributed applications are divided into three layers:\n(1) a user-interface layer, (2) a processing layer, and (3) a data layer. One\nDS 4.01\n \n\n\n2.3. LAYERED-SYSTEM ARCHITECTURES\n81\napproach for organizing clients and servers is then to distribute these layers\nacross different machines, as shown in Figure 2.17 (see also Umar [1997]).\nAs a first step, we make a distinction between only two kinds of machines:\nclient machines and server machines, leading to what is also referred to as a\n(physically) two-tiered architecture.\nUser interface\nUser interface\nUser interface\nApplication\nUser interface\nApplication\nUser interface\nApplication\nDatabase\nn\noit\na\ncilp\np\nA\nn\noit\na\ncilp\np\nA\nn\noit\na\ncilp\np\nA\nDatabase\nDatabase\nDatabase\nDatabase\nDatabase\nUser interface\nClient machine\nServer machine\n(a)\n(b)\n(c)\n(d)\n(e)\nFigure 2.17: Client-server organizations in a two-tiered architecture.\nOne possible organization is to have only the terminal-dependent part\nof the user interface on the client machine, as shown in Figure 2.17(a), and\ngive the applications remote control over the presentation of their data. An\nalternative is to place the entire user-interface software on the client side, as\nshown in Figure 2.17(b). In such cases, we essentially divide the application\ninto a graphical front end, which communicates with the rest of the application\n(residing at the server) through an application-specific protocol. In this model,\nthe front end (the client software) does no processing other than necessary for\npresenting the application’s interface.\nContinuing along this line of reasoning, we may also move part of the\napplication to the front end, as shown in Figure 2.17(c). An example where\nthis makes sense is where the application makes use of a form that needs to\nbe filled in entirely before it can be processed. The front end can then check\nthe correctness and consistency of the form, and where necessary interact\nwith the user. Another example of the organization of Figure 2.17(c), is that of\na word processor in which the basic editing functions execute on the client\nside where they operate on locally cached, or in-memory data, but where the\nadvanced support tools such as checking the spelling and grammar execute\non the server side.\nIn many client-server environments, the organizations shown in Fig-\nure 2.17(d) and Figure 2.17(e) are particularly popular. These organizations\nare used where the client machine is a PC or workstation, connected through\na network to a distributed file system or database. Essentially, most of the\n \nDS 4.01\n",
      "page_number": 87
    },
    {
      "number": 11,
      "title": "Segment 11 (pages 95-104)",
      "start_page": 95,
      "end_page": 104,
      "detection_method": "topic_boundary",
      "content": "82\nCHAPTER 2. ARCHITECTURES\napplication is running on the client machine, but all operations on files or\ndatabase entries go to the server. For example, many banking applications\nrun on an end-user’s machine, where the user prepares transactions and such.\nOnce finished, the application contacts the database on the bank’s server and\nuploads the transactions for further processing. Figure 2.17(e) represents the\nsituation where the client’s local disk contains part of the data. For example,\nwhen browsing the Web, a client can gradually build a huge cache on local\ndisk of most recent inspected Web pages.\nNote 2.5 (More information: Is there something like the best organization?)\nWe note that there has been a strong trend to move away from the configurations\nshown in Figure 2.17(d) and Figure 2.17(e) in those cases, that client software is\nplaced at end-user machines. Instead, most of the processing and data storage\nis handled at the server side. The reason for this is simple: although client\nmachines do a lot, they are also more problematic to manage. Having more\nfunctionality on the client machine means that a wide range of end users will\nneed to be able to handle that software. This implies that more effort needs to\nbe spent on making software resilient to end-user behavior. In addition, client-\nside software is dependent on the client’s underlying platform (i.e., operating\nsystem and resources), which can easily mean that multiple versions will need\nto be maintained. From a systems-management perspective, having what are\ncalled fat clients is not optimal. Instead, the thin clients as represented by the\norganizations shown in Figure 2.17(a)–(c) are much easier, perhaps at the cost of\nless sophisticated user interfaces and client-perceived performance.\nDoes this mean the end of fat clients? Not in the least. For one thing, there\nare many applications for which a fat-client organization is often still the best. We\nalready mentioned office suites, but also many multimedia applications require\nthat processing is done on the client’s side. Moreover, when end users need\nto operate offline, we see that installing applications will be necessary. Second,\nwith the advent of advanced Web browsing technology, it is now much easier\nto dynamically place and manage client-side software by simply uploading (the\nsometimes very sophisticated) scripts to the client.\nCombined with the fact\nthat this type of client-side software runs in well-defined commonly deployed\nenvironments, and thus that platform dependency is much less of an issue, we\nsee that the counter-argument of management complexity is often no longer\nvalid. This has led to the deployment of virtual desktop environments, which we\ndiscuss further in Chapter 3.\nFinally, note that moving away from fat clients does not imply that we no\nlonger need distributed systems. On the contrary, what we continue to see is\nthat server-side solutions are becoming increasingly more distributed as a single\nserver is being replaced by multiple servers running on different machines. Cloud\ncomputing is a good example in this case: the complete server side is being\nexecuted in data centers, and generally on multiple servers.\nWhen distinguishing only client and server machines as we did so far, we\nmiss the point that a server may sometimes need to act as a client, as shown\nDS 4.01\n \n\n\n2.3. LAYERED-SYSTEM ARCHITECTURES\n83\nin Figure 2.18, leading to a (physically) three-tiered architecture.\nFigure 2.18: An example of an application server AS acting as client for a\ndatabase server DS.\nIn this architecture, traditionally programs that form part of the process-\ning layer are executed by a separate server, but may additionally be partly\ndistributed across the client and server machines. A typical example of where\na three-tiered architecture is used is in transaction processing. A separate\nprocess, called the transaction processing monitor, coordinates all transactions\nacross possibly different data servers.\nAnother, but very different example where we often see a three-tiered\narchitecture is in the organization of Websites. In this case, a Web server\nacts as an entry point to a site, passing requests to an application server\nwhere the actual processing takes place. This application server, in turn,\ninteracts with a database server. We already came across such an organization\nwhen discussing this book’s Website and the facilities for generating and\ndownloading a personalized copy.\n2.3.3\nExample: The Network File System\nMany distributed files systems are organized like client-server architectures,\nwith Sun Microsystem’s Network File System (NFS) being one of the most\nwidely deployed ones for Unix systems [Callaghan, 2000; Haynes, 2015;\nNoveck and Lever, 2020].\nThe basic idea behind NFS is that each file server provides a standardized\nview of its local file system. In other words, it should not matter how that\nlocal file system is implemented; each NFS server supports the same model.\nThis approach has been adopted for other distributed files systems as well.\nNFS comes with a communication protocol that allows clients to access the\nfiles stored on a server, thus allowing a heterogeneous collection of processes,\npossibly running on different operating systems and machines, to share a\ncommon file system.\nThe model underlying NFS and similar systems is that of a remote file\nservice. In this model, clients are offered transparent access to a file system\nthat is managed by a remote server. However, clients are normally unaware\n \nDS 4.01\n\n\n84\nCHAPTER 2. ARCHITECTURES\nof the actual location of files. Instead, they are offered an interface to a file\nsystem that is similar to the interface offered by a conventional local file\nsystem. In particular, the client is offered only an interface containing various\nfile operations, but the server is responsible for implementing those operations.\nThis model is therefore also referred to as the remote access model. It is\nshown in Figure 2.19(a).\nClient\nClient\nFile stays\non server\nServer\nServer\nRequests from\nclient to access\nremote file\n1. File moved to client\n3. When client is done,\nfile is returned to\nserver\n2. Accesses are\ndone on client\nOld file\nNew file\n(a)\n(b)\nFigure 2.19: (a) The remote access model. (b) The upload/download model.\nIn contrast, in the upload/download model a client accesses a file locally\nafter having downloaded it from the server, as shown in Figure 2.19(b) When\nthe client is finished with the file, it is uploaded back to the server again so\nthat it can be used by another client. The Internet’s FTP service can be used\nthis way when a client downloads a complete file, modifies it, and then puts\nit back.\nNFS has been implemented for numerous operating systems, although the\nUnix versions are predominant. For virtually all modern Unix systems, NFS\nis generally implemented following the architecture shown in Figure 2.20.\nA client accesses the file system using the system calls provided by its local\noperating system. However, the local Unix file system interface is replaced\nby an interface to the Virtual File System (VFS), which by now is a de facto\nstandard for interfacing to different (distributed) file systems [Kleiman, 1986].\nVirtually all modern operating systems provide VFS, and not doing so more\nor less forces developers to largely reimplement huge parts of an operating\nsystem when adopting a new file-system structure. With NFS, operations on\nthe VFS interface are either passed to a local file system, or passed to a separate\ncomponent known as the NFS client, which takes care of handling access to\nfiles stored at a remote server. In NFS, all client-server communication is done\nthrough so-called remote procedure calls (RPCs). As mentioned before, an\nRPC is essentially a standardized way to let a client on a machine A make an\nordinary call to a procedure that is implemented on another machine B. We\ndiscuss RPCs extensively in Chapter 4. The NFS client implements the NFS\nfile system operations as remote procedure calls to the server. Note that the\noperations offered by the VFS interface can be different from those offered by\nDS 4.01\n \n\n\n2.3. LAYERED-SYSTEM ARCHITECTURES\n85\nVirtual file system\n(VFS) layer\nVirtual file system\n(VFS) layer\nSystem call layer\nSystem call layer\nNFS client\nRPC client\nstub\nRPC server\nstub\nNFS server\nLocal file\nsystem interface\nLocal file\nsystem interface\nNetwork\nClient\nServer\nFigure 2.20: The basic NFS architecture for Unix systems.\nthe NFS client. The whole idea of the VFS is to hide the differences between\nvarious file systems.\nOn the server side, we see a similar organization. The NFS server is\nresponsible for handling incoming client requests. The RPC component at\nthe server converts incoming requests to regular VFS file operations that\nare subsequently passed to the VFS layer. Again, the VFS is responsible for\nimplementing a local file system in which the actual files are stored.\nAn important advantage of this scheme is that NFS is largely independent\nof local file systems. It does not matter whether the operating system at the\nclient or server uses a Unix file system, a Windows file system, or even an old\nMS-DOS file system. The only important issue is that these file systems are\ncompliant with the file system model offered by NFS. For example, MS-DOS\nwith its short file names cannot be used to implement an NFS server in a fully\ntransparent way.\n2.3.4\nExample: The Web\nThe architecture of Web-based distributed systems is not fundamentally dif-\nferent from other distributed systems. However, it is interesting to see how\nthe initial idea of supporting distributed documents has evolved since its in-\nception in the 1990s. Documents turned from being purely static and passive\nto dynamically generated content. Furthermore, recently, many organizations\nhave begun supporting services instead of just documents.\nSimple Web-based systems\nMany Web-based systems are still organized as relatively simple client-server\narchitectures. The core of a Web site is formed by a process that has access to a\n \nDS 4.01\n\n\n86\nCHAPTER 2. ARCHITECTURES\nlocal file system storing documents. The simplest way to refer to a document\nis by a reference called a uniform resource locator (URL). It specifies where\na document is located by embedding the DNS name of its associated server\nalong with a file name by which the server can look up the document in its\nlocal file system. Furthermore, a URL specifies the application-level protocol\nfor transferring the document across the network.\nA client interacts with Web servers through a browser, which is responsible\nfor properly displaying a document. Furthermore, a browser accepts input\nfrom a user mostly by letting the user select a reference to another document,\nwhich it then subsequently fetches and displays. The communication between\na browser and Web server is standardized: they both adhere to the HyperText\nTransfer Protocol (HTTP). This leads to the overall organization shown in\nFigure 2.21.\nFigure 2.21: The overall organization of a traditional Web site.\nLet us zoom in a bit into what a document actually is. Perhaps the simplest\nform is a standard text file. In that case, the server and browser have barely\nanything to do: the server copies the file from the local file system and\ntransfers it to the browser. The latter, in turn, merely displays the content of\nthe file ad verbatim without further ado.\nMore interesting are Web documents that have been marked up, which is\nusually done in the HyperText Markup Language, or simply HTML. In that\ncase, the document includes various instructions expressing how its content\nshould be displayed, similar to what one can expect from any decent word-\nprocessing system (although those instructions are normally hidden from the\nend user). For example, instructing text to be emphasized is done by the\nfollowing markup:\n<emph>Emphasize this text</emph>\nThere are many more of such markup instructions. The point is that the\nbrowser understands these instructions and will act accordingly when dis-\nplaying the text.\nDS 4.01\n \n\n\n2.3. LAYERED-SYSTEM ARCHITECTURES\n87\nDocuments can contain much more than just markup instructions. In\nparticular, they can have complete programs embedded, of which JavaScript\nis the one most often deployed. In this case, the browser is warned that there\nis some code to execute as in:\n<script type=”text/javascript”>....</script>\nand as long as the browser has an appropriate embedded interpreter for the\nspecified language, everything between “<script>” and “</script>” will be\nexecuted as any other program. The main benefit of including scripts is that\nit allows for much better interaction with the end user, including sending\ninformation back to the server. (The latter, by the way, has always been\nsupported in HTML through forms.)\nMuch more can be said about Web documents, but this is not the place to\ndo so. A good introduction on how to build Web-based applications can be\nfound in [Sebesta, 2015].\nMultitiered architectures\nThe Web started out as the relatively simple two-tiered client-server system\nshown in Figure 2.21. By now, this simple architecture has been extended to\nsupport much more sophisticated means of documents. In fact, one could\njustifiably argue that the term “document” is no longer appropriate. For one,\nmost things that we get to see in our browser has been generated on the spot\nas the result of sending a request to a Web server. Content is stored in a\ndatabase at the server’s side, along with client-side scripts and such, to be\ncomposed on-the-fly into a document which is then subsequently sent to the\nclient’s browser. Documents have thus become completely dynamic.\nOne of the first enhancements to the basic architecture was support for\nsimple user interaction by the Common Gateway Interface or simply CGI.\nCGI defines a standard way by which a Web server can execute a program\ntaking user data as input. Usually, user data come from an HTML form; it\nspecifies the program that is to be executed at the server side, along with\nparameter values that are filled in by the user. Once the form has been\ncompleted, the program’s name and collected parameter values are sent to\nthe server, as shown in Figure 2.22.\nWhen the server sees the request, it starts the program named in the\nrequest and passes it the parameter values. At that point, the program simply\ndoes its work and generally returns the results in the form of a document that\nis sent back to the user’s browser to be displayed.\nCGI programs can be as sophisticated as a developer wants. For example,\nas shown in Figure 2.22 many programs operate on a database local to the\nWeb server. After processing the data, the program generates an HTML\ndocument and returns that document to the server. The server will then pass\nthe document to the client. An interesting observation is that to the server,\n \nDS 4.01\n\n\n88\nCHAPTER 2. ARCHITECTURES\nFigure 2.22: The principle of using server-side CGI programs.\nit appears as if it is asking the CGI program to fetch a document. In other\nwords, the server does nothing but delegate the fetching of a document to an\nexternal program.\nThe main task of a server used to be handling client requests by simply\nfetching documents. With CGI programs, fetching a document could be\ndelegated in such a way that the server would remain unaware of whether\na document had been generated on the fly, or actually read from the local\nfile system. Note that we have just described a two-tiered organization of\nserver-side software.\nHowever, servers nowadays do much more than just fetching documents.\nOne of the most important enhancements is that servers can also process a\ndocument before passing it to the client. In particular, a document may contain\na server-side script, which is executed by the server when the document has\nbeen fetched locally. The result of executing a script is sent along with the\nrest of the document to the client. The script itself is not sent. In other words,\nusing a server-side script changes a document by essentially replacing the\nscript with the results of its execution. To make matters concrete, take a look\nat a simple example of dynamically generating a document. Assume a file is\nstored at the server with the following content:\n<strong> <?php echo $_SERVER[’REMOTE_ADDR’]; ?> </strong>\nThe server will examine the file and subsequently process the PHP code (be-\ntween “<?php” and “?>”) replacing the code with the address of the requesting\nclient. Much more sophisticated settings are possible, such as accessing a\nlocal database and subsequently fetching content from that database to be\ncombined with other dynamically generated content.\n2.4\nSymmetrically distributed system architectures\nMultitiered client-server architectures are a direct consequence of dividing\ndistributed applications into a user interface, processing components, and\nDS 4.01\n \n\n\n2.4. SYMMETRICALLY DISTRIBUTED SYSTEM ARCHITECTURES\n89\ndata-management components. The different tiers correspond directly with\nthe logical organization of applications. In many business environments,\ndistributed processing is equivalent to organizing a client-server application\nas a multitiered architecture. We refer to this type of distribution as vertical\ndistribution. The characteristic feature of vertical distribution is that it is\nachieved by placing logically different components on different machines. The\nterm is related to the concept of vertical fragmentation as used in distributed\nrelational databases, where it means that tables are split columnwise, and\nsubsequently distributed across multiple machines [Özsu and Valduriez, 2020].\nAgain, from a systems-management perspective, having a vertical distri-\nbution can help: functions are logically and physically split across multiple\nmachines, where each machine is tailored to a specific group of functions.\nHowever, vertical distribution is only one way of organizing client-server\napplications. In modern architectures, it is often the distribution of the clients\nand the servers that counts, which we refer to as horizontal distribution. In\nthis type of distribution, a client or server may be physically split up into\nlogically equivalent parts, but each part is operating on its own share of the\ncomplete data set, thus balancing the load. In this section, we will take a look\nat a class of modern system architectures that support horizontal distribution,\nknown as peer-to-peer systems.\nFrom a high-level perspective, the processes that constitute a peer-to-peer\nsystem are all equal. This means that the functions that need to be carried\nout are represented by every process that constitutes the distributed system.\nAs a consequence, much of the interaction between processes is symmetric:\neach process will act as a client and a server at the same time (which is also\nreferred to as acting as a servant).\nGiven this symmetric behavior, peer-to-peer architectures revolve around\nthe question of how to organize the processes in an overlay network [Tarkoma,\n2010]: a network in which the nodes are formed by the processes and the links\nrepresent the possible communication channels (which are often realized as\nTCP connections). A node may not be able to communicate directly with an\narbitrary other node, but is required to send messages through the available\ncommunication channels. Two types of overlay networks exist: those that are\nstructured and those that are not. These two types are surveyed extensively\nin Lua et al. [2005] along with numerous examples. Buford and Yu [2010]\nadditionally includes an extensive list of various peer-to-peer systems. Aberer\net al. [2005] provide a reference architecture that allows for a more formal\ncomparison of the different types of peer-to-peer systems. A survey taken from\nthe perspective of content distribution is provided by Androutsellis-Theotokis\nand Spinellis [2004]. Finally, Buford et al. [2009], Tarkoma [2010] and Vu et al.\n[2010] go beyond the level of surveys and form adequate textbooks for initial\nor further study.\n \nDS 4.01\n\n\n90\nCHAPTER 2. ARCHITECTURES\n2.4.1\nStructured peer-to-peer systems\nAs its name suggests, in a structured peer-to-peer system the nodes (i.e.,\nprocesses) are organized in an overlay that adheres to a specific, deterministic\ntopology: a ring, a binary tree, a grid, etc. This topology is used to efficiently\nlook up data. Characteristic for structured peer-to-peer systems, is that they\nare generally based on using a so-called semantic-free index. What this means\nis that each data item that is to be maintained by the system, is uniquely\nassociated with a key, and that this key is subsequently used as an index. To\nthis end, it is common to use a hash function so that we get:\nkey(data item) = hash(data item’s value).\nThe peer-to-peer system as a whole is now responsible for storing (key,value)\npairs. To this end, each node is assigned an identifier from the same set\nof all possible hash values, and each node is made responsible for storing\ndata associated with a specific subset of keys. In essence, the system is\nthus seen to implement a distributed hash table, generally abbreviated to a\nDHT [Balakrishnan et al., 2003].\nFollowing this approach now reduces the essence of structured peer-to-\npeer systems to being able to look up a data item by its key. That is, the\nsystem provides an efficient implementation of a function lookup that maps a\nkey to an existing node:\nexisting node = lookup(key).\nThis is where the topology of a structured peer-to-peer system plays a crucial\nrole. Any node can be asked to look up a given key, which then boils down to\nefficiently routing that lookup request to the node responsible for storing the\ndata associated with the given key.\nTo clarify these matters, let us consider a simple peer-to-peer system with\na fixed number of nodes, organized into a hypercube. A hypercube is an\nn-dimensional cube. The hypercube shown in Figure 2.23 is four-dimensional.\nIt can be thought of as two ordinary cubes, each with 8 vertices and 12 edges.\nTo expand the hypercube to five dimensions, we would add another set of\ntwo interconnected cubes to the figure, connect the corresponding edges in\nthe two halves, and so on.\nFor this (admittedly naive) system, each data item is associated with one\nof the 16 nodes. This can be achieved by hashing the value of a data item to a\nkey k ∈{0, 1, 2, . . . , 24 −1}. Now suppose that the node with identifier 0111\nis requested to look up the data having key 14, corresponding to the binary\nvalue 1110. In this example, we assume that the node with identifier 1110 is\nresponsible for storing all data items that have key 14. What node 0111 can\nsimply do, is forward the request to a neighbor who is closer to node 1110. In\nthis case, this is either node 0110 or node 1111. If it picks a node 0110, that\nDS 4.01\n \n\n\n2.4. SYMMETRICALLY DISTRIBUTED SYSTEM ARCHITECTURES\n91\nFigure 2.23: A simple peer-to-peer system organized as a four-dimensional\nhypercube.\nnode will then forward the request directly to a node 1110 from where the\ndata can be retrieved.\nNote 2.6 (Example: The Chord system)\nThe previous example illustrates two things: (1) the use of a hashing function to\nidentify the node responsible for storing some data item, and (2) the routing along\nthe topology of a peer-to-peer system when looking up a data item given its key.\nHowever, it is not a very realistic example, if only for the reason that we assumed\nthat the total set of nodes is fixed. Let us therefore consider a more realistic\nexample of a structured peer-to-peer system that is considered as belonging to\nthe foundations for many other such systems.\nIn the Chord system [Stoica et al., 2003] the nodes are logically organized\nin a ring such that a data item with an m-bit key k is mapped to the node with\nthe smallest (again, also m bit) identifier id ≥k. This node is referred to as the\nsuccessor of key k and denoted as succ(k). Keys and identifiers are typically 128\nor 160 bits long. Figure 2.24 shows a much smaller Chord ring, where m = 5 and\nwith nine nodes {1, 4, 9, 11, 14, 18, 20, 21, 28}. The successor of key 7 is equal to\n9. Likewise, succ(5) = 9, but also succ(9) = 9. In Chord, each node maintains\nshortcuts to other nodes. A shortcut appears as a directed edge from one node\nto another. How these shortcuts are constructed is explained in Chapter 6. The\nconstruction is done in such a way that the length of the shortest path between\nany pair of nodes is of order O(log N), where N is the total number of nodes.\nTo look up a key, a node will try to forward the request “as far as possible,” but\nwithout passing it beyond the node responsible for that key. To clarify, suppose\nthat in our example Chord ring, node 9 is asked to look up the node responsible\nfor key 3 (which is node 4). Node 9 has four shortcuts: to nodes 11, 14, 18, and 28,\nrespectively. As the node 28 is the farthest node 9 knows about and still preceding\nthe one responsible for key 3, it will get the lookup request. Node 28 has three\nshortcuts: to nodes 1, 4, and 14, respectively. Note that node 28 has no knowledge\nabout the existence of nodes between nodes 1 and 4. For this reason, the best\nwhat it can do is forward the request to the node 1. The latter knows that its\nsuccessor in the ring is node 4, and thus that this is the node responsible for the\nkey 3, to which it will subsequently forward the request.\n \nDS 4.01\n",
      "page_number": 95
    },
    {
      "number": 12,
      "title": "Segment 12 (pages 105-113)",
      "start_page": 105,
      "end_page": 113,
      "detection_method": "topic_boundary",
      "content": "92\nCHAPTER 2. ARCHITECTURES\nFigure 2.24: The organization of nodes and data items in Chord.\nNow suppose that a node, with the unique identifier u, wants to join a Chord\noverlay. To that end, it contacts an arbitrary node and requests it to look up u,\nthat is, return the value v= succ(u). At that point, node u will simply need to\ninsert itself between the predecessor of v and v itself, thus becoming the new\npredecessor of v. During this process, shortcuts from u to other nodes will be\nestablished, but also some existing ones previously directed toward v will now be\nadjusted to point to u (again, details are deferred until later chapters). Obviously,\nany data item with key k stored at v but for which succ(k) is now equal to u is\ntransferred from v to u. Leaving is just as simple: node u informs its departure to\nits predecessor and successor, and transfers its data items to succ(u).\nWe return to Chord in more detail in Section 6.2.3 when discussing the\nresolution of random bit strings to network addresses.\n2.4.2\nUnstructured peer-to-peer systems\nStructured peer-to-peer systems attempt to maintain a specific, deterministic\noverlay network. In contrast, in an unstructured peer-to-peer system, each\nnode maintains an ad hoc list of neighbors. The resulting overlay resembles\nwhat is known as a random graph: a graph in which an edge ⟨u, v⟩between\ntwo nodes u and v exists only with a certain probability P[⟨u, v⟩]. Ideally, this\nprobability is the same for all pairs of nodes, but in practice a wide range of\ndistributions is observed.\nIn an unstructured peer-to-peer system, when a node joins, it often contacts\na well-known node to obtain a starting list of other peers in the system. This\nlist can then be used to find more peers, and perhaps ignore others, and so\nDS 4.01\n \n\n\n2.4. SYMMETRICALLY DISTRIBUTED SYSTEM ARCHITECTURES\n93\non. In practice, a node generally changes its local list almost continuously.\nFor example, a node may discover that a neighbor is no longer responsive\nand that it needs to be replaced. There may be other reasons, which we will\ndescribe shortly.\nUnlike structured peer-to-peer systems, looking up data cannot follow a\npredetermined route when lists of neighbors are constructed in an ad hoc\nfashion. Instead, in an unstructured peer-to-peer systems, we really need\nto resort to searching for data [Risson and Moors, 2006]. Let us look at two\nextremes and consider the case in which we are requested to search for specific\ndata (e.g., identified by keywords).\nFlooding: In the case of flooding, an issuing node u simply passes a request\nfor a data item to all its neighbors. A request will be ignored when its\nreceiving node, say v, had seen it before. Otherwise, v searches locally\nfor the requested data item. If v has the required data, it can either\nrespond directly to the issuing node u, or send it back to the original\nforwarder, who will then return it to its original forwarder, and so on. If\nv does not have the requested data, it forwards the request to all of its\nown neighbors.\nObviously, flooding can be expensive, for which reason a request often\nhas an associated time-to-live or TTL value, giving the maximum num-\nber of hops a request is allowed to be forwarded. Choosing the right\nTTL value is crucial: too small means that a request will stay close to the\nissuer and may thus not reach a node having the data. Too large incurs\nhigh communication costs.\nAs an alternative to setting TTL values, a node can also start a search\nwith an initial TTL value of 1, meaning that it will first query only its\nneighbors. If no, or not enough results are returned, the TTL is increased,\nand a new search is initiated.\nRandom walks: At the other end of the search spectrum, an issuing node u\ncan simply try to find a data item by asking a randomly chosen neighbor,\nsay v. If v does not have the data, it forwards the request to one of its\nrandomly chosen neighbors, and so on. The result is known as a random\nwalk [Gkantsidis et al., 2006; Lv et al., 2002]. Obviously, a random walk\nimposes much less network traffic, yet it may take much longer before\na node is reached that has the requested data. To decrease the waiting\ntime, an issuer can simply start n random walks simultaneously. Indeed,\nstudies show that in this case, the time it takes before reaching a node\nthat has the data drops approximately by a factor n. Lv et al. [2002]\nreports that relatively small values of n, such as 16 or 64, turn out to be\neffective.\nA random walk also needs to be stopped. To this end, we can either again\nuse a TTL, or alternatively, when a node receives a lookup request, check\n \nDS 4.01\n\n\n94\nCHAPTER 2. ARCHITECTURES\nwith the issuer whether forwarding the request to another randomly\nselected neighbor is still needed.\nNote that neither method relies on a specific comparison technique to decide\nwhen requested data has been found. For structured peer-to-peer systems,\nwe assumed the use of keys for comparison; for the two approaches just\ndescribed, any comparison technique would suffice.\nBetween flooding and random walks lie policy-based search methods.\nFor example, a node may decide to keep track of peers who responded\npositively, effectively turning them into preferred neighbors for succeeding\nqueries. Likewise, we may want to restrict flooding to fewer neighbors, but in\nany case give preference to neighbors having many neighbors themselves.\nNote 2.7 (Advanced: Flooding versus random walks)\nWhen giving the matter some thought, it may come as a surprise that people have\neven considered a random walk as an alternative way to search. At first instance,\nit would seem like a technique resembling the search for a needle in a haystack.\nHowever, we need to realize that in practice we are dealing with replicated data,\nand even for minimal replication factors and different replication distributions,\nstudies show that deploying random walks is not only effective, it can also be\nmuch more efficient in comparison to flooding.\nTo see why, we closely follow the model described in Lv et al. [2002] and\nCohen and Shenker [2002]. Assume there are a total of N nodes and that each data\nitem is replicated across r randomly chosen nodes. A search consists of repeatedly\nselecting a node at random until the item is found. If P[k] is the probability that\nthe item is found after k attempts, we have\nP[k] = r\nN (1 −r\nN )k−1.\nLet the average search size S be the expected number of nodes that need to be\nprobed before finding the requested data item:\nS =\nN\n∑\nk=1\nk · P[k] =\nN\n∑\nk=1\nk · r\nN (1 −r\nN )k−1 ≈N/r for 1 ≪r ≤N.\nBy simply replicating every data item to each node, S = 1 and it is clear that a\nrandom walk will always outperform flooding even for TTL values of 1. More\nrealistically, however, is to assume that r/N is relatively low, such as 0.1%,\nmeaning that the average search size would be approximately 1000 nodes.\nTo compare this to flooding, assume that each node, on average, forwards a\nrequest to d randomly selected neighbors. After one step, the request will have\narrived at d nodes, each of who will forward it to another d −1 nodes (assuming\nthat the node from where the request came is skipped), and so on. In other words,\nafter k steps, and considering that a node can receive the request more than once,\nwe will have reached (at most) the following number of nodes:\nR(k) = d(d −1)k−1\nDS 4.01\n \n\n\n2.4. SYMMETRICALLY DISTRIBUTED SYSTEM ARCHITECTURES\n95\nVarious studies show that R(k) is a good estimate for the actual number of nodes\nreached, as long as we have only a few number of flooding steps. Of these nodes,\nwe can expect a fraction of r/N to have the requested data item, meaning that\nwhen r\nN · R(k) ≥1, we will most likely have found a node that has the data item.\nTo illustrate, let r/N = 0.001 = 0.1%, which means that S ≈1000. With\nflooding to, on average, d = 10 neighbors, we would require at least 4 flooding\nsteps, reaching some 7290 nodes, which is considerably more than the 1000 nodes\nrequired when using a random walk. Only with d = 33 will we need to contact\napproximately also 1000 nodes in k = 2 flooding steps and having r/N · R(k) ≥1.\nThe obvious drawback of deploying random walks, is that it may take much\nlonger before an answer is returned.\n2.4.3\nHierarchically organized peer-to-peer networks\nNotably in unstructured peer-to-peer systems, locating relevant data items\ncan become problematic as the network grows. The reason for this scalability\nproblem is simple: as there is no deterministic way of routing a lookup request\nto a specific data item, essentially the only technique a node can resort to\nis searching for the request by flooding or randomly walking through the\nnetwork. As an alternative, many peer-to-peer systems have proposed to\nmake use of special nodes that maintain an index of data items.\nThere are other situations in which abandoning the symmetric nature of\npeer-to-peer systems is sensible. Consider a collaboration of nodes that offer\nresources to each other. For example, in a collaborative Content Delivery\nNetwork (CDN), nodes may offer storage for hosting copies of Web documents\nallowing Web clients to access pages nearby, and thus to access them quickly.\nWhat is needed is a means to find out where documents can be stored best.\nIn that case, making use of a broker that collects data on resource usage\nand availability for several nodes that are in each other’s proximity allows\nselecting a node quickly with sufficient resources.\nNodes such as those maintaining an index or acting as a broker are\ngenerally referred to as super peers. As the name suggests, super peers\nare often also organized in a peer-to-peer network, leading to a hierarchical\norganization, as explained in Yang and Garcia-Molina [2003].\nA simple\nexample of such an organization is shown in Figure 2.25. In this organization,\nevery regular peer, now referred to as a weak peer, is connected as a client to\na super peer. All communication from and to a weak peer proceeds through\nthat peer’s associated super peer.\nOften, the association between a weak peer and its super peer is fixed:\nwhenever a weak peer joins the network, it attaches to one of the super peers\nand remains attached until it leaves the network. Obviously, it is expected that\nsuper peers are long-lived processes with high availability. To compensate for\npotential unstable behavior of a super peer, backup schemes can be deployed,\n \nDS 4.01\n\n\n96\nCHAPTER 2. ARCHITECTURES\nFigure 2.25: A hierarchical organization of nodes into a super-peer network.\nsuch as pairing every super peer with another one and requiring weak peers\nto attach to both.\nHaving a fixed association with a super peer may not always be the best\nsolution. For example, in the case of file-sharing networks, it may be better\nfor a weak peer to attach to a super peer that maintains an index of files\nthat the weak peer is currently interested in. In that case, chances are bigger\nthat when a weak peer is looking for a specific file, its super peer will know\nwhere to find it. Garbacki et al. [2010] describe a relatively simple scheme in\nwhich the association between weak peer and strong peer can change as weak\npeers discover better super peers to associate with. In particular, a super peer\nreturning the result of a lookup operation is given preference over other super\npeers.\nAs we have seen, peer-to-peer networks offer a flexible means for nodes\nto join and leave the network. However, with super-peer networks a new\nproblem is introduced, namely how to select the nodes that are eligible to\nbecome super peer. This problem is closely related to the leader-election\nproblem, which we discuss in Section 5.4.\n2.4.4\nExample: BitTorrent\nLet us consider the widely popular BitTorrent file-sharing system [Cohen,\n2003] as an example of a (largely) unstructured peer-to-peer system. BitTorrent\nis a file-downloading system. Its principle working is shown in Figure 2.26.\nThe basic idea is that when an end user is looking for a file, she downloads\nchunks of the file from other users until the downloaded chunks can be as-\nsembled, yielding the complete file. An important design goal was to ensure\ncollaboration. In most file-sharing systems, a significant fraction of partici-\npants merely download files but otherwise contribute close to nothing [Adar\nand Huberman, 2000; Saroiu et al., 2003; Yang et al., 2005], a phenomenon\nreferred to as free riding. To prevent this situation, in BitTorrent a file can\nDS 4.01\n \n\n\n2.4. SYMMETRICALLY DISTRIBUTED SYSTEM ARCHITECTURES\n97\nNode 1\nNode 2\nNode N\ntorrent file\nfor file F\nA BitTorrent\nWeb page or\nsearch engine\nList of nodes\nwith (chunks of)\nfile F\nWeb server\nFile server\nTracker\nClient node\nK out of N nodes\nLookup(F)\nFigure 2.26: The principle working of BitTorrent [adapted with permission\nfrom Pouwelse et al. [2005].\nbe downloaded only when the downloading client is providing content to\nsomeone else.\nTo download a file, a user needs to access a global directory, which is\ngenerally just one of a few well-known Websites. Such a directory contains\nreferences to what are called torrent files. A torrent file contains the informa-\ntion that is needed to download a specific file. In particular, it contains a link\nto what is known as a tracker, which is a server that is keeping an accurate\naccount of active nodes that have (chunks of) the requested file. An active\nnode is one that is currently downloading the file as well. Obviously, there\nwill be many trackers, although there will generally be only a single tracker\nper file (or collection of files).\nOnce the nodes have been identified from where chunks can be down-\nloaded, the downloading node effectively becomes active. At that point, it\nwill be forced to help others, for example by providing chunks of the file it\nis downloading that others do not yet have. This enforcement comes from a\nsimple rule: if a node P notices that a node Q is downloading more than it\nis uploading, P can decide to decrease the rate at which it sends data to Q.\nThis scheme works well, provided P has something to download from Q. For\nthis reason, nodes are often supplied with references to many other nodes,\nputting them in a better position to trade data.\nClearly, BitTorrent combines centralized with decentralized solutions. As\nit turns out, the bottleneck of the system is easily formed by the trackers.\nIn an alternative implementation of BitTorrent, a node also joins a separate\nstructured peer-to-peer system (i.e., a DHT) to assist in tracking file downloads.\nIn effect, a central tracker’s load is now distributed across the participating\nnodes, with each node acting as a tracker for a relatively small set of torrent\nfiles.\nThe original function of the tracker coordinating the collaborative\ndownloading of a file is retained. However, we note that in many BitTorrent\nsystems used today, the tracking functionality has actually been minimized to\na one-time provisioning of peers currently involved in downloading the file.\nFrom that moment on, the newly participating peer will communicate only\n \nDS 4.01\n\n\n98\nCHAPTER 2. ARCHITECTURES\nwith those peers and no longer with the initial tracker. The initial tracker for\nthe requested file is looked up in the DHT through a so-called magnet link.\nWe return to DHT-based lookups in Section 6.2.3.\n2.5\nHybrid system architectures\nReal-world distributed systems are complex in the sense that they combine a\nmyriad of architectures: centralized features are combined with peer-to-peer\nfeatures are combined with hierarchical organizations, etc. The complexity\nis aggravated by the fact that many distributed systems cross organizational\nboundaries, leading to truly decentralized solutions in which even no single\norganization can take responsibility for a system’s operation. In this section,\nwe will take a closer look into these complex, hybrid system architectures.\n2.5.1\nCloud computing\nOrganizations in charge of running data centers have been seeking ways for\nopening up their resources to customers. Eventually, this led to the concept of\nutility computing by which a customer could upload tasks to a data center\nand be charged on a per-resource basis. Utility computing formed the basis\nfor what is now commonly referred to as cloud computing.\nFollowing Vaquero et al. [2008], cloud computing is characterized by an\neasily usable and accessible pool of virtualized resources. Which and how\nresources are used can be configured dynamically, providing the basis for\nscalability: if more work needs to be done, a customer can simply acquire\nmore resources. The link to utility computing is formed by the fact that cloud\ncomputing is generally based on a pay-per-use model in which guarantees are\noffered by customized service-level agreements (SLAs). Keeping it simple,\nclouds are organized into four layers, as shown in Figure 2.27.\nHardware: The lowest layer is formed by the means to manage the necessary\nhardware: processors, routers, but also power and cooling systems. It is\ngenerally implemented at data centers and contains the resources that\ncustomers normally never get to see directly.\nInfrastructure: This is an important layer forming the backbone for most\ncloud computing platforms. It deploys virtualization techniques (dis-\ncussed in Section 3.2) to provide customers an infrastructure consisting\nof virtual storage and computing resources. Indeed, nothing is what\nit seems: cloud computing evolves around allocating and managing\nvirtual storage devices and virtual servers.\nPlatform: One could argue that the platform layer provides to a cloud-\ncomputing customer what an operating system provides to application\ndevelopers, namely the means to easily develop and deploy applications\nDS 4.01\n \n\n\n2.5. HYBRID SYSTEM ARCHITECTURES\n99\nthat need to run in a cloud. In practice, an application developer is\noffered a vendor-specific API, which includes calls to uploading and ex-\necuting a program in that vendor’s cloud. In a sense, this is comparable\nto the Unix exec family of system calls, which take an executable file as\na parameter and pass it to the operating system to be executed.\nFurthermore, like operating systems, the platform layer provides higher-\nlevel abstractions for storage and such. For example, as we discussed,\nthe Amazon S3 storage system [Murty, 2008; Culkin and Zazon, 2022]\nis offered to the application developer in the form of an API allowing\n(locally created) files to be organized and stored in buckets. By storing a\nfile in a bucket, that file is automatically uploaded to the Amazon cloud.\nApplication: Actual applications run in this layer and are offered to users\nfor further customization. Well-known examples include those found\nin office suites (text processors, spreadsheet applications, presentation\napplications, and so on). It is important to realize that these applica-\ntions are again executed in the vendor’s cloud. As before, they can be\ncompared to the traditional suite of applications that are shipped when\ninstalling an operating system.\nCloud-computing providers offer these layers to their customers through\nvarious interfaces (including command-line tools, programming interfaces,\nand Web interfaces), leading to three different types of services:\n• Infrastructure-as-a-Service (IaaS) covering the hardware and infra-\nstructure layer.\n• Platform-as-a-Service (PaaS) covering the platform layer.\n• Software-as-a-Service (SaaS) in which their applications are covered.\nApplication\nInfrastructure\nComputation (VM)\ntorage (block\n)\n, s\n, file\nHardware\nPlatforms\nSoftware framework (Java/Python/.Net)\nStorage (\n)\ndatabases\nInfrastructure\naa Svc\nPlatform\naa Svc\nSoftware\naa Svc\nMS Azure\nGoogle App engine\nAmazon S3\nAmazon EC2\nDatacenters\nCPU, memory, disk, bandwidth\nWeb services, multimedia, business apps\nGoogle docs\nGmail\nYouTube, Flickr\nFigure 2.27: The organization of clouds (adapted from Zhang et al. [2010]).\n \nDS 4.01\n\n\n100\nCHAPTER 2. ARCHITECTURES\nAs of now, making use of clouds is relatively easy, and we discuss in later\nchapters more concrete examples of interfaces to cloud providers.\nAs a\nconsequence, cloud computing as a means for outsourcing local computing\ninfrastructures has become a serious option for many enterprises.\nFrom the perspective of a system architecture, which deals with config-\nuring (micro)services across some infrastructure, one may argue that in the\ncase of cloud computing, we are dealing with a highly advanced client-server\narchitecture. However, let it be noted that the actual implementation of a\nserver is generally completely hidden from the client: it is often unclear where\nthe server actually is, and even whether the server is actually implemented\nin a fully distributed manner (which it often is). To further illustrate this\npoint, the notion of a Function-as-a-Service, or simply Faas, allows a client to\nexecute code without bothering even with starting a server to handle the code\n(see also Shahrad et al. [2019]).\n2.5.2\nThe edge-cloud architecture\nIn the advent of increasingly more network-connected devices and the emer-\ngence of the Internet-of-Things (IoT) many became aware of the fact that we\nmay need more than just cloud computing. Edge computing was born. There\nis a lot to say about edge computing, and much has already been said. And\nas is the case with so many topics in distributed systems, it simply takes a\nfew years before things settle down a bit. In this section, we take a look at\nedge computing from an architectural perspective and will return to various\nelements throughout the book, often without even explicitly mentioning edge\ncomputing. An excellent overview of edge computing is given by Yousefpour\net al. [2019] and the interested reader is referred to that paper to get a better\ngrip on its nomenclature. We deliberately take a simplified and broad view\nof edge computing, using it as a general term for most of the things sitting\nbetween the devices that comprise the Internet-of-Things and the services typi-\ncally offered through cloud computing. In this sense, we follow the discussion\nas presented by Horner [2021].\nAs its name suggests, edge computing deals with the placement of services\n“at the edge” of the network. This edge is often formed by the boundary\nbetween enterprise networks and the actual Internet, for example, as provided\nby an Internet Service Provider (ISP). For example, many universities reside\non a campus consisting of various buildings, each having their own local\nnetwork, in turn connected through a campuswide network. As part of the\ncampus, there may be multiple on-premise services for storage, computing,\nsecurity, lectures, and so on. On-premise means that the local IT department\nis responsible for hosting those services on servers directly hooked up to the\ncampus network. Much of the traffic related to those services will never leave\nthe campus network, and the network together with its servers and services\nform a typical edge infrastructure.\nDS 4.01\n \n",
      "page_number": 105
    },
    {
      "number": 13,
      "title": "Segment 13 (pages 114-124)",
      "start_page": 114,
      "end_page": 124,
      "detection_method": "topic_boundary",
      "content": "2.5. HYBRID SYSTEM ARCHITECTURES\n101\nAt the same time, such servers may be connected to those of other univer-\nsities and perhaps even making use of, again, other servers. In other words,\ninstead of setting up connections between universities in a peer-to-peer fash-\nion, we also see configurations in which various universities share services\nthrough a logically centralized infrastructure. Such an infrastructure may be\nsituated “in the cloud,” but it may equally well have been set up through a\nregional infrastructure using locally available data centers. As we move closer\nto cloud infrastructures, the term fog computing is often used. We thus see an\noverall picture emerge as the one shown in Figure 2.28, where the boundaries\nbetween cloud and edge are becoming blurred.\nFigure 2.28: A collection of infrastructures involving edge devices, edge\ninfrastructures and cloud infrastructures, and a possible setup between two\nenterprise edge infrastructures, an intermediate edge infrastructure, and a\ncloud infrastructure.\nMany configurations for an edge infrastructure easily come to mind, rang-\ning from infrastructures needed to keep track of your activities, layered\nvideo-streaming infrastructures, gaming infrastructures, etc. What all of these\nhave in common is that there is some smart end device that one way or the\nother needs to (eventually) connect to a service hosted somewhere in the\ncloud. The question then pops up why an edge infrastructure is needed at all.\nLogically, it seems much simpler to just connect to the cloud service directly\nusing existing and often excellent networking facilities. Let us take a critical\nlook at a few arguments.\nLatency and bandwidth\nWhat should have become clear from our examples\nis that edge infrastructures are considered to be close to the end devices.\nCloseness can be measured in terms of latency and often also bandwidth.\nThroughout the decades, bandwidth, or actually lack of bandwidth, has\n \nDS 4.01\n\n\n102\nCHAPTER 2. ARCHITECTURES\nalways been used as an argument for introducing solutions close to specific\ndevices. However, if anything has become clear all this time, is that available\nbandwidth continues to increase, now reaching the point that one should\nseriously question how problematic it actually is, and whether installing\nand maintaining edge infrastructures for having insufficient bandwidth is\na good reason. Nevertheless, there are situations in which closeness to end\ndevices is actually needed to guarantee quality of service. The canonical\nexample is formed by video services: the closer the video sources are, the\nbetter bandwidth guarantees can be given, reducing issues such as jitter.\nMore problematic is when Mother Nature gets in our way. This may easily\nhappen when dealing with latency. It may take 100 ms to reach a cloud,\nrendering many interactive applications quite useless. One such important\napplication is (semi-)autonomous driving. A car will need to continuously\nobserve its environment through a myriad of sensors and react accordingly.\nHaving to coordinate its movements through the cloud is not acceptable from\na real-time aspect alone. This example also illustrates that cars may need to\ndetect each other beyond the capabilities of their sensors, for example, when\nheading toward a junction with clear visibility. In a real-time system, cars may\nbe able to provide their current position to a local edge infrastructure and\nreveal themselves to each other when approaching the junction.\nOther examples in which latency plays a crucial role easily come to mind.\nOvercoming latency is one of the most compelling reasons for developing\nedge infrastructures.\nReliability\nMany argue that cloud connectivity is simply not reliable enough\nfor many applications, for which reason edge infrastructures should be de-\nployed. To what extent this is a valid argument remains to be seen. The fact\nis that for many networked applications, connectivity is generally good and\nreliable, if not excellent. Of course, there are situations in which relying on\n24/7 reliability is not an option. This may be the case for hospitals, factories,\nand other critical settings in general. Yet, in those cases, measures have been\ntraditionally already taken and to what extent edge computing brings in\nanything new is not always clear.\nSecurity and privacy\nFinally, many argue that edge solutions enhance secu-\nrity and privacy. It all depends. One could argue that if a cloud solution is not\nsecure, then there is no reason why an edge solution would be. An implicit\nassumption that many people make is that an edge infrastructure is owned by\na specific organization and operates within the (protected) network bound-\naries of that organization. In that case, it often does indeed become simpler to\nprotect data and operations, yet one should ask whether such protection is\nsufficient. As we shall discuss in Chapter 9, simply trying to protect assets\nby developing a secure wall around an organization does not help against\nDS 4.01\n \n\n\n2.5. HYBRID SYSTEM ARCHITECTURES\n103\ninsider attacks, whether they are intended or not. A same reasoning holds\nfor privacy: if we cannot protect personal data in the cloud, then why would\nan edge infrastructure suffice for privacy? A thorough discussion on the role\nand position of privacy in the edge and edge devices is given by Hong [2017].\nFrom that discussion, it is clear that there is still considerable work to be done.\nHowever, there may be another reason related to security and privacy why\nedge infrastructures are needed. In many cases, organizations are simply not\nallowed, for whatever regulatory reasons, to place data in the cloud or have\ndata be processed by a cloud service. For example, medical records may have\nto be kept on premise on certified servers and with strict audit procedures in\nplace. In this case, an organization will have to resort to maintaining an edge\ninfrastructure.\nIntroducing additional layers between end devices and cloud infrastructures\nopens a whole can of worms compared to the relatively simple situation of\njust having to deal with cloud computing. For the latter, one can argue that\nthe cloud provider to a considerable extent decides where and how a service\nis actually implemented. In practice, we will be dealing with a data center\nin which the (micro)services that make up the entire service are distributed\nacross multiple machines.\nMatters become more intricate in the case of edge computing. In this case,\nthe client organization will now have to make informed decisions on what\nto do where. Which services need to be placed on premise on a local edge\ninfrastructure, and which can be moved to the cloud? To what extent does an\nedge infrastructure offer facilities for virtual resources, akin to the facilities\noffered in cloud computing? Moreover, where we may be able to assume that\ncomputational and storage resources are in abundance when dealing with a\ncloud, this is not necessarily the case for an edge infrastructure. In practice,\nthe latter simply have less hardware resources available, but often also offer\nless flexibility in terms of available platforms.\nBy and large, allocating resources in the case of edge computing appears\nto be much more challenging in comparison to clouds. As summarized\nby Hong and Varghese [2019], we are dealing with limitations when it comes to\nresources, higher degrees of hardware heterogeneity, and much more dynamic\nworkloads, which, when taken together, have led to a higher demand of\norchestration. Moreover, where from a client’s perspective the cloud appears\nto be hiding many of its internal intricacies, this is necessarily no longer the\ncase, making it much more difficult to do the orchestration [Bittencourt et al.,\n2018]. Orchestration boils down to the following (see also Taleb et al. [2017]):\n• Resource allocation: specific services require specific resources. The\nquestion is then to guarantee the availability of the resources required to\nperform a service. Typically, resources amount to CPU, storage, memory,\nand networking facilities.\n \nDS 4.01\n\n\n104\nCHAPTER 2. ARCHITECTURES\n• Service placement: regardless the availability of resources, it is impor-\ntant to decide when and where to place a service. This is notably relevant\nfor mobile applications, for in that case finding the edge infrastructure\nthat is closest to that application may be crucial. A typical use case is\nthat of video conferencing, for which the encoding is often not done on\nthe mobile device, but at an edge infrastructure. In practice, one needs\nto decide at which edges the service should be installed. An extensive\noverview of service placement in the case of edge computing is provided\nby Salaht et al. [2020].\n• Edge selection: related to service placement is deciding which edge\ninfrastructure should be used when the service needs to be offered. It\nmay seem logical to use the edge infrastructure closest to the end device,\nbut all kinds of circumstances may ask for an alternative solution, for\nexample the connectivity of that edge to the cloud provider.\nOther issues play a role as well, but it should be clear by now that the edge-\ncloud architecture is much more demanding than one might initially think it\nto be. Moreover, the different perspectives on how the continuum between end\ndevices and the cloud should be filled with edge components and solutions\nhas still to converge [Antonini et al., 2019].\n2.5.3\nBlockchain architectures\nAn upcoming and much debated type of distributed system is that of so-called\nblockchains. Blockchain systems enable the registration of transactions, for\nwhich reason they are also referred to as distributed ledgers. The latter is\nactually more accurate, with blockchains forming one of different ways for\nimplementing distributed ledgers.\nThe key issue in transaction systems is that a transaction is validated,\neffectuated, and subsequently stored for various auditing purposes. For\nexample, Alice may decide to create a transaction stating that she transfers\n$10 to Bob’s account. Normally, she would go to a bank, where she would\nhave to sign the transaction to prove that she really wants it to be carried\nout. Whether this all happens physically or digitally does not really matter.\nThe bank will check whether she has enough credit, whether Bob is eligible\nfor receiving the money, and assuming everything is fine, will subsequently\ntransfer the money. A record of the transaction is kept for all kinds of auditing\npurposes. Note that transactions in blockchains systems are taken very broad.\nBesides monetary transactions, systems have been developed for registering\nidentification documents, registering resource usage and allocation, electronic\nvoting, and sharing health records, to name a few.\nThe bank operates as a trusted third party. An important design as-\nsumption for blockchains is that participating parties can, in principle, not\nbe trusted. This also excludes having a trusted third party that handles all\nDS 4.01\n \n\n\n2.5. HYBRID SYSTEM ARCHITECTURES\n105\ntransactions. We will return to trust in Section 9.4, and concentrate on the\nimplications lack of trust has for the architecture of a system.\nIn the case of blockchains, we assume there is a (potentially very large)\nset of participants who jointly register transactions among them in a publicly\navailable ledger. In this way, any participant can see what has happened and\nalso verify the validity of a transaction. For example, in a blockchain system\nfor digital coins, each having a unique and unforgeable ID, any participant\nshould be able to check whether a coin has already been spent by checking all\ntransactions that have taken place since the beginning.\nFigure 2.29: The principle operation of a blockchain.\nTo this end, when Alice wants to transfer $10 to Bob, she essentially tells\nall the participants in the blockchain system about this intent, thus allowing\nvolunteers to validate the intended transaction. This is shown as Step 1 in\nFigure 2.29. To avoid having to check every transaction separately one-by-one\nas they are submitted, a validator groups several transactions into a block to\nincrease efficiency, shown as Step 2 in Figure 2.29. If everything goes well, i.e.,\nthe transactions in the block are considered to be valid, the validator securely\nprotects the block against any modifications, and appends the now immutable\nblock to the chain of other blocks with validated transactions. It does so\nby broadcasting the validated block to all participants, shown as Step 3 in\nFigure 2.29.\nAn important observation is that there is logically only a single chain of\nblocks with validated transactions. Each block is immutable, in the sense\nthat if an adversary decides to modify any transaction from any block in that\nchain, the modification can never go unnoticed. Securely protecting blocks of\ntransactions against modifications, but also securely appending a block to an\nexisting list, are well-understood techniques, which we will explain further\n \nDS 4.01\n\n\n106\nCHAPTER 2. ARCHITECTURES\nin Section 9.4.3. The immutability of a block makes it an ideal fit for massive\nreplication: it will never be changed anyway, so someone may just as well store\nit locally to make verification as simple as possible. Effectively, the logically\nsingle chain of immutable blocks may be physically massively replicated\nacross the Internet among all participating parties. This is precisely what\nhappens: each block is broadcast to every participating node in a blockchain,\nas we just explained.\nWhat differentiates so many blockchain systems from each other is de-\nciding on which node(s) may actually carry out validation tasks. In other\nwords, we need to figure out who is allowed to append a block of validated\ntransactions to the existing chain. Appending such a block means that there\nis global consensus on fulfilled transactions. It is therefore important that we\nalso reach consensus on which validator can move ahead. All others will have\nto do their validation over again, as their transactions may be affected by the\nnewly appended ones and thus may need to be revisited.\nDeciding on which validator can move ahead requires (distributed) con-\nsensus. In principle, there are three options:\n1. A centralized solution, in which a trusted third party validates transac-\ntions as before.\n2. A distributed solution, in which a small, preselected group of processes\ntakes over the role of a trusted third party.\n3. A fully decentralized solution, in which, in principle, all participating\nnodes in the blockchain jointly reach consensus without any (distributed)\nthird party.\nThese three options are shown in Figure 2.30. As mentioned, each node\nparticipating in the blockchain is assumed to have a full copy locally available.\nObviously, a centralized architecture for a blockchain does not fit its design\ngoals, which state that there is essentially no place for a trusted third party.\nThe distributed architecture is an interesting one. In this case, there is a\nrelatively small group of nodes that are permissioned to validate transactions.\nFor blockchains, it is important to realize that none of these permissioned\nnodes are assumed to be trusted, yet they are assumed to run a consensus\nprotocol that can withstand malicious behavior. Specifically, if there are n\npermissioned nodes, then it is assumed that at most k ≤(n −1)/3 will fail\nand perhaps act maliciously. One problem with such so-called permissioned\nblockchains is that n is quite limited, in practice, to less than a few tens of\nnodes.\nFinally, in so-called permissionless blockchains all nodes collectively\nparticipate to validate transactions. In practice, this means that all nodes who\nwant to validate transactions are engaged in a process called leader election.\nThe process elected as leader appends a block to the current chain (and is\nDS 4.01\n \n\n\n2.5. HYBRID SYSTEM ARCHITECTURES\n107\n(a) Centralized\n(b) Distributed (permissioned)\n(c) Decentralized (permissionless)\nFigure 2.30: The three different organizations of blockchains: (a) centralized,\n(b) distributed, (c) fully decentralized. Filled nodes represent validators; other\nnodes are participants not engaged in validation.\noften rewarded for that). In practice, not all participating nodes will want to\nact as validator, if only because the leader-election algorithm is costly in terms\nof resources. We return to leader elections in Section 5.4.\nThe architecture of a blockchain system is thus seen to be quite complex. In\na permissioned system, we have a few tens of nodes for validating transactions.\nNone of these nodes needs to be individually trusted beforehand, yet it may\nbe argued that they form a centralized, fault-tolerant distributed group. Trust\n \nDS 4.01\n\n\n108\nCHAPTER 2. ARCHITECTURES\nis needed in so far that we need to assume that not too many of those\nnodes act maliciously or collude against any decisions they should make.\nOn the other hand, permissionless blockchains may be viewed as being fully\ndecentralized, but here we see that special measures are needed to guarantee\nsome form of fairness among willing validators. In fact, through the dynamics\nof permissionless blockchains, we often see that, in practice, only a relatively\nfew number of nodes can carry out validation tasks, effectively also leading to\na more centralized system. An overview of the various settings in blockchains\nfrom the perspective of architectures is given by Xu et al. [2017].\n2.6\nSummary\nDistributed systems can be organized in many ways. We can make a dis-\ntinction between software architecture and system architecture. The latter\nconsiders where the components that constitute a distributed system are\nplaced across the various machines. The former is more concerned about the\nlogical organization of the software: how do components interact, in what\nways can they be structured, how can they be made independent, and so on?\nA keyword when talking about architectures is architectural style. A\nstyle reflects the basic principle that is followed in organizing the interaction\nbetween the software components comprising a distributed system. Important\nstyles include layering, service-oriented styles, and styles in which handling\nevents are prominent, exemplified by are known as publish-subscribe styles.\nThere are many organizations of distributed systems. An important class is\nwhere machines are divided into clients and servers. A client sends a request\nto a server, who will then produce a result that is returned to the client. The\nclient-server architecture reflects the traditional way of modularizing software,\nin which a module calls the functions available in another module. By placing\ndifferent components on different machines, we obtain a natural physical\ndistribution of functions across a collection of machines.\nClient-server architectures are often highly centralized. In decentralized\narchitectures, we often see an equal role played by the processes that constitute\na distributed system, also known as peer-to-peer systems. In peer-to-peer\nsystems, the processes are organized into an overlay network, which is a\nlogical network in which every process has a local list of other peers that\nit can communicate with. The overlay network can be structured, in which\ncase deterministic schemes can be deployed for routing messages between\nprocesses. In unstructured networks, the list of peers is more or less random,\nimplying that search algorithms need to be deployed for locating data or other\nprocesses.\nIn hybrid architectures, elements from centralized and decentralized orga-\nnizations are combined. A typical example is that of cloud computing, which\nlogically follows a client-server architecture, but where the server is generally\nDS 4.01\n \n\n\n2.6. SUMMARY\n109\ncompletely distributed across a data center. In the last decade, we have seen a\nstrong emergence of what is known as edge computing. Edge infrastructures\nform several steps between end devices and clouds and are demanding from\nthe view point of organizing and configuring distributed systems. Finally, as\nan example in which decentralization plays a prominent role, the increasing\npopular blockchain architecture illustrates yet another class of hybrid system\narchitectures.\n \nDS 4.01\n\n\n03\nPROCESSES\n\n\n112\nCHAPTER 3. PROCESSES\nIn this chapter, we take a closer look at how the different types of processes\nplay a crucial role in distributed systems. The concept of a process originates\nfrom the field of operating systems, where it is generally defined as a program\nin execution. From an operating-system perspective, the management and\nscheduling of processes are perhaps the most important issues to deal with.\nHowever, when it comes to distributed systems, other issues turn out to be\nequally or more important.\nWe start with extensively discussing threads and their role in distributed\nsystems. As it turns out, threads play a crucial role in obtaining performance\nin multicore and multiprocessor environments, but also help in structuring\nclients and servers. There are many cases where we see threads being replaced\nby processes and using the underlying operating system for guaranteeing\nprotection and facilitating communication. Nevertheless, when performance\nis at stake, threads continue to play an important role.\nSince a few years, the concept of virtualization has regained much pop-\nularity. Virtualization allows an application, and possibly also its complete\nenvironment including the operating system, to run concurrently with other\napplications, but highly independent of the underlying hardware and plat-\nforms, leading to a high degree of portability. Moreover, virtualization helps\nin isolating failures caused by errors or security problems. It is an important\nconcept for distributed systems, and we pay attention to it in a separate\nsection.\nClient-server organizations are important in distributed systems. In this\nchapter, we take a closer look at typical organizations of both clients and\nservers. We also pay attention to general design issues for servers, including\nthose typically used in object-based distributed systems. A widely used Web\nserver is Apache, to which we pay separate attention. The organization of\nserver clusters remains important, especially when they need to collaboratively\nprovide the illusion of a single system. we will discuss examples of how to\nachieve this perspective, including wide-area servers like PlanetLab.\nAn important issue, especially in wide-area distributed systems, is moving\nprocesses between different machines. Process migration or more specifically,\ncode migration, can help in achieving scalability, but can also help to configure\nclients and servers dynamically. What is actually meant by code migration\nand what its implications are is also discussed in this chapter.\n3.1\nThreads\nAlthough processes form a building block in distributed systems, practice\nindicates that the granularity of processes as provided by the operating\nsystems on which distributed systems are built is not sufficient. Instead, it\nturns out that having a finer granularity in the form of multiple threads of\ncontrol per process makes it much easier to build distributed applications\nDS 4.01\n \n",
      "page_number": 114
    },
    {
      "number": 14,
      "title": "Segment 14 (pages 125-138)",
      "start_page": 125,
      "end_page": 138,
      "detection_method": "topic_boundary",
      "content": "3.1. THREADS\n113\nand to get better performance. In this section, we take a closer look at the\nrole of threads in distributed systems and explain why they are so important.\nMore on threads and how they can be used to build applications can be found\nin [Lewis and Berg, 1998; Stevens, 1999; Robbins and Robbins, 2003]. Herlihy\nand Shavit [2008] is highly recommended to learn more about multithreaded\nconcurrent programming in general.\n3.1.1\nIntroduction to threads\nTo understand the role of threads in distributed systems, it is important\nto understand what a process is, and how processes and threads relate. To\nexecute a program, an operating system creates a number of virtual processors,\neach one for running a different program. To keep track of these virtual\nprocessors, the operating system has a process table, containing entries to\nstore CPU register values, memory maps, open files, accounting information,\nprivileges, etc. Jointly, these entries form a process context.\nA process context can be viewed as the software analog of the hardware’s\nprocessor context. The latter consists of the minimal information that is\nautomatically stored by the hardware to handle an interrupt, and to later\nreturn to where the CPU left off. The processor context contains at least the\nprogram counter, but sometimes also other register values such as the stack\npointer.\nA process is often defined as a program in execution, that is, a program\nthat is currently being executed on one of the operating system’s virtual\nprocessors. An important issue is that the operating system takes great care\nto ensure that independent processes cannot maliciously or inadvertently\naffect the correctness of each other’s behavior.\nIn other words, the fact\nthat multiple processes may be concurrently sharing the same CPU and\nother hardware resources is made transparent. Usually, the operating system\nrequires hardware support to enforce this separation.\nThis concurrency transparency comes at a price. For example, each time a\nprocess is created, the operating system must create a complete independent\naddress space. Allocation can mean initializing memory segments by, for\nexample, zeroing a data segment, copying the associated program into a text\nsegment, and setting up a stack for temporary data. Likewise, switching\nthe CPU between two processes may require some effort as well. Apart\nfrom saving the data as currently stored in various registers (including the\nprogram counter and stack pointer), the operating system will also have to\nmodify registers of the Memory Management Unit (MMU) and invalidate\naddress translation caches, such as in the Translation Lookaside Buffer (TLB).\nIn addition, if the operating system supports more processes than it can\nsimultaneously hold in main memory, it may have to swap processes between\nmain memory and disk before the actual switch can take place.\n \nDS 4.01\n\n\n114\nCHAPTER 3. PROCESSES\nLike a process, a thread executes its own piece of code, independently\nof other threads. However, in contrast to processes, no attempt is made to\nachieve a high degree of concurrency transparency if this would result in\nperformance degradation. Therefore, a thread system generally maintains only\nthe minimum information to allow a CPU to be shared by several threads. In\nparticular, a thread context often consists of nothing more than the processor\ncontext, along with some other information for thread management. For\nexample, a thread system may keep track of the fact that a thread is currently\nblocked on a mutex variable, so as not to select it for execution. Information\nthat is not strictly necessary to manage multiple threads is generally ignored.\nFor this reason, protecting data against inappropriate access by threads within\na single process is left entirely to application developers. We thus see that a\nprocessor context is contained in a thread context, and that, in turn, a thread\ncontext is contained in a process context.\nThere are two important implications of deploying threads, as we just\nsketched. First, the performance of a multithreaded application need hardly\never be worse than that of its single-threaded counterpart. In fact, often, mul-\ntithreading even leads to a performance gain. Second, because threads are not\nautomatically protected against each other the way processes are, development\nof multithreaded applications requires additional intellectual effort. Proper\ndesign and keeping things simple, as usual, help a lot. Unfortunately, current\npractice does not demonstrate that this principle is equally well understood.\nThread usage in nondistributed systems\nBefore discussing the role of threads in distributed systems, let us first consider\ntheir usage in traditional, nondistributed systems. There are several benefits\nto multithreaded processes that have increased the popularity of using thread\nsystems.\nThe most important benefit comes from the fact that in a single-threaded\nprocess, whenever a blocking system call is executed, the process as a whole is\nblocked. To illustrate, consider an application such as a spreadsheet program,\nand assume that a user continuously and interactively wants to change values.\nAn important property of a spreadsheet program is that it maintains the func-\ntional dependencies between different cells, often from different spreadsheets.\nTherefore, whenever a cell is modified, all dependent cells are automatically\nupdated. When a user changes the value in a single cell, such a modification\ncan trigger a large series of computations. If there is only a single thread of\ncontrol, computation cannot proceed while the program is waiting for input.\nLikewise, it may be difficult to provide input while dependencies are being\ncalculated. The easy solution is to have at least two threads of control: one\nfor handling interaction with the user and one for updating the spreadsheet.\nMeanwhile, a third thread could be used for backing up the spreadsheet to\ndisk while the other two are doing their work.\nDS 4.01\n \n\n\n3.1. THREADS\n115\nAnother advantage of multithreading is that it becomes possible to exploit\nparallelism when executing the program on a multiprocessor or multicore\nsystem. In that case, each thread is assigned to a different CPU or core, while\nshared data are stored in shared main memory. When properly designed,\nsuch parallelism can be transparent: the process will run equally well on a\nuniprocessor system, albeit slower. Multithreading for parallelism is becoming\nincreasingly important with the availability of relatively cheap multiprocessor\nand multicore computers. Such computer systems are typically used for\nrunning servers in client-server applications, but are by now also extensively\nused in devices such as smartphones.\nMultithreading is also useful in the context of large applications. Such\napplications are often developed as a collection of cooperating programs,\neach to be executed by a separate process. This approach is typical for a\nUnix environment. Cooperation between programs is implemented through\ninterprocess communication (IPC) mechanisms. For Unix systems, these\nmechanisms typically include (named) pipes, message queues, and shared\nmemory segments (see also Stevens and Rago [2005]). The major drawback of\nall IPC mechanisms is that communication often requires relatively extensive\ncontext switching, shown at three different points in Figure 3.1.\nProcess A\nProcess B\nOperating system\nS1: Switch from user space\nto kernel space\nS3: Switch from kernel\nspace to user space\nS2: Switch context from\nprocess A to process B\nFigure 3.1: Context switching as the result of IPC.\nBecause IPC requires kernel intervention, a process will generally first\nhave to switch from user mode to kernel mode, shown as S1 in Figure 3.1.\nThis requires changing the memory map in the MMU, as well as flushing the\nTLB. Within the kernel, a process context switch takes place (S2 in the figure),\nafter which the other party can be activated by switching from kernel mode to\nuser mode again (S3 in Figure 3.1). The latter switch again requires changing\nthe MMU map and flushing the TLB.\nInstead of using processes, an application can also be constructed such\nthat different parts are executed by separate threads. Communication between\nthose parts is entirely dealt with by using shared data. Thread switching can\n \nDS 4.01\n\n\n116\nCHAPTER 3. PROCESSES\nsometimes be done entirely in user space, although in other implementations,\nthe kernel is aware of threads and schedules them. The effect can be a dramatic\nimprovement in performance.\nFinally, there is also a pure software engineering reason to use threads:\nmany applications are simply easier to structure as a collection of cooperating\nthreads. Think of applications that need to perform several (more or less\nindependent) tasks, like our spreadsheet example discussed previously.\nNote 3.1 (Advanced: The cost of a context switch)\nThere have been many studies on measuring the performance effects of context\nswitches. As in so many cases with measuring computer systems, finding the\nground truth is not easy. Tsafrir [2007] notes that handling clock ticks has become\nmore or less ubiquitous in operating systems, making it an excellent candidate\nto measure overheads. A clock handler is activated once every T milliseconds by\na clock interrupt. Common values for T range between 0.5 and 20 milliseconds,\ncorresponding to interrupt frequencies of 2000 Hz and 50 Hz, respectively. The\nhandler typically assists in realizing various timing and CPU usage services, sends\nalarm signals, and assists in preempting running tasks for fair CPU sharing. By\nsimply varying the frequency by which the hardware generates an interrupt, one\ncan easily get an impression of the incurred overhead.\nTo measure the performance effects of an interrupt, a distinction is made\nbetween direct overhead and indirect overhead. The direct overhead consists of\nthe time it takes to do the actual context switch, along with the time it takes for\nthe handler to do its work and subsequently switching back to the interrupted\ntask. The indirect overhead is everything else, and is mainly caused by cache\nperturbations (to which we will return shortly). For various Intel processors,\nTsafrir [2007] found that the time to switch context is in the order of 0.5–1\nmicrosecond, and that the handler itself takes in the order of 0.5–7 microseconds\nto do its work, depending strongly on the implementation.\n(a)\n(b)\n(c)\nFigure 3.2: The organization of the cache when dealing with interrupts:\n(a) before the context switch, (b) after the context switch, and (c) after\naccessing block D. (Adapted from Liu and Solihin [2010].)\nHowever, it turns out that the direct overhead is not really that influential. In\na complimentary study, Liu and Solihin [2010] make clear that context switching\ncan greatly perturbate the cache, resulting in a loss of performance in comparison\nto the situation before an interrupt occurred. In fact, for the simple case of clock\nDS 4.01\n \n\n\n3.1. THREADS\n117\ninterrupts, Tsafrir [2007] measured an indirect overhead of approximately 80%.\nTo understand what is going on, consider the data organizations as sketched in\nFigure 3.2. Assume the cache is organized such that a least-recently used block of\ndata is removed from the cache when room is needed for a fresh data block.\nFigure 3.2(a) shows the situation before the interrupt occurs. After the inter-\nrupt has been handled, block D may have been evicted from the cache, leaving a\nhole as shown in Figure 3.2(b). Accessing block D will copy it back into the cache,\npossibly evicting block C, and so on. In other words, even a simple interrupt may\ncause a considerable, and relatively long-lasting reorganization of the cache, in\nturn, affecting the overall performance of an application.\n1 from multiprocessing import Process\n2 from time import *\n3 from random import *\n4\n5 def sleeper(name):\n6\nt = gmtime()\n7\ns = randint(1,20)\n8\ntxt = str(t.tm_min)+’:’+str(t.tm_sec)+’ ’+name+’ is going to sleep for ’+str(s)+’ seconds’\n9\nprint(txt)\n10\nsleep(s)\n11\nt = gmtime()\n12\ntxt = str(t.tm_min)+’:’+str(t.tm_sec)+’ ’+name+’ has woken up’\n13\nprint(txt)\n14\n15 if __name__ == ’__main__’:\n16\np = Process(target=sleeper, args=(’eve’,))\n17\nq = Process(target=sleeper, args=(’bob’,))\n18\np.start(); q.start()\n19\np.join(); q.join()\n(a)\n40:23 eve is going to sleep for 14 seconds\n40:23 bob is going to sleep for 4 seconds\n40:27 bob has woken up\n40:37 eve has woken up\n(b)\nFigure 3.3: (a) A simple example in which two processes are started, and\n(b) the output after a run.\nA simple example in Python\nTo make matters more concrete, let us look at a simple example in Python,\nalso to illustrate the differences between processes and threads. Consider the\ncode shown in Figure 3.3(a), which shows how we start to separate processes\n \nDS 4.01\n\n\n118\nCHAPTER 3. PROCESSES\nin Python using the multiprocessing package. The core of the example is\nformed by the function sleeping which simply puts the calling process to\nsleep for a randomly chosen number of seconds.\n1 from multiprocessing import Process\n2 from threading import Thread\n3\n4 shared_x = random.randint(10,99)\n5\n6 def sleeping(name):\n7\nglobal shared_x\n8\ns = randint(1,20)\n9\nsleep(s)\n10\nshared_x = shared_x + 1\n11\n12 def sleeper(name):\n13\nsleeplist = list()\n14\nfor i in range(3):\n15\nsubsleeper = Thread(target=sleeping, args=(name+’ ’+str(i),))\n16\nsleeplist.append(subsleeper)\n17\n18\nfor s in sleeplist: s.start()\n19\nfor s in sleeplist: s.join()\n(a)\neve sees shared x being 71\n53:21 eve 0 is going to sleep for 20 seconds\nbob sees shared x being 84\n53:21 eve 1 is going to sleep for 15 seconds\n53:21 eve 2 is going to sleep for 3 seconds\n53:21 bob 0 is going to sleep for 8 seconds\n53:21 bob 1 is going to sleep for 16 seconds\n53:21 bob 2 is going to sleep for 8 seconds\n53:24 eve 2 has woken up, seeing shared x being 72\n53:29 bob 0 has woken up, seeing shared x being 85\n53:29 bob 2 has woken up, seeing shared x being 86\n53:36 eve 1 has woken up, seeing shared x being 73\n53:37 bob 1 has woken up, seeing shared x being 87\nbob sees shared x being 87\n53:41 eve 0 has woken up, seeing shared x being 74\neve sees shared x being 74\n(b)\nFigure 3.4: (a) A multithreading example in which two processes are started,\neach with three threads, and (b) the output after a run.\nTo create two processes, we call the operation Process in lines 16 and 17,\nrespectively, to subsequently start each of them. The join operation tells the\nDS 4.01\n \n\n\n3.1. THREADS\n119\nmain process to wait until the newly created processes have finished. A possi-\nble output is shown in Figure 3.3(b), indicating the time in “minutes:seconds”\nformat when each process outputs some text.\nThe differences between threads and processes can be observed when we\nextend our example as shown in Figure 3.4 (where we have left out many\nstatements for recording time and printing text). In this case, we again start\ntwo processes, named eve and bob (the code is the same as lines 15–19 in\nFigure 3.3 and has been omitted for clarity). Each process subsequently\nstarts three threads, each, in turn, executing the function sleeping. The\nmain difference is that there is now a shared variable shared_x. (To keep\nmatters simple, we incorrectly assume that the assignment in line 10 is atomic.\nWe explain atomic operations in detail in Chapter 5). What the output in\nFigure 3.4 shows is that this is a variable shared among the threads in a single\nprocess, but not shared between the two processes eve and bob. In other words,\neach process has its own instance of shared_x.\nThe output also shows that the sleep operation works at the thread level\nas well as the process level. In this case, each thread is suspended for a few\nseconds, yet the process hosting that thread is not blocked when sleep is\ncalled. Instead, another thread is scheduled (who subsequently also calls\nsleep). How this has been implemented is transparent to the programmer.\nLikewise, it is also transparent to what extent different threads are executed\non different cores, if available, of the used CPU. If we had started 1000 threads\nper process, we would still see accurate timing. However, if we would replace\nthe call to sleep with a busy waiting loop, such as in:\nc = s * 26000000\nfor i in range(c):\nx = x + 1.0\nwe would see that the thread execution may be completely serialized per\nprocess, whereas each process would be assigned to a separate core and thus\nrun in parallel. What exactly is done, depends on the underlying operating\nsystem and the used Python runtime system. The standard implementations\nof Python assign all threads within a single process to just one core.\nThread implementation\nThreads are often provided in the form of a thread package. Such a package\ncontains operations to create and destroy threads, as well as operations on\nsynchronization variables such as mutexes and condition variables. There are\nbasically two approaches to implement a thread package. The first approach\nis to construct a thread library that is executed entirely in user space. The\nsecond approach is to have the kernel be aware of threads and schedule them.\nA user-level thread library has several advantages. First, it is cheap to\ncreate and destroy threads. Because all thread administration is kept in the\n \nDS 4.01\n\n\n120\nCHAPTER 3. PROCESSES\nuser’s address space, the price of creating a thread is primarily determined\nby the cost for allocating memory to set up a thread stack. Analogously,\ndestroying a thread mainly involves freeing memory for the stack, which is\nno longer used. Both operations are cheap.\nA second advantage of user-level threads is that switching thread context\ncan often be done in just a few instructions. Basically, only the values of\nthe CPU registers need to be stored and subsequently reloaded with the\npreviously stored values of the thread to which it is being switched. There is\nno need to change memory maps, flush the TLB, do CPU accounting, and so\non. Switching thread context is done when two threads need to synchronize,\nfor example, when entering a section of shared data. However, as discussed in\nNote 3.1, much of the overhead of context switching is caused by perturbing\nmemory caches.\nA major drawback of user-level threads comes from deploying the many-\nto-one threading model: multiple threads are mapped to a single schedulable\nentity. We already saw this with our simple multithreaded Python example\nin Figure 3.4. As a consequence, the invocation of a blocking system call\nwill immediately block the entire process to which the thread belongs, and\nthus also all the other threads in that process. As we explained, threads are\nparticularly useful to structure large applications into parts that could be\nlogically executed at the same time. In that case, blocking on I/O should not\nprevent other parts to be executed in the meantime. For such applications,\nuser-level threads are of no help.\nThese problems can be mostly circumvented by implementing threads in\nthe operating system’s kernel, leading to what is known as the one-to-one\nthreading model in which every thread is a schedulable entity. The price to\npay is that every thread operation (creation, deletion, synchronization, etc.),\nwill have to be carried out by the kernel, requiring a system call. Switching\nthread contexts may now become as expensive as switching process contexts.\nHowever, because the performance of context switching is generally dictated\nby ineffective use of memory caches, and not by the distinction between the\nmany-to-one or one-to-one threading model, many operating systems now\noffer the latter model, if only for its simplicity.\nNote 3.2 (Advanced: Many-to-many threading model)\nAn alternative to the two threading extremes is a hybrid form of user-level and\nkernel-level threads, a so-called many-to-many threading model. In the following,\nwe simplify our terminology and speak of user threads and kernel threads. A\nkernel thread runs in the context of a single process, and there can be several\nkernel threads per process. In addition to managing kernel threads, a runtime\nsystem also offers a user-level thread package, offering applications the usual\noperations for creating and destroying threads. In addition, the package provides\nfacilities for thread synchronization, such as mutexes and condition variables. The\nDS 4.01\n \n\n\n3.1. THREADS\n121\nimportant issue is that the thread package is implemented entirely in user space:\nall operations on threads are carried out without intervention of the kernel.\nThe thread package can be shared by multiple kernel threads, as shown in\nFigure 3.5. This means that each kernel thread can be running its own (user level)\nthread. Multithreaded applications are constructed by creating user and kernel\nthreads, and subsequently assigning each user thread to a kernel thread.\nThe combination of user threads and kernel threads works as follows. The\nthread package has a single routine to schedule the next thread. When creating a\nkernel thread (which is done through a system call), the kernel thread is given its\nown stack, and is instructed to execute the scheduling routine searching for a user\nthread to execute. If there are several kernel threads, then each of them executes\nthe scheduler. The thread table, which is used to keep track of the current set of\nthreads, is thus shared by the kernel threads. Protecting this table to guarantee\nmutually exclusive access is done through mutexes that are implemented entirely\nin user space. In other words, synchronization between kernel threads does not\nrequire any kernel support. A thread table is often implemented as a ready queue.\nFigure 3.5: Combining kernel-level and user-level threads.\nWhen a kernel thread finds a runnable user thread, it switches context to that\nthread. Meanwhile, other kernel threads may be looking for other runnable user\nthreads as well. If a user thread needs to block on a mutex or condition variable,\nit does the necessary administration and eventually calls the scheduling routine.\nWhen another runnable user thread has been found, a context switch is made\nto that thread. The beauty of all this is that the kernel thread executing the user\nthread need not be informed: the context switch is implemented completely in\nuser space and appears to the kernel thread as normal program code.\nNow let us see what happens when a user thread does a blocking system\ncall. In that case, execution changes from user mode to kernel mode, but still\ncontinues in the context of the current kernel thread. At the point where the\ncurrent kernel thread can no longer continue, the operating system may decide to\nswitch context to another kernel thread, which also implies that a context switch\nis made back to user mode. The selected kernel thread will simply continue where\nit had previously left off.\nThere are several advantages to using kernel threads with a user-level thread\npackage. First, creating, destroying, and synchronizing threads is relatively cheap\n \nDS 4.01\n\n\n122\nCHAPTER 3. PROCESSES\nand involves no kernel intervention at all. Second, provided that a process has\nenough kernel threads, a blocking system call will not suspend the entire process.\nThird, there is no need for an application to know about the kernel threads. All it\nsees are user threads. Fourth, kernel threads can be easily used in multiprocessing\nenvironments by executing different kernel threads on different CPUs or different\ncores. This multiprocessing can be hidden entirely from the application.\nThe approach just sketched is actually the general form of combining user\nand kernel threads. This approach has been implemented in the Go program-\nming language [Donovan and Kernighan, 2015]. The libfibre runtime system\ndescribed and evaluated by Karsten and Barghi [2020] is also exemplary for the\nmany-to-many threading model. A slightly different approach can be found in\nArachne [Qin et al., 2018]. Arachne hides the kernel threads from applications,\nbut instead assumes that an application can get full insight in the cores that have\nbeen assigned. It assigns one kernel thread per allocated core. An important\nconsequence is that Arachne does not provide support for blocking I/O calls.\nAs a final note, it is important to realize that using threads is one way\nof organizing simultaneous and concurrent executions within an application.\nIn practice, we often see that applications are constructed as a collection of\nconcurrent processes, jointly making use of the interprocess facilities offered by\nan operating system (see also [Robbins and Robbins, 2003; Stevens, 1999]). A\ngood example of this approach is the organization of the Apache Web server,\nwhich, by default, starts with a handful of processes for handling incoming\nrequests. Each process forms a single-threaded instantiation of the server, yet\nis capable of communicating with other instances through standard means.\nAs argued by Srinivasan [2010], using processes instead of threads has\nthe important advantage of separating the data space: each process works on\nits own part of data and is protected from interference from others through\nthe operating system. The advantage of this separation should not be un-\nderestimated: thread programming is considered to be notoriously difficult\nbecause the developer is fully responsible for managing concurrent access\nto shared data. Using processes, data spaces, in the end, are protected by\nhardware support. If a process attempts to access data outside its allocated\nmemory, the hardware will raise an exception, which is then further processed\nby the operating system. No such support is available for threads concurrently\noperating within the same process.\n3.1.2\nThreads in distributed systems\nAn important property of threads is that they can provide a convenient\nmeans of allowing blocking system calls without blocking the entire process\nin which the thread is running (assuming we do not have a many-to-one\nthreading model). This property makes threads particularly attractive to use\nin distributed systems, as it makes it much easier to express communication\nDS 4.01\n \n\n\n3.1. THREADS\n123\nin the form of maintaining multiple logical connections at the same time.\nWe illustrate this point by taking a closer look at multithreaded clients and\nservers, respectively.\nMultithreaded clients\nTo establish a high degree of distribution transparency, distributed systems\nthat operate in wide-area networks may need to conceal long interprocess\nmessage propagation times. The round-trip delay in a wide-area network can\neasily be in the order of hundreds of milliseconds, or sometimes even seconds.\nThe usual way to hide communication latencies is to initiate communica-\ntion and immediately proceed with something else. A typical example where\nthis happens is in Web browsers. Often, a Web document consists of an HTML\nfile containing plain text along with a collection of images, icons, etc. To fetch\neach element of a Web document, the browser has to set up a TCP/IP con-\nnection, read the incoming data, and pass it to a display component. Setting\nup a connection as well as reading incoming data are inherently blocking\noperations. When dealing with long-haul communication, we also have the\ndisadvantage that the time for each operation to complete may be long.\nA Web browser often starts with fetching the HTML page and subsequently\ndisplays it. To hide communication latencies as much as possible, some\nbrowsers start displaying data while it is still coming in. While the text is\nmade available to the user, including the facilities for scrolling and such, the\nbrowser continues with fetching other files that make up the page, such as\nthe images. The latter are displayed as they are brought in. The user need\nthus not wait until all the components of the entire page are fetched before\nthe page is made available.\nIn effect, it is seen that the Web browser is doing several tasks simulta-\nneously. As it turns out, developing the browser as a multithreaded client\nsimplifies matters considerably. As soon as the main HTML file has been\nfetched, separate threads can be activated to take care of fetching the other\nparts. Each thread sets up a separate connection to the server and pulls\nin the data. Setting up a connection and reading data from the server can\nbe programmed using the standard (blocking) system calls, assuming that\na blocking call does not suspend the entire process. As is also illustrated\nin [Stevens, 1998], the code for each thread is the same and, above all, simple.\nMeanwhile, the user notices only delays in the display of images and such,\nbut can otherwise browse through the document.\nThere is another important benefit to using multithreaded Web browsers,\nin which several connections can be opened simultaneously. In the previous\nexample, several connections were set up to the same server. If that server is\nheavily loaded, or just plain slow, no real performance improvements will be\nnoticed compared to pulling in the files that make up the page strictly one\nafter the other.\n \nDS 4.01\n\n\n124\nCHAPTER 3. PROCESSES\nHowever, often, Web servers have been replicated across multiple machines,\nwhere each server provides the same set of Web documents. The replicated\nservers are located at the same site, and are known under the same name.\nWhen a request for a Web page comes in, the request is forwarded to one of\nthe servers, often using a round-robin strategy or some other load-balancing\ntechnique. When using a multithreaded client, connections may be set up\nto different replicas, allowing data to be transferred in parallel, effectively\nestablishing that the entire Web document is fully displayed in a much shorter\ntime than with a nonreplicated server. This approach is possible only if the\nclient can handle truly parallel streams of incoming data. Threads are ideal\nfor this purpose.\nNote 3.3 (Advanced: Exploiting client-side threads for performance)\nAlthough there are obvious opportunities for using threads to reach high perfor-\nmance, it is interesting to see whether multithreading is effectively exploited. In a\nstudy to see to what extent multiple threads put a multicore processor to work,\nBlake et al. [2010] looked at the execution of various applications on modern\narchitectures. Browsers, like many other client-side applications, are interactive\ninnately, for which reason the expected processor idle time may be quite high. To\nproperly measure to what extent a multicore processor is being used, Blake et al.\nused a metric known as thread-level parallelism (TLP). Let ci denote the fraction\nof time that exactly i threads are being executed simultaneously. Thread-level\nparallelism is then defined as:\nTLP = ∑N\ni=1 i · ci\n1 −c0\nwhere N is the maximum number of threads that (can) execute at the same time.\nIn their study, a typical Web browser at that time had a TLP value between 1.5\nand 2.5, meaning that to effectively exploit parallelism, the client machine should\nhave two or three cores, or likewise, 2–3 processors.\nThese results are interesting when considering that modern Web browsers\ncreate hundreds of threads, and that tens of threads are active at the same time\n(note that an active thread is not necessarily running; it may be blocked waiting for\nan I/O request to complete). We thus see that multithreading is used to organize\nan application, but that this multithreading is not leading to dramatic performance\nimprovements through hardware exploitation. That browsers can be effectively\ndesigned for exploiting parallelism is shown, for example, by Meyerovich and\nBodik [2010]. By adapting existing algorithms, the authors manage to establish\nseveral-fold speedups.\nMultithreaded servers\nAlthough there are important benefits to multithreaded clients, the main use\nof multithreading in distributed systems is found at the server side. Practice\nDS 4.01\n \n\n\n3.1. THREADS\n125\nshows that multithreading not only simplifies server code considerably, but\nalso makes it much easier to develop servers that exploit parallelism to attain\nhigh performance, even on uniprocessor systems. However, with modern\nmulticore processors, multithreading for parallelism is an obvious path to\nfollow.\nTo understand the benefits of threads for writing server code, consider the\norganization of a file server that occasionally has to block waiting for the disk.\nThe file server normally waits for an incoming request for a file operation,\nsubsequently carries out the request, and then sends back the reply. One\npossible, and particularly popular, organization is shown in Figure 3.6. Here,\none thread, the dispatcher, reads incoming requests for a file operation. The\nrequests are sent by clients to a well-known end point for this server. After\nexamining the request, the server chooses an idle (i.e., blocked) worker thread\nand hands it the request.\nFigure 3.6: A multithreaded server organized in a dispatcher/worker model.\nThe worker proceeds by performing a blocking read on the local file system,\nwhich may cause the thread to be suspended until the data are fetched from\ndisk. If the thread is suspended, another thread is selected to be executed. For\nexample, the dispatcher may be selected to acquire more work. Alternatively,\nanother worker thread can be selected that is now ready to run.\nNow consider how the file server might have been written without threads.\nOne possibility is to have it operate as a single thread. The main loop of the\nfile server gets a request, examines it, and carries it out to completion before\ngetting the next one. While waiting for the disk, the server is idle and does\nnot process any other requests. Consequently, requests from other clients\ncannot be handled. In addition, if the file server is running on a dedicated\nmachine, as is commonly the case, the CPU is simply idle while the file server\nis waiting for the disk. The net result is that many fewer requests per time\nunit can be processed. Thus threads gain considerable performance, but each\nthread is programmed sequentially, in the usual way.\nSo far, we have seen two possible designs: a multithreaded file server\n \nDS 4.01\n\n\n126\nCHAPTER 3. PROCESSES\nand a single-threaded file server. A third alternative is to run the server as\na big single-threaded finite-state machine. When a request comes in, the\none and only thread examines it. If it can be satisfied from the in-memory\ncache, fine, but if not, the thread must access the disk. However, instead\nof issuing a blocking disk operation, the thread schedules an asynchronous\n(i.e., nonblocking) disk operation for which it will be later interrupted by the\noperating system. To make this work, the thread will record the status of the\nrequest (namely, that it has a pending disk operation), and continues to see if\nthere were any other incoming requests that require its attention.\nOnce a pending disk operation has been completed, the operating system\nwill notify the thread, who will then, in due time, look up the status of the\nassociated request and continue processing it. Eventually, a response will be\nsent to the originating client, again using a nonblocking call to send a message\nover the network.\nIn this design, the “sequential process” model that we had in the first\ntwo cases is lost. Every time the thread needs to do a blocking operation, it\nneeds to record exactly where it was in processing the request, possibly also\nstoring additional state. Once that has been done, it can start the operation\nand continue with other work. Other work means processing newly arrived\nrequests, or post-processing requests for which a previously started operation\nhas completed. Of course, if there is no work to be done, the thread may\nindeed block. In effect, we are simulating the behavior of multiple threads\nand their respective stacks the hard way. The process is being operated as\na finite-state machine that gets an event and then reacts to it, depending on\nwhat is in it.\nModel\nCharacteristics\nMultithreading\nParallelism, blocking system calls\nSingle-threaded process\nNo parallelism, blocking system calls\nFinite-state machine\nParallelism, nonblocking system calls\nFigure 3.7: Three ways to construct a server.\nIt should now be clear what threads have to offer. They make it possible to\nretain the idea of sequential processes that make blocking system calls and still\nachieve parallelism. Blocking system calls make programming easier as they\nappear as just normal procedure calls. In addition, multiple threads allow for\nparallelism and thus performance improvement. The single-threaded server\nretains the ease and simplicity of blocking system calls, but may severely\nhinder performance in terms of number of requests that can be handled\nper time unit. The finite-state machine approach achieves high performance\nthrough parallelism, but uses nonblocking calls, which are generally hard to\nprogram and thus to maintain. These models are summarized in Figure 3.7.\nDS 4.01\n \n",
      "page_number": 125
    },
    {
      "number": 15,
      "title": "Segment 15 (pages 139-149)",
      "start_page": 139,
      "end_page": 149,
      "detection_method": "topic_boundary",
      "content": "3.2. VIRTUALIZATION\n127\nAgain, note that instead of using threads, we can also use multiple pro-\ncesses to organize a server (leading to the situation that we actually have a\nmultiprocess server). The advantage is that the operating system can offer\nmore protection against accidental access to shared data. However, if pro-\ncesses need to communicate a lot, we may see a noticeable adverse effect on\nperformance in comparison to using threads.\n3.2\nVirtualization\nThreads and processes can be seen as a way to do more things at the same\ntime. In effect, they allow us to build (pieces of) programs that appear to be\nexecuted simultaneously. On a single-processor (single core) computer, this\nsimultaneous execution is, of course, an illusion. As there is only a single\nCPU, only an instruction from a single thread or process will be executed at\na time. By rapidly switching between threads and processes, the illusion of\nparallelism is created.\nThis separation between having a single CPU and being able to pretend\nthere are more can be extended to other resources as well, leading to what\nis known as resource virtualization. This virtualization has been applied for\nmany decades, but has received renewed interest as (distributed) computer\nsystems have become more commonplace and complex, leading to the sit-\nuation that application software is mostly always outliving its underlying\nsystems software and hardware.\n3.2.1\nPrinciple of virtualization\nIn practice, every (distributed) computer system offers a programming inter-\nface to higher-level software, as shown in Figure 3.8(a). There are many types\nof interfaces, ranging from the basic instruction set as offered by a CPU to the\nvast collection of application programming interfaces that are shipped with\nmany current middleware systems. In its essence, virtualization deals with\nextending or replacing an existing interface to mimic the behavior of another\nsystem, as shown in Figure 3.8(b). We will come to discuss technical details\non virtualization shortly, but let us first concentrate on why virtualization is\nimportant.\nVirtualization and distributed systems\nOne of the most important reasons for introducing virtualization, back in the\n1970s, was to allow legacy software to run on expensive mainframe hardware.\nThe software not only included various applications, but in fact also the\noperating systems they were developed for. This approach toward supporting\nlegacy software has been successfully applied on the IBM 370 mainframes (and\n \nDS 4.01\n\n\n128\nCHAPTER 3. PROCESSES\n(a)\n(b)\nFigure 3.8: (a) General organization between a program, interface, and system.\n(b) General organization of virtualizing system A on top of B.\ntheir successors) that offered a virtual machine to which different operating\nsystems had been ported.\nAs hardware became cheaper, computers became more powerful, and the\nnumber of different operating system flavors was reducing, virtualization\nbecame less of an issue. However, matters have changed again since the\nlate 1990s. First, while hardware and low-level systems software change\nreasonably fast, software at higher levels of abstraction (e.g., middleware and\napplications), are often much more stable. In other words, we are facing\nthe situation that legacy software cannot be maintained in the same pace as\nthe platforms it relies on. Virtualization can help here by porting the legacy\ninterfaces to the new platforms, and thus immediately opening up the latter\nfor large classes of existing programs.\nEqually important is the fact that networking has become completely\npervasive. It is hard to imagine that a modern computer is not connected to\na network. In practice, this connectivity requires that system administrators\nmaintain a large and heterogeneous collection of server computers, each one\nrunning very different applications, which can be accessed by clients. At\nthe same time, the various resources should be easily accessible to these\napplications. Virtualization can help a lot: the diversity of platforms and\nmachines can be reduced by essentially letting each application run on its\nown virtual machine, possibly including the related libraries and operating\nsystem, which, in turn, run on a common platform.\nThis last type of virtualization provides a high degree of portability and\nflexibility. For example, in order to realize content delivery networks that\ncan easily support replication of dynamic content, Awadallah and Rosenblum\n[2002] have argued that management becomes much easier if edge servers\nwould support virtualization, allowing a complete site, including its environ-\nDS 4.01\n \n\n\n3.2. VIRTUALIZATION\n129\nment, to be dynamically copied. These arguments are still valid, and indeed,\nportability is perhaps the most important reason why virtualization plays\nsuch a key role in many distributed systems.\nFinally, an important reason for virtualization is that it provides an ad-\nditional means of isolating code, which is particularly relevant in the case\nof cloud computing. At the same time, virtualization also introduces new\nsecurity threats.\nNote 3.4 (Discussion: Stable software?)\nAlthough there is indeed a lot of legacy software that can benefit from stable\ninterfaces to rapidly changing underlying hardware, it is a mistake to believe that\nthe software for widely available services hardly changes. With the increasing\nshift toward server-side computing in the form of Software-as-a-Service (SaaS),\nmuch software can be maintained for a relatively homogeneous platform, owned\nentirely by the organization offering the associated service. As a consequence,\nmaintaining software products can be much easier, as there is much lesser need\nto distribute changes to potentially millions of customers. In fact, changes may\nrapidly succeed each other following changes in available hardware and platform,\nbut without any client actually noticing downtimes [Barroso et al., 2018].\nTypes of virtualization\nThere are many ways in which virtualization can be realized. An overview\nof these various approaches is described by Smith and Nair [2005a]. A more\nrecent account is described by Bugnion et al. [2017], which provides many\ntechnical details on the realization of various forms of virtualization. To\nunderstand the differences in virtualization, it is important to realize that\ncomputer systems generally offer four different types of interfaces, at three\ndifferent levels:\n1. An interface between the hardware and software, referred to as the in-\nstruction set architecture (ISA), forming the set of machine instructions.\nThis set is divided into two subsets:\n• Privileged instructions, which are allowed to be executed only by\nthe operating system.\n• General instructions, which can be executed by any program.\n2. An interface consisting of system calls as offered by an operating system.\n3. An interface consisting of library calls, generally forming what is known\nas an application programming interface (API). Often, the aforemen-\ntioned system calls are hidden by an API.\nThese different types are shown in Figure 3.9. The essence of virtualization is\nto mimic the behavior of these interfaces.\n \nDS 4.01\n\n\n130\nCHAPTER 3. PROCESSES\nFigure 3.9: Various interfaces offered by computer systems.\nVirtualization can take place in two different ways. First, we can build a\nruntime system that essentially provides an abstract instruction set that is to\nbe used for executing applications. Instructions can be interpreted (as is the\ncase for the Java runtime environment), but could also be emulated, as is done\nfor running Windows applications on Unix platforms. Note that in the latter\ncase, the emulator will also have to mimic the behavior of system calls, which\nhas proven to be generally far from trivial. This type of virtualization, shown\nin Figure 3.10(a), leads to what Smith and Nair [2005a] call a process virtual\nmachine, stressing that virtualization is only for a single process.\n(a)\n(b)\n(c)\nFigure 3.10: (a) A process virtual machine. (b) A native virtual machine\nmonitor. (c) A hosted virtual machine monitor.\nAn alternative approach toward virtualization, shown in Figure 3.10(b),\nis to provide a system that is implemented as a layer shielding the original\nhardware, but offering the complete instruction set of that same (or other\nhardware) as an interface. This leads to what is known as a native virtual\nmachine monitor. It is called native because it is implemented directly on\ntop of the underlying hardware. Note that the interface offered by a virtual\nmachine monitor can be offered simultaneously to different programs. As\nDS 4.01\n \n\n\n3.2. VIRTUALIZATION\n131\na result, it is now possible to have multiple, and different guest operating\nsystems run independently and concurrently on the same platform.\nA native virtual machine monitor will have to provide and regulate access\nto various resources, like external storage and networks. Like any operating\nsystem, this implies that it will have to implement device drivers for those\nresources. Rather than doing all this effort anew, a hosted virtual machine\nmonitor will run on top of a trusted host operating system as shown in Fig-\nure 3.10(c). In this case, the virtual machine monitor can make use of existing\nfacilities provided by that host operating system. It will generally have to be\ngiven special privileges instead of running as a user-level application. Using\na hosted virtual machine monitor is highly popular in modern distributed\nsystems such as data centers and clouds.\nAs argued by Rosenblum and Garfinkel [2005], virtual machines are impor-\ntant in the context of reliability and security for (distributed) systems. As they\nallow for the isolation of a complete application and its environment, a failure\ncaused by an error or security attack need no longer affect a complete machine.\nIn addition, as we also mentioned before, portability is greatly improved as\nvirtual machines provide a further decoupling between hardware and soft-\nware, allowing a complete environment to be moved from one machine to\nanother. We return to migration in Section 3.5.\nNote 3.5 (Advanced: On the performance of virtual machines)\nVirtual machines perform surprisingly well. In fact, many studies show that\nmodern virtual machines perform close to running applications directly on the\nhost operating system. Let us take a closer look at what is going under the hood\nof virtual machines. A detailed and comprehensive account of virtual machines is\nprovided by Smith and Nair [2005b].\nPart of the answer to performance issues is shown in Figure 3.11, which forms\nan extension of Figure 3.10(c): a large part of the code constituting a virtual\nmachine monitor, guest operating system, and application is running natively on\nthe underlying hardware. In particular, all general (i.e., unprivileged) machine\ninstructions are directly executed by the underlying machine.\nThis approach is not new and is founded on research by Popek and Goldberg\n[1974] who formalized the requirements for the efficient execution of virtual\nmachines.\nIn a nutshell, Popek and Goldberg assumed that the underlying\nmachine provided at least two modes of operation (system and user mode), that\na subset of the instructions could be executed only in system mode, and that\nmemory addressing was relative (i.e., a physical address was obtained by adding\na relative address to an offset found in a relocation register). A distinction was\nfurther made between two types of instructions. A privileged instruction is an\ninstruction that is characterized by the fact that if and only if executed in user\nmode, it causes a trap to the operating system. Nonprivileged instructions are\nall other instructions.\n \nDS 4.01\n\n\n132\nCHAPTER 3. PROCESSES\nFigure 3.11: Applications, guest operating system, virtual machine moni-\ntor, and host operating system on a single hardware platform.\nGiven these formal assumptions, Popek and Goldberg defined two classes\nof special instructions. A control-sensitive instruction is one that may affect\nthe configuration of a machine. A typical example is an instruction that affects\nthe memory layout, for example, by changing the memory offset as stored in a\nrelocation register. Another example is instructions that affect the interrupt table,\ncontaining pointers to interrupt handlers.\nA behavior-sensitive instruction is one whose effect is partially determined\nby the context in which it is executed. For example, Intel x86 processors have\ninstructions that may, or may not, affect certain registers depending on whether\nthat instruction is executed in system mode or user mode. An example given\nin [Smith and Nair, 2005b] is that of the POPF instruction, which may set an\ninterrupt-enabled flag, but only when executed in system mode.\nWe now have the following important result:\nFor any conventional computer, a virtual machine monitor may be con-\nstructed if the set of sensitive instructions for that computer is a subset of\nthe set of privileged instructions.\nWhat this says is that as long as sensitive instructions are caught when executed\nin user mode, we can safely run all nonsensitive instructions natively on the\nunderlying hardware. This also means that when designing instruction sets, if\nwe take care that the above requirement is met, we will not be unnecessarily\nobstructing efficient virtualization of that instruction set.\nUnfortunately, not all instruction sets have privileged-only sensitive instruc-\ntions, including perhaps the most popular one, namely the Intel x86 instruction set.\nAs it turns out, this set has 17 sensitive instructions that are not privileged [Robin\nand Irvine, 2000]. In other words, each of these instructions can be executed in\nuser mode without causing a trap to the operating system, yet affect the way\nthat the operating system is managing its resources. In these cases, there are\nessentially two solutions.\nThe first solution is to emulate all instructions. Of course, this would have\na serious adverse effect on performance. To circumvent problems, an approach\nimplemented in VMWare [Sugerman et al., 2001], is to scan the executable and\nto insert code around the nonprivileged sensitive instructions to divert control\nDS 4.01\n \n\n\n3.2. VIRTUALIZATION\n133\nto the virtual machine monitor. There, appropriate emulation will take place, for\nexample, by considering the context in which the instruction was to be executed.\nThe effect is that full virtualization can take place, meaning that execution can\ntake place without changing the guest operating system, nor the application itself.\nAn alternative solution is to apply paravirtualization, which requires the\nguest operating system to be modified. In particular, the guest operating system is\nmodified such that all side effects of running nonprivileged sensitive instructions\nin user mode, which would normally be executed in system mode, are dealt\nwith. For example, code can be rewritten such that these instructions simply no\nlonger occur, or if they do, that their semantics are the same regardless whether\nbeing executed in user or system mode. Paravirtualization has been adopted by\nXen [Barham et al., 2003; Chisnall, 2007].\n3.2.2\nContainers\nVirtual machines offer a means to run applications relying on a specific\noperating environment, including its instruction set and operating system,\nto run independently across different platforms. As we have seen, this may\nrequire significant efforts to ensure portability and performance. However,\noften we see that applications are relatively stable when it comes to the used\ninstruction set and operating system, yet do rely on specific libraries and other\nsupport software. In these cases, what we really want is to allow different\napplications to run side-by-side, yet each uses its own environment of support\nsoftware without even noticing that there be other applications with a different\nenvironment. This is where containers come into the game.1\nA container can be thought of a collection of binaries (also called images)\nthat jointly constitute the software environment for running applications. The\neasiest way to think of a container is what a user would get to see when\nlogging into, for example, a Unix system: it will consist of several standard\ndirectories containing executable programs, libraries, documentation, etc. A\nnaive implementation of a container would be to copy an entire environment\nfor a specific use case and install it as a subdirectory of, say, the root file\nsystem. Using a command such as chroot, the user would then be diverted to\nthat subdirectory and run various applications, with this subdirectory now\nacting as the root. An application would see exactly the libraries and other\ndependencies it needed, while applications in other containers would have\ntheir own view on what the operating system is offering. In this sense, a\ncontainer effectively virtualizes the software environment for an application.\nHowever, this naive implementation is certainly not enough from a virtual-\nization perspective. For one, applications and processes operating in different\n1The material in this section has been inspired by Julia Evans’s wonderful material at\nwizardzines.com.\n \nDS 4.01\n\n\n134\nCHAPTER 3. PROCESSES\ncontainers need to be isolated from each other. Likewise, simply copying an\nentire environment is not very efficient, certainly not because we may expect\nthat many libraries and such are the same across different containers. Finally,\nit is important that an operating system hosting containers has some control\nover the usage of its own resources. All of these aspects are handled in Unix\nenvironments (i.e., notably Linux) through three important mechanisms:\n• Namespaces, by which a collection of processes associated with a con-\ntainer is given their own view of identifiers and such, independent of\nother containers.\n• Union file system, which allows to, literally, combine several file systems\ninto a layered fashion with only the highest layer allowing for write\noperations (and the one being part of a container).\n• Control groups, or simply cgroups, by which resource restrictions can\nbe imposed upon a collection of processes.\nLet us look a bit deeper into each of these mechanisms. Namespaces are\nnecessary for giving a process running inside a container the illusion that it is\non its own. As such, namespaces are important for isolating containers from\neach other. Perhaps the one most illustrative is setting the PID namespace.\nAs every machine has only a single init process (with PID equal to 1), every\ncontainer should see its own “init” process. This is established through the\nUnix unshare command:\nunshare --pid --fork --mount-proc bash\nwill bring the calling process into a new shell in which the command ps -ef\nyields:\nUID\nPID\nPPID\nC STIME TTY\nTIME CMD\nroot\n1\n0\n0 06:27 pts/0\n00:00:00 bash\nroot\n2\n1\n0 06:27 pts/0\n00:00:00 ps -ef\nIndeed, we see that there now seems to be a new collection of processes with\njust one having PID equal to 1. All other processes have become invisible\nwhen working from this new shell.\nAnother important mechanism is efficient sharing of existing file systems.\nMany containers will be based on a common instance of an operating system,\nsay Ubuntu 20.4. Instead of copying that entire environment and installing it\nas a subdirectory as explained above, we can use it as a base layer and stack\nother parts on top of it. For example, we may decide to replace the entire\ncollection of subdirectories that constitute PHP7.4 for an older version by\nsimply stacking those directories on top the ones for version 7.4. The result is\nthat a PHP application will be using the older version. Note that this approach\nis very similar to mounting a file system at a directory dir. Anything that was\nDS 4.01\n \n\n\n3.2. VIRTUALIZATION\n135\ncontained in dir will no longer be visible until the file system is unmounted\nagain. Indeed, taking the union of file systems is done through successive\ncalls to the mount system call, with each layer being mounted in read-only\nmode. Only the top layer can be written to, and will need to be explicitly\nsaved when a running container finishes.\nFinally, to control what a container can actually use, Unix systems offer\ncgroups. In essence, when creating a control group, the collection of processes\nrunning in that group may be restricted to the amount of main memory that\nthey can use, the priority when it comes to using the CPU, etc. In this way,\nthe hosting operating system can prevent that a single container is using too\nmuch of its resources, preventing perhaps other containers to do their work.\nThere are many other things related to isolate containers and properly\nrestrict what processes can do within a container. In the end, a container can\nbe thought of an archive of files that are placed somewhere in a filesystem,\ntogether with a specific stack of common, shared, existing read-only subdi-\nrectories. Processes running inside the context of a container are presented\nwith a view that their context is the only one (through the use of namespaces)\nand they have certain abilities when it comes tot using resources (through\ncgroups, but also restrictions when it comes to, for example, system calls).\nThis view is summarized in Figure 3.12. Besides the material from Julia Evans\nat wizardzines.com, the interested reader is referred to [Pahl et al., 2019] for\nan overview of container technologies.\nFigure 3.12: The organization of a container within a hosting environment.\nNote 3.6 (Example: PlanetLab)\nThere are many examples of container technologies, yet at this point it is interesting\nto look at a specific case where the technology was used for developing a wide-\narea cluster of computers, even before it became popular in the context of cloud\n \nDS 4.01\n\n\n136\nCHAPTER 3. PROCESSES\ncomputing. PlanetLab was a collaborative distributed system in which different\norganizations each donated one or more computers, adding up to a total of\nhundreds of nodes. Together, these computers formed a 1-tier server cluster, where\naccess, processing, and storage could all take place on each node individually.\nManagement of PlanetLab was by necessity almost entirely distributed. The\nproject closed down in 2020.\nGeneral organization\nIn PlanetLab, a participating organization donated one\nor more nodes (i.e., computers) that were subsequently shared among all Plan-\netLab users. Each node was organized as shown in Figure 3.13. There are two\nimportant components [Bavier et al., 2004; Peterson et al., 2006]. The first one\nis the virtual machine monitor (VMM), which is an enhanced Linux operating\nsystem, essentially one capable of supporting containers along the lines sketched\nabove. The enhancements mainly comprise adjustments for supporting the second\ncomponent, namely (Linux) Vservers. A Vserver is essentially a container in\nexecution.\nFigure 3.13: The basic organization of a PlanetLab node.\nThe Linux VMM ensured that Vservers were separated: processes in different\nVservers are executed concurrently and independently, each making use only of\nthe software packages and programs available in their own environment. The\nisolation between processes in different Vservers is strict. For example, two\nprocesses in different Vservers could have the same user ID, but this did not imply\nthat they would stem from the same user. This separation considerably eased\nsupporting users from different organizations that wanted to use PlanetLab as,\nfor example, a testbed to experiment with entirely different distributed systems\nand applications. Note that this separation is precisely the one that is realized\nthrough the unshare command.\nTo support such experimentation, PlanetLab used slices, each slice being\na set of Vservers, each Vserver running on a different node, as illustrated in\nFigure 3.14. A slice can thus be thought of as a virtual server cluster, implemented\nby a collection of containers connected through a wide-area network.\nDS 4.01\n \n\n\n3.2. VIRTUALIZATION\n137\nCentral to managing PlanetLab resources was the node manager. Each node\nhad such a manager, implemented by a separate Vserver, whose only task was to\ncreate other Vservers on the node it managed and to control resource allocation.\nTo create a new slice, each node would also run a slice creation service (SCS),\nwhich, in turn, could contact the node manager requesting it to create a Vserver\nand to allocate resources. The node manager itself could not be contacted directly\nover a network, allowing it to concentrate only on local resource management. In\nturn, the SCS would not accept slice-creation requests from just anybody. Only\nspecific slice authorities were eligible for requesting the creation of a slice. Each\nslice authority would have access rights to a collection of nodes. The simplest\nmodel was that there is only a single, centralized slice authority that is allowed\nto request slice creation on all nodes. In practice, we saw that this slice authority\nwas the one used to get a user up-and-running on PlanetLab.\nFigure 3.14: The principle of a PlanetLab slice, showing sets of associated\nVservers across different nodes.\nKeeping track of resources was done by a resource specification, or rspec for\nshort. An rspec specified a time interval during which certain resources had been\nallocated. Resources include disk space, file descriptors, inbound and outbound\nnetwork bandwidth, transport-level end points, main memory, and CPU usage.\nAn rspec was identified through a globally unique 128-bit identifier known as a\nresource capability (rcap). Given an rcap, the node manager could look up the\nassociated rspec in a local table.\nResources were bound to slices. In other words, to make use of resources, it\nwas necessary to create a slice. Each slice was associated with a service provider,\nwhich can best be seen as an entity having an account on PlanetLab. Every slice\ncould then be identified by a (principal_id, slice_tag) pair, where the principal_id\nidentified the provider and slice_tag being an identifier chosen by the provider.\nVservers\nLet us now turn our attention to PlanetLab’s Vservers, which have\nbeen described and evaluated by Soltesz et al. [2007]. A Vserver was organized\nas a container. The primary task of a Vserver was therefore to merely support a\ngroup of processes and keep that group isolated from processes running under\nthe jurisdiction of another Vserver.\nAn important advantage of the container-based approach toward virtualiza-\ntion, in comparison to running separate guest operating systems, is that resource\nallocation could generally be much simpler. In particular, it was possible to\noverbook resources by allowing for dynamic resource allocation, just as is done\n \nDS 4.01\n",
      "page_number": 139
    },
    {
      "number": 16,
      "title": "Segment 16 (pages 150-157)",
      "start_page": 150,
      "end_page": 157,
      "detection_method": "topic_boundary",
      "content": "138\nCHAPTER 3. PROCESSES\nwith allocating resources to normal processes. Normally, when using a guest\noperating system, the guest will have to be allocated a fixed number of resources\nin advance (notably main memory). When considering that the nodes provided\nby participating PlanetLab organizations were required to have only a few GByte\nof main memory, it is not hard to imagine that memory would be a scarce re-\nsource. It was therefore necessary to dynamically allocate memory to allow tens\nof containers to be running at the same time on a single node. Vservers were\nideal for this type of resource management; operating systems are much harder\nto support in such cases. Of course, this could not prevent a Vserver from using\ntoo much memory on a busy node. The PlanetLab policy in that case was simple:\nthe Vserver, hogging memory when swap space was almost filled, was reset.\nPlanetLab status\nAlthough the official PlanetLab closed down in 2020, a similar\nsystem is running worldwide as EdgeNet. Not surprisingly, where Vservers were\ncontainers avant-la-lettre, that technology has been replaced in EdgeNet by modern\ncontainer technology, namely Docker in combination with Kubernetes.\n3.2.3\nComparing virtual machines and containers\nEver since containers became popular, mainly caused by their introduction\nthrough Docker, an oftentimes heated debate has been going on what is better:\nvirtual machines or containers? This debate has been hindered through the\nimproper use of terminology, such as lightweight containers versus heavyweight\nvirtual machines, immediately leading to often unsubstantiated performance\nstatements (suggesting that heavyweight means slow). However, life is not so\nsimple and understanding the technology of virtual machines as well as those\nof containers can help in making better judgments on when to use which\ntechnology. In this section, let us take a closer look at one specific, important\naspect: performance. We return to portability later when discussing code\nmigration.\nMeasuring the performance of any system requires looking at a multitude\nof criteria. Obvious ones include CPU and memory usage. Likewise, various\nI/O measurements are needed to get a good insight into how well a system\nis performing, in particular accessing disks and network I/O. On top of\nthis, we need to ask ourselves how measurements are carried out. In other\nwords, which workloads or benchmarks are used to evaluate and compare\nthe performing systems.\nA systematic study on comparing Linux containers (LXC) against Linux\nvirtual machines (KVM) was conducted by Sharma et al. [2016]. If we just look\nat a baseline comparison in which an application is running either within a\ncontainer or on top of a virtual machine, differences can be observed in favor\nof containers, yet these differences are not that big, except when it comes to\nI/O. In that case, we see that virtual machines perform significantly less than\nDS 4.01\n \n\n\n3.2. VIRTUALIZATION\n139\ncontainers. This should not come as a surprise, as notably with traditional I/O,\nthe operating system plays a crucial role: it has to execute many privileged\ninstructions.\nNevertheless, even the obvious may come with surprises. In a more recent\nstudy on comparing different container technologies with virtual-machine\napproaches, van Rijn and Rellermeyer [2021] demonstrate that the differences\nbetween the two may often be close to negligible, even when looking at disk\nand network I/O. There are several reasons for this small difference, but\none is that the host operating system caches results in main memory. In\nother words, when actually performing I/O operations, many subsequent\noperations are performed on in-memory data instead of data that is stored\non disk. This makes benchmarking more difficult, yet also reflects realistic\napplication-driven behavior. Furthermore, when running actual application-\nlevel benchmarks, such as those available for mysql, differences may exist, but\ncan be small. Nevertheless, depending on the actual I/O behavior, the overall\nconclusion is that virtual machines do impose more overhead in comparison\nto containers.\nOf course, it is more natural that several applications run side-by-side. The\nquestion then is to what extent the performance of one application influences\nthat of another. In effect, this aspect boils down to the question how well\nscheduling resources among competitors actually is. In this case, the general\ntrend is that containerization has more difficulty isolating independent appli-\ncations and that scheduling for CPU usage as well as for disk performance is\nhandled better through virtual machines.\nWhat van Rijn and Rellermeyer [2021] and other recent studies show is\nthat over the years many improvements have been made and that there is\nno real need for virtualization techniques to perform significantly slower in\ncomparison to running applications directly on top of the hosting operating\nsystem.\n3.2.4\nApplication of virtual machines to distributed systems\nFrom the perspective of distributed systems, the most important applica-\ntion of virtualization lies in cloud computing. As we already mentioned in\nSection 1.3.1, cloud providers offer roughly three different types of services:\n• Infrastructure-as-a-Service (IaaS) covering the basic infrastructure\n• Platform-as-a-Service (PaaS) covering system-level services\n• Software-as-a-Service (SaaS) containing actual applications\nVirtualization plays a key role in IaaS. Instead of renting out a physical\nmachine, a cloud provider will rent out a virtual machine (monitor) that\nmay, or may not, be sharing a physical machine with other customers. The\nbeauty of virtualization is that it allows for almost complete isolation between\n \nDS 4.01\n\n\n140\nCHAPTER 3. PROCESSES\ncustomers, who will indeed have the illusion that they have just rented a\ndedicated physical machine. Isolation is, however, never complete, if only\nfor the fact that the actual physical resources are shared, in turn leading to\nobservable lower performance.\nTo make matters concrete, let us consider the Amazon Elastic Compute\nCloud, or simply EC2. EC2 allows one to create an environment consisting\nof several networked virtual servers, thus jointly forming the basis of a\ndistributed system.\nTo make life easy, there is a (large) number of pre-\nconfigured machine images available, referred to as Amazon Machine Images,\nor simply AMIs. An AMI is an installable software package consisting of an\noperating-system kernel along with several services. An example of a simple,\nbasic AMI is a LAMP image, consisting of a Linux kernel, the Apache Web\nserver, a MySQL database system, and PHP libraries. More elaborate images\ncontaining additional software are also available, as well as images based on\nother Unix kernels or Windows. In this sense, an AMI is essentially the same\nas a boot disk (although there are a few important differences, to which we\nreturn shortly).\nAn EC2 customer needs to select an AMI, possibly after adapting or\nconfiguring one. An AMI can then be launched, resulting in what is called an\nEC2 instance: the actual virtual machine that can be used to host a customer’s\napplications. An important issue is that a customer will hardly ever know\nexactly where an instance is actually being executed. Obviously, it is running\non a single physical machine, but where that machine is located remains\nhidden. The closest one can get to pinpoint the location where an instance\nshould run is by selecting one of a few regions provided by Amazon (US,\nSouth America, Europe, Asia).\nTo communicate, each instance obtains two IP addresses: a private one that\ncan be used for internal communication between different instances, making\nuse of EC2’s internal networking facilities, and a public IP address allowing\nany Internet clients to contact an instance. The public address is mapped to\nthe private one using standard network-address translation (NAT) technology.\nA simple way to manage an instance is to make use of an SSH connection, for\nwhich Amazon provides the means for generating the appropriate keys.\nThe EC2 environment in which an instance is executed provides different\nlevels of the following services:\n• CPU: allows selecting the number and type of core, including GPUs\n• Memory: defines how much main memory is allocated to an instance\n• Storage: defines how much local storage is allocated\n• Platform: distinguishes between 32-bit or 64-bit architectures\n• Networking: sets the bandwidth capacity that can be used\nDS 4.01\n \n\n\n3.3. CLIENTS\n141\nIn addition, extra resources can be requested, such as an additional networking\ninterface. The local storage that comes with an instance is transient: when\nthe instance stops, all the data stored locally is lost. To prevent data loss, a\ncustomer will need to explicitly save data to a persistent store, for example,\nby making use of Amazon’s Simple Storage Service (S3). An alternative is to\nattach a storage device that is mapped to Amazon’s Elastic Block Store (EBS).\nAgain, this is yet another service, but one that can be used in the form of a\nvirtual block device that is simply mounted as one would mount an additional\nhard disk. When an instance is stopped, all data that was stored on EBS will\npersist. And just as one would expect, an EBS device can be (re)mounted to\nany other instance as well.\nIt should be clear by now that, without having gone into any significant\nlevel of detail, the IaaS as offered by EC2 allows a customer to create a (po-\ntentially large) number of virtual machines, each configured with resources\nas needed, and capable of exchanging messages through an IP network. In\naddition, these virtual machines can be accessed from anywhere over the\nInternet (provided a client has the proper credentials). As such, Amazon\nEC2, like many other IaaS providers, offers the means to configure a com-\nplete distributed system consisting of networked virtual servers and running\ncustomer-supplied distributed applications. At the same time, those customers\nwill not need to maintain any physical machine, which by itself is often al-\nready a huge gain, as we will encounter at several occasions throughout this\ntext. One can indeed argue that virtualization lies at the core of modern cloud\ncomputing.\n3.3\nClients\nIn the previous chapters we discussed the client-server model, the roles of\nclients and servers, and the ways they interact. Let us now take a closer look\nat the anatomy of clients and servers, respectively. We start in this section\nwith a discussion of clients. Servers are discussed in the next section.\n3.3.1\nNetworked user interfaces\nA major task of client machines is to provide the means for users to interact\nwith remote servers. There are roughly two ways in which this interaction can\nbe supported. First, for each remote service, the client machine will have a\nseparate counterpart that can contact the service over the network. A typical\nexample is a calendar running on a user’s smartphone that needs to synchro-\nnize with a remote, possibly shared calendar. In this case, an application-level\nprotocol will handle the synchronization, as shown in Figure 3.15(a).\nA second solution is to provide direct access to remote services by offer-\ning only a convenient user interface. Effectively, this means that the client\nmachine is used only as a terminal with no need for local storage, leading\n \nDS 4.01\n\n\n142\nCHAPTER 3. PROCESSES\nto an application-neutral solution as shown in Figure 3.15(b). In the case of\nnetworked user interfaces, everything is processed and stored at the server.\nThis thin-client approach has received much attention with the increase in\nInternet connectivity and the use of mobile devices. Thin-client solutions are\nalso popular as they ease the task of system management.\n(a)\n(b)\nFigure 3.15: (a) A networked application with its own protocol. (b) A general\nsolution to allow access to remote applications.\nExample: The X window system\nPerhaps one of the oldest and still widely used networked user interfaces is\nthe X Window System. The X Window System, generally referred to simply as\nX, is used to control bit-mapped terminals, which include a monitor, keyboard,\nand a pointing device such as a mouse.\nNext to supporting traditional\nterminals as can be found with desktop computers and workstations, X also\nsupports modern devices such a touchscreens on tablets and smartphones. In\na sense, X can be viewed as that part of an operating system that controls the\nterminal. The heart of the system is formed by what we shall call the X kernel.\nIt contains all the terminal-specific device drivers, and as such, is generally\nhighly hardware dependent.\nThe X kernel offers a relatively low-level interface for controlling the\nscreen, but also for capturing events from the keyboard and mouse. This\nDS 4.01\n \n\n\n3.3. CLIENTS\n143\ninterface is made available to applications as a library called Xlib. Its organi-\nzation is shown in Figure 3.16. Note that Xlib is hardly ever used directly by\napplications, which instead deploy toolkits implemented on top of Xlib.\nFigure 3.16: The basic organization of the X Window System.\nThe interesting aspect of X is that the X kernel and the X applications need\nnot necessarily reside on the same machine. In particular, X provides the X\nprotocol, which is an application-level communication protocol by which an\ninstance of Xlib can exchange data and events with an X kernel. For example,\nXlib can send requests to the X kernel for creating or killing a window, setting\ncolors, and defining the type of cursor to display, among many other requests.\nIn turn, the X kernel will react to local events such as keyboard and mouse\ninput by sending event packets back to Xlib.\nSeveral applications can communicate at the same time with the X kernel.\nThere is one specific application that is given special rights, known as the\nwindow manager. This application can dictate the “look and feel” of the\ndisplay as it appears to the user. For example, the window manager can\nprescribe how each window is decorated with extra buttons, how windows\nare to be placed on the display, and so on. Other applications will have to\nadhere to these rules. In practice, this means that much of the interaction\nbetween an application and an X terminal is redirected through a window\nmanager.\nIt is interesting to note how the X window system actually fits into client-\nserver computing. From what we have described so far, it should be clear\nthat the X kernel receives requests to manipulate the display. It gets these\nrequests from (possibly remote) applications. In this sense, the X kernel acts\nas a server, while the applications play the role of clients. This terminology\nhas been adopted by X, and although strictly speaking it is correct, it can\neasily lead to confusion.\n \nDS 4.01\n\n\n144\nCHAPTER 3. PROCESSES\nThin-client network computing\nObviously, applications manipulate a display using the specific display com-\nmands as offered by X. These commands are generally sent over the network\nwhere they are subsequently executed by the X kernel. By its nature, ap-\nplications written for X should preferably separate application logic from\nuser-interface commands. Unfortunately, this is often not the case. As re-\nported by Lai and Nieh [2002] it turns out that much of the application logic\nand user interaction are tightly coupled, meaning that an application will send\nmany requests to the X kernel for which it will expect a response before being\nable to make a next step. This synchronous behavior may adversely affect\nperformance when operating over a wide-area network with long latencies.\nThere are several solutions to this problem. One is to re-engineer the\nimplementation of the X protocol, as is done with NX [Pinzari, 2003]. An\nimportant part of this work concentrates on bandwidth reduction by reducing\nthe size of X messages. To this end, messages are considered to consist of\na fixed part, which is treated as an identifier, and a variable part. Often,\nmultiple messages will have the same identifier, in which case they will often\ncontain similar data. This property can be used to send only the differences\nbetween messages having the same identifier. By having the sender and\nreceiver maintain identifiers, decoding at the receiver can be readily applied.\nBandwidth reductions up to a factor 1000 have been reported, which allows X\nto also run through low-bandwidth links of only 9600 kbps.\nAs an alternative to using X, researchers and practitioners have also sought\nto let an application completely control the remote display, that is, up to the\npixel level. This approach is also referred to as controlling a remote desktop.\nChanges in the bitmap are then sent over the network to the display, where\nthey are immediately transferred to the local frame buffer. A well-known\nexample of this approach is Virtual Network Computing (VNC) [Richardson\net al., 1998], which has been around ever since the late 1990s. Obviously, letting\nthe application control the display requires sophisticated encoding techniques\nto prevent bandwidth availability to become a problem. For example, consider\ndisplaying a video stream at 30 frames per second on a simple 320 × 240\nscreen. If each pixel is encoded by 24 bits, then without an efficient encoding\nscheme, we would need a bandwidth of approximately 53 Mbps. In practice,\nvarious encoding techniques are used, yet choosing the best one is generally\napplication dependent.\n3.3.2\nVirtual desktop environment\nAs cloud computing further matured, and notably the number of cloud\napplications was growing, it became opportune to actually turn the cloud into\na virtual desktop environment for end users. The only thing needed was\nthe client-side software to access that desktop environment. One of the first\nDS 4.01\n \n\n\n3.3. CLIENTS\n145\nproviders of this model was Google with the introduction of Chrome OS. The\nbasic idea is simple: let the browser provide the local desktop interface. Next\nto the browser, multiple stand-alone applications can be available of which\neach, in principle, eventually operates with a cloud-based counterpart. In this\nsense, the desktop is actually akin to what is offered by modern smartphones.\nWith an increasing trend to transform applications to browser extensions, we\ncan see that the browser is taking over the role of an operating system’s user\ninterface.\nThe anatomy of a Web browser\nTo get a better appreciation of what is going on, let us take a closer look at\nthe anatomy of the Chrome browser, which has been reported to be the most\nwidely used among all browsers.2 The Chrome browser is an intricate piece of\nsoftware consisting of over 25 million lines of code, comparable to the size of\nthe Linux kernel. Where in the beginning the Web consisted of merely simple\nHTML pages, we are now dealing with not only a highly advanced markup\nlanguage, but also an array of tools for interaction and client-side scripting\nlanguages. A high-level overview of how the Chrome browser works is shown\nin Figure 3.17.\nAt the core, we see the resource loader, responsible for fetching content\nfrom a Web server. It generally starts with fetching an HTML file and subse-\nquently, in parallel, sets up connections for other material referenced in that\npage. This is typically done through separate threads. Note that the resource\nloader will need to partially parse the original HTML file to discover which\nother content it needs to fetch. Most of the parsing, however, is done by a\nseparate component that constructs what is known as a Document Object\nModel, or DOM for short. In essence, a DOM is a tree representation of the\nHTML file.\nWhere the DOM can be said to represent structure, actual styling infor-\nmation is provided by a separate document. For example, it may state that\nevery paragraph should be represented in a specific color and in a specific\nfont. This information is parsed separately and essentially added to the DOM,\nleading to a render tree. This tree contains all the information for the next step:\ndetermining exactly where the various elements in the tree will be displayed.\nIn particular, geometric regions need to be computed for different parts of the\nDOM, but also where lines will be broken (and considering language-specific\nissues such as reading text from left to right, or vice versa as is the case with\nHebrew or Arabic. Line breaking, in turn, requires exact computations for\nwhich the styling component will need to take font characteristics into account.\nIt is not difficult to see that the process of determining the layout can become\n2See gs.statcounter.com.\n \nDS 4.01\n",
      "page_number": 150
    },
    {
      "number": 17,
      "title": "Segment 17 (pages 158-169)",
      "start_page": 158,
      "end_page": 169,
      "detection_method": "topic_boundary",
      "content": "146\nCHAPTER 3. PROCESSES\nHTTP(S)\nWeb server\nResource\nloader\nHTML\nparsing\nStyling\nMake\nlayout\nCompositing\nPainting &\nrasterization\nExecute\nscripts\nImage\nText\nList\nMovie\nHTML files\nCSS files\nScripts\nImages\n...\nUser\ninteraction\nDOM\nRender\ntree\nFigure 3.17: An overview of how the Chrome browser renders a Web page\n(adapted from Pourghassemi [2021]).\nquite complex when, for example, floating images or multiple columns need\nto be rendered.\nOnce the layout has been determined, the painting component, takes the\nlayout instructions and constructs a program consisting of paint operations,\nlike drawRectangle(x,y,height,width). There are many of such operations,\nwhich are subsequently executed by a rasterization process which fills in\nall the details for every pixel on the screen, notably, of course, its color.\nRasterization also takes the embedded images into account (and based on the\ninformation provided by the painting process) ensures that each pixel on an\nembedded image gets properly displayed. What we have not shown explicitly\nin Figure 3.17, is that the DOM is actually decomposed into several layers,\nand that each layer is eventually rasterized separately. As a result, the layers\nneed to be composed into a final image that can be displayed. Meanwhile, the\ncompositor can interact with the user, who may be scrolling through a page.\nLast, yet certainly not least, every browser now has a separate component\nfor handling scripts, that is, executable code. A popular scripting language\nfor client-side Web applications is JavaScript, but increasingly more often we\nalso see WebAssembly codes [Sletten, 2022]. The latter offer performance that\nDS 4.01\n \n\n\n3.3. CLIENTS\n147\ncan be close to executing native code, certainly in combination with actual\ncompilations. The generated code is always restricted to the permissions the\nbrowser has, making it (relatively) safe. The power of being able to run code\ninside a browser cannot be underestimated. It forms the core of giving the\nillusion to an end user that she is indeed running an application on the local\ndesktop. We return to this phenomenon below.\nAlthough we have skipped many details, it should be clear that actually\nrendering a Web page is a highly complex endeavor. Furthermore, it is not\ndifficult to imagine that many of the elements just described, such as raster-\nizing layers, can be done in parallel and perhaps even on special processors,\nsuch a GPU. This is precisely what a modern Web browser does: spawning\nthreads and processes, not only to provide more structure and organization\nto this immense complex software, but also to make sure that the rendering\nas a whole is done efficiently.\nIn fact, modern Web browsers also use processes to protect various parts\nof their code from each other. For example, the whole rendering in Chrome\nis done by a separate process (i.e., the components HTML parsing, styling,\nmaking the layout, painting, and compositing are taken together), while raster-\nization is separated to make use of a possibly available GPU. The rasterization\nprocess communicates with the main process through message passing. More-\nover, every browser tab gets its own renderer process. To improve security,\neach renderer is running in a separate sandbox: a protection mechanism that\nprecludes direct communication with the underlying operating system. We\nreturn to sandboxes when discussing mobile code.\nBrowsers and applications\nAs we already indicated, having a browser is often sufficient for offering a\nvirtual desktop environment. Important is the fact that browsers can execute\nscripts as the client-side part of an otherwise remote application. Such scripts\ncan largely handle everything that is needed to provide the illusion that a\nuser is working on a local machine. This is precisely what Chrome OS offers.\nHowever, things become a bit more complicated when local resources are\ntruly needed for offering a desktop environment. The first type of resources\nthat come to mind are related to media: camera, microphone, speakers, etc.\nMany Web-based applications will ask the user for permission to use those\nresources.\nIt is often also possible to run applications natively on the computer\nhosting the client-side desktop. In essence, this is what happens with modern\nsmartphones. Native applications (also referred to as mobile apps) operate as\nany other locally executing application. Their main advantage over running\nWeb-based applications is that, in principle, a user can work offline. However,\nby simply examining how many mobile apps are useful when there is no\n \nDS 4.01\n\n\n148\nCHAPTER 3. PROCESSES\nnetwork connectivity already illustrates that working offline is not assumed\nto be the default.\nA development that is gradually emerging is that of using Progressive Web\napps (PWA). These applications use the browser as their hosting environment,\nyet appear as an ordinary mobile app. In a nutshell, what a PWA does is move\na lot of the server-side content that is not dependent on (high quality) network\nconnectivity, to the client where it is subsequently cached. The effect is that\nmany of these apps, which can run in the browser or even appear as a mobile\napp (i.e., the browser user interface itself is hidden) can be executed much\nfaster and comparable to that of their mobile-app counterpart. Furthermore,\nbecause much less needs to be communicated with the server, many PWAs\ncan operate well even when the quality of the network is at stake.\nBy and large, we see that virtual desk environments are moving extremely\nthin clients to ones that are hosts to much more functionality, and for which\ncommunication over the Internet has been highly optimized. As we mentioned\nbefore, a major advantage over the traditional fat clients that have mainly\nlocally installed applications is that management of browser-based apps is\nmuch easier: the server can simply upload new parts to the client as needed.\n3.3.3\nClient-side software for distribution transparency\nClient software comprises more than just user interfaces. Often, parts of the\nprocessing and data level in a client-server application are executed on the\nclient side as well. A special class is formed by embedded client software,\nsuch as for automatic teller machines (ATMs), cash registers, barcode readers,\nTV set-top boxes, etc. In these cases, the user interface is a relatively small part\nof the client software, in contrast to the local processing and communication\nfacilities.\nBesides the user interface and other application-related software, client\nsoftware comprises components for achieving distribution transparency.\nIdeally, a client should not be aware that it is communicating with remote\nprocesses. In contrast, distribution is often less transparent to servers for\nreasons of performance and correctness.\nAccess transparency is generally handled through the generation of a\nclient stub from an interface definition of what the server has to offer. The\nstub provides the same interface as the one available at the server, but hides\nthe possible differences in machine architectures, as well as the actual commu-\nnication. The client stub transforms local calls to messages that are sent to the\nserver, and vice versa transforms messages from the server to return values as\none would expect when calling an ordinary procedure.\nThere are different ways to handle location, migration, and relocation\ntransparency . Using a convenient naming system is crucial. Often, coopera-\ntion with client-side software is also important. For example, when a client is\nalready bound to a server, the client can be directly informed when the server\nDS 4.01\n \n\n\n3.4. SERVERS\n149\nchanges location. In this case, the client’s middleware can hide the server’s\ncurrent network location from the user, and also transparently rebind to the\nserver if necessary. At worst, the client’s application may notice a temporary\nloss of performance.\nSimilarly, many distributed systems implement replication transparency\nemploying client-side solutions. For example, imagine a distributed system\nwith replicated servers, Such replication can be achieved by forwarding a\nrequest to each replica, as shown in Figure 3.18. Client-side software can\ntransparently collect all responses and pass a single response to the client\napplication.\nFigure 3.18: Transparent replication of a server using a client-side solution.\nRegarding failure transparency, masking communication failures with\na server is typically done through client middleware. For example, client\nmiddleware can be configured to repeatedly attempt to connect to a server, or\nperhaps try another server after several attempts. There are even situations\nin which the client middleware returns data it had cached during a previous\nsession, as is sometimes done by Web browsers that fail to connect to a server.\nFinally, concurrency transparency can be handled through special inter-\nmediate servers, notably transaction monitors, and requires less support from\nclient software.\n3.4\nServers\nLet us now take a closer look at the organization of servers. In the following\npages, we first concentrate on a number of general design issues for servers,\nfollowed by a discussion on server clusters.\n3.4.1\nGeneral design issues\nA server is a process implementing a specific service on behalf of a collection\nof clients. In essence, each server is organized in the same way: it waits for an\n \nDS 4.01\n\n\n150\nCHAPTER 3. PROCESSES\nincoming request from a client and subsequently ensures that the request is\ntaken care of, after which it waits for the next incoming request.\nConcurrent versus iterative servers\nThere are several ways to organize servers. In the case of an iterative server,\nthe server itself handles the request and, if necessary, returns a response to the\nrequesting client. A concurrent server does not handle the request itself, but\npasses it to a separate thread or another process, after which it immediately\nwaits for the next incoming request. A multithreaded server is an example of\na concurrent server. An alternative implementation of a concurrent server is to\nfork a new process for each new incoming request. This approach is followed\nin many Unix systems. The thread or process that handles the request is\nresponsible for returning a response to the requesting client.\nContacting a server: end points\nAnother issue is where clients contact a server. In all cases, clients send\nrequests to an end point, also called a port, at the machine where the server\nis running. Each server listens to a specific end point. How do clients know\nthe end point of a service? One approach is to globally assign end points for\nwell-known services. For example, servers that handle Internet FTP requests\nalways listen to TCP port 21. Likewise, an HTTP server for the World Wide\nWeb will always listen to TCP port 80. These end points have been assigned\nby the Internet Assigned Numbers Authority (IANA), and are documented\nin [Reynolds and Postel, 1994]. With assigned end points, the client needs to\nfind only the network address of the machine where the server is running.\nName services can be used for that purpose.\nThere are many services that do not require a preassigned end point.\nFor example, a time-of-day server may use an end point that is dynamically\nassigned to it by its local operating system. In that case, a client will first\nhave to look up the end point. One solution is to have a special daemon\nrunning on each machine that runs servers. The daemon keeps track of the\ncurrent end point of each service implemented by a co-located server. The\ndaemon itself listens to a well-known end point. A client will first contact the\ndaemon, request the end point, and then contact the specific server, as shown\nin Figure 3.19(a).\nIt is common to associate an end point with a specific service. However,\nactually implementing each service by means of a separate server may be\na waste of resources. For example, in a typical Unix system, it is common\nto have many servers running simultaneously, with most of them passively\nwaiting until a client request comes in. Instead of having to keep track of so\nmany passive processes, it can be more efficient to have a single superserver\nlistening to each end point associated with a specific service, as shown in\nDS 4.01\n \n\n\n3.4. SERVERS\n151\n(a)\n(b)\nFigure 3.19: (a) Client-to-server binding using a daemon. (b) Client-to-server\nbinding using a superserver.\nFigure 3.19(b). For example, the inetd daemon in Unix listens to a number of\nwell-known ports for Internet services. When a request comes in, the daemon\nforks a process to handle it. That process will exit when finished.\nInterrupting a server\nAnother issue that needs to be considered when designing a server is whether\nand how a server can be interrupted. For example, consider a user who has\njust decided to upload a huge file to an FTP server. Then, suddenly realizing\nthat it is the wrong file, she wants to interrupt the server to cancel further data\ntransmission. There are several ways to do this. One approach that works only\ntoo well in the current Internet (and is sometimes the only alternative) is for\nthe user to abruptly exit the client application (which will automatically break\nthe connection to the server), immediately restart it, and pretend nothing\nhappened. The server will eventually tear down the old connection, thinking\nthe client has probably crashed.\nA much better approach for handling communication interrupts is to\ndevelop the client and server such that it is possible to send out-of-band\ndata, which is data that is to be processed by the server before any other data\nfrom that client. One solution is to let the server listen to a separate control\nend point to which the client sends out-of-band data, while at the same time\nlistening (with a lower priority) to the end point through which the normal\n \nDS 4.01\n\n\n152\nCHAPTER 3. PROCESSES\ndata passes. Another solution is to send out-of-band data across the same\nconnection through which the client is sending the original request. In TCP,\nfor example, it is possible to transmit urgent data. When urgent data are\nreceived at the server, the latter is interrupted (e.g., through a signal in Unix\nsystems), after which it can inspect the data and handle them accordingly.\nStateless versus stateful servers\nA final, important design issue, is whether the server is stateless. A stateless\nserver does not keep information on the state of its clients, and can change its\nown state without having to inform any client [Birman, 2012]. A Web server,\nfor example, is stateless. It merely responds to incoming HTTP requests, which\ncan be either for uploading a file to the server or (most often) for fetching\na file. When the request has been processed, the Web server forgets the\nclient completely. Likewise, the collection of files that a Web server manages\n(possibly in cooperation with a file server), can be changed without clients\nhaving to be informed.\nNote that in many stateless designs, the server actually does maintain\ninformation on its clients, but crucial is the fact that if this information is\nlost, it will not lead to a disruption of the service offered by the server. For\nexample, a Web server generally logs all client requests. This information is\nuseful, for example, to decide whether certain documents should be replicated,\nand where they should be replicated to. Clearly, there is no penalty, other\nthan perhaps in the form of suboptimal performance if the log is lost.\nA particular form of a stateless design is where the server maintains what\nis known as soft state. In this case, the server promises to maintain state on\nbehalf of the client, but only for a limited time. After that time has expired,\nthe server falls back to default behavior, thereby discarding any information it\nkept on account of the associated client. An example of this type of state is\na server promising to keep a client informed about updates, but only for a\nlimited time. Thereafter, the client is required to poll the server for updates.\nSoft-state approaches originate from protocol design in computer networks,\nbut can be equally applied to server design [Clark, 1989; Lui et al., 2004].\nIn contrast, a stateful server generally maintains persistent information\non its clients. This means that the information needs to be explicitly deleted\nby the server. A typical example is a file server that allows a client to keep\na local copy of a file, even for performing update operations. Such a server\nwould maintain a table containing (client, file) entries. Such a table allows the\nserver to keep track of which client currently has the update permissions on\nwhich file, and thus possibly, also the most recent version of that file.\nThis approach can improve the performance of read and write operations\nas perceived by the client. Performance improvement over stateless servers\nis often an important benefit of stateful designs. However, the example also\nillustrates the major drawback of stateful servers. If the server crashes, it has\nDS 4.01\n \n\n\n3.4. SERVERS\n153\nto recover its table of (client, file) entries, or otherwise it cannot guarantee\nthat it has processed the most recent updates on a file. In general, a stateful\nserver needs to recover its entire state as it was just before the crash. Enabling\nrecovery can introduce considerable complexity, as we discuss in Chapter 8.\nIn a stateless design, no special measures need to be taken at all for a crashed\nserver to recover. It simply starts running again, and waits for client requests\nto come in.\nLing et al. [2004] argue that one should actually make a distinction between\n(temporary) session state and permanent state. The example above is typical\nfor session state: it is associated with a series of operations by a single user\nand should be maintained for some time, but not indefinitely. As it turns\nout, session state is often maintained in three-tiered client-server architectures,\nwhere the application server actually needs to access a database server through\na series of queries before being able to respond to the requesting client. The\nissue here is that no real harm is done if session state is lost, provided that\nthe client can simply re-issue the original request. This observation allows for\nsimpler and less reliable storage of state.\nWhat remains for permanent state is typically information maintained\nin databases, such as customer information, keys associated with purchased\nsoftware, etc. However, for most distributed systems, maintaining session state\nalready implies a stateful design requiring special measures when failures do\nhappen and making explicit assumptions about the durability of state stored\nat the server. We will return to these matters when discussing fault tolerance.\nWhen designing a server, the choice for a stateless or stateful design should\nnot affect the services provided by the server. For example, if files have to\nbe opened before they can be read from, or written to, then a stateless server\nshould one way or the other mimic this behavior. A common solution is that\nthe server responds to a read or write request by first opening the referred\nfile, then does the actual read or write operation, and immediately closes the\nfile again.\nIn other cases, a server may want to keep a record of a client’s behavior so\nthat it can more effectively respond to its requests. For example, Web servers\nsometimes offer the possibility to immediately direct a client to its favorite\npages. This approach is possible only if the server has history information on\nthat client. When the server cannot maintain state, a common solution is then\nto let the client send along additional information on its previous accesses. In\nthe case of the Web, this information is transparently stored by the client’s\nbrowser in what is called a cookie, which is a small piece of data containing\nclient-specific information that is of interest to the server. Cookies are never\nexecuted by a browser; they are merely stored and sent to the server when\naccessed a next time.\nThe first time a client accesses a server, the latter sends a cookie along with\nthe requested Web pages back to the browser, after which the browser safely\n \nDS 4.01\n\n\n154\nCHAPTER 3. PROCESSES\ntucks the cookie away. Each subsequent time the client accesses the server, its\ncookie for that server is sent along with the request.\n3.4.2\nObject servers\nLet us take a look at the general organization of object servers needed for\ndistributed objects. The important difference between a general object server\nand other (more traditional) servers is that an object server by itself does not\nprovide a specific service. Specific services are implemented by the objects\nthat reside in the server. Essentially, the server provides only the means to\ninvoke local objects, based on requests from remote clients. As a consequence,\nit is relatively easy to change services by simply adding and removing objects.\nAn object server thus acts as a place where objects live. An object consists\nof two parts: data representing its state and the code for executing its methods.\nWhether these parts are separated, or whether method implementations are\nshared by multiple objects, depends on the object server. Furthermore, there\nare differences in the way an object server invokes its objects. For example,\nin a multithreaded server, each object may be assigned a separate thread, or\na separate thread may be used for each invocation request. These and other\nissues are discussed next.\nFor an object to be invoked, the object server needs to know which code to\nexecute, on which data it should operate, whether it should start a separate\nthread to take care of the invocation, and so on. A simple approach is to\nassume that all objects look alike and that there is only one way to invoke\nan object. Unfortunately, such an approach is generally inflexible and often\nunnecessarily constrains developers of distributed objects.\nA much better approach is for a server to support different policies. Con-\nsider, for example, a transient object: an object that exists only as long as\nits server exists, but possibly for a shorter period of time. An in-memory,\nread-only copy of a file could typically be implemented as a transient object.\nLikewise, a calculator could also be implemented as a transient object. A\nreasonable policy is to create a transient object at the first invocation request\nand to destroy it as soon as no clients are bound to it anymore.\nThe advantage of this approach is that a transient object will need a server’s\nresources only as long as the object is really needed. The drawback is that\nan invocation may take some time to complete because the object needs to\nbe created first. Therefore, an alternative policy is sometimes to create all\ntransient objects at the time the server is initialized, at the cost of consuming\nresources even when no client is making use of the object.\nSimilarly, a server could follow the policy that each of its objects is placed\nin a memory segment of its own. In other words, objects share neither code\nnor data. Such a policy may be necessary when an object implementation\ndoes not separate code and data, or when objects need to be separated for\nsecurity reasons. In the latter case, the server will need to provide special\nDS 4.01\n \n\n\n3.4. SERVERS\n155\nmeasures, or require support from the underlying operating system, to ensure\nthat segment boundaries are not violated.\nThe alternative approach is to let objects at least share their code. For\nexample, a database containing objects that belong to the same class can be\nefficiently implemented by loading the class implementation only once into\nthe server. When a request for an object invocation comes in, the server need\nonly fetch that object’s state and execute the requested method.\nLikewise, there are many policies regarding threading.\nThe simplest\napproach is to implement the server with only a single thread of control.\nAlternatively, the server may have several threads, one for each of its objects.\nWhenever an invocation request comes in for an object, the server passes the\nrequest to the thread responsible for that object. If the thread is currently busy,\nthe request is temporarily queued.\nThe advantage of this approach is that objects are automatically protected\nagainst concurrent access: all invocations are serialized through the single\nthread associated with the object. Neat and simple. Of course, it is also\npossible to use a separate thread for each invocation request, requiring that\nobjects should have already been protected against concurrent access. Inde-\npendent of using a thread per object or thread per method is the choice of\nwhether threads are created on demand or the server maintains a pool of\nthreads. Generally, there is no single best policy. Which one to use depends\non whether threads are available, how much performance matters, etc.\nDecisions on how to invoke an object are commonly referred to as activa-\ntion policies, to emphasize that often the object itself must first be brought\ninto the server’s address space (i.e., activated) before it can actually be in-\nvoked. What is needed then is a mechanism to group objects per policy. Such\na mechanism is sometimes called an object adapter, or alternatively an object\nwrapper. An object adapter can best be thought of as software implementing\na specific activation policy. The main issue, however, is that object adapters\ncome as generic components to assist developers of distributed objects, and\nwhich need only to be configured for a specific policy.\nAn object adapter has one or more objects under its control. Because a\nserver should be capable of simultaneously supporting objects that require\ndifferent activation policies, several object adapters may reside in the same\nserver. When an invocation request is delivered to the server, the request is\nfirst dispatched to the appropriate object adapter, as shown in Figure 3.20.\nAn important observation is that object adapters are unaware of the specific\ninterfaces of the objects they control. Otherwise, they could never be generic.\nThe only issue that is important to an object adapter is that it can extract an\nobject reference from an invocation request, and subsequently dispatch the\nrequest to the referenced object, but now following a specific activation policy.\nAs is also illustrated in Figure 3.20, rather than passing the request directly\nto the object, an adapter hands an invocation request to the server-side stub\n \nDS 4.01\n\n\n156\nCHAPTER 3. PROCESSES\nFigure 3.20: An object server supporting different activation policies.\nof that object. The stub, also called a skeleton, is normally generated from\nthe interface definitions of the object, unmarshals the request and invokes the\nappropriate method.\nAn object adapter can support different activation policies by simply\nconfiguring it at runtime. For example, in CORBA-compliant systems [OMG,\n2001], it is possible to specify whether an object should continue to exist after\nits associated adapter has stopped. Likewise, an adapter can be configured to\ngenerate object identifiers, or to let the application provide one. An adapter\ncan also be configured to operate in single-threaded or multithreaded mode.\nNote that although in Figure 3.20 we have spoken about objects, we\nhave said nothing about what these objects actually are. In particular, it\nshould be stressed that as part of the implementation of such an object the\nserver may (indirectly) access databases or call special library routines. The\nimplementation details are hidden for the object adapter, who communicates\nonly with a skeleton. As such, the actual implementation may have nothing\nto do with what we often see with language-level (i.e., compile-time) objects.\nFor this reason, a different terminology is generally adopted. A servant is the\ngeneral term for a piece of code that forms the implementation of an object.\nExample: The Ice runtime system\nLet us briefly consider the Ice distributed-object system, which has been partly\ndeveloped in response to the intricacies of commercial object-based distributed\nsystems [Henning, 2004]. An object server in Ice is nothing but an ordinary\nprocess that simply starts with initializing the Ice runtime system. The basis\nDS 4.01\n \n\n\n3.4. SERVERS\n157\nof the runtime environment is formed by what is called a communicator. A\ncommunicator is a component that manages several basic resources, of which\nthe most important one is formed by a pool of threads. Likewise, it will\nhave associated dynamically allocated memory, and so on. In addition, a\ncommunicator provides the means for configuring the environment. For\nexample, it is possible to specify maximum message lengths, maximum\ninvocation retries, and so on.\nNormally, an object server would have only a single communicator. How-\never, when different applications need to be fully separated and protected\nfrom each other, a separate communicator (with possibly a different config-\nuration) can be created within the same process. At the very least, such an\napproach would separate the different thread pools so that if one application\nhas consumed all its threads, then this would not affect the other application.\nA communicator is used to create an object adapter, such as shown in\nFigure 3.21. In this example, we start with creating and initializing the runtime\nenvironment, which returns a communicator. Using the communicator, an\nobject adapter is created. In this case, it is instructed to listen for incoming\nTCP connections on port 11000. Note that the adapter is created in the context\nof the just created communicator. We are now in the position to create objects\nand add those to the adapter. In this case, we create two objects, object1\nand object2, respectively. Both are added to the adapter, yet under different\nnames. What we see here, is that the adapter will be listening for incoming\nrequests on a single port, yet will use an object’s name to invoke the proper\nobject. Once the objects have been added, the adapter is activated, meaning\nthat, under the hood, a thread is activated that will start listening for incoming\nrequests.\nOn the client side, we see that two printer objects are created, one for each\nof their server-side counterparts. And, indeed, after starting the server and\nthen the client, the output on the server’s side will match:\nObject1 says: Hello World from printer1!\nObject2 says: Hello World from printer2!\nNote that if we had associated printer2 in line 9 of the client with base1, the\noutput would have been:\nObject1 says: Hello World from printer1!\nObject1 says: Hello World from printer2!\nIn other words, printer2 would have been associated to object1 instead of\nobject2.\nThis code does not yet show much differentiation in activation policies.\nPolicies can be changed by modifying the properties of an adapter. One family\nof properties is related to maintaining an adapter-specific set of threads that\nare used for handling incoming requests. For example, one can specify that\n \nDS 4.01\n",
      "page_number": 158
    },
    {
      "number": 18,
      "title": "Segment 18 (pages 170-180)",
      "start_page": 170,
      "end_page": 180,
      "detection_method": "topic_boundary",
      "content": "158\nCHAPTER 3. PROCESSES\n1 import sys, Ice\n2 import Demo\n3\n4 class PrinterI(Demo.Printer):\n5\ndef __init__(self, t):\n6\nself.t = t\n7\n8\ndef printString(self, s, current=None):\n9\nprint(self.t, s)\n10\n11 communicator = Ice.initialize(sys.argv)\n12\n13 adapter = communicator.createObjectAdapterWithEndpoints(\"SimpleAdapter\", \"default -p 11000\")\n14 object1 = PrinterI(\"Object1 says:\")\n15 object2 = PrinterI(\"Object2 says:\")\n16 adapter.add(object1, communicator.stringToIdentity(\"SimplePrinter1\"))\n17 adapter.add(object2, communicator.stringToIdentity(\"SimplePrinter2\"))\n18 adapter.activate()\n19\n20 communicator.waitForShutdown()\n(a)\n1 import sys, Ice\n2 import Demo\n3\n4 communicator = Ice.initialize(sys.argv)\n5\n6 base1 = communicator.stringToProxy(\"SimplePrinter1:default -p 11000\")\n7 base2 = communicator.stringToProxy(\"SimplePrinter2:default -p 11000\")\n8 printer1 = Demo.PrinterPrx.checkedCast(base1)\n9 printer2 = Demo.PrinterPrx.checkedCast(base2)\n10 if (not printer1) or (not printer2):\n11\nraise RuntimeError(\"Invalid proxy\")\n12\n13 printer1.printString(\"Hello World from printer1!\")\n14 printer2.printString(\"Hello World from printer2!\")\n15\n16 communicator.waitForShutdown()\n(b)\nFigure 3.21: (a) An example of creating a simple object server in Ice, and (b) a\ncorresponding client (slightly adapted from [ZeroC, 2022]).\nthere should always be only one thread, effectively serializing all accesses to\nobjects that have been added to the adapter.\nIn the example above, an object is created as part of the application, after\nwhich it is added to an adapter. Effectively, this means that an adapter may\nneed to support many objects at the same time, leading to potential scalability\nproblems. An alternative solution is to dynamically load objects into memory\nwhen they are needed. To do this, Ice provides support for special objects\nknown as locators. A locator can be viewed as a special type of servant; it is\nDS 4.01\n \n\n\n3.4. SERVERS\n159\ncalled when the adapter receives an incoming request for an object that has\nnot been explicitly added. In that case, the request is forwarded to the locator,\nwhose job is to further handle the request.\nTo make matters more concrete, suppose a locator is handed a request\nfor an object of which the locator knows that its state is stored in a relational\ndatabase system. Of course, there is no magic here: the locator has been\nprogrammed explicitly to handle such requests. In this case, the object’s\nidentifier may correspond to the key of a record in which that state is stored.\nThe locator will then simply do a lookup on that key, fetch the state, and will\nthen be able to further process the request.\nThere can be more than one locator added to an adapter. In that case,\nthe adapter would keep track of which object identifiers would belong to the\nsame locator. Using multiple locators allows supporting many objects by a\nsingle adapter. Of course, objects (or rather their state) would need to be\nloaded at runtime, but this dynamic behavior would possibly make the server\nitself relatively simple. More examples and detailed information on Ice can be\nfound in [ZeroC, 2022].\n3.4.3\nExample: The Apache Web server\nAn interesting example of a server that balances the separation between\npolicies and mechanisms is the Apache Web server. It is also an extremely\npopular server, estimated to be used to host approximately 25% of all Websites.\nApache is a complex piece of software, and with the numerous enhancements\nto the types of documents that are now offered on the Web, it is important\nthat the server be highly configurable and extensible, and at the same time\nlargely independent of specific platforms.\nMaking the server platform independent is realized by essentially provid-\ning its own basic runtime environment, which is then subsequently imple-\nmented for different operating systems. This runtime environment, known as\nthe Apache Portable Runtime (APR), is a library that provides a platform-\nindependent interface for file handling, networking, locking, threads, and so\non. When extending Apache, portability is largely guaranteed provided that\nonly calls to the APR are made and none to platform-specific libraries.\nFrom a certain perspective, Apache can be considered as a completely gen-\neral server tailored to produce a response to an incoming request. Of course,\nthere are all kinds of hidden dependencies and assumptions by which Apache\nturns out to be primarily suited for handling requests for Web documents.\nFor example, as we mentioned, Web browsers and servers use HTTP as their\ncommunication protocol. HTTP is virtually always implemented on top of\nTCP, for which reason the core of Apache assumes that all incoming requests\nadhere to a TCP-based connection-oriented way of communication. Requests\nbased on UDP cannot be handled without modifying the Apache core.\n \nDS 4.01\n\n\n160\nCHAPTER 3. PROCESSES\nFigure 3.22: The general organization of the Apache Web server.\nOtherwise, the Apache core makes few assumptions on how incoming\nrequests should be handled. Its overall organization is shown in Figure 3.22.\nFundamental to this organization are modules. A module consists of one, or\nseveral, functions that should be called for properly handling a request. This\nraises several questions:\n1. How do we ensure that a function is called in the first place?\n2. How do we ensure that a function is called at the right moment?\n3. How do we prevent that a function is called for a request it was not\nsupposed to handle?\nThe last question is actually the simplest: each function will be called (along\nwith the request), yet each function will return the value DECLINED if the\nrequest was not meant for it.\nGetting a function to be called at all is handled through a hook, which\nis a placeholder for a function. There is a hook for each function, and each\nmodule provides the Apache core with a list of hooks to its functions. By\nstatically or dynamically linking modules to the Apache core, we establish a\nconnection between a hook and its associated function.\nFor example, there is a hook to translate a URL to a local file name. Such a\ntranslation will almost certainly need to be done when processing a request.\nLikewise, there is a hook for writing information to a log, a hook for checking\na client’s identification, a hook for checking access rights, and a hook for\nDS 4.01\n \n\n\n3.4. SERVERS\n161\nchecking which MIME type the request is related to (e.g., to make sure that\nthe request can be properly handled). As shown in Figure 3.22, the hooks\nare processed in a specific order. It is here that we explicitly see that Apache\nenforces a specific flow of control concerning the processing of requests.\nOften, functions can be processed independently of each other: they\noperate in perfect isolation on a request. However, this may not be generally\nthe case, for which Apache distinguishes a number of phases. When hooking\nup a function to Apache, we need to specify whether that function should be\ncalled in the beginning, the middle, or the end of the total request-processing\nflow. If fine-grained control is necessary, one can also specify before or after\nwhich other module a function should be called. However, it is easily seen\nthat trying to develop functions that operate in isolation (and are, in effect,\nstateless) contributes to a modular design.\nMuch more on the Apache Web server can be found in the (by now some-\nwhat outdated) book by Laurie and Laurie [2002], as well as the developer’s\ndocumentation provided by Apache itself.\n3.4.4\nServer clusters\nIn Chapter 1, we briefly discussed cluster computing as one of the many\nappearances of distributed systems. We now take a closer look at the organiza-\ntion of server clusters, along with the salient design issues. We first consider\ncommon server clusters that are organized in local-area networks. A special\ngroup is formed by wide-area server clusters, which we subsequently discuss.\nLocal-area clusters\nSimply put, a server cluster is nothing else but a collection of machines\nconnected through a network, where each machine runs one or more servers.\nThe server clusters that we consider here, are the ones in which the machines\nare connected through a local-area network, often offering high bandwidth\nand low latency.\nGeneral organization\nOften, a server cluster is logically organized into three\ntiers, as shown in Figure 3.23. The first tier consists of a (logical) switch\nthrough which client requests are routed. Such a switch can vary widely. For\nexample, transport-layer switches accept incoming TCP connection requests\nand pass requests on to one of the servers in the cluster. A completely different\nexample is a Web server that accepts incoming HTTP requests, but that partly\npasses requests to application servers for further processing only to later\ncollect results from those servers and return an HTTP response.\nAs in any multitiered client-server architecture, many server clusters also\ncontain servers dedicated to application processing. In cluster computing,\nthese are typically servers running on high-performance hardware dedicated\n \nDS 4.01\n\n\n162\nCHAPTER 3. PROCESSES\nLogical switch\n(possibly multiple)\nApplication/compute servers\nDistributed\nfile/database\nsystem\nClient requests\nDispatched\nrequest\nFirst tier\nSecond tier\nThird tier\nFigure 3.23: The general organization of a three-tiered server cluster.\nto delivering compute power.\nHowever, in the case of enterprise server\nclusters, it may be the case that applications need only run on relatively\nlow-end machines, as the required compute power is not the bottleneck, but\naccess to storage is.\nThis brings us to the third tier, which consists of data-processing servers,\nnotably file and database servers. Again, depending on the usage of the server\ncluster, these servers may be running on specialized machines, configured for\nhigh-speed disk access and having large server-side data caches.\nOf course, not all server clusters will follow this strict separation. It is\nfrequently the case that each machine is equipped with its own local storage,\noften integrating application and data processing in a single server, leading\nto a two-tiered architecture. For example, when dealing with streaming\nmedia using a server cluster, it is common to deploy a two-tiered system\narchitecture, where each machine acts as a dedicated media server [Steinmetz\nand Nahrstedt, 2004].\nWhen a server cluster offers multiple services, different machines may run\ndifferent application servers. As a consequence, the switch will have to be\nable to distinguish services, or otherwise it cannot forward requests to the\nproper machines. As a consequence, we may find that certain machines are\ntemporarily idle, while others are receiving an overload of requests. What\nwould be useful is to temporarily migrate services to idle machines. A solution\nis to use virtual machines, allowing a relatively easy migration of services.\nRequest dispatching\nLet us now take a closer look at the first tier, consisting\nof the switch, also known as the front end. An important design goal for\nserver clusters is to hide the fact that there are multiple servers. In other\nwords, client applications running on remote machines should have no need\nto know anything about the internal organization of the cluster. This access\nDS 4.01\n \n\n\n3.4. SERVERS\n163\ntransparency is invariably offered through a single access point, in turn\nimplemented through some kind of hardware switch such as a dedicated\nmachine.\nThe switch forms the entry point for the server cluster, offering a single\nnetwork address. For scalability and availability, a server cluster may have\nmultiple access points, where each access point is then realized by a separate\ndedicated machine. We consider only the case of a single access point.\nIn practice, we see two types of switches. In the case of transport-layer\nswitches, the switch accepts incoming TCP connection requests, and hands\noff such connections to one of the servers. The client sets up a TCP connection\nsuch that all requests and responses pass through the switch. The switch,\nin turn, will set up a TCP connection with a selected server and pass client\nrequests to that server, and also accept server responses (which it will pass\non to the client). In effect, the switch sits in the middle of a TCP connection\nbetween the client and a selected server, rewriting the source and destination\naddresses when passing TCP segments. This approach is a form of network-\naddress translation (NAT) [Srisuresh and Holdrege, 1999].\nAs an alternative, application-layer switches are used. As its name suggest,\nan application-layer switch operates by inspecting the content of requests\ninstead of just looking at information available in TCP. For example, the\nswitch can inspect the actual URL in case of a Web server. This distinction\nallows for developing server clusters in which dedicated machines can be\nconfigured for handling, for example, video or other media, next to those\nrequiring access to specific databases, etc. In general, the more a switch knows\nabout what is being requested, the better it can decide on which server to\nhandle the request. An obvious drawback of application-layer switches is that\nthey may be slower than transport-layer switches. On the other hand, using\nthe right software and hardware, costs can be kept acceptable low. This is\ndemonstrated, for example, by the nginx server, which has been designed to\nhandle thousands of simultaneous connections and is used for many sites as\nwhat is also called a reverse proxy [DeJonghe, 2022]. Note that the Apache\nWeb server can also be configured as an application-layer switch.\nNote 3.7 (Example: TCP handoff)\nIn the days that request dispatching was relatively expensive, a simple and elegant\nway of ensuring that performance criteria could still be met, was by implementing\nTCP handoff. The idea is a switch can actually hand off the connection to a\nselected server such that all responses are directly communicated to the client\nwithout passing through the switch [Hunt et al., 1997; Pai et al., 1998]. The\nprinciple working is shown in Figure 3.24.\nWhen the switch receives a TCP connection request, it first identifies the best\nserver for handling that request, and forwards the request packet to that server.\nThe server, in turn, will send an acknowledgment back to the requesting client, but\n \nDS 4.01\n\n\n164\nCHAPTER 3. PROCESSES\ninserting the switch’s IP address as the source field of the header of the IP packet\ncarrying the TCP segment. Note that this address rewriting is necessary for the\nclient to continue executing the TCP protocol: it is expecting an answer back from\nthe switch, not from some arbitrary server it has never heard of before. Clearly, a\nTCP-handoff implementation requires operating-system level modifications. TCP\nhandoff is especially effective when responses are much larger than requests, as\nin the case of Web servers.\nFigure 3.24: The principle of TCP handoff.\nIt can already be seen that the switch can play an important role in distributing\nthe load among the various servers. By deciding where to forward a request to,\nthe switch also decides which server is to handle further processing of the request.\nThe simplest load-balancing policy that the switch can follow is round robin: each\ntime it picks the next server from its list to forward a request to. Of course, the\nswitch will have to keep track to which server it handed off a TCP connection, at\nleast until that connection is torn down. As it turns out, maintaining this state\nand handing off subsequent TCP segments belonging to the same TCP connection,\nmay actually slow down the switch.\nWide-area clusters\nWe came across wide-area clusters in our discussion on PlanetLab (see Note 3.6):\nan architecture in which participants contribute some (relatively simple) ma-\nchines for hosting containers that are subsequently “sliced” across as many\nmachines as a client needs. Thereafter, the client is on her own. Much more\nsophisticated and commercially deployed wide-area clusters exist today.\nA straightforward version is seen with cloud providers like Amazon\nand Google, who manage several data centers placed at different locations\nworldwide. As such, they can offer an end user the ability to build a wide-area\ndistributed system consisting of a potentially large collection of networked\nvirtual machines, scattered across the Internet. An important reason for\nwanting such distributed systems is to provide locality: offering data and\nservices that are close to clients. An example where such locality is important\nis streaming media: the closer a video server is located to a client, the easier\nDS 4.01\n \n\n\n3.4. SERVERS\n165\nit becomes to provide high-quality streams. This approach is followed by\nso-called cloud-based Content Delivery Networks, or simply CDNs, which\nwe will discuss shortly.\nAn alternative is to have a single organization place servers across the\nInternet, effectively negotiating with local ISPs to decide how to make use\nof their facilities. This is the approach followed by the Akamai CDN [Dilley\net al., 2002; Nygren et al., 2010], in 2022 having some 400,000 servers spread\nacross 1350 ISPs and more than 135 countries.\nThe general organization of a CDN\nAs CDNs form an important group of\ndistributed systems that make use of wide-area clusters, let us take a closer\nlook at how they are generally organized. We take a simplified view of the\nAkamai organization, shown in Figure 3.25. More information on CDNs\ncan be found in [Passarella, 2012; Stocker et al., 2017] and [Zolfaghari et al.,\n2021]. The basic idea is that there is an origin server that hosts a Website\nwith all its documents. As we will explain in Chapter 6, each document of\nsuch a site is referred to by a URL containing the domain name of the origin\nserver, such as www.example.com. To access a document, the domain name\nneeds to be resolved to a network address, which is done by the Domain\nName System, which we will discuss in detail also in Chapter 6. To have\nthe content of the origin server be hosted by a CDN, Akamai first makes\nsure that the domain name www.example.com is resolved to something like\nwww.example.com.akamai.net, which, in turn, will refer to an edge server that\nis part of the Akamai CDN. To be able to still access the origin server, its\ndomain name will have to be changed to, say, org-www.example.com. The\nprinciple is shown in Figure 3.25.\nThe client first looks up the regular domain name, but is redirected to the\nFigure 3.25: A simplified version of the working of the Akamai CDN.\n \nDS 4.01\n\n\n166\nCHAPTER 3. PROCESSES\nakamai.net resolvers (step 1). The Akamai name resolvers will look up the\nbest edge server to serve the client, and return its network address (step 2).\nThis allows the client to contact the edge server (step 3), who is aware of the\nnew name of the origin server. If the requested content is not in the edge\nserver’s cache, it fetches documents from the origin server (step 4), caches\nthose documents and returns the requested ones to the client. More details\ncan be found in [Su et al., 2006].\nRequest dispatching\nThis example already shows the importance of client-\nrequest redirection. In principle, by properly redirecting clients, a CDN\ncan stay in control when it comes to client-perceived performance, but also\nconsidering global system performance by, for example, avoiding that requests\nare sent to heavily loaded servers.\nThese so-called adaptive redirection\npolicies can be applied when information on the system’s current behavior is\nprovided to the processes that take redirection decisions.\nAn important issue is whether request redirection is transparent to the\nclient or not. In essence, there are only three redirection techniques: TCP\nhandoff, DNS redirection, and HTTP redirection. We discussed TCP handoff\nin Note 3.7. This technique is applicable only for server clusters and does not\nscale to wide-area networks.\nDNS redirection is a transparent mechanism by which the client can be\nkept completely unaware of where documents are located. Akamai’s two-level\nredirection is one example of this technique. We can also directly deploy DNS\nto return one of several addresses. Note, however, that DNS redirection can\nbe applied only to an entire site (or, more specifically, only at the level of a\ndomain name): the name of individual documents does not fit into the DNS\nname space.\nUnfortunately, DNS redirection is not perfect for two reasons. First, a\nclient generally contacts the Domain Name System through a local DNS\nserver that then acts as a proxy for that client. As a consequence, not the\nclient’s IP address, but that of the local DNS server, is used to identify the\nlocation of the client. Mao et al. [2002] have shown that there may be a huge\nadditional communication cost, as the local DNS server is often not that local.\nFurthermore, even when clients are returned several options for selecting\nan edge server, simply picking the first on the list, which is what normally\nhappens, may not be the best choice [Goel et al., 2015].\nSecondly, depending on the scheme that is used for resolving a domain\nname, it may even be the case that the address of the local DNS server is not\neven being used. Instead, it may happen that the DNS server that is deciding\non which IP address to return, may be fooled by the fact that the requester is\nyet another DNS server acting as an intermediate between the original client\nand the deciding DNS server (we will explain the details of this scheme in\nChapter 6. In those cases, locality awareness has been completely lost.\nDS 4.01\n \n\n\n3.5. CODE MIGRATION\n167\nDespite that DNS-based redirection may not always be very accurate, it\nis widely deployed if only for the fact that it is relatively easy to implement\nand also transparent to the client. In addition, there is no need to rely on\nlocation-aware client-side software.\nHTTP redirection, finally, is a nontransparent mechanism. When a client\nrequests a specific document, it may be given an alternative URL as part of\nan HTTP response message, to which it is then redirected. An important\nobservation is that this URL is visible to the client’s browser. In fact, the\nuser may decide to bookmark the referral URL, potentially rendering the\nredirection policy useless.\n3.5\nCode migration\nSo far, we have been mainly concerned with distributed systems in which\ncommunication is limited to passing data. However, there are situations\nin which passing programs, sometimes even while they are being executed,\nsimplifies the design of a distributed system. In this section, we take a detailed\nlook at what code migration actually is.\n3.5.1\nReasons for migrating code\nTraditionally, code migration in distributed systems took place in the form\nof process migration in which an entire process was moved from one node\nto another [Milojicic et al., 2000]. Moving a running process to a different\nmachine is a costly and intricate task, and there had better be a good reason\nfor doing so. Let us first consider why one would even want to migrate code\nfrom one machine to another.\nPerformance\nBy far the most important reason for code migration has always\nbeen performance. The basic idea is that overall system performance can\nbe improved if processes are moved from heavily loaded to lightly loaded\nmachines. Load is often expressed in terms of the CPU queue length or\nCPU utilization, but other performance indicators are used as well. When\ncompleting their survey, Milojicic et al. had already come to the conclusion\nthat process migration was no longer a viable option for improving distributed\nsystems.\nInstead of offloading machines, we can now witness that code is moved\nto make sure that a machine is sufficiently loaded. In particular, migrating\ncomplete virtual machines with their suite of applications to lightly loaded\nmachines to minimize the total number of nodes being used is common\npractice in optimizing energy usage in data centers. Interestingly enough,\nalthough migrating virtual machines may require more resources, the task\nitself is far less intricate than migrating a process, as we discuss below.\n \nDS 4.01\n\n\n168\nCHAPTER 3. PROCESSES\nIn general, load-distribution algorithms by which decisions are made con-\ncerning the allocation and redistribution of tasks regarding a set of machines,\nplay an important role in compute-intensive systems. However, in many\nmodern distributed systems, optimizing computing capacity is less an issue\nthan, for example, trying to minimize communication. Moreover, due to the\nheterogeneity of the underlying platforms and computer networks, perfor-\nmance improvement through code migration is often based on qualitative\nreasoning instead of mathematical models.\nConsider, as an example, a client-server system in which the server man-\nages a huge database. If a client application needs to perform many database\noperations involving large quantities of data, it may be better to ship part\nof the client application to the server and send only the results across the\nnetwork. Otherwise, the network may be swamped with the transfer of data\nfrom the server to the client. In this case, code migration is assuming that it\ngenerally makes sense to process data close to where those data reside.\nThis same reason can be used for migrating parts of the server to the client.\nFor example, in many interactive database applications, clients need to fill in\nforms that are subsequently translated into a series of database operations.\nProcessing the form at the client side, and sending only the completed form\nto the server, can sometimes avoid that a relatively large number of small\nmessages need to cross the network. The result is that the client perceives\nbetter performance, while at the same time the server spends less time on\nform processing and communication. In the case of smartphones, moving\ncode to be executed at the handheld instead of the server may be the only\nviable solution to obtain acceptable performance, both for the client and the\nserver (see Kumar et al. [2013] for a survey on offloading computations).\nSupport for code migration can also help improve performance by ex-\nploiting parallelism, but without the usual intricacies related to parallel pro-\ngramming. A typical example is searching for information in the Web. It is\nrelatively simple to implement a search query in the form of a small mobile\nprogram, called a mobile agent, that moves from site to site. By making\nseveral copies of such a program, and sending each off to different sites, we\nmay be able to achieve a linear speed-up compared to using just a single\nprogram instance. However, Carzaniga et al. [2007] conclude that mobile\nagents have never become successful because they did not really offer an\nobvious advantage over other technologies.\nPrivacy and security\nAnother reason for moving code to where the data is,\nhas to do with security. Recently, the canonical example for this approach\nis found in federated learning. Federated learning comes from the need to\ntrain machine-learning models, notably all kinds of variants of artificial neural\nnetworks. To keep it simple, a neural network consists of a collection of nodes,\norganized as a series of several layers, and having weighted links between\nDS 4.01\n \n",
      "page_number": 170
    },
    {
      "number": 19,
      "title": "Segment 19 (pages 181-193)",
      "start_page": 181,
      "end_page": 193,
      "detection_method": "topic_boundary",
      "content": "3.5. CODE MIGRATION\n169\nFigure 3.26: The principle of federated learning.\nnodes of successive layers. Each node puts data on its outgoing links, which\nis the result of a (relatively simple) computation that it gets from data on its\nincoming links. Links have an adjustable weight. During a training phase,\nthe weights of the links are gradually computed by feeding the network with\ndata items for which it is known what the network should produce as a result.\nBy systematically adjusting the weights to minimize the difference between\nwhat a network produces and what it should have produced, we eventually\nestablish a final model. That model can then be used on unknown data items,\nfor which we then take the produced result as a given.\nA traditional approach is to collect the training data at a centralized\nlocation, often using specialized high-performance computers to construct\nan acceptable model. Obviously, this could mean that sensitive data, such as\npersonal photo’s and such, needed to be handed out to an organization that\nsomeone may not trust.\nIn such cases, a better approach is to bring the (partially) trained model to\nwhere the data is, and continue training with that local data. This will lead\nto an updated model (i.e., the weights have been further adjusted because of\nusing new data). If several entities are involved in training with local data,\na server can simply collect the different models, aggregate the results, and\nreturn an updated model to the local participants who can then continue\nwith training. This iterative process, sketched in Figure 3.26 stops when the\naggregated model is deemed sufficiently trained and fit for actual use.\nIt must be said that federated learning is easier from a code-migration\nperspective than, e.g., migrating processes. In general, the code involved in a\nneural network is relatively straightforward, which makes it easier to have it\nadopted by a local participant. This has been a high-level view on federated\nlearning, of which a good introduction is given by Zhang et al. [2021a]. As\ndescribed in Lyu et al. [2020], simply doing local training may not be sufficient\nfrom a privacy and security perspective.\n \nDS 4.01\n\n\n170\nCHAPTER 3. PROCESSES\nFlexibility\nThere are other reasons for supporting code migration as well.\nAn important one is that of flexibility. The traditional approach to building\ndistributed applications is to partition the application into different parts, and\ndecide in advance where each part should be executed. This approach, for\nexample, has lead to different multitiered client-server applications discussed\nin Chapter 2.\nHowever, if code can move between different machines, it becomes possible\nto dynamically configure distributed systems. For example, suppose a server\nimplements a standardized interface to a file system. To allow remote clients\nto access the file system, the server makes use of a proprietary protocol.\nNormally, the client-side implementation of the file system interface, which is\nbased on that protocol, would need to be linked with the client application.\nThis approach requires that the software be readily available to the client at\nthe time the client application is being developed.\nAn alternative is to let the server provide the client’s implementation no\nsooner than is strictly necessary, that is, when the client binds to the server.\nAt that point, the client dynamically downloads the implementation, goes\nthrough the necessary initialization steps, and subsequently invokes the server.\nThis principle is shown in Figure 3.27 (we note that the code repository is\ngenerally located as part of the server). This model of dynamically moving\ncode from a remote site does require that the protocol for downloading\nand initializing code is standardized. Furthermore, it is necessary that the\ndownloaded code can be executed on the client’s machine. Typically, scripts\nthat run in a virtual machine embedded in, for example, a Web browser, will\ndo the trick. Arguably, this form of code migration has been key to the success\nof the dynamic Web. These and other solutions are discussed below and in\nlater chapters.\nFigure 3.27: The principle of dynamically configuring a client to communicate\nwith a server.\nThe important advantage of this model of dynamically downloading client-\nside software is that clients need not have all the software preinstalled to talk\nDS 4.01\n \n\n\n3.5. CODE MIGRATION\n171\nto servers. Instead, the software can be moved in as necessary, and likewise,\ndiscarded when no longer needed. Another advantage is that as long as\ninterfaces are standardized, we can change the client-server protocol and its\nimplementation as often as we like. Changes will not affect existing client\napplications that rely on the server.\nThere are, of course, also disadvantages. The most serious one, which\nwe discuss in Chapter 9, has to do with security. Blindly trusting that the\ndownloaded code implements only the advertised interface while accessing\nyour unprotected hard disk and does not send the juiciest parts to heaven-\nknows-who may not always be such a good idea. Fortunately, it is well\nunderstood how to protect the client against malicious, downloaded code.\nNote 3.8 (More information: Moving away from thin-client computing?)\nBy now, there is much more insight and expertise concerning transparent and\nsafe dynamic migration of code to clients. As a result, the trend that we described\nin Note 2.5 of moving toward thin-client computing because managing client-\nside software often turned out to be cumbersome, has been partly reverted. By\ndynamically migrating client-side software, yet keeping the management of that\nsoftware entirely at the server side (or rather, at its owner), having “richer” client-\nside software has become practically feasible. The most important domain where\nwe see this happening is through applications running on smartphones. In fact,\nas soon as, for example, a bug is discovered, and update can take place. It is for\nthis reason why many banks consider it safer to use a mobile app instead of a\nfixed piece of client-side software.\n3.5.2\nModels for code migration\nAlthough code migration suggests that we move only code between machines,\nthe term actually covers a much richer area. Traditionally, communication in\ndistributed systems is concerned with exchanging data between processes.\nCode migration in the broadest sense deals with moving programs between\nmachines, with the intention to have those programs be executed at the target.\nIn some cases, as in process migration, the execution status of a program,\npending signals, and other parts of the environment must be moved as well.\nTo get a better understanding of the different models for code migration,\nwe use a framework proposed by Fuggetta et al. [1998]. In this framework, a\nprocess consists of three segments. The code segment is the part that contains\nthe set of instructions that make up the program that is being executed. The\nresource segment contains references to external resources needed by the\nprocess, such as files, printers, devices, other processes, and so on. Finally, an\nexecution segment is used to store the current execution state of a process,\nconsisting of private data, the stack, and, of course, the program counter.\n \nDS 4.01\n\n\n172\nCHAPTER 3. PROCESSES\nA further distinction can be made between sender-initiated and receiver-\ninitiated migration. In sender-initiated migration, migration is initiated at\nthe machine where the code currently resides or is being executed. Typically,\nsender-initiated migration is done when uploading programs to a compute\nserver. Another example is sending a query, or batch of queries, to a remote\ndatabase server. In receiver-initiated migration, the initiative for code mi-\ngration is taken by the target machine. Java applets are an example of this\napproach.\nReceiver-initiated migration is simpler than sender-initiated migration.\nOften, code migration occurs between a client and a server, where the client\ntakes the initiative for migration. Securely uploading code to a server, as is\ndone in sender-initiated migration, often requires that the client has previ-\nously been registered and authenticated at that server. In other words, the\nserver is required to know all its clients, the reason being is that the client\nwill presumably want access to the server’s resources such as its disk. Pro-\ntecting such resources is essential. In contrast, downloading code, as in the\nreceiver-initiated case, can often be done anonymously. Moreover, the server\nis generally not interested in the client’s resources. Instead, code migration\nto the client is done only for improving client-side performance. To that end,\nonly a limited number of resources need to be protected, such as memory and\nnetwork connections.\nThis brings us to four different paradigms for code mobility, as shown in\nFigure 3.28. Following Fuggetta et al. [1998], we make a distinction between\nsimple client-server computing, remote evaluation, code-on-demand, and\nmobile agents. Figure 3.28 shows the situation at respectively the client and\nthe server, before and after execution of the mobile code.\nIn the case of client-server computing, the code, execution state, and\nresource segment are all located at the server, and after execution, only the\nexecution state at the server is generally modified. This state modification is\ndenoted using an asterisk. With the sender-initiated remote evaluation, the\nclient migrates code to the server where that code is executed and leading\nto a modification of the execution state at the server. Code-on-demand is a\nreceiver-initiated scheme by which the client obtains code from the server,\nwith its execution modifying the client-side execution state and operating on\nthe client’s resources. Finally, mobile agents typically follow a sender-initiated\napproach, moving code as well as execution state from the client to the server,\noperating on both the client’s and the server’s resources. Running a mobile\nagent will generally lead to modification of the associated execution state.\nThe bare minimum for code migration is to provide only weak mobility.\nIn this model, it is possible to transfer only the code segment, along with\nperhaps some initialization data. A characteristic feature of weak mobility\nis that a transferred program is always started anew. This is what happens,\nfor example, with Java applets, which start from the same initial state. In\nDS 4.01\n \n\n\n3.5. CODE MIGRATION\n173\nBefore execution\nAfter execution\nClient\nServer\nClient\nServer\nCS\ncode\nexec\nresource\ncode\nexec*\nresource\nREV\ncode\n−→\nexec\nresource\n−→\ncode\nexec*\nresource\nCoD\nexec\nresource\n←−\ncode\ncode\nexec*\nresource\n←−\nMA\ncode\nexec\nresource\n−→\nresource\nresource\n−→\ncode\nexec*\nresource\nCS: Client-Server\nREV: Remote evaluation\nCoD: Code-on-demand\nMA: Mobile agents\nFigure 3.28: Four different paradigms for code mobility.\nother words, no history from where the migrated code left off at a previous\nlocation is maintained by the underlying middleware. If such history needs to\nbe preserved, it will have to be encoded as part of the mobile application itself.\nThe benefit of weak mobility is its simplicity, as it requires only that the target\nmachine can execute the code segment. In essence, this boils down to making\nthe code portable. We return to these matters when discussing migration in\nheterogeneous systems.\nIn contrast to weak mobility, in systems that support strong mobility\nthe execution segment can be transferred as well. The characteristic feature\nof strong mobility is that a running process can be stopped, subsequently\nmoved to another machine, and then resume execution exactly where it left off.\nClearly, strong mobility is much more general than weak mobility, but also\nmuch more difficult to implement. In particular, when migrating a process,\nthe execution segment generally also contains data that is highly dependent\non a specific implementation of the underlying operating system. For example,\nit may rely on information normally found in the operating system’s process\ntable. As a consequence, migrating to a different operating system, even one\nthat belongs to the same family as the source, may cause plenty of headaches.\n \nDS 4.01\n\n\n174\nCHAPTER 3. PROCESSES\nIn the case of weak mobility, it also makes a difference if the migrated code\nis executed by the target process, or whether a separate process is started.\nFor example, Java applets are simply downloaded by a Web browser and are\nexecuted in the browser’s address space. The benefit of this approach is that\nthere is no need to start a separate process, thereby avoiding interprocess\ncommunication at the target machine. The main drawback, obviously, is that\nthe target process needs to be protected against malicious or inadvertent code\nexecutions, which may be reason enough to isolate the migrated code in a\nseparate process.\nInstead of moving a running process, also referred to as process migration,\nstrong mobility can also be supported by remote cloning. In contrast to\nprocess migration, cloning yields an exact copy of the original process, but\nnow running on a different machine. The cloned process is executed in parallel\nto the original process. In Unix systems, remote cloning takes place by forking\noff a child process and letting that child continue on a remote machine. The\nbenefit of cloning is that the model closely resembles the one that is already\nused in many applications. The only difference is that the cloned process\nis executed on a different machine. In this sense, migration by cloning is a\nsimple way to improve distribution transparency.\n3.5.3\nMigration in heterogeneous systems\nSo far, we have tacitly assumed that the migrated code can be easily executed\nat the target machine. This assumption is in order when dealing with homo-\ngeneous systems. In general, however, distributed systems are constructed\non a heterogeneous collection of platforms, each having their own operating\nsystem and machine architecture.\nThe problems coming from heterogeneity are in many respects the same\nas those of portability. Not surprisingly, solutions are also very similar. For\nexample, at the end of the 1970s, a simple solution to alleviate many of the\nproblems of porting Pascal to different machines was to generate machine-\nindependent intermediate code for an abstract virtual machine [Barron, 1981].\nThat machine, of course, would need to be implemented on many platforms,\nbut it would then allow Pascal programs to be run anywhere. Although this\nsimple idea was widely used for some years, it never really caught on as the\ngeneral solution to portability problems for other languages, notably C.\nAbout 25 years later, code migration in heterogeneous systems is being\ntackled by scripting languages and highly portable languages such as Java\nand Python. In essence, these solutions adopt the same approach as was done\nfor porting Pascal. All such solutions have in common that they rely on a\n(process) virtual machine that either directly interprets source code (as in\nthe case of scripting languages), or otherwise interprets intermediate code\ngenerated by a compiler (as in Java). Being in the right place at the right time\nis also important for language developers.\nDS 4.01\n \n\n\n3.5. CODE MIGRATION\n175\nFurther developments have weakened the dependency on programming\nlanguages. In particular, solutions have been proposed to migrate not only\nprocesses, but to migrate entire computing environments. The basic idea\nis to compartmentalize the overall environment and to provide processes\nin the same part their own view on their computing environment. That\ncompartmentalization takes place in the form of virtual machine monitors\nrunning an operating system and a suite of applications.\nWith virtual machine migration, it becomes possible to decouple a com-\nputing environment from the underlying system and actually migrate it to\nanother machine (see Medina and Garcia [2014] or Zhang et al. [2018] for\noverviews on migration mechanisms for virtual machines). A major advantage\nof this approach is that processes can remain ignorant of the migration itself:\nthey need not be interrupted in their execution, nor should they experience\nany problems with used resources. The latter are either migrating along with\na process, or the way that a process accesses a resource is left unaffected (at\nleast, for that process).\nAs an example, Clark et al. [2005] concentrated on real-time migration of a\nvirtualized operating system, typically something that would be convenient\nin a cluster of servers where a tight coupling is achieved through a single,\nshared local-area network. Under these circumstances, migration involves two\nmajor problems: migrating the entire memory image and migrating bindings\nto local resources.\nAs to the first problem, there are, in principle, three ways to handle\nmigration (which can be combined):\n1. Pushing memory pages to the new machine and resending the ones that\nare later modified during the migration process.\n2. Stopping the current virtual machine; migrate memory, and start the\nnew virtual machine.\n3. Letting the new virtual machine pull in new pages as needed, that is,\nlet processes start on the new virtual machine immediately and copy\nmemory pages on demand.\nThe second option may lead to unacceptable downtime if the migrating\nvirtual machine is running a live service, that is, one that offers continuous\nservice. On the other hand, a pure on-demand approach as represented by\nthe third option may extensively prolong the migration period, but may also\nlead to poor performance because it takes a long time before the working set\nof the migrated processes has been moved to the new machine.\nAs an alternative, Clark et al. [2005] propose to use a pre-copy approach\nwhich combines the first option, along with a brief stop-and-copy phase as\nrepresented by the second option. As it turns out, this combination can lead\nto very low service downtimes.\n \nDS 4.01\n\n\n176\nCHAPTER 3. PROCESSES\nConcerning local resources, matters are simplified when dealing only with\na cluster server. First, because there is a single network, the only thing that\nneeds to be done is to announce the new network-to-MAC address binding, so\nthat clients can contact the migrated processes at the correct network interface.\nFinally, if it can be assumed that storage is provided as a separate tier (like we\nshowed in Figure 3.23), then migrating binding to files is similarly simple, as\nit effectively means reestablishing network connections.\nMatters become more intricate when we need to migrate a virtual machine\nto another data center. Although the transfer of memory can be largely\ndone as before, we do need to actually transfer files to the target data center.\nSomewhat problematic is also the network connectivity: one way or the other\nclients need to be able to continue contacting the virtual machine while, and\nafter, its migration to the new destination. Zhang et al. [2018] mention various\nsolutions. In essence, many of these either boil down to extending the local\nnetwork to the target using techniques such as tunneling, or using techniques\nthat support transparent reassigning of network addresses (meaning that a\nclient uses dynamic rebinding to actual network addresses).\nNote 3.9 (Advanced: On the performance of live virtual machine migration)\nOne potential problem with virtual-machine migration is that it may take consid-\nerable time. This by itself need not be bad, as long as the services that are running\non the migrating virtual machine can continue to operate. An approach used in\npractice was briefly described above. First, memory pages are copied to the target\nmachine, possibly sending updates of pages that were modified while copying\ntook place (remember that copying lots of memory may take tens of seconds, even\nacross a high-speed local network). Second, when most pages have been faithfully\ncopied, the current machine is stopped, the remaining dirty pages are copied to\nthe target, where the now exact copy can be started where the original left off.\nThe downtime in which the remaining dirty pages need to be copied depends\non the applications running on the virtual machine. Clark et al. [2005] report\ndowntimes for specific configurations between 60 milliseconds and less than 4\nseconds. Voorsluys et al. [2009] come to similar values. However, what may be\nmore interesting is to observe what the response time is of the service running\non the virtual machine while the latter is being migrated. The model in this\ncase is that the service continues to operate on the original machine until full\nmigration has completed. However, we cannot ignore that migration itself is a\nresource-intensive operation, requiring considerable processing capacity as well\nas network bandwidth.\nVoorsluys et al. [2009] have observed that a complete migration may actually\ntake tens of seconds, leading to a ten- to twentyfold increase in response time. In\naddition, we need to realize that during the migration, a service will be completely\nunavailable (i.e., unresponsive) for perhaps 4 seconds. The good news is that\nthe response time goes up significantly only after the downtime to complete the\nmigration, as shown in Figure 3.29.\nDS 4.01\n \n\n\n3.6. SUMMARY\n177\nOften, virtual machines are migrated to optimize the usage of actual machines.\nHowever, it may also be desirable to clone a virtual machine, for example because\nthe workload for the current machine is becoming too high. Such cloning is very\nsimilar to using multiple processes in concurrent servers, by which a dispatcher\nprocess creates worker processes to handle incoming requests. This scheme was\nexplained in Figure 3.6 when discussing multithreaded servers.\nFigure 3.29: The effect on the response time of a service while migrating\nits underlying virtual machine. Adapted from Voorsluys et al. [2009].\nWhen cloning for this type of performance, it often makes more sense not to\nfirst copy memory pages, but, in fact, start with as few pages as possible as the\nservice running on the cloned machine will essentially start anew. Note that this\nbehavior is very similar to the usual parent-child behavior we see when forking a\nUnix process. Namely, the child will start with loading its own executable, thereby\neffectively cleaning the memory it inherited from its parent. This analogy inspired\nLagar-Cavilla et al. [2009] to develop an analogous mechanism for forking a virtual\nmachine. However, unlike the mechanism used traditionally for migrating virtual\nmachines, their VM fork copies pages primarily on demand. The result is an\nextremely efficient cloning mechanism.\nIt is thus seen that there is no single best way to place copies of a virtual\nmachine on different physical machines: it very much depends on how and why\na virtual machine is being deployed.\n3.6\nSummary\nProcesses play a fundamental role in distributed systems, as they form a\nbasis for communication between different machines. An important issue\nis how processes are internally organized and, in particular, whether or not\nthey support multiple threads of control. Threads in distributed systems are\nparticularly useful to continue using the CPU when a blocking I/O operation\nis performed. In this way, it becomes possible to build highly efficient servers\nthat run multiple threads in parallel, of which several may be blocking to wait\nuntil disk I/O or network communication completes. In general, threads are\n \nDS 4.01\n\n\n178\nCHAPTER 3. PROCESSES\npreferred over the use of processes when performance is at stake.\nVirtualization has since long been an important field in computer science,\nbut in the advent of cloud computing has regained tremendous attention. Pop-\nular virtualization schemes allow users to run a suite of applications on top\nof their favorite operating system and configure complete virtual distributed\nsystems in the cloud. Impressively enough, performance remains close to run-\nning applications on the host operating system, unless that system is shared\nwith other virtual machines or when the virtual machine is I/O bound. The\nflexible application of virtual machines has led to different types of services\nfor cloud computing, including infrastructures, platforms, and software —\nall running in virtual environments. A special form of virtualization is that\nof containerization, which boils down to providing an application with its\nown environment (notably libraries and specific supporting programs) while\nsharing the same operating system. By sharing the same operating system,\ncontainers generally tend to perform better in the case of I/O-bound appli-\ncations, yet it is fair to say that differences in performance between virtual\nmachines and containers is diminishing.\nOrganizing a distributed application in terms of clients and servers has\nproven to be useful. Client processes generally implement user interfaces,\nwhich may range from simple displays to advanced interfaces that can handle\ncompound documents. Client software is furthermore aimed at achieving\ndistribution transparency by hiding details concerning the communication\nwith servers, where those servers are currently located, and whether servers\nare replicated. In addition, client software is partly responsible for hiding fail-\nures and recovery from failures. An interesting phenomenon is the increasing\npopularity of virtual desktop environments, by which an entire desktop more\nor less runs in the cloud.\nServers are often more intricate than clients, but are nevertheless subject\nto only a relatively few design issues. For example, servers can either be\niterative or concurrent, implement one or more services, and can be stateless\nor stateful. Other design issues deal with addressing services and mechanisms\nto interrupt a server after a service request has been issued and is possibly\nalready being processed.\nSpecial attention needs to be paid when organizing servers into a cluster.\nA common objective is to hide the internals of a cluster from the outside\nworld. This means that the organization of the cluster should be shielded\nfrom applications. To this end, most clusters use a single entry point that\ncan hand off messages to servers in the cluster. A challenging problem is to\ntransparently replace this single entry point by a fully distributed solution.\nAdvanced object servers have been developed for hosting remote objects.\nAn object server provides many services to basic objects, including facilities\nfor storing objects, or to ensure serialization of incoming requests. Another\nimportant role is providing the illusion to the outside world that a collection\nDS 4.01\n \n\n\n3.6. SUMMARY\n179\nof data and procedures operating on that data correspond to the concept of an\nobject. This role is implemented by object adapters. Object-based systems have\ncome to a point where we can build entire frameworks that can be extended\nfor supporting specific applications. Java has proven to provide a powerful\nmeans for setting up more generic services, exemplified by the highly popular\nEnterprise Java Beans concept and its implementation.\nAn exemplary server for Web-based systems is the one from Apache.\nAgain, the Apache server can be seen as a general solution for handling a\nmyriad of HTTP-based queries. By offering the right hooks, we essentially ob-\ntain a flexibly configurable Web server. Apache has served as an example not\nonly for traditional Websites, but also for setting up clusters of collaborative\nWeb servers, even across wide-area networks.\nAn important development is that of content delivery networks in wide-\narea networks, which facilitate accessing data and other resources close to\nclients. An essential component is ensuring that resources from an origin\nserver are copied to the proper edge servers transparently. To this end, the\ncombination of client-request redirection techniques and advanced nearby\ncaching is essential.\nAnother important topic for distributed systems is the migration of code\nbetween different machines. Two important reasons to support code migration\nare increasing performance and flexibility. When communication is expensive,\nwe can sometimes reduce communication by shipping computations from\nthe server to the client, and let the client do as much local processing as\npossible. Flexibility is increased if a client can dynamically download software\nneeded to communicate with a specific server. The downloaded software\ncan be specifically targeted to that server, without forcing the client to have\nit preinstalled. Lately, we see that also privacy and security have become\nreasons for migrating code, as is illustrated by federated learning.\nCode migration brings along problems related to usage of local resources\nfor which it is required that either resources are migrated as well, new bind-\nings to local resources at the target machine are established, or for which\nsystemwide network references are used. Another problem is that code mi-\ngration requires that we take heterogeneity into account. Current practice\nindicates that the best solution to handle heterogeneity is to use virtual ma-\nchines. These can take either the form of process virtual machines as in the\ncase of, for example, Java, or through using virtual machine monitors that\neffectively allow the migration of a collection of processes along with their\nunderlying operating system.\n \nDS 4.01\n\n\n04\nCOMMUNICATION\n\n\n182\nCHAPTER 4. COMMUNICATION\nInterprocess communication is at the heart of all distributed systems. It\nmakes no sense to study distributed systems without carefully examining\nthe ways that processes on different machines can exchange information.\nCommunication in distributed systems has traditionally always been based on\nlow-level message passing as offered by the underlying network. Expressing\ncommunication through message passing is more difficult than using prim-\nitives based on shared memory, as available for nondistributed platforms.\nModern distributed systems often consist of thousands or even millions of\nprocesses scattered across a network with unreliable communication, such as\nthe Internet. Unless the primitive communication facilities of computer net-\nworks are replaced by something else, development of large-scale distributed\napplications is extremely difficult.\nIn this chapter, we start by discussing the rules that communicating pro-\ncesses must adhere to, known as protocols, and concentrate on structuring\nthose protocols in the form of layers. We then look at two widely used models\nfor communication: Remote Procedure Call (RPC), and Message-Oriented\nMiddleware (MOM). We also discuss the general problem of sending data to\nmultiple receivers, called multicasting.\nOur first model for communication in distributed systems is the remote\nprocedure call (RPC). An RPC aims at hiding most of the intricacies of message\npassing, and is ideal for client-server applications. However, realizing RPCs\ntransparently is easier said than done. We look at several important details\nthat cannot be ignored, while diving into actually code to illustrate to what\nextent distribution transparency can be realized such that performance is still\nacceptable.\nIn many distributed applications, communication does not follow the\nrather strict pattern of client-server interaction. In those cases, it turns out\nthat thinking in terms of messages is more appropriate. The low-level com-\nmunication facilities of computer networks are in many ways not suitable,\nagain due to their lack of distribution transparency. An alternative is to use a\nhigh-level message-queuing model, in which communication proceeds much\nthe same as in e-mail systems. Message-oriented communication is a subject\nimportant enough to warrant a section of its own. We look at numerous\naspects, including application-level routing.\nFinally, since our understanding of setting up multicast facilities has im-\nproved, novel and elegant solutions for data dissemination have emerged.\nWe pay separate attention to this subject in the last section of this chapter,\ndiscussing traditional deterministic means of multicasting, as well as proba-\nbilistic approaches as used in flooding and gossiping. The latter have been\nreceiving much attention over the past years due to their elegance, reliability,\nand simplicity.\nDS 4.01\n \n",
      "page_number": 181
    },
    {
      "number": 20,
      "title": "Segment 20 (pages 194-202)",
      "start_page": 194,
      "end_page": 202,
      "detection_method": "topic_boundary",
      "content": "4.1. FOUNDATIONS\n183\n4.1\nFoundations\nBefore we start our discussion on communication in distributed systems, we\nfirst recapitulate some fundamental issues related to communication. In the\nnext section, we briefly discuss network communication protocols, as these\nform the basis for any distributed system. Thereafter, we take a different\napproach by classifying the different types of communication that usually\noccur in distributed systems.\n4.1.1\nLayered Protocols\nDue to the absence of shared memory, all communication in distributed\nsystems is based on sending and receiving (low level) messages.\nWhen\nprocess P wants to communicate with process Q, it first builds a message in\nits own address space. Then it executes a system call that causes the operating\nsystem to send the message over the network to Q. Although this basic\nidea sounds simple enough, to prevent chaos, P and Q have to agree on the\nmeaning of the bits being sent.\nThe OSI reference model\nTo make it easier to deal with the numerous levels and issues involved in\ncommunication, the International Standards Organization (ISO) developed a\nreference model that clearly identifies the various levels involved, gives them\nstandard names, and points out which level should do which job. This model\nis called the Open Systems Interconnection Reference Model [Day and\nZimmerman, 1983] usually abbreviated as ISO OSI or sometimes just the OSI\nmodel. It should be emphasized that the protocols that were developed as part\nof the OSI model were never widely used and are essentially dead. However,\nthe underlying model itself has proved to be quite useful for understanding\ncomputer networks. Although we do not intend to give a full description of\nthis model and all of its implications here, a brief introduction will be helpful.\nFor more details, see [Tanenbaum et al., 2021].\nThe OSI model is designed to allow open systems to communicate. An\nopen system is one that is prepared to communicate with any other open\nsystem by using standard rules that govern the format, contents, and meaning\nof the messages sent and received. These rules are formalized in what are\ncalled communication protocols. To allow a group of computers to commu-\nnicate over a network, they must all agree on the protocols to be used. A\nprotocol is said to provide a communication service. There are two types of\nsuch services. In the case of a connection-oriented service, before exchang-\ning data the sender and receiver first explicitly establish a connection, and\npossibly negotiate specific parameters of the protocol they will use. When\nthey are done, they release (terminate) the connection. The telephone is a\n \nDS 4.01\n\n\n184\nCHAPTER 4. COMMUNICATION\ntypical connection-oriented communication service. With a connectionless\nservices, no setup in advance is needed. The sender just transmits the first\nmessage when it is ready. Dropping a letter in a mailbox is an example of\nmaking use of connectionless communication service. With computers, both\nconnection-oriented and connectionless communication are common.\nFigure 4.1: Layers, interfaces, and protocols in the OSI model.\nIn the OSI model, communication is divided into seven levels or layers, as\nshown in Figure 4.1. Each layer offers one or more specific communication\nservices to the layer above it. In this way, the problem of getting a message\nfrom A to B can be divided into manageable pieces, each of which can be\nsolved independently of the others. Each layer provides an interface to the\none above it. The interface consists of a set of operations that together define\nthe service the layer is prepared to offer. The seven OSI layers are:\nPhysical layer Deals with standardizing how two computers are connected\nand how 0s and 1s are represented.\nData link layer Provides the means to detect and possibly correct transmis-\nsion errors, as well as protocols to keep a sender and receiver in the\nsame pace.\nNetwork layer Contains the protocols for routing a message through a com-\nputer network, as well as protocols for handling congestion.\nTransport layer Mainly contains protocols for directly supporting applica-\ntions, such as those that establish reliable communication, or support\nreal-time streaming of data.\nDS 4.01\n \n\n\n4.1. FOUNDATIONS\n185\nSession layer Provides support for sessions between applications.\nPresentation layer Prescribes how data is represented in a way that is inde-\npendent of the hosts on which communicating applications are running.\nApplication layer Essentially, everything else: e-mail protocols, Web access\nprotocols, file-transfer protocols, and so on.\nWhen a process P wants to communicate with some remote process Q, it\nbuilds a message and passes that message to the application layer as offered\nto it through an interface. This interface will typically appear in the form of a\nlibrary procedure. The application layer software then adds a header to the\nfront of the message and passes the resulting message across the layer 6/7\ninterface to the presentation layer. The presentation layer, in turn, adds its\nown header and passes the result down to the session layer, and so on. Some\nlayers add not only a header to the front, but also a trailer to the end. When\nit hits the bottom, the physical layer actually transmits the message (which\nby now might look as shown in Figure 4.2) by putting it onto the physical\ntransmission medium.\nFigure 4.2: A typical message as it appears on the network.\nWhen the message arrives at the remote machine hosting Q, it is passed\nupward, with each layer stripping off and examining its own header. Finally,\nthe message arrives at the receiver, process Q, which may reply to it using\nthe reverse path. The information in the layer-n header is used for the layer-n\nprotocol.\nIn the OSI model, there are not two layers, but seven, as we saw in\nFigure 4.1. The collection of protocols used in a particular system is called\na protocol suite or protocol stack. It is important to distinguish a reference\nmodel from its actual protocols. As said, the OSI protocols were never popular,\nin contrast to protocols developed for the Internet, such as TCP and IP.\n \nDS 4.01\n\n\n186\nCHAPTER 4. COMMUNICATION\nNote 4.1 (More information: Protocols in the OSI model)\nLet us briefly examine each of the OSI layers in turn, starting at the bottom.\nInstead of giving examples of OSI protocols, where appropriate, we will point out\nsome Internet protocols used in each layer.\nLower-level protocols\nThe three lowest layers of the OSI protocol suite imple-\nment the basic functions that encompass a computer network.\nThe physical layer is concerned with transmitting the 0s and 1s. How many\nvolts to use for 0 and 1, how many bits per second can be sent, and whether\ntransmission can take place in both directions simultaneously are key issues in\nthe physical layer. In addition, the size and shape of the network connector (plug),\nas well as the number of pins and meaning of each, are of concern here.\nThe physical layer protocol deals with standardizing the electrical, optical,\nmechanical, and signaling interfaces so that when one machine sends a 0 bit it is\nactually received as a 0 bit and not a 1 bit. Many physical layer standards have\nbeen developed (for different media), for example, the USB standard for serial\ncommunication lines.\nThe physical layer just sends bits. As long as no errors occur, all is well.\nHowever, real communication networks are subject to errors, so some mechanism\nis needed to detect and correct them. This mechanism is the main task of the data\nlink layer. What it does is to group the bits into units, also called frames, and see\nthat each frame is correctly received.\nThe data link layer does its work by putting a special bit pattern on the start\nand end of each frame to mark them, as well as computing a checksum by adding\nup all the bytes in the frame in a certain way. The data link layer appends the\nchecksum to the frame. When the frame arrives, the receiver recomputes the\nchecksum from the data and compares the result to the checksum following\nthe frame. If the two agree, the frame is considered correct and is accepted. If\nthey disagree, the receiver asks the sender to retransmit it. Frames are assigned\nsequence numbers (in the header), so everyone can tell which is which.\nOn a LAN, there is usually no need for the sender to locate the receiver. It just\nputs the message out on the network and the receiver takes it off. A wide-area\nnetwork, however, consists of numerous machines, each with some number of\nlines to other machines, rather like a large-scale map showing major cities and\nroads connecting them. For a message to get from the sender to the receiver it\nmay have to make a number of hops, at each one choosing an outgoing line to use.\nThe question of how to choose the best path is called routing, and is essentially\nthe primary task of the network layer.\nThe problem is complicated by the fact that the shortest route is not always\nthe best route. What really matters is the amount of delay on a given route, which,\nin turn, is related to the amount of traffic and the number of messages queued up\nfor transmission over the various lines. The delay can thus change over the course\nof time. Some routing algorithms try to adapt to changing loads, whereas others\nare content to make decisions based on long-term averages.\nDS 4.01\n \n\n\n4.1. FOUNDATIONS\n187\nAt present, the most widely used network protocol is the connectionless IP\n(Internet Protocol), which is part of the Internet protocol suite. An IP packet (the\ntechnical term for a message in the network layer) can be sent without any setup.\nEach IP packet is routed to its destination independent of all others. No internal\npath is selected and remembered.\nTransport protocols\nThe transport layer forms the last part of what could be\ncalled a basic network protocol stack, in the sense that it implements all those\nservices that are not provided at the interface of the network layer, but which are\nreasonably needed to build network applications. In other words, the transport\nlayer turns the underlying network into something that an application developer\ncan use.\nPackets can be lost on the way from the sender to the receiver. Although\nsome applications can handle their own error recovery, others prefer a reliable\nconnection. The job of the transport layer is to provide this service. The idea is\nthat the application layer should be able to deliver a message to the transport\nlayer with the expectation that it will be delivered without loss.\nUpon receiving a message from the application layer, the transport layer\nbreaks it into pieces small enough for transmission, assigns each one a sequence\nnumber, and then sends them all. The discussion in the transport layer header\nconcerns which packets have been sent, which have been received, how many\nmore the receiver has room to accept, which should be retransmitted, and similar\ntopics.\nReliable transport connections (which by definition are connection-oriented)\ncan be built on top of connection-oriented or connectionless network services. In\nthe former case all the packets will arrive in the correct sequence (if they arrive at\nall), but in the latter case it is possible for one packet to take a different route and\narrive earlier than the packet sent before it. It is up to the transport layer software\nto put everything back to maintain the illusion that a transport connection is like\na big tube–you put messages into it, and they come out undamaged and in the\nsame order in which they went in. Providing this end-to-end communication\nbehavior is an important aspect of the transport layer.\nThe Internet transport protocol is called TCP (Transmission Control Protocol)\nand is described in detail by Comer [2013]. The combination TCP/IP is now\nused as a de facto standard for network communication. The Internet protocol\nsuite also supports a connectionless transport protocol called UDP (Universal\nDatagram Protocol), which is essentially just IP with some minor additions. User\nprograms that do not need a connection-oriented protocol normally use UDP.\nAdditional transport protocols are regularly proposed. For example, to sup-\nport real-time data transfer, the Real-time Transport Protocol (RTP) has been\ndefined. RTP is a framework protocol in the sense that it specifies packet formats\nfor real-time data without providing the actual mechanisms for guaranteeing\ndata delivery. In addition, it specifies a protocol for monitoring and controlling\ndata transfer of RTP packets [Schulzrinne et al., 2003]. Likewise, the Streaming\nControl Transmission Protocol (SCTP) has been proposed as an alternative to\n \nDS 4.01\n\n\n188\nCHAPTER 4. COMMUNICATION\nTCP [Stewart, 2007]. The main difference between SCTP and TCP is that SCTP\ngroups data into messages, whereas TCP merely moves bytes between processes.\nDoing so may simplify application development.\nHigher-level protocols\nAbove the transport layer, OSI distinguishes three addi-\ntional layers. In practice, only the application layer is ever used. In fact, in the\nInternet protocol suite, everything above the transport layer is grouped together.\nIn the face of middleware systems, we shall see that neither the OSI nor the\nInternet approach is really appropriate.\nThe session layer is essentially an enhanced version of the transport layer. It\nprovides dialog control, to keep track of which party is currently talking, and it\nprovides synchronization facilities. The latter are useful to allow users to insert\ncheckpoints into long transfers, so that in the event of a crash, it is necessary to\ngo back only to the last checkpoint, rather than all the way back to the beginning.\nIn practice, few applications are interested in the session layer, and it is rarely\nsupported. It is not even present in the Internet protocol suite. However, in\nthe context of developing middleware solutions, the concept of a session and\nits related protocols has turned out to be quite relevant, notably when defining\nhigher-level communication protocols.\nUnlike the lower layers, which are concerned with getting the bits from the\nsender to the receiver reliably and efficiently, the presentation layer is concerned\nwith the meaning of the bits. Most messages do not consist of random bit strings,\nbut more structured information such as people’s names, addresses, amounts\nof money, and so on. In the presentation layer, it is possible to define records\ncontaining fields like these and then have the sender notify the receiver that a\nmessage contains a particular record in a certain format. This makes it easier for\nmachines with different internal representations to communicate with each other.\nThe OSI application layer was originally intended to contain a collection of\nstandard network applications such as those for electronic mail, file transfer, and\nterminal emulation. By now, it has become the container for all applications and\nprotocols that in one way or the other do not fit into one of the underlying layers.\nFrom the perspective of the OSI reference model, virtually all distributed systems\nare just applications.\nWhat is missing in this model is a clear distinction between applications,\napplication-specific protocols, and general-purpose protocols. For example, the\nInternet File Transfer Protocol (FTP) [Postel and Reynolds, 1985; Horowitz and\nLunt, 1997] defines a protocol for transferring files between a client and server\nmachine. The protocol should not be confused with the ftp program, which\nis an end-user application for transferring files and which also (not entirely\ncoincidentally) happens to implement the Internet FTP.\nAnother example of a typical application-specific protocol is the HyperText\nTransfer Protocol (HTTP) [Fielding and Reschke, 2014] which is designed to\nremotely manage and handle the transfer of Web pages. The protocol is imple-\nmented by applications such as Web browsers and Web servers. However, HTTP\nis now also used by systems that are not intrinsically tied to the Web. For example,\nDS 4.01\n \n\n\n4.1. FOUNDATIONS\n189\nJava’s object-invocation mechanism can use HTTP to request the invocation of\nremote objects that are protected by a firewall.\nThere are also many general-purpose protocols that are useful to many ap-\nplications, but which cannot be qualified as transport protocols. Often, such\nprotocols fall into the category of middleware protocols.\nMiddleware protocols\nMiddleware is an application that logically lives (mostly) in the OSI application\nlayer, but which contains many general-purpose protocols that warrant their\nown layers, independent of other, more specific applications. Let us briefly\nlook at some examples.\nThe Domain Name System (DNS) [Liu and Albitz, 2006] is a distributed\nservice that is used to look up a network address associated with a name, such\nas the address of a so-called domain name like www.distributed-systems.net.\nIn terms of the OSI reference model, DNS is an application and therefore\nis logically placed in the application layer.\nHowever, it should be quite\nobvious that DNS is offering a general-purpose, application-independent\nservice. Arguably, it forms part of the middleware.\nAs another example, there are various ways to establish authentication,\nthat is, provide proof of a claimed identity. Authentication protocols are\nnot closely tied to any specific application, but instead, can be integrated\ninto a middleware system as a general service.\nLikewise, authorization\nprotocols by which authenticated users and processes are granted access only\nto those resources for which they have authorization, tend to have a general,\napplication-independent nature. Being labeled as applications in the OSI\nreference model, these are clear examples that belong in the middleware.\nDistributed commit protocols establish that in a group of processes, pos-\nsibly spread out across several machines, either all processes carry out a\nparticular operation, or that the operation is not carried out at all. This phe-\nnomenon is also referred to as atomicity and is widely applied in transactions.\nAs it turns out, commit protocols can present an interface independently of\nspecific applications, thus providing a general-purpose transaction service.\nIn such a form, they typically belong to the middleware and not to the OSI\napplication layer.\nAs a last example, consider a distributed locking protocol, by which a\nresource can be protected against simultaneous access by a collection of pro-\ncesses that are distributed across multiple machines. It is not hard to imagine\nthat such protocols can be designed in an application-independent fashion,\nand accessible through a relatively simple, again application-independent\ninterface. As such, they generally belong in the middleware.\nThese protocol examples are not directly tied to communication, yet there\n \nDS 4.01\n\n\n190\nCHAPTER 4. COMMUNICATION\nFigure 4.3: An adapted reference model for networked communication.\nare also many middleware communication protocols. For example, with\na so-called remote procedure call, a process is offered a facility to locally\ncall a procedure that is effectively implemented on a remote machine. This\ncommunication service belongs to one of the oldest types of middleware\nservices and is used for realizing access transparency. In a similar vein, there\nare high-level communication services for setting and synchronizing streams\nfor transferring real-time data, such as needed for multimedia applications.\nAs a last example, some middleware systems offer reliable multicast services\nthat scale to thousands of receivers spread across a wide-area network.\nTaking this approach to layering leads to the adapted and simplified\nreference model for communication, as shown in Figure 4.3. Compared to\nthe OSI model, the session and presentation layer have been replaced by\na single middleware layer that contains application-independent protocols.\nThese protocols do not belong in the lower layers we just discussed. Network\nand transport services have been grouped into communication services as\nnormally offered by an operating system, which, in turn, manages the specific\nlowest-level hardware used to establish communication.\n4.1.2\nTypes of Communication\nIn the remainder of this chapter, we concentrate on high-level middleware\ncommunication services. Before doing so, there are other general criteria\nfor distinguishing (middleware) communication. To understand the various\nalternatives in communication that middleware can offer to applications, we\nview the middleware as an additional service in client-server computing, as\nshown in Figure 4.4. Consider, for example, an e-mail system. In principle, the\ncore of the mail delivery system can be seen as a middleware communication\nservice. Each host runs a user agent allowing users to compose, send, and\nreceive e-mail. A sending user agent passes such mail to the mail delivery\nDS 4.01\n \n\n\n4.1. FOUNDATIONS\n191\nsystem, expecting it, in turn, to eventually deliver the mail to the intended\nrecipient. Likewise, the user agent at the receiver’s side connects to the mail\ndelivery system to see whether any mail has come in. If so, the messages are\ntransferred to the user agent so that they can be read by the user.\nFigure 4.4: Viewing middleware as an intermediate (distributed) service in\napplication-level communication.\nAn e-mail system is a typical example in which communication is persis-\ntent. With persistent communication, a message that has been submitted\nfor transmission is stored by the communication middleware as long as it\ntakes to deliver it to the receiver. In this case, the middleware will store the\nmessage at one or several of the storage facilities shown in Figure 4.4. As\na consequence, it is not necessary for the sending application to continue\nexecution after submitting the message. Likewise, the receiving application\nneed not be executing when the message is submitted.\nIn contrast, with transient communication, a message is stored by the\ncommunication system only as long as the sending and receiving application\nare executing. More precisely, in terms of Figure 4.4, if the middleware cannot\ndeliver a message due to a transmission interrupt, or because the recipient is\ncurrently not active, it will simply be discarded. Typically, all transport-level\ncommunication services offer only transient communication. In this case, the\ncommunication system consists of traditional store-and-forward routers. If a\nrouter cannot deliver a message to the next one or the destination host, it will\nsimply drop the message.\nBesides being persistent or transient, communication can also be asyn-\nchronous or synchronous. The characteristic feature of asynchronous com-\nmunication is that a sender continues immediately after it has submitted its\nmessage for transmission. This means that the message is (temporarily) stored\nimmediately by the middleware upon submission. With synchronous com-\nmunication, the sender is blocked until its request is known to be accepted.\nThere are essentially three points where synchronization can take place. First,\n \nDS 4.01\n",
      "page_number": 194
    },
    {
      "number": 21,
      "title": "Segment 21 (pages 203-214)",
      "start_page": 203,
      "end_page": 214,
      "detection_method": "topic_boundary",
      "content": "192\nCHAPTER 4. COMMUNICATION\nthe sender may be blocked until the middleware notifies that it will take over\ntransmission of the request. Second, the sender may synchronize until its\nrequest has been delivered to the intended recipient. Third, synchronization\nmay take place by letting the sender wait until its request has been fully\nprocessed, that is, up to the time that the recipient returns a response.\nVarious combinations of persistence and synchronization occur in practice.\nPopular ones are persistence in combination with synchronization at request\nsubmission, which is a common scheme for many message-queuing systems,\nwhich we discuss later in this chapter. Likewise, transient communication\nwith synchronization after the request has been fully processed is also widely\nused. This scheme corresponds with remote procedure calls, which we discuss\nin the following section.\n4.2\nRemote procedure call\nMany distributed systems have been based on explicit message exchange\nbetween processes. However, the operations send and receive do not conceal\ncommunication at all, which is important to achieve access transparency in\ndistributed systems. This problem has long been known, but little was done\nabout it until researchers in the 1980s [Birrell and Nelson, 1984] introduced\nan entirely different way of handling communication. Although the idea is\nrefreshingly simple (once someone has thought of it), the implications are\noften subtle. In this section we will examine the concept, its implementation,\nits strengths, and its weaknesses.\nIn a nutshell, the proposal was to allow programs to call procedures\nlocated on other machines. When a process on a machine A calls a procedure\non a machine B, the calling process on A is suspended, and execution of the\ncalled procedure takes place on B. Information can be transported from the\ncaller to the callee in the parameters and can come back in the procedure\nresult. No message passing at all is visible to the programmer. This method is\nknown as remote procedure call, or often just RPC.\nWhile the basic idea sounds simple and elegant, subtle problems exist. To\nstart with because the calling and called procedures run on different machines,\nthey execute in different address spaces, which causes complications. Parame-\nters and results also have to be passed, which can be complicated, especially\nif the machines are not identical. Finally, either or both machines can crash,\nand each of the possible failures causes different problems. Still, most of these\ncan be dealt with, and RPC is a widely used technique that underlies many\ndistributed systems.\n4.2.1\nBasic RPC operation\nThe idea behind RPC is to make a remote procedure call look as much as\npossible as a local one. In other words, we want RPC to be transparent—the\nDS 4.01\n \n\n\n4.2. REMOTE PROCEDURE CALL\n193\ncalling procedure should not be aware that the called procedure is executing\non a different machine or vice versa. Suppose that a program has access to a\ndatabase that allows it to append data to a stored list, after which it returns a\nreference to the modified list. The operation is made available to a program\nby a routine append:\nnewlist = append(data, dbList)\nIn a traditional (single processor) system, append is extracted from a library\nby the linker and inserted into the object program. In principle, it can be a\nshort procedure, which could be implemented by a few file operations for\naccessing the database.\nEven though append eventually does only a few basic file operations, it\nis called in the usual way, by pushing its parameters onto the stack. The\nprogrammer does not know the implementation details of append, and this is,\nof course, how it is supposed to be.\nNote 4.2 (More information: Conventional procedure calls)\nTo understand how RPC works and some of its pitfalls, it may help to first under-\nstand how a conventional (i.e., single machine) procedure call works. Consider\nthe operation newlist = append(data, dbList);\nWe assume that the purpose of this call is to take a globally defined list object,\nreferred here to as dbList, and append a simple data element to it, represented\nby the variable data. An important observation is that in various programming\nlanguages such as C, dbList is implemented as a reference to a list object (i.e.,\na pointer), whereas data may be represented directly by its value (which we\nassume to be the case here). When calling append, both the representations of data\nand dbList are pushed onto the stack, making those representations accessible\nto the implementation of append. For data, this means the variable follows a\ncall-by-value policy, the policy for dblist is call-by-reference. What happens\nbefore and during the call is shown in Figure 4.5.\n(a)\n(b)\nFigure 4.5: (a) Parameter passing in a local procedure call: the stack before\nthe call to append. (b) The stack while the called procedure is active.\n \nDS 4.01\n\n\n194\nCHAPTER 4. COMMUNICATION\nSeveral things are worth noting. For one, a value parameter, such as data, is\njust an initialized local variable. The called procedure may modify it, but such\nchanges do not affect the original value at the calling side.\nWhen a parameter like dbList is actually a pointer to a variable rather than\nthe value of the variable, something else happens. What is pushed onto the stack\nis the address of the list object as stored in main memory. When the value of data\nis appended to the list, a call to append does modify the list object. The difference\nbetween call-by-value and call-by-reference is quite important for RPC.\nOne other parameter passing mechanism also exists, although it is not used\nin most programming languages. It is called call-by-copy/restore. It consists of\nhaving the variable copied to the stack by the caller, as in call-by-value, and then\ncopied back after the call, overwriting the caller’s original value. Under most\nconditions, this achieves the same effect as call-by-reference, but in some situations,\nsuch as the same parameter being present multiple times in the parameter list,\nthe semantics are different.\nThe decision of which parameter passing mechanism to use is normally made\nby the language designers and is a fixed property of the language. Every so\noften, it depends on the data type being passed. In C, for example, integers and\nother scalar types are always passed by value, whereas arrays are always passed\nby reference. Some Ada compilers use copy/restore for inout parameters, but\nothers use call-by-reference. The language definition permits either choice, which\nmakes the semantics a bit fuzzy. In Python, all variables are passed by reference,\nbut some actually get copied to local variables, thus mimicking the behavior of\ncopy-by-value.\nRPC achieves its transparency analogously. When append is actually a\nremote procedure, a different version of append, called a client stub, is offered\nto the calling client. Like the original one, it, too, is called using a normal\ncalling sequence. However, unlike the original one, it does not perform\nan append operation. Instead, it packs the parameters into a message and\nrequests that message to be sent to the server, as illustrated in Figure 4.6.\nFollowing the call to send, the client stub calls receive, blocking itself until\nthe reply comes back.\nFigure 4.6: The principle of RPC between a client and server program.\nDS 4.01\n \n\n\n4.2. REMOTE PROCEDURE CALL\n195\nWhen the message arrives at the server, the server’s operating system\npasses it to a server stub. A server stub is the server-side equivalent of a client\nstub: it is a piece of code that transforms requests coming in over the network\ninto local procedure calls. Typically, the server stub will have called receive\nand be blocked waiting for incoming messages. The server stub unpacks the\nparameters from the message and then calls the server procedure in the usual\nway. From the server’s perspective, it is as though it is being called directly by\nthe client—the parameters and return address are all on the stack where they\nbelong and nothing seems unusual. The server performs its work and then\nreturns the result to the caller (in this case the server stub) in the usual way.\nWhen the server stub gets control back after the call has completed, it packs\nthe result in a message and calls send to return it to the client. Thereafter, the\nserver stub usually does a call to receive again, to wait for the next incoming\nrequest.\nWhen the result message arrives at the client’s machine, the operating\nsystem passes it through the receive operation, which had been called pre-\nviously, to the client stub, and the client process is subsequently unblocked.\nThe client stub inspects the message, unpacks the result, copies it to its caller,\nand returns in the usual way. When the caller gets control following the call\nto append, all it knows is that it appended some data to a list. It has no idea\nthat the work was done remotely at another machine.\nThis blissful ignorance for the client is the beauty of the whole scheme. As\nfar as it is concerned, remote services are accessed by making ordinary (i.e.,\nlocal) procedure calls, not by calling send and receive. All the details of the\nmessage passing are hidden away in the two library procedures, just as the\ndetails of actually making system calls are hidden away in traditional libraries.\nTo summarize, a remote procedure call occurs in the following steps:\n1. The client procedure calls the client stub in the normal way.\n2. The client stub builds a message and calls the local operating system.\n3. The client’s OS sends the message to the remote OS.\n4. The remote OS gives the message to the server stub.\n5. The server stub unpacks the parameter(s) and calls the server.\n6. The server does the work and returns the result to the stub.\n7. The server stub packs the result in a message and calls its local OS.\n8. The server’s OS sends the message to the client’s OS.\n9. The client’s OS gives the message to the client stub.\n10. The stub unpacks the result and returns it to the client.\nThe first steps are shown in Figure 4.7 for an abstract two-parameter\nprocedure doit(a,b), where we assume that parameter a is of type type1, and\nb of type type2. The net effect of all these steps is to convert the local call by\nthe client procedure to the client stub, to a local call to the server procedure,\n \nDS 4.01\n\n\n196\nCHAPTER 4. COMMUNICATION\nImplementation\nof doit\nClient OS\nServer OS\nClient machine\nServer machine\nClient stub\nClient process\nServer process\n1. Client call to\nprocedure\n2. Stub builds\nmessage\n5. Stub unpacks\nmessage\n6. Stub makes\nlocal call to “doit”\n3. Message is sent\nacross the network\n4. Server OS\nhands message\nto server stub\nServer stub\nr =\na,b\ndoit(\n)\nr =\na,b\ndoit(\n)\nproc: “doit”\ntype1:  val(a)\ntype2:  val(b)\nproc: “doit”\ntype1:  val(a)\ntype2:  val(b)\nproc: “doit”\ntype1:  val(a)\ntype2:  val(b)\nFigure 4.7: The steps involved in calling a remote procedure doit(a,b). The\nreturn path for the result is not shown.\nwithout either client or server being aware of the intermediate steps or the\nexistence of the network.\nNote 4.3 (More information: An example in Python)\nTo make matters concrete, let us consider how a remote procedure call could\nbe implemented for the operation append discussed previously. Take a look at\nthe Python code shown in Figure 4.8 (from which we omit nonessential code\nfragments).\nThe class DBList is a simple representation of a list object, mimicking what one\nwould expect to see in a version that would be found in a database environment.\nThe client stub, represented by the class Client, consists of an implementation\nof append. When called with parameters data and dbList, the following happens.\nThe call is transformed into a tuple (APPEND, data, dbList) containing all the\ninformation the server would need to do its work. The client stub then sends the\nrequest off to the server, and subsequently waits for the response. In the channel\npackage, a recvFrom operation always returns a (sender,message) pair, allowing the\ncaller to identify the process who had sent the message. In our case, when the\nresponse comes in, the client stub finishes the call to append by simply passing\nthe returned message from the server to the program that initially called the stub.\nOn the server side, we see that in the server stub, the server waits for any\nincoming message, and inspects which operation it is required to call. Again, the\nchannel package returns the identifier of the original sender (line 24). Assuming\nthe server received a request to call append, it then simply does a local call to its\nimplementation of append with the appropriate parameters as also found in the\nrequest tuple. The result is then sent back to the identified client.\nNote that an actual client would simply call c.append(...) where c is an\ninstance of the class Client. Indeed, the call truly seems to take place locally.\nDS 4.01\n \n\n\n4.2. REMOTE PROCEDURE CALL\n197\n1 import channel, pickle\n2\n3 class DBList:\n4\ndef append(self, data):\n5\nself.value.extend(data)\n6\nreturn self\n7\n8 class Client:\n9\ndef append(self, data, dbList):\n10\nmsglst = (APPEND, data, dbList)\n# message payload\n11\nself.channel.sendTo(self.server, msglst)\n# send message to server\n12\nmsgrcv = self.channel.recvFrom(self.server) # wait for an incoming message\n13\n14\n# A call to recvFrom returns a [senderID, message] pair\n15\nreturn msgrcv[1]\n# pass returned message to caller\n16\n17 class Server:\n18\ndef append(self, data, dbList):\n19\nreturn dbList.append(data)\n20\n21\ndef run(self):\n22\nwhile True:\n23\nmsgreq = self.channel.recvFromAny() # wait for any request\n24\nclient = msgreq[0]\n# see who is the caller\n25\nmsgrpc = msgreq[1]\n# fetch the actual request\n26\n27\n# At this point, msgreq should have the form (operation, data, list)\n28\nif APPEND == msgrpc[0]:\n# check what is being requested\n29\nresult = self.append(msgrpc[1], msgrpc[2]) # do local call\n30\nself.channel.sendTo(client,result)\n# return response\nFigure 4.8: A simple RPC example for operation append.\n4.2.2\nParameter passing\nThe function of the client stub is to take its parameters, pack them into a\nmessage, and send them to the server stub. While this sounds straightforward,\nit is not quite as simple as it at first appears.\nPacking parameters into a message is called parameter marshaling. Re-\nturning to our append operation, we need to ensure that its two parameters\n(data and dbList) are sent over the network and correctly interpreted by the\nserver. The thing to realize, is that the server will just be seeing a series\nof bytes coming in that constitute the original message sent by the client.\nHowever, no additional information on what those bytes mean is normally\nprovided with the message. Also, we would be facing the same problem again:\nhow should the meta-information be recognized as such by the server?\n \nDS 4.01\n\n\n198\nCHAPTER 4. COMMUNICATION\nBesides this interpretation problem, we also need to handle the case that\nthe placement of bytes in memory may differ between machine architectures.\nIn particular, we need to account for the fact that some machines, such as\nIntel processors, number their bytes from right to left, whereas many others,\nsuch as the older ARM processors, number them the other way (ARM now\nsupports both). The Intel format is called little endian and the (older) ARM\nformat is called big endian. Byte ordering is also important for networking:\nalso here we can witness that machines may use a different ordering when\ntransmitting (and thus receiving) bits and bytes. However, big endian is what\nis normally used for transferring bytes across a network.\nThe solution to this problem is to transform data that is to be sent to a\nmachine- and network-independent format, next to making sure that both\ncommunicating parties expect the same message data type to be transmitted.\nThe latter can typically be solved at the level of programming languages. The\nformer is accomplished by using machine-dependent routines that transform\ndata to and from machine- and network-independent formats.\nMarshaling and unmarshaling is all about this transformation to neutral\nformats and forms an essential part of remote procedure calls.\nNote 4.4 (More information: An example in Python revisited)\n1 import channel, pickle\n2\n3 class Client:\n4\ndef append(self, data, dbList):\n5\nmsglst = (APPEND, data, dbList)\n# message payload\n6\nmsgsnd = pickle.dumps(msglst)\n# wrap call\n7\nself.channel.sendTo(self.server, msgsnd)\n# send request to server\n8\nmsgrcv = self.channel.recvFrom(self.server) # wait for response\n9\nretval = pickle.loads(msgrcv[1])\n# unwrap return value\n10\nreturn retval\n# pass it to caller\n11\n12 class Server:\n13\ndef run(self):\n14\nwhile True:\n15\nmsgreq = self.channel.recvFromAny() # wait for any request\n16\nclient = msgreq[0]\n# see who is the caller\n17\nmsgrpc = pickle.loads(msgreq[1])\n# unwrap the call\n18\nif APPEND == msgrpc[0]:\n# check what is being requested\n19\nresult = self.append(msgrpc[1], msgrpc[2]) # do local call\n20\nmsgres = pickle.dumps(result)\n# wrap the result\n21\nself.channel.sendTo(client,msgres)\n# send response\nFigure 4.9: A simple RPC example for operation append, but now with\nproper marshaling.\nDS 4.01\n \n\n\n4.2. REMOTE PROCEDURE CALL\n199\nIt is not difficult to see that the solution to remote procedure calling as shown\nin Figure 4.8 will not work in general. Only if the client and server are operating\non machines that obey the same byte-ordering rules and have the same machine\nrepresentations for data structures, will the exchange of messages as shown lead\nto correct interpretations. A robust solution is shown in Figure 4.9 (where we\nagain have omitted code for brevity).\nIn this example, we use the Python pickle library for marshaling and unmar-\nshaling data structures. Note that the code hardly changes in comparison to what\nwe have shown in Figure 4.8. The only changes occur just before sending, and\nafter receiving a message. Also note that both client and server are programmed\nto work on the same data structures, as we discussed above.\n(We do note that, behind the scene, whenever a class instance is passed as a\nparameter, Python generally takes care of pickling and later unpickling the instance.\nIn this sense, our explicit use of pickle is, strictly speaking, not necessary.)\nWe now come to a difficult problem: How are pointers, or in general,\nreferences passed? The answer is: only with the greatest of difficulty, if at\nall. A pointer is meaningful only within the address space of the process\nin which it is being used. Getting back to our append example, we stated\nthat the second parameter, dbList, is implemented through a reference to a\nlist stored in a database. If that reference is just a pointer to a local data\nstructure somewhere in the caller’s main memory, we cannot simply pass it\nto the server. The transferred pointer value will most likely be referring to\nsomething entirely different.\nOne solution is just to forbid pointers and reference parameters in general.\nHowever, these are so important that this solution is highly undesirable. In\nfact, it is often not necessary either. First, reference parameters are often used\nwith fixed-sized data types, such as static arrays, or with dynamic data types\nfor which it is easy to compute their size at runtime, such as strings or dynamic\narrays. In such cases, we can simply copy the entire data structure to which the\nparameter is referring, effectively replacing the copy-by-reference mechanism\nby copy-by-value/restore. Although this is semantically not always identical,\nit frequently is good enough. An obvious optimization is that when the client\nstub knows the referred data will be only read, there is no need to copy it\nback when the call has finished. Copy-by-value is thus good enough.\nMore intricate data types can often be supported as well, and certainly if a\nprogramming language supports those data types. For example, a language\nsuch as Python or Java supports user-defined classes, allowing a language\nsystem to provide fully automated marshaling and unmarshaling of those\ndata types. Note, however, that as soon as we are dealing with large, nested,\nor otherwise intricate dynamic data structures, automatic (un)marshaling may\nnot be available, or even desirable.\nThe problem with pointers and references, as discussed so far, is that\nthey make sense only locally: they refer to memory locations that have\n \nDS 4.01\n\n\n200\nCHAPTER 4. COMMUNICATION\nmeaning only to the calling process. Problems can be alleviated by using\nglobal references: references that are meaningful to the calling and the called\nprocess. For example, if the client and the server have access to the same file\nsystem, passing a file handle instead of a pointer may do the trick. There is\none important observation: both processes need to know exactly what to do\nwhen a global reference is passed. In other words, if we consider a global\nreference having an associated data type, the calling and called process should\nhave the same picture of the operations that can be performed. Moreover, both\nprocesses should have agreement on exactly what to do when a file handle\nis passed. Again, these are typically issues that can be solved by proper\nprogramming-language support. We will return to this subject shortly.\nNote 4.5 (Advanced: Parameter passing in object-based systems)\nObject-based systems often use global references. Consider the situation that\nall objects in the system can be accessed from remote machines. In that case,\nwe can consistently use object references as parameters in method invocations.\nReferences are passed by value, and thus copied from one machine to the other.\nWhen a process is given an object reference as the result of a method invocation, it\ncan simply bind to the object referred to when needed later (see also Section 2.1.2).\nUnfortunately, using only distributed objects can be highly inefficient, espe-\ncially when objects are small, such as integers, or worse yet, Booleans. Each\ninvocation by a client that is not co-located in the same server as the object, gener-\nates a request between different address spaces or, even worse, between different\nmachines. Therefore, references to remote objects and those to local objects are\noften treated differently.\nLocal object\nO1\nCopy of O1\nRemote object\nO2\nLocal\nreference L1\nNew local\nreference\nRemote\nreference R1\nRemote\ninvocation with\nL1 and R1 as\nparameters\nCopy of R1 to O2\nMachine A\nMachine B\nMachine C\nClient code with\nRMI to server at C\n(proxy)\nServer code\n(method implementation)\nFigure 4.10: Passing an object by reference or by value.\nWhen invoking a method with an object reference as parameter, that reference\nis copied and passed as a value parameter only when it refers to a remote object.\nIn this case, the object is literally passed by reference. However, when the reference\nrefers to a local object, that is an object in the same address space as the client,\nthe referred object is copied as a whole and passed along with the invocation. In\nDS 4.01\n \n\n\n4.2. REMOTE PROCEDURE CALL\n201\nother words, the object is passed by value.\nThese two situations are illustrated in Figure 4.10 which shows a client pro-\ngram running on a machine A, and a server program on a machine C. The client\nhas a reference to a local object O1 that it uses as a parameter when calling the\nserver program on machine C. In addition, it holds a reference to a remote object\nO2 residing at machine B, which is also used as a parameter. When calling the\nserver, a copy of O1 is passed to the server on machine C, along with only a copy\nof the reference to O2.\nNote that whether we are dealing with a reference to a local object or a\nreference to a remote object can be highly transparent, such as in Java. In Java, the\ndistinction is visible only because local objects are essentially of a different data\ntype than remote objects. Otherwise, both types of references are treated very\nmuch the same (see also [Wollrath et al., 1996]). On the other hand, when using\nconventional programming languages such as C, a reference to a local object can\nbe as simple as a pointer, which can never be used to refer to a remote object.\nThe side effect of invoking a method with an object reference as parameter is\nthat we may be copying an object. Obviously, hiding this aspect is unacceptable\nso that we are consequently forced to make an explicit distinction between local\nand distributed objects. Clearly, this distinction not only violates distribution\ntransparency, but also makes it harder to write distributed applications.\nWe can now also easily explain how global references can be implemented\nwhen using portable, interpreted languages such as Python or Java: use the entire\nclient stub as a reference. The key observation is that a client stub is often just\nanother data structure that is compiled into (portable) bytecode. That compiled\ncode can actually be transferred across the network and executed at the receiver’s\nside. In other words, there is no need for explicit binding anymore; simply\ncopying the client stub to the recipient is enough to allow the latter to invoke the\nassociated server-side object. Of course, it may be necessary to marshall that code\nbefore shipping it to the other machine, although strictly speaking, there is no\nreason why that other machine would work with different layouts.\n4.2.3\nRPC-based application support\nFrom what we have explained so far, it is clear that hiding a remote procedure\ncall requires that the caller and the callee agree on the format of the messages\nthey exchange and that they follow the same steps when it comes to, for\nexample, passing complex data structures. In other words, both sides in an\nRPC should follow the same protocol or the RPC will not work correctly.\nThere are at least two ways in which RPC-based application development can\nbe supported. The first one is to let a developer specify exactly what needs\nto be called remotely, from which complete client-side and server-side stubs\ncan be generated. A second approach is to embed remote procedure calling\nas part of a programming-language environment.\n \nDS 4.01\n\n\n202\nCHAPTER 4. COMMUNICATION\nStub generation\nConsider the function someFunction of Figure 4.11(a). It has three parameters,\na character, a floating-point number, and an array of five integers. Assuming a\nword is four bytes, the RPC protocol might prescribe that we should transmit a\ncharacter in the rightmost byte of a word (leaving the next three bytes empty),\na float as a whole word, and an array as a group of words whose size is\nequal to the array length, preceded by a word giving the length, as shown in\nFigure 4.11(b). Thus given these rules, the client stub for someFunction knows\nthat it must use the format of Figure 4.11(b), and the server stub knows that\nincoming messages for someFunction will have the format of Figure 4.11(b).\nvoid someFunction(char x; float y; int z[5])\n(a)\n(b)\nFigure 4.11: (a) A function. (b) The corresponding message, and the order in\nwhich bytes and words are sent across the network.\nDefining the message format is one aspect of an RPC protocol, but it\nis not sufficient. What we also need is the client and the server to agree\non the representation of simple data structures, such as integers, characters,\nBooleans, etc. For example, the protocol could prescribe that integers are\nrepresented in two’s complement, characters in 16-bit Unicode, and floats in\nthe IEEE standard #754 format, with everything stored in little endian. With\nthis additional information, messages can be unambiguously interpreted.\nWith the encoding rules now pinned down to the last bit, the only thing\nthat remains to be done is that the caller and callee agree on the actual\nexchange of messages. For example, it may be decided to use a connection-\noriented transport service, such as TCP/IP. An alternative is to use an unreli-\nable datagram service and let the client and server implement an error control\nscheme as part of the RPC protocol. In practice, several variants exist, and it\nis up to the developer to indicate the preferred underlying communication\nservice.\nOnce the RPC protocol has been fully defined, the client and server stubs\nneed to be implemented. Fortunately, stubs for the same protocol, but different\nDS 4.01\n \n\n\n4.2. REMOTE PROCEDURE CALL\n203\nprocedures, normally differ only in their interface to the applications. An\ninterface consists of a collection of procedures that can be called by a client,\nand which are implemented by a server. An interface is usually available in\nthe same programming language as the one in which the client or server is\nwritten (although this is, strictly speaking, not necessary). To simplify matters,\ninterfaces are often specified through an Interface Definition Language (IDL).\nAn interface specified in such an IDL is then subsequently compiled into a\nclient stub and a server stub, along with the appropriate compile-time or\nrun-time interfaces. This process is sketched in Figure 4.12.\nFigure 4.12: The principle of generating stubs from an interface definition file.\nThe figure shows the situation for compiled languages, yet it is not hard\nto imagine that a very similar situation holds for interpreted languages. Also\nnote that it is possible that the client and server code are written in different\nlanguages. There is no principal reason why the client side cannot consist of\ncomponents written in, for example, Python, while the server side is written\nin C. Of course, in that case, the box in Figure 4.12 representing common\nincludes will then contain separate files for the client and server, respectively.\nImportant in this scheme is the runtime library: it forms the interface to the\nactual runtime system, constituting the middleware.\nPractice shows that using an interface definition language considerably\nsimplifies client-server applications based on RPCs. Because it is easy to fully\n \nDS 4.01\n",
      "page_number": 203
    },
    {
      "number": 22,
      "title": "Segment 22 (pages 215-223)",
      "start_page": 215,
      "end_page": 223,
      "detection_method": "topic_boundary",
      "content": "204\nCHAPTER 4. COMMUNICATION\ngenerate client and server stubs, all RPC-based middleware systems offer an\nIDL to support application development. In some cases, using the IDL is even\nmandatory.\nNote 4.6 (More information: Language-based RPC in Python)\nLet us see by an example of how remote procedure calling can be integrated in a\nlanguage. We have been using the Python language for most of our examples, and\nwill continue to do so now as well. In Figure 4.13 we show a simple server for our\nDBList data structure. In this case, it has two exposed operations: exposed_append\nfor appending elements, and exposed_value to display what is currently in the\nlist. We use the Python RPyC package for embedding RPCs.\n1 import rpyc\n2 from rpyc.utils.server import ForkingServer\n3\n4 class DBList(rpyc.Service):\n5\nvalue = [] # Used to build a list of strings\n6\n7\ndef exposed_append(self, data):\n8\nself.value.extend(str(data)) # Extend the list with the data\n9\nreturn self.value\n# Return the current list\n10\n11 class Server:\n12\n# Create a forking server at inititalization time and immediately start it.\n13\n# For each incoming request, the server will spawn another process to handle\n14\n# that request. The process that started the (main) server can simply kill\n15\n# it when it’s time to do so.\n16\ndef __init__(self):\n17\nself.server = ForkingServer(DBList, hostname=SERVER, port=PORT)\n18\n19\ndef start(self):\n20\nself.server.start()\n21\n22 class Client:\n23\ndef run(self):\n24\nconn = rpyc.connect(SERVER, PORT) # Connect to the server\n25\nconn.root.exposed_append(2)\n# Call an exposed operation,\n26\nconn.root.exposed_append(4)\n# and append two elements\n27\nprint(conn.root.exposed_value())\n# Print the result\nFigure 4.13: Embedding RPCs in a language\nThe client is also shown in Figure 4.13. When a connection is made to the\nserver, a new instance of DBList will be created and the client can immediately\nappend values to the list. The exposed operations are called without further ado.\nNote that as the client breaks the connection to the server, the list will be lost.\nIt is a transient object and special measures will need to be taken to make it a\npersistent object.\nDS 4.01\n \n\n\n4.2. REMOTE PROCEDURE CALL\n205\nLanguage-based support\nThe approach described up until now is largely independent of a specific pro-\ngramming language. As an alternative, we can also embed remote procedure\ncalling into a language itself. The main benefit is that application development\noften becomes much simpler. Furthermore, reaching a high degree of access\ntransparency is often simpler, as many issues related to parameter passing\ncan be circumvented altogether.\nA well-known example in which remote procedure calling is fully em-\nbedded is Java, where an RPC is referred to as a remote method invocation\n(RMI). In essence, a client being executed by its own (Java) virtual machine\ncan invoke a method of an object managed by another virtual machine. By\nsimply reading an application’s source code, it may be hard or even impossible\nto see whether a method invocation is to a local or to a remote object.\n4.2.4\nVariations on RPC\nAs in conventional procedure calls, when a client calls a remote procedure, the\nclient will block until a reply is returned. This strict request-reply behavior\nis unnecessary when there is no result to return, or may hinder efficiency\nwhen multiple RPCs need to be performed. In the following, we look at two\nvariations on the RPC scheme we have discussed so far.\nAsynchronous RPC\nTo support situations in which there is simply no result to return to the client,\nRPC systems may provide facilities for what are called asynchronous RPCs.\nWith asynchronous RPCs, the server, in principle, immediately sends a reply\nback to the client the moment the RPC request is received, after which it\nlocally calls the requested procedure. The reply acts as an acknowledgment\nto the client that the server is going to process the RPC. The client will\ncontinue without further blocking as soon as it has received the server’s\nacknowledgment. Figure 4.14(b) shows how client and server interact in the\ncase of asynchronous RPCs. For comparison, Figure 4.14(a) shows the normal\nrequest-reply behavior.\nAsynchronous RPCs can also be useful when a reply will be returned, but\nthe client is not prepared to wait for it and do nothing in the meantime. A\ntypical case is when a client needs to contact several servers independently.\nIn that case, it can send the call requests one after the other, effectively\nestablishing that the servers operate more or less in parallel. After all call\nrequests have been sent, the client can start waiting for the various results to be\nreturned. In cases such as these, it makes sense to organize the communication\nbetween the client and server through an asynchronous RPC combined with a\ncallback, as shown in Figure 4.15. In this scheme, also referred to as deferred\nsynchronous RPC, the client first calls the server, waits for the acceptance,\n \nDS 4.01\n\n\n206\nCHAPTER 4. COMMUNICATION\n(a)\n(b)\nFigure 4.14: (a) The interaction between client and server in a traditional RPC.\n(b) The interaction using asynchronous RPC.\nand continues. When the results become available, the server sends a response\nmessage that leads to a callback at the client’s side. A callback is a user-defined\nfunction that is invoked when a special event happens, such as an incoming\nmessage. A straightforward implementation is to spawn a separate thread and\nlet it block on the occurrence of the event while the main process continues.\nWhen the event occurs, the thread is unblocked and calls the function.\nFigure 4.15: A client and server interacting through a deferred synchronous\nRPC.\nIt should be noted that variants of asynchronous RPCs exist in which the\nclient continues executing immediately after sending the request to the server.\nIn other words, the client does not wait for an acknowledgment of the server’s\nacceptance of the request. We refer to such RPCs as one-way RPCs. The\nproblem with this approach is that when reliability is not guaranteed, the\nclient cannot know for sure whether its request will be processed. We return\nto these matters in Chapter 8. Likewise, in the case of deferred synchronous\nRPC, the client may poll the server to see whether the results are available yet,\ninstead of letting the server calling back the client.\nDS 4.01\n \n\n\n4.2. REMOTE PROCEDURE CALL\n207\nMulticast RPC\nAsynchronous and deferred synchronous RPCs facilitate another alternative\nto remote procedure calls, namely executing multiple RPCs at the same time.\nAdopting the one-way RPCs (i.e., when a server does not tell the client it has\naccepted its call request but immediately starts processing it, while the client\ncontinues just after issuing the RPC), a multicast RPC boils down to sending\nan RPC request to a group of servers. This principle is shown in Figure 4.16.\nIn this example, the client sends a request to two servers, who subsequently\nprocess that request independently and in parallel. When done, the result is\nreturned to the client where a callback takes place.\nFigure 4.16: The principle of a multicast RPC.\nThere are several issues that we need to consider. First, as before, the\nclient application may be unaware of the fact that an RPC is actually being\nforwarded to more than one server. For example, to increase fault tolerance,\nwe may decide to have all operations executed by a backup server who can\ntake over when the main server fails. That a server has been replicated can be\ncompletely hidden from a client application by an appropriate stub. Yet even\nthe stub need not be aware that the server is replicated, for example because\nwe are using a transport-level multicast address.\nSecond, we need to consider what to do with the responses. In particular,\nwill the client proceed after all responses have been received, or wait just for\none? It all depends. When the server has been replicated for fault tolerance,\nwe may decide to wait for just the first response, or perhaps until a majority\nof the servers returns the same result. On the other hand, if the servers have\nbeen replicated to do the same work but on different parts of the input, their\nresults may need to be merged before the client can continue. Again, such\nmatters can be hidden in the client-side stub, yet the application developer\nwill, at the very least, have to specify the purpose of the multicast RPC.\n \nDS 4.01\n\n\n208\nCHAPTER 4. COMMUNICATION\n4.3\nMessage-oriented communication\nRemote procedure calls and remote object invocations contribute to hiding\ncommunication in distributed systems, that is, they enhance access trans-\nparency. Unfortunately, neither mechanism is always appropriate. In particu-\nlar, when it cannot be assumed that the receiving side is executing at the time\na request is issued, alternative communication services are needed. Likewise,\nthe inherent synchronous nature of RPCs, by which a client is blocked until\nits request has been processed, may need to be replaced by something else.\nThat something else is messaging. In this section, we concentrate on\nmessage-oriented communication in distributed systems by first taking a closer\nlook at what exactly synchronous behavior is and what its implications are.\nThen, we discuss messaging systems that assume that parties are executing\nat the time of communication. Finally, we will examine message-queuing\nsystems that allow processes to exchange information, even if the other party\nis not executing at the time communication is initiated.\n4.3.1\nSimple transient messaging with sockets\nMany distributed systems and applications are built directly on top of the\nsimple message-oriented model offered by the transport layer. To better un-\nderstand and appreciate the message-oriented systems as part of middleware\nsolutions, we first discuss messaging through transport-level sockets.\nSpecial attention has been paid to standardizing the interface of the trans-\nport layer to allow programmers to make use of its entire suite of (messaging)\nprotocols through a simple set of operations. Furthermore, standard interfaces\nmake it easier to port an application to a different machine. As an example,\nwe briefly discuss the socket interface as introduced in the 1970s in Berkeley\nUnix, and which has been adopted as a POSIX standard (with only very few\nadaptations).\nConceptually, a socket is a communication end point to which an applica-\ntion can write data that are to be sent out over the underlying network, and\nfrom which incoming data can be read. A socket forms an abstraction over the\nactual port that is used by the local operating system for a specific transport\nprotocol. In the following text, we concentrate on the socket operations for\nTCP, which are shown in Figure 4.17.\nServers generally execute the first four operations, normally in the order\ngiven. When calling the socket operation, the caller creates a new commu-\nnication end point for a specific transport protocol. Internally, creating a\ncommunication end point means that the local operating system reserves\nresources for sending and receiving messages for the specified protocol.\nThe bind operation associates a local address with the newly created socket.\nFor example, a server should bind the IP address of its machine together with\na (possibly well-known) port number to a socket. Binding tells the operating\nDS 4.01\n \n\n\n4.3. MESSAGE-ORIENTED COMMUNICATION\n209\nOperation\nDescription\nsocket\nCreate a new communication end point\nbind\nAttach a local address to a socket\nlisten\nTell operating system what the maximum number of pending\nconnection requests should be\naccept\nBlock caller until a connection request arrives\nconnect\nActively attempt to establish a connection\nsend\nSend some data over the connection\nreceive\nReceive some data over the connection\nclose\nRelease the connection\nFigure 4.17: The socket operations for TCP/IP.\nsystem that the server wants to receive messages only on the specified address\nand port. In the case of connection-oriented communication, the address is\nused to receive incoming connection requests.\nThe listen operation is called only in the case of connection-oriented\ncommunication. It is a nonblocking call that allows the local operating sys-\ntem to reserve enough buffers for a specified maximum number of pending\nconnection requests that the caller is willing to accept.\nA call to accept blocks the caller until a connection request arrives. When\na request arrives, the local operating system creates a new socket with the\nsame properties as the original one, and returns it to the caller. This approach\nwill allow the server to, for example, fork a process that will subsequently\nhandle the actual communication through the new connection. The server can\ngo back and wait for another connection request on the original socket.\nFigure 4.18: Connection-oriented communication pattern using sockets.\nLet us now take a look at the client side. Here, too, a socket must first be\ncreated using the socket operation, but explicitly binding the socket to a local\naddress is not necessary, since the operating system can dynamically allocate\na port when the connection is set up. The connect operation requires that the\ncaller specifies the transport-level address to which a connection request is to\nbe sent. The client is blocked until a connection has been set up successfully,\nafter which both sides can start exchanging information through the send and\nreceive operations. Finally, closing a connection is symmetric when using\n \nDS 4.01\n\n\n210\nCHAPTER 4. COMMUNICATION\nsockets, and is established by having both the client and server call the close\noperation. Although there are many exceptions to the rule, the general pattern\nfollowed by a client and server for connection-oriented communication using\nsockets is as shown in Figure 4.18. Details on network programming using\nsockets and other interfaces in Unix can be found in [Stevens, 1998].\nNote 4.7 (Example: A simple socket-based client-server system)\nAs an illustration of the recurring pattern in Figure 4.18, consider the simple\nsocket-based client-server system shown in Figure 4.19 (see also Note 2.1). We see\nthe server starting by creating a socket, and subsequently binding an address to\nthat socket. It calls the listen operation, and waits for an incoming connection\nrequest.\nWhen the server accepts a connection, the socket library creates a\nseparate connection, conn, which is used to receive data and send a response to\nthe connected client. The server enters a loop receiving and sending messages,\nuntil no more data has been received. It then closes the connection.\n1 from socket\nimport *\n2\n3 class Server:\n4\ndef run(self):\n5\ns = socket(AF_INET, SOCK_STREAM)\n6\ns.bind((HOST, PORT))\n7\ns.listen(1)\n8\n(conn, addr) = s.accept()\n# returns new socket and addr. client\n9\nwhile True:\n# forever\n10\ndata = conn.recv(1024)\n# receive data from client\n11\nif not data: break\n# stop if client stopped\n12\nconn.send(data+b\"*\")\n# return sent data plus an \"*\"\n13\nconn.close()\n# close the connection\n(a)\n1 class Client:\n2\ndef run(self):\n3\ns = socket(AF_INET, SOCK_STREAM)\n4\ns.connect((HOST, PORT)) # connect to server (block until accepted)\n5\ns.send(b\"Hello, world\") # send same data\n6\ndata = s.recv(1024)\n# receive the response\n7\nprint(data)\n# print what you received\n8\ns.send(b\"\")\n# tell the server to close\n9\ns.close()\n# close the connection\n(b)\nFigure 4.19: A simple socket-based client-server system.\nThe client again follows the pattern from Figure 4.18. It creates a socket, and\ncalls connect to request a connection with the server. Once the connection has\nbeen established, it sends a single message, waits for the response, and after\nprinting the result, closes the connection.\nDS 4.01\n \n\n\n4.3. MESSAGE-ORIENTED COMMUNICATION\n211\nNote 4.8 (Advanced: Implementing stubs as global references revisited)\nTo provide a more in-depth insight in the working of sockets, let us look\nat a more elaborate example, namely the use of stubs as global references.\n1 class DBClient:\n2\ndef __sendrecv(self, message):\n# this is a private method\n3\nsock = socket()\n# create a socket\n4\nsock.connect((self.host, self.port))\n# connect to server\n5\nsock.send(pickle.dumps(message))\n# send some data\n6\nresult = pickle.loads(sock.recv(1024)) # receive the response\n7\nsock.close()\n# close the connection\n8\nreturn result\n9\n10\ndef create(self):\n11\nself.listID = self.__sendrecv([CREATE])\n12\nreturn self.listID\n13\n14\ndef getValue(self):\n15\nreturn self.__sendrecv([GETVALUE, self.listID])\n16\n17\ndef appendData(self, data):\n18\nreturn self.__sendrecv([APPEND, data, self.listID])\n(a)\n1 class Server:\n2\nself.setOfLists = {}\n# init: no lists to manage\n3\n4\ndef run(self):\n5\nwhile True:\n6\n(conn, addr) = self.sock.accept() # accept incoming call\n7\ndata = conn.recv(1024)\n# fetch data from client\n8\nrequest = pickle.loads(data)\n# unwrap the request\n9\n10\nif request[0] == CREATE:\n# create a list\n11\nlistID = len(self.setOfLists) + 1\n# allocate listID\n12\nself.setOfLists[listID] = []\n# initialize to empty\n13\nconn.send(pickle.dumps(listID))\n# return ID\n14\n15\nelif request[0] == APPEND:\n# append request\n16\nlistID = request[2]\n# fetch listID\n17\ndata\n= request[1]\n# fetch data to append\n18\nself.setOfLists[listID].append(data) # append it to the list\n19\nconn.send(pickle.dumps(OK))\n# return an OK\n20\n21\nelif request[0] == GETVALUE:\n# read request\n22\nlistID = request[1]\n# fetch listID\n23\nresult = self.setOfLists[listID]\n# get the elements\n24\nconn.send(pickle.dumps(result))\n# return the list\n(b)\nFigure 4.20: Implementing a list server in Python.\n \nDS 4.01\n\n\n212\nCHAPTER 4. COMMUNICATION\nWe return to our example of implementing a shared list, which we now\ndo using a list server, implemented in the form of the Python class shown in\nFigure 4.20(b). Figure 4.20(a) shows the stub implementation of a shared list.\nAgain, we have omitted code for readability.\nThe DBClient class represents a client-side stub that, once marshaled, can be\npassed between processes. It provides three operations associated with a list:\ncreate, getValue, and append, with obvious semantics. A DBClient is assumed to\nbe associated with one specific list as managed by the server. An identifier for\nthat list is returned when the list is created. Note how the (internal) sendrecv\noperation follows the client-side pattern explained in Figure 4.18.\nThe server maintains lists, as shown in Figure 4.20(b).\nIts internal data\nstructure is a setOfLists with each element being a previously created list. The\nserver simply waits for incoming requests, unmarshals the request, and checks\nwhich operation is being requested. Results are sent back to the requesting client\n(which always issues the sendrecv operation implemented as part of DBClient).\nAgain, we see that the server follows the pattern shown in Figure 4.18: it creates\na socket, binds an address to it, informs the operating system to how many\nconnections it should listen, and then waits to accept an incoming connection\nrequest. Once a connection has been established, the server receives data, sends a\nresponse, and closes the connection again.\n1 class Client:\n2\ndef __init__(self, port):\n3\nself.host = ’localhost’\n# this machine\n4\nself.port = port\n# port it will listen to\n5\nself.sock = socket()\n# socket for incoming calls\n6\nself.sock.bind((self.host, self.port)) # bind socket to an address\n7\nself.sock.listen(2)\n# max num connections\n8\n9\ndef sendTo(self, host, port, data):\n10\nsock = socket()\n11\nsock.connect((host, port))\n# connect to server (blocking call)\n12\nsock.send(pickle.dumps(data)) # send some data\n13\nsock.close()\n14\n15\ndef recvAny(self):\n16\n(conn, addr) = self.sock.accept()\n17\nreturn conn.recv(1024)\nFigure 4.20: (c) Implementing a list server in Python: the client.\nTo use a stub as a global reference, we represent each client application by\nthe class Client shown in Figure 4.20(c). The class is instantiated in the same\nprocess running the application (exemplified by the value of self.host), and will\nbe listening on a specific port for messages from other applications, as well as\nthe server. Otherwise, it merely sends and receives messages, coded through the\noperations sendTo and recvAny, respectively.\nNow consider the code shown in Figure 4.20(d), which mimics two client\napplications. The first one creates a new list and appends data to it. Then note\nDS 4.01\n \n",
      "page_number": 215
    },
    {
      "number": 23,
      "title": "Segment 23 (pages 224-233)",
      "start_page": 224,
      "end_page": 233,
      "detection_method": "topic_boundary",
      "content": "4.3. MESSAGE-ORIENTED COMMUNICATION\n213\nhow dbClient1 is simply sent to the other client. Under the hood, we now know\nthat it is marshaled in the operation sendTo (line 12) of class Client shown in\nFigure 4.20(c).\n1 def client1():\n2\nc1\n= Client(PORTC1)\n# create client\n3\ndbC1 = DBClient(HOSTS,PORTS)\n# create reference\n4\ndbC1.create()\n# create new list\n5\ndbC1.appendData(’Client 1’)\n# append some data\n6\nc1.sendTo(HOSTC2,PORTC2,dbC1)\n# send to other client\n7\n8 def client2():\n9\nc2\n= Client(PORTC2)\n# create a new client\n10\ndata = c2.recvAny()\n# block until data is sent\n11\ndbC2 = pickle.loads(data)\n# receive reference\n12\ndbC2.appendData(’Client 2’)\n# append data to same list\nFigure 4.20: (d) Passing stubs as references.\nThe second client simply waits for an incoming message (line 12), unmarshals\nthe result, knowing that it is a DBClient instance, and subsequently appends some\nmore data to the same list as the one the first client appended data. Indeed, an\ninstance of DBClient is seen to be passed as a global reference, seemingly along\nwith all the operations that go with the associated class.\n4.3.2\nAdvanced transient messaging\nThe standard socket-based approach toward transient messaging is very basic\nand, as such, rather brittle: a mistake is easily made. Furthermore, sockets\nessentially support only TCP or UDP, meaning that any extra facility for\nmessaging needs to be implemented separately by an application programmer.\nIn practice, we do often need more advanced approaches for message-oriented\ncommunication to make network programming easier, to expand beyond the\nfunctionality offered by existing networking protocols, to make better use of\nlocal resources, and so on.\nUsing messaging patterns: ZeroMQ\nOne approach toward making network programming easier is based on the\nobservation that many messaging applications, or their components, can be\neffectively organized according to a few simple communication patterns. By\nsubsequently providing enhancements to sockets for each of these patterns,\nit may become easier to develop a networked, distributed application. This\napproach has been followed in ZeroMQ and documented in [Hintjens, 2013;\nAkgul, 2013].\n \nDS 4.01\n\n\n214\nCHAPTER 4. COMMUNICATION\nLike in the Berkeley approach, ZeroMQ also provides sockets through\nwhich all communication takes place. Actual message transmission gener-\nally takes place over TCP connections, and like TCP, all communication is\nessentially connection-oriented, meaning that a connection will first be set up\nbetween a sender and receiver before message transmission can take place.\nHowever, setting up, and maintaining connections is kept mostly under the\nhood: an application programmer need not bother with those issues. To\nfurther simplify matters, a socket may be bound to multiple addresses, ef-\nfectively allowing a server to handle messages from very different sources\nthrough a single interface. For example, a server can listen to multiple ports\nusing a single blocking receive operation. ZeroMQ sockets can thus support\nmany-to-one communication instead of just one-to-one communication, as is the\ncase with standard Berkeley sockets. To complete the story: ZeroMQ sockets\nalso support one-to-many communication, i.e., multicasting.\nEssential to ZeroMQ is that communication is asynchronous: a sender will\nnormally continue after having submitted a message to the underlying com-\nmunication subsystem. An interesting side effect of combining asynchronous\nwith connection-oriented communication, is that a process can request a con-\nnection setup, and subsequently send a message even if the recipient is not yet\nup-and-running and ready to accept incoming connection requests, let alone\nincoming messages. What happens, of course, is that a connection request and\nsubsequent messages are queued at the sender’s side, while a separate thread\nas part of ZeroMQ’s library will take care that eventually the connection is set\nup and messages are transmitted to the recipient.\nSimplifying matters, ZeroMQ establishes a higher level of abstraction in\nsocket-based communication by pairing sockets: a specific type of socket used\nfor sending messages is paired with a corresponding socket type for receiving\nmessages. Each pair of socket types corresponds to a communication pattern.\nThe three most important communication patterns supported by ZeroMQ are\nrequest-reply, publish-subscribe, and pipeline.\nThe request-reply pattern is used in traditional client-server communi-\ncation, like the ones normally used for remote procedure calls. A client\napplication uses a request socket (of type REQ) to send a request message to a\nserver and expects the latter to respond with an appropriate response. The\nserver is assumed to use a reply socket (of type REP). The request-reply pattern\nsimplifies matters for developers by avoiding the need to call the listen\noperation, as well as the accept operation. Moreover, when a server receives\na message, a subsequent call to send is automatically targeted toward the\noriginal sender. Likewise, when a client calls the recv operation (for receiving\na message) after having sent a message, ZeroMQ assumes the client is wait-\ning for a response from the original recipient. Note that this approach was\neffectively encoded in the local sendrecv operation of Figure 4.20(b), which\nwe discussed in Note 4.8.\nDS 4.01\n \n\n\n4.3. MESSAGE-ORIENTED COMMUNICATION\n215\nNote 4.9 (Example: The request-reply pattern)\nLet us look at a simple programming example to illustrate the request-reply\npattern. Figure 4.21 shows a server that appends an asterisk to a received message.\nAs before, it creates a socket, and binds it to a combination of a protocol (in this\ncase TCP), and a host and port. In our example, the server is willing to accept\nincoming connection requests on two different ports. It then waits for incoming\nmessages. The request-reply pattern effectively ties the receipt of a message to the\nsubsequent response. In other words, when the server calls send, it will transmit\na message to the same client from which it previously had received a message. Of\ncourse, this simplicity can be achieved only if the programmer indeed abides to\nthe request-reply pattern.\n1 import zmq\n2\n3 def server():\n4\ncontext = zmq.Context()\n5\nsocket\n= context.socket(zmq.REP)\n# create reply socket\n6\nsocket.bind(\"tcp://*:12345\")\n# bind socket to address\n7\n8\nwhile True:\n9\nmessage = socket.recv()\n# wait for incoming message\n10\nif not \"STOP\" in str(message):\n# if not to stop...\n11\nreply = str(message.decode())+’*’\n# append \"*\" to message\n12\nsocket.send(reply.encode())\n# send it away (encoded)\n13\nelse:\n14\nbreak\n# break out of loop and end\n15\n16 def client():\n17\ncontext = zmq.Context()\n18\nsocket\n= context.socket(zmq.REQ)\n# create request socket\n19\n20\nsocket.connect(\"tcp://localhost:12345\") # block until connected\n21\nsocket.send(b\"Hello world\")\n# send message\n22\nmessage = socket.recv()\n# block until response\n23\nsocket.send(b\"STOP\")\n# tell server to stop\n24\nprint(message.decode())\n# print result\nFigure 4.21: A ZeroMQ client-server system.\nThe client, also shown in Figure 4.21, creates a socket and connects to the\nassociated server. When it sends a message, it can expect to receive, from that\nsame server, a response. By sending the string “STOP”, it tells the server it is done,\nafter which the server will actually stop.\nInterestingly, the asynchronous nature of ZeroMQ allows one to start the client\nbefore starting the server. An implication is that if, in this example, we would start\nthe server, then a client, and after a while a second client, that the latter will be\nblocked until the server is restarted. Furthermore, note that ZeroMQ does not\nrequire the programmer to specify how many bytes are expected to be received.\nUnlike TCP, ZeroMQ uses messages instead of byte streams.\n \nDS 4.01\n\n\n216\nCHAPTER 4. COMMUNICATION\nIn the case of a publish-subscribe pattern, clients subscribe to specific mes-\nsages that are published by servers. We came across this pattern in Section 2.1.3\nwhen discussing coordination. In effect, only the messages to which the client\nhas subscribed will be transmitted. If a server is publishing messages to which\nno one has subscribed, these messages will be lost. In its simplest form, this\npattern establishes multicasting messages from a server to several clients. The\nserver is assumed to use a socket of type PUB, while each client must use SUB\ntype sockets. Each client socket is connected to the socket of the server. By\ndefault, a client subscribes to no specific message. This means that as long\nas no explicit subscription is provided, a client will not receive a message\npublished by the server.\nNote 4.10 (Example: The publish-subscribe pattern)\nAgain, let us make this pattern more concrete through a simple example. Fig-\nure 4.22 shows an admittedly naive time server that publishes its current, local\ntime, through a PUB socket. The local time is published every five seconds, for any\ninterested client.\n1 import multiprocessing\n2 import zmq, time\n3\n4 def server():\n5\ncontext = zmq.Context()\n6\nsocket = context.socket(zmq.PUB)\n# create a publisher socket\n7\nsocket.bind(\"tcp://*:12345\")\n# bind socket to the address\n8\nwhile True:\n9\ntime.sleep(5)\n# wait every 5 seconds\n10\nt = \"TIME \" + time.asctime()\n11\nsocket.send(t.encode())\n# publish the current time\n12\n13 def client():\n14\ncontext = zmq.Context()\n15\nsocket = context.socket(zmq.SUB)\n# create a subscriber socket\n16\nsocket.connect(\"tcp://localhost:12345\")\n# connect to the server\n17\nsocket.setsockopt(zmq.SUBSCRIBE, b\"TIME\") # subscribe to TIME messages\n18\n19\nfor i in range(5):\n# Five iterations\n20\ntime = socket.recv()\n# receive a message related to subscription\n21\nprint(time.decode())\n# print the result\nFigure 4.22: A multicasting socket-based setup.\nA client is equally simple, as also shown in Figure 4.22. It first creates a SUB\nsocket which it connects to the corresponding PUB socket of the server. To receive\nthe appropriate messages, it needs to subscribe to messages that have TIME as\ntheir tag. In our example, a client will simply print the first five messages received\nfrom the server. Note that we can have as many clients as we want: the server’s\nmessage will be multicasted to all subscribers. Most important in this example, is\nDS 4.01\n \n\n\n4.3. MESSAGE-ORIENTED COMMUNICATION\n217\nthat it illustrates that the only messages received through the SUB socket, are the\nones the client had subscribed to.\nFinally, the pipeline pattern is characterized by the fact that a process\nwants to push out its results, assuming that there are other processes that want\nto pull in those results. The essence of the pipeline pattern is that a pushing\nprocess does not really care which other process pulls in its results: the first\navailable one will do just fine. Likewise, any process pulling in results from\nmultiple other processes will do so from the first pushing process making its\nresults available. The intention of the pipeline pattern is thus seen to keep as\nmany processes working as possible, pushing results through a pipeline of\nprocesses as quickly as possible.\nNote 4.11 (Example: The pipeline pattern)\nAs our last example, consider the following template for keeping a collection\nof worker tasks busy. Figure 4.23 shows the code for a so-called farmer task: a\nprocess producing tasks to be picked up by others. In this example, we simulate\nthe task by letting the producer pick a random number modeling the duration,\nor load, of the work to be done. This workload is then sent to the PUSH socket,\neffectively being queued until another process picks it up.\n1 def producer():\n2\ncontext = zmq.Context()\n3\nsocket\n= context.socket(zmq.PUSH)\n# create a push socket\n4\nsocket.bind(\"tcp://127.0.0.1:12345\")\n# bind socket to address\n5\n6\nwhile True:\n7\nworkload = random.randint(1, 100)\n# compute workload\n8\nsocket.send(pickle.dumps(workload))\n# send workload to worker\n9\ntime.sleep(workload/NWORKERS)\n# balance production by waiting\n10\n11 def worker(id):\n12\ncontext = zmq.Context()\n13\nsocket\n= context.socket(zmq.PULL)\n# create a pull socket\n14\nsocket.connect(\"tcp://localhost:12345\") # connect to the producer\n15\n16\nwhile True:\n17\nwork = pickle.loads(socket.recv())\n# receive work from a source\n18\ntime.sleep(work)\n# pretend to work\nFigure 4.23: A producer-worker pattern.\nSuch other processes are known as worker tasks, of which a sketch is also\ngiven in Figure 4.23. A worker task connects to a single PULL socket. Once it picks\nup some work, it simulates that it is actually doing something by sleeping for\nsome time proportional to the received workload.\n \nDS 4.01\n\n\n218\nCHAPTER 4. COMMUNICATION\nThe semantics of this push-pull pattern is such that the first available worker\nwill pick up work from the producer, and likewise, if there are multiple workers\nready to pick up work, each one of them will be provided with a task. How work\ndistribution is actually done fairly requires some specific attention, which we will\nnot discuss further here.\nThe Message-Passing Interface (MPI)\nWith the advent of high-performance multicomputers, developers have been\nlooking for message-oriented operations that would allow them to easily write\nhighly efficient applications. This means that the operations should be at a\nconvenient level of abstraction (to ease application development), and that\ntheir implementation incurs only minimal overhead. Sockets were deemed\ninsufficient for two reasons. First, they were at the wrong level of abstraction\nby supporting only simple send and receive operations. Second, sockets\nhad been designed to communicate across networks using general-purpose\nprotocol stacks such as TCP/IP. They were not considered suitable for the\nproprietary protocols developed for high-speed interconnection networks,\nsuch as those used in high-performance server clusters. Those protocols\nrequired an interface that could handle more advanced features, such as\ndifferent forms of buffering and synchronization.\nThe result was that most interconnection networks and high-performance\nmulticomputers were shipped with proprietary communication libraries.\nThese libraries offered a wealth of high-level and generally efficient com-\nmunication operations. Of course, all libraries were mutually incompatible, so\nthat application developers now had a portability problem.\nThe need to be hardware and platform independent eventually lead to\nthe definition of a standard for message passing, simply called the Message-\nPassing Interface or MPI. MPI is designed for parallel applications and\nas such is tailored to transient communication. It makes direct use of the\nunderlying network. Furthermore, it assumes that serious failures such as\nprocess crashes or network partitions are fatal and do not require automatic\nrecovery.\nMPI assumes communication takes place within a known group of pro-\ncesses. Each group is assigned an identifier. Each process within a group is\nalso assigned a (local) identifier. A (groupID, processID) pair therefore uniquely\nidentifies the source or destination of a message, and is used instead of a\ntransport-level address. There may be several, possibly overlapping, groups\nof processes involved in a computation and that are all executing at the same\ntime.\nAt the core of MPI are messaging operations to support transient com-\nmunication, of which the most intuitive ones are summarized in Figure 4.25.\nTo understand their semantics, it helps to keep Figure 4.4 in mind, with the\nDS 4.01\n \n\n\n4.3. MESSAGE-ORIENTED COMMUNICATION\n219\nmiddleware formed entirely by an MPI implementation. In particular, the\nmiddleware maintains its own buffers and synchronization is often related to\nwhen the necessary data has been copied from the calling application to the\nmiddleware.\nOperation\nDescription\nMPI_BSEND\nAppend outgoing message to a local send buffer\nMPI_SEND\nSend a message and wait until copied to local or remote\nbuffer\nMPI_SSEND\nSend a message and wait until transmission starts\nMPI_SENDRECV\nSend a message and wait for reply\nMPI_ISEND\nPass reference to outgoing message, and continue\nMPI_ISSEND\nPass reference to outgoing message, and wait until receipt\nstarts\nMPI_RECV\nReceive a message; block if there is none\nMPI_IRECV\nCheck if there is an incoming message, but do not block\nFigure 4.24: Some of the more intuitive message-passing operations of MPI.\nTransient asynchronous communication is supported by the MPI_BSEND\noperation. The sender submits a message for transmission, which is generally\nfirst copied to a local buffer in the MPI runtime system. When the message\nhas been copied, the sender continues. The local MPI runtime system will\nremove the message from its local buffer and take care of transmission as soon\nas a receiver has called a receive operation.\nThere is also a blocking send operation, called MPI_SEND, of which the\nsemantics are implementation dependent. The operation MPI_SEND may either\nblock the caller until the specified message has been copied to the MPI\nruntime system at the sender’s side, or until the receiver has initiated a receive\noperation. Synchronous communication by which the sender blocks until its\nrequest is accepted for further processing is available through the MPI_SSEND\noperation. Finally, the strongest form of synchronous communication is also\nsupported: when a sender calls MPI_SENDRECV, it sends a request to the receiver\nand blocks until the latter returns a reply. Basically, this operation corresponds\nto a normal RPC.\nBoth MPI_SEND and MPI_SSEND have variants that avoid copying messages\nfrom user buffers to buffers internal to the local MPI runtime system. These\nvariants essentially correspond to a form of asynchronous communication.\nWith MPI_ISEND, a sender passes a pointer to the message, after which the MPI\nruntime system takes care of communication. The sender immediately contin-\nues. To prevent overwriting the message before communication completes,\nMPI offers operations to check for completion, or even to block if required.\nAs with MPI_SEND, whether the message has actually been transferred to the\nreceiver or that it has merely been copied by the local MPI runtime system to\nan internal buffer is left unspecified.\n \nDS 4.01\n\n\n220\nCHAPTER 4. COMMUNICATION\nLikewise, with MPI_ISSEND, a sender also passes only a pointer to the MPI\nruntime system. When the runtime system indicates it has processed the\nmessage, the sender is then guaranteed that the receiver has accepted the\nmessage and is now working on it.\nThe operation MPI_RECV is called to receive a message; it blocks the\ncaller until a message arrives. There is also an asynchronous variant, called\nMPI_IRECV, by which a receiver indicates that it is prepared to accept a mes-\nsage. The receiver can check whether a message has indeed arrived, or block\nuntil one does.\nThe semantics of MPI communication operations are not always straight-\nforward, and different operations can sometimes be interchanged without\naffecting the correctness of a program. The official reason why so many differ-\nent forms of communication are supported is that it gives implementers of\nMPI systems enough possibilities for optimizing performance. Cynics might\nsay the committee could not make up its collective mind, so it threw in every-\nthing. By now, MPI is in its fourth version with over 650 operations available.\nBeing designed for high-performance parallel applications, it is perhaps easier\nto understand its diversity. More on MPI can be found in [Gropp et al., 2016].\nThe complete MPI-4 reference can be found in [Message Passing Interface\nForum, 2021].\n4.3.3\nMessage-oriented persistent communication\nWe now come to an important class of message-oriented middleware services,\ngenerally known as message-queuing systems, or just message-oriented\nmiddleware (MOM). Message-queuing systems provide extensive support for\npersistent asynchronous communication. The essence of these systems is that\nthey offer intermediate-term storage capacity for messages, without requiring\neither the sender or receiver to be active during message transmission. An\nimportant difference with sockets and MPI is that message-queuing systems\nare typically targeted to support message transfers that are allowed to take\nminutes instead of seconds or milliseconds.\nMessage-queuing model\nThe basic idea behind a message-queuing system is that applications commu-\nnicate by inserting messages in specific queues. These messages are forwarded\nover a series of communication servers and are eventually delivered to the\ndestination, even if it was down when the message was sent. In practice, most\ncommunication servers are directly connected to each other. In other words, a\nmessage is generally transferred directly to a destination server. In principle,\neach application has its own private queue to which other applications can\nsend messages. A queue can be read only by its associated application, but it\nis also possible for multiple applications to share a single queue.\nDS 4.01\n \n\n\n4.3. MESSAGE-ORIENTED COMMUNICATION\n221\nAn important aspect of message-queuing systems is that a sender is gen-\nerally given only the guarantees that its message will eventually be inserted\nin the recipient’s queue. No guarantees are given about when, or even if\nthe message will actually be read, which is completely determined by the\nbehavior of the recipient.\nThese semantics permit communication to be decoupled in time, as also\ndiscussed in Section 2.1.3. There is thus no need for the receiver to be executing\nwhen a message is being sent to its queue. Likewise, there is no need for the\nsender to be executing the moment its message is picked up by the receiver.\nThe sender and receiver can execute completely independently of each other.\nIn fact, once a message has been deposited in a queue, it will remain there\nuntil it is removed, irrespective of whether its sender or receiver is executing.\nThis gives us four combinations regarding the execution mode of the sender\nand receiver, as shown in Figure 4.25.\nFigure 4.25: Four combinations for loosely coupled communication using\nqueues.\nIn Figure 4.25(a), both the sender and receiver are in execution during\nthe entire transmission of a message. In Figure 4.25(b), only the sender is in\nexecution, while the receiver is passive, that is, in a state in which message\ndelivery is not possible. Nevertheless, the sender can still send messages.\nThe combination of a passive sender and an active receiver is shown in\nFigure 4.25(c). In this case, the receiver can read messages that were sent\nto it, but it is not necessary that their respective senders are in execution\nas well. Finally, in Figure 4.25(d), we see the situation that the system is\nstoring (and possibly transmitting) messages even while sender and receiver\n \nDS 4.01\n\n\n222\nCHAPTER 4. COMMUNICATION\nare passive. One may argue that only if this last configuration is supported,\nthe message-queuing system truly provides persistent messaging.\nMessages can, in principle, contain any data. The only important aspect\nfrom the perspective of middleware is that messages are properly addressed.\nIn practice, addressing is done by providing a systemwide unique name of the\ndestination queue. In some cases, message size may be limited, although it is\nalso possible that the underlying system takes care of fragmenting and assem-\nbling large messages in a way that is completely transparent to applications.\nAn effect of this approach is that the basic interface offered to applications\ncan be simple, as shown in Figure 4.26.\nOperation\nDescription\nPUT\nAppend a message to a specified queue\nGET\nBlock until the specified queue is nonempty, and remove the\nfirst message\nPOLL\nCheck a specified queue for messages, and remove the first.\nNever block\nNOTIFY\nInstall a handler to be called when a message is put into the\nspecified queue\nFigure 4.26: Basic interface to a queue in a message-queuing system.\nThe PUT operation is called by a sender to pass a message to the underlying\nsystem that is to be appended to the specified queue. As we explained, this is a\nnonblocking call. The GET operation is a blocking call by which an authorized\nprocess can remove the longest pending message in the specified queue. The\nprocess is blocked only if the queue is empty. Variations on this call allow\nsearching for a specific message in the queue, for example, using a priority, or\na matching pattern. The nonblocking variant is given by the POLL operation.\nIf the queue is empty, or if a specific message could not be found, the calling\nprocess simply continues.\nFinally, most queuing systems also allow a process to install a handler\nas a callback function, which is automatically invoked whenever a message\nis put into the queue. Arranging this scheme is handled through a NOTIFY\noperation. Callbacks can also be used to automatically start a process that\nwill fetch messages from the queue if no process is currently in execution.\nThis approach is often implemented through a daemon on the receiver’s side\nthat continuously monitors the queue for incoming messages and handles\naccordingly.\nGeneral architecture of a message-queuing system\nLet us now take a closer look at what a general message-queuing system looks\nlike. First, queues are managed by queue managers. A queue manager is\neither a separate process, or is implemented through a library that is linked\nDS 4.01\n \n",
      "page_number": 224
    },
    {
      "number": 24,
      "title": "Segment 24 (pages 234-245)",
      "start_page": 234,
      "end_page": 245,
      "detection_method": "topic_boundary",
      "content": "4.3. MESSAGE-ORIENTED COMMUNICATION\n223\nwith an application. Secondly, as a rule of thumb, an application can put\nmessages only into a local queue. Likewise, getting a message is possible by\nextracting it from a local queue only. As a consequence, if a queue manager\nQMA handling the queues for an application A runs as a separate process,\nboth processes QMA and A will generally be placed on the same machine, or\nat worst on the same LAN. Also note that if all queue managers are linked\ninto their respective applications, we can no longer speak of a persistent\nasynchronous messaging system.\nIf applications can put messages only into local queues, then clearly each\nmessage will have to carry information concerning its destination. It is the\nqueue manager’s task to make sure that a message reaches its destination.\nThis brings us to several issues.\nIn the first place, we need to consider how the destination queue is ad-\ndressed. Obviously, to enhance location transparency, it is preferable that\nqueues have logical, location-independent names. Assuming that a queue man-\nager is implemented as a separate process, using logical names implies that\neach name should be associated with a contact address, such as a (host,port)-\npair, and that the name-to-address mapping is readily available to a queue\nmanager, as shown in Figure 4.27. In practice, a contact address carries more\ninformation, notably the protocol to be used, such as TCP or UDP. We came\nacross such contact addresses in our examples of advanced sockets in, for\nexample, Note 4.9.\nFigure 4.27: The relationship between queue-level naming and network-level\naddressing.\nA second issue that we need to consider is how the name-to-address\nmapping is actually made available to a queue manager. A common approach\nis to simply implement the mapping as a lookup table and copy that table\nto all managers. Obviously, this leads to a maintenance problem, for every\ntime that a new queue is added or named, many, if not all tables, need to be\nupdated. There are various ways to alleviate such problems, which we will\ndiscuss in Chapter 6.\n \nDS 4.01\n\n\n224\nCHAPTER 4. COMMUNICATION\nThis brings us to a third issue, related to the problems of efficiently\nmaintaining name-to-address mappings. We have implicitly assumed that if a\ndestination queue at manager QMB is known to queue manager QMA, then\nQMA can directly contact QMB to transfer messages. In effect, this means that\n(the contact address of) each queue manager should be known to all others.\nObviously, when dealing with large message-queuing systems, we will have a\nscalability problem. In practice, there are often special queue managers that\noperate as routers: they forward incoming messages to other queue managers.\nIn this way, a message-queuing system may gradually grow into a complete,\napplication-level, overlay network.\nIf only a few routers need to know about the network topology, then a\nsource queue manager need only to know to which adjacent router, say R, it\nshould forward a message, given a destination queue. The router R, in turn,\nmay need to keep track only of its adjacent routers to see where to forward\nthe message to, and so on. Of course, we still need to have name-to-address\nmappings for all queue managers, including the routers, but it is not difficult\nto imagine that such tables can be much smaller and easier to maintain.\nMessage brokers\nAn important application area of message-queuing systems is integrating\nexisting and new applications into a single, coherent distributed information\nsystem. If we assume that communication with an application takes place\nthrough messages, then integration requires that applications can understand\nthe messages they receive. In practice, this requires the sender to have its\noutgoing messages in the same format as that of the receiver, but also that\nits messages adhere to the same semantics as those expected by the receiver.\nSender and receiver essentially need to speak the same language, that is,\nadhere to the same messaging protocol.\nThe problem with this approach is that each time an application A is\nadded to the system having its own messaging protocol, then for each other\napplication B that is to communicate with A we will need to provide the means\nfor converting their respective messages. In a system with N applications, we\nwill thus need N × N messaging-protocol converters.\nAn alternative is to agree on a common messaging protocol, as is done\nwith traditional network protocols. Unfortunately, this approach will generally\nnot work for message-queuing systems. The problem is the level of abstraction\nat which these systems operate. A common messaging protocol makes sense\nonly if the collection of processes that make use of that protocol indeed\nhave enough in common. If the collection of applications that make up a\ndistributed information system is highly diverse (which it often is), then\ninventing a one-size-fits-all solution is simply not going to work.\nIf we focus only on the format and meaning of messages, commonality can\nbe achieved by lifting the level of abstraction, as is done with XML messages.\nDS 4.01\n \n\n\n4.3. MESSAGE-ORIENTED COMMUNICATION\n225\nIn this case, messages carry information on their own organization, and what\nhas been standardized is the way that they can describe their content. As a\nconsequence, an application can provide information on the organization of\nits messages that can be automatically processed. Of course, this information\nis generally not enough: we also need to make sure that the semantics of\nmessages are well understood.\nGiven these problems, the general approach is to learn to live with differ-\nences, and try to provide the means to make conversions as simple as possible.\nIn message-queuing systems, conversions are handled by special nodes in a\nqueuing network, known as message brokers. A message broker acts as an\napplication-level gateway in a message-queuing system. Its main purpose is to\nconvert incoming messages so that they can be understood by the destination\napplication. Note that to a message-queuing system, a message broker is just\nanother application, as shown in Figure 4.28. In other words, a message broker\nis generally not considered to be an integral part of the queuing system.\nFigure 4.28: The general organization of a message broker in a message-\nqueuing system.\nA message broker can be as simple as a reformatter for messages. For\nexample, assume an incoming message contains a table from a database in\nwhich records are separated by a special end-of-record delimiter and fields\nwithin a record have a known, fixed length. If the destination application\nexpects a different delimiter between records, and also expects that fields have\nvariable lengths, a message broker can be used to convert messages to the\nformat expected by the destination.\nIn a more advanced setting, a message broker may act as an application-\nlevel gateway, in which information on the messaging protocol of several\napplications has been encoded. In general, for each pair of applications, we\nwill have a separate subprogram capable of converting messages between the\ntwo applications. In Figure 4.28, this subprogram is drawn as a plugin to\nemphasize that such parts can be dynamically plugged in, or removed from a\nbroker.\n \nDS 4.01\n\n\n226\nCHAPTER 4. COMMUNICATION\nFinally, note that often a message broker is used for advanced enterprise\napplication integration (EAI), as we discussed in Section 1.3.2. In this case,\nrather than (only) converting messages, a broker is responsible for matching\napplications based on the messages that are being exchanged. In such a\npublish-subscribe model, applications send messages in the form of publishing.\nIn particular, they may publish a message on topic X, which is then sent to the\nbroker. Applications that have stated their interest in messages on topic X, that\nis, who have subscribed to those messages, will then receive these messages\nfrom the broker. More advanced forms of mediation are also possible.\nAt the heart of a message broker lies a repository of rules for transforming\na message of one type to another. The problem is defining the rules and\ndeveloping the plugins. Most message-broker products come with sophisti-\ncated development tools, but the bottom line is still that the repository needs\nto be filled by experts. Here we see a perfect example where commercial\nproducts are often misleadingly said to provide “intelligence,” where, in fact,\nthe intelligence is to be found only in the heads of those experts. It may be\nbetter to consistently talk about “advanced” systems (but even then, we often\nsee that this stands for complex or complicated).\nNote 4.12 (More information: A note on message-queuing systems)\nConsidering what we have said about message-queuing systems, it would appear\nthat they have long existed in the form of implementations for e-mail services.\nE-mail systems are generally implemented through a collection of mail servers\nthat store and forward messages on behalf of the users on hosts directly connected\nto the server. Routing is generally left out, as e-mail systems can make direct use\nof the underlying transport services. For example, in the mail protocol for the\nInternet, SMTP [Postel, 1982], a message is transferred by setting up a direct TCP\nconnection to the destination mail server.\nWhat makes e-mail systems special compared to message-queuing systems\nis that they are primarily aimed at providing direct support for end users. This\nexplains, for example, why several groupware applications are based directly\non an e-mail system [Khoshafian and Buckiewicz, 1995]. In addition, e-mail\nsystems may have very specific requirements such as automatic message filtering,\nsupport for advanced messaging databases (e.g., to easily retrieve previously\nstored messages), and so on.\nGeneral message-queuing systems are not aimed at supporting only end users.\nAn important issue is that they are set up to enable persistent communication\nbetween processes, regardless of whether a process is running a user application,\nhandling access to a database, performing computations, and so on. This approach\nleads to a different set of requirements for message-queuing systems than pure e-\nmail systems. For example, e-mail systems generally need not provide guaranteed\nmessage delivery, message priorities, logging facilities, efficient multicasting, load\nbalancing, fault tolerance, and so on for general usage.\nGeneral-purpose message-queuing systems, therefore, have a wide range\nDS 4.01\n \n\n\n4.3. MESSAGE-ORIENTED COMMUNICATION\n227\nof applications, including e-mail, workflow, groupware, and batch processing.\nHowever, as we have stated before, the most important application area is the in-\ntegration of a (possibly widely dispersed) collection of databases and applications\ninto a federated information system [Hohpe and Woolf, 2004]. For example, a\nquery expanding several databases may need to be split into subqueries that are\nforwarded to individual databases. Message-queuing systems assist by providing\nthe basic means to package each subquery into a message and routing it to the\nappropriate database. Other communication facilities we have discussed in this\nchapter are far less appropriate.\n4.3.4\nExample: Advanced Message Queuing Protocol (AMQP)\nAn interesting observation about message-queuing systems is that they have\nbeen developed in part to allow legacy applications to interoperate, yet at\nthe same time we see that when it comes to operations between different\nmessage-queuing systems, we often hit a wall. As a consequence, once an\norganization chooses to use a message-queuing system from manufacturer X,\nthey may have to settle for solutions that only X provides. Message-queuing\nsolutions are thus in large part proprietary solutions. So much for openness.\nIn 2006, a working group was formed to change this situation, which\nresulted in the specification of the Advanced Message-Queuing Protocol,\nor simply AMQP. There are different versions of AMQP, with version 1.0\nbeing the most recent one. There are also various implementations of AMQP,\nnotably of versions before 1.0, which by the time version 1.0 was established,\nhad gained considerable popularity. Because a pre-1.0 version is so different\nfrom the 1.0 version, yet has also a steady user base, we may see various\npre-1.0 AMQP servers exist next to (their undeniably incompatible) 1.0 servers.\nIn this section, we will describe AMQP, but will more or less deliberately\nmix the pre-1.0 and 1.0 versions, sticking to the essentials and spirit of AMQP.\nDetails can be found in the specifications [AMQP Working Group, 2008;\nOASIS, 2012]. Implementations of AMQP include RabbitMQ [Roy, 2018] and\nApache’s ActiveMQ.\nBasics\nAMQP revolves around applications, queue managers, and queues. Taking\nan approach that is common for many networking situations, we make a\ndistinction between AMQP as a messaging service, the actual messaging protocol,\nand, finally, the messaging interface as offered to applications. To this end,\nit is easiest to consider having only a single queue manager, running as a\nsingle, separate server, forming the implementation of AMQP as a service. An\napplication communicates with this queue manager through a local interface.\n \nDS 4.01\n\n\n228\nCHAPTER 4. COMMUNICATION\nFigure 4.29: An overview of a single-server AMQP instance.\nBetween an application and the queue manager, communication proceeds\naccording to the AMQP protocol.\nThis situation is shown in Figure 4.29 and should look familiar. The AMQP\nstub shields the application (as well as the queue manager) from the details\nconcerning message transfer and communication in general. At the same\ntime, it implements a message-queuing interface, allowing the application to\nmake use of AMQP as a message-queuing service. Although the distinction\nbetween AMQP stub and queue manager is made explicit for queue managers,\nthe strictness of the separation is left to an implementation. Nevertheless, if\nnot strict, conceptually there is a distinction between handling queues and\nhandling related communication as we shall make clear shortly.\nAMQP communication\nAMQP allows an application to set up a connection to a queue manager; a\nconnection is a container for a number of one-way channels. Whereas the\nlifetime of a channel can be highly dynamic, connections are assumed to\nbe relatively stable. This difference between connection and channel allows\nfor efficient implementations, notably by using a single transport-layer TCP\nconnection to multiplex many different channels between an application and\na queue manager. In practice, AMQP assumes TCP is used for establishing\nAMQP connections.\nBidirectional communication is established through sessions: a logical\ngrouping of two channels. A connection may have multiple sessions, but note\nthat a channel need not necessarily be part of a session.\nFinally, to actually transfer messages, a link is needed. Conceptually, a\nlink, or rather its end points, keep track of the status of messages that are\nbeing transferred. It thus provides fine-grained flow control between an\napplication and a queue manager, and, indeed, different control policies can\nbe put simultaneously in place for different messages that are transferred\nDS 4.01\n \n\n\n4.3. MESSAGE-ORIENTED COMMUNICATION\n229\nthrough the same session or connection. Flow control is established through\ncredits: a receiver can tell the sender how many messages it is allowed to send\nover a specific link.\nWhen a message is to be transferred, the application passes it to its local\nAMQP stub. As mentioned, each message transfer is associated with one\nspecific link. Message transfer normally proceeds in three steps.\n1. At the sender’s side, the message is assigned a unique identifier and\nis recorded locally to be in an unsettled state. The stub subsequently\ntransfers the message to the server, where the AMQP stub also records it\nas being in an unsettled state. At that point, the server-side stub passes\nit to the queue manager.\n2. The receiving application (in this case the queue manager), is assumed\nto handle the message and normally reports back to its stub that it is\nfinished. The stub passes this information to the original sender, at\nwhich point the message at the original sender’s AMQP stub enters a\nsettled state.\n3. The AMQP stub of the original sender now tells the stub of the original\nreceiver that message transfer has been settled (meaning that the original\nsender will forget about the message from now on). The receiver’s stub\ncan now also discard anything about the message, formally recording it\nas being settled as well.\nNote that because the receiving application can indicate to the underlying\nAMQP communication layer that it is done with a message, AMQP enables\ntrue end-to-end communication reliability. In particular, the application, be\nit a client application or an actual queue manager, can instruct the AMQP\ncommunication layer to keep hold of a message (i.e., a message stays in the\nunsettled state).\nAMQP messaging\nMessaging in AMQP logically takes place at the layer above the one handling\ncommunication. It is here that an application can indicate what needs to be\ndone with a message, but can also see what has happened so far. Messaging\nformally takes place between two nodes, of which there are three types: a\nproducer, a consumer, or a queue. Typically, producer and consumer nodes\nrepresent regular applications, whereas queues are used to store and forward\nmessages. Indeed, a queue manager will typically consist of multiple queue\nnodes. In order for message transfer to take place, two nodes will have to\nestablish a link between them.\nThe receiver can indicate to the sender whether its message was accepted\n(meaning that it was successfully processed), or rejected.\nNote that this\nmeans that a notification is returned to the original sender. AMQP also\n \nDS 4.01\n\n\n230\nCHAPTER 4. COMMUNICATION\n1 import rabbitpy\n2\n3 def producer():\n4\nconnection = rabbitpy.Connection() # Connect to RabbitMQ server\n5\nchannel = connection.channel()\n# Create new channel on the connection\n6\n7\nexchange = rabbitpy.Exchange(channel, ’exchange’) # Create an exchange\n8\nexchange.declare()\n9\n10\nqueue1 = rabbitpy.Queue(channel, ’example1’) # Create 1st queue\n11\nqueue1.declare()\n12\n13\nqueue2 = rabbitpy.Queue(channel, ’example2’) # Create 2nd queue\n14\nqueue2.declare()\n15\n16\nqueue1.bind(exchange, ’example-key’) # Bind queue1 to a single key\n17\nqueue2.bind(exchange, ’example-key’) # Bind queue2 to the same key\n18\n19\nmessage = rabbitpy.Message(channel, ’Test message’)\n20\nmessage.publish(exchange, ’example-key’) # Publish the message using the key\n21\nexchange.delete()\n(a)\n1 import rabbitpy\n2\n3 def consumer():\n4\nconnection = rabbitpy.Connection()\n5\nchannel = connection.channel()\n6\n7\nqueue = rabbitpy.Queue(channel, ’example1’)\n8\n9\n# While there are messages in the queue, fetch them using Basic.Get\n10\nwhile len(queue) > 0:\n11\nmessage = queue.get()\n12\nprint(’Message Q1: %s’ % message.body.decode())\n13\nmessage.ack()\n14\n15\nqueue = rabbitpy.Queue(channel, ’example2’)\n16\n17\nwhile len(queue) > 0:\n18\nmessage = queue.get()\n19\nprint(’Message Q2: %s’ % message.body.decode())\n20\nmessage.ack()\n(b)\nFigure 4.30: A simple (a) producer and (b) consumer for RabbitMQ, adapted\nfrom [Roy, 2018].\nDS 4.01\n \n\n\n4.3. MESSAGE-ORIENTED COMMUNICATION\n231\nsupports fragmentation and assembly of large messages, for which additional\nnotifications are sent.\nOf course, an important aspect of AMQP is its support for persistent\nmessaging. Achieving persistence is handled through several mechanisms.\nFirst, a message can be marked as durable, indicating that the source expects\nany intermediate node, such as a queue, to be able to recover in the case\nof a failure. An intermediate node that cannot guarantee such durability\nwill have to reject a message.\nSecond, a source or target node can also\nindicate its durability: if durable, will it maintain its state, or will it also\nmaintain the (unsettled) state of durable messages? Combining the latter\nwith durable messages effectively establishes reliable message transfer and\npersistent messaging.\nAMQP is truly a messaging protocol in the sense that it does not by itself\nsupport, for example, publish-subscribe primitives. It expects that such issues\nare handled by more advanced, proprietary queue managers, akin to the\nmessage brokers discussed in Section 4.3.3.\nFinally, there is no reason why a queue manager cannot be connected to\nanother queue manager. In fact, it is quite common to organize queue man-\nagers into an overlay network in which messages are routed from producers to\ntheir consumers. AMQP does not specify how the overlay network should be\nconstructed and managed, and, indeed, different providers of AMQP-based\nsystems offer different solutions. Of particular importance is specifying how\nmessages should be routed through the network. The bottom line is that ad-\nministrators will need to do a lot of this specification manually. Only in cases\nwhere overlays have regular structures, such as cycles or trees, it becomes\neasier to provide the necessary routing details.\nAMQP in practice\nOne of the more popular implementations of message brokering is the Rab-\nbitMQ server, extensively described by Roy [2018]. The RabbitMQ server is\nbased on the 0.9 version of AMQP, while also fully supporting version 1.0. An\nimportant difference between these two versions is the use of exchanges. In-\nstead of directly manipulating queues, producers contact an exchange, which,\nin turn, places messages in one or several queues. In essence, an exchange\nallows a producer to use a synchronous or asynchronous RPC to a queue\nmanager. An exchange never stores messages; it simply makes sure that a\nmessage is placed in an appropriate queue.\nTo illustrate this concept, consider Figure 4.30(a) showing a simple pro-\nducer. As mentioned previously, AMQP embeds channels as part of more\ndurable connections, and the first we do is create a means for communicating\nwith the server (we are omitting various details; in this case we establish a\ndefault connection with the server). In the following lines, an exchange is\ncreated within the realm of the server, along with two queues. In Lines 16\n \nDS 4.01\n\n\n232\nCHAPTER 4. COMMUNICATION\nand 17, both queues are bound to the same exchange by a simple key named\nexample-key. After creating a message, the producer tells the exchange that it\nshould publish that message to any queue bound by the specified key.\nAs to be expected, the exchange will place the message in both queues,\nwhich is verified by the simple consumer shown in Figure 4.30(b). In this case,\nthe consumer simply fetches messages from either queue and prints their\ncontent.\nExchanges and queues have many options, for which we refer the inter-\nested reader to Roy [2018]. It is important to note that using systems such\nas RabbitMQ, but also other messaging brokers, one can generally set up\nadvanced overlay networks for application-level message routing. At the same\ntime, maintenance of those networks can easily become a nightmare.\n4.4\nMulticast communication\nAn important topic in communication in distributed systems is the support for\nsending data to multiple receivers, also known as multicast communication.\nFor many years, this topic has belonged to the domain of network protocols,\nwhere numerous proposals for network-level and transport-level solutions\nhave been implemented and evaluated [Janic, 2005; Obraczka, 1998]. A major\nissue in all solutions was setting up the communication paths for information\ndissemination. In practice, this involved a huge management effort, often\nrequiring human intervention. In addition, as long as there is no convergence\nof proposals, ISPs have shown to be reluctant to support multicasting [Diot\net al., 2000].\nWith the advent of peer-to-peer technology, and notably structured overlay\nmanagement, it became easier to set up communication paths. As peer-to-peer\nsolutions are typically deployed at the application layer, various application-\nlevel multicasting techniques have been introduced. In this section, we will\ntake a brief look at these techniques.\nMulticast communication can also be accomplished in other ways than\nsetting up explicit communication paths. As we also explore in this sec-\ntion, gossip-based information dissemination provides simple (yet often less\nefficient) ways for multicasting.\n4.4.1\nApplication-level tree-based multicasting\nThe basic idea in application-level multicasting is that nodes are organized\ninto an overlay network, which is then used to disseminate information to its\nmembers. An important observation is that network routers are not involved\nin group membership. As a consequence, the connections between nodes in\nthe overlay network may cross several physical links, and as such, routing\nmessages within the overlay may not be optimal in comparison to what could\nhave been achieved by network-level routing.\nDS 4.01\n \n\n\n4.4. MULTICAST COMMUNICATION\n233\nA crucial design issue is the construction of the overlay network. In\nessence, there are two approaches [El-Sayed et al., 2003; Hosseini et al., 2007;\nAllani et al., 2009]. First, nodes may organize themselves directly into a tree,\nmeaning that there is a unique (overlay) path between every pair of nodes.\nAn alternative approach is that nodes organize into a mesh network in which\nevery node will have multiple neighbors and, in general, there exist multiple\npaths between every pair of nodes. The main difference between the two is\nthat the latter generally provides higher robustness: if a connection breaks\n(e.g., because a node fails), there will still be an opportunity to disseminate\ninformation without having to immediately reorganize the entire network.\nNote 4.13 (Advanced: Constructing a multicast tree in Chord)\nTo make matters concrete, let us consider a relatively simple scheme for construct-\ning a multicast tree in Chord, which we described in Note 2.6. This scheme was\noriginally proposed for Scribe [Castro et al., 2002b] which is an application-level\nmulticasting scheme built on top of Pastry [Rowstron and Druschel, 2001]. The\nlatter is also a DHT-based peer-to-peer system.\nAssume a node wants to start a multicast session. To this end, it simply\ngenerates a multicast identifier, say, mid which is just a randomly chosen 160-bit\nkey. It then looks up succ(mid), which is the node responsible for that key, and\npromotes it to become the root of the multicast tree that will be used for sending\ndata to interested nodes. To join the tree, a node P simply executes the operation\nlookup(mid) having the effect that a lookup message with the request to join the\nmulticast group mid will be routed from P to succ(mid). The routing algorithm\nitself will be explained in detail in Chapter 6.\nOn its way toward the root, the join request will pass several nodes. Assume\nit first reaches node Q. If Q had never seen a join request for mid before, it will\nbecome a forwarder for that group. At that point, P will become a child of Q\nwhereas the latter will continue to forward the join request to the root. If the next\nnode on the root, say, R is also not yet a forwarder, it will become one and record\nQ as its child and continue to send the join request.\nOn the other hand, if Q (or R) is already a forwarder for mid, it will also record\nthe previous sender as its child (i.e., P or Q, respectively), but there will not be a\nneed to send the join request to the root anymore, as Q (or R) will already be a\nmember of the multicast tree.\nNodes such as P that have explicitly requested to join the multicast tree are, by\ndefinition, also forwarders. The result of this scheme is that we construct a multi-\ncast tree across the overlay network with two types of nodes: pure forwarders that\nact as helpers, and nodes that are also forwarders, but have explicitly requested\nto join the tree. Multicasting is now simple: a node merely sends a multicast\nmessage toward the root of the tree by again executing the lookup(mid) operation,\nafter which that message can be sent along the tree.\nWe note that this high-level description of multicasting in Scribe does not do\ncomplete justice to its original design. The interested reader is encouraged to take\na look at the details, which can be found in [Castro et al., 2002b].\n \nDS 4.01\n\n\n234\nCHAPTER 4. COMMUNICATION\nPerformance issues in overlays\nFrom the high-level description given above, it should be clear that although\nbuilding a tree by itself is not that difficult once we have organized the nodes\ninto an overlay, building an efficient tree may be a different story. Note that\nin our description so far, the selection of nodes that participate in the tree\ndoes not take into account any performance metrics: it is purely based on the\n(logical) routing of messages through the overlay.\nTo understand the problem at hand, take a look at Figure 4.31 which\nshows a small set of five nodes that are organized in a simple overlay network,\nwith the node A forming the root of a multicast tree. The costs for traversing\na physical link are also shown. Now, whenever A multicasts a message to\nthe other nodes, the logical route, i.e., at the level of the overlay, is simply\nA →B →E →D →C. The actual route crosses the network-level links in the\nfollowing order: A →Ra →Rb →B →Rb →Ra →Re →E →Re →Rc →\nRd →D →Rd →Rc →C. It is thus seen that this message will traverse each\nof the links ⟨B, Rb⟩, ⟨Ra, Rb⟩, ⟨E, Re⟩, ⟨Rc, Rd⟩, and ⟨D, Rd⟩twice. The overlay\nnetwork would have been more efficient if we had not constructed overlay links\n⟨B, E⟩, and ⟨D, E⟩, but instead ⟨A, E⟩and ⟨C, E⟩. Such a configuration would\nhave saved the double traversal across physical links ⟨Ra, Rb⟩and ⟨Rc, Rd⟩.\nFigure 4.31: The relation between links in an overlay and network-level routes.\nThe quality of an application-level multicast tree is generally measured\nby three different metrics: link stress, stretch, and tree cost. Link stress is\ndefined per link and counts how often a packet crosses the same link [Chu\net al., 2002]. A link stress greater than 1 comes from the fact that although at a\nlogical level a packet may be forwarded along two different connections, part\nof those connections may actually correspond to the same physical link, as we\nshowed in Figure 4.31.\nThe stretch or relative delay penalty (RDP) measures the ratio of the\ndelay between two nodes in the overlay, and the delay that those two nodes\nwould experience in the underlying network. For example, messages from\nDS 4.01\n \n",
      "page_number": 234
    },
    {
      "number": 25,
      "title": "Segment 25 (pages 246-255)",
      "start_page": 246,
      "end_page": 255,
      "detection_method": "topic_boundary",
      "content": "4.4. MULTICAST COMMUNICATION\n235\nB to C follow the route B →Rb →Ra →Re →E →Re →Rc →Rd →\nD →Rd →Rc →C in the overlay network, having a total cost of 73 units.\nHowever, messages would have been routed in the underlying network along\nthe path B →Rb →Rd →Rc →C, with a total cost of 47 units, leading to a\nstretch of 1.55. Obviously, when constructing an overlay network, the goal is\nto minimize the aggregated stretch, or similarly, the average RDP measured\nover all node pairs.\nFinally, the tree cost is a global metric, generally related to minimizing\nthe aggregated link costs. For example, if the cost of a link is taken to be the\ndelay between its two end nodes, then optimizing the tree cost boils down\nto finding a minimal spanning tree in which the total time for disseminating\ninformation to all nodes is minimal.\nTo simplify matters somewhat, assume that a multicast group has an\nassociated and well-known node that keeps track of the nodes that have joined\nthe tree. When a new node issues a join request, it contacts this rendezvous\nnode to obtain a (potentially partial) list of members. The goal is to select\nthe best member that can operate as the new node’s parent in the tree. Who\nshould it select? There are many alternatives, and different proposals often\nfollow very different solutions.\nConsider, for example, a multicast group with only a single source. In\nthis case, the selection of the best node is obvious: it should be the source\n(because in that case, we can be assured that the stretch will be equal to 1).\nHowever, in doing so, we would introduce a star topology with the source\nin the middle. Although simple, it is not difficult to imagine the source may\neasily become overloaded. In other words, selection of a node will generally\nbe constrained in such a way that only those nodes may be chosen who\nhave k or fewer neighbors, with k being a design parameter. This constraint\nseverely complicates the tree-establishment algorithm, as a suitable solution\nmay require that part of the existing tree is reconfigured. Tan et al. [2003]\nprovide an extensive overview and evaluation of various solutions to this\nproblem.\nNote 4.14 (Advanced: Switch-trees)\nAs an illustration, let us take a closer look at one specific family, known as switch-\ntrees [Helder and Jamin, 2002]. The basic idea is simple. Assume we already have\na multicast tree with a single source as root. In this tree, a node P can switch\nparents by dropping the link to its current parent in favor of a link to another\nnode. The only constraints imposed on switching links is that the new parent can\nnever be a member of the subtree rooted at P (as this would partition the tree\nand create a loop), and that the new parent will not have too many immediate\nchildren. This last requirement is needed to limit the load of forwarding messages\nby any single node.\nThere are different criteria for deciding to switch parents. A simple one is to\n \nDS 4.01\n\n\n236\nCHAPTER 4. COMMUNICATION\noptimize the route to the source, effectively minimizing the delay when a message\nis to be multicasted. To this end, each node regularly receives information on\nother nodes (we will explain one specific way of doing this below). At that point,\nthe node can evaluate whether another node would be a better parent in terms of\ndelay along the route to the source, and if so, initiates a switch.\nAnother criterion could be whether the delay to the potential other parent\nis lower than to the current parent. If every node takes this as a criterion, then\nthe aggregated delays of the resulting tree should ideally be minimal. In other\nwords, this is an example of optimizing the cost of the tree, as we explained\nabove. However, more information would be needed to construct such a tree, but\nas it turns out, this simple scheme is a reasonable heuristic leading to a good\napproximation of a minimal spanning tree.\nAs an example, consider the case where a node P receives information on\nthe neighbors of its parent. Note that the neighbors consist of P’s grandparent,\nalong with the other siblings of P’s parent. Node P can then evaluate the delays\nto each of these nodes and subsequently choose the one with the lowest delay,\nsay Q, as its new parent. To that end, it sends a switch request to Q. To prevent\nloops from being formed due to concurrent switching requests, a node that has an\noutstanding switch request will simply refuse to process any incoming requests.\nIn effect, this leads to a situation where only completely independent switches\ncan be carried out simultaneously. Furthermore, P will provide Q with enough\ninformation to allow the latter to conclude that both nodes have the same parent,\nor that Q is the grandparent.\nAn important problem that we have not yet addressed is node failure. In the\ncase of switch-trees, a simple solution is proposed: whenever a node notices that\nits parent has failed, it attaches itself to the root. At that point, the optimization\nprotocol can proceed as usual and will eventually place the node at a good point\nin the multicast tree. Experiments described in [Helder and Jamin, 2002] show\nthat the resulting tree is indeed close to a minimal spanning one.\n4.4.2\nFlooding-based multicasting\nSo far, we have assumed that when a message is to be multicasted, it is to\nbe received by every node in the overlay network. Strictly speaking, this\ncorresponds to broadcasting. In general, multicasting refers to sending a\nmessage to a subset of all the nodes, that is, a specific group of nodes. A\nkey design issue when it comes to multicasting is to minimize the use of\nintermediate nodes for which the message is not intended. To make this clear,\nif the overlay is organized as a multi-level tree, yet only the leaf nodes are the\nones who should receive a multicast message, then clearly there may be quite\nsome nodes who need to store and subsequently forward a message that is\nnot meant for them.\nOne simple way to avoid such inefficiency, is to construct an overlay\nnetwork per multicast group. As a consequence, multicasting a message m to a\nDS 4.01\n \n\n\n4.4. MULTICAST COMMUNICATION\n237\ngroup G is the same as broadcasting m to G. The drawback of this solution is\nthat a node belonging to several groups, will, in principle, need to maintain a\nseparate list of its neighbors for each group of which it is a member.\nIf we assume that an overlay corresponds to a multicast group, and thus\nthat we need to broadcast a message, a naive way of doing so is to apply\nflooding. In this case, each node simply forwards a message m to each of its\nneighbors, except to the one from which it received m. Furthermore, if a node\nkeeps track of the messages it received and forwarded, it can simply ignore\nduplicates.\nTo understand the performance of flooding, we model an overlay network\nas a connected undirected graph G = (V, E) with nodes V and links E.\nLet v0 be the node that initiates flooding. In principle, every node other\nnode than v0 will send out the message to its neighbors once, except to the\nneighbor from which it had received the message. We will thus see a total of\nδ(v0) + ∑v∈V−v0(δ(v) −1) messages, with δ(v) the number of neighbors of\nthe node v. For any undirected graph, ∑v∈V δ(v) = 2 · |E|, with |E| denoting\nthe total number of edges. In other words, we will see 2|E| −|V| + 1 messages\nbeing sent, making flooding quite inefficient. Only if G is a tree, will flooding\nbe optimal, for in that case, |E| = |V| −1. In the worst case, when G is fully\nconnected, we have |E| = (|V|\n2 ) leading to an order of |V|2 messages.\nSuppose now that we have no information on the structure of the overlay\nnetwork and that the best we can assume is that it can be represented as\na random graph, which (to keep it simple) is a graph having a probability\npedge that two vertices are joined by an edge, also known as an Erdös-Rényi\ngraph [Erdös and Rényi, 1959]. Note that we are actually considering our\noverlay network to be an unstructured peer-to-peer network, and that we do\nnot have any information on how it is being constructed. With a probability\npedge that two nodes are joined, and a total of (|V|\n2 ) edges, it is not difficult to\nsee that we can expect our overlay to have |E| = 1\n2 · pedge · |V| · (|V| −1) edges.\nTo give an impression of what we are dealing with, Figure 4.32 shows the\nrelationship between the number of nodes and edges for different values of\npedge. As can be seen, the number of edges can easily become large, even for\nsmall values of pedge.\nTo reduce the number of messages, we can also use probabilistic flooding\nas introduced by Banaei-Kashani and Shahab [2003] and formally analyzed\nby Oikonomou and Stavrakakis [2007]. The idea is simple: when a node is\nflooding a message m and needs to forward m to a specific neighbor, it will\ndo so with a probability pflood. The effect can be dramatic: the total number\nof messages sent will drop linearly in pflood. However, there is also a risk:\nthe lower pflood, the higher the chance that not all nodes in the network will\nbe reached. This risk is caused by the simple fact that all neighbors of a\nspecific node Q may have decided not to forward m to Q. If Q has n neighbors,\nthen this can happen roughly with a probability of (1 −pflood)n. Clearly, the\n \nDS 4.01\n\n\n238\nCHAPTER 4. COMMUNICATION\nFigure 4.32: The size of a random overlay as function of the number of nodes.\nnumber of neighbors plays an important role in deciding whether to forward a\nmessage, and, indeed, we can replace the static probability of forwarding with\none that takes the degree of the neighbor into account. This has been further\ndeveloped and analyzed by Sereno and Gaeta [2011]. To give an idea of the\nefficiency of probabilistic broadcasting: in a random network of 10,000 nodes\nand pedge = 0.1, we need only set pflood = 0.01 to establish a more than 50-fold\nreduction in the number of messages sent in comparison to full flooding.\nWhen dealing with a structured overlay, that is, one having a more or less\ndeterministic topology, designing efficient flooding schemes is simpler. As an\nexample, consider an n-dimensional hypercube, shown in Figure 4.33 for the\ncase n = 4, as also discussed in Section 2.4.1.\nFigure 4.33: A simple peer-to-peer, four-dimensional hypercube.\nA simple and efficient broadcast scheme has been designed by Schlosser\net al. [2002] and relies on keeping track of neighbors per dimension. This is\nbest explained by considering that every node in an n-dimensional hypercube\nis represented by a bit string of length n. Each edge in the overlay is labeled\nwith its dimension. For the case n = 4, node 0000 will have as its neighbors\nthe set {0001, 0010, 0100, 1000}. The edge between 0000 and 0001 is labeled\nDS 4.01\n \n\n\n4.4. MULTICAST COMMUNICATION\n239\n“4” corresponding to changing the 4th bit when comparing 0000 to 0001 and\nvice versa. Likewise, the edge ⟨0000, 0100⟩is labeled “2,” and so forth. A node\ninitially broadcasts a message m to all of its neighbors, and tags m with the\nlabel of the edge over which it sends the message. In our example, if node\n1001 broadcasts a message, it will send the following:\n• (m,1) to 0001\n• (m,2) to 1101\n• (m,3) to 1011\n• (m,4) to 1000\nWhen a node receives a broadcast message, it will forward it only along edges\nthat have a higher dimension. In other words, in our example, node 1101 will\nforward m only to nodes 1111 (joined to 1101 by an edge labeled “3”) and\n1100 (joined by an edge with label “4”). Using this scheme, it can be shown\nthat every broadcast requires precisely N −1 messages, where N = 2n, that is\nthe number of nodes in a n-dimensional hypercube. This broadcasting scheme\nis therefore optimal in terms of the number of messages sent.\nNote 4.15 (Advanced: Ring-based flooding)\nFigure 4.34: A Chord ring in which node 9 broadcasts a message.\nA hypercube is a straightforward example of how we can effectively use\nknowledge of the structure of an overlay network to establish efficient flooding. In\nthe case of Chord, we can follow an approach proposed by Ghodsi [2010]. Recall\nthat in Chord each node is identified by a number p, and each resource (typically\n \nDS 4.01\n\n\n240\nCHAPTER 4. COMMUNICATION\na file), is assigned a key k from the same space as used for node identifiers. The\nsuccessor succ(k) of a key k is the node with the smallest identifier p ≥k. Consider\nthe small Chord ring shown in Figure 4.34 and assume that node 9 wants to flood\na message to all other nodes.\nIn our example, node 9 divides the identifier space into four segments (one\nfor each of its neighbors). Node 28 is requested to make sure that the message\nreaches all nodes with identifiers 28 ≤k < 9 (recall that we are applying modulo\narithmetic); node 18 takes care of nodes with identifiers 18 ≤k < 28; node 14 for\n14 ≤k < 18; and 11 for identifiers 11 ≤k < 14.\nNode 28 will subsequently divide the part of the identifier space it is requested\nto handle into two subsegments: one for its neighboring node 1 and another for 4.\nLikewise, node 18, responsible for segment [18, 28) will “split” that segment into\nonly one part: it has only one neighbor to delegate the flood to, and forwards the\nmessage to node 20, telling it that it should handle segment [20, 28).\nIn the last step, only node 20 has work to do. It forwards the message to node\n21, telling it to forward it to nodes known to it in the segment [21, 28). As there\nare no such nodes anymore, the broadcast completes.\nAs in the case of our hypercube example, we see that flooding is done with\nN −1 messages, with N being the number of nodes in the system.\n4.4.3\nGossip-based data dissemination\nAn important technique for disseminating information is to rely on epidemic\nbehavior, also referred to as gossiping. Observing how diseases spread\namong people, researchers have since long investigated whether simple tech-\nniques could be developed for spreading information in very large-scale\ndistributed systems. The main goal of these epidemic protocols is to rapidly\npropagate information among a large collection of nodes using only local infor-\nmation. In other words, there is no central component by which information\ndissemination is coordinated.\nTo explain the general principles of these algorithms, we assume that all\nupdates for a specific data item are initiated at a single node. In this way, we\nsimply avoid write-write conflicts. The following presentation is based on the\nclassical paper by Demers et al. [1987] on epidemic algorithms. An overview\nof epidemic information dissemination can be found in [Eugster et al., 2004].\nInformation dissemination models\nAs the name suggests, epidemic algorithms are based on the theory of epi-\ndemics, which studies the spreading of infectious diseases. In the case of\nlarge-scale distributed systems, instead of spreading diseases, they spread\ninformation. Research on epidemics for distributed systems also aims at an\nentirely different goal: whereas health organizations will do their best to\nprevent infectious diseases from spreading across large groups of people,\nDS 4.01\n \n\n\n4.4. MULTICAST COMMUNICATION\n241\ndesigners of epidemic algorithms for distributed systems will try to “infect”\nall nodes with new information as fast as possible.\nUsing the terminology from epidemics, a node that is part of a distributed\nsystem is called infected if it holds data that it is willing to spread to other\nnodes. A node that has not yet seen this data is called susceptible. Finally, an\nupdated node that is not willing or able to spread its data is said to have been\nremoved. Note that we assume we can distinguish old from new data, for\nexample because it has been timestamped or versioned. In this light, nodes\nare also said to spread updates.\nA popular propagation model is that of anti-entropy. In this model, a\nnode P picks another node Q at random, and subsequently exchanges updates\nwith Q. There are three approaches to exchanging updates:\n1. P only pulls in new updates from Q\n2. P only pushes its own updates to Q\n3. P and Q send updates to each other (i.e., a push-pull approach)\nWhen it comes to rapidly spreading updates, only pushing updates turns\nout to be a bad choice. Intuitively, this can be understood as follows. First,\nnote that in a pure push-based approach, updates can be propagated only by\ninfected nodes. However, if many nodes are infected, the probability of each\none selecting a susceptible node is relatively small. Consequently, chances are\nthat a particular node remains susceptible for a long period simply because\nan infected node does not select it.\nIn contrast, the pull-based approach works much better when many nodes\nare infected. In that case, spreading updates is essentially triggered by suscep-\ntible nodes. Chances are big that such a node will contact an infected one to\nsubsequently pull in the updates and become infected as well.\nIf only a single node is infected, updates will rapidly spread across all\nnodes using either form of anti-entropy, although push-pull remains the best\nstrategy [Jelasity et al., 2007]. Define a round as spanning a period in which\nevery node will have taken the initiative once to exchange updates with a\nrandomly chosen other node. It can then be shown that the number of rounds\nto propagate a single update to all nodes is of the order O(log(N)), where N\nis the number of nodes in the system. This indicates indeed that propagating\nupdates is fast, but above all scalable.\nNote 4.16 (Advanced: An analysis of anti-entropy)\nA simple and straightforward analysis will give some idea on how well anti-\nentropy works. Consider a system with N nodes. One of these nodes initiates the\nspreading of a message m to all other nodes. Let pi denote the probability that a\nnode P has not yet received m after the ith round. We distinguish the following\nthree cases:\n \nDS 4.01\n\n\n242\nCHAPTER 4. COMMUNICATION\n• With a pure pull-based approach, pi+1 = (pi)2: not only had P not yet been\nupdated in the previous round, also P contacts a node that had not yet\nreceived m.\n• With a pure push-based approach, pi+1 = pi · (1 −\n1\nN−1)N(1−pi): again, P\nshould not have been updated in the previous round, but also none of the\nupdated nodes should contact P. The probability that not a single node\ncontacts P is 1 −\n1\nN−1; we can expect that there are N(1 −pi) updated nodes\nin round i.\n• In a push-pull approach, we can simply combine the two: P should not\ncontact an updated node, and should not be contacted by one.\nFigure 4.35: (a) The number of nodes that have not been updated as a\nfunction of the number of dissemination rounds.\nFigure 4.35: (b) Zooming in the differences between the three anti-entropy\napproaches when almost all nodes have been updated.\nFigure 4.35(a) shows how quickly the probability of not yet being updated\ndrops as a function of the number of rounds in a network of 10,000 nodes. After\na slow start, the information is rapidly disseminated. In Figure 4.35(b) we have\nzoomed into what happens in the last number of rounds while also using a log\nscale for the y-axis. Indeed, assuming that nodes are up-and-running all the time,\nDS 4.01\n \n\n\n4.4. MULTICAST COMMUNICATION\n243\nit turns out that an anti-entropy push-pull strategy can be an extremely effective\ndissemination protocol.\nOne specific variant of epidemic protocols is called rumor spreading. It\nworks as follows. If node P has just been updated for a data item x, it contacts\nan arbitrary other node Q and tries to push the update to Q. However, it is\npossible that Q was already updated by another node. In that case, P may\nlose interest in spreading the update any further, say with probability pstop. In\nother words, it then becomes removed.\nRumor spreading is gossiping as we mostly experience it in real life. When\nBob has some hot news to spread around, he may phone his friend Alice,\ntelling her all about it. Alice, like Bob, will be really excited to spread the\nrumor to her friends as well. However, she will become disappointed when\nphoning a friend, say Chuck, only to hear that the news has already reached\nhim. Chances are that she will stop phoning other friends, for what good is it\nif they already know?\nRumor spreading turns out to be an excellent way of rapidly spreading\nnews. However, it cannot guarantee that all nodes will actually be updated [De-\nmers et al., 1987]. In fact, when there are many nodes that participate in the\nepidemics, the fraction s of nodes that will remain ignorant of an update, that\nis, remain susceptible, satisfies the equation:\ns = e−(1/pstop+1)(1−s)\nTo get an idea of what this means, take a look at Figure 4.36, which\nshows s as a function of pstop. Even for high values of pstop we see that the\nfraction of nodes that remains ignorant is relatively low, and always less than\napproximately 0.2. For pstop = 0.20 it can be shown that s = 0.0025. However,\nin those cases when pstop is relatively high, additional measures will need to\nbe taken to ensure that all nodes are updated.\nNote 4.17 (Advanced: Analysis of rumor spreading)\nTo formally analyze the situation for rumor spreading, we let s denote the fraction\nof nodes that have not yet been updated, i.e., the fraction of susceptible nodes.\nLikewise, let i denote the fraction of infected nodes: the ones that have been\nupdated and are still contacting other nodes to spread information. Finally, r\nis the fraction of nodes that have been updated, but have given up, i.e., they\nare passive and no longer play a role in disseminating information. Obviously,\ns + i + r = 1. Using theory from epidemics, it is not difficult to see the following:\n(1)\nds/dt\n=\n−s · i\n(2)\ndi/dt\n=\ns · i −pstop · (1 −s) · i\n⇒\ndi/ds\n=\n−(1 + pstop) +\npstop\ns\n⇒\ni(s)\n=\n−(1 + pstop) · s + pstop · ln(s) + C\n \nDS 4.01\n\n\n244\nCHAPTER 4. COMMUNICATION\nFigure 4.36: The relation between the fraction s of update-ignorant nodes and\nthe probability pstop that a node will stop gossiping once it contacts a node\nthat has already been updated.\nwhere we use the notation i(s) to express i as a function of s. When s = 1, no\nnodes have yet been infected, meaning that i(1) = 0. This allows us to derive that\nC = 1 + pstop, and thus\ni(s) = (1 + pstop) · (1 −s) + pstop · ln(s)\nWe are looking for the situation that there is no more rumor spreading, i.e., when\ni(s) = 0. Having a closed expression for i(s) then leads to\ns = e−(1/pstop+1)(1−s)\nOne of the main advantages of epidemic algorithms is their scalability\nsince the number of synchronizations between processes is relatively small\ncompared to other propagation methods. For wide-area systems, Lin and\nMarzullo [1999] have shown that it makes sense to take the actual network\ntopology into account to achieve better results. In that case, nodes that are\nconnected to only a few other nodes are contacted with a relatively high\nprobability. The underlying assumption is that such nodes form a bridge to\nother remote parts of the network; therefore, they should be contacted as soon\nas possible. This approach is referred to as directional gossiping and comes\nin different variants.\nThis problem touches upon an important assumption that most epidemic\nsolutions make, namely that a node can randomly select any other node to\ngossip with. This implies that, in principle, the complete set of nodes should\nbe known to each member. In a large system, this assumption can never hold,\nand special measures will need to be taken to mimic such properties. We\nreturn to this issue in Section 5.5.2 when we discuss a peer-sampling service.\nDS 4.01\n \n",
      "page_number": 246
    },
    {
      "number": 26,
      "title": "Segment 26 (pages 256-264)",
      "start_page": 256,
      "end_page": 264,
      "detection_method": "topic_boundary",
      "content": "4.5. SUMMARY\n245\nRemoving data\nEpidemic algorithms are fantastic for spreading updates. However, they have\na rather strange side effect: spreading the deletion of a data item is hard. The\nessence of the problem lies in the fact that deletion of a data item destroys all\ninformation on that item. Consequently, when a data item is simply removed\nfrom a node, that node will eventually receive old copies of the data item and\ninterpret those as updates on something it did not have before.\nThe trick is to record the deletion of a data item as just another update, and\nkeep a record of that deletion. In this way, old copies will not be interpreted\nas something new, but merely treated as versions that have been updated by\na delete operation. The recording of a deletion is done by spreading death\ncertificates.\nOf course, the problem with death certificates is that they should eventually\nbe cleaned up, or otherwise each node will gradually build a huge local\ndatabase of historical information on deleted data items that is otherwise not\nused. Demers et al. [1987] propose to use what are called dormant death\ncertificates. Each death certificate is timestamped when it is created. If it can\nbe assumed that updates propagate to all nodes within a known finite time,\nthen death certificates can be removed after this maximum propagation time\nhas elapsed.\nHowever, to provide hard guarantees that deletions are indeed spread to\nall nodes, only a very few nodes maintain dormant death certificates that are\nnever thrown away. Assume node P has such a certificate for a data item x.\nIf by any chance an obsolete update for x reaches P, P will react by simply\nspreading the death certificate for x again.\n4.5\nSummary\nHaving powerful and flexible facilities for communication between processes\nis essential for any distributed system. In traditional network applications,\ncommunication is often based on the low-level message-passing primitives\noffered by the transport layer. An important issue in middleware systems\nis to offer a higher level of abstraction that will make it easier to express\ncommunication between processes than the support offered by the interface\nto the transport layer.\nOne of the most widely used abstractions is the Remote Procedure Call\n(RPC). The essence of an RPC is that a service is implemented through a\nprocedure, of which the body is executed at a server. The client is offered\nonly the signature of the procedure, that is, the procedure’s name along\nwith its parameters. When the client calls the procedure, the client-side\nimplementation, called a stub, takes care of wrapping the parameter values\ninto a message and sending that to the server. The latter calls the actual\nprocedure and returns the results, again in a message. The client’s stub\n \nDS 4.01\n\n\n246\nCHAPTER 4. COMMUNICATION\nextracts the result values from the return message and passes it back to the\ncalling client application.\nRPCs offer synchronous communication facilities, by which a client is\nblocked until the server has sent a reply.\nAlthough variations of either\nmechanism exist by which this strict synchronous model is relaxed, it turns\nout that general-purpose, high-level message-oriented models are often more\nconvenient.\nIn message-oriented models, the issues are whether communication is\npersistent, and whether communication is synchronous.\nThe essence of\npersistent communication is that a message that is submitted for transmission,\nis stored by the communication system as long as it takes to deliver it. In\nother words, neither the sender nor the receiver needs to be up and running\nfor message transmission to take place.\nIn transient communication, no\nstorage facilities are offered so that the receiver must be prepared to accept\nthe message when it is sent.\nIn asynchronous communication, the sender is allowed to continue imme-\ndiately after the message has been submitted for transmission, possibly before\nit has even been sent. In synchronous communication, the sender is blocked\nat least until a message has been received. Alternatively, the sender may be\nblocked until message delivery has taken place or even until the receiver has\nresponded, as with RPCs.\nMessage-oriented middleware models generally offer persistent asyn-\nchronous communication, and are used where RPCs are not appropriate.\nThey are often used to assist the integration of (widely dispersed) collections\nof databases into large-scale information systems.\nFinally, an important class of communication protocols in distributed\nsystems is multicasting. The basic idea is to disseminate information from\none sender to multiple receivers. We have discussed two different approaches.\nFirst, multicasting can be achieved by setting up a tree from the sender to\nthe receivers. Considering that it is now well understood how nodes can self-\norganize into peer-to-peer system, solutions have also appeared to dynamically\nset up trees in a decentralized fashion. Second, flooding messages across\nthe network is extremely robust, yet requires special attention if we want to\navoid severe waste of resources as nodes may see messages multiple times.\nProbabilistic flooding, by which a node forwards a message with a certain\nprobability, often proves to combine simplicity and efficiency, while being\nhighly effective.\nAnother important class of dissemination solutions deploys epidemic\nprotocols. These protocols have proven to be simple and extremely robust.\nDS 4.01\n \n\n\n05\nCOORDINATION\n\n\n248\nCHAPTER 5. COORDINATION\nIn the previous chapters, we have looked at processes and communication\nbetween processes. While communication is important, it is not the entire\nstory. Closely related is how processes cooperate and synchronize with one\nanother. Cooperation is partly supported by naming, which allows processes\nto at least share resources, or entities in general.\nIn this chapter, we mainly concentrate on how processes can synchronize\nand coordinate their actions.\nFor example, it is important that multiple\nprocesses do not simultaneously access a shared resource, such as a file, but\ninstead cooperate in granting each other temporary exclusive access. Another\nexample is that multiple processes may sometimes need to agree on the\nordering of events, such as whether message m1 from process P was sent\nbefore or after message m2 from process Q.\nSynchronization and coordination are two closely related phenomena. In\nprocess synchronization we make sure that one process waits for another to\ncomplete its operation. When dealing with data synchronization, the problem\nis to ensure that two sets of data are the same. When it comes to coordination,\nthe goal is to manage the interactions and dependencies between activities\nin a distributed system [Malone and Crowston, 1994]. From this perspective,\none could state that coordination encapsulates synchronization.\nAs it turns out, coordination in distributed systems is often much more\ndifficult compared to that in uniprocessor or multiprocessor systems. The\nproblems and solutions that are discussed in this chapter are, by their nature,\nrather general, and occur in many situations in distributed systems.\nWe start with a discussion of the issue of synchronization based on actual\ntime, followed by synchronization in which only relative ordering matters\nrather than ordering in absolute time.\nOften, it is important that a group of processes can appoint one process\nas a coordinator, which can be done through election algorithms. We discuss\nvarious election algorithms in a separate section. Before that, we look into\nseveral algorithms for coordinating mutual exclusion to a shared resource. As\na special class of coordination problems, we also dive into location systems,\nby which we place a process in a multidimensional plane. Such placements\nare useful when dealing with very large distributed systems.\nWe also consider three different gossip-based coordination problems: ag-\ngregation, peer sampling, and overlay construction.\nFinally, we already came across publish-subscribe systems, but have not\nyet discussed in any detail how we actually match subscriptions to publica-\ntions. There are many ways to do this, and we look at centralized as well as\ndecentralized implementations.\nDistributed algorithms come in all sorts and flavors and have been devel-\noped for different types of distributed systems. Many examples (and further\nreferences) can be found in Andrews [2000], Cachin et al. [2011], and Fokkink\n[2018]. More formal approaches to a wealth of algorithms can be found in\nDS 4.01\n \n\n\n5.1. CLOCK SYNCHRONIZATION\n249\ntextbooks from Attiya and Welch [2004], Lynch [1996], Santoro [2007], and Tel\n[2000].\n5.1\nClock synchronization\nIn a centralized system, time is unambiguous. When a process wants to know\nthe time, it simply makes a call to the operating system. If process A asks for\nthe time, and then a little later process B asks for the time, the value that B\ngets will be higher than (or possibly equal to) the value A got. It will certainly\nnot be lower. In a distributed system, achieving agreement on time is not\ntrivial.\nJust think, for a moment, about the implications of the lack of global time\non the Unix make program, as a simple example. Normally, in Unix, large\nprograms are split up into multiple source files, so that a change to one source\nfile requires only one file to be recompiled, not all the files. If a program\nconsists of 100 files, not having to recompile everything because one file has\nbeen changed greatly increases the speed at which programmers can work.\nThe way make normally works is simple. When the programmer has\nfinished changing all the source files, she runs make, which examines the times\nat which all the source and object files were last modified. If the source file\ninput.c has time 2151 and the corresponding object file input.o has time\n2150, make knows that input.c has been changed since input.o was created,\nand thus input.c must be recompiled. On the other hand, if output.c has\ntime 2144 and output.o has time 2145, no compilation is needed. Thus make\ngoes through all the source files to find out which ones need to be recompiled\nand calls the compiler to recompile them.\nNow imagine what could happen in a distributed system in which there\nwas no global agreement on time. Suppose that output.o has time 2144 as\nabove, and shortly thereafter output.c is modified but is assigned time 2143\nbecause the clock on its machine is slightly behind, as shown in Figure 5.1.\nMake will not call the compiler. The resulting executable binary program will\nthen contain a mixture of object files from the old sources and the new sources.\nIt may crash, and the programmer will go crazy trying to understand what is\nwrong with the code.\nThere are many more examples where an accurate account of time is\nneeded. The example above can easily be reformulated to file timestamps in\ngeneral. In addition, think of application domains such as financial brokerage,\nsecurity auditing, and collaborative sensing, and it will become clear that\naccurate timing is important. From a different perspective, Najafi et al. [2021]\nargue that accurate timing is essential for most systems research, if only to\nensure that performance measurements can be properly compared. Since\ntime is so basic to the way people think and the effect of not having all the\nclocks synchronized can be so dramatic, it is fitting that we begin our study of\n \nDS 4.01\n\n\n250\nCHAPTER 5. COORDINATION\nFigure 5.1: When each machine has its own clock, an event that occurred after\nanother event may nevertheless be assigned an earlier time.\nsynchronization with the simple question: Would it be possible to synchronize\nall the clocks in a distributed system? The answer is surprisingly complicated.\n5.1.1\nPhysical clocks\nNearly all computers often have several circuits for keeping track of time.\nDespite the widespread use of the word “clock” to refer to these devices,\nthey are not actually clocks in the usual sense. Timer is perhaps a better\nword. A computer timer is usually a precisely machined quartz crystal. When\nkept under tension, quartz crystals oscillate at a well-defined frequency that\ndepends on the kind of crystal, how it is cut, and the amount of tension.\nAssociated with each crystal are two registers, a counter and a holding\nregister. Each oscillation of the crystal decrements the counter by one. When\nthe counter gets to zero, an interrupt is generated and the counter is reloaded\nfrom the holding register. In this way, it is possible to program a timer to\ngenerate an interrupt 60 times a second, or at any other desired frequency.\nEach interrupt is called one clock tick.\nWhen the system is booted and initialized for the very first time, the user is\nasked for the current time zone, or even time, to convert time to the number of\nticks after some known starting date and stored in memory. Most computers\nhave a special battery-backed up CMOS RAM so that the date and time need\nnot be entered on subsequent boots. At every clock tick, the interrupt service\nprocedure adds one to the time stored in memory. In this way, the (software)\nclock is kept up to date.\nWith a single computer and a single clock, it does not matter much if this\nclock is off by a small amount. Since all processes on the machine use the\nsame clock, they will still be internally consistent. For example, if the file\ninput.c has time 2151 and file input.o has time 2150, make will recompile the\nsource file, even if the clock is off by 2 and the true times are 2153 and 2152,\nrespectively. All that really matters are the relative times.\nAs soon as multiple CPUs are introduced, each with its own clock, the sit-\nuation changes radically. Although the frequency at which a crystal oscillator\nruns is usually fairly stable, it is impossible to guarantee that the crystals in\nDS 4.01\n \n\n\n5.1. CLOCK SYNCHRONIZATION\n251\ndifferent computers all run at the same frequency. In practice, when a system\nhas n computers, all n crystals will run at slightly different rates, causing\nthe (software) clocks gradually to get out of sync and give different values\nwhen read out. This difference in time values is called clock skew. As a\nconsequence of this clock skew, programs that expect the time associated\nwith a file, object, process, or message to be correct and independent of the\nmachine on which it was generated (i.e., which clock it used) can fail, as we\nsaw in the make example above.\nIn some systems (e.g., real-time systems), the actual clock time is important.\nUnder these circumstances, external physical clocks are needed. For reasons of\nefficiency and redundancy, multiple physical clocks are generally considered\ndesirable, which yields two problems: (1) how do we synchronize them with\nreal-world clocks, and (2) how do we synchronize the clocks with each other?\nNote 5.1 (More information: Determining real time)\nBefore answering these questions, let us digress slightly to see how time is\nactually measured. It is not nearly as easy as one might think, especially when\nhigh accuracy is required. Since the invention of mechanical clocks in the 17th\ncentury, time has been measured astronomically. Every day, the sun appears to\nrise on the eastern horizon, then climbs to a maximum height in the sky, and\nfinally sinks in the west. The event of the sun’s reaching its highest apparent\npoint in the sky is called the transit of the sun. This event occurs at about noon\neach day. The interval between two consecutive transits of the sun is called the\nsolar day. Since there are 24 hours in a day, each containing 3600 seconds, the\nsolar second is defined as exactly 1/86400th of a solar day. The geometry of the\nmean solar day calculation is shown in Figure 5.2.\nFigure 5.2: Computation of the mean solar day.\n \nDS 4.01\n\n\n252\nCHAPTER 5. COORDINATION\nIn the 1940s, it was established that the period of the earth’s rotation is not\nconstant. The earth is slowing down due to tidal friction and atmospheric drag.\nBased on studies of growth patterns in ancient coral, geologists now believe that\n300 million years ago there were about 400 days per year. The length of the year\n(the time for one trip around the sun) is not thought to have changed; the day has\nsimply become longer. In addition to this long-term trend, short-term variations in\nthe length of the day also occur, probably caused by turbulence deep in the earth’s\ncore of molten iron. These revelations lead astronomers to compute the length\nof the day by measuring a large number of days and taking the average before\ndividing by 86,400. The resulting quantity was called the mean solar second.\nWith the invention of the atomic clock in 1948, it became possible to measure\ntime much more accurately, and independent of the wiggling and wobbling of the\nearth, by counting transitions of the cesium 133 atom. The physicists took over\nthe job of timekeeping from the astronomers and defined the second to be the\ntime it takes the cesium 133 atom to make exactly 9,192,631,770 transitions. The\nchoice of 9,192,631,770 was made to make the atomic second equal to the mean\nsolar second in the year of its introduction. Currently, several laboratories around\nthe world have cesium 133 clocks. Periodically, each laboratory tells the Bureau\nInternational de l’Heure (BIH) in Paris how many times its clock has ticked. The\nBIH averages these to produce International Atomic Time, which is abbreviated\nto TAI. Thus TAI is just the mean number of ticks of the cesium 133 clocks since\nmidnight on Jan. 1, 1958 (the beginning of time) divided by 9,192,631,770.\nAlthough TAI is highly stable and available to anyone who wants to go to the\ntrouble of buying a cesium clock, there is a serious problem with it; 86,400 TAI\nseconds is now about 3 msec less than a mean solar day (because the mean solar\nday is getting longer all the time). Using TAI for keeping time would mean that\nover the course of the years, noon would get earlier and earlier, until it would\neventually occur in the wee hours of the morning. People might notice this and\nwe could have the same kind of situation as occurred in 1582 when Pope Gregory\nXIII decreed that 10 days be omitted from the calendar. This event caused riots in\nthe streets because landlords demanded a full month’s rent and bankers a full\nmonth’s interest, while employers refused to pay workers for the 10 days they did\nnot work, to mention only a few of the conflicts. The Protestant countries, as a\nmatter of principle, refused to have anything to do with papal decrees and did\nnot accept the Gregorian calendar for 170 years.\nBIH solves the problem by introducing leap seconds whenever the discrepancy\nbetween TAI and solar time grows to 800 msec. The use of leap seconds is\nillustrated in Figure 5.3. This correction gives rise to a time system based on\nconstant TAI seconds but which stays in phase with the apparent motion of the\nsun. This time system is known as Coordinated Universal Time abbreviated to\nUTC.\nMost electric power companies synchronize the timing of their 60-Hz or 50-Hz\nclocks to UTC, so when BIH announces a leap second, the power companies raise\ntheir frequency to 61 Hz or 51 Hz for 60 or 50 sec, to advance all the clocks in their\ndistribution area. Since 1 sec is a noticeable interval for a computer, an operating\nsystem that needs to keep accurate time over a period of years must have special\nDS 4.01\n \n\n\n5.1. CLOCK SYNCHRONIZATION\n253\nsoftware to account for leap seconds as they are announced (unless they use the\npower line for time, which is usually too crude). The total number of leap seconds\nintroduced into UTC so far is about 30.\nFigure 5.3: TAI seconds are of constant length, unlike solar seconds. Leap\nseconds are introduced when necessary to keep in phase with the sun.\nThe basis for keeping global time is a called Coordinated Universal Time,\nbut is abbreviated as UTC. UTC is the basis of all modern civil timekeeping\nand is a worldwide standard. To provide UTC to people who need precise\ntime, some 40 shortwave radio stations around the world broadcast a short\npulse at the start of each UTC second. The accuracy of these stations is about\n± 1 msec, but due to random atmospheric fluctuations that can affect the\nlength of the signal path, in practice the accuracy is no better than ± 10\nmilliseconds.\nSeveral earth satellites also offer a UTC service. The Geostationary Oper-\national Environment Satellite can provide UTC accurately to 0.5 msec, and\nsome other satellites do even better. By combining receptions from several\nsatellites, ground timeservers can be built, offering an accuracy of 50 nanosec-\nonds. UTC receivers are commercially available, and many computers are\nequipped with one.\n5.1.2\nClock synchronization algorithms\nIf one machine has a UTC receiver, the goal becomes keeping all the other\nmachines synchronized to it. If no machines have UTC receivers, each machine\nkeeps track of its own time, and the goal is to keep all the machines together\nas well as possible. Many algorithms have been proposed for doing this\nsynchronization. Surveys are provided by Ramanathan et al. [1990], Horauer\n[2004], Shin et al. [2011], and Levesque and Tipper [2016].\nAll clocks are based on some harmonic oscillator: an object that resonates\nat a certain frequency and from which we can subsequently derive time.\nAtomic clocks are based on the transitions of the cesium 133 atom, which is\nnot only very high, but also very constant. Hardware clocks in most computers\nuse a crystal oscillator based on quartz, which is also capable of producing\n \nDS 4.01\n",
      "page_number": 256
    },
    {
      "number": 27,
      "title": "Segment 27 (pages 265-273)",
      "start_page": 265,
      "end_page": 273,
      "detection_method": "topic_boundary",
      "content": "254\nCHAPTER 5. COORDINATION\na very high, stable frequency, although not as stable as that of atomic clocks.\nA software clock in a computer is derived from that computer’s hardware\nclock. In particular, the hardware clock is assumed to cause an interrupt f\ntimes per second. When this timer goes off, the interrupt handler adds 1 to a\ncounter that keeps track of the number of ticks (interrupts) since some agreed-\nupon time in the past. This counter acts as a software clock C, resonating at\nfrequency F.\nWhen the UTC time is t, denote by Cp(t) the value of the software clock\non machine p. The goal of clock synchronization algorithms is to keep the\ndeviation between the respective clocks of any two machines in a distributed\nsystem, within a specified bound, known as the precision π:\n∀t, ∀p, q : |Cp(t) −Cq(t)| ≤π\nNote that precision refers to the deviation of clocks only between machines\nthat are part of a distributed system. When considering an external reference\npoint, like UTC, we speak of accuracy, aiming to keep it bound to a value α:\n∀t, ∀p : |Cp(t) −t| ≤α\nThe whole idea of clock synchronization is that we keep clocks precise, referred\nto as internal synchronization or accurate, known as external synchronization.\nA set of clocks that are accurate within bound α, will be precise within bound\nπ = 2α. However, being precise does not allow us to conclude anything about\nthe accuracy of clocks.\nIn a perfect world, we would have Cp(t) = t for all p and all t, and\nthus α = π = 0. Unfortunately, hardware clocks, and thus also software\nclocks, are subject to clock drift: because their frequency is not perfect and\naffected by external sources such as temperature, clocks on different machines\nwill gradually start showing different values for time. This is known as\nthe clock drift rate: the difference per unit of time from a perfect reference\nclock. A typical quartz-based hardware clock has a clock drift rate of some\n10−6 seconds per second, or approximately 31.5 seconds per year. Computer\nhardware clocks exist that have much lower drift rates.\nThe specifications of a hardware clock include its maximum clock drift\nrate ρ. If F(t) denotes the actual oscillator frequency of the hardware clock at\ntime t and F its ideal (constant) frequency, then a hardware clock is living up\nto its specifications if\n∀t : (1 −ρ) ≤F(t)\nF\n≤(1 + ρ)\nBy using hardware interrupts we are directly coupling a software clock to the\nhardware clock, and thus also its clock drift rate. In particular, we have that\nCp(t) = 1\nF\nZ t\n0 F(t)dt, and thus: dCp(t)\ndt\n= F(t)\nF\nDS 4.01\n \n\n\n5.1. CLOCK SYNCHRONIZATION\n255\nwhich brings us to our goal, namely keeping the software clock drift rate also\nbounded to ρ:\n∀t : 1 −ρ ≤dCp(t)\ndt\n≤1 + ρ\nSlow, perfect, and fast clocks are shown in Figure 5.4.\nFigure 5.4: The relation between clock time and UTC when clocks tick at\ndifferent rates.\nIf two clocks are drifting from UTC in the opposite direction, at a time\n∆t after they were synchronized, they may be as much as 2ρ · ∆t apart. If\nthe system designers want to guarantee a precision π, that is, that no two\nclocks ever differ by more than π seconds, clocks must be resynchronized\n(in software) at least every π/(2ρ) seconds. The various algorithms differ in\nprecisely how this resynchronization is done.\nNetwork Time Protocol\nA common approach in many protocols, and originally proposed by Cristian\n[1989], is to let clients contact a timeserver. The latter can accurately provide\nthe current time, for example because it is equipped with a UTC receiver\nor an accurate clock. The problem, of course, is that when contacting the\nserver, message delays will have outdated the reported time. The trick is to\nfind a good estimation for these delays. Consider the situation sketched in\nFigure 5.5.\nIn this case, A will send a request to B, timestamped with value T1. B,\nin turn, will record the time of receipt T2 (taken from its own local clock),\nand returns a response timestamped with value T3, and piggybacking the\npreviously recorded value T2. Finally, A records the time of the response’s\narrival, T4. Let us assume that the propagation delays from A to B is roughly\nthe same as B to A, meaning that δTreq = T2 −T1 ≈T4 −T3 = δTres. In that\n \nDS 4.01\n\n\n256\nCHAPTER 5. COORDINATION\nFigure 5.5: Getting the current time from a time server.\ncase, A can estimate its offset relative to B as\nθ = T3 + (T2 −T1) + (T4 −T3)\n2\n−T4 = (T2 −T1) + (T3 −T4)\n2\nOf course, time is not allowed to run backward. If A’s clock is fast, θ < 0,\nmeaning that A should, in principle, set its clock backward. This is not allowed\nas it could cause serious problems, such as an object file compiled just after\nthe clock change having a time earlier than the source which was modified\njust before the clock change.\nSuch a change must be introduced gradually. One way is as follows.\nSuppose that the timer is set to generate 100 interrupts per second. Normally,\neach interrupt would add 10 msec to the time. When slowing down, the\ninterrupt routine adds only 9 msec each time until the correction has been\nmade. Similarly, the clock can be advanced gradually by adding 11 msec at\neach interrupt instead of jumping it forward all at once.\nIn the case of the Network Time Protocol (NTP), this protocol is set up\npairwise between servers. In other words, B will also probe A for its current\ntime. The offset θ is computed as given above, along with the estimation δ for\nthe delay:\nδ = (T4 −T1) −(T3 −T2)\n2\nEight pairs of (θ, δ) values are buffered, finally taking the minimal value\nfound for δ as the best estimation for the delay between the two servers, and\nsubsequently the associated value θ as the most reliable estimation of the\noffset.\nApplying NTP symmetrically should, in principle, also let B adjust its\nclock to that of A. However, if B’s clock is known to be more accurate, then\nsuch an adjustment would be foolish. To solve this problem, NTP divides\nservers into strata. A server with a reference clock such as a UTC receiver or\nan atomic clock, is known to be a stratum-1 server (the clock itself is said to\noperate at stratum 0). When A contacts B, it will adjust only its time if its own\nstratum level is higher than that of B. Moreover, after the synchronization, A’s\nDS 4.01\n \n\n\n5.1. CLOCK SYNCHRONIZATION\n257\nstratum level will become one higher than that of B. In other words, if B is a\nstratum-k server, then A will become a stratum-(k + 1) server if its original\nstratum level was already larger than k. Due to the symmetry of NTP, if A’s\nstratum level was lower than that of B, B will adjust itself to A.\nThere are many important features about NTP, of which many relate to\nidentifying and masking errors, but also security attacks (see, e.g., Malhotra\net al. [2016]). Many security issues, such as also described by Levesque and\nTipper [2016], can be dealt with by establishing a secure channel between a\ntime server and its client. NTP was originally described in [Mills, 1992] and is\nknown to achieve (worldwide) accuracy in the range of 1–50 msec. A detailed\ndescription of NTP can be found in [Mills, 2011].\nClock synchronization in wireless networks\nAn important advantage of more traditional distributed systems is that we can\neasily and efficiently deploy timeservers. Moreover, most machines can contact\neach other, allowing for a relatively simple dissemination of information.\nThese assumptions are no longer valid in many wireless networks, notably\nsensor networks. Nodes are resource constrained, and multihop routing\nis expensive. In addition, it is often important to optimize algorithms for\nenergy consumption. These and other observations have led to the design\nof very different clock synchronization algorithms for wireless networks. In\nthe following, we consider one specific solution. Sivrikaya and Yener [2004]\nprovide a brief overview of other solutions. An extensive survey can be found\nin [Sundararaman et al., 2005].\nReference broadcast synchronization (RBS) is a clock synchronization\nprotocol that is quite different from other proposals [Elson et al., 2002]. First,\nthe protocol does not assume that there is a single node with an accurate\naccount of the actual time available. Instead of aiming to provide all nodes\nUTC time, it aims at merely internally synchronizing the clocks. Second,\nthe solutions we have discussed so far are designed to bring the sender and\nreceiver into sync, essentially following a two-way protocol. RBS deviates\nfrom this pattern by letting only the receivers synchronize, keeping the sender\nout of the loop.\nIn RBS, a sender broadcasts a reference message that allows its receivers\nto adjust their clocks. A key observation is that in a sensor network the\ntime to propagate a signal to other nodes is roughly constant, provided no\nmulti-hop routing is assumed. Propagation time in this case is measured from\nthe moment that a message leaves the network interface of the sender. As a\nconsequence, two important sources of variation in message transfer no longer\nplay a role in estimating delays: the time spent to construct a message, and\nthe time spent to access the network. This principle is shown in Figure 5.6.\nNote that in protocols such as NTP, a timestamp is added to the message\nbefore it is passed on to the network interface. Furthermore, as wireless\n \nDS 4.01\n\n\n258\nCHAPTER 5. COORDINATION\nFigure 5.6: The usual critical path and the one used in RBS in determining\nnetwork delays.\nnetworks are based on a contention protocol, there is generally no saying how\nlong it will take before a message can actually be transmitted. These factors\nof nondeterminism are eliminated in RBS. What remains is the delivery time\nat the receiver, but this time varies considerably less than the network-access\ntime.\nThe idea underlying RBS is simple: when a node broadcasts a reference\nmessage m, each node p simply records the time Tp,m that it received m. Note\nthat Tp,m is read from p’s local clock. Ignoring clock skew, two nodes p and\nq can exchange each other’s delivery times to estimate their mutual, relative\noffset:\nOffset[p, q] = ∑M\nk=1(Tp,k −Tq,k)\nM\nwhere M is the total number of reference messages sent. This information is\nimportant: node p will know the value of q’s clock relative to its own value.\nMoreover, if it simply stores these offsets, there is no need to adjust its own\nclock, which saves energy.\nUnfortunately, clocks can drift apart. The effect is that simply computing\nthe average offset as done above will not work: the last values sent are\nsimply less accurate than the first ones.\nMoreover, as time goes by, the\noffset will presumably increase. Elson et al. [2002] use a simple algorithm to\ncompensate for this: instead of computing an average, they apply standard\nlinear regression to compute the offset as a function:\nOffset[p, q](t) = αt + β\nThe constants α and β are computed from the pairs (Tp,k, Tq,k). This new form\nallows a much more accurate computation of q’s current clock value by node\np, and vice versa.\nDS 4.01\n \n\n\n5.1. CLOCK SYNCHRONIZATION\n259\nNote 5.2 (More information: How important is an accurate account of time?)\nSo why is time such a big deal for distributed systems? As we shall discuss in\nthe remainder of this chapter, reaching consensus on a global ordering of events\nis what we really want, and this can be achieved without any notion of global\nabsolute time. However, as will become clear, alternative methods for distributed\ncoordination do not come easy.\nLife would be much simpler if processes in a distributed system could time-\nstamp their events with infinite precision. Although infinite precision is asking\ntoo much, we can come practically close. Researchers at Google were confronted\nwith the fact that their customers would really like to make use of a globally\ndistributed database that supported transactions. Such a database would need\nto serve massive numbers of clients, rendering the use of, for example, a central\ntransaction processing monitor as we discussed in Section 1.3.2, infeasible. Instead,\nfor their Spanner system, Google decided to implement a true-time service, called\nTrueTime [Corbett et al., 2013]. This service provides three operations:\nOperation\nResult\nTT.now()\nA time interval [Tlwb, Tupb] with Tlwb < Tupb\nTT.after(t)\nTrue if timestamp t has definitely passed\nTT.before(t)\nTrue if timestamp t has definitely not arrived\nThe most important aspect is that Tlwb and Tupb are guaranteed bounds. Of\ncourse, if ϵ = Tupb −Tlwb is large, say 1 hour, then implementing the service\nis relatively easy. Impressively enough, ϵ = 6ms. To achieve this accuracy, the\nTrueTime service makes use of time-master machines of which there are several\nper data center. Time-slave daemons run on every machine in a data center\nand query multiple time masters, including ones from other data centers, very\nsimilar to what we described for NTP. Many time masters are equipped with\naccurate GPS receivers, while many others are independently equipped with\natomic clocks. The result is a collection of time sources with a high degree of\nmutual independence (which is important for reasons of fault tolerance). Using\na version of an algorithm developed by Marzullo and Owicki [1983], outliers\nare kept out of the computations. Meanwhile, the performance of TrueTime is\ncontinuously monitored and “bad” time machines are (manually) removed to give\nat least very high guarantees for the accuracy of the TrueTime service.\nWith a guaranteed accuracy of 6 milliseconds, building a transactional system\nbecomes much easier: transactions can actually be timestamped, even by different\nservers, with the restriction that timestamping may need to be delayed for ϵ\ntime units. More precisely, to know for sure that a transaction has committed,\nreading the resulting data may impose a wait for ϵ units. This is achieved by\npessimistically assigning a timestamp to a transaction that writes data to the\nglobal database and making sure that clients never see any changes before the\nassigned timestamp (which is relatively easy to implement).\nThere are many details to this approach, which can be found in [Corbett\net al., 2013]. As we are still dealing with a time interval, taking more traditional\n \nDS 4.01\n\n\n260\nCHAPTER 5. COORDINATION\nordering mechanisms into account it is possible to improve results, as explained\nby Demirbas and Kulkarni [2013].\n5.2\nLogical clocks\nClock synchronization is naturally related to time, although it may not be\nnecessary to have an accurate account of the real time: it may be sufficient that\nevery node in a distributed system agrees on a current time. We can go one\nstep further. For running make it is adequate that two nodes agree that input.o\nis outdated by a new version of input.c, for example. In this case, keeping\ntrack of each other’s events (such as a producing a new version of input.c) is\nwhat matters. For these algorithms, it is conventional to speak of the clocks as\nlogical clocks.\nIn a seminal paper, Lamport [1978] showed that although clock synchro-\nnization is possible, it need not be absolute. If two processes do not interact,\nit is not necessary that their clocks be synchronized because the lack of syn-\nchronization would not be observable and thus could not cause problems.\nFurthermore, he pointed out that what usually matters is not that all processes\nagree on exactly what time it is, but rather that they agree on the order in which\nevents occur. In the make example, what counts is whether input.c is older or\nnewer than input.o, not their respective absolute creation times.\n5.2.1\nLamport’s logical clocks\nTo synchronize logical clocks, Lamport defined a relation called happens-\nbefore. The expression a →b is read “event a happens before event b” and\nmeans that all processes agree that first event a occurs, then afterward, event b\noccurs. The happens-before relation can be observed directly in two situations:\n1. If a and b are events in the same process, and a occurs before b, then\na →b is true.\n2. If a is the event of a message being sent by one process, and b is the\nevent of the message being received by another process, then a →b is\nalso true. A message cannot be received before it is sent, or even at the\nsame time it is sent, since it takes a finite, nonzero amount of time to\narrive.\nHappens-before is a transitive relation, so if a →b and b →c, then a →c.\nIf two events, x and y, happen in different processes that do not exchange\nmessages (not even indirectly via third parties), then x →y is not true, but\nneither is y →x. These events are said to be concurrent, which simply means\nDS 4.01\n \n\n\n5.2. LOGICAL CLOCKS\n261\nthat nothing can be said (or need be said) about when the events happened or\nwhich event happened first.\nWhat we need is a way of measuring a notion of time such that for every\nevent, a, we can assign it a time value C(a) on which all processes agree.\nThese time values must have the property that if a →b, then C(a) < C(b).\nTo rephrase the conditions we stated earlier, if a and b are two events within\nthe same process and a occurs before b, then C(a) < C(b). Similarly, if a\nis the sending of a message by one process and b is the reception of that\nmessage by another process, then C(a) and C(b) must be assigned in such a\nway that everyone agrees on the values of C(a) and C(b) with C(a) < C(b).\nIn addition, the clock time, C, must always go forward (increasing), never\nbackward (decreasing). Corrections to time can be made by adding a positive\nvalue, never by subtracting one.\nNow let us look at the algorithm Lamport proposed for assigning times\nto events. Consider the three processes depicted in Figure 5.7. The processes\nrun on different machines, each with its own clock. For the sake of argument,\nwe assume that a clock is implemented as a software counter: the counter\nis incremented by a specific value every T time units. However, the value\nby which a clock is incremented differs per process. The clock in process\nP1 is incremented by 6 units, 8 units in process P2, and 10 units in process\nP3, respectively. (Below, we explain that Lamport clocks are, in fact, event\ncounters, which explains why their value may differ between processes.)\n(a)\n(b)\nFigure 5.7: (a) Three processes, each with its own (logical) clock. The clocks\nrun at different rates. (b) Lamport’s algorithm corrects their values.\nAt time 6, process P1 sends message m1 to process P2. How long this\nmessage takes to arrive depends on whose clock you believe. In any event,\nthe clock in process P2 reads 16 when it arrives. If the message carries the\nstarting time, 6, in it, process P2 will conclude that it took 10 ticks to make the\njourney. This value is certainly possible. According to this reasoning, message\nm2 from P2 to P3 takes 16 ticks, again a plausible value.\n \nDS 4.01\n\n\n262\nCHAPTER 5. COORDINATION\nNow consider message m3. It leaves process P3 at 60 and arrives at P2 at\n56. Similarly, message m4 from P2 to P1 leaves at 64 and arrives at 54. These\nvalues are clearly impossible. It is this situation that must be prevented.\nLamport’s solution follows directly from the happens-before relation. Since\nm3 left at 60, it must arrive at 61 or later. Therefore, each message carries\nthe sending time according to the sender’s clock. When a message arrives\nand the receiver’s clock shows a value before the time the message was sent,\nthe receiver fast forwards its clock to be one more than the sending time. In\nFigure 5.7, we see that m3 now arrives at 61. Similarly, m4 arrives at 70.\nLet us formulate this procedure more precisely. At this point, it is impor-\ntant to distinguish three different layers of software, as we already encountered\nin Section 2.2: the network, a middleware layer, and an application layer, as\nshown in Figure 5.8. What follows is typically part of the middleware layer.\nFigure 5.8: The positioning of Lamport’s logical clocks in distributed systems.\nTo implement Lamport’s logical clocks, each process Pi maintains a local\ncounter Ci. These counters are updated according to the following steps [Ray-\nnal and Singhal, 1996]:\n1. Before executing an event (i.e., sending a message over the network,\ndelivering a message to an application, or some other internal event), Pi\nincrements Ci: Ci ←Ci + 1.\n2. When process Pi sends a message m to process Pj, it sets m’s timestamp\nts(m) equal to Ci after having executed the previous step.\n3. Upon the receipt of a message m, process Pj adjusts its own local counter\nas Cj ←max{Cj, ts(m)} after which it then executes the first step and\ndelivers the message to the application.\nIn some situations, an additional requirement is desirable: no two events ever\noccur at the same time. To achieve this goal, we also use the unique process\nidentifier to break ties and use tuples instead of only the counter’s values. For\nexample, an event at time 40 at process Pi will be timestamped as ⟨40, i⟩. If\nwe also have an event ⟨40, j⟩and i < j, then ⟨40, i⟩< ⟨40, j⟩.\nDS 4.01\n \n",
      "page_number": 265
    },
    {
      "number": 28,
      "title": "Segment 28 (pages 274-282)",
      "start_page": 274,
      "end_page": 282,
      "detection_method": "topic_boundary",
      "content": "5.2. LOGICAL CLOCKS\n263\nNote that by assigning the event time C(a) ←Ci(a) if a happened at\nprocess Pi at time Ci(a), we have a distributed implementation of the global\ntime value we were initially seeking for; we have thus constructed a logical\nclock.\nExample: Totally ordered multicasting\nAs an application of Lamport’s logical clocks, consider the situation in which\na database has been replicated across several sites. For example, to improve\nquery performance, a bank may place copies of an account database in two\ndifferent cities, say New York and San Francisco. A query is always forwarded\nto the nearest copy. The price for a fast response to a query is partly paid in\nhigher update costs because each update operation must be carried out at\neach replica.\nIn fact, there is a more stringent requirement regarding updates. Assume\na customer in San Francisco wants to add $100 to her account, which cur-\nrently contains $1,000. At the same time, a bank employee in New York\ninitiates an update by which the customer’s account is to be increased with\n1 percent interest. Both updates should be carried out at both copies of the\ndatabase. However, due to communication delays in the underlying network,\nthe updates may arrive in the order as shown in Figure 5.9.\nFigure 5.9: Updating a replicated database and leaving it in an inconsistent\nstate.\nThe customer’s update operation is performed in San Francisco before the\ninterest update. In contrast, the copy of the account in the New York replica is\nfirst updated with the 1 percent interest, and after that with the $100 deposit.\nConsequently, the San Francisco database will record a total amount of $1,111,\nwhereas the New York database records $1,110.\nThe problem that we are faced with is that the two update operations\nshould have been performed in the same order at each copy. Although it\nmakes a difference whether the deposit is processed before the interest update\nor the other way around, which order is followed is not essential from a\nconsistency perspective. The important issue is that both copies should be the\n \nDS 4.01\n\n\n264\nCHAPTER 5. COORDINATION\nsame after the updates have taken place. In general, situations such as these\nrequire a totally ordered multicast, that is, a multicast operation by which all\nmessages are delivered in the same order to each receiver. Lamport’s logical\nclocks can be used to implement totally ordered multicasts in a completely\ndistributed fashion.\nConsider a group of processes multicasting messages to each other. Each\nmessage is always timestamped with the current (logical) time of its sender.\nWhen a message is multicasted, it is conceptually also sent to the sender. In\naddition, we assume that messages from the same sender are received in the\norder they were sent, and that no messages are lost.\nWhen a process receives a message, it is put into a local queue, ordered\naccording to its timestamp. The receiver multicasts an acknowledgment to the\nother processes. Note that if we follow Lamport’s algorithm for adjusting local\nclocks, the timestamp of the received message is lower than the timestamp\nof the acknowledgment. The interesting aspect of this approach is that all\nprocesses will eventually have the same copy of the local queue (provided no\nmessages are removed).\nA process can deliver a queued message to the application it is running\nonly when that message is at the head of the queue and has been acknowl-\nedged by each other process. At that point, the message is removed from the\nqueue and handed over to the application; the associated acknowledgments\ncan simply be removed. Because each process has the same copy of the queue,\nall messages are delivered in the same order everywhere. In other words, we\nhave established totally ordered multicasting. We leave it as an exercise to\nthe reader to figure out that it is not strictly necessary that each multicast\nmessage has been explicitly acknowledged. It is sufficient that a process reacts\nto an incoming message, either by returning an acknowledgment or sending\nits own multicast message.\nTotally ordered multicasting is an important vehicle for replicated services,\nwhere the replicas are kept consistent by letting them execute the same\noperations in the same order everywhere. As the replicas essentially follow\nthe same transitions in the same finite state machine, it is also known as state\nmachine replication [Schneider, 1990].\nNote 5.3 (Advanced: Using Lamport clocks to achieve mutual exclusion)\nTo further illustrate the usage of Lamport’s clocks, let us see how we can use the\nprevious algorithm for totally ordered multicasting to establish access to what\nis commonly known as a critical region: a section of code that can be executed\nby at most one process at a time. This algorithm is very similar to the one for\nmulticasting, as essentially all processes need to agree on the order by which\nprocesses are allowed to enter their critical region.\nFigure 5.10(a) shows the code that each process executes when requesting,\nreleasing, or allowing access to the critical region (again, omitting details). Each\nDS 4.01\n \n\n\n5.2. LOGICAL CLOCKS\n265\nprocess maintains a request queue as well as a logical clock. To enter the critical\nregion, a call to requestToEnter is made, which results in inserting an ENTER\nmessage with timestamp (clock,procID) into the local queue and sending that\nmessage to the other processes. The operation cleanupQ essentially sorts the\nqueue. We return to it shortly.\n1 class Process:\n2\ndef __init__(self, chanID, procID, procIDSet):\n3\nself.chan.join(procID)\n4\nself.procID\n= int(procID)\n5\nself.otherProcs.remove(self.procID)\n6\nself.queue\n= []\n# The request queue\n7\nself.clock\n= 0\n# The current logical clock\n8\n9\ndef requestToEnter(self):\n10\nself.clock = self.clock + 1\n# Increment clock value\n11\nself.queue.append((self.clock, self.procID, ENTER)) # Append request to q\n12\nself.cleanupQ()\n# Sort the queue\n13\nself.chan.sendTo(self.otherProcs, (self.clock, self.procID, ENTER)) # Send request\n14\n15\ndef ackToEnter(self, requester):\n16\nself.clock = self.clock + 1\n# Increment clock value\n17\nself.chan.sendTo(requester, (self.clock, self.procID, ACK)) # Permit other\n18\n19\ndef release(self):\n20\ntmp = [r for r in self.queue[1:] if r[2] == ENTER]\n# Remove all ACKs\n21\nself.queue = tmp\n# and copy to new queue\n22\nself.clock = self.clock + 1\n# Increment clock value\n23\nself.chan.sendTo(self.otherProcs, (self.clock, self.procID, RELEASE)) # Release\n24\n25\ndef allowedToEnter(self):\n26\ncommProcs = set([req[1] for req in self.queue[1:]]) # See who has sent a message\n27\nreturn (self.queue[0][1] == self.procID and len(self.otherProcs) == len(commProcs))\nFigure 5.10: (a) Using Lamport’s logical clocks for mutual exclusion.\nWhen a process P receives an ENTER message from process Q, it can simply\nacknowledge that Q can enter its critical region, even if P wants to do so as well.\nIn the latter case, P’s ENTER request will have a lower logical timestamp than the\nACK message sent by P to Q, meaning that P’s request will have been inserted into\nQ’s queue before P’s ACK message.\nFinally, when a process leaves its critical region, it calls release. It cleans up\nits local queue by removing all received ACK messages, leaving only the ENTER\nrequests from other processes. It then multicasts a RELEASE message.\nTo actually enter a critical region, a process will have to repeatedly call\nallowedToEnter and when returned False, will have to block on a next incoming\nmessage. The operation allowedToEnter does what is to be expected: it checks\nif the calling process’s ENTER message is at the head of the queue, and sees if all\nother processes have sent a message as well. The latter is encoded through the set\n \nDS 4.01\n\n\n266\nCHAPTER 5. COORDINATION\ncommProcs, which contains the procIDs of all processes having sent a message by\ninspecting all messages in the local queue from the second position and onwards.\n1\ndef receive(self):\n2\nmsg = self.chan.recvFrom(self.otherProcs)[1]\n# Pick up any message\n3\nself.clock = max(self.clock, msg[0])\n# Adjust clock value...\n4\nself.clock = self.clock + 1\n# ...and increment\n5\nif msg[2] == ENTER:\n6\nself.queue.append(msg)\n# Append an ENTER request\n7\nself.ackToEnter(msg[1])\n# and unconditionally allow\n8\nelif msg[2] == ACK:\n9\nself.queue.append(msg)\n# Append a received ACK\n10\nelif msg[2] == RELEASE:\n11\ndel(self.queue[0])\n# Just remove first message\n12\nself.cleanupQ()\n# And sort and cleanup\nFigure 5.10: (b) Using Lamport’s logical clocks for mutual exclusion:\nhandling incoming requests.\nWhat to do when a message is received is shown in Figure 5.10(b). First,\nthe local clock is adjusted according to the rules for Lamport’s logical clocks\nexplained above. When receiving an ENTER or ALLOW message, that message is\nsimply inserted into the queue. An entry request is always acknowledged, as we\njust explained. When a RELEASE message is received, the original ENTER request is\nremoved. Note that this request is at the head of the queue. Thereafter, the queue\nis cleaned up again.\nAt this point, note that if we would clean up the queue by only sorting it,\nwe may get into trouble. Suppose that processes P and Q want to enter their\nrespective critical regions at roughly the same time, but that P is allowed to go\nfirst based on logical-clock values. P may find Q’s request in its queue, along\nwith ENTER or ALLOW messages from other processes. If its own request is at the\nhead of its queue, P will proceed and enter its critical region. However, Q will\nalso send an ALLOW message to P as well, in addition to its original ENTER message.\nThat ALLOW message may arrive after P had already entered its critical region, but\nbefore ENTER messages from other processes. When Q eventually enters, and leaves\nits critical region, Q’s RELEASE message would result in removing Q’s original\nENTER message, but not the ALLOW message it had previously sent to P. By now,\nthat message is at the head of P’s queue, effectively blocking the entrance to the\ncritical region of other processes in P’s queue. Cleaning up the queue thus also\ninvolves removing old ALLOW messages.\n5.2.2\nVector clocks\nLamport’s logical clocks lead to a situation where all events in a distributed\nsystem are totally ordered with the property that if event a happened before\nevent b, then a will also be positioned in that ordering before b, that is,\nC(a) < C(b).\nDS 4.01\n \n\n\n5.2. LOGICAL CLOCKS\n267\nHowever, with Lamport clocks, nothing can be said about the relationship\nbetween two events a and b by merely comparing their time values C(a)\nand C(b), respectively. In other words, if C(a) < C(b), then this does not\nnecessarily imply that a indeed happened before b. Something more is needed\nfor that.\nTo explain, consider the messages as sent by the three processes shown\nin Figure 5.11. Denote by Tsnd(mi) the logical time at which message mi was\nsent, and likewise, by Trcv(mi) the time of its receipt. By construction, we\nknow that for each message Tsnd(mi) < Trcv(mi). But what can we conclude\nin general from Trcv(mi) < Tsnd(mj) for different messages mi and mj?\nFigure 5.11: Concurrent message transmission using logical clocks.\nIn the case for which mi = m1 and mj = m3, we know that these values\ncorrespond to events that took place at process P2, meaning that m3 was\nindeed sent after the receipt of message m1.\nThis may indicate that the\nsending of message m3 depended on what was received through message m1.\nAt the same time, we also know that Trcv(m1) < Tsnd(m2). However, as far as\nwe can tell from Figure 5.11, the sending of m2 has nothing to do with the\nreceipt of m1.\nThe problem is that Lamport clocks do not capture causality. In practice,\ncausality is captured by means of vector clocks. To better understand where\nthese come from, we follow the explanation as given by Baquero and Preguica\n[2016]. In fact, tracking causality is simple if we assign each event a unique\nname such as the combination of a process ID and a locally incrementing\ncounter: pk is the kth event that happened at process P. The problem then\nboils down to keeping track of causal histories. For example, if two local\nevents happened at process P, then the causal history H(p2) of event p2 is\n{p1, p2}.\nNow assume that process P sends a message to process Q (which is an\nevent at P and thus recorded as pk for some k), and that at the time of arrival\n(an event for Q), the most recent causal history of Q was {q1}. To track\n \nDS 4.01\n\n\n268\nCHAPTER 5. COORDINATION\ncausality, P also sends its most recent causal history (assume it was {p1, p2},\nextended with p3 expressing the sending of the message). Upon arrival, Q\nrecords the event (q2), and merges the two causal histories into a new one:\n{p1, p2, p3, q1, q2}.\nChecking whether an event p causally precedes an event q can be done\nby checking whether H(p) ⊂H(q) (i.e., it should be a proper subset). In fact,\nwith our notation, it even suffices to check whether p ∈H(q), assuming that\nq is always the last local event in H(q).\nThe problem with causal histories, is that their representation is not very\nefficient. However, there is no need to keep track of all successive events from\nthe same process: the last one will do. If we subsequently assign an index to\neach process, we can represent a causal history as a vector, in which the jth\nentry represents the number of events that happened at process Pj. Causality\ncan then be captured by means of vector clocks, which are constructed by\nletting each process Pi maintain a vector VCi with the following two properties:\n1. VCi[i] is the number of events that have occurred so far at Pi. In other\nwords, VCi[i] is the local logical clock at process Pi.\n2. If VCi[j] = k then Pi knows that k events have occurred at Pj. It is thus\nPi’s knowledge of the local time at Pj.\nThe first property is maintained by incrementing VCi[i] at the occurrence of\neach new event that happens at process Pi. The second property is maintained\nby piggybacking vectors along with messages that are sent. In particular, the\nfollowing steps are performed:\n1. Before executing an event (i.e., sending a message over the network,\ndelivering a message to an application, or some other internal event), Pi\nexecutes VCi[i] ←VCi[i] + 1. This is equivalent to recording a new event\nthat happened at Pi.\n2. When process Pi sends a message m to Pj, it sets m’s (vector) timestamp\nts(m) equal to VCi after having executed the previous step (i.e., it also\nrecords the sending of the message as an event that takes place at Pi).\n3. Upon the receipt of a message m, process Pj adjusts its own vector by\nsetting VCj[k] ←max{VCj[k], ts(m)[k]} for each k (which is equivalent\nto merging causal histories), after which it executes the first step (record-\ning the receipt of the message) and then delivers the message to the\napplication.\nNote that if an event a has timestamp ts(a), then ts(a)[i] −1 denotes the\nnumber of events processed at Pi that causally precede a. As a consequence,\nwhen Pj receives a message m from Pi with timestamp ts(m), it knows about\nthe number of events that have occurred at Pi that causally preceded the\nDS 4.01\n \n\n\n5.2. LOGICAL CLOCKS\n269\nsending of m. More important, however, is that Pj is also told how many\nevents at other processes have taken place, known to Pi, before Pi sent message\nm. In other words, timestamp ts(m) tells the receiver how many events in\nother processes have preceded the sending of m, and on which m may causally\ndepend.\nTo see what this means, consider Figure 5.12 which shows three processes.\nIn Figure 5.12(a), P2 sends a message m1 at logical time VC2 = (0, 1, 0) to\nprocess P1. Message m1 thus receives timestamp ts(m1) = (0, 1, 0). Upon\nits receipt, P1 adjusts its logical time to VC1 ←(1, 1, 0) and delivers it. Mes-\nsage m2 is sent by P1 to P3 with timestamp ts(m2) = (2, 1, 0). Before P1\nsends another message, m3, an event happens at P1, eventually leading to\ntimestamping m3 with value (4, 1, 0). After receiving m3, process P2 sends\nmessage m4 to P3, with timestamp ts(m4) = (4, 3, 0).\n(a)\n(b)\nFigure 5.12: Capturing potential causality when exchanging messages.\nNow consider the situation shown in Figure 5.12(b). Here, we have delayed\nsending message m2 until after message m3 has been sent, and after the\nevent had taken place. It is not difficult to see that ts(m2) = (4, 1, 0), while\nts(m4) = (2, 3, 0). Compared to Figure 5.12(a), we have the following situation:\n \nDS 4.01\n\n\n270\nCHAPTER 5. COORDINATION\nSituation\nts(m2)\nts(m4)\nts(m2)\nts(m2)\nConclusion\n<\n>\nts(m4)\nts(m4)\nFigure 5.12(a)\n(2, 1, 0)\n(4, 3, 0)\nYes\nNo\nm2 may causally precede m4\nFigure 5.12(b)\n(4, 1, 0)\n(2, 3, 0)\nNo\nNo\nm2 and m4 may conflict\nWe use the notation ts(a) < ts(b) if and only if for all k, ts(a)[k] ≤ts(b)[k]\nand there is at least one index k′ for which ts(a)[k′] < ts(b)[k′]. Thus, by using\nvector clocks, process P3 can detect whether m4 may be causally dependent\non m2, or whether there may be a potential conflict. Note, by the way, that\nwithout knowing the actual information contained in messages, it is not\npossible to state with certainty that there is indeed a causal relationship, or\nperhaps a conflict.\nNote 5.4 (Advanced: Enforcing causal communication)\nUsing vector clocks, it is now possible to ensure that a message is delivered only\nif all messages that may have causally preceded it have been received as well. To\nenable such a scheme, we will assume that messages are multicast within a group\nof processes. Note that this causally ordered multicasting is weaker than totally\nordered multicasting. Specifically, if two messages are not in any way related to\neach other, we do not care in which order they are delivered to applications. They\nmay even be delivered in different order at different locations.\nFor enforcing causal message delivery, we assume that clocks are adjusted\nonly when sending and delivering messages (note, again, that messages are not\nadjusted when they are received by a process, but only when they are delivered\nto an application). In particular, only upon sending a message, will process Pi\nincrement VCi[i] by 1. Only when it delivers a message m with timestamp ts(m),\nwill it adjust VCi[k] to max{VCi[k], ts(m)[k]} for each k.\nNow suppose that Pj receives a message m from Pi with (vector) timestamp\nts(m). The delivery of the message to the application layer will then be delayed\nuntil the following two conditions are met:\n1. ts(m)[i] = VCj[i] + 1\n2. ts(m)[k] ≤VCj[k] for all k ̸= i\nThe first condition states that m is the next message that Pj was expecting from\nprocess Pi. The second condition states that Pj has delivered all the messages that\nhave been delivered by Pi when it sent message m. Note that there is no need for\nprocess Pj to delay the delivery of its own messages.\nAs an example, consider three processes P1, P2, and P3 as shown in Figure 5.13.\nAt local time (1, 0, 0), P1 multicasts message m to the other two processes. Note\nthat ts(m) = (1, 0, 0). Its receipt and subsequent delivery by P2, will bring the\nlogical clock at P2 to (1, 0, 0), effectively indicating that it has received one message\nfrom P1, has itself sent no message so far, and has not yet delivered a message\nfrom P3. P2 then decides to multicast m∗, at updated time (1, 1, 0), which arrives\nat P3 sooner than m.\nDS 4.01\n \n\n\n5.2. LOGICAL CLOCKS\n271\nFigure 5.13: Enforcing causal communication.\nWhen comparing the timestamp of m with its current time, which is (0, 0, 0),\nP3 concludes that it is still missing a message from P1 which P2 apparently had\ndelivered before sending m∗. P3 therefore, decides to postpone the delivery of m∗\n(and will also not adjust its local, logical clock). Later, after m has been received\nand delivered by P3, which brings its local clock to (1, 0, 0), P3 can deliver message\nm∗and also update its clock.\nA note on ordered message delivery\nSome middleware systems, notably ISIS\nand its successor Horus [Birman and van Renesse, 1994], provide support for\ntotally ordered and causally ordered (reliable) multicasting. There has been some\ncontroversy whether such support should be provided as part of the message-\ncommunication layer, or whether applications should handle ordering (see, e.g.,\nCheriton and Skeen [1993]; Birman [1994]). Matters have not been settled, but\nmore important is that the arguments still hold today.\nThere are two main problems with letting the middleware deal with message\nordering. First, because the middleware cannot tell what a message actually\ncontains, only potential causality is captured. For example, two messages from the\nsame sender that are completely independent will always be marked as causally\nrelated by the middleware layer. This approach is overly restrictive and may lead\nto efficiency problems.\nA second problem is that not all causality may be captured. Consider some\ndigital chat room. Suppose Alice posts a message. If she then phones Bob telling\nabout what she just wrote, Bob may post another message as a reaction without\nhaving seen Alice’s posting. In other words, there is a causality between Bob’s\nposting and that of Alice due to external communication. This causality is not\ncaptured by the chat room system.\nIn essence, ordering issues, like many other application-specific communi-\ncation issues, can be adequately solved by looking at the application for which\ncommunication is taking place. This is also known as the end-to-end principle in\nsystems design [Saltzer et al., 1984]. A drawback of having only application-level\nsolutions is that a developer is forced to concentrate on issues that do not immedi-\nately relate to the core functionality of the application. For example, ordering may\n \nDS 4.01\n",
      "page_number": 274
    },
    {
      "number": 29,
      "title": "Segment 29 (pages 283-291)",
      "start_page": 283,
      "end_page": 291,
      "detection_method": "topic_boundary",
      "content": "272\nCHAPTER 5. COORDINATION\nnot be the most important problem when developing a messaging system such\nas the one for a chat room. In that case, having an underlying communication\nlayer handle ordering may turn out to be convenient. We will come across the\nend-to-end argument several times.\n5.3\nMutual exclusion\nFundamental to distributed systems is the concurrency and collaboration\namong multiple processes. In many cases, this also means that processes\nwill need to simultaneously access the same resources. To prevent that such\nconcurrent accesses corrupt the resource, or make it inconsistent, solutions are\nneeded to grant mutual exclusive access by processes. In this section, we take\na look at some important and representative distributed algorithms that have\nbeen proposed. Surveys of distributed algorithms for mutual exclusion are\nprovided by Saxena and Rai [2003] and Velazquez [1993]. Various algorithms\nare also presented in [Kshemkalyani and Singhal, 2008].\n5.3.1\nOverview\nDistributed mutual exclusion algorithms can be classified into two different\ncategories. In token-based solutions mutual exclusion is achieved by passing\na special message between the processes, known as a token. There is only one\ntoken available, and who ever has that token is allowed to access the shared\nresource. When finished, the token is passed on to a next process. If a process\nhaving the token is not interested in accessing the resource, it passes it on.\nToken-based solutions have a few important properties. First, depending\non how the processes are organized, they can fairly easily ensure that every\nprocess will get a chance at accessing the resource. In other words, they pro-\nvide guarantees for safety by avoiding what is known as starvation. Second,\ndeadlocks by which several processes are indefinitely waiting for each other\nto proceed, can easily be avoided, contributing to their simplicity. The main\ndrawback of token-based solutions is a rather serious one: when the token\nis lost (e.g. because the process holding it crashed), an intricate distributed\nprocedure needs to be started to ensure that a new token is created, but above\nall, that it is also the only token.\nAs an alternative, many distributed mutual exclusion algorithms follow\na permission-based approach. In this case, a process wanting to access the\nresource first requires the permission from other processes. There are many\nways toward granting such permission and in the sections that follow we will\nconsider a few of them.\nDS 4.01\n \n\n\n5.3. MUTUAL EXCLUSION\n273\n5.3.2\nA centralized algorithm\nA straightforward way to achieve mutual exclusion in a distributed system is\nto simulate how it is done in a one-processor system. One process is elected\nas the coordinator. Whenever a process wants to access a shared resource, it\nsends a request message to the coordinator stating which resource it wants to\naccess and asking for permission. If no other process is currently accessing\nthat resource, the coordinator sends back a reply granting permission, as\nshown in Figure 5.14(a). When the reply arrives, the requester can go ahead.\n(a)\n(b)\n(c)\nFigure 5.14: (a) Process P1 asks for permission to access a shared resource. Per-\nmission is granted. (b) Process P2 asks permission to access the same resource,\nbut receives no reply. (c) When P1 releases the resource, the coordinator\nreplies to P2.\nNow suppose that another process, P2 in Figure 5.14(b) asks for permission\nto access the resource. The coordinator knows that a different process is\nalready at the resource, so it cannot grant permission. The exact method used\nto deny permission is system dependent. In Figure 5.14(b) the coordinator just\nrefrains from replying, thus blocking process P2, which is waiting for a reply.\nAlternatively, it could send a reply saying “permission denied.” Either way, it\nqueues the request from P2 for the time being and waits for more messages.\nWhen process P1 is finished with the resource, it sends a message to the\ncoordinator releasing its exclusive access, as shown in Figure 5.14(c). The\ncoordinator takes the first item off the queue of deferred requests and sends\nthat process a grant message. If the process was still blocked (i.e., this is\nthe first message to it), it unblocks and accesses the resource. If an explicit\nmessage has already been sent denying permission, the process will have to\npoll for incoming traffic or block later. Either way, when it sees the grant, it\ncan go ahead as well.\nIt is easy to see that the algorithm guarantees mutual exclusion: the\ncoordinator lets only one process at a time access the resource. It is also fair,\nsince requests are granted in the order in which they are received. No process\never waits forever (no starvation). The scheme is easy to implement, too, and\nrequires only three messages per use of resource (request, grant, release). Its\nsimplicity makes it an attractive solution for many practical situations.\n \nDS 4.01\n\n\n274\nCHAPTER 5. COORDINATION\nThe centralized approach also has shortcomings. The coordinator is a\nsingle point of failure, so if it crashes, the entire system may go down. If\nprocesses normally block after making a request, they cannot distinguish a\ndead coordinator from “permission denied” since in both cases no message\ncomes back. In addition, in a large system, a single coordinator can become a\nperformance bottleneck. Nevertheless, the benefits coming from its simplicity\noften outweigh the potential drawbacks. Moreover, distributed solutions are\nnot necessarily better, as we illustrate next.\n5.3.3\nA distributed algorithm\nUsing Lamport’s logical clocks, and inspired by Lamport’s original solution\nfor distributed mutual exclusion (which we discussed in Note 5.3), Ricart and\nAgrawala [1981] provided the following algorithm. Their solution requires a\ntotal ordering of all events in the system. That is, for any pair of events, such\nas messages, it must be unambiguous which one actually happened first.\nThe algorithm works as follows. When a process wants to access a shared\nresource, it builds a message containing the name of the resource, its process\nnumber, and the current (logical) time. It then sends the message to all other\nprocesses, conceptually including itself. The sending of messages is assumed\nto be reliable; that is, no message is lost.\nWhen a process receives a request message from another process, the\naction it takes depends on its own state regarding the resource named in the\nmessage. Three different cases have to be clearly distinguished:\n• If the receiver is not accessing the resource and does not want to access\nit, it sends back an OK message to the sender.\n• If the receiver already has access to the resource, it simply does not reply.\nInstead, it queues the request.\n• If the receiver wants to access the resource as well but has not yet done\nso, it compares the timestamp of the incoming message with the one\ncontained in the message that it has sent everyone. The lowest one wins.\nIf the incoming message has a lower timestamp, the receiver sends back\nan OK message. If its own message has a lower timestamp, the receiver\nqueues the incoming request and sends nothing.\nAfter sending out requests asking permission, a process sits back and waits\nuntil everyone else has given permission. As soon as all the permissions are\nin, it may go ahead. When it is finished, it sends OK messages to all processes\nin its queue and deletes them all from the queue. If there is no conflict, it\nclearly works. However, suppose that two processes try to access the resource\nsimultaneously, as shown in Figure 5.15(a).\nProcess P0 sends everyone a request with timestamp 8, while at the same\ntime, process P2 sends everyone a request with timestamp 12. P1 is not\nDS 4.01\n \n\n\n5.3. MUTUAL EXCLUSION\n275\n(a)\n(b)\n(c)\nFigure 5.15: (a) Two processes want to access a shared resource at the same\nmoment. (b) P0 has the lowest timestamp, so it wins. (c) When process P0 is\ndone, it sends an OK also, so P2 can now go ahead.\ninterested in the resource, so it sends OK to both senders. Processes P0 and\nP2 both see the conflict and compare timestamps. P2 sees that it has lost,\nso it grants permission to P0 by sending OK. Process P0 now queues the\nrequest from P2 for later processing and accesses the resource, as shown\nin Figure 5.15(b). When it is finished, it removes the request from P2 from\nits queue and sends an OK message to P2, allowing the latter to go ahead,\nas shown in Figure 5.15(c). The algorithm works because in the case of a\nconflict, the lowest timestamp wins and everyone agrees on the ordering of\nthe timestamps.\nWith this algorithm, mutual exclusion is guaranteed without deadlock or\nstarvation. If the total number of processes is N, then the number of messages\nthat a process needs to send and receive before it can enter its critical region\nis 2 · (N −1): N −1 request messages to all other processes, and subsequently\nN −1 OK messages, one from each other process. A critical region is a series\nof instructions to be executed by a process, which requires mutually exclusive\naccess.\nUnfortunately, this algorithm has N points of failure.\nIf any process\ncrashes, it will fail to respond to requests. This silence will be interpreted\n(incorrectly) as denial of permission, thus blocking all subsequent attempts by\nall processes to enter any of their respective critical regions. The algorithm can\nbe patched up as follows. When a request comes in, the receiver always sends\na reply, either granting or denying permission. Whenever either a request or a\nreply is lost, the sender times out and keeps trying until either a reply comes\nback or the sender concludes that the destination is dead. After a request is\ndenied, the sender should block, waiting for a subsequent OK message.\nAnother problem with this algorithm is that either a multicast commu-\nnication primitive must be used, or each process must maintain the group\nmembership list itself, including processes entering the group, leaving the\ngroup, and crashing. The method works best with small groups of processes\n \nDS 4.01\n\n\n276\nCHAPTER 5. COORDINATION\nthat never change their group memberships. Finally, note that all processes are\ninvolved in all decisions concerning accessing the shared resource, which may\nimpose a burden on processes running on resource-constrained machines.\nVarious minor improvements are possible to this algorithm. For example,\ngetting permission from everyone is overkill. All that is needed is a method to\nprevent two processes from accessing the resource at the same time. The algo-\nrithm can be modified to grant permission when it has collected permission\nfrom a simple majority of the other processes, rather than from all of them.\n5.3.4\nA token-ring algorithm\nAn entirely different approach to deterministically achieving mutual exclusion\nin a distributed system is illustrated in Figure 5.16. In software, we construct\nan overlay network in the form of a logical ring in which each process is\nassigned a position in the ring. All that matters is that each process knows\nwho is next in line after itself.\nFigure 5.16: An overlay network constructed as a logical ring with a token\ncirculating between its members.\nWhen the ring is initialized, process P0 is given a token.\nThe token\ncirculates around the ring. Assuming there are N processes, the token is\npassed from process Pk to process P(k+1) mod N in point-to-point messages.\nWhen a process acquires the token from its neighbor, it checks to see if it\nneeds to access the shared resource. If so, the process goes ahead, does all the\nwork it needs to, and releases the resources. After it has finished, it passes\nthe token along the ring. It is not permitted to enter the resource immediately\nagain using the same token.\nIf a process is handed the token by its neighbor and is not interested in the\nresource, it just passes the token along. As a consequence, when no processes\nneed the resource, the token just circulates around the ring.\nThe correctness of this algorithm is easy to see. Only one process has the\ntoken at any instant, so only one process can actually get to the resource. Since\nthe token circulates among the processes in a well-defined order, starvation\ncannot occur. Once a process decides it wants to have access to the resource,\nat worst it will have to wait for every other process to use the resource.\nThis algorithm has its own problems. If the token is ever lost, for example\nbecause its holder crashes or due to a lost message containing the token, it\nmust be regenerated. In fact, detecting that it is lost may be difficult, since the\nDS 4.01\n \n\n\n5.3. MUTUAL EXCLUSION\n277\namount of time between successive appearances of the token on the network\nis unbounded. The fact that the token has not been spotted for an hour does\nnot mean that it has been lost; somebody may still be using it.\nThe algorithm also runs into trouble if a process crashes, but recovery is\nrelatively easy. If we require a process receiving the token to acknowledge\nreceipt, a dead process will be detected when its neighbor tries to give it\nthe token and fails. At that point, the dead process can be removed from\nthe group, and the token holder can throw the token over the head of the\ndead process to the next member down the line, or the one after that, if\nnecessary. Of course, doing so requires that everyone maintains the current\nring configuration.\n5.3.5\nA decentralized algorithm\nLet us take a look at a fully decentralized solution. Lin et al. [2004] propose to\nuse a voting algorithm. Each resource is assumed to be replicated N times.\nEvery replica has its own coordinator for controlling the access by concurrent\nprocesses.\nHowever, whenever a process wants to access the resource, it will simply\nneed to get a majority vote from m > N/2 coordinators. We assume that\nwhen a coordinator does not give permission to access a resource (which it\nwill do when it had granted permission to another process), it will tell the\nrequester.\nThe assumption is that when a coordinator crashes, it recovers quickly\nbut will have forgotten any vote it gave before it crashed. Another way of\nviewing this is that a coordinator resets itself at arbitrary moments. The risk\nthat we are taking is that a reset will make the coordinator forget that it had\npreviously granted permission to some process to access the resource. As a\nconsequence, it may incorrectly grant this permission again to another process\nafter its recovery.\nLet p = ∆t/T be the probability that a coordinator resets during a time\ninterval ∆t, while having a lifetime of T. The probability P[k] that k out of m\ncoordinators reset during the same interval is then\nP[k] =\n\u0012m\nk\n\u0013\npk(1 −p)m−k\nIf f coordinators reset, then the correctness of the voting mechanism will be\nviolated when we have more than m other coordinators think it is okay to\nallocate the resource, that is, when N −(m −f ) ≥m, or, in other words, when\nf ≥2m −N. The probability that such a violation occurs is ∑m\nk=2m−N P[k]. To\ngive an impression of what this could mean, Figure 5.17 shows the probability\nof violating correctness for different values of N, m, and p. Note that we\ncompute p by considering the number of seconds per hour that a coordinator\nresets, and also taking this value to be the average time needed to access\n \nDS 4.01\n\n\n278\nCHAPTER 5. COORDINATION\na resource. Our values for p are considered to be (very) conservative. The\nconclusion is that, in general, the probability of violating correctness can be\nso low that it can be neglected in comparison to other types of failure.\nN\nm\np\nViolation\n8\n5\n3 sec/hour\n< 10−5\n8\n6\n3 sec/hour\n< 10−11\n16\n9\n3 sec/hour\n< 10−4\n16\n12\n3 sec/hour\n< 10−21\n32\n17\n3 sec/hour\n< 10−4\n32\n24\n3 sec/hour\n< 10−43\nN\nm\np\nViolation\n8\n5\n30 sec/hour\n< 10−3\n8\n6\n30 sec/hour\n< 10−7\n16\n9\n30 sec/hour\n< 10−2\n16\n12\n30 sec/hour\n< 10−13\n32\n17\n30 sec/hour\n< 10−2\n32\n24\n30 sec/hour\n< 10−27\nFigure 5.17: Violation probabilities for various parameter values of decentral-\nized mutual exclusion.\nTo implement this scheme, we can use a system in which a resource is\nreplicated N times. Assume that the resource is known under its unique\nname rname. We can then assume that the ith replica is named rnamei which\nis then used to compute a unique key using a known hash function. As a\nconsequence, every process can generate the N keys given a resource’s name,\nand subsequently look up each node responsible for a replica (and controlling\naccess to that replica) using some commonly used naming system.\nIf permission to access the resource is denied (i.e., a process gets less\nthan m votes), it is assumed that it will back off for some randomly chosen\ntime, and make a next attempt later. The problem with this scheme is that if\nmany nodes want to access the same resource, it turns out that the utilization\nrapidly drops. In that case, there are so many nodes competing to get access\nthat eventually no one can get enough votes, leaving the resource unused. A\nsolution to solve this problem can be found in [Lin et al., 2004].\nNote 5.5 (More information: A comparison of the mutual-exclusion algorithms)\nA brief comparison of the mutual exclusion algorithms we have looked at is\ninstructive. In Figure 5.18 we have listed the algorithms and two performance\nproperties: the number of messages required for a process to access and release a\nshared resource, and the delay before access can occur (assuming messages are\npassed sequentially over a network).\nIn the following, we assume only point-to-point messages (or, equivalently,\ncount a multicast to N processes as N messages).\n• The centralized algorithm is simplest and also most efficient. It requires\nonly three messages to enter and leave a critical region: a request, a grant\nto enter, and a release to exit.\nDS 4.01\n \n\n\n5.3. MUTUAL EXCLUSION\n279\n• The distributed algorithm requires N −1 request messages, one to each of\nthe other processes, and an additional N −1 grant messages, for a total of\n2(N −1).\n• With the token ring algorithm, the number is variable. If every process\nconstantly wants to enter a critical region, then each token pass will result\nin one entry and exit, for an average of one message per critical region\nentered. At the other extreme, the token may sometimes circulate for hours\nwithout anyone being interested in it. In this case, the number of messages\nper entry into a critical region is unbounded.\n• The decentralized case requires sending N messages to coordinators, and\nanother N responses. If it does not get a majority, it will have to release\n(at most) N/2 votes. If it did get enough votes, it will have to send an\nadditional N release messages later on. A process may need to go through\nk ≥1 attempts.\nMessages per\nDelay before entry\nAlgorithm\nentry/exit\n(in message times)\nCentralized\n3\n2\nDistributed\n2(N −1)\n2(N −1)\nToken ring\n1, . . . , ∞\n0, . . . , N −1\nDecentralized\n2kN + (k −1)N/2 + N, k = 1, 2, . . .\n2kN + (k −1)N/2\nFigure 5.18: A comparison of four mutual exclusion algorithms.\nThe delay from the moment a process needs to enter a critical region until its\nactual entry also varies. For a worst-case analysis, we assume that messages are\nsent one after the other (i.e., there are never two or more messages in transit at\nthe same time), and that message transfer time is roughly the same everywhere.\nDelay can then be expressed in message transfer time units, or simply MTTU.\nUnder these assumptions, when the time using a resource is short, the dominant\nfactor in the delay is determined by the total number of messages sent through\nthe system before access can be granted. When resources are used for a long\nperiod of time, the dominant factor is waiting for everyone else to take their turn.\nIn Figure 5.18 we show the former case.\n• It takes only two MTTUs to enter a critical region in the centralized case,\ncaused by a request message and the subsequent grant message sent by the\ncoordinator.\n• The distributed algorithm requires sending N −1 request messages, and\nreceiving another N −1 grant messages, adding up to 2(N −1) MTTUs.\n• For the token ring, the delay varies from 0 MTTU (in case the token had\njust arrived) to N −1 (for when the token had just departed).\n• In the case of decentralized, the delay is dependent on the number of times\na process needed to return the (minority of) votes. With having to go\nthrough k ≥1 attempts, a process may see 2kN + (k −1)N/2 MTTUs.\n \nDS 4.01\n\n\n280\nCHAPTER 5. COORDINATION\nVirtually all algorithms suffer badly in the event of crashes. Special measures\nand additional complexity must be introduced to avoid having a crash bring down\nthe entire system. It is somewhat ironic that distributed algorithms are generally\nmore sensitive to crashes than centralized ones. In this sense, it should not come\nas a surprise that, indeed, centralized mutual exclusion is widely applied: it\nis simple to understand the behavior, and relatively easy to increase the fault\ntolerance of the centralized server.\n5.3.6\nExample: Simple locking with ZooKeeper\nFor many practical reasons, mutual exclusion in distributed systems is often\ndone with a centralized coordinator, not in the least because the behavior of\nthese solutions is much easier to understand than many other noncentralized\nversions. Let us briefly look at a system that is designed for coordination tasks\nin distributed systems, and which is by now also widely deployed. ZooKeeper\nwas developed to provide facilities for supporting various coordination tasks,\nincluding locking, leader election, monitoring, to name but just a few. It\nhas been designed for scalability and fault tolerance. For our purposes now,\nwe concentrate only on a relatively simple setup, namely to support locking\nthrough a single server. ZooKeeper’s fault tolerance aspects are discussed in\nChapter 8. The system was first described in [Hunt et al., 2010], to be later\nfollowed up with a practical description by Junqueira and Reed [2014].\nZooKeeper basics\nAs mentioned, ZooKeeper is designed to facilitate different coordination\nfunctions. An important design principle is its lack of blocking primitives:\nclients send messages to the ZooKeeper service and, in principle, are always\nimmediately returned a response. In the case of locking, this means that a\nclient will, for example, be informed whether it was able to grab a lock. If the\nlock could not be acquired, a new attempt will be necessary, as we discuss\nshortly.\nTo facilitate a range of coordination functions, ZooKeeper maintains a\nnamespace, organized as a tree. Operations on the tree are simple: creating\nand deleting nodes, as well as reading and updating the data contained in a\nnode (if any). A partial update of a node is not possible: all the node’s data\nwill be overwritten in the case of an update. In addition, a client can check\nwith the server whether a node exists. At this point, it should be become clear\nhow one could implement a locking service in ZooKeeper: to acquire a lock,\nsimply let a process create a special node, say lock, but have that operation\nfail if the node already exists. Releasing a lock is done by merely deleting the\nnode lock. We return to some important details below.\nDS 4.01\n \n",
      "page_number": 283
    },
    {
      "number": 30,
      "title": "Segment 30 (pages 292-301)",
      "start_page": 292,
      "end_page": 301,
      "detection_method": "topic_boundary",
      "content": "5.3. MUTUAL EXCLUSION\n281\nThere are two types of nodes in ZooKeeper. Persistent nodes need to\nbe created and deleted explicitly. In contrast, ephemeral nodes are created\nexplicitly, but are automatically removed if the connection with the creating\nclient closes (perhaps because of a failure), or expires. Of course, an ephemeral\nnode can also be explicitly deleted.\nAn important consequence of not supporting blocking operations, is that a\nclient will have to regularly check the status of the namespace: have nodes\nbeen added or removed, have nodes in the namespace been changed? However,\npolling is generally not considered to be very efficient. To this end, ZooKeeper\nsupports a notification mechanism by which a client can subscribe to a change\nin a node or a branch in the tree. When a change happens, the client receives\na message.\nThere are a few things that need to be considered to make this all work.\nFirst, suppose a client subscribes to changes at a specific node after having\nread the state of that node. If the node is updated twice in a row, we want\nto prevent that the client sees the second update before being notified, as the\nnotification dealt with changes to the previous state, i.e., the state after the first\nupdate took place.\nSecond, it should be clear that there can be a lot of concurrency among\ncompeting clients. As we shall discuss in detail in Chapter 7, problematic are,\nin particular, the situations in which one client C1 reads data to subsequently\ndecide to update that data. If, between the read and intended update another\nclient C2 performs an update, client C1 may now request an update based on\nout-of-date information. Such intended updates can be prevented by using\nversion numbers, as shown in Figure 5.19.\nFigure 5.19: Preventing updates based on out-of-date information through\nversions (based on [Junqueira and Reed, 2014].\nWe use the notation W(n, k)a to denote the request to write the value a to\nnode n, under the assumption that its current version is k. R(n, k) denotes that\nthe current version of node n is k. The operation R(n) tells that a client wants\nto read the current value of node n, and R(n, k)a means that the value a from\n \nDS 4.01\n\n\n282\nCHAPTER 5. COORDINATION\nnode n is returned with its current version k. In Figure 5.19 we see that client\nC1 writes value a to node n, assuming its version is 1. If no write has ever\ntaken place, this assumption is correct. The ZooKeeper service (ZK) returns\nthe new version number, namely 2.\nMeanwhile, client C2 issues a read request for node n and is returned the\npreviously written value a having version number 2. C2 decides to update\nn, assuming its current version is still 2, by means of the write operation\nW(n, 2)b. ZooKeeper accepts the write, and returns the new version number\n3. This concurrent update places C1 in the position that its intended write\noperation W(n, 2)c will fail: ZooKeeper states that its assumption about the\nversion number is incorrect. The best what C1 could do is read n again to see\nif it still wants to update the node.\nClearly, each client may need to try several times before an update actually\ntakes place. This may not always seem so efficient, yet this approach ensures\nthat data maintained by ZooKeeper is at least consistent with what clients\nexpect it to be. As mentioned, we will return to consistency in much more\ndetail in Chapter 7.\nA ZooKeeper locking protocol\nImplementing a lock using ZooKeeper is now fairly straightforward. ZooKeeper\nuses the same path notation for nodes as in Unix file systems. That means\nthat we can create a node /lock at the root of the tree. The existence of that\nnode means that a client has successfully acquired the lock. Releasing the lock\nis simply done by deleting node /lock.\nAny client wanting to create the same node will receive the message that\nthe node already exists and thus that the operation failed. Capturing such\nexceptions is at the core of blocking a client until /lock is removed. When the\nnode already exists, the client will request ZooKeeper to send a notification\nwhen the node is deleted. Until that moment, the client simply waits (i.e.,\nlocally blocks) until notified, after which it tries to create the node again.\nThere are many subtleties to deal with. For example, a decent locking\nmechanism should allow a client to bail out after several attempts. Likewise,\nif a client who has created /lock crashes before deleting it again, we need to\nmake sure that ZooKeeper will delete the node. Furthermore, we will find\nourselves in an unfortunate race when the following happens:\n1. A client C1 creates a node /lock.\n2. A client C2 wants to acquire the lock but is notified that the associated\nnode already exists.\n3. Before C2 subscribes to a notification, C1 releases the lock, i.e., deletes\n/lock.\n4. Client C2 subscribes to changes to /lock and blocks locally.\nDS 4.01\n \n\n\n5.4. ELECTION ALGORITHMS\n283\nThis is analogous to the situation we described before: C2 should be\nable to subscribe to changes based on the existence of /lock. In other words,\nwhen performing the fourth step, C2 should be immediately notified that the\nsituation has already changed since it last visited the tree. These subtleties are\nhandled by ZooKeeper.\n5.4\nElection algorithms\nMany distributed algorithms require one process to act as coordinator, initiator,\nor otherwise perform some special role. In general, it does not matter which\nprocess takes on this special responsibility, but one of them has to do it. In\nthis section, we will look at algorithms for electing a coordinator. We will\noften also speak of a leader election.\nIf all processes are the same, with no distinguishing characteristics, there is\nno way to select one of them to be special. Consequently, we will assume that\neach process P has a unique identifier id(P). In general, election algorithms\nattempt to locate the process with the highest identifier and designate it as\ncoordinator. The algorithms differ in the way they locate the coordinator.\nFurthermore, we also assume that every process knows the identifier of\nevery other process. In other words, each process has complete knowledge of\nthe process group in which a coordinator must be elected. What the processes\ndo not know is which ones are currently up and which ones are currently\ndown. The goal of an election algorithm is to ensure that when an election\nstarts, it concludes with all processes agreeing on whom the new coordinator\nis to be. There are many algorithms and variations, of which several important\nones are discussed in the textbooks by Tel [2000] and Lynch [1996].\n5.4.1\nThe bully algorithm\nA well-known solution for electing a coordinator is the bully algorithm de-\nvised by Garcia-Molina [1982]. In the following, we consider N processes\n{P0, . . . , PN−1} and let id(Pk) = k. When any process notices that the coordi-\nnator is no longer responding to requests, it initiates an election. A process,\nPk, holds an election as follows:\n1. Pk sends an ELECTION message to all processes with higher identifiers:\nPk+1, Pk+2, . . . , PN−1.\n2. If no one responds, Pk wins the election and becomes coordinator.\n3. If one of the higher-ups answers, it takes over and Pk’s job is done.\nAt any moment, a process can get an ELECTION message from one of its\nlower-numbered colleagues. When such a message arrives, the receiver sends\nan OK message back to the sender to indicate that it is alive and will take\n \nDS 4.01\n\n\n284\nCHAPTER 5. COORDINATION\n(a)\n(b)\n(c)\n(d)\n(e)\nFigure 5.20: The bully election algorithm. (a) Process 4 holds an election. (b)\nProcesses 5 and 6 respond, telling 4 to stop. (c) Now 5 and 6 each hold an\nelection. (d) Process 6 tells 5 to stop. (e) Process 6 wins and tells everyone.\nover. The receiver then holds an election, unless it is already holding one.\nEventually, all processes give up but one, and that one is the new coordinator.\nIt announces its victory by sending all processes a message telling them that\nstarting immediately it is the new coordinator.\nIf a process that was previously down comes back up, it holds an election.\nIf it happens to be the highest-numbered process currently running, it will\nwin the election and take over the coordinator’s job. Thus the biggest guy in\ntown always wins, hence the name “bully algorithm.”\nIn Figure 5.20 we see an example of how the bully algorithm works. The\ngroup consists of eight processes, with identifiers numbered from 0 to 7.\nDS 4.01\n \n\n\n5.4. ELECTION ALGORITHMS\n285\nPreviously, process P7 was the coordinator, but it has just crashed. Process\nP4 is the first one to notice this, so it sends ELECTION messages to all the\nprocesses higher than it, namely P5, P6, and P7, as shown in Figure 5.20(a).\nProcesses P5 and P6 both respond with OK, as shown in Figure 5.20(b). Upon\ngetting the first of these responses, P4 knows that its job is over, knowing that\neither one of P5 or P6 will take over and become coordinator. Process P4 just\nsits back and waits to see who the winner will be (although at this point it\ncan make a pretty good guess).\nIn Figure 5.20(c) both P5 and P6 hold elections, each one sending messages\nonly to those processes with identifiers higher than itself. In Figure 5.20(d),\nP6 tells P5 that it will take over. At this point, P6 knows that P7 is dead and\nthat it (P6) is the winner. If there is state information to be collected from disk\nor elsewhere to pick up where the old coordinator left off, P6 must now do\nwhat is needed. When it is ready to take over, it announces the takeover by\nsending a COORDINATOR message to all running processes. When P4 gets\nthis message, it can now continue with the operation it was trying to do when\nit discovered that P7 was dead, but using P6 as the coordinator this time. In\nthis way, the failure of P7 is handled, and the work can continue.\nIf process P7 is ever restarted, it will send all the others a COORDINATOR\nmessage and bully them into submission.\n5.4.2\nA ring algorithm\nConsider the following election algorithm that is based on the use of a (logical)\nring. Unlike some ring algorithms, this one does not use a token. We assume\nthat each process knows who its successor is. When any process notices that\nthe coordinator is not functioning, it builds an ELECTION message containing\nits own process identifier and sends the message to its successor. If the\nsuccessor is down, the sender skips over the successor and goes to the next\nmember along the ring, or the one after that, until a running process is located.\nAt each step along the way, the sender adds its own identifier to the list in the\nmessage, effectively making itself a candidate to be elected as coordinator.\nEventually, the message gets back to the process that started it all. That pro-\ncess recognizes this event when it receives an incoming message containing its\nown identifier. At that point, the message type is changed to COORDINATOR\nand circulated once again, this time to inform everyone else who the coordi-\nnator is (the list member with the highest identifier) and who the members of\nthe new ring are. When this message has circulated once, it is removed and\neveryone goes back to work.\nIn Figure 5.21 we see what happens if two processes, P3 and P6, discover\nsimultaneously that the previous coordinator, process P7, has crashed. Each\nof these builds an ELECTION message and each of them starts circulating its\nmessage, independent of the other one. Eventually, both messages will go all\nthe way around, and both P3 and P6 will convert them into COORDINATOR\n \nDS 4.01\n\n\n286\nCHAPTER 5. COORDINATION\nFigure 5.21: Election algorithm using a ring. The solid line shows the election\nmessages initiated by P6; the dashed one those by P3.\nmessages, with exactly the same members and in the same order. When both\nhave gone around again, both will be removed. It does no harm to have extra\nmessages circulating; at worst it consumes a little bandwidth, but this is not\nconsidered wasteful.\n5.4.3\nExample: Leader election in ZooKeeper\nLet us look at a practical example of how leader election takes place in a\ndistributed system. As mentioned, ZooKeeper is logically centralized coordi-\nnation service. In Section 5.3.6 we considered a simple setup with just a single\nZooKeeper server. In practice, we see that ZooKeeper maintains a (relatively\nsmall) set of servers, forming what is called an ensemble. For a client, an\nensemble appears as just a single server. For ZooKeeper, this ensemble is\nalso coordinated by a single server, called the leader. The other servers are\ncalled followers and essentially act as up-to-date standbys for whenever the\nleader malfunctions. In that case, one of the followers will be elected as the\nnew leader. From the client’s perspective, a malfunctioning leader is mostly\ninvisible: as soon as one of the standbys has taken over the role of leader,\neverything proceeds as if nothing happened. We return to many details of\nsuch fault-tolerant behavior in Chapter 8, but for now, let us dive a bit deeper\ninto how the server in a ZooKeeper ensemble choose their leader.\nIt is important to note that a leader-election algorithm within a ZooKeeper\nensemble is fundamentally different from devising a leader-election algorithm\nby means of ZooKeeper. The first deals with the implementation of ZooKeeper\nas a coordination service; the second with using ZooKeeper as a coordination\nservice, perhaps as part of the implementation of a larger distributed system.\nWhich leader-election algorithm is used within a ZooKeeper ensemble is\nnot that important, as long as, in the end, a single leader is chosen and enough\nfollowers are running as up-to-date standbys. Enough in this case means that\na majority of the servers that form an ensemble are operating properly. For\nnow, we will simply assume this to be the case.\nDS 4.01\n \n\n\n5.4. ELECTION ALGORITHMS\n287\nThe default election algorithm in an implementation of ZooKeeper is\na simple version of bullying and works as follows [Junqueira and Reed,\n2014]. Each server s in the ensemble has an identifier id(s), as well as a\nmonotonically increasing counter tx(s) of the latest transaction it handled.\nThink of a transaction as a series of operations the server has executed, such\nas the combination of adding a node and registering that it should send a client\na notification when anything changes. Typically, the leader of the ensemble\nwill have performed the transaction on its own, locally stored, namespace and\ninstructed its followers to do so as well on their respective local copy of that\nnamespace.\nWhen a follower s believes something is wrong with the leader (e.g., it\nsuspects that the leader crashed), it sends out an ELECTION message to all\nother servers, along with the pair (voteID,voteTX). For this first message,\nit sets voteID to id(s) and voteTX to tx(s). During an election, each server s\nmaintains two variables. The first, leader(s), records the identifier of the server\nthat s believes may turn out to be the final leader, and is initialized to id(s).\nThe second, lastTX(s) is what s has learned to be the most recent transaction,\ninitially being its own value, namely id(s).\nWhen a server s∗receives (voteID,voteTX), it proceeds as follows:\n• If lastTX(s∗) < voteTX, then s∗just received more up-to-date informa-\ntion on the most recent transaction. In that case, it sets\n– leader(s∗) ←voteID\n– lastTX(s∗) ←voteTX\n• If lastTX(s∗) = voteTX and leader(s∗) < voteID, then s∗knows as much\nabout the most recent transaction as what it was just sent, but its per-\nspective on which server will be the next leader needs to be update:\n– leader(s∗) ←voteID\nEach time a server s∗receives a (voteID,voteTX) message, it may update its\nown information on whom it suspects to be the next leader. If s∗believes it\nshould be the next leader, and has not sent out a message stating this, it will\nbroadcast the pair (id(s∗),tx(s∗)). Under the assumption that communication is\nreliable, this broadcast alone should do the job. Typically, s∗will send out a\nmessage stating that it is the leader, when either initiating an election, or when\nreceiving a message with a lower voteTX than its own tx(s∗), or receiving a\nmessage with an up-to-date value for voteTX, but with a smaller voteID than\nid(s∗). Once a leader has been elected, all servers will make sure that they\nsynchronize on the latest transaction.\n \nDS 4.01\n\n\n288\nCHAPTER 5. COORDINATION\nNote 5.6 (Advanced: ZooKeeper leader election in Python)\n1 class Process:\n2\ndef __init__(self, chanID, procID, procIDSet, initTX):\n3\nself.txID\n= initTX\n# Your own most recent transaction\n4\nself.leader\n= self.procID\n# Who you believe may become leader\n5\nself.lastTX\n= self.txID\n# What is the most recent transaction\n6\nself.noleader\n= False\n# Are you still in the race for leader?\n7\n8\ndef receive(self):\n9\nwhile True:\n10\nmsg\n= self.chan.recvFrom(self.otherProcs)\n11\nsender, payload = msg[0], msg[1]\n12\nif payload[0] == ELECTION: # A process started an election\n13\nvoteID, voteTX = payload[1], payload[2]\n14\n15\nif self.lastTX < voteTX: # You’re not up to date on most recent transaction\n16\nself.leader = voteID\n# Record the suspected leader\n17\nself.lastTX = voteTX\n# As well as the likely most recent transaction\n18\n19\nelif (self.lastTX == voteTX) and (self.leader < voteID): # Wrong leader\n20\nself.leader = voteID\n# Update your suspected leader\n21\n22\nelif (self.procID > voteID) and (self.txID >= voteTX) and (not self.noleader):\n23\n# At this point, you may very well be the new leader (having a sufficiently\n24\n# high process identifier as well as perhaps the most recent transaction).\n25\n# No one has told you so far that you could not be leader. Tell the others.\n26\nself.chan.sendTo(self.otherProcs, (LEADER, self.procID, self.txID))\n27\n28\nif payload[0] == LEADER:\n29\n# Check if the sender should indeed be leader\n30\nif ((self.lastTX < payload[2]) or\n31\n((self.lastTX == payload[2]) and (self.leader <= payload[1]))):\n32\n# The sender is more up-to-date than you, or is equally up-to-date but\n33\n# has a higher process identifier. Declare yourself follower.\n34\nself.chan.sendTo(sender, (FOLLOWER, self.procID))\n35\nelse:\n36\n# Sender is wrong: you have information that the sender based its decision\n37\n# on outdated information\n38\nself.chan.sendTo(sender, (NOLEADER))\nFigure 5.22: A simplified version of ZooKeeper’s leader election for an\nensemble of servers.\nComing to the conclusion that one of the servers in a ZooKeeper ensemble is\nnow indeed the new leader, can be a bit tricky. One way is to let a server come to\nthe conclusion that it may never become a leader in the current round, in which\ncase it tells the alleged leader that it will become a follower. This means that as\nsoon as a server has collected enough followers, it can promote itself to leader.\nIn ZooKeeper, this happens when a server has a majority of the other servers in\nthe ensemble as followers. If we take an oversimplified approach by assuming\nDS 4.01\n \n\n\n5.4. ELECTION ALGORITHMS\n289\nthat messages are never lost, nor do servers crash during an election, a leader is\nelected when all other servers are its followers. The code is shown in Figure 5.22\n(again, omitting many details).\n5.4.4\nExample: Leader election in Raft\nAs another example of a leader-election algorithm that is in practical use, let\nus take a look at Raft [Ongaro and Ousterhout, 2014]. We will return to Raft\nin Chapter 8 when discussing consensus algorithms and focus here only on\nhow it selects a leader.\nRaft operates in a setting in which a handful of known replicated servers\n(typically five) collaborate by ensuring that each server executes the same set\nof operations, and all in the same order. To this end, one of the servers is\nelected as leader to tell the others what the exact order is of those operations.\nThe protocol assumes that messages may be lost and that servers may crash.\nEach server can be in one of three states: follower, candidate, or leader.\nFurthermore, the protocol operates in terms, where during each term there\nis exactly one leader, although it could have perhaps crashed. Each term is\nnumbered, starting with 0. The leader is assumed to regularly send out a\nmessage, either containing information on an operation that should be carried\nout, or otherwise a heartbeat message to tell the other servers that their leader\nis still up and running.\nEach server initially starts in the follower state (that is, there is initially no\nleader). Adopting the terminology from Howard et al. [2015], after a follower\ntimeout, a following server concludes that the leader may have crashed (which,\nby the way, may be a false conclusion). As a result, it enters the candidate state\nand starts an election, volunteering to be the new leader. An election starts\nwith a broadcast to all other servers, along with increasing the term number\nby 1. At that point, three situations may happen.\n1. A candidate may receive a message from an alleged leader. If that server\nindicates it is operating in the same term as the candidate server, the\nlatter will become follower again for the current term.\n2. When a following server receives an election message for the first time\n(in a new term), it simply votes for the candidate and ignores any other\nelection messages (for that new term). Therefore, a candidate server can\nalso receive a vote. If it has a majority of votes (i.e., more than half of the\nservers, including itself), it promotes itself as leader for the new term.\n3. As long as there is no alleged leader, or not enough votes have been\nreceived, the candidate server waits until a candidate timeout happens.\nAt that point, the candidate server will simply start a new election (and\nagain, for a next term).\n \nDS 4.01\n\n\n290\nCHAPTER 5. COORDINATION\nOf course, if all servers enter the candidate state, we bear the risk of\nindefinitely not being able to cast enough votes for a single server. A simple\nsolution is to slightly vary the follower timeout and candidate timeout on a\nper-server basis. The result is that, generally, there is only a single candidate\nfor the new term, allowing each other server to vote for that candidate and\nbecome a follower. As soon as a server becomes leader, it will send out a\nheartbeat message to the rest.\n5.4.5\nElections in large-scale systems\nMany leader-election algorithms apply to only relatively small distributed\nsystems. In such cases, the various nodes exchange information among each\nother, often through several rounds, to eventually collectively decide on the\nnew leader. In Chapter 8, we shall see that this collective decision-making can\ntake place even when a fraction of the participating nodes exhibits noncon-\nforming behavior, as in the case of security attacks or faults. The problem\nof electing a leader becomes rather nasty when there are potentially many\nprocesses to choose from. This is the case, for example, in permissionless\nblockchains.\nProof of work\nA relatively simple, yet by now heavily criticized solution, is to have the\ncandidates run a computational race, referred to as proof of work. Running\nsuch a race, which is done by solving a computational puzzle, should be\nknown to be possible, yet difficult. The first process solving the puzzle, wins,\nand may proceed as leader to append a block of validated transactions to the\nexisting blockchain.\nThe type of problem used for blockchains is based on what is known as\nhashing. As introduced in Section 1.2.5, a hash function takes as input a\n(possibly large) data set and produces a fixed-length string of bits, typically\nof length 1024 or 2048, called a hash. A cryptographically well-defined hash\nfunction has several important properties [Ferguson and Schneier, 2003]:\n1. Computing the hash of a given data set is relatively easy, i.e., it does not\nrequire significant computational efforts.\n2. However, given a specific hash, it is computationally very difficult to\nfind a corresponding data set with the same associated hash.\n3. With very high probability, any two different input data sets will lead\nto two seemingly unrelated, different hashes. Even if the two data sets\nare minimally different, their associated hashes will most likely be very\ndifferent.\nDS 4.01\n \n",
      "page_number": 292
    },
    {
      "number": 31,
      "title": "Segment 31 (pages 302-310)",
      "start_page": 302,
      "end_page": 310,
      "detection_method": "topic_boundary",
      "content": "5.4. ELECTION ALGORITHMS\n291\nThe third property is used to securely protect blocks of validated transac-\ntions against adversarial modifications: even the change of a single bit will\nnot go unnoticed. Combined with the second property, it becomes virtually\nimpossible to modify a block meaningfully, such that the modified block’s\nhash is the same as the original block’s hash.\nTo set up a race between validators, each validator computes the hash of\nits block of validated transactions. Note again that a hash is technically just\na fixed-length string of bits. We denote the computed hash over a block a\ndigest. The validator is then required to find an additional bit string, called\na nonce, such that the hash computed over the digest and the nonce when\ntaken together produces a bit string with a predetermined number of leading\nzeroes. Given property 2 of hash functions, we know that it is computationally\nvery difficult to find a data set that matches a given hash. In our case, we have\nas input the hash of the block of validated transactions (i.e., the digest), and\nare now required to find a bit string (i.e., nonce) that, taken together with the\ndigest, has an associated hash that starts with a given number of zeroes. This\nis computationally very difficult. In essence, each validator simply needs to\ngo through a most likely lengthy trial-and-error process of generating a nonce\nand checking whether that nonce, combined with the digest, will lead to the\nrequired result.\nBy controlling how many leading zeroes that the outcome should have,\nwe essentially control the difficulty of the computations. For example, with\njust 1 leading zero, there is a 50% chance that a generated nonce will lead to\nthe desired result. Demanding 2 leading zeroes reduces this probability to\n25%, 3 leading zeroes to 12.5%, and so forth. With 64 leading zeroes, which\nis common practice, the chance that an arbitrarily chosen nonce will do the\ntrick is a mere 0.0000 0000 0000 0000 05% (that is, 17 zeroes after the decimal\ndot). Put differently, a validator will on average need to check about 18 billion\nbillion nonces to find one that leads to the desired result. Using dedicated\nsupercomputers, this takes about 10 minutes. It would take an average laptop\nabout 100 years.\nWith increasing hardware capacity, the time it takes to find a nonce will\ndrop. For this reason, the difficulty of finding a nonce is deliberately con-\ntrolled in such a way that a race will have an expected duration. For Bitcoin\nsystems, a popular application of blockchains, the duration is approximately\n10 minutes. If races tend to become shorter, then the difficulty for finding a\nnonce is increased. If races turn out to be too lengthy, the difficulty is lowered.\nAdjusting the difficulty is done by regularly computing the average time it\ntook to run the race over the last 2000 blocks of transactions, or so. The\nadjustment of the difficulty is done by all validators using the same globally\nknown method, and is therefore done in a completely decentralized manner.\nThere is a reason for properly setting the expected duration of a race.\nSuppose we have very lengthy races. This means that validators would have\n \nDS 4.01\n\n\n292\nCHAPTER 5. COORDINATION\nto do a lot of work to find a proper nonce. The good part of the story is that\nthe chance that two validators find a nonce at more or less the same time is\nrelatively small (although this depends, of course, on how many validators\nparticipate in the race). As a consequence, the chance that there will be only\none winner who will have enough time to successfully broadcast its victory to\nall others is relatively high.\nThe downside of the story, however, is that with lengthy races, the transac-\ntion processing capacity may be too low. Suppose that we have a race duration\nof 10 minutes and an average number of 2500 transactions per block (which\nare common values for Bitcoin). This means that, effectively, the system can\nhandle about 4 transactions per second. Increasing the number of transactions\nper block is an obvious path to follow, yet even such improvements still lead\nto low rates in comparison to many centralized solutions with a fixed, trusted\nthird party validating transactions.\nOn the other hand, assume we would have very short-lasting races. In that\ncase, two validators may more easily concurrently find a proper nonce, both\nwill declare victory, append their block to the blockchain (which was already\nmassively replicated), and before other validators had the chance to stop their\nwork, we would find ourselves with different copies of the same blockchain.\nThere are different ways to correct for these concurrent versions of what is\nsupposed to be a single blockchain, but obviously, it comes at the price of\ninvalidating potentially many transactions, and rolling back to a valid state.\nOf course, the advantage of a smaller race duration is that, in principle, we\ncan handle more transactions per time unit.\nProof of stake\nAs a reaction to the waste of computational resources found in proof-of-work\nsystems, much effort has been spent on alternative leader-election algorithms\nfor permissionless blockchains. An important class is formed by so-called\nproof-of-stake systems. Leaving out many details, as well as the many variants\nof such systems, the basic principle is as follows. An easy-to-read overview of\nthe principles of proof-of-stake leader election is provided by Nguyen et al.\n[2019].\nFirst, we need to make the assumption that each transaction as recorded\nin a blockchain has one or more associated tokens. Moreover, at each moment,\neach token has exactly one owner. This is typically the case with mone-\ntary transactions, where a token is associated with a digital coin. Because\nblockchains are fully readable by any participant, we may also assume that\ntokens may be passed between owners, and that, indeed, copying a token and\nassociating it with multiple owners cannot go undetected. How this can be\nrealized is discussed in Section 9.4.3. Each token will, therefore, have only a\nsingle owner. Second, we make also make the (realistic) assumption that for\nDS 4.01\n \n\n\n5.4. ELECTION ALGORITHMS\n293\na given blockchain, there are a total of N tokens, which may vary over time\ndepending on the application for which a blockchain is being used.\nA simple leader-election process for blockchains then consists of a function\nthat generates a random number k between 1 and N. That number is used\nas an index of the kth token, of which the owner becomes the next leader.\nThe function used to generate a random number is public, meaning that any\nparticipant can execute it to determine k. Obviously, the more tokens a process\nP owns, the higher the probability that P will be elected as leader.\nThe simplicity of this algorithm and the fact that there are still so many\nrace-based blockchains, indicates that there are many issues to deal with\nbefore proof-of-stake solutions can actually work. To understand, we need to\nrealize that with proof of work, there is a price to pay to become leader, namely\nusing considerable computational resources. If that price is compensated by\na reward (namely a transaction fee), we have some sort of balance. In many\nproof-of-stake systems, there may also be a reward, but there is no price\nto be paid in advance for becoming a leader. As a result, these systems\nare generally more vulnerable to security attacks, for example, by letting\nparticipants generate invalid transactions that will disrupt the work of honest\nleaders.\nLeader election in blockchains is part of reaching consensus on the status\nof a blockchain. We return to these matters in Section 8.2.6.\nNote 5.7 (Advanced: Selecting superpeers)\nMany leader-election algorithms often concentrate on the selection of only a single\nnode. There are situations when several nodes should actually be selected, such\nas in the case of super peers in peer-to-peer networks, which we discussed in\nSection 2.4.3.\nThe following requirements need to be met for super-peer selection (see\nalso [Lo et al., 2005]):\n1. Normal nodes should have low-latency access to super peers.\n2. Super peers should be evenly distributed across the overlay network.\n3. There should be a predefined portion of super peers relative to the total\nnumber of nodes in the overlay network.\n4. Each super peer should not need to serve more than a fixed number of\nnormal nodes.\nFortunately, these requirements are relatively easy to meet in most peer-to-\npeer systems, given the fact that the overlay network is either structured (as in\nDHT-based systems), or randomly unstructured (as, for example, can be realized\nwith gossip-based solutions). Let us take a look at solutions proposed by Lo et al.\n[2005].\nIn the case of DHT-based systems, the basic idea is to reserve a fraction of\nthe identifier space for super peers. In a DHT-based system, each node receives\na random and uniformly assigned m-bit identifier. Now suppose we reserve the\n \nDS 4.01\n\n\n294\nCHAPTER 5. COORDINATION\nfirst (i.e., leftmost) k bits to identify super peers. For example, if we need N\nsuperpeers, then the first ⌈log2(N)⌉bits of any key can be used to identify these\nnodes.\nTo explain, assume we have a (small) Chord system with m = 8 and k = 3.\nWhen looking up the node responsible for a specific key K, we can first decide\nto route the lookup request to the node responsible for the pattern K ∧11100000\nwhich is then treated as the superpeer. (We use the binary operator “∧” to denote\na bitwise and.) Note that each node with identifier ID can check whether it is a\nsuper peer by looking up ID ∧11100000 to see if this request is routed to itself.\nProvided node identifiers are uniformly assigned to nodes, it can be seen that\nwith a total of N nodes the number of super peers is, on average, equal to 2k−mN.\nFigure 5.23: Moving tokens in a two-dimensional space using repulsion\nforces.\nA different approach is based on positioning nodes in an m-dimensional\ngeometric space. In this case, assume we need to place N super peers evenly\nthroughout the overlay. The basic idea is simple: a total of N tokens are spread\nacross N randomly chosen nodes. No node can hold more than one token. Each\ntoken represents a repelling force by which another token is inclined to move\naway. The net effect is that if all tokens exert the same repulsion force, they will\nmove away from each other and spread themselves evenly in the geometric space.\nThis approach requires that nodes holding a token learn about other tokens. To\nthis end, we can use a gossiping protocol, by which a token’s force is disseminated\nthroughout the network. If a node discovers that the total forces that are acting\non it exceed a threshold, it will move the token in the direction of the combined\nforces, as shown in Figure 5.23. When a token is held by a node for a given\namount of time, that node will promote itself to superpeer.\n5.4.6\nElections in wireless environments\nTraditional election algorithms are generally based on assumptions that are\nnot realistic in wireless environments. For example, they assume that message\npassing is reliable and that the topology of the network does not change.\nThese assumptions are false in most wireless environments, especially when\ndealing with mobile devices.\nOnly few protocols for elections have been developed that work in mobile\nenvironments. Vasudevan et al. [2004] propose a solution that can handle\nDS 4.01\n \n\n\n5.4. ELECTION ALGORITHMS\n295\nfailing nodes and partitioning networks. An important property of their\nsolution is that the best leader can be elected rather than just a random one as\nwas more or less the case in the previously discussed solutions. Their protocol\nworks as follows. To simplify our discussion, we concentrate only on ad hoc\nnetworks and ignore that nodes can actually move. This may be the case, for\nexample, in sensor networks.\nConsider such a wireless ad hoc network. To elect a leader, any node in the\nnetwork, called the source, can initiate an election by sending an ELECTION\nmessage to its immediate neighbors (i.e., the nodes in its range). When a\nnode receives an ELECTION for the first time, it designates the sender as its\nparent, and subsequently sends out an ELECTION message to all its immediate\nneighbors, except for the parent. When a node receives an ELECTION message\nfrom a node besides its parent, it merely acknowledges the receipt.\nWhen node R has designated node Q as its parent, it forwards the\nELECTION message to its immediate neighbors (excluding Q) and waits for\nacknowledgments to come in before acknowledging the ELECTION message\nfrom Q. This waiting has an important consequence. First, note that neighbors\nwho have already selected a parent will immediately respond to R. More\nspecifically, if all neighbors already have a parent, R is a leaf node and will be\nable to report back to Q quickly. In doing so, it will also report information\nsuch as its battery lifetime and other resource capacities.\nThis information will later allow Q to compare R’s capacities to that of\nother downstream nodes, and select the best eligible node for leadership. Of\ncourse, Q had sent an ELECTION message only because its own parent P had\ndone so as well. In turn, when Q eventually acknowledges the ELECTION\nmessage previously sent by P, it will pass the most eligible node to P as well.\nIn this way, the source will eventually get to know which node is best to be\nselected as leader, after which it will broadcast this information to the rest.\nThis process is illustrated in Figure 5.24. Nodes have been labeled a to\nj, along with their capacity. Node a initiates an election by broadcasting\nan ELECTION message to nodes b and j, as shown in Figure 5.24(b) After\nthat step, ELECTION messages are propagated to all nodes, ending with the\nsituation shown in Figure 5.24(e), where we have omitted the last broadcast\nby nodes f and i. From there on, each node reports to its parent the node\nwith the best capacity, as shown in Figure 5.24(f). For example, when node g\nreceives the acknowledgments from its children e and h, it will notice that h\nis the best node, propagating [h, 8] to its own parent, node b. In the end, the\nsource will note that h is the best leader and will broadcast this information\nto all other nodes.\nWhen multiple elections are initiated, each node will decide to join only\none election. To this end, each source tags its ELECTION message with a\nunique identifier. Nodes will participate only in the election with the highest\nidentifier, stopping any running participation in other elections.\n \nDS 4.01\n\n\n296\nCHAPTER 5. COORDINATION\n(a)\n(b)\n(c)\n(d)\n(e)\n(f)\nFigure 5.24: Election algorithm in a wireless network, with node a as the\nsource. (a) Initial network. (b)–(e) The build-tree phase (last broadcast step by\nnodes f and i not shown). (f) Reporting of best node to source.\nDS 4.01\n \n\n\n5.5. GOSSIP-BASED COORDINATION\n297\nWith some minor adjustments, the protocol can be shown to operate also\nwhen the network partitions, and when nodes join and leave. The details can\nbe found in Vasudevan et al. [2004].\n5.5\nGossip-based coordination\nAs a next topic in coordination, we take a look at a few important examples\nin which gossiping is deployed. In the following, we look at aggregation,\nlarge-scale peer sampling, and overlay construction, respectively.\n5.5.1\nAggregation\nLet us take a look at some interesting applications of epidemic protocols. We\nalready mentioned spreading updates, which is perhaps the most widely de-\nployed application. In the same light, gossiping can be used to discover nodes\nthat have a few outgoing wide-area links, to subsequently apply directional\ngossiping.\nAnother interesting application area is simply collecting, or actually aggre-\ngating information [Jelasity et al., 2005]. Consider the following information\nexchange. Every node Pi initially chooses an arbitrary number, say vi. When\nnode Pi contacts node Pj, they each update their value as:\nvi, vj ←(vi + vj)/2\nObviously, after this exchange, both Pi and Pj will have the same value. In\nfact, it is not difficult to see that eventually all nodes will have the same\nvalue, namely the average of all initial values. Propagation speed is again\nexponential.\nWhat use does computing the average have? Consider the situation that\nall nodes Pi have set vi to zero, except for P1 who has set v1 to 1:\nvi ←\n(\n1\nif i = 1\n0\notherwise\nIf there are N nodes, then eventually each node will compute the average,\nwhich is 1/N. As a consequence, every node Pi can estimate the size of the\nsystem as being 1/vi.\nComputing the average may be difficult when nodes regularly join and\nleave the system. One practical solution to this problem is to introduce epochs.\nAssuming that node P1 is stable, it simply starts a new epoch now and then.\nWhen node Pi sees a new epoch for the first time, it resets its own variable vi\nto zero and starts computing the average again.\nOf course, other results can also be computed. For example, instead of\nhaving a fixed node such as P1 start the computation of the average, we\n \nDS 4.01\n\n\n298\nCHAPTER 5. COORDINATION\ncan easily pick a random node as follows. Every node Pi initially sets vi\nto a random number from the same interval, say (0, 1], and also stores it\npermanently as mi. Upon an exchange between nodes Pi and Pj, each change\ntheir value to:\nvi, vj ←max{vi, vj}\nEach node Pi for which mi < vi will lose the competition for being the initiator\nin starting the computation of the average. In the end, there will be a single\nwinner. Of course, although it is easy to conclude that a node has lost, it is\nmuch more difficult to decide that it has won, as it remains uncertain whether\nall results have come in. The solution to this problem is to be optimistic: a\nnode always assumes it is the winner until proven otherwise. At that point, it\nsimply resets the variable it is using for computing the average to zero. Note\nthat by now, several computations (in our example, computing a maximum\nand computing an average) may be executing simultaneously.\n5.5.2\nA peer-sampling service\nAn important aspect in epidemic protocols is the ability of a node P to choose\nanother node Q at random from all available nodes in the network. When\ngiving the matter some thought, we may actually have a serious problem:\nif the network consists of thousands of nodes, how can P ever pick one of\nthese nodes at random without having a complete overview of the network?\nFor smaller networks, one could often resort to a central service that had\nregistered every participating node. Obviously, this approach can never scale\nto large networks.\nA solution is to construct a fully decentralized peer-sampling service, or\nPSS for short. As it turns out, and somewhat counter-intuitive, a PSS can be\nbuilt using an epidemic protocol. As explored by Jelasity et al. [2007], each\nnode maintains a list of c neighbors, where, ideally, each of these neighbors\nrepresents a randomly chosen live node from the current set of nodes. This\nlist of neighbors is also referred to as a partial view. There are many ways to\nconstruct such a partial view. In the solution of Jelasity et al., it is assumed that\nnodes regularly exchange entries from their partial view. Each entry identifies\nanother node in the network, and has an associated age that indicates how old\nthe reference to that node is. Two threads are used, as shown in Figure 5.25.\nThe different selection operations are specified as follows:\n• selectPeer: Randomly select a neighbor from the local partial view\n• selectToSend: Select some other entries from the partial view, and add\nto the list intended for the selected neighbor.\n• selectToKeep: Add received entries to the partial view, remove repeated\nitems, and shrink the view to c items.\nDS 4.01\n \n\n\n5.5. GOSSIP-BASED COORDINATION\n299\n1 selectPeer(&Q);\n2 selectToSend(&bufs);\n3 sendTo(Q, bufs);\n4\n5 receiveFrom(Q, &bufr);\n6 selectToKeep(p_view, bufr);\n−→\n←−\n1\n2\n3 receiveFromAny(&P, &bufr);\n4 selectToSend(&bufs);\n5 sendTo(P, bufs);\n6 selectToKeep(p_view, bufr);\n(a)\n(b)\nFigure 5.25: Communication between the (a) active and (b) passive thread in\na peer-sampling service.\nThe active thread takes the initiative to communicate with another node. It\nselects that node from its current partial view. It continues by constructing a\nlist containing c/2 + 1 entries, including an entry identifying itself. The other\nentries are taken from the current partial view. After sending the list to the\nselected neighbor, it waits for a response.\nThat neighbor, meanwhile, will also have constructed a list through the\npassive thread shown in Figure 5.25(b) whose activities strongly resemble that\nof the active thread.\nThe crucial point is the construction of a new partial view. This view, for\ncontacting as well as for the contacted peer, will contain exactly c entries, part\nof which will come from the received list. In essence, there are two ways to\nconstruct the new view. First, the two nodes may decide to discard the entries\nthat they had sent to each other. Effectively, this means that they will swap\npart of their original views. The second approach is to discard as many old\nentries as possible (meaning, in practice, that after every gossiping round, the\nage of each entry in every partial view is incremented by one).\nAs it turns out, as long as peers regularly run the exchange algorithm just\ndescribed, selecting a random peer from a thus dynamically changing partial\nview, is statistically indistinguishable from randomly selecting a peer from\nthe entire network. Of course, selecting a peer from a partial view should\noccur at approximately the same frequency as the refreshing of partial views.\nWe have thus constructed a fully decentralized gossip-based peer-sampling\nservice. A simple and often-used implementation of a peer-sampling service\nis Cyclon [Voulgaris et al., 2005].\n5.5.3\nGossip-based overlay construction\nAlthough it would seem that structured and unstructured peer-to-peer sys-\ntems form strict independent classes, this need actually not be the case (see\nalso Castro et al. [2005]). One key observation is that by carefully exchanging\nand selecting entries from partial views, it is possible to construct and main-\ntain specific topologies of overlay networks. This topology management is\nachieved by adopting a two-layered approach, as shown in Figure 5.26.\n \nDS 4.01\n",
      "page_number": 302
    },
    {
      "number": 32,
      "title": "Segment 32 (pages 311-318)",
      "start_page": 311,
      "end_page": 318,
      "detection_method": "topic_boundary",
      "content": "300\nCHAPTER 5. COORDINATION\nFigure 5.26: A two-layered approach for constructing and maintaining specific\noverlay topologies using techniques from unstructured peer-to-peer systems.\nThe lowest layer constitutes an unstructured peer-to-peer system in which\nnodes periodically exchange entries of their partial views with the aim to\nprovide a peer-sampling service. Accuracy in this case refers to the fact that\nthe partial view should be filled with entries referring to randomly selected\nlive nodes.\nThe lowest layer passes its partial view to the higher layer, where an\nadditional selection of entries takes place. This then leads to a second list\nof neighbors corresponding to the desired topology. Jelasity and Kermarrec\n[2006] propose to use a ranking function by which nodes are ordered according\nto some criterion relative to a given node. A simple ranking function is to\norder a set of nodes by increasing distance from a given node P. In that case,\nnode P will gradually build up a list of its nearest neighbors, provided the\nlowest layer continues to pass randomly selected nodes.\nAs an illustration, consider a logical grid of size N × N with a node placed\non each point of the grid. Every node is required to maintain a list of c\nnearest neighbors, where the distance between a node at (a1, a2) and (b1, b2)\nis defined as d1 + d2, with di = min(N −|ai −bi|, |ai −bi|). If the lowest layer\nperiodically executes the protocol as outlined in Figure 5.25, the topology that\nwill evolve is a two-dimensional torus, shown in Figure 5.27. In this example,\nN = 50 and we show the results after first initializing each list with random\nentries. Figure 5.27(b) shows the results after five rounds of exchanges, while\nthe final result, shown in Figure 5.27(c) is achieved after 20 rounds.\nNote 5.8 (Advanced:Gossip-based overlay construction in Python)\nTo better appreciate and understand the construction of overlay networks through\ngossiping, let us see what a concrete implementation in Python would look like.\nAs we have mentioned, the principle is simple: we have two separate layers\nand each node is responsible for exchanging links with selected neighbors. A\nstraightforward implementation would seem to be to use a separate thread per\nlayer, as suggested in Figure 5.26. However, such a choice will instantly lead to\npotential deadlock problems. Suppose node A decides to exchange links with\nDS 4.01\n \n\n\n5.5. GOSSIP-BASED COORDINATION\n301\n(a)\n(b)\n(c)\nFigure 5.27: Generating a torus overlay network using a two-layered unstruc-\ntured peer-to-peer system.\nnode B, but B has chosen another node, say C for exchanging links. If C chooses A\nfor exchanging links, we may have a deadlock if these three nodes first collectively\nchoose their respective neighbor for exchanging links, and then collectively wait\nfor that neighbor to respond.\nThe general solution to this problem is to essentially avoid synchronous\nrequest-response behavior, but instead to use asynchronous, persistent com-\nmunication. In other words, we let the middleware store a message before it\nis delivered, after which the sender can continue doing other things. This type\nof communication is precisely supported by the channel package used for many\nof our Python examples. The outline of the code is shown in Figure 5.28. (The\ncomplete code is readily available as accompanying online material for the book.)\nNote that for each layer, the approach is essentially always the same: select a\npeer, decide on the links to exchange, and send that information asynchronously\nto the selected peer. Thereafter, a node that initiated an exchange will have to\nwait for a response. When that comes in, it merely needs to update its own view.\n(There are many subtleties that need to be considered, which we will discuss\nshortly.) In principle, there will be a regular call to maintainViews(), if only to\nensure that a node will also react to incoming exchange requests. Note that in our\nsolution, we simply let a node ignore an incoming exchange request when it has\nan outstanding initiated exchange itself. Ignoring a request is done by telling the\ninitiating node to give up its own attempt. Although this approach will prevent\ndeadlocks, it bears the risk that no exchange will take place at all.\nAs mentioned, the actual code for handling gossip-based overlay construction\ninvolves more than what we have shown in Figure 5.28. Crucial are the criteria\nfor selecting a neighboring peer, as well as the selection of links to exchange. As\nexplained by Voulgaris and van Steen [2013], there are several things that can be\ndone to speed up convergence of the overlay in comparison to random choices.\nAt the same time, including random choices is essential to achieve convergence to\nthe requested overlay.\nIn the first place, at the top layer for constructing the overlay, links should\nbe exchanged that make most sense for the receiving peer. In our example, this\n \nDS 4.01\n\n\n302\nCHAPTER 5. COORDINATION\nmeans that when a node A sends links to a node B, it should select the ones to\nneighbors that are closest to B. Furthermore, B should not return links that A had\njust sent: it is much better that A learns about new nodes first.\n1 def maintainViews():\n2\nfor viewType in [viewOverlay, viewPSS]: # For each view, do the same\n3\npeer[viewType] = None\n4\nif time to maintain viewType: # This viewType needs to be updated\n5\npeer[viewType] = selectPeer(viewType)\n# Select a peer\n6\nlinks = selectLinks(viewType, peer[viewType])\n# Select links\n7\nsendTo(peer[viewType], Request[viewType], links) # Send links asynchronously\n8\n9\nwhile True:\n10\nblock = (peer[viewOverlay] != None) or (peer[viewPSS] != None)\n11\nsender, msgType, msgData = recvFromAny(block) # Block if expecting something\n12\n13\nif msg == None: # All work has been done, simply return from the call\n14\nreturn\n15\n16\nfor viewType in [viewOverlay, viewPSS]: # For each view, do the same\n17\nif msgType == Response[viewType]:\n# Response to previously sent links\n18\nupdateOwnView(viewType, msgData) # Just update the own view\n19\n20\nelif msgType == Request[viewType]: # Request for exchanging links\n21\nif peer[viewType] == None:\n# No outstanding exchange request\n22\nlinks = selectLinks(viewType, sender)\n# Select links\n23\nsendTo(sender, Response[viewType], links) # Send them asynchronously\n24\nupdateOwnView(viewType,msgData)\n# Update own view\n25\nelse: # This node already has a pending exchange request, ignore this one\n26\nsendTo(sender, IgnoreRequest[viewType])\n27\n28\nelif msgType == IgnoreRequest[viewType]: # Request has been denied, give up\n29\npeer[viewType] = None\nFigure 5.28: Pseudocode in Python for implementing a gossip-based\napproach toward overlay construction.\nMoreover, when A selects a peer, we should try to prevent selecting one with\nwhich a recent exchange has taken place. In other words, A should try to maximize\ndiversity in selecting a peer. This diversity can be obtained by selecting peers\nin a round-robin fashion. This approach also has the benefit that in a dynamic\nnetwork, nodes that have left are guaranteed to be discovered quickly and can\nthus be removed from a view.\nIf we were to use only the top layer, the greediness of exchanging only\nbest links may lead to a situation that a collection of nodes will jointly form\na closed set within the network: jointly, they are referring to each other and\nas such, may be missing out on better nodes. This is the reason introducing\nrandomness is essential, and why we need to incorporate information from the\nlower random overlay in the selection process of the higher structured overlay.\nDS 4.01\n \n\n\n5.5. GOSSIP-BASED COORDINATION\n303\nThis aspect is completely analogous to getting stuck in a local optimum when\noptimizing through hill-climbing procedures. What is needed is to introduce\nsome randomness to ensure that indeed a global optimum will eventually be\nreached.\n5.5.4\nSecure gossiping\nGossiping is an attractive means for coordination. However, the speed by\nwhich a large collection of nodes manages to synchronize, is also an inherent\nvulnerability. The time it takes to exchange and disseminate proper informa-\ntion is also the time it takes to spread false information. This is perhaps best\nillustrated by means of an example. Consider a peer-sampling service for\nsome large network. Assume that each node maintains a partial view of size c,\nand that, on average, c/2 references to neighboring nodes are exchanged. Let\nus also assume that there are c colluding attackers. Their behavior is simple:\neach attacker also maintains a partial view, but when returning c/2 references,\nonly references to other colluding attackers are returned. The effect is that,\ngradually, the partial view of each benign node in the network is polluted by\nreferences to the attackers, to the extent that each partial view contains only\nreferences to attackers.\nFigure 5.29: The speed by which a hub attack can take effect.\nThe effect can be dramatic. Figure 5.29 shows the speed by which partial\nviews are fully polluted, that is, each contains references only to attackers.\nIn this example, we consider a network of 100,000 nodes, a partial view size\nof 30, and only 30 attackers. After less than 300 rounds, all benign nodes\nhave fully polluted partial views. Also note that, completely consistent with\nthe push-pull behavior of epidemic protocols, it may take a while before any\nserious effect is seen. However, as soon as a few hundred nodes are completely\n \nDS 4.01\n\n\n304\nCHAPTER 5. COORDINATION\npolluted, they increasingly contribute to contaminating the rest of the nodes,\nand so on.\nIt can be argued that there is no standard security measure that can combat\nthese kinds of attacks. For example, even with using secure channels by which\nboth parties have genuinely authenticated each other, there is no reason to\nassume that both of them will also behave as they should. In other words,\nauthentication provides no guarantees for trust. In the case of gossiping\nsystems, security often comes in the form of trying to detect and prevent\nmalicious behavior. For our example, the question is how can a benign node\ncan detect that it is under attack, and which countermeasures can it take to\nmitigate the effects of an attack?\nA solution in the case of peer sampling, and developed by Jesi et al. [2010],\nworks as follows. The essence is to discover if there are nodes that behave\nbadly. The attack we just described is characterized by the fact that, eventually,\nmany nodes will be referencing a very small of set of nodes. In terms of\ngraphs, this means that the indegree of some nodes is extraordinarily high,\nwhile for most nodes, their indegree will be low, and actually 0. An indegree\nof 0 means that a node is unknown to any other node in the network.\nWhen using Cyclon [Voulgaris et al., 2005] as the peer-sampling service,\nwe know that the indegrees follow a normal distribution, as shown in Fig-\nure 5.30(a). In this example, the y-axis shows the fraction of nodes with a\nspecific indegree value. Even with a mere 30 colluding attackers, we already\nsee that after 10 rounds, the indegree distribution has started to becoming\nwider and shifting to the left, as shown in Figure 5.30(b). This continues,\nand after 40 rounds (Figure 5.30(e)), we already have that about 15% of all\nnodes have an indegree of 0. (Note that for Figure 5.29, we were counting\nthe number of nodes that were referencing only attacking nodes, which is\ndifferent from measuring indegrees. An attacked node can still be referenced\nby others.) Finally, after less than 300 rounds, virtually all nodes have an\nindegree of 0; the attackers have now full control over the entire network.\nFigure 5.30 also gives us a hint toward a solution. As explained by Jesi et al.\n[2010], each node can gather statistics on which nodes are being referenced.\nIf certain nodes are gradually being referenced unusually more often than\nothers, then something fishy may be going on. There are a few issues we\nneed to deal with. First, spreading of “bad” links can be so efficient, that\nwe need to consider that once a benign node has come to the conclusion\nthat it has identified an attacker, it may already be too late. Second, we also\nwant to prevent that every benign node has to build up complete knowledge\nof the entire network, partly also because attackers have to be identified\nquickly. Third, attackers do not want to be caught, i.e., be recognized as acting\nmaliciously, as they collectively do need some time to be successful.\nNotably the last aspect, not wanting to be caught, provides a solution to\nmitigating an attack. In essence, a benign node can force an attacker to behave\nDS 4.01\n \n\n\n5.5. GOSSIP-BASED COORDINATION\n305\n(a)\n(b)\n(c)\n(d)\n(e)\n(f)\nFigure 5.30: The development of the indegree distribution at several stages of\na peer-sampling service under attack. Each x-axis shows the indegree, and\nthe y-axis the fraction of nodes with that degree.\n \nDS 4.01\n\n\n306\nCHAPTER 5. COORDINATION\naccording to the rules. What happens is that when a benign node initiates\nan exchange of links with a selected node, it will process the returned links\neither for updating its own partial view, or for gathering statistics (it may do\nboth, but this may not be on par with efficient resource usage). Moreover, to\naccelerate the process of discovering attackers, a node will initiate several link\nexchanges simultaneously (and, in the end, process only one of the replies). A\nmalicious node is now faced with a dilemma: always returning references to\nits colluders will quickly reveal the attackers. The only thing that it can do, is\noccasionally play by the rules and return links to other, benign nodes. As it\nturns out, this dilemma is enough to force the attackers to behave decently\nenough, effectively rendering an attack useless. Note that this procedure will\nalso be applied when an attacker initiates an exchange: the recipient can decide\nto use the links passed to it for updating its statistics on indegrees, as well as\nuse it for running the exchange protocol. The attacker will, however, never\nknow whether the recipient is going to collect statistics. To fly under the radar,\nit will have to behave according to the rules of the game enough in order not\nto be caught. The details can be found in [Jesi et al., 2010].\nThere are many other types of attacks possible. For example, attackers\nmay decide to initiate information exchange at a much higher frequency than\nspecified by the protocol. With a push-based approach, this may result in\nattackers rapidly polluting values of benign nodes, which are then further\ndisseminated. Mousazadeh and Ladani [2015] come to the conclusion that for\nsuch attacks, in principle, only pulling should be allowed (as the benign nodes\nwill then collectively dictate the pace at which information is disseminated).\nLikewise, in the case of aggregation, attackers may deliberately return\nincorrect values. To illustrate, suppose that when collectively computing the\naverage value as we described in Section 5.5.1, an attacker A always returns its\nown value vA. Every node vi communicating with A will therefore compute\nvi ←(vi + vA)/2\nwhich gradually converges to the value vA. In all these cases, attacks can\nbe mitigated only by trying to detect if a node is not behaving according to\nthe protocol. That detection mechanism, of course, should be known to the\nattacker, while at the same time will be effective if it forces an attacker to try\nto go ahead unnoticed. In turn, if well designed, the mechanism will force\nthe attacker to actually behave well, or at least to the extent that any possible\ndamage remains limited. More on how these data-injection attacks work and\ncan be mitigated, are described by Gentz et al. [2016].\n5.6\nDistributed event matching\nLet us now draw our attention to distributed event matching. Event matching,\nor more precisely, notification filtering, is at the heart of publish-subscribe\nsystems. The problem boils down to the following:\nDS 4.01\n \n\n\n5.6. DISTRIBUTED EVENT MATCHING\n307\n• A process specifies through a subscription S in which events it is inter-\nested.\n• When a process publishes a notification N on the occurrence of an event,\nthe system needs to see if S matches N.\n• In the case of a match, the system should send the notification N, possibly\nincluding the data associated with the event that took place, to the\nsubscriber.\nAs a consequence, we need to facilitate at least two things: (1) matching\nsubscriptions against events, and (2) notifying a subscriber in the case of a\nmatch. The two can be separated, but this need not always be the case. In the\nfollowing, we assume the existence of a function match(S, N) which returns\ntrue when subscription S matches the notification N, and false otherwise. As\nwe argue below, publish-subscribe systems turn out to face difficult scalability\nproblems when the matching function cannot be easily distributed across\nmultiple servers. This is often the case when subscriptions can be expressive,\nas in content-based publish-subscribe systems.\nWe discuss scalability of\ndistributed event matching separately below.\nAnother, rather nasty problem, is combining security and privacy while\nkeeping publishers and subscribers mutually unaware of each other, but also\nensuring that servers have only enough information available to perform\ntheir matching function. In this sense, it may seem that the goals of publish-\nsubscribe systems, and those of secure distributed systems conflict. We return\nto this issue below as well.\n5.6.1\nCentralized implementations\nA simple, naive implementation of event matching is to have a fully centralized\nserver that handles all subscriptions and notifications. In such a scheme, a\nsubscriber simply submits a subscription, which is subsequently stored. When\na publisher submits a notification, that notification is checked against each\nand every subscription, and when a match is found, the notification is copied\nand forwarded to the associated subscriber.\nObviously, this is not a very scalable solution. Nevertheless, provided\nthe matching can be done efficiently and the server itself has enough pro-\ncessing power, the solution is feasible for many cases. For example, using\na centralized server is the canonical solution for implementing Linda tuple\nspaces. Likewise, many publish-subscribe systems that run within a single\ndepartment or organization can be implemented through a central server.\nImportant, in these cases, is that the matching function can be implemented\nefficiently. In practice, this is often the case when dealing with topic-based\nfiltering: matching then resorts to checking for equality of attribute values.\n \nDS 4.01\n",
      "page_number": 311
    },
    {
      "number": 33,
      "title": "Segment 33 (pages 319-327)",
      "start_page": 319,
      "end_page": 327,
      "detection_method": "topic_boundary",
      "content": "308\nCHAPTER 5. COORDINATION\nNote that a simple way to scale up a centralized implementation, is to de-\nterministically divide the work across multiple servers. A standard approach\nis to make use of two functions, as explained by Baldoni et al. [2009]:\n• a function sub2node(S), which takes a subscription S and maps it to a\nnonempty subset of servers\n• a function not2node(N), which takes a notification N and maps it to a\nnonempty subset of servers.\nThe servers to which sub2node(S) is mapped are called the rendezvous nodes\nfor S.\nLikewise, sub2node(N) are the rendezvous nodes for N.\nThe only\nconstraint that needs to be satisfied, is that for any subscription S and matching\nnotification N, sub2node(S) ∩not2node(N) ̸= ∅. In other words, there must be\nat least one server that can handle the subscription when there is a matching\nnotification. In practice, this constraint is satisfied by topic-based publish-\nsubscribe systems by using a hashing function on the names of the topics.\nThe idea of having a central server can be extended by distributing the\nmatching across multiple servers and dividing the work. The servers, generally\nreferred to as brokers, are organized into an overlay network. The issue then\nbecomes how to route notifications to the appropriate set of subscribers. A\nstraightforward way to make sure that notifications reach their subscribers, is\nto deploy flooding. There are essentially two approaches. First, we store each\nsubscription at every broker, while publishing notifications only at a single\nbroker. The latter will handle identifying the matching subscriptions and\nsubsequently copy and forward the notification. The alternative is to store a\nsubscription only at one broker, while broadcasting notifications to all brokers.\nIn that case, matching is distributed across the brokers, which may lead to a\nmore balanced workload among the brokers.\nNote 5.9 (Example: TIB/Rendezvous)\nFlooding notifications is used in TIB/Rendezvous, of which the basic archi-\ntecture is shown in Figure 5.31 [TIBCO]. In this approach, a notification is\na message tagged with a compound keyword describing its content, such as\nnews.comp.os.books. A subscriber provides (parts of) a keyword, or indicating the\nmessages it wants to receive, such as news.comp. ∗.books. These keywords are\nsaid to indicate the subject of a message.\nFundamental to its implementation is the use of broadcasting common in\nlocal-area networks, although it also uses more efficient communication facilities\nwhen possible. For example, if it is known exactly where a subscriber resides,\npoint-to-point messages will generally be used. Each host on such a network will\nrun a rendezvous daemon, which takes care that messages are sent and delivered\naccording to their subject. Whenever a message is published, it is multicasted to\neach host on the network running a rendezvous daemon. Typically, multicasting\nDS 4.01\n \n\n\n5.6. DISTRIBUTED EVENT MATCHING\n309\nis implemented using the facilities offered by the underlying network, such as\nIP-multicasting or hardware broadcasting.\nNetwork\nMulticast message on B to subscribers\nMulticast message\non A to subscribers\nSubj: A\nPubl. on A\nRV\ndaemon\nRV lib\nSubs. to A\nRV\ndaemon\nRV lib\nSubj: B\nRV\ndaemon\nRV lib\nSubs. to A\nPubl. on B\nRV\ndaemon\nRV lib\nSubs. to A\nSubs. to B\nRV\ndaemon\nRV lib\nSubs. to B\nFigure 5.31: The principle of a publish/subscribe system as implemented\nin TIB/Rendezvous.\nProcesses that subscribe to a subject pass their subscription to their local\ndaemon. The daemon constructs a table of (process, subject), entries and whenever\na message on subject S arrives, the daemon simply checks in its table for local\nsubscribers, and forwards the message to each one. If there are no subscribers for\nS, the message is discarded immediately.\nWhen using multicasting as is done in TIB/Rendezvous, there is no reason\nwhy subscriptions cannot be elaborate and be more than string comparison, as\nis currently the case. The crucial observation here is that because messages are\nforwarded to every node anyway, the potentially complex matching of published\ndata against subscriptions can be done entirely locally without further network\ncommunication needed.\nWhen subscriptions are allowed to be more expressive, scalability may\neasily become a problem. In practice, expressive subscriptions take the form\nof (attribute,value) pairs in which a value returns as an expression on the\npossible values for the specified attribute. Examples include range values\n(“1 ≤x < 10”), containment (“x ∈{red, blue}”), prefix and suffix expressions\n(“url.startswith(“https”)”), etc. More complicated expressions including\ncombinations of conjunctions and disjunctions are, in theory, also possible,\nthus gradually resembling what one would find in SQL queries for databases.\nIt is not hard to imagine that expressive subscriptions can be handled by\ncentralized brokers, but when scalability is at stake, we may need to limit\nexpressiveness altogether to the point that we find ourselves looking at topic-\nbased event matching.\nOne way out that has been explored is combining peer-to-peer networks\nand publish-subscribe systems, as described in Kermarrec and Triantafillou\n[2013]. As the authors show, there is no simple general solution, and most\nsolutions often have very specific limitations.\n \nDS 4.01\n\n\n310\nCHAPTER 5. COORDINATION\nSelective routing\nIf we consider that publish-subscribe is all about routing messages between\npublishers and subscribers, one thought is to install specific filters in an overlay\nnetwork that effectively ignore paths toward nodes that are not interested in\nwhat is being published. In other words, instead of flooding a network with\neither subscriptions or publications, we apply selective routing, as proposed\nby Carzaniga et al. [2004]. Consider a publish-subscribe system consisting\nof N brokers to which clients (i.e., applications) can send subscriptions and\nretrieve notifications. Carzaniga et al. propose a two-layered routing scheme,\nin which the lowest layer consists of a shared broadcast tree connecting the\nN brokers. There are various ways for setting up such a tree, ranging from\nnetwork-level multicast support to application-level multicast trees, as we\ndiscussed in Chapter 4. Here, we also assume that such a tree has been set\nup with the N brokers as end nodes, along with a collection of intermediate\nnodes forming routers. Note that the distinction between a server and a router\nis only a logical one: a single machine may host both kinds of processes.\n(a)\n(b)\nFigure 5.32: A first approach toward content-based routing in which brokers\n(a) first broadcast subscriptions to later (b) forward notifications only to\nrelevant brokers.\nEvery broker broadcasts its subscriptions to all other brokers, as shown\nin Figure 5.32(a). As a result, every broker will be able to compile a list of\n(subject, destination) pairs. Then, whenever a process publishes a notification\nN, its associated broker prepends the destination brokers to that message and\nforwards the notification to the others, shown in Figure 5.32(b). When the\nmessage reaches a router, the latter can use the list to decide on the paths that\nthe message should follow, as shown in Figure 5.32.\nWe can now refine the capabilities of routers for deciding where to forward\nnotifications. To that end, each broker broadcasts its subscription across the\nnetwork so that routers can compose routing filters. For example, assume\nthat node 3 in Figure 5.32 subscribes to notifications for which an attribute a\nlies in the range [0, 3], but that node 4 wants messages with a ∈[2, 5]. In this\nDS 4.01\n \n\n\n5.6. DISTRIBUTED EVENT MATCHING\n311\ncase, router R2 will create a routing filter as a table with an entry for each of\nits outgoing links (in this case three: one to node 3, one to node 4, and one\ntoward router R1), as shown in Figure 5.33.\nInterface\nFilter\nTo node 3\na ∈[0, 3]\nTo node 4\na ∈[2, 5]\nToward router R1\n(unspecified)\nFigure 5.33: A partially filled routing table.\nMore interesting is what happens at router R1.\nIn this example, the\nsubscriptions from nodes 3 and 4 dictate that any notification with a lying in\nthe interval [0, 3] ∪[2, 5] = [0, 5] should be forwarded along the path to router\nR2, and this is precisely the information that R1 will store in its table. It is\nnot difficult to imagine that more intricate subscription compositions can be\nsupported.\nThis simple example also illustrates that whenever a node leaves the\nsystem, or when it is no longer interested in specific notifications, it should\ncancel its subscription and essentially broadcast this information to all routers.\nThis cancellation, in turn, may lead to adjusting various routing filters. Late\nadjustments will at worst lead to unnecessary traffic, as notifications may be\nforwarded along paths for which there are no longer subscribers. Nevertheless,\ntimely adjustments are needed to keep performance at an acceptable level.\nGossiping\nSelective routing may help to avoid broadcasting notifications to all routers,\nbut ultimately, it may still not be enough to reach acceptable scalable solutions.\nAnother approach is based on gossiping. The basic idea is that subscribers\ninterested in the same notifications form their own overlay network (which\nis constructed through gossiping as we describe further below), so that once\na notification is published, it merely needs to be routed to the appropriate\noverlay. For the latter, a random walk can be deployed. This approach is\nfollowing in TERA [Baldoni et al., 2007].\nA more sophisticated approach toward combining gossiping and event\nmatching is followed in Sub-2-Sub [Voulgaris et al., 2006]. It is still one\nof the very few content-based approaches that combines scalability with\nexpressiveness of subscriptions.\nConsider a publish-subscribe system in\nwhich data items can be described by N attributes a1, . . . , aN whose value\ncan be directly mapped to a floating-point number. Such values include, for\nexample, floats, integers, enumerations, Booleans, and strings. A subscription\nS takes the form of a tuple of (attribute, value/range) pairs, such as\nS = ⟨a1 →3.0, a4 →[0.0, 0.5)⟩\n \nDS 4.01\n\n\n312\nCHAPTER 5. COORDINATION\nIn this example, S specifies that a1 should be equal to 3.0, and a4 should lie in\nthe interval [0.0, 0.5). Other attributes are allowed to take on any value. For\nclarity, assume that every node i enters only one subscription Si.\nNote that each subscription Si actually specifies a subset Si in the N-\ndimensional space of floating-point numbers. Such a subset is also called a\nhyperspace. For the system as a whole, notifications that fall in the union\nS = ∪Si of these hyperspaces are the only ones of interest. The whole idea is\nto automatically partition S into M disjoint hyperspaces S1, . . . , SM such that\neach falls completely in one of the subscription hyperspaces Si, and together\nthey cover all subscriptions. More formally, we have that:\n(Sm ∩Si ̸= ∅) ⇒(Sm ⊆Si)\nSub-2-Sub keeps M minimal in the sense that there is no partitioning with\nfewer parts Sm. To this end, for each hyperspace Sm, it registers exactly those\nnodes i for which Sm ⊆Si. In that case, when a notification is published, the\nsystem need merely find the Sm to which the associated event belongs, from\nwhich point it can forward the notification to the appropriate nodes.\nTo this end, nodes regularly exchange subscriptions through gossiping. If\ntwo nodes i and j notice that their respective subscriptions intersect, that is,\nSij ≡Si ∩Sj ̸= ∅they will record this fact and keep references to each other.\nIf they discover a third node k with Sijk ≡Sij ∩Sk ̸= ∅, the three of them\nwill connect to each other so that a notification N from Sijk can be efficiently\ndisseminated. Note that if Sij −Sijk ̸= ∅, nodes i and j will maintain their\nmutual references, but now associate it strictly with Sij −Sijk.\nIn essence, what we are seeking is a means to cluster nodes into M different\ngroups, such that nodes i and j belong to the same group if and only if their\nsubscriptions Si and Sj intersect. Moreover, nodes in the same group should\nbe organized into an overlay network that allows efficient dissemination of a\ndata item in the hyperspace associated with that group. This situation for a\nsingle attribute is sketched in Figure 5.34.\nHere, we see a total of seven nodes, in which the horizontal line for node\ni indicates its range of interest for the value of the single attribute. Also\nshown is the grouping of nodes into disjoint ranges of interests in values of\nthe attribute. For example, nodes 3, 4, 7, and 10 will be grouped together\nrepresenting the interval [16.5, 21.0]. Any data item with a value in this range\nshould be disseminated to only these four nodes.\nTo construct these groups, the nodes are organized into a gossip-based\nunstructured network. Each node maintains a list of references to other\nneighbors (i.e., a partial view), which it periodically exchanges with one of\nits neighbors. Such an exchange allows a node to learn about random other\nnodes in the system. Every node keeps track of the nodes it discovers with\noverlapping interests (i.e., with an intersecting subscription).\nAt a certain moment, every node i will generally have references to other\nnodes with overlapping interests. As part of exchanging information with a\nDS 4.01\n \n\n\n5.6. DISTRIBUTED EVENT MATCHING\n313\nFigure 5.34: Grouping nodes for supporting range queries in a gossip-based\npublish-subscribe system.\nnode j, node i orders these nodes by their identifiers and selects the one with\nthe lowest identifier i1 > j, such that its subscription overlaps with that of\nnode j, that is, Sj,i1 ≡Si1 ∩Sj ̸= ∅.\nThe next one to be selected is i2 > i1 such that its subscription also overlaps\nwith that of j, but only if it contains elements not yet covered by node i1. In\nother words, we should have that Sj,i1,i2 ≡(Si2 −Sj,i1) ∩Sj ̸= ∅. This process\nis repeated until all nodes that have an overlapping interest with node i have\nbeen inspected, leading to an ordered list i1 < i2 < · · · < in. Note that a node\nik is in this list because it covers a region R of common interest to node i and j\nnot yet jointly covered by nodes with a lower identifier than ik. In effect, node\nik is the first node that node j should forward a notification to that falls in this\nunique region R. This procedure can be expanded to let node i construct a\nbidirectional ring. Such a ring is also shown in Figure 5.34.\nWhenever a notification N is published, it is disseminated as quickly\nas possible to any node that is interested in it. As it turns out, with the\ninformation available at every node finding a node i interested in N is simple.\nFrom there on, node i need simply forward N along the ring of subscribers for\nthe particular range that N falls into. To speed up dissemination, shortcuts\nare maintained for each ring as well.\n5.6.2\nSecure publish-subscribe solutions\nA characteristic feature of publish-subscribe systems is that publishers and\nsubscribers are referentially decoupled, and possibly also temporally decou-\npled. Notably, referential decoupling means that in a secure system messages\nshould be able to flow from a publisher to subscribers while guaranteeing\nmutual anonymity. To guarantee confidentiality and integrity of messages,\ncommunicating parties usually set up a secure channel, but such an approach\nwould break the party’s anonymity.\n \nDS 4.01\n\n\n314\nCHAPTER 5. COORDINATION\nA simple solution is to let a (possibly distributed) broker handle messages.\nThe broker would handle all the matching and storage, if necessary. Obviously,\nsuch a broker would need to be trusted. Yet, it is not obvious at all that such\ntrust is justified. For example, many publish-subscribe services are offered by\nthird parties operating in a cloud setting. It is often unclear to which extent\nthey can actually provide guarantees when it comes to protecting data. In\naddition, messages may often contain information that should definitely not,\noften even by law, be revealed to third parties, such as medical records.\nWe now seem to have several clashing requirements. First, for any publish-\nsubscribe system, we need to ensure that the communicating parties remain\nreferentially decoupled, that is, we need to guarantee mutual anonymity. Not\nknowing where messages come from imposes integrity issues: how can we be\nsure the messages have not been tampered with? Second, we cannot simply\nassume that brokers can be trusted. Facing confidentiality issues, we then\ncannot allow them to see (all of) the content of messages, yet this may impose\nserious routing problems. But there is more: if we cannot trust brokers, how\ncan we ensure availability in the sense that subscribers, entitled to specific\nmessages, actually receive those messages? Equally important is to ensure\nthat messages are not delivered to unauthorized subscribers. Cui et al. [2021]\nalso address an additional requirement: assuming there are colluders in place,\nbrokers should not learn about the interests of innocent subscribers.\nThese problems are not unique to publish-subscribe systems, and have\nbecome more prevalent with the advent of cloud-based services. The key\nquestion is how to let a third party search through data to make decisions,\nyet without revealing that data. This is also known as searchable encryp-\ntion [Bosch et al., 2014]. For publish-subscribe systems, an important tech-\nnique is to conduct secure keyword search. Boneh et al. [2004] introduced\nPublic Key Encryption with Keyword Search, generally known as PEKS. We\nwill explain only the principle of PEKS without going into the cryptographic\ndetails.\nIn PEKS, a message is accompanied by a collection of keywords. To that\nend, using a public key PK, a message m and its n keywords KW1, . . . , KWn\nare stored at a server as the message m∗:\nm∗= [PK(m)|PEKS(PK, KW1)|PEKS(PK, KW2)| · · · |PEKS(PK, KWn)]\nFor each keyword KWi a trapdoor TKWi is generated: TW(m∗) will return true\nif W ∈{KW1, . . . , KWn} and false otherwise.\nUsing PEKS, we can now set up a cloud-based publish-subscribe system\nwith (conceptually) a single broker that resides in the cloud. Such a scheme is\ndescribed in [Yang et al., 2017] and sketched in Figure 5.35. We note we have\ndeliberately simplified matters significantly to focus on the essentials.\nAn important role is played by the key authority: a trusted third party that\ngenerates keys for publishers and subscribers. In our example, it provides the\nDS 4.01\n \n\n\n5.7. LOCATION SYSTEMS\n315\nFigure 5.35: The principle of privacy-preserving publish-subscribe.\npublisher with a key PK that can be used for encrypting the publication m. In\naddition, the key is used for constructing the encrypted tags KW∗\ni = PEKS(PK,\nKWi). Likewise, each subscriber is given a secret key SK that it can use to\ngenerate a trapdoor TW to be used by the broker to see whether the tag W\nis associated with the publication m. If there is a match, the broker returns\nPK(m) which can then be decrypted using SK.\nOur simplified scheme misses many important details, for which we refer\nthe interested reader to Yang et al. [2017]. The authors assume that the broker\nis honest-but-curious and does not collude with publishers or subscribers.\nHonest-but-curious means that the server will behave according to the specifi-\ncations, but may keep track of everything it does and use that information.\nCui et al. [2021] describe a system that drops the assumption on collusion, and\nis one of the few known publish-subscribe systems that can handle colluding\nbrokers. An overview of the security issues in publish-subscribe systems is\ngiven by Uzunov [2016]. For a good overview on preserving confidentiality,\nwe refer to Onica et al. [2016]. The authors also come to the conclusion that\nsecurity becomes easier if brokers can be trusted. Otherwise, good support\nfor operating on encrypted data is needed.\n5.7\nLocation systems\nWhen looking at large distributed systems that are dispersed across a wide-\narea network, it is often necessary to take proximity into account. Just imagine\na distributed system organized as an overlay network in which two processes\nare neighbors in the overlay network, but are actually placed far apart in\nthe underlying network. If these two processes communicate a lot, it may\nhave been better to ensure that they are also physically placed in each other’s\nproximity. In this section, we take a look at location-based techniques to\ncoordinate the placement of processes and their communication.\n5.7.1\nGPS: Global Positioning System\nLet us start by considering how to determine your geographical position\nanywhere on Earth. This positioning problem is by itself solved through\na highly specific, dedicated distributed system, namely GPS, which is an\n \nDS 4.01\n\n\n316\nCHAPTER 5. COORDINATION\nacronym for Global Positioning System. GPS is a satellite-based distributed\nsystem that was launched in 1978. Although it initially was used mainly for\nmilitary applications, it by now has found its way to many civilian applications,\nnotably for traffic navigation. However, many more application domains exist.\nFor example, modern smartphones now allow owners to track each other’s\nposition. This principle can easily be applied to tracking other things as well,\nincluding pets, children, cars, boats, and so on.\nGPS uses up to 72 satellites, each circulating in an orbit at a height of\napproximately 20,000 km. Each satellite has up to four atomic clocks, which\nare regularly calibrated from special stations on Earth. A satellite continuously\nbroadcasts its position, and time stamps each message with its local time. This\nbroadcasting allows every receiver on Earth to accurately compute its own\nposition using, in principle, only four satellites. To explain, let us first assume\nthat all clocks, including the receiver’s, are synchronized.\nTo compute a position, consider first the two-dimensional case, as shown\nin Figure 5.36, in which three satellites are drawn, along with the circles\nrepresenting points at the same distance from each respective satellite. We see\nthat the intersection of the three circles is a unique point.\nFigure 5.36: Computing a node’s position in a two-dimensional space.\nThis principle of intersecting circles can be expanded to three dimensions,\nmeaning that we need to know the distance to four satellites to determine the\nlongitude, latitude, and altitude of a receiver on Earth. This positioning is\nall fairly straightforward, but determining the distance to a satellite becomes\ncomplicated when we move from theory to practice. There are at least two\nimportant real-world facts that we need to take into account:\n1. It takes a while before data on a satellite’s position reaches the receiver.\n2. The receiver’s clock is generally not in sync with that of a satellite.\nDS 4.01\n \n",
      "page_number": 319
    },
    {
      "number": 34,
      "title": "Segment 34 (pages 328-335)",
      "start_page": 328,
      "end_page": 335,
      "detection_method": "topic_boundary",
      "content": "5.7. LOCATION SYSTEMS\n317\nAssume that the timestamp from a satellite is completely accurate. Let\n∆r denote the deviation of the receiver’s clock from the actual time. When a\nmessage is received from satellite Si with timestamp Ti, then the measured\ndelay ∆i by the receiver consists of two components: the actual delay, along\nwith its own deviation:\n∆i = (Tnow −Ti) + ∆r\nwhere Tnow is the actual current time. As signals travel with the speed of light,\nc, the measured distance ˜di to satellite Si is equal to c · ∆i. With\ndi = c · (Tnow −Ti)\nbeing the real distance between the receiver and satellite Si, the measured\ndistance can be rewritten to ˜di = di + c · ∆r. The real distance is now computed\nas:\n˜di −c · ∆r =\nq\n(xi −xr)2 + (yi −yr)2 + (zi −zr)2\nwhere xi, yi, and zi denote the coordinates of satellite Si. What we see now is\na system of quadratic equations with four unknowns (xr, yr, zr, and also ∆r).\nWe thus need four reference points (i.e., satellites) to find a unique solution\nthat will also give us ∆r. A GPS measurement will thus also give an account\nof the actual time.\nSo far, we have assumed that measurements are perfectly accurate. Of\ncourse, they are not. There are many sources of errors, starting with the\nfact that the atomic clocks in the satellites are not always in perfect sync, the\nposition of a satellite is not known precisely, the receiver’s clock has a finite\naccuracy, the signal propagation speed is not constant (as signals appear to\nslow down when entering, e.g., the ionosphere), and so on. On average, this\nleads to an error of some 5–10 meters. Special modulation techniques, as\nwell as special receivers, are needed to improve accuracy. Using so-called\ndifferential GPS, by which corrective information is sent through wide-area\nlinks, accuracy can be further improved. More information can be found in\n[LaMarca and de Lara, 2008], as well as an excellent overview by Zogg [2002].\n5.7.2\nWhen GPS is not an option\nA major drawback of GPS is that it generally cannot be used indoors. For that\npurpose, other techniques are necessary. An increasingly popular technique\nis to make use of the numerous WiFi access points available. The basic idea\nis simple: if we have a database of known access points along with their\ncoordinates, and we can estimate our distance to an access point, then with\nonly three detected access points, we should be able to compute our position.\nOf course, it really is not that simple at all.\nA major problem is determining the coordinates of an access point. A\npopular approach is to do this through war driving: using a WiFi-enabled\n \nDS 4.01\n\n\n318\nCHAPTER 5. COORDINATION\ndevice along with a GPS receiver, someone drives or walks through an area\nand records observed access points. An access point can be identified through\nits SSID or its MAC-level network address.\nAn access point AP should\nbe detected at several locations before its coordinates can be estimated. A\nsimple method is to compute the centroid: assume we have detected AP at\nN different locations {⃗x1, ⃗x2, . . . , ⃗xN}, where each location ⃗xi consists of a\n(latitude, longitude)-pair as provided by the GPS receiver. We then simply\nestimate AP’s location ⃗xAP as\n⃗xAP = ∑N\ni=1 ⃗xi\nN\n.\nAccuracy can be improved by taking the observed signal strength into account,\nand giving more weight to a location with relatively high observed signal\nstrength than to a location where only a weak signal was detected. In the end,\nwe obtain an estimation of the coordinates of the access point. The accuracy\nof this estimation is strongly influenced by:\n• the accuracy of each GPS detection point ⃗xi\n• the fact that an access point has a nonuniform transmission range\n• the number of sampled detection points N.\nStudies show that estimates of the coordinates of an access point may be\ntens of meters off from the actual location (see, e.g., Kim et al. [2006] or\nTsui et al. [2010]). Moreover, access points come and go at a relatively high\nrate. Nevertheless, locating and positioning access points is widely popular,\nexemplified by the open-access Wigle database which is populated through\ncrowdsourcing.1\n5.7.3\nLogical positioning of nodes\nInstead of trying to find the absolute location of a node in a distributed system,\nan alternative is to use a logical, proximity-based location. In geometric\noverlay networks each node is given a position in an m-dimensional geometric\nspace, such that the distance between two nodes in that space reflects a real-\nworld performance metric. Computing such a position is the core business of a\nNetwork Coordinates System, or simply NCS, which are surveyed by Donnet\net al. [2010]. The simplest, and most applied example, is where distance\ncorresponds to internode latency. In other words, given two nodes P and Q,\nthen the distance ˆd(P, Q) reflects how long it would take for a message to\ntravel from P to Q and vice versa. We use the notation ˆd to denote distance in\na system where nodes have been assigned coordinates.\nThere are many applications of geometric overlay networks. Consider the\nsituation where a Website at server O has been replicated to multiple servers\n1See wigle.net.\nDS 4.01\n \n\n\n5.7. LOCATION SYSTEMS\n319\nS1, . . . , SN on the Internet, as typically happens with a Content Delivery\nNetwork (CDN). When a client C requests a page from O, the CDN may\ndecide to redirect that request to the server closest to C, that is, the one that\nwill give the best response time. If the geometric location of C is known, as\nwell as those of each replica server, the CDN can then simply pick that server\nSi for which ˆd(C, Si) is minimal.\nAnother example is optimal replica placement. Consider again a CDN that\nhas gathered the positions of clients for one of its major customers. If the CDN\nwere to replicate content to N servers, it can compute the N best positions\nwhere to place replicas such that the average client-to-replica response time is\nminimal. Performing such computations is almost trivially feasible if clients\nand servers have geometric positions that reflect internode latencies.\nAs a last example, consider position-based routing (see, e.g., [Popescu\net al., 2012] or [Bilal et al., 2013]). In such schemes, a message is forwarded\nto its destination using only positioning information. For example, a naive\nrouting algorithm to let each node forward a message to the neighbor closest\nto the destination. Although it can be easily shown that this specific algorithm\nneed not converge, it illustrates that only local information is used to decide.\nThere is no need to propagate link information or such to all nodes in the\nnetwork, as is the case with conventional routing algorithms.\nCentralized positioning\nPositioning a node in an m-dimensional geometric space requires m + 1\ndistance measures to nodes with known positions. Assuming that node P\nwants to compute its own position, it contacts three other nodes with known\npositions and measures its distance to each of them. Contacting only one node\nwould tell P about the circle it is located on; contacting only two nodes would\ntell it about the position of the intersection of two circles (which generally\nconsists of two points); a third node would subsequently allow P to compute\nits actual location.\nNode P can compute its own coordinates (xP, yP) by solving the three\nquadratic equations with the two unknowns xP and yP:\n˜di =\nq\n(xi −xP)2 + (yi −yP)2\n(i = 1, 2, 3)\nHere, we use ˜d to denote measured, or estimated distance. As said, ˜di generally\ncorresponds to measuring the latency between P and the node at (xi, yi). This\nlatency can be estimated as being half the round-trip delay, but it should\nbe clear that its value will be different over time. The effect is a different\npositioning whenever P would want to recompute its position. Moreover, if\nother nodes would use P’s current position to compute their own coordinates,\nthen it should be clear that the error in positioning P will affect the accuracy\nof the positioning of other nodes.\n \nDS 4.01\n\n\n320\nCHAPTER 5. COORDINATION\nIt should also be clear that measured distances between a set of nodes\nwill generally not even be consistent. For example, assume we are computing\ndistances in a one-dimensional space, as shown in Figure 5.37. In this example,\nwe see that although R measures its distance to Q as 2.0, and ˜d(P, Q) has been\nmeasured to be 1.0, when R measures ˜d(P, R) it finds 2.8, which is clearly\ninconsistent with the other two measurements.\nFigure 5.37: Inconsistent distance measurements in a one-dimensional space.\nFigure 5.37 also suggests how this situation can be improved. In our simple\nexample, we could solve the inconsistencies by merely computing positions\nin a two-dimensional space. This by itself, however, is not a general solution\nwhen dealing with many measurements. In fact, considering that Internet\nlatency measurements may violate the triangle inequality, it is generally\nimpossible to resolve inconsistencies completely. The triangle inequality states\nthat in a geometric space, for any arbitrary three nodes P, Q, and R it must\nalways be true that\nd(P, R) ≤d(P, Q) + d(Q, R).\nThere are various ways to approach these issues. One common approach,\nproposed by Ng and Zhang [2002], is to use N special nodes L1, . . . , LN, known\nas landmarks. Landmarks measure their pairwise latencies ˜d(Li, Lj) and\nsubsequently let a central node compute the coordinates for each landmark.\nTo this end, the central node seeks to minimize the following aggregated error\nfunction:\nN\n∑\ni=1\nN\n∑\nj=i+1\n\u0012 ˜d(Li, Lj) −ˆd(Li, Lj)\n˜d(Li, Lj)\n\u00132\nwhere, again, ˆd(Li, Lj) corresponds to the distance after nodes Li and Lj have\nbeen positioned.\nThe hidden parameter in minimizing the aggregated error function is the\ndimension m. Obviously, we have that N > m, but nothing prevents us from\nchoosing a value for m that is much smaller than N. In that case, a node P\nmeasures its distance to each of the N landmarks and computes its coordinates\nby minimizing\nN\n∑\ni=1\n\u0012 ˜d(Li, P) −ˆd(Li, P)\n˜d(Li, P)\n\u00132\nDS 4.01\n \n\n\n5.7. LOCATION SYSTEMS\n321\nAs it turns out, with well-chosen landmarks, m can be as small as 6 or 7, with\nˆd(P, Q) being no more than a factor 2 different from the actual latency d(P, Q)\nfor arbitrary nodes P and Q [Szymaniak et al., 2004; 2008].\nDecentralized positioning\nAnother way to tackle this problem is to view the collection of nodes as a huge\nsystem in which nodes are attached to each other through springs. In this\ncase, | ˜d(P, Q) −ˆd(P, Q)| indicates to what extent nodes P and Q are displaced\nrelative to the situation in which the system of springs would be at rest. By\nletting each node (slightly) change its position, it can be shown that the system\nwill eventually converge to an optimal organization in which the aggregated\nerror is minimal. This approach is followed in Vivaldi, described in [Dabek\net al., 2004a].\nIn a system with N nodes P1, . . . , PN, Vivaldi aims at minimizing the\nfollowing aggregated error:\nN\n∑\ni=1\nN\n∑\nj=1\n| ˜d(Pi, Pj) −ˆd(Pi, Pj)|2\nwhere ˜d(Pi, Pj) is the measured distance (i.e., latency) between nodes Pi and\nPj, and ˆd(Pi, Pj) the distance computed from the network coordinates of each\nnode. Let ⃗xi denote the coordinates of node Pi. In a situation that each node\nis placed in a geometric space, the force that node Pi exerts on node Pj is\ncomputed as:\n⃗Fij =\n\u0000 ˜d(Pi, Pj) −ˆd(Pi, Pj)\n\u0001 × u(⃗xi −⃗xj)\nwith u(⃗xi −⃗xj) denoting the unit vector in the direction of ⃗xi −⃗xj. In other\nwords, if Fij > 0, node Pi will push Pj away from itself, and will otherwise\npull it toward itself. Node Pi now repeatedly executes the following steps:\n1. Measure the latency ˜dij to node Pj, and also receive Pj’s coordinates ⃗xj.\n2. Compute the error e = ˜d(Pi, Pj) −ˆd(Pi, Pj)\n3. Compute the direction ⃗u = u(⃗xi −⃗xj).\n4. Compute the force vector Fij = e · ⃗u\n5. Adjust own position by moving along the force vector: ⃗xi ←⃗xi + δ · ⃗u.\nA crucial element is the choice of δ: too large and the system will oscillate;\ntoo small and convergence to a stable situation will take a long time. The\ntrick is to have an adaptive value, which is large when the error is large as\nwell, but small when only small adjustments are needed. Details can be found\nin [Dabek et al., 2004a].\n \nDS 4.01\n\n\n322\nCHAPTER 5. COORDINATION\n5.8\nSummary\nStrongly related to communication between processes is the issue of how\nprocesses in distributed systems synchronize. Synchronization is all about\ndoing the right thing at the right time. A problem in distributed systems, and\ncomputer networks in general, is that there is no notion of a globally shared\nclock. In other words, processes on different machines have their own idea of\nwhat time it is.\nThere are various ways to synchronize clocks in a distributed system,\nbut all methods are essentially based on exchanging clock values, while\nconsidering the time it takes to send and receive messages. Variations in\ncommunication delays, and the way those variations are dealt with, largely\ndetermine the accuracy of clock synchronization algorithms.\nKnowing the absolute time is often not necessary. What counts is that\nrelated events at different processes happen in the correct order. Lamport\nshowed that by introducing a notion of logical clocks, it is possible for a\ncollection of processes to reach global agreement on the correct ordering of\nevents. In essence, each event e, such as sending or receiving a message,\nis assigned a globally unique logical timestamp C(e) such that when event\na happened before b, C(a) < C(b). Lamport timestamps can be extended\nto vector timestamps: if C(a) < C(b), we even know that event a causally\npreceded b.\nAn important class of synchronization algorithms is that of distributed\nmutual exclusion. These algorithms ensure that in a distributed collection\nof processes, at most one process at a time has access to a shared resource.\nDistributed mutual exclusion can easily be achieved if we make use of a\ncoordinator that keeps track of whose turn it is. Fully distributed algorithms\nalso exist, but have the drawback that they are generally more susceptible to\ncommunication and process failures.\nSynchronization between processes often requires that one process acts\nas a coordinator. In those cases where the coordinator is not fixed, it is\nnecessary that processes in a distributed computation decide on who is\ngoing to be that coordinator. Such a decision is taken by election algorithms.\nElection algorithms are primarily used in cases where the coordinator can\ncrash. However, they can also be applied for the selection of superpeers in\npeer-to-peer systems.\nThe most important aspect in gossip-based coordination is being able to\nselect another peer randomly from an entire overlay. As it turns out, we can\nimplement such a peer-sampling service using gossiping, by ensuring that the\npartial view is refreshed regularly and randomly. Combining peer sampling\nwith a selective replacement of entries in a partial view allows us to efficiently\nconstruct structured overlay networks.\nParticularly challenging when it comes to coordination is distributed event\nmatching, which sits at the core of publish-subscribe systems. Relatively\nDS 4.01\n \n\n\n5.8. SUMMARY\n323\nsimple is the case when we have a central implementation where matching\nsubscriptions against notifications can be done by essentially doing one-to-one\ncomparisons. However, as soon as we aim at distributing the load, we are\nfaced with the problem of deciding beforehand which node is responsible for\nwhich part of the subscriptions, without knowing what kind of notifications\nto expect. This is particularly problematic for content-based matching, which,\nin the end, requires advanced filtering techniques to route notifications to the\nproper subscribers.\nRelated to these synchronization problems is positioning nodes in a ge-\nometric overlay. The basic idea is to assign each node coordinates from an\nm-dimensional space such that the geometric distance can be used as an\naccurate measure for the latency between two nodes. The method of assigning\ncoordinates strongly resembles the one applied in determining the location\nand time in GPS.\n \nDS 4.01\n\n\n06\nNAMING\n",
      "page_number": 328
    },
    {
      "number": 35,
      "title": "Segment 35 (pages 336-345)",
      "start_page": 336,
      "end_page": 345,
      "detection_method": "topic_boundary",
      "content": "326\nCHAPTER 6. NAMING\nNames play an important role in all computer systems. They are used\nto sharing resources, to uniquely identify entities, to refer to locations, and\nmore. An important issue with naming is that a name can be resolved to the\nentity it refers to. Name resolution thus allows a process to access the named\nentity. To resolve names, it is necessary to implement a naming system. The\ndifference between naming in distributed systems and nondistributed systems\nlies in the way naming systems are implemented.\nIn a distributed system, the implementation of a naming system is itself\noften distributed across multiple machines. How this distribution is done\nplays a key role in the efficiency and scalability of the naming system. In this\nchapter, we concentrate on three different, important ways that names are\nused in distributed systems.\nFirst, we consider so-called flat-naming systems. In such systems, entities\nare referred to by an identifier that, in principle, has no meaning at all. In\naddition, flat names bear no structure, implying that we need special mecha-\nnisms to trace the location of such entities. We discuss various approaches,\nranging from distributed hash tables to hierarchical location services.\nIn practice, humans prefer to use readable names. Such names are of-\nten structured, as is well known from the way Web pages are referred to.\nStructured names allow for a highly systematic way of finding the server\nresponsible for the named entity, as exemplified by the Domain Name System.\nWe discuss the general principles, as well as scalability issues.\nFinally, humans often prefer to describe entities through various charac-\nteristics, leading to a situation in which we need to resolve a description\nusing the attributes assigned to an entity. As we shall see, this type of name\nresolution is notoriously difficult, especially with searching.\nName resolution and routing are closely related to each other. Normally,\nwe look up an address given a name, to subsequently access the named entity\nthrough its address. As an alternative to looking up an address, researchers\nhave been exploring how a name can be directly used to route toward the\nentity, to subsequently return a copy of its associated data. This so-called\nnamed-based routing is gradually maturing as an alternative for a future\nInternet. We discuss it briefly in this chapter.\n6.1\nNames, identifiers, and addresses\nA name in a distributed system is a string of bits or characters that is used to\nrefer to an entity. An entity in a distributed system, can be practically any-\nthing. Typical examples include resources such as hosts, printers, disks, and\nfiles. Other well-known examples of entities that are often explicitly named\nare processes, users, mailboxes, Web pages, graphical windows, messages,\nnetwork connections, and so on.\nDS 4.01\n \n\n\n6.1. NAMES, IDENTIFIERS, AND ADDRESSES\n327\nEntities can be operated on. For example, a resource such as a printer\noffers an interface containing operations for printing a document, requesting\nthe status of a print job, and the like. Furthermore, an entity such as a network\nconnection may provide operations for sending and receiving data, setting\nquality-of-service parameters, requesting the status, and so forth.\nTo operate on an entity, it is necessary to access it, for which we need an\naccess point. An access point is yet another, but special, kind of entity in a\ndistributed system. The name of an access point is called an address. The\naddress of an access point of an entity is also simply called an address of that\nentity.\nAn entity can offer more than one access point.\nAs a comparison, a\ntelephone can be viewed as an access point of a person, whereas the phone\nnumber corresponds to an address. Indeed, many people have several phone\nnumbers, each number corresponding to a point where they can be reached.\nIn a distributed system, a typical example of an access point is a host running\na specific server, with its address formed by the combination of, for example,\nan IP address and port number (i.e., the server’s transport-level address).\nAn entity may change its access points over time. For example, when a\nmobile computer moves to another location, it is often assigned a different\nIP address than the one it had before. Likewise, when a person changes jobs,\nthere is likely a change in phone numbers as well. Similarly, changing your\nInternet Service Provider, often means changing an e-mail address.\nAn address is thus just a special kind of name: it refers to an access point\nof an entity. Because an access point is tightly associated with an entity, it\nwould seem convenient to use the address of an access point as a regular\nname for the associated entity. Nevertheless, this is hardly ever done, as such\nnaming is generally very inflexible and often human unfriendly.\nFor example, it is not uncommon to regularly reorganize a distributed\nsystem so that a specific server is now running on a different host than it did\npreviously. The old machine on which the server used to be running may be\nreassigned to a different server. In other words, an entity may easily change\nan access point, or an access point may be reassigned to a different entity. If\nan address is used to refer to an entity, we will have an invalid reference the\ninstant the access point changes or is reassigned to another entity. Therefore,\nit is much better to let a service be known by a separate name independent of\nthe address of the associated server.\nLikewise, if an entity offers more than one access point, it is not clear which\naddress to use as a reference. For instance, many organizations distribute their\nWeb service across several servers. If we would use the addresses of those\nservers as a reference for the Web service, it is not obvious which address\nshould be chosen as the best one. Again, a much better solution is to have a\nsingle name for the Web service, independent of the addresses of the different\nWeb servers.\n \nDS 4.01\n\n\n328\nCHAPTER 6. NAMING\nThese examples illustrate that a name for an entity that is independent of\nits addresses is often much easier and more flexible to use. Such a name is\ncalled location independent.\nIn addition to addresses, there are other types of names that deserve\nspecial treatment, such as names that are used to uniquely identify an entity.\nA true identifier is a name that has the following properties [Wieringa and\nde Jonge, 1995]:\n1. An identifier refers to at most one entity.\n2. Each entity is referred to by at most one identifier.\n3. An identifier always refers to the same entity (i.e., it is never reused).\nBy using identifiers, it becomes much easier to unambiguously refer to\nan entity. For example, assume two processes each refer to an entity by an\nidentifier. To check if the processes are referring to the same entity, it is\nsufficient to test if the two identifiers are equal. Such a test would not be\nsufficient if the two processes were using regular, nonunique, nonidentifying\nnames. For example, the name “John Smith” cannot be taken as a unique\nreference to just a single person.\nLikewise, if an address can be reassigned to a different entity, we cannot\nuse an address as an identifier. Consider again the use of phone numbers,\nwhich are reasonably stable in the sense that a phone number will often for\nsome time refer to the same person or organization. However, using a phone\nnumber as an identifier will not work, as it can be, and often is, reassigned\nover time. Consequently, Bob’s new bakery may be receiving phone calls for\nAlice’s old antique store for a long time. In this case, it would have been better\nto use a true identifier for Alice instead of her phone number.\nAddresses and identifiers are two important types of names that are each\nused for very different purposes. In many computer systems, addresses and\nidentifiers are represented in machine-readable form only, that is, in the form\nof bit strings. For example, an Ethernet address is essentially a random string\nof 48 bits. Likewise, memory addresses are typically represented as 32-bit or\n64-bit strings.\nAnother important type of name is that which is tailored to be used by\nhumans, also referred to as human-friendly names. In contrast to addresses\nand identifiers, a human-friendly name is generally represented as a character\nstring. These names appear in many different forms. For example, files in\nUnix systems have character-string names that can generally be as long as 255\ncharacters, and which are defined entirely by the user. Similarly, DNS names\nare represented as relatively simple case-insensitive character strings.\nHaving names, identifiers, and addresses brings us to the central theme of\nthis chapter: how do we resolve names and identifiers to addresses? As we\nshall see, there are essentially two approaches. In the first one, we maintain\nDS 4.01\n \n\n\n6.2. FLAT NAMING\n329\na (generally distributed) table of (name, address) pairs. This is the approach\nfollowed by naming systems such as DNS, which we discuss extensively in\nthis chapter. In the second approach, a name is resolved by routing the request\ngradually to the name’s associated address, or even directly to an access point.\nTypically, this is the approach followed in structured peer-to-peer systems,\nbut also in what is known as information-centric networking (which we\nalso discuss later in this chapter). It is interesting to note that in such cases\nthe boundaries between name resolution and message routing are starting\nto blur, as was noted by Shoch [1978] already almost 50 years ago. In fact,\nwe will challenge the need for name-to-address resolution when discussing\nnamed-data networking. To stay in historical perspective, it is then also\ninteresting to note how certain discussions become topical again: in a sense,\nnaming and resolving a name to an address is precisely what is referred to\nas the identifier-location split (see also Ramirez et al. [2014] and Feng et al.\n[2017]).\nIn the following sections, we will consider four different classes of naming\nsystems. First, we will take a look at how identifiers can be resolved to\naddresses. In this case, we will also see an example where name resolution\nis actually indistinguishable from message routing. After that, we consider\nhuman-friendly names and then descriptive names (i.e., entities that are\ndescribed by a collection of names). Finally, we pay attention to named-based\nnetworking.\n6.2\nFlat naming\nAbove, we explained that identifiers are convenient to uniquely represent enti-\nties. Often, identifiers are simply random bit strings, which we conveniently\nrefer to as unstructured, or flat names. An important property of such a name\nis that it does not contain any information whatsoever on how to locate the\naccess point of its associated entity. In the following, we will take a look at\nhow flat names can be resolved, or, equivalently, how we can locate an entity\nwhen given only its identifier.\n6.2.1\nSimple solutions\nWe first consider two simple solutions for locating an entity: broadcasting and\nforwarding pointers. Both solutions are mainly applicable only to local-area\nnetworks. Nevertheless, in that environment, they often do the job well,\nmaking their simplicity particularly attractive.\nBroadcasting\nConsider a distributed system built on a computer network that offers efficient\nbroadcasting facilities.\nTypically, such facilities are offered by local-area\n \nDS 4.01\n\n\n330\nCHAPTER 6. NAMING\nnetworks, in which all machines are connected to a single cable or the logical\nequivalent thereof. Also, local-area wireless networks fall into this category.\nLocating an entity in such an environment is simple: a message containing\nthe identifier of the entity is broadcasted to each machine, and each machine is\nrequested to check whether it has that entity. Only the machines that can offer\nan access point for the entity send a reply message containing the address of\nthat access point.\nThis principle is used in the Internet Address Resolution Protocol (ARP) to\nfind the data-link address of a machine when given only an IP address [Plum-\nmer, 1982]. In essence, a machine broadcasts a packet on the local-network\nasking who is the owner of a given IP address. When the message arrives at\na machine, the receiver checks whether it should listen to the requested IP\naddress. If so, it sends a reply packet containing, for example, its Ethernet\naddress.\nBroadcasting becomes inefficient when the network grows. Not only is\nnetwork bandwidth wasted by request messages, but, more seriously, too\nmany hosts may be interrupted by requests they cannot answer. One possible\nsolution is to switch to multicasting, by which only a restricted group of hosts\nreceives the request. Ethernet networks support data-link level multicasting\ndirectly in hardware.\nMulticasting can also be used to locate entities in point-to-point networks.\nFor example, the Internet supports network-level multicasting by allowing\nhosts to join a specific multicast group. Such groups are identified by a\nmulticast address. When a host sends a message to a multicast address, the\nnetwork layer provides a best-effort service to deliver that message to all\ngroup members. Efficient implementations for multicasting on the Internet\nare discussed in Deering and Cheriton [1990] and Deering et al. [1996].\nA multicast address can be used as a general location service for multiple\nentities. Consider an organization where each employee has his or her own\nmobile computer. When such a computer connects to the locally available\nnetwork, it is dynamically assigned an IP address. In addition, it joins a\nspecific multicast group. When a process wants to locate a computer A, it\nsends a “where is A?” request to the multicast group. If A is connected, it\nresponds with its current IP address.\nAnother way to use a multicast address is to associate it with a replicated\nentity, and to use multicasting to locate the nearest replica. When sending\na request to the multicast address, each replica responds with its current\n(normal) IP address. A crude way to select the nearest replica is to choose the\none whose reply comes in first, but as it turns out, selecting a nearest replica\nis generally not that easy.\nDS 4.01\n \n\n\n6.2. FLAT NAMING\n331\nForwarding pointers\nAnother approach to locating mobile entities is to make use of forwarding\npointers [Fowler, 1985]. The principle is simple: when an entity moves from\nA to B, it leaves behind in A a reference to its new location at B. The main\nadvantage of this approach is its simplicity: as soon as an entity has been\nlocated, for example by using a traditional naming service, a client can look\nup the current address by following the chain of forwarding pointers.\nThere are also drawbacks. First, if no special measures are taken, a chain\nfor a highly mobile entity can become so long that locating that entity is\nprohibitively expensive. Second, all intermediate locations in a chain will have\nto maintain their part of the chain of forwarding pointers as long as needed.\nA third (and related) drawback is the vulnerability to broken links. As soon\nas any forwarding pointer is lost, the entity can no longer be reached. An\nimportant issue is, therefore, to keep chains relatively short, and to ensure\nthat forwarding pointers are robust.\n6.2.2\nHome-based approaches\nA popular approach to supporting mobile entities in large-scale networks is\nto introduce a home location, which keeps track of the current location of\nan entity. Special techniques may be applied to safeguard against network or\nprocess failures. In practice, the home location is often chosen to be the place\nwhere an entity was created.\nThe home-based approach is used as a fall-back mechanism for location\nservices based on forwarding pointers. Another example where the home-\nbased approach is followed is in Mobile IP [Perkins et al., 2011]. Each mobile\nhost uses a fixed IP address. All communication to that IP address is initially\ndirected to the mobile host’s home agent. This home agent is located on the\nlocal-area network corresponding to the network address contained in the\nmobile host’s IP address. In the case of IPv6, it is realized as a network-layer\ncomponent. Whenever the mobile host moves to another network, it requests\na temporary address that it can use for communication. This care-of address\nis registered at the home agent.\nWhen the home agent receives a packet for the mobile host, it looks up the\nhost’s current location. If the host is on the current local network, the packet\nis simply forwarded. Otherwise, it is tunneled to the host’s current location,\nthat is, wrapped as data in an IP packet and sent to the care-of address. At the\nsame time, the sender of the packet is informed of the host’s current location.\nThis principle is shown in Figure 6.1 Note that the IP address is effectively\nused as an identifier for the mobile host.\nAn important aspect is that this whole mechanism is largely hidden for\napplications. In other words, the original IP address associated with the\nmobile host can be used by an application without further ado. Client-side\n \nDS 4.01\n\n\n332\nCHAPTER 6. NAMING\nsoftware that is part of the application-independent communication layer will\nhandle the redirection to the target’s current location. Likewise, at the target’s\nlocation, a message that has been tunneled will be unpacked and handed\nto the application on the mobile host as if it were using its original address.\nIndeed, Mobile IP establishes a high degree of location transparency.\nHost's current location\nClient's\nlocation\n1. Send packet to host at its home\n2. Return address\nof current location\n3. Tunnel packet to\ncurrent location\n4. Send successive packets\nto current location\nHost's home\nlocation\nFigure 6.1: The principle of Mobile IP.\nFigure 6.1 also illustrates a drawback of home-based approaches in large-\nscale networks. To communicate with a mobile entity, a client first has to\ncontact the home, which may be at an entirely different location than the\nentity itself. The result is an increase in communication latency.\nAnother drawback of the home-based approach is the use of a fixed home\nlocation. For one thing, it must be ensured that the home location always\nexists. Otherwise, contacting the entity will become impossible. Problems\nare aggravated when a long-lived entity decides to move permanently to an\nentirely different part of the network than where its home is located. In that\ncase, it would have been better if the home could have moved along with the\nhost.\nA solution to this problem is to register the home at a traditional naming\nservice and to let a client first look up the location of the home. Because the\nhome location can be assumed to be relatively stable, that location can be\neffectively cached after it has been looked up.\nDS 4.01\n \n\n\n6.2. FLAT NAMING\n333\n6.2.3\nDistributed hash tables\nLet us now take a closer look at how to resolve an identifier to the address of\nthe associated entity. We have already mentioned distributed hash tables a\nnumber of times, but have deferred discussion on how they actually work. In\nthis section, we correct this situation by first considering the Chord system as\nan easy-to-explain DHT-based system.\nGeneral mechanism\nMany DHT-based systems have been developed in the past decade, with the\nChord system [Stoica et al., 2003] being a typical representative. Chord uses\nan m-bit identifier space to assign randomly chosen identifiers to nodes as\nwell as keys to specific entities. The latter can be virtually anything: files,\nprocesses, etc. The number m of bits is usually 128 or 160, depending on\nwhich hash function is used. An entity with key k falls under the jurisdiction\nof the node with the smallest identifier id ≥k. This node is referred to as\nthe successor of k and denoted as succ(k). To keep our notation simple and\nconsistent, in the following, we refer to a node with identifier p as node p.\nThe main issue in DHT-based systems is to efficiently resolve a key k to\nthe address of succ(k). A naive approach is to let each node p keep track of\nthe successor succ(p + 1). In that case, whenever a node p receives a request\nto resolve key k, it will simply forward the request to its successor, unless\npred(p) < k ≤p, in which case node p should return its own address to\nthe process that initiated the resolution of key k. A lookup request would,\non average, need to travel half of the ring. Obviously, this approach is not\nscalable. Keeping track of the predecessor and forwarding a request in that\ndirection will cut the expected number of hops by only 50%, which is not by\nfar good enough.\nInstead of this linear approach toward key lookup, each Chord node\nmaintains a finger table containing s ≤m entries. If FTp denotes the finger\ntable of node p, then\nFTp[i] = succ(p + 2i−1)\nPut in other words, the ith entry points to the first node succeeding p by at\nleast 2i−1 units. Note that these references are actually shortcuts to existing\nnodes in the identifier space, where the short-cutted distance from node p\nincreases exponentially as the index in the finger table increases. To look up a\nkey k, node p will then immediately forward the request to node q with index\nj in p’s finger table where:\nq = FTp[j] ≤k < FTp[j + 1]\nor q = FTp[1] when p < k < FTp[1]. (For clarity, we ignore modulo arith-\nmetic.) Note that when the finger-table size s is equal to 1, a Chord lookup\ncorresponds to naively traversing the ring linearly, as we just discussed.\n \nDS 4.01\n\n\n334\nCHAPTER 6. NAMING\nFigure 6.2: Resolving key 26 from node 1 and key 12 from node 28 in a Chord\nsystem.\nTo illustrate this lookup, consider resolving k = 26 from node 1 as shown in\nFigure 6.2. First, node 1 will look up k = 26 in its finger table to discover that\nthis value is larger than FT1[5], meaning that the request will be forwarded\nto node 18 = FT1[5]. Node 18, in turn, will select node 20, as FT18[2] ≤k <\nFT18[3]. Finally, the request is forwarded from node 20 to node 21 and from\nthere to node 28, which is responsible for k = 26. At that point, the address\nof node 28 is returned to node 1 and the key has been resolved. For similar\nreasons, when node 28 is requested to resolve the key k = 12, a request will\nbe routed as shown by the dashed line in Figure 6.2.\nIt should come as no surprise that a lookup will generally require O(log(N))\nsteps, with N being the number of nodes in the system. The result of a simple\nexperiment by which we look up k = p −1 starting at node p, yet initially\nignore p’s predecessor, is shown in Figure 6.3. Note that, by ignoring p’s\npredecessor at the first lookup step, we need to effectively go to a node at\ndistance roughly 2i−1 for decreasing values of i.\nDS 4.01\n \n\n\n6.2. FLAT NAMING\n335\nFigure 6.3: The length of a lookup path as function of the size of a Chord ring.\nIn large distributed systems, the collection of participating nodes can be\nexpected to change all the time. Not only will nodes join and leave voluntarily,\nwe also need to consider the case of nodes failing (and thus effectively leaving\nthe system), to later recover again (at which point they rejoin).\nJoining a DHT-based system such as Chord is relatively simple. Suppose\nnode p wants to join. It simply contacts an arbitrary node in the existing\nsystem and requests a lookup for succ(p + 1).\nOnce this node has been\nidentified, p can insert itself into the ring. Likewise, leaving can be just as\nsimple. Note that nodes also keep track of their predecessor.\nObviously, the complexity comes from keeping the finger tables up-to-date.\nMost important is that for every node q, FTq[1] is correct as this entry refers\nto the next node in the ring, that is, the successor of q + 1. To achieve this goal,\neach node q regularly runs a simple procedure that contacts succ(q + 1) and\nrequests to return pred(succ(q + 1)). If q = pred(succ(q + 1)) then q knows its\ninformation is consistent with that of its successor. Otherwise, if q’s successor\nhas updated its predecessor, then apparently a new node p had entered the\nsystem, with q < p ≤succ(q + 1), so that q will adjust FTq[1] to p. At that\npoint, it will also check whether p has recorded q as its predecessor. If not,\nanother adjustment of FTq[1] is needed.\nSimilarly, to update a finger table, node q simply needs to find the successor\nfor k = q + 2i−1 for each entry i. Again, this can be done by issuing a request\nto resolve succ(k).\nIn Chord, such requests are issued regularly using a\nbackground process.\nLikewise, each node q will regularly check whether its predecessor is alive.\nIf the predecessor has failed, the only thing that q can do is record the fact by\nsetting pred(q) to “unknown.” On the other hand, when node q is updating\nits link to the next known node in the ring, and finds that the predecessor of\nsucc(q + 1) has been set to “unknown,” it will simply notify succ(q + 1) that\n \nDS 4.01\n",
      "page_number": 336
    },
    {
      "number": 36,
      "title": "Segment 36 (pages 346-358)",
      "start_page": 346,
      "end_page": 358,
      "detection_method": "topic_boundary",
      "content": "336\nCHAPTER 6. NAMING\nit suspects it to be the predecessor. By and large, these simple procedures\nensure that a Chord system is generally consistent, only perhaps except for a\nfew nodes. The details can be found in [Stoica et al., 2003].\nNote 6.1 (Advanced: Chord in Python)\nCoding Chord in Python is relatively simple.\nAgain, omitting many of the\nnonessential coding details, the core of the behavior of a Chord node can be\ndescribed as shown in Figure 6.4. The function finger(i) with succNode(i)\ncomputes succ(i) for the given node. All nodes known to a specific Chord node\nare collected in a local set nodeSet, which is sorted by node identifier. The node\nfirst looks up its own position in this set, and that of its right-hand neighbor.\nThe operation inbetween(k,l,u) computes if k ∈[l, u), taking modulo arithmetic\ninto account. Computing inbetween(k,l+1,u+1) is therefore the same as testing\nwhether k ∈(l, u]. We thus see that finger(i) returns the largest existing node\nidentifier, less or equal to i.\n1 class ChordNode:\n2\n3\ndef __succNode(self, key):\n4\nif (key <= self.nodeSet[0] or\n5\nkey > self.nodeSet[len(self.nodeSet)-1]): # key is in segment for which\n6\nreturn self.nodeSet[0]\n# this node is responsible\n7\nfor i in range(1,len(self.nodeSet)):\n8\nif (key <= self.nodeSet[i]):\n# key is in segment for which\n9\nreturn self.nodeSet[i]\n# node (i+1) may be responsible\n10\n11\ndef __finger(self, i):\n12\nreturn self.__succNode((self.nodeID + pow(2,i-1)) % self.MAXPROC) # succ(p+2^(i-1))\n13\n14\ndef __recomputeFingerTable(self):\n15\nself.FT[0]\n= self.nodeSet[(self.nodeInd - 1)%len(self.nodeSet)] # Predecessor\n16\nself.FT[1:] = [self.__finger(i) for i in range(1,self.nBits+1)]\n# Successors\n17\nself.FT.append(self.nodeID)\n# This node\n18\n19\ndef __localSuccNode(self, key):\n20\nif self.__inbetween(key, self.FT[0]+1, self.nodeID+1):\n# key in (pred,self]\n21\nreturn self.nodeID\n# this node is responsible\n22\nelif self.__inbetween(key, self.nodeID+1, self.FT[1]):\n# key in (self,FT[1]]\n23\nreturn self.FT[1]\n# successor responsible\n24\nfor i in range(1, self.nBits+2):\n# go through rest of FT\n25\nif self.__inbetween(key, self.FT[i], self.FT[(i+1)]): # key in [FT[i],FT[i+1])\n26\nreturn self.FT[i]\n# FT[i] is responsible\nFigure 6.4: The essence of a Chord node expressed in Python.\nEvery time a node learns about a new node in the system (or discovers that\none has left), it simply adjusts the local nodeSet and recomputes its finger table\nby calling recomputeFingerTable. The finger table itself is implemented as a local\ntable FT, with FT[0] pointing to the node’s predecessor and FT[nBits+1] to the\nDS 4.01\n \n\n\n6.2. FLAT NAMING\n337\nnode itself, where nBits is the number of bits used for node identifiers and keys.\nThe core of what a node does during a lookup is encoded in localSuccNode(k).\nWhen handed a key k, it will either return itself, its immediate successor FT[1],\nor go through the finger table to search the entry satisfying FT[i] ≤k < FT[i+1].\nThe code does not show what is done with the returned value (which is a node\nidentifier), but typically in an iterative scheme, the referenced node will be contacted\nto continue looking up k, unless the node had returned itself as the one being\nresponsible for k. When deploying a recursive scheme, the node itself contacts the\nreferenced node.\nExploiting network proximity\nOne of the potential problems with systems such as Chord is that requests\nmay be routed erratically across the Internet. For example, assume that\nnode 1 in Figure 6.2 is placed in Amsterdam, The Netherlands; node 18\nin San Diego, California; node 20 in Amsterdam again; and node 21 in\nSan Diego. The result of resolving key 26 will then incur three wide-area\nmessage transfers, which arguably could have been reduced to at most one.\nTo minimize these pathological cases, designing a DHT-based system requires\ntaking the underlying network into account.\nCastro et al. [2002a] distinguish three different ways for making a DHT-\nbased system aware of the underlying network. In the case of topology-based\nassignment of node identifiers the idea is to assign identifiers such that two\nnearby nodes will have identifiers that are also close to each other. It is not\ndifficult to imagine that this approach may impose severe problems in the\ncase of relatively simple systems such as Chord. In the case where node\nidentifiers are sampled from a one-dimensional space, mapping a logical ring\nto the Internet is far from trivial. Moreover, such a mapping can easily expose\ncorrelated failures: nodes on the same enterprise network will have identifiers\nfrom a relatively small interval. When that network becomes unreachable, we\nsuddenly have a gap in the otherwise uniform distribution of identifiers.\nWith proximity routing, nodes maintain a list of alternatives to forward\na request to. For example, instead of having only a single successor, each\nnode in Chord could equally well keep track of r successors. In fact, this\nredundancy can be applied for every entry in a finger table. For node p, FTp[i]\nnormally points to the first node in the range [p + 2i−1, p + 2i −1]. Whenever\nit needs to look up a key k, it tries to prevent “overshooting” by passing the\nrequest to a node q with k < q without knowing for sure if there is a node q′\nwith k ≤q′ < q. For this reason, p passes k to the node known to p with the\nlargest identifier smaller or equal to k.\nHowever, there is no reason why p cannot keep track of r nodes in range\n[p + 2i−1, p + 2i −1]: each node q in this range can be used to route a lookup\nrequest for a key k as long as q ≤k. In that case, when choosing to forward\n \nDS 4.01\n\n\n338\nCHAPTER 6. NAMING\na lookup request, a node can pick one of the r successors that is closest to\nitself while making sure not to “overshoot.” An additional advantage of\nhaving multiple successors for every table entry is that node failures need not\nimmediately lead to failures of lookups, as multiple routes can be explored.\nFinally, in proximity neighbor selection the idea is to optimize routing\ntables such that the nearest node is selected as neighbor. This selection works\nonly when there are more nodes to choose from. In Chord, this is normally\nnot the case. However, in other protocols such as Pastry [Rowstron and\nDruschel, 2001], when a node joins, it receives information about the current\noverlay from multiple other nodes. This information is used by the new node\nto construct a routing table. Obviously, when there are alternative nodes\nto choose from, proximity neighbor selection will allow the joining node to\nchoose the best one.\nNote that it may not be that easy to draw a line between proximity routing\nand proximity neighbor selection. In fact, when Chord is modified to include\nr successors for each finger table entry, proximity neighbor selection resorts\nto identifying the closest r neighbors, which comes very close to proximity\nrouting, as we just explained [Dabek et al., 2004b].\n6.2.4\nHierarchical approaches\nWe now discuss a general approach to a hierarchical location scheme, includ-\ning a number of optimizations. The approach we present is based on the\nGlobe location service [van Steen et al., 1998]. A detailed description can be\nfound in [Ballintijn, 2003]. This is a general-purpose location service that is\nrepresentative of many hierarchical location services proposed for what are\ncalled Personal Communication Systems, of which a general overview can be\nfound in Pitoura and Samaras [2001].\nIn a hierarchical scheme, a network is divided into a collection of domains.\nThere is a single top-level domain that spans the entire network. Each domain\ncan be subdivided into multiple, smaller subdomains. A lowest-level domain,\ncalled a leaf domain, typically corresponds to a local-area network in a\ncomputer network or a cell in a mobile telephone network. The general\nassumption is that within a smaller domain, the average time it takes to\ntransfer a message from one node to another is less than in a large domain.\nEach domain D has an associated directory node dir(D) that keeps track\nof the entities in that domain. This leads to a tree of directory nodes. The\ndirectory node of the top-level domain, called the root (directory) node, knows\nabout all entities. This general organization of a network into domains and\ndirectory nodes is illustrated in Figure 6.5\nTo keep track of the whereabouts of an entity, each entity currently located\nin a domain D is represented by a location record in the directory node\ndir(D). A location record for entity E in the directory node N for a leaf\ndomain D contains the entity’s current address in that domain. In contrast,\nDS 4.01\n \n\n\n6.2. FLAT NAMING\n339\nFigure 6.5: Hierarchical organization of a location service into domains, each\nhaving an associated directory node.\nthe directory node N′ for the next higher-level domain D′ that contains D,\nwill have a location record for E containing only a pointer to N. Likewise,\nthe parent node of N′ will store a location record for E containing only a\npointer to N′. Consequently, the root node will have a location record for each\nentity, where each location record stores a pointer to the directory node of the\nnext lower-level subdomain where that record’s associated entity is currently\nlocated.\nAn entity may have multiple addresses, for example if it is replicated.\nIf an entity has an address in leaf domain D1 and D2 respectively, then the\ndirectory node of the smallest domain containing both D1 and D2, will have\ntwo pointers, one for each subdomain containing an address. This leads to\nthe general organization of the tree as shown in Figure 6.6.\nFigure 6.6: An example of storing information of an entity having two ad-\ndresses in different leaf domains.\n \nDS 4.01\n\n\n340\nCHAPTER 6. NAMING\nLet us now consider how a lookup operation proceeds in such a hierarchi-\ncal location service. As is shown in Figure 6.7, client,nt wishing to locate an\nentity E, issues a lookup request to the directory node of the leaf domain D in\nwhich the client resides. If the directory node does not store a location record\nfor the entity, then the entity is currently not located in D. Consequently, the\nnode forwards the request to its parent. Note that the parent node represents\na larger domain than its child. If the parent also has no location record for E,\nthe lookup request is forwarded to a next level higher, and so on.\nFigure 6.7: Looking up a location in a hierarchically organized location service.\nAs soon as the request reaches a directory node M that stores a location\nrecord for entity E, we know that E is somewhere in the domain dom(M)\nrepresented by node M. In Figure 6.7, M is shown to store a location record\ncontaining a pointer to one of its subdomains. The lookup request is then\nforwarded to the directory node of that subdomain, which in turn forwards\nit further down the tree, until the request finally reaches a leaf node. The\nlocation record stored in the leaf node will contain the address of E in that\nleaf domain. This address can then be returned to the client that initially\nrequested the lookup to take place.\nAn important observation regarding hierarchical location services is that\nthe lookup operation exploits locality. In principle, the entity is searched\nin a gradually increasing ring centered around the requesting client. The\nsearch area is expanded each time the lookup request is forwarded to a next\nhigher-level directory node. In the worst case, the search continues until the\nrequest reaches the root node. Because the root node has a location record\nfor each entity, the request can then simply be forwarded along a downward\npath of pointers to one of the leaf nodes.\nUpdate operations exploit locality similarly, as shown in Figure 6.8. Con-\nsider an entity E that has created a replica in a leaf domain D for which it\nneeds to insert its address. The insertion is initiated at the leaf node dir(D)\nDS 4.01\n \n\n\n6.2. FLAT NAMING\n341\n(a)\n(b)\nFigure 6.8: (a) An insert request is forwarded to the first node that knows\nabout entity E. (b) A chain of forwarding pointers to the leaf node is created.\nof D which immediately forwards the insert request to its parent. The parent\nwill forward the insert request as well, until it reaches a directory node M that\nalready stores a location record for E.\nNode M will then store a pointer in the location record for E, referring to\nthe child node from where the insert request was forwarded. At that point,\nthe child node creates a location record for E, containing a pointer to the next\nlower-level node from where the request came. This process continues until\nwe reach the leaf node from which the insert was initiated. The leaf node,\nfinally, creates a record with the entity’s address in the associated leaf domain.\nInserting an address as just described leads to installing the chain of\npointers in a top-down fashion, starting at the lowest-level directory node\nthat has a location record for entity E. An alternative is to create a location\n \nDS 4.01\n\n\n342\nCHAPTER 6. NAMING\nrecord before passing the insert request to the parent node. In other words,\nthe chain of pointers is constructed from the bottom up. The advantage of\nthe latter is that an address becomes available for lookups as soon as possible.\nConsequently, if a parent node is temporarily unreachable, the address can\nstill be looked up within the domain represented by the current node.\nA delete operation is analogous to an insert operation. When an address\nfor an entity E in a leaf domain D needs to be removed, the directory node\ndir(D) is requested to remove that address from its location record for E. If\nthat location record becomes empty, that is, it contains no other addresses\nfor E in D, the record can be removed. In that case, the parent node of dir(D)\nwants to remove its pointer to dir(D). If the location record for E at the parent\nnow also becomes empty, that record should be removed as well and the next\nhigher-level directory node should be informed. Again, this process continues\nuntil a pointer is removed from a location record that remains nonempty\nafterward or until the root is reached.\nNote 6.2 (Advanced: Scalability issues)\nOne question that immediately comes to mind is whether the hierarchical ap-\nproach just described can actually scale. A seemingly obvious design flaw, is\nthat the root node needs to keep track of all identifiers. However, it is important\nto make a distinction between a logical design and its physical implementation.\nLet us make this distinction here and see how we can actually come to a highly\nscalable implementation of a hierarchical location service.\nTo this end, we assume that each entity is assigned a unique identifier uniform\nat random from a large space of m-bit identifiers, just as in Chord. Furthermore,\nlet us assume that there are a total of N physical hosts {H1, H2, . . . , HN} that can\naccommodate the lookup service, spread across the Internet. Each host is capable\nof running one or more location servers. Typically, two servers running on the\nsame host will represent two nodes at different levels of the logical tree. Let Dk(A)\ndenote the domain at level k that contains address A, with k = 0 denoting the\nroot domain. Likewise, let LSk(E, A) denote the unique location server in Dk(A)\nresponsible for keeping track of the whereabouts of the entity E.\nWe can now make a distinction between a logical root and its implementation.\nLet Dk = {Dk,1, Dk,2, . . . , Dk,Nk} denote the Nk domains at level k, with, obviously,\nN0 = |D0| = 1. For each level k, the set of hosts is partitioned into Nk subsets,\nwith each host running a location server representing exactly one of the domains\nDk,i from Dk. This principle is shown in Figure 6.9.\nIn this example, we consider a simple tree with four levels and nine hosts.\nThere are two level-1 domains, four level-2 domains, and eight leaf domains. We\nalso show a tree for one specific entity E: any contact address associated with E\nwill be stored in one of the eight level-3 location servers, depending, of course,\non the domain to which that address belongs. The root location server for E is\nrunning on host H3. Note that this host also runs a leaf-level location server for E.\nAs explained by van Steen and Ballintijn [2002], by judiciously choosing which\nhost should run a location server for E, we can combine the principle of local\nDS 4.01\n \n\n\n6.2. FLAT NAMING\n343\noperations (which is good for geographical scalability) and full distribution of\nhigher level servers (which is good for size scalability).\nFigure 6.9: The principle of distributing logical location servers over\nphysical hosts.\n6.2.5\nSecure flat naming\nFlat names do not contain any information on how to resolve a name to the\nentity it is referring to. As a consequence, one needs to, in principle, entirely\nrely on the name-resolution process to eventually access the associated entity.\nIf the name-resolution process cannot be trusted, there is no reason to believe\nthat any response can be trusted as well. There are then, essentially, two\napproaches to follow: (1) secure the name-resolution process, or (2) secure the\nidentifier-to-entity association. Let us first take a look at this last option.\nSecuring the identifier-to-entity association is what happens in a so-called\nself-certifying name. As a general principle, we can compute an identifier\nfrom an entity by simply using a hash function:\nid(entity) = hash(data associated with the entity).\nThe crux is, of course, which associated data is used. In the case of nonmodifi-\nable entities, such as read-only files, a client can simply check that it received\nthe correct file by separately computing the hash over the file and comparing\nit to the identifier it used for looking up that file. Of course, to make this\nwork, the client would need to know which hash function to use along with\nperhaps other information.\nIn practice, entities are modified, such as when dealing with mobile objects.\nIn that case, the entity is the current address of the object. What we need\nto know, for sure, is that the returned address is indeed the one that can\nbe used for accessing the object. Likewise, when dealing with modifiable\nfiles, the returned information should allow the client to check that it is\n \nDS 4.01\n\n\n344\nCHAPTER 6. NAMING\nindeed accessing the correct file. Omitting various details, a scheme proposed\nin [Dannewitz et al., 2010] is to have\nid(entity) = public key(entity).\nA client will be returned the associated entity, along with additional data\nthat will allow it to verify that it is indeed dealing with the correct entity.\nFor example, the additional data could contain a signed digest of the entity,\neffectively forming a signature of the entity’s owner. If necessary, the returned\ninformation could also contain a certificate stating the validity of the public\nkey that has been used as an identifier.\nBy securing the identifier-to-entity binding, it becomes less important to\ntrust the name-resolution process. The worse that can now happen is that the\nprocess returns false or no entities. However, whatever it returns, the client\nwill be able to verify its correctness. Trust is now degraded to providing a\ndecent service.\nSecuring the name-resolution process is more involved, yet equally impor-\ntant, if only to guarantee proper reliability (we will return to the relationship\nbetween security and reliability in Chapter 8). For lookup services such as\nthose for mobile IP or hierarchical location services, we need to ensure that\nreturned (intermediate) answers make sense. We will discuss this in the\nnext section when zooming into Secure DNS. As mentioned before, securing\nDHT-based systems has proved to be rather problematic. There are several\nproblems to deal with, yet the most important ones deal with addressing\nSybil and eclipse attacks, as also discussed in Section 9.4.2. The bottom line\nis that robustness for DHT-based systems comes largely from ensuring that a\nnode identifier is genuine: it belongs to exactly one owner, and this fact can\nbe verified. In practice, this means that a centralized authority should be used\nfor handing out identifiers [Urdaneta et al., 2011].\n6.3\nStructured naming\nFlat names are good for machines, but are generally not very convenient\nfor humans to use. As an alternative, naming systems generally support\nstructured names that are composed from simple, human-readable names.\nNot only file naming, but also host naming on the Internet, follows this\napproach. In this section, we concentrate on structured names and the way\nthat these names are resolved to addresses.\n6.3.1\nName spaces\nNames are commonly organized into what is called a name space. Name\nspaces for structured names can be represented as a labeled, directed graph\nwith two types of nodes. A leaf node represents a named entity and has\nDS 4.01\n \n\n\n6.3. STRUCTURED NAMING\n345\nthe property that it has no outgoing edges. A leaf node generally stores\ninformation on the entity it is representing–for example, its address–so that a\nclient can access it. Alternatively, it can store the state of that entity, such as in\nthe case of file systems in which a leaf node actually contains the complete\nfile it is representing. We return to the contents of nodes below.\nIn contrast to a leaf node, a directory node has a number of outgoing\nedges, each labeled with a name, as shown in Figure 6.10 Each node in a\nnaming graph is considered as yet another entity in a distributed system, and,\nin particular, has an associated identifier. A directory node stores a table in\nwhich an outgoing edge is represented as a pair (node identifier, edge label).\nSuch a table is called a directory table.\nFigure 6.10: A general naming graph with a single root node.\nThe naming graph shown in Figure 6.10 has one node, namely n0, which\nhas only outgoing and no incoming edges. Such a node is called the root\n(node) of the naming graph. Although it is possible for a naming graph to\nhave several root nodes, for simplicity, many naming systems have only one.\nEach path in a naming graph can be referred to by the sequence of labels\ncorresponding to the edges in that path, such as N:[label1, label2, ..., labeln],\nwhere N refers to the first node in the path. Such a sequence is called a path\nname. If the first node in a path name is the root of the naming graph, it is\ncalled an absolute path name. Otherwise, it is called a relative path name.\nIt is important to realize that names are always organized in a name space.\nAs a consequence, a name is always defined relative only to a directory node.\nIn this sense, the term “absolute name” is somewhat misleading. Likewise,\nthe difference between global and local names can often be confusing. A\nglobal name is a name that denotes the same entity, no matter where that\nname is used in a system. In other words, a global name is always interpreted\nregarding the same directory node. In contrast, a local name is a name whose\ninterpretation depends on where that name is being used. Put differently,\na local name is essentially a relative name whose directory in which it is\ncontained is (implicitly) known.\n \nDS 4.01\n\n\n346\nCHAPTER 6. NAMING\nThis description of a naming graph comes close to what is implemented\nin many file systems. However, instead of writing the sequence of edge\nlabels to represent a path name, path names in file systems are generally\nrepresented as a single string in which the labels are separated by a special\nseparator character, such as a slash (“/”). This character is also used to indicate\nwhether a path name is absolute. For example, in Figure 6.10 instead of using\nn0:[home, steen, mbox], that is, the actual path name, it is common practice to\nuse its string representation “/home/steen/mbox.” Note also that when there\nare several paths that lead to the same node, that node can be represented by\ndifferent path names. For example, node n5 in Figure 6.10 can be referred to\nby “/home/steen/keys” as well as “/keys.” The string representation of path\nnames can be equally well applied to naming graphs other than those used for\nonly file systems. In Plan 9 [Pike et al., 1995], all resources, such as processes,\nhosts, I/O devices, and network interfaces, are named in the same fashion as\ntraditional files. This approach is analogous to implementing a single naming\ngraph for all resources in a distributed system.\nThere are many ways to organize a name space. As we mentioned, most\nname spaces have only a single root node. Often, a name space is also strictly\nhierarchical, in the sense that the naming graph is organized as a tree. This\nmeans that each node, except the root, has exactly one incoming edge; the\nroot has no incoming edges. As a consequence, each node also has exactly\none associated (absolute) path name.\nThe naming graph shown in Figure 6.10 is an example of directed acyclic\ngraph. In such an organization, a node can have more than one incoming\nedge, but the graph is not permitted to have a cycle. There are also name\nspaces that do not have this restriction.\nNote 6.3 (More information: Implementing the Unix naming graph)\nTo make matters more concrete, consider the way that files in a traditional Unix\nfile system are named. In a naming graph for Unix a directory node represents a\nfile directory, whereas a leaf node represents a file. There is a single root directory,\nrepresented in the naming graph by the root node. The implementation of the\nnaming graph is an integral part of the complete implementation of the file system.\nThat implementation consists of a contiguous series of blocks from a logical disk,\ngenerally divided into a boot block, a superblock, a series of index nodes (called\ninodes), and file data blocks. See also [Silberschatz et al., 2019] or [Tanenbaum\nand Bos, 2022]. This organization is shown in Figure 6.11.\nThe boot block is a special block of data and instructions that are automatically\nloaded into main memory when the system is booted. The boot block is used to\nload the operating system into main memory.\nThe superblock contains information on the entire file system, such as its size,\nwhich blocks on disk are not yet allocated, which inodes are not yet used, and so\non. Inodes are referred to by an index number, starting at number zero, which is\nreserved for the inode representing the root directory.\nDS 4.01\n \n\n\n6.3. STRUCTURED NAMING\n347\nFigure 6.11: The general organization of the Unix file system implementa-\ntion on a logical disk of contiguous disk blocks.\nEach inode contains information on where the data of its associated file can\nbe found on disk. In addition, an inode contains information on its owner, time\nof creation and last modification, protection, and the like. Consequently, when\ngiven the index number of an inode, it is possible to access its associated file.\nEach directory is implemented as a file as well. This is also the case for the root\ndirectory, which contains a mapping between file names and index numbers of\ninodes. It is thus seen that the index number of an inode corresponds to a node\nidentifier in the naming graph.\n6.3.2\nName resolution\nName spaces offer a convenient mechanism for storing and retrieving infor-\nmation about entities through names. More generally, given a path name, it\nshould be possible to look up any information stored in the node referred to\nby that name. The process of looking up a name is called name resolution.\nTo explain how name resolution works, let us consider a path name such\nas N:[label1, label2, ..., labeln]. Resolution of this name starts at node N of the\nnaming graph, where the name label1 is looked up in the directory table, and\nwhich returns the identifier of the node to which label1 refers. Resolution then\ncontinues at the identified node by looking up the name label2 in its directory\ntable, and so on. Assuming that the named path actually exists, resolution\nstops at the last node referred to by labeln, by returning that node’s content.\nNote 6.4 (More information: The Unix naming graph again)\nA name lookup returns the identifier of a node, from where the name resolution\nprocess continues. In particular, it is necessary to access the directory table of\nthe identified node. Consider again a naming graph for a Unix file system. As\nmentioned, a node identifier is implemented as the index number of an inode.\nAccessing a directory table means that first the inode has to be read to find out\nwhere the actual data are stored on disk, and then subsequently to read the data\nblocks containing the directory table.\n \nDS 4.01\n\n\n348\nCHAPTER 6. NAMING\nClosure mechanism\nName resolution can take place only if we know how and where to start. In\nour example, the starting node was given, and we assumed we had access to its\ndirectory table. Knowing how and where to start name resolution is generally\nreferred to as a closure mechanism. Essentially, a closure mechanism deals\nwith selecting the initial node in a name space, from which name resolution\nis to start [Radia, 1989]. What makes closure mechanisms sometimes hard\nto understand is that they are necessarily partly implicit and may be very\ndifferent when comparing them to each other.\nConsider, for example, the string “00312059837784”. Many people will not\nknow what to do with these numbers, unless they are told that the sequence\nis a telephone number. That information is enough to start the resolution\nprocess, in particular, by entering the number at a device for making phone\ncalls. The telephone system subsequently does the rest.\nAs another example, consider the use of global and local names in dis-\ntributed systems. A typical example of a local name is an environment variable.\nFor example, in Unix systems, the variable named HOME is used to refer to\nthe home directory of a user. Each user has their own copy of this variable,\nwhich is initialized to the global, systemwide name corresponding to the\nuser’s home directory. The closure mechanism associated with environment\nvariables ensure that the name of the variable is properly resolved by looking\nit up in a user-specific table.\nNote 6.5 (More information: The Unix naming graph and its closure mechanism)\nName resolution in the naming graph for a Unix file system makes use of the fact\nthat the inode of the root directory is the first inode in the logical disk representing\nthe file system. Its actual byte offset is calculated from the values in other fields\nof the superblock, together with hard-coded information in the operating system\nitself on the internal organization of the superblock.\nTo make this point clear, consider the string representation of a file name,\nsuch as /home/steen/mbox. To resolve this name, it is necessary to already\nhave access to the directory table of the root node of the appropriate naming\ngraph. Being a root node, the node itself cannot have been looked up unless it\nis implemented as a different node in another naming graph, say G. But in that\ncase, it would have been necessary to already have access to the root node of G.\nConsequently, resolving a file name requires that some mechanism has already\nbeen implemented by which the resolution process can start.\nIn this respect, observe how the closure mechanism works in the case of\ncontainers: the chroot command is used to make applications within a specific\ncontainer see a different root than those in another container. In other words, each\ncontainer offers its own naming graph to the contained applications, whereas the\noperating system hosting the containers provides a closure to properly start name\nresolution independent of each other.\nDS 4.01\n \n",
      "page_number": 346
    },
    {
      "number": 37,
      "title": "Segment 37 (pages 359-381)",
      "start_page": 359,
      "end_page": 381,
      "detection_method": "topic_boundary",
      "content": "6.3. STRUCTURED NAMING\n349\nLinking and mounting\nStrongly related to name resolution is the use of aliases. An alias is another\nname for the same entity. An environment variable is an example of an alias.\nIn terms of naming graphs, there are basically two different ways to implement\nan alias. The first approach is to simply allow multiple absolute paths names\nto refer to the same node in a naming graph. This approach is illustrated in\nFigure 6.10, in which the node n5 can be referred to by two different path\nnames. In Unix terminology, both path names /keys and /home/steen/keys\nin Figure 6.12 are called hard links to node n5.\nThe second approach is to represent an entity by a leaf node, say N, but\ninstead of storing the address or state of that entity, the node stores an absolute\npath name. When first resolving an absolute path name that leads to N, name\nresolution will return the path name stored in N, at which point it can continue\nwith resolving that new path name. This principle corresponds to the use of\nsymbolic links in Unix file systems, and is illustrated in Figure 6.12 In this\nexample, the path name /home/steen/keys, which refers to a node containing\nthe absolute path name /keys, is a symbolic link to node n5.\nFigure 6.12: The concept of a symbolic link explained in a naming graph.\nName resolution as described so far takes place completely within a single\nname space. However, name resolution can also be used to merge different\nname spaces transparently. Let us first consider a mounted file system. In\nterms of our naming model, a mounted file system corresponds to letting a\ndirectory node store the identifier of a directory node from a different name\nspace, which we refer to as a foreign name space. The directory node storing\nthe node identifier is called a mount point. Accordingly, the directory node in\nthe foreign name space is called a mounting point. Normally, the mounting\npoint is the root of a name space. During name resolution, the mounting point\nis looked up and resolution proceeds by accessing its directory table.\nThe principle of mounting can be generalized to other name spaces as\nwell. In particular, what is needed is a directory node that acts as a mount\n \nDS 4.01\n\n\n350\nCHAPTER 6. NAMING\npoint and stores all the necessary information for identifying and accessing\nthe mounting point in the foreign name space. This approach is followed in\nmany distributed file systems.\nConsider a collection of name spaces that is distributed across different\nmachines. In particular, each name space is implemented by a different server,\neach possibly running on a separate machine. Consequently, if we want to\nmount a foreign name space NS2 into a name space NS1, it may be necessary\nto communicate over a network with the server of NS2, as that server may be\nrunning on a different machine than the server for NS1. To mount a foreign\nname space in a distributed system requires at least the following information:\n1. The name of an access protocol.\n2. The name of the server.\n3. The name of the mounting point in the foreign name space.\nNote that each of these names needs to be resolved. The name of an access\nprotocol needs to be resolved to the implementation of a protocol by which\ncommunication with the server of the foreign name space can take place. The\nname of the server needs to be resolved to an address where that server can\nbe reached. As the last part in name resolution, the name of the mounting\npoint needs to be resolved to a node identifier in the foreign name space.\nIn nondistributed systems, none of the three points may actually be needed.\nFor example, in Unix there is no access protocol and no server. Also, the name\nof the mounting point is not necessary, as it is simply the root directory of the\nforeign name space.\nThe name of the mounting point is to be resolved by the server of the\nforeign name space. However, we also need name spaces and implementations\nfor the access protocol and the server name. One possibility is to represent\nthe three names listed above as a URL.\nTo make matters concrete, consider a situation in which a user with\na laptop computer wants to access files that are stored on a remote file\nserver. The client machine and the file server are both configured with the\nNetwork File System (NFS). In particular, to allow NFS to work across\nthe Internet, a client can specify exactly which file it wants to access by\nmeans of an NFS URL, for example, nfs://flits.cs.vu.nl/home/steen. This URL\nnames a file (which happens to be a directory) called /home/steen on an NFS\nfile server flits.cs.vu.nl, which can be accessed by a client through the NFS\nprotocol [Haynes, 2015; Noveck and Lever, 2020].\nThe name nfs is a well-known name, in the sense that worldwide agreement\nexists on how to interpret that name. Given that we are dealing with a URL,\nthe name nfs will be resolved to an implementation of the NFS protocol. The\nserver name is resolved to its address using DNS, which is discussed in a\nlater section. As we said, /home/steen is resolved by the server of the foreign\nname space.\nDS 4.01\n \n\n\n6.3. STRUCTURED NAMING\n351\nFigure 6.13: Mounting remote name spaces through a specific protocol.\nThe organization of a file system on the client machine is partly shown in\nFigure 6.13 The root directory has a number of user-defined entries, including\na subdirectory called /remote. This subdirectory is intended to include mount\npoints for foreign name spaces, such as the user’s home directory at VU\nUniversity. To this end, a directory node named /remote/vu is used to store\nthe URL nfs://flits.cs.vu.nl/home/steen.\nNow consider the name /remote/vu/mbox. This name is resolved by\nstarting in the root directory on the client’s machine and continues until the\nnode /remote/vu is reached. The process of name resolution then continues\nby returning the URL nfs://flits.cs.vu.nl/home/steen, in turn leading the client\nmachine to contact the file server flits.cs.vu.nl through the NFS protocol, and\nto subsequently access directory /home/steen. Name resolution can then be\ncontinued by reading the file named mbox in that directory, after which the\nresolution process stops.\nDistributed systems that allow mounting a remote file system as just\ndescribed allow a client machine to, for example, execute the following com-\nmands (assume the client machine is named horton):\nhorton$ cd /remote/vu\nhorton$ ls -l\nwhich subsequently lists the files in the directory /home/steen on the remote\nfile server. The beauty of all this is that the user is spared the details of the\n \nDS 4.01\n\n\n352\nCHAPTER 6. NAMING\nactual access to the remote server. Ideally, only some loss in performance is\nnoticed compared to accessing locally available files. In effect, to the client it\nappears that the name space rooted on the local machine, and the one rooted\nat /home/steen on the remote machine, form a single name space.\nNote 6.6 (More information: Mounting across a network in Unix)\nThere are many ways in which mounting across a network can take place. One\npractical solution and adopted by many small-scale distributed systems, is to\nsimply assign fixed IP addresses to machines and subsequently offer mounting\npoints to clients. Consider the following example. Suppose we have a Unix\nmachine named coltrane using the private address 192.168.2.3, storing a collection\nof music files under the local directory /audio. This directory can be exported as a\nmounting point, and as a consequence can be imported by another machine.\nLet quandar be such a machine, and suppose it wants to mount the collection\nof audio files at the local mount point /home/maarten/Music. The following\ncommand will do the job (assuming the correct privileges have been set):\nquandar$ mount -t nfs 192.168.2.3:/audio /home/maarten/Music\nFrom that moment on, all files available on coltrane in its directory /audio can be\naccessed by quandar in the directory /home/maarten/Music. The beauty of this\nscheme is that once mounted, there is no need to think of remote access anymore\n(until something fails, of course).\n6.3.3\nThe implementation of a name space\nA name space forms the heart of a naming service, that is, a service that\nallows users and processes to add, remove, and look up names. A naming\nservice is implemented by name servers. If a distributed system is restricted\nto a local-area network, it is often feasible to implement a naming service by\nonly a single name server. However, in large-scale distributed systems with\nmany entities, possibly spread across a large geographical area, it is necessary\nto distribute the implementation of a name space over multiple name servers.\nName space distribution\nName spaces for a large-scale, possibly worldwide distributed system, are\nusually organized hierarchically. As before, assume such a name space has\nonly a single root node. To effectively implement such a name space, it\nis convenient to partition it into logical layers. Cheriton and Mann [1989]\ndistinguish the following three layers.\nThe global layer is formed by highest-level nodes, that is, the root node\nand other directory nodes logically close to the root, namely its children.\nNodes in the global layer are often characterized by their stability, in the\nsense that directory tables are rarely changed. Such nodes may represent\nDS 4.01\n \n\n\n6.3. STRUCTURED NAMING\n353\norganizations, or groups of organizations, for which names are stored in the\nname space.\nThe administrational layer is formed by directory nodes that, together, are\nmanaged within a single organization. A characteristic feature of the directory\nnodes in the administrational layer is that they represent groups of entities\nthat belong to the same organization or administrational unit. For example,\nthere may be a directory node for each department in an organization, or a\ndirectory node from which all hosts can be found. Another directory node\nmay be used as the starting point for naming all users, and so forth. The\nnodes in the administrational layer are relatively stable, although changes\ngenerally occur more frequently than to nodes in the global layer.\nFinally, the managerial layer consists of nodes that may typically change\nregularly. For example, nodes representing hosts in the local network belong\nto this layer. For the same reason, the layer includes nodes representing shared\nfiles, such as those for libraries or binaries. Another important class of nodes\nincludes those that represent user-defined directories and files. In contrast\nto the global and administrational layer, the nodes in the managerial layer\nare maintained not only by system administrators, but also by individual end\nusers of a distributed system.\norg\nnet\njp\nus\nnl\noracle\neng\nyale\neng\nai\nlinda\nrobot\nacm\njack\njill\nieee\nkeio\ncs\ncs\npc24\nco\nnec\ncsl\nuva\nvu\ncs\nftp\nwww\nac\ncom\nedu\ngov\nmil\npub\nglobule\nindex.htm\nMana-\ngerial\nlayer\nAdminis-\ntrational\nlayer\nGlobal\nlayer\nZone\nFigure 6.14: An example partitioning of the DNS name space, including\nInternet-accessible files, into three layers.\nTo make matters more concrete, Figure 6.14 shows an example of the\npartitioning of part of the DNS name space, including the names of files within\n \nDS 4.01\n\n\n354\nCHAPTER 6. NAMING\nan organization that can be accessed through the Internet, for example, Web\npages and transferable files. The name space is divided into nonoverlapping\nparts, called zones in DNS [Mockapetris, 1987a;b]. A zone is a part of the\nname space that is implemented by a separate name server. Some of these\nzones are illustrated in Figure 6.14.\nIf we take a look at availability and performance, name servers in each\nlayer have to meet different requirements. High availability is especially\ncritical for name servers in the global layer. If a name server fails, a large\npart of the name space will be unreachable because name resolution cannot\nproceed beyond the failing server.\nPerformance is somewhat subtle. Due to the low rate of change of nodes\nin the global layer, the results of lookup operations generally remain valid for\na long time. Consequently, those results can be effectively cached (i.e., stored\nlocally) by the clients. The next time the same lookup operation is performed,\nthe results can be retrieved from the client’s cache instead of letting the name\nserver return the results. As a result, name servers in the global layer do\nnot have to respond quickly to a single lookup request. On the other hand,\nthroughput may be important, especially in large-scale systems with millions\nof users.\nThe availability and performance requirements for name servers in the\nglobal layer can be met by replicating servers, with client-side caching. Up-\ndates in this layer generally do not have to come into effect immediately,\nmaking it much easier to keep replicas consistent.\nAvailability for a name server in the administrational layer is primarily\nimportant for clients in the same organization as the name server. If the name\nserver fails, many resources within the organization become unreachable\nbecause they cannot be looked up. On the other hand, it may be less important\nthat resources in an organization are temporarily unreachable for users outside\nthat organization.\nRegarding performance, name servers in the administrational layer have\nsimilar characteristics as those in the global layer. Because changes to nodes\ndo not occur all that often, caching lookup results can be highly effective,\nmaking performance less critical. However, in contrast to the global layer,\nthe administrational layer should take care that lookup results are returned\nwithin a few milliseconds, either directly from the server or from the client’s\nlocal cache. Likewise, updates should generally be processed quicker than\nthose of the global layer. For example, it is unacceptable that an account for a\nnew user takes hours to become effective.\nThese requirements can often be met by using relatively powerful machines\nto run name servers. In addition, client-side caching should be applied,\ncombined with replication, for increased overall availability.\nAvailability requirements for name servers at the managerial level are\ngenerally less demanding.\nIn particular, it often suffices to use a single\nDS 4.01\n \n\n\n6.3. STRUCTURED NAMING\n355\nmachine to run name servers at the risk of temporary unavailability. However,\nperformance is crucial: operations must take place immediately. Because\nupdates occur regularly, client-side caching is often less effective.\nIssue\nGlobal\nAdministrational\nManagerial\nGeographical scale\nWorldwide\nOrganization\nDepartment\nNumber of nodes\nFew\nMany\nVast numbers\nResponsiveness to lookups\nSeconds\nMilliseconds\nImmediate\nUpdate propagation\nLazy\nImmediate\nImmediate\nNumber of replicas\nMany\nNone or few\nNone\nClient-side caching\nYes\nYes\nSometimes\nFigure 6.15: A comparison between name servers for implementing nodes\nfrom a large-scale name space partitioned into a global layer, an administra-\ntional layer, and a managerial layer.\nA comparison between name servers at different layers is shown in Fig-\nure 6.15. In distributed systems, name servers in the global and administra-\ntional layer are the most difficult to implement. Difficulties are caused by\nreplication and caching, which are needed for availability and performance,\nbut which also introduce consistency problems. Some of the problems are\naggravated by the fact that caches and replicas are spread across a wide-area\nnetwork, which may introduce long communication delays during lookups.\nImplementation of name resolution\nThe distribution of a name space across multiple name servers affects the\nimplementation of name resolution. To explain the implementation of name\nresolution in large-scale name services, we assume for the moment that name\nservers are not replicated and that no client-side caches are used.\nEach\nclient has access to a local name resolver, which is responsible for ensuring\nthat the name resolution process is carried out. Referring to Figure 6.14,\nassume the (absolute) path name root:[nl, vu, cs, ftp, pub, globe, index.html] is to\nbe resolved. Using a URL notation, this path name would correspond to\nftp://ftp.cs.vu.nl/pub/globe/index.html. There are now two ways to imple-\nment name resolution.\nIn iterative name resolution, a name resolver hands over the complete\nname to the root name server. It is assumed that the address where the root\nserver can be contacted is well known. The root server will resolve the path\nname as far as it can, and return the result to the client. In our example, the\nroot server can resolve only the label nl, for which it will return the address of\nthe associated name server.\nAt that point, the client passes the remaining path name (i.e., nl:[vu, cs, ftp,\npub, globe, index.html]) to that name server. This server can resolve only the\n \nDS 4.01\n\n\n356\nCHAPTER 6. NAMING\nlabel vu, and returns the address of the associated name server, along with\nthe remaining path name vu:[cs, ftp, pub, globe, index.html].\nThe client’s name resolver will then contact this next name server, which\nresponds by resolving the label cs, and subsequently also ftp, returning the\naddress of the FTP server along with the path name ftp:[pub, globe, index.html].\nThe client then contacts the FTP server, requesting it to resolve the last part of\nthe original path name. The FTP server will subsequently resolve the labels\npub, globe, and index.html, and transfer the requested file (in this case using\nFTP). This process of iterative name resolution is shown in Figure 6.16. (The\nnotation #[cs] is used to indicate the address of the server responsible for\nhandling the node referred to by [cs].)\nFigure 6.16: The principle of iterative name resolution.\nIn practice, the last step, namely contacting the FTP server and requesting\nit to transfer the file with path name ftp:[pub, globe, index.html], is carried out\nseparately by the client process. In other words, the client would normally\nhand only the path name root:[nl, vu, cs, ftp] to the name resolver, from which\nit would expect the address where it can contact the FTP server, as is also\nshown in Figure 6.16\nAn alternative to iterative name resolution is to use recursion during name\nresolution. Instead of returning each intermediate result to the client’s name\nresolver, with recursive name resolution, a name server passes the result to\nthe next name server it finds. So, for example, when the root name server finds\nthe address of the name server implementing the node named nl, it requests\nthat name server to resolve the path name nl:[vu, cs, ftp, pub, globe, index.html].\nUsing recursive name resolution as well, this next server will resolve the\ncomplete path and eventually return the file index.html to the root server,\nwhich, in turn, will pass that file to the client’s name resolver.\nDS 4.01\n \n\n\n6.3. STRUCTURED NAMING\n357\nRecursive name resolution is shown in Figure 6.17. As in iterative name\nresolution, the last step (contacting the FTP server and asking it to transfer\nthe indicated file) is generally carried out as a separate process by the client.\nFigure 6.17: The principle of recursive name resolution.\nThe main drawback of recursive name resolution is that it puts a higher\nperformance demand on each name server. Basically, a name server is required\nto handle the complete resolution of a path name, although it may do so in\ncooperation with other name servers. This additional burden is generally\nso high that name servers in the global layer of a name space support only\niterative name resolution.\nThere are two important advantages to recursive name resolution. The first\nadvantage is that caching results is more effective compared to iterative name\nresolution. The second advantage is that communication costs may be reduced.\nTo explain these advantages, assume that a client’s name resolver will accept\npath names referring only to nodes in the global or administrational layer\nof the name space. To resolve that part of a path name that corresponds to\nnodes in the managerial layer, a client will separately contact the name server\nreturned by its name resolver, as we discussed above.\nRecursive name resolution allows each name server to gradually learn\nthe address of each name server responsible for implementing lower-level\nnodes. As a result, caching can be effectively used to enhance performance.\nFor example, when the root server is requested to resolve the path name\nroot:[nl, vu, cs, ftp], it will eventually get the address of the name server imple-\nmenting the node referred to by that path name. To come to that point, the\nname server for the nl node has to look up the address of the name server for\nthe vu node, whereas the latter has to look up the address of the name server\nhandling the cs node.\nBecause changes to nodes in the global and administrational layer do not\noccur often, the root name server can effectively cache the returned address.\n \nDS 4.01\n\n\n358\nCHAPTER 6. NAMING\nMoreover, because the address is also returned, by recursion, to the name\nserver responsible for implementing the vu node and to the one implementing\nthe nl node, it might as well be cached at those servers too.\nLikewise, the results of intermediate name lookups can also be returned\nand cached. For example, the server for the nl node will have to look up the\naddress of the vu node server. That address can be returned to the root server\nwhen the nl server returns the result of the original name lookup. A complete\noverview of the resolution process, and the results that can be cached by each\nname server, is shown in Figure 6.18.\nServer\nShould\nLooks up\nPasses to\nReceives\nReturns\nfor node\nresolve\nchild\nand caches\nto requester\ncs\n[ftp]\n#[ftp]\n—\n—\n#[ftp]\nvu\n[cs, ftp]\n#[cs]\n[ftp]\n#[ftp]\n#[cs]\n#[cs, ftp]\nnl\n[vu, cs, ftp]\n#[vu]\n[cs, ftp]\n#[cs]\n#[vu]\n#[cs, ftp]\n#[vu, cs]\n#[vu, cs, ftp]\nroot\n[nl, vu, cs, ftp] #[nl]\n[vu, cs, ftp]\n#[vu]\n#[nl]\n#[vu, cs]\n#[nl, vu]\n#[vu, cs, ftp]\n#[nl, vu, cs]\n#[nl, vu, cs, ftp]\nFigure 6.18: Recursive name resolution of [nl, vu, cs, ftp]. Name servers cache\nintermediate results for subsequent lookups.\nThe main benefit of this approach is that, eventually, lookup operations\ncan be handled quite efficiently. For example, suppose that another client later\nrequests resolution of the path name root:[nl, vu, cs, flits]. This name is passed\nto the root, which can immediately forward it to the name server for the cs\nnode, and request it to resolve the remaining path name cs:[flits].\nWith iterative name resolution, caching is necessarily restricted to the\nclient’s name resolver. Consequently, if a client A requests the resolution of a\nname, and another client B later requests that same name to be resolved, name\nresolution will have to pass through the same name servers as was done for\nclient A. As a compromise, many organizations use a local, intermediate name\nserver that is shared by all clients. This local name server handles all naming\nrequests and caches results. Such an intermediate server is also convenient\nfrom a management point of view. For example, only that server needs to\nknow where the root name server is located; other machines do not require\nthis information.\nThe second advantage of recursive name resolution is that it is often\ncheaper regarding communication. Again, consider the resolution of the path\nname root:[nl, vu, cs, ftp] and assume the client is located in San Francisco.\nAssuming that the client knows the address of the server for the nl node,\nDS 4.01\n \n\n\n6.3. STRUCTURED NAMING\n359\nwith recursive name resolution, communication follows the route from the\nclient’s host in San Francisco to the nl server in The Netherlands, shown\nas R1 in Figure 6.19 From there on, communication is subsequently needed\nbetween the nl server and the name server of VU University on the campus in\nAmsterdam, The Netherlands. This communication is shown as R2. Finally,\ncommunication is needed between the vu server and the name server in the\nComputer Science Department, shown as R3. The route for the reply is the\nsame, but in the opposite direction. Clearly, communication costs are dictated\nby the message exchange between the client’s host and the nl server.\nIn contrast, with iterative name resolution, the client’s host has to commu-\nnicate separately with the nl server, the vu server, and the cs server, of which\nthe total costs may be roughly three times that of recursive name resolution.\nThe arrows in Figure 6.19 labeled I1, I2, and I3 show the communication path\nfor iterative name resolution.\nFigure 6.19: The comparison between recursive and iterative name resolution\nregarding communication costs.\n6.3.4\nExample: The Domain Name System\nOne of the largest distributed naming services in use today is the Internet\nDomain Name System (DNS). DNS is primarily used for looking up IP\naddresses of hosts and mail servers. In the following pages, we concentrate\non the organization of the DNS name space and the information stored in its\nnodes. Also, we take a closer look at the actual implementation of DNS. More\ninformation can be found in [Mockapetris, 1987a;b] and [Liu and Albitz, 2006].\nAn excellent tutorial on DNS is provided by van der Toorn et al. [2022].\nThe DNS name space\nThe DNS name space is hierarchically organized as a rooted tree. A label is\na case-insensitive string made up of alphanumeric characters. A label has\na maximum length of 63 characters; the length of a complete path name is\n \nDS 4.01\n\n\n360\nCHAPTER 6. NAMING\nrestricted to 255 characters. The string representation of a path name consists\nof listing its labels, starting with the rightmost one, and separating the labels\nby a dot (“.”). The root is represented by a dot. So, for example, the path\nname root:[nl, vu, cs, flits], is represented by the string “flits.cs.vu.nl.”, which\nincludes the rightmost dot to indicate the root node. We generally omit this\ndot for readability.\nBecause each node in the DNS name space has exactly one incoming edge\n(except for the root node, which has no incoming edges), the label attached to\na node’s incoming edge is also used as the name for that node. A subtree is\ncalled a domain; a path name to its root node is called a domain name. Note\nthat, just like a path name, a domain name can be either absolute or relative.\nThe contents of a node is formed by a collection of resource records.\nThere are different types of resource records. The major ones are shown in\nFigure 6.20.\nType\nRefers to\nDescription\nSOA\nZone\nHolds info on the represented zone\nA\nHost\nIP addr. of host this node represents\nMX\nDomain\nMail server to handle mail for this node\nSRV\nDomain\nServer handling a specific service\nNS\nZone\nName server for the represented zone\nCNAME\nNode\nSymbolic link\nPTR\nHost\nCanonical name of a host\nHINFO\nHost\nInfo on this host\nTXT\nAny kind\nAny info considered useful\nFigure 6.20: The most important types of resource records forming the con-\ntents of nodes in the DNS name space.\nA node in the DNS name space will often represent several entities at the\nsame time. For example, a domain name such as vu.nl is used to represent\na domain and a zone. In this case, the domain is implemented by means of\nseveral (nonoverlapping) zones.\nAn SOA (start of authority) resource record contains information such as\nan e-mail address of the system administrator responsible for the represented\nzone, the name of the host where data on the zone can be fetched, and so on.\nAn A (address) record, represents a particular host on the Internet. The A\nrecord contains an IP address for that host to allow communication. If a host\nhas several IP addresses, as is the case with multi-homed machines, the node\nwill contain an A record for each address.\nAnother type of record is the MX (mail exchange) record, which is like a\nsymbolic link to a node representing a mail server. For example, the node\nrepresenting the domain cs.vu.nl has an MX record that used to contain the\nDS 4.01\n \n\n\n6.3. STRUCTURED NAMING\n361\nname zephyr.cs.vu.nl which refers to a mail server. That server would handle\nall incoming mail addressed to users in the cs.vu.nl domain. There may be\nseveral MX records stored in a node.\nRelated to MX records are SRV records, which contain the name of a server\nfor a specific service. The service itself is identified through a name along with\nthe name of a protocol. For example, the Web server in the cs.vu.nl domain\ncould be named using an SRV record, such as website.cs.vu.nl. This record\nwould then refer to the actual name of the server (which is soling.cs.vu.nl).\nAn important advantage of SRV records is that clients need no longer know\nthe DNS name of the host providing a specific service. Instead, only service\nnames need to be standardized, after which the providing host can be looked\nup.\nNodes that represent a zone, contain one or more NS (name server) records.\nLike MX records, an NS record contains the name of a name server that\nimplements the zone represented by the node. In principle, each node in\nthe name space can store an NS record referring to the name server that\nimplements it. However, as we discuss below, the implementation of the\nDNS name space is such that only nodes representing zones need to store NS\nrecords.\nDNS distinguishes aliases from what are called canonical names. Each\nhost is assumed to have a canonical, or primary name. An alias is implemented\nusing a node storing a CNAME record containing the canonical name of a host.\nThe name of the node storing such a record is thus the same as a symbolic\nlink, as was shown in Figure 6.12.\nDNS maintains an inverse mapping of IP addresses to host names using\nPTR (pointer) records. To accommodate the lookups of host names when\ngiven only an IP address, DNS maintains a domain named in-addr.arpa, which\ncontains nodes that represent Internet hosts and which are named by the IP\naddress of the represented host. For example, host www.cs.vu.nl once had\nIP address 130.37.20.20. DNS creates a node named 20.20.37.130.in-addr.arpa,\nwhich is used to store the canonical name of that host (which happens to be\nsoling.cs.vu.nl in a PTR record).\nFinally, an HINFO (host info) record is used to store additional information\non a host, such as its machine type and operating system. Similarly, TXT\nrecords are used for any other kind of data that a user finds useful to store\nabout the entity represented by the node.\nDNS implementation\nIn essence, the DNS name space can be divided into a global layer and an\nadministrational layer, as shown in Figure 6.14. The managerial layer, which\nis generally formed by local file systems, is formally not part of DNS, and is\ntherefore also not managed by it.\n \nDS 4.01\n\n\n362\nCHAPTER 6. NAMING\nEach zone is implemented by a name server, which is virtually always\nreplicated for availability. Updates for a zone are normally handled by the\nprimary name server. Updates take place by modifying the DNS database\nlocal to the primary server. Secondary name servers do not access the database\ndirectly, but, instead, request the primary server to transfer its content. The\nlatter is called a zone transfer in DNS terminology.\nA DNS database is implemented as a (small) collection of files, of which\nthe most important one contains all the resource records for all the nodes in a\nparticular zone. This approach allows nodes to be simply identified through\ntheir domain name, by which the notion of a node identifier reduces to an\n(implicit) index into a file.\nNote 6.7 (More information: An example DNS database)\nTo better understand these implementation issues, Figure 6.21 shows a small part\nof the file that contains most of the information for a previous organization of the\ncs.vu.nl domain. Note that we have deliberately chosen an outdated version for\nsecurity reasons. The file has been edited for readability. It shows the content\nof several nodes that used to be part of the cs.vu.nl domain, where each node is\nidentified through its domain name.\nIn this example, the node cs.vu.nl represents the domain as well as the zone.\nIts SOA resource record contains specific information on the validity of this file,\nwhich will not concern us further. There are four name servers for this zone,\nreferred to by their canonical host names in the NS records. The TXT record is\nused to give some additional information on this zone, but cannot be automatically\nprocessed by any name server. Furthermore, there is a single mail server that can\nhandle incoming mail addressed to users in this domain. The number preceding\nthe name of a mail server specifies a selection priority. A sending mail server\nshould always first attempt to contact the mail server with the lowest number.\nThe host star.cs.vu.nl operates as a name server for this zone. Name servers\nare critical to any naming service. What can be seen about this name server\nis that additional robustness has been created by giving two separate network\ninterfaces, each represented by a separate A resource record. In this way, the\neffects of a broken network link can be somewhat alleviated, as the server will\nremain accessible.\nThe next four lines (for zephyr.cs.vu.nl) give the necessary information about\none of the department’s mail servers. Note that this mail server is also backed up\nby another mail server, whose path is tornado.cs.vu.nl.\nThe next six lines show a typical configuration in which the department’s\nWeb server, as well as the department’s FTP server, are implemented by a single\nmachine, called soling.cs.vu.nl. By executing both servers on the same machine\n(and essentially using that machine only for Internet services and not anything\nelse), system management becomes easier. For example, both servers will have\nthe same view of the file system, and for efficiency, part of the file system may be\nimplemented on soling.cs.vu.nl. This approach is often applied in the case of Web\nand FTP services.\nDS 4.01\n \n\n\n6.3. STRUCTURED NAMING\n363\nThe following two lines show information on one of the department’s server\nclusters at that time. In this case, it tells us that the address 130.37.198.0 is\nassociated with the host name vucs-das1.cs.vu.nl.\nName\nRecord type\nRecord value\ncs.vu.nl.\nSOA\nstar.cs.vu.nl. hostmaster.cs.vu.nl.\n2005092900 7200 3600 2419200 3600\ncs.vu.nl.\nTXT\n“VU University - Computer Science”\ncs.vu.nl.\nMX\n1 mail.few.vu.nl.\ncs.vu.nl.\nNS\nns.vu.nl.\ncs.vu.nl.\nNS\ntop.cs.vu.nl.\ncs.vu.nl.\nNS\nsolo.cs.vu.nl.\ncs.vu.nl.\nNS\nstar.cs.vu.nl.\nstar.cs.vu.nl.\nA\n130.37.24.6\nstar.cs.vu.nl.\nA\n192.31.231.42\nstar.cs.vu.nl.\nMX\n1 star.cs.vu.nl.\nstar.cs.vu.nl.\nMX\n666 zephyr.cs.vu.nl.\nstar.cs.vu.nl.\nHINFO\n“Sun” “Unix”\nzephyr.cs.vu.nl.\nA\n130.37.20.10\nzephyr.cs.vu.nl.\nMX\n1 zephyr.cs.vu.nl.\nzephyr.cs.vu.nl.\nMX\n2 tornado.cs.vu.nl.\nzephyr.cs.vu.nl.\nHINFO\n“Sun” “Unix”\nftp.cs.vu.nl.\nCNAME\nsoling.cs.vu.nl.\nwww.cs.vu.nl.\nCNAME\nsoling.cs.vu.nl.\nsoling.cs.vu.nl.\nA\n130.37.20.20\nsoling.cs.vu.nl.\nMX\n1 soling.cs.vu.nl.\nsoling.cs.vu.nl.\nMX\n666 zephyr.cs.vu.nl.\nsoling.cs.vu.nl.\nHINFO\n“Sun” “Unix”\nvucs-das1.cs.vu.nl.\nPTR\n0.198.37.130.in-addr.arpa.\nvucs-das1.cs.vu.nl.\nA\n130.37.198.0\ninkt.cs.vu.nl.\nHINFO\n“OCE” “Proprietary”\ninkt.cs.vu.nl.\nA\n192.168.4.3\npen.cs.vu.nl.\nHINFO\n“OCE” “Proprietary”\npen.cs.vu.nl.\nA\n192.168.4.2\nlocalhost.cs.vu.nl.\nA\n127.0.0.1\nFigure 6.21: An excerpt from an (old) DNS database for the zone cs.vu.nl.\nThe next four lines show information on two major printers connected to the\nlocal network. Note that addresses in the range 192.168.0.0 to 192.168.255.255\nare private: they can be accessed only from inside the local network and are\ninaccessible from an arbitrary Internet host.\nBecause the cs.vu.nl domain was implemented as a single zone, Figure 6.21\ndoes not include references to other zones.\nThe way to refer to nodes in a\nsubdomain that are implemented in a different zone is shown in Figure 6.22.\nWhat needs to be done is to specify a name server for the subdomain by simply\n \nDS 4.01\n\n\n364\nCHAPTER 6. NAMING\ngiving its domain name and IP address. When resolving a name for a node that\nlies in the cs.vu.nl domain, name resolution will continue at a certain point by\nreading the DNS database stored by the name server for the cs.vu.nl domain.\nName\nRecord type\nRecord value\ncs.vu.nl.\nNS\nsolo.cs.vu.nl.\ncs.vu.nl.\nNS\nstar.cs.vu.nl.\ncs.vu.nl.\nNS\nns.vu.nl.\ncs.vu.nl.\nNS\ntop.cs.vu.nl.\nns.vu.nl.\nA\n130.37.129.4\ntop.cs.vu.nl.\nA\n130.37.20.4\nsolo.cs.vu.nl.\nA\n130.37.20.5\nstar.cs.vu.nl.\nA\n130.37.24.6\nstar.cs.vu.nl.\nA\n192.31.231.42\nFigure 6.22: Part of the description for the vu.nl domain which contains\nthe cs.vu.nl domain.\nModern DNS\nFollowing the terminology from van der Toorn et al. [2022], we speak of\nthe modern DNS to refer to the current-day implementation of DNS. There\nare a number of changes to the DNS implementation that are important for\nunderstanding its behavior. The presentation so far, roughly assumes that that\napplications contact a local DNS resolver, and that this resolver subsequently\ncontacts various name servers, as shown in Figure 6.23(a). The bounding\nboxes with dashed lines represent the borders of the organization where the\nclients, resolver, and name servers belong to, respectively. In the traditional\nsetup, the clients contact the local DNS resolver, which can be thought of as\nconnected to the same local network, or the one from the local ISP. The name\nservers each belong to a different organization.\nIn the modern DNS, we see three phenomena. First, many organizations\nwill make use of an external DNS resolver. We explained in Section 3.4.4 that\nservices like CDNs use the client’s address to select a nearby server when\nresolving a URL. However, the address that the CDN service gets is not that\nof the client, but of the DNS resolver that the client uses. Clearly, if the DNS\nresolver is not close to the client, then a CDN may make a poor decision on\nselecting a nearby server. This problem can be mitigated if the local DNS\nresolver allows the client (or the requesting host) to also specify its own IP\naddress. In that case, a CDN DNS name server can use that address to select\nthe best server to eventually redirect the client to [Contavalli et al., 2016].\nSecond, is that many clients, and notably browsers, may actually bypass\nany configuration of their local organization and directly contact the DNS\nDS 4.01\n \n\n\n6.3. STRUCTURED NAMING\n365\n(a)\n(b)\nFigure 6.23: (a) The traditional organization of the implementation of DNS and\n(b) the modern organization that has already been partly realized (adapted\nfrom [van der Toorn et al., 2022]).\nresolver of their own choice. Of course, there is nothing wrong with this, yet\nit makes it much harder to measure what is happening with DNS requests\nfrom an organization’s perspective, especially if the client-to-resolver com-\nmunication is also encrypted. In addition, the drawback of using an external\nresolver for redirecting requests to a nearby server also holds in this case.\nThe third phenomenon is that increasingly fewer organizations are running\ntheir own DNS servers. Instead, the name-resolution process is outsourced to\nthird parties. In a sense, this means that the DNS is becoming increasingly\nless decentralized [Moura et al., 2020]. It is yet unclear what the consequences\nare of this centralization, but considering the many discussions on the role\nof the Big Tech companies, striving for spreading the DNS across multiple\norganizations may not be a bad idea.\nAs with so many (public) naming and lookup services, we need to provide\nthe means for checking the validity of an answer. DNS is in the sense no\nexception. Moreover, being one of the most used and even necessary services\non the Internet, securing the DNS is crucial. At the same time, when we\nrealize that the DNS is becoming more centralized and end users are actually\nsubmitting a lot of information on how they make use of the Internet using\ntheir DNS queries, we also need to consider protecting the privacy of end\nusers. Let us look briefly into these two subjects. A systematic overview of\nsecurity and privacy issues in DNS is provided by Khormali et al. [2021].\n \nDS 4.01\n\n\n366\nCHAPTER 6. NAMING\nSecuring DNS responses\nDiscussions on facilitating the validation of DNS\nresponses started already in the 1990s. At present, we see that in a vast major-\nity of countries worldwide, all top-level domains support what is known as\nDNSSEC, i.e., DNS Security extensions. DNSSEC is, in principle, a straight-\nforward system by which resource records are signed by the organization\nowning a zone. To this end, DNS needed to be extended in two ways. The\nfirst, obvious one, is that new fields needed to be added to the set of records\nfor containing signatures and keys. Second, and quite important, is that larger\nqueries and responses had to be supported than what traditional UDP mes-\nsages would allow. The original DNS completely relied on fitting everything\ninto 512-byte packets. Using so-called extension mechanisms for DNS allows\nfor the acceptance of DNS queries and responses beyond 512 bytes [Damas\net al., 2013].\nThe basic idea is simple. First, resource records of the same type are\ngrouped into a separate set, which is then subsequently signed. So, for\nexample, a zone will contain a separate set with all its IPv4 addresses, a\nseparate set for all its IPv6 addresses, its name servers, and so on. The public\nkey associated with the secret key used for signing a set of resource records\nis also added to a zone. At that point, any client receiving a set of resource\nrecords can check that set against the provided signature. To recall, this means\nthat the set of resource records is hashed, and the hashed value is encrypted\nwith the secret key of the zone owner. When receiving the set, the client\nhashes it as well, and decrypts the version that was also in the response.\nWhen the two match, the client will believe the returned records are valid.\nOf course, the client will need to trust that the provided public key, known\nas a zone-signing key is valid. To this end, all the provided zone-signing keys\nare grouped again into a separate set, which is subsequently signed using yet\nanother secret key. The associated public key is known as the key-signing\nkey. What happens is that a hash of the key-signing key is stored, and signed\nby the parent domain. The parent domain, of course, signs this hash with\nthe secret key associated with its zone-signing key, which, in turn, is signed\nwith the secret key associated with the parent’s key-signing key. In this way,\nwe establish a trust chain all the way to the root. This scheme of signing in\nDNSSEC is shown in Figure 6.24.\nWe show part of the zone information available at three different levels,\nincluding the root level (level 0). For the lowest level, we show only one specific\nset of resource records RR. The zone at each level k includes information\nconcerning which hash function HZk is used for signing records, or HKk for\nsigning a zone-signing key. We use the notation SKZk to denote the secret key\nassociated with the (public) key ZSKk and, likewise, SKKk for the secret key\nassociated with the key-signing key KSKk. Knowing HZ2 and ZSK2 will allow\na client to verify the signature SKZ2(HZ2(RR)) by checking\nZSK2(SKZ2(HZ2(RR))) ?= HZ2(RR)\nDS 4.01\n \n\n\n6.3. STRUCTURED NAMING\n367\nFigure 6.24: The relation between various resource records and keys in\nDNSSEC across three levels.\nIf the client wants to be sure that the public zone-signing key ZSK2 is in order,\nit needs to get information from the parent zone, i.e., the zone at level 1. At\nthat level, the zone owner has stored a signed hash value SKZ1(HZ1(KSK2)),\neffectively allowing anyone to validate the key-signing key KSK2 and the use\nof its associated secret key SKK2 that was used for signing ZSK2. Obviously,\nthe parent zone would never store such information without having going\nthrough a process of ensuring that its child zone is indeed properly owned\nand operating as it should.\nProtecting DNS users\nIn general, one can state that information stored in\nDNS is public: it can be viewed as a huge open database that allows us\nto resolve human-friendly names to addresses and other data. However,\nwhat a client is asking from the DNS is, in principle, no one else’s business.\nThat means that queries should be kept confidential. There are roughly two\nincreasingly often supported protection mechanisms deployed in the modern\nDNS.\nFirst, systems today allow applications to set up a secure channel to a\nremote DNS resolver through TLS, mostly by that application’s local resolver,\nwhich runs on the local operating system. We discuss TLS in Section 9.3.2. In\neffect, having DNS over TLS prevents a third party from discovering to which\nWebsites an application is actually referring. Obviously, both the local DNS\nresolver and the remote resolver need to be trusted not to leak information,\nand are sufficiently protected against attacks. Note that facilitating DNS over\nTLS requires that a resolver uses a specific port (in this case, port 853).\nSecond, many modern browsers support issuing DNS queries over HTTPS.\nIn this case, the browser is configured to directly access a remote DNS resolver\nthat supports DNS over HTTPS. As HTTPS runs over TLS, this mechanism\nessentially offers the same protection as DNS over TLS. A major difference, of\ncourse, is that DNS queries are now completely handled out of the control of\nlocal administrators. This also means that local policies concerning allowing\nor denying access to certain sites are bypassed, for better or for worse.\nUsing DNS over either TLS or HTTPS is already an improvement over\n \nDS 4.01\n\n\n368\nCHAPTER 6. NAMING\nhaving no confidentiality concerning DNS queries, yet it may not be suffi-\ncient. Name resolution as explained so far, and illustrated in Figure 6.16 and\nFigure 6.17, shows that the entire path is sent to a name server. Of course,\nthe queries between name servers can also be protected, yet a more efficient\nand generally sufficient protection mechanism is to let a name server ask for\nresolving only the relevant part of a path. So, for example, instead of asking\nto return an answer for ftp.cs.vu.nl (and get the address for the name server\nhandling the nl domain), a resolver asks the root server to resolve .nl. We omit\na few important details (such as how does the resolver know whether multiple\ncomponents in a path are handled by the same name server), yet it can be\nseen that simply limiting a query can indeed help in attaining confidentiality.\nNote 6.8 (Advanced: Decentralized versus hierarchical DNS implementations)\nThe implementation of DNS we described so far is the standard one. It follows\na hierarchy of servers with 13 well-known root nodes and ending in millions of\nservers at the leaves (but read on). An important observation is that higher-level\nnodes receive many more requests than lower-level nodes. Only by caching the\nname-to-address bindings of these higher levels, it becomes possible to avoid\nsending requests to them and thus swamping them.\nThese scalability problems can, in principle, be avoided altogether with fully\ndecentralized solutions. In particular, we can compute the hash of a DNS name,\nand subsequently take that hash as a key value to be looked up in a distributed\nhash table or a hierarchical location service with a fully partitioned root node.\nThe obvious drawback of this approach is that we lose the structure of the original\nname. This loss may prevent efficient implementations of, for example, finding all\nchildren in a specific domain.\nAs argued by Walfish et al. [2004], when there is a need for many names,\nusing identifiers as a semantic-free way of accessing data will allow different\nsystems to make use of a single naming system. The reason is simple: by now,\nit is well understood how a huge collection of (flat) names can be efficiently\nsupported. What needs to be done is to maintain the mapping of identifier-to-\nname information, where in this case a name may come from the DNS space,\nbe a URL, and so on. Using identifiers can be made easier by letting users or\norganizations use a strict local name space. The latter is completely analogous to\nmaintaining a private setting of environment variables on a computer.\nNevertheless, stating that a decentralized implementation of DNS will cir-\ncumvent many of its scalability problems is too simple. In a comparative study,\nPappas et al. [2006] showed that there are many trade-offs to consider and that\nthe current, hierarchical design of DNS is not so bad for at least two reasons:\n• In a hierarchical design, not all nodes are equal and in the case of DNS,\nnotably the higher-level nodes are engineered differently.\nFor example,\ndespite that there are officially 13 root nodes, each of these nodes is highly\ndistributed and replicated for performance and availability. To illustrate,\nthe root node provided by RIPE NCC is implemented at some 25 different\nDS 4.01\n \n\n\n6.3. STRUCTURED NAMING\n369\nsites (all using the same IP address), each implemented as a highly robust\nand replicated server cluster.\nAgain, we see the important difference between a logical and physical\ndesign. Exploiting this difference is crucial for the operation of a distributed\nsystem such as DNS. However, in virtually all DHT-based systems, making\nthis distinction can be much more difficult when dealing with a logical\nnaming hierarchy, as all names are necessarily treated to be equal. In such\ncases, it becomes much more difficult to engineer the system so that, for\nexample, top-level domains are separated out by special (physical) nodes.\nOf course, the obvious drawback of not having all nodes being equal, is that\nspecial measures need to be taken to protect the more important parts of a\nsystem against abuse. We have already mentioned that top-level nodes in\nDNS are implemented as distributed and replicated servers (clusters), but\nalso that an associated server will not provide recursive name resolution.\nSuch implementation decisions are necessary also from a perspective of\nrobustness.\n• DNS caches are highly effective and driven almost entirely by the local\ndistribution of queries: if a domain D is queried often at a server S, then the\nreferences for name servers of D will be cached at S. The behavior at another\nserver S′ is determined by what is queried at S′. This important feature has\nbeen confirmed in a more recent study that also shows how difficult it can\nbe to understand the effectiveness of caching and the locality principles of\nDNS resolvers. In particular, an ISP’s DNS resolver may be very effective in\nredirecting traffic to content that is localized in that ISP [Ager et al., 2010].\nIn contrast, caching and replication in DHT-based systems generally does\nnot show such principles of locality: results are simply cached at nodes on\nthe return path of a lookup and have very little to do with the fact that a\nlookup was locally initiated at a specific node in the DHT, or a resolver for\nwhich the local ISP can assist in looking up content.\nThe fact remains that replacing DNS by a decentralized implementation is not\nnecessarily a good idea. DNS as it stands today, is a well-engineered system that\nis difficult to beat when it comes to performance and robustness (see Vixie [2009],\nVixie [2014], but also Allman [2020]).\n6.3.5\nExample: The Network File System\nAs another, and very different example, consider naming in NFS. The funda-\nmental idea underlying the NFS naming model is to provide clients complete\ntransparent access to a remote file system as maintained by a server. This\ntransparency is achieved by letting a client be able to mount a remote file\nsystem into its own local file system, as shown in Figure 6.25.\nInstead of mounting an entire file system, NFS allows clients to mount\nonly part of a file system, as also shown in Figure 6.25. A server is said to\n \nDS 4.01\n\n\n370\nCHAPTER 6. NAMING\nNetwork\nClient A\nClient B\nServer\nvu\nme\nremote\nwork\nbin\nbin\nmbox\nmbox\nmbox\nExported directory\nmounted by client\nExported directory\nmounted by client\nusers\nsteen\nFigure 6.25: Mounting (part of) a remote file system in NFS.\nexport a directory when it makes that directory and its entries available to\nclients. An exported directory can be mounted into a client’s local name space.\nThis design approach has a serious implication: in principle, users do not\nshare name spaces. As shown in Figure 6.25 the file named /remote/vu/mbox\nat client A is named /work/me/mbox at client B. A file’s name therefore\ndepends on how clients organize their own local name space, and where\nexported directories are mounted. The drawback of this approach in a dis-\ntributed file system is that sharing files becomes much harder. For example,\nAlice cannot tell Bob about a file using the name she assigned to that file, for\nthat name may have an entirely different meaning in Bob’s name space of\nfiles.\nThere are several ways to solve this problem, but the most common one\nis to provide each client with a name space that is partly standardized. For\nexample, each client may be using the local directory /usr/bin to mount a\nfile system containing a standard collection of programs that are available to\neveryone. Likewise, the directory /local may be used as a standard to mount\na local file system that is located on the client’s host.\nAn NFS server can itself mount directories that are exported by other\nservers. However, it is not allowed to export those directories to its own\nclients. Instead, a client will have to explicitly mount such a directory from\nthe server that maintains it, as shown in Figure 6.26. This restriction comes\npartly from simplicity. If a server could export a directory that it mounted\nfrom another server, it would have to return special file handles that include\nan identifier for a server. NFS does not support such file handles.\nTo explain this point in more detail, assume that the server A hosts a file\nsystem FSA from which it exports the directory /packages. This directory\ncontains a subdirectory /draw that acts as a mount point for a file system\nDS 4.01\n \n\n\n6.3. STRUCTURED NAMING\n371\nNetwork\nClient\nServer B\nServer A\nExported directory\ncontains imported\nsubdirectory\nClient needs to\nexplicitly import\nsubdirectory from\nserver B\nClient\nimports\ndirectory\nfrom\nserver A\nServer A\nimports\ndirectory\nfrom\nserver B\nbin\ndraw\ndraw\ninstall\ninstall\ninstall\npackages\nFigure 6.26: Mounting nested directories from multiple servers in NFS.\nFSB that is exported by the server B and mounted by A. Let A also export\n/packages/draw to its own clients, and assume that a client has mounted\n/packages into its local directory /bin as shown in Figure 6.26.\nIf name resolution is iterative, then to resolve the name /bin/draw/install,\nthe client contacts server A when it has locally resolved /bin and requests A to\nreturn a file handle for directory /draw. In that case, server A should return a\nfile handle that includes an identifier for server B, as only B can resolve the\nrest of the path name, in this case /install. As we have said, this kind of name\nresolution is not supported by NFS.\nName resolution in earlier versions of NFS is strictly iterative, in the sense\nthat only a single file name at a time can be looked up. In other words,\nresolving a name such as /bin/draw/install requires three separate calls to the\nNFS server. Moreover, the client is fully responsible for implementing the\nresolution of a path name. NFSv4 also supports recursive name lookups. In\nthis case, a client can pass a complete path name to a server and request that\nserver to resolve it.\nThere is another peculiarity with NFS name lookups that has been solved\nwith the most recent version (NFSv4). Consider a file server hosting several\nfile systems. With the strict iterative name resolution, whenever a lookup is\ndone for a directory on which another file system was mounted, the lookup\nwould return the file handle of the directory. Subsequently, reading that\ndirectory would return its original content, not that of the root directory of the\nmounted file system.\n \nDS 4.01\n",
      "page_number": 359
    },
    {
      "number": 38,
      "title": "Segment 38 (pages 382-390)",
      "start_page": 382,
      "end_page": 390,
      "detection_method": "topic_boundary",
      "content": "372\nCHAPTER 6. NAMING\nTo explain, assume that in our previous example that both file systems FSA\nand FSB are hosted by a single server. If the client has mounted /packages into\nits local directory /bin, then looking up the file name draw at the server would\nreturn the file handle for draw. A subsequent call to the server for listing\nthe directory entries of draw by readdir would then return the list of directory\nentries that were originally stored in FSA in subdirectory /packages/draw. Only\nif the client had also mounted file system FSB, would it be possible to properly\nresolve the path name draw/install relative to /bin.\nNFSv4 solves this problem by allowing lookups to cross mount points at a\nserver. In particular, lookup returns the file handle of the mounted directory\ninstead of that of the original directory. The client can detect that the lookup\nhas crossed a mount point by inspecting the file system identifier of the looked\nup file. If required, the client can locally mount that file system as well.\nA file handle is a reference to a file within a file system. It is independent\nof the name of the file it refers to. A file handle is created by the server that is\nhosting the file system and is unique regarding all file systems exported by\nthe server. It is created when the file is created. The client is kept ignorant of\nthe actual content of a file handle; it is completely opaque. File handles were\n32 bytes in NFS version 2, but were variable up to 64 bytes in version 3 and\n128 bytes in version 4. Of course, the length of a file handle is not opaque.\nIdeally, a file handle is implemented as a true identifier for a file relative to\na file system. For one thing, this means that as long as the file exists, it should\nhave one and the same file handle. This persistence requirement allows a\nclient to store a file handle locally once the associated file has been looked up\nthrough its name. One benefit is performance: as most file operations require\na file handle instead of a name, the client can avoid having to look up a name\nrepeatedly before every file operation. Another benefit of this approach is that\nthe client can now access the file regardless which (current) name it has.\nBecause a file handle can be locally stored by a client, it is also important\nthat a server does not reuse a file handle after deleting a file. Otherwise, a\nclient may mistakenly access the wrong file when it uses its locally stored file\nhandle.\nNote that the combination of iterative name lookups and not letting a\nlookup operation allow crossing a mount point introduces a problem with\ngetting an initial file handle. To access files in a remote file system, a client\nwill need to provide the server with a file handle of the directory where the\nlookup should take place, along with the name of the file or directory that is\nto be resolved. NFSv3 solves this problem through a separate mount protocol,\nby which a client actually mounts a remote file system. After mounting, the\nclient is passed back the root file handle of the mounted file system, which it\ncan subsequently use as a starting point for looking up names.\nIn NFSv4, this problem is solved by providing a separate operation\nputrootfh that tells the server to solve all file names relative to the root file\nDS 4.01\n \n\n\n6.3. STRUCTURED NAMING\n373\nhandle of the file system it manages. The root file handle can be used to\nlook up any other file handle in the server’s file system. This approach has\nthe additional benefit that there is no need for a separate mount protocol.\nInstead, mounting can be integrated into the regular protocol for looking up\nfiles. A client can simply mount a remote file system by requesting the server\nto resolve names relative to the file system’s root file handle using putrootfh.\nNote 6.9 (Advanced: Automounting)\nAs we mentioned, the NFS naming model essentially provides users with their\nown name space. Sharing in this model may become difficult if users name the\nsame file differently. One solution to this problem is to provide each user with a\nlocal name space that is partly standardized, and subsequently mounting remote\nfile systems the same for each user.\nAnother problem with the NFS naming model has to do with deciding when a\nremote file system should be mounted. Consider a large system with thousands\nof users. Assume that each user has a local directory /home that is used to mount\nthe home directories of other users. For example, Alice’s home directory may\nbe locally available to her as /home/alice, although the actual files are stored on\na remote server. This directory can be automatically mounted when Alice logs\ninto her workstation. In addition, she may have access to Bob’s public files by\naccessing Bob’s directory through /home/bob.\nThe question, however, is whether Bob’s home directory should also be\nmounted automatically when Alice logs in. The benefit of this approach would be\nthat the whole business of mounting file systems would be transparent to Alice.\nHowever, if this policy were followed for every user, logging in could incur a lot\nof communication and administrative overhead. In addition, it would require\nthat all users are known in advance. A much better approach is to transparently\nmount another user’s home directory on demand, that is, when it is first needed.\nOn-demand mounting of a remote file system (or actually an exported direc-\ntory) is handled in NFS by an automounter, which runs as a separate process\non the client’s machine. The principle underlying an automounter is relatively\nsimple. Consider a simple automounter implemented as a user-level NFS server\non a Unix operating system. (For other implementations, see [Callaghan, 2000]).\nAssume that for each user, the home directories of all users are available\nthrough the local directory /home, as described above. When a client machine\nboots, the automounter starts with mounting this directory. The effect of this local\nmount is that whenever a program attempts to access /home, the Unix kernel will\nforward a lookup operation to the NFS client, which, in this case, will forward the\nrequest to the automounter in its role as NFS server, as shown in Figure 6.27.\nFor example, suppose that Alice logs in. The login program will attempt to\nread the directory /home/alice to find information such as login scripts. The\nautomounter will thus receive the request to look up subdirectory /home/alice,\nfor which reason it first creates a subdirectory /alice in /home. It then looks up\nthe NFS server that exports Alice’s home directory to subsequently mount that\ndirectory in /home/alice. At that point, the login program can proceed.\n \nDS 4.01\n\n\n374\nCHAPTER 6. NAMING\nhome\nusers\nalice\nalice\nServer machine\nNFS client\nAutomounter\nLocal file system interface\n1. Lookup \"/home/alice\"\n2. Create subdir \"alice\"\n4. Mount subdir \"alice\"\nfrom server\n3. Mount request\nClient machine\nFigure 6.27: A simple automounter for NFS.\nThe problem with this approach is that the automounter will have to be\ninvolved in all file operations to guarantee transparency. If a referenced file is not\nlocally available because the corresponding file system has not yet been mounted,\nthe automounter will have to know. In particular, it will need to handle all read\nand write requests, even for file systems that have already been mounted. This\napproach may incur a large performance problem. It would be better to have\nthe automounter only mount and unmount directories, and otherwise, stay out\nof the loop. A simple solution is to let the automounter mount directories in a\nspecial subdirectory, and install a symbolic link to each mounted directory. This\napproach is shown in Figure 6.28.\nFigure 6.28: Using symbolic links with automounting.\nIn our example, the user home directories are mounted as subdirectories of\n/tmp_mnt. When Alice logs in, the automounter mounts her home directory\nin /tmp_mnt/home/alice and creates a symbolic link /home/alice that refers to\nthat subdirectory. In this case, whenever Alice executes a command such as ls\n–l /home/alice the NFS server that exports Alice’s home directory is contacted\ndirectly without further involvement of the automounter.\nDS 4.01\n \n\n\n6.4. ATTRIBUTE-BASED NAMING\n375\n6.4\nAttribute-based naming\nFlat and structured names generally provide a unique and location-independent\nway of referring to entities. Moreover, structured names have been partly\ndesigned to provide a human-friendly way to name entities so that they can be\nconveniently accessed. In most cases, it is assumed that the name refers to only\na single entity. However, location independence and human friendliness are\nnot the only criterion for naming entities. In particular, as more information\nis being made available, it becomes important to effectively search for entities.\nThis approach requires that a user can provide merely a description of what\nshe is looking for.\nThere are many ways in which descriptions can be provided, but a popular\none in distributed systems is to describe an entity in terms of (attribute, value)\npairs, generally referred to as attribute-based naming. In this approach,\nan entity is assumed to have an associated collection of attributes. Each\nattribute says something about that entity. By specifying which values a\nspecific attribute should have, a user essentially constrains the set of entities\nthat she is interested in. It is up to the naming system to return one or more\nentities that meet the user’s description. In this section, we take a closer look\nat attribute-based naming systems.\n6.4.1\nDirectory services\nAttribute-based naming systems are also known as directory services, whereas\nsystems that support structured naming are generally called naming systems.\nWith directory services, entities have a set of associated attributes that can be\nused for searching. In some cases, the choice of attributes can be relatively\nsimple. For example, in an e-mail system, messages can be tagged with\nattributes for the sender, recipient, subject, and so on. However, even in the\ncase of e-mail, matters become difficult when other types of descriptors are\nneeded, as is illustrated by the difficulty of developing filters that will allow\nonly certain messages (based on their descriptors) to be passed through.\nWhat it all boils down to is that designing an appropriate set of attributes\nis not trivial. In most cases, attribute design has to be done manually. Even if\nthere is consensus on the set of attributes to use, practice shows that setting\nthe values consistently by a diverse group of people is a problem by itself, as\nmany will have experienced when accessing music and video databases on\nthe Internet.\nTo alleviate some of these problems, research has been conducted on\nunifying the ways that resources can be described. In the context of distributed\nsystems, one particularly relevant development is the Resource Description\nFramework (RDF). Fundamental to the RDF model is that resources are\ndescribed as triplets consisting of a subject, a predicate, and an object. For\nexample, (Person, name, Alice) describes a resource referred to as Person whose\n \nDS 4.01\n\n\n376\nCHAPTER 6. NAMING\nname is Alice. In RDF, each subject, predicate, or object can be a resource itself.\nThis means that Alice may be implemented as a reference to a file that can\nbe subsequently retrieved. In the case of a predicate, such a resource could\ncontain a textual description of that predicate. Resources associated with\nsubjects and objects can be anything. References in RDF are essentially URLs.\nIf resource descriptions are stored, it becomes possible to query that\nstorage in a way that is common for many attribute-based naming systems.\nFor example, an application could ask for the information associated with a\nperson named Alice. Such a query would return a reference to the person\nresource associated with Alice. This resource can then subsequently be fetched\nby the application.\nIn this example, the resource descriptions are stored at a central location.\nThere is no reason why the resources should reside at the same location as\nwell. However, not having the descriptions in the same place may incur a\nserious performance problem. Unlike structured naming systems, looking up\nvalues in an attribute-based naming system essentially requires an exhaustive\nsearch through all descriptors. (Various techniques can be applied to avoid\nsuch exhaustive searches, an obvious one being indexing.) When considering\nperformance, an exhaustive search may be less of a problem within a single,\nnondistributed data store, but simply sending a search query to hundreds of\nservers that jointly implement a distributed data store is generally not such\na good idea. In the following, we will take a look at different approaches to\nsolving this problem in distributed systems.\n6.4.2\nHierarchical implementations: LDAP\nA common approach to tackling distributed directory services is to combine\nstructured naming with attribute-based naming. This approach has been\nwidely adopted, for example, in Microsoft’s Active Directory service and other\nsystems. Many of these systems use, or rely on the Lightweight Directory\nAccess Protocol commonly referred simply as LDAP. The LDAP directory\nservice has been derived from OSI’s X.500 directory service. As with many OSI\nservices, the quality of their associated implementations hindered widespread\nuse, and simplifications were needed to make it useful. Detailed information\non LDAP can be found in [Arkills, 2003].\nConceptually, an LDAP directory service consists of a number of records,\nusually referred to as directory entries. A directory entry is comparable\nto a resource record in DNS. Each record is made up of a collection of (at-\ntribute, value) pairs, where each attribute has an associated type. A distinction\nis made between single-valued attributes and multiple-valued attributes. The\nlatter typically represent arrays and lists. As an example, a simple direc-\ntory entry identifying the network addresses of some general servers from\nFigure 6.22 is shown in Figure 6.28.\nDS 4.01\n \n\n\n6.4. ATTRIBUTE-BASED NAMING\n377\nAttribute\nAbbr.\nValue\nCountry\nC\nNL\nLocality\nL\nAmsterdam\nOrganization\nO\nVU University\nOrganizationalUnit\nOU\nComputer Science\nCommonName\nCN\nMain server\nMail_Servers\n–\n137.37.20.3, 130.37.24.6, 137.37.20.10\nFTP_Server\n–\n130.37.20.20\nWWW_Server\n–\n130.37.20.20\nFigure 6.29: A simple example of an LDAP directory entry using LDAP\nnaming conventions.\nIn our example, we have used a naming convention described in the\nLDAP standards, which applies to the first five attributes. The attributes\nOrganization and OrganizationUnit describe, respectively, the organization and\nthe department associated with the data that are stored in the record. Likewise,\nthe attributes Locality and Country provide additional information on where\nthe entry is stored. The CommonName attribute is often used as an (ambiguous)\nname to identify an entry within a limited part of the directory. For example,\nthe name “Main server” may be enough to find our example entry given the\nspecific values for the other four attributes Country, Locality, Organization, and\nOrganizationalUnit. In our example, only attribute Mail_Servers has multiple\nvalues associated with it. All other attributes have only a single value.\nThe collection of all directory entries in an LDAP directory service is\ncalled a directory information base (DIB). An important aspect of a DIB\nis that each record is uniquely named so that it can be looked up. Such a\nglobally unique name appears as a sequence of naming attributes in each\nrecord. Each naming attribute is called a relative distinguished name, or\nRDN for short. In our example in Figure 6.29 the first five attributes are\nall naming attributes. Using the conventional abbreviations for representing\nnaming attributes in LDAP, as shown in Figure 6.29, the attributes Country,\nOrganization, and OrganizationalUnit could be used to form the name\n/C = NL/O = VU University/OU = Computer Science\nwhich is globally unique, analogous to the DNS name nl.vu.cs.\nAs in DNS, the use of globally unique names by listing RDNs in sequence,\nleads to a hierarchy of the collection of directory entries, which is referred to\nas a directory information tree (DIT). A DIT essentially forms the naming\ngraph of an LDAP directory service, in which each node represents a directory\nentry. In addition, a node may also act as a directory in the traditional sense,\nin that there may be several children for which the node acts as parent. To\nexplain, consider the naming graph, as partly shown in Figure 6.30. (Recall\nthat labels are associated with edges.)\n \nDS 4.01\n\n\n378\nCHAPTER 6. NAMING\n(a)\nAttribute\nValue\nAttribute\nValue\nLocality\nAmsterdam\nLocality\nAmsterdam\nOrganization\nVUUniversity\nOrganization\nVUUniversity\nOrganizationalUnit\nComputerScience\nOrganizationalUnit\nComputerScience\nCommonName\nMainserver\nCommonName\nMainserver\nHostName\nstar\nHostName\nzephyr\nHostAddress\n192.31.231.42\nHostAddress\n137.37.20.10\n(b)\nFigure 6.30: (a) Part of a directory information tree. (b) Two directory entries\nhaving HostName as RDN.\nThe node N corresponds to the directory entry shown in Figure 6.29. At\nthe same time, this node acts as a parent to a number of other directory\nentries that have an additional naming attribute HostName that is used as an\nRDN. For example, such entries may be used to represent hosts as shown in\nFigure 6.30.\nA node in an LDAP naming graph can thus simultaneously represent a\ndirectory in the traditional sense, as we discussed previously, as well as an\nLDAP record. This distinction is supported by two different lookup operations.\nThe read operation is used to read a single record given its path name in the\nDIT. In contrast, the list operation is used to list the names of all outgoing\nedges of a given node in the DIT. Each name corresponds to a child node of\nthe given node. Note that the list operation does not return any records; it\nmerely returns names. In other words, calling read with as input the name\n/C = NL/O = VU University/OU = Computer Science/CN = Main server\nwill return the record shown in Figure 6.30, whereas calling list will return\nthe names star and zephyr from the entries shown in Figure 6.30 as well as the\nnames of other hosts that have been registered in a similar way.\nDS 4.01\n \n\n\n6.4. ATTRIBUTE-BASED NAMING\n379\nImplementing an LDAP directory service proceeds in much the same way\nas implementing a naming service, such as DNS, except that LDAP supports\nmore lookup operations, as we will discuss shortly. When dealing with a large-\nscale directory, the DIT is usually partitioned and distributed across several\nservers, known as directory service agents (DSA). Each part of a partitioned\nDIT thus corresponds to a zone in DNS. Likewise, each DSA behaves very\nmuch the same as a normal name server, except that it implements a number\nof typical directory services, such as advanced search operations.\nClients are represented by what are called directory user agents, or simply\nDUA. A DUA is similar to a name resolver in structured-naming services. A\nDUA exchanges information with a DSA according to a standardized access\nprotocol.\nWhat makes an LDAP implementation different from a DNS implementa-\ntion are the facilities for searching through a DIB. In particular, facilities are\nprovided to search for a directory entry given a set of criteria that attributes\nof the searched entries should meet. For example, suppose that we want a list\nof all main servers at VU University. Using the notation defined in Smith and\nHowes [2006], such a list can be returned using a search operation like\nsearch(“(C=NL)(O=VU University)(OU=*)(CN=Main server)”)\nIn this example, we have specified that the place to look for main servers\nis the organization named VU_University in country NL, but that we are not\ninterested in a particular organizational unit. However, each returned result\nshould have the CN attribute equal to Main_server.\nAs we already mentioned, searching in a directory service is generally an\nexpensive operation. For example, to find all main servers at VU University\nrequires searching all entries at each department and combining the results\nin a single answer. In other words, we will generally need to access several\nleaf nodes of a DIT in order to get an answer. In practice, this also means that\nseveral DSAs need to be accessed. In contrast, naming services can often be\nimplemented in such a way that a lookup operation requires accessing only a\nsingle leaf node.\nThis whole setup of LDAP can be taken one step further by allowing\nseveral trees to co-exist, while also being linked to each other.\nThis ap-\nproach is followed in Microsoft’s Active Directory leading to a forest of LDAP\ndomains [Allen and Lowe-Norris, 2003]. Obviously, searching in such an\norganization can be overwhelmingly complex. To circumvent some of the\nscalability problems, Active Directory usually assumes there is a global index\nserver (called a global catalog) that can be searched first. The index will\nindicate which LDAP domains need to be searched further.\nAlthough LDAP by itself already exploits hierarchy for scalability, it is\ncommon to combine LDAP with DNS. For example, every tree in LDAP needs\nto be accessible at the root (known in Active Directory as a domain controller).\n \nDS 4.01\n\n\n380\nCHAPTER 6. NAMING\nThe root is often known under a DNS name, which, in turn, can be found\nthrough an appropriate SRV record, as we explained above.\n6.4.3\nDecentralized implementations\nNotably with the advent of peer-to-peer systems, researchers have also been\nlooking for solutions for decentralized attribute-based naming systems. In\nparticular, peer-to-peer systems are often used to store files. Initially, files\ncould not be searched—they could only be looked up by their key. However,\nhaving the possibility to search for a file based on descriptors can be extremely\nconvenient, where each descriptor is nothing but an (attribute, value) pair.\nObviously, querying every node in a peer-to-peer system to see if it contains\na file matching one or more of such pairs, is infeasible. What we need is a\nmapping of (attribute, value) pairs to index servers, which, in turn, point to\nfiles matching those pairs.\nUsing a distributed index\nLet us first look at the situation of building a (distributed) index. The basic\nidea is that a search query is formulated as a list of (attribute, value) pairs, just\nas in the case of our LDAP examples. The result should be a list of (references\nto) entities that match all pairs. In the case of a peer-to-peer system storing\nfiles, a list of keys to relevant files may be returned, after which the client can\nlook up each of those files using the returned keys.\nA straightforward approach toward a distributed index is the following.\nAssume there are d different attributes. In that case, we can use a server for\neach of the d attributes, where a server for attribute A maintains a set of (E,val)\npairs for each entity E that has the value val for attribute A. A search query\nsuch as\nsearch(“(Country=NL)(Organization=VU University)\n(OrganizationalUnit=*)(CommonName=Main server)”)\nwould be sent to the servers for Country, Organization, and CommonName,\nrespectively, after which the client would need to see which entities occur in\nall three sets as returned by the servers. To prevent that a server needs to\nmaintain a large set of entities, the set for each server can be further partitioned\nand distributed across several subservers, each subserver associated with the\nsame attribute.\nMore precisely, if we have a set of attributes {a1, . . . , aN}, then for each\nattribute ak we associate a set Sk = {Sk\n1, . . . , Sknk} of nk servers. Assuming that\nan attribute ak takes values from a set Rk, we construct a global mapping F\nsuch that\nF(ak, v) = Sk\nj with Sk\nj ∈Sk and v ∈Rk\nDS 4.01\n \n",
      "page_number": 382
    },
    {
      "number": 39,
      "title": "Segment 39 (pages 391-400)",
      "start_page": 391,
      "end_page": 400,
      "detection_method": "topic_boundary",
      "content": "6.4. ATTRIBUTE-BASED NAMING\n381\nIn this example, the server Sk\nj would keep track of each key associated with a\nfile having ak = v. The beauty of this scheme is its simplicity. If L(ak, v) is the\nset of keys returned by the server F(ak, v), then a query can be formulated as\na logical expression such as\n\u0000F(a1, v1) ∧F(a2, v2)\n\u0001 ∨F(a3, v3)\nwhich can then be processed on the client side by constructing the set\n\u0000L(a1, v1) ∩L(a2, v2)\n\u0001 ∪L(a3, v3)\nUnfortunately, there are important drawbacks to this scheme. First, any\nquery involving k attributes requires contacting k index servers, which may\nincur significant communication costs. Furthermore, and related, is that the\nclient is required to process the sets returned by the index servers. Just\nimagine that each file has two attributes firstName and lastName, respectively,\nand that a client is looking for the file owned by Pheriby Smith. Now, although\nPheriby may be quite unique for a first name, Smith definitely is not. However,\nour poor client will have to receive perhaps millions of keys of files for which\nlastName = Smith, while there may actually be only a handful of files for\nwhich firstName = Pheriby. Thirdly, although this scheme does allow leaving\ncertain attributes unspecified (by simply not mentioning them in the query),\nit does not easily support range queries, such as, price = [1000 −−2500].\nSpace-filling curves\nA common approach to implementing decentralized attribute-based naming\nsystems is to use what are known as space-filling curves. The basic idea is to\nmap the N-dimensional space covered by the N attributes {a1, . . . , aN} into a\nsingle dimension, and then use, for example, a simple hashing technique to\ndistribute the resultant space among index servers. One of the key issues is to\nhave (attribute, value) pairs that are “close” to each other be handled by the\nsame index server.\nLet us make matters concrete and look into one popular case, namely\nHilbert space-filling curves (see, for example, [Lawder and King, 2000]). These\nare easiest to explain by looking at only two dimensions, that is, considering\nonly two distinct attributes. The possible values that each attribute can have\ncorresponds to one axis in a two-dimensional space. Without loss of generality,\nwe assume that each attribute takes on values in the interval [0, 1). As a first\napproximation of the square, we divide it into four quadrants, as shown in\nFigure 6.31(a). All data values (x, y) with 0 ≤x, y < 0.5 are associated with\nindex 0. Values (x, y) with 0.5 ≤x, y < 1.0 are associated with index 2.\nWe can repeat this procedure recursively for each subsquare: divide it\ninto four smaller squares and connect the smaller squares through a single\nline. Using rotation and reflection, we make sure that this line can be nicely\n \nDS 4.01\n\n\n382\nCHAPTER 6. NAMING\n(a)\n(b)\nFigure 6.31: Reducing a two-dimensional space to a single dimension through\na Hilbert space-filling curve of (a) order 1, and (b) order 4.\nconnected to the one in the previously neighboring larger subsquare (which\nhas also been divided into smaller squares). To illustrate, where Figure 6.31(a)\nshows a Hilbert curve of order 1, Figure 6.31(b) shows a curve of order 4 with\n256 indices. In general, a Hilbert curve of order k connects 22k subsquares,\nand thus has also 22k indices.\nThere are various ways in which we can\nsystematically draw a curve through a two-dimensional space that has been\npartitioned into equally sized squares. Furthermore, the process can be easily\nexpanded to higher dimensions, as explained by Sagan [1994] and Bader\n[2013].\nAn important property of space-filling curves is that they preserve locality:\ntwo indices that are close to each other on the curve correspond to two\npoints that are also close to each other in the multidimensional space. (Note\nthat the reverse is not always true: two points close to each other in the\nmultidimensional space need not necessarily lie close to each other on the\ncurve.)\nTo complete the story, several things need to be done. First, attribute values\nneed to be indexed. Assume that we are dealing with a total of N possible\nattributes {a1, . . . , aN}, and that each entity assigns a value to each of these N\nattributes (possibly including the equivalent of a “don’t care” value). To keep\nmatters simple, we assume that each attribute value is normalized to a value\nin the interval [0, 1). Then clearly, an entity E having the tuple of values (v1,\n. . . , vN) is associated with a real-valued coordinate in an N-dimensional space,\nin turn uniquely associated with an N-dimensional subsquare as we discussed\nfor the two-dimensional case. The center of such a subsquare corresponds to\nan index on the associated Hilbert space-filling curve, and is now the index\nassociated with the entity E. Of course, multiple entities whose associated\nDS 4.01\n \n\n\n6.4. ATTRIBUTE-BASED NAMING\n383\ncoordinates fall in the same subsquare will all have the same index. If we want\nto avoid such collisions as much as possible, we need to use high-ordered\nspace-filling curves. Orders of 32 or 64 are not uncommon.\nSecond, we also need to be able to search for entities. The principle of\nsearching for entities based on their attribute values should now be clear.\nSuppose we were looking for files whose two attribute values a1 and a2 lie\nin intervals [v1\nl , v1u) and [v2\nl , v2u), respectively (with vi\nl < viu). Clearly, this\ndelineates a rectangular region through which the curve passes, and all files\nindexed by those segments of the curve that intersect with that region match\nthe search criterion. We therefore need an operation that returns a series of\ncurve-related indices given a region (expressed in terms of subsquares) in\nthe associated N-dimensional space. Such an operation is clearly dependent\non which space-filling curve has been used, but interestingly, need not be\ndependent on actual entities.\nFinally, we need to maintain (references to) the entities associated with\nindices. One approach, used in the Squid system [Schmidt and Parashar,\n2008], is to use a Chord ring. In Squid, the index space is chosen to be the\nsame as that of the Chord ring, that is, both use m-bit identifiers. Then clearly,\nthe Chord node responsible for index i will store (references to) the entities\nindexed by i.\nNote 6.10 (Example: The SWORD system)\nDecentralized implementations of attribute-based naming systems have received\na lot of attention. The ones based on space-filling curves are relatively popular,\nbut several alternatives have been proposed as well. As an example, we discuss a\nsolution adopted in the SWORD resource discovery system [Albrecht et al., 2008].\nIn SWORD, (attribute, value) pairs are first transformed into a key for a DHT.\nThese pairs always contain a single value; only queries may contain value ranges\nfor attributes. When computing the key (by means of a hash) the name of the\nattribute and its value are kept separate. Specific bits in the key will identify the\nattribute name, while others identify its value. In addition, the key will contain\na number of random bits to guarantee uniqueness among all keys that need to\nbe generated. In this way, the space of attributes is conveniently partitioned: if\nn bits are reserved to code attribute names, 2n different server groups can be\nused, one group for each attribute name. Likewise, by using m bits to encode\nvalues, a further partitioning per server group can be applied to store specific\n(attribute, value) pairs. DHTs are used only for distributing attribute names.\nFor each attribute name, the possible range of its value is partitioned into\nsubranges and a single server is assigned to each subrange. To explain, consider\na resource description with two attributes: a1 taking values in the range [1..10]\nand a2 taking values in the range [101...200]. Assume there are two servers for\na1: S11 takes care of recording values of a1 in [1..5], and S12 for values in [6..10].\nLikewise, server S21 records values for a2 in range [101..150] and server S22\nfor values in [151..200]. Then, when an entity E has associated attribute values\n \nDS 4.01\n\n\n384\nCHAPTER 6. NAMING\n(a1 = 7, a2 = 175), server S12 and server S22 will maintain a copy of, or a reference\nto E.\nThe advantage of this scheme is that range queries can be easily supported.\nWhen a query is issued to return resources that have a2 lying between 165 and 189,\nthe query can be forwarded to the server S22 who can then return the resources\nthat match the query range. The drawback, however, is that updates need to be\nsent to multiple servers. Moreover, it is not immediately clear how well the load is\nbalanced between the various servers. In particular, if certain range queries turn\nout to be very popular, specific servers will receive a high fraction of all queries.\nSummarizing remarks\nThere are indeed many ways of supporting attribute-\nbased naming systems in a decentralized fashion. The essence in all cases is to\nassign attributes to servers so that clients know where to direct their queries,\nyet at the same time make sure that there is a balance in the load for the set of\nservers. In this light, supporting range queries requires special attention, if\nonly to decide which server will be responsible for which subrange.\nIn practice, we see that when dealing with N attributes, many systems\nmodel the collection of (attribute, value) pairs as an N-dimensional space in\nwhich each entity is represented by a unique point in that space. Conceptually,\na search addresses a subspace and leads to identifying the servers responsible\nfor that subspace. In the simplest case, we assign each attribute to one server,\nleading to O(N) servers. In this scheme, a query addressing k attributes needs\nto be sent to k servers, while the querying client needs to combine the results.\nWe have discussed this case previously. The problem is to divide the ranges\nper attribute among subservers such that we have a reasonable balance of the\nworkload. A solution to this problem is discussed in [Bharambe et al., 2004].\nInstead of letting a client combine results, we can let servers collaborate. To\nthis end, the N-dimensional space is divided into subspaces by splitting each\ndimension d into nd intervals. This splitting leads to a total of n1 × · · · × nN\nsubspaces, where each subspace is assigned to a separate server. Even with\nnd = 2 for each dimension, we will face a total of O(2N) servers. Using\nspace-filling curves, we can reduce the number of dimensions to one, and use\na separate technique for deciding which N-dimensional subspace is served\nby which server. Practice indicates that load balancing may become an issue.\nAn alternative solution in which the number of dimensions is still reduced,\nbut larger than one, while also maintaining load balancing, has been built\ninto HyperDex [Escriva et al., 2012]. The authors also address the problem of\nreplication and consistency in case the naming system at the same time stores\nthe entities which it indexes. In that case, whenever a server indexes an entity\nE, it will have to be copied to the respective server.\nAttribute-based naming is particularly relevant for distributed systems\nwhen it comes to resource discovery and selection. An interesting case is\nDS 4.01\n \n\n\n6.5. NAMED-DATA NETWORKING\n385\ndescribed by Stratan et al. [2012]. Again, the attribute space is modeled by an\nN-dimensional space in which each resource is associated with a coordinate.\nIn this situation, each resource maintains a link to another resource, but one\nthat is responsible for a subspace of exponentially increasing size. The net\neffect is that each resource needs to have only a fixed number of neighbors,\nwhile routing a query to the relevant subspace, takes only a linear number\nof steps. The organization is akin to the use of finger tables in Chord. An\nextensive overview of resource discovery in distributed systems is discussed\nby Zarrin et al. [2018].\n6.5\nNamed-data networking\nIn our discussion so far, we have made a distinction between names, identifiers,\nand addresses. In particular, we have argued that a name needs to be resolved\nto an address, to access the named entity (recall that we referred to an address\nas the name of an entity’s access point). At least on one occasion, we dropped\nthis name-resolution process, namely when discussing how an identifier as\nused in Chord, or other DHTs, could be directly used to route a lookup\nrequest to a specific node. Let us now challenge the need for name-to-address\nresolution by taking a closer look into Information-centric networking, or\nsimply ICN [Ahlgren et al., 2012]. In particular, we concentrate on its perhaps\nmost popular form, namely named-data networking (NDN).\n6.5.1\nBasics\nNamed-data networking revolves around the principle that applications are\nnot really interested to know where an entity is stored, but rather that they can\nget a copy to access it locally when needed. To this end, much research has\nbeen spent since approximately 2007 on designing an alternative to the host-\nbased addressing schemes that are common in today’s Internet. In particular,\nthe main idea is that an application can retrieve an entity from the network\nby using that entity’s name. The network takes that name as input, and\nsubsequently routes a request to an appropriate location where the entity is\nstored, to return a copy to the requester. In effect, NDN takes over the role of\nIP in a future architecture of the Internet, as illustrated in Figure 6.32.\nAn important consequence of this organization is that instead of first\nresolving a name to an address, and then routing a request toward that\naddress, the name of an entity is directly used to fetch the associated data.\nWe already came across this scheme when discussing how a lookup request\nin DHTs, based on a unique key associated with an entity, is routed toward a\nnode responsible for that key.\nIn NDN, names are assumed to be structured. For example, this chapter\nmay be referred to as\n \nDS 4.01\n\n\n386\nCHAPTER 6. NAMING\nFigure 6.32: The role of NDN in comparison to IP when viewing the Internet\nprotocol stack as an hourglass (slightly adapted from [Afanasyev et al., 2018]).\n/distributed-systems.net/books/Distributed Systems/4/01/Naming\nindicating the book at distributed-systems.net entitled Distributed Systems, its\n4th edition, version 01, and, in particular, the chapter called Naming. This\nimmediately raises the question how users and applications can and should\nname entities. One way or the other, the name, or naming scheme, of an\nentity should be globally known, and otherwise it becomes impossible to\nfetch the data associated with a name. Likewise, globally available entities\nshould have globally unique names. How this naming is realized is outside\nthe scope of NDN. A general overview and introduction to NDN can be found\nin [Afanasyev et al., 2018] and [Saxena et al., 2016].\nNote that named-data networking assumes that data cannot be modified\nwithout generating a new name. Without this assumption, efficiency may be\nat stake, as caching by routers becomes by far less effective (as we describe\nshortly). This may seem to be a drawback, yet as long as a user knows that\nupdates may be available, she can always ask for the latest version. There\nare various ways to achieve this. For example, when sending out a request\nfor named data, a source may respond with the required data, but also with\nadditional information that an update is available (and may even send that\nupdate along with the originally requested data). An example of how such\nschemes can be deployed for keeping up-to-date in a chat conversation is\ndescribed in [Zhu and Afanasyev, 2013].\nTo better facilitate updates, named-data networking provides separate\nsynchronization protocols, which are surveyed in [Moll et al., 2021]. In essence,\nall these protocols allow the owner of named data to announce updates to\ninterested parties, thus essentially sending a multicast message within an\nNDN network. Depending on what is actually announced, a recipient may\nsubsequently decide to fetch the update through an explicit request (which,\nagain, is a name for the updated data).\nDS 4.01\n \n\n\n6.5. NAMED-DATA NETWORKING\n387\n6.5.2\nRouting\nFor our discussion, perhaps the most interesting part of NDN is how to realize\nrouting and forwarding of requests for named data. Initially, one might think\nthat with seemingly arbitrary structured names routing may be inherently\nsubject to serious scalability problems, for how to find content on the Internet\nby using just its name? When giving the matter some thought, the problem is\nfundamentally not very different when deploying IP addresses, for how would\none find the access point associated with the IPv4 address 145.100.190.243, or\nthe IPv6 address 2001:610:508:108:192:87:108:15 (both belong to surf.nl)?\nAs argued by Zhang et al. [2019], there is really no difference and a decision\nneeds to be made on which part of a name or address (i.e., a prefix) should be\nannounced within a global routing substrate, just as is currently done with\nIPv4 addresses with BGP routers. Once a named packet has found its way\ninto an organization’s network, specific techniques can be used to forward it\nto places where the associated content can be found.\nReturning to our example name, for\ndistributed-systems.net/books/Distributed Systems/4/01/Naming\nwe could decide to use /distributed-systems.net as a global prefix that should\nbe used at the level of BGP routers for globally routing requests to an organi-\nzation’s network responsible for that prefix. Within that network, we can use\nthe rest of the name to search for the associated content. Special NDN routers\nwill be needed for this purpose, which we explain next.\nAn NDN router, shown in Figure 6.33, consists of three elements:\n1. A content store is essentially a cache for keeping data associated with a\n(previously looked up) name. If a named request enters a router, and\nthe named data is in this cache, the router immediately returns that data\nto the requester, as shown in Figure 6.33(a).\n2. A pending interest table is nothing but a table that keeps track of a\n(name,interface) pair: if a request for data named N arrived through\ninterface I of the router, then (N,I) is stored. This will allow a router to\nreturn a response whenever the associated data arrives at the router. As\nshown in Figure 6.33(b), if data enters the router but there is no (longer\nany) interest, the router can decide to drop the data.\n3. A forwarding information base tells the router what to do when it\ncannot serve a request, as shown in Figure 6.33(a). For example, the\nrequest may be flooded to all neighboring routers, a random walk may be\ninitiated, or, perhaps for whatever reason, the request may be dropped.\nAgain, note that these decisions are fundamentally not different from\nrouting using IPv4 or IPv6 address.\n \nDS 4.01\n\n\n388\nCHAPTER 6. NAMING\n(a)\n(b)\nFigure 6.33: The proposed general organization of an NDN router when (a) a\nrequest flows in to the router and (b) the data is returned from another router\nor the source.\nWhen a request forwarded by a router eventually returns a response, the\nrouter will look up whether there was a pending request, send it through the\nassociated interface, and clear the entry in the pending interest table. Also,\nthe router may decide to store the returned content in its content store for\nfuture requests, as also shown in Figure 6.33(b).\nThis design opens many opportunities for routing optimizations, including\ndecisions on what to cache, when to evict data from the content store, how\nand to whom to forward requests, and so on. Practice will have to show\nwhether named-data networking can indeed form a (partial) replacement of\nthe current IP-based Internet.\n6.5.3\nSecurity in named-data networking\nThere are various aspects related to security in named-data networking. Be-\nsides secure naming, a weak aspect of any naming system is that the name\nservers and routers need to be protected as well. There are numerous threats\nto the NDN routers, which in the end all boil down to effectively attempting to\ndisrupt the service. A complete overview of the various threats and possible\nDS 4.01\n \n\n\n6.6. SUMMARY\n389\nsolutions is provided by Tourani et al. [2018] to which we refer the interested\nreader. Here, analogous to our discussion on secure DNS, we briefly discuss\nsecure naming.\nSecure naming is all about ensuring that the provided name is unforgeably\nlinked to the content it refers to. The simplest way of doing this, is by including\na signed digest of that content into the name, similar to self-certifying names,\nas we discussed in Section 6.2.5. Assuming additional information is available\nto the recipient of the named data, such as information on which hash function\nhas been used, as well as the public key (perhaps including its certificate), the\nrecipient can verify that the returned content is indeed associated with the\nname.\n6.6\nSummary\nNames are used to refer to entities. Essentially, there are three types of names.\nAn address is the name of an access point associated with an entity, also\nsimply called the address of an entity. An identifier is another type of name.\nIt has three properties: each entity is referred to by exactly one identifier, an\nidentifier refers to only one entity, and is never assigned to another entity.\nFinally, human-friendly names are targeted to be used by humans, and as such\nare represented as character strings. Given these types, we make a distinction\nbetween flat naming, structured naming, and attribute-based naming.\nSystems for flat naming essentially need to resolve an identifier to the\naddress of its associated entity. This locating of an entity can be done in\ndifferent ways. The first approach is to use broadcasting or multicasting. The\nidentifier of the entity is broadcast to every process in the distributed system.\nThe process offering an access point for the entity responds by providing an\naddress for that access point. Obviously, this approach has limited scalability.\nA second approach is to use forwarding pointers. Each time an entity\nmoves to a next location, it leaves behind a pointer telling where it will be\nnext. Locating the entity requires traversing the path of forwarding pointers.\nTo avoid large chains of pointers, it is important to reduce chains periodically\nA third approach is to allocate a home to an entity. Each time an entity\nmoves to another location, it informs its home where it is. Locating an entity\nproceeds by first asking its home for the current location.\nA fourth approach is to organize all nodes into a structured peer-to-peer\nsystem, and systematically assign nodes to entities, taking their respective\nidentifiers into account. By subsequently devising a routing algorithm by\nwhich lookup requests are moved toward the node responsible for a given\nentity, efficient and robust name resolution is possible.\nA fifth approach is to build a hierarchical search tree. The network is\ndivided into nonoverlapping domains. Domains can be grouped into higher-\nlevel (nonoverlapping) domains, and so on. There is a single top-level domain\n \nDS 4.01\n\n\n390\nCHAPTER 6. NAMING\nthat covers the entire network. Each domain at every level has an associated\ndirectory node. If an entity is located in a domain D, the directory node of the\nnext higher-level domain will have a pointer to D. A lowest-level directory\nnode stores the address of the entity. The top-level directory node knows\nabout all entities.\nStructured names are easily organized in a name space. A name space\ncan be represented by a naming graph in which a node represents a named\nentity and the label on an edge represents the name under which that entity\nis known. A node having multiple outgoing edges represents a collection of\nentities and is also known as a context node or directory. Large-scale naming\ngraphs are often organized as rooted acyclic directed graphs.\nNaming graphs are convenient to organize human-friendly names in a\nstructured way. An entity can be referred to by a path name. Name resolution\nis the process of traversing the naming graph by looking up the components\nof a path name, one at a time. A large-scale naming graph is implemented by\ndistributing its nodes across multiple name servers. When resolving a path\nname by traversing the naming graph, name resolution continues at the next\nname server as soon as a node is reached, implemented by that server.\nMore problematic are attribute-based naming schemes in which entities are\ndescribed by a collection of (attribute, value) pairs. Queries are also formulated\nas such pairs, essentially requiring an exhaustive search through all descriptors.\nSuch a search is feasible only when the descriptors are stored in a single\ndatabase. However, alternative solutions have been devised by which the pairs\nare mapped onto DHT-based systems, essentially leading to a distribution of\nthe collection of entity descriptors. Using space-filling curves, we can then\nmake different nodes responsible for different values of an attribute, which\nhelps in effectively distributing the load among the nodes in the case of search\noperations.\nInstead of making the distinction between the name and an address of\nan entity, researchers have been exploring the possibility of routing requests\ndirectly based on an entity’s name, similar to using an identifier when looking\nup information in a peer-to-peer system. In so-called named-data networks,\nan application systematically fetches (read only) data by providing a name. In\nthe end, the network returns the associated data instead of an address of the\naccess point.\nDS 4.01\n \n",
      "page_number": 391
    },
    {
      "number": 40,
      "title": "Segment 40 (pages 401-415)",
      "start_page": 401,
      "end_page": 415,
      "detection_method": "topic_boundary",
      "content": "07\nCONSISTENCY\nAND\nREPLICATION\n\n\n392\nCHAPTER 7. CONSISTENCY AND REPLICATION\nAn important issue in distributed systems is the replication of data. Data\nare generally replicated to enhance reliability or improve performance. One\nof the major problems is keeping replicas consistent. Informally, this means\nthat when one copy is updated, we need to ensure that the other copies are\nupdated as well; otherwise the replicas will no longer be the same. In this\nchapter, we take a detailed look at what consistency of replicated data actually\nmeans, and the various ways that consistency can be achieved.\nWe start with a general introduction discussing why replication is useful\nand how it relates to scalability. We then continue by focusing on what consis-\ntency actually means. An important class of what are known as consistency\nmodels assumes that multiple processes simultaneously access shared data.\nConsistency for these situations can be formulated regarding what processes\ncan expect when reading and updating the shared data, knowing that others\nare accessing that data as well.\nConsistency models for shared data are often hard to implement efficiently\nin large-scale distributed systems. Moreover, often simpler models can be\nused, which are also often easier to implement. One specific class is formed\nby client-centric consistency models, which concentrate on consistency from\nthe perspective of a single (possibly mobile) client. Client-centric consistency\nmodels are discussed in a separate section.\nConsistency is only half of the story.\nWe also need to consider how\nconsistency is actually implemented. There are essentially two, more or less\nindependent, issues we need to consider. First, we start with concentrating on\nmanaging replicas, which considers not only the placement of replica servers,\nbut also how content is distributed to these servers.\nThe second issue is how replicas are kept consistent.\nIn most cases,\napplications require a strong form of consistency. Informally, this means that\nupdates are to be propagated more or less immediately between replicas.\nThere are various alternatives for implementing strong consistency, which are\ndiscussed in a separate section. Also, attention is paid to caching protocols,\nwhich form a special case of consistency protocols.\nBeing arguably the largest distributed system, we pay separate attention\nto caching and replication in Web-based systems, notably looking at content\ndelivery networks as well as edge-server caching techniques.\n7.1\nIntroduction\nIn this section, we start with discussing the important reasons for wanting to\nreplicate data in the first place. We concentrate on replication as a technique\nfor achieving scalability, and motivate why reasoning about consistency is so\nimportant.\nDS 4.01\n \n\n\n7.1. INTRODUCTION\n393\n7.1.1\nReasons for replication\nThere are two primary reasons for replicating data. First, data are replicated\nto increase the reliability of a system. If a file system has been replicated,\nit may be possible to continue working after one replica crashes by simply\nswitching to one of the other replicas. Also, by maintaining multiple copies,\nit becomes possible to provide better protection against corrupted data. For\nexample, imagine there are three copies of a file, and every read and write\noperation is performed on each copy. We can safeguard ourselves against a\nsingle, failing write operation, by considering the value that is returned by at\nleast two copies as being the correct one.\nThe other reason for replicating data is performance. Replication for\nperformance is important when a distributed system needs to scale in terms\nof size or in terms of the geographical area it covers. Scaling regarding size\noccurs, for example, when an increasing number of processes needs to access\ndata that are managed by a single server. In that case, performance can be\nimproved by replicating the server and subsequently dividing the workload\namong the processes accessing the data.\nScaling regarding a geographical area may also require replication. The\nbasic idea is that by placing a copy of data in proximity of the process using\nthem, the time to access the data decreases. As a consequence, the performance\nas perceived by that process increases. This example also illustrates that the\nbenefits of replication for performance may be hard to evaluate. Although a\nclient process may perceive better performance, it may also be the case that\nmore network bandwidth is now consumed keeping all replicas up to date.\nIf replication helps to improve reliability and performance, who could be\nagainst it? Unfortunately, there is a price to be paid when data are replicated.\nThe problem with replication is that having multiple copies may lead to\nconsistency problems. Whenever a copy is modified, that copy becomes\ndifferent from the rest. Consequently, modifications have to be carried out on\nall copies to ensure consistency. Exactly when and how those modifications\nneed to be carried out determines the price of replication.\nTo understand the problem, consider improving access times to Web pages.\nIf no special measures are taken, fetching a page from a remote Web server\nmay sometimes even take seconds to complete. To improve performance,\nWeb browsers often locally store a copy of a previously fetched Web page\n(i.e., they cache a Web page). If a user requires that page again, the browser\nautomatically returns the local copy. The access time as perceived by the user,\nis excellent. However, if the user always wants to have the latest version of a\npage, she may be in for bad luck. The problem is that if the page has been\nmodified in the meantime, modifications will not have been propagated to\ncached copies, making those copies out-of-date.\nOne solution to the problem of returning a stale copy to the user is to\nforbid the browser to keep local copies in the first place, effectively letting the\n \nDS 4.01\n\n\n394\nCHAPTER 7. CONSISTENCY AND REPLICATION\nserver be fully in charge of replication. However, this solution may still lead\nto poor access times if no replica is placed near the user. Another solution is\nto let the Web server invalidate or update each cached copy, but this requires\nthat the server keeps track of all caches and sending them messages. This,\nin turn, may degrade the overall performance of the server. We return to\nperformance versus scalability issues below.\nIn the following, we will mainly concentrate on replication for performance.\nReplication for reliability is discussed in Chapter 8.\n7.1.2\nReplication as scaling technique\nReplication and caching for performance are widely applied as scaling tech-\nniques. Scalability issues generally appear in the form of performance prob-\nlems. Placing copies of data close to the processes using them can improve\nperformance through reduction of access time, and thus solve scalability\nproblems.\nA possible trade-off that needs to be made is that keeping copies up to date\nmay require more network bandwidth. Consider a process P that accesses\na local replica N times per second, whereas the replica itself is updated M\ntimes per second. Assume that an update completely refreshes the previous\nversion of the local replica. If N ≪M, that is, the access-to-update ratio is\nvery low, we have the situation where many updated versions of the local\nreplica will never be accessed by P, rendering the network communication\nfor those versions useless. In this case, it may have been better not to install\na local replica close to P, or to apply a different strategy for updating the\nreplica.\nA more serious problem, however, is that keeping multiple copies con-\nsistent may itself be subject to serious scalability problems. Intuitively, a\ncollection of copies is consistent when the copies are always the same. This\nmeans that a read operation performed at any copy will always return the\nsame result. Consequently, when an update operation is performed on one\ncopy, the update should be propagated to all copies before a subsequent\noperation takes place, no matter at which copy that operation is initiated or\nperformed.\nThis type of consistency is sometimes informally (and imprecisely) re-\nferred to as tight consistency, as provided by what is also called synchronous\nreplication. (In Section 7.2, we will provide precise definitions of consistency\nand introduce a range of consistency models.) The key idea is that an update\nis performed at all copies as a single atomic operation, or transaction. Unfor-\ntunately, implementing atomicity involving many replicas that may be widely\ndispersed across a large-scale network is inherently difficult when operations\nare also required to complete quickly.\nDifficulties come from the fact that we need to synchronize all replicas. In\nessence, this means that all replicas first need to reach agreement on when\nDS 4.01\n \n\n\n7.2. DATA-CENTRIC CONSISTENCY MODELS\n395\nexactly an update is to be performed locally. For example, replicas may need\nto decide on a global ordering of operations using Lamport timestamps, or\nlet a coordinator assign such an order. Global synchronization simply takes\na lot of communication time, especially when replicas are spread across a\nwide-area network.\nWe are now faced with a dilemma. On the one hand, scalability problems\ncan be alleviated by applying replication and caching, leading to improved per-\nformance. On the other hand, to keep all copies consistent generally requires\nglobal synchronization, which is inherently costly in terms of performance.\nThe cure may be worse than the disease.\nOften, the only real solution is to relax the consistency constraints. In\nother words, if we can relax the requirement that updates need to be executed\nas atomic operations, we may be able to avoid (instantaneous) global syn-\nchronizations, and may thus gain performance. The price paid is that copies\nmay not always be the same everywhere. As it turns out, to what extent\nconsistency can be relaxed depends highly on the access and update patterns\nof the replicated data, as well as on the purpose for which those data are used.\nThere is a range of consistency models and many ways to implement\nmodels through what are called distribution and consistency protocols. Ap-\nproaches to classifying consistency and replication can be found in [Gray et al.,\n1996; Wiesmann et al., 2000; Aguilera and Terry, 2016], and [Viotti and Vukolic,\n2016].\n7.2\nData-centric consistency models\nTraditionally, consistency has been discussed in the context of read and write\noperations on shared data, available through (distributed) shared memory, a\n(distributed) shared database, or a (distributed) file system. Here, we use the\nbroader term data store. A data store may be physically distributed across\nmultiple machines. In particular, each process that can access data from the\nstore is assumed to have a local (or nearby) copy available of the entire store.\nWrite operations are propagated to the other copies, as shown in Figure 7.1. A\ndata operation is classified as a write operation when it changes the data, and\nis otherwise classified as a read operation.\nA (date centric) consistency model is essentially a contract between pro-\ncesses and the data store. It says that if processes agree to obey certain rules,\nthe store promises to work correctly. Normally, a process that performs a read\noperation on a data item, expects the operation to return a value that shows\nthe results of the last write operation on that data.\nLacking a global clock, it is difficult to define precisely which write opera-\ntion is the last one. As an alternative, we need to provide other definitions,\nleading to a range of consistency models. Each model effectively restricts the\nvalues that a read operation on a data item can return. As is to be expected,\n \nDS 4.01\n\n\n396\nCHAPTER 7. CONSISTENCY AND REPLICATION\nFigure 7.1: The general organization of a logical data store, physically dis-\ntributed and replicated across multiple processes.\nthe ones with major restrictions are easy to use, for example when developing\napplications, whereas those with minor restrictions are generally considered\nto be difficult to use in practice. The trade-off is, of course, that the easy-to-use\nmodels do not perform nearly as well as the difficult ones. Such is life.\n7.2.1\nConsistent ordering of operations\nThere is a huge body of work on data-centric consistency models from the\npast decades. An important class of models comes from the field of parallel\nprogramming.\nConfronted with the fact that in parallel and distributed\ncomputing multiple processes will need to share resources and access these\nresources simultaneously, researchers have sought to express the semantics\nof concurrent accesses when shared resources are replicated. The models\nthat we discuss here all deal with consistently ordering operations on shared,\nreplicated data.\nSequential consistency\nIn the following, we will use a special notation in which we draw the opera-\ntions of a process along a time axis. The time axis is always drawn horizontally,\nwith time increasing from left to right. We use the notation Wi(x)a to denote\nthat process Pi writes value a to data item x. Similarly, Ri(x)b represents the\nfact that process Pi reads x and is returned the value b. We assume that each\ndata item has an initial value NIL. When there is no confusion about which\nprocess is accessing data, we omit the index from the symbols W and R.\nAs an example, in Figure 7.2 P1 does a write to a data item x, modifying\nits value to a. Note that, according to our system model the operation W1(x)a\nis first performed on a copy of the data store that is local to P1, and only then\nis it propagated to the other local copies. In our example, P2 later reads the\nvalue NIL, and some time after that a (from its local copy of the store). What\nDS 4.01\n \n\n\n7.2. DATA-CENTRIC CONSISTENCY MODELS\n397\nFigure 7.2: Behavior of two processes operating on the same data item. The\nhorizontal axis is time.\nwe are seeing here is that it took some time to propagate the update of x to\nP2, which is perfectly acceptable.\nSequential consistency is an important data-centric consistency model,\nwhich was first defined by Lamport [1979] in the context of shared memory\nfor multiprocessor systems. A data store is said to be sequentially consistent\nwhen it satisfies the following condition:\nThe result of any execution is the same as if the (read and write) operations\nby all processes on the data store were executed in some sequential order\nand the operations of each individual process appear in this sequence in\nthe order specified by its program.\nWhat this definition means is that when processes run concurrently on\n(possibly) different machines, any valid interleaving of read and write op-\nerations is acceptable behavior, but all processes see the same interleaving of\noperations. Note that nothing is said about time; that is, there is no reference\nto the “most recent” write operation on a data item. Also, a process “sees”\nthe writes from all process, but only through its own reads.\nThat time does not play a role can be seen from Figure 7.3. Consider four\nprocesses operating on the same data item x. In Figure 7.3(a) process P1 first\nperforms W1(x)a on x. Later (in absolute time), process P2 also performs\na write operation W2(x)b, by setting the value of x to b. However, both\nprocesses P3 and P4 first read value b, and later value a. In other words,\nthe write operation W2(x)b of process P2 appears to have taken place before\nW1(x)a of P1.\n(a)\n(b)\nFigure 7.3: (a) A sequentially consistent data store. (b) A data store that is not\nsequentially consistent.\nIn contrast, Figure 7.3(b) violates sequential consistency because not all\nprocesses see the same interleaving of write operations. In particular, to\n \nDS 4.01\n\n\n398\nCHAPTER 7. CONSISTENCY AND REPLICATION\nprocess P3, it appears as if the data item has first been changed to b, and later\nto a. On the other hand, P4 will conclude that the final value is b.\nProcess P1\nProcess P2\nProcess P3\nx ←1;\ny ←1;\nz ←1;\nprint(y,z);\nprint(x,z);\nprint(x,y);\nFigure 7.4: Three concurrently executing processes.\nTo make the notion of sequential consistency more concrete, consider\nthree concurrently executing processes P1, P2, and P3, shown in Figure 7.4\n(taken from [Dubois et al., 1988]). The data items in this example are formed\nby the three integer variables x, y, and z, which are stored in a (possibly\ndistributed) shared sequentially consistent data store. We assume that each\nvariable is initialized to 0. In this example, an assignment corresponds to a\nwrite operation, whereas a print statement corresponds to a simultaneous read\noperation of its two arguments. All statements are assumed to be indivisible.\nVarious interleaved execution sequences are possible. With six indepen-\ndent statements, there are potentially 720 (6!) possible execution sequences,\nalthough some of these violate program order. Consider the 120 (5!) sequences\nthat begin with x ←1. Half of these have print(x,z) before y ←1 and\nthus violate program order. Half also have print(x,y) before z ←1 and\nalso violate program order. Only 1/4 of the 120 sequences, or 30, are valid.\nAnother 30 valid sequences are possible starting with y ←1 and another 30\ncan begin with z ←1, for a total of 90 valid execution sequences. Four of\nthese are shown in Figure 7.5.\nExecution 1\nExecution 2\nExecution 3\nExecution 4\nP1:\nx ←1;\nP1:\nx ←1;\nP2:\ny ←1;\nP2:\ny ←1;\nP1:\nprint(y,z);\nP2:\ny ←1;\nP3:\nz ←1;\nP1:\nx ←1;\nP2:\ny ←1;\nP2:\nprint(x,z);\nP3:\nprint(x,y);\nP3:\nz ←1;\nP2:\nprint(x,z);\nP1:\nprint(y,z);\nP2:\nprint(x,z);\nP2:\nprint(x,z);\nP3:\nz ←1;\nP3:\nz ←1;\nP1:\nx ←1;\nP1:\nprint(y,z);\nP3:\nprint(x,y);\nP3:\nprint(x,y);\nP1:\nprint(y,z);\nP3:\nprint(x,y);\nPrints: 001011\nPrints: 101011\nPrints: 010111\nPrints: 111111\nSignature: 0 0 1 0 1 1\nSignature: 1 0 1 0 1 1\nSignature: 1 1 0 1 0 1\nSignature: 1 1 1 1 1 1\n(a)\n(b)\n(c)\n(d)\nFigure 7.5: Four valid execution sequences for the processes of Figure 7.4. The\nvertical axis is time.\nIn Figure 7.5(a) the three processes are run in order, first P1, then P2,\nthen P3. The other three examples demonstrate different, but equally valid,\ninterleaving of the statements in time. Each of the three processes prints\nDS 4.01\n \n\n\n7.2. DATA-CENTRIC CONSISTENCY MODELS\n399\ntwo variables. Since the only values each variable can take on are the initial\nvalue (0), or the assigned value (1), each process produces a 2-bit string. The\nnumbers after Prints are the actual outputs that appear on the output device.\nIf we concatenate the output of P1, P2, and P3 in that order, we get a 6-bit\nstring that characterizes a particular interleaving of statements. This is the\nstring listed as the Signature in Figure 7.5. Below, we will characterize each\nordering by its time-independent signature rather than by its printout.\nNot all 64 signature patterns are allowed. As a trivial example, 00 00 00 is\nnot permitted because that would imply that the print statements ran before\nthe assignment statements, violating the requirement that statements are\nexecuted in program order. A more subtle example is 00 10 01. The first two\nbits, 00, mean that y and z were both 0 when P1 did its printing. This situation\noccurs only when P1 executes both statements before P2 or P3 starts. The next\ntwo bits, 10, mean that P2 must run after P1 has started but before P3 has\nstarted. The last two bits, 01, mean that P3 must complete before P1 starts, but\nwe have already seen that P1 must go first. Therefore, 00 10 01 is not allowed.\nIn short, the 90 different valid statement orderings produce a variety of\ndifferent program results (less than 64, though) that are allowed under the\nassumption of sequential consistency. The contract between the processes and\nthe distributed shared data store is that the processes must accept all of these\nas valid results. In other words, the processes must accept the four results\nshown in Figure 7.5 and all the other valid results as proper answers, and\nmust work correctly if any of them occurs. A program that works for some of\nthese results and not for others violates the contract with the data store and is\nincorrect.\nThis example also shows that sequential consistency is not easy to under-\nstand at first sight. In the following note, we zoom more into the intricacies.\nNote 7.1 (Advanced: The importance and intricacies of sequential consistency)\nThere is no doubt that sequential consistency is an important model. In essence, of\nall consistency models that exist and have been developed, it is the easiest one to\nunderstand when developing concurrent and parallel applications. This is because\nthe model matches our expectations best when we let several programs operate\non shared data simultaneously.\nAt the same time, implementing sequential\nconsistency is far from trivial [Adve and Boehm, 2010]. To illustrate, consider the\nexample involving two variables x and y, shown in Figure 7.6.\nFigure 7.6: Both x and y are each handled in a sequentially consistent\nmanner, but taken together, sequential consistency is violated.\nIf we just consider the write and read operations on x, the fact that P1 reads\n \nDS 4.01\n\n\n400\nCHAPTER 7. CONSISTENCY AND REPLICATION\nthe value a is perfectly consistent. The same holds for the operation R2(y)b by\nprocess P2. However, when taken together, there is no way that we can order the\nwrite operations on x and y such that we can have R1(x)a and R2(y)b (note that\nwe need to keep the ordering as executed by each process):\nOrdering of operations\nResult\nW1(x)a; W1(y)a; W2(y)b; W2(x)b\nR1(x)b\nR2(y)b\nW1(x)a; W2(y)b; W1(y)a; W2(x)b\nR1(x)b\nR2(y)a\nW1(x)a; W2(y)b; W2(x)b; W1(y)a\nR1(x)b\nR2(y)a\nW2(y)b; W1(x)a; W1(y)a; W2(x)b\nR1(x)b\nR2(y)a\nW2(y)b; W1(x)a; W2(x)b; W1(y)a\nR1(x)b\nR2(y)a\nW2(y)b; W2(x)b; W1(x)a; W1(y)a\nR1(x)a\nR2(y)a\nIn terms of transactions, the operations carried out by P1 and P2 are not serializ-\nable. Our example shows that sequential consistency is not compositional: when\nhaving data items that are each kept sequentially consistent, their composition\nas a set need not be so [Herlihy et al., 2021]. The problem of noncompositional\nconsistency can be solved by assuming linearizability. This is best explained\nby making a distinction between the start and completion of an operation, and\nassuming that it may take some time. Linearizability [Herlihy and Wing, 1991]\nstates that:\nEach operation should appear to take effect instantaneously at some moment\nbetween its start and completion.\nReturning to our example, Figure 7.7 shows the same set of write operations, but\nwe have now also indicated when they take place: the shaded area designates\nthe time the operation is being executed. Linearizability states that the effect of\nan operation should take place somewhere during the interval indicated by the\nshaded area. In principle, this means that at the time of completion of a write\noperation, the results should be propagated to the other data stores.\nFigure 7.7: An example of taking linearizable sequential consistency into\naccount, with only one possible outcome for x and y.\nWith that in mind, the possibilities for properly ordering become limited:\nOrdering of operations\nResult\nW1(x)a; W2(y)b; W1(y)a; W2(x)b\nR1(x)b\nR2(y)a\nW1(x)a; W2(y)b; W2(x)b; W1(y)a\nR1(x)b\nR2(y)a\nW2(y)b; W1(x)a; W1(y)a; W2(x)b\nR1(x)b\nR2(y)a\nW2(y)b; W1(x)a; W2(x)b; W1(y)a\nR1(x)b\nR2(y)a\nIn particular, W2(y)b is completed before W1(y)a starts, so that y will have the\nvalue a. Likewise, W1(x)a completes before W2(x)b starts, so that x will have\nDS 4.01\n \n\n\n7.2. DATA-CENTRIC CONSISTENCY MODELS\n401\nvalue b. It should not come as a surprise that implementing linearizability on\na many-core architecture may impose serious performance problems. Yet at the\nsame time, it eases programmability considerably, so a trade-off needs to be made.\nCausal consistency\nThe causal consistency model [Hutto and Ahamad, 1990] represents a weak-\nening of sequential consistency in that it makes a distinction between events\nthat are potentially causally related and those that are not. We already came\nacross causality when discussing vector timestamps in the previous chapter.\nIf event b is caused or influenced by an earlier event a, causality requires that\neveryone else first see a, then see b.\nConsider a simple interaction using a distributed shared database. Suppose\nthat process P1 writes a data item x. Then P2 reads x and writes y. Here, the\nreading of x and the writing of y are potentially causally related because the\ncomputation of y may have depended on the value of x as read by P2 (i.e., the\nvalue written by P1).\nOn the other hand, if two processes spontaneously and simultaneously\nwrite two different data items, these are not causally related. Operations that\nare not causally related are said to be concurrent.\nFor a data store to be considered causally consistent, it is necessary that\nthe store obeys the following condition:\nWrites that are potentially causally related must be seen by all processes\nin the same order. Concurrent writes may be seen in a different order on\ndifferent machines.\nAs an example of causal consistency, consider Figure 7.8. Here we have an\nevent sequence that is allowed with a causally consistent store, but which is\nforbidden with a sequentially consistent store or a strictly consistent store.\nThe thing to note is that the writes W2(x)b and W1(x)c are concurrent, so it is\nnot required that all processes see them in the same order.\nFigure 7.8: This sequence is allowed with a causally consistent store, but not\nwith a sequentially consistent store.\nNow consider a second example. In Figure 7.9(a) we have W2(x)b poten-\ntially depending on W1(x)a because writing the value b into x may be a result\n \nDS 4.01\n\n\n402\nCHAPTER 7. CONSISTENCY AND REPLICATION\nof a computation involving the previously read value by R2(x)a. The two\nwrites are causally related, so all processes must see them in the same order.\nTherefore, Figure 7.9(a) is incorrect. On the other hand, in Figure 7.9(b) the\nread has been removed, so W1(x)a and W2(x)b are now concurrent writes.\nA causally consistent store does not require concurrent writes to be globally\nordered, so Figure 7.9(b) is correct. Note that Figure 7.9(b) reflects a situation\nthat would not be acceptable for a sequentially consistent store.\n(a)\n(b)\nFigure 7.9: (a) A violation of a causally consistent store. (b) A correct sequence\nof events in a causally consistent store.\nImplementing causal consistency requires keeping track of which processes\nhave seen which writes. There are many subtle issues to consider. To illustrate,\nassume we replace W2(x)b in Figure 7.9(a) with W2(y)b, and likewise R3(x)b\nwith R3(y)b, respectively. This situation is shown in Figure 7.10.\nFigure 7.10: A slight modification of Figure 7.9(a). What should R3(x) or R4(y)\nreturn?\nLet us first look at operation R3(x). Process P3 executes this operation\nafter R3(y)b. We know at this point for sure that W(x)a happened before W(y)b.\nIn particular, W(x)a →R(x)a →W(y)b, meaning that if we are to preserve\ncausality, reading x after reading b from y can return only a. If the system\nreturned NIL to P3 it would violate the preservation of causal relationships.\nDS 4.01\n \n\n\n7.2. DATA-CENTRIC CONSISTENCY MODELS\n403\nWhat about R4(y)? Could it return the initial value of y, namely NIL? The\nanswer is affirmative: although we have the formal happened-before relationship\nW(x)a →W(y)b, without having read b from y, process P4 can still justifiably\nobserve that W(x)a took place independently of the initialization of y.\nImplementation wise, preserving causality introduces some interesting\nquestions. Consider, for example, the middleware underlying process P3\nfrom Figure 7.10. At the point that this middleware returns the value b from\nreading y, it must know about the relationship W(x)a →W(y)b. In other\nwords, when the most recent value of y was propagated to P3’s middleware,\nat the very least, metadata on y’s dependency should have been propagated\nas well. Alternatively, the propagation may have also been done together\nwith updating x at P3’s node. By-and-large, the bottom line is that we need a\ndependency graph of which operation is dependent on which other operations.\nSuch a graph may be pruned at the moment that dependent data is also locally\nstored.\nGrouping operations\nMany consistency models are defined at the level of elementary read and write\noperations. This level of granularity is for historical reasons: these models\nhave initially been developed for shared-memory multiprocessor systems and\nwere actually implemented at the hardware level.\nThe fine granularity of these consistency models often does not match the\ngranularity as provided by applications. What we see there is that concurrency\nbetween programs sharing data is generally kept under control through syn-\nchronization mechanisms for mutual exclusion and transactions. Effectively,\nwhat happens is that at the program level, read and write operations are\nbracketed by the pair of operations ENTER_CS and LEAVE_CS. A process\nthat has successfully executed ENTER_CS will be ensured that all the data\nin its local store is up-to-date. At that point, it can safely execute a series of\nread and write operations on that store, and subsequently wrap things up by\ncalling LEAVE_CS. Data and instructions between ENTER_CS and LEAVE_CS\nis denoted as a critical region.\nIn essence, what happens is that within a program, the data that are\noperated on by a series of read and write operations are protected against\nconcurrent accesses that would lead to seeing something else than the result\nof executing the series as a whole. Put differently, the bracketing turns the\nseries of read and write operations into an atomically executed unit, thus\nraising the level of granularity.\nTo reach this point, we do need to have precise semantics concerning the\noperations ENTER_CS and LEAVE_CS. These semantics can be formulated\nin terms of shared synchronization variables, or simply locks. A lock has\nshared data items associated with it, and each shared data item is associated\nwith at most one lock. In the case of coarse-grained synchronization, all\n \nDS 4.01\n\n\n404\nCHAPTER 7. CONSISTENCY AND REPLICATION\nshared data items would be associated to just a single lock. Fine-grained\nsynchronization is achieved when each shared data item has its own unique\nlock. Of course, these are just two extremes of associating shared data to a\nlock. When a process enters a critical region, it should acquire the relevant\nlocks, and likewise when it leaves the critical region, it releases these locks.\nEach lock has a current owner, namely, the process that last acquired it. A\nprocess not currently owning a lock but wanting to acquire it has to send a\nmessage to the current owner asking for ownership and the current values of\nthe data associated with that lock. While having exclusive access to a lock, a\nprocess is allowed to perform read and write operations. It is also possible for\nseveral processes to simultaneously have nonexclusive access to a lock, meaning\nthat they can read, but not write, the associated data. Of course, nonexclusive\naccess can be granted if and only if there is no other process having exclusive\naccess.\nWe now demand that the following criteria are met [Bershad et al., 1993]:\n• Acquiring a lock can succeed only when all updates to its associated\nshared data have completed.\n• Exclusive access to a lock can succeed only if no other process has\nexclusive or nonexclusive access to that lock.\n• Nonexclusive access to a lock is allowed only if any previous exclusive\naccess has been completed, including updates to the lock’s associated\ndata.\nNote that we are effectively demanding that the usage of locks is linearized,\nadhering to sequential consistency. Figure 7.11 shows an example of what\nis known as entry consistency. We associate a lock with each data item\nseparately. We use the notation L(x) as an abbreviation for acquiring the lock\nfor x, that is, locking x. Likewise, U(x) stands for releasing the lock on x, or\nunlocking it. In this case, P1 locks x, changes x once, after which it locks y.\nProcess P2 also acquires the lock for x but not for y so that it will read value a\nfor x, but may read NIL for y. However, because process P3 first acquires the\nlock for y, it will read the value b when y was unlocked by P1. It is important\nto note here that each process has a copy of a variable, but that this copy\nneed not be instantly or automatically updated. When locking or unlocking a\nvariable, a process is explicitly telling the underlying distributed system that\nthe copies of that variable need to be synchronized. A simple read operation\nwithout locking may thus result in reading a local value that is effectively\nstale.\nOne of the programming problems with entry consistency is properly\nassociating data with locks. One straightforward approach is to explicitly\ntell the middleware which data will be accessed, as is generally done by\ndeclaring which database tables will be affected by a transaction. In an object-\nDS 4.01\n \n\n\n7.2. DATA-CENTRIC CONSISTENCY MODELS\n405\nFigure 7.11: A valid event sequence for entry consistency.\nbased approach, we could associate a unique lock with each declared object,\neffectively serializing all invocations to such objects.\nNote 7.2 (More information: Consistency models, serializability, transactions)\nComing to this point, the consistency models may at first sight appear to be\noverwhelming. Yet, despite their seemingly complexity, there are strong analogies\nwith models that many of us are used to. In particular, let us consider transactions.\nAs discussed in Section 1.3.2, transactions effectively group a series of read and\nwrite operations such that it is guaranteed that these operations are executed in\nthe order of their appearance in the transaction. Moreover, when considering\na collection of transactions that simultaneously operate on a data set, then the\nfinal values of that data set can be explained by one specific ordering of those\ntransactions.\nThe keyword here is serializability: can we order the execution of operations\nthat comprise the transactions in such a way that the final result matches a serial\nexecution of the transactions? Consider the example shown in Figure 7.12. It is\nimportant to note that it is not necessary to know what is exactly being computed,\nbut instead, only that we are dealing with read and write operations. In this sense,\neach transaction Ti can be represented as the series ⟨Wi(x); Ri(x); Wi(x)⟩.\nBEGIN_TRANSACTION\nBEGIN_TRANSACTION\nBEGIN_TRANSACTION\nx = 0\nx = 0\nx = 0\nx = x + 1\nx = x + 2\nx = x + 3\nEND_TRANSACTION\nEND_TRANSACTION\nEND_TRANSACTION\nTransaction T1\nTransaction T2\nTransaction T3\nFigure 7.12: Three transactions.\nTo ensure consistency, the underlying transaction system will have to devise\nlegal schedules: orderings of the read and write operations from the three\ntransactions such that the final result corresponds to a serial execution of those\ntransactions. Consider the four schedules shown in Figure 7.13.\nBoth schedules S1 and S2 produce the result x == 3. This result can be\nexplained by assuming that the scheduler executed the transactions in the order\nT1 →T2 →T3. This ordering happens to match S1, but not S2, yet that is\nnot relevant. Likewise, S3 is an illegal schedule, having the final result x == 5.\nSchedule S4 is interesting: the final result is x == 3, but that is only because of a\ncoincidence. As the scheduler sees only (read and) write operations, and not the\n \nDS 4.01\n",
      "page_number": 401
    },
    {
      "number": 41,
      "title": "Segment 41 (pages 416-423)",
      "start_page": 416,
      "end_page": 423,
      "detection_method": "topic_boundary",
      "content": "406\nCHAPTER 7. CONSISTENCY AND REPLICATION\neffects of write operations, scheduling the operations x = x + 1 and then x = x + 2\nis illegal.\nTime −→\nS1\nx = 0\nx = x + 1\nx = 0\nx = x + 2\nx = 0\nx = x + 3\nLegal\nS2\nx = 0\nx = 0\nx = x + 1\nx = x + 2\nx = 0\nx = x + 3\nLegal\nS3\nx = 0\nx = 0\nx = x + 1\nx = 0\nx = x + 2\nx = x + 3\nIllegal\nS4\nx = 0\nx = 0\nx = x + 3\nx = 0\nx = x + 1\nx = x + 2\nIllegal\nFigure 7.13: Various schedules from the transactions shown in Figure 7.12.\nNote that what we have just described corresponds to entry consistency.\nTransactions consisting of only a single operation are, from a consistency point of\nview, analogous to sequential consistency.\nConsistency versus coherence\nAt this point, it is useful to clarify the difference between two closely related\nconcepts. The models we have discussed so far, all deal with the fact that a\nnumber of processes execute read and write operations on a set of data items.\nA consistency model describes what can be expected regarding that set when\nmultiple processes concurrently operate on that data. The set is then said to\nbe consistent if it adheres to the rules described by the model.\nWhere data consistency is concerned with a set of data items, coher-\nence models describe what can be expected to hold for only a single data\nitem [Cantin et al., 2005]. In this case, we assume that a data item is replicated;\nit is said to be coherent when the various copies abide to the rules as defined\nby its associated consistency model. A popular model is that of sequential\nconsistency, but now applied to only a single data item. In effect, it means\nthat in the case of concurrent writes, all processes will eventually see the same\norder of updates taking place.\n7.2.2\nEventual consistency\nTo what extent processes actually operate in a concurrent fashion, and to\nwhat extent consistency needs to be guaranteed, may vary. There are many\nexamples in which concurrency appears only in a restricted form. For exam-\nple, in many database systems, most processes hardly ever perform update\noperations; they mostly read data from the database. Only one, or very few,\nprocesses perform update operations. The question then is how fast updates\nshould be made available to only-reading processes. In the advent of globally\noperating content delivery networks, developers often choose to propagate\nupdates slowly, implicitly assuming that most clients are always redirected to\nthe same replica and will therefore never experience inconsistencies.\nDS 4.01\n \n\n\n7.2. DATA-CENTRIC CONSISTENCY MODELS\n407\nAnother example is the Web. In virtually all cases, Web pages are updated\nby a single authority, such as a webmaster or the actual owner of the page.\nThere are normally no write-write conflicts to resolve. On the other hand, to\nimprove efficiency, browsers and Web proxies are often configured to keep a\nfetched page in a local cache and to return that page upon the next request.\nAn important aspect of both types of Web caches is that they may return\nout-of-date Web pages. In other words, the cached page that is returned to\nthe requesting client is an older version compared to the one available at\nthe actual Web server. As it turns out, many users find this inconsistency\nacceptable (to a certain degree), as long as they have access only to the same\ncache. In effect, they remain unaware of the fact that an update had taken\nplace, just as in the previous case of content delivery networks.\nYet another example, is a worldwide naming system such as DNS. The DNS\nname space is partitioned into domains, where each domain is assigned to a\nnaming authority, which acts as owner of that domain. Only that authority is\nallowed to update its part of the name space. Consequently, conflicts resulting\nfrom two operations that both want to perform an update on the same data\n(i.e., write-write conflicts), never occur. The only situation that needs to be\nhandled are read-write conflicts, in which one process intends to update a\ndata item while another is concurrently attempting to read that item. As it\nturns out, also in this case it is often acceptable to propagate an update in\na lazy fashion, meaning that a reading process will see an update only after\nsome time has passed since the update took place.\nThese examples can be viewed as cases of (large scale) distributed and\nreplicated databases that tolerate a relatively high degree of inconsistency.\nThey have in common that if no updates take place for a long time, all replicas\nwill gradually become consistent, that is, have the same data stored. This\nform of consistency is called eventual consistency [Vogels, 2009].\nData stores that are eventually consistent thus have the property that\nlacking write-write conflicts, all replicas will converge toward identical copies\nof each other. Eventual consistency essentially requires only that updates\nare guaranteed to propagate to all replicas. Write-write conflicts are often\nrelatively easy to solve when assuming that only a small group of processes\ncan perform updates. In practice, we often also see that in the case of conflicts,\none specific write operation is (globally) declared as “winner,” overwriting\nthe effects of any other conflicting write operation. Eventual consistency is\ntherefore often cheap to implement.\nNote 7.3 (Advanced: Making eventual consistency stronger)\nEventual consistency is a relatively easy model to understand, but equally im-\nportant is the fact that it is also relatively easy to implement. Nevertheless, it\nis a weak-consistency model with its own peculiarities. Consider a calendar\nshared between Alice, Bob, and Chuck. A meeting M has two attributes: a pro-\nDS 4.01\n\n\n408\nCHAPTER 7. CONSISTENCY AND REPLICATION\nposed starting time and a set of people who have confirmed their attendance.\nWhen Alice proposes to start meeting M at time T, and assuming no one else\nhas confirmed attendance, she executes the operation WA(M)[T, {A}]. When\nBob confirms his attendance, he will have read the tuple [T, {A}] and update M\naccordingly: WB(M)[T, {A, B}]. In our example two meetings M1 and M2 need to\nbe planned.\nAssume the sequence of events\nWA(M1)[T1, {A}] →RB(M1)[T1, {A}] →\nWB(M1)[T1, {A, B}] →WB(M2)[T2, {B}].\nIn other words, Bob confirms his attendance at M1 and then immediately proposes\nto schedule M2 at T2. Unfortunately, Chuck concurrently proposes to schedule M1\nat T3 when Bob confirms he can attend M1 at T1. Formally, using the symbol “∥”\nto denote concurrent operations, we have,\nWB(M1)[T1, {A, B}] ∥WC(M1)[T3, {C}].\nUsing our usual notation, these operations can be illustrated as shown in Fig-\nure 7.14.\nFigure 7.14: The situation of updating two meetings M1 and M2.\nEventual consistency may lead to very different scenarios. There are a number\nof write-write conflicts, but in any case, eventually [T2, {B}] will be stored for\nmeeting M2, as the result of the associated write operation by Bob. For the value\nof meeting M1 there are different options. In principle, we have three possible\noutcomes: [T1, {A}], [T1, {A, B}], and [T3, {C}]. Assuming we can maintain some\nnotion of a global clock, it is not very likely that WA(M1)[T1, {A}] will prevail.\nHowever, the two write operations WB(M1)[T1, {A, B}] and WC(M1)[T3, {C}] are\ntruly in conflict. In practice, one of them will win, presumably through a decision\nby a central coordinator.\nResearchers have been seeking to combine eventual consistency with stricter\nguarantees on ordering.\nBailis et al. [2013] propose to use a separate layer\nthat operates on top of an eventually consistent, distributed store. This layer\nimplements causal consistency, of which it has been formerly proven that it is\nthe best attainable consistency in the presence of network partitioning [Mahajan\net al., 2011]. In our example, we have only one chain of dependencies:\nWA(M1)[T1, {A}] →RB(M1)[T1, {A}] →\nWB(M1)[T1, {A, B}] →WB(M2)[T2, {B}].\nDS 4.01\n \n\n\n7.2. DATA-CENTRIC CONSISTENCY MODELS\n409\nAn important observation is that with causal consistency in place, once a pro-\ncess reads [T2, {B}] for meeting M2, obtaining the value for M1 returns ei-\nther [T1, {A, B}] or [T3, {C}], but certainly not [T1, {A}].\nThe reason is that\nWB(M1)[T1, {A, B}] immediately precedes WB(M2)[T2, {B}], and at worse may\nhave been overwritten by WC(M1)[T3, {C}]. Causal consistency rules out that the\nsystem could return [T1, {A}].\nHowever, eventual consistency may overwrite previously stored data items.\nIn doing so, dependencies may be lost. To make this point clear, it is impor-\ntant to realize that in practice, an operation at best keeps track of the immedi-\nate preceding operation it depends on. As soon as Wc(M1)[T3, {C}] overwrites\nWB(M1)[T1, {A, B}] (and propagates to all replicas), we also break the chain of\ndependencies\nWA(M1)[T1, {A}] →RB(M1)[T1, {A}] →· · · →WB(M2)[T2, {B}]\nwhich\nwould\nnormally\nprevent\nWA(M1)[T1, {A}]\never\novertaking\nWB(M1)[T1, {A, B}] and any operation depending on it.\nAs a consequence,\nmaintaining causal consistency requires that we do maintain a history of\ndependencies, instead of just keeping track of immediately preceding operations.\nAssuming that write-write conflicts hardly occur is generally not realistic.\nAs mentioned, improvements can be made by grouping operations and using\nlocks. What this entails, is that processes need to coordinate their actions by\nmaking use of mutual-exclusion mechanisms. For many large-scale systems,\ncoordination among processes has turned out to form a real performance\nbottleneck. Note that we are dealing here with coordination for consistency.\nAlleviating potential bottleneck problems then boils down to bringing down\ncoordination, or weakening consistency requirements. At least two approaches\nhave been, by now, reasonably well explored, and are gradually finding their\nway into practical solutions.\nThe first one, referred to as strong eventual consistency, ensures that\nif there are conflicting updates, that nevertheless the replicas where those\nupdates have taken place, are in the same state. Note that this is indeed\nstronger than (weak) eventual consistency, as in that case, nothing is specified\nwhat to do when the same replicated data item is updated by two different\nprocesses, except that the conflict may be reported. The seminal paper by\nShapiro et al. [2011] introduced the Conflict-Free Replicated Data Type, or\nsimply CRDT. A CRDT is a data type that can be replicated at many different\nsites, yet most importantly, can be updated in a concurrent fashion without\nfurther coordination. Of course, the meaning of concurrent updates may be\ndifferent per type. For example, in the case of a variable for which the last\nupdate wins, its implementation will need to keep track of dependencies. A\ncrude, but perhaps acceptable semantics, is that a good approximation of the\nactual time when an update is initiated is considered (e.g., using NTP), along\n \nDS 4.01\n\n\n410\nCHAPTER 7. CONSISTENCY AND REPLICATION\nwith some random number to come to a deterministic choice when several\nupdates happen within the same small time span. An alternative is to keep\nall updates so that a final decision can be made at application level. Many of\nsuch examples are discussed by Preguica [2018]. Kleppmann and Beresford\n[2017] describe how CRDTs can be implemented to support data structures in\nwhich no update is lost. In effect, it boils down to keeping all updates while at\nthe same time avoiding clear duplicates, and maintaining clear dependencies.\nThe second approach is to move away from data-centric consistency and\nto look at program consistency. Again motivated by the observation that\ncoordination for consistency may be extremely costly, the question arises if and\nwhere coordination is truly necessary. Program consistency is all about the\nquestion whether a program produces the expected outcome, despite various\nkinds of anomalies that may occur (like race conditions). A key observation is\nthat of problem monotonicity:\nA problem P is monotonic if for any input sets S and T, P(S) ⊆P(T).\nThe basic idea behind a monotonic problem is that it can come to a (partial)\nsolution even if certain input information is missing.\nIn other words, a\nprogram solving a monotonic problem can start with incomplete information,\nbut is guaranteed not to have to roll back when missing information becomes\navailable. A typical example of such a problem is filling a (digital) shopping\ncart: operations can be performed in any order by any server. Indeed, there\nis no write-write conflict. However, if we also need to support the removal\nof items, we bump into a problem. In this case, monotonicity can help if we\nsplit the add and delete operations into two different sets, and let each of\nthem simply grow to a final state. In this case, we need to coordinate only\nwhen each set has converged to a final state. The difference between what\nhas been added and what has been deleted is what needs to be coordinated\nto reach consistency. Further details on program consistency can be found\nin [Hellerstein and Alvaro, 2020].\n7.2.3\nContinuous consistency\nThere is no such thing as the best solution to replicating data. Replicating data\nposes consistency problems that cannot be solved efficiently in a general way.\nOnly if we loosen consistency can there be hope for attaining efficient solutions.\nUnfortunately, there are also no general rules for loosening consistency: exactly\nwhat can be tolerated is highly dependent on applications.\nThere are different ways for applications to specify what inconsistencies\nthey can tolerate. Yu and Vahdat [2002] take a general approach by distin-\nguishing three independent axes for defining inconsistencies: deviation in\nnumerical values between replicas, deviation in staleness between replicas,\nand deviation with respect to the ordering of update operations. They refer to\nthese deviations as forming continuous consistency ranges.\nDS 4.01\n \n\n\n7.2. DATA-CENTRIC CONSISTENCY MODELS\n411\nMeasuring inconsistency in terms of numerical deviations can be used\nby applications for which the data have numerical semantics. One obvious\nexample is the replication of records containing stock market prices. In this\ncase, an application may specify that two copies should not deviate more than\n$0.02, which would be an absolute numerical deviation. Alternatively, a relative\nnumerical deviation could be specified, stating that two copies should differ by\nno more than, for example, 0.5%. In both cases, we would see that if a stock\ngoes up (and one of the replicas is immediately updated) without violating\nthe specified numerical deviations, the replicas would still be considered to\nbe mutually consistent.\nNumerical deviation can also be understood in terms of the number of\nupdates that have been applied to a given replica, but have not yet been seen\nby others. For example, a Web cache may not have seen a batch of operations\ncarried out by a Web server. In this case, the associated deviation in the value\nis also referred to as its weight.\nStaleness deviations relate to the last time a replica was updated. For some\napplications, it can be tolerated that a replica provides old data as long as it is\nnot too old. For example, weather reports typically stay reasonably accurate\nover some time, say a few hours. In such cases, a main server may receive\ntimely updates, but may decide to propagate updates to the replicas only once\nin a while.\nFinally, there are classes of applications in which the ordering of updates\nis allowed to be different at the various replicas, as long as the differences\nremain bounded. One way of looking at these updates is that they are applied\ntentatively to a local copy, awaiting global agreement from all replicas. As\na consequence, some updates may need to be rolled back and applied in a\ndifferent order before becoming permanent. Intuitively, ordering deviations\nare much harder to grasp than the other two consistency metrics.\nThe notion of a conit\nTo define inconsistencies, Yu and Vahdat introduce a consistency unit, ab-\nbreviated to conit. A conit specifies the unit over which consistency is to\nbe measured. For example, in our stock-exchange example, a conit could\nbe defined as a record representing a single stock. Another example is an\nindividual weather report.\nTo give an example of a conit, and at the same time illustrate numerical\nand ordering deviations, consider the situation of keeping track of a fleet of\ncars. In particular, the fleet owner is interested in knowing how much she\npays on average for gas. To this end, whenever a driver tanks gasoline, she\nreports the amount of gasoline that has been tanked (recorded as g), the price\npaid (recorded as p), and the total distance since the last time she tanked\n(recorded by the variable d). Technically, the three variables g, p, and d form a\nconit. This conit is replicated across two servers, as shown in Figure 7.15, and\n \nDS 4.01\n\n\n412\nCHAPTER 7. CONSISTENCY AND REPLICATION\na driver regularly reports her gas usage to one of the servers by separately\nupdating each variable (without further considering the car in question).\nThe task of the servers is to keep the conit “consistently” replicated. To\nthis end, each replica server maintains a two-dimensional vector clock. We\nuse the notation ⟨T, R⟩to express an operation that was carried out by replica\nR at (its) logical time T.\nFigure 7.15: An example of keeping track of consistency deviations.\nIn this example, we see two replicas that operate on a conit containing the\ndata items g, p, and d from our example. All variables are assumed to have\nbeen initialized to 0. Replica A received the operation\n⟨5, B⟩: g ←g + 45\nfrom replica B. We have shaded this operation gray to indicate that A has\ncommitted this operation to its local store. In other words, it has been made\npermanent and cannot be rolled back. Replica A also has three tentative\nupdate operations listed: ⟨8, A⟩, ⟨9, A⟩, and ⟨10, A⟩, respectively. In terms of\ncontinuous consistency, the fact that A has three tentative operations pending\nto be committed is referred to as an order deviation of, in this case, value 3.\nAnalogously, with in total three operations of which two have been committed,\nB has an order deviation of 1.\nFrom this example, we see that A’s logical clock value is now 11. Because\nthe last operation from B that A had received had timestamp 5, the vector\nclock at A will be (11, 5), where we assume the first component of the vector\nis used for A and the second for B. Along the same lines, the logical clock at\nB is (0, 8).\nThe numerical deviation at a replica R consists of two components: the\nnumber of operations at all other replicas that have not yet been seen by\nDS 4.01\n \n\n\n7.2. DATA-CENTRIC CONSISTENCY MODELS\n413\nR, along with the sum of corresponding missed values (more sophisticated\nschemes are, of course, also possible). In our example, A has not yet seen\noperations ⟨6, B⟩and ⟨7, B⟩with a total value of 70 + 412 units, leading to a\nnumerical deviation of (2, 482). Likewise, B is still missing the three tentative\noperations at A, with a total summed value of 686, bringing B’s numerical\ndeviation to (3, 686).\nUsing these notions, it becomes possible to specify specific consistency\nschemes. For example, we may restrict order deviation by specifying an\nacceptable maximal value. Likewise, we may want two replicas to never nu-\nmerically deviate by more than 1000 units. Having such consistency schemes\ndoes require that a replica knows how much it is deviating from other replicas,\nimplying that we need separate communication to keep replicas informed.\nThe underlying assumption is that such communication is much less expen-\nsive than communication to keep replicas synchronized. Admittedly, it is\nquestionable if this assumption also holds for our example.\nNote 7.4 (Advanced: On the granularity of conits)\nThere is a trade-off between maintaining fine-grained and coarse-grained conits.\nIf a conit represents a lot of data, such as a complete database, then updates are\naggregated for all the data in the conit. As a consequence, this may bring replicas\nsooner in an inconsistent state. For example, assume that in Figure 7.16 two\nreplicas may differ in no more than one outstanding update. In that case, when\nthe data items in Figure 7.16 have each been updated once at the first replica, the\nsecond one will need to be updated as well. This is not the case when choosing\na smaller conit, as shown in Figure 7.16 There, the replicas are still considered\nto be up-to-date. This problem is particularly important when the data items\ncontained in a conit are used completely independently, in which case they are\nsaid to falsely share the conit.\n(a)\n(b)\nFigure 7.16: Choosing the appropriate granularity for a conit. (a) Two\nupdates lead to update propagation. (b) No update propagation is needed.\nUnfortunately, making conits small is not a good idea, for the simple reason\nthat the total number of conits that need to be managed grows as well. In other\nwords, there is an overhead related to managing the conits that needs to be\nconsidered. This overhead, in turn, may adversely affect overall performance,\nwhich also has to be considered.\n \nDS 4.01\n",
      "page_number": 416
    },
    {
      "number": 42,
      "title": "Segment 42 (pages 424-439)",
      "start_page": 424,
      "end_page": 439,
      "detection_method": "topic_boundary",
      "content": "414\nCHAPTER 7. CONSISTENCY AND REPLICATION\nAlthough, from a conceptual point of view, conits form an attractive means\nfor capturing consistency requirements, there are two important issues that\nneed to be dealt with before they can be put to practical use. First, to enforce\nconsistency, we need to have protocols. Protocols for continuous consistency\nare discussed later in this chapter.\nA second issue is that program developers must specify the consistency\nrequirements for their applications. Practice indicates that obtaining such\nrequirements may be extremely difficult. Programmers are generally not used\nto handling replication, let alone understanding what it means to provide\ndetailed information on consistency. Therefore, it is mandatory that there are\nsimple and easy-to-understand programming interfaces.\nNote 7.5 (Advanced: Programming conits)\nContinuous consistency can be implemented as a toolkit which appears to pro-\ngrammers as just another library that they link with their applications. A conit is\nsimply declared alongside an update of a data item. For example, the fragment of\npseudocode\nAffectsConit(ConitQ, 1, 1);\nappend message m to queue Q;\nstates that appending a message to queue Q belongs to a conit named ConitQ.\nLikewise, operations may now also be declared as being dependent on conits:\nDependsOnConit(ConitQ, 4, 0, 60);\nread message m from head of queue Q;\nIn this case, the call to DependsOnConit() specifies that the numerical deviation,\nordering deviation, and staleness should be limited to the values 4, 0, and 60\n(seconds), respectively. This can be interpreted as that there should be at most\n4 unseen update operations at other replicas, there should be no tentative local\nupdates, and the local copy of Q should have been checked for staleness no more\nthan 60 seconds ago. If these requirements are not fulfilled, the underlying\nmiddleware will attempt to bring the local copy of Q to a state such that the read\noperation can be carried out.\nThe question, of course, is how does the system know that Q is associated\nwith ConitQ? For practical reasons, we can avoid explicit declarations of conits\nand concentrate only on the grouping of operations. The data to be replicated is\ncollectively considered belonging together. By subsequently associating a write\noperation with a named conit, and likewise for a read operation, we tell the\nmiddleware layer when to start synchronizing the entire replica. Indeed, there may\nbe a considerable amount of false sharing in such a case. If false sharing needs\nto be avoided, we would have to introduce a separate programming construct to\nexplicitly declare conits.\nDS 4.01\n \n\n\n7.3. CLIENT-CENTRIC CONSISTENCY MODELS\n415\n7.3\nClient-centric consistency models\nData-centric consistency models aim at providing a systemwide consistent\nview on a data store. An important assumption is that concurrent processes\nmay be simultaneously updating the data store, and that it is necessary to\nprovide consistency in the face of such concurrency. For example, in the case\nof object-based entry consistency, the data store guarantees that when an\nobject is called, the calling process is provided with a copy of the object that\nreflects all changes to the object that have been made so far, possibly by other\nprocesses. During the call, it is also guaranteed that no other process can\ninterfere, that is, mutual exclusive access is provided to the calling process.\nBeing able to handle concurrent operations on shared data while maintain-\ning strong consistency is fundamental to distributed systems. For performance\nreasons, strong consistency may be guaranteed only when processes use mech-\nanisms such as transactions or synchronization variables. Along the same\nlines, it may be impossible to guarantee strong consistency, and weaker forms\nneed to be accepted, such as causal consistency with eventual consistency.\nIn this section, we take a look at a special class of distributed data stores.\nThe data stores we consider are characterized by the lack of simultaneous\nupdates, or when such updates happen, it is assumed that they can be\nrelatively easily resolved. Most operations involve reading data. These data\nstores offer a weak consistency model, such as eventual consistency. By\nintroducing special client-centric consistency models, it turns out that many\ninconsistencies can be hidden in a relatively cheap way.\nFigure 7.17: The principle of a mobile user accessing different replicas of a\ndistributed database.\n \nDS 4.01\n\n\n416\nCHAPTER 7. CONSISTENCY AND REPLICATION\nEventually, consistent data stores generally work fine as long as clients\nalways access the same replica. However, problems arise when different\nreplicas are accessed over a short period of time. This is best illustrated\nby considering a mobile user accessing a distributed database, as shown in\nFigure 7.17.\nThe mobile user, say, Alice, accesses the database by connecting to one\nof the replicas in a transparent way. In other words, the application running\non Alice’s mobile device is unaware on which replica it is actually operating.\nAssume Alice performs several update operations and then disconnects again.\nLater, she accesses the database again, possibly after moving to a different\nlocation or by using a different access device. At that point, she may be\nconnected to a different replica than before, as shown in Figure 7.17. However,\nif the updates performed previously have not yet been propagated, Alice\nwill notice inconsistent behavior. In particular, she would expect to see all\npreviously made changes, but instead, it appears as if nothing at all has\nhappened.\nThis example is typical for eventually consistent data stores and is caused\nby the fact that users may sometimes operate on different replicas, while\nupdates have not been fully propagated. The problem can be alleviated by\nintroducing client-centric consistency. In essence, client-centric consistency\nprovides guarantees for a single client concerning the consistency of accesses\nto a data store by that client. No guarantees are given concerning concurrent\naccesses by different clients. If Bob modifies data that is shared with Alice\nbut which is stored at a different location, we may easily create write-write\nconflicts. Moreover, if neither Alice nor Bob access the same location for some\ntime, such conflicts may take a long time before they are discovered.\nClient-centric consistency models originate from the work on Bayou and,\nmore general, from mobile-data systems (see, for example, Terry et al. [1994],\nTerry et al. [1998], or Terry [2008]). Bayou is a database system developed\nfor mobile computing, where it is assumed that network connectivity is\nunreliable and subject to various performance problems. Wireless networks\nand networks that span large areas, such as the Internet, fall into this category.\nBayou essentially distinguishes four different consistency models. To ex-\nplain these models, we again consider a data store that is physically distributed\nacross multiple machines. When a process accesses the data store, it generally\nconnects to the locally (or nearest) available copy, although, in principle, any\ncopy will do just fine. All read and write operations are performed on that\nlocal copy. Updates are eventually propagated to the other copies.\nClient-centric consistency models are described using the following no-\ntations. Let xi denote the version of data item x. The version xi is the result\nof a series of write operations that took place since initialization, its write\nset WS(xi). By appending write operations to thatseries, series we obtain\nanother version xj and say that xj follows from xi. We use the notation W(xi; xj)\nDS 4.01\n \n\n\n7.3. CLIENT-CENTRIC CONSISTENCY MODELS\n417\nto indicate that xj follows from xi. If we do not know if xj follows from xi, we\nuse the notation W(xi|xj).\n7.3.1\nMonotonic reads\nThe first client-centric consistency model is that of monotonic reads.\nA\n(distributed) data store is said to provide monotonic-read consistency if the\nfollowing condition holds:\nIf a process reads the value of a data item x, any successive read operation\non x by that process will always return that same value or a more recent\nvalue.\nIn other words, monotonic-read consistency guarantees that once a process\nhas seen a value of x, it will never see an older version of x.\nAs an example where monotonic reads are useful, consider a distributed\ne-mail database. In such a database, each user’s mailbox may be distributed\nand replicated across multiple machines. Mail can be inserted in a mailbox\nat any location. However, updates are propagated in a lazy (i.e., on demand)\nfashion. Only when a copy needs certain data for consistency are those data\npropagated to that copy. Suppose a user reads her mail in San Francisco.\nAssume that only reading mail does not affect the mailbox, that is, messages\nare not removed, stored in subdirectories, or even tagged as having already\nbeen read, and so on. When the user later flies to New York and opens her\nmailbox again, monotonic-read consistency guarantees that the messages that\nwere in the mailbox in San Francisco will also be in the mailbox when it is\nopened in New York.\nUsing a notation similar to that for data-centric consistency models,\nmonotonic-read consistency can be graphically represented as shown in Fig-\nure 7.18. Rather than showing processes along the vertical axis, we now show\nlocal data stores, in our example L1 and L2. A write or read operation is in-\ndexed by the process that executed the operation, that is, W1(x)a denotes that\nprocess P1 wrote value a to x. As we are not interested in specific values\nof shared data items, but rather their versions, we use the notation W1(x2)\nto indicate that process P1 produces version x2 without knowing anything\nabout other versions. W2(x1; x2) indicates that process P2 is responsible for\nproducing version x2 that follows from x1. Likewise, W2(x1|x2) denotes that\nprocess P2 producing version x2 concurrently to version x1 (and thus poten-\ntially introducing a write-write conflict). R1(x2) simply means that P1 reads\nversion x2.\nIn Figure 7.18(a) process P1 first performs a write operation on x at L1,\nproducing version x1 and later reads this version. At L2 process P2 first\nproduces version x2, following from x1. When process P1 moves to L2 and\nreads x again, it finds a more recent value, but one that at least took its\nprevious write into account.\n \nDS 4.01\n\n\n418\nCHAPTER 7. CONSISTENCY AND REPLICATION\n(a)\n(b)\nFigure 7.18: The read operations performed by a single process P at two\ndifferent local copies of the same data store. (a) A monotonic-read consistent\ndata store. (b) A data store that does not provide monotonic reads.\nFigure 7.18(b) shows a situation in which monotonic-read consistency is\nviolated. After process P1 has read x1 at L1, it later performs the operation\nR1(x2) at L2. However, the preceding write operation W2(x1|x2) by process\nP2 at L2 is known to produce a version that does not follow from x1. As a\nconsequence, P1’s read operation at L2 is known not to include the effect of\nthe write operations when it performed R1(x1) at location L1.\n7.3.2\nMonotonic writes\nIn many situations, it is important that write operations are propagated in\nthe correct order to all copies of the data store. This property is expressed\nin monotonic-write consistency. In a monotonic-write consistent store, the\nfollowing condition holds:\nA write operation by a process on a data item x is completed before any\nsuccessive write operation on x by the same process.\nMore formally, if we have two successive operations Wk(xi) and Wk(xj) by\nprocess Pk, then, regardless where Wk(xj) takes place, we also have Wk(xi; xj).\nThus, completing a write operation means that the copy on which a successive\noperation is performed reflects the effect of a previous write operation by\nthe same process, no matter where that operation was initiated. In other\nwords, a write operation on a copy of item x is performed only if that copy\nhas been brought up to date through any preceding write operation by that\nsame process, which may have taken place on other copies of x. If need be,\nthe new write must wait for old ones to finish.\nNote that monotonic-write consistency resembles data-centric FIFO consis-\ntency. The essence of FIFO consistency is that write operations by the same\nprocess are performed in the correct order everywhere. This ordering con-\nstraint also applies to monotonic writes, except that we are now considering\nconsistency only for a single process, instead of for a collection of processes.\nBringing a copy of x up to date need not be necessary when each write\noperation completely overwrites the present value of x. However, write opera-\ntions are often performed on only part of the state of a data item. Consider, for\nDS 4.01\n \n\n\n7.3. CLIENT-CENTRIC CONSISTENCY MODELS\n419\nexample, a software library. Often, updating such a library is done by replac-\ning one or more functions, leading to a next version. With monotonic-write\nconsistency, guarantees are given that if an update is performed on a copy of\nthe library, all preceding updates will be performed first. The resulting library\nwill then indeed become the most recent version and will include all updates\nthat have led to previous versions of the library.\nMonotonic-write consistency is shown in Figure 7.19. In Figure 7.19(a)\nprocess P1 performs a write operation on x at L1, presented as the operation\nW1(x1). Later, P1 performs another write operation on x, but this time at\nL2, shown as W1(x2; x3). The version produced by P1 at L2 follows from an\nupdate by process P2, in turn based on version x1. The latter is expressed\nby the operation W2(x1; x2). To ensure monotonic-write consistency, it is\nnecessary that the previous write operation at L1 has already been propagated\nto L2, and possibly updated.\n(a)\n(b)\n(c)\n(d)\nFigure 7.19: The write operations performed at two different local copies\nof the same data store. (a) A monotonic-write consistent data store. (b) A\ndata store that does not provide monotonic-write consistency. (c) Again, no\nconsistency as W2(x1|x2) and thus also W1(x1|x3). (d) Consistent as W1(x1; x3)\nalthough x1 has apparently overwritten x2.\nIn contrast, Figure 7.19(b) shows a situation in which monotonic-write\nconsistency is not guaranteed. Compared to Figure 7.19(a), what is missing is\nthe propagation of x1 to L2 before another version of x is produced, expressed\nby the operation W2(x1|x2). In this case, process P2 produced a concurrent\nversion to x1, after which process P1 simply produces version x3, but again\nconcurrently to x1. Only slightly more subtle, but still violating monotonic-\nwrite consistency, is the situation sketched in Figure 7.19(c). Process P1 now\nproduces version x3 which follows from x2. However, because x2 does not\nincorporate the write operations that led to x1, that is, W2(x1|x2), we also have\nW1(x1|x3).\nAn interesting case is shown in Figure 7.19(d). The operation W2(x1|x2)\nproduces version x2 concurrently to x1. However, later, process P1 produces\nversion x3, but apparently based on the fact that version x1 had become\n \nDS 4.01\n\n\n420\nCHAPTER 7. CONSISTENCY AND REPLICATION\navailable at L2. How and when x1 was transferred to L2 is left unspecified,\nbut in any case a write-write conflict was created with version x2 and resolved\nin favor of x1. A consequence is that the situation shown in Figure 7.19(d)\nfollows the rules for monotonic-write consistency. Note, however, that any\nsubsequent write by process P2 at L2 (without having read version x1) will\nimmediately violate consistency again. How such a violation can be prevented\nis left as an exercise to the reader.\nNote that, by the definition of monotonic-write consistency, write opera-\ntions by the same process are performed in the same order as they are initiated.\nA somewhat weaker form of monotonic writes is one in which the effects of a\nwrite operation are seen only if all preceding writes have been carried out as\nwell, but perhaps not in the order in which they have been originally initiated.\nThis consistency is applicable in those cases in which write operations are\ncommutative, so that ordering is really not necessary. Details are found in\n[Terry et al., 1994].\n7.3.3\nRead your writes\nA data store is said to provide read-your-writes consistency, if the following\ncondition holds:\nThe effect of a write operation by a process on data item x will always be\nseen by a successive read operation on x by the same process.\nIn other words, a write operation is always completed before a successive\nread operation by the same process, no matter the location where that read\noperation takes place.\nThe absence of read-your-writes consistency is sometimes experienced\nwhen updating Web documents and subsequently viewing the effects. Update\noperations frequently take place through a standard editor or word processor,\nperhaps embedded as part of a content management system, which then saves\nthe new version on a file system that is shared by the Web server. The user’s\nWeb browser accesses that same file, possibly after requesting it from the\nlocal Web server. However, once the file has been fetched, either the server or\nthe browser often caches a local copy for subsequent accesses. Consequently,\nwhen the Web page is updated, the user will not see the effects if the browser\nor the server returns the cached copy instead of the original file. Read-your-\nwrites consistency can guarantee that if the editor and browser are integrated\ninto a single program, the cache is invalidated when the page is updated, so\nthat the updated file is fetched and displayed.\nSimilar effects occur when updating passwords. For example, to enter a\ndigital library on the Web, it is often necessary to have an account with an\naccompanying password. However, changing a password may take some time\nto come into effect, with the result that the library may be inaccessible to the\nuser for a few minutes. The delay can be caused because a separate server\nDS 4.01\n \n\n\n7.3. CLIENT-CENTRIC CONSISTENCY MODELS\n421\nis used to manage passwords, and it may take some time to subsequently\npropagate (encrypted) passwords to the various servers that constitute the\nlibrary.\nFigure 7.20(a) shows a data store that provides read-your-writes consis-\ntency. Note that Figure 7.20(a) is very similar to Figure 7.18(a), except that\nconsistency is now determined by the last write operation by process P1,\ninstead of its last read.\n(a)\n(b)\nFigure 7.20: (a) A data store that provides read-your-writes consistency. (b) A\ndata store that does not.\nIn Figure 7.20(a) process P1 performed a write operation W1(x1) and\nlater a read operation at a different local copy. Read-your-writes consistency\nguarantees that the effects of the write operation can be seen by the succeeding\nread operation. This is expressed by W2(x1; x2), which states that a process P2\nproduced a new version of x, yet one based on x1. In contrast, in Figure 7.20(b)\nprocess P2 produces a version concurrently to x1, expressed as W2(x1|x2).\nThis means that the effects of the previous write operation by process P1 have\nnot been propagated to L2 at the time x2 was produced. When P1 reads x2, it\nwill not see the effects of its own write operation at L1.\n7.3.4\nWrites follow reads\nThe last client-centric consistency model is one in which updates are propa-\ngated as the result of previous read operations. A data store is said to provide\nwrites-follow-reads consistency, if the following holds.\nA write operation by a process on a data item x following a previous read\noperation on x by the same process is guaranteed to take place on the same\nor a more recent value of x that was read.\nIn other words, any successive write operation by a process on a data item\nx will be performed on a copy of x that is up to date with the value most\nrecently read by that process.\nWrites-follow-reads consistency can be used to guarantee that users of a\nnetwork newsgroup see a posting of a reaction to an article only after they\nhave seen the original article [Terry et al., 1994]. To understand the problem,\nassume that a user first reads an article A. Then, she reacts by posting a\nresponse B. By requiring writes-follow-reads consistency, B will be written\nto any copy of the newsgroup only after A has been written as well. Note\n \nDS 4.01\n\n\n422\nCHAPTER 7. CONSISTENCY AND REPLICATION\nthat users who only read articles need not require any specific client-centric\nconsistency model. The writes-follows-reads consistency assures that reactions\nto articles are stored at a local copy only if the original is stored there as well.\n(a)\n(b)\nFigure 7.21: (a) A writes-follow-reads consistent data store. (b) A data store\nthat does not provide writes-follow-reads consistency.\nThis consistency model is shown in Figure 7.21. In Figure 7.21(a), process\nP2 reads version x1 at local copy L1. This version of x was previously pro-\nduced at L1 by process P1 through the operation W1(x1). That version was\nsubsequently propagated to L2, and used by another process P3 to produce a\nnew version x2, expressed as W3(x1; x2). When process P2 later updates its\nversion of x after moving to L2, it is known that it will operate on a version that\nfollows from x1, expressed as W2(x2; x3). Because we also have W3(x1; x2), we\nknown that W1(x1; x3).\nThe situation shown in Figure 7.21(b) is different. Process P3 produces a\nversion x2 concurrently to that of x1. As a consequence, when P2 updates x\nafter reading x1, it will be updating a version it had not read before. Writes-\nfollow-reads consistency is then violated.\n7.3.5\nExample: client-centric consistency in ZooKeeper\nAn interesting example in which we see elements of data-centric and client-\ncentric consistency combined, is the model provided by ZooKeeper [Hunt\net al., 2010]. First, ZooKeeper guarantees that update operations are serializ-\nable and keep precedence. What this means, is that the state of ZooKeeper can\nalways be explained by some linear ordering in the execution of all submitted\nupdate operations, while preserving monotonic writes. In other words, while\nmultiple clients can concurrently update ZooKeeper’s state, the final result\ncan be understood by some interleaving of those updates while the ordering\nof operations as submitted per client is preserved. In addition, ZooKeeper\nguarantees monotonic reads. It does not, however, guarantee read-your-writes\nor writes-follow-read consistency.\nA simple perspective is to consider ZooKeeper as a collection of servers,\nwhile each client is connected to its own specific server. There is one, fixed\nprimary server to which all write operations are forwarded, and processed\nin the order as submitted by their respective clients. Read operations are\nexecuted by the server to which the client is connected (and in the order as\nsubmitted by that client). Nothing, however, is said about when the primary\nDS 4.01\n \n\n\n7.4. REPLICA MANAGEMENT\n423\nFigure 7.22: The consistency model of ZooKeeper explained through a naive\nimplementation.\nserver brings the other servers up to date. In other words, a client is left in\nthe dark concerning when it will see its own updates, or concurrent updates\nfrom other clients. This model is sketched in Figure 7.22.\nAssume that P1 first submits the operation W(x)a and then W(x)b. Process\nP2 submits the operation W(x)c. What is important is that monotonic writes\nare supported. In our example, the primary server receives the three write\noperations and decides to forward the operations W(x)a, W(x)c, and W(x)b\nin that order to the other stores. We have not specified when these operations\nare submitted or actually performed. Important is that this order needs to be\nobeyed.\nIf P1 submits read requests R(x), it may first read the initial value NIL,\nand then subsequently R(x)a and later R(x)c (and eventually, it will be able to\nread only R(x)b). Likewise, P2 may initially read NIL and later the final value\nR(x)b. Note that both P1 and P2 may read NIL even after having submitted\ntheir respective write operations. This demonstrates that ZooKeeper does\nnot provide read-your-writes consistency. Also, even if P1 had first read\nNIL and then submitted W(x)a; W(x)b, it may still read R(x)c if its latest\nwrite operation (R(x)b) had not yet been processed. This demonstrates that\nZooKeeper also does not provide writes-follow-reads consistency.\n7.4\nReplica management\nA key issue for any distributed system that supports replication is to decide\nwhere and when replicas should be placed, and subsequently which mech-\nanisms to use for keeping the replicas consistent. The placement problem\nitself should be split into two subproblems: that of placing replica servers, and\nthat of placing content. The difference is subtle and the two issues are often\nnot clearly separated. Replica-server placement is concerned with finding the\nbest locations to place a server that can host (part of) a data store. Content\n \nDS 4.01\n\n\n424\nCHAPTER 7. CONSISTENCY AND REPLICATION\nplacement deals with finding the best servers for placing content. Note that\nthis often means that we are looking for the optimal placement of only a single\ndata item. Obviously, before content placement can take place, replica servers\nwill have to be placed first.\n7.4.1\nFinding the best server location\nWhere perhaps over a decade ago one could be concerned about where to\nplace an individual server, matters have changed considerably with the advent\nof the many large-scale data centers located across the Internet. Likewise, con-\nnectivity continues to improve, making precisely locating servers less critical.\nThere are various ways to compute the best placement of replica servers,\nbut virtually all boil down to an optimization problem in which the best K\nout of N locations need to be selected (K < N). These problems are known\nto be computationally complex and can be solved only through heuristics.\nImportant in this respect is to decide on the criteria to even judge on a “best”\nsolution. In an extensive overview, Sahoo et al. [2017] distinguish cost-related\ncriteria and network-related criteria. Typical network-related criteria are\nlatencies between a server and its clients, the available bandwidth, the (logical)\ndistance as discussed in Section 5.7.3, and hop count. Of course, combinations\nare possible as well.\nBy now, there are many (often theoretical) models for deciding on the\nplacement of replica servers. Sahoo et al. [2017] classify these models as shown\nin Figure 7.23.\nMain class\nSubclass\nQoS Aware\nOptimized QoS\nBounded QoS\nConsistency Aware\nPeriodic update\nAperiodic update\nExpiration-based update\nCache-based update\nEnergy\nOthers\nFigure 7.23: Taxonomy of replica-placement algorithms (adapted from [Sahoo\net al., 2017]).\nLet us take a closer look at these different classes. When considering\nQuality of Service, that is QoS, server placement is decided by optimizing\nfor some or more QoS parameters. QoS is generally expressed in terms of\none or more of the network-related parameters. In the case of bounded QoS,\nsolutions are sought that guarantee a value of a certain QoS parameter, for\nexample, guaranteed bandwidth.\nDS 4.01\n \n\n\n7.4. REPLICA MANAGEMENT\n425\nAs mentioned, QoS awareness requires solving a computationally difficult\nproblem, meaning in practice that we need to resort to heuristics, and thus\napproximations of optimal values. This is generally not a problem, considering\nthat the QoS parameters itself may be rather imprecise. Consider, for example,\naccurately measuring latency between a client (end user) and a replica server.\nAs discussed in Section 5.7.3, this is by itself not an easy problem to solve\nwhen we cannot simply access that client. The best one can hope for, is\nthat an existing server is often enough connected to a client to get some idea\nof latencies. The same problem occurs for other parameters, in particular,\nbandwidth. As a consequence, we can try to accurately optimize on QoS, but\nwhen the basic input values are already very difficult to measure accurately,\noptimizations can quickly become quite theoretical. Quick-and-dirty heuristics\nmay be enough, yet we will need to take their results with a grain of salt.\nConsistency-aware algorithms take an entirely different approach. The\nbasic assumption is that there is an existing network for which we can decide\nwhere to place replica servers. Placement of servers will then involve costs\nfor keeping replicated content up to date. Those costs can be expressed in\nterms of when updates take place, as well as how. We return to these matters\nlater in Section 7.4.3 where we discuss replica management. The four different\nsubclasses deal with deciding on when updates are propagated to the replica\nserver (periodically, instantly, or only after some time), or from where (is a\nreplica server going to check the main server, or is it going to see whether a\nnearby server has an update). Again, we see that many theoretical models\nhave been developed to optimize consistency-aware algorithms, yet in this\ncase, such optimizations rely heavily on knowledge concerning read and\nupdate patterns. In practice, such knowledge is not readily available and may\neven be hard to get, let alone when it comes to predicting future patterns.\nEnergy-aware algorithms also assume an existing network to which clients\nconnect.\nPlacement of a replica server is then decided based on energy\nconsumption. To keep it simple, placing a server at a specific node and\nkeeping it up and running when there are only few clients, may be costly\nin terms of energy. The server in that case does not have enough work\nto do, while its idle time does consume energy.\nAnother criterion is to\ndecide on placement at nodes that support energy efficiency, for example,\nby switching between different power modes. Finally, placement may also\nbe influenced by optimizing the distribution of work (measured in terms of\nenergy consumption) among more or less replica servers, given that we know\nthe various access patterns of a set of clients. As before, we see that much\nneeds to be known about those patterns, as well as the capacities and facilities\nof the network, to make practically sensible decisions.\nFinally, there are other classes for deciding on replica-server placement.\nSahoo et al. have concentrated on server placement for CDNs. Such dis-\ntributed systems are spread across many organizations (formally known as\n \nDS 4.01\n\n\n426\nCHAPTER 7. CONSISTENCY AND REPLICATION\nAutonomous Systems, that is, an organization in charge of a separate network\nwithin the Internet). Replica-server placement then also involves monetary\ncosts that need to be negotiated with those organizations. Likewise, placement\ndecisions can be based on the connectivity of clients to a specific autonomous\nsystem, along with the costs in terms of QoS parameters or monetary costs.\nFurther details can be found in [Sahoo et al., 2017].\n7.4.2\nContent replication and placement\nWhen it comes to content replication and placement, three different types of\nreplicas can be distinguished, logically organized as shown in Figure 7.24.\nPermanent\nreplicas\nServer-initiated replicas\nClient-initiated replicas\nClients\nClient-initiated replication\nServer-initiated replication\nFigure 7.24: The logical organization of different kinds of copies of a data\nstore into three concentric rings.\nPermanent replicas\nPermanent replicas can be considered as the initial set of replicas that con-\nstitute a distributed data store. Often, the number of permanent replicas is\nsmall. Consider, for example, a Website. Distribution of a Website generally\ncomes in one of two forms. The first kind of distribution is one in which the\nfiles that constitute a site are replicated across a limited number of servers at\na single location. Whenever a request comes in, it is forwarded to one of the\nservers, for instance, using a round-robin strategy.\nThe second form of distributed Websites is what is called mirroring. In\nthis case, a Website is copied to a limited number of servers, called mirror\nsites, which are geographically spread across the Internet. Often, clients\nsimply choose one of the various mirror sites from a list offered to them, or\nare transparently forwarded to one of the mirrors. Mirrored Websites have in\ncommon with cluster-based Websites that there are only a few replicas, which\nare more or less statically configured.\nSimilar static organizations also appear with distributed databases [Kemme\net al., 2010; Özsu and Valduriez, 2020]. Again, the database can be distributed\nDS 4.01\n \n\n\n7.4. REPLICA MANAGEMENT\n427\nand replicated across a number of servers that together form a cluster of\nservers, often referred to as a shared-nothing architecture, emphasizing that\nneither disks nor main memory are shared by processors. Alternatively, a\ndatabase is distributed and possibly replicated across a number of geograph-\nically dispersed sites. This architecture is generally deployed in federated\ndatabases [Sheth and Larson, 1990; Azevedo et al., 2020].\nServer-initiated replicas\nIn contrast to permanent replicas, server-initiated replicas are copies of a\ndata store that exist to enhance performance, and created at the initiative of\nthe (owner of the) data store. Consider, for example, a Web server placed in\nNew York. Normally, this server can handle incoming requests effortlessly,\nbut it may happen that over a couple of days a sudden burst of requests\ncome in from an unexpected location far from the server. In that case, it may\nbe worthwhile to install a number of temporary replicas in regions where\nrequests are coming from.\nWeb hosting has often been taken over by Content Delivery Networks, and\nfor good reasons. Most important is that Web pages are no longer just a simple\ncollection of static pages, but combine databases with static and dynamic\ncontent. As a result, replication needs to be much more sophisticated than\njust pushing pages to specific locations. We outlined the principal operation\nof a CDN in Section 3.4.4. Important is that, in general, replication is on\ndemand. The CDN notices that requests are coming from a client, the client is\ndirected to a nearest replica server, and that server checks to see whether it\nhas the requested content cached locally. Obviously, there are many options\nconcerning decisions on where to redirect the client to, and also when and\nwhich content to actually store. For our discussion here, despite that content\nis replicated to a server because of a client request, because the CDN is in\ncontrol when it comes to the aforementioned decisions, it is still appropriate\nto speak of server-initiated replication. That the initiative has been delegated\nto a CDN is less important.\nNote 7.6 (More information: An example of dynamic Web-content placement)\nThe problem of dynamically placing replicas has since long been addressed in\nWeb hosting services (and by now in content delivery networks). Historically,\nthese services offered an often relatively static collection of servers spread across\nthe Internet that maintained and provided access to Web files belonging to third\nparties. To provide optimal facilities, such hosting services dynamically replicated\nfiles to servers where those files are needed to enhance performance, that is, close\nto demanding (groups of) clients.\nGiven that the replica servers are already in place, deciding where to place\ncontent is not that difficult. An early case toward dynamic replication of files in\nthe case of a Web hosting service is described by Rabinovich et al. [1999]. The\n \nDS 4.01\n\n\n428\nCHAPTER 7. CONSISTENCY AND REPLICATION\nalgorithm is designed to support Web pages, for which reason it assumes that\nupdates are relatively rare compared to read requests. Using files as the unit of\ndata, the algorithm works as follows.\nThe algorithm for dynamic replication takes two issues into account. First,\nreplication can take place to reduce the load on a server. Second, specific files\non a server can be migrated or replicated to servers placed in the proximity of\nclients that issue many requests for those files. In the following, we concentrate\nonly on this second issue. We also omit a number of details, which can be found\nin [Rabinovich et al., 1999].\nFigure 7.25: Counting access requests from different clients.\nEach server keeps track of access counts per file, and where access requests\ncome from. In particular, when a client C enters the service, it does so through\na server close to it. If client C1 and client C2 share the same closest server P, all\naccess requests for file F at server Q from C1 and C2 are jointly registered at Q as\na single access count cntQ(P, F). This situation is shown in Figure 7.25.\nWhen the number of requests for a specific file F at server S drops below a\ndeletion threshold del(S, F), that file can be removed from S. As a consequence,\nthe number of replicas of that file is reduced, possibly leading to higher work\nloads at other servers. Special measures are taken to ensure that at least one copy\nof each file continues to exist.\nA replication threshold rep(S, F), which is always chosen higher than the\ndeletion threshold, indicates that the number of requests for a specific file is so\nhigh that it may be worthwhile replicating it on another server. If the number of\nrequests lies somewhere between the deletion and replication threshold, the file\nis allowed to be only migrated. In other words, in that case, it is important to at\nleast keep the number of replicas for that file the same.\nWhen a server Q decides to reevaluate the placement of the files it stores, it\nchecks the access count for each file. If the total number of access requests for F\nat Q drops below the deletion threshold del(Q, F), it will delete F unless it is the\nlast copy. Furthermore, if for some server P, cntQ(P, F) exceeds more than half of\nthe total requests for F at Q, server P is requested to take over the copy of F. In\nother words, server Q will attempt to migrate F to P.\nMigration of file F to server P may not always succeed, for example because P\nis already heavily loaded or is out of disk space. In that case, Q will attempt to\nDS 4.01\n \n\n\n7.4. REPLICA MANAGEMENT\n429\nreplicate F on other servers. Of course, replication can take place only if the total\nnumber of access requests for F at Q exceeds the replication threshold rep(Q, F).\nServer Q checks all other servers in the Web hosting service, starting with the one\nfarthest away. If, for some server R, cntQ(R, F) exceeds a certain fraction of all\nrequests for F at Q, an attempt is made to replicate F to R.\nWhat we have just described is an alternative to simply caching content at a\nreplica server when a client request comes in, as we described for content delivery\nnetworks. There is no fundamental reason why the algorithm for copying and\nmigration of content cannot be applied in CDNs as well.\nClient-initiated replicas\nAn important kind of replica is the one initiated by a client. Client-initiated\nreplicas are more commonly known as client caches. In essence, a cache is a\nlocal storage facility that is used by a client to temporarily store a copy of the\ndata it has just requested. In principle, managing the cache is left entirely to\nthe client. The data store from where the data had been fetched has nothing to\ndo with keeping cached data consistent. However, there are many occasions\nin which the client can rely on participation from the data store to inform it\nwhen cached data has become stale.\nClient caches are used only to improve access times to data. Normally,\nwhen a client wants access to some data, it connects to the nearest copy of the\ndata store from where it fetches the data it wants to read, or to where it stores\nthe data it had just modified. When most operations involve only reading\ndata, performance can be improved by letting the client store requested data\nin a nearby cache. Such a cache could be located on the client’s machine, or\non a separate machine in the same local-area network as the client. The next\ntime that same data needs to be read, the client can simply fetch it from this\nlocal cache. This scheme works fine as long as the fetched data have not been\nmeanwhile modified.\nData are generally kept in a cache for a limited amount of time, for example,\nto prevent extremely stale data from being used, or simply to make room\nfor other data. Whenever requested data can be fetched from the local cache,\na cache hit is said to have occurred. To improve the number of cache hits,\ncaches can be shared between clients. The underlying assumption is that a\ndata request from client C1 may also be useful for a request from another\nnearby client C2.\nWhether this assumption is correct depends very much on the type of data\nstore. For example, in traditional file systems, data files are rarely shared at all\n(see, e.g., Muntz and Honeyman [1992] and Blaze [1993]) rendering a shared\ncache useless. Likewise, it turns out that using Web caches to share data\nhas been losing ground, partly also because of the improvement in network\n \nDS 4.01\n",
      "page_number": 424
    },
    {
      "number": 43,
      "title": "Segment 43 (pages 440-450)",
      "start_page": 440,
      "end_page": 450,
      "detection_method": "topic_boundary",
      "content": "430\nCHAPTER 7. CONSISTENCY AND REPLICATION\nand server performance. Instead, server-initiated replication schemes are\nbecoming more effective.\nPlacement of client caches is relatively simple: a cache is normally placed\non the same machine as its client, or otherwise on a machine shared by clients\non the same local-area network. However, in some cases, extra levels of\ncaching are introduced by system administrators by placing a shared cache\nbetween a number of departments or organizations, or even placing a shared\ncache for an entire region such as a province or country.\nYet another approach is to place (cache) servers at specific points in a\nwide-area network and let a client locate the nearest server. When the server is\nlocated, it can be requested to hold copies of the data the client was previously\nfetching from somewhere else [Noble et al., 1999].\n7.4.3\nContent distribution\nReplica management also deals with propagation of (updated) content to the\nrelevant replica servers. There are various trade-offs to make.\nState versus operations\nAn important design issue concerns what is actually to be propagated. Basi-\ncally, there are three possibilities:\n• Propagate only a notification of an update.\n• Transfer data from one copy to another.\n• Propagate the update operation to other copies.\nPropagating a notification is what invalidation protocols do. In an invali-\ndation protocol, other copies are informed that an update has taken place\nand that the data they contain are no longer valid. The invalidation may\nspecify which part of the data store has been updated, so that only part of\na copy is actually invalidated. The important issue is that no more than a\nnotification is propagated. Whenever an operation on an invalidated copy is\nrequested, that copy generally needs to be updated first, depending on the\nspecific consistency model that is to be supported.\nThe main advantage of invalidation protocols is that they use little network\nbandwidth. The only information that needs to be transferred is a specification\nof which data are no longer valid. Such protocols generally work best when\nthere are many update operations compared to read operations, that is, the\nread-to-write ratio is relatively small.\nConsider, for example, a data store in which updates are propagated by\nsending the modified data to all replicas. If the size of the modified data is\nlarge, and updates occur frequently compared to read operations, we may\nhave the situation that two updates occur after one another without any read\nDS 4.01\n \n\n\n7.4. REPLICA MANAGEMENT\n431\noperation being performed between them. Consequently, propagation of the\nfirst update to all replicas is effectively useless, as it will be overwritten by\nthe second update. Instead, sending a notification that the data have been\nmodified would have been more efficient.\nTransferring the modified data among replicas is the second alternative,\nand is useful when the read-to-write ratio is relatively high. In that case, the\nprobability that an update will be effective in the sense that the modified data\nwill be read before the next update takes place is high. Instead of propagating\nmodified data, it is also possible to log the changes and transfer only those\nlogs to save bandwidth. In addition, transfers are often aggregated in the\nsense that multiple modifications are packed into a single message, thus\nsaving communication overhead.\nThe third approach is not to transfer any data modifications at all, but\nto tell each replica which update operation it should perform (and sending\nonly the parameter values that those operations need). This approach, also\nreferred to as active replication, assumes that each replica is represented\nby a process capable of “actively” keeping its associated data up to date by\nperforming operations [Schneider, 1990]. The main benefit of active replication\nis that updates can often be propagated at minimal bandwidth costs, provided\nthe size of the parameters associated with an operation are relatively small.\nMoreover, the operations can be of arbitrary complexity, which may allow\nfurther improvements in keeping replicas consistent. On the other hand, more\nprocessing power may be required by each replica, especially in those cases\nwhen operations are relatively complex.\nPull versus push protocols\nAnother design issue is whether updates are pulled or pushed. In a push-\nbased approach, also referred to as server-based protocols, updates are\npropagated to other replicas without those replicas even asking for the updates.\nPush-based approaches are often used between permanent and server-initiated\nreplicas, but can also be used to push updates to client caches. Server-based\nprotocols are generally applied when strong consistency is required.\nThis need for strong consistency is related to the fact that permanent and\nserver-initiated replicas, as well as large shared caches, are often shared by\nmany clients, which, in turn, mainly perform read operations. Consequently,\nthe read-to-update ratio at each replica is relatively high. In these cases, push-\nbased protocols are efficient in the sense that every pushed update can be\nexpected to be of use for at least one, but perhaps more readers. In addition,\npush-based protocols make consistent data immediately available when asked\nfor.\nIn contrast, in a pull-based approach, a server or client requests another\nserver to send it any updates it has at that moment. Pull-based protocols, also\ncalled client-based protocols, are often used by client caches. For example, a\n \nDS 4.01\n\n\n432\nCHAPTER 7. CONSISTENCY AND REPLICATION\ncommon strategy applied to Web caches is first to check whether cached data\nitems are still up-to-date. When a cache receives a request for items that are\nstill locally available, the cache checks with the original Web server, whether\nthose data items have been modified since they were cached. In the case of\na modification, the modified data are first transferred to the cache, and then\nreturned to the requesting client. If no modifications took place, the cached\ndata are returned. In other words, the client polls the server to see whether\nan update is needed. A similar approach is followed in content delivery\nnetworks where a replica server caches content, yet checks with the origin\nserver whether updates are available before delivering its (cached) content to\nthe actual client (i.e., end user). Note that in this respect, the replica server\nacts as a client to the origin server.\nA pull-based approach is efficient when the read-to-update ratio is rela-\ntively low. This is often the case with (nonshared) client caches, which have\nonly one client. However, even when a cache is shared by many clients, a\npull-based approach may also be efficient when the cached data items are\nrarely shared. The main drawback of a pull-based strategy in comparison to a\npush-based approach is that the response time increases in the case of a cache\nmiss.\nWhen comparing push-based and pull-based solutions, there are a number\nof trade-offs to be made, as shown in Figure 7.26. For simplicity, consider a\nclient-server system consisting of a single, nondistributed server, and a number\nof client processes, each having their own cache. We make no distinction\nbetween clients at end users (such as Web browsers), or clients within, for\nexample, a content delivery network (such as replica servers).\nIssue\nPush-based\nPull-based\nState at server\nList of client replicas and caches\nNone\nMessages sent\nUpdate (and possibly fetch update\nlater)\nPoll and update\nResponse time\nat client\nImmediate (or fetch-update time)\nFetch-update\ntime\nFigure 7.26: A comparison between push-based and pull-based protocols in\nthe case of multiple-client, single-server systems.\nAn important issue is that in push-based protocols, the server needs to\nkeep track of all client caches, be they at end users or replica servers. Apart\nfrom the fact that stateful servers are often less fault tolerant, keeping track\nof all such caches may introduce a considerable overhead at the server. For\nexample, in a push-based approach, a Web server may easily need to keep\ntrack of tens of thousands of client caches. Each time a Web page is updated,\nthe server will have to go through its list of client caches holding a copy of that\npage and subsequently propagate the update. Worse yet, if a client purges a\nDS 4.01\n \n\n\n7.4. REPLICA MANAGEMENT\n433\npage due to lack of space, it has to inform the server, leading to even more\ncommunication.\nThe messages that need to be sent between a client and the server also\ndiffer. In a push-based approach, the only communication is that the server\nsends updates to each client. When updates are only invalidations, additional\ncommunication is needed by a client to fetch the modified data. In a pull-\nbased approach, a client will have to poll the server, and, if necessary, fetch\nthe modified data.\nFinally, the response time at the client is also different. When a server\npushes modified data to the client caches, it is clear that the response time at\nthe client side is zero. When invalidations are pushed, the response time is\nthe same as in the pull-based approach, and is determined by the time it takes\nto fetch the modified data from the server.\nThese trade-offs have lead to a hybrid form of update propagation based\non leases. In the case of replica management, a lease is a promise by the\nserver that it will push updates to the client for a specified time. When a\nlease expires, the client is forced to poll the server for updates and pull in the\nmodified data if necessary. An alternative is that a client requests a new lease\nfor pushing updates when the previous lease expires.\nLeases, originally introduced by Gray and Cheriton [1989], provide a\nconvenient mechanism for dynamically switching between a push-based\nand pull-based strategy. Consider the following lease system that allows\nthe expiration time to be dynamically adapted depending on different lease\ncriteria, described in [Duvvuri et al., 2003]. We distinguish the following three\ntypes of leases. (Note that in all cases, updates are pushed by the server as\nlong as the lease has not expired.)\nFirst, age-based leases are given out on data items depending on the last\ntime the item was modified. The underlying assumption is that data that\nhave not been modified for a long time can be expected to remain unmodified\nfor some time yet to come. This assumption has shown to be reasonable\nin the case of, for example, Web-based data and regular files. By granting\nlong-lasting leases to data items that are expected to remain unmodified, the\nnumber of update messages can be strongly reduced compared to the case\nwhere all leases have the same expiration time.\nAnother lease criterion is how often a specific client requests its cached\ncopy to be updated. With renewal-frequency-based leases, a server will hand\nout a long-lasting lease to a client whose cache often needs to be refreshed.\nOn the other hand, a client that asks only occasionally for a specific data item\nwill be handed a short-term lease for that item. The effect of this strategy is\nthat the server essentially keeps track only of those clients where its data are\npopular; moreover, those clients are offered a high degree of consistency.\nThe last criterion is that of state-space overhead at the server. When\nthe server realizes that it is gradually becoming overloaded, it lowers the\n \nDS 4.01\n\n\n434\nCHAPTER 7. CONSISTENCY AND REPLICATION\nexpiration time of new leases it hands out to clients. The effect of this state-\nbased lease strategy is that the server needs to keep track of fewer clients as\nleases expire more quickly. In other words, the server dynamically switches\nto a more stateless mode of operation, thereby expecting to offload itself so\nthat it can handle requests more efficiently. The obvious drawback is that it\nmay need to do more work when the read-to-update ratio is high.\nUnicasting versus multicasting\nRelated to pushing or pulling updates is deciding whether unicasting or\nmulticasting should be used. In unicast communication, when a server that is\npart of the data store sends its update to N other servers, it does so by sending\nN separate messages, one to each server. With multicasting, the underlying\nnetwork takes care of sending a message efficiently to multiple receivers.\nOften, it is cheaper to use available multicasting facilities. An extreme\nsituation is when all replicas are located in the same local-area network\nand that hardware broadcasting is available. In that case, broadcasting or\nmulticasting a message is no more expensive than a single point-to-point\nmessage. Unicasting updates would then be less efficient.\nMulticasting can often be efficiently combined with a push-based approach\nto propagating updates. When the two are carefully integrated, a server that\ndecides to push its updates to a number of other servers simply uses a single\nmulticast group to send its updates. In contrast, with a pull-based approach, it\nis generally only a single client or server that requests its copy to be updated.\nIn that case, unicasting may be the most efficient solution.\n7.4.4\nManaging replicated objects\nAs we mentioned, data-centric consistency for distributed objects comes\nnaturally in the form of entry consistency. Recall that in this case, the goal\nis to group operations on shared data using synchronization variables (e.g.,\nin the form of locks). As objects naturally combine data and the operations\non that data, locking objects during an invocation serializes access and keeps\nthem consistent.\nAlthough conceptually associating a lock with an object is simple, it does\nnot necessarily provide a proper solution when an object is replicated. There\nare two issues that need to be solved for implementing entry consistency. The\nfirst one is that we need a means to prevent concurrent execution of multiple\ninvocations on the same object. In other words, when any method of an\nobject is being executed, no other methods may be executed. This requirement\nensures that access to the internal data of an object is indeed serialized. Simply\nusing local locking mechanisms will ensure this serialization.\nThe second issue is that in the case of a replicated object, we need to ensure\nthat all changes to the replicated state of the object are the same. In other\nDS 4.01\n \n\n\n7.4. REPLICA MANAGEMENT\n435\nwords, we need to make sure that no two independent method invocations\ntake place on different replicas at the same time. This requirement implies\nthat we need to order invocations such that each replica sees all invocations\nin the same order. We describe a few general solutions in Section 7.5.\nOften, designing replicated objects is done by first designing a single object,\npossibly protecting it against concurrent access through local locking, and\nsubsequently replicating it. The role of middleware is to ensure that if a client\ninvokes a replicated object, the invocation is passed to the replicas and handed\nto the their respective object servers in the same order everywhere. However,\nwe also need to ensure that all threads in those servers process those requests\nin the correct order as well. The problem is sketched in Figure 7.27.\nMiddleware\nLocal OS\nThreads\nUnordered requests\nTotally ordered\nrequests\nMiddleware\nLocal OS\nThreads\nThread\nscheduler\nDeterministic\nthread scheduling\nUnordered requests\nObject\nComputer 1\nComputer 2\nT1\n1\nT2\n1\nT2\n2\nT1\n2\nReplica\nFigure 7.27: Deterministic thread scheduling for replicated object servers.\nMultithreaded (object) servers simply pick up an incoming request, pass\nit on to an available thread, and wait for the next request to come in. The\nserver’s thread scheduler subsequently allocates the CPU to runnable threads.\nOf course, if the middleware has done its best to provide a total ordering\nfor request delivery, the thread schedulers should operate in a deterministic\nfashion in order not to mix the ordering of method invocations on the same\nobject. In other words, If threads T1\n1 and T2\n1 from Figure 7.27 handle the\nsame incoming (replicated) invocation request, they should both be scheduled\nbefore T1\n2 and T2\n2, respectively.\nSimply scheduling all threads deterministically is not necessary. In prin-\nciple, if we already have totally ordered request delivery, we need only to\nensure that all requests for the same replicated object are handled in the order\nthey were delivered. Such an approach would allow invocations for different\nobjects to be processed concurrently, and without further restrictions from the\nthread scheduler. Only few systems exist that support such concurrency.\n \nDS 4.01\n\n\n436\nCHAPTER 7. CONSISTENCY AND REPLICATION\nOne approach, described by Basile et al. [2002], ensures that threads\nsharing the same (local) lock are scheduled in the same order on every replica.\nAt the basics lies a primary-based scheme in which one of the replica servers\ntakes the lead in determining, for a specific lock, which thread goes first.\nAn improvement that avoids frequent communication between servers is\ndescribed in [Basile et al., 2003]. Note that threads that do not share a lock\ncan thus operate concurrently on each server.\nOne drawback of this scheme is that it operates at the level of the under-\nlying operating system, meaning that every lock needs to be managed. By\nproviding application-level information, a huge improvement in performance\ncan be made by identifying only those locks that are required for serializing\naccess to replicated objects (see Taiani et al. [2005]).\nNote 7.7 (Advanced: Replicated invocations)\nAnother problem that needs to be solved is that of replicated invocations. Con-\nsider an object A calling another object B as shown in Figure 7.28. Object B is\nassumed to call yet another object C. If B is replicated, each replica of B will,\nin principle, call C independently. The problem is that C is now called multiple\ntimes instead of only once. If the called method on C results in the transfer of\n$100,000, then clearly, someone is, sooner or later, going to complain.\nFigure 7.28: The problem of replicated object invocations.\nThere are not many general-purpose solutions to solve the problem of repli-\ncated invocations. One solution is to simply forbid it [Maassen et al., 2001],\nwhich makes sense when performance is at stake. However, when replicating for\nfault tolerance, the following solution proposed by Mazouni et al. [1995] may be\ndeployed. Their solution is independent of the replication policy, that is, the exact\ndetails of how replicas are kept consistent. The essence is to provide a replication-\naware communication layer on top of which (replicated) objects execute. When\na replicated object B invokes another replicated object C, the invocation request\nis first assigned the same, unique identifier by each replica of B. At that point, a\ncoordinator of the replicas of B forwards its request to all the replicas of object C,\nDS 4.01\n \n\n\n7.5. CONSISTENCY PROTOCOLS\n437\nwhile the other replicas of B hold back their copy of the invocation request, as\nshown in Figure 7.29. The result is that only a single request is forwarded to each\nreplica of C.\nThe same mechanism is used to ensure that only a single reply message is\nreturned to the replicas of B. This situation is shown in Figure 7.29. A coordinator\nof the replicas of C notices it is dealing with a replicated reply message that has\nbeen generated by each replica of C. However, only the coordinator forwards that\nreply to the replicas of object B, while the other replicas of C hold back their copy\nof the reply message.\n(a)\n(b)\nFigure 7.29: (a) Forwarding an invocation request from a replicated object\nto another replicated object. (b) Returning a reply from one replicated\nobject to another.\nWhen a replica of B receives a reply message for an invocation request it had\neither forwarded to C or held back because it was not the coordinator, the reply is\nthen handed to the actual object.\nIn essence, the scheme just described is based on using multicast communica-\ntion, but preventing that the same message is multicast by different replicas. As\nsuch, it is essentially a sender-based scheme. An alternative solution is to let a\nreceiving replica detect multiple copies of incoming messages belonging to the\nsame invocation, and to pass only one copy to its associated object. Details of this\nscheme are left as an exercise.\n7.5\nConsistency protocols\nWe now concentrate on the actual implementation of consistency models\nby taking a look at several consistency protocols. A consistency protocol\ndescribes an implementation of a specific consistency model. We follow the\norganization of our discussion on consistency models by first taking a look at\ndata-centric models, followed by protocols for client-centric models.\n \nDS 4.01\n\n\n438\nCHAPTER 7. CONSISTENCY AND REPLICATION\n7.5.1\nSequential consistency: Primary-based protocols\nIn practice, we see that distributed applications generally follow consistency\nmodels that are relatively easy to understand. These models include those for\nbounding staleness deviations, and to a lesser extent also those for bounding\nnumerical deviations. When it comes to models that handle consistent order-\ning of operations, sequential consistency, notably those in which operations\ncan be grouped through locking or transactions, are popular.\nAs soon as consistency models become slightly difficult to understand for\napplication developers, we see that they are ignored even if performance could\nbe improved. The bottom line is that if the semantics of a consistency model\nare not intuitively clear, application developers will have a hard time building\ncorrect applications. Simplicity is appreciated (and perhaps justifiably so).\nIn the case of sequential consistency, it turns out that primary-based\nprotocols prevail. In these protocols, each data item x in the data store has an\nassociated primary, which is responsible for coordinating write operations on\nx. A distinction can be made whether the primary is fixed at a remote server\nor if write operations can be carried out locally after moving the primary to\nthe process where the write operation is initiated.\nRemote-write protocols\nThe simplest primary-based protocol that supports replication is the one in\nwhich all write operations need to be forwarded to a fixed single server.\nRead operations can be carried out locally. Such schemes are also known\nas primary-backup protocols [Budhijara et al., 1993]. A primary-backup\nprotocol works as shown in Figure 7.30. A process wanting to perform a write\noperation on data item x, forwards that operation to the primary server for\nx. The primary performs the update on its local copy of x, and subsequently\nforwards the update to the backup servers. Each backup server performs\nthe update as well, and sends an acknowledgment to the primary. When all\nbackups have updated their local copy, the primary sends an acknowledgment\nto the initial process, which, in turn, informs the client.\nA potential performance problem with this scheme is that it may take a\nrelatively long time before the process that initiated the update is allowed to\ncontinue. In effect, an update is implemented as a blocking operation. An\nalternative is to use a nonblocking approach. As soon as the primary has\nupdated its local copy of x, it returns an acknowledgment. After that, it tells\nthe backup servers to perform the update as well. Nonblocking primary-\nbackup protocols are discussed in [Budhiraja and Marzullo, 1992].\nThe main problem with nonblocking primary-backup protocols has to do\nwith fault tolerance. In a blocking scheme, the client process knows for sure\nthat the update operation is backed up by several other servers. This is not\nDS 4.01\n \n\n\n7.5. CONSISTENCY PROTOCOLS\n439\nFigure 7.30: The principle of a primary-backup protocol.\nthe case with a nonblocking solution. The advantage, of course, is that write\noperations may speed up considerably.\nPrimary-backup protocols provide a straightforward implementation of\nsequential consistency, as the primary can order all incoming writes in a\nglobally unique order. Evidently, all processes see all write operations in\nthe same order, no matter which backup server they use to perform read\noperations. Also, with blocking protocols, processes will always see the effects\nof their most recent write operation (note that this cannot be guaranteed with\na nonblocking protocol without taking special measures).\nLocal-write protocols\nA variant of primary-backup protocols is one in which the primary copy\nmigrates between processes that wish to perform a write operation.\nAs\nbefore, whenever a process wants to update a data item x, it locates the\nprimary copy of x, and subsequently moves it to its own location, as shown in\nFigure 7.31. The main advantage of this approach is that multiple, successive\nwrite operations can be carried out locally, while reading processes can still\naccess their local copy. However, such an improvement can be achieved only\nif a nonblocking protocol is followed by which updates are propagated to the\nreplicas after the primary has finished with locally performing the updates.\nThis primary-backup local-write protocol can also be applied to mobile\ncomputers that can operate in disconnected mode. Before disconnecting, the\nmobile computer becomes the primary server for each data item it expects to\nupdate. While being disconnected, all update operations are carried out locally,\nwhile other processes can still perform read operations (but no updates).\n \nDS 4.01\n\n\n440\nCHAPTER 7. CONSISTENCY AND REPLICATION\nFigure 7.31: Primary-backup protocol in which the primary migrates to the\nprocess wanting to perform an update.\nLater, when connecting again, updates are propagated from the primary to\nthe backups, bringing the data store in a consistent state again.\nAs a last variant of this scheme, nonblocking local-write primary-based\nprotocols are also used for distributed file systems in general. In this case, there\nmay be a fixed central server through which normally all write operations\ntake place, as in the case of remote-write primary backup. However, the server\ntemporarily allows one of the replicas to perform a series of local updates,\nas this may considerably speed up performance. When the replica server is\ndone, the updates are propagated to the central server, from where they are\nthen distributed to the other replica servers.\n7.5.2\nSequential consistency: Replicated-write protocols\nIn replicated-write protocols, write operations can be carried out at multiple\nreplicas instead of only one, as in the case of primary-based replicas. A\ndistinction can be made between active replication, in which an operation is\nforwarded to all replicas, and consistency protocols based on majority voting.\nActive replication\nIn active replication, each replica has an associated process that carries out\nupdate operations.\nIn contrast to other protocols, updates are generally\npropagated through the write operation that causes the update. In other\nwords, the operation is sent to each replica. However, it is also possible to\nsend the update.\nDS 4.01\n \n",
      "page_number": 440
    },
    {
      "number": 44,
      "title": "Segment 44 (pages 451-458)",
      "start_page": 451,
      "end_page": 458,
      "detection_method": "topic_boundary",
      "content": "7.5. CONSISTENCY PROTOCOLS\n441\nOne problem with active replication is that operations need to be carried\nout in the same order everywhere. Consequently, what is needed is a totally\nordered multicast mechanism.\nA practical approach to accomplish total\nordering is by a central coordinator, also called a sequencer. One approach\nis to first forward each operation to the sequencer, which assigns it a unique\nsequence number and subsequently forwards the operation to all replicas.\nOperations are carried out in the order of their sequence number.\nNote 7.8 (Advanced: Achieving scalability)\nNote that using a sequencer may easily introduce scalability problems. In fact, if\ntotally ordered multicasting is needed, a combination of symmetric multicasting\nusing Lamport timestamps [Lamport, 1978] and sequencers may be necessary.\nSuch a solution is described by Rodrigues et al. [1996]. The essence of that solution\nis to have multiple sequencers multicast update operations to each other and\norder the updates using Lamport’s total-ordering mechanism, as described in\nChapter 5. Nonsequencing processes are grouped such that each group uses\na single sequencer. Any nonsequencing process sends update requests to its\nsequencer and waits until it receives an acknowledgment that its request has been\nprocessed (i.e., multicast to the other sequencers in a totally ordered fashion).\nObviously, there is a trade-off between the number of processes that act as\nsequencer and those that do not, as well as the choice of processes to act as\nsequencer. As it turns out, this trade-off depends very much on the application\nand, in particular, the relative update rate at each process.\nQuorum-based protocols\nA different approach to supporting replicated writes is to use voting, as\noriginally proposed by Thomas [1979] and generalized by Gifford [1979].\nThe basic idea is to require clients to request and acquire the permission of\nmultiple servers before either reading or writing a replicated data item.\nAs a simple example of how the algorithm works, consider a distributed\nfile system and suppose that a file is replicated on N servers. We could make\na rule stating that to update a file, a client must first contact at least half the\nservers plus one (a majority) and get them to agree to do the update. Once\nthey have agreed, the file is changed and a new version number is associated\nwith the new file. The version number is used to identify the version of the\nfile and is the same for all the newly updated files.\nTo read a replicated file, a client must also contact at least half the servers\nplus one and ask them to send the version numbers associated with the file.\nIf all the version numbers are the same, this must be the most recent version\nbecause an attempt to update only the remaining servers would fail because\nthere are not enough of them.\nFor example, if there are five servers and a client determines that three of\nthem have version 8, it is impossible that the other two have version 9. After\n \nDS 4.01\n\n\n442\nCHAPTER 7. CONSISTENCY AND REPLICATION\nall, any successful update from version 8 to version 9 requires getting three\nservers to agree to it, not just two.\nWhen quorum-based replication was originally introduced, a somewhat\nmore general scheme was proposed. In it, to read a file of which N replicas\nexist, a client needs to assemble a read quorum, an arbitrary collection of any\nNR servers, or more. Similarly, to modify a file, a write quorum of at least\nNW servers is required. The values of NR and NW are subject to the following\ntwo constraints:\n1. NR + NW > N\n2. NW > N/2\nThe first constraint is used to prevent read-write conflicts, whereas the\nsecond prevents write-write conflicts. Only after the appropriate number of\nservers has agreed to participate can a file be read or written.\nTo see how this algorithm works, consider Figure 7.32(a) which has NR = 3\nand NW = 10. Imagine that the most recent write quorum consisted of the\n10 servers C through L. All of these get the new version and the new version\nnumber. Any subsequent read quorum of three servers will have to contain at\nleast one member of this set. When the client looks at the version numbers, it\nwill know which is most recent and take that one.\n(a)\n(b)\n(c)\nFigure 7.32: Three examples of the voting algorithm. The gray areas denote a\nread quorum; the white ones a write quorum. Servers in the intersection are\ndenoted in boldface. (a) A correct choice of read and write set. (b) A choice\nthat may lead to write-write conflicts. (c) A correct choice, known as ROWA\n(read one, write all).\nIn Figure 7.32 we see two more examples. In Figure 7.32(b) a write-write\nconflict may occur because NW ≤N/2. In particular, if one client chooses\n{A, B, C, E, F, G} as its write set and another client chooses {D, H, I, J, K, L} as\nits write set, then clearly we will run into trouble, as the two updates will\nboth be accepted without detecting that they actually conflict.\nThe situation shown in Figure 7.32(c) is especially interesting because it\nsets NR to one, making it possible to read a replicated file by finding any copy\nand using it. The price paid for this good read performance, however, is that\nDS 4.01\n \n\n\n7.5. CONSISTENCY PROTOCOLS\n443\nwrite updates need to acquire all copies. This scheme is generally referred to\nas Read-One, Write-All, (ROWA).\nQuorum-based replication has been an active field of research and an\ninspiration for various protocols. However, in practice, we often see primary-\nbased protocols at work (to which we return in Chapter 8). Jalote [1994]\nprovides a good overview of various quorum-based protocols. A more formal\nintroduction is given by Merideth and Reiter [2010], whereas many formal\ndetails and analyses of different protocols are described in [Vukoli´c, 2012].\n7.5.3\nCache-coherence protocols\nCaches form a special case of replication, in the sense that they are generally\ncontrolled by clients instead of servers. However, cache-coherence protocols,\nwhich ensure that a cache is consistent with the server-initiated replicas are,\nin principle, not very different from the consistency protocols discussed so far.\nThere has been much research in the design and implementation of caches,\nespecially in the context of shared-memory multiprocessor systems. Many\nsolutions are based on support from the underlying hardware, for example,\nby assuming that snooping or efficient broadcasting can be done. In the\ncontext of middleware-based distributed systems that are built on top of\ngeneral-purpose operating systems, software-based solutions to caches are\nmore interesting. In this case, two separate criteria are often maintained to\nclassify caching protocols (see also Min and Baer [1992], Lilja [1993], or Tartalja\nand Milutinovic [1997]).\nFirst, caching solutions may differ in their coherence detection strategy,\nthat is, when inconsistencies are actually detected.\nIn static solutions, a\ncompiler is assumed to perform the necessary analysis before execution, and\nto determine which data may actually lead to inconsistencies because they may\nbe cached. The compiler simply inserts instructions that avoid inconsistencies.\nDynamic solutions are typically applied in the distributed systems studied\nin this book. In these solutions, inconsistencies are detected at runtime. For\nexample, a check is made with the server to see whether the cached data have\nbeen modified since they were cached.\nIn the case of distributed databases, dynamic detection-based protocols\ncan be further classified by considering exactly when, during a transaction,\nthe detection is done. Franklin et al. [1997] distinguish the following three\ncases. First, when during a transaction a cached data item is accessed, the\nclient needs to verify whether that data item is still consistent with the version\nstored at the (possibly replicated) server. The transaction cannot proceed to\nuse the cached version until its consistency has been definitively validated.\nA second, optimistic, approach is to let the transaction proceed while\nverification is taking place. In this case, it is assumed that the cached data\nwere up-to-date when the transaction started. If that assumption later proves\nto be false, the transaction will have to abort.\n \nDS 4.01\n\n\n444\nCHAPTER 7. CONSISTENCY AND REPLICATION\nThe third approach is to verify whether the cached data are up-to-date only\nwhen the transaction commits. In effect, the transaction just starts operating\non the cached data and hopes for the best. After all the work has been done,\naccessed data are verified for consistency. When stale data were used, the\ntransaction is aborted.\nAnother design issue for cache-coherence protocols is the coherence en-\nforcement strategy, which determines how caches are kept consistent with the\ncopies stored at servers. The simplest solution is to disallow shared data to be\ncached at all. Instead, shared data are kept only at the servers, which maintain\nconsistency using one of the primary-based or replication-write protocols\ndiscussed above. Clients are allowed to cache only private data. Obviously,\nthis solution can offer only limited performance improvements.\nWhen shared data can be cached, there are two approaches to enforce\ncache coherence. The first is to let a server send an invalidation to all caches\nwhenever a data item is modified. The second is to simply propagate the\nupdate. Most caching systems use one of these two schemes. Dynamically\nchoosing between sending invalidations or updates is sometimes supported\nin client-server databases.\nFinally, we also need to consider what happens when a process modifies\ncached data. When read-only caches are used, update operations can be\nperformed only by servers, which subsequently follow some distribution\nprotocol to ensure that updates are propagated to caches. Often, a pull-based\napproach is followed. In this case, a client detects that its cache is stale, and\nrequests a server for an update.\nAn alternative approach is to allow clients to directly modify the cached\ndata, and forward the update to the servers.\nThis approach is followed\nin write-through caches, which are often used in distributed file systems.\nIn effect, write-through caching is similar to a primary-based local-write\nprotocol in which the client’s cache has become a temporary primary. To\nguarantee (sequential) consistency, it is necessary that the client has been\ngranted exclusive write permissions, or otherwise write-write conflicts may\noccur.\nWrite-through caches potentially offer improved performance over other\nschemes, as all operations can be carried out locally. Further enhancements\ncan be made if we delay the propagation of updates by allowing multiple\nwrites to take place before informing the servers. This leads to what is known\nas a write-back cache, which is, again, mainly applied in distributed file\nsystems.\nNote 7.9 (Example: Client-side caching in NFS)\nAs a practical example, consider the general caching model in NFS as shown in\nFigure 7.33. Each client can have a memory cache that contains data previously\nDS 4.01\n \n\n\n7.5. CONSISTENCY PROTOCOLS\n445\nread from the server. In addition, there may also be a disk cache that is added as\nan extension to the memory cache, using the same consistency parameters.\nFigure 7.33: Client-side caching in NFS.\nTypically, clients cache file data, attributes, file handles, and directories. Dif-\nferent strategies exist to handle consistency of the cached data, cached attributes,\nand so on. Let us first take a look at caching file data.\nNFSv4 supports two different approaches for caching file data. The simplest\napproach is when a client opens a file and caches the data it obtains from the\nserver as the result of various read operations. In addition, write operations can\nbe carried out in the cache as well. When the client closes the file, NFS requires\nthat if modifications have taken place, the cached data must be flushed back\nto the server. This approach corresponds to implementing session semantics as\ndiscussed earlier.\nOnce (part of) a file has been cached, a client can keep its data in the cache\neven after closing the file. Also, several clients on the same machine can share a\nsingle cache. NFS requires that whenever a client opens a previously closed file\nthat has been (partly) cached, the client must immediately revalidate the cached\ndata. Revalidation takes place by checking when the file was last modified and\ninvalidating the cache in case it contains stale data.\nIn NFSv4 a server may delegate some of its rights to a client when a file is\nopened. Open delegation takes place when the client machine is allowed to\nlocally handle open and close operations from other clients on the same machine.\nNormally, the server is in charge of checking whether opening a file should\nsucceed, for example because share reservations need to be considered. With\nopen delegation, the client machine is sometimes allowed to make such decisions,\navoiding the need to contact the server.\nFor example, if a server has delegated the opening of a file to a client that\nrequested write permissions, file locking requests from other clients on the same\nmachine can also be handled locally. The server will still handle locking requests\nfrom clients on other machines, by simply denying those clients access to the file.\nNote that this scheme does not work in the case of delegating a file to a client that\nrequested only read permissions. In that case, whenever another local client wants\nto have write permissions, it will have to contact the server; it is not possible to\nhandle the request locally.\nAn important consequence of delegating a file to a client is that the server\n \nDS 4.01\n\n\n446\nCHAPTER 7. CONSISTENCY AND REPLICATION\nneeds to be able to recall the delegation, for example, when another client on a\ndifferent machine needs to obtain access rights to the file. Recalling a delegation\nrequires that the server can do a callback to the client, as illustrated in Figure 7.34.\nFigure 7.34: Using the NFSv4 callback mechanism to recall file delegation.\nA callback is implemented in NFS using its underlying RPC mechanisms.\nNote, however, that callbacks require that the server keeps track of clients to which\nit has delegated a file. Here, we see another example where an NFS server cannot\nbe implemented in a stateless manner. Note, however, that the combination of\ndelegation and stateful servers may lead to various problems in the presence of\nclient and server failures. For example, what should a server do when it had\ndelegated a file to a now unresponsive client?\nClients can also cache attribute values, but are largely left on their own when\nit comes to keeping cached values consistent. In particular, attribute values of the\nsame file cached by two different clients may be different unless the clients keep\nthese attributes mutually consistent. Modifications to an attribute value should\nbe immediately forwarded to the server, thus following a write-through cache\ncoherence policy.\nA similar approach is followed for caching file handles (or rather, the name-\nto-file handle mapping) and directories. To mitigate the effects of inconsistencies,\nNFS uses leases on cached attributes, file handles, and directories. After some\ntime has elapsed, cache entries are thus automatically invalidated and revalidation\nis needed before they are used again.\n7.5.4\nImplementing continuous consistency\nAs part of their work on continuous consistency, Yu and Vahdat [2000] have\ndeveloped a number of protocols to tackle the three forms of continuous\nconsistency. In the following, we briefly consider a number of solutions,\nomitting details for clarity.\nBounding numerical deviation\nWe first concentrate on one solution for keeping the numerical deviation\nwithin bounds. Again, our purpose is not to go into all the details for each\nprotocol, but rather to give the general idea. Details for bounding numerical\ndeviation can be found in [Yu and Vahdat, 2000].\nDS 4.01\n \n\n\n7.5. CONSISTENCY PROTOCOLS\n447\nWe concentrate on writes to a single data item x. Each write W(x) has an\nassociated value that represents the numerical value by which x is updated,\ndenoted as val(W(x)), or simply val(W).\nFor simplicity, we assume that\nval(W) > 0. Each write W is initially submitted to one out of the N available\nreplica servers, in which case that server becomes the write’s origin, denoted\nas origin(W). If we consider the system at a specific moment we will see\nseveral submitted writes that still need to be propagated to all servers. To this\nend, each server Si will keep track of a log Li of writes that it has performed\non its own local copy of x.\nLet TW[i, j] be the effect of performing the writes executed by server Si\nthat originated from server Sj:\nTW[i, j] = ∑{val(W)|origin(W) = Sj and W ∈Li}\nNote that TW[i, i] represents the aggregated writes submitted to Si. Our\ngoal is for any time t, to let the current value vi of x at server Si deviate\nwithin bounds from the actual value v of x. This actual value is completely\ndetermined by all submitted writes. That is, if v0 is the initial value of x, then\nv = v0 +\nN\n∑\nk=1\nTW[k, k]\nand\nvi = v0 +\nN\n∑\nk=1\nTW[i, k]\nNote that vi ≤v. Let us concentrate only on absolute deviations. In particular,\nfor every server Si, we associate an upper bound δi such that we need to\nenforce:\nv −vi ≤δi\nWrites submitted to a server Si will need to be propagated to all other servers.\nThere are different ways in which this can be done, but typically an epidemic\nprotocol will allow rapid dissemination of updates. In any case, when a server\nSi propagates a write originating from Sj to Sk, the latter will be able to learn\nabout the value TW[i, j] at the time the write was sent. In other words, Sk can\nmaintain a view TWk[i, j] of what it believes Si will have as value for TW[i, j].\nObviously,\n0 ≤TWk[i, j] ≤TW[i, j] ≤TW[j, j]\nThe whole idea is that when a server Sk notices that Si has not been staying in\nthe right pace with the updates that have been submitted to Sk, it forwards\nwrites from its log to Si.\nThis forwarding effectively advances the view\nTWk[i, k] that Sk has of TW[i, k], making the deviation TW[i, k] −TWk[i, k]\nsmaller. In particular, Sk advances its view on TW[i, k] when an application\nsubmits a new write that would increase TW[k, k] −TWk[i, k] beyond δi/(N −\n1). We leave it as an exercise to the reader to show that advancement always\nensures that v −vi ≤δi.\n \nDS 4.01\n\n\n448\nCHAPTER 7. CONSISTENCY AND REPLICATION\nBounding staleness deviations\nThere are many ways to keep the staleness of replicas within specified bounds.\nOne simple approach is to let the server Sk keep a real-time vector clock\nRVCk where RVCk[i] = ti means that Sk has seen all writes that have been\nsubmitted to Si up to time ti. In this case, we assume that each submitted\nwrite is timestamped by its origin server, with ti denoting the time local to Si.\nIf the clocks between the replica servers are loosely synchronized, then an\nacceptable protocol for bounding staleness would be the following. Whenever\nthe server Sk notes that tk −RVCk[i] is about to exceed a specified limit, it\nsimply starts pulling in writes that originated from Si with a timestamp later\nthan RVCk[i].\nNote that in this case, a replica server is responsible for keeping its copy\nof x up to date regarding writes that have been issued elsewhere. In contrast,\nwhen maintaining numerical bounds, we followed a push approach by letting\nan origin server keep replicas up to date by forwarding writes. The problem\nwith pushing writes in the case of staleness is that no guarantees can be given\nfor consistency when it is unknown in advance what the maximal propagation\ntime will be. This situation is somewhat improved by pulling in updates, as\nmultiple servers can help to keep a server’s copy of x up to date.\nBounding ordering deviations\nRecall that ordering deviations in continuous consistency are caused by the\nfact that a replica server tentatively applies updates that have been submitted\nto it. As a result, each server will have a local queue of tentative writes for\nwhich the actual order in which they are to be applied to the local copy of\nx still needs to be determined. The deviation is bounded by specifying the\nmaximal length of the queue of tentative writes.\nAs a consequence, detecting when ordering consistency needs to be en-\nforced is simple: when the length of this local queue exceeds a specified\nmaximal length. At that point, a server will no longer accept any newly\nsubmitted writes, but will instead attempt to commit tentative writes by nego-\ntiating with other servers in which order its writes should be executed. We\nthus have to enforce a globally consistent ordering of tentative writes.\n7.5.5\nImplementing client-centric consistency\nFor our last topic on consistency protocols, let us draw our attention to imple-\nmenting client-centric consistency. Implementing client-centric consistency is\nrelatively straightforward if performance issues are ignored.\nIn a naive implementation of client-centric consistency, each write opera-\ntion W is assigned a globally unique identifier. Such an identifier is assigned\nby the server to which the write had been submitted. We refer to this server\nas the origin of W. Then, for each client, we keep track of two sets of writes.\nDS 4.01\n \n",
      "page_number": 451
    },
    {
      "number": 45,
      "title": "Segment 45 (pages 459-466)",
      "start_page": 459,
      "end_page": 466,
      "detection_method": "topic_boundary",
      "content": "7.5. CONSISTENCY PROTOCOLS\n449\nThe read set for a client consists of the writes relevant for the read operations\nperformed by a client. Likewise, the write set consists of the (identifiers of\nthe) writes performed by the client.\nMonotonic-read consistency is implemented as follows. When a client\nwants to perform a read operation at a server, that server is handed the client’s\nread set to check whether all the identified writes have taken place locally.\nIf not, it contacts the other servers to ensure that it is brought up to date\nbefore carrying out the read operation. Alternatively, the read operation is\nforwarded to a server where the write operations have already taken place.\nAfter the read operation is performed, the write operations that have taken\nplace at the selected server and which are relevant for the read operation are\nadded to the client’s read set.\nNote that it should be possible to determine exactly where the write\noperations identified in the read set have taken place. For example, the write\nidentifier could include the identifier of the server to which the operation was\nsubmitted. That server is required to, for example, log the write operation so\nthat it can be replayed at another server. In addition, write operations should\nbe performed in the order they were submitted. Ordering can be achieved by\nletting the client generate a globally unique sequence number that is included\nin the write identifier. If each data item can be modified only by its owner,\nthe latter can supply the sequence number.\nMonotonic-write consistency is implemented analogous to monotonic\nreads. Whenever a client initiates a new write operation at a server, the\nserver is handed over the client’s write set. (Again, the size of the set may be\nprohibitively large in the face of performance requirements. An alternative\nsolution is discussed below.) It then ensures that the identified write opera-\ntions are performed first and in the correct order. After performing the new\noperation, that operation’s write identifier is added to the write set. Note\nthat bringing the current server up to date with the client’s write set may\nintroduce a considerable increase in the client’s response time, since the client\nthen waits for the operation to fully complete.\nLikewise, read-your-writes consistency requires that the server where the\nread operation is to be performed has seen all the write operations in the\nclient’s write set. The writes can simply be fetched from other servers before\nthe read operation is actually executed, although this may lead to a poor\nresponse time. Alternatively, the client-side software can search for a server\nwhere the identified write operations in the client’s write set have already\nbeen performed.\nFinally, writes-follow-reads consistency can be implemented by first bring-\ning the selected server up to date with the write operations in the client’s read\nset, and then later adding the identifier of the write operation to the write set,\nalong with the identifiers in the read set (which have now become relevant\nfor the write operation just performed).\n \nDS 4.01\n\n\n450\nCHAPTER 7. CONSISTENCY AND REPLICATION\nNote 7.10 (Advanced: Improving efficiency)\nIt is easy to see that the read set and write set associated with each client can\nbecome very large. To keep these sets manageable, a client’s read and write\noperations are grouped into sessions. A session is typically associated with an\napplication: it is opened when the application starts and is closed when it exits.\nHowever, sessions may also be associated with applications that are temporarily\nexited, such as user agents for e-mail. Whenever a client closes a session, the sets\nare simply cleared. Of course, if a client opens a session that it never closes, the\nassociated read and write sets can still become very large.\nThe main problem with a naive implementation lies in the representation of\nthe read and write sets. Each set consists of a number of identifiers for write\noperations. Whenever a client forwards a read or write request to a server, a set\nof identifiers is handed to the server as well to see whether all write operations\nrelevant to the request have been carried out by that server.\nThis information can be more efficiently represented by vector timestamps\nas follows. First, whenever a server accepts a new write operation W, it assigns\nthat operation a globally unique identifier along with a timestamp ts(W). A\nsubsequent write operation submitted to that server is assigned a higher-valued\ntimestamp. Each server Si maintains a vector timestamp WVCi, where WVCi[j] is\nequal to the timestamp of the most recent write operation originating from Sj that\nhas been processed by Si.\nFor clarity, assume that for each server, writes from Sj are processed in the\norder that they were submitted. Whenever a client issues a request to perform\na read or write operation O at a specific server, that server returns its current\ntimestamp along with the results of O. Read and write sets are subsequently\nrepresented by vector timestamps. More specifically, for each session A, we\nconstruct a vector timestamp SVCA with SVCA[i] set equal to the maximum\ntimestamp of all write operations in A that originate from server Si:\nSVCA[j] = max{ts(W)|W ∈A and origin(W) = Sj}\nIn other words, the timestamp of a session always represents the latest write\noperations that have been seen by the applications that are being executed as part\nof that session. The compactness is obtained by representing all observed write\noperations originating from the same server through a single timestamp.\nAs an example, suppose a client, as part of session A, logs in at server Si. To\nthat end, it passes SVCA to Si. Assume that SVCA[j] > WVCi[j]. What this means\nis that Si has not yet seen all the writes originating from Sj that the client has\nseen. Depending on the required consistency, server Si may now have to fetch\nthese writes before being able to consistently report back to the client. Once the\noperation has been performed, server Si will return its current timestamp WVCi.\nAt that point, SVCA is adjusted to:\nSVCA[j] ←max{SVCA[j], WVCi[j]}\nAgain, we see how vector timestamps can provide an elegant and compact way of\nrepresenting history in a distributed system.\nDS 4.01\n \n\n\n7.6. EXAMPLE: CACHING AND REPLICATION IN THE WEB\n451\n7.6\nExample: Caching and replication in the Web\nThe Web is arguably the largest distributed system ever built. Originating from\na relatively simple client-server architecture, it is now a sophisticated system\nconsisting of many techniques to ensure stringent performance and availability\nrequirements. These requirements have led to numerous proposals for caching\nand replicating Web content. Where the original schemes (which are still\nlargely deployed) have been targeted toward supporting static content, much\neffort has also been put into supporting dynamic content, that is, supporting\ndocuments that are generated on-the-spot as the result of a request, as well as\nthose containing scripts and such. An overview of traditional Web caching\nand replication is provided by Rabinovich and Spastscheck [2002].\nClient-side caching in the Web generally occurs at two places. In the first\nplace, most browsers are equipped with a relatively simple caching facility.\nWhenever a document is fetched, it is stored in the browser’s cache, from\nwhere it is loaded the next time. In the second place, a client’s site often runs a\nWeb proxy. A Web proxy accepts requests from local clients and passes these\nto Web servers. When a response comes in, the result is passed to the client.\nThe advantage of this approach is that the proxy can cache the result and\nreturn that result to another client, if necessary. In other words, a Web proxy\ncan implement a shared cache. With so many documents being generated\non the fly, the server generally provides the document in pieces, instructing\nthe client to cache only those parts that are not likely to change when the\ndocument is requested a next time.\nIn addition to caching at browsers and proxies, ISPs generally also place\ncaches in their networks. Such schemes are mainly used to reduce network\ntraffic (which is good for the ISP) and to improve performance (which is\ngood for end users). However, with multiple caches along the request path\nfrom client to server, there is a risk of increased latencies when caches do not\ncontain the requested information.\nNote 7.11 (Advanced: Cooperative caching)\nAs an alternative to building hierarchical caches, one can also organize caches\nfor cooperative deployment, as shown in Figure 7.35. In cooperative caching or\ndistributed caching, whenever a cache miss occurs at a Web proxy, the proxy\nfirst checks a number of neighboring proxies to see if one of them contains the\nrequested document. If such a check fails, the proxy forwards the request to the\nWeb server responsible for the document. In more traditional settings, this scheme\nis primarily deployed with Web caches belonging to the same organization or\ninstitution.\nA study by Wolman et al. [1999] shows that cooperative caching may be effec-\ntive for only relatively small groups of clients (in the order of tens of thousands\nof users). However, such groups can also be serviced by using a single proxy\ncache, which is much cheaper in terms of communication and resource usage.\n \nDS 4.01\n\n\n452\nCHAPTER 7. CONSISTENCY AND REPLICATION\nHowever, in a study from a decade later, Wendell and Freedman [2011] show that\nin a highly decentralized system, cooperative caching actually turned out to be\nhighly effective. These studies do not necessarily contradict each other: in both\ncases, the conclusion is that the effect of cooperative caching depends highly on\nthe demands from clients.\nA comparison between hierarchical and cooperative caching by Rodriguez\net al. [2001] makes clear that there are various trade-offs to make. For example,\nbecause cooperative caches are generally connected through high-speed links,\nthe transmission time needed to fetch a document is much lower than for a\nhierarchical cache. Also, as is to be expected, storage requirements are less strict\nfor cooperative caches than hierarchical ones.\nWeb\nproxy\nWeb\nserver\nWeb\nproxy\nWeb\nproxy\nCache\nCache\nCache\nClient\nClient\nClient\nClient\nClient\nClient\nClient\nClient\nClient\n2. Ask neighboring proxy caches\n1. Look in\nlocal cache\nHTTP Get request\n3. Forward request\nto Web server\nFigure 7.35: The principle of cooperative caching.\nDifferent cache-consistency protocols have been deployed in the Web.\nTo guarantee that a document returned from the cache is consistent, some\nWeb proxies first send a conditional HTTP get request to the server with an\nadditional If-Modified-Since request header, specifying the last modification\ntime associated with the cached document. Only if the document has been\nchanged since that time, will the server return the entire document. Otherwise,\nthe Web proxy can simply return its cached version to the requesting local\nclient, which corresponds to a pull-based protocol.\nUnfortunately, this strategy requires that the proxy contacts a server for\neach request. To improve performance at the cost of weaker consistency, the\nwidely used Squid Web proxy [Wessels, 2004] assigns an expiration time Texpire\nthat depends on how long ago the document was last modified when it is\ncached. In particular, if Tlast_modified is the last modification time of a document\n(as recorded by its owner), and Tcached is the time it was cached, then\nTexpire = α(Tcached −Tlast_modified) + Tcached\nDS 4.01\n \n\n\n7.6. EXAMPLE: CACHING AND REPLICATION IN THE WEB\n453\nwith α = 0.2 (this value has been derived from practical experience). Until\nTexpire, the document is considered valid, and the proxy will not contact the\nserver. After the expiration time, the proxy requests the server to send a fresh\ncopy, unless it had not been modified. We note that Squid also allows the\nexpiration time to be bounded by a minimum and a maximum time.\nAs an alternative to a pull-based protocol is that the server notifies proxies\nthat a document has been modified by sending an invalidation. The problem\nwith this approach for Web proxies is that the server may need to keep track\nof many proxies, inevitably leading to a scalability problem. However, by\ncombining leases and invalidations, the state to be maintained at the server\ncan be kept within acceptable bounds. Note that this state is largely dictated\nby the expiration times set for leases: the lower, the less caches a server needs\nto keep track of. Nevertheless, invalidation protocols for Web proxy caches are\nhardly ever applied. A comparison of Web caching consistency policies can\nbe found in [Cao and Ozsu, 2002]. Their conclusion is that letting the server\nsend invalidations can outperform any other method in terms of bandwidth\nand perceived client latency, while maintaining cached documents consistent\nwith those at the origin server.\nFinally, we should also mention that much research has been conducted to\nfind out what the best cache replacement strategies are. Numerous proposals\nexist, but by-and-large, simple replacement strategies such as evicting the\nleast recently used object work well enough. An in-depth survey of replace-\nment strategies is presented by Podling and Boszormenyi [2003]; Ali et al.\n[2011] provide a more recent overview, which also includes Web prefetching\ntechniques.\nAs the importance of the Web continues to increase as a vehicle for organi-\nzations to present themselves and to directly interact with end users, we see\na shift between maintaining the content of a Web site and making sure that\nthe site is easily and continuously accessible. This distinction has paved the\nway for Content Delivery Networks (CDN). The main idea underlying these\nCDNs is that they act as a Web hosting service, providing an infrastructure\nfor distributing and replicating the Web documents of multiple sites across\nthe Internet. The size of the infrastructure can be impressive. As mentioned\nbefore, as of 2022, Akamai is reported to have over 400,000 servers worldwide.\nThe sheer size of a CDN requires that hosted documents are automatically\ndistributed and replicated. In most cases, a large-scale CDN is organized\nsimilar to a feedback-control loop, as shown in Figure 7.36 and which is\ndescribed extensively in [Sivasubramanian et al., 2004b].\nThere are essentially three different kinds of aspects related to replication\nin Web hosting systems: metric estimation, adaptation triggering, and taking\nappropriate measures. The latter can be subdivided into replica placement de-\ncisions, consistency enforcement, and client-request routing. In the following,\nwe briefly pay attention to each of these.\n \nDS 4.01\n\n\n454\nCHAPTER 7. CONSISTENCY AND REPLICATION\nFigure 7.36: The general organization of a CDN as a feedback-control system.\nAn interesting aspect of CDNs is that they need to make a trade-off between\nmany aspects when it comes to hosting replicated content. For example, access\ntimes for a document may be optimal if a document is massively replicated,\nbut at the same time this incurs a financial cost, as well as a cost in terms of\nbandwidth usage for disseminating updates. By and large, there are many\nproposals for estimating how well a CDN is performing. These proposals can\nbe grouped into several classes.\nFirst, there are latency metrics, by which the time is measured for an action,\nfor example, fetching a document, to take place. Trivial as this may seem,\nestimating latencies becomes difficult when, for example, a process deciding\non the placement of replicas needs to know the delay between a client and\nsome remote server. Typically, an algorithm for globally positioning nodes as\ndiscussed in Section 5.7.3 will need to be deployed.\nInstead of estimating latency, it may be more important to measure the\navailable bandwidth between two nodes. This information is particularly\nimportant when large documents have to be transferred, as in that case, the\nresponsiveness of the system is largely dictated by the time that a document\ncan be transferred. There are various tools for measuring available bandwidth,\nbut in all cases it turns out that accurate measurements can be difficult to\nattain (see also Strauss et al. [2003], Shriram and Kaur [2007], Chaudhari and\nBiradar [2015], and Atxutegi et al. [2016]).\nAnother class consists of spatial metrics, which mainly consist of measuring\nthe distance between nodes in terms of the number of network-level routing\nhops, or hops between autonomous systems. Again, determining the number\nof hops between two arbitrary nodes can be very difficult, and may also not\neven correlate with latency [Huffaker et al., 2002]. Moreover, simply looking\nat routing tables is not going to work when low-level techniques such as\nMulti-Protocol Label Switching (MPLS) are deployed. MPLS circumvents\nDS 4.01\n \n\n\n7.6. EXAMPLE: CACHING AND REPLICATION IN THE WEB\n455\nnetwork-level routing by using virtual-circuit techniques to immediately and\nefficiently forward packets to their destination (see also Guichard et al. [2005]).\nPackets may thus follow entirely different routes than advertised in the tables\nof network-level routers.\nA third class is formed by network usage metrics, which most often entails\nconsumed bandwidth. Computing consumed bandwidth in terms of the\nnumber of bytes to transfer is generally easy. However, to do this correctly,\nwe need to consider how often the document is read, how often it is updated,\nand how often it is replicated.\nConsistency metrics tell us to what extent a replica is deviating from its mas-\nter copy. We already discussed extensively how consistency can be measured\nin the context of continuous consistency [Yu and Vahdat, 2002].\nFinally, financial metrics form another class for measuring how well a CDN\nis doing. Although not technical at all, considering that most CDN operate\non a commercial basis, it is clear that often financial metrics will be decisive.\nMoreover, the financial metrics are closely related to the actual infrastructure of\nthe Internet. For example, most commercial CDNs place servers at the edge of\nthe Internet, meaning that they hire capacity from ISPs directly servicing end\nusers. At this point, business models become intertwined with technological\nissues, an area that is not at all well understood. There is only few material\navailable on the relation between financial performance and technological\nissues [Janiga et al., 2001].\nFrom these examples, it should become clear that simply measuring the\nperformance of a CDN, or even estimating its performance, may by itself be\nan extremely complex task. In practice, for commercial CDNs the issue that\nreally counts is whether they can meet the service-level agreements that have\nbeen made with customers. These agreements are often formulated simply in\nterms of how quickly customers are to be serviced. It is then up to the CDN\nto make sure that these agreements are met.\nAnother question that needs to be addressed is when and how adaptations\nare to be triggered. A simple model is to periodically estimate metrics and\nsubsequently take measures as needed. This approach is often seen in practice.\nSpecial processes located at the servers collect information and periodically\ncheck for changes.\nAn interesting aspect of this scheme is the simplicity by which consistency\nof documents can be enforced. Clearly, whenever a main document is changed,\na client will always be able to fetch it from the origin server. In the case of\nembedded documents, a different approach needs to be followed as these\ndocuments are, in principle, fetched from a nearby replica server. To this end,\na URL for an embedded document not only refers to a special host name that\neventually leads to a CDN DNS server, but also contains a unique identifier\nthat is changed every time the embedded document changes. In effect, this\nidentifier changes the name of the embedded document. As a consequence,\n \nDS 4.01\n\n\n456\nCHAPTER 7. CONSISTENCY AND REPLICATION\ndatabase\nSchema\nSchema\nServer\nServer\nquery\nresponse\nfull/partial data replication\nquery templates\ncache\ncache\ncopy\nClient\nEdge-server side\nOrigin-server side\nFigure 7.37: Alternatives for caching and replication with Web applications.\nwhen the client is redirected to a specific CDN server, that server will not find\nthe named document in its cache and will thus fetch it from the origin server.\nThe old document will eventually be evicted from the server’s cache as it is\nno longer referenced.\nUp to this point, we have mainly concentrated on caching and replicating\nstatic Web content. In practice, we see that the Web is increasingly offering\nmore dynamically generated content, but that it is also expanding toward\noffering services that can be called by remote applications. Also in these situa-\ntions we see that caching and replication can help considerably in improving\nthe overall performance, although the methods to reach such improvements\nare more subtle than what we discussed so far (see also Conti et al. [2005]).\nWhen considering improving performance of Web applications through\ncaching and replication, matters are complicated by the fact that several so-\nlutions can be deployed, with no single one standing out as the best. Let us\nconsider the edge-server situation as sketched in Figure 7.37 (see also Sivasub-\nramanian et al. [2007]). In this case, we assume a CDN in which each hosted\nsite has an origin server that acts as the authoritative site for all read and\nupdate operations. An edge server is used to handle client requests, and has\nthe ability to store (partial) information as also kept at an origin server.\nRecall that in an edge-server architecture, Web clients request data through\nan edge server, which, in turn, gets its information from the origin server\nassociated with the specific Website referred to by the client. As also shown in\nFigure 7.37 we assume that the origin server consists of a database from which\nresponses are dynamically created. Although we have shown only a single\nWeb server, it is common to organize each server according to a multitiered\narchitecture, as we discussed before. An edge server can now be roughly\norganized along the following lines.\nDS 4.01\n \n",
      "page_number": 459
    },
    {
      "number": 46,
      "title": "Segment 46 (pages 467-475)",
      "start_page": 467,
      "end_page": 475,
      "detection_method": "topic_boundary",
      "content": "7.6. EXAMPLE: CACHING AND REPLICATION IN THE WEB\n457\nFirst, to improve performance, we can decide to apply full replication of\nthe data stored at the origin server. This scheme works well whenever the\nupdate ratio is low and when queries require an extensive database search.\nAs mentioned above, we assume that all updates are carried out at the origin\nserver, which takes responsibility for keeping the replicas and the edge servers\nin a consistent state. Read operations can thus take place at the edge servers.\nHere, we see that replicating for performance will fail when the update ratio\nis high, as each update will incur communication over a wide-area network to\nbring the replicas into a consistent state. As shown by Sivasubramanian et al.\n[2004a], the read-to-update ratio is the determining factor to what extent the\norigin database in a wide-area setting should be replicated.\nAnother case for full replication is when queries are generally complex. In\nthe case of a relational database, this means that a query requires that multiple\ntables need to be searched and processed, as is generally the case with a join\noperation. Opposed to complex queries are simple ones that generally require\naccess to only a single table to produce a response. In the latter case, partial\nreplication by which only a subset of the data is stored at the edge server may\nsuffice.\nAn alternative to partial replication is to make use of content-aware caches.\nThe basic idea in this case is that an edge server maintains a local database\nthat is now tailored to the type of queries that can be handled at the origin\nserver. To explain, in a full-fledged database system a query will operate\non a database in which the data has been organized into tables such that,\nfor example, redundancy is minimized. Such databases are also said to be\nnormalized.\nIn such databases, any query that adheres to the data schema can, in\nprinciple, be processed, although perhaps at considerable costs. With content-\naware caches, an edge server maintains a database that is organized according\nto the structure of queries. What this means is that queries are assumed to\nadhere to a limited number of templates, effectively meaning that the different\nkinds of queries that can be processed is restricted. In these cases, whenever\na query is received, the edge server matches the query against the available\ntemplates, and subsequently looks in its local database to compose a response,\nif possible. If the requested data is not available, the query is forwarded to\nthe origin server, after which the response is cached before returning it to the\nclient.\nIn effect, what the edge server is doing is checking whether a query can be\nanswered with the data that is stored locally. This is also referred to as a query\ncontainment check. Note that such data was stored locally as responses to\npreviously issued queries. This approach works best when queries tend to be\nrepeated.\nPart of the complexity of content-aware caching comes from the fact\nthat the data at the edge server needs to be kept consistent. To this end,\n \nDS 4.01\n\n\n458\nCHAPTER 7. CONSISTENCY AND REPLICATION\nthe origin server needs to know which records are associated with which\ntemplates, so that any update of a record, or any update of a table, can be\nproperly addressed by, for example, sending an invalidation message to the\nappropriate edge servers. Another source of complexity comes from the fact\nthat queries still need to be processed at edge servers. In other words, there is\nnonnegligible computational power needed to handle queries. Considering\nthat databases often form a performance bottleneck in Web servers, alternative\nsolutions may be needed. Finally, caching results from queries that span\nmultiple tables (i.e., when queries are complex) such that a query containment\ncheck can be carried out effectively is not trivial. The reason is that the\norganization of the results may be very different from the organization of the\ntables on which the query operated.\nThese observations lead us to a third solution, namely content-blind\ncaching. The idea of content-blind caching is simple: when a client submits\na query to an edge server, the server first computes a unique hash value for\nthat query. Using this hash value, it subsequently looks in its cache whether it\nhas processed this query before. If not, the query is forwarded to the origin\nand the result is cached before returning it to the client. If the query had been\nprocessed before, the previously cached result is returned to the client.\nThe main advantage of this scheme is the reduced computational effort\nthat is required from an edge server in comparison to the database approaches\ndescribed above. However, content-blind caching can be wasteful in terms of\nstorage, as the caches may contain much more redundant data in comparison\nto content-aware caching or database replication. Note that such redundancy\nalso complicates the process of keeping the cache up-to-date, as the origin\nserver may need to keep an accurate account of which updates can potentially\naffect cached query results. These problems can be alleviated when assuming\nthat queries can match only a limited set of predefined templates, as we\ndiscussed above.\n7.7\nSummary\nThere are primarily two reasons for replicating data: improving the reliability\nof a distributed system and improving performance. Replication introduces\na consistency problem: whenever a replica is updated, that replica becomes\ndifferent from the others. To keep replicas consistent, we need to propagate\nupdates in such a way that temporary inconsistencies are not noticed. Unfor-\ntunately, doing so may severely degrade performance, especially in large-scale\ndistributed systems.\nThe only solution to this problem is to relax consistency somewhat. Dif-\nferent consistency models exist. For continuous consistency, the goal is to\nset bounds to numerical deviation between replicas, staleness deviation, and\ndeviations in the ordering of operations.\nDS 4.01\n \n\n\n7.7. SUMMARY\n459\nNumerical deviation refers to the value by which replicas may be different.\nThis type of deviation is highly application dependent, but can, for example,\nbe used in replication of stocks. Staleness deviation refers to the time by\nwhich a replica is still considered to be consistent, despite that updates may\nhave taken place some time ago. Staleness deviation is often used for Web\ncaches. Finally, ordering deviation refers to the maximum number of tentative\nwrites that may be outstanding at any server without having synchronized\nwith the other replica servers.\nConsistent ordering of operations has since long formed the basis for\nmany consistency models. Many variations exist, but only a few seem to\nprevail among application developers. Sequential consistency essentially\nprovides the semantics that programmers expect in concurrent programming:\nall write operations are seen by everyone in the same order.\nLess used,\nbut still relevant, is causal consistency, which reflects that operations that\nare potentially dependent on each other are carried out in the order of that\ndependency.\nWeaker consistency models consider series of read and write operations.\nIn particular, they assume that each series is appropriately “bracketed” by ac-\ncompanying operations on synchronization variables, such as locks. Although\nthis requires explicit effort from programmers, these models are generally\neasier to implement efficiently than, for example, pure sequential consistency.\nAs opposed to these data-centric models, researchers in the field of dis-\ntributed databases for mobile users have defined a number of client-centric\nconsistency models. Such models do not consider the fact that data may be\nshared by several users, but instead, concentrate on the consistency that an\nindividual client should be offered. The underlying assumption is that a client\nconnects to different replicas in the course of time, but that such differences\nshould be made transparent. In essence, client-centric consistency models\nensure that whenever a client connects to a new replica, that replica is brought\nup to date with the data that had been manipulated by that client before, and\nwhich may reside at other replica sites.\nTo propagate updates, different techniques can be applied. A distinction\nneeds to be made concerning what is exactly propagated, to where updates are\npropagated, and by whom propagation is initiated. We can decide to propagate\nnotifications, operations, or state. Likewise, not every replica always needs to\nbe updated immediately. Which replica is updated at which time depends\non the distribution protocol. Finally, a choice can be made whether updates\nare pushed to other replicas, or that a replica pulls in updates from another\nreplica.\nConsistency protocols describe specific implementations of consistency\nmodels. Regarding sequential consistency and its variants, a distinction can\nbe made between primary-based protocols and replicated-write protocols. In\nprimary-based protocols, all update operations are forwarded to a primary\n \nDS 4.01\n\n\n460\nCHAPTER 7. CONSISTENCY AND REPLICATION\ncopy that subsequently ensures the update is properly ordered and forwarded.\nIn replicated-write protocols, an update is forwarded to several replicas at the\nsame time. In that case, correctly ordering operations often becomes more\ndifficult.\nWe pay separate attention to caching and replication in the Web and,\nrelated, content delivery networks. As it turns out, using existing servers and\nservices, much of the techniques discussed before can be readily implemented\nusing appropriate redirection techniques. Particularly challenging is caching\ncontent when databases are involved, as in those cases, much of what a\nWeb server returns is dynamically generated. However, even in those cases,\nby carefully administrating what has already been cached at the edge, it is\npossible to invent highly efficient and effective caching schemes.\nDS 4.01\n \n\n\n08\nFAULT\nTOLERANCE\n\n\n462\nCHAPTER 8. FAULT TOLERANCE\nA characteristic feature of distributed systems that distinguishes them from\nsingle-machine systems is the notion of partial failure: part of the system is\nfailing while the remaining part continues to operate, and seemingly correctly.\nAn important goal in distributed-systems design is to construct the system\nin such a way that it can automatically recover from partial failures without\nseriously affecting the overall performance. In particular, whenever a failure\noccurs, the system should continue to operate in an acceptable way while\nrepairs are being made. In other words, a distributed system is expected to be\nfault tolerant.\nIn this chapter, we take a closer look at techniques to achieve fault toler-\nance. After providing some general background, we will first look at process\nresilience through process groups. In this case, multiple identical processes\ncooperate, providing the appearance of a single logical process, to ensure that\none or more of them can fail without a client noticing. A specifically difficult\npoint in process groups is reaching consensus among the group members\non which a client-requested operation is to perform. By now, Paxos is a\ncommonly adopted, yet relatively intricate algorithm. We take two approaches\nin explaining Paxos. One that builds on how the protocol can be logically\nviewed as it is now, and one that gradually builds it up from scratch. The latter\nmay help to understand many of its design decisions. We also pay extensive\nattention to the case in which servers may not just crash, but actually produce\nfaulty results that cannot be immediately recognized as being faulty.\nAchieving fault tolerance and reliable communication are strongly related.\nNext to reliable client-server communication, we pay attention to reliable\ngroup communication and notably atomic multicasting. In the latter case,\na message is delivered to all nonfaulty processes in a group, or to none.\nHaving atomic multicasting makes development of fault-tolerant solutions\nmuch easier.\nAtomicity is a property that is important in many applications. In this\nchapter, we look into what are known as distributed commit protocols by\nwhich a group of processes is conducted to either jointly commit their local\nwork, or collectively abort and return to a previous system state.\nFinally, we will examine how to recover from a failure. In particular, we\nconsider when and how the state of a distributed system should be saved to\nallow recovery to that state later on.\n8.1\nIntroduction to fault tolerance\nFault tolerance has been subject to much research in computer science. In\nthis section, we start with presenting the basic concepts related to processing\nfailures, followed by a discussion of failure models. The key technique for\nhandling failures is redundancy, which is also discussed. For more general\nDS 4.01\n \n\n\n8.1. INTRODUCTION TO FAULT TOLERANCE\n463\ninformation on fault tolerance in distributed systems, see, for example Jalote\n[1994]; Shooman [2002] or Koren and Krishna [2007].\n8.1.1\nBasic concepts\nTo understand the role of fault tolerance in distributed systems, we first need\nto take a closer look at what it actually means for a distributed system to\ntolerate faults. Being fault tolerant is strongly related to what are called\ndependable systems. Dependability is a term that covers a number of useful\nrequirements for distributed systems, including the following [Kopetz and\nVerissimo, 1993]:\n• Availability\n• Reliability\n• Safety\n• Maintainability\nAvailability is defined as the property that a system is ready to be used\nimmediately. In general, it refers to the probability that the system is operating\ncorrectly at any given moment, and is available to perform its functions on\nbehalf of its users. In other words, a highly available system is one that will\nmost likely be working at a given instant in time.\nReliability refers to the property that a system can run continuously without\nfailure. In contrast to availability, reliability is defined in terms of a time\ninterval, instead of an instant in time. A highly reliable system is one that will\nmost likely continue to work without interruption during a relatively long\nperiod of time. This is a subtle but important difference when compared to\navailability. If a system goes down on average for one, seemingly random\nmillisecond every hour, it has an availability of more than 99.9999 percent,\nbut is still unreliable. Similarly, a system that never crashes but is shut down\nfor two specific weeks every August, has high reliability but only 96 percent\navailability. The two are not the same.\nSafety refers to the situation that when a system temporarily fails to\noperate correctly, no catastrophic event happens. For example, many process-\ncontrol systems, such as those used for controlling nuclear power plants or\nsending people into space, are required to provide a high degree of safety. If\nsuch control systems temporarily fail for only a very brief moment, the effects\ncould be disastrous. Many examples from the past (and probably many more\nyet to come) show how hard it is to build safe systems.\nFinally, maintainability refers to how easily a failed system can be repaired.\nA highly maintainable system may also show a high degree of availability,\nespecially if failures can be detected and repaired automatically. However,\nas we shall see later in this chapter, automatically recovering from failures is\neasier said than done.\n \nDS 4.01\n\n\n464\nCHAPTER 8. FAULT TOLERANCE\nNote 8.1 (More information: Traditional metrics)\nWe can be a bit more precise when it comes to describing availability and reliability.\nFormally, the availability A(t) of a component in the time interval [0, t) is defined\nas the average fraction of time that the component has been functioning correctly\nduring that interval. The long-term availability A of a component is defined as\nA(∞).\nLikewise, the reliability R(t) of a component in the time interval [0, t) is\nformally defined as the conditional probability that it has been functioning cor-\nrectly during that interval, given that it was functioning correctly at time T = 0.\nFollowing Pradhan [1996], to establish R(t) we consider a system of N identical\ncomponents. Let N0(t) denote the number of correctly operating components at\ntime t and N1(t) the number of failed components. Then, clearly,\nR(t) = N0(t)\nN\n= 1 −N1(t)\nN\n=\nN0(t)\nN0(t) + N1(t)\nThe rate at which components are failing can be expressed as the derivative\ndN1(t)/dt. Dividing this by the number of correctly operating components at\ntime t gives us the failure rate function z(t):\nz(t) =\n1\nN0(t)\ndN1(t)\ndt\nFrom\ndR(t)\ndt\n= −1\nN\ndN1(t)\ndt\nit follows that\nz(t) =\n1\nN0(t)\ndN1(t)\ndt\n= −\nN\nN0(t)\ndR(t)\ndt\n= −\n1\nR(t)\ndR(t)\ndt\nIf we make the simplifying assumption that a component does not age (and thus\nessentially has no wear-out phase), its failure rate will be constant, i.e., z(t) = z,\nimplying that\ndR(t)\ndt\n= −zR(t)\nBecause R(0) = 1, we obtain\nR(t) = e−zt\nIn other words, if we ignore aging of a component, we see that a constant failure\nrate leads to a reliability following an exponential distribution, having the form\nshown in Figure 8.1.\nDS 4.01\n \n\n\n8.1. INTRODUCTION TO FAULT TOLERANCE\n465\nFigure 8.1: The reliability of a component having a constant failure rate.\nTraditionally, fault-tolerance has been related to the following three metrics:\n• Mean Time To Failure (MTTF): The average time until a component fails.\n• Mean Time To Repair (MTTR): The average time needed to repair a\ncomponent.\n• Mean Time Between Failures (MTBF): Simply MTTF + MTTR.\nNote that\nA = MTTF\nMTBF =\nMTTF\nMTTF + MTTR\nAlso, these metrics make sense only if we have an accurate notion of what a failure\nactually is. As we will encounter later, identifying the occurrence of a failure may\nactually not be so obvious.\nOften, dependable systems are also required to provide a high degree of\nsecurity, especially when it comes to issues such as integrity. We will discuss\nsecurity extensively in the next chapter.\nA system is said to fail when it does not meet its promises. In particular,\nif a distributed system is designed to provide its users with a number of\nservices, the system has failed when one or more of those services cannot be\n(completely) provided. An error is a part of a system’s state that may lead\nto a failure. For example, when transmitting packets across a network, it is\nto be expected that some packets have been damaged when they arrive at\nthe receiver. Damaged in this context means that the receiver may incorrectly\nsense a bit value (e.g., reading a 1 instead of a 0), or may even be unable to\ndetect that something has arrived.\nThe cause of an error is called a fault. Clearly, finding out what caused an\nerror is important. For example, a wrong or bad transmission medium may\neasily cause packets to be damaged. In this case, it is relatively easy to remove\nthe fault. However, transmission errors may also be caused by bad weather\nconditions, such as in wireless networks. Changing the weather to reduce or\nprevent errors is a bit trickier.\nAs another example, a crashed program is clearly a failure, which may\nhave happened because the program entered a branch of code containing\na programming bug (i.e., a programming error). The cause of that bug is\n \nDS 4.01\n",
      "page_number": 467
    },
    {
      "number": 47,
      "title": "Segment 47 (pages 476-485)",
      "start_page": 476,
      "end_page": 485,
      "detection_method": "topic_boundary",
      "content": "466\nCHAPTER 8. FAULT TOLERANCE\ntypically a programmer. In other words, the programmer is the cause of the\nerror (programming bug), in turn leading to a failure (a crashed program).\nBuilding dependable systems closely relates to controlling faults.\nAs\nexplained by Avizienis et al. [2004], a distinction can be made between pre-\nventing, tolerating, removing, and forecasting faults. For our purposes, the\nmost important issue is fault tolerance, meaning that a system can provide\nits services even in the presence of faults. For example, by applying error-\ncorrecting codes for transmitting packets, it is possible to tolerate, to a certain\nextent, relatively poor transmission lines and reducing the probability that an\nerror (a damaged packet) may lead to a failure.\nFaults are generally classified as transient, intermittent, or permanent.\nTransient faults occur once and then disappear. If the operation is repeated,\nthe fault goes away. A bird flying through the beam of a microwave transmitter\nmay cause lost bits on some network. If the transmission times out and is\nretried, it will probably work the second time.\nAn intermittent fault occurs, then vanishes of its own accord, then reap-\npears, and so on. A loose contact on a connector will often cause an inter-\nmittent fault. Intermittent faults cause a great deal of aggravation because\nthey are difficult to diagnose. Typically, when the fault doctor shows up, the\nsystem works fine.\nA permanent fault is one that continues to exist until the faulty compo-\nnent is replaced. Burnt-out chips, software bugs, and disk-head crashes are\nexamples of permanent faults.\n8.1.2\nFailure models\nA system that fails is not adequately providing the services it was designed for.\nIf we consider a distributed system as a collection of servers that communicate\nwith one another and with their clients, not adequately providing services\nmeans that servers, communication channels, or possibly both, are not doing\nwhat they are supposed to do. However, a malfunctioning server itself may\nnot always be the fault we are looking for. If such a server depends on other\nservers to adequately provide its services, the cause of an error may need to\nbe searched for somewhere else.\nSuch dependency relations appear in abundance in distributed systems. A\nfailing disk may make life difficult for a file server that is designed to provide\na highly available file system. If such a file server is part of a distributed\ndatabase, the proper working of the entire database may be at stake, as only\npart of its data may be accessible.\nTo get a better grasp on how serious a failure actually is, several classifica-\ntion schemes have been developed. One such scheme is shown in Figure 8.2,\nand is based on schemes described by Cristian [1991] and Hadzilacos and\nToueg [1993].\nDS 4.01\n \n\n\n8.1. INTRODUCTION TO FAULT TOLERANCE\n467\nType of failure\nDescription of server’s behavior\nCrash failure\nHalts, but is working correctly until it halts\nOmission failure\nFails to respond to incoming requests\nReceive omission\nFails to receive incoming messages\nSend omission\nFails to send messages\nTiming failure\nResponse lies outside a specified time interval\nResponse failure\nResponse is incorrect\nValue failure\nThe value of the response is wrong\nState-transition failure\nDeviates from the correct flow of control\nArbitrary failure\nMay produce arbitrary responses at arbitrary times\nFigure 8.2: Different types of failures.\nA crash failure occurs when a server prematurely halts, but was working\ncorrectly until it stopped. An important aspect of crash failures is that once\nthe server has halted, nothing is heard from it anymore. A typical example of\na crash failure is an operating system that comes to a grinding halt, and for\nwhich there is only one solution: reboot it. Many personal computer systems\n(be they desktop computers or laptops) suffer from crash failures so often that\npeople have come to expect them to be normal. Consequently, moving the\nreset button, for example, from the back of a cabinet to the front was done\nfor good reason. Perhaps one day it can be moved to the back again, or even\nremoved altogether.\nAn omission failure occurs when a server fails to respond to a request.\nSeveral things might go wrong. In the case of a receive-omission failure,\npossibly the server never got the request in the first place. Note that it may\nwell be the case that the connection between a client and a server has been\ncorrectly established, but that there was no thread listening for incoming\nrequests. Also, a receive-omission failure will generally not affect the current\nstate of the server, as the server is unaware of any message sent to it.\nLikewise, a send-omission failure happens when the server has done its\nwork, but somehow fails in sending a response. Such a failure may happen,\nfor example, when a send buffer overflows while the server was not prepared\nfor such a situation. Note that, in contrast to a receive-omission failure, the\nserver may now be in a state reflecting that it has just completed a service for\nthe client. As a consequence, if the sending of its response fails, the server has\nto be prepared for the client to reissue its previous request.\nOther types of omission failures not related to communication may be\ncaused by software errors such as infinite loops or improper memory manage-\nment, by which the server is said to “hang.”\nAnother class of failures is related to timing. Timing failures occur when\nthe response lies outside a specified real-time interval. For example, in the\ncase of streaming videos, providing data too soon may easily cause trouble for\na recipient if there is not enough buffer space to hold all the incoming data.\n \nDS 4.01\n\n\n468\nCHAPTER 8. FAULT TOLERANCE\nMore common, however, is that a server responds too late, in which case a\nperformance failure is said to occur.\nA serious type of failure is a response failure, by which the server’s\nresponse is simply incorrect. Two kinds of response failures may happen.\nIn the case of a value failure, a server simply provides the wrong reply to a\nrequest. For example, a search engine that systematically returns Web pages\nnot related to any of the search terms used, has failed.\nThe other type of response failure is known as a state-transition failure.\nThis kind of failure happens when the server reacts unexpectedly to an\nincoming request. For example, if a server receives a message it cannot\nrecognize, a state-transition failure happens if no measures have been taken\nto handle such messages. In particular, a faulty server may incorrectly take\ndefault actions it should never have initiated.\nThe most serious are arbitrary failures, also known as Byzantine failures.\nIn effect, when arbitrary failures occur, clients should be prepared for the\nworst. In particular, a server may be producing output it should never have\nproduced, but which cannot be detected as being incorrect. Byzantine failures\nwere first analyzed by Pease et al. [1980] and Lamport et al. [1982]. We return\nto such failures below.\nNote 8.2 (More information: Omission and commission failures)\nIt has become somewhat of a habit to associate the occurrence of Byzantine\nfailures with maliciously operating processes. The term “Byzantine” refers to the\nByzantine Empire, a time (330–1453) and place (the Balkans and modern Turkey)\nin which endless conspiracies, intrigue, and untruthfulness were alleged to be\ncommon in ruling circles.\nHowever, it may not be possible to detect whether an act was actually benign or\nmalicious. Is a networked computer running a poorly engineered operating system\nthat adversely affects the performance of other computers acting maliciously? In\nthis sense, it is better to make the following distinction, which effectively excludes\njudgment:\n• An omission failure occurs when a component fails to take an action that\nit should have taken.\n• A commission failure occurs when a component takes an action that it\nshould not have taken.\nThis difference, introduced by Mohan et al. [1983], also illustrates that a separation\nbetween dependability and security may at times be pretty difficult to make.\nMany of the aforementioned cases deal with the situation that a process\nP no longer perceives any actions from another process Q. However, can P\nconclude that Q has indeed come to a halt? To answer this question, we need\nto make a distinction between two types of distributed systems:\nDS 4.01\n \n\n\n8.1. INTRODUCTION TO FAULT TOLERANCE\n469\n• In an asynchronous system, no assumptions about process execution\nspeeds or message delivery times are made. The consequence is that\nwhen process P no longer perceives any actions from Q, it cannot\nconclude that Q crashed. Instead, it may just be slow, or its messages\nmay have been lost.\n• In a synchronous system, process execution speeds and message-delivery\ntimes are bounded. This also means that when Q shows no more activity\nwhen it is expected to do so, process P can rightfully conclude that Q\nhas crashed.\nUnfortunately, pure synchronous systems exist only in theory. On the other\nhand, simply stating that every distributed system is asynchronous also does\nnot do justice to what we see in practice, and we would be overly pessimistic in\ndesigning distributed systems under the assumption that they are necessarily\nasynchronous. Instead, it is more realistic to assume that a distributed system\nis partially synchronous: most of the time it behaves as a synchronous system,\nyet there is no bound on the time that it behaves in an asynchronous fashion.\nIn other words, asynchronous behavior is an exception, meaning that we can\nnormally use timeouts to conclude that a process has indeed crashed, but that\noccasionally such a conclusion is false. In practice, this means that we will\nhave to design fault-tolerant solutions that can withstand incorrectly detecting\nthat a process halted.\nIn this context, halting failures can be classified as follows, from the least\nto the most severe (see also Cachin et al. [2011]). We let process P attempt to\ndetect that process Q has failed.\n• Fail-stop failures refer to crash failures that can be reliably detected.\nThis may occur when assuming nonfaulty communication links and\nwhen the failure-detecting process P can place a worst-case delay on\nresponses from Q.\n• Fail-noisy failures are like fail-stop failures, except that P will only\neventually come to the correct conclusion that Q has crashed. This means\nthat there may be some a priori unknown time in which P’s detections\nof the behavior of Q are unreliable.\n• When dealing with fail-silent failures, we assume that communication\nlinks are nonfaulty, but that process P cannot distinguish crash failures\nfrom omission failures.\n• Fail-safe failures cover the case of dealing with arbitrary failures by\nprocess Q, yet these failures are benign: they cannot do any harm.\n• Finally, when dealing with fail-arbitrary failures, Q may fail in any\npossible way; failures may be unobservable in addition to being harmful\nto the otherwise correct behavior of other processes.\n \nDS 4.01\n\n\n470\nCHAPTER 8. FAULT TOLERANCE\nClearly, having to deal with fail-arbitrary failures is the worst that can happen.\nAs we shall discuss shortly, we can design distributed systems in such a way\nthat they can even tolerate these types of failures.\n8.1.3\nFailure masking by redundancy\nIf a system is to be fault tolerant, the best it can do is to try to hide the\noccurrence of failures from other processes. The key technique for masking\nfaults is to use redundancy. Three kinds are possible: information redundancy,\ntime redundancy, and physical redundancy (see also Johnson [1995]). With\ninformation redundancy, extra bits are added to allow recovery from garbled\nbits. For example, a Hamming code can be added to transmitted data to\nrecover from noise on the transmission line.\nWith time redundancy, an action is performed, and then, if need be, it is\nperformed again. Transactions use this approach. If a transaction aborts, it\ncan be redone with no harm because nothing has yet been finalized. Another\nwell-known example is retransmitting a request to a server when lacking an\nexpected response. Time redundancy is especially helpful when the faults are\ntransient or intermittent.\nWith physical redundancy, extra equipment or processes are added to\nmake it possible for the system as a whole to tolerate the loss or malfunction-\ning of some components. Physical redundancy can thus be done either in\nhardware or in software. For example, extra processes can be added to the\nsystem, so that if a few of them crash, the system can still function correctly. In\nother words, by replicating processes, a high degree of fault tolerance may be\nachieved. We return to this type of software redundancy later in this chapter.\nNote 8.3 (More information: Triple modular redundancy)\nIt is illustrative to see how redundancy has been applied in the design of electronic\ndevices. Consider, for example, the circuit of Figure 8.3(a). Here signals pass\nthrough devices A, B, and C, in sequence. If one of them is faulty, the final result\nwill probably be incorrect.\nIn Figure 8.3(b), each device is replicated three times. Following each stage\nin the circuit is a triplicated voter. Each voter is a circuit that has three inputs\nand one output. If two or three of the inputs are the same, the output is equal to\nthat input. If all three inputs are different, the output is undefined. This kind of\ndesign is known as triple modular redundancy (TMR).\nSuppose that element A2 fails. Each of the voters, V1, V2, and V3 gets two\ngood (identical) inputs and one rogue input, and each of them outputs the correct\nvalue to the second stage. In essence, the effect of A2 failing is completely masked\nso that the inputs to B1, B2, and B3 are the same as they would have been had no\nfault occurred.\nDS 4.01\n \n\n\n8.2. PROCESS RESILIENCE\n471\n(a)\n(b)\nFigure 8.3: Triple modular redundancy.\nNow consider what happens if B3 and C1 are also faulty, in addition to A2.\nThese effects are also masked, so the three final outputs are still correct.\nAt first, it may not be obvious why three voters are needed at each stage.\nAfter all, one voter could also detect and pass the majority view. However, a\nvoter is also a component and can be faulty. Suppose, for example, that voter\nV1 malfunctions. The input to B1 will then be wrong, but as long as everything\nelse works, B2 and B3 will produce the same output and V4, V5, and V6 will all\nproduce the correct result into stage three. A fault in V1 is effectively no different\nfrom a fault in B1. In both cases B1 produces incorrect output, but in both cases,\nit is voted down later, and the final result is still correct.\nAlthough not all fault-tolerant distributed systems use TMR, the technique is\nvery general, and should give a clear feeling for what a fault-tolerant system is, as\nopposed to a system whose individual components are highly reliable but whose\norganization cannot tolerate faults (i.e., operate correctly even in the presence of\nfaulty components). Of course, TMR can be applied recursively, for example, to\nmake a chip highly reliable by using TMR inside it, unknown to the designers\nwho use the chip, possibly in their own circuit containing multiple copies of the\nchips along with voters.\n8.2\nProcess resilience\nNow that the basic issues of fault tolerance have been discussed, let us\nconcentrate on how fault tolerance can actually be achieved in distributed\nsystems. The first topic we discuss is protection against process failures,\nwhich is achieved by replicating processes into groups. In the following pages,\nwe consider the general design issues of process groups and discuss what\na fault-tolerant group actually is. Also, we look at how to reach consensus\nwithin a process group when one or more of its members cannot be trusted to\ngive correct answers.\n \nDS 4.01\n\n\n472\nCHAPTER 8. FAULT TOLERANCE\n8.2.1\nResilience by process groups\nThe key approach to tolerating a faulty process is to organize several identical\nprocesses into a group. The key property that all groups have is that when a\nmessage is sent to the group itself, all members of the group receive it. In this\nway, if one process in a group fails, hopefully some other process can take\nover for it [Guerraoui and Schiper, 1997].\nProcess groups may be dynamic. New groups can be created, and old\ngroups can be destroyed. A process can join a group or leave one during\nsystem operation. A process can be a member of several groups at the same\ntime. Consequently, mechanisms are required for managing groups and group\nmembership.\nThe purpose of introducing groups is to allow a process to deal with\ncollections of other processes as a single abstraction. Thus, a process P can\nsend a message to a group Q = {Q1, . . . , QN} of servers without having to\nknow who they are, how many there are, or where they are, which may\nchange from one call to the next. To P, the group Q appears to be a single,\nlogical process.\nGroup organization\nAn important distinction between different groups has to do with their internal\nstructure. In some groups, all processes are equal, i.e., we have a flat group.\nThere is no distinctive leader and all decisions are made collectively. Typically,\nmany peer-to-peer systems operate in this way. An alternative organization\nis that of a hierarchical group. For example, one process is the coordinator\nand all the others are workers. In this model, when a request for work is\ngenerated, either by an external client or by one of the workers, it is sent to\nthe coordinator. The coordinator then decides which worker is best suited to\ncarry it out, and forwards it there. More complex hierarchies are also possible,\nof course. The Domain Name System can be argued to operate as a (indeed,\nquite complex) hierarchical group. Simpler organizations include primary-\nbased backup schemes, as we discussed in Section 7.5.1. These communication\npatterns within groups are illustrated in Figure 8.4.\nEach of these organizations has its own advantages and disadvantages.\nThe flat group is symmetrical and has no single point of failure. If one of\nthe processes crashes, the group simply becomes smaller, but can otherwise\ncontinue. A disadvantage is that decision-making may be more complicated.\nFor example, to decide anything, a vote often has to be taken, incurring some\ndelay and overhead.\nThe hierarchical group has the opposite properties. Loss of the coordinator\nbrings the entire group to a grinding halt, but as long as it is running, it\ncan make decisions without bothering everyone else. In practice, when the\ncoordinator in a hierarchical group fails, its role will need to be taken over and\nDS 4.01\n \n\n\n8.2. PROCESS RESILIENCE\n473\n(a)\n(b)\nFigure 8.4: Communication in a (a) flat group and in a (b) hierarchical group.\none of the workers is elected as new coordinator. We discussed leader-election\nalgorithms in Section 5.4.\nMembership management\nWhen group communication is present, some method is required for creating\nand deleting groups, as well as for allowing processes to join and leave groups.\nOne possible approach is to have a group server to which all these requests\ncan be sent. The group server can then maintain a complete database of all the\ngroups and their exact membership. This method is straightforward, efficient,\nand fairly easy to implement. Unfortunately, it shares a major disadvantage\nwith many (physically) centralized solutions: a single point of failure. If the\ngroup server crashes, group management ceases to exist. Probably most or\nall groups will have to be reconstructed from scratch, possibly terminating\nwhatever work was going on.\nThe opposite approach is to manage group membership in a distributed\nway. For example, if (reliable) multicasting is available, an outsider can send a\nmessage to all group members announcing its wish to join the group.\nIdeally, to leave a group, a member just sends a goodbye message to\neveryone. In the context of fault tolerance, assuming fail-stop failure semantics,\nis generally not appropriate. The trouble is, there is no polite announcement\nthat a process crashes, as there is when a process leaves voluntarily. The other\nmembers have to discover this experimentally by noticing that the crashed\nmember no longer responds to anything. Once it is certain that the crashed\nmember is really down (and not just slow), it can be removed from the group.\nAnother knotty issue is that leaving and joining have to be synchronous\nwith data messages being sent. In other words, starting at the instant that a\nprocess has joined a group, it must receive all messages sent to that group.\n \nDS 4.01\n\n\n474\nCHAPTER 8. FAULT TOLERANCE\nSimilarly, as soon as a process has left a group, it must not receive any more\nmessages from the group, and the other members must not receive any more\nmessages from it. One way of making sure that a join or leave is integrated\ninto the message stream at the right place is to convert this operation into a\nsequence of messages sent to the whole group.\nOne final issue relating to group membership is what to do if so many\nprocesses go down that the group can no longer function at all. Some protocol\nis needed to rebuild the group. Invariably, some process will have to take the\ninitiative to start the ball rolling, but what happens if two or three try at the\nsame time? The protocol must be able to withstand this. Again, coordination\nthrough, for example, a leader-election algorithm may be needed.\n8.2.2\nFailure masking and replication\nProcess groups are part of the solution for building fault-tolerant systems.\nIn particular, having a group of identical processes allows us to mask one\nor more faulty processes in that group. In other words, we can replicate\nprocesses and organize them into a group to replace a single (vulnerable)\nprocess with a (fault tolerant) group. As discussed in the previous chapter,\nthere are two ways to approach such replication: by means of primary-based\nprotocols, or through replicated-write protocols.\nPrimary-based replication in the case of fault tolerance generally appears\nin the form of a primary-backup protocol. In this case, a group of processes\nis organized in a hierarchical fashion, in which a primary coordinates all write\noperations. In practice, the primary is fixed, although its role can be taken\nover by one of the backups if need be. In effect, when the primary crashes,\nthe backups execute some election algorithm to choose a new primary.\nReplicated-write protocols are used in the form of active replication, as\nwell as by quorum-based protocols. These solutions correspond to organizing\na collection of identical processes into a flat group. The main advantage is\nthat such groups have no single point of failure, at the cost of distributed\ncoordination.\nAn important issue with using process groups to tolerate faults is how\nmuch replication is needed.\nTo simplify our discussion, let us consider\nonly replicated-write systems. A system is said to be k-fault tolerant if it\ncan survive faults in k components and still meet its specifications. If the\ncomponents, say processes, fail silently, then having k + 1 of them is enough\nto provide k-fault tolerance. If k of them simply stop, then the answer from\nthe other one can be used.\nOn the other hand, if processes exhibit arbitrary failures, continuing to\nrun when faulty and sending out erroneous or random replies, a minimum of\n2k + 1 processes is needed to achieve k-fault tolerance. In the worst case, the k\nfailing processes could accidentally (or even intentionally) generate the same\nDS 4.01\n \n\n\n8.2. PROCESS RESILIENCE\n475\nreply. However, the remaining k + 1 will also produce the same answer, so\nthe client or voter can just believe the majority.\nNow suppose that in a k-fault tolerant group, a single process fails. The\ngroup as a whole is still living up to its specifications, namely that it can\ntolerate the failure of up to k of its members (of which one has just failed). But\nwhat happens if more than k members fail? In that case, all bets are off and\nwhatever the group does, its results, if any, cannot be trusted. Another way of\nlooking at this is that the process group, in its appearance of mimicking the\nbehavior of a single, robust process, has failed.\n8.2.3\nConsensus in faulty systems with crash failures\nAs mentioned, in terms of clients and servers, we have adopted a model in\nwhich a potentially considerable collection of clients now send commands to\na group of processes that jointly behave as a single, highly robust process. To make\nthis work, we need to make an important assumption:\nIn a fault-tolerant process group, each nonfaulty process executes the\nsame commands, in the same order, as every other nonfaulty process.\nFormally, this means that the group members need to reach consensus on\nwhich command to execute. If failures cannot happen, reaching consensus\nis easy. For example, we can use Lamport’s totally ordered multicasting, as\ndescribed in Section 5.2.1. Or, to keep it simple, using a centralized sequencer\nthat hands out a sequence number to each command that needs to be executed\nwill do the job as well. Unfortunately, life is not without failures, and reaching\nconsensus among a group of processes under more realistic assumptions turns\nout to be tricky.\nFlooding-based consensus\nTo illustrate the problem at hand, let us assume we have a group of processes\nP = {P1, . . . , Pn} operating under fail-stop failure semantics. In other words,\nwe assume that crash failures can be reliably detected among the group\nmembers. Typically, a client contacts a group member requesting it to execute\na command. Every group member maintains a list of proposed commands:\nsome which it received directly from clients; others which it received from its\nfellow group members. We can reach consensus using the following approach,\nadopted from Cachin et al. [2011], and referred to as flooding consensus.\nConceptually, the algorithm operates in rounds. In each round, a process Pi\nsends its list of proposed commands it has seen so far to every other process\nin P. At the end of a round, each process merges all received proposed\ncommands into a new list, from which it then will deterministically select the\ncommand to execute, if possible. It is important to realize that the selection\nalgorithm is the same for all processes. In other words, if all process have the\n \nDS 4.01\n",
      "page_number": 476
    },
    {
      "number": 48,
      "title": "Segment 48 (pages 486-495)",
      "start_page": 486,
      "end_page": 495,
      "detection_method": "topic_boundary",
      "content": "476\nCHAPTER 8. FAULT TOLERANCE\nsame list, they will all select the same command to execute (and remove that\ncommand from their list).\nIt is not difficult to see that this approach works as long as processes do\nnot fail. Problems start when a process Pi detects, during round r, that, say,\nprocess Pk has crashed. To make this concrete, assume we have a process\ngroup of four processes {P1, . . . , P4} and that P1 crashes during round r.\nAlso, assume that P2 receives the list of proposed commands from P1 before\nit crashes, but that P3 and P4 do not (in other words, P1 crashes before it got\na chance to send its list to P3 and P4). This situation is sketched in Figure 8.5.\nFigure 8.5: Reaching consensus through flooding in the presence of crash\nfailures. Adopted from Cachin et al. [2011].\nAssuming that all processes knew who was a group member at the begin-\nning of round r, P2 is ready to decide on which command to execute when\nit receives the respective lists of the other members: it has all commands\nproposed so far. Not so for P3 and P4. For example, P3 may detect that P1\ncrashed, but it does not know if either P2 or P4 had already received P1’s\nlist. From P3’s perspective, if there is another process that did receive P1’s\nproposed commands, that process may then make a different decision than\nitself. As a consequence, the best that P3 can do is postpone its decision\nuntil the next round. The same holds for P4 in this example. A process will\ndecide to move to a next round when it has received a message from every\nnonfaulty process. This assumes that each process can reliably detect the\ncrashing of another process, for otherwise it would not be able to decide who\nthe nonfaulty processes are.\nBecause process P2 received all commands, it can indeed decide and can\nsubsequently broadcast that decision to the others. Then, during the next\nround r + 1, processes P3 and P4 will also be able to decide: they will decide\nto execute the same command selected by P2.\nTo understand why this algorithm is correct, it is important to realize that\na process will move to a next round without having made a decision, only\nwhen it detects that another process has failed. In the end, this means that in\nthe worst case at most one nonfaulty process remains, and this process can\nDS 4.01\n \n\n\n8.2. PROCESS RESILIENCE\n477\nsimply decide whatever proposed command to execute. Again, note that we\nare assuming reliable failure detection.\nBut then, what happens when the decision by process P2 that it sent to P3\nwas lost? In that case, P3 can still not make a decision. Worse, we need to\nmake sure that it makes the same decision as P2 and P4. If P2 did not crash,\nwe can assume that a retransmission of its decision will save the day. If P2 did\ncrash, this will also be detected by P4 who will then subsequently rebroadcast\nits decision. Meanwhile, P3 has moved to a next round, and after receiving\nthe decision by P4, will terminate its execution of the algorithm.\nA more realistic approach: Raft\nLet us now take a look at a consensus protocol that operates under crash-\nfailure semantics, or actually, a fail-noisy failure model: a process will even-\ntually correctly conclude that another process has crashed. Raft, described\nby Ongaro and Ousterhout [2014] was developed in reaction to the inherent\nintricacies of a famous consensus protocol, Paxos (which we discuss further\nbelow). In this section, we will stick to the essence of Raft, thereby even\nsimplifying a few matters to focus entirely on understanding how and why it\nworks.\nIn Raft, we typically have a group of some five replicated servers. We\nassume the set of servers is fixed (although Raft allows servers to join and\nleave the group). Each server maintains a log of operations, some of which\nhave already been executed (i.e., committed), as well as pending operations.\nConsensus is expressed in terms of these logs: committed operations have\nthe same position in each of the respective server’s logs. One of the servers\noperates as a leader and decides on the order in which pending operations\nare to be committed. In essence, Raft is a primary-backup protocol, with the\nprimary acting as leader and the backups as followers. We discussed Raft’s\nleader-election algorithm in Section 5.4.4.\nA client always sends an operation request to the leader (possibly after\nhaving been redirected by one of the followers). That means that the leader\nis fully aware of all pending requests. Each client request for executing\nan operation o is appended to the leader’s log, in the form of a tuple ⟨o,\nt, k⟩in which t is the term under which the current leader serves, and k\nthe index of o in the leader’s log.\nTo recall, after electing a next leader,\nthe term for new operations will be t + 1. Let c be the index of the most\nrecently committed operation. Raft guarantees that operations that have been\nregistered as committed, have been performed by a majority of the servers,\nand that the result has been returned to the original client.\nAssume the leader has a log of length n, is operating in term t, and receives\na request for executing operation o. In that case, it appends ⟨o, t, n + 1⟩and\nconceptually sends its entire log to all the other servers, along with the current\nvalue of c. Again conceptually, each following server copies the entire log, and\n \nDS 4.01\n\n\n478\nCHAPTER 8. FAULT TOLERANCE\nreturns an acknowledgement to the leader, while ensuring that all operations\nup to and including index c have been executed. Note that operation o cannot\nyet be committed by a follower.\nAs soon as the leader receives a majority of acknowledgements, it executes\no, returns the result (if any, but at least an acknowledgement) to the client,\nand sets c to n + 1. The next time it communicates with the other servers,\nit also sends c so that each of them can commit operations, in particular,\no. It is important to note that in this scheme, the leader is indeed in full\ncontrol: its state (as expressed by its log), is to be seen as the collective\nstate of the server group. Of course, in reality, the leader will send only the\ntuple ⟨o, t, n + 1⟩, where it will be appended to the local log of the respective\nfollowers. In this sense, the protocol essentially follows the one described in\nSection 7.5.1 (except that clients always send a request to the primary, and\nnot through a follower). More important, however, is that by stating that the\nleader, conceptually speaking, sends the entire log, it overwrites the log of its\nfollowers. If the leader receives no acknowledgement from one of its followers,\nit will simply repeat sending the log until acknowledged.\nSuppose the leader crashes. In that case, a new one is elected as described\nin Section 5.4.4, and this new leader’s log is the collective state of the server\ngroup. There is only one problem: if that log misses committed operations,\nthen it is not representative for what the majority of servers has decided on.\nFor this reason, during an election, a server S will not vote for a candidate\nserver S′ if it turns out that S’s log is more up to date, than that of S′.\nOversimplifying matters somewhat, a log is more up to date when it contains\nmore committed operations (meaning that S′ has missed several commits\nalready done by a majority of other servers), or when it contains operations\nfrom more recent terms (meaning that S′ has missed elections). Assuming\nthat the new leader will have executed all the committed operations, its state\nwill therefore be the same as that of the previous leader before it crashed.\nHowever, do note that the new leader may not necessarily have received all\npending requests. From a consensus point of view, this is not a problem. To\navoid missing any client requests, Raft does assume that when a client does\nnot receive a response from the server, it will resubmit its original request.\nWhat if the leader crashed after executing o1 (because there was a majority\nof servers), yet did not have a chance to inform (all of) the other servers?\nFirst, note that the new leader will have a log that is at least a subset of the\nlogs of a majority of the remaining servers, in terms of committed operations\n(otherwise it would have never been elected as new leader). When handling a\nnew operation o2, broadcasting its log to the other servers, and receiving an\nacknowledgement from a majority, it can not only commit o2, but now also o1.\nThis situation is shown in Figure 8.6. First, note that server S5 will be brought\nup to date about operation o1 as soon as the new leader tells about o2. After\nreceiving enough acknowledgements, the leader can go ahead and commit o1\nDS 4.01\n \n\n\n8.2. PROCESS RESILIENCE\n479\nC2\nS5\nS4\nLEADER\nS3\nLEADER\nS2\nS1\nC1\n⟨o1⟩\n⟨APP, o1, 1, 1⟩\n⟨ACK, o1⟩\n⟨ACK, o1⟩\n⟨ACK, o1⟩\no1\n⟨o2⟩\n⟨APP, o2, 2, 2⟩\n⟨ACK, o2⟩\n⟨ACK, o2⟩\n⟨ACK, o2⟩\no1 o2\n⟨HB, 2⟩\no1\no1\no1\nFigure 8.6: The situation when a leader crashes after executing an operation\nbut before being able to tell other servers that the operation has been commit-\nted.\n(as well as o2). All other servers can commit o1 as soon as they know that the\nleader did so as well.\nWe have skipped a number of details, notably details related to the fact\nthat the leader does not send entire logs, but only operation requests. For\none, this means that after an election, servers may be missing operations, or\ncould have extraneous operations, or both. Bringing the logs of followers into\na consistent state with the new leader requires some attention, which can be\nignored by assuming that entire logs are sent. These, and other details, are\nfound in Ongaro and Ousterhout [2014] and Ongaro [2014].\n8.2.4\nExample: Paxos\nDiscussing consensus in the presence of crash failures cannot be decently done\nwithout discussing Paxos. It was originally published in 1989 as a technical\nreport by Leslie Lamport, but it took about a decade before someone decided\nthat it may not be such a bad idea to disseminate it through a regular scientific\nchannel [Lamport, 1998]. The original publication is not easy to understand,\nexemplified by other publications that aim at explaining it [Lampson, 1996;\nPrisco et al., 1997; Lamport, 2001; van Renesse and Altinbuken, 2015]. In\nfact, it is generally agreed that Paxos is not only quite difficult to explain and\nunderstand, but that these intricacies have led to implementations that actually\ndiffer from the original protocol.\nThese intricacies formed an important\nmotivation for developing Raft, which we explained above.\n \nDS 4.01\n\n\n480\nCHAPTER 8. FAULT TOLERANCE\nEssential Paxos\nThe assumptions under which Paxos operates are rather weak:\n• The distributed system is partially synchronous (in fact, it may even be\nasynchronous).\n• Communication between processes may be unreliable, meaning that\nmessages may be lost, duplicated, or reordered.\n• Messages that are corrupted can be detected as such (and thus subse-\nquently ignored).\n• All operations are deterministic: once an execution is started, it is known\nexactly what it will do.\n• Processes may exhibit crash failures, but not arbitrary failures, nor do\nprocesses collude.\nBy-and-large, these are realistic assumptions for many practical distributed\nsystems.\nWe first roughly follow the explanation given by Lamport [2001] and Kirsch\nand Amir [2008]. The algorithm operates as a network of logical processes, of\nwhich there are different types. First, there are clients that request a specific\noperation to be executed. At the server side, each client is represented by a\nsingle proposer, which attempts to have a client’s request accepted. Normally,\na single proposer has been designated as being the leader, and drives the\nprotocol toward reaching consensus.\nWhat we need to establish is that a proposed operation is accepted by an\nacceptor. If a majority of acceptors accepts the same proposal, the proposal is\nsaid to be chosen. However, what is chosen still needs to be learned. To this\nend, we will have a number of learner processes, each of which will execute a\nchosen proposal once it has been informed by a majority of acceptors.\nIt is important to note that a single proposer, acceptor, and learner form a\nsingle physical process, running on a single machine that the client commu-\nnicates with, as shown in Figure 8.7. We thus assume that if, for example, a\nproposer crashes, then the physical process that it is part of will have crashed.\nBy replicating this server, we aim at obtaining fault tolerance in the presence\nof crash failures.\nThe basic model is that the leading proposer receives requests from clients,\none at a time. A nonleading proposer forwards any client request to the leader.\nThe leading proposer sends its proposal to all acceptors, telling each to accept\nthe requested operation. Each acceptor will subsequently broadcast a learn\nmessage. If a learner receives the same learn message from a majority of\nacceptors, it knows that consensus has been reached on which operation to\nexecute, and will execute it.\nDS 4.01\n \n\n\n8.2. PROCESS RESILIENCE\n481\nFigure 8.7: The organization of Paxos into different logical processes.\nThere are at least two specific issues that need further attention. First, not\nonly do the servers need to reach consensus on which operation to execute,\nwe also need to make sure that each of them actually executes it. In other\nwords, how do we know for sure that a majority of the nonfaulty servers will\ncarry out the operation? There is essentially only one way out: have learn\nmessages be retransmitted. However, to make this work, an acceptor will have\nto log its decisions (in turn requiring a mechanism for purging logs). Because\nwe are assuming globally ordered proposal timestamps (as explained shortly),\nmissing messages can be easily detected, and also accepted operations will\nalways be executed in the same order by all learners.\nAs a general rule, the server hosting the leading proposer will also inform\nthe client when its requested operation has been executed. If another process\nhad taken over the lead, then it will also handle the response to the client.\nThis brings us to the second important issue: a failing leader. Life would\nbe easy if the failure of a leader would be reliably detected, after which a\nnew leader would be elected, and later, the recovering leader would instantly\nnotice that the world around it had changed. Unfortunately, life is not so easy.\nPaxos has been designed to tolerate proposers who still believe they are in the\nlead. The effect is that proposals may be sent out concurrently by different\nproposers (each believing to be the leader). We therefore need to make sure\nthat these proposals can be distinguished from one another to ensure that the\nacceptors handle only the proposals from the current leader.\nNote that relying on a leading proposer implies that any practical im-\nplementation of Paxos will need to be accompanied by a leader-election\nalgorithm. In principle, that algorithm can operate independently of Paxos,\nbut is normally part of it.\n \nDS 4.01\n\n\n482\nCHAPTER 8. FAULT TOLERANCE\nTo distinguish concurrent proposals from different proposers, each pro-\nposal p has a uniquely associated (logical) timestamp ts(p). How uniqueness\nis achieved is left to an implementation, but we will describe some of the\ndetails shortly. Let oper(p) denote the operation associated with proposal p.\nThe trick is to allow multiple proposals to be accepted, but that each of these\naccepted proposals has the same associated operation. This can be achieved\nby guaranteeing that if a proposal p is chosen, then any proposal with a higher\ntimestamp will also have the same associated operation. In other words, we\nrequire that\np is chosen ⇒for all p′ with ts(p′) > ts(p) : oper(p′) = oper(p)\nOf course, for p to be chosen, it needs to be accepted. That means that we\ncan guarantee our requirement when guaranteeing that if p is chosen, then\nany higher-timestamped proposal accepted by any acceptor, has the same\nassociated operation as p. However, this is not sufficient, for suppose that\nat a certain moment, a proposer simply sends a new proposal p′, with the\nhighest timestamp so far, to an acceptor A that had not received any proposal\nbefore. Note that this may indeed happen according to our assumptions\nconcerning message loss and multiple proposers, each believing to be in the\nlead. In absence of any other proposals, A will simply accept p′. To prevent\nthis situation from happening, we thus need to guarantee that\nIf proposal p is chosen, then any higher-timestamped proposal issued by a\nproposer, has the same associated operation as p.\nWhen explaining the Paxos algorithm below, we will indeed see that a pro-\nposer may need to adopt an operation coming from acceptors in favor of its\nown. This will happen after a leading proposer had failed, but its proposed\noperation had already made it to a majority of the acceptors.\nThe processes collectively formally ensure safety, in the sense that only\nproposed operations will be learned, and that at most one operation will be\nlearned at a time. In general, a safety property asserts that nothing bad will\nhappen. Furthermore, Paxos ensures conditional liveness in the sense that if\nenough processes remain up-and-running, then a proposed operation will\neventually be learned (and thus executed). Liveness, which tells us that\neventually something good will happen, is not guaranteed in Paxos, unless\nsome adaptations are made. We return to liveness in Note 8.4.\nThere are now two phases, each, in turn, consisting of two subphases.\nDuring the first phase, the leading proposer interacts with acceptors to get\na requested operation accepted for execution. The first phase is needed to\nrule out any trouble caused by different proposers, each believing they are\nthe leader. The best that can happen is that an individual acceptor promises\nto consider the proposer’s operation and ignore other requests. The worst is\nthat the proposer was too late and that it will be asked to adopt some other\nDS 4.01\n \n\n\n8.2. PROCESS RESILIENCE\n483\nproposer’s request instead. Apparently, a leadership change had taken place\nand there may be former requests that need to be handled first.\nIn the second phase, the acceptors will have informed proposers about the\npromises they have made. The leading proposer essentially takes up a slightly\ndifferent role by promoting a single operation to the one to be executed, and\nsubsequently telling the acceptors.\nPhase 1a (prepare): The goal of this phase is that a proposer P who believes\nit is the leader and is proposing operation o, tries to get its proposal\ntimestamp anchored, in the sense that any lower timestamp failed, or that\no had also been previously proposed (i.e., with some lower proposal\ntimestamp). To this end, P broadcasts its proposal to the acceptors.\nFor the operation o, the proposer selects a proposal number m higher\nthan any of its previously selected numbers. This leads to a proposal\ntimestamp t = (m, i) where i is the (numerical) process identifier of P.\nNote that\n(m, i) < (n, j) ⇔(m < n) or (m = n and i < j)\nThis timestamp for a proposal p is an implementation of the previously\nmentioned timestamp ts(p). Proposer P sends prepare(t) to all accep-\ntors (but note that messages may be lost). In doing so, it is (1) asking the\nacceptors to promise not to accept any proposals with a lower proposal\ntimestamp, and (2) to inform it about an accepted proposal, if any, with\nthe highest timestamp less than t. If such a proposal exists, the proposer\nwill adopt it.\nPhase 1b (promise): An acceptor A may receive multiple proposals. Assume\nit receives prepare(t) from P. There are three cases to consider:\n(1) t is the highest proposal timestamp received from any proposer so\nfar. In that case, A will return promise(t) to P stating that A will\nignore any future proposals with a lower timestamp.\n(2) If t is the highest timestamp so far, but another proposal (t′, o′) had\nalready been accepted, A also returns (t′, o′) to P. This will allow P\nto decide on the final operation that needs to be accepted.\n(3) In all other cases, do nothing: there is apparently another proposal\nwith a higher timestamp that is being processed.\nOnce the first phase has been completed, the leading proposer P knows what\nthe acceptors have promised. Essentially, the leading proposer knows that all\nacceptors have agreed on the same operation. This will put P into a position\nto tell the acceptors that they can go ahead. This is needed because although\nthe leading proposer knows on which operation consensus has been reached,\nthis consensus is not known to the others. Again, we assume that P received\n \nDS 4.01\n\n\n484\nCHAPTER 8. FAULT TOLERANCE\na response from a majority of acceptors (whose respective responses may be\ndifferent).\nPhase 2a (accept): There are two cases to consider:\n(1) If P does not receive any accepted operation from any of the ac-\nceptors, it will forward its own proposal for acceptance by sending\naccept(t, o) to all acceptors.\n(2) Otherwise, it was informed about another operation o′, which it will\nadopt and forward for acceptance. It does so by sending accept(t,\no′), where t is P’s proposal timestamp and o′ is the operation with\nproposal timestamp highest among all accepted operations that\nwere returned by the acceptors in Phase 1b.\nPhase 2b (learn): Finally, if an acceptor receives accept(t, o′), but did not\npreviously send a promise with a higher proposal timestamp, it will ac-\ncept operation o′, and tell all learners to execute o′ by sending learn(o′).\nAt that point, the acceptor can forget about o′. A learner L receiving\nlearn(o′) from a majority of acceptors, will execute the operation o′.\nWe now also know that a majority of learners share the same idea on\nwhich operation to execute.\nIt is important to realize that this description of Paxos indeed captures only its\nessence: using a leading proposer to drive the acceptors toward the execution\nof the same operation. When it comes to practical implementations, much\nmore needs to be done (and more than we are willing to describe here). An\nexcellent description of what it means to realize Paxos has been written by\nKirsch and Amir [2008]. Another write-up on its practical implications can be\nfound in [Chandra et al., 2007].\nUnderstanding Paxos\nTo properly understand Paxos, but also many other consensus algorithms, it\nis useful to see how its design could have evolved. We say “could have,” as\nthe evolution of the algorithm has never been documented. The following\ndescription is largely based on work described by Meling and Jehl [2013]1. As\nour starting point, we consider a server that we wish to make more robust. By\nnow, we know that this can be achieved through replication and making sure\nthat all commands submitted by clients are executed by all servers in the same\norder. The simplest situation is to add one server, thus creating a group of two\nprocesses, say S1 and S2. Also, to make sure that all commands are executed\nin the same order, we appoint one process to be a sequencer, which increments\nand associates a unique timestamp with every submitted command. Servers\n1Special credits go to Hein Meling for helping us better understand what Paxos is all about.\nDS 4.01\n \n\n\n8.2. PROCESS RESILIENCE\n485\nare required to execute commands according to their timestamp. In Paxos,\nsuch a server is referred to as the leader. We can also consider it to be a\nprimary server, with the other acting as a backup server.\nWe assume that a client broadcasts its requested command to all servers.\nIf a server notices it is missing a command, it can rely on the other server\nto forward it when necessary. We will not describe how this happens, but\nsilently assume that all commands are stored at the servers and that we merely\nneed to make sure that the servers agree on which command to execute next.\nAs a consequence, all remaining communication between servers consists of\ncontrol messages. To make this point clear, consider the situation sketched in\nFigure 8.8. (In what follows, we use subscripts to designate processes, and\nsuperscripts to designate operations and states.)\nFigure 8.8: Two clients communicating with a 2-server process group.\nIn this example, server S1 is the leader and as such will hand out time-\nstamps to submitted requests. Client C1 has submitted command o1 while C2\nsubmitted o2. S1 instructs S2 to execute operation o2 with timestamp 1, and\nlater operation o1 with timestamp 2. After processing a command, a server\nwill return the result to the associated client. We designate this using the\nnotation ⟨σj\ni ⟩, where i is the index of the reporting server, and j the state it\nwas in, expressed as the sequence of operations it has carried out. In our\nexample, client C1 will thus see the results ⟨σ21\n1 ⟩and ⟨σ21\n2 ⟩, meaning that each\nserver has executed o1 after executing o2.\nIn Paxos, when a leader associates a timestamp with an operation, it does\nso by sending an accept message to the other server(s). As we assume that\nmessages may be lost, a server accepting an operation o does so by telling\nthe leader it has learned the operation by returning a learn(o) message.\nWhen the leader does not notice that operation o has been learned, it simply\nretransmits an accept(o, t) message, with t being the original timestamp. Note\nthat in our description, we are skipping the phase of coming to agreement on\nthe operation to be carried out: we assume the leader has decided and now\nneeds to reach consensus on executing that operation.\n \nDS 4.01\n",
      "page_number": 486
    },
    {
      "number": 49,
      "title": "Segment 49 (pages 496-506)",
      "start_page": 496,
      "end_page": 506,
      "detection_method": "topic_boundary",
      "content": "486\nCHAPTER 8. FAULT TOLERANCE\nCompensating for a lost message is relatively easy, but what happens when\nalso a server crashes? Let us first assume that a crash can be reliably detected.\nConsider the situation sketched in Figure 8.9(a). The issue, of course, is that\nserver S2 will never have learned (about) operation o1. This situation can be\nprevented by demanding that a server may execute an operation only if it\nknows that the other server has learned the operation as well, as illustrated in\nFigure 8.9(b).\n(a)\n(b)\nFigure 8.9: (a) What may happen when the leader crashes in combination\nwith a lost accept, and (b) the solution, namely demanding that the other\nserver has learned the operation as well before executing it.\nIt is not difficult to see that with a larger process group, we can get into the\nsame situation as in Figure 8.9(a). Simply consider a group of three servers\n{S1, S2, S3} with S1 being the leader. If its accept(o1, t) message to S3 is lost,\nyet it knows that S2 has learned o1, then it should still not execute o1 until\nit has also received a learn(o1) message from S3. This situation is shown in\nFigure 8.10.\nLet us consider the three-server case and imagine what would happen\nif learn(o1) returned by S2 would not make it to S1. Of course, S1 would\nDS 4.01\n \n\n\n8.2. PROCESS RESILIENCE\n487\nFigure 8.10: The situation when dealing with three servers, of which two\ncrash. In this case, S1 should have waited with executing operation o1 until it\nhad received learn(o1) from S3, but also S2 should wait until it knows that\nS3 has learned about o1.\nnot execute o1, but otherwise we would still be in trouble: S2 will execute o1\nwhile S3 would take over leadership and execute o2 without ever knowing\nthat o1 had already been processed. In other words, also S2 must wait with\nthe execution of o1 until it knows that S3 has learned that operation. This\nbrings us to the following:\nIn Paxos, a server S cannot execute an operation o until it has received a\nlearn(o) from all other nonfaulty servers.\nUp to this point, we have assumed that a process can reliably detect that\nanother process has crashed. In practice, this is not the case. As we will\ndiscuss more extensively shortly, a standard approach toward failure detection\nis to set a timeout on expected messages. For example, each server is required\nto send a message declaring it is still alive, and at the same time the other\nservers set timeouts on the expected receipt of such messages. If a timeout\nexpires, the sender is suspected to have failed. In a partially synchronous or\nfully asynchronous system, there is essentially no other solution. However,\nthe consequence is that a failure may be falsely detected, as the delivery of\nsuch “I’m alive” messages may have simply been delayed or lost.\nLet us assume that Paxos has realized a failure detection mechanism, but\nthat the two servers falsely conclude that the other has failed, as shown in\nFigure 8.11. The problem is clear: each may now independently decide to\nexecute their operation of choice, leading to divergent behavior. It is at this\npoint that we need to introduce an extra server, and demand that a server\ncan execute an operation only if it is certain that a majority will execute that\noperation. Note, that in the three-server case, execution of operation o by\n \nDS 4.01\n\n\n488\nCHAPTER 8. FAULT TOLERANCE\nserver S can take place as soon as S has received at least one (other) learn(o)\nmessage. Together with the sender of that message, S will form a majority.\nFigure 8.11: The situation in the case of false failure detections.\nWe have now come to a point where it should be clear that Paxos requires\nat least three replicated servers {S1, S2, S3} to operate correctly. Let us concen-\ntrate on the situation that one of these servers crashes. We make the following\nassumptions.\n• Initially, S1 is the leader.\n• A server can reliably detect it has missed a message. The latter can\nbe realized, for example, through timestamps in the form of strictly\nincreasing sequence numbers. Whenever a server notices it has missed\na message, it can then simply request a retransmission and catch up\nbefore continuing.\n• When a new leader needs to be elected, the remaining servers follow a\nstrictly deterministic algorithm. For example, we can safely assume that\nif S1 crashes, then S2 will become leader. Likewise, if S2 crashes, S3 will\ntake over, and so on.\n• Clients may receive duplicate responses, but besides being required to\nrecognize duplicates, form no further part of the Paxos protocol. In\nother words, a client cannot be asked to help the servers to resolve a\nsituation.\nUnder these circumstances, no matter when one of S2 or S3 crashes, Paxos\nwill behave correctly. Of course, we are still demanding that execution of an\noperation can take place only if a server knows that a majority will execute\nthat operation.\nSuppose now that S1 in its role as leader, crashes after the execution of\noperation o1. The worst that can happen in this case is that S3 is completely\nignorant of the situation until the new leader, S2 tells it to accept operation o2.\nNote that this is announced through an accept(o2, 2) message such that the\nDS 4.01\n \n\n\n8.2. PROCESS RESILIENCE\n489\ntimestamp t = 2 will alert S3 that it missed a previous accept message. S3 will\ntell so to S2, who can then retransmit accept(o1, 1), allowing S3 to catch up.\nLikewise, if S2 missed accept(o1, 1), but did detect that S1 crashed, it\nwill eventually either send accept(o1, 1) or accept(o2, 1) to S3 (i.e., in both\ncases using timestamp t = 1, which was previously used by S1). Again, S3\nhas enough information to get S2 on the right track again. If S2 had sent\naccept(o1, 1), S3 can simply tell S2 that it already learned o1. In the other\ncase, when S2 sends accept(o2, 1), S3 will inform S2 that it apparently missed\noperation o1. We conclude that when S1 crashes after executing an operation,\nPaxos behaves correctly.\nSo, what can happen if S1 crashes immediately after having sent accept(o1,\n1) to the other two servers? Suppose again that S3 is completely ignorant of\nthe situation because messages are lost, until S2 has taken over leadership\nand announces that o2 should be accepted. Like before, S3 can tell S2 that\nit (i.e., S3) missed operation o1, so that S2 can help S3 to catch up. If S2\nmisses messages, but does detect that S1 crashed, then as soon as it takes over\nleadership and proposes an operation, it will be using a stale timestamp. This\nwill trigger S3 to inform S2 that it missed operation o1, which saves the day.\nAgain, Paxos is seen to behave correctly.\nC2\nS3\nS2\nLEADER\nS1\nLEADER\nC1\n⟨o1⟩\n⟨o2⟩\n⟨ACC, o1, 1⟩\n⟨ACC, o2, 2⟩\n⟨LRN, o2⟩\ndrop leadership\no2\n⟨σ2\n3⟩\nconfusion\nFigure 8.12: Why incorporating the ID of the current leader is needed: S2\nfalsely concludes that S1 has crashed.\nProblems may arise with false detections of crashes. Consider the sit-\nuation sketched in Figure 8.12. We see that the accept messages from S1\nare considerably delayed and that S2 falsely detects S1 having crashed. S2\ntakes over leadership and sends accept(o2, 1), i.e., with a timestamp t = 1.\nHowever, when finally accept(o1, 1) arrives, S3 cannot do anything: this is\nnot a message it is expecting. Note that, in principle, S3 does not check who\nis the current leader. The only thing it knows is that it is itself not the leader.\n \nDS 4.01\n\n\n490\nCHAPTER 8. FAULT TOLERANCE\nPrecisely for this reason, it does not expect an accept message with the same\ntimestamp as before. Things change, however, if it does know who the current\nleader is, in combination with a deterministic leader election. In that case,\nit could safely reject accept(o1, 1), knowing that by now S2 has taken over,\nand even perhaps retransmit learn(o2) to S1. A (perhaps previously sent)\nlearn(o2) message received by S1 will allow S1 to conclude that leadership\nhad been taken over. We conclude that the leader should include its ID in an\naccept message.\nWe have covered almost all cases and have thus far shown that Paxos\nbehaves correctly. Unfortunately, although being correct, the algorithm can\nstill come to a grinding halt. Consider the situation illustrated in Figure 8.13.\nWhat we are seeing here is that because the learn messages returned by S3\nare lost, neither S1 nor S2 will ever be able to know what S3 actually executed:\ndid it learn (and execute) accept(o1, 1) before or after learning accept(o2,\n1), or perhaps it learned neither operation? A solution to this problem is\ndiscussed in Note 8.4.\nC2\nS3\nS2\nLEADER\nS1\nLEADER\nC1\n⟨o1⟩\n⟨o2⟩\n⟨ACC, S1, o1, 1⟩\n⟨LRN, o1⟩\no1\n⟨σ1\n3⟩\n⟨ACC, S2, o2, 1⟩\n⟨LRN, o2⟩\no2\n⟨σ12\n3 ⟩\nFigure 8.13: When Paxos can make no further progress.\nNote 8.4 (Advanced: Making progress in Paxos)\nUp to this point, we have discussed the development of Paxos such that safety is\nensured. Safety essentially means that nothing bad will happen, or, put differently,\nthat the behavior of the algorithm is correct. To also ensure that eventually\nsomething good will happen, generally referred to as liveness of an algorithm, we\nneed to do a bit more. In particular, we need to get out of the situation sketched\nin Figure 8.13.\nThe real problem with this situation is that the servers have no consensus on\nwhom the leader is. Once S2 decides it should take over leadership, it needs to\nensure that any outstanding operations initiated by S1 have been properly dealt\nwith. In other words, it has to ensure that its own leadership is not hindered\nDS 4.01\n \n\n\n8.2. PROCESS RESILIENCE\n491\nby operations that have not yet been completed by all nonfaulty processes. If\nleadership is taken over too quickly and a new operation is proposed, a previous\noperation that has been executed by at least one server may not get a chance to be\nexecuted by all servers first.\nTo this end, Paxos enforces an explicit leadership takeover, and this is where\nthe role of proposers come from. When a server crashes, the next one in line\nwill need to take over (recall that Paxos assumes a deterministic leader-election\nalgorithm), but also ensure that any outstanding operations are dealt with. This ex-\nplicit takeover is implemented by broadcasting a proposal message: propose(Si),\nwhere Si is the next server to be leader. When server Sj receives this message,\nit replies with a promise(oj, tj) message, containing the most recently executed\noperation oj and its corresponding timestamp tj. Note that Si is particularly\ninterested in the most recent operation o∗executed by a majority of servers. By\n“adopting” this operation from the (apparently crashed) server S∗that had origi-\nnally proposed its acceptance, Si can effectively complete what S∗could not due\nto its failure.\nThere are two obvious optimizations to this procedure. The first one is not\nthat servers return the most recently executed operation, but the most recently\nlearned operation that is still waiting to be executed, if any. Furthermore, because\nit may be that the collection of servers has no more pending operations, Si can\nalso suggest a next operation oi when initially proposing to take over leadership,\ngiving rise to a propose(Si, oi) message. In essence, this is the situation we\ndescribed earlier, yet now it should be clear where the idea of proposals actually\ncomes from.\nWhen Si receives a majority of promises for operation o∗, and the highest\nreturned timestamp is t∗, it broadcasts accept(Si, o∗, t∗), which is essentially a\nretransmission of the last operation proposed before Si took over leadership. If no\nsuch o∗exists, Si will propose to accept its own operation oi.\n8.2.5\nConsensus in faulty systems with arbitrary failures\nSo far, we assumed that replicas were subject to only crash failures, in which\ncase a process group needs to consist of 2k + 1 servers to survive k crashed\nmembers. An important assumption in these cases, is that a process does\nnot collude with another process, or, more specifically, is consistent in its\nmessages to others. The situations shown in Figure 8.14 should not happen.\nIn the first case, we see that process P2 is forwarding a different value or\noperation than it is supposed to. Referring to Paxos, this could mean that a\nprimary tells the backups that not operation o had been accepted, but instead\npropagates a different operation o′. In the second case, P1 is telling different\nthings to different processes, such as having a leader sending operation o to\nsome backups, and at the same time operation o′ to others. Again, we note\nthat this need not be malicious actions, but simply omission or commission\nfailures.\n \nDS 4.01\n\n\n492\nCHAPTER 8. FAULT TOLERANCE\n(a)\n(b)\nFigure 8.14: A process in a replicated group acting inconsistently: (a) not\nforwarding properly, and (b) telling different things to different processes.\nIn this section, we take a look at reaching consensus in a fault-tolerant\nprocess group in which k members can fail, assuming arbitrary failures.\nIn particular, we will show that we need at least 3k + 1 members to reach\nconsensus under these failure assumptions.\nConsider a process group consisting of n members, of which one has been\ndesignated to be the primary, P, and the remaining n −1 to be the backups\nB1, . . . , Bn−1. We make the following assumptions:\n• A client sends a value v ∈{T, F} to the primary, where v stands for\neither true or false.\n• Messages may be lost, but this can be detected.\n• Messages cannot be corrupted without that being detected (and thus\nsubsequently ignored).\n• A receiver of a message can reliably detect its sender.\nTo achieve what is known as Byzantine agreement, we need to satisfy the\nfollowing two requirements:\nBA1: Every nonfaulty backup process stores the same value.\nBA2: If the primary is nonfaulty, then every nonfaulty backup process stores\nexactly what the primary had sent.\nNote that if the primary is faulty, BA1 tells us that the backups may store\nthe same, but different (and thus wrong) value than the one initially sent by\nthe client. Furthermore, it should be clear that if the primary is not faulty,\nsatisfying BA2 implies that BA1 is also satisfied.\nWhy having 3k processes is not enough\nTo see why having only 3k processes is not enough to reach consensus, let\nus consider the situation in which we want to tolerate the failure of a single\nprocess, that is, k = 1. Consider Figure 8.15, which is essentially an extension\nof Figure 8.14.\nDS 4.01\n \n\n\n8.2. PROCESS RESILIENCE\n493\n(a)\n(b)\nFigure 8.15: Impossibility to reach consensus with 3 processes and trying to\ntolerate a single arbitrarily failing process.\nIn Figure 8.15(a), we see that the faulty primary P is sending two different\nvalues to the backups B1 and B2, respectively. To reach consensus, both\nbackup processes forward the received value to the other, leading to a second\nround of message exchanges. At that point, B1 and B2 each have received the\nset of values {T, F}, from which it is impossible to draw a conclusion.\nLikewise, we cannot reach consensus when wrong values are forwarded.\nIn Figure 8.15(b), the primary P and backup B2 operate correctly, but B1 is\nnot. Instead of forwarding the value T to process B2, it sends the incorrect\nvalue F. The result is that B2 will now have seen the set of values {T, F}\nfrom which it cannot draw any conclusions. In other words, P and B2 cannot\nreach consensus. More specifically, B2 can not decide what to store so that we\ncannot satisfy requirement BA2.\nNote 8.5 (Advanced: The case where k > 1 and n ≤3k)\nGeneralizing this situation to other values of k is not that difficult. As explained\nby Kshemkalyani and Singhal [2008], we can use a simple reduction scheme.\nAssume that there is a solution for the case where k ≥1 and n ≤3k. Partition the\nn processes Q1, . . . , Qn into three disjoint sets S1, S2, and S3, together containing\nall processes. Moreover, let each set Sk have less or equal than n/3 members.\nFormally, this means that\n• S1 ∩S2 = S1 ∩S3 = S2 ∩S3 = ∅\n• S1 ∪S2 ∪S3 = {Q1, . . . , Qn}\n• for each Si, |Si| ≤n/3\nNow consider a situation in which three processes Q∗\n1, Q∗\n2, and Q∗\n3 simulate the\nactions that take place in and between the processes of S1, S2, and S3, respectively.\nIn other words, if a process in S1 sends a message to another process in S2, then\nQ∗\n1 will send a same message to Q2. The same holds for process communication\nwithin a group. Assume that Q∗\n1 is faulty, yet Q∗\n2 and Q∗\n3 are not. All processes\nsimulated by Q∗\n1 are now assumed to be faulty, and will thus lead to incorrect\n \nDS 4.01\n\n\n494\nCHAPTER 8. FAULT TOLERANCE\n(a)\n(b)\nFigure 8.16: Reaching consensus with four processes, of which one may fail\narbitrarily.\nmessages being sent to Q∗\n2 and Q∗\n3, respectively. Not so for Q∗\n2 (and Q∗\n3): all\nmessages coming from processes in S2 (and S3, respectively) are assumed to be\ncorrect. Because n ≤3k and for each set Si we have that |Si| ≤n/3, at most n/3\nof the simulated processes Q1, . . . , Qn are faulty. In other words, we are satisfying\nthe condition for which we assumed that there would be a general solution.\nWe can now come to a contradiction, for if there would exist a solution for\nthe general case, then the processes Q∗\n1, Q∗\n2, and Q∗\n3 could simulate this solution,\nwhich would then also be a solution for the special case that n = 3 and k = 1. Yet,\nwe just proved that this cannot be so, leading to a contradiction. We conclude that\nour assumption that there is a general solution for k ≥1 and n ≤3k is false.\nWhy having 3k + 1 processes is enough\nLet us now focus on the case in which we have a group of 3k + 1 processes.\nOur goal is to show that we can establish a solution in which k group members\nmay suffer from fail-arbitrary failures, yet the remaining nonfaulty processes\nwill still reach consensus. Again, we first concentrate on the case n = 4, k = 1.\nConsider Figure 8.16, which shows a situation with one primary P and three\nbackup processes B1, B2, and B3.\nIn Figure 8.16(a) we have sketched the situation in which the primary P is\nDS 4.01\n \n\n\n8.2. PROCESS RESILIENCE\n495\nfaulty and is providing inconsistent information to its backups. In our solution,\nthe processes will forward what they receive to the others. During the first\nround, P sends T to B1, F to B2, and T to B3, respectively. Each of the backups\nthen sends what they have to the others. With only the primary failing, this\nmeans that after two rounds, each of the backups will have received the set of\nvalues {T, T, F}, meaning that they can reach consensus on the value T.\nWhen we consider the case that one of the backups fails, we get the\nsituation sketched in Figure 8.16(b). Assume that the (nonfaulty) primary\nsends T to all the backups, yet B2 is faulty. Where B1 and B3 will send out T\nto the other backups in a second round, the worst that B2 may do is send out\nF, as shown in the figure. Despite this failure, B1 and B3 will come to the same\nconclusion, namely that P had sent out T, thereby meeting our requirement\nBA2 as stated before.\nNote 8.6 (Advanced: The case where k > 1 and n = 3k + 1)\nAs a sketch toward a general solution, consider the more intricate case in which\nn = 7 and k = 2. We let the primary P send out a value v0. Using a similar\nnotation as found in [Kshemkalyani and Singhal, 2008], we proceed as follows.\nNote that we effectively use the index 0 to denote the primary P (think of P being\nequal to a special backup process B0).\n1. We let P send v0 to the six backups. Backup Bi stores the received value\nas vi,0⟨⟩. This notation indicates that the value was received by process Bi,\nthat it was sent by P = B0, and that the value of v0 was directly sent to Bi\nand not through another process (using the notation ⟨⟩). So, for example,\nB4 will store v0 in v4,0⟨⟩.\n2. Each backup Bi, in turn, will send vi,0⟨⟩to every one of the other five\nbackups, which is stored by Bj as vj,i⟨0⟩. This notation indicates that the\nvalue is stored at Bj, was sent by Bi, but that it originated from P = B0\n(through the notation ⟨0⟩). Looking at B4 again, it will receive values from\nB1, B2, B3, B5, and B6. For example, B2 will send v2,0⟨⟩, which is then\nstored as v4,2⟨0⟩by B4. Likewise, B4 will also store v4,1⟨0⟩, v4,3⟨0⟩, v4,5⟨0⟩,\nand v4,6⟨0⟩.\n3. Suppose that Bi now has the value vi,j⟨0⟩. Again, it will send out this value\nto all processes except P = B0, Bj, and Bi (i.e., itself). If Bk receives vi,j⟨0⟩\nfrom Bi, it stores this received value in vk,i⟨j, 0⟩. Indeed, by then v0 will\nhave traveled the path P →Bj →Bi →Bk. For example, in the previous\nround, B2 will have stored v2,1⟨0⟩, which it eventually sends to B4, who, in\nturn, will store it as v4,2⟨1, 0⟩. Note at this point, that B4 can send out this\nvalue only to processes B3, B5, and B6. There is no use in sending it out to\nother processes.\n4. Continuing this line of thought, assume that Bi has value vi,j⟨k, 0⟩, which\nit sends out to the three remaining processes not equal to P = B0, Bk, Bj,\nand Bi (itself). Returning to B4, eventually, B4 will also receive a similar\nmessage from, say, B3, such as v3,2⟨5, 0⟩: the value v0 initially sent to B5,\n \nDS 4.01\n\n\n496\nCHAPTER 8. FAULT TOLERANCE\nwhich then forwarded it to B2, who, in turn, sent it to B3. B4 will store that\nvalue as v4,3⟨2, 5, 0⟩. That value can be sent only to B1 and B6, after which\nonly a single round is left.\nOnce all these messages have been sent, each backup can start moving out of the\nrecursion again. Note that in the above scheme we have effectively constructed a\ntree, rooted at value v0 with six child nodes (representing the six backups). Each\nof these nodes, in turn, will have five children of its own, and so on. In total, there\nwill be 6! = 720 leaf nodes. Each path from the root to a leaf node is encoded by\nthe value stored at that leaf node, such as v4,1⟨6, 5, 3, 2, 0⟩. This leaf node will have\na single parent (namely B1 storing v1,6⟨5, 3, 2, 0⟩), in turn with a single sibling (B4\nstoring v4,6⟨5, 3, 2, 0⟩).\nFigure 8.17: Rounds of broadcasting v0 to the backups, by P and the\nbackups B1, . . . , B6.\nWe can now let each backup start computing estimates of v0, that is, a value\nthat it believes v0 should be. To this end, we assume that each (nonfaulty) process\nexecutes the same procedure majority() that selects a unique value from a given\nset of inputs. In practice, this will be the majority among the input set. If there\nis no majority, a default value is chosen. To give a few examples, also shown in\nFigure 8.17:\nw4,1⟨5, 3, 2, 0⟩\n←\nmajority(v4,1⟨5, 3, 2, 0⟩, v6,4⟨1, 5, 3, 2, 0⟩)\nw6,1⟨5, 3, 2, 0⟩\n←\nmajority(v6,1⟨5, 3, 2, 0⟩, v4,6⟨1, 5, 3, 2, 0⟩)\nw1,4⟨5, 3, 2, 0⟩\n←\nmajority(v1,4⟨5, 3, 2, 0⟩, v6,1⟨4, 5, 3, 2, 0⟩)\nw6,4⟨5, 3, 2, 0⟩\n←\nmajority(v6,4⟨5, 3, 2, 0⟩, v1,6⟨4, 5, 3, 2, 0⟩)\nw1,6⟨5, 3, 2, 0⟩\n←\nmajority(v1,6⟨5, 3, 2, 0⟩, v4,1⟨6, 5, 3, 2, 0⟩)\nw4,6⟨5, 3, 2, 0⟩\n←\nmajority(v4,6⟨5, 3, 2, 0⟩, v1,4⟨6, 5, 3, 2, 0⟩)\nDS 4.01\n \n",
      "page_number": 496
    },
    {
      "number": 50,
      "title": "Segment 50 (pages 507-517)",
      "start_page": 507,
      "end_page": 517,
      "detection_method": "topic_boundary",
      "content": "8.2. PROCESS RESILIENCE\n497\nIn turn, B1, B4, and B6 can compute estimates like:\nw1,5⟨3, 2, 0⟩\n←\nmajority(v1,5⟨3, 2, 0⟩, w4,1⟨5, 3, 2, 0⟩, w6,1⟨5, 3, 2, 0⟩\nw4,5⟨3, 2, 0⟩\n←\nmajority(v4,5⟨3, 2, 0⟩, w1,4⟨5, 3, 2, 0⟩, w6,4⟨5, 3, 2, 0⟩\nw6,5⟨3, 2, 0⟩\n←\nmajority(v6,5⟨3, 2, 0⟩, w1,6⟨5, 3, 2, 0⟩, w4,6⟨5, 3, 2, 0⟩\nAnd from there, B5 can continue, for example, with:\nw5,3⟨2, 0⟩\n←\nmajority(v5,3⟨2, 0⟩, w1,5⟨3, 2, 0⟩, w4,5⟨3, 2, 0⟩, w6,5⟨3, 2, 0⟩)\nThis process continues until, eventually, B2 from Figure 8.17 will be able to execute\nw2,0⟨⟩←majority(v2,0⟨⟩, w1,2⟨0⟩, w3,2⟨0⟩, w4,2⟨0⟩, w5,2⟨0⟩, w6,2⟨0⟩)\nand reach the final outcome.\nLet us now see why this scheme actually works. We denote by BAP(n,k)\nthe above sketched protocol to reach consensus. BAP(n,k) starts by having the\nprimary send out its value v0 to the n −1 backups. In the case the primary\noperates correctly, each of the backups will indeed receive v0. If the primary is\nfaulty, some backups receive v0 while others receive v0 (i.e., the opposite of v0).\nBecause we assume a backup Bi cannot know whether the primary is working\ncorrectly, it will have to check with the other backups.\nWe therefore let Bi\nrun the protocol again, but in this case, with value vi,0⟨⟩and with a smaller\nprocess group, namely {B1, . . . , Bi−1, Bi+1, . . . , Bn}. In other words, Bi executes\nBAP(n-1,k-1) with a total of n −2 other processes. Note that at this point there\nare n −1 instances of BAP(n-1,k-1) being executed in parallel.\nIn the end, we see that these executions result in each backup Bi taking the\nmajority of n −1 values:\n• One value comes from the primary: vi,0⟨⟩\n• n −2 values come from the other backups, in particular, Bi is dealing with\nthe values vi,1⟨⟩, . . . , vi,i−1⟨⟩, vi,i+1⟨⟩, . . . , vi,n−1⟨⟩.\nHowever, because Bi cannot trust a received value vi,j⟨⟩, it will have to check that\nvalue with the other n −2 backups: B1, . . . , Bi−1, Bi+1, . . . , Bj−1, Bj+1, . . . , Bn−1.\nThis leads to the execution of BAP(n-2,k-2), of which a total of n −2 instances\nwill be running in parallel. This story continues, and eventually, a backup process\nwill need to run BAP(n-k,0), which simply returns the value sent by the primary,\nafter which we can move up the recursion as described above.\nWith this general scheme, we can now see why the protocol is correct. Fol-\nlowing Koren and Krishna [2007], we use induction on k to prove that BAP(n,k)\nmeets the requirements BA1 and BA2 for n ≥3k + 1 and for all k ≥0.\nFirst, consider the case k = 0. In other words, we assume that there are no\nfaulty processes. In that case, whatever the primary sends to the backups, that\nvalue will be consistently propagated throughout the system, and no other value\nwill ever pop up. In other words, for any n, BAP(n,0) is correct. Now consider\nthe case k > 0.\nFirst, consider the case that the primary is operating correctly. Without loss of\ngenerality, we can assume the primary sends out T. All the backups receive the\n \nDS 4.01\n\n\n498\nCHAPTER 8. FAULT TOLERANCE\nsame value, namely T. Each backup will then run BAP(n-1,k-1). By induction,\nwe know that each of these instances will be executed correctly. This means that\nfor any nonfaulty backup B, all the other nonfaulty backups will store the value\nthat was sent by B, namely T. Each nonfaulty backup receives, in total, n −1\nvalues, of which n −2 come from other backups. Of those n −2, at most k values\nmay be wrong (i.e., F). With k ≤(n −1)/3, this means that every nonfaulty\nbackup receives at least 1 + (n −2) −(n −1)/3 = (2n −2)/3 values T. Because\n(2n −2)/3 > n/3 for all n > 2, this means that every nonfaulty backup can take\na correct majority vote on the total number of received values, thus satisfying\nrequirement BA2.\nLet us now consider the case that the primary is faulty, meaning that at most\nk −1 backups may operate incorrectly as well. The primary is assumed to send\nout any value it likes. There are a total of n −1 backups, of which at most k −1\nare faulty. Each backup runs BAP(n-1,k-1) and by, induction, each one of these\ninstances is executed correctly. In particular, for every nonfaulty backup B, all\nthe other nonfaulty backups will vote for the value sent by B. This means that\nall nonfaulty backups will have the same vector of n −2 results from their fellow\nbackups. Any difference between two nonfaulty backups can be caused only by\nthe fact that the primary sent something else to each of them. As a result, when\napplying majority() to those complete vectors, the result for each backup will be\nthe same, so that requirement BA1 is met.\nExample: Practical Byzantine Fault Tolerance\nByzantine fault tolerance was for long more or less an exotic topic, partly\nbecause it turned out that combining safety, liveness, and practical performance\nwas difficult to achieve. It was around 2000 that Barbara Liskov and Miguel\nCastro managed to come up with a practical implementation of a protocol\nfor replicating servers that could handle arbitrary failures. Let us briefly take\na look at their solution, which has been coined Practical Byzantine Fault\nTolerance, or simply PBFT [Castro and Liskov, 2002]. To better understand\nhow the protocol works, it may help to also consult Liskov [2010].\nLike Paxos, PBFT makes only a few assumptions about its environment. It\nmakes no assumptions about the behavior of replica servers: a faulty server\nis assumed to exhibit arbitrary behavior. Likewise, messages may be lost,\ndelayed, and received out of order. However, a message’s sender is assumed\nto be identifiable (which is achieved by having messages signed, as we discuss\nin Section 9.2.3). Under these assumptions, and as long as no more than k\nservers fail, it can be proven that PBFT is safe, meaning that a client will always\nreceive a correct answer. If we can additionally assume synchrony, meaning\nthat message delays and response times are bounded, it also provides liveness.\nIn practice, this means that PBFT assumes a partially synchronous model, in\nwhich unbounded delays are an exception, for example, caused by an attack.\nDS 4.01\n \n\n\n8.2. PROCESS RESILIENCE\n499\nTo understand the algorithm, let us take a step back and partly review\nwhat we have discussed so far on establishing a k-fault-tolerant process group.\nAn essential issue is that such a group behaves as a single, central server. As\na consequence, under the assumption of having only crash failures, when a\nclient sends a request, it should expect k + 1 identical answers. If a server had\ncrashed, fewer responses would be returned, but they would be the same.\nThe first problem that we need to solve is that concurrent requests are all\nhandled in the same order. To this end, PBFT adopts a primary-backup model\nwith a total of 3k + 1 replica servers. To keep matters simple, let us assume for\nnow that the primary is nonfaulty. In that case, a client C sends a request to\nexecute operation o to the primary (denoted as P in Figure 8.18). The primary\nhas a notion of the current collection of nonfaulty replica servers, expressed in\nterms of a view v, which is simply a number. The primary assigns a timestamp\nt to o, which is then incremented to be used for a subsequent request. The\nprimary subsequently sends a (signed) pre-prepare message pre-prepare(t, v,\no) to the backups (denoted as Bi in Figure 8.18). We assume that backup B2 is\nfaulty, indicated by the dashed line used for its messages.\nFigure 8.18: The different phases in PBFT. C is the client, P is the primary, and\nB1, B2, B3 are the backups. We assume that B2 is faulty.\nA (nonfaulty) backup will accept to pre-prepare if it is in v and has never\naccepted an operation with timestamp t in v before. Each backup that accepts\nto pre-prepare sends an (again signed) message prepare(t, v, o) to the others,\nincluding the primary. A key observation is that when a nonfaulty replica\nserver S has logged 2k messages prepare(t, v, o) (including its own) that all\nmatch the pre-prepare message S itself received by the primary (i.e., all have\nthe same value for t, v, and o, respectively), there is consensus among the\nnonfaulty servers on the order of which operation goes first. To see why,\nlet a prepare certificate PC(t, v, o) denote a certificate that is based on such\na set of 2k + 1 messages. Let PC(t, v, o′) be another prepare certificate with\n \nDS 4.01\n\n\n500\nCHAPTER 8. FAULT TOLERANCE\nthe same values for t and v respectively, but with a different operation o′.\nBecause each prepare certificate is based on 2k + 1 values from a total of 3k + 1\nreplica servers, the intersection of two certificates will necessarily be based on\nmessages from a subset of at least k + 1 servers. Of this subset, we know that\nthere is at least one nonfaulty server, which will have sent the same prepare\nmessage. Hence, o = o′.\nIn Figure 8.18, notice that, regardless what B2 sends (or does not send),\nthe two other nonfaulty backups, namely B1 and B2, will each have logged\nthree (2k + 1, with k = 1) messages for the tuple ⟨t, v, o⟩: the original message\nfrom P, their own message, and the same message from the other backup. At\nthat point, there is consensus to execute o, and not some other operation. We\ncan then move on to the next phase.\nThe next phase for a replica server starts when it has a prepare certificate: it\ncommits to the operation by broadcasting commit(t, v, o) to the other members\nin v. Each server S, in turn, collects 2k of such commit messages from other\nservers, leading to a commit certificate to execute operation o. At that point, it\nexecutes o and sends a response to the client. Again, with its own message and\nthe 2k other messages, S knows that there is consensus among the nonfaulty\nservers on which operation to actually execute now. In Figure 8.18, we see\nthat for the primary, as well as the backups B1 and B3, there are indeed again\nthree messages that state the same: we can execute o. Each server knows that\nthere are at least two other servers besides itself that will indeed execute o,\nand it is therefore good to go. What B2 had sent is not relevant: it will not\naffect the decision of the others.\nThe client collects all the results and takes as the answer the response that\nis returned by at least k + 1 replicas, of which it knows that there is at least\none nonfaulty replica server contributing to that answer. Again notice that\nin Figure 8.18, regardless what B2 tells the client about which operation B2\nhad executed, the client can safely assume that its requested operation was\nexecuted by a majority of the servers.\nSo far, so good. However, we also need to deal with the situation that\nthe primary fails. If a backup detects that the primary fails, it broadcasts\na view-change message for view v + 1. What we wish to establish is that a\nrequest that was still being processed at the time the primary failed, will\neventually get executed once and only once by all nonfaulty servers. To this end,\nwe first need to ensure that there are no two commit certificates with the same\ntimestamp that have different associated operations, regardless the view that\neach of them is associated with. This situation can be prevented by having\na quorum of 2k + 1 commit certificates just as before, but this time based on\nprepare certificates. In other words, we want to regenerate commit certificates,\nbut now for the new view, and only to make sure that a nonfaulty server is\nnot missing any operation. In this respect, note that we may be generating a\ncertificate for an operation that a server S had already executed (which can be\nDS 4.01\n \n\n\n8.2. PROCESS RESILIENCE\n501\nobserved by looking at timestamps), but that certificate will be ignored by S\nas long as it keeps an account of its execution history.\nA backup server will broadcast a (signed) message view-change(v + 1, P),\nwith P being the set of its prepare certificates. (Note that we ignore garbage\ncollecting issues.) PBFT includes a deterministic function primary(w) known\nto all backups that returns who the next primary will be given a view w.\nThis new primary will wait until it has a total of 2k + 1 view-change messages,\nleading to a view-change certificate X of prepare certificates. The new primary\nthen broadcasts new-view(v + 1, X, O), where O consists of new pre-prepare\nmessages constructed according to one of the following situations:\n• pre-prepare(t, v + 1, o) ∈O if the prepare certificate PC(t, v′, o) ∈X\nsuch that there is no prepare certificate PC(t, v′′, o′) with v′′ > v′,\n• pre-prepare(t, v + 1, none) ∈O if there is no prepare certificate\nPC(t, v′, o′) ∈X.\nWhat happens is that any outstanding, pre-prepared operation from a previous\nview is moved to the new view, but considering only the most recent view\nthat led to the installment of the current new view. In this sense, the new\nprimary effectively sends out appropriate new pre-prepare messages, based\non what the other backups had already committed to in their prepare phase.\nSimplifying matters a bit, each backup will check O and X to make sure\nthat all operations are indeed authentic and broadcast prepare messages for\nall pre-prepare messages in O. We are then back into the situation shown in\nFigure 8.18, but now with one of the backups operating as primary, all the\nother original backups operating as nonfaulty servers, and the old primary\noperating as a faulty backup.\nWe have skipped many elements of PBFT that deal with its correctness\nand above all its efficiency. For example, we did not touch upon garbage\ncollecting logs or efficient ways of authenticating messages. Such details\ncan be found in [Castro and Liskov, 2002].\nA description of a wrapper\nthat will allow the incorporation of Byzantine fault tolerance with legacy\napplications is described in [Castro et al., 2003]. Notably the performance\nof Byzantine fault tolerance has been subject to much research, leading to\nmany new protocols (see, for example, Zyzzyva [Kotla et al., 2009] and\nAbstract [Guerraoui et al., 2010]), yet even these new proposals often rely on\nthe original PBFT implementation. That there is still room for improvement\nwhen actually using PBFT for developing robust applications is discussed by\nChondros et al. [2012]. For example, PBFT assumes static membership (i.e.,\nclients and servers are known to each other in advance), but also assumes that\na replica server’s memory acts as a stable, persistent storage.\nThese and other shortcomings along with the inherent complexity of\nByzantine fault tolerance have formed a hurdle for widespread use of PBFT.\nInterestingly, attention for PBFT returned in the advent of permissioned\n \nDS 4.01\n\n\n502\nCHAPTER 8. FAULT TOLERANCE\nblockhains, being one of the few alternatives that could offer a consenus\nprotocol in a public network. New research was initiated to address short-\ncomings, notably the relatively small number of participants that PBFT can\nmaximally handle. An important development has been HotStuff [Yin et al.,\n2019], which effectively provides a much more efficient view change than in\nPBFT, significantly contributing to the scalability of the protocol.\n8.2.6\nConsensus in blockchain systems\nComing to this point, let us return to the much debated blockchain systems.\nIn particular, let us zoom in a bit into what consensus entails in these systems.\nFollowing the approach presented by Xiao et al. [2020], we can distinguish\nfour requirements for blockchain consensus:\n1. Agreement: All nonfaulty nodes agree on the acceptance of a block of\ntransactions and its position in the blockchain, or agree that it should be\ndiscarded.\n2. Integrity: Each nonfaulty node sees the same blocks of accepted trans-\nactions, and the same positions of these blocks in the blockchain.\n3. Termination: Every nonfaulty node either discards or accepts a transac-\ntion, as contained within a block, to be part of the blockchain.\n4. Validity: If every node receives the same validated block, it should be\naccepted for the blockchain.\nThe first two requirements are at the core of safety: the blockchain does what\nit is supposed to do (i.e., nothing bad happens). The last two can be argued\nto deal with liveness: eventually everything turns out to be good. For our\npresent discussion, reaching agreement is crucial.\nFor permissionless blockchains, we see that leader election is important:\nonce a leader has been elected, we can essentially ensure agreement by letting\nthe leader decide on the block that is to be appended to the blockchain.\nAs we discuss in Section 9.4.3, guaranteeing the integrity of a blockchain\ncan be established using well-known cryptographic techniques. The only\nproblem with leader elections happens if two or more leaders are elected,\nwhich may happen when the declaration of a winner does not reach its\ncompetitor in time. In such a case, two processes will start to append blocks\nto a chain, effectively leading to two branches. A common solution is that\nonce a participant discovers it is reading from the smallest branch, it ignores\nthat branch completely and makes sure that it gets the blocks from the longer\nbranch.\nFor permissioned blockchains, a common solution is to adopt PBFT. In\nother words, the decision to append blocks to an existing chain is handled\nby a relatively small fault-tolerant group of processes (who need not trust\nDS 4.01\n \n\n\n8.2. PROCESS RESILIENCE\n503\neach other). Because PBFT is a relatively costly and nonscalable solution,\nalternatives have been designed, with HotStuff [Yin et al., 2019] playing a\nprominent role as experiments showed that the number of replica servers\ncould go up beyond 100.\nXiao et al. [2020] provides an excellent overview of the various consensus\nprotocols for blockchains, along with a discussion on the many trade-offs to\nbe made.\n8.2.7\nSome limitations on realizing fault tolerance\nOrganizing replicated processes into a group helps to increase fault tolerance.\nHowever, what should have become clear by now is that there is a price to\npay, namely a potential loss of performance. In the solutions discussed so far,\nprocesses in a fault-tolerant group may need to exchange numerous messages\nbefore reaching a decision. The Byzantine agreement protocol is an excellent\nillustration of how tightly coupled processes may be. The question that comes\nto mind is whether realizing specific forms of fault tolerance, like being able\nto withstand arbitrary failures, is always possible.\nOn reaching consensus\nAs we mentioned, if a client can base its decisions through a voting mechanism,\nwe can tolerate that k out of 2k + 1 processes are lying about their result. The\nassumption we are making, however, is that processes do not team up to\nproduce a wrong result. In general, matters become more intricate if we\ndemand that a process group reaches consensus, which is needed in many\ncases. There are three requirements for reaching consensus [Fischer et al.,\n1985]:\n• Processes produce the same output value\n• Every output value must be valid\n• Every process must eventually provide output\nSome examples where reaching consensus is necessary include electing a\ncoordinator, deciding whether to commit a transaction, and dividing up tasks\namong workers. When the communication and processes are all perfect,\nreaching consensus is often straightforward, but when they are not, problems\narise.\nThe general goal of distributed consensus algorithms is to have all the\nnonfaulty processes reach consensus on some issue, and to establish that\nconsensus within a finite number of steps. The problem is complicated by the\nfact that different assumptions about the underlying system require different\nsolutions, assuming solutions even exist. Turek and Shasha [1992] distinguish\nthe following cases:\n \nDS 4.01\n\n\n504\nCHAPTER 8. FAULT TOLERANCE\n1. Synchronous versus asynchronous systems. Rephrasing our description\nsomewhat, a system is synchronous if and only if the processes are\nknown to operate in a lock-step mode. Formally, this means that there\nshould be some constant c ≥1, such that if any process has taken c + 1\nsteps, every other process has taken at least 1 step.\n2. Communication delay is bounded or not. Delay is bounded if and\nonly if we know that every message is delivered with a globally and\npredetermined maximum time.\n3. Message delivery is ordered (in real time) or not. In other words, we\ndistinguish the situation where messages from the different senders are\ndelivered in the order that they were sent in real global time, from the\nsituation in which we do not have such guarantees.\n4. Message transmission is done through unicasting or multicasting.\nAs it turns out, reaching consensus is possible only for the situations\nshown in Figure 8.19. In all other cases, it can be shown that no solution exists.\nNote that most distributed systems in practice assume that processes behave\nasynchronously, message transmission is unicast, and communication delays\nare unbounded. As a consequence, we need to make use of ordered (reliable)\nmessage delivery, such as provided by TCP. And again, in practical situations\nwe assume synchronous behavior to be the default, but take into account that\nthere may be unbounded delays as well. Figure 8.19 illustrates the nontrivial\nnature of distributed consensus when processes may fail.\nProcess behavior\nCommun. delay\nBounded\nUnbounded\nBounded\nUnBounded\nUnicast\nMulticast\nUnicast\nMulticast\nMessage ordering\nSynchronous\n✓\n✓\n✓\n✓\n✓\n✓\nAsynchronous\n✓\n✓\nMessage transmission\n\u001a\n\u001a\nUnordered\nz\n}|\n{\nOrdered\nz\n}|\n{\nFigure 8.19: Circumstances under which distributed consensus can be reached.\nReaching consensus may not be possible. Fischer et al. [1985] proved that\nif messages cannot be guaranteed to be delivered within a known, finite time,\nno consensus is possible if even one process is faulty (albeit if that one process\nfails silently). The problem with such systems is that arbitrarily slow processes\nare indistinguishable from crashed ones (i.e., you cannot tell the dead from\nthe living). These and other theoretical results are surveyed by Barborak et al.\n[1993] and Turek and Shasha [1992].\nDS 4.01\n \n\n\n8.2. PROCESS RESILIENCE\n505\nIt should also be noted that the schemes described so far assume that nodes\nare either Byzantine, or collaborative. The latter cannot always be simply\nassumed when processes are from different administrative domains. In that\ncase, they will more likely exhibit rational behavior, for example, by reporting\ntimeouts when doing so is cheaper than executing an update operation. How\nto deal with these cases is not trivial. A first step toward a solution is captured\nin the form of BAR fault tolerance, which stands for Byzantine, Altruism,\nand Rationality. BAR fault tolerance is described in Aiyer et al. [2005] and\nClement et al. [2008].\nConsistency, availability, and partitioning\nStrongly related to the conditions under which consensus can (not) be reached,\nis when consistency can be reached. Consistency in this case means that when\nwe have a process group to which a client is sending requests, that the\nresponses returned to that client are correct. We are dealing with a safety\nproperty: a property that asserts that nothing bad will happen. For our\npurposes, the types of operations we consider are those that seem to be\nexecuted in a clearly defined order by a single, centralized server. By now, we\nknow better: these operations are executed by a process group to withstand\nthe failures of k group members.\nWe introduced process groups to improve fault tolerance, and, more\nspecifically, to improve availability. Availability is typically a liveness property:\neventually, something good will happen. In terms of our process groups, we\naim to eventually get a (correct) response to every request issued by a client.\nBeing consistent in responses while also being highly available is not an\nunreasonable requirement for services that are part of a distributed system.\nUnfortunately, we may be asking too much.\nIn practical situations, our underlying assumption that the processes in a\ngroup can indeed communicate with each other may be false. Messages may\nbe lost; a group may be partitioned due to a faulty network. In 2000, Eric\nBrewer posed an important theorem which was later proven to be correct by\nGilbert and Lynch [2002]:\nCAP Theorem: Any networked system providing shared data can provide\nonly two of the following three properties:\n• C: consistency, by which a shared and replicated data item appears\nas a single, up-to-date copy\n• A: availability, by which updates will always be eventually executed\n• P: Tolerant to the partitioning of process group (e.g., because of a\nfailing network).\nIn other words, in a network subject to communication failures, it is impossible\nto realize an atomic read/write shared memory that guarantees a response to\nevery request [Gilbert and Lynch, 2012].\n \nDS 4.01\n\n\n506\nCHAPTER 8. FAULT TOLERANCE\nThis has now become known as the CAP theorem, first published as [Fox\nand Brewer, 1999]. As explained by Brewer [2012], one way of understanding\nthe theorem is to think of two processes unable to communicate because of a\nfailing network. Allowing one process to accept updates leads to inconsistency,\nso that we can only have properties {A, P}. If the illusion of consistency is\nto be provided while the two processes cannot communicate, then one of the\ntwo processes will have to pretend to be unavailable, implying having only\n{C, P}. However, only if the two processes can communicate, is it possible to\nmaintain both consistency and high availability, meaning that we have only\n{C, A}, but no longer property P.\nNote also the relationship with reaching consensus; in fact, where con-\nsensus requires proving that processes produce the same output, providing\nconsistency is weaker. This also means that if achieving CAP is impossible,\nthen so is consensus.\nFor some time, many people thought that the CAP theorem actually told\nus we were dealing with a practical horrendous situation. However, the CAP\ntheorem is all about reaching a trade-off between safety and liveness, based on\nthe observation that obtaining both in an inherently unreliable system cannot\nbe achieved. Practical distributed systems are inherently unreliable. What\nBrewer and his colleagues observed is that in practical distributed systems,\none simply has to make a choice to proceed, although another process cannot\nbe reached. In other words, we need to do something when a partition\nmanifests itself through high latency. What this means, is that we need to\nlook at the distributed application at hand to see how we can salvage the\nseemingly impossibility implications of the CAP theorem.\nThe bottom line when it seems that partitioning is taking place, is to\nproceed (tolerating partitions in favor of either consistency or availability),\nwhile simultaneously starting a recovery procedure that can mitigate the\neffects of potential inconsistencies. Exactly deciding on how to proceed is\napplication-dependent: in many cases having duplicate keys in a database\ncan easily be fixed (implying that we should tolerate an inconsistency), while\nduplicate transfers of large sums of money may not (meaning that we should\ndecide to tolerate lower availability). One can argue that the CAP theorem\nessentially moves designers of distributed systems from theoretical solutions\nto engineering solutions. The interested reader is referred to [Brewer, 2012] to\nsee how such a move can be made.\n8.2.8\nFailure detection\nIt may have become clear from our discussions so far that to properly mask\nfailures, we generally need to detect them as well. Failure detection is one\nof the cornerstones of fault tolerance in distributed systems. What it all boils\ndown to is that for a group of processes, nonfaulty members should be able\nDS 4.01\n \n\n\n8.2. PROCESS RESILIENCE\n507\nto decide who is still a member, and who is not. In other words, we need to\nbe able to detect when a member has failed.\nWhen it comes to detecting process failures, there are essentially only two\nmechanisms. Either processes actively send “are you alive?” messages to each\nother (for which they obviously expect an answer), or passively wait until\nmessages come in from different processes. The latter approach makes sense\nonly when it can be guaranteed that there is enough communication.\nThere is a huge body of theoretical work on failure detectors. What it,\nin the end, all boils down to is that a timeout mechanism is used to check\nwhether a process has failed. If a process P probes another process Q to see if\nit has failed, P is said to suspect Q to have crashed if Q has not responded\nwithin some time.\nNote 8.7 (More information: On perfect failure detectors)\nIt should be clear that in a synchronous distributed system, a suspected crash\ncorresponds to a known crash. In practice, however, we will be dealing with\npartially synchronous systems. In that case, it makes more sense to assume\neventually perfect failure detectors. In this case, a process P will suspect another\nprocess Q to have crashed after t time units have elapsed and still Q did not\nrespond to P’s probe. However, if Q later does send a message that is (also)\nreceived by P, P will (1) stop suspecting Q, and (2) increase the timeout value t.\nNote that if Q does crash (and does not recover), P will continue to suspect Q.\nIn real settings, there are problems with using probes and timeouts. For\nexample, due to unreliable networks, simply stating that a process has failed\nbecause it does not return an answer to a probe message may be wrong. In\nother words, it is easy to generate false positives. If a false positive has the\neffect that a perfectly healthy process is removed from a membership list,\nthen clearly we are doing something wrong. Another serious problem is that\ntimeouts are just plain crude. As noticed by Birman [2012], there is hardly\nany work on building proper failure detection subsystems that take more into\naccount than only the lack of a reply to a single message. This statement is\neven more evident when looking at industry-deployed distributed systems.\nThere are various issues that need to be considered when designing a\nfailure-detection subsystem (see also Zhuang et al. [2005]). For example, fail-\nure detection can take place through gossiping in which each node regularly\nannounces to its neighbors that it is still up and running. As we mentioned,\nan alternative is to let nodes actively probe each other.\nFailure detection can also be done as a side effect of regularly exchanging\ninformation with neighbors, as is the case with gossip-based information dis-\nsemination (which we discussed in Chapter 4). This approach was essentially\nalso adopted in Obduro [Vogels, 2003]: processes periodically gossip their\nservice availability. This information is gradually disseminated through the\n \nDS 4.01\n",
      "page_number": 507
    },
    {
      "number": 51,
      "title": "Segment 51 (pages 518-528)",
      "start_page": 518,
      "end_page": 528,
      "detection_method": "topic_boundary",
      "content": "508\nCHAPTER 8. FAULT TOLERANCE\nnetwork. Eventually, every process will know about every other process, but\nmore importantly, will have enough information locally available to decide\nwhether a process has failed or not. A member for which the availability\ninformation is old, will presumably have failed.\nAnother important issue is that a failure detection subsystem should\nideally be able to distinguish network failures from node failures. One way of\ndealing with this problem is not to let a single node decide whether one of its\nneighbors has crashed. Instead, when noticing a timeout on a probe message,\na node requests other neighbors to see whether they can reach the presumed\nfailing node. Of course, positive information can also be shared: if a node is\nstill alive, that information can be forwarded to other interested parties (who\nmay be detecting a link failure to the suspected node).\nThis brings us to another key issue: when a member failure is detected,\nhow should other nonfaulty processes be informed? One simple, and some-\nwhat radical approach is the following. In FUSE [Dunagan et al., 2004],\nprocesses can be joined in a group that spans a wide-area network. The group\nmembers create a spanning tree that is used for monitoring member failures.\nMembers send ping messages to their neighbors. When a neighbor does not\nrespond, the pinging node immediately switches to a state in which it will\nalso no longer respond to pings from other nodes. By recursion, it is seen that\na single node failure is rapidly promoted to a group failure notification.\n8.3\nReliable client-server communication\nOften, fault tolerance in distributed systems concentrates on faulty processes.\nHowever, we also need to consider communication failures. Most of the\nfailure models discussed previously apply equally well to communication\nchannels. In particular, a communication channel may exhibit crash, omission,\ntiming, and arbitrary failures. In practice, when building reliable communica-\ntion channels, the focus is on masking crash and omission failures. Arbitrary\nfailures may occur in the form of duplicate messages, resulting from the fact\nthat in a computer network messages may be buffered for a relatively long\ntime, and are reinjected into the network after the original sender has already\nissued a retransmission (see, for example, Tanenbaum et al. [2021]).\n8.3.1\nPoint-to-point communication\nIn many distributed systems, reliable point-to-point communication is es-\ntablished by making use of a reliable transport protocol, such as TCP. TCP\nmasks omission failures, which occur in the form of lost messages, by using\nacknowledgments and retransmissions. Such failures are completely hidden\nfrom a TCP client.\nHowever, crash failures of connections are not masked. A crash failure\nmay occur when (for whatever reason) a TCP connection is abruptly broken so\nDS 4.01\n \n\n\n8.3. RELIABLE CLIENT-SERVER COMMUNICATION\n509\nthat no more messages can be transmitted through the channel. In most cases,\nthe client is informed that the channel has crashed by raising an exception.\nThe only way to mask such failures is to let the distributed system attempt\nto automatically set up a new connection, by simply resending a connection\nrequest. The underlying assumption is that the other side is still, or again,\nresponsive to such requests.\n8.3.2\nRPC semantics in the presence of failures\nLet us now take a closer look at client-server communication when using\nhigh-level communication facilities such as remote procedure calls (RPCs).\nThe goal of RPC is to hide communication by making remote procedure calls\nlook just like local ones. With a few exceptions, so far we have come fairly\nclose. Indeed, as long as both client and server are functioning perfectly, RPC\ndoes its job well. The problem comes about when errors occur. It is then that\nthe differences between local and remote calls are not always easy to mask.\nTo structure our discussion, let us distinguish between five different classes\nof failures that can occur in RPC systems, as follows:\n1. The client is unable to locate the server.\n2. The request message from the client to the server is lost.\n3. The server crashes after receiving a request.\n4. The reply message from the server to the client is lost.\n5. The client crashes after sending a request.\nEach of these categories poses different problems and requires different solu-\ntions.\nClient cannot locate the server\nTo start with, it can happen that the client cannot locate a suitable server. All\nservers might be down, for example. Alternatively, suppose that the client is\ncompiled using a particular version of the client stub, and the binary is not\nused for a considerable period of time. Meanwhile, the server evolves and a\nnew version of the interface is installed; new stubs are generated and put into\nuse. When the client is eventually run, the binder will be unable to match\nit up with a server and will report failure. While this mechanism is used to\nprotect the client from accidentally trying to talk to a server that may not\nagree with it in terms of what parameters are required or what it is supposed\nto do, the problem remains of how should this failure be dealt with.\nOne possible solution is to have the error raise an exception. In some\nlanguages, (e.g., Java), programmers can write special procedures that are\ninvoked upon specific errors, such as division by zero. In C, signal handlers\n \nDS 4.01\n\n\n510\nCHAPTER 8. FAULT TOLERANCE\ncan be used for this purpose. In other words, we could define a new signal\ntype SIGNOSERVER, and allow it to be handled in the same way as other\nsignals.\nThis approach, too, has drawbacks. To start with, not every language has\nexceptions or signals. Another point is that having to write an exception\nor signal handler destroys the transparency we have been trying to achieve.\nSuppose that you are a programmer, and you are requested to write the append\nprocedure. You smile and tell her it will be written, tested, and documented\nin five minutes. Then she mentions that you also have to write an exception\nhandler as well, just in case the procedure is not there today. At this point, it\nis pretty hard to maintain the illusion that remote procedures are no different\nfrom local ones, since writing an exception handler for “Cannot locate server”\nwould be a rather unusual request in a nondistributed system.\nLost request messages\nThe second item on the list is dealing with lost request messages. This is\nthe easiest one to deal with: just have the operating system or client stub\nstart a timer when sending the request. If the timer expires before a reply or\nan acknowledgment comes back, the message is sent again. If the message\nwas truly lost, the server will not be able to tell the difference between the\nretransmission and the original, and everything will work fine. Unless, of\ncourse, so many request messages are lost that the client gives up and falsely\nconcludes that the server is down, in which case we are back to “Cannot\nlocate server.” If the request was not lost, the only thing we need to do is let\nthe server be able to detect it is dealing with a retransmission. Unfortunately,\ndoing so is not so simple, as we explain when discussing lost replies.\nServer crashes\nThe next failure on the list is a server crash. The normal sequence of events\nat a server is shown in Figure 8.20(a). A request arrives, is carried out, and a\nreply is sent. Now consider Figure 8.20(b). A request arrives and is carried\nout, just as before, but the server crashes before it can send the reply. Finally,\nlook at Figure 8.20(c). Again a request arrives, but this time the server crashes\nbefore it can even be carried out. And, of course, no reply is sent back.\nThe annoying part of Figure 8.20 is that the correct treatment differs for (b)\nand (c). In (b) the system has to report failure back to the client (e.g., raise an\nexception), whereas in (c) it can just retransmit the request. The problem is\nthat the client’s operating system cannot tell which is which. All it knows is\nthat its timer has expired.\nThree schools of thought exist on what to do here [Spector, 1982]. One\nphilosophy is to wait until the server reboots (or let the client’s middleware\ntransparently rebind to a new server) and try the operation again. The idea is\nDS 4.01\n \n\n\n8.3. RELIABLE CLIENT-SERVER COMMUNICATION\n511\n(a)\n(b)\n(c)\nFigure 8.20: A server in client-server communication. (a) The normal case.\n(b) Crash after execution. (c) Crash before execution.\nto keep trying until a reply has been received, then give it to the client. This\ntechnique is called at-least-once semantics and guarantees that the RPC has\nbeen carried out at least one time, but possibly more.\nThe second philosophy gives up immediately and reports back failure.\nThis approach is called at-most-once semantics and guarantees that the RPC\nhas been carried out at most one time, but possibly not at all.\nThe third philosophy is to guarantee nothing. When a server crashes, the\nclient gets no help and no promises about what happened. The RPC may\nhave been carried out anywhere from zero to many times. The main virtue of\nthis scheme is that it is easy to implement.\nNone of these are terribly attractive. What one would like is exactly-once\nsemantics, but in general, there is no way to arrange this. Imagine that\nthe remote operation consists of processing a document, such as producing\na number of PDF files from LATEX and other sources. The server sends a\ncompletion message to the client when the document has been completely\nprocessed. Also assume that when a client issues a request, it receives an\nacknowledgment that the request has been delivered to the server. There are\ntwo strategies the server can follow. It can either send a completion message\njust before it actually tells the document processor to do its work, or after the\ndocument has been processed.\nAssume that the server crashes and subsequently recovers. It announces\nto all clients that it has just crashed but is now up and running again. The\nproblem is that the client does not know whether its request to process a\ndocument will actually have been carried out.\nThere are four strategies the client can follow. First, the client can decide\nto never reissue a request, at the risk that the document will not be processed.\nSecond, it can decide to always reissue a request, but this may lead to the\ndocument being processed twice (which may easily incur a significant amount\nof work when dealing with intricate documents). Third, it can decide to\nreissue a request only if it did not yet receive an acknowledgment that its\nrequest had been delivered to the server. In that case, the client is counting\non the fact that the server crashed before the request could be delivered.\nThe fourth and last strategy is to reissue a request only if it has received an\n \nDS 4.01\n\n\n512\nCHAPTER 8. FAULT TOLERANCE\nacknowledgment for the request. With two strategies for the server, and four\nfor the client, there are a total of eight combinations to consider. Unfortunately,\nas it turns out, no combination is satisfactory: it can be shown that for any\ncombination either the request is lost forever, or carried out twice.\nNote 8.8 (Advanced: Why fully transparent server recovery is impossible)\nTo explain about server recovery, note that there are three events that can happen\nat the server: send the completion message (M), complete the processing of\nthe document (P), and crash (C). Note that crashing during the processing of a\ndocument is considered the same as crashing before its completion. These events\ncan occur in six different orderings:\n1. M →P →C: A crash occurs after sending the completion message and\nprocessing the document.\n2. M →C(→P): A crash happens after sending the completion message, but\nbefore the document could be (completely) processed.\n3. P →M →C: A crash occurs after sending the completion message and\nprocessing the document.\n4. P →C(→M): The document was processed, after which a crash occurs\nbefore the completion message could be sent.\n5. C(→P →M): A crash happens before the server could complete the\nprocessing of the document.\n6. C(→M →P): A crash happens before the server could even do anything.\nThe parentheses indicate an event that can no longer happen because the server\nalready crashed. Figure 8.21 shows all possible combinations. As can be readily\nverified, there is no combination of client strategy and server strategy that will\nwork correctly under all possible event sequences. The bottom line is that the\nclient can never know whether the server crashed just before or after having the\ntext printed.\nReissue strategy\nAlways\nNever\nOnly when ACKed\nOnly when not ACKed\nClient\nStrategy M →P\nMPC\nMC(P)\nC(MP)\nDUP\nOK\nOK\nOK\nZERO\nZERO\nDUP\nOK\nZERO\nOK\nZERO\nOK\nServer\nStrategy P →M\nPMC\nPC(M)\nC(PM)\nDUP\nDUP\nOK\nOK\nOK\nZERO\nDUP\nOK\nZERO\nOK\nDUP\nOK\nServer\nOK\n=\nDocument processed once\nDUP\n=\nDocument processed twice\nZERO\n=\nDocument not processed at all\nFigure 8.21: Different combinations of client and server strategies in the\npresence of server crashes. Events between brackets never take place\nbecause of a previous crash.\nIn short, the possibility of server crashes radically changes the nature of RPC\nand clearly distinguishes single-processor systems from distributed ones. In the\nDS 4.01\n \n\n\n8.3. RELIABLE CLIENT-SERVER COMMUNICATION\n513\nformer case, a server crash also implies a client crash, so recovery is neither\npossible nor necessary. In the latter we can and should take action.\nLost reply messages\nLost replies can also be difficult to deal with. The obvious solution is just to\nrely on a timer again that has been set by the client’s operating system. If no\nreply is forthcoming within a reasonable period, just send the request once\nmore. The trouble with this solution is that the client is not really sure why\nthere was no answer. Did the request or reply get lost, or is the server merely\nslow? It may make a difference.\nIn particular, some operations can safely be repeated as often as necessary\nwith no damage being done. A request such as asking for the first 1024\nbytes of a file has no side effects and can be executed as often as necessary\nwithout any harm being done. A request that has this property is said to be\nidempotent.\nNow consider a request to a banking server asking to transfer money from\none account to another. If the request arrives and is carried out, but the reply\nis lost, the client will not know this and will retransmit the message. The\nbank server will interpret this request as a new one, and will carry it out too.\nTwice the amount of money will be transferred. Transferring money is not\nidempotent.\nOne way of solving this problem is to try to structure all the requests in\nan idempotent way. In practice, however, many requests (e.g., transferring\nmoney) are inherently nonidempotent, so something else is needed. Another\nmethod is to have the client assign each request a sequence number. By\nhaving the server keep track of the most recently received sequence number\nfrom each client that is using it, the server can tell the difference between\nan original request and a retransmission and can refuse to carry out any\nrequest a second time. However, the server will still have to send a response\nto the client. Note that this approach does require that the server maintains\nadministration on each client. Furthermore, it is not clear how long to maintain\nthis administration. An additional safeguard is to have a bit in the message\nheader that is used to distinguish initial requests from retransmissions (the\nidea being that it is always safe to perform an original request; retransmissions\nmay require more care).\nClient crashes\nThe final item on the list of failures is the client crash. What happens if a\nclient sends a request to a server to do some work and crashes before the\nserver replies? At this point a computation is active and no parent is waiting\nfor the result. Such a computation is called an orphan (computation).\n \nDS 4.01\n\n\n514\nCHAPTER 8. FAULT TOLERANCE\nOrphan computations can cause a variety of problems that can interfere\nwith normal operation of the system. As a bare minimum, they waste pro-\ncessing power. They can also lock files or otherwise tie up valuable resources.\nFinally, if the client reboots and does the RPC again, but the reply from the\norphan comes back immediately afterward, confusion can result. Note that,\nin this case, we are essentially dealing with the problem of guaranteeing\nat-most-once semantics and bringing the client back into a state just before it\ncrashed. As we will explain later, checkpointing just before sending a request,\nand restoring the client to the checkpointed state will solve many problems\nwith orphan computations. In essence, it boils down to let the orphan do its\nwork, and properly restoring the client.\nYet, what can be done about orphans? Four solutions have been pro-\nposed [Nelson, 1981]. First, before a client stub sends an RPC message, it\nmakes a log entry telling what it is about to do. The log is kept on disk or some\nother medium that survives crashes. After a reboot, the log is checked and the\norphan is explicitly killed off. This solution is called orphan extermination,\nan admittedly not very empathically sounding name.\nThe disadvantage of this scheme is the expense of writing a disk record\nfor every RPC. Furthermore, it may not even work, since orphans themselves\nmay do RPCs, thus creating grandorphans or further descendants that are\ndifficult or impossible to locate. Finally, the network may be partitioned, for\nexample because of a failed gateway, making it impossible to kill them, even\nif they can be located. All in all, this is not a promising approach, and, in\ngeneral, will need to be avoided due to its complexity.\nWith the second solution, called reincarnation, all these problems can\nbe solved without the need to write disk records. The way it works is to\ndivide time up into sequentially numbered epochs. When a client recovers,\nit broadcasts a message to all machines declaring the start of a new epoch.\nWhen such a broadcast comes in, all remote computations are killed. Of\ncourse, if the network is partitioned, some orphans may survive. Fortunately,\nhowever, when they report back, their replies will contain an obsolete epoch\nnumber, making them easy to detect.\nThe third solution is a variant on this idea, but somewhat less Draconian.\nIt is called gentle reincarnation. When an epoch broadcast comes in, each\nmachine checks to see if it has any remote computations running locally, and\nif so, tries its best to locate their owners. Only if the owners cannot be located\nanywhere is the computation killed.\nIn the fourth solution, called expiration, each RPC is given a standard\namount of time, T, to do the job. If it cannot finish, it must explicitly ask for\nanother quantum. Of course, this is quite a nuisance. On the other hand, if\nafter a crash the client waits a time T before rebooting, all orphans are sure to\nbe gone. The problem to be solved here is choosing a reasonable value of T in\nthe face of RPCs with wildly differing requirements.\nDS 4.01\n \n\n\n8.4. RELIABLE GROUP COMMUNICATION\n515\nIn practice, all of these methods are crude and undesirable. Worse yet,\nkilling an orphan may have unforeseen consequences. For example, suppose\nthat an orphan has obtained locks on one or more files or database records.\nIf the orphan is suddenly killed, these locks may remain forever. Also, an\norphan may have already made entries in various remote queues to start\nup other processes at some future time, so even killing the orphan may not\nremove all traces of it. Conceivably, it may even have started again, with\nunforeseen consequences. Orphan elimination is discussed in more detail\nby Panzieri and Shrivastava [1988].\nAs mentioned, the best solution is often not to do anything special, but\nattempt to restore the client to a state in which it can handle any response\nfrom its previously orphaned computation. This brings us to checkpointing\nand message logging, which we discuss in Section 8.6.\n8.4\nReliable group communication\nConsidering how important process resilience by replication is, it is not\nsurprising that reliable multicast services are important as well. Such services\nguarantee that messages are delivered to all members in a process group.\nUnfortunately, reliable multicasting turns out to be surprisingly tricky. In\nthis section, we take a closer look at the issues involved in reliably delivering\nmessages to a process group.\n8.4.1\nIntroduction\nLet us first define what reliable group communication actually is. Intuitively,\nit means that a message that is sent to a process group should be delivered\nto each member of that group. If we separate the logic of handling messages\nfrom the core functionality of a group member, we can conveniently make the\ndistinction between receiving messages and delivering messages, as illustrated\nin Figure 8.22. A message is received by a message-handling component,\nwhich, in turn, delivers a message to the component containing the core\nfunctionality of a group member. Informally, a message that is received by\nprocess P will also be delivered by P.\nAs an example, ensuring that messages from the same sender are delivered\nin the same order as they were sent, is typically taken care of by a message-\nhandling component.\nLikewise, providing reliable message-passing is a\nfeature that can and should be separated from the core functionality of a group\nmember, and is typically implemented by a message-handling component (if\nnot by the underlying operating system).\nWith this separation between receiving and delivering messages, we can\nbe more precise about what reliable group communication means. Let us\nmake a distinction between reliable communication in the presence of faulty\nprocesses, and reliable communication when processes are assumed to operate\n \nDS 4.01\n\n\n516\nCHAPTER 8. FAULT TOLERANCE\nFigure 8.22: The distinction between receiving and delivering messages.\ncorrectly. In the first case, group communication is considered to be reliable\nwhen it can be guaranteed that a message is received by and subsequently\ndelivered to all nonfaulty group members.\nThe tricky part here is that agreement should be reached on what the\ngroup actually looks like before a message can be delivered. If a sender\nintended to have a message delivered by each member of a group G, but that,\nfor whatever reason, at the time of delivery we actually have another group\nG′ ̸= G, we should ask ourselves whether the message can be delivered.\nThe situation becomes simpler if we can ignore consensus on group mem-\nbership. In particular, let us first assume that a sending process has a list of\nintended recipients. In that case, it can simply deploy reliable transport-level\nprotocols such as TCP and, one by one, sends its message to each recipient. If\na receiving process fails, the message may be resent later when the process\nrecovers, or ignored altogether (for example, because the sender had left the\ngroup). In case a group member is expected to send a response, even if it\nis just an acknowledgement, communication can be speeded up by separat-\ning the sending of a request from receiving a response, as illustrated by the\nmessage sequence charts in Figure 8.23.\nMost transport layers offer reliable point-to-point channels; they rarely\noffer reliable communication to a group of processes. The best they offer is to\nlet a process set up a point-to-point connection to each other process it wants\nto communicate with. When process groups are relatively small, this approach\nto establishing reliability is a straightforward and practical solution. On the\nother hand, we can often assume that the underlying communication system\ndoes offer unreliable multicasting, meaning that a multicast message may be\nlost part way and delivered by some, but not all, of the intended receivers.\nDS 4.01\n \n\n\n8.4. RELIABLE GROUP COMMUNICATION\n517\n(a)\n(b)\nFigure 8.23: (a) A sender sends out requests, but waits for a response before\nsending out the next one. (b) Requests are sent out in parallel, after which the\nsender waits for incoming responses.\nA simple solution to reach reliable group communication is shown in\nFigure 8.24. The sending process assigns a sequence number to each message\nit multicasts and stores the message locally in a history buffer. Assuming\nthe receivers are known to the sender, the sender simply keeps the message\nin its history buffer until each receiver has returned an acknowledgement.\nA receiver can suspect it is missing a message m with sequence number s\nwhen it has received messages with sequence numbers higher than s. In that\ncase, it returns a negative acknowledgement to the sender, requesting for a\nretransmission of m.\nThere are various design trade-offs to be made. For example, to reduce\nthe number of messages returned to the sender, acknowledgements could\npossibly be piggybacked with other messages. Also, retransmitting a message\ncan be done using point-to-point communication to each requesting process,\nor using a single multicast message sent to all processes. General issues on\nreliable multicasting are discussed by Popescu et al. [2007]. A survey and\noverview of reliable multicasting in the context of publish/subscribe systems,\nwhich is also relevant here, is provided by Esposito et al. [2013].\n \nDS 4.01\n\n\n518\nCHAPTER 8. FAULT TOLERANCE\n(a)\n(b)\nFigure 8.24: A solution for reliable multicasting. (a) Message transmission.\n(b) Reporting feedback.\n8.4.2\nScalability in reliable multicasting\nThe main problem with the reliable multicast scheme just described is that\nit cannot support large numbers of receivers. If there are N receivers, the\nsender must be prepared to accept at least N acknowledgements. With many\nreceivers, the sender may be swamped with such feedback messages, which is\nalso referred to as a feedback implosion. When replicating processes for fault\ntolerance, this situation is not likely to occur as process groups are relatively\nsmall. When replicating for performance, we have a different case. Moreover,\nwe may then also need to take into account that the receivers are spread across\na wide-area network.\nOne solution to the problem of a feedback implosion is not to have re-\nceivers acknowledge the receipt of a message. Instead, a receiver returns a\nfeedback message only to inform the sender it is missing a message. Return-\ning only such negative acknowledgements can be shown to generally scale\nbetter [Towsley et al., 1997], but no hard guarantees can be given that feedback\nimplosions will never happen.\nAnother problem with returning only negative acknowledgements is that\nthe sender will, in theory, be forced to keep a message in its history buffer\nforever. Because the sender can never know if a message has been correctly\ndelivered to all receivers, it should always be prepared for a receiver requesting\nDS 4.01\n \n",
      "page_number": 518
    },
    {
      "number": 52,
      "title": "Segment 52 (pages 529-537)",
      "start_page": 529,
      "end_page": 537,
      "detection_method": "topic_boundary",
      "content": "8.4. RELIABLE GROUP COMMUNICATION\n519\nthe retransmission of an old message. In practice, the sender will remove a\nmessage from its history buffer after some time has elapsed to prevent the\nbuffer from overflowing. However, removing a message is done at the risk of\na request for a retransmission not being honored.\nSeveral proposals for scalable, reliable multicasting exist. A comparison\nbetween different schemes can be found in [Levine and Garcia-Luna-Aceves,\n1998]. We now briefly discuss two very different approaches that are represen-\ntative of many existing solutions.\nThe key issue to scalable solutions for reliable multicasting is to reduce\nthe number of feedback messages that are returned to the sender. A popular\nmodel that has been applied to several wide-area applications is feedback\nsuppression.\nThis scheme underlies the Scalable Reliable Multicasting\n(SRM) protocol developed by Floyd et al. [1997] and works as follows.\nFirst, in SRM, receivers never acknowledge the successful delivery of a\nmulticast message, but instead, report only when they are missing a mes-\nsage. How message loss is detected is left to the application. Only negative\nacknowledgements are returned as feedback. Whenever a receiver notices that\nit missed a message, it multicasts its feedback to the rest of the group.\nMulticasting feedback allows another group member to suppress its own\nfeedback. Suppose several receivers missed message m. Each of them will\nneed to return a negative acknowledgement to the sender, S, so that m can\nbe retransmitted. However, if we assume that retransmissions are always\nmulticast to the entire group, it is sufficient that only a single request for\nretransmission reaches S.\nFor this reason, a receiver R that did not receive message m schedules a\nfeedback message with some random delay. That is, the request for retrans-\nmission is not sent until some random time has elapsed. If, in the meantime,\nanother request for retransmission for m reaches R, R will suppress its own\nfeedback, knowing that m will be retransmitted shortly. In this way, ideally,\nonly a single feedback message will reach S, which in turn subsequently\nretransmits m. This scheme is shown in Figure 8.25.\nFeedback suppression has shown to scale reasonably well, and has been\nused as the underlying mechanism for a number of collaborative Internet\napplications, such as a shared whiteboard.\nHowever, the approach also\nintroduces a number of serious problems. First, ensuring that only one request\nfor retransmission is returned to the sender requires a reasonably accurate\nscheduling of feedback messages at each receiver. Otherwise, many receivers\nwill still return their feedback at the same time. Setting timers accordingly in\na group of processes that is dispersed across a wide-area network is not that\neasy.\nAnother problem is that multicasting feedback also interrupts those pro-\ncesses to which the message has been successfully delivered. In other words,\nother receivers are forced to receive and process messages that are useless\n \nDS 4.01\n\n\n520\nCHAPTER 8. FAULT TOLERANCE\nFigure 8.25: Several receivers have scheduled a request for retransmission, but\nthe first retransmission request leads to the suppression of others.\nto them.\nThe only solution to this problem is to let receivers that have\nnot received message m join a separate multicast group for m, as explained\nby Kasera et al. [1997]. Unfortunately, this solution requires that groups can\nbe managed in a highly efficient manner, which is hard to accomplish in a\nwide-area system. A better approach is therefore to let receivers that tend to\nmiss the same messages team up and share the same multicast channel for\nfeedback messages and retransmissions. Details on this approach are found\nin [Liu et al., 1998].\nTo enhance the scalability of SRM, it is useful to let receivers assist in local\nrecovery. In particular, if a receiver to which message m has been successfully\ndelivered, receives a request for retransmission, it can decide to multicast m\neven before the retransmission request reaches the original sender. Further\ndetails can be found in [Floyd et al., 1997] and [Liu et al., 1998].\nFeedback suppression as just described is basically a nonhierarchical so-\nlution. However, achieving scalability for large groups of receivers requires\nthat hierarchical approaches are adopted. A solution is shown in Figure 8.26.\nThe group of receivers is partitioned into a number of subgroups, which\nare subsequently organized into a tree. Within each subgroup, any reliable\nmulticasting scheme that works for small groups can be used. Each subgroup\nappoints a local coordinator, which represents that group in the multicast tree.\nA link in the tree between two nodes corresponds to a reliable connection\nbetween the coordinators of the respective subgroups.\nWhen a process S in group G wants to send a message, it simply uses the\nreliable multicast scheme for G to reach all its members, including the group’s\ncoordinator, say C. C, in turn, will forward the message to its neighboring\ncoordinators. As a general rule, a coordinator will forward an incoming\nmessage m to all its neighboring coordinators, except the one from which it\nreceived m. In addition, a coordinator will reliably multicast the incoming\nmessage to all members of the subgroup it represents, and notably also handle\nretransmissions for that group.\nDS 4.01\n \n\n\n8.4. RELIABLE GROUP COMMUNICATION\n521\nIn an ACK-based scheme, if coordinator C of group G sends a message\nm to coordinator C′ of another, neighboring group G′, it will keep m in its\nhistory buffer at least until C′ has sent an acknowledgement. In a NACK-\nbased scheme, only if G′ detects it has missed m (and thus also all members\nof G′, and all coordinators to which G′ would have forwarded m), it will send\na nack message to C. It is thus seen that a single ack or nack message from a\ncoordinator, aggregates many feedback control messages from other processes,\nleading to a much more scalable, reliable multicasting scheme. Scalability\nis further improved by letting a coordinator handle the retransmissions to\nneighboring coordinators, to which it had forwarded a message.\nFigure 8.26: The essence of hierarchical reliable multicasting. Each local\ncoordinator forwards the message to its neighboring coordinators in the tree\nand later handles retransmission requests.\nNote that the nonhierarchical feedback control which we discussed before\ncan be used to improve the scalability of a single multicast group. Together\nwith hierarchical feedback control, we would combine relatively large reliable-\nmulticast subgroups into potentially large trees, thus being able to support\nreliable multicasting for large groups of processes.\nThe main problem with hierarchical solutions is the construction and\nmanagement of the tree: how are subgroups formed, which processes are\nappointed to be coordinator, and how are the subgroups organized in a tree.\nIn many cases, a tree needs to be constructed dynamically. Unfortunately,\ntraditional network-level solutions provide almost no adequate services for\ntree management. For this reason, application-level multicasting solutions as\nwe discussed in Section 4.4.1 have gained popularity.\nFinally, let us briefly consider gossip-based multicasting schemes, in par-\nticular the following push-pull anti-entropy scheme that we discussed exten-\nsively in Section 4.4.3.\nIn this scheme, a node P picks another node Q at random, and subsequently\nexchanges updates with Q. In other words, P pushes updates that Q has not\n \nDS 4.01\n\n\n522\nCHAPTER 8. FAULT TOLERANCE\nseen before to Q, and pulls in any updates that Q has, but which were missed\nby P. After the exchange, both processes have the same data. Clearly, this\nscheme is already inherently robust, for if the communication between P\nand Q fails for whatever reason, P will simply pick some other node to\nexchange updates.\nThe net effect is that the speed by which an update\npropagates through the system slows down, but the reliability is affected only\nin extreme cases. Nevertheless, this slowdown is considered important for\nsome applications. In this light, the comparison between traditional tree-based\nmulticasting and gossip-based multicasting for the purpose of aggregation as\ndiscussed by Nyers and Jelasity [2015] may be of interest.\n8.4.3\nAtomic multicast\nLet us now return to the situation in which we need to achieve reliable\nmulticasting in the presence of process failures. In particular, what is often\nneeded in a distributed system is the guarantee that a message is delivered to\neither all (nonfaulty) group members or to none. This is also known as the\natomic multicast problem, to which we return with greater precision below.\nTo see why atomicity is so important, consider a replicated database con-\nstructed as an application on top of a distributed system. The distributed\nsystem offers reliable multicasting facilities. In particular, it allows the con-\nstruction of process groups to which messages can be reliably sent. The\nreplicated database is therefore constructed as a group of processes, one\nprocess for each replica. Update operations are always multicasted to all\nreplicas and subsequently performed locally. We are thus assuming that an\nactive-replication protocol is being used.\nTo keep matters simple, assume a client contacts a replica P and requests\nit to perform an update. The replica does so by multicasting the update to\nthe other group members. Unfortunately, before the multicast completes,\nP crashes, leaving the rest of the group in a difficult position: some group\nmembers will have received the update request; others will not. If the members\nwho have received the request, deliver it to the database, then obviously\nwe will have an inconsistent replicated database. Some replicas will have\nprocessed the update, others will not. This situation needs to be avoided, and\nwe should either have that the update is delivered to all nonfaulty members, or\nto none. The former case reflects that P crashed after completing the multicast,\nwhile the latter represents P crashing before it even got a chance to request\nthe update.\nBoth these situations are fine, and correspond to the case in which a client\ncommunicates with a single server that is allowed to crash. If a number\nof the group members would execute the update, while others would not,\ndistribution transparency is at stake, but even worse, the client would not\nknow what to make of the situation.\nDS 4.01\n \n\n\n8.4. RELIABLE GROUP COMMUNICATION\n523\nVirtual synchrony\nReliable multicast in the presence of process failures can be accurately defined\nin terms of process groups and changes to group membership. As we did\nearlier, we make a distinction between receiving and delivering a message. In\nparticular, we again adopt a model in which the distributed system consists\nof message-handling components, as was shown in Figure 8.22. A received\nmessage is locally buffered in this component until it can be delivered to the\napplication, which is logically placed as a group member at a higher layer.\nThe whole idea of atomic multicasting is that a multicast message m is\nuniquely associated with a list of processes that should deliver it. This delivery\nlist corresponds to a group view, namely, the view on the set of processes\ncontained in the group, which the sender had at the time message m was\nmulticasted. An important observation is that each process on that list has the\nsame view. In other words, they should all agree that m should be delivered\nby each one of them and by no other process.\nNow suppose that message m is multicasted at the time its sender, say\nP, has group view G.\nFurthermore, assume that while the multicast is\ntaking place, another process Q joins or leaves the group. This change in\ngroup membership is naturally announced to all processes in G. Stated\nsomewhat differently, a view change takes place by multicasting a message\nvc announcing the joining or leaving of Q.\nWe now have two multicast\nmessages simultaneously in transit: m and vc. What we need to guarantee\nis that m is either delivered by all processes in G before any one executes\nthe view change as specified by vc, or m is not delivered at all. Note that\nthis requirement is comparable to totally ordered multicasting, which we\ndiscussed in Section 5.2.1.\nA question that quickly comes to mind is that if m is not delivered by\nany process, how can we speak of a reliable multicast protocol? In principle,\nthere is only one case in which delivery of m is allowed to fail: when the\ngroup membership change is the result of the sender P of m crashing. In that\ncase, either all remaining (nonfaulty) members of G should deliver m before\nagreeing P is no longer member of the group, or none should deliver m. As\nmentioned before, the latter corresponds to the situation that P is considered\nto have crashed before it had a chance to send m.\nThis stronger form of reliable multicast guarantees that a message multicast\nto group view G is delivered by each nonfaulty process in G. If the sender of\nthe message crashes during the multicast, the message is either delivered to\nall remaining processes, or ignored by each of them. Such a reliable multicast\nis said to be virtually synchronous [Birman and Joseph, 1987].\nTo illustrate these matters, consider the four processes shown in Figure 8.27.\nAt a certain moment, we have a group consisting of S1, S2, S3, and S4. After\nsome messages have been multicast, S3 crashes. However, before crashing,\nit succeeded in multicasting a message to processes S2 and S4, but not to S1.\n \nDS 4.01\n\n\n524\nCHAPTER 8. FAULT TOLERANCE\nFigure 8.27: The principle of virtual synchronous multicast.\nVirtual synchrony in this case guarantees that the message is not delivered\nat all, effectively establishing the situation that the message was never sent\nbefore S3 crashed.\nAfter S3 has been removed from the group, communication proceeds\nbetween the remaining group members. Later, when S3 recovers, it can join\nthe group again, after its state has been brought up to date.\nThe principle of virtual synchrony comes from the fact that all multicasts\ntake place between view changes. Put somewhat differently, a view change\nacts as a barrier across which no multicast can pass. In a sense, it is comparable\nto the use of a synchronization variable in distributed data stores, as discussed\nin the Chapter 7. All multicasts that are in transit while a view change\ntakes place are completed before the view change comes into effect. The\nimplementation of virtual synchrony is not trivial, as we discuss below.\nMessage Ordering\nVirtual synchrony allows an application developer to think about multicasts\nas taking place in epochs that are separated by group membership changes.\nHowever, nothing has yet been said concerning the ordering of multicasts. In\ngeneral, four different orderings are distinguished:\n1. Unordered multicasts\n2. FIFO-ordered multicasts\n3. Causally ordered multicasts\n4. Totally ordered multicasts\nA reliable, unordered multicast is a virtually synchronous multicast\nin which no guarantees are given concerning the order in which received\nmessages are delivered by different processes. (Note that reliable multicasting\nis still about realizing the all-or-nothing property when it comes to delivering\nDS 4.01\n \n\n\n8.4. RELIABLE GROUP COMMUNICATION\n525\nmessages to group members.) To explain, assume that reliable multicasting is\nsupported by a library providing a send and a receive primitive. The receive\noperation blocks the caller until a message can be delivered.\nEvent order\nProcess P1\nProcess P2\nProcess P3\n1\nsends m1\nreceives m1\nreceives m2\n2\nsends m2\nreceives m2\nreceives m1\nFigure 8.28: Three communicating processes in the same group. The ordering\nof events per process is shown along the vertical axis.\nNow suppose a sender P1 multicasts two messages to a group, while two\nother processes in that group are waiting for messages to arrive, as shown\nin Figure 8.28. Assuming that processes do not crash or leave the group\nduring these multicasts, it is possible that the message-handling component\nat P2 first receives message m1 and then m2. Because there are no message-\nordering constraints, the messages may be delivered in the order that they are\nreceived. In contrast, the message-handling component at P3 may first receive\nmessage m2 followed by m1, and delivers these two in this same order to the\nhigher-level application of P3.\nIn the case of reliable FIFO-ordered multicasts, the message-handling\ncomponent layer is forced to deliver incoming messages from the same process\nin the same order as they have been sent. Consider the communication within\na group of four processes, as shown in Figure 8.29. With FIFO ordering,\nthe only thing that matters is that message m1 is always delivered before\nm2, and, likewise, that message m3 is always delivered before m4. This rule\nhas to be obeyed by all processes in the group. In other words, when the\ncommunication layer at P3 receives m2 first, it will wait with delivery to P3\nuntil it has received and delivered m1.\nEvent order\nProcess P1\nProcess P2\nProcess P3\nProcess P4\n1\nsends m1\nreceives m1\nreceives m3\nsends m3\n2\nsends m2\nreceives m3\nreceives m1\nsends m4\n3\nreceives m2\nreceives m2\n4\nreceives m4\nreceives m4\nFigure 8.29: Four processes in the same group with two different senders, and\na possible delivery order of messages under FIFO-ordered multicasting.\nHowever, there is no constraint regarding the delivery of messages sent\nby different processes. In other words, if process P2 receives m1 before m3, it\nmay deliver the two messages in that order. Meanwhile, process P3 may have\nreceived m3 before receiving m1. FIFO ordering states that P3 may deliver m3\nbefore m1, although this delivery order is different from that of P2.\n \nDS 4.01\n\n\n526\nCHAPTER 8. FAULT TOLERANCE\nFinally, reliable causally ordered multicast delivers messages so that\npotential causality between different messages is preserved. In other words, if\na message m1 causally precedes another message m2, regardless of whether\nthey were multicasted by the same sender, then the communication layer\nat each receiver will always deliver m2 after it has received and delivered\nm1. Note that causally ordered multicasts can be implemented using vector\ntimestamps, as discussed in Chapter 5.\nBesides these three orderings, there may be the additional constraint that\nmessage delivery is to be totally ordered as well. Totally ordered delivery\nmeans that regardless of whether message delivery is unordered, FIFO or-\ndered, or causally ordered, it is required additionally that when messages are\ndelivered, they are delivered in the same order to all group members.\nFor example, with the combination of FIFO and totally ordered multicast,\nprocesses P2 and P3 in Figure 8.29 may both first deliver message m3 and\nthen message m1. However, if P2 delivers m1 before m3, while P3 delivers m3\nbefore delivering m1, they would violate the total-ordering constraint. Note\nthat FIFO ordering should still be respected. In other words, m2 should be\ndelivered after m1 and, accordingly, m4 should be delivered after m3.\nVirtually synchronous reliable multicasting offering totally ordered de-\nlivery of messages is called atomic multicasting. It encompasses the all-\nor-nothing property discussed before (i.e., all members have the message\ndelivered to, or none of them do), yet atomic multicasting also requires a to-\ntally ordered delivery of messages. With the three different message ordering\nconstraints discussed above, this leads to six forms of reliable multicasting, as\nshown in Figure 8.30 [Hadzilacos and Toueg, 1993].\nMulticast\nBasic message ordering\nTO delivery?\nReliable multicast\nNone\nNo\nFIFO multicast\nFIFO-ordered delivery\nNo\nCausal multicast\nCausal-ordered delivery\nNo\nAtomic multicast\nNone\nYes\nFIFO atomic multicast\nFIFO-ordered delivery\nYes\nCausal atomic multicast\nCausal-ordered delivery\nYes\nFigure 8.30: Six different versions of virtually synchronous reliable multicast-\ning and considering totally ordered delivery.\nNote 8.9 (Advanced: Implementing virtual synchrony)\nLet us now consider a possible implementation of a virtually synchronous reliable\nmulticast. An example of such an implementation appears in Isis, a fault-tolerant\ndistributed system that has been in practical use in industry for several years. We\nwill focus on some of the implementation issues of this technique as described in\nBirman et al. [1991].\nDS 4.01\n \n\n\n8.4. RELIABLE GROUP COMMUNICATION\n527\nReliable multicasting in Isis makes use of available reliable point-to-point com-\nmunication facilities of the underlying network, in particular, TCP. Multicasting a\nmessage m to a group of processes is implemented by reliably sending m to each\ngroup member. As a consequence, although each transmission is guaranteed to\nsucceed, there are no guarantees that all group members receive m. In particular,\nthe sender may fail before having transmitted m to each member.\nBesides reliable point-to-point communication, Isis also assumes that messages\nfrom the same source are received by a communication layer in the order they\nwere sent by that source. In practice, this requirement is solved by using TCP\nconnections for point-to-point communication.\nThe main problem that needs to be solved is to guarantee that all messages\nsent to view G are delivered to all nonfaulty processes in G before the next group\nmembership change takes place. The first issue that needs to be taken care of\nis making sure that each process in G has received all messages that were sent\nto G. Note that because the sender of a message m to G may have failed before\ncompleting its multicast, there may indeed be processes in G that will never\nreceive m. Because the sender has crashed, these processes should get m from\nsomewhere else.\nThe solution to this problem is to let every process in G keep m until it knows\nfor sure that all members in G have received it. If m has been received by all\nmembers in G, m is said to be stable. Only stable messages are allowed to be\ndelivered. To ensure stability, it is sufficient to select an arbitrary live process in\nG and request it to send m to all other processes in G.\n(a)\n(b)\n(c)\nFigure 8.31: (a) Process 4 notices that process 7 has crashed and sends a\nview change. (b) Process 6 sends out all its unstable messages, followed by\na flush message. (c) Process 6 installs the new view when it has received\na flush message from everyone else.\nTo be more specific, assume the current view is Gi, but that it is necessary\nto install the next view Gi+1. Without loss of generality, we assume that Gi and\nGi+1 differ by at most one process. A process P notices the view change when\nit receives a view-change message. Such a message may come from the process\nwanting to join or leave the group, or from a process that had detected the failure\n \nDS 4.01\n",
      "page_number": 529
    },
    {
      "number": 53,
      "title": "Segment 53 (pages 538-551)",
      "start_page": 538,
      "end_page": 551,
      "detection_method": "topic_boundary",
      "content": "528\nCHAPTER 8. FAULT TOLERANCE\nof a process in Gi that is now to be removed, as shown in Figure 8.31(a).\nWhen a process P receives the view-change message for Gi+1, it first forwards\na copy of any unstable message from Gi it still has to every process in Gi+1, and\nsubsequently marks it as being stable. Recall that Isis assumes point-to-point\ncommunication is reliable, so that forwarded messages are never lost. Such\nforwarding guarantees that all messages in Gi that have been received by at least\none process are received by all nonfaulty processes in Gi. Note that it would also\nhave been sufficient to elect a single coordinator to forward unstable messages.\nTo indicate that P no longer has any unstable messages and that it is prepared\nto install Gi+1 as soon as the other processes can do that as well, it multicasts a\nflush message for Gi+1, as shown in Figure 8.31(b). After P has received a flush\nmessage for Gi+1 from each other process, it can safely install the new view, as\nshown in Figure 8.31(c).\nWhen a process Q receives a message m while Q still believes the current\nview is Gi, it delivers m taking any additional message-ordering constraints into\naccount. If it had already received m, it considers the message to be a duplicate\nand discards it.\nBecause process Q will eventually receive the view-change message for Gi+1,\nit will also first forward any of its unstable messages and subsequently wrap\nthings up by sending a flush message for Gi+1. Note that due to the assumed\nFIFO-message ordering as provided by the underlying communication layer, a\nflush message from a process is always received after the receipt of an unstable\nmessage from that same process.\nThe major flaw in the protocol described so far is that it cannot deal with\nprocess failures while a new view change is being announced. In particular, it\nassumes that until the new view Gi+1 has been installed by each member in\nGi+1, no process in Gi+1 will fail (which would lead to a next view Gi+2). This\nproblem is solved by announcing view changes for any view Gi+k even while\nprevious changes have not yet been installed by all processes. The details are\nrather intricate, yet the principle should be clear.\n8.5\nDistributed commit\nThe atomic multicasting problem discussed in the previous section is an\nexample of a more general problem, known as distributed commit. The\ndistributed commit problem involves having an operation being performed\nby each member of a process group, or none at all. In the case of reliable\nmulticasting, the operation is the delivery of a message. With distributed\ntransactions, the operation may be the commit of a transaction at a single site\nthat takes part in the transaction. Other examples of distributed commit, and\nhow it can be solved, are discussed by Tanisch [2000].\nDistributed commit is often established by a coordinator. In a simple\nscheme, this coordinator tells all other processes that are also involved, called\nparticipants, whether to (locally) perform the operation in question. This\nDS 4.01\n \n\n\n8.5. DISTRIBUTED COMMIT\n529\nscheme is referred to as a one-phase commit protocol. It has the obvious\ndrawback that if one of the participants cannot actually perform the operation,\nthere is no way to tell the coordinator. For example, in the case of distributed\ntransactions, a local commit may not be possible because this would violate\nconcurrency control constraints.\nIn practice, more sophisticated schemes are needed, the most common one\nbeing the two-phase commit protocol, which we discuss in detail below. The\nmain drawback of this protocol is that it cannot generally efficiently handle\nthe failure of the coordinator. To that end, a three-phase protocol has been\ndeveloped, which we discuss separately in Note 8.11.\nThe original two-phase commit protocol (2PC) is due to Gray [1978].\nWithout loss of generality, consider a distributed transaction involving the\nparticipation of a number of processes, each running on a different machine.\nAssuming that no failures occur, the protocol consists of the following two\nphases, each consisting of two steps (see also Bernstein and Newcomer [2009]):\n1. The coordinator sends a vote-request message to all participants.\n2. When a participant receives a vote-request message, it returns either a\nvote-commit message to the coordinator, telling the coordinator that it\nis prepared to locally commit its part of the transaction, or otherwise, a\nvote-abort message.\n3. The coordinator collects all votes from the participants. If all participants\nhave voted to commit the transaction, then so will the coordinator. In that\ncase, it sends a global-commit message to all participants. However,\nif one participant had voted to abort the transaction, the coordinator\nwill also decide to abort the transaction and multicasts a global-abort\nmessage.\n4. Each participant that voted for a commit waits for the final reaction\nby the coordinator. If a participant receives a global-commit mes-\nsage, it locally commits the transaction. Otherwise, when receiving a\nglobal-abort message, the transaction is locally aborted as well.\nThe first phase is the voting phase, and consists of steps 1 and 2. The second\nphase is the decision phase, and consists of steps 3 and 4. These four steps\nare shown as finite state diagrams in Figure 8.32.\nSeveral problems arise when this basic 2PC protocol is used in a system\nwhere failures occur. First, note that the coordinator as well as the participants\nhave states in which they block waiting for incoming messages. Consequently,\nthe protocol can easily fail when a process crashes, as other processes may be\nindefinitely waiting for a message from that process. For this reason, timeout\nmechanisms are used. These mechanisms are explained next.\nWhen taking a look at the finite state machines in Figure 8.32, it can be seen\nthat there are a total of three states in which either a coordinator or participant\n \nDS 4.01\n\n\n530\nCHAPTER 8. FAULT TOLERANCE\n(a)\n(b)\nFigure 8.32: (a) The finite state machine for the coordinator in 2PC. (b) The\nfinite state machine for a participant.\nis blocked waiting for an incoming message. First, a participant may be\nwaiting in its INIT state for a vote-request message from the coordinator.\nIf that message is not received after some time, the participant will simply\ndecide to locally abort the transaction, and thus send a vote-abort message\nto the coordinator.\nLikewise, the coordinator can be blocked in state WAIT, waiting for the\nvotes of each participant. If not all votes have been collected after a cer-\ntain period of time, the coordinator should vote for an abort as well, and\nsubsequently send global-abort to all participants.\nFinally, a participant can be blocked in state READY, waiting for the global\nvote as sent by the coordinator. If that message is not received within a given\ntime, the participant cannot simply decide to abort the transaction. Instead,\nit must find out which message the coordinator actually sent. The simplest\nsolution to this problem is to let each participant block until the coordinator\nrecovers again.\nA better solution is to let a participant P contact another participant Q to\nsee if it can decide from Q’s current state what it should do. For example,\nsuppose that Q had reached state COMMIT.\nThis is possible only if the\ncoordinator had sent a global-commit message to Q just before crashing.\nApparently, this message had not yet been sent to P. Consequently, P may\nnow also decide to locally commit. Likewise, if Q is in state ABORT, P can\nsafely abort as well.\nNow suppose that Q is still in state INIT. This situation can occur when\nthe coordinator has sent vote-request to all participants, but this message\nhas reached P (which subsequently responded with a vote-commit message),\nbut has not reached Q. In other words, the coordinator had crashed while\nmulticasting vote-request. In this case, it is safe to abort the transaction:\nboth P and Q can make a transition to state ABORT.\nThe most difficult situation occurs when Q is also in state READY, waiting\nfor a response from the coordinator. In particular, if it turns out that all\nDS 4.01\n \n\n\n8.5. DISTRIBUTED COMMIT\n531\nparticipants are in state READY, no decision can be taken. The problem\nis that although all participants are willing to commit, they still need the\ncoordinator’s vote to reach the final decision. Consequently, the protocol\nblocks until the coordinator recovers. The various options are summarized in\nFigure 8.33.\nState of Q\nAction by P\nCOMMIT\nMake transition to COMMIT\nABORT\nMake transition to ABORT\nINIT\nMake transition to ABORT\nREADY\nContact another participant\nFigure 8.33: Actions taken by a participant P when residing in state READY\nand having contacted another participant Q.\nTo ensure that a process can actually recover, it is necessary that it saves\nits state to persistent storage. For example, if a participant was in state INIT,\nit can safely decide to locally abort the transaction when it recovers, and then\ninform the coordinator. Likewise, when it had already taken a decision such\nas when it crashed while being in either state COMMIT or ABORT, it is to\nrecover to that state again, and retransmit its decision to the coordinator.\nProblems arise when a participant crashed while residing in state READY.\nIn that case, when recovering, it cannot decide on its own what it should do\nnext, that is, commit or abort the transaction. Consequently, it is forced to\ncontact other participants to find what it should do, analogous to the situation\nwhen it times out while residing in state READY as described above.\nThe coordinator has only two critical states it needs to keep track of. When\nit starts the 2PC protocol, it should record that it is entering state WAIT so\nthat it can possibly retransmit the vote-request message to all participants\nafter recovering. Likewise, if it had come to a decision in the second phase, it\nis sufficient if that decision has been recorded so that it can be retransmitted\nwhen recovering.\nIt may thus be possible that a participant will need to block until the\ncoordinator recovers. This situation occurs when all participants have received\nand processed the vote-request message from the coordinator, while mean-\nwhile, the coordinator crashed. In that case, participants cannot cooperatively\ndecide on the final action to take. For this reason, 2PC is also referred to as a\nblocking commit protocol.\nThere are several solutions to avoid blocking. One solution is to use a\nmulticast primitive, by which a receiver immediately multicasts a received\nmessage to all other processes [Babaoglu and Toueg, 1993]. It can be shown\nthat this approach allows a participant to reach a final decision, even if the\ncoordinator has not yet recovered. Another solution is to use three instead of\ntwo phases, as we discuss in Note 8.11.\n \nDS 4.01\n\n\n532\nCHAPTER 8. FAULT TOLERANCE\nNote 8.10 (Advanced: 2PC outlined in Python)\nAn outline of the actions that are executed by the coordinator is given in Fig-\nure 8.34. The coordinator starts by multicasting a vote-request to all participants\nto collect their votes. It subsequently records that it is entering the WAIT state,\nafter which it waits for incoming votes from participants.\nIf not all votes have been collected, but no more votes are received within\na given time interval prescribed in advance, the coordinator assumes that one\nor more participants have failed. Consequently, it should abort the transaction\nand multicasts a global-abort to the (remaining) participants. Likewise, if only\na single participant decides to abort the transaction, the coordinator will have\nto call off the transaction. If all participants vote to commit, global-commit is\nfirst logged and subsequently sent to all processes. Otherwise, the coordinator\nmulticasts a global-abort (after recording it in the local log).\n1 class Coordinator:\n2\ndef run(self):\n3\nyetToReceive = list(self.participants)\n4\nself.log.info(’WAIT’)\n5\nself.chan.sendTo(self.participants, VOTE_REQUEST)\n6\nwhile len(yetToReceive) > 0:\n7\nmsg = self.chan.recvFrom(self.participants, BLOCK, TIMEOUT)\n8\nif msg == -1 or (msg[1] == VOTE_ABORT):\n9\nself.log.info(’ABORT’)\n10\nself.chan.sendTo(self.participants, GLOBAL_ABORT)\n11\nreturn\n12\nelse: # msg[1] == VOTE_COMMIT\n13\nyetToReceive.remove(msg[0])\n14\nself.log.info(’COMMIT’)\n15\nself.chan.sendTo(self.participants, GLOBAL_COMMIT)\nFigure 8.34: The steps taken by the coordinator in a 2PC protocol.\nAfter receiving a vote request, the participant does its work. All bets are\noff if its work failed, but otherwise, it will vote for committing the transaction.\nIt records its decision in a local log and informs the coordinator by sending a\nvote-commit message. The participant must then wait for the global decision.\nAssuming this decision (which again should come from the coordinator) comes in\non time, it is simply written to the local log, after which it can be carried out (the\nlatter is not shown in the code).\nFigure 8.35 shows the steps taken by a participant. First, the process waits for\na vote request from the coordinator. If no message comes in, the transaction is\nsimply aborted. Apparently, the coordinator had failed.\nHowever, if the participant times out while waiting for the coordinator’s\ndecision to come in, it executes a termination protocol by first multicasting a\ndecision-request message to the other processes, after which it subsequently\nblocks while waiting for a response. When a decisive response comes in (possibly\nfrom the coordinator, which is assumed to eventually recover), the participant\nDS 4.01\n \n\n\n8.5. DISTRIBUTED COMMIT\n533\nwrites the decision to its local log and handles accordingly. Any request from\nanother participant for the final decision is left unanswered as long as that decision\nis not known.\n1 class Participant:\n2\ndef run(self):\n3\nself.log.info(’INIT’)\n4\nmsg = self.chan.recvFrom(self.coordinator, BLOCK, TIMEOUT)\n5\nif msg == -1:\n# Crashed coordinator - give up entirely\n6\ndecision = LOCAL_ABORT\n7\nelse: # Coordinator will have sent VOTE_REQUEST\n8\ndecision = self.do_work()\n9\nif decision == LOCAL_ABORT:\n10\nself.chan.sendTo(self.coordinator, VOTE_ABORT)\n11\nself.log.info(’LOCAL_ABORT’)\n12\nelse: # Ready to commit, enter READY state\n13\nself.log.info(’READY’)\n14\nself.chan.sendTo(self.coordinator, VOTE_COMMIT)\n15\nmsg = self.chan.recvFrom(self.coordinator, BLOCK, TIMEOUT)\n16\nif msg == -1: # Crashed coordinator - check the others\n17\nself.log.info(’NEED_DECISION’)\n18\nself.chan.sendTo(self.participants, NEED_DECISION)\n19\nwhile True:\n20\nmsg = self.chan.recvFromAny()\n21\nif msg[1] in [GLOBAL_COMMIT, GLOBAL_ABORT, LOCAL_ABORT]:\n22\ndecision = msg[1]\n23\nbreak\n24\nelse: # Coordinator came to a decision\n25\ndecision = msg[1]\n26\nif decision == GLOBAL_COMMIT:\n27\nself.log.info(’COMMIT’)\n28\nelse: # decision in [GLOBAL_ABORT, LOCAL_ABORT]:\n29\nself.log.info(’ABORT’)\n30\nwhile True: # Help any other participant when coordinator crashed\n31\nmsg = self.chan.recvFrom(self.participants)\n32\nif msg[1] == NEED_DECISION:\n33\nself.chan.sendTo([msg[0]], decision)\nFigure 8.35: The steps taken by a participant process in 2PC.\nWe keep every participant up-and-running after it decided to either commit\nor abort. It can then assist other participants in need of a decision after detecting\nthat the coordinator had crashed. To this end, a participant blocks on incoming\nmessages and returns its own decision when asked for. Note that we are actually\nproviding an implementation that supports partially synchronous behavior: we\nassume that timeouts can be applied as a mechanism to detect failures, but take\ninto account that we may have mistakenly concluded that a server crashed.\nOf course, the final, now endless loop should eventually terminate. To that\nend, we need a mechanism to detect that all processes have indeed come to a\ndecision. We leave it as an exercise to the reader for designing such a detector.\n \nDS 4.01\n\n\n534\nCHAPTER 8. FAULT TOLERANCE\nNote 8.11 (Advanced: Three-phase commit)\nA problem with the two-phase commit protocol is that when the coordinator has\ncrashed, participants may not be able to reach a final decision. Consequently,\nparticipants may need to remain blocked until the coordinator recovers. Skeen\n[1981] developed a variant of 2PC, called the three-phase commit protocol (3PC),\nthat avoids blocking processes in the presence of fail-stop crashes. Although 3PC\nis widely referred to in the literature, it is not applied often in practice, as the\nconditions under which 2PC blocks rarely occur. We discuss the protocol, as\nit provides further insight into solving fault-tolerance problems in distributed\nsystems.\nLike 2PC, 3PC is also formulated in terms of a coordinator and a number of\nparticipants. Their respective finite state machines are shown in Figure 8.36. The\nessence of the protocol is that the states of the coordinator and each participant\nsatisfy the following two conditions:\n1. There is no single state from which it is possible to make a transition directly\nto either a COMMIT or an ABORT state.\n2. There is no state in which it is not possible to make a final decision, and\nfrom which a transition to a COMMIT state can be made.\nIt can be shown that these two conditions are necessary and sufficient for a commit\nprotocol to be nonblocking [Skeen and Stonebraker, 1983].\n(a)\n(b)\nFigure 8.36: (a) The finite state machine for the coordinator in 3PC. (b) The\nfinite state machine for a participant.\nThe coordinator in 3PC starts with sending a vote-request message to all\nparticipants, after which it waits for incoming responses. If any participant\nvotes to abort the transaction, the final decision will be to abort as well, so\nthe coordinator sends global-abort. However, when the transaction can be\ncommitted, a prepare-commit message is sent. Only after each participant has\nacknowledged it is now prepared to commit, will the coordinator send the final\nglobal-commit message by which the transaction is actually committed.\nAgain, there are only a few situations in which a process is blocked while\nwaiting for incoming messages. First, if a participant is waiting for a vote request\nDS 4.01\n \n\n\n8.5. DISTRIBUTED COMMIT\n535\nfrom the coordinator while residing in state INIT, it will eventually make a\ntransition to state ABORT, thereby assuming that the coordinator has crashed.\nThis situation is identical to that in 2PC. Analogously, the coordinator may be in\nstate WAIT, waiting for the votes from participants. On a timeout, the coordinator\nwill conclude that a participant crashed, and will thus abort the transaction by\nmulticasting a global-abort message.\nNow suppose the coordinator is blocked in state PRECOMMIT. On a timeout,\nit will conclude that one of the participants had crashed, but that participant\nis known to have voted for committing the transaction. Consequently, the co-\nordinator can instruct the operational participants to commit by multicasting a\nglobal-commit message. In addition, it relies on a recovery protocol for the\ncrashed participant to commit its part of the transaction when it comes up again.\nA participant P may block in the READY state or in the PRECOMMIT state.\nOn a timeout, P can conclude only that the coordinator has failed so that it now\nneeds to find out what to do next. As in 2PC, if P contacts any other participant\nthat is in state COMMIT (or ABORT), P should move to that state as well. In\naddition, if all participants are in state PRECOMMIT, the transaction can be\ncommitted.\nAgain analogous to 2PC, if another participant Q is still in the INIT state,\nthe transaction can safely be aborted. It is important to note that Q can be in\nstate INIT only if no other participant is in state PRECOMMIT. A participant\ncan reach PRECOMMIT only if the coordinator had reached state PRECOMMIT\nbefore crashing, and has thus received a vote to commit from each participant. In\nother words, no participant can reside in state INIT while another participant is in\nstate PRECOMMIT.\nIf each of the participants that P can contact is in state READY (and they\ntogether form a majority), the transaction should be aborted. The point to note\nis that another participant may have crashed and will later recover. However,\nneither P, nor any other of the operational participants knows what the state of\nthe crashed participant will be when it recovers. If the process recovers to state\nINIT, then deciding to abort the transaction is the only correct decision. At worst,\nthe process may recover to state PRECOMMIT, but in that case, it cannot do any\nharm to still abort the transaction.\nThis situation is the major difference with 2PC, where a crashed participant\ncould recover to a COMMIT state while all the others were still in state READY.\nIn that case, the remaining operational processes could not reach a final decision\nand would have to wait until the crashed process recovered. With 3PC, if any\noperational process is in its READY state, no crashed process will recover to a state\nother than INIT, ABORT, or PRECOMMIT. For this reason, surviving processes\ncan always come to a final decision.\nFinally, if the processes that P can reach are in state PRECOMMIT (and they\nform a majority), then it is safe to commit the transaction. Again, it can be shown\nthat in this case, all other processes will either be in state READY or at least,\nwill recover to state READY, PRECOMMIT, or COMMIT when they had crashed.\nMore on 3PC can be found in [Bernstein et al., 1987].\n \nDS 4.01\n\n\n536\nCHAPTER 8. FAULT TOLERANCE\n8.6\nRecovery\nSo far, we have mainly concentrated on algorithms that allow us to tolerate\nfaults. However, once a failure has occurred, it is essential that the process\nwhere the failure happened can recover to a correct state. In what follows, we\nfirst concentrate on what it actually means to recover to a correct state, and\nsubsequently when and how the state of a distributed system can be recorded\nand recovered to, through checkpointing and message logging.\n8.6.1\nIntroduction\nFundamental to fault tolerance is the recovery from an error. Recall that an\nerror is that part of a system that may lead to a failure. The whole idea of\nerror recovery is to replace an erroneous state with an error-free state. There\nare essentially two forms of error recovery.\nIn backward recovery, the main issue is to bring the system from its\npresent erroneous state back into a previously correct state. To do so, it will\nbe necessary to record the system’s state from time to time, and to restore\nsuch a recorded state when things go wrong. Each time (part of) the system’s\npresent state is recorded, a checkpoint is said to be made.\nAnother form of error recovery is forward recovery. In this case, when the\nsystem has entered an erroneous state, instead of moving back to a previous,\ncheckpointed state, an attempt is made to bring the system to a correct new\nstate from which it can continue to execute. The main problem with forward\nerror recovery mechanisms is that it has to be known in advance which errors\nmay occur. Only in that case, it is possible to correct those errors and move to\na new state.\nThe distinction between backward and forward error recovery is easily\nexplained when considering the implementation of reliable communication.\nThe common approach to recover from a lost packet is to let the sender\nretransmit that packet. In effect, packet retransmission establishes that we\nattempt to go back to a previous, correct state, namely the one in which the\npacket that was lost is being sent. Reliable communication through packet\nretransmission is therefore an example of applying backward error recovery\ntechniques.\nAn alternative approach is to use a method known as erasure correction.\nIn this approach, a missing packet is constructed from other, successfully\ndelivered packets. For example, in an (n, k)-block erasure code, a set of k\nsource packets is encoded into a set of n encoded packets, such that any set of k\nencoded packets is enough to reconstruct the original k source packets. Typical\nvalues are k = 16 or k = 32, and k < n ≤2k (see, for example, Rizzo [1997]). If\nnot enough packets have yet been delivered, the sender will have to continue\ntransmitting packets until a previously lost packet can be constructed. Erasure\ncorrection is a typical example of a forward error recovery approach.\nDS 4.01\n \n\n\n8.6. RECOVERY\n537\nBy and large, backward error recovery techniques are widely applied as a\ngeneral mechanism for recovering from failures in distributed systems. The\nmajor benefit of backward error recovery is that it is a generally applicable\nmethod independent of any specific system or process. In other words, it\ncan be integrated into (the middleware layer) of a distributed system as a\ngeneral-purpose service.\nHowever, backward error recovery also introduces some problems [Singhal\nand Shivaratri, 1994]. First, restoring a system or process to a previous state\nis generally a relatively costly operation in terms of performance. As will be\ndiscussed in succeeding sections, much work generally needs to be done to\nrecover from, for example, a process crash or site failure. A potential way out\nof this problem is to devise very cheap mechanisms by which components are\nsimply rebooted.\nSecond, because backward error recovery mechanisms are independent of\nthe distributed application for which they are actually used, no guarantees\ncan be given that once recovery has taken place, the same or similar failure\nwill not happen again. If such guarantees are needed, handling errors often\nrequires that the application gets into the loop of recovery. In other words,\nfull-fledged failure transparency can generally not be provided by backward\nerror recovery mechanisms.\nFinally, although backward error recovery requires checkpointing, some\nstates can simply never be rolled back to. For example, once a (possibly\nmalicious) person has taken the $1,000 that suddenly came rolling out of the\nincorrectly functioning automated teller machine, there is only a small chance\nthat money will be stuffed back in the machine. Likewise, recovering to a\nprevious state in most Unix systems after having enthusiastically typed\n/bin/rm -fr *\nbut from the wrong working directory, may turn a few people pale. Some\nthings are simply irreversible.\nCheckpointing allows the recovery to a previous, correct state. However,\ntaking a checkpoint is often a costly operation and may have a severe perfor-\nmance penalty. As a consequence, many fault-tolerant distributed systems\ncombine checkpointing with message logging. In this case, after a check-\npoint has been taken, a process logs its messages before sending them off\n(called sender-based logging). An alternative solution is to let the receiving\nprocess first log an incoming message before delivering it to the application\nit is executing. This scheme is also referred to as receiver-based logging.\nWhen a receiving process crashes, it is necessary to restore the most recently\ncheckpointed state, and from there on replay the messages that have been sent.\nConsequently, combining checkpoints with message logging makes it possible\nto restore a state that lies beyond the most recent checkpoint without the cost\nof checkpointing.\nIn a system where only checkpointing is used, processes will be restored\n \nDS 4.01\n\n\n538\nCHAPTER 8. FAULT TOLERANCE\nto a checkpointed state. From there on, their behavior may be different from\nit was before the failure occurred. For example, because communication times\nare not deterministic, messages may now be delivered in a different order,\nin turn leading to different reactions by the receivers. However, if message\nlogging takes place, an actual replay of the events that happened since the\nlast checkpoint takes place. Such a replay makes it easier to interact with the\noutside world.\nFor example, consider the case that a failure occurred because a user\nprovided erroneous input. If only checkpointing is used, the system would\nhave to take a checkpoint before accepting the user’s input in order to recover\nto the same state. With message logging, an older checkpoint can be used, after\nwhich a replay of events can take place up to the point that the user should\nprovide input. In practice, the combination of having fewer checkpoints and\nmessage logging is more efficient than having to take many checkpoints.\nElnozahy et al. [2002] provide a survey of checkpointing and logging in\ndistributed systems. Various algorithmic details can be found in Chow and\nJohnson [1997].\n8.6.2\nCheckpointing\nIn a fault-tolerant distributed system, backward error recovery requires that\nthe system regularly saves its state2.\nIn particular, we need to record a\nconsistent global state, also called a distributed snapshot. In a distributed\nsnapshot, if a process P has recorded the receipt of a message, then there\nshould also be a process Q that has recorded the sending of that message.\nAfter all, it must have come from somewhere.\nFigure 8.37: A recovery line.\nTo recover after a process or system failure requires that we construct a\nconsistent global state from local states as saved by each process. In particular,\nit is best to recover to the most recent distributed snapshot, also referred to\nas a recovery line. In other words, a recovery line corresponds to the most\nrecent consistent collection of checkpoints, as shown in Figure 8.37.\n2We assume that each process has access to a local, reliable storage.\nDS 4.01\n \n\n\n8.6. RECOVERY\n539\nCoordinated checkpointing\nIn coordinated checkpointing all processes synchronize to jointly write their\nstate to local storage. The main advantage of coordinated checkpointing is\nthat the saved state is automatically globally consistent. A simple solution\nis to use a two-phase blocking protocol. A coordinator first multicasts a\ncheckpoint-request message to all processes.\nWhen a process receives\nsuch a message, it takes a local checkpoint, queues any subsequent message\nhanded to it by the application it is executing, and acknowledges to the\ncoordinator that it has taken a checkpoint. When the coordinator has received\nan acknowledgment from all processes, it multicasts a checkpoint-done\nmessage to allow the (blocked) processes to continue.\nIt is easy to see that this approach will indeed lead to a globally consis-\ntent state because no incoming message will ever be registered as part of a\ncheckpoint. This is because any message that follows a request for taking\na checkpoint is not considered to be part of the local checkpoint. At the\nsame time, outgoing messages (as handed to the checkpointing process by\nthe application it is running), are queued locally until the checkpoint-done\nmessage is received.\nAn improvement to this algorithm is to send a checkpoint request only to\nthose processes that depend on the recovery of the coordinator, and ignore the\nother processes. A process is dependent on the coordinator if it has received a\nmessage that is directly or indirectly causally related to a message that the\ncoordinator had sent since the last checkpoint. This leads to the notion of an\nincremental snapshot.\nTo take an incremental snapshot, the coordinator sends a checkpoint\nrequest only to those processes it had sent a message to since it last took a\ncheckpoint. When a process P receives such a request, it forwards the request\nto all those processes to which P itself had sent a message since the last\ncheckpoint, and so on. A process forwards the request only once. When all\nprocesses have been identified, a second multicast is used to actually trigger\ncheckpointing and to let the processes continue where they had left off.\nIndependent checkpointing\nNow consider the case in which each process simply records its local state\nfrom time to time in an uncoordinated fashion. To discover a recovery line,\nrequires that each process is rolled back to its most recently saved state. If\nthese local states jointly do not form a distributed snapshot, further rolling\nback is necessary. This process of a cascaded rollback may lead to what is\ncalled the domino effect and is shown in Figure 8.38.\nWhen process P2 crashes, we need to restore its state to the most recently\nsaved checkpoint. As a consequence, process P1 will also need to be rolled\nback. Unfortunately, the two most recently saved local states do not form a\n \nDS 4.01\n\n\n540\nCHAPTER 8. FAULT TOLERANCE\nFigure 8.38: The domino effect.\nconsistent global state: the state saved by P2 indicates the receipt of a message\nm, but no other process can be identified as its sender. Consequently, P2 needs\nto be rolled back to an earlier state.\nHowever, the next state to which P2 is rolled back also cannot be used as\npart of a distributed snapshot. In this case, P1 will have recorded the receipt\nof message m∗, but there is no recorded event of this message being sent. It is\ntherefore necessary to also roll P1 back to a previous state. In this example, it\nturns out that the recovery line is actually the initial state of the system.\nAs processes take local checkpoints independent of each other, this method\nis also referred to as independent checkpointing. Its implementation requires\nthat dependencies are recorded in such a way that processes can jointly roll\nback to a consistent global state. To that end, let CPi(m) denote the mth\ncheckpoint taken by process Pi. Also, let INTi(m) denote the interval between\ncheckpoints CPi(m −1) and CPi(m).\nWhen process Pi sends a message in interval INTi(m), it piggybacks the\npair (i, m) to the receiving process. When process Pj receives a message in in-\nterval INTj(n), along with the pair of indices (i, m), it records the dependency\nINTi(m) →INTj(n). Whenever Pj takes checkpoint CPj(n), it additionally\nsaves this dependency to its local storage, along with the rest of the recovery\ninformation that is part of CPj(n).\nNow suppose that at a certain moment, process Pi is required to roll back\nto checkpoint CPi(m −1). To ensure global consistency, we need to ensure\nthat all processes that have received messages from Pi and that were sent in\ninterval INTi(m), are rolled back to a checkpointed state preceding the receipt\nof such messages. In particular, process Pj in our example, will need to be\nrolled back at least to checkpoint CPj(n −1). If CPj(n −1) does not lead to a\nglobally consistent state, further rolling back may be necessary.\nCalculating the recovery line requires an analysis of the interval dependen-\ncies recorded by each process when a checkpoint was taken. It turns out that\nsuch calculations are fairly complex. In addition, as it turns out, it is often\nnot the coordination between processes that is the dominating performance\nfactor, but the overhead as the result of having to save the state to local stable\nstorage. Therefore, coordinated checkpointing, which is much simpler than\nindependent checkpointing, is often more popular, and will presumably stay\nso even when systems grow to much larger sizes [Elnozahy and Plank, 2004]\nDS 4.01\n \n\n\n8.6. RECOVERY\n541\n8.6.3\nMessage logging\nConsidering that checkpointing can be an expensive operation, techniques\nhave been sought to reduce the number of checkpoints, but still enable re-\ncovery. One such technique is logging messages. The basic idea underlying\nmessage logging is that if the transmission of messages can be replayed, we\ncan still reach a globally consistent state, but without having to restore that\nstate from local storage. Instead, a checkpointed state is taken as a starting\npoint, and all messages that have been sent since are simply retransmitted\nand handled accordingly.\nThis approach works fine under the assumption of what is called a piece-\nwise deterministic execution model. In such a model, the execution of each\nprocess is assumed to take place as a series of intervals in which events take\nplace. These events are the same as those discussed in the context of Lam-\nport’s happened-before relationship in Section 5.2.1. For example, an event\nmay be the execution of an instruction, the sending of a message, and so on.\nEach interval in the piecewise deterministic model is assumed to start with\na nondeterministic event, such as the receipt of a message. However, from\nthat moment on, the execution of the process is completely deterministic. An\ninterval ends with the last event before a nondeterministic event occurs.\nIn effect, an interval can be replayed with a known result, that is, in a\ncompletely deterministic way, provided it is replayed, starting with the same\nnondeterministic event as before. Consequently, if we record all nondeter-\nministic events in such a model, it becomes possible to completely replay the\nentire execution of a process in a deterministic way.\nConsidering that message logs are necessary to recover from a process\ncrash so that a globally consistent state is restored, it becomes important to\nknow precisely when messages are to be logged. Following the approach\ndescribed by Alvisi and Marzullo [1998], it turns out that many existing\nmessage-logging schemes can be easily characterized if we concentrate on\nhow they deal with orphan processes.\nAn orphan process is a process that survives the crash of another process,\nbut whose state is inconsistent with the crashed process after its recovery. As\nan example, consider the situation shown in Figure 8.39. Process Q receives\nmessages m1 and m2 from process P and R, respectively, and subsequently\nsends a message m3 to R. However, in contrast to all other messages, message\nm2 is not logged. If process Q crashes and later recovers again, only the logged\nmessages required for the recovery of Q are replayed, in our example, m1.\nBecause m2 was not logged, its transmission will not be replayed, meaning\nthat the transmission of m3 may also not take place.\nHowever, the situation after the recovery of Q is inconsistent with that\nbefore its recovery. In particular, R holds a message (m3) that was sent before\nthe crash, but whose receipt and delivery do not take place when replaying\nwhat had happened before the crash. This should obviously be avoided.\n \nDS 4.01\n",
      "page_number": 538
    },
    {
      "number": 54,
      "title": "Segment 54 (pages 552-559)",
      "start_page": 552,
      "end_page": 559,
      "detection_method": "topic_boundary",
      "content": "542\nCHAPTER 8. FAULT TOLERANCE\nFigure 8.39: Incorrect replay of messages after recovery, leading to an orphan\nprocess R.\nNote 8.12 (Advanced: Characterizing message-logging schemes)\nTo characterize different message-logging schemes, we follow the approach de-\nscribed by Alvisi and Marzullo [1998]. Each message m is considered to have a\nheader that contains all information necessary to retransmit m, and to properly\nhandle it. For example, each header will identify the sender and the receiver, but\nalso a sequence number to recognize it as a duplicate. In addition, a delivery\nnumber may be added to decide when exactly it should be handed over to the\nreceiving application.\nA message is said to be stable if it can no longer be lost, for example because\nit has been written to reliable, local storage. Stable messages can thus be used for\nrecovery by replaying their transmission.\nEach message m leads to a set DEP(m) of processes that depend on the\ndelivery of m. In particular, DEP(m) consists of those processes to which m has\nbeen delivered. In addition, if another message m∗is causally dependent on\nthe delivery of m, and m∗has been delivered to a process Q, then Q will also\nbe contained in DEP(m). Note that m∗is causally dependent on the delivery of\nm, if it was sent by the same process that previously delivered m, or which had\ndelivered another message that was causally dependent on the delivery of m.\nThe set COPY(m) consists of those processes that have a copy of m, but have\nnot (yet) reliably stored it. When a process Q delivers message m, it also becomes\na member of COPY(m). Note that COPY(m) consists of those processes that could\nhand over a copy of m that can be used to replay the transmission of m. If all\nthese processes crash, replaying the transmission of m is clearly not feasible.\nUsing these notations, it is now easy to define precisely what an orphan\nprocess is. Let FAIL denote the collection of crashed processes, and assume Q is\none of the survivors. Q is an orphan process if there is a message m, such that\nQ is contained in DEP(m), while at the same time every process in COPY(m) has\ncrashed. More formally:\nQ is orphaned ⇔∃m : Q ∈DEP(m) and COPY(m) ⊆FAIL\nIn other words, an orphan process appears when it is dependent on m, but there\nDS 4.01\n \n\n\n8.7. SUMMARY\n543\nis no way to replay m’s transmission.\nTo avoid orphan processes, we thus need to ensure that if each process in\nCOPY(m) crashed, then no surviving process is left in DEP(m). In other words, all\nprocesses in DEP(m) should have crashed as well. This condition can be enforced\nif we can guarantee that whenever a process becomes a member of DEP(m), it also\nbecomes a member of COPY(m). In other words, whenever a process becomes\ndependent on the delivery of m, it will keep a copy of m.\nThere are essentially two approaches that can now be followed. The first\napproach is represented by what are called pessimistic logging protocols. These\nprotocols take care that for each nonstable message m, there is at most one process\ndependent on m. In other words, pessimistic logging protocols ensure that each\nnonstable message m is delivered to at most one process. Note that as soon as m\nis delivered to, say, process P, P becomes a member of COPY(m).\nThe worst that can happen is that process P crashes without m ever having\nbeen logged. With pessimistic logging, P is not allowed to send any messages\nafter the delivery of m without first having ensured that m has been written to\nreliable storage. Consequently, no other processes will ever become dependent on\nthe delivery of m to P, without having the possibility of replaying the transmission\nof m. In this way, orphan processes are always avoided.\nIn contrast, in an optimistic logging protocol, the actual work is done after\na crash occurs. In particular, assume that for some message m, each process in\nCOPY(m) has crashed. In an optimistic approach, any orphan process in DEP(m)\nis rolled back to a state in which it no longer belongs to DEP(m). Clearly, optimistic\nlogging protocols need to keep track of dependencies, which complicates their\nimplementation.\nAs pointed out by Elnozahy et al. [2002], pessimistic logging is so much\nsimpler than optimistic approaches, that it is the preferred way of message\nlogging in practical distributed systems design.\n8.7\nSummary\nFault tolerance is an important subject in distributed systems design. Fault\ntolerance is defined as the characteristic by which a system can mask the\noccurrence and recovery from failures. In other words, a system is fault\ntolerant if it can continue to operate in the presence of failures.\nSeveral types of failures exist. A crash failure occurs when a process\nsimply halts. An omission failure occurs when a process does not respond to\nincoming requests. When a process responds too soon or too late to a request,\nit is said to exhibit a timing failure. Responding to an incoming request, but in\nthe wrong way, is an example of a response failure. The most difficult failures\nto handle are those by which a process exhibits any kind of failure, called\narbitrary or Byzantine failures.\nRedundancy is the key technique needed to achieve fault tolerance. When\napplied to processes, the notion of process groups becomes important. A\n \nDS 4.01\n\n\n544\nCHAPTER 8. FAULT TOLERANCE\nprocess group consists of a number of processes that closely cooperate to\nprovide a service. In fault-tolerant process groups, one or more processes\ncan fail without affecting the availability of the service the group implements.\nOften, it is necessary that communication within the group be highly reliable,\nand adheres to stringent ordering and atomicity properties to achieve fault\ntolerance.\nThe real problem is that members of a process group need to reach consen-\nsus in the presence of various failures. Paxos is by now a well-established and\nhighly robust consensus algorithm. By using 2k + 1 servers, it can establish\nk-fault tolerance. However, we need a total of 3k + 1 servers if it is needed to\ndeal with arbitrary failures.\nReliable group communication, also called reliable multicasting, comes\nin different forms. As long as groups are relatively small, it turns out that\nimplementing reliability is feasible. However, as soon as large groups have to\nbe supported, scalability of reliable multicasting becomes problematic. The\nkey issue in achieving scalability is to reduce the number of feedback messages\nby which receivers report the (un)successful receipt of a multicasted message.\nMatters become worse when atomicity is to be provided. In atomic mul-\nticast protocols, it is essential that each group member has the same view\nconcerning to which members a multicasted message has been delivered.\nAtomic multicasting can be precisely formulated in terms of a virtual syn-\nchronous execution model. In essence, this model introduces boundaries\nbetween which group membership does not change and which messages are\nreliably transmitted. A message can never cross a boundary.\nGroup membership changes are an example where each process needs to\nagree on the same list of members. Such agreement can be reached through a\ncommit protocol, of which the two-phase commit protocol is the most widely\napplied. In a two-phase commit protocol, a coordinator first checks whether\nall processes agree to perform the same operation (i.e., whether they all agree\nto commit), and in a second round, multicasts the outcome of that poll. A\nthree-phase commit protocol is used to handle the crash of the coordinator\nwithout having to block all processes to reach agreement until the coordinator\nrecovers.\nRecovery in fault-tolerant systems is invariably achieved by checkpointing\nthe state of the system on a regular basis.\nCheckpointing is completely\ndistributed. Unfortunately, taking a checkpoint is an expensive operation.\nTo improve performance, many distributed systems combine checkpointing\nwith message logging. By logging the communication between processes,\nit becomes possible to replay the execution of the system after a crash has\noccurred.\nDS 4.01\n \n\n\n09\nSECURITY\n\n\n546\nCHAPTER 9. SECURITY\nWhat makes a distributed system secure? Answering this question can\neasily fill entire books, and can certainly not be fully addressed in a single\nchapter. One of the challenges in making systems secure is that we need to\naddress a negative goal [Saltzer and Kaashoek, 2009]: we need to protect a\nsystem against all unauthorized actions. Proving or demonstrating that this\ngoal has been reached is generally (close to) impossible. Much easier is to\nshow that a positive goal has been accomplished, for example, showing that\nAlice can log in to a system.\nIn this chapter, we aim to provide a brief introduction into secure dis-\ntributed systems. We do so by mainly concentrating on two important mecha-\nnisms: authentication and authorization. Authentication is all about ensuring\nthat you are dealing with people and devices that have been properly identi-\nfied before providing access to a system. Authorization is all about ensuring\nthat identified entities, having access to the system, can perform only those\noperations they are allowed to execute.\nYet, authentication and authorization are not enough. It is equally impor-\ntant to ensure that operations are carried out correctly: have they affected data\nin a way that may leave the system in an inconsistent state, has the request to\nexecute an operation not been tampered with, etc.? This aspect of ensuring\nintegrity, or at the very least identifying that integrity has been affected, is\nessential for any secure system and will be discussed as well.\nThis brings us to perhaps one of the most discussed topics in the last\ndecade: confidentiality, or, to keep it simple, ensuring that information is kept\nprivate. Achieving confidentiality time and again turns out to be a difficult\nsubject, not in the least because keeping information private depends so much\non the context of that information. For example, in the European’s General\nData Protection Regulation (GDPR) it is stated that without explicit consent,\nno data set should allow for the identification of an individual. However,\nrealizing this otherwise indisputable reasonable requirement turns out to\nbe technically a very demanding task in general, yet solutions for specific\nsituations have been developed. Understanding the context turns out to be\nimportant, and as we shall see in this chapter, this actually holds for many\nsituations when trying to secure a distributed system.\nRealizing security mechanisms and establishing confidentiality and in-\ntegrity relies heavily on cryptography, which is a huge field in itself. Never-\ntheless, explaining the basic principles of cryptographic protocols necessary\nfor distributed systems is actually not too difficult and are also discussed in\nthis chapter.\n9.1\nIntroduction to security\nWe start our description of security in distributed systems by taking a look\nat some general security issues. First, it is necessary to define what a secure\nDS 4.01\n \n\n\n9.1. INTRODUCTION TO SECURITY\n547\nsystem is. We distinguish security policies from security mechanisms. Our\nsecond concern is to consider some general design issues for secure systems.\nFinally, we briefly discuss some cryptographic algorithms, which play a key\nrole in the design of security protocols.\n9.1.1\nSecurity threats, policies, and mechanisms\nSecurity in a computer system is strongly related to the notion of dependability.\nInformally, a dependable computer system is one that we justifiably trust\nto deliver its services [Laprie, 1995].\nDependability includes availability,\nreliability, safety, and maintainability. However, if we are to put our trust in a\ncomputer system, then confidentiality and integrity should also be considered.\nConfidentiality refers to the property that information is disclosed only\nto authorized parties.\nIntegrity is the characteristic that alterations to a\nsystem’s assets can be made only in an authorized way, ensuring accuracy\nand completeness during the lifetime of assets. In other words, improper\nalterations in a secure computer system should be detectable and recoverable.\nMajor assets of any computer system are its hardware, software, and data (see\nalso Beckers et al. [2015]).\nAnother way of looking at security in computer systems is that we attempt\nto protect the services and data it offers against security threats. Follow-\ning Saltzer and Kaashoek [2009] we distinguish the following three broad\nclasses of threats:\n1. Unauthorized information disclosure\n2. Unauthorized information modification\n3. Unauthorized denial of use\nIn all these cases, we explicitly mention unauthorized actions: actions taken by\npeople, software, or devices (and generally as a combination) that are, simply\nput, not allowed, or have not been intended to be allowed. To what extent\nallowing or disallowing actions has been sufficiently expressed or enforced is\nless important for qualifying a security threat as such: the intent is sufficient\nfor now.\nEach of these three classes of threats relate directly to confidentiality,\nintegrity, and availability, respectively.\nSimply stating that a system should be able to protect itself against all\npossible security threats is not the way to actually build a secure system.\nWhat is first needed is a description of security requirements, that is, a\nsecurity policy.\nA security policy describes precisely which actions the\nentities in a system are allowed to take and which ones are prohibited. Entities\ninclude users, services, data, machines, and so on. We will not go into the\nmany aspects of formulating security policies. A good introduction is given\nby Bishop [2019]. Once a security policy has been laid down, it becomes\n \nDS 4.01\n\n\n548\nCHAPTER 9. SECURITY\npossible to concentrate on the security mechanisms by which a policy can be\nenforced. We distinguish the following four important security mechanisms:\n1. Encryption\n2. Authentication\n3. Authorization\n4. Monitoring and auditing\nEncryption is fundamental to computer security. Encryption allows us to\ntransform data into something an attacker cannot understand. In other words,\nencryption provides a means to implement data confidentiality. In addition,\nencryption allows us to check whether data have been modified. It thus also\nprovides support for integrity checks.\nAuthentication is used to verify the claimed identity of a user, client,\nserver, host, device, and so on. In the case of clients, the basic premise is that\nbefore a service starts to perform any work on behalf of a client, the service\nmust learn the client’s identity (unless the service is available to all). Typically,\nusers are still authenticated through passwords, but there are many other\nways to authenticate clients.\nAfter a client has been authenticated, it is necessary to check whether\nthat client is authorized to perform the action requested. Access to records\nin a medical database is a typical example. Depending on who accesses the\ndatabase, permission may be granted to read records, to modify certain fields\nin a record, or to add or remove a record.\nMonitoring and auditing tools are used to trace accesses to assets, such\nas which clients are accessing or have accessed what, and in which way. It\nhas become increasingly important to not just record what has happened, but\nto continuously monitor what is going on in a system with the aim to detect\nany unauthorized intrusions. With the rise of advanced machine-learning\ntechniques, we are witnessing increasingly sophisticated intrusion detection\nsystems, which we shall discuss further in Section 9.6. Although auditing does\nnot really provide any protection against security threats, audit logs can be\nextremely useful for the analysis of a security breach, and subsequently taking\nmeasures against intruders. For this reason, attackers are generally keen not\nto leave any traces that could eventually lead to exposing their identity. In\nthis sense, logging accesses makes attacking sometimes a riskier business.\n9.1.2\nDesign issues\nSecurity principles\nA distributed system, or any computer system for that matter, must provide se-\ncurity services by which a wide range of security policies can be implemented.\nThere are a number of important design issues that need to be considered\nDS 4.01\n \n\n\n9.1. INTRODUCTION TO SECURITY\n549\nwhen implementing general-purpose security services. Various design princi-\nples have been devised over the years, starting with the influential list of eight\nsuch principles by Saltzer and Schroeder [1975]. Almost 40 years later, Smith\n[2012] concluded that many still thrive:\n• Fail-safe defaults\n• Open design\n• Separation of privilege\n• Least privilege\n• Least common mechanism\nFail-safe defaults are assuming that any set of defaults will generally not\nbe changed. Perhaps the most infamous example is the initial (user,password)\ncombination “(admin, admin)” or something similar, for edge devices. In many\ncases, the password is never changed, making edge devices the source of\ncountless security breaches. This principle states that defaults should already\nguarantee a good degree of protection. In particular, access decisions should\nbe based on permissions, not exclusions. For edge devices, it could mean\nthat each should be shipped with a default, unique strong password (which\nhas become common practice by now when purchasing and installing a new\nmodem, for example).\nThe principle of open design is all about not applying security by obscurity:\nit is essential that every aspect of a distributed system is open for review.\nEveryone should be able to see which mechanisms are being used, how they\nare being used, how they have been implemented, etc. An obvious problem\nwith this principle for modern distributed systems, is that many of them\nhave become so immense complex that a mere inspection of design and\nimplementation is no longer a guarantee for openness. Good documentation\nnext to the continuous focus on keeping systems and their components as\nsimple as possible are key. Unfortunately, simplicity is increasingly becoming\nmore of an ideal state than something that most engineers can realize.\nSeparation of privilege is about ensuring that truly critical aspects of a\nsystem can never be fully controlled by just a single entity. A top-secret file\nmay need to be double encrypted, with keys in the hands of two different\npeople. Likewise, shutting down critical services may need to be controlled\nby two authorized administrators, each having their own keys to push the\n(digital) button.\nThe principle of least privilege states that a process should operate with\nthe fewest possible privileges. As a practical example, in Unix systems, most\nprocesses (and thus users) cannot execute operations that are intended to\nbe executed by the root. It is therefore needed to explicitly execute the sudo\noperation, after which one would normally need to provide a password in\norder to gain administrative rights.\n \nDS 4.01\n",
      "page_number": 552
    },
    {
      "number": 55,
      "title": "Segment 55 (pages 560-567)",
      "start_page": 560,
      "end_page": 567,
      "detection_method": "topic_boundary",
      "content": "550\nCHAPTER 9. SECURITY\nFinally, the least common mechanism refers to designing systems in\nsuch a way that if multiple components require the same mechanism, then\nthey should all be offered the same implementation of that mechanism. An\nimportant motivation for this principle is that maintenance and simplicity is\nmuch easier to achieve with a single implementation than having a mechanism\nspread across the system, possibly with different implementations. A typical\nexample of this approach is that all users have access to the same library\n(implementation).\nSaltzer and Schroeder [1975] also mentioned three other principles, in-\ncluding economy of mechanism, complete mediation, and psychological\nacceptability. Economy of mechanism means making systems as simple as\npossible. Although this is still an excellent goal, achieving it is often close to\nimpossible considering how modern distributed systems are, literally, com-\nposed. Nevertheless, it also sometimes seems that designers have let go of this\nprinciple entirely. Accepting that systems can become complex in an almost\nuncontrolled fashion does not mean, however, that striving for simplicity\nshould be abandoned.\nComplete mediation means that every access to every object must be\nchecked when it comes to whether it is allowed. With the complex, distributed\nnature of modern systems, it has become extremely difficult to even figure\nout how and where an adversary has entered a system.\nFinally, psychological acceptance often translates to building the appro-\npriate user interfaces so that people can do only the right thing. It has a\nlot to do with building a mental model of how a system is operating, and\nsubsequently operate according to that model. Smith [2012] may be correct in\nstating that this aspect is receiving more attention than before, but that further\nadvancements are simply hindered by costs. This may change, however, as or-\nganizations are increasingly becoming aware of how vulnerable they are, only\nbecause their employees find it so difficult to work with modern information\nsystems.\nLayering of security mechanisms\nAn important issue in designing secure systems is to decide at which level\nsecurity mechanisms should be placed. A level in this context is related to\nthe logical organization of a system into a number of layers. For example,\ncomputer networks are often organized into layers following some reference\nmodel, as we discussed in Section 4.1.1. In Section 2.2, we introduced the\norganization of distributed systems consisting of separate layers for appli-\ncations, middleware, operating system services, and the operating system\nkernel. Combining the two organizations leads roughly to what is shown in\nFigure 9.1.\nTypically, what we have shown as low-level protocols encompass general\nnetwork-security solutions. An often-used solution is to set up a virtual\nDS 4.01\n \n\n\n9.1. INTRODUCTION TO SECURITY\n551\nFigure 9.1: The logical organization of a distributed system into several layers.\nprivate network, generally abbreviated to VPN. In essence, a VPN sets up a\ntunnel between two remote local networks, or between a host and a remote\nnetwork. The effect is that a computer on one network seems to be directly\nconnected to the remote network. Although not strictly necessary, a VPN\nnormally encrypts all traffic between its end points and operates at the level\nof the data link layer or the network layer, as we discussed in Section 4.1.1.\nGoing higher up the network stack, a well-known example is the transport-\nlayer security (TLS) service, which can be used to securely send messages\nacross a TCP connection. TLS forms the standard approach for secure commu-\nnication with Websites employing HTTPS. HTTPS establishes an authenticated\nconnection to a Website through which all data exchanged between a client\nand the server is encrypted.\nWhere VPNs and secure Website communication can be considered as\noperating at the level of networking protocols, this is less obvious for protocols\nsuch as SSH. The Secure Shell Protocol (SSH) is used to establish a secure\nremote login. As such, one can argue that it operates as an operating-system\nservice. Unlike HTTPS (which formally operates at the application level in\nterms of networking stacks), SSH comes with its own security protocol and\ndoes not rely on a transport-layer security service.\nOne of the main reasons for introducing middleware was to offer services\nthat are useful for a wide range of distributed applications, while at the same\nbeing independent of specific operating systems. One example that we will\ndiscuss in detail later is that of an authentication service such as Kerberos.\nThe service is indeed independent of a specific operating system (Kerberos\nhas been implemented for a wide range of operating systems, including\nWindows, many Unix versions, and other non-Unix systems). Other examples\nof secure middleware services include secure RPC, secure Web servers (think\nof WordPress), as well as a range of secure databases.\nFinally, an approach that is increasingly being adopted is developing end-\nto-end application-level security. In these cases, all secure communication\n \nDS 4.01\n\n\n552\nCHAPTER 9. SECURITY\nwithin the distributed application is handled by the application itself. There is\nno reliance on middleware security services. A well-known example is formed\nby modern user-messaging services like WhatsApp, Signal, and Telegram. Like-\nwise, distributed applications that, for example, make use of cloud storage\nservices, may be configured to first encrypt any data before sending it off to\nthe cloud, as is done with BoxCryptor.\nWhat these examples illustrate is that there are choices to be made con-\ncerning where and which security mechanisms will be deployed. Obviously,\napplication-level security need generally not rely on lower-level security guar-\nantees, yet the price to pay is that all mechanisms need to be deployed and\nmaintained by the application itself. This is not always the best choice, as it\ndoes make sense to separate application functionality from what is needed\nregarding security. Just imagine automating your own backup services for\na collection of remote computers. Making use of available operating-system\nlevel services for secure execution of remote commands and file transfers\nmakes life a lot easier.\nTrusted Computing Base\nDependencies between services regarding trust lead to the notion of a trusted\ncomputing base (TCB). A TCB is the set of all security mechanisms in a\n(distributed) computer system that are necessary and sufficient to enforce\na security policy, and that thus need to be trusted [Committee on National\nSecurity Systems, 2015]. The TCB encompasses firmware, hardware, software,\nas well as humans. The smaller the TCB, the better. The idea is that if the\nTCB can be clearly identified, we at least know what to concentrate on when\nscrutinizing a computer system to state that it is secure.\nIdentifying the TCB means identifying the modules that need to be trusted,\nand those that do not. Unfortunately, identifying the trusted modules is not\nthat simple, nor is it even that simple to design a system such that there is\nalways a clear distinction between trusted and untrusted modules.\nFor example, it is clear that a program needing administrative privileges\nto be executed will be part of the TCB, for the simple reason that if that\nprogram is compromised, an attacker may be able to do much more than\nwhat that program was designed for. But what about a Web-based service\nthat facilitates storage on a local server, such as ownCloud? Such a service\nis typically implemented as a collection of scripts that are executed by a\nprocess spawned by the Apache server. The spawned process runs entirely\nwithout any special privileges, yet the collection of scripts also include code for\nadding and removing users (separate from the users known to the underlying\noperating system). Are the set of scripts that make up this service to be trusted\nor not? Or more specifically, which scripts from this set are to be trusted?\nClearly, the answer to this question depends on the security specifications\nfor, in this case, the ownCloud service. If the policy states that users should be\nDS 4.01\n \n\n\n9.1. INTRODUCTION TO SECURITY\n553\nfully separated, then the scripts for user management and access control will\nneed to be inspected, but also the dependency of those scripts (and perhaps\nothers) on other modules that ownCloud depends on (such as a mysql database\nand the Apache server).\nThe ownCloud example illustrates that it may not be that easy to separate\ntrusted from untrusted modules, especially when no security policy has been\nexplicitly specified, or is perhaps otherwise incomplete. The same may hold\nwhen designing for security. For example, often we assume a so-called honest-\nbut-curious server: a server that behaves according to some protocol, but in\nthe worst case keeps track of all the things it does [Goldreich, 2009]. Making\nsuch an assumption may be fine, but what measures have been taken that\njustify such an assumption? Equally important, are those measures sufficient?\nWhen components or modules are complex, it may be very difficult to establish\nwhether a module actually satisfies its specifications and to what extent we\nmay need to classify it as trusted or not.\nPrivacy\nIf there is one thing clear when it comes to designing for secure distributed\nsystems, then it is the role of data. In this era of data and notably the effect\nit has on the personal lives of many, protecting privacy has become a major\nissue for distributed systems. Privacy and confidentiality are closely related,\nyet are different. Following Francis [2008], one could state that privacy is\ninvaded, whereas confidentiality is breached. Important is to recognize that\njust ensuring confidentiality, that is, data and information is not disclosed in\nany unauthorized manner, is not enough to guarantee privacy. In this light,\none can understand why Nissenbaum [2010] states that the right to privacy is\nabout “a right to appropriate flow of personal information.” In other words,\ncontrolling who gets to see what, when, and how. This also implies, for\nexample, that a person should be able to stop and revoke a flow of personal\ninformation.\nDiscussions on how to design distributed systems that meet such privacy\nrequirements have only recently started to mature. One approach is to con-\ncentrate on ownership, such as done in Solid [Sambra et al., 2016], which\nessentially puts control on personal information at a single person. To what\nextent this will be sufficient remains to be seen. A point of debate is whether\nownership by itself is sufficient to provide the necessary privacy guarantees.\nAnother approach is to look at what regulations state and to what extent\nit is possible to design systems that comply to those regulations. Impor-\ntant in this respect is the General Data Protection Regulation, or simply\nGDPR [Voigt and Von dem Bussche, 2017], which was installed in 2016. The\nGDPR is a comprehensive set of regulations aiming to protect personal data.\nAs with many regulations, it is yet unclear to what extent one can develop a\ntruly GDPR-compliant distributed system, but it can be argued that making\n \nDS 4.01\n\n\n554\nCHAPTER 9. SECURITY\na system GDPR-compliant after the fact may be much more difficult, if not\nimpossible.\nLike Solid, Schwarzkopf et al. [2019] follow an approach in which a user\nhas a separate, privately owned and controlled database with personal in-\nformation, denoted as a shard. Acknowledging that the real challenge lies\nin keeping track of how personal information flows into other systems, the\nauthors argue for designing a distributed system by considering it to consist\nof as being a large dataflow computation. A user can contribute her shard\nto the system, but equally remove it and along with that removal, revoke\nparticipation in all related data flows.\nAs an example, consider a collection of users, each maintaining their own\nshard. A shard represents a user’s contributions to an online social network\nwith three elements:\n• Some personal information, such as name, organization, etc.\n• A set of connections, each connection referring to another shard.\n• A set of posts, as is common in many social networks, often as a reaction\nto another post.\nAn application can be developed that builds a tree consisting of posts and\nreactions to posts. The development of that tree starts with a single, new\npost P and implements the function react taking the original post P and a\n(dynamic) list of reactions R1, R2, . . . , Rn as input. Each reaction is, of course,\nalso a post and can be reacted to. When Alice at a certain point decides she\nwants to completely withdraw from the discussion, she can simply withdraw\nher post(s), leading to a new tree. All reactions to her posts may necessarily\nbe removed as well, as each of her posts operates as the root of a branch. This\ncan be done automatically, assuming that the function react is continuously\nupdated on its inputs, and we assume that removal of the post that led to\nreactions, recursively leads to the removal of the entire branch.\nMore intricate examples are described by Agarwal et al. [2022], yet the\nessence is that removal of an element as part of a dataflow leads to an update\nof that flow but without the personal information represented by that element.\nThe example above also illustrates that we may not be out of the woods yet,\nfor what happens if Alice is explicitly mentioned in one of the reactions? In\nother words, more needs to be done to ensure that all references to Alice and\nher posts are indeed removed.\nThis example already illustrates that taking a database perspective may\nhelp in designing GDPR-compliant systems. Shastri et al. [2020] show that\nsuch a perspective may indeed be fruitful, yet the real challenge is maintaining\na large amount of metadata, as shown in Figure 9.2. The authors come to\nthe conclusion that extending databases so that a system can meet GDPR\nrequirements is doable from a functional point of view, but has serious adverse\neffect on performance and, in turn, on the scalability of solutions.\nDS 4.01\n \n\n\n9.2. CRYPTOGRAPHY\n555\nGDPR regulation\nImpact on database systems\nAttributes\nActions\nCollect data for explicit purposes\nPurpose\nMetadata indexing\nDo not store data indefinitely\nTTL\nTimely deletion\nInform customers about GDPR\nmetadata associated with their data\nPurpose, TTL,\nOrigin, Sharing\nMetadata indexing\nAllow customers to access their data\nPerson id\nMetadata indexing\nAllow customers to erase their data\nTTL\nTimely deletion\nDo not use data for objected reasons\nObjections\nMetadata indexing\nAllow customers to withdraw from\nalgorithmic decision-making\nAutomated\ndecisions\nMetadata indexing\nSafeguard and restrict access to data\nAccess control\nDo not grant unlimited access to data\nAccess control\nAudit operations on personal data\nAudit trail\nMonitor and log\nImplement appropriate data security\nEncryption\nShare audit trails from affected\nsystems\nAudit trail\nMonitor and log\nFigure 9.2: The effects on (distributed) databases when designing for GDPR\ncompliance (adapted from [Shastri et al., 2020]).\n9.2\nCryptography\nLet us now draw attention to an essential mechanism in developing secure\ndistributed systems, namely the application of cryptographic solutions. In\nthe following, we first pay attention to some basic cryptographic functions,\nincluding symmetric and asymmetric cryptosystems, and secure hashing, to\nthen continue with managing security.\n9.2.1\nBasics\nFundamental to security in distributed systems is the use of cryptographic\ntechniques. The basic idea of applying these techniques is simple. Consider a\nsender S wanting to transmit message m to a receiver R. To protect the message\nagainst security threats, the sender first encrypts it into an unintelligible\nmessage m′, and subsequently sends m′ to R. R, in turn, must decrypt the\nreceived message into its original form m.\nEncryption and decryption are accomplished by using cryptographic meth-\nods parameterized by keys, as shown in Figure 9.3. The original form of the\nmessage that is sent is called the plaintext, shown as P in Figure 9.3. The\nencrypted form is referred to as the ciphertext, illustrated as C.\nTo describe the various security protocols that are used in building security\nservices for distributed systems, it is useful to have a notation to relate\n \nDS 4.01\n\n\n556\nCHAPTER 9. SECURITY\nFigure 9.3: Intruders and eavesdroppers in communication.\nplaintext, ciphertext, and keys. Following common notational conventions, we\nwill use C = EK(P) to denote that the ciphertext C is obtained by encrypting\nthe plaintext P using key EK. Likewise, P = DK(C) is used to express the\ndecryption of the ciphertext C using key DK, resulting in the plaintext P.\nReturning to our example shown in Figure 9.3, while transferring a mes-\nsage as ciphertext C, there are three different attacks that we need to protect\nagainst, and for which encryption helps. First, an intruder may intercept the\nmessage without either the sender or receiver being aware that eavesdropping\nis happening. Of course, if the transmitted message has been encrypted in\nsuch a way that it cannot be easily decrypted without having the proper key,\ninterception is useless: the intruder will see only unintelligible data. (By the\nway, the fact alone that a message is being transmitted may sometimes be\nenough for an intruder to draw conclusions. For example, if during a world\ncrisis, the amount of traffic into the White House suddenly drops dramati-\ncally while the amount of traffic going into a certain mountain in Colorado\nincreases, there may be useful information in knowing that.)\nThe second type of attack that needs to be dealt with is that of modifying\nthe message. Modifying plaintext is easy; modifying ciphertext that has been\nproperly encrypted is much more difficult because the intruder will first have\nto decrypt the message before it can be meaningfully modified. In addition,\nthe intruder will also have to properly encrypt it again, or otherwise the\nreceiver may notice that the message has been tampered with.\nThe third type of attack is when an intruder inserts encrypted messages\ninto the communication system, attempting to make R believe these messages\ncame from S. Again, encryption can help protect against such attacks. Note\nthat if an intruder can modify messages, she can also insert messages.\nThe art and science of devising algorithms for cryptographic systems has\na long and fascinating history [Kahn, 1967], and building secure systems is\nDS 4.01\n \n\n\n9.2. CRYPTOGRAPHY\n557\noften surprisingly difficult. It is beyond the scope of this book to discuss any\nof these algorithms in detail. Information on cryptographic algorithms can be\nfound in [Ferguson et al., 2010] and [Smart, 2016].\n9.2.2\nSymmetric and asymmetric cryptosystems\nThere is a fundamental distinction between different cryptographic systems,\nbased on whether the encryption and decryption key are the same. In a\nsymmetric cryptosystem, the same key is used to encrypt and decrypt a\nmessage:\nif P = DK(EK(P)) then DK = EK.\nSymmetric cryptosystems are also referred to as secret-key or shared-key\nsystems because the sender and receiver are required to share the same key,\nand to ensure that protection works, this shared key must be kept secret; no\none else is allowed to see the key. We will use the notation KA,B to denote a\nkey shared by A and B.\nIn an asymmetric cryptosystem, the keys for encryption and decryption\nare different, but together form a unique pair. In other words, there is a\nseparate key EK for encryption and one for decryption, DK, such that\nif P = DK(EK(P)) then DK ̸= EK.\nOne of the keys in an asymmetric cryptosystem is kept private; the other is\nmade public. For this reason, asymmetric cryptosystems are also referred to\nas public-key systems. In what follows, we use the notation PKA to denote a\npublic key belonging to A, and SKA as its corresponding private (i.e., secret)\nkey.\nWhich one of the encryption or decryption keys that is actually made\npublic depends on how the keys are used. For example, if Alice wants to send\na confidential message m to Bob, she should use Bob’s public key to encrypt\nthe message. Because Bob is the only one holding the associated and private\ndecryption key, he is also the only person who can decrypt the message:\nif m is to be kept private: C = PKB(m).\nOn the other hand, suppose that Bob wants to know for sure that the message\nhe just received actually came from Alice.\nIn that case, Alice can keep\nher encryption key private to encrypt the messages she sends. If Bob can\nsuccessfully decrypt a message using Alice’s public key (and the plaintext\nin the message has enough information to make it meaningful to Bob), he\nknows that message must have come from Alice because the decryption key\nis uniquely tied to the encryption key:\nif m is to be authenticated: C = SKA(m).\nWe return to digitally signing messages shortly.\n \nDS 4.01\n",
      "page_number": 560
    },
    {
      "number": 56,
      "title": "Segment 56 (pages 568-576)",
      "start_page": 568,
      "end_page": 576,
      "detection_method": "topic_boundary",
      "content": "558\nCHAPTER 9. SECURITY\nAn aspect of asymmetric cryptosystems that is becoming increasingly\nimportant is that of homomorphic encryption. What it boils down to is that\nwhen using homomorphic encryption, mathematical operations on plaintext\ncan also be performed on the corresponding ciphertext. In particular, if x and\ny are two numbers, then\nEK(x) ⋆EK(y) = EK(x ⋆y)\nwhere “⋆” is some mathematical operation, typically an addition or multiplica-\ntion. The importance of homomorphic encryption cannot be underestimated.\nBy now, we understand what it takes to store data safely on a remote, un-\ntrusted server: simply encrypt it with a public key before sending it to the\nserver. This is what tools such as BoxCryptor do. However, whenever stored\ndata needs to be operated on, servers generally require that the data is avail-\nable as plaintext. Homomorphic encryption changes that: a server can apply\noperations on encrypted data and the result (also automatically encrypted\nwith the same key) can be safely stored as well, or used in other computations.\nThere is only one problem with homomorphic encryption: its general form\n(known as full homomorphic encryption or simply FHE) is performance-\nwise slow. FHE supports addition and multiplication, which is enough to\nimplement any mathematical operation. Currently, FHE implementations are\noften too slow to be generally applicable. In contrast, there are also partial\nhomomorphic encryption (PHE) schemes, which support either addition\nor multiplication, for which efficient implementations exist. However, PHE\nschemes do require often very specific applications. For a good overview of\nhomomorphic encryption, see Acar et al. [2018].\nNote 9.1 (Example: Counting pedestrians over time and space)\nAs a practical and advanced example of how homomorphic encryption can be\napplied, consider the following. In many cities, it has become common practice to\nmonitor pedestrian behavior by simply picking up Wi-Fi signals from carry-on\ndevices, notably Wi-Fi–enabled smartphones. Most of these signals are network\npackets carrying the unique MAC address of the device. By extracting the MAC\naddress as a device identifier, it becomes possible to track movements. That by\nitself need not necessarily be a problem, but without having explicit consent from\na device owner, it is simply a serious infringement of privacy.\nInterestingly, many cities are not interested in actually tracking individuals.\nThey are interested in simple questions such as how many people moved from\none location to another, or what is the average time that people stayed at a specific\nlocation. Such questions are easy to answer when you know the identifier of\na device, yet become much more difficult when keeping those identifiers long\nenough to come to an answer, is simply forbidden.\nStanciu et al. [2020] propose a solution that allows to count devices over\ntime and space without the need to keep device identifiers. A setup consists\nof a collection of sensors, each sensor essentially being a Wi-Fi–packet sniffer.\nDS 4.01\n \n\n\n9.2. CRYPTOGRAPHY\n559\nDuring a short epoch (typically a few minutes), a sensor picks up Wi-Fi packets,\nextracts MAC addresses, and subsequently stores (a pseudonymized version) of\neach MAC address in a so-called Bloom filter. A Bloom filter is a vector of m\nbits, initially all set to 0 [Bloom, 1970]. Using a collection of k hash functions,\nan element x is added to a Bloom filter by setting the position hi(x) to 1 for\neach of the k hash functions. Each element is thus represented as an m-bit vector\nconsisting of exactly k bits set to 1. More elements are added by performing a\nbitwise OR operation each time an element is added.\nA Bloom filter has the important property that one cannot retrieve the elements\nof the set it represents other than by exhaustively testing for all possible elements.\nIn other words, a Bloom filter supports only membership tests. To check if x is in\na set A represented by the Bloom filter BF, one needs to check if every position\nhi(x) has been set to 1:\nx ∈A only if\nk\n∏\ni=i\nBF[hi(x)] = 1\nCounting is possible by a simple estimation n∗of the number of elements in a\nBloom filter [Swamidass and Baldi, 2007]:\nn∗= −m\nk ln(1 −X\nm )\nwhere X is the number of nonzero elements in the Bloom filter.\nCounting the number of devices that were at one location and later at another,\nthen resorts to taking the intersection of two Bloom filters and estimating the size\nof the intersection. Likewise, checking how many people stayed at a location for\na specific, long time, amounts to constructing intersections of Bloom filters and\nestimating the size. In all cases, there is, strictly speaking, no need to test for\nmembership.\nHowever, using Bloom filters in the clear is not safe: a simple brute-force\nattack can easily give a very good impression of detected devices, and thus also\nthe ability to track devices. Of course, when the Bloom filters are encrypted, de-\ntecting actual devices becomes more difficult. Moreover, computing intersections\nshould preferably be done on encrypted Bloom filters. Fortunately, computing\nan intersection is nothing else but constructing a Bloom filter through a bitwise\nAND operation, which is equivalent to a multiplication of 0’s and 1’s. Specifically,\nif we need to compute the intersection of two Bloom filters A and B, we do so\nusing their homomorphically encrypted versions and compute:\n∀i : PK(A ⊙B)[i] = PK(A[i]) · PK(B[i])\nwhere “⊙” represents an elementwise multiplication of two vectors. The basic\nidea is that a third party, say Alice, who needs the value of a count provides a\npublic key PK by which each sensor homomorphically encrypts the entries of its\nBloom filters. Note that if a value p is encrypted, leading to p1 = PK(p), and that\nsame value is encrypted a next time, leading to p2 = PK(p), the two encrypted\n \nDS 4.01\n\n\n560\nCHAPTER 9. SECURITY\nvalues will be different: p1 ̸= p2 and an observer will not be able to distinguish\nthe two underlying values to be the same.\nAn encrypted filter can be handed out to a separate server without disclosing\nany detections. That server also computes intersections, but completely ignorant\nof the results, for the simple reason that it cannot decrypt any of the filters. The\nonly thing the server does is shuffle the elements of any (computed) Bloom filter\nbefore handing it to Alice, who owns the private key SK associated with PK. This\nshuffling is important: when Alice decrypts the result, she will have a Bloom\nfilter that has nothing to do with the original, unshuffled Bloom filter. One might\nsay that it represents a completely random set of detections. The only thing in\ncommon with the original filter is the number of nonzero elements, from which\nshe can then estimate the size and thus the number of detections. This number is\nthe only information that Alice can get from the server’s response.\n9.2.3\nHash functions\nOne final application of cryptography in distributed systems, is the use of\nhash functions. A hash function H takes a message m of arbitrary length as\ninput and produces a bit string h having a fixed length as output:\nh = H(m) with length of h fixed.\nA hash h is somewhat comparable to the extra bits that are appended to a\nmessage in communication systems to allow for error detection, such as a\ncyclic-redundancy check (CRC). A well-known application is securely storing\npasswords: instead of storing a password pw, we keep only H(pw). Then,\nwhen Alice logs in with a password pw′, we need merely check if H(pw) =\nH(pw′).\nHash functions that are used in cryptographic systems, also known as\ntrapdoors, have a number of essential properties. First, they are one-way\nfunctions, meaning that it is computationally infeasible to find the input\nm that corresponds to a known output h. On the other hand, computing h\nfrom m is easy. Second, they have the weak collision resistance property,\nmeaning that given an input m and its associated output h = H(m), it is\ncomputationally infeasible to find another, different input m′ ̸= m, such\nthat H(m) = H(m′). Finally, cryptographic hash functions also have the\nstrong collision resistance property, which means that, when given only H,\nit is computationally infeasible to find any two different input values m and\nm′, such that H(m) = H(m′). In this way, an attacker will need to guess\npasswords instead of simply stealing or trying to derive them what is already\nknown.\nSimilar properties must apply to any encryption function E and the keys\nthat are used. For any encryption function EK, it should be computationally\ninfeasible to find the key EK when given the plaintext P and associated\nDS 4.01\n \n\n\n9.2. CRYPTOGRAPHY\n561\nciphertext C = EK(P). Likewise, analogous to collision resistance, when given\na plaintext P and a key EK, it should be effectively impossible to find another\nkey EK′ such that EK(P) = EK′(P).\nDigital signatures\nLet us now take a look at an often-used application of hash functions, namely\nplacing digital signatures as part of sending messages. Consider the situation\nin which Bob has just sold Alice a collector’s item of some vinyl record for\n$500. The whole deal was done through e-mail. In the end, Alice sends Bob a\nmessage confirming that she will buy the record for $500. There are at least\ntwo issues that need to be taken care of regarding the integrity of the message.\n1. Alice needs to be assured that Bob will not maliciously change the\n$500 mentioned in her message into something higher, and claim she\npromised more than $500.\n2. Bob needs to be assured that Alice cannot deny ever having sent the\nmessage, for example because she had second thoughts.\nThese two issues can be dealt with if Alice digitally signs the message in\nsuch a way that her signature is uniquely tied to its content. The unique\nassociation between a message and its signature prevents that modifications to\nthe message will go unnoticed. In addition, if Alice’s signature can be verified\nto be genuine, she cannot later repudiate the fact that she signed the message.\nThere are several ways to place digital signatures. One popular form is to\nuse a public-key cryptosystem. When Alice sends a message m to Bob, she\nencrypts it with her private key SKA, and sends it off to Bob. If she also wants\nto keep the message content a secret, she can use Bob’s public key and send\nPKB(m, SKA(m)), which combines m and the version signed by Alice:\nAlice: send C = PKB([m, sig]) with sig = SKA(m).\nWhen Bob receives the ciphertext C, he decrypts it with his private key SKB\nand uses Alice’s public key to verify the signature:\nBob: receive and decrypt [m, sig] = SKB(C) and verify m = PKA(sig).\nIf Bob can be assured that the public key is indeed owned by Alice, then\ndecrypting the signed version of m and successfully comparing it to m can\nmean only that it came from Alice. Alice is protected against any malicious\nmodifications to m by Bob because Bob will always have to prove that the\nmodified version of m was also signed by Alice. In other words, the decrypted\nmessage alone essentially never counts as proof. It is also in Bob’s own interest\nto keep the signed version of m to protect himself against repudiation by Alice.\nAn issue with the scheme just described is that Alice encrypts the entire\nmessage with her private key. Such an encryption may be costly in terms of\n \nDS 4.01\n\n\n562\nCHAPTER 9. SECURITY\nprocessing requirements and is actually unnecessary. Recall that we need to\nuniquely associate a signature with only a specific message. A cheaper and\narguably more elegant scheme is to use a message digest.\nA message digest is a fixed-length bit string h that has been computed\nfrom an arbitrary-length message m through a cryptographic hash function H.\nIf m is changed to m′, its hash H(m′) will be different from h = H(m) so that\nit can easily be detected that a modification has taken place.\nTo digitally sign a message, Alice can first compute a message digest and\nsubsequently encrypt the digest with her private key. The encrypted digest is\nsent along with the message to Bob:\nAlice: send [m, sig] with sig = SKA(H(m)).\nWhen Bob receives the message and its encrypted digest, he need merely\ndecrypt the digest with Alice’s public key, and separately calculate the message\ndigest. If the digest calculated from the received message and the decrypted\ndigest match, Bob knows the message has been signed by Alice:\nBob: receive [m, sig], compute h′ = H(m) and verify h′ = PKA(sig).\nNote that the message itself is sent as plaintext: everyone is allowed to read it.\nIf confidentiality is required, then the message should also be encrypted with\nBob’s public key.\nThere are still a number of problems with both schemes, although the\nprotocols are correct. First, the validity of Alice’s signature holds only as\nlong as Alice’s private key remains a secret. If Alice wants to bail out of\nthe deal even after sending Bob her confirmation, she could claim that her\nprivate key was stolen before the message was sent. We will later describe\nhow blockchains may help in keeping a decentralized account of transactions,\nsuch as those between Alice and Bob.\nAnother problem occurs when Alice decides to change her private key.\nDoing so may in itself be not such a bad idea, as changing keys from time to\ntime generally helps against intrusion. However, once Alice has changed her\nkey, her statement sent to Bob, becomes worthless. What may be needed in\nsuch cases is a central authority that keeps track of when keys are changed, in\naddition to using timestamps when signing messages. We look at this issue\nnext; Figure 9.4 summarizes the notations and abbreviations we use in the\nmathematical expressions throughout this book.\n9.2.4\nKey management\nSo far, we have described cryptographic protocols in which we (implicitly)\nassumed that various keys are readily available. For example, in the case of\npublic-key cryptosystems, we assumed that a sender of a message had the\npublic key of the receiver at its disposal so that it could encrypt the message\nDS 4.01\n \n\n\n9.2. CRYPTOGRAPHY\n563\nNotation\nDescription\nKA,B\nSecret key shared by A and B\nPKA\nPublic key of A\nSKA\nPrivate (secret) key of A\nEK(P)\nEncryption of plaintext P using key EK (or key K)\nDK(C)\nDecryption of ciphertext C using key DK (or key K)\nH(m)\nThe hash of m computed using function H\n[m]A\nThe message m digitally signed by A\nFigure 9.4: Notations used in this chapter.\nto ensure confidentiality. Likewise, when verifying the signature of a message,\nthe receiver will need to have the public key of the sender. In both these\nexamples, we also need to be sure that the public key being used actually\nbelongs to the presumed owner.\nHowever, establishing and distributing keys is not a trivial matter. For\nexample, digitally distributing secret keys without using encryption is out of\nthe question and there are cases where we even have to resort to out-of-band\nmethods. Also, mechanisms are needed to revoke keys, that is, prevent a key\nfrom being used after it has been compromised or invalidated.\nKey establishment\nHow are keys actually established? Let us take a look at a simple and widely\ndeployed approach for automatically establishing remote secure connections\nthrough SSH. As we mentioned, SSH allows a person to securely log in to\na remote computer. We can also use SSH to let a user alice at computer\nA log in as user bob at computer B using a (public, private)-key pair. An\nactual authentication protocol will be described later; here we are interested\nin establishing and distributing keys in the SSH system using the openSSL\nframework.\nFirst, Alice needs to generate a (public, private)-key pair, which can be\ndone as follows:1\nssh-keygen -f a\nThis will generate two keys: a private key contained in the file a and a\ncorresponding public key in the file a.pub. The file a will be stored in a special\ndirectory (namely in .ssh in Alice’s home directory). The file a.pub will have\nto be transferred to computer B, which can be done as follows:\n1We are deliberately taking an extremely simple example that works in practice yet is not\nvery sophisticated.\n \nDS 4.01\n\n\n564\nCHAPTER 9. SECURITY\nssh-copy-id -i a bob@B\nWe assume that B is the actual computer name that can be used when Alice\nwould normally log in to B as user bob. It is important to note that Alice is\nassumed to know the password of Bob at B. The ssh-copy-id command will\nask for Bob’s password at B before completing the transfer. If successful, the\nfile a.pub will be appended to a special file in the .ssh directory in the home\ndirectory of user bob at B. From that moment on, Alice can simply log in to B\nthrough the command\nssh bob@B\nwhere she will no longer be asked for a password.\nThis simple example illustrates two important issues. First, security keys\nare simply generated through programs such as ssh-keygen and stored in files\nthat can be distributed as any other file (or should be kept secret and properly\nprotected against unauthorized access). Second, we can easily distribute keys\nprovided we have the authorization to do so. That authorization can come from\nknowing a password, but there are other means as well, as we discuss shortly.\nInterestingly, in lack of authorization (and thus authentication), we would\nneed to rely on the receiving party to trust the claimed ownership of the keys.\nWe return to trust below.\nLet us move on to a more sophisticated example and consider how session\nkeys can be established. As it name suggests, a session key is a temporary\nshared secret key that is used during a single communication session between\ntwo parties. A session typically consists of a series of message exchanges.\nWhen the session ends, the session key is discarded and never used again.\nAs we shall also explain later, an important reason for using session keys is\nthat one should use long-lasting keys, be they shared, public, or private as\nlittle as possible: the more data that is used for encrypting or decrypting data,\nthe easier it becomes to discover the keys used. Two ways immediately come\nto mind, by which Alice and Bob can agree on establishing a session key. In\na symmetric cryptosystem and assuming that Alice and Bob already have a\nlong-lasting shared secret key KA,B, Alice could decide to generate a session\nkey sk and send it to Bob as the message\nAlice: send m = KA,B(sk).\nLikewise, in an asymmetric cryptosystem, Alice could encrypt the key with\nBob’s public key:\nAlice: send m = PKB(sk).\nAfter that, sk can be used for encrypting and decrypting messages for as long\nas the session lasts.\nBoth methods require that the communicating parties already have the\nmeans available to send and receive encrypted messages. In other words,\nsome form of key establishment and distribution must have taken place before.\nDS 4.01\n \n\n\n9.2. CRYPTOGRAPHY\n565\nAn elegant scheme that is widely applied for establishing a shared key\nacross an insecure channel is the Diffie-Hellman key exchange [Diffie and\nHellman, 1976]. The protocol works as follows. Suppose that Alice and Bob\nwant to establish a shared secret key. The first requirement is that they agree\non two large numbers, p and g that are subject to a number of mathematical\nproperties (which we do not discuss here). Both p and g can be made public;\nthere is no need to hide them from outsiders. Alice picks a large random\nnumber, say x, which she keeps secret. Likewise, Bob picks his own secret\nlarge number, say y. At this point, there is enough information to construct a\nshared secret key, as shown in Figure 9.5.\nFigure 9.5: The principle of Diffie-Hellman key exchange.\nAlice starts by sending gx mod p to Bob, along with p and g. It is impor-\ntant to note that this information can be sent as plaintext, as it is virtually\nimpossible to compute x given gx mod p. When Bob receives the message,\nhe subsequently calculates (gx mod p)y which is mathematically equal to\ngxy mod p. In addition, he sends gy mod p to Alice, who can then compute\n(gy mod p)x = gxy mod p. Consequently, both Alice and Bob, and only those\ntwo, will now have the shared secret key gxy mod p. Note that neither of them\nneeded to make their private number (x and y, respectively), known to the\nother. Diffie-Hellman can also be viewed as a public-key cryptosystem. In the\ncase of Alice, x is her private key, whereas gx mod p is her public key.\nIn practice, Alice will not send p and g to Bob, but first negotiate which\nso-called Diffie-Hellman group they will use. In essence, the choice of group\ndefines p and g, but also exactly which cryptographic algorithm to use. In\nour example, we have used gx mod p, yet an alternative is to use a so-called\nelliptic curve.\nIt is also relevant to note that in practice, Alice and Bob will regularly\nchange their respective private keys. In particular, new values for x and y may\nbe chosen for each new communication session between Alice and Bob, in\nwhich case we speak of ephemeral Diffie-Hellman key exchange. As we shall\nsee, the Diffie-Hellman key exchange has shown to be a powerful security\nmechanism throughout many practical situations. In the following note, we\ndiscuss another example of its application.\n \nDS 4.01\n\n\n566\nCHAPTER 9. SECURITY\nNote 9.2 (Advanced: Computing while keeping data private)\nIn many distributed systems, we see that security comes almost as an afterthought:\ndesigners focus on providing functionality to later adjust the system to meet\nspecific security requirements. For long, it has been thought that functionality\nmay actually suffer from imposing security (or privacy) demands, yet it is unclear\nto what extent there is actually a tradeoff to consider [Rowe et al., 2012]. Let us\nlook at an increasingly popular technique that makes use of Diffie-Hellman key\nexchange.\nAs also mentioned in our discussion on privacy, an important challenge that\nmany distributed systems will need to face is to deal with enormous amounts of\ndata while preserving privacy. A particular case is when private data is essential\nto compute important statistics. A simple example is computing who has the\nhighest salary among a number of people without anyone having to reveal their\nsalary. Along the same lines, we may wish to compute the number of votes cast\nfor a specific candidate without revealing who voted for whom.\nWhat we are dealing with is known as (secure) multiparty computations\n(MPC). For a long time, it has been a field of cryptography that was difficult to put\ninto practice for its low performance, but the last decade has shown impressively\nbetter implementations that make MPC a practical tool for secure distributed\ncomputations. At the same time, one may need to devise application-specific\nsolutions for the simple reason that there are too many parties to make general\ntools practically feasible. We will discuss an example in which resource constraints\ndemand an alternative solution.\nIt is beyond the scope of this chapter to go into any significant depth con-\ncerning MPC; the interested reader is referred to Evans et al. [2018] for a good\nintroduction. Let us first consider an important building block for MPC, namely\noblivious transfer. In this case, we assume Alice has n secret messages m1, . . . , mn,\nwhile Bob is interested (and allowed) to know only one of those messages. Which\nspecific message he wants to know should be kept secret to Alice, while at the\nsame time all other messages should be kept secret to Bob. Assume Bob wishes\nto know the ith message. In that case, he generates a number Q that Alice, in turn,\nuses to generate a total of n different keys PK1, . . . , PKn to encrypt each message:\nm∗\ni = PKi(mi)\nBob, meanwhile, uses Q to generate a decryption key SKi that matches only PKi.\nClearly, when Bob receives the set of encrypted messages m∗\n1, . . . , m∗n there will be\nonly a single message that he can decrypt, namely m∗\ni . Using SKi any attempt to\ndecrypt m∗\nj (with i ̸= j) will fail.\nAn important assumption for this scheme to work, is that having only Q,\nBob cannot successfully generate any decryption key SKj for PKj. For the case\nthat n = 2, there is an elegant, simple protocol that achieves this, based on a\nDiffie-Hellman key exchange [Chou and Orlandi, 2015]. The protocol is shown\nin Figure 9.6 (note that all computations are assumed to take place in Zp, that is,\nmodulo p).\nDS 4.01\n \n",
      "page_number": 568
    },
    {
      "number": 57,
      "title": "Segment 57 (pages 577-586)",
      "start_page": 577,
      "end_page": 586,
      "detection_method": "topic_boundary",
      "content": "9.2. CRYPTOGRAPHY\n567\nFigure 9.6: A simple 1-out-of-2 oblivious transfer.\nIn the protocol, besides having his own private key y, Bob also has a choice for\nan additional binary parameter, denoted here as c. The value of c determines what\nBob will do in response to the initial message from Alice. Assume first that c = 0,\nin which case Bob will choose Q = gy. This is, actually, the regular Diffie-Hellman\nkey exchange: Bob computes BK = gxy, while Alice also computes AK1 = gxy,\nafter which she encrypts m1 using the now shared secret key gxy = BK. Alice also\ncomputes AK2 = gxy−x2, yet using BK is useless. Moreover, because Bob does not\nhave x, computing gxy−x2 is computationally infeasible.\nNow assume that c = 1, so that Bob sets Q = gx+y. Alice computes AK1 =\ngx2+xy and AK2 = (gxgy/gx)x = gxy. In other words, we now see that BK = AK2\nallowing Bob to successfully decrypt only message m∗\n2. He will never get to know\nm∗\n1, while Alice in this setup will also never know which message Bob was able\nto decrypt.\nTo illustrate how oblivious transfer is used in MPC, suppose we have two\nparties P1 and P2 who need to compute a function F(a, b) on two input values:\na secret a known only to P1 and a secret b known only to P2. For simplicity,\nlet us also assume that a ∈X and b ∈Y and that both X and Y are finite, i.e.,\neach contains only a finite number of elements. In that case, we can construct a\nmatrix F of size |X| · |Y| with F[i, j] = F(xi, yj) for each pair (xi, yj) ∈X × Y. The\nproblem we want to solve is to let both P1 and P2 compute F(a, b) yet the other\nshould not be able to discover b or a, respectively.\nTo this end, P1 generates |X| · |Y| unique key pairs (Ki, Kj) and encrypts each\nentry of the table F, leading to a table F∗[i, j] = Ki(Kj(F(xi, xj))). Assume that a\ncorresponds to the ith element of X (i.e., a = xi). P1 then sends F∗and Ki to P2,\nbut not before having permuted all its elements. In addition, it sends Q using a\n1-out-of-|Y| oblivious transfer. Assume that b = yj. Using Q, P2 can construct\nthe key Kj, and only the key Kj that allows it to decrypt F∗[i, j], corresponding\nto F(a, b). All other entries will remain a secret to P2, while at the same time, P1\nwill not know about b = yj.\nNote that permuting the table before sending it to P2 is essential, for oth-\nerwise a and b could be looked up. Also, we assume that P2 can recognize\nthat it decrypted the correct entry, for how would it otherwise know that the\ndecrypted value makes sense? This recognition can be done by adding some extra\ninformation, such as a specific bit string that pops up after successful decryption.\n \nDS 4.01\n\n\n568\nCHAPTER 9. SECURITY\nKey distribution\nOne of the more difficult parts in key management is the actual distribution\nof initial keys. In a symmetric cryptosystem, the initial shared secret key must\nbe communicated along a secure channel: a communication channel that, in\nprinciple, provides mutual authentication of the two communicating parties,\nas well as confidentiality for the messages that are exchanged, as shown in\nFigure 9.7. We will return to secure channels later in this chapter. If there\nare no keys available to Alice and Bob to set up such a secure channel, it is\nnecessary to distribute the key out-of-band. In other words, Alice and Bob\nwill have to get in touch with each other using some other communication\nchannel.\n(a)\n(b)\nFigure 9.7:\n(a) Secret-key distribution.\n(b) Public-key distribution (see\nalso [Menezes et al., 1996]).\nIn the case of a public-key cryptosystem, we need to distribute the public\nkey in such a way that the receivers can be sure that the key is indeed paired\nto a claimed private key. In other words, as shown in Figure 9.7, although\nthe public key itself may be sent as plaintext, it is necessary that the channel\nDS 4.01\n \n\n\n9.2. CRYPTOGRAPHY\n569\nthrough which it is sent can provide authentication. The private key, of course,\nneeds to be sent across a secure channel, providing authentication as well as\nconfidentiality.\nWhen it comes to key distribution, the authenticated distribution of public\nkeys is perhaps the most interesting. In practice, public-key distribution takes\nplace by public-key certificates. Such a certificate consists of a public key\ntogether with a string identifying the entity to which that key is associated.\nThe entity could be a user, but also a host or some special device. The public\nkey and identifier have together been signed by a certification authority, and\nthis signature has been placed on the certificate as well. (The identity of\nthe certification authority is naturally part of the certificate.) Signing takes\nplace by a private key SKCA that belongs to the certification authority. The\ncorresponding public key PKCA is assumed to be well known. For example,\nthe public keys of various certification authorities are built into most Web\nbrowsers and shipped with the binaries.\nUsing a public-key certificate works as follows. Assume that a client wishes\nto ascertain that the public key found in the certificate, indeed belongs to the\nidentified entity. It then uses the public key of the associated certification\nauthority to verify the certificate’s signature. If the signature on the certificate\nmatches the (public key, identifier)-pair, the client accepts that the public key\nindeed belongs to the identified entity.\nIt is important to note that by accepting the certificate as being in order, the\nclient actually trusts that the certificate has not been forged. In particular, the\nclient must assume that the public key PKCA indeed belongs to the associated\ncertification authority. If in doubt, it should be possible to verify the validity\nof PKCA through another certificate coming from a different, possibly more\ntrusted certification authority.\nNote 9.3 (More information: Lifetime of certificates)\nAn important issue concerning certificates is their longevity. First, let us consider\nthe situation in which a certification authority hands out lifelong certificates.\nEssentially, what the certificate then states is that the public key will always be\nvalid for the entity identified by the certificate. Clearly, such a statement is not\nwhat we want. If the private key of the identified entity is ever compromised, no\nunsuspecting client should ever be able to use the public key (let alone malicious\nclients). In that case, we need a mechanism to revoke the certificate by making it\npublicly known that the certificate is no longer valid.\nThere are several ways to revoke a certificate. One common approach is with a\ncertificate revocation list (CRL) published regularly by the certification authority.\nWhenever a client checks a certificate, it will have to check the CRL to see whether\nthe certificate has been revoked or not. This means that the client will at least have\nto contact the certification authority each time a new CRL is published. Note that\nif a CRL is published daily, it also takes a day to revoke a certificate. Meanwhile, a\n \nDS 4.01\n\n\n570\nCHAPTER 9. SECURITY\ncompromised certificate can be falsely used until it is published on the next CRL.\nConsequently, the time between publishing CRLs cannot be too long.\nAn alternative approach is to restrict the lifetime of each certificate. The valid-\nity of a certificate automatically expires after some time. If, for whatever reason,\nthe certificate should be revoked before it expires, the certification authority can\nstill publish it on a CRL. However, this approach will still force clients to check\nthe latest CRL whenever verifying a certificate.\nA final extreme case is to reduce the lifetime of a certificate to nearly zero. In\neffect, this means that certificates are no longer used; instead, a client will always\nhave to contact the certification authority to check the validity of a public key.\nAs a consequence, the certification authority must be continuously online and\ncapable of handling potentially continuous streams of validity checks.\nIn practice, certificates are handed out with restricted lifetimes, after which\nthey need to be renewed. Depending on the application, renewal may require\nmanual intervention, akin to renewing automatically expired passwords. In other\ncases, such as identifying Web servers, renewal can also be done completely\nautomatically as essentially a check of the existence of a specific file at a spe-\ncific location suffices. The latter happens with the Let′s Encrypt system for TLS\ncertificates.\nUsing certification authorities is one way of ensuring that a public key\nis valid in the sense of claimed ownership. However, it can easily come\nwith administrative hassle. Also, making use of certification authorities is\nno guarantee that certificates are correct: there have been cases in which the\nownership of a public key was systematically not properly established, and\nalso certification authorities are known to have been subject to successful\nattacks.\nAs an alternative, systems have been developed relying on developing a\nweb of trust. A well-known example comes from its initiator, Phil Zimmerman,\nthe developer of the Pretty Good Privacy (PGP) system, which has been\naround ever since the 1990s [Garfinkel, 1995]. The key idea, when developing\na web of trust, is that groups of people get to together and exchange their\npublic keys. At that point, one establishes the true ownership of a public\nkey. In particular, Alice may digitally sign Bob’s public key PKbob, effectively\nendorsing that the public key belongs to Bob. Other people will also endorse\nBob’s public key (and that of many others during the meeting). The result\nis that anyone who trusts the ownership of Alice’s public key, that is, trusts\nthe signature attached to Bob’s public key, has no reason not to believe that\nPKbob is indeed owned by Bob.\nIn a more sophisticated setup, one can also attach a weight to Alice’s\nsignature. For example, if Chuck believes Alice to be somewhat sloppy when it\ncomes to signing other people’s public key, he may decide to wait until he has\nseen at least k > 1 people in his web of trust who have signed Bob’s public key\nas well before deciding that PKbob is genuinely owned by Bob. An important\nDS 4.01\n \n\n\n9.3. AUTHENTICATION\n571\nquestion is whether Chuck, in turn, could ever endorse Bob’s key without ever\nhaving truly established his identity. With automatic endorsements, we open\nthe floor to digital attacks of all sorts, including ones in which an attacker\nbehaves well for a long time to strike hard only after considerable trust has\nbeen established. For this reason, the big question with a web of trust is how\nquickly, and with which confidence, can we actually disseminate trustworthy\ncertificates? It has been a topic of much research, yet after all these years there\nis no consensus to what extent webs of trust can operate on a large scale. In\nthis sense, Ulrich et al. [2011] draw interesting conclusions from a practical\nanalysis of that web: its core is formed by mutually connected (and endorsed)\nrelationships, yet is relatively small. In particular, many users are connected\nto each other and that core through relatively few and often long paths. Such\npaths make it much harder to establish trust in a robust way.\n9.3\nAuthentication\nWe continue our discussion by looking at authentication. After discussing\nsome of the basics, we concentrate on various authentication protocols, the\nuse of an authentication service, and how various aspects come together when\nsetting up a secure communication channel.\n9.3.1\nIntroduction to authentication\nAs we mentioned before, authentication is all about verifying the claimed\nidentity of a person, a software component, a device, and so on. In the follow-\ning, we shall use the generic term “client” for any of these types of entities.\nFollowing Stallings [2017], we distinguish four means of authentication:\n1. Authentication based on what a client knows, such as a password or a\npersonal identification number.\n2. Authentication based on what a client has, such as an ID card, cell\nphone, or software token.\n3. Authentication based on what a client is, i.e., static biometrics such as a\nfingerprint or facial characteristics.\n4. Authentication based on what a client does, i.e., dynamic biometrics\nsuch as voice patterns or typing patterns.\nIn the case of single-factor authentication, only one of the four means of\nauthentication is used. In practice, this means that clients are asked to enter\nsomething they know, such as a password. However, we have also come across\nsingle-factor authentication based on what a client has, namely a software\ntoken in the case of automatically logging in within the SSH framework using\na (private,public)-key pair. With modern cell phones, it is by now also common\n \nDS 4.01\n\n\n572\nCHAPTER 9. SECURITY\nto make use of what a client is, typically, face recognition or fingerprints.\nSingle-factor authentication based on dynamic biometrics is less common.\nIt is safe to say that humans are generally not good at all when it comes to\nmanaging passwords (see, for example, a study by Ur et al. [2016] that shows\nthat users are generally not even aware of how bad their passwords are). In\nthis light, we have been seeing increasingly more multi-factor authentication\nschemes being used. A common one is to use a cell phone that a user has\nregistered with a service. When logging into a system using a password or\nPIN, the user is asked to acknowledge the login through that cell phone, or\neven provide additional information like a number sent by the service to that\nphone, a PIN code, or have a fingerprint scanned and verified (in which case\nwe sometimes speak of additional electronic authentication).\nAn important observation is that, in general, authentication takes place\nonly once: when a client wants access to a service. However, this one-time\nauthentication for the duration of a session is often not good enough to\nguarantee that the service is dealing with the client it originally authenticated.\nThe simplest example is when someone is helping out, but for a different\naccount. Alice logs in, and grants Bob access from the same computer. Of\ncourse, this may be fine if Alice trusts Bob (and the service trusts Alice enough\nto allow for these type of take-overs to happen), but the situation becomes\ndifferent if Alice is forced by Bob to let him into the system. In such cases,\ncontinuous authentication is needed: the client is not only authenticated\nwhen requesting access at the beginning of a session, but also during the\nentire session.\nContinuous authentication is not new, yet with the availability of powerful\ninternet-of-things devices, new scenarios have been considered [Ayeswarya\nand Norman, 2019; Gonzalez-Manzano et al., 2019]. For example, if a user\ncan be continuously authenticated, it becomes possible to monitor different\nsituations, such as safely driving a vehicle, or ensuring that a room is opti-\nmized for a specific person. When ensuring that logins are not handed off to\nunauthorized people, as just described, it may help to see if a personalized\ndevice is still close to the computer accessing the service. Jakubeit et al. [2022]\ndescribe a situation in which the location of a user is fingerprinted based on\nWi-Fi signals to see whether the client is at a known location from which it\nwas previously authenticated. If not, a second authentication factor may be\nexplicitly required from the client.\n9.3.2\nAuthentication protocols\nBefore going into the details of various authentication protocols, it is worth-\nwhile noting that authentication and message integrity cannot do without\neach other. Consider, for example, a distributed system that supports authen-\ntication of two communicating parties, but does not provide mechanisms to\nensure message integrity. In such a system, Bob may know for sure that Alice\nDS 4.01\n \n\n\n9.3. AUTHENTICATION\n573\nis the sender of a message m. However, if Bob cannot be given guarantees that\nm has not been modified during transmission, what use is it to him to know\nthat Alice sent (the original version of) m?\nLikewise, suppose that only message integrity is supported, but no mecha-\nnisms exist for authentication. When Bob receives a message stating that he\nhas just won $1,000,000 in the lottery, how happy can he be if he cannot verify\nthat the message was sent by the organizers of that lottery?\nConsequently, authentication and message integrity should go together. In\nmany protocols, the combination works roughly as follows. Again, assume\nthat Alice and Bob want to communicate, and that Alice takes the initiative in\nsetting up a channel. Alice starts by sending a message to Bob, or otherwise to\na trusted third party, who will help set up the channel. Once the channel has\nbeen set up, Alice knows for sure that she is talking to Bob, and Bob knows\nfor sure he is talking to Alice, they can exchange messages.\nTo subsequently ensure integrity of the data messages that are exchanged\nafter authentication has taken place, it is common practice to use secret-key\ncryptography through session keys. As we explained, a session key is a shared\n(secret) key that is used to encrypt messages for integrity and possibly also\nconfidentiality. Such a key is generally used only for as long as the channel\nexists. When the channel is closed, its associated session key is destroyed. We\nreturn to session keys below.\nAuthentication based on a shared secret key\nLet us start by taking a look at an authentication protocol based on a secret key\nthat is already shared between Alice and Bob. How the two actually managed\nto obtain a shared key securely is not essential for now. In the description\nof the protocol, Alice and Bob are abbreviated by A and B, respectively, and\ntheir shared key is denoted as KA,B. The protocol takes a common approach\nwhereby one party challenges the other to a response that can be correct only\nif the other knows the shared secret key. Such solutions are also known as\nchallenge-response protocols.\nIn the case of authentication based on a shared secret key, the protocol\nproceeds as shown in Figure 9.8. First, Alice sends her identity to Bob (message\n1), indicating that she wants to set up a communication channel between the\ntwo. Bob subsequently sends a challenge RB to Alice, shown as message 2.\nSuch a challenge could take the form of a random number. Alice is required to\nencrypt the challenge with the secret key KA,B that she shares with Bob, and\nreturn the encrypted challenge to Bob. This response is shown as message 3\nin Figure 9.8 containing KA,B(RB).\nWhen Bob receives the response KA,B(RB) to his challenge RB, he can\ndecrypt the message using the shared key again to see if it contains RB. If\nso, he then knows that Alice is on the other side, for who else could have\nencrypted RB with KA,B in the first place? In other words, Bob has now\n \nDS 4.01\n\n\n574\nCHAPTER 9. SECURITY\nFigure 9.8: Authentication based on a shared secret key.\nverified that he is indeed talking to Alice. However, note that Alice has not\nyet verified that it is indeed Bob on the other side of the channel. Therefore,\nshe sends a challenge RA (message 4), which Bob responds to by returning\nKA,B(RA), shown as message 5. When Alice decrypts it with KA,B and sees\nher RA, she knows she is talking to Bob.\nNote 9.4 (Advanced: On the design of security protocols)\nOne of the difficult issues in security is designing protocols that actually work.\nTo illustrate how easily things can go wrong, consider an “optimization” of the\nauthentication protocol in which the number of messages has been reduced from\nfive to three, as shown in Figure 9.9. The basic idea is that if Alice eventually\nwants to challenge Bob anyway, she might as well send a challenge along with\nher identity when setting up the channel. Likewise, Bob returns his response to\nthat challenge, along with his own challenge, in a single message.\nFigure 9.9: Authentication based on a shared secret key, but using three\ninstead of five messages.\nUnfortunately, this protocol no longer works. It can easily be defeated by what\nis known as a reflection attack. To explain how such an attack works, consider an\nintruder called Chuck, whom we denote as C in our protocols. Chuck’s goal is to\nset up a channel with Bob so that Bob believes he is talking to Alice. Chuck can\nestablish this if he responds correctly to a challenge sent by Bob, for instance, by\nreturning the encrypted version of a number that Bob sent. Without knowledge\nDS 4.01\n \n\n\n9.3. AUTHENTICATION\n575\nof KA,B, only Bob can do such an encryption, and this is precisely what Chuck\ntricks Bob into doing.\nFigure 9.10: The reflection attack.\nThe attack is illustrated in Figure 9.10 Chuck starts out by sending a message\ncontaining Alice’s identity A, along with a challenge RC. Bob returns his challenge\nRB and the response KA,B(RC) in a single message. At that point, Chuck would\nneed to prove he knows the secret key by returning KA,B(RB) to Bob. Unfortu-\nnately, he does not have KA,B. Instead, what he does is attempt to set up a second\nchannel to let Bob do the encryption for him.\nTherefore, Chuck sends A and RB in a single message as before, but now\npretends that he wants a second channel. This is shown as message 3 in Figure 9.10\nBob, not recognizing that he, himself, had used RB before as a challenge, responds\nwith KA,B(RB) and another challenge RB2, shown as message 4. At that point,\nChuck has KA,B(RB) and finishes setting up the first session by returning message\n5 containing the response KA,B(RB), which was originally requested from the\nchallenge sent in message 2.\nAs explained by Kaufman et al. [2003], one of the mistakes made during the\nadaptation of the original protocol was that the two parties in the new version of\nthe protocol were using the same challenge in two different runs of the protocol.\nA better design is to always use different challenges for the initiator and for the\nresponder. For example, if Alice always uses an odd number and Bob an even\nnumber, Bob would have recognized that something fishy was going on when\nreceiving RB in message 3 in Figure 9.10. (Unfortunately, this solution is subject\nto other attacks, notably the one known as the “man-in-the-middle-attack,” which\nis explained in [Ferguson et al., 2010].) In general, letting the two parties setting\nup a secure channel doing a number of things identically is not a good idea.\nAnother principle that is violated in the adapted protocol is that Bob gave\naway valuable information in the form of the response KA,B(RC) without knowing\nfor sure to whom he was giving it. This principle was not violated in the original\nprotocol, in which Alice first needed to prove her identity, after which Bob was\nwilling to pass her encrypted information.\nThere are many principles that developers of cryptographic protocols have\ngradually come to learn over the years. One important lesson is that designing\nsecurity protocols that do what they are supposed to do is often much harder\nthan it looks. Also, tweaking an existing protocol to improve its performance,\n \nDS 4.01\n\n\n576\nCHAPTER 9. SECURITY\ncan easily affect its correctness. More on design principles for protocols can be\nfound in [Abadi and Needham, 1996] with a more recent analysis in [Fiebig\net al., 2018].\nAuthentication using a key distribution center\nOne of the problems with using a shared secret key for authentication is\nscalability. If a distributed system contains N hosts, and each host is required\nto share a secret key with each of the other N −1 hosts, the system as a whole\nneeds to manage N(N −1)/2 keys, and each host has to manage N −1 keys.\nFor large N, this will lead to problems. An alternative is to use a centralized\napproach by a key distribution center (KDC). This KDC shares a secret key\nwith each of the hosts, but no pair of hosts is required to have a shared secret\nkey as well. In other words, using a KDC requires that we manage N keys\ninstead of N(N −1)/2, which is clearly an improvement.\nIf Alice wants to set up a secure channel with Bob, she can do so through a\n(trusted) KDC. The whole idea is that the KDC hands out a key to both Alice\nand Bob that they can use for communication, shown in Figure 9.11.\nFigure 9.11: The principle of using a Key Distribution Center (KDC).\nAlice first sends a message to the KDC, telling it that she wants to talk to\nBob. The KDC returns a message containing a shared secret key KA,B that\nshe can use. The message is encrypted with the secret key KA,KDC that Alice\nshares with the KDC. In addition, the KDC sends KA,B also to Bob, but now\nencrypted with the secret key KB,KDC it shares with Bob.\nThe main drawback of this approach is that Alice may want to start setting\nup a secure channel with Bob even before Bob had received the shared key\nfrom the KDC. In addition, the KDC is required to get Bob into the loop by\npassing him the key. These problems can be circumvented if the KDC just\npasses KB,KDC(KA,B) back to Alice, and lets her take care of connecting to Bob.\nThis leads to the protocol shown in Figure 9.12. The message KB,KDC(KA,B) is\nalso known as a ticket. It is Alice’s job to pass this ticket to Bob. Note that Bob\nis still the only one who can make sensible use of the ticket, as he is the only\none besides the KDC who knows how to decrypt the information it contains.\nDS 4.01\n \n",
      "page_number": 577
    },
    {
      "number": 58,
      "title": "Segment 58 (pages 587-599)",
      "start_page": 587,
      "end_page": 599,
      "detection_method": "topic_boundary",
      "content": "9.3. AUTHENTICATION\n577\nFigure 9.12: Using a ticket and letting Alice set up a connection to Bob.\nNote 9.5 (Advanced: The Needham-Schroeder protocol)\nThe protocol shown in Figure 9.12 is actually a variant of a well-known example\nof an authentication protocol using a KDC, known as the Needham-Schroeder\nauthentication protocol, named after its inventors [Needham and Schroeder,\n1978]. The Needham-Schroeder protocol, shown in Figure 9.13 is a so-called\nmultiway challenge-response protocol and works as follows.\nWhen Alice wants to set up a secure channel with Bob, she sends a request to\nthe KDC containing a challenge RA, along with her identity A and, of course, that\nof Bob. The KDC responds by giving her the ticket KB,KDC(KA,B), along with the\nsecret key KA,B that she can subsequently share with Bob.\nFigure 9.13: The Needham-Schroeder authentication protocol.\nThe challenge RA1 that Alice sends to the KDC along with her request to set\nup a channel to Bob is also known as a nonce. A nonce is a random number that\nis used only once, such as one chosen from a very large set. The main purpose of\na nonce is to uniquely relate two messages to each other, in this case message 1\nand message 2. In particular, by including RA1 again in message 2, Alice will\nknow for sure that message 2 is sent as a response to message 1, and that it is not,\nfor example, a replay of an older message.\nTo understand the problem at hand, assume that we did not use nonces, and\nthat Chuck has stolen one of Bob’s old keys, say Kold\nB,KDC. In addition, Chuck has\nintercepted an old response KA,KDC(B, KA,B, Kold\nB,KDC(A, KA,B)) that the KDC had\nreturned to a previous request from Alice to talk to Bob. Meanwhile, Bob will\n \nDS 4.01\n\n\n578\nCHAPTER 9. SECURITY\nhave negotiated a new shared secret key with the KDC. However, Chuck patiently\nwaits until Alice again requests to set up a secure channel with Bob. At that point,\nhe replays the old response, and fools Alice into making her believe she is talking\nto Bob because he can decrypt the ticket and prove he knows the shared secret key\nKA,B. Clearly this is unacceptable and must be defended against. By including a\nnonce, such an attack is impossible because replaying an older message (having a\ndifferent nonce) will immediately be discovered.\nMessage 2 also contains B, the identity of Bob. By including B, the KDC pro-\ntects Alice against the following attack. Suppose that B was left out of message 2.\nIn that case, Chuck could modify message 1 by replacing the identity of Bob with\nhis own identity, say C. The KDC would then think Alice wants to set up a secure\nchannel to Chuck, and responds accordingly. As soon as Alice intends to contact\nBob, Chuck intercepts the message and fools Alice into believing she is talking\nto Bob. By copying the identity of the other party from message 1 to message 2,\nAlice will immediately detect that her request had been modified.\nAfter the KDC has passed the ticket to Alice, the secure channel between Alice\nand Bob can be set up. Alice starts with sending message 3, which contains the\nticket to Bob, and a challenge RA2 encrypted with the shared key KA,B that the\nKDC had just generated. Bob then decrypts the ticket to find the shared key, and\nreturns a response RA2 −1 along with a challenge RB for Alice.\nThe following remark regarding message 4 is in order. In general, by returning\nRA2 −1 and not just RA2, Bob not only proves he knows the shared secret key, but\nalso that he has actually decrypted the challenge. Again, this ties message 4 to\nmessage 3 in the same way that the nonce RA tied message 2 to message 1. The\nprotocol is thus more protected against replays. However, in this special case, it\nwould have been sufficient to just return KA,B(RA2, RB), for the simple reason that\nthis message has not yet been used anywhere in the protocol before. KA,B(RA2, RB)\nalready proves that Bob has been capable of decrypting the challenge sent in\nmessage 3. Message 4 as shown in Figure 9.13 is due to historical reasons.\nThe Needham-Schroeder protocol as presented here still has the weak point\nthat if Chuck ever got a hold of an old key Kold\nA,B, he could replay message 3 and\nget Bob to set up a channel. Bob will then believe he is talking to Alice, while,\nin fact, Chuck is at the other end. In this case, we need to relate message 3 to\nmessage 1, that is, make the key dependent on the initial request from Alice to set\nup a channel with Bob. The solution is shown in Figure 9.14.\nThe trick is to incorporate a nonce in the request sent by Alice to the KDC.\nHowever, the nonce has to come from Bob: this assures Bob that whoever wants\nto set up a secure channel with him, will have gotten the appropriate information\nfrom the KDC. Therefore, Alice first requests Bob to send her a nonce RB1,\nencrypted with the key shared between Bob and the KDC. Alice incorporates this\nnonce in her request to the KDC, which will then subsequently decrypt it and\nput the result in the generated ticket. In this way, Bob will know for sure that the\nsession key is tied to the original request from Alice to talk to Bob.\nDS 4.01\n \n\n\n9.3. AUTHENTICATION\n579\nFigure 9.14: Protection against malicious reuse of a previously generated\nsession key in the Needham-Schroeder protocol.\nAuthentication using public-key cryptography\nLet us now look at authentication with a public-key cryptosystem that does\nnot require a KDC. Again, consider the situation that Alice wants to set\nup a secure channel to Bob, and that both are in the possession of each\nother’s public key. A typical authentication protocol based on public-key\ncryptography is shown in Figure 9.15 which we explain next.\nFigure 9.15: Mutual authentication in a public-key cryptosystem.\nAlice starts with sending a challenge RA to Bob encrypted with his public\nkey PKB. It is Bob’s job to decrypt the message and return the challenge to\nAlice. Because Bob is the only person that can decrypt the message (using\nthe private key that is associated with the public key Alice used), Alice will\nknow that she is talking to Bob. Note again that it is important that Alice is\nguaranteed to be using Bob’s public key, and not the public key of someone\nimpersonating Bob.\nWhen Bob receives Alice’s request to set up a channel, he returns the\ndecrypted challenge, along with his own challenge RB to authenticate Alice.\nIn addition, he generates a session key KA,B that can be used for further\ncommunication. Bob’s response to Alice’s challenge, his own challenge, and\n \nDS 4.01\n\n\n580\nCHAPTER 9. SECURITY\nthe session key are put into a message encrypted with the public key PKA\nbelonging to Alice, shown as message 2 in Figure 9.15. Only Alice will be\ncapable of decrypting this message using her private key SKA.\nAlice, finally, returns her response to Bob’s challenge using the session\nkey KA,B generated by Bob. In that way, she will have proven that she could\ndecrypt message 2, and thus that she is actually Alice to whom Bob is talking.\nThe need for session keys\nDuring the establishment of a secure channel, after the authentication phase\nhas completed, the communicating parties generally use a unique shared\nsession key for confidentiality. The session key is safely discarded when\nthe channel is no longer used. An alternative would have been to use the\nsame keys for confidentiality as those that are used for setting up the secure\nchannel. However, there are a number of important benefits to using session\nkeys [Kaufman et al., 2003].\nFirst, when a key is used often, it becomes easier to reveal it. In a sense,\ncryptographic keys are subject to “wear and tear” just like ordinary keys.\nThe basic idea is that if an intruder can intercept a lot of data that has been\nencrypted using the same key, it becomes possible to mount attacks to find\ncertain characteristics of the keys used, and possibly reveal the plaintext or\nthe key itself. For this reason, it is much safer to use the authentication keys\nas little as possible. In addition, such keys are often exchanged using some\nrelatively time-expensive out-of-band mechanism, such as regular mail or\ntelephone. Exchanging keys that way should be kept to a minimum.\nAnother important reason for generating a unique key for each secure\nchannel is to ensure protection against replay attacks, as we have come across\npreviously a number of times. By using a unique session key each time a\nsecure channel is set up, the communicating parties are at least protected\nagainst replaying an entire session. To protect replaying individual messages\nfrom a previous session, additional measures are generally needed, such as\nincluding timestamps or sequence numbers as part of the message content.\nSuppose that message integrity and confidentiality were achieved by using\nthe same key used for session establishment. In that case, whenever the key\nis compromised, an intruder may be able to decrypt messages transferred\nduring an old conversation, clearly not a desirable feature. Instead, it is much\nsafer to use per-session keys because if such a key is compromised, at worst,\nonly a single session is affected. Messages sent during other sessions stay\nconfidential.\nRelated to this last point is that Alice may want to exchange some confi-\ndential data with Bob, but she does not trust him so much that she would\nprovide him information in the form of data that have been encrypted with\nlong-lasting keys. She may want to reserve such keys for highly confidential\nDS 4.01\n \n\n\n9.3. AUTHENTICATION\n581\nmessages that she exchanges with parties she really trusts. In such cases,\nusing a relatively cheap session key to talk to Bob is sufficient.\nBy and large, authentication keys are often established in such a way that\nreplacing them is relatively expensive. Therefore, the combination of such\nlong-lasting keys with the much cheaper and more temporary session keys is\noften a good choice for implementing secure channels for exchanging data.\nExample of an authentication service: Kerberos\nIt should be clear by now that incorporating security into distributed systems\nis not trivial. Problems are caused by the fact that the entire system must be\nsecure; if some part is insecure, the whole system may be compromised. To\nassist the construction of distributed systems that can enforce a myriad of\nsecurity policies, a number of supporting systems have been developed that\ncan be used as a basis for further development. An important system that is\nwidely used is Kerberos [Steiner et al., 1988; Kohl et al., 1994]\nKerberos was developed at M.I.T. and is based on the Needham-Schroeder\nauthentication protocol. A detailed description of the Kerberos system can\nbe found in [Neuman et al., 2005] whereas practical information on running\nKerberos is described by Garman [2003]. A publicly available implementation\nof Kerberos, known as Shishi, is described in [Josefsson, 2015].\nKerberos can be viewed as a security system that assists clients in setting\nup a secure channel with any server that is part of a distributed system.\nSecurity is based on shared secret keys. There are two different components.\nThe authentication server (AS) is responsible for handling a login request\nfrom a user. The AS authenticates a user and provides a key that can be used\nto set up secure channels with servers. Setting up secure channels is handled\nby a ticket-granting service (TGS). The TGS hands out special messages,\nknown as tickets, that are used to convince a server that the client is really\nwho it claims to be.\nLet us take a look at how Alice logs onto a distributed system that uses\nKerberos and how she can set up a secure channel with server Bob. We\nassume that Alice has previously been registered at the distributed system, so\nthat there already exists a shared secret key KA,AS between her and the authen-\ntication server. That key is assumed to be derived from Alice’s password. For\nexample, assuming a character-string password, we can take a cryptographic\nhash of that password as the secret key. Of course, we do need to ensure that\nthe secret key is protected against unauthorized access. For Alice to log onto\nthe system, she can use any workstation available. The workstation sends her\nname in plaintext to the AS, which returns a session key KA,TGS and a ticket\nthat she will need to hand over to the TGS.\nThe ticket that is returned by the AS contains the identity of Alice, along\nwith a generated secret key that Alice and the TGS can use to communicate\nwith each other. The ticket itself will be handed over to the TGS by Alice.\n \nDS 4.01\n\n\n582\nCHAPTER 9. SECURITY\nTherefore, it is important that no one but the TGS can read it. For this reason,\nthe ticket is encrypted with the secret key KAS,TGS shared between the AS\nand the TGS.\nFigure 9.16: Authentication in Kerberos.\nThis part of the login procedure is shown as messages 1, 2, and 3 in\nFigure 9.16, respectively. Message 1 is not really a message, but corresponds\nto Alice typing in her login name at a workstation. Message 2 contains that\nname and is sent to the AS. Message 3 contains the session key KA,TGS and\nthe ticket KAS,TGS(A, KA,TGS). To ensure privacy, message 3 is encrypted with\nthe secret key KA,AS shared between Alice and the AS.\nWhen the workstation receives the response from the AS, it prompts Alice\nfor her password (shown as message 4), which it uses subsequently to generate\nthe shared key KA,AS. Note that this approach not only has the advantage that\nAlice’s password is never sent as plaintext across the network, but also that the\nworkstation does not even have to temporarily store it. Moreover, as soon as\nit has derived the shared key KA,AS from that password, the workstation will\nfind the session key KA,TGS, and can forget about Alice’s password altogether\n(as well as the shared secret KA,AS).\nAfter this part of the authentication has taken place, Alice can consider\nherself logged into the system through the current workstation. The ticket\nreceived from the AS is stored temporarily (typically for 8–24 hours), and\nwill be used for accessing remote services. Of course, if Alice leaves her\nworkstation, she should destroy any cached tickets. If she wants to talk to Bob,\nshe requests the TGS to generate a session key for Bob, shown as message 6 in\nFigure 9.16. The fact that Alice has the ticket KAS,TGS(A, KA,TGS) proves that\nshe is Alice. The TGS responds with a session key KA,B, again encapsulated\nin a ticket that Alice will later have to pass to Bob.\nMessage 6 also contains a timestamp, t, encrypted with the secret key\nshared between Alice and the TGS. This timestamp is used to prevent Chuck\nfrom maliciously replaying message 6 again, and trying to set up a channel to\nBob. The TGS will verify the timestamp before returning a ticket to Alice. If it\nDS 4.01\n \n\n\n9.3. AUTHENTICATION\n583\ndiffers more than a few minutes from the current time, the request for a ticket\nis rejected.\nThis scheme establishes what is known as single sign-on. As long as\nAlice does not change workstations, there is no need for her to authenticate\nherself to any other server that is part of the distributed system. This feature\nis important when having to deal with many services that are spread across\nmultiple machines.\nIn principle, servers in a way have delegated client\nauthentication to the AS and TGS, and will accept requests from any client\nthat has a valid ticket. Of course, services such as remote login will require that\nthe associated user has an account, but this is independent of authentication\nthrough Kerberos.\nFigure 9.17: Setting up a secure channel in Kerberos.\nSetting up a secure channel with Bob is now straightforward, and is shown\nin Figure 9.17. First, Alice sends to Bob a message containing the ticket she\ngot from the TGS, along with an encrypted timestamp. When Bob decrypts\nthe ticket, he notices that Alice is talking to him because only the TGS could\nhave constructed the ticket. He also finds the secret key KA,B, allowing him to\nverify the timestamp. At that point, Bob knows he is talking to Alice and not\nsomeone maliciously replaying message 1. By responding with KA,B(t + 1),\nBob proves to Alice that he is indeed Bob.\nExample of a secure channel: HTTP over TLS\nLet us now look at an often-used protocol suite for setting up a secure channel:\nthe Transport Layer Security protocol, or simply TLS. The protocol suite\ncomes in a number of flavors, originating from the Secure Socket Layer\nprotocol that was designed in 1994. The most recent version is TLS 1.3,\nspecified in [Rescorla et al., 2018]. TLS is generally best known for its use in\nsecuring the connection to a Web server when using HTTP, also known as\nHTTPS. In this case, HTTP is secured by setting up a secure channel between\na client and the Web server using TLS in combination with TCP.\nUnderstanding TLS can be quite difficult, mainly for two reasons. First,\nTLS 1.3 needs to be backward compatible with previous versions (at least\nthe ones that have not been deprecated). Second, the two communicating\nparties need to go through a negotiation phase to decide precisely how they\nare actually going to use TLS. The latter starts with agreeing on the version,\nbut also includes agreements on which cryptosystems (called cipher suites)\n \nDS 4.01\n\n\n584\nCHAPTER 9. SECURITY\nto use. TLS 1.3 simplifies matters in comparison to its predecessors in that it\nlimits the options. We are going to ignore all kinds of extra information that\nis sent during the negotiation phase and stick to the core of the protocol.\nAs mentioned, TLS 1.3 limits the choices for client and server when it\ncomes to using cipher suites. Let us assume that a client wants to set up\na secure channel based on ephemeral Diffie-Hellman key exchange, using\none of the possible Diffie-Hellman groups, say G. For example, G could be\nffdhe2048 which corresponds to g = 2 and p equal to\np = 22048 −21984 + (⌊21918 ∗e⌋+ 560316) ∗264 −1\nwhere e denotes the base of the natural logarithm (i.e., e ≈2.718281).\nFigure 9.18: The principle of setting up a secure channel using TLS 1.3.\nThe client starts with choosing a private key x as explained when intro-\nducing Diffie-Hellman key exchange. By choice of G, the client computes a\ncorresponding public key PKDH\nC\n= gx mod p. The client continues by sending\na client-hello message to the server. This message contains at least the\npublic key PKDH\nC , a nonce RC and G:\nClient: sends client-hello = [PKDH\nC , RC, G]\nThe server, assuming it accepts G, also chooses a private key y and gener-\nates its associated public key PKDH\nS\n= gy mod p. It subsequently returns a\nserver-hello message:\nServer: responds server-hello = [PKDH\nS , RS]\nDS 4.01\n \n\n\n9.4. TRUST IN DISTRIBUTED SYSTEMS\n585\nNote that at this point, the client has no guarantees that it is actually com-\nmunicating with the intended server. The only thing the two have essentially\ncommunicated are generated public keys. These keys can be used to compute\na shared secret key SKDH\nC,S = gxy mod p. As a next step, the client and the\nserver first each compute the following hash:\nMAC = H([PKDH\nC , RC, G, PKDH\nS , RS])\nwhere H is the SHA256 hashing function [Eastlake and Hansen, 2011]. In other\nwords, MAC is the 256-bit hash obtained by concatenating the client-hello\nand server-hello messages. MAC and SKDH are then used to generate the\nfinal shared secret session key SK∗\nC,S = f (MAC, SKDH\nC,S) where f is a so-called\nkey-derivation function. From this moment on, the communication between\nthe client and the server is kept private, i.e., encrypted with the shared secret\nkey SK∗\nC,S. The server then continues with authenticating itself. To that end,\nwe assume it can provide a certificate containing a public key PKS signed by\nthe certification authority CA. The server encrypts all its communication with\nthe client using SK∗\nC,S:\nServer sends SK∗\nC,S([PKS, sigCA]) with sigCA = SKCA(PKS)\nAt this point, the client can authenticate the server. Applications running on\ntop of TLS could, in principle, rely entirely on the use of the shared secret key\nSK∗\nC,S while keeping the communication private. Better is to generate keys\nthat the application-level protocol can use, independent of what is being used\nby the TLS connection. To that end, both client and server each compute a\nshared secret key from the information exchanged so far:\nAMAC = H([PKDH\nC , RC, G, PKDH\nS , RS, PKS, sigCA])\nthat is, essentially the concatenation of the messages client-hello and\nserver-hello, along with the certificate and again hashed using H = SHA256.\nThe final application-level shared secret key is computed as SK∗∗\nC,S = f (AMAC,\nSK∗\nC,S). A summary of what we have just discussed is shown in Figure 9.18.\n9.4\nTrust in distributed systems\nFundamental to authentication is that a process can prove to be who it claims\nto be. Once that proof has been given, the question arises how good that proof\nactually is. One can argue that this is where trust starts to play: does the\nreceiver of the proof accept that proof to be sufficient to provide the process\naccess to the system? Yet trust as facilitated or implemented in distributed\nsystems extends beyond just authentication, as witnessed by the vast interest\nin distributed ledger systems such as those implemented by blockchains.\nThe issue of trust has also become more prominent with the increase of\n \nDS 4.01\n\n\n586\nCHAPTER 9. SECURITY\n(semi-)automated decision-making procedures that have been installed in\nnumerous information systems and that directly affect the lives of many\nhuman beings. Making unjustified decisions does not help in building trust,\nand many such decisions have been made, and are presumably still being\nmade. Perhaps most problematic are the situations in which one needs to\ntrust decision-making without understanding the underlying process, as is\ngenerally inherently the case when applying machine-learning techniques.\nIn this section, we will zoom into matters of trust, yet will stay close to\ntechnical issues relevant for the design and implementation of distributed\nsystems. Wierzbicki [2010] discusses trust in a broader context while still\nlinking it strongly to information systems. A recent survey on trust and\nreputation models for information systems is provided by Braga et al. [2018].\n9.4.1\nTrust in the face of Byzantine failures\nBefore we take a more explicit look at trust, it is worthwhile considering its\nrelation to failure models. Trust becomes an issue when there is a dependency\nof one process P on another process Q and a possibility that the latter no\nlonger behaves according to what P expects. More specifically:\nTrust is the assurance that one entity holds that another will perform\nparticular actions according to a specific expectation.\nThis definition, by Bursell [2022], can be refined in many ways, yet will do\nfor now. The point is that when expectations have been made explicit, i.e.,\nspecified, there may be no need to talk about trust anymore. If we take a look\nat Byzantine failures within process groups, the underlying assumption is that\nthere may be processes from which we cannot expect anything anymore: they\nmay be behaving correctly or incorrectly, but we have no means of always\ncorrectly detecting whether they are living up to their specifications.\nThe interesting aspect of Byzantine failure models is that we can let go of\ntrust and develop solutions in which there is no need to trust the individual\nprocesses. The only thing that matters is that the process group lives up to its\nspecifications, that is, with a group size of n processes, at most k ≤(n −1)/3\nwill go rogue. Such a group can still reach a correct agreement among the\nnonfaulty processes. If the group cannot meet its specifications, for example,\nbecause of too many faulty processes, all bets are off.\n9.4.2\nTrusting an identity\nLet us start by looking at a rather nasty issue when accepting incoming\nrequests from a source without bothering about further authentication. This\nsituation is not unusual: it constantly happens in many decentralized peer-\nto-peer systems. The problem we need to face is that of a so-called Sybil\nattack [Douceur, 2002]. The essence of this attack is that in distributed systems,\nDS 4.01\n \n\n\n9.4. TRUST IN DISTRIBUTED SYSTEMS\n587\nwe generally rely on the fact that when presented with a logical identity, there\nis just a single associated physical entity. In other words, we rely on the\nfollowing three properties, as also discussed in Section 6.1:\n1. An identifier refers to at most one entity\n2. Each entity is referred to by at most one identifier.\n3. An identifier always refers to the same entity (i.e., it is never reused).\nIn the case of a Sybil attack, these assumptions are violated: an attacker simply\ncreates multiple identities and joins the system separately with each of these\nidentities to subsequently stage a specific attack. The general principle of a\nSybil attack can be elegantly summarized as shown in Figure 9.19.\n1 H = set of honest nodes\n2 S = set of Sybil nodes\n3 A = Attacker node\n4 d = minimal fraction of Sybil nodes needed for an attack\n5\n6 while True:\n7\ns = A.createNode()\n# create a Sybil node\n8\nS.add(s)\n# add it to the set S\n9\n10\nh = random.choice(H)\n# pick an arbitrary honets node\n11\ns.connectTo(h)\n# connect the new sybil node to h\n12\n13\nif len(S) / len(H) > d:\n# enough sybil nodes for...\n14\nA.attack()\n# ...an attack\nFigure 9.19: The principle of a Sybil attack (adopted from [Iqbal and Matule-\nviˇcius, 2021].\nA typical example of a Sybil attack is when operating a decentralized\npeer-to-peer network such as Chord or Kademlia. An attacker simply creates\nmultiple logical nodes that join the network. As the attacker has full control\nover these nodes, from a security perspective, they are viewed as a collection\nof colluders. In particular, there is no reason to assume that they behave as\nexpected. For example, together, they can easily launch a denial-of-service\nattack by not forwarding lookup requests. If the attacker has control over a\nsufficient number of nodes, it is with high probability that any lookup request\nwill need to go through a malicious node. Likewise, the colluding nodes can\njoin in attacking the content stored in a network, if only to delete files they\nare collectively responsible for. Even in the face of using file replication, such\na behavior may easily lead to permanent loss of data.\nAs another example of a Sybil attack, consider the aforementioned web of\ntrust. If we allowed automatic endorsement of public keys, i.e., having Chuck\nendorse the public key of Bob without an out-of-band checking that the key\n \nDS 4.01\n\n\n588\nCHAPTER 9. SECURITY\nis really owned by Bob, we may find ourselves in the following situation.\nNote that the web of trust is essentially based on reputation: assuming Chuck\ndoes not entirely trust Alice when it comes to validating the public key of\nBob, he may decide to also consider the validations from k > 1 others before\naccepting the validity of Bob’s public key. Yet, with automatic endorsement,\nAlice could launch a Sybil attack by simply cloning her efforts by installing\nmany nodes claiming they have validated Bob’s public key. If k of these nodes\nare consulted by Chuck, then Chuck will believe the key indeed belongs to\nBob. There is no harm in this, unless Alice had stolen Bob’s private key and\nis now trying to act as Bob. Without automatic endorsement, such an attack\nwould be much more difficult to realize.\nClosely related to a Sybil attack is the so-called eclipse attack. In this case,\na collection of colluding nodes will try to isolate a node from the network.\nWe showed in Section 5.5.4, how with almost minimal effort a gossip-based\nservice can be brought to a grinding halt before benevolent nodes may even\nsuspect that something fishy is going on. That service is based on continuously\nexchanging randomly chosen links with neighbors in an attempt to maintain\nan overlay network that resembles a random graph. The links are chosen\nfrom a relatively small list that is local to each node in the network. An\nexchanged link replaces the link in this local list. In an eclipse attack, a\nnumber of colluding nodes never return randomly chosen links, but only\nlinks to their fellow colluders. The effect is devastating: within only relatively\nfew exchanges by all nodes in the network, the malicious links will have\ncontaminated the local lists to the extent that each local list contains only links\nto the colluding nodes. At that point, the colluders have full control over the\nnetwork (see also Jesi et al. [2007]).\nThe simple way out in both cases is to use a centralized certification\nauthority: whenever Alice connects to Bob, she will have to prove to be the\nholder of the digital identity associated with her. A certificate signed by a\ntrusted authority should, in principle, do the job. Suppose the certification\nauthority is not (sufficiently) trusted. This may happen, for example because\nthe certification authority is not known enough. In that case, we may rely on\na trust chain, by which the public key PKCA that is used to sign the certificate\nis accompanied by its own certificate, signed by another certification authority,\nsay CA∗. If the public key PKCA∗is not trusted, then we can repeat the\nprocedure by having that key be accompanied by another certificate signed by\nyet another certification authority CA∗∗, and so on. However, in the end, the\nrecipient will have to trust the certification authority at the end of this chain.\nPreventing Sybil attacks: blockchain solutions\nLevine et al. [2006] and later Urdaneta et al. [2011] have looked at Sybil attacks\nin decentralized networks. Both come to the conclusion, as also already stated\nby Douceur [2002] that these attacks are almost impossible to prevent without\nDS 4.01\n \n\n\n9.4. TRUST IN DISTRIBUTED SYSTEMS\n589\nmaking use of a trusted authority. All other decentralized solutions up to that\npoint could at best discourage Sybil attacks, but not prevent them. However,\naccepting a centralized, trusted party in an otherwise decentralized system is\nsomething that many find difficult to accept. Yet, if we could devise a system\nthat would make having multiple identities unattractive, then maybe a trusted\nparty may not be necessary. This is where permissionless blockchains come\ninto play.\nLaunching multiple identities is attractive if the attacker knows that there\nis substantial gain in doing so compared to the price to pay for maintaining\nmultiple identities. But the price is high when, for example, an identity\nis assumed to throw in considerable resources to be able to act. This is\nprecisely what is expected in proof-of-work (PoW) blockchain systems. In\nPoW systems, validators of a block of transactions are engaged in a race,\nrequiring considerable computational resources. There is no incentive for an\nattacker to launch another identity for the same physical node, as that identity\nwill need to compete as well.\nHaving to run computational races is arguably a bad design choice for any\ndistributed system. In an attempt to still prevent Sybil attacks but avoiding\ncomputational races, designers of blockchain systems have been investigating\nproof-of-stake (PoS) solutions [Nguyen et al., 2019]. In this case, those nodes\nfor making decisions on validating transactions are selected according to how\nmuch stake they have in the system. Assuming stakes are expressed as certain\ntokens (such as digital coins), each token is indexed, after which a search is\nmade for the owner of that indexed token. Obviously, the more tokens a node\nhas, the higher the chance of being selected for decision-making. Again, we\nsee that simply creating multiple identities is not rewarding, as each of these\nidentities will need to obtain tokens before being able to act.\nNone of these blockchain solutions are without security problems (see\nSaad et al. [2020] and Li et al. [2020] for extensive overviews). Yet from the\nperspective of preventing Sybil attacks, one can argue that they do their job\nwell.\nSybil-resistant accounting mechanisms\nWhen trust in central authorities within a distributed system drops, we need\nto resort to decentralized solutions. The fundamental problem is that Alice\nhas no reason whatsoever to trust Bob a priori whenever the two get in touch\nand one needs the other to engage in a transaction of some sort. A common\nsolution is to build a reputation system by which Bob can prove to Alice that\nhe is trustworthy. At the same time, such a system should be resistant to a\nSybil attack, as we illustrated in the web-of-trust model.\nAs part of their work on building robust blockchain systems, Otte et al.\n[2020] introduced an accounting mechanism by which a node Q can show\nthat it has already done considerable work to convince node P to let it do\n \nDS 4.01\n",
      "page_number": 587
    },
    {
      "number": 59,
      "title": "Segment 59 (pages 600-607)",
      "start_page": 600,
      "end_page": 607,
      "detection_method": "topic_boundary",
      "content": "590\nCHAPTER 9. SECURITY\nsome work for P. The benefit for Q, of course, is that its own performed work\nfurther increases so that it may later use that to ask others to work for it. The\nNetFlow accounting mechanism introduced by Otte et al. is based on earlier\nwork by Seuken and Parkes [2014]. Interesting for our current discussion is\nthat this decentralized accounting mechanism is resistant to Sybil attacks.\nThe basic idea is that each node P in the network maintains a list of nodes\nthat are interested in doing work for P, called the choice set of P, denoted\nas choice(P). Which node is selected from choice(P) depends on that node’s\nreputation, expressed in terms of work done for others.\nTo this end, P maintains a view of what nodes in the network have done\nso far for each other. The view is necessarily subjective: it may be incomplete\n(because P has no knowledge of all the participating nodes) and it may be\ninaccurate. In any case, P does know what it has done for others, and also\nwhat others have done for P. This information is enough for P to compute a\ncapacity cap(Q) for any node Q ∈choice(P):\ncap(Q) = max{MF(Q, P) −MF(P, Q), 0}\nwhere MF(P, Q) is the value of the maximum flow from P to Q, i.e., the\namount of work that P has, or could have contributed to work done for Q,\nincluding the work done by others. For example, if node R directly contributed\n3 units of work for Q, and R had processed 7 units for P, then P indirectly may\nhave contributed 3 units of work for Q, yet through R. The reasoning is that R\nmay never have been able to work for Q if not for the work it did for P. The\ncapacity of node Q from P’s perspective, is thus the result of the work Q has\ndirectly and indirectly done for P, minus the work P has done for Q. When\npositive, one could say that P “owes” Q some work to do. These capacities\nare then used in maximum-flow computations that result in reputation scores\nfor each node.\nNow let us consider a Sybil attack by a node Q ∈choice(P). To that end,\nQ creates n Sybil nodes Q∗\n1, . . . , Q∗n. We denote Q = Q∗\n0 as just another Sybil.\nFirst, note that for any work contributed by a Sybil Q∗\ni to another Sybil Q∗\nj\nto cause an increase in cap(Q∗\ni ), at least two conditions need to hold: (1) Q∗\nj\nneeds to have contributed work to some honest node R and (2) that node\nR needs to have contributed (indirectly) to P. What this means, is that Q\ncan successfully launch an attack only if it had already performed work for\nhonest nodes. Furthermore, the attack makes sense only if Q expects that\nother, honest nodes will contribute work to Q, and that this work is more\nthan Q’s total contributions to its Sybils. This can happen if the total capacity\nTcap(Q) of the Sybils can grow, with\nTcap(Q) =\nn\n∑\nk=0\ncap(Q∗\nk)\nNow assume that a unit of work is contributed by P to one of the Sybils, say\nQ∗\ni . In that case, MF(P, Q∗\ni ) increases by 1 unit, so that cap(Q∗\ni ) drops by 1\nDS 4.01\n \n\n\n9.4. TRUST IN DISTRIBUTED SYSTEMS\n591\nunit, and so does Tcap(Q). This may continue until Tcap(Q) = 0, at which\npoint P will direct its attention to other nodes and ignore any of the Sybils\nuntil their joint capacity has grown, notably because other honest nodes have\ncontributed work to those Sybils.\nHaving the Sybils perform work for each other does not help: if Q∗\ni\nperforms a unit of work for Q∗\nj , then cap(Q∗\ni ) goes up by 1 unit, yet cap(Q∗\nj )\ngoes down by 1, leaving Tcap(Q) unaffected. The only way that Tcap(Q) can\ngo up without P contributing work to one of the Sybils, is if some other honest\nnode R contributes work. If P is unaware of R, then P will not know about this\nwork and keep Tcap(Q) the same. In other words, Q cannot benefit from work\nit does for R to trick P into contributing work to one of its Sybils, including\nitself. However, if P does know about R, we can expect that both will have the\nsame perspective on the value of Tcap(Q). As a consequence, R will act the\nsame as P: it will contribute work to one of the Sybils until Tcap(Q) drops to\n0. At that point, Q is where it stood before the attack: empty-handed and in\nneed of a node willing to let it do some work.\nThis rather intuitive reasoning shows that a proper accounting mechanism\n(in the case of NetFlow based on maximum flows in a network) is actually\nSybil resistant. A precise and formal reasoning can be found in [Stannat et al.,\n2021]. Also, [Otte, 2016] will be useful in understanding some underlying\ndetails of NetFlow that we have purposefully omitted here.\n9.4.3\nTrusting a system\nAn important claimed feature of many blockchain systems is that they can\noperate without the need for a trusted third party (i.e., they are completely\ndecentralized), in addition to the fact that there is also no need to trust any\nof the individual participants. To understand this reasoning, we need to\nseparate the blockchain from the way it is maintained. The latter is strongly\ndetermined by the consensus protocol that is executed to figure out which\nblock of validated transactions can be appended to the current blockchain. The\nformer has everything to do with the transparency and protection of essentially\na read-only distributed ledger. This is where ensuring data integrity is crucial.\nRecall that a blockchain is literally a chain of blocks, with each block\nconsisting of a number of validated transactions. When it comes to ensuring\ndata integrity, we need a means to be able to detect that the current blockchain\nhas not been tampered with, i.e., ensuring that any change to the current\nchain cannot go unnoticed and thus be flagged as an attack.\nThe principle of a blockchain is shown in Figure 9.20. The first block,\ncalled the genesis block, contains the number 0x00000000 which is effectively\na null pointer. Important is that each block contains a number of transactions\nand a hash value over the data contained in the block. That hash value is\ncopied to the successor in the chain, and also serves as input to the hash value\nof the succeeding block. This cryptographic linking between two blocks is\n \nDS 4.01\n\n\n592\nCHAPTER 9. SECURITY\nFigure 9.20: The principle of a blockchain.\nimportant. Suppose that block Bi has hash value hi and its successor, Bi+1\nhas hash value hi+1. Obviously, any change of block Bi will invalidate hi. An\nattacker may compute a new hash value, say h∗\ni , but this value will have to\nbe propagated to block Bi+1, in turn invalidating hi+1. In other words, an\nattack can be successful only if all blocks succeeding Bi are modified as well.\nConsidering that a blockchain is assumed to be a read-only data structure, it\nwill most likely have been massively replicated. Changing the chain while\ngoing unnoticed is deemed to be too difficult, to say the least.\nA transaction can, in principle, take any form. Important is that a transac-\ntion has been validated, for example because signatures of the parties involved\nin the transaction have been verified as well as the content of the transaction.\nWhat this validation entails is thus specific to the application of a blockchain.\nAs a simple example, consider an e-voting system that is implemented\nusing a blockchain.\nIn such a system, voters are assumed to have been\nregistered (and verified that they are entitled to vote). Registration entails\nthat a voter receives a single token that is to be used for voting. When Alice\nwants to cast her vote, she can essentially engage in a transaction with her\nfavorite candidate, say Bob, and transfer the token to Bob. The latter is the\nactual transaction. Validating that transaction means, for example, that the\nentire chain needs to be checked to see whether that token had not been used\nbefore. Of course, e-voting through blockchains violates some of its claimed\nadvantages, such as being fully decentralized.\nE-voting by making use of blockchains is also illustrative in the face of\ntrust. Although one can set up a system with a tamper-proof and verifiable\ndistributed ledger, may not be enough to warrant trust. In the case of e-voting,\nPark et al. [2021] are clear: blockchains suffer from the same problems as\nany electronic voting system. What it then boils down to is that one needs to\ntrust that the distributed system has been properly implemented and secured\nagainst attacks.\nAs also argued by Werbach [2018], it is not just that one needs to trust\nthe correctness of the implementation of a system, but also that it functions\nDS 4.01\n \n\n\n9.5. AUTHORIZATION\n593\nas intended. In the case of blockchains, an upcoming phenomenon is the\nuse of smart contracts: programs that are automatically executed when\ncertain conditions are met within a block. This can be as simple as sending\na notification to Alice and Bob when their transaction made it to the chain,\nbut could also entail automatically engaging new transactions. Even if such\ncontracts can be proven to be correct given a specification, the question is\nwhether the specification meets intentions. Practice in law shows that humans\nare not always that good at transforming intentions into specifications (or\nregulations).\nFinally, the claim that (permissionless) blockchains do not require trust in\neach participating entity, but that only the ledger needs to be trusted, may\nnot stand so firm. In practice, there are intermediaries who offer services to\nend users for making use of blockchain applications, if only to make it easy\nfor people to participate. Those intermediaries, and the systems they use,\nwill need to be trusted. In many ways, blockchain systems and any other\ndistributed system share a lot when it comes to trusting a system.\nFor an extensive and in-depth discussion on trust in computer systems,\nwe refer the interested reader to Bursell [2022].\n9.5\nAuthorization\nWe now concentrate on providing an entity proper access to a system’s\nresources after that entity has been authenticated.\n9.5.1\nGeneral issues in access control\nTo understand the various issues involved in access control, the simple model\nshown in Figure 9.21 is generally adopted. It consists of subjects that issue a\nrequest to access an object. An object is very much like the objects we have\nbeen discussing so far. It can be thought of as encapsulating its own state and\nimplementing the operations on that state. The operations of an object that\nsubjects can request to be carried out are made available through interfaces.\nSubjects can best be thought of as being processes acting on behalf of users,\nbut can also be objects that need the services of other objects in order to carry\nout their work.\nFigure 9.21: General model of controlling access to objects.\n \nDS 4.01\n\n\n594\nCHAPTER 9. SECURITY\nControlling the access to an object is all about protecting the object against\ninvocations by subjects that are not allowed to have specific (or even any) of the\nmethods carried out. Also, protection may include object management issues,\nsuch as creating, renaming, or deleting objects. Protection is often enforced\nby a program called a reference monitor. A reference monitor records which\nsubject may do what, and decides whether a subject is allowed to have a\nspecific operation carried out. This monitor is called (e.g., by the underlying\ntrusted operating system) each time an object is invoked. Consequently, it is\ncritical that the reference monitor is itself tamperproof: an attacker must not\nbe able to fool around with it.\nAccess control policies\nWhen considering the protection of an application, there are essentially three\napproaches that can be followed, as shown in Figure 9.22. The first approach\nis to concentrate directly on the protection of the data that is associated with\nthe application. By direct, we mean that irrespective of the various operations\nthat can possibly be performed, the primary concern is to ensure data integrity.\nTypically, this type of protection occurs in database systems in which various\nintegrity constraints can be formulated that are automatically checked each\ntime a data item is modified (see, for example, Doorn and Rivero [2002]).\nThe second approach is to concentrate on protection by specifying exactly\nwhich operations may be performed, and by whom, when certain data or\nresources are to be accessed. In this case, the focus of control is strongly\nrelated to access control mechanisms, which we discuss extensively later\nin this chapter. For example, in an object-based system, it may be decided\nto specify for each method that is made available which specific clients are\npermitted to invoke that method. Alternatively, access control methods can be\napplied to an entire interface offered by an object, or to the entire object itself.\nThis approach thus allows for various granularities of access control.\nA third approach is to focus directly on users by taking measures by which\nonly specific people, or their proxies in the case of, for example, delegation,\nhave access to the application, irrespective of the operations they want to carry\nout. For example, Alice may have been given read access to a specific file, but\nno write access. On the other hand, Bob may be allowed to change the file,\nor even delete it. Again, combinations of these three approaches are possible\nand occur in practice.\nIn general, we can distinguish several access control policies. A common\ndistinction is often made into the following four types:\n1. Mandatory access control\n2. Discretionary access control\n3. Role-based access control\nDS 4.01\n \n\n\n9.5. AUTHORIZATION\n595\n(a)\n(b)\n(c)\nFigure 9.22: Three approaches for protection against security threats. (a) Pro-\ntection against invalid operations, (b) Protection against unauthorized opera-\ntions. (c) Protection against unauthorized callers.\n4. Attribute-based access control\nPerhaps conceptually the simplest access control policy is that of Mandatory\nAccess Control (MAC). In this case, access control policies are decided beyond\nthe control of an individual: a central administration defines who gets access\nto what. In the context of military security, data is typically labeled according\nto some level of secrecy, ranging from “public access” to “top secret.” Only\nif Alice has been assigned the appropriate confidentiality level, will she get\naccess to data up to that level. Although conceptually simple, mandatory\naccess control can be quite difficult from a security-management perspective.\nEasier and generally more common in many distributed systems is to\nmake use of Discretionary Access Control (DAC). In this case, the owner of\nan object (such as a file) is entitled to change access rights (such as read, write,\nor execute), but also who may have access to that object. Typically, in Unix\nsystems a distinction is made between the owner, a group, and the world.\nMAC and DAC are often seen to be combined.\nAs a next step, we can make objects in a distributed system less dependent\non owners, but instead concentrate on how they are supposed to be used by\nlooking at the roles of people. This leads to what is known as Role-based\n \nDS 4.01\n\n\n596\nCHAPTER 9. SECURITY\nAccess Control (RBAC) [Ferraiolo et al., 2007]. The essence of RBAC is\nthat users are not authorized based on their identity, but based on the role\nthey have within an organization. For example, within a university, we can\ndistinguish roles such as teacher, student, project controller, data steward,\ngroup leader, dean, etc. When Alice is authenticated, she will also be linked\nto a role, which may need to be indicated at the time she logs into the system.\nThen, in the associated role, she will have been granted various access rights\nto specific objects.\nMore recently, attention is being paid to Attribute-based Access Control\n(ABAC) [Hu et al., 2014; 2015]. In ABAC, attributes of users and of objects they\nwant to access are considered for deciding on the specific access rule. ABAC\nallows for much finer-grained access control in comparison to RBAC. For\nexample, not all teachers at a university may be allowed access to the exam\nresults of all students. Instead, one may want to formulate the constraint that\nonly teachers of the Distributed Systems course have read access to grades\nfrom students enrolled in that course. Likewise, only the formal leader of the\ngroup on Pervasive Systems may be entitled to read the yearly review reports\nfrom members in that group, except the ones of the full professors. We will\nreturn to ABAC later in this chapter.\nAccess control matrix\nA common approach to modeling the access rights of subjects with respect to\nobjects is to construct an access control matrix. Each subject is represented\nby a row in this matrix; each object is represented by a column. If the matrix\nis denoted M, then an entry M[s, o] lists precisely which operations subject s\ncan request to be carried out on object o. In other words, whenever a subject s\nrequests to perform the operation m on object o, the reference monitor should\ncheck if m is listed in M[s, o]. If m is not listed in M[s, o], the execution of the\noperation fails.\nConsidering that a system may easily need to support thousands of users\nand millions of objects that require protection, implementing an access control\nmatrix as a true matrix, is not the way to go. Many entries in the matrix will\nbe empty: a single subject will generally have access to relatively few objects.\nTherefore, other, more efficient ways are followed to implement an access\ncontrol matrix.\nOne widely applied approach is to have each object maintain a list of the\naccess rights of subjects that want to access the object. In essence, this means\nthat the matrix is distributed column-wise across all objects, and that empty\nentries are left out. This type of implementation leads to what is called an\naccess control list (ACL). Each object is assumed to have its own associated\nACL.\nAnother approach is to distribute the matrix row-wise by giving each sub-\nject a list of capabilities it has for each object. A capability thus corresponds\nDS 4.01\n \n\n\n9.5. AUTHORIZATION\n597\nto an entry in the access control matrix. Not having a capability for a specific\nobject means that the subject has no access rights for that object.\nA capability can be compared to a ticket: its holder is given certain rights\nthat are associated with that ticket. It is also clear that a ticket should be\nprotected against modifications by its holder. One approach that is particu-\nlarly suited in distributed systems, is to protect (a list of) capabilities with a\nsignature.\nThe difference between how ACLs and capabilities are used to protect the\naccess to an object is shown in Figure 9.23. Using ACLs, when a client sends\na request to a server, the server’s reference monitor will check whether it\nknows the client and if that client is known and allowed to have the requested\noperation carried out, as shown in Figure 9.23(a).\n(a)\n(b)\nFigure 9.23: Comparison between ACLs and capabilities for protecting objects.\n(a) Using an ACL. (b) Using capabilities.\nWhen using capabilities, a client simply sends its request to the server.\nThe server is not necessarily interested in whether it knows the client; the\ncapability may say enough. However, such an approach does not prevent a\nclient to pass its capability to another program. This is precisely the problem\nof delegation that we discussed before. Therefore, in practice, the client will\none way or the other have been registered at the server, while the capability\nis simply bound to that specific client. At that point, the server need only\ncheck whether the capability is valid (i.e., belongs to the client) and whether\nthe requested operation is listed in the capability. This approach to protecting\nobjects using capabilities is shown in Figure 9.23(b).\n \nDS 4.01\n",
      "page_number": 600
    },
    {
      "number": 60,
      "title": "Segment 60 (pages 608-619)",
      "start_page": 608,
      "end_page": 619,
      "detection_method": "topic_boundary",
      "content": "598\nCHAPTER 9. SECURITY\n9.5.2\nAttribute-based access control\nLet us concentrate a bit more on an emerging type of access control, namely the\none based on attributes. Attribute-based access control (ABAC) is a powerful\naccess control policy that can viewed as superseding other policies. Yet, ABAC\nstill has a long way to go when it comes to its adoption in distributed systems,\nas also explained by Servos and Osborn [2017] who investigated the various\nissues and challenges that ABAC is facing.\nBasic model\nIn essence, ABAC assumes that access policies are described in terms of\nattributes and their values. Attributes can belong to many things, including\nusers, objects, and also the current state of a distributed system. To make\nthings concrete, let us consider ABAC for a university setting. We could then\nhave the following:\n• User attributes may include name, data of birth, current roles, home\naddress, department, qualifiers obtained, contract status, etc. Depending\non the role (e.g., teacher or student), a different set of attributes may be\nrelevant.\n• Object attributes can be anything, such as creator, last-modified time,\nversion number, file type, file size, but also information related to its\ncontent, such as the student or course associated with the object.\n• Environmental attributes describe the current state of the system in\nwhich access is requested, including date and time, current workload,\nmaintenance status, storage properties, available services, and such.\n• Connection attributes provide information on the current session, for ex-\nample an IP address, session duration, available bandwidth and latency\nestimates, type and strength of security used, and so on.\n• Finally, administrative attributes may reflect global policies, including\nminimal security settings, general access regulations, and maximum\nsession durations, to name a few.\nExample: The Policy Machine\nTo make matters concrete, let us look at an example system for attribute-based\naccess control, namely the Policy Machine, described in [Ferraiolo et al.,\n2011; 2015]. The architecture of the Policy Machine is a simple client-server\nmodel, where a centralized server maintains a database of (attribute,value)\npairs associated with users, applications, operations, and objects. At the client\nside, a small support program is used to communicate with the server, notably\nfor handling the access privileges of client-side applications. Obviously, the\nserver and the client-side support program need to be trusted to work as\nDS 4.01\n \n\n\n9.5. AUTHORIZATION\n599\nspecified. Essential to the Policy Machine is the expression of access control\nrules. To that end, a distinction is made between assignments, prohibitions,\nand obligations.\nAn assignment is simply telling the system that a user u has an associated\nattribute ua: u is said to be assigned to ua, denoted as u →ua. Likewise, an\nobject o can be assigned to an object attribute oa. In the same fashion, an\nattribute can be assigned to another attribute. For example, if ua1 →ua2, then\nall users associated with ua1 will also be associated with ua2. Assignments\nthus essentially yield sets: if u →ua, then u ∈ua.\nIn a similar vein, user attributes can be assigned to operation sets, and\noperation sets can be assigned to object attributes. This leads to triplets of the\nform allowed(ua, ops, oa) which expresses that a user u can perform operation\nop on object o only if u ∈ua, op ∈ops, o ∈oa.\nA prohibition expresses what users or applications are not allowed to\ndo. In particular, a user can be denied certain operations of certain objects,\nexpressed as denied(u, ops, os) with ops a set of operations and os a set of\nobjects. To ensure that operations are truly restricted to a given set of objects,\nthat is, denied to all other objects, the Policy Machine supports expressions\ndenied(u, ops, ¬os). In other words, if u requests to perform operation op ∈ops\non an object o ̸∈os, the Policy Machine will deny that request.\nFinally, an obligation is used to automatically take actions when certain\nevents happen. A simple example is denying a user to copy information from\none set of files to another:\nwhen u reads f ∈fs then denied(u, {write}, ¬fs).\nThis is an interesting example in the sense that it forms the basis for preventing\ninformation leakage. We have mentioned only a part of what can be expressed\nby the Policy Machine, yet it should be clear that attribute-based access control\nis by itself a powerful approach for expressing many kinds of access control\npolicies. Interestingly, the Policy Machine can also be used for MAC, DAC,\nand RBAC.\nThe simplest case is perhaps RBAC. By simple assignments such as Alice →\nTeachers we effectively assign the role of teacher to Alice. Alice can be assigned\nother roles as well, but the important aspect is that the system will take those\nroles as its starting point for access control.\nWe do note that advanced\nRBAC schemes require more sophisticated assignments in terms of the Policy\nMachine, yet the principle should be clear.\nWhen it comes to mandatory access control (MAC), the basic idea is that\none can introduce a notion of security levels L1, . . . , Ln where L1 denotes the\nlowest and Ln the highest level of security. More concrete, if Alice has access\nto “top secret” documents, she should also have access to “secret” documents.\nThe idea is straightforward: each object is assigned to an appropriate object\nsecurity-level attribute, such as OLi. Likewise, each user is assigned to a\n \nDS 4.01\n\n\n600\nCHAPTER 9. SECURITY\nuser security-level attribute, such as ULj. Moreover, each user security-level\nattribute ULi is assigned to ULi−1 indicating that all users assigned to ULi have\nthe same rights as users at a less secure level, represented by the user attribute\nULi−1.\nThe real issue with MAC is that we need to prevent information leaking\nfrom higher levels to lower levels. As before, this can be prevented by the\nobligation\nwhen u reads f ∈OLi then denied(u, {write}, ¬{∪n\nk=iOLk}).\nSo, for example, if we have five security levels, then anyone who reads a\ndocument from level OL3, cannot write to documents at level {OL1, OL2} or\nequivalently cannot write to documents not in {OL3, OL4, OL5}.\nFinally, let us have a look at discretionary access (DAC). The essence of\nDAC is that each object has an owner, and that this owner can actually set\naccess rights for others. For example, in Unix systems, a user alice belonging\nto a group teachers can set read, write and execute access rights for herself,\nmembers of the group teachers, and anyone else. A user with administrative\nprivileges (typically, the root user) can additionally assign objects to users and\ngroups. Some simple examples illustrate these principles.\nalice$ chmod u=rw,g=r,o= document\nexpresses that user alice changes the rights for herself to read (r) and write (w)\ndocument, yet allows members of the group to which document has been as-\nsigned to only read the file, while anyone else has no access rights whatsoever.\nLikewise,\nroot# chown alice:teachers document\ntells us that the user root assigns ownership of document to user alice and\ngroup teachers.\nFollowing Ferraiolo et al. [2011], one can create a unique user attribute per\nuser. So, Alice would be known to the system by assigning her to the user\nattribute alice. Likewise, each group is represented by a user attribute, and\nwe could, for example, perform the assignment alice →teachers. Following\nUnix conventions, we create an object attribute alice home which represents\nthe home directory of user alice. The trick is to make sure that Alice is entitled\nto execute an appropriate set of administrative commands, but also to ensure\nthat the results match the DAC model. For example, we would need Alice\nto allow to create objects within the home directory. This can be done by\nassigning a create operation to the object attribute alice home and installing\nthe obligation\nwhen alice performs create(o) at alice home then o →alice home.\nDS 4.01\n \n\n\n9.5. AUTHORIZATION\n601\nWhen considering the Unix DAC model, in which (almost) everything is a file,\nwe also need to consider creating objects that represent a subdirectory. Again,\nbeing a directory can be expressed in terms of an object attribute, and typically\neach directory object will need to be associated with a parent directory. In\ngeneral, we may thus have:\nwhen alice performs create(o) at directory then o →directory.\nThese examples also illustrate that expressing a DAC model in an ABAC\nmodel requires careful consideration of all the operations and elements of\nthe specific DAC model at hand. In fact, being able to accurately and com-\npletely expressing other models in terms of attribute-based access control is\nconsidered to be one of the open challenges [Servos and Osborn, 2017].\n9.5.3\nDelegation\nNow consider the following problem. A user Alice makes use of an e-mail\nservice provider who stores her mailbox somewhere within that provider’s\norganization. Typically, she is required to log in to the provider through her\nWeb browser, after which she gets to see an appropriate interface for handling\nher mail. However, Alice would prefer to use her own favorite mail client,\nwhich is installed on her laptop. The core question is how to allow that mail\nclient to act on behalf of Alice? In other words, the mail client would need\nto get access to Alice’s mailbox, and allow her to then retrieve new mail,\nread mail, send mail, and so on. In essence, Alice would like to delegate her\naccess rights to the mail client, and in such a way that the mail client can also\nautomatically log in and do its work.\nDelegation of access rights is an important technique for implementing\nprotection in computer systems and distributed systems, in particular. The\nbasic idea is simple: by passing certain access rights from one process to\nanother, it becomes easier to distribute work between several processes without\nadversely affecting the protection of resources. In the case of distributed\nsystems, processes may run on different machines and even within different\nadministrative domains. Delegation can avoid much overhead, as protection\ncan often be handled locally.\nThere are several ways to implement delegation. The least favorable one\nis to hand over the user credentials directly to an application. In fact, doing\nso would be a bad idea: there is, in general, no reason to trust an application\nor the machine it is running on. A much better and general approach, as\ndescribed by Neuman [1993] and implemented in the Kerberos system, is to\nmake use of a proxy. A proxy in the context of security in computer systems\nis a token that allows its owner to operate with the same or restricted rights\nand privileges as the subject that granted the token. A process (or user for\nthat matter) can create a proxy with at best the same rights and privileges it\nhas itself. If a process creates a new proxy based on one it currently has, the\n \nDS 4.01\n\n\n602\nCHAPTER 9. SECURITY\nderived proxy will have at least the same restrictions as the original one, and\npossibly more.\nBefore considering a general scheme for delegation, consider the following\ntwo approaches. First, delegation is relatively simple if Alice knows everyone.\nIf she wants to delegate rights to Bob, she merely needs to construct a certifi-\ncate saying “Alice says Bob has rights R,” such as [A, B, R]A (i.e., the message\ncontaining the identifiers A of Alice and B of Bob, along with the specified\naccess right R, and subsequently signed by Alice). If Bob wants to pass some\nof these rights to Chuck, he will ask Chuck to contact Alice and ask her for an\nappropriate certificate.\nIn a second case, Alice can simply construct a certificate saying, “The\nbearer of this certificate has rights R.” However, in this case, we need to\nprotect the certificate against illegal copying. Neuman’s scheme handles this\ncase, as well as avoiding the issue that Alice needs to know everyone to whom\nrights have to be delegated. Note that in this case, she does trust Bob in\ndelegating rights to Chuck. In practice, this means that the user Alice trusts\nthe application to which she delegated some rights, to correctly and justifiably\ndelegate some of those rights to another application (she may not even be\naware of). One obvious way to prevent further delegation is to ensure that it\nis not specified as part of Bob’s rights. The service that hands out a delegation\ncertificate for Bob, will check whether he actually is authorized to do so.\nA proxy in Neuman’s scheme has two parts, as illustrated in Figure 9.24.\nLet A be the process that created the proxy. The first part of the proxy is\na set C = {R, PKproxy}, consisting of a set R of access rights that have been\ndelegated by A, along with a publicly known part of a secret that is used to\nauthenticate the holder of the certificate. We will explain the use of PKproxy\nbelow. The certificate carries the signature sig(A, C) of A, to protect it against\nmodifications. The second part contains the other part of the secret, denoted\nas SKproxy. It is essential that SKproxy is protected against disclosure when\ndelegating rights to another process.\nFigure 9.24: The general structure of a proxy as used for delegation.\nAnother way of looking at the proxy is as follows. If Alice wants to\ndelegate some of her rights to Bob, she makes a list of rights (R) that Bob\ncan exercise. By signing the list, she prevents Bob from tampering with it.\nHowever, having only a signed list of rights is often not enough. If Bob would\nlike to exercise his rights, he may have to prove that he actually got the list\nDS 4.01\n \n\n\n9.5. AUTHORIZATION\n603\nfrom Alice and did not, for example, steal it from someone else. Therefore,\nAlice comes up with a very nasty question (PKproxy) that only she knows the\nanswer to (SKproxy). Anyone can easily verify the correctness of the answer\nwhen given the question. The question is appended to the list before Alice\nadds her signature.\nWhen delegating some of her rights, Alice gives the signed list of rights,\nalong with the nasty question, to Bob. She also gives Bob the answer, ensuring\nthat no one can intercept it. Bob now has a list of rights, signed by Alice,\nwhich he can hand over to, say, Chuck, when necessary. Chuck will ask him\nthe nasty question at the bottom of the list. If Bob knows the answer to it,\nChuck will know that Alice had indeed delegated the listed rights to Bob.\nAn important property of this scheme is that Alice need not be consulted.\nIn fact, Bob may decide to pass on (some of) the rights on the list to Dave. In\ndoing so, he will also tell Dave the answer to the question, so that Dave can\nprove the list was handed over to him by someone entitled to it. Alice never\nneeds to know about Dave at all.\nA protocol for delegating and exercising rights is shown in Figure 9.25.\nAssume that Alice and Bob share a secret key KA,B that can be used for\nencrypting messages they send to each other. Then, Alice first sends Bob\nthe certificate [R, PKproxy]A, signed by Alice. There is no need to encrypt this\nmessage: it can be sent as plaintext. Only the private part of the secret needs\nto be encrypted, shown as KA,B(SKproxy) in message 1.\nFigure 9.25: Using a proxy to delegate and prove ownership of access rights.\nNow suppose that Bob wants to carry out an operation at a specific server.\nAlso, assume that Alice is authorized to have that operation carried out, and\nthat she has delegated those rights to Bob. Therefore, Bob hands over his\ncredentials to the server in the form of the signed certificate [R, PKproxy]A.\nAt that point, the server will be able to verify that C has not been tampered\nwith: any modification to the list of rights, or the nasty question will be\nnoticed because both have been jointly signed by Alice. However, the server\ndoes not know yet whether Bob is the rightful owner of the certificate. To\nverify this, the server must use the secret that came with [R, PKproxy]A. To that\nend, the server sends Bob a nonce (which is just an arbitrarily chosen string)\nN, encrypted with PKproxy. By decrypting PKproxy(N) and returning N, Bob\nproves he knows the secret and is thus the rightful holder of the certificate.\n \nDS 4.01\n\n\n604\nCHAPTER 9. SECURITY\nNote 9.6 (More information: OAuth (Open Authorization))\nDelegation is, in principle, fairly straightforward.\nYet, it has already taken\nmany years to come to a practical scheme that was acceptable by many players.\nAlso, solutions that are designed by multiple parties coming from different\norganizations tend not to be examples of simplicity, to say the least. This is\ncertainly true for Open Authorization, generally known as OAuth. Nevertheless,\nOAuth is by now an important delegation protocol used by many organizations\nincluding Amazon, Google, Facebook, Microsoft, and Twitter. Its main purpose\nis to grant an application access to resources that are normally accessible to a\nuser only through a Web interface. A typical example is that of using a local mail\nclient, which acts on behalf of its owner, as described previously.\nLet us take a closer look at the OAuth 2.1 framework, which distinguishes\nfour different roles:\n• A resource owner, which is typically an end user, such as Alice who\nnormally accesses her mail through her provider’s Web service.\n• A client, which is an application that one would like to act on behalf of the\nresource owner, such as an e-mail client.\n• A resource server, in practice forming some kind of Web interface through\nwhich a person like Alice would normally first authenticate herself after\nwhich she can access and manage her mail.\n• An authorization server, forming the core entity when it comes to handing\nout certificates to a client on behalf of a resource owner.\nThe client application will have to be known at the authorization server\nthrough some separately executed registration process (which can also take place\nas part of the delegation process). The result is that the client receives its own,\nunique identifier, say cid. When Alice wants her application to operate on her\nbehalf when it comes to a list R of rights, the application sends\nClient: send [cid, R,H(S)]\nin which the hash of a temporary secret S is sent, computed with the hash\nfunction H. As its name suggests, the secret S is (for now) known only to the\nclient application. In the message above, we omit some additional information,\nsuch as details of the hash function, as well as some other options.\nIf Alice is not yet logged in to the authorization server, she will be required to\ndo so and confirm that the client application is entitled to the rights as expressed\nby R. At that point, the client receives a temporary authorization code AC from\nthe server, which it should use to get the final access token. The client then sends\na request for that token:\nClient: sends [cid, AC, S].\nBy sending the secret S to the authorization server, the latter can check that it is\ndealing with the same client application as before, as it simply needs to compute\nH(S) that was sent with the previous message from that application. Note that\nby now, the authorization server has verified that Alice indeed wants to delegate\nDS 4.01\n \n\n\n9.5. AUTHORIZATION\n605\naccess rights to the client. The client simply needs to prove that it is the same\none that initiated the delegation request. If all is verified, the authorization server\nreturns an access token AT to the client.\nIt should be clear that an access token is precious data: it gives the client\napplication the same rights as Alice would have when going directly to the\nresource server. Therefore, the access token is communicated through a secure\nchannel, and is also stored securely on the machine hosting the client (such as\nAlice’s laptop). Likewise, one way or the other the client will have to authenticate\nitself, which is determined at registration time. There are different ways OAuth 2.1\nsupports authentication, a simple one being the scheme by which the client has\na private key and the server keeps the associated public key, as we explained\npreviously, when discussing SSH.\nOAuth 2.1 distinguishes two types of access tokens. The first one is essentially\njust an identifier that the resource server can use to check the access rights of the\nclient application. It does so by passing the token to the authorization server and\nretrieving those rights. This scheme requires that the resource server contacts the\nauthorization server every time the client wants to perform an operation.\nThe second type takes the form of a (signed) certificate: it contains all the\naccess rights of the client as granted by Alice. Those rights will hold until the\ncertificate expires (and indeed, with this type of access token, there is an associated\nexpiration time).\nWe have given a very concise description of OAuth 2.1, omitting many details\nand many of its options. The specification of OAuth 2.0 is found in [Hardt et al.,\n2012]. There are also several books that explain how to set up clients and servers\nso that they adhere to the framework (see, e.g., Parecki [2020] and Boyd [2012]).\n9.5.4\nDecentralized authorization: an example\nSo far, we have been discussing various authentication and authorization\nsolutions, of which many have in common that there is a centralized compo-\nnent where permissions are checked and granted (or denied). For example,\nKerberos deploys a centralized authentication server and a centralized ticket-\ngranting service. Likewise, when dealing with delegation, a client application\ngenerally needs to be registered at an authorization server to receive a capa-\nbility to perform certain operations at a service, or that the service can check\nthe permissions at the authorization server. Each of these types of centralized\nservices will have been made robust through replication using protocols such\nas Paxos or Byzantine Fault Tolerance. Also, using straightforward workload-\nbalancing schemes, we can relatively easily scale out servers. For example, we\nmay decide that all requests coming from applications with an ID less than\nsome value K go to server #1, while the requests from other applications go to\nserver #2.\nThe situation becomes more difficult when we decentralize a service\nacross multiple administrative units, such as across different departments or\n \nDS 4.01\n\n\n606\nCHAPTER 9. SECURITY\norganizations. We then bump into the problem of administrative scalabil-\nity [Neuman, 1994]. In this section, we take a look at a scalable decentralized\nauthorization service, called WAVE, specifically developed to operate across\nmultiple organizations. WAVE is a good example of some of the things we\nneed to deal with when scaling out across administrative domains. Detailed\ninformation on WAVE can be found in [Andersen, 2019; Andersen et al., 2019].\nGraph-based authorization\nFundamental to the WAVE framework is the application of graph-based\nauthorization. In this scheme, a global, possibly worldwide directed graph\nis maintained. Each vertex represents an entity that is capable of granting\nor receiving permissions. For example, a vertex may represent Alice’s home\ndirectory (where she has the right to, for example, create and delete files, and\nset various permissions, including giving Bob access to some files). A vertex\ncould also represent a department in charge of a collection of applications, an\nonline cloud service that offers various resources, and so on. Each entity has a\ncollection of public keys, from which a hash is derived that serves as a means\nto look up those keys. The collection of associated private keys is, of course,\nkept secret by the party represented by the entity. The key pairs are used for\nvarious protections and signatures that we describe below.\nEach directed edge represents a delegation of permissions from one entity\n(the issuer) to another (the subject). For example, Alice can, as an issuer,\ndelegate specific file permissions to Bob, the subject. In WAVE, an edge\nrepresents an attestation. Permissions are always granted on resources, such\nas files, database (records), devices, and so on. An entity B gathers proof of its\nright to operate on a resource owned by A by showing that there is a directed\npath in the graph from A to B.\nTo this end, WAVE uses a policy mechanism called an RTree, which stands\nfor resource tree. Keeping it simple, a resource is denoted by a URI such\nas user-entity/music/albums/popular/band/. The first element in the URI is\nparticularly important: it identifies the entity responsible for the resource\nand the one which is responsible for all permissions. Each resource has\nan associated collection of permissions, which is part of an RTree.\nThe\nidentification of a resource, a specification of granted permissions on that\nresource, a duration for which the grant is valid, and possible restrictions on\nfurther delegation add up to an RTree statement. An attestation will then\nroughly consist of:\n• The hash of the issuer and that of the subject.\n• Identifiers of where information on issuer and subject can be found.\n• A set of RTree statements.\n• A signature of the issuer.\nDS 4.01\n \n\n\n9.5. AUTHORIZATION\n607\nThere is more related to an attestation, which we describe below. Andersen\n[2019] shows that with these basic ingredients, graph-based authorization can\nbe used to emulate DAC and RBAC models.\nThere are two important issues that need to be dealt with. First, the\ngraph needs to be stored and maintained in a scalable and fully decentralized\nfashion. Second, delegating permissions is one thing, but letting the whole\nworld know that Alice delegated specific permissions to Bob is maybe not\nsuch a good idea. In other words, there is data that needs to be protected. Let\nus next look into these issues.\nDecentralized storage\nIt is important to realize that the authorization service need, essentially,\nstore information only on resources and attestations. Moreover, there should\npreferably be no reason at all to trust the storage: the less, the better. As we\nstated before, there is increasingly more interest in using distributed systems\nin which the individual participating parties need not be trusted. Instead, one\nrelies on the fact that the system ensures that the provided information can be\ntrusted. This is precisely what happens in distributed ledgers implemented\nas blockchains. A similar reasoning is applied in WAVE: assuming that each\nentity is responsible for its own resources, then the party represented by that\nentity need not be trusted, as long as the information it provides is reliable.\nIn essence, only availability of relevant information is required. With this in\nmind, Andersen [2019] formulated the following minimal requirements for\nstorage:\n1. Proof of monotonicity: A storage operates as an unforgeable append-\nonly log.\n2. Proof of inclusion: When an object is added or retrieved, it must exist\nin storage.\n3. Proof of nonexistence: When an object does not exist, the storage should\nstate so.\n4. Proof of nonequivocation: The storage offers the same view to every\nclient.\nTogether, these requirements ensure the integrity of the global authorization\ngraph. Note that these requirements come very close to what blockchain-based\ndistributed ledgers offer.\nAssuming that these requirements can be met, we may also assume that\neach entity offers its own local storage. In this way, scalability should, in\nprinciple, be easy to realize as long as an application can indeed identify the\nlocation where that entity’s information is stored. Including global identifiers\nalong with proper name resolution as provided through DNS should do the\n \nDS 4.01\n\n\n608\nCHAPTER 9. SECURITY\ntrick. Of course, bundling multiple entities so that they make use of the same\nphysical storage may be required for reaching certain efficiency goals, yet it\nshould be clear that size scalability is not fundamentally hindered by letting\neach entity have its own storage. We will subsequently speak of an entity\nstore.\nAgain, keeping things simple, every entity store essentially maintains an\nappend-only operation log. Every time an object is appended to the log, it is\ncryptographically bound to its predecessor, very much like the secure linking\nin blockchains. In addition, the hash value of the appended object is securely\nappended to a separate map log, which is subsequently returned to the client\nperforming the operation on the entity store.\nWhen a client wants to retrieve on object (such as an attestation), it provides\nthe entity store with the appropriate object identifier (namely its hash value)\nand its most recent version of the map log. Suppose the object has indeed\nbeen logged. The store will return (1) the object, (2) a proof that the object\nexisted in the operation log (by returning a chain of hashes), (3) that the hash\nassociated with the object is part of the map log, and (4) that the current map\nlog is consistent with the one the client provided. Along the same lines, if the\nobject does not exist, the store simply returns nil and proves that the object\nwas not in the operation log by demonstrating that the hash value can never\nbe part of the map log.\nMeanwhile, separate processes regularly audit an entity store by recon-\nstructing the operation log and checking its consistency with what is in the\nstore. The scheme we just described is incomplete. More information can be\nfound in [Andersen, 2019].\nData protection\nFinally, let us see how data, and in particular attestations, can be protected.\nAgain, we concentrate on only the simplest case of WAVE, called structural\nsecurity. Assume A creates and attestation att for B. It appends the decryption\nkey SKatt\nA to the message, but not after encrypting it with an appropriate public\nkey PKatt\nB (as we shall see shortly, adding the decryption key by A, and only\nA, is strictly speaking not necessary):\nA sends: PKatt\nB ([att|SKatt\nA ]\n|\n{z\n}\nm1\n))\nLet us now also assume that B creates an attestation att′ for C that is\nderived from att. For example, if att allowed B to write to a specific file and\nto pass on read permissions to others, B may allow C to read the file. No one\nbut A, B, and C should know about this: it is simply no one else’s business.\nHowever, in order for C to read the file, it will have to prove it may do so.\nDS 4.01\n \n\n\n9.6. MONITORING\n609\nWhen B creates att′, it sends the following to C:\nB sends: PKatt′\nC ([att′|m1|SKatt\nB ]\n|\n{z\n}\nm2\n)\nBeing able to decrypt this message, C will find att′, m1, and SKatt\nB . Having\nSKatt\nB , it can decrypt m1 revealing att. Note that there is no reason for either\nA or B to be online: C has all the information it needs to prove it is allowed\nto read the file. It should now also be clear that having A also send SKatt\nA\nis not necessary. We include it to show the systematic approach of chaining\nattestations such that a node on a path can reveal all necessary attestations in\na reverse order. Note, by the way, that this scheme strongly resembles the way\nthat delegation is handled in Kerberos.\n9.6\nMonitoring\nAn important security aspect of any system is to check that policies are\nsufficient, correctly implemented, and enforced. It would be naive to assume\nthat this is always the case. For this reason alone, it is important to keep track\nof what is going on in a distributed system so that proper measures can be\ntaken when needed. A passive way of keeping track is to simply log special\nevents: when do users sign in to a system, when and which applications\naccess specific resources, and so on. Logging is important to understand what\nto do after the fact, yet will not help when the damage has been done. In\nthis section, we take a closer look at an increasingly more important aspect\nof monitoring for security, namely intrusion detection, which is all about\ndetecting unauthorized activities. As intrusion detection is often tied to a\nsingle computer, we only briefly discuss the basics to subsequently concentrate\non distributed monitoring. We start our discussion by having a look at an\nalmost ubiquitous intrusion-detection system, namely firewalls.\n9.6.1\nFirewalls\nBefore we take a look at the basics of intrusion detection, consider a common\napproach to ensuring that intruders stay out: using a firewall [Cheswick and\nBellovin, 2000; Zwicky et al., 2000]. Firewalls form one of the most often\nused protection mechanisms in networked systems. Essentially, a firewall\ndisconnects any part of a distributed system from the outside world, as shown\nin Figure 9.26. All outgoing, but especially all incoming packets are routed\nthrough a special computer and inspected before they are passed through.\nUnauthorized traffic is discarded and not allowed to continue. An important\nissue is that the firewall itself should be heavily protected against any kind of\nsecurity threat: it should never fail. Equally important is that the rules that\nprescribe what can pass through are consistent and establish what is intended.\n \nDS 4.01\n",
      "page_number": 608
    },
    {
      "number": 61,
      "title": "Segment 61 (pages 620-627)",
      "start_page": 620,
      "end_page": 627,
      "detection_method": "topic_boundary",
      "content": "610\nCHAPTER 9. SECURITY\nFigure 9.26: A common implementation of a firewall.\nAs reported by Wool [2010] and Voronkov et al. [2017], properly configuring a\nfirewall is a considerable challenge.\nFirewalls essentially come in two different flavors that are often combined.\nAn important type of firewall is a packet-filtering gateway. This type of\nfirewall operates as a router and makes decisions whether to pass a network\npacket based on the source and destination address as contained in the\npacket’s header. Typically, the packet-filtering gateway shown on the outside\nLAN in Figure 9.26 would protect against incoming packets, whereas the one\non the inside LAN would filter outgoing packets. For example, to protect an\ninternal Web server against requests from hosts that are not on the internal\nnetwork, a packet-filtering gateway could decide to drop all incoming packets\naddressed to the Web server.\nMore subtle is the situation in which a company’s network consists of\nmultiple local-area networks. Each LAN can be protected using a packet-\nfiltering gateway, which is configured to pass incoming traffic only if it\noriginated from a host on one of the other LANs. In this way, a private virtual\nnetwork can be set up.\nThe other type of firewall is an application-level gateway. In contrast to a\npacket-filtering gateway, which inspects only the header of network packets,\nthis type of firewall actually inspects the content of an incoming or outgoing\nmessage. A typical example is a mail gateway that discards incoming or\noutgoing mail exceeding a certain size. More sophisticated mail gateways\nexist that are, for example, capable of filtering spam e-mail.\nAnother example of an application-level gateway is one that allows external\naccess to a digital library server, but will supply only abstracts of documents.\nIf an external user wants more, an electronic payment protocol is started.\nUsers inside the firewall have direct access to the library service.\nA special kind of application-level gateway is what is known as a proxy\ngateway. This type of firewall works as a front end to a specific kind of\napplication, and ensures that only those messages are passed that meet certain\ncriteria. Consider, for example, surfing the Web. Many Web pages contain\nDS 4.01\n \n\n\n9.6. MONITORING\n611\nscripts or applets that are to be executed in a user’s browser. To prevent such\ncode to be downloaded to the inside LAN, all Web traffic could be directed\nthrough a Web proxy gateway. This gateway accepts regular HTTP requests,\neither from inside or outside the firewall. In other words, it appears to its\nusers as a normal Web server. However, it filters all incoming and outgoing\ntraffic, either by discarding certain requests and pages, or modifying pages\nwhen they contain executable code.\nIt should be clear that firewalls have important limitations when consid-\nered as a general-purpose security mechanism. As they operate on network\ntraffic, they generally cannot handle authentication and authorization for\nspecific resources. That also means that once an intruder has found a way\nto bypass the rules of a firewall, all bets are off that the firewall can protect\nthe internal network. For example, if an attacker manages to take over an\naccount, all unauthorized accesses will go unnoticed by the firewall. Instead,\nother detection mechanisms need to be in place to discover unusual or even\nunauthorized behavior.\n9.6.2\nIntrusion detection: basics\nIntrusion detection systems generally come in two flavors. In signature-\nbased intrusion detection systems (SIDS) patterns of known network-level\nintrusions have been collected against which a new pattern is matched. If\nthere is a match, security operators are warned that an intrusion may be\ntaking place. Patterns typically consist of a (collection of) specific network\npackets. What can easily complicate discovering patterns is when a pattern\nspans a series of network packets, intertwined with regular traffic. Most\nproblematic with a SIDS is when no pattern is yet available, which typically\nhappens with new, unknown attacks, such as zero-day attacks: attacks based\non vulnerabilities that have not yet been made public [Bilge and Dumitra¸s,\n2012]. The increase of zero-day attacks has rendered SIDS less useful.\nMore important are the anomaly-based intrusion detection systems\n(AIDS). As it name suggests, an AIDS assumes that we can model or extract\ntypical behavior to subsequently detect nontypical, or anomalous behavior.\nAnomaly-based detection relies heavily on modern artificial-intelligence tech-\nnologies, and notably machine learning. To this end, an AIDS will first have to\ngo through a training phase and collect data that reflects typical, nonmalicious\nbehavior. Once appropriate data sets have been collected and a detection\nmodel has been constructed based on that data (such as decision trees, specific\nneural networks, or classifiers), a test phase starts by taking new data and\nletting the model decide on anomalies.\nAn important problem with an AIDS is minimizing so-called false negatives:\nflagging an anomaly as typical behavior. Doing so means that the model\nis missing events that should have been reported to a security operator. To\nminimize false negatives, many systems follow a pessimistic approach and\n \nDS 4.01\n\n\n612\nCHAPTER 9. SECURITY\nflag behavior as being anomalous, in turn leading to many false positives. The\nresult of many false positives is that security operators become weary of all\nthe alerts [Hassan et al., 2019]. Combatting the number of false positives\nwhile still ensuring a very low number of false negatives has proven to be a\ndifficult challenge requiring advanced techniques (see, for example, van Ede\net al. [2022]).\nThere is much more to say about intrusion detection systems. Khraisat\net al. [2019] provide a recent overview; a good introduction is provided by\nBhuyan et al. [2014].\n9.6.3\nCollaborative intrusion detection\nWhen considering large-scale distributed systems, it is clear that there cannot\nbe a single point where monitoring can take place that allows to build a\ncomplete picture of all events that may indicate that the system is under\nattack. This is where a collaborative intrusion detection system (CIDS)\nbecomes relevant. In essence, a CIDS is a collection of intrusion detection\nsystems that share detections and analyses. Each of the IDS is considered to\nbe positioned somewhere in the system. How a CIDS can be organized is\ndiscussed in [Vasilomanolakis et al., 2015], along with examples of existing\nsystems. Here, we concentrate on the effects of such organizations when it\ncomes to successfully detecting intrusions.\nTo this end, and inspired by Cordero et al. [2015], consider a collection of\nsensors that may be spread across a distributed system, each sensor measuring\ndata potentially related to intrusions. For example, a sensor may be one\nthat logs events related to a specific Web application, or one that captures\nnetwork traffic at a specific node in the system. We assume that sensors can,\nin principle, not only collect data, but perform analyses and detect intrusions.\nSensors are grouped into communities. Each community has a community\nhead, which is responsible for collecting the data from the other members in\nits community, as well as conducting analyses on that data and detecting any\nintrusions. Communities may overlap: a sensor may be a member of multiple\ncommunities, in which case it will also report to multiple community heads.\nIn a way, each community can be viewed as a single IDS.\nThe basic idea is that community heads exchange information with each\nother. If this does not happen, nor do any two communities have a sensor\nin common, then we are simply dealing with a collection of isolated IDSs. A\ncommon configuration is to let communities be disjunct, yet all community\nheads report to the same, single entity, leading to what is known as a centralized\nCIDS. More interesting is the configuration in which the community heads\nare organized into some kind of peer-to-peer network, i.e., a distributed CIDS.\nWhy is this setup interesting? As mentioned, from the perspective of\nintrusion detection, it is important to minimize false negatives, while not\nmissing out on actual intrusions, that is, true positives. To be more specific, the\nDS 4.01\n \n\n\n9.7. SUMMARY\n613\nperformance of an IDS is generally measured along the following metrics. We\ndenote by TP the true positives: detections that have been correctly flagged\nas belonging to an intrusion. TN are true negatives: detections that have been\ncorrectly flagged as belonging to authorized behavior. False positives (FP) are\ndetections that are incorrectly labeled as belonging to an intrusion, while false\nnegatives (FN) denote missed intrusion detections. The whole idea is then to\nconfigure the sensors into communities such that accuracy and precision are\nmaximized, with:\nAccuracy:\nACC\n=\nTP + TN\nTP + TN + FP + FN\nPrecision:\nPRE\n=\nTP\nTP + FP\nAn aspect that was further investigated in [Cordero et al., 2015] is to\nhave sensors be member of multiple communities. As a result, some sensors\nmay report their findings to multiple community heads. The question then\nbecomes how to configure the CIDS as a whole in terms of the number of\ncommunities, their sizes, and the sensors reporting to multiple community\nheads. One can expect that in a centralized setup (in particular, with just a\nsingle community and all sensors reporting to a single, centralized entity),\naccuracy and precision are best. This is indeed the case, but obviously, we\nmay have a serious scalability problem when dealing with a large system.\nIn the experiments reported by Cordero et al. [2015], having large com-\nmunities tends to lead to higher accuracy and precision, whereas it is also\nimportant to keep the total number of communities as low as scalability\npermits. Accuracy and precision also benefit from having overlapping com-\nmunities, effectively meaning that sensor findings are considered by multiple\ncommunity heads, to be later combined into the final detections.\nTo what extent the reported experiments are conclusive for other settings\nremains to be seen. However, the approach does give a means to think about\nhow to organize a CIDS while taking scalability and performance into account.\nTypically, running various experiments with different datasets will be needed\nto find a satisfactory configuration.\n9.7\nSummary\nSecurity plays an essential role in distributed systems. A distributed system\nshould provide the mechanisms that allow a variety of different security\npolicies to be enforced. Developing and properly applying those mechanisms\ngenerally makes security a difficult engineering exercise.\nSecure distributed systems are built around at least five design principles:\n(1) having fail-safe defaults, (2) offering designs and implementations that\nare open, (3) providing a separation of privileges, (4) providing only those\n \nDS 4.01\n\n\n614\nCHAPTER 9. SECURITY\nprivileges that are needed, and (5) minimizing redundancy of mechanisms\nand their implementations. Furthermore, we see that it is important to provide\nmechanisms at different layers in a distributed system, ranging from the lower\nlevels of operating systems to layers in which applications are running. In this\nsense, understanding what exactly the trusted computing base entails of a\nsystem is important, as this base that needs to meet all security requirements.\nFinally, and increasingly important, is that distributed systems provide\nprivacy where needed. Guaranteeing that privacy is protected is easier said\nthan done, but the fact that regulations are more firmly installed, such as the\nGDPR, contributes to the awareness that systems should be designed and\ndeveloped with security and privacy built in from the start.\nEssential to realizing secure distributed systems is the understanding and\napplication of cryptography. Next to symmetric and asymmetric cryptosys-\ntems, we see increasingly more cryptographic mechanisms come into practical\nuse due to efficient implementations. Notably homomorphic encryption\nschemes and multiparty computations are gradually seeing their way into\ndistributed systems, mainly because they allow for untrusted third parties,\nsuch as operating in the cloud, to do computations without having to reveal\nsensitive data.\nOne could argue that security in distributed systems largely boils down\nto realizing authentication and authorization.\nAuthentication deals with\nverifying claim identities. Authorization deals with protecting resources in\nsuch a way that only processes that have the proper access rights can actually\naccess and use those resources. Access control always take place after a\nprocess has been authenticated. It is important to realize that having being\nable to verify an identity is not enough for establishing trust.\nAs distributed systems scale out to multiple organizations, we see a de-\nmand for solutions that need to rely less on trusting the individual parties\ninvolved in an application. This is one of the reasons why blockchain-based\nsystems have grown in popularity, yet whether blockchain-based solutions\ncan be taken as a general solution for handling lack of trust remains to be\nseen. Often, simpler and more efficient application-specific solutions may do\nthe job, and perhaps even better.\nBesides cryptography, authentication, and authorization, it is important\nto continuously monitor what is going on in a distributed system. Advances\nin intrusion detection systems have led to using often advanced machine-\nlearning techniques for detecting anomalous behavior. An open question is\nhow such systems can be effectively scaled out to distributed settings.\nMany existing designs of distributed systems have incorporated security\nand privacy as an afterthought, often also because one may easily think that\nsecurity and functionality demand a tradeoff to be made. However, there\nis ample evidence that such a tradeoff is not necessary, provided security is\nconsidered from the start of a design.\nDS 4.01\n \n\n\nINDEX\n2PC, see Distributed commit, two-\nphase protocol\n3PC, see Distributed commit, three-\nphase protocol\nABAC, see Access control, attribute\nbased\nAbstract regions, 49\nAcces control\nlist, 596\nAccess control, 595\nattribute-based, 596, 598\ndiscretionary, 595, 599,600\nmandatory, 595, 599\nmatrix, 596\npolicy, 595\nrole based, 595, 599\nAccess point, 9\nAccess transparency, see Distribu-\ntion transparency\nAccuracy, 613\nACL, see Access control, list\nActivation policies, 155\nActive Directory, 376, 379\nActuator, 43, 51\nAdapter, 75\nAdaptive redirection policy, 166\nAddress Resolution Protocol, 330\nAdvanced Message-Queuing Pro-\ntocol, 227\nchannel, 228\nconnection, 228\nexchange, 231\nlink, 228,229\nnode, 229\nsession, 228\nAIDS, see Intrusion Detection Sys-\ntem, anomaly based\nAkamai, 6, 165, 453\norigin server, 165\nAmazon\nElastic Block Store, 141\nElastic Compute Cloud, 140\nMachine Image, 140\nSimple Storage Service, 66,67,\n75\nAmazon AMI, see Amazon, Machine\nImage\nAmazon S3, see Amazon, Simple\nStorage Service, 99\nbucket, 99\nAMQP, see Advanced Message-Queuing\nProtocol\nApache, 122, 159, 552\nhook, 160\nmodule, 160\nPortable Runtime, 159\nApache APR, see Apache, Portable\nRuntime\nAPI, see Application programming\ninterface\nApplication layer, 188\nApplication programming interface,\n129\nApplication-layer switch, 163\nArchitectural perspective, 8\nArchitectural style, 56\nARP, see Address resolution proto-\ncol\nAsynchronous system, 469\nAtomicity, 189\n615\n\n\n616\nINDEX\nAuthentication, 10, 21, 189\nAuthorization, 21, 189\ngraph-based, 606\nAutonomous System, 426\nAvailability, see Dependability, avail-\nability\nBackup server, 485\nBig endian, 198\nBitcoin, 291\nBits-per-second, 2\nBitTorrent, 10, 96\nmagnet link, 98\ntorrent file, 97\ntracker, 97\nBlockchain, 5, 22, 104\ngenesis block, 591\npermissioned, 106, 501,502\npermissionless, 106, 290, 502,\n589\nProof of Stake, 292, 589\nProof of Work, 290, 589\nsmart contract, 593\nBroadcasting, 236\nBrowser, 86\nByzantine agreement, 492\nByzantine failure, 468\nCache, 393, 407, 429\ncache hit, 429\ncoherence detection, 443\ncoherence enforcement, 444\ncoherence protocol, 443\ncontent aware, 457\ncontent blind, 458\ncooperative cache, 451\ndistributed cache, 451\nNetwork File System, 444\nWeb, 451\nwrite back, 444\nwrite through, 444\nCallback, 205\nCAP theorem, 506\nCapability, 596\nCausal history, 267\nCausality, 267\nCDN, see Content Delivery Network\nCGI, see Common Gateway Inter-\nface\nCgroups, 135\nChallenge-response protocol, 573\nchallenge, 573, 579\nmultiway, 577\nnonce, 577\nCheckpointing\ncoordinated, 539\ndistributed snapshot, 538\ndomino effect, 539\nindependent, 539,540\nrecovery line, 538\nChecksum, 186\nChord, 91, 233, 294, 333\nfinger table, 333\nflooding, 239\nforwarder, 233\nsuccessor, 91\nChrome OS, 145\nCIDS, see Intrusion Detection Sys-\ntem, collaborative\nClient, 27, 37, 60, 79\nfat, 82\nthin, 82, 142\nClient stub, 148, 194\nClient-server computing, 27, 172\nClock\naccuracy, 254\nclock drift rate, 254\ndrift, 254\nexternal synchronization, 254\ninternal synchronization, 254\nprecision, 254\nskew, 251\nsynchronization, 254\ntick, 250\nClosure mechanism, 348\ncontainer, 348\nCloud computing, 12, 98\nDS 4.01\n \n\n\nINDEX\n617\nCluster computing, 32, 34\nCode segment, 171\nCode-on-demand, 172\nCoherence model, 406\nCollaborative Intrusion Detection\nSystem, see Intrusion De-\ntection System, collabora-\ntive\nCommon Gateway Interface, 87\nCommunication\nasynchronous, 191, 214, 301\nasysnchronous, 219\npersistent, 191, 231, 301\nsynchronous, 27, 191\ntransient, 191, 219\nCommunication pattern, 214\npipeline, 217\npublish-subscribe, 216\nrequest-reply, 214\nCommunication perspective, 9\nCommunication protocol, 59, 183\nstack, 58\nCommunication service, 58, 183\nComputational grid, 27\nComputer timer, 250\ncounter, 250\nholding register, 250\nConcurrency transparency, see Dis-\ntribution transparency\nConcurrent operations, 260, 401\nConfidentiality, 20, 313\nConflict-Free Replicated Data Type,\n409\nConit, see Consistency unit\nConnection-oriented service, 60, 183\nConnectionless service, 184\nConsensus, 475\nflooding, 475\nPaxos, 477, 479\nPaxos, accept message, 485\nPaxos, acceptor, 480\nPaxos, client, 480\nPaxos, leader, 480, 485\nPaxos, learned message, 485\nPaxos, learner, 480\nPaxos, proposal message, 491\nPaxos, proposal timestamp, 483\nPaxos, proposer, 480, 491\nRaft, 289, 477\nRaft, follower, 477\nRaft, leader, 477\nRaft, leader election, 289\nRaft, log, 477\nRaft, term, 289, 477\nConsistency, 31\nConsistency and replication perspec-\ntive, 9\nConsistency model, 406\ncausal consistency, 401, 408\nclient centric, 415,416, 448\ncompositional, 400\ncontinuous consistency, 410, 446\ndata centric, 395\nentry consistency, 404, 415, 434\neventual consistency, 407\nlinearizable, 400\nmonotonic read, 417\nmonotonic write, 418\nprogram consistency, 410\nread your writes, 420\nschedule, 405\nsequential consistency, 397\nserializable, 400, 405, 422\nstrong eventual consistency, 409\nwrites-follow-reads, 421\nConsistency protocol, 437\nprimary based, 438,439, 474\nprimary-backup, 438\nquorum based, 441\nread quorum, 442\nreplicated-write, 440\nwrite quorum, 442\nConsistency unit, 411\ndeclaration, 414\nfalse share, 413\nContact address, 223\n \nDS 4.01\n",
      "page_number": 620
    },
    {
      "number": 62,
      "title": "Segment 62 (pages 628-635)",
      "start_page": 628,
      "end_page": 635,
      "detection_method": "topic_boundary",
      "content": "618\nINDEX\nContainer, 133, 348\nContent Delivery Network, 6, 95,\n165, 319, 425, 427, 453\nContext awareness, 45\nCookie, 153\nCoordinated Universal Time, 252,253\nCoordination, 68, 248\ndirect, 68\nevent-based, 69\nmailbox, 69, 221\nreferentially coupled, 68, 313\ntemporally coupled, 68, 221,\n313\nCoordination perspective, 9\nCopy-before-use, 15\nCRDT, see Conflict-Free Replicated\nData Type\nCritical region, 264, 266, 275, 403\nCRL, see Cryptosystem, certificate\nrevocation list\nCryptosystem\nassymmetric, 21\nasymmetric, 557\ncertificate revocation, 569\ncertification authority, 569\ncertification revocation list, 569\npublic-key certificate, 569\npublic-key system, 21, 557, 568\nsecret-key system, 557\nsession key, 564, 579,580\nshared-key system, 557\nsymmetric, 21, 557\nCyclon, 304\nDAC, see Access control, discretionary\nData link layer, 186\nframe, 186\nData store, 395\nData synchronization, 248\nDeadlock, 272\nDecentralization, 3, 7\nDecentralized system, 4\nDecryption, 555\nDelegation, 601\nDependability, 18, 463\navailability, 19, 463,464\navailability, long-term, 464\nconfidentiality, 547\nintegrity, 547\nmaintainability, 19, 463\nreliability, 19, 463,464\nsafety, 19, 272, 463\nDetection\nfalse negative, 613\nfalse positive, 613\ntrue negative, 613\ntrue positive, 613\nDHCP, see Dynamic Host Configu-\nration Protocol\nDHT, see Distributed hash table\nDifferential GPS, 317\nDiffie-Hellman group, 565\nDiffie-Hellman key exchange, 565,566\nephemeral, 565\nDigital signature, 22, 561\nDirected acyclic graph, 346\nDirectory node, 345\nlocation record, 338\nroot, 338\nDirectory table, 345\nDispatcher, 125\nDistribtion\nhorizontal, 89\nDistributed commit, 40, 189, 528\nblocking protocol, 531\none-phase protocol, 529\nthree-phase protocl, 534\ntwo-phase protocol, 529\nDistributed consensus, 106\nDistributed hash table, 90\nDistributed ledger, 5, 104\nDistributed object, 63\nDistributed shared memory, 33\nDistributed system, 4\nDistributed transaction, 37\nDistribution, 3\nvertical, 89\nDS 4.01\n \n\n\nINDEX\n619\nDistribution transparency, 6, 11, 148\naccess transparency, 11, 15, 67,\n148\nconcurrency transparency, 13,\n149\nfailure transparency, 13, 149\nlocation transparency, 12, 148,\n332\nmigration transparency, 12, 148\nrelocation transparency, 12, 148\nreplication transparency, 13, 149\nDNS, see Domain Name System,\n359\ndomain name, 189\nDNSSEC, see Domain Name Sys-\ntem, security extension\nDocument Object Model, 145\nDOM, see Document Object Model\nDomain, 338\nDomain name, 165\nDomain Name System, 6, 165, 189,\n359,360, 472\ncanonical name, 361\ndomain, 30\nkey-signing key, 366\nresource record, 360\nsecurity extension, 366\nzone, 30, 354\nzone transfer, 362\nzone-signing key, 366\nEnd point, 150\nEnd-to-end principle, 271, 551\nEnterprise application integration,\n38, 75, 226\nEpidemic behavior, 240\nanti-entropy, 241, 521\ninfected, 241\nremoved, 241\nround, 241\nrumor spreading, 243\nsusceptible, 241\nEpidemic protocol, 240, 297\ndeath certificate, 245\ndormant death certificate, 245\nErdös-Rényi graph, 237\nError, 19, 465\nEvent bus, 70\nEvent counter, 261\nExecution segment, 171\nExtended markup language, 42, 224\nExtensible, 16\nFaaS, see Function-as-a-Service\nFail, 19\nFailure, 465\narbitrary, 468\ncommission, 468\ncommunication, 508\ncrash, 467\nexception handling, 509\nfail arbitrary, 469\nfail noisy, 469\nfail safe, 469\nfail silent, 469\nfail stop, 469\nomission, 467,468\nperformance, 468\nreceive omission, 467\nresponse, 468\nsend omission, 467\ntiming, 467\nFailure detection, 506\neventually perfect, 507\nsuspect, 507\nDowncall, 57\nDSM, see Distributed shared mem-\nory\nDynamic Host Configuration Pro-\ntocol, 46\nEAI, see Enterprise application in-\ntegration\nEBS, see Amazon, Elastic Block Store \nEclipse attack, 344, 588\nEdge computing, 100, 456\ninfrastructure, 100 \norchestration, 103 \nEncapsulation, 63,64\n \nDS 4.01\n\n\n620\nINDEX\nFailure rate function, 464\nFailure transparency, see Distribu-\ntion transparency\nFarmer task, 217\nFault, 20, 465\nintermittent, 20, 466\npermanent, 20, 466\ntransient, 20, 466\nFault tolerance, 5, 18, 20, 466\nByzantine, Altruism, Rational-\nity (BAR), 505\nFault-tolerance perspective, 9\nFederated learning, 4, 168\nFHE, see Security mechanism, full\nhomomorphic encryption\nFile Transfer Protocol, 188\nFirewall, 609\napplication-level gateway, 610\npacket-filtering gateway, 610\nproxy gateway, 610\nFog computing, 101\nFree riding, 96\nFront end, 162\nFTP, see File Transfer Protocol\nFunction-as-a-Service, 100\nGDPR, see General Data Protection\nRegulation\nGeneral Data Protection Regulation,\n553\nGentle reincarnation, 514\nGlobal Positioning System, 316\nGoogle Mail, 5\nGossiping, 240, 297, 311\nData-injection attack, 306\ndirectional, 244, 297\npartial view, 298, 312\nGPS, see Global Positioning System\nGrid computer, 4\nGrid computing, 32, 35\napplication layer, 37\ncollective layer, 37\nconnectivity layer, 36\nfabric layer, 36\nresource layer, 36\nGroupware, 10\nHappens-before relation, 260\nHash function, 22, 290, 560\ndigest, 291\nnonce, 291\nstrong collision resistance, 560\ntrapdoor, 560\nweak collision resistance, 560\nHonest-but-curious, 315, 553\nHTML, see HyperText Markup Lan-\nguage\nHTTP, see HyperText Transfer Pro-\ntocol\nHTTPS, see HyperText Transfer Pro-\ntocol, secure, 583\nHypercube, 90\nHyperspace, 312\nHyperText Markup Language, 86\nHyperText Transfer Protocol, 86, 188\nsecure, 367, 551\nIaaS, see Infrastructure-as-a-Service,\n139\nIANA, see Internet Assigned Num-\nbers Authority\nICN, see Information-centric network-\ning\nIdempotent operation, 80, 513\nIdentifier-location split, 329\nIDL, see Interface Definition Lan-\nguage\nImplicit action, 45\nIn-network data processing, 50\nIncremental snapshot, 539\nInformation-centric networking, see\nNamed-data networking,\n385\nInfrastructure-as-a-Service, 99, 139\nInstruction\nbehavior-sensitive, 132\ncontrol-sensitive, 132\nnonprivileged, 131\nDS 4.01\n \n\n\nINDEX\n621\nprivileged, 131\nInstruction set architecture, 129\nIntegrity, 20, 313\nInterceptor, 76\nmessage-level, 77\nrequest-level, 77\nInterface, 15, 184\nInterface Definition Language, 15,\n203\nInternational Atomic Time, 252\nInternet Assigned Numbers Author-\nity, 150\nInternet of Things, 44\nInternet Protocol, 187\nInternet Service Provider, 28, 100\nInternet-of-Things, 100\nInteroperability, 16\nInterprocess communication, 115\nInterrupt\ndirect overhead, 116\nindirect overhead, 116\nIntruder, 556\nIntrusion detection, 609\nIntrusion Detection System\nanomaly-based, 611\ncollaborative, 612\ncommunity, 612\nsignature-based, 611\nIoT, see Internet-of-Things\nIP, see Internet Protocol\nIPC, see Interprocess communica-\ntion\nISA, see Instruction set architecture\nISP, see Internet Service Provider,\nsee Internet Service Provider\nJavaScript, 87, 146\nKDC, see Key distribution center\nKerberos, 551, 581, 605\nauthentication service, 581\nticket-granting service, 581\nKey distribution center, 576\nsingle sign-on, 583\nticket, 576, 581\nKey-derivation function, 585\nLAMP, 140\nLAN, see Local-area network\nLandmark, 320\nLDAP, see Lightweight Directory\nAccess Protocol\nLeader election, 96, 106, 283\nbully algorithm, 283\nring algorithm, 285\nLeaf domain, 338\nLease, 72, 433\nage-based, 433\nrenewal-frequency based, 433\nstate-based, 434\nLightweight Directory Access Pro-\ntocol, 376\ndirectory information base, 377\ndirectory information tree, 377\ndirectory service agent, 379\ndirectory user agent, 379\nrelative distinguished name, 377\nLinda, 70, 307\nLittle endian, 198\nLiveness property, 482, 490, 502,\n505\nLocal-area network, 2\nLocation transparency, see Distribu-\ntion transparency\nLock, 403, 434\nLogical clock, 260, 263\nMAC, see Access control, manda-\ntory\nMaintainability, see Dependability,\nmaintainability\nMANET, see Mobile ad hoc network\nMCC, see Mobile Cloud Comput-\ning\nMean Time Between Failures, 19,\n465\nMean Time To Failure, 19, 465\nMean Time To Repair, 19, 465\n \nDS 4.01\n\n\n622\nINDEX\nMEC, see Mobile Edge Computing\nMechanism, 17\nMemory Management Unit, 113\nMesh network, 233\nMessage broker, 75, 95, 225, 308\nMessage digest, 562\nMessage logging, 537, 542\noptimistic, 543\npessimistic, 543\nreceiver based, 537\nsender based, 537\nMessage transfer time unit, 279\nMessage-oriented middleware, 41,\n220\nrouter, 224\nMessage-Passing Interface, 218\nMessage-queuing system, 220\nMicroservice, 65\nMiddleware, 11, 74\nmodifiable, 78\nMigration\nreceiver initiated, 172\nsender initiated, 172\nMigration transparency, see Distri-\nbution transparency\nMMU, see Memory Management\nUnit\nMobile ad hoc network, 47\nMobile agent, 168, 172\nMobile Cloud Computing, 48\nMobile computing, 47\nMobile Edge Computing, 48\nMobile host\ncare-of-address, 331\nhome agent, 331\nMOM, see Message-oriented mid-\ndleware\nMPC, see Multiparty computation\nMPI, see Message-Passing Interface\nMPLS, see Multi-Protocol Label Switch-\ning\nMTBF, see Mean Time Between Fail-\nures\nMTTF, see Mean Time To Failure\nMTTR, see Mean Time To Repair\nMTTU, see Message transfer time\nunit\nMulti-Protocol Label Switching, 454\nMulticasting, 232, 236\napplication-level, 232\natomic, 522, 526\ncausally ordered, 270, 526\nfeedback implosion, 518\nfeedback suppression, 519\nFIFO-ordered, 525\nflooding, 237\ngroup view, 523\nlink stress, 234\nprobabilistic flooding, 237\nrelative delay penalty, 234\nstretch, 234\ntotally ordered, 264, 523, 526\ntree cost, 235\nunordered, 524\nview change, 523\nMulticomputer, 33\nMultiparty computation, 23, 566\noblivious transfer, 566\nMultiprocessor, 33\nMutual exclusion, 189\npermission-based, 272\ntoken based, 272\nName\nalias, 349\nglobal, 345\nlocal, 345\nName resolution, 347\nautomounting, 373\nfile handle, 371,372\niterative, 355\nrecursive, 356\nName resolver, 355\nName space, 344\nabsolute path name, 345\nadministrational layer, 353\ndirectory node, 345\nDS 4.01\n \n\n\nINDEX\n623\nforeign, 349\nglobal layer, 352\nhard link, 349\nleaf node, 344\nmanagerial layer, 353\nmount point, 349\nmounting, 349, 369\nmounting point, 349\npath name, 345\nrelative path name, 345\nroot node, 345\nUnix, 346, 348\nNamed-data networking, 329, 385\ncontent store, 387\nforwarding information base,\n387\npending interest table, 387\nNaming\naccess point, 327\naddress, 327\nattribute-based, 375\ndirectory service, 375\nflat name, 329\nhome location, 331\nhuman-friendly name, 328\nidentifier, 328\nindex server, 380\nlocation independent, 328\nnaming system, 375\nNetFlow, 590\nchoice set, 590\nNetwork Coordinates System, 318\nNetwork File System, 83, 350, 369,\n445\nexport directory, 370\nNFS client, 84\nNFS server, 85\nopen delegation, 445\nNetwork layer, 186\npacket, 187\nNetwork Time Protocol, 256\nreference clock, 256\nstartum server, 256\nNetwork-address translation, 140,\n163\nNetwork-Attached Storage, 6\nNetworked computer system, 2\nexpansive view, 4\nintegrative view, 4\nNFS, see Network File System\nNode, 89\nNonce, 603\nNotification, 69\nNotification filtering, 306\nNTP, see Network Time Protocol\nOAuth, see Open Authorization\nObject\ninterface, 63\nmethod, 63\npersistent, 204\nstate, 63\ntransient, 204\nObject adapter, 75, 155\nObject wrapper, 155\nOGSA, see Open Grid Services Ar-\nchitecture\nOne-way function, 560\nOpen Authorization, 604\naccess token, 604\nauthorization code, 604\nOpen Grid Services Architecture,\n37\nNaming graph\nsymbolic link, 349\nNaming perspective, 9\nNaming service, 30\nNano computers, 2\nNAS, see Network-Attached Stor-\nage\nNAT, see Network-address transla-\ntion\nNCS, see Network Coordinates Sys-\ntem\nNDN, see Named-data networking \nNeedham-Schroeder authentication\nprotocol, 577, 581\n \nDS 4.01\n\n\n624\nINDEX\nOpen Systems Interconnection Ref-\nerence Model, 183\nOpenness, 15\nOrchestration, 65\nOrder deviation, 412\nOrphan computation, 513, 541\nexpiration, 514\nextermination, 514\ngrandorphan, 514\nreincarnation, 514\nOSI, see Open Systems Interconnec-\ntion Reference Model\nOut-of-band data, 151\nOverlay network, 89, 224, 231, 299,\n308, 310,311, 315\ngeometric, 318\nPaaS, see Platform-as-a-Service, 139\nParallel processing, 33\nParameter marshaling, 197\nParameter passing\ncall-by-copy/restore, 194\ncall-by-reference, 193\ncall-by-value, 193\nobject reference, 200\nParavirtualization, 133\nPartial failure, 7, 18\nPartially synchronous, 469\nPaxos, see Consensus, Paxos\nPBFT, see Practical Byzantine Fault\nTolerance\nPeer-sampling service, 244, 298, 300,\n303\nPeer-to-peer search\nflooding, 93\npolicy-based, 94\nrandom walk, 93,94, 311\nPeer-to-peer system, 89\nstructured, 90\nunstructured, 92\nPEKS, see Public Key Encryption\nwith Keyword Search\nPervasive system, 43\nPGP, see Pretty Good Privacy\nPHE, see Security mechanism, par-\ntial homomorphic encryp-\ntion\nPhysical layer, 186\nPiecewise deterministic execution\nmodel, 541\nPlanetLab, 136\nPlatform-as-a-Service, 99, 139\nPlugin, 225\nPolicy, 17\nPolicy Machine, 598\nassignment, 599\nobligation, 599\nprohibition, 599\nPort, 150\nPortability, 16\nPoS, see Blockchain, proof of stake\nPosition-based routing, 319\nPoW, see Blockchain, proof of work\nPractical Byzantine Fault Tolerance,\n498\ncommit certificate, 500\nprepare certificate, 499\nview, 499\nview-change certificate, 501\nPrecision, 613\nPresentation layer, 188\nPretty Good Privacy, 570\nPrimary server, 485\nProblem monotonicity, 410\nProcess, 113\ncontext, 113\nprocess table, 113\nProcess group, 472\nflat, 472\ngroup server, 473\nhierarchical, 472\nk-fault tolerant, 474\nProcess migration, 167\nProcess perspective, 9\nProcess synchronization, 248\nProcessor context, 113\nProgressive Web app, 148\nDS 4.01\n \n\n\nINDEX\n625\nProtocol stack, 185\nProtocol suite, 185\nProximity neighbor selection, 338\nProximity routing, 337\nPSS, see Peer-sampling service\nPublic key, 21\nPublic Key Encryption with Key-\nword Search, 314\nPublish, 69, 71\nPublish-subscribe, 41, 226, 306\ncontent-based, 72\nmatching, 72\nmessage subject, 308\nrouting filter, 310\ntopic-based, 72\nPWA, see Progressive Web app\nQoS, see Quality of Service\nQuality of Service, 424\nQuery containment check, 457\nQueue manager, 222\nRabbitMQ, 231\nRaft, see Consensus, Raft\nRandom graph, 92, 237\nRBAC, see Access control, role based\nRBS, see Reference Broadcast Syn-\nchronization\nRDF, see Resource Description Frame-\nwork\nRDP, see Relative delay penalty\nRead-One, Write-All, 443\nRead-write conflict, 407\nReal-time Transport Protocol, 187\nRecovery\nbackward, 536\ncheckpointing, 536\nerasure correction, 536\nforward, 536\nRedundancy\ninformation, 470\nphysical, 470\ntime, 470\ntriple modular, 470\nReference Broadcast Synchroniza-\ntion, 257\nReference monitor, 594\nReflection attack, 574\nReliability, see Dependability, relia-\nbility\nRelocation transparency, see Distri-\nbution transparency\nRemote desktop, 144\nRemote evaluation, 172\nRemote file service, 83\nremote access model, 84\nupload/download model, 84\nRemote method invocation, 41, 205\nRemote object, 63,64\nbinding to, 63\nproxy, 63\nskeleton, 64\nRemote procedure call, 38, 41,42,\n84, 190, 192\nasynchronous, 205, 231\nat-least-once semantics, 511\nat-most-once semantics, 511\nclient stub, 63\ndeferred synchronous, 205\nexactly-once semantics, 511\nfailure, 509\nmulticast, 207\none-way, 206\nsynchronous, 231\nRendezvous node, 235, 308\nReplicated object invocation, 436\nReplication\nactive, 431, 440, 474\nclient initiated, 429\ninvalidation protocol, 430\nmirror site, 426\nmirroring, 426\npartial, 457\npermanent replica, 426\nquorum based, 474\nsequencer, 441\nserver initiated, 427\n \nDS 4.01\n",
      "page_number": 628
    },
    {
      "number": 63,
      "title": "Segment 63 (pages 636-643)",
      "start_page": 636,
      "end_page": 643,
      "detection_method": "topic_boundary",
      "content": "626\nINDEX\nshared nothing, 427\nupdate protocol, client-based,\n431\nupdate protocol, pull-based, 431\nupdate protocol, push-based,\n431\nupdate protocol, server-based,\n431\nReplication transparency, see Distri-\nbution transparency\nRepresentational State Transfer, 66\nRequest-reply, 79\nResource Description Framework,\n375\nResource segment, 171\nResource sharing, 10\nResource virtualization, 127\nREST, see Representational State Trans-\nfer\nRESTful architecture, 66\nReverse proxy, 163\nRMI, see Remote method invoca-\ntion\nRouting, 186\nROWA, see Read-One, Write-All\nRPC, see Remote procedure call\nRTP, see Real-Time Transport Proto-\ncol\nSaaS, see Software-as-a-Service, 139\nSafety, see Dependability, safety\nSafety property, 482, 490, 502, 505\nSandbox, 147\nScalability\nadministrative, 24, 27\nanalysis of size scalability, 25\ngeographical, 24, 26\nsize, 24\nScalable Reliable Multicasting, 519\nScaling out, 28\nScaling technique\nasynchronous communication,\n29\ncaching, 31\nhide latency, 29\npartitioning and distribution,\n30\nreplication, 31\nScaling up, 28\nSCS, see Vserver, slice creation ser-\nvice\nSCTP, see Streaming Control Trans-\nmission Protocol\nSearchable encryption, 314\nSecret key, 21\nSecure channel, 22, 568\nSecure Shell Protocol, 551\nSecure Socket Layer, 583\nSecurity\nproxy, 601\nSecurity key, 21\nSecurity mechanism, 548\nauthentication, 548, 571\nauthentication, continuous, 572\nauthentication, electronic, 572\nauthentication, multi-factor, 572\nauthentication, single-factor, 571\nauthorization, 548\ndecryption, 21\nencryption, 21, 548, 555\nencryption, ciphertext, 555\nencryption, plaintext, 555\nfull homomorphic encryption,\n558\nhomomorphic encryption, 558\npartial homomorphic encryp-\ntion, 558\nSecurity perspective, 10\nSecurity policy, 547\nSecurity principle, 549\nfail-safe defaults, 549\nleast common mechanism, 550\nleast privilege, 549\nopen design, 549\nseparation of privilege, 549\nSecurity threat, 547\nSelective routing, 310\nDS 4.01\n \n\n\nINDEX\n627\nSelf-certifying name, 343\nSelf-configurable system, 18\nSensor, 43\nSensor network, 49, 295\nServant, 89, 156\nServer, 24, 27, 60, 79\nconcurrent, 150\niterative, 150\npermanent state, 153\nsession state, 153\nsoft state, 152\nstateful, 152\nstateless, 152\nServer stub, 195\nServer-side script, 88\nService-level agreement, 98\nService-oriented architecture, 37, 64\nSession key, 573\nSession layer, 188\nShard, 554\nShared data space, 46, 69\nattribute, 71\ntuple, 69\nSIDS, see Intrusion Detection Sys-\ntem, signature based\nSLA, see Service-level agreement\nSmartphone, 2\nSOA, see Service-oriented architec-\nture\nSocket, 208\nSocket interface, 208\nSoftware architecture, 56\ncomponent, 57\nconnector, 57\nevent based, 70\ninterface, 57,58\nlayered, 57, 61\nmicroservice, 63\nobject, 63\npublish-subscribe, 70\nservice, 63\nshared data space, 70\nSoftware-as-a-Service, 99, 129, 139\nSpace-filling curve, 381\nSpanner, 259\nSRM, see Scalable Reliable Multi-\ncasting\nSSH, see Secure Shell Protocol\nStarvation, 272\nState machine replication, 264\nStateless execution, 66\nStreaming Control Transmission Pro-\ntocol, 187\nStrong mobility, 173\nSubscribe, 69, 72\nSuccessor, 333\nSuper peer, 95, 293\nSuperserver, 150\nSwitch tree, 235\nSybil attack, 344, 586\nSynchronization variable, see Lock\nSynchronous, 504\nSynchronous system, 469\nSystem architecture, 56, 79\nthree-tiered, 83\ntwo-tiered, 81\nSystem calls, 129\nTAI, see International Atomic Time\nTCB, see Trusted Computing Base\nTCP, see Transmission Control Pro-\ntocol, 187\nTCP handoff, 163\nThread\ncontext, 114\nmany-to-many model, 120\nmany-to-one model, 120, 122\none-to-one model, 120\nThread-level parallelism, 124\nTIB/Rendezvous, 308\nrendezvous daemon, 308\nTime\nleap second, 252\nmean solar second, 252\nsolar day, 251\nsolar second, 251\ntransit sun, 251\n \nDS 4.01\n\n\n628\nINDEX\nTime-to-live, 93\nTLB, see Translation Lookaside Buffer\nTLP, see Thread-level parallelism\nTLS, see Transport Layer Security\nTMR, see Redundancy, triple mod-\nular\nTopology-based identifier, 337\nTP monitor, see Transaction-processing\nmonitor\nTransaction, 38\nACID, 38\nnested, 39\nTransaction-processing monitor, 40\nTransactional RPC, 38\nTransient object, 154\nTranslation Lookaside Buffer, 113\nTransmission Control Protocol, 59,\n187\nTransport layer, 187\nTransport Layer Security, 551, 583\nTransport-layer switch, 163\nTrap, 131\nTrapdoor, 314\nTriangle inequality, 320\nTrueTime, 259\nTrust, 10, 21, 304, 586\nTrust chain, 366, 588\nTrusted Computing Base, 552\nTrusted third party, 104\nTTL, see Time-to-live\nTunnel, 551\nTuple space, 70\nUbiquitous computing system, 44\nUDP, see Universal Datagram Pro-\ntocol\nUniform Resource Identifier, 66\nUniform Resource Locator, 12, 86\nUniversal Datagram Protocol, 187\nUniversal Plug and Play protocol,\n46\nUnix\nnamespaces, 134\nUpcall, 57\nhandle, 58\nUPnP, see Universal Plug and Play\nprotocol\nURI, see Uniform Resource Identi-\nfier\nURL, see Uniform Resource Locator\nUTC, see Coordinated Universal Time,\n253\nUtility computing, 98\nUtilization, 26\nVector clock, 267,268\nVFS, see Virtual File System\nVirtual desktop environment, 82,\n144\nVirtual File System, 84\nVirtual machine monitor\nhosted, 131\nnative, 130\nVirtual Network Computing, 144\nVirtual organization, 35\nVirtual private network, 550\nVirtual synchrony, 523\nflush message, 528\nstable message, 527\nVirtualization, 127\nguest operating system, 131\nhost operating system, 131\nprocess virtual machine, 130\nvirtual processor, 113\nVM fork, 177\nVNC, see Virtual Network Comput-\ning\nVPN, see Virtual private network\nVserver, 136\nnode manager, 137\nservice provider, 137\nslice, 136\nslice authority, 137\nslice creation service, 137\nWAN, see Wide-area network\nWar driving, 317\nWAVE, 606\nDS 4.01\n \n\n\nINDEX\n629\nattestation, 606\nentity store, 608\nissuer, 606\nmap log, 608\noperation log, 608\nresource, 606\nRTree, 606\nRTree statement, 606\nstructural security, 608\nsubject, 606\nWeak mobility, 172\nWeak peer, 95\nWeb of trust, 570, 587\nWebAssembly, 146\nWide-area network, 2\nWindow manager, 143\nWorker task, 217\nWorker thread, 125\nWrapper, 75\nWrite set, 416\nWrite-write conflict, 407\nX kernel, 142\nX protocol, 143\nX Window System, 142\nXML, see Extended markup language\nZeroconf, 46\nZeroMQ, 213\nZooKeeper, 280, 286, 422\nensemble, 286\n \nDS 4.01\n\n\nBIBLIOGRAPHY\nAbadi M. and Needham R. Prudent Engineering Practice for Cryptographic Protocols.\nIEEE Transactions on Software Engineering, 22(1):6–15, Jan. 1996. →576.\nAbbas N., Zhang Y., Taherkordi A., and Skeie T. Mobile Edge Computing: A Survey.\nIEEE Internet of Things Journal, 5(1):450–465, 2018. →48.\nAberer K., Alima L. O., Ghodsi A., Girdzijauskas S., Hauswirth M., and Haridi S. The\nEssence of P2P: A Reference Architecture for Overlay Networks. In 5th International\nConference on Peer-to-Peer Computing, pages 11–20, Los Alamitos, CA., Aug. 2005.\nIEEE, IEEE Computer Society Press. →89.\nAcar A., Aksu H., Uluagac A. S., and Conti M. A Survey on Homomorphic Encryption\nSchemes: Theory and Implementation. ACM Computing Surveys, 51(4):1–35, 2018.\n→558.\nAdar E. and Huberman B. A. Free Riding on Gnutella. Hewlett Packard, Information\nDynamics Lab, Jan. 2000. →96.\nAdelstein F., Gupta S., Richard G., and Schwiebert L. Fundamentals of Mobile and\nPervasive Computing. McGraw-Hill, New York, NY, 2005. →47.\nAdve S. V. and Boehm H.-J. Memory Models: A Case for Rethinking Parallel Languages\nand Hardware. Communications of the ACM, 53(8):90–101, Aug. 2010. →399.\nAfanasyev A., Burke J., Refaei T., Wang L., Zhang B., and Zhang L. A Brief Introduction\nto Named Data Networking. In IEEE Military Communications Conference (MILCOM),\npages 1–6, 2018. →386.\nAgarwal A., George M., Jeyaraj A., and Schwarzkopf M. Retrofitting GDPR Compliance\nonto Legacy Databases. Proceedings of the VLDB Endowment, 15(4):958–970, Dec. 2022.\n→554.\nAger B., Mühlbauer W., Smaragdakis G., and Uhlig S. Comparing DNS Resolvers in\nthe Wild. In 10th Internet Measurement Conference, pages 15–21, New York, NY, 2010.\nACM Press. →369.\nAguilera M. and Terry D. The Many Faces of Consistency. Data Engineering, page 3,\n2016. →395.\nAhlgren B., Dannewitz C., Imbrenda C., Kutscher D., and Ohlman B. A Survey of\nInformation-centric Networking. IEEE Communications Magazine, 50(7):26–36, July\n2012. →385.\nAiyer A., Alvisi L., Clement A., Dahlin M., and Martin J.-P. BAR Fault Tolerance for\nCooperative Services. In 20th Symposium on Operating System Principles, pages 45–58,\nNew York, NY, Oct. 2005. ACM, ACM Press. →505.\nAkgul F. ZeroMQ. Packt Publishing, Birmingham, UK, 2013. →213.\n631\n\n\n632\nBIBLIOGRAPHY\nAkyildiz I. F. and Kasimoglu I. H. Wireless Sensor and Actor Networks: Research\nChallenges. Ad Hoc Networks, 2:351–367, 2004. →49.\nAkyildiz I. F., Su W., Sankarasubramaniam Y., and Cayirci E. A Survey on Sensor\nNetworks. IEEE Communications Magazine, 40(8):102–114, Aug. 2002. →49.\nAkyildiz I. F., Wang X., and Wang W. Wireless Mesh Networks: A Survey. Computer\nNetworks, 47(4):445–487, Mar. 2005. →49.\nAlbrecht J., Oppenheimer D., Vahdat A., and Patterson D. A. Design and Implemen-\ntation Trade-Offs for Wide-Area Resource Discovery. ACM Transactions on Internet\nTechnology, 8(4):1–44, 2008. →383.\nAlegre U., Augusto J. C., and Clark T. Engineering Context-Aware Systems and\nApplications: A Survey. Journal of Systems and Software, 117:55–83, 2016. →45.\nAli W., Shamsuddin S. M., and Ismail A. S. A Survey of Web Caching and Prefetching.\nInternational Journal of Advances in Soft Computing and Its Applications, 3(1):18–44, 2011.\n→453.\nAllani M., Garbinato B., and Pedone F. Application Layer Multicast. In Garbinato B.,\nMirando H., and Rodrigues L., editors, Middleware for Network Eccentric and Mobile\nApplications, pages 191–214. Springer-Verlag, Berlin, 2009. →233.\nAllen R. and Lowe-Norris A. Windows 2000 Active Directory. O’Reilly & Associates,\nSebastopol, CA., 2nd edition, 2003. →379.\nAllman M. Putting DNS in Context. In Internet Measurement Conference, page 309–316,\n2020. →369.\nAlonso G., Casati F., Kuno H., and Machiraju V. Web Services: Concepts, Architectures\nand Applications. Springer-Verlag, Berlin, 2004. →37.\nAlvisi L. and Marzullo K. Message Logging: Pessimistic, Optimistic, Causal, and Opti-\nmal. IEEE Transactions on Software Engineering, 24(2):149–159, Feb. 1998. →541, 542.\nAMQP Working Group . AMQP, Protocol specification, Version 0-9-1, Nov. 2008.\n→227.\nAmza C., Cox A., Dwarkadas S., Keleher P., Lu H., Rajamony R., Yu W., and\nZwaenepoel W. TreadMarks: Shared Memory Computing on Networks of Worksta-\ntions. Computer, 29(2):18–28, Feb. 1996. →33.\nAndersen M. P. Decentralized Authorization with Private Delegation. Ph.D., University of\nCalifornia, Berkeley, 2019. →606, 607, 608.\nAndersen M. P., Kumar S., AbdelBaky M., Fierro G., Kolb J., Kim H.-S., Culler D. E.,\nand Popa R. A. WAVE: A Decentralized Authorization Framework with Transitive\nDelegation. In 28th USENIX Security Symposium, pages 1375–1392, 2019. →606.\nAndrews G. Foundations of Multithreaded, Parallel, and Distributed Programming. Addison-\nWesley, Reading, MA., 2000. →248.\nAndroutsellis-Theotokis S. and Spinellis D. A Survey of Peer-to-Peer Content Distribu-\ntion Technologies. ACM Computing Surveys, 36(4):335–371, Dec. 2004. →89.\nAntonini M., Vecchio M., and Antonelli F. Fog Computing Architectures: A Reference\nfor Practitioners. IEEE Internet of Things Magazine, 2(3):19–25, 2019. →104.\nArkills B. LDAP Directories Explained: An Introduction and Analysis. Addison-Wesley,\nReading, MA., 2003. →376.\nDS 4.01\n \n\n\nBIBLIOGRAPHY\n633\nAttiya H. and Welch J. Distributed Computing Fundamentals, Simulations, and Advanced\nTopics. John Wiley, New York, 2nd edition, 2004. →249.\nAtxutegi E., Liberal F., Saiz E., and Ibarrola E. Toward Standardized Internet Speed\nMeasurements for End Users: Current Technical Constraints. IEEE Communications\nMagazine, 54(9):50–57, Sept. 2016. →454.\nAvizienis A., Laprie J.-C., Randell B., and Landwehr C. Basic Concepts and Taxonomy\nof Dependable and Secure Computing. IEEE Transactions on Dependable and Secure\nComputing, 1(1):11–33, Jan. 2004. →20, 466.\nAwadallah A. and Rosenblum M.\nThe vMatrix: A Network of Virtual Machine\nMonitors for Dynamic Content Distribution. In 7th Web Caching Workshop, Aug. 2002.\n→128.\nAyeswarya S. and Norman J.\nA Survey on Different Continuous Authentication\nSystems. International Journal of Biometrics, 11(1):67–99, 2019. →572.\nAzevedo L. G., Souza Soares E. F.de , Souza R., and Moreno M. F. Modern Federated\nDatabase Systems: An Overview.\nIn 25th International Conference on Enterprise\nInformation Systems, pages 276–283, May 2020. →427.\nBabaoglu O. and Toueg S. Non-Blocking Atomic Commitment. In Mullender S., editor,\nDistributed Systems, pages 147–168. Addison-Wesley, Wokingham, 2nd edition, 1993.\n→531.\nBader M. Space-Filling Curves, An Introduction with Applications in Scientific Computing.\nSpringer-Verlag, Berlin, 2013. →382.\nBailis P., Ghodsi A., Hellerstein J. M., and Stoica I. Bolt-on Causal Consistency. In\nSIGMOD International Conference on Management Of Data, pages 761–772, New York,\nNY, 2013. ACM, ACM Press. →408.\nBalakrishnan H., Kaashoek M. F., Karger D., Morris R., and Stoica I. Looking up Data\nin P2P Systems. Communications of the ACM, 46(2):43–48, Feb. 2003. →90.\nBaldauf M., Dustdar S., and Rosenberg F. A Survey on Context-aware Systems. Int. J.\nAd Hoc Ubiquitous Comput., 2:263–277, June 2007. →46.\nBaldoni R., Beraldi R., Quema V., Querzoni L., and Tucci-Piergiovanni S. TERA: Topic-\nbased Event Routing for Peer-to-Peer Architectures. In International Conference on\nDistributed Event-Based Systems, pages 2–13, New York, NY, 2007. ACM Press. →311.\nBaldoni R., Querzoni L., Tarkoma S., and Virgillito A. Distributed Event Routing in\nPublish/Subscribe Communication Systems: a Survey. In Garbinato B., Miranda H.,\nand Rodrigues L., editors, Middleware for Network Eccentric and Mobile Applications,\npages 219–244. Springer-Verlag, Berlin, 2009. →308.\nBallintijn G. Locating Objects in a Wide-area System. PhD thesis, Vrije Universiteit\nAmsterdam, 2003. →338.\nBanaei-Kashani F. and Shahab C. Criticality-based Analysis and Design of Unstructured\nPeer-to-Peer Networks as “Complex Systems”. In 3rd International Symposium on\nCluster Computing and the Grid, pages 351–356, Los Alamitos, CA., May 2003. IEEE,\nIEEE Computer Society Press. →237.\nBaquero C. and Preguica N. Why Logical Clocks Are Easy. Communications of the ACM,\n59(4):43–47, Mar. 2016. →267.\n \nDS 4.01\n\n\n634\nBIBLIOGRAPHY\nBarborak M., Malek M., and Dahbura A. The Consensus Problem in Fault-Tolerant\nComputing. ACM Computing Surveys, 25(2):171–220, June 1993. →504.\nBarham P., Dragovic B., Fraser K., Hand S., Harris T., Ho A., Neugebar R., Pratt I., and\nWarfield A. Xen and the Art of Virtualization. In 19th Symposium on Operating System\nPrinciples, pages 164–177, New York, NY, Oct. 2003. ACM, ACM Press. →133.\nBarron D. Pascal – The Language and its Implementation. John Wiley, New York, 1981.\n→174.\nBarroso L., Hölze U., and Ranganathan P. The Datacenter as a Computer: An Intro-\nduction to the Design of Warehouse-Scale Machines. Synthesis Lectures on Computer\nArchitectures. Morgan and Claypool, San Rafael, CA, 3rd edition, 2018. →129.\nBaset S. and Schulzrinne H. An Analysis of the Skype Peer-to-Peer Internet Telephony\nProtocol. In 25th INFOCOM Conference, pages 1–11, Los Alamitos, CA., Apr. 2006.\nIEEE, IEEE Computer Society Press. →28.\nBasile C., Whisnant K., Kalbarczyk Z., and Iyer R. K.\nLoose Synchronization of\nMultithreaded Replicas. In 21st Symposium on Reliable Distributed Systems, pages\n250–255, Los Alamitos, CA., 2002. IEEE, IEEE Computer Society Press. →436.\nBasile C., Kalbarczyk Z., and Iyer R. K. A Preemptive Deterministic Scheduling\nAlgorithm for Multithreaded Replicas. In International Conference on Dependable\nSystems and Networks, pages 149–158, Los Alamitos, CA., June 2003. IEEE Computer\nSociety Press. →436.\nBass L., Clements P., and Kazman R. Software Architecture in Practice. Addison-Wesley,\nReading, MA., 4th edition, 2021. →56, 57, 79.\nBavier A., Bowman M., Chun B., Culler D., Karlin S., Muir S., Peterson L., Roscoe\nT., Spalink T., and Wawrzoniak M. Operating System Support for Planetary-Scale\nNetwork Services. In 1st Symposium on Networked Systems Design and Implementation,\npages 245–266, Berkeley, CA, Mar. 2004. USENIX, USENIX. →136.\nBeckers K., Heisel M., and Hatebur D. Pattern and Security Requirements. Springer-\nVerlag, Berlin, 2015. →547.\nBen-Ari M. Principles of Concurrent and Distributed Programming. Prentice Hall, Engle-\nwood Cliffs, N.J., 2nd edition, 2006. →33.\nBernstein P. Middleware: A Model for Distributed System Services. Communications of\nthe ACM, 39(2):87–98, Feb. 1996. →37, 74.\nBernstein P. and Newcomer E. Principles of Transaction Processing. Morgan Kaufman,\nSan Mateo, CA., 2nd edition, 2009. →38, 529.\nBernstein P., Hadzilacos V., and Goodman N. Concurrency Control and Recovery in\nDatabase Systems. Addison-Wesley, Reading, MA., 1987. →535.\nBershad B., Zekauskas M., and Sawdon W. The Midway Distributed Shared Memory\nSystem. In COMPCON, pages 528–537. IEEE, 1993. →404.\nBharambe A. R., Agrawal M., and Seshan S. Mercury: Supporting Scalable Multi-\nAttribute Range Queries. In SIGCOMM, pages 353–366, New York, NY, Aug. 2004.\nACM Press. →384.\nBhuyan M. H., Bhattacharyya D. K., and Kalita J. K. Network Anomaly Detection:\nMethods, Systems and Tools. IEEE Communications Surveys & Tutorials, 16(1):303–336,\nDS 4.01\n \n",
      "page_number": 636
    },
    {
      "number": 64,
      "title": "Segment 64 (pages 644-667)",
      "start_page": 644,
      "end_page": 667,
      "detection_method": "topic_boundary",
      "content": "BIBLIOGRAPHY\n635\n2014. →612.\nBilal S. M., Bernardos C. J., and Guerrero C. Position-based Routing in Vehicular\nNetworks: A Survey. Journal of Network and Computer Applications, 36(2):685–697,\nMar. 2013. →319.\nBilge L. and Dumitra¸s T. Before We Knew It: An Empirical Study of Zero-day Attacks\nin the Real World. In Conference on Computer and Communications Security, pages\n833–844, 2012. →611.\nBirman K. Guide to Reliable Distributed Systems: Building High-Assurance Applications\nand Cloud-Hosted Services. Springer-Verlag, Berlin, 2012. →152, 507.\nBirman K. A Response to Cheriton and Skeen’s Criticism of Causal and Totally Ordered\nCommunication. Operating Systems Review, 28(1):11–21, Jan. 1994. →271.\nBirman K. and Joseph T. Reliable Communication in the Presence of Failures. ACM\nTransactions on Computer Systems, 5(1):47–76, Feb. 1987. →523.\nBirman K. and van Renesse R., editors. Reliable Distributed Computing with the Isis\nToolkit. IEEE Computer Society Press, Los Alamitos, CA., 1994. →271.\nBirman K., Schiper A., and Stephenson P. Lightweight Causal and Atomic Group\nMulticast. ACM Transactions on Computer Systems, 9(3):272–314, Aug. 1991. →526.\nBirrell A. and Nelson B. Implementing Remote Procedure Calls. ACM Transactions on\nComputer Systems, 2(1):39–59, Feb. 1984. →192.\nBishop M. Computer Security: Art and Science. Addison-Wesley, Reading, MA., 2nd\nedition, 2019. →547.\nBittencourt L., Immich R., Sakellariou R., Fonseca N., Madeira E., Curado M., Villas L.,\nDaSilva L., Lee C., and Rana O. The Internet of Things, Fog and Cloud continuum:\nIntegration and challenges. Internet of Things, 3-4:134–155, 2018. →103.\nBlair G. and Stefani J.-B. Open Distributed Processing and Multimedia. Addison-Wesley,\nReading, MA., 1998. →16.\nBlake G., Dreslinski R. G., Mudge T., and Flautner K. Evolution of Thread-Level\nParallelism in Desktop Applications. SIGARCH Computer Architecture News, 38(3):\n302–313, 2010. →124.\nBlaze M. Caching in Large-Scale Distributed File Systems. PhD thesis, Department of\nComputer Science, Princeton University, Jan. 1993. →429.\nBloom B. H. Space/time Trade-offs in Hash Coding with Allowable Errors. Communi-\ncations of the ACM, 13(7):422–426, 1970. →559.\nBoneh D., Crescenzo G. D., Ostrovsky R., and Persiano G. Public Key Encryption with\nKeyword Search. In International Conference Theory and Applications of Cryptographic\nTechniques, volume 3027 of Lecture Notes in Computer Science, pages 506–522, Berlin,\n2004. Springer-Verlag. →314.\nBonnet P., Gehrke J., and Seshadri P. Towards Sensor Database Systems. In 2nd\nInternational Conference on Mobile Data Management, volume 1987 of Lecture Notes in\nComputer Science, pages 3–14, Berlin, Jan. 2002. Springer-Verlag. →50.\nBosch C., Hartel P., Jonker W., and Peter A. A Survey of Provably Secure Searchable\nEncryption. ACM Computing Surveys, 47(2), Aug. 2014. →314.\nBoyd R. Getting Started with OAuth 2.0. O’Reilly & Associates, Sebastopol, CA., 2012.\n \nDS 4.01\n\n\n636\nBIBLIOGRAPHY\n→605.\nBraga D. D. S., Niemann M., Hellingrath B., and Neto F. B. D. L. Survey on Compu-\ntational Trust and Reputation Models. ACM Computing Surveys, 51(5):1–40, 2018.\n→586.\nBrewer E. CAP Twelve Years Later: How the \"Rules\" Have Changed. Computer, 45(2):\n23–29, Feb. 2012. →506.\nBudhijara N., Marzullo K., Schneider F., and Toueg S. The Primary-Backup Ap-\nproach. In Mullender S., editor, Distributed Systems, pages 199–216. Addison-Wesley,\nWokingham, 2nd edition, 1993. →438.\nBudhiraja N. and Marzullo K. Tradeoffs in Implementing Primary-Backup Protocols.\nTechnical Report TR 92-1307, Department of Computer Science, Cornell University,\n1992. →438.\nBuford J. and Yu H. Peer-to-Peer Networking and Applications: Synopsis and Research\nDirections. In Shen et al. [2010], pages 3–45. →89.\nBuford J., Yu H., and Lua E. P2P Networking and Applications. Morgan Kaufman, San\nMateo, CA., 2009. →89.\nBugnion E., Nieh J., and Tsafrir D. Hardware and Software Support for Virtualization.\nSynthesis Lectures on Computer Architecture. Morgan and Claypool, San Rafael,\nCA, 2017. →129.\nBursell M. Trust in Computer Systems and The Cloud. John Wiley, New York, 2022.\n→586, 593.\nCabri G., Leonardi L., and Zambonelli F. Mobile-Agent Coordination Models for\nInternet Applications. Computer, 33(2):82–89, Feb. 2000. →68.\nCachin C., Guerraoui R., and Rodrigues L. Introduction to Reliable and Secure Distributed\nProgramming. Springer-Verlag, Berlin, 2nd edition, 2011. →248, 469, 475, 476.\nCallaghan B. NFS Illustrated. Addison-Wesley, Reading, MA., 2000. →83, 373.\nCantin J., Lipasti M., and Smith J. The Complexity of Verifying Memory Coherence\nand Consistency. IEEE Transactions on Parallel and Distributed Systems, 16(7):663–671,\nJuly 2005. →406.\nCao L. and Ozsu T. Evaluation of Strong Consistency Web Caching Techniques. World\nWide Web, 5(2):95–123, June 2002. →453.\nCarriero N. and Gelernter D. Linda in Context. Communications of the ACM, 32(4):\n444–458, 1989. →70.\nCarzaniga A., Rutherford M. J., and Wolf A. L. A Routing Scheme for Content-Based\nNetworking. In 23rd INFOCOM Conference, Los Alamitos, CA., Mar. 2004. IEEE,\nIEEE Computer Society Press. →310.\nCarzaniga A., Picco G. P., and Vigna G. Is Code Still Moving Around? Looking Back\nat a Decade of Code Mobility. In 29th International Conference on Software Engineering\n(ICSE) (companian), pages 9–20, Los Alamitos, CA., 2007. IEEE Computer Society\nPress. →168.\nCastro M. and Liskov B. Practical Byzantine Fault Tolerance and Proactive Recovery.\nACM Transactions on Computer Systems, 20(4):398–461, Nov. 2002. →498, 501.\nCastro M., Druschel P., Hu Y. C., and Rowstron A.\nTopology-aware Routing in\nDS 4.01\n \n\n\nBIBLIOGRAPHY\n637\nStructured Peer-to-Peer Overlay Networks.\nTechnical Report MSR-TR-2002-82,\nMicrosoft Research, Cambridge, UK, June 2002a. →337.\nCastro M., Druschel P., Kermarrec A.-M., and Rowstron A. Scribe: A Large-Scale and\nDecentralized Application-Level Multicast Infrastructure. IEEE Journal on Selected\nAreas in Communication, 20(8):100–110, Oct. 2002b. →233.\nCastro M., Rodrigues R., and Liskov B. BASE: Using Abstraction to Improve Fault\nTolerance. ACM Transactions on Computer Systems, 21(3):236–269, Aug. 2003. →501.\nCastro M., Costa M., and Rowstron A. Debunking Some Myths about Structured\nand Unstructured Overlays. In 2nd Symposium on Networked Systems Design and\nImplementation, Berkeley, CA, Mar. 2005. USENIX, USENIX. →299.\nChandra T., Griesemer R., and Redstone J. Paxos Made Live: An Engineering Perspec-\ntive. In 26th Symposium on Principles of Distributed Computing, pages 398–407, New\nYork, NY, Aug. 2007. ACM, ACM Press. →484.\nChaudhari S. S. and Biradar R. C. Survey of Bandwidth Estimation Techniques in\nCommunication Networks. Wireless Personal Communications, 83(2):1425–1476, 2015.\n→454.\nCheriton D. and Mann T. Decentralizing a Global Naming Service for Improved\nPerformance and Fault Tolerance. ACM Transactions on Computer Systems, 7(2):\n147–183, May 1989. →352.\nCheriton D. and Skeen D. Understanding the Limitations of Causally and Totally\nOrdered Communication. In 14th Symposium on Operating System Principles, pages\n44–57. ACM, Dec. 1993. →271.\nCheswick W. and Bellovin S. Firewalls and Internet Security. Addison-Wesley, Reading,\nMA., 2nd edition, 2000. →609.\nChisnall D. The Definitive Guide to the Xen Hypervisor. Prentice Hall, Englewood Cliffs,\nN.J., 2007. →133.\nChondros N., Kokordelis K., and Roussopoulos M. On the Practicality of Practical\nByzantine Fault Tolerance. In Middleware 2012, volume 7662 of Lecture Notes in\nComputer Science, pages 436–455, Berlin, 2012. ACM/IFIP/USENIX, Springer-Verlag.\n→501.\nChou T. and Orlandi C. The Simplest Protocol for Oblivious Transfer. In International\nConference Cryptology and Information Security in Latin America, volume 9230 of Lecture\nNotes in Computer Science, pages 40–58, 2015. →566.\nChow R. and Johnson T. Distributed Operating Systems and Algorithms. Addison-Wesley,\nReading, MA., 1997. →538.\nChu Y., Rao S. G., Seshan S., and Zhang H. A Case for End System Multicast. IEEE\nJournal on Selected Areas in Communication, 20(8):1456–1471, Oct. 2002. →234.\nClark C., Fraser K., Hand S., Hansen J. G., Jul E., Limpach C., Pratt I., and Warfield A.\nLive Migration of Virtual Machines. In 2nd Symposium on Networked Systems Design\nand Implementation, Berkeley, CA, May 2005. USENIX, USENIX. →175, 176.\nClark D. The Design Philosophy of the DARPA Internet Protocols. In SIGCOMM,\npages 106–114, New York, NY, Sept. 1989. ACM, ACM Press. →152.\nClement A., Li H., Napper J., Martin J.-P., Alvisi L., and Dahlin M. BAR primer. In\n \nDS 4.01\n\n\n638\nBIBLIOGRAPHY\nInternational Conference on Dependable Systems and Networks, pages 287–296, 2008.\n→505.\nCohen B. Incentives Build Robustness in Bittorrent. In 1st Workshop on Economics of\nPeer-to-Peer Systems, June 2003. →96.\nCohen E. and Shenker S. Replication Strategies in Unstructured Peer-to-Peer Networks.\nIn SIGCOMM, pages 177–190, New York, NY, Aug. 2002. ACM, ACM Press. →94.\nComer D. Internetworking with TCP/IP, Volume I: Principles, Protocols, and Architecture.\nPrentice Hall, Upper Saddle River, N.J., 6th edition, 2013. →187.\nCommittee on National Security Systems . (CNSS) Glossary. Technical Report 4009,\nApr. 2015. →552.\nContavalli C., van der Gaast W., Lawrence D., and Kumari W. Client Subnet in DNS\nQueries. RFC 7871, May 2016. →364.\nConti M., Gregori E., and Lapenna W. Content Delivery Policies in ReplicatedWeb\nServices: Client-Side vs. Server-Side. Cluster Computing, 8:47–60, Jan. 2005. →456.\nCorbett J. C., Dean J., Epstein M., Fikes A., Frost C., Furman J. J., Ghemawat S., Gubarev\nA., Heiser C., Hochschild P., Hsieh W., Kanthak S., Kogan E., Li H., Lloyd A., Melnik\nS., Mwaura D., Nagle D., Quinlan S., Rao R., Rolig L., Saito Y., Szymaniak M., Taylor\nC., Wang R., and Woodford D. Spanner: Google’s Globally Distributed Database.\nACM Transactions on Computer Systems, 31(3):8:1–8:22, Aug. 2013. →259.\nCordero C. G., Vasilomanolakis E., Mühlhäuser M., and Fischer M. Community-based\nCollaborative Intrusion Detection. In International Conference on Security and Privacy\nin Communication Systems, pages 665–681. Springer, 2015. →612, 613.\nCristian F. Probabilistic Clock Synchronization. Distributed Computing, 3:146–158, 1989.\n→255.\nCristian F. Understanding Fault-Tolerant Distributed Systems. Communications of the\nACM, 34(2):56–78, Feb. 1991. →466.\nCui S., Belguith S., De Alwis P., Asghar M. R., and Russello G. Collusion Defender:\nPreserving Subscribers’ Privacy in Publish and Subscribe Systems. IEEE Transactions\non Dependable and Secure Computing, 18(3):1051–1064, 2021. →314, 315.\nCulkin J. and Zazon M. AWS Cookbook, Recipes for Success on AWS. O’Reilly & Associates,\nSebastopol, CA., 2022. →66, 99.\nDabek F., Cox R., Kaashoek F., and Morris R. Vivaldi: A Decentralized Network\nCoordinate System. In SIGCOMM, New York, NY, Aug. 2004a. ACM, ACM Press.\n→321.\nDabek F., Li J., Sit E., Robertson J., Kaashoek M. F., and Morris R. Designing a dht for\nlow latency and high throughput. In 1st Symposium on Networked Systems Design and\nImplementation, pages 85–98, Berkeley, CA, Mar. 2004b. USENIX, USENIX. →338.\nDamas J., Graff M., and Vixie P. Extension Mechanisms for DNS (EDNS(0)). RFC 6891,\nApr. 2013. →366.\nDannewitz C., Golic J., Ohlman B., and Ahlgren B. Secure Naming for a Network of\nInformation. In 29th INFOCOM Conference Workshops, pages 1–6, Los Alamitos, CA.,\n2010. IEEE Computer Society Press. →344.\nDay J. and Zimmerman H. The OSI Reference Model. Proceedings of the IEEE, 71(12):\nDS 4.01\n \n\n\nBIBLIOGRAPHY\n639\n1334–1340, Dec. 1983. →183.\nDeering S. and Cheriton D. Multicast Routing in Datagram Internetworks and Extended\nLANs. ACM Transactions on Computer Systems, 8(2):85–110, May 1990. →330.\nDeering S., Estrin D., Farinacci D., Jacobson V., Liu C.-G., and Wei L.\nThe PIM\nArchitecture for Wide-Area Multicast Routing. IEEE/ACM Transactions on Networking,\n4(2):153–162, Apr. 1996. →330.\nDeJonghe D. NGINX Cookbook. O’Reilly & Associates, Sebastopol, CA., 2nd edition,\n2022. →163.\nDemers A., Greene D., Hauser C., Irish W., Larson J., Shenker S., Sturgis H., Swinehart\nD., and Terry D. Epidemic Algorithms for Replicated Database Maintenance. In\n6th Symposium on Principles of Distributed Computing, pages 1–12. ACM, Aug. 1987.\n→240, 243, 245.\nDemirbas M. and Kulkarni S. Beyond TrueTime: Using Augmented Time for Improving\nGoogle Spanner. In 7th International Workshop on Large Scale Distributed Systems and\nMiddleware, New York, NY, 2013. ACM Press. →260.\nDey A. Context-Aware Computing. In Krumm J., editor, Ubiquitous Computing Funda-\nmentals, pages 321–352. CRC Press, Boca Raton, FL, 2010. →46.\nDey A. and Abowd G. Towards a Better Understanding of Context and Contex-\nAwareness. In Workshop on the What, Who, Where, When, Why and How of Context-\nAwareness, New York, NY, Apr. 2000. ACM, ACM Press. →45.\nDiffie W. and Hellman M. New Directions in Cryptography. IEEE Transactions on\nInformation Theory, IT-22(6):644–654, Nov. 1976. →565.\nDilley J., Maggs B., Parikh J., Prokop H., Sitaraman R., and Weihl B. Globally Dis-\ntributed Content Delivery. IEEE Internet Computing, 6(5):50–58, Sept. 2002. →165.\nDimou A., Iliopoulos C., Polytidou E., Dhurandher S. K., Papadimitriou G., and\nNicopolitidis P. A Comprehensive Review on Edge Computing: Focusing on Mobile\nUsers. In Nicopolitidis P., Misra S., Yang L. T., Zeigler B., and Ning Z., editors,\nAdvances in Computing, Informatics, Networking and Cybersecurity, number 289 in\nLecture Notes in Networks and Systems, pages 121–152. Springer-Verlag, Berlin,\n2022. →48.\nDiot C., Levine B., Lyles B., Kassem H., and Balensiefen D. Deployment Issues for the\nIP Multicast Service and Architecture. IEEE Network, 14(1):78–88, Jan. 2000. →232.\nDonnet B., Gueye B., and Kaafar M. A Survey on Network Coordinates Systems,\nDesign, and Security. IEEE Communications Surveys & Tutorials, 12(4), Dec. 2010.\n→318.\nDonovan A. A. and Kernighan B. W. The Go Programming Language. Addison-Wesley,\nReading, MA., 2015. →122.\nDoorn J. H. and Rivero L. C., editors. Database Integrity: Challenges and Solutions. Idea\nGroup, Hershey, PA, 2002. →594.\nDouceur J. R. The Sybil Attack. In 1st International Workshop on Peer-to-Peer Systems,\nvolume 2429 of Lecture Notes in Computer Science, pages 251–260, Berlin, Mar. 2002.\nSpringer-Verlag. → 586, 588.\nDroms R. Dynamic Host Configuration Protocol. RFC 2161, Apr. 1997. → 46.\n \nDS 4.01\n\n\n640\nBIBLIOGRAPHY\nDubois M., Scheurich C., and Briggs F.\nSynchronization, Coherence, and Event\nOrdering in Multiprocessors. Computer, 21(2):9–21, Feb. 1988. →398.\nDunagan J., Harvey N. J. A., Jones M. B., Kostic D., Theimer M., and Wolman A.\nFUSE: Lightweight Guaranteed Distributed Failure Notification. In 6th Symposium\non Operating System Design and Implementation, Berkeley, CA, Dec. 2004. USENIX,\nUSENIX. →508.\nDuvvuri V., Shenoy P., and Tewari R. Adaptive Leases: A Strong Consistency Mecha-\nnism for the World Wide Web. IEEE Transactions on Knowledge and Data Engineering,\n15(5):1266–1276, Sept. 2003. →433.\nEastlake D. and Hansen T. Us Secure Hash Algorithms (SHA and SHA-based HMAC\nand HKDF), May 2011. →585.\nEl-Sayed A., Roca V., and Mathy L. A Survey of Proposals for an Alternative Group\nCommunication Service. IEEE Network, 17(1):46–51, Jan. 2003. →233.\nElnozahy E., Alvisi L., Wang Y.-M., and Johnson D. A Survey of Rollback-Recovery\nProtocols in Message-Passing Systems. ACM Computing Surveys, 34(3):375–408, Sept.\n2002. →538, 543.\nElnozahy E. N. and Plank J. S. Checkpointing for Peta-Scale Systems: A Look into the\nFuture of Practical Rollback-Recovery. IEEE Transactions on Dependable and Secure\nComputing, 1(2):97–108, Apr. 2004. →540.\nElson J., Girod L., and Estrin D. Fine-Grained Network Time Synchronization using Ref-\nerence Broadcasts. In 5th Symposium on Operating System Design and Implementation,\npages 147–163, Berkeley, CA, Dec. 2002. USENIX, USENIX. →257, 258.\nErdös P. and Rényi A. On Random Graphs. Publicationes Mathematicae, 6:290–297, 1959.\n→237.\nEscriva R., Wong B., and Sirer E. G. HyperDex: A Distributed, Searchable Key-value\nStore. In SIGCOMM, pages 25–36, New York, NY, 2012. ACM Press. →384.\nEsposito C., Cotroneo D., and Russo S. On Reliability in Publish/Subscribe Services.\nComputer Networks, X(0):xxx, 2013. →517.\nEugster P., Guerraoui R., Kermarrec A.-M., and Massoulié L. Epidemic Information\nDissemination in Distributed Systems. Computer, 37(5):60–67, May 2004. →240.\nEvans D., Kolesnikov V., and Rosulek M. A Pragmatic Introduction to Secure Multi-Party\nComputation. NOW Publishers, Boston, MA; Delft, NL, 2018. →566.\nFeng B., Zhang H., Zhou H., and Yu S.\nLocator/Identifier Split Networking: A\nPromising Future Internet Architecture. IEEE Communications Surveys & Tutorials, 19\n(4):2927–2948, 2017. →329.\nFerguson N. and Schneier B. Practical Cryptography. John Wiley, New York, 2003.\n→290.\nFerguson N., Schneier B., and Kohno T. Cryptography Engineering: Design Principles and\nPractical Applications. John Wiley, New York, 2010. →557, 575.\nFerraiolo D., Kuhn D. R., and Chandramouli R. Role-based Access Control. Artech house,\n2nd edition, 2007. →596.\nFerraiolo D., Atluri V., and Gavrila S. The Policy Machine: A Novel Architecture\nand Framework for Access Control Policy Specification and Enforcement. Journal of\nDS 4.01\n \n\n\nBIBLIOGRAPHY\n641\nSystems Architecture, 57(4):412–424, 2011. →598, 600.\nFerraiolo D., Gavrila S., and Jansen W. Policy Machine: Features, Architecture, and\nSpecification.\nTechnical Report NISTIR 7987, Revision 1, National Institute of\nStandards and Technology (NIST), Oct. 2015. →598.\nFerrer A. J., Marquès J. M., and Jorba J. Towards the Decentralised Cloud: Survey\non Approaches and Challenges for Mobile, Ad hoc, and Edge Computing. ACM\nComputing Surveys, 51(6):1–36, 2019. →47.\nFiebig T., Lichtblau F., Streibelt F., Krüger T., Lexis P., Bush R., and Feldmann A.\nLearning from the Past: Designing Secure Network Protocols. In Cybersecurity Best\nPractices, pages 585–613. Springer-Verlag, Berlin, 2018. →576.\nFielding R. Architectural Styles and the Design of Network-based Software Architectures.\nPh.d., University of California, Irvine, 2000. →66.\nFielding R. and Reschke J. Hypertext Transfer Protocol (HTTP/1.1): Message Syntax\nand Routing. RFC 7230, June 2014. →188.\nFischer M., Lynch N., and Patterson M. Impossibility of Distributed Consensus with\none Faulty Processor. Journal of the ACM, 32(2):374–382, Apr. 1985. →503, 504.\nFloyd S., Jacobson V., McCanne S., Liu C.-G., and Zhang L. A Reliable Multicast\nFramework for Light-weight Sessions and Application Level Framing. IEEE/ACM\nTransactions on Networking, 5(6):784–803, Dec. 1997. →519, 520.\nFokkink W. Distributed Algorithms: An Intuitive Approach. MIT Press, Cambridge, MA.,\n2nd edition, 2018. →248.\nFoster I., Kesselman C., and Tuecke S. The Anatomy of the Grid, Enabling Scalable\nVirtual Organizations. Journal of Supercomputer Applications, 15(3):200–222, Fall 2001.\n→36, 37.\nFoster I. and others . The Open Grid Services Architecture, Version 1.5. GGF Informa-\ntional Document GFD-I.080, June 2006. →37.\nFowler R. Decentralized Object Finding Using Forwarding Addresses. Ph.D., University of\nWashington, Seattle, 1985. →331.\nFox A. and Brewer E. Harvest, Yield, and Scalable Tolerant Systems. In 7th Worksop-\nWorkshop on Hot Topics in Operating Systems (HotOS), pages 174–178, Los Alamitos,\nCA., Mar. 1999. IEEE, IEEE Computer Society Press. →506.\nFrancis L. P. Privacy and Confidentiality: The Importance of Context. The Monist, 91\n(1):52–67, 2008. →553.\nFranklin M. J., Carey M. J., and Livny M. Transactional Client-Server Cache Consistency:\nAlternatives and Performance. ACM Transactions on Database Systems, 22(3):315–363,\nSept. 1997. →443.\nFuggetta A., Picco G. P., and Vigna G. Understanding Code Mobility. IEEE Transactions\non Software Engineering, 24(5):342–361, May 1998. →171, 172.\nGamma E., Helm R., Johnson R., and Vlissides J. Design Patterns, Elements of Reusable\nObject-Oriented Software. Addison-Wesley, Reading, MA., 1994. →75.\nGarbacki P., Epema D., and van Steen M.\nThe Design and Evaluation of a Self-\nOrganizing Super-Peer Network. IEEE Transactions on Computers, 59(3):317–331, Mar.\n2010. →96.\n \nDS 4.01\n\n\n642\nBIBLIOGRAPHY\nGarcia-Molina H. Elections in a Distributed Computing System. IEEE Transactions on\nComputers, 31(1):48–59, Jan. 1982. →283.\nGarfinkel S. PGP: Pretty Good Privacy. O’Reilly & Associates, Sebastopol, CA., 1995.\n→570.\nGarman J. Kerberos: The Definitive Guide. O’Reilly & Associates, Sebastopol, CA., 2003.\n→581.\nGazis A. and Katsiri E. Middleware 101: What to Know Now and for the Future. ACM\nQueue, 20(1):10–23, feb 2022. →11.\nGelernter D. and Carriero N. Coordination Languages and their Significance. Commu-\nnications of the ACM, 35(2):96–107, Feb. 1992. →68.\nGentz R., Wu S. X., Wai H.-T., Scaglione A., and Leshem A. Data Injection Attacks in\nRandomized Gossiping. IEEE Transactions on Signal and Information Processing over\nNetworks, 2(4):523–538, 2016. →306.\nGerofi B., Ishikawa Y., Riesen R., and Wisniewski R. W., editors. Operating Systems\nfor Supercomputers and High Performance Computing. Springer-Verlag, Berlin, 2019.\n→34, 35.\nGhodsi A. Multicast and Bulk Lookup in Structured Overlay Networks. In Shen et al.\n[2010], pages 933–958. →239.\nGifford D. Weighted Voting for Replicated Data. In 7th Symposium on Operating System\nPrinciples, pages 150–162. ACM, Dec. 1979. →441.\nGilbert S. and Lynch N. Brewer’s Conjecture and the Feasibility of Consistent, Available,\nPartition-tolerant Web Services. ACM SIGACT News, 33(2):51–59, June 2002. →505.\nGilbert S. and Lynch N. Perspectives on the CAP Theorem. Computer, 45(2):30–35, Feb.\n2012. →505.\nGkantsidis C., Mihail M., and Saberi A. Random Walks in Peer-to-Peer Networks:\nAlgorithms and Evaluation. Performance Evaluation, 63:241–263, Mar. 2006. →93.\nGoel U., Wittie M. P., and Steiner M. Faster Web through Client-Assisted CDN Server\nSelection. In 14th International Conference on Computer Communications and Networks,\npages 1–10, 2015. →166.\nGoldreich O. Foundations of Cryptography: Volume 2, Basic Applications. Cambridge\nUniversity Press, Cambridge, UK, 2009. →553.\nGonzalez-Manzano L., Fuentes J. M. D., and Ribagorda A. Leveraging User-related\nInternet of Things for Continuous Authentication: A Survey. ACM Computing\nSurveys, 52(3):1–38, 2019. →572.\nGray C. and Cheriton D. Leases: An Efficient Fault-Tolerant Mechanism for Distributed\nFile Cache Consistency. In 12th Symposium on Operating System Principles, pages\n202–210, New York, NY, Dec. 1989. ACM, ACM Press. →433.\nGray J. Notes on Database Operating Systems. In Bayer R., Graham R., and Seegmuller\nG., editors, Operating Systems: An Advanced Course, volume 60 of Lecture Notes in\nComputer Science, pages 393–481. Springer-Verlag, Berlin, 1978. →529.\nGray J. and Reuter A. Transaction Processing: Concepts and Techniques. Morgan Kaufman,\nSan Mateo, CA., 1993. →38.\nGray J., Helland P., O’Neil P., and Sashna D. The Dangers of Replication and a Solution.\nDS 4.01\n \n\n\nBIBLIOGRAPHY\n643\nIn SIGMOD International Conference on Management Of Data, pages 173–182, Montreal,\nJune 1996. ACM. →395.\nGropp W., Lusk E., and Skjellum A. Using MPI-2, Portable Parallel Programming with the\nMessage-Passing Interface. MIT Press, Cambridge, MA., 3rd edition, 2016. →220.\nGuerraoui R. and Schiper A. Software-Based Replication for Fault Tolerance. Computer,\n30(4):68–74, Apr. 1997. →472.\nGuerraoui R., Kneževi´c N., Quéma V., and Vukoli´c M. The next 700 bft protocols. In\n5th EuroSys (European Conference on Computer Systems), pages 363–376, New York,\nNY, 2010. ACM Press. →501.\nGuichard J., Faucheur F. L., and Vasseur J.-P. Definitive MPLS Network Designs. Cisco\nPress, Indianapolis, IN, 2005. →455.\nGuttman E. Autoconfiguration for IP Networking: Enabling Local Communication.\nIEEE Internet Computing, 5:81–86, 2001. →46.\nHadzilacos V. and Toueg S. Fault-Tolerant Broadcasts and Related Problems. In\nMullender S., editor, Distributed Systems, pages 97–145. Addison-Wesley, Wokingham,\n2nd edition, 1993. →466, 526.\nHahmy H. Concepts, Applications, Experimentation and Analysis of Wireless Sensor Networks.\nSpringer-Verlag, Berlin, 2nd edition, 2021. →49.\nHardt D. and others . The OAuth 2.0 Authorization Framework. RFC 6746, Oct. 2012.\n→605.\nHassan W. U., Guo S., Li D., Chen Z., Jee K., Li Z., and Bates A. Nodoze: Combatting\nThreat Alert Fatigue with Automated Provenance Triage. In Symposium on Network\nand Distributed System Security, 2019. →612.\nHaynes T. Network File System (NFS) Version 4 Protocol. RFC 7530, Mar. 2015.\n→83, 350.\nHelder D. A. and Jamin S. End-Host Multicast Communication Using Switch-Trees\nProtocols. In 2nd International Symposium on Cluster Computing and the Grid, pages 419–\n424, Los Alamitos, CA., May 2002. IEEE, IEEE Computer Society Press. →235, 236.\nHellerstein J. M. and Alvaro P. Keeping CALM: When Distributed Consistency is Easy.\nCommunications of the ACM, 63(9):72–81, Sept. 2020. →410.\nHenning M. A New Approach to Object-Oriented Middleware. IEEE Internet Computing,\n8(1):66–75, Jan. 2004. →156.\nHerlihy M. and Shavit N. The Art of Multiprocessor Programming. Morgan Kaufman,\nSan Mateo, CA., 2008. →113.\nHerlihy M. and Wing J. Linearizability: A Correctness Condition for Concurrent\nObjects. ACM Transactions on Programming Languages and Systems, 12(3):463–492, July\n1991. →400.\nHerlihy M., Shavit N., Luchangco V., and Spear M. The Art of Multiprocessor Program-\nming. Morgan Kaufman, San Mateo, CA., 2nd edition, 2021. →33, 400.\nHintjens P. ZeroMQ. O’Reilly & Associates, Sebastopol, CA., 2013. →213.\nHohpe G. and Woolf B. Enterprise Integration Patterns: Designing, Building, and Deploying\nMessaging Solutions. Addison-Wesley, Reading, MA., 2004. →37, 41, 227.\n \nDS 4.01\n\n\n644\nBIBLIOGRAPHY\nHong C.-H. and Varghese B. Resource Management in Fog/Edge Computing: A\nSurvey on Architectures, Infrastructure, and Algorithms. ACM Computing Surveys,\n52(5), 2019. →103.\nHong J. The Privacy Landscape of Pervasive Computing. IEEE Pervasive Computing, 16\n(3):40–48, 2017. →103.\nHorauer M. Clock Synchronization in Distributed Systems. Ph.D., University of Vienna,\nDepartment of Computer Science, Feb. 2004. →253.\nHorner L. J. Edge Strategies in Industry: Overview and Challenges. IEEE Transactions\non Network and Service Management, 18(3):2825–2831, 2021. →100.\nHorowitz M. and Lunt S. FTP Security Extensions. RFC 2228, Oct. 1997. →188.\nHosseini M., Ahmed D., Shirmohammadi S., and Georganas N.\nA Survey of\nApplication-Layer Multicast Protocols. IEEE Communications Surveys & Tutorials, 9\n(3):58–74, 2007. →233.\nHoward H., Schwarzkopf M., Madhavapeddy A., and Crowcroft J. Raft Refloated: Do\nWe Have Consensus? Operating Systems Review, 49(1):12–21, jan 2015. →289.\nHu V. C., Ferraiolo D., Kuhn R., Schnitzer A., Sandlin K., Miller R., and Scarfone K.\nGuide to Attribute Based Access Control (ABAC) Definition and Considerations.\nTechnical Report NIST 800-162, National Institute of Standards and Technology, Jan.\n2014. →596.\nHu V. C., Kuhn D. R., Ferraiolo D. F., and Voas J. Attribute-Based Access Control.\nComputer, 48(2):85–88, 2015. →596.\nHuffaker B., Fomenkov M., Plummer D. J., Moore D., and Claffy K. Distance Metrics\nin the Internet. In International Telecommunications Symposium, Los Alamitos, CA.,\nSept. 2002. IEEE, IEEE Computer Society Press. →454.\nHunt G., Nahum E., and Tracey J. Enabling Content-Based Load Distribution for\nScalable Services. Technical report, IBM T.J. Watson Research Center, May 1997.\n→163.\nHunt P., Konar M., Junqueira F. P., and Reed B. ZooKeeper: Wait-free Coordination for\nInternet-scale Systems. In USENIX Annual Technical Conference, 2010. →280, 422.\nHutto P. and Ahamad M. Slow Memory: Weakening Consistency to Enhance Concur-\nrency in Distributed Shared Memories. In 10th International Conference on Distributed\nComputing Systems, pages 302–311, Paris, France, May 1990. IEEE. →401.\nIqbal M. and Matuleviˇcius R. Exploring Sybil and Double-Spending Risks in Blockchain\nSystems. IEEE Access, 9:76153–76177, 2021. →587.\nISO . Open Distributed Processing Reference Model - Part 2: Foundations. International\nStandard ISO/IEC IS 10746-2, 1995. →12.\nJakubeit P., Peter A., and van Steen M. The Measurable Environment as Nonintrusive\nAuthentication Factor on the Example of WiFi Beacon Frames. In 5th International\nWorkshop on Emerging Technologies for Authorization and Authentication, Sept. 2022.\n→572.\nJalote P. Fault Tolerance in Distributed Systems. Prentice Hall, Englewood Cliffs, N.J.,\n1994. →443, 463.\nJanic M. Multicast in Network and Application Layer. Ph.d., Delft University of Technology,\nDS 4.01\n \n\n\nBIBLIOGRAPHY\n645\nThe Netherlands, Oct. 2005. →232.\nJaniga M. J., Dibner G., and Governali F. J. Internet Infrastructure: Content Delivery.\nGoldman Sachs Global Equity Research, Apr. 2001. →455.\nJelasity M. and Kermarrec A.-M. Ordered Slicing of Very Large-Scale Overlay Networks.\nIn 6th International Conference on Peer-to-Peer Computing, pages 117–124, Los Alamitos,\nCA., Sept. 2006. IEEE Computer Society Press. →300.\nJelasity M., Montresor A., and Babaoglu O.\nGossip-based Aggregation in Large\nDynamic Networks. ACM Transactions on Computer Systems, 23(3):219–252, Aug. 2005.\n→297.\nJelasity M., Voulgaris S., Guerraoui R., Kermarrec A.-M., and van Steen M. Gossip-\nbased Peer Sampling. ACM Transactions on Computer Systems, 25(3), Aug. 2007.\n→241, 298.\nJesi G., Montresor A., and van Steen M. Secure Peer Sampling. Computer Networks, 54\n(12):2086–2098, Aug. 2010. →304, 306.\nJesi G.-P., Hales D., and van Steen M. Identifying Malicious Peers Before It’s Too Late:\nA Decentralized Secure Peer Sampling Service. In 1st International Conference on\nSelf-Adaptive and Self-Organizing Systems, Los Alamitos, CA., June 2007. IEEE, IEEE\nComputer Society Press. →588.\nJohnson B. An Introduction to the Design and Analysis of Fault-Tolerant Systems. In\nPradhan D., editor, Fault-Tolerant Computer System Design, pages 1–87. Prentice Hall,\nUpper Saddle River, N.J., 1995. →470.\nJosefsson S. Shishi – Kerberos 5 Implementation. Samurai Media Limited, Wickford, UK,\n2015. →581.\nJoseph J., Ernest M., and Fellenstein C. Evolution of grid computing architecture and\ngrid adoption models. IBM Systems Journal, 43(4):624–645, Apr. 2004. →37.\nJunqueira F. and Reed B. ZooKeeper. O’Reilly & Associates, Sebastopol, CA., 2014.\n→280, 281, 287.\nKahn D. The Codebreakers. Macmillan, New York, 1967. →556.\nKarsten M. and Barghi S. User-level Threading: Have Your Cake and Eat It Too. In\nInternational Conference on Measurements and Modeling of Computer Systems, volume 4.\nACM, Mar. 2020. →122.\nKasera S., Kurose J., and Towsley D. Scalable Reliable Multicast Using Multiple Multi-\ncast Groups. In International Conference on Measurements and Modeling of Computer\nSystems, pages 64–74, Seattle, WA, June 1997. ACM. →520.\nKaufman C., Perlman R., and Speciner M. Network Security: Private Communication in a\nPublic World. Prentice Hall, Englewood Cliffs, N.J., 2nd edition, 2003. →575, 580.\nKemme B., Jimenez Peris R., and Patino-Martinez M. Replicated Databases. Synthesis\nLectures on Computer Architectures. Morgan and Claypool, San Rafael, CA, 2010.\n→426.\nKermarrec A.-M. and Triantafillou P. XL Peer-to-peer Pub/Sub Systems. ACM Comput-\ning Surveys, 46(2):16:1–16:45, Nov. 2013. →309.\nKhormali A., Park J., Alasmary H., Anwar A., Saad M., and Mohaisen D. Domain\nName System Security and Privacy: A Contemporary Survey. Computer Networks,\n \nDS 4.01\n\n\n646\nBIBLIOGRAPHY\n185, 2021. →365.\nKhoshafian S. and Buckiewicz M. Introduction to Groupware, Workflow, and Workgroup\nComputing. John Wiley, New York, 1995. →226.\nKhraisat A., Gondal I., Vamplew P., and Kamruzzaman J. Survey of Intrusion Detection\nSystems: Techniques, Datasets and Challenges. Cybersecurity, 2(1):1–22, 2019. →612.\nKim M., Fielding J. J., and Kotz D. Risks of Using AP Locations Discovered Through\nWar Driving. In 4th International Conference Pervasive Computing, volume 3968 of\nLecture Notes in Computer Science, pages 67–82, Berlin, May 2006. Springer-Verlag.\n→318.\nKirsch J. and Amir Y. Paxos for System Builders. Technical Report CNDS-2008-2, John\nHopkins University, Mar. 2008. →480, 484.\nKleiman S. Vnodes: an Architecture for Multiple File System Types in UNIX. In\nSummer Technical Conference, pages 238–247, Atlanta, GA, June 1986. USENIX. →84.\nKleppmann M. and Beresford A. R. A Conflict-Free Replicated JSON Datatype. IEEE\nTransactions on Parallel and Distributed Systems, 28(10):2733–2745, Oct. 2017. →410.\nKohl J., Neuman B., and T’so T. The Evolution of the Kerberos Authentication System.\nIn Brazier F. and Johansen D., editors, Distributed Open Systems, pages 78–94. IEEE\nComputer Society Press, Los Alamitos, CA., 1994. →581.\nKopetz H. and Verissimo P. Real Time and Dependability Concepts. In Mullender\nS., editor, Distributed Systems, pages 411–446. Addison-Wesley, Wokingham, 2nd\nedition, 1993. →18, 463.\nKoren I. and Krishna C. M. Fault-Tolerant Systems. Morgan Kaufman, San Mateo, CA.,\n2007. →463, 497.\nKotla R., Alvisi L., Dahlin M., Clement A., and Wong E.\nZyzzyva: Speculative\nByzantine Fault Tolerance. ACM Transactions on Computer Systems, 27(4), Dec. 2009.\n→501.\nKrakowiak S. Middleware Architecture with Patterns and Frameworks. Creative Commons,\n2009. →58.\nKreitz G. and Niemelä F. Spotify – Large Scale, Low Latency, P2P Music-on-Demand\nStreaming. In 10th International Conference on Peer-to-Peer Computing, pages 266–275,\nLos Alamitos, CA., Aug. 2010. IEEE, IEEE Computer Society Press. →28.\nKshemkalyani A. and Singhal M. Distributed Computing, Principles, Algorithms, and\nSystems. Cambridge University Press, Cambridge, UK, 2008. →272, 493, 495.\nKucharski A. The Rules of Contagion, Why Things Spread – And Why They Stop. Profile\nBooks, 2020. →62.\nKumar K., Liu J., Lu Y.-H., and Bhargava B. A Survey of Computation Offloading for\nMobile Systems. Mobile Networks and Applications, 18(1):129–140, 2013. →168.\nLagar-Cavilla H. A., Whitney J. A., Scannell A. M., Patchin P., Rumble S. M., Lara E.de ,\nBrudno M., and Satyanarayanan M. SnowFlock: Rapid Virtual Machine Cloning for\nCloud Computing. In 4th EuroSys (European Conference on Computer Systems), pages\n1–12, New York, NY, 2009. ACM Press. →177.\nLai A. and Nieh J. Limits of Wide-Area Thin-Client Computing. In International\nConference on Measurements and Modeling of Computer Systems, pages 228–239, New\nDS 4.01\n \n\n\nBIBLIOGRAPHY\n647\nYork, NY, June 2002. ACM, ACM Press. →144.\nLaMarca A. and Lara E.de . Location Systems: An Introduction to the Technology Behind\nLocation Awareness. Morgan & Claypool, San Rafael, CA, 2008. →317.\nLamport L. The Part-Time Parliament. ACM Transactions on Computer Systems, 16(2):\n133–169, May 1998. →479.\nLamport L. Paxos Made Simple. ACM SIGACT News, 32(4):51–58, Dec. 2001. →479, 480.\nLamport L. Time, Clocks, and the Ordering of Events in a Distributed System. Commu-\nnications of the ACM, 21(7):558–565, July 1978. →260, 441.\nLamport L. How to Make a Multiprocessor Computer that Correctly Executes Mul-\ntiprocessor Programs. IEEE Transactions on Computers, C-29(9):690–691, Sept. 1979.\n→397.\nLamport L., Shostak R., and Paese M.\nThe Byzantine Generals Problem.\nACM\nTransactions on Programming Languages and Systems, 4(3):382–401, July 1982. →468.\nLampson B. How to Build a Highly Available System using Consensus. In Babaoglu\nO. and Marzullo K., editors, 12th International Workshop on Distributed Algorithms,\nvolume 1151 of Lecture Notes in Computer Science, pages 1–17, Berlin, Oct. 1996.\nSpringer-Verlag. →479.\nLaprie J.-C. Dependability – Its Attributes, Impairments and Means. In Randell B.,\nLaprie J.-C., Kopetz H., and Littlewood B., editors, Predictably Dependable Computing\nSystems, pages 3–24. Springer-Verlag, Berlin, 1995. →547.\nLaurie B. and Laurie P. Apache: The Definitive Guide. O’Reilly & Associates, Sebastopol,\nCA., 3rd edition, 2002. →161.\nLawder J. and King P. Querying Multi-dimensional Data Indexed Using Hilbert\nSpace-Filling Curve. ACM Sigmod Record, 30(1):19–24, Mar. 2000. →381.\nLevesque M. and Tipper D.\nA Survey of Clock Synchronization Over Packet-\nSwitched Networks.\nIEEE Communications Surveys & Tutorials, 18(4):2926–2947,\n2016. →253, 257.\nLevine B. and Garcia-Luna-Aceves J. A Comparison of Reliable Multicast Protocols.\nACM Multimedia Systems Journal, 6(5):334–348, 1998. →519.\nLevine B. N., Shields C., and Margolin N. B. A Survey of Solutions to the Sybil Attack.\nTechnical report, University of Massachusetts Amherst, Amherst, MA, 2006. →588.\nLewis B. and Berg D. J.\nMultithreaded Programming with Pthreads.\nPrentice Hall,\nEnglewood Cliffs, N.J., 2nd edition, 1998. →113.\nLi X., Jiang P., Chen T., Luo X., and Wen Q. A Survey on the Security of Blockchain\nSystems. Future Generation Computer Systems, 107:841–853, 2020. →589.\nLilja D. Cache Coherence in Large-Scale Shared-Memory Multiprocessors: Issues and\nComparisons. ACM Computing Surveys, 25(3):303–338, Sept. 1993. →443.\nLin M.-J. and Marzullo K. Directional Gossip: Gossip in a Wide-Area Network. In\nProceedings 3rd European Dependable Computing Conf., volume 1667 of Lecture Notes in\nComputer Science, pages 364–379. Springer-Verlag, Berlin, Sept. 1999. →244.\nLin S.-D., Lian Q., Chen M., , and Zhang Z. A Practical Distributed Mutual Exclusion\nProtocol in Dynamic Peer-to-Peer Systems. In 3rd International Workshop on Peer-to-\nPeer Systems, volume 3279 of Lecture Notes in Computer Science, pages 11–21, Berlin,\n \nDS 4.01\n\n\n648\nBIBLIOGRAPHY\nFeb. 2004. Springer-Verlag. →277, 278.\nLing B. C., Kiciman E., and Fox A. Session State: Beyond Soft State. In 1st Symposium\non Networked Systems Design and Implementation, pages 295–308, Berkeley, CA, Mar.\n2004. USENIX, USENIX. →153.\nLiskov B. From viewstamped Replication to Byzantine Fault Tolerance. In Charron-\nBost B., Pedone F., and Schiper A., editors, Replication, Theory and Practice, volume\n5959 of Lecture Notes in Computer Science, chapter 5, pages 121–149. Springer-Verlag,\nBerlin, 2010. →498.\nLiu C. and Albitz P. DNS and BIND. O’Reilly & Associates, Sebastopol, CA., 5th\nedition, 2006. →189, 359.\nLiu C.-G., Estrin D., Shenker S., and Zhang L. Local Error Recovery in SRM: Compari-\nson of Two Approaches. IEEE/ACM Transactions on Networking, 6(6):686–699, Dec.\n1998. →520.\nLiu F. and Solihin Y. Understanding the Behavior and Implications of Context Switch\nMisses. ACM Transactions on Architecture and Code Optimization, 7(4):21:1–21:28, Dec.\n2010. →116.\nLo V., Zhou D., Liu Y., GauthierDickey C., and Li J. Scalable Supernode Selection in\nPeer-to-Peer Overlay Networks. In 2nd Workshop on Hot Topics in Peer-to-Peer Systems\n(HotP2P), pages 18–27, Los Alamitos, CA., July 2005. IEEE Computer Society Press.\n→293.\nLua E., Crowcroft J., Pias M., Sharma R., and Lim S. A Survey and Comparison of\nPeer-to-Peer Overlay Network Schemes. IEEE Communications Surveys & Tutorials, 7\n(2):22–73, Apr. 2005. →32, 89.\nLui J., Misra V., and Rubenstein D. On the Robustness of Soft State Protocols. In 12th\nInternational Conference on Network Protocols, pages 50–60, Los Alamitos, CA., Oct.\n2004. IEEE, IEEE Computer Society Press. →152.\nLv Q., Cao P., Cohen E., Li K., and Shenker S. Search and Replication in Unstructured\nPeer-to-Peer Networks. In 16th International Conference on Supercomputing, pages\n84–95, New York, NY, June 2002. ACM, ACM Press. →93, 94.\nLynch N. Distributed Algorithms. Morgan Kaufman, San Mateo, CA., 1996. →249, 283.\nLyu L., Yu H., Zhao J., and Yang Q. Threats to Federated Learning, volume 12500 of\nLecture Notes in Artificial Intelligence, pages 3–16. Springer Nature, Cham, 2020.\n→169.\nMaassen J., Kielmann T., and Bal H. E. Parallel Application Experience with Replicated\nMethod Invocation. Concurrency & Computation: Practice and Experience, 13(8-9):\n681–712, 2001. →436.\nMadden S. R., Franklin M. J., Hellerstein J. M., and Hong W. TinyDB: An Acquisitional\nQuery Processing System for Sensor Networks.\nACM Transactions on Database\nSystems, 30(1):122–173, 2005. →51.\nMahajan P., Alvisi L., and Dahlin M.\nConsistency, availability, and convergence.\nTechnical Report TR-11-22, University of Texas at Austin, May 2011. →408.\nMalhotra A., Cohen I. E., Brakke E., and Goldberg S. Attacking the Network Time\nProtocol. In Symposium on Network and Distributed System Security, Feb. 2016. →257.\nDS 4.01\n \n\n\nBIBLIOGRAPHY\n649\nMalone T. and Crowston K. The Interdisciplinary Study of Coordination. ACM\nComputing Surveys, 26(1):87–119, Mar. 1994. →248.\nMao Z. M., Cranor C. D., Douglis F., Rabinovich M., Spatscheck O., and Wang J. A\nPrecise and Efficient Evaluation of the Proximity between Web Clients and their\nLocal DNS Servers. In USENIX Annual Technical Conference, pages 229–242, Berkeley,\nCA, June 2002. USENIX, USENIX. →166.\nMarzullo K. and Owicki S. Maintaining The Time in a Distributed System. In 2nd\nSymposium on Principles of Distributed Computing, pages 295–305, New York, NY, 1983.\nACM, ACM Press. →259.\nMattern F. and Floerkemeier C. From the Internet of Computers to the Internet of Things,\npages 242–259. Springer-Verlag, Berlin, 2010. →44.\nMazouni K., Garbinato B., and Guerraoui R. Building Reliable Client-Server Software\nUsing Actively Replicated Objects. In Graham I., Magnusson B., Meyer B., and\nNerson J.-M., editors, Technology of Object Oriented Languages and Systems, pages\n37–53. Prentice Hall, Englewood Cliffs, N.J., 1995. →436.\nMedina V. and Garcia J. A Survey of Migration Mechanisms of Virtual Machines. ACM\nComputing Surveys, 46(3):30, Jan. 2014. →175.\nMeling H. and Jehl L. Tutorial Summary: Paxos Explained from Scratch. In 17th\nInternational Conference on Principles of Distributed Systems, pages 1–10. Springer, 2013.\n→484.\nMenasce D. and Almeida V. Capacity Planning for Web Services. Prentice Hall, Englewood\nCliffs, N.J., 2002. →25.\nMenezes A. J., Oorschot P. C.van , and Vanstone S. A. Handbook of Applied Cryptography.\nCRC Press, Boca Raton, 3rd edition, 1996. →568.\nMerideth M. G. and Reiter M. K. Selected Results from the Latest Decade of Quorum\nSystems Research, pages 185–206. Springer-Verlag, Berlin, 2010. →443.\nMessage Passing Interface Forum . MPI: A Message-Passing Interface Standard, version\n4.0. Technical report, University of Tenness, Knoxville, June 2021. →220.\nMeyerovich L. A. and Bodik R. Fast and Parallel Webpage Layout. In 19th International\nWorld Wide Web Conference, pages 711–720, New York, NY, 2010. ACM Press. →124.\nMills D.\nNetwork Time Protocol (version 3): Specification, Implementation, and\nAnalysis. RFC 1305, July 1992. →257.\nMills D. L. Computer Network Time Synchronization: The Network Time Protocol on Earth\nand in Space. CRC Press, Boca Raton, FL, 2nd edition, 2011. →257.\nMilojicic D., Douglis F., Paindaveine Y., Wheeler R., and Zhou S. Process Migration.\nACM Computing Surveys, 32(3):241–299, Sept. 2000. →167.\nMin S. L. and Baer J.-L. Design and Analysis of a Scalable Cache Coherence Scheme\nBased on Clocks and Timestamps. IEEE Transactions on Parallel and Distributed\nSystems, 3(1):25–44, Jan. 1992. →443.\nMockapetris P. Domain Names - Concepts and Facilities. RFC 1034, Nov. 1987a.\n→354, 359.\nMockapetris P. Domain Names - Implementation and Specification. RFC 1035, Nov.\n1987b. →354, 359.\n \nDS 4.01\n\n\n650\nBIBLIOGRAPHY\nMohan C., Strong R., and Finkelstein S. Method for Distributed Transaction Commit\nand Recovery using Byzantine Agreement within Clusters of Processors. In 2nd\nSymposium on Principles of Distributed Computing, pages 89–103, New York, NY, 1983.\nACM Press. →468.\nMoll P., Shang W., Yu Y., Afanasyev A., and Zhang L. A Survey of Distributed Dataset\nSynchronization in Named Data Networking. Technical Report NDN-0053, UCLA,\nMay 2021. →386.\nMottola L. and Picco G. P. Programming Wireless Sensor Networks: Fundamental\nConcepts and State of the Art. ACM Computing Surveys, 43(3):19:1–19:51, Apr. 2011.\n→49.\nMoura G. C. M., Castro S., Hardaker W., Wullink M., and Hesselman C. Clouding up\nthe Internet: How Centralized is DNS Traffic Becoming? In Internet Measurement\nConference, page 42–49, 2020. →365.\nMousazadeh M. and Ladani B. T. Gossip-based Data Aggregation in Hostile Environ-\nments. Computer Communications, 62:1–12, 2015. →306.\nMühl G., Fiege L., and Pietzuch P. Distributed Event-Based Systems. Springer-Verlag,\nBerlin, 2006. →69.\nMuntz D. and Honeyman P. Multi-level Caching in Distributed File Systems. In Winter\nTechnical Conference, pages 305–313, San Francisco, CA, Jan. 1992. USENIX. →429.\nMurty J. Programming Amazon Web Services. O’Reilly & Associates, Sebastopol, CA.,\n2008. →66, 99.\nNajafi A., Tai A., and Wei M. Systems Research is Running out of Time. In Workshop\non Hot Topics in Operating Systems (HotOS), page 65–71, 2021. →249.\nNaur P. and Randell B. Report on the NATO Software Engineering Conference 1968.\nTechnical report, Scientific Affairs Division NATO, Brussels, Belgium, Oct. 1968.\n→74.\nNeedham R. and Schroeder M. Using Encryption for Authentication in Large Networks\nof Computers. Communications of the ACM, 21(12):993–999, Dec. 1978. →577.\nNelson B. Remote Procedure Call. Ph.D., Carnegie-Mellon University, 1981. →514.\nNeuman B. Proxy-Based Authorization and Accounting for Distributed Systems.\nIn 13th International Conference on Distributed Computing Systems, pages 283–291,\nPittsburgh, May 1993. IEEE. →601.\nNeuman B. Scale in Distributed Systems. In Casavant T. and Singhal M., editors,\nReadings in Distributed Computing Systems, pages 463–489. IEEE Computer Society\nPress, Los Alamitos, CA., 1994. →24, 28, 606.\nNeuman C., Yu T., Hartman S., and Raeburn K. The Kerberos Network Authentication\nService. RFC 4120, July 2005. →581.\nNg E. and Zhang H. Predicting Internet Network Distance with Coordinates-Based\nApproaches. In 21st INFOCOM Conference, Los Alamitos, CA., June 2002. IEEE, IEEE\nComputer Society Press. →320.\nNguyen C. T., Hoang D. T., Nguyen D. N., Niyato D., Nguyen H. T., and Dutkiewicz E.\nProof-of-Stake Consensus Mechanisms for Future Blockchain Networks: Fundamen-\ntals, Applications and Opportunities. IEEE Access, 7:85727–85745, 2019. →292, 589.\nDS 4.01\n \n\n\nBIBLIOGRAPHY\n651\nNissenbaum H. Privacy in Context. Stanford University Press, Stanford, CA, 2010.\n→553.\nNoble B., Fleis B., and Kim M. A Case for Fluid Replication. In NetStore’99, Seattle,\nWA, Oct. 1999. →430.\nNoveck D. and Lever C. Network File System (NFS) Version 4 Minor Verion 1 Protocol.\nRFC 8881, Aug. 2020. →83, 350.\nNyers L. and Jelasity M. A Comparative Study of Spanning Tree and Gossip Protocols\nfor Aggregation. Concurrency & Computation: Practice and Experience, 2015. →522.\nNygren E., Sitaraman R. K., and Sun J. The Akamai Network: A Platform for High-\nPerformance Internet Applications. Operating Systems Review, 44(3):2–19, July 2010.\n→165.\nOASIS . AMQP, Protocol specification, Version 1.0, Oct. 2012. →227.\nObraczka K. Multicast Transport Protocols: A Survey and Taxonomy. IEEE Communi-\ncations Magazine, 36(1):94–102, Jan. 1998. →232.\nOikonomou K. and Stavrakakis I. Performance Analysis of Probabilistic Flooding\nUsing Random Graphs. In World of Wireless, Mobile and Multimedia Networks, 2007.\nWoWMoM 2007. IEEE International Symposium on a, pages 1–6, June 2007.\ndoi:\n10.1109/WOWMOM.2007.4351694. →237.\nOMG . The Common Object Request Broker: Architecture and Specification, revision\n2.4.2. OMG Document formal/00-02-33, Object Management Group, Framingham,\nMA, Feb. 2001. →156.\nOMG . UML 2.0 Superstructure Specification. OMG Document ptc/04-10-02, Object\nManagement Group, Framingham, MA, Oct. 2004. →57.\nOngaro D. Consensus: Bridging Theory AND Practice. Ph.D., Stanford University, Aug.\n2014. →479.\nOngaro D. and Ousterhout J. In Search of an Understandable Consensus Algorithm.\nIn USENIX Annual Technical Conference, pages 305–319, Berkeley, CA, June 2014.\nUSENIX, USENIX. →289, 477, 479.\nOnica E., Felber P., Mercier H., and Riviere E. Confidentiality-Preserving Publish/Sub-\nscribe: A Survey. ACM Computing Surveys, 49(2), June 2016. →315.\nOram A., editor. Peer-to-Peer: Harnessing the Power of Disruptive Technologies. O’Reilly &\nAssociates, Sebastopol, CA., 2001. →32.\nOtte P. Sybil-resistant Trust Mechanisms in Distributed Systems. Msc, Delft University\nof Technology, Dec. 2016. →591.\nOtte P., Vos M.de , and Pouwelse J. TrustChain: A Sybil-resistant Scalable Blockchain.\nFuture Generation Computer Systems, 107:770–780, 2020. →589, 590.\nÖzsu T. and Valduriez P. Principles of Distributed Database Systems. Springer-Verlag,\nBerlin, 4th edition, 2020. →89, 426.\nPahl C., Brogi A., Soldani J., and Jamshidi P.\nCloud Container Technologies: A\nState-of-the-Art Review. IEEE Transactions on Cloud Computing, 7(3):677–692, 2019.\n→135.\nPai V., Aron M., Banga G., Svendsen M., Druschel P., Zwaenepoel W., and Nahum\nE. Locality-Aware Request Distribution in Cluster-Based Network Servers. In\n \nDS 4.01\n\n\n652\nBIBLIOGRAPHY\n8th International Conference on Architectural Support for Programming Languages and\nOperating Systems, pages 205–216, New York, NY, Oct. 1998. ACM, ACM Press.\n→163.\nPanzieri F. and Shrivastava S. Rajdoot: A Remote Procedure Call Mechanism with\nOrphan Detection and Killing. IEEE Transactions on Software Engineering, 14(1):30–37,\nJan. 1988. →515.\nPappas V., Massey D., Terzis A., and Zhang L. A Comparative Study of the DNS\nDesign with DHT-Based Alternatives. In 25th INFOCOMConference, Los Alamitos,\nCA., May 2006. IEEE, IEEE Computer Society Press. →368.\nParecki A. OAuth 2.0 Simplified: A Guide to Building OAuth 2.0 Servers. Lulu Press, Inc,\n2020. →605.\nPark S., Specter M., Narula N., and Rivest R. L. Going From Bad to Worse: From\nInternet Voting to Blockchain Voting. Journal of Cybersecurity, 7(1):1–15, 2021. →592.\nParlavantzas N. and Coulson G. Designing and Constructing Modifiable Middleware\nusing Component Frameworks. IET Software, 1(4):113–126, Aug. 2007. →78.\nPassarella A. A Survey on Content-centric Technologies for the Current Internet: CDN\nand P2P Solutions. Computer Communications, 35(1):1–32, 2012. →165.\nPautasso C., Zimmermann O., and Leymann F. Restful Web Services vs. \"Big\" Web\nServices: Making the Right Architectural Decision. In 17th International World Wide\nWeb Conference, pages 805–814, New York, NY, Aug. 2008. ACM Press. →66, 67.\nPease M., Shostak R., and Lamport L. Reaching Agreement in the Presence of Faults.\nJournal of the ACM, 27(2):228–234, Apr. 1980. →468.\nPerkins C. IP Mobility Support in IPv4, Revised. RFC 5944, Nov. 2010. →47.\nPerkins C., Johnson D., and Arkko J. Mobility Support in IPv6. RFC 6275, July 2011.\n→47, 331.\nPeterson L., Bavier A., Fiuczynski M. E., and Muir S. Experiences Building PlanetLab.\nIn 7th Symposium on Operating System Design and Implementation, pages 351–366,\nBerkeley, CA, Nov. 2006. USENIX, USENIX. →136.\nPike R., Presotto D., Dorward S., Flandrena B., Thompson K., Trickey H., and Winter-\nbottom P. Plan 9 from Bell Labs. Computing Systems, 8(3):221–254, Summer 1995.\n→346.\nPinzari G. NX X Protocol Compression. Technical Report D-309/3-NXP-DOC, NoMa-\nchine, Rome, Italy, Sept. 2003. →144.\nPitoura E. and Samaras G. Locating Objects in Mobile Computing. IEEE Transactions\non Knowledge and Data Engineering, 13(4):571–592, July 2001. →338.\nPlummer D. An Ethernet Address Resolution Protocol. RFC 826, Nov. 1982. →330.\nPodling S. and Boszormenyi L. A Survey of Web Cache Replacement Strategies. ACM\nComputing Surveys, 35(4):374–398, Dec. 2003. →453.\nPopek G. J. and Goldberg R. P. Formal Requirements for Virtualizable Third Generation\nArchitectures. Communications of the ACM, 17(7):412–421, July 1974. →131, 132.\nPopescu A., Constantinescu D., Erman D., and Ilie D. A Survey of Reliable Multicast\nCommunication. In 3rd Conference on Next Generation Internet Networks, pages 111–\n118, May 2007. →517.\nDS 4.01\n \n\n\nBIBLIOGRAPHY\n653\nPopescu A. M., Tudorache G. I., Peng B., and Kemp A. H. Surveying Position Based\nRouting Protocols for Wireless Sensor and Ad-hoc Networks. International Journal on\nCommunication Networks and Information Security, 4(1):41–67, Apr. 2012. →319.\nPoslad S. Ubiquitous Computing: Smart Devices, Environments and Interactions. John\nWiley, New York, 2009. →44, 46.\nPostel J. Simple Mail Transfer Protocol. RFC 821, Aug. 1982. →226.\nPostel J. and Reynolds J. File Transfer Protocol. RFC 995, Oct. 1985. →188.\nPourghassemi B. Adaptive Tools for Performance Analysis of Large-scale Applications. Phd,\nUniversity of California at Irvine, 2021. →146.\nPouwelse J. A., Garbacki P., Epema D. H. J., and Sips H. J. The Bittorrent P2P File-\nSharing System: Measurements and Analysis. In 4th International Workshop on\nPeer-to-Peer Systems, volume 3640 of Lecture Notes in Computer Science, pages 205–216,\nBerlin, Feb. 2005. Springer-Verlag. →97.\nPradhan D. Fault-Tolerant Computer System Design. Prentice Hall, Englewood Cliffs,\nN.J., 1996. →464.\nPreguica N. Conflict-Free Replicated Data Types: An Overview. arXiv:1806.10254,\n2018. →410.\nPrisco R. D., Lampson B., and Lynch N. Revisiting the Paxos Algorithm. In Mavroni-\ncolas M. and Tsigas P., editors, 11th International Workshop on Distributed Algorithms,\nvolume 1320 of Lecture Notes in Computer Science. Springer-Verlag, Berlin, Sept. 1997.\n→479.\nQin H., Li Q., Speiser J., Kraft P., and Ousterhout J. Arachne: Core-Aware Thread\nManagement. In 13th Symposium on Operating System Design and Implementation,\npages 145–161. USENIX, Oct. 2018. →122.\nRabinovich M. and Spastscheck O. Web Caching and Replication. Addison-Wesley,\nReading, MA., 2002. →451.\nRabinovich M., Rabinovich I., Rajaraman R., and Aggarwal A. A Dynamic Object\nReplication and Migration Protocol for an Internet Hosting Service. In 19th Interna-\ntional Conference on Distributed Computing Systems, pages 101–113, Austin, TX, June\n1999. IEEE. →427, 428.\nRadia S. Names, Contexts, and Closure Mechanisms in Distributed Computing Environments.\nPh.D., University of Waterloo, Ontario, 1989. →348.\nRajaraman V. Grid Computing. Resonance, 21(5):401–415, 2016. →35.\nRamanathan P., Shin K., and Butler R. Fault-Tolerant Clock Synchronization in Dis-\ntributed Systems. Computer, 23(10):33–42, Oct. 1990. →253.\nRamirez W., Masip-Bruin X., Yannuzzi M., Serral-Gracia R., Martinez A., and Siddiqui\nM. A Survey and Taxonomy of ID/Locator Split Architectures. Computer Networks,\n60:13–33, 2014. →329.\nRaynal M. and Singhal M. Logical Time: Capturing Causality in Distributed Systems.\nComputer, 29(2):49–56, Feb. 1996. →262.\nRescorla E. and others . The Transport Layer Security (TLS) Protocol Version 1.3. RFC\n8446, Aug. 2018. → 583.\nReynolds J. and Postel J. Assigned Numbers. RFC 1700, Oct. 1994. → 150.\n \nDS 4.01\n\n\n654\nBIBLIOGRAPHY\nRicart G. and Agrawala A. An Optimal Algorithm for Mutual Exclusion in Computer\nNetworks. Communications of the ACM, 24(1):9–17, Jan. 1981. →274.\nRichards M. and Ford N. Fundamentals of Software Architecture. O’Reilly & Associates,\nSebastopol, CA., 2020. →56.\nRichardson T., Stafford-Fraser Q., Wood K. R., and Hopper A.\nVirtual Network\nComputing. IEEE Internet Computing, 2(1):33–38, Jan. 1998. →144.\nRisson J. and Moors T. Survey of Research towards Robust Peer-to-Peer Networks:\nSearch Methods. Computer Networks, 50(17):3485–3521, 2006. →93.\nRizzo L. Effective Erasure Codes for Reliable Computer Communication Protocols.\nSIGCOMM Computer Communications Review, 27(2):24–36, Apr. 1997. →536.\nRobbins K. and Robbins S. UNIX Systems Programming. Prentice Hall, Englewood\nCliffs, N.J., 2003. →113, 122.\nRobin J. S. and Irvine C. E. Analysis of the Intel Pentium’s Ability to Support a\nSecure Virtual Machine Monitor. In 9th USENIX Security Symposium, pages 129–144,\nBerkeley, CA, 2000. USENIX. →132.\nRodrigues L., Fonseca H., and Verissimo P. Totally Ordered Multicast in Large-Scale\nSystems. In 16th International Conference on Distributed Computing Systems, pages\n503–510, Hong Kong, May 1996. IEEE. →441.\nRodriguez P., Spanner C., and Biersack E. Analysis of Web Caching Architecture:\nHierarchical and Distributed Caching. IEEE/ACM Transactions on Networking, 21(4):\n404–418, Aug. 2001. →452.\nRosenblum M. and Garfinkel T. Virtual Machine Monitors: Current Technology and\nFuture Trends. Computer, 38(5):39–47, May 2005. →131.\nRoussos G., Marsh A. J., and Maglavera S. Enabling Pervasive Computing with Smart\nPhones. IEEE Pervasive Computing, 4(2):20–26, Apr. 2005. →44.\nRowe F., Baskerville R., and Wolff F.-C. Functionality vs. Security in IS: Tradeoff or\nEquilibrium? In 33rd International Conference on Information Systems, 2012. →566.\nRowstron A. and Druschel P.\nPastry: Scalable, Distributed Object Location and\nRouting for Large-Scale Peer-to-Peer Systems. In Middleware 2001, volume 2218 of\nLecture Notes in Computer Science, pages 329–350, Berlin, Nov. 2001. Springer-Verlag.\n→233, 338.\nRoy G.\nRabbitMQ in Depth.\nManning Publications, Shelter Island, NY, 2018.\n→227, 230, 231, 232.\nSaad M., Spaulding J., Njilla L., Kamhoua C., Shetty S., Nyang D., and Mohaisen\nD. Exploring the Attack Surface of Blockchain: A Comprehensive Survey. IEEE\nCommunications Surveys & Tutorials, 22(3):1977–2008, 2020. →589.\nSagan H. Space-Filling Curves. Springer-Verlag, Berlin, 1994. →382.\nSahoo J., Salahuddin M. A., Glitho R., Elbiaze H., and Ajib W. A Survey on Replica\nServer Placement Algorithms for Content Delivery Networks. IEEE Communications\nSurveys & Tutorials, 19(2):1002–1026, 2017. →424, 425, 426.\nSalaht F. A., Desprez F., and Lebre A. An Overview of Service Placement Problem in\nFog and Edge Computing. ACM Computing Surveys, 53(3), June 2020. →104.\nSaltzer J. and Kaashoek M. Principles of Computer System Design, An Introduction.\nDS 4.01\n \n\n\nBIBLIOGRAPHY\n655\nMorgan Kaufman, San Mateo, CA., 2009. →79, 546, 547.\nSaltzer J. and Schroeder M. The Protection of Information in Computer Systems.\nProceedings of the IEEE, 63(9):1278–1308, Sept. 1975. →549, 550.\nSaltzer J., Reed D., and Clark D. End-to-End Arguments in System Design. ACM\nTransactions on Computer Systems, 2(4):277–288, Nov. 1984. →271.\nSambra A. V., Mansour E., Hawke S., Zereba M., Greco N., Ghanem A., Zagidulin\nD., Aboulnaga A., and Berners-Lee T. Solid: A Platform for Decentralized Social\nApplications based on Linked Data. MIT CSAIL & Qatar Computing Research Institute,\nTech. Rep., 2016. →553.\nSantoro N. Design and Analysis of Distributed Algorithms. John Wiley, New York, 2007.\n→249.\nSaroiu S., Gummadi P. K., and Gribble S. D. Measuring and Analyzing the Character-\nistics of Napster and Gnutella Hosts. ACM Multimedia Systems, 9(2):170–184, Aug.\n2003. →96.\nSaxena D., Raychoudhury V., Suri N., Becker C., and Cao J. Named data networking:\nA survey. Computer Science Review, 19:15–55, 2016. →386.\nSaxena P. and Rai J. A Survey of Permission-based Distributed Mutual Exclusion\nAlgorithms. Computer Standards and Interfaces, 25(2):159–181, May 2003. →272.\nSchlosser M., Sintek M., Decker S., and Nejdl W. HyperCuP – Hypercubes, Ontologies,\nand Efficient Search on Peer-to-Peer Networks. In 1st International Workshop on\nAgents and Peer-to-Peer Computing, volume 2530 of Lecture Notes in Computer Science,\npages 112–124, Berlin, July 2002. Springer-Verlag. →238.\nSchmidt A. Implicit Human Computer Interaction Through Context. Personal and\nUbiquitous Computing, 4(2-3):191–199, June 2000. →45.\nSchmidt C. and Parashar M. Squid: Enabling Search in DHT-based systems. Journal of\nParallel and Distributed Computing, 68:962–975, 2008. →383.\nSchmidt D., Stal M., Rohnert H., and Buschmann F. Pattern-Oriented Software Archi-\ntecture – Patterns for Concurrent and Networked Objects. John Wiley, New York, 2000.\n→76.\nSchneider F. Implementing Fault-Tolerant Services Using the State Machine Approach:\nA Tutorial. ACM Computing Surveys, 22(4):299–320, Dec. 1990. →264, 431.\nSchulzrinne H., Casner S., Frederick R., and Jacobson V. RTP: A Transport Protocol for\nReal-Time Applications. RFC 3550, July 2003. →187.\nSchwarzkopf M., Kohler E., Frans Kaashoek M., and Morris R. Position: GDPR\nCompliance by Construction. In Gadepally V., Mattson T., Stonebraker M., Wang\nF., Luo G., Laing Y., and Dubovitskaya A., editors, Heterogeneous Data Management,\nPolystores, and Analytics for Healthcare (DMAH 2019, Poly 2019), volume 11721 of\nLecture Notes in Computer Science, pages 39–53, Berlin, 2019. Springer-Verlag. →554.\nSebesta R. Programming the World Wide Web. Addison-Wesley, Reading, MA., 8th\nedition, 2015. →87.\nSereno M. and Gaeta R. Generalized Probabilistic Flooding in Unstructured Peer-to-\nPeer Networks. IEEE Transactions on Parallel and Distributed Systems, 22(12):2055–2062,\n2011. ISSN 1045-9219. →238.\n \nDS 4.01\n\n\n656\nBIBLIOGRAPHY\nServos D. and Osborn S. L. Current Research and Open Problems in Attribute-based\nAccess Control. ACM Computing Surveys, 49(4):1–45, 2017. →598, 601.\nSeuken S. and Parkes D. C. Sybil-proof Accounting Mechanisms with Transitive Trust.\nIn International Joint Conference on Autonomous Agents and Multiagent Systems, pages\n205–212. ACM, 2014. →590.\nShahrad M., Balkind J., and Wentzlaff D. Architectural Implications of Function-as-\na-Service Computing. In Annual IEEE/ACM International Symposium on Microar-\nchitecture, page 1063–1075, New York, NY, USA, 2019. Association for Computing\nMachinery. →100.\nShapiro M., Preguiça N., Baquero C., and Zawirski M. Conflict-Free Replicated Data\nTypes. In 13th International Conference Stabilization, Safety, and Security of Distributed\nSystems, page 386–400, Berlin, 2011. Springer-Verlag. →409.\nSharma P., Chaufournier L., Shenoy P., and Tay Y. Containers and Virtual Machines at\nScale: A Comparative Study. In Middleware 2016, pages 1–13. ACM/IFIP/USENIX,\nDec. 2016. →138.\nShastri S., Banakar V., Wasserman M., Kumar A., and Chidambaram V. Understanding\nand Benchmarking the Impact of GDPR on Database Systems. Proceedings of the\nVLDB Endowment, 13(7):1064–1077, mar 2020. →554, 555.\nShen X., Yu H., Buford J., and Akon M., editors. Handbook of Peer-to-Peer Networking.\nSpringer-Verlag, Berlin, 2010. →636, 642.\nSheth A. P. and Larson J. A. Federated Database Systems for Managing Distributed,\nHeterogeneous, and Autonomous Databases. ACM Computing Surveys, 22(3):183–236,\nSept. 1990. →427.\nShin M., Park M., Oh D., Kim B., and Lee J. Survey on the Clock Synchronization\nSchemes for Propagation Delay Measurement. International Journal of Advanced\nScience and Technology, 35:139–140, Oct. 2011. →253.\nShoch J. Internetwork Naming, Addressing, and Routing. In 17th International Computer\nConference, pages 72–79, Los Alamitos, CA., 1978. IEEE, IEEE Computer Society\nPress. →329.\nShooman M. L. Reliability of Computer Systems and Networks: Fault Tolerance, Analysis,\nand Design. John Wiley, New York, 2002. →463.\nShriram A. and Kaur J. Empirical Evaluation of Techniques for Measuring Available\nBandwidth. In 26th INFOCOM Conference, pages 2162–2170, Los Alamitos, CA., 2007.\nIEEE, IEEE Computer Society Press. →454.\nSilberschatz A., Galvin P., and Gagne G. Operating System Concepts. John Wiley, New\nYork, 10th edition, 2019. →346.\nSinghal M. and Shivaratri N. Advanced Concepts in Operating Systems: Distributed,\nDatabase, and Multiprocessor Operating Systems. McGraw-Hill, New York, 1994. →537.\nSivasubramanian S., Pierre G., and van Steen M. Replicating Web Applications On-\nDemand. In 1st International Conference on Services Computing, pages 227–236, Los\nAlamitos, CA., Sept. 2004a. IEEE, IEEE Computer Society Press. →457.\nSivasubramanian S., Szymaniak M., Pierre G., and van Steen M. Replication for Web\nHosting Systems. ACM Computing Surveys, 36(3):1–44, Sept. 2004b. →453.\nDS 4.01\n \n\n\nBIBLIOGRAPHY\n657\nSivasubramanian S., Pierre G., van Steen M., and Alonso G. Analysis of Caching and\nReplication Strategies for Web Applications. IEEE Internet Computing, 11(1):60–66,\nJan. 2007. →456.\nSivrikaya F. and Yener B. Time Synchronization in Sensor Networks: A Survey. IEEE\nNetwork, 18(4):45–50, July 2004. →257.\nSkeen D. Nonblocking Commit Protocols. In SIGMOD International Conference on\nManagement Of Data, pages 133–142. ACM, 1981. →534.\nSkeen D. and Stonebraker M. A Formal Model of Crash Recovery in a Distributed\nSystem. IEEE Transactions on Software Engineering, SE-9(3):219–228, Mar. 1983. →534.\nSletten B. WebAssembly: The Definitive Guide. O’Reilly & Associates, Sebastopol, CA.,\n2022. →146.\nSmart N. P. Cryptography Made Simple. Springer-Verlag, Berlin, 2016. →557.\nSmith J. and Nair R. The Architecture of Virtual Machines. Computer, 38(5):32–38, May\n2005a. →129, 130.\nSmith J. and Nair R. Virtual Machines: Versatile Platforms for Systems and Processes.\nMorgan Kaufman, San Mateo, CA., 2005b. →131, 132.\nSmith M. and Howes T. Lightweight Directory Access Protocol (LDAP): String Repre-\nsentation of Search Filters. RFC 4515, June 2006. →379.\nSmith R. E. A Contemporary Look at Saltzer and Schroeder’s 1975 Design Principles.\nIEEE Security & Privacy, 10(6):20–25, 2012. →549, 550.\nSoltesz S., Pötzl H., Fiuczynski M. E., Bavier A., and Peterson L. Container-Based\nOperating System Virtualization: A Scalable, High-Performance Alternative to\nHypervisors.\nIn 2nd EuroSys (European Conference on Computer Systems), pages\n275–287, New York, NY, Mar. 2007. ACM, ACM Press. →137.\nSpector A. Performing Remote Operations Efficiently on a Local Computer Network.\nCommunications of the ACM, 25(4):246–260, Apr. 1982. →510.\nSrinivasan S. Kilim: A Server Framework with Lightweight Actors, Isolation Types and\nZero-Copy Messaging. Ph.d., University of Cambridge, Computer Laboratory, Feb.\n2010. →122.\nSrisuresh P. and Holdrege M. IP Network Address Translator (NAT) Terminology and\nConsiderations. RFC 2663, Aug. 1999. →163.\nStallings W. Crypotgraphy and Network Security. Pearson Education, Englewood Cliffs,\nN.J., 7th edition, 2017. →571.\nStanciu V., van Steen M., Peter A., and Dobre C. Privacy-Preserving Crowd Sensing and\nAnalytics. In 17th International Conference Mobile and Ubiquitous Systems: Computing,\nNetworking, and Services, 12 2020. →558.\nStankovic J. A. Research Directions for the Internet of Things. IEEE Internet of Things\nJournal, 1(1):3–9, Feb. 2014. →44.\nStannat A., Ileri C. U., Gijswijt D., and Pouwelse J. Achieving Sybil-proofness in\nDistributed Work Systems. In International Joint Conference on Autonomous Agents and\nMultiagent Systems, pages 1263–1271, 2021. →591.\nSteiner J., Neuman C., and Schiller J. Kerberos: An Authentication Service for Open\nNetwork Systems. In Winter Technical Conference, pages 191–202. USENIX, 1988.\n \nDS 4.01\n\n\n658\nBIBLIOGRAPHY\n→581.\nSteinmetz R. and Nahrstedt K. Multimedia Systems. Springer-Verlag, Berlin, 2004.\n→162.\nStevens W. TCP/IP Illustrated, Volume 1: The Protocols. Addison-Wesley, Reading, MA.,\n1994. →59.\nStevens W. UNIX Network Programming – Networking APIs: Sockets and XTI. Prentice\nHall, Englewood Cliffs, N.J., 2nd edition, 1998. →123, 210.\nStevens W. UNIX Network Programming – Interprocess Communication. Prentice Hall,\nEnglewood Cliffs, N.J., 2nd edition, 1999. →113, 122.\nStevens W. and Rago S. Advanced Programming in the UNIX Environment. Addison-\nWesley, Reading, MA., 2nd edition, 2005. →115.\nStewart R. Stream Control Transmission Protocol. RFC 4960, Sept. 2007. →188.\nStocker V., Smaragdakis G., Lehr W., and Bauer S.\nThe Growing Complexity of\nContent Delivery Networks: Challenges and Implications for the Internet Ecosystem.\nTelecommunications Policy, 41(10):1003–1016, 2017. →165.\nStoica I., Morris R., Liben-Nowell D., Karger D. R., Kaashoek M. F., Dabek F., and\nBalakrishnan H. Chord: A Scalable Peer-to-peer Lookup Protocol for Internet Appli-\ncations. IEEE/ACM Transactions on Networking, 11(1):17–32, Feb. 2003. →91, 333, 336.\nStratan C., Sacha J., Napper J., Costa P., and Pierre G.\nThe XtreemOS Resource\nSelection Service. ACM Transactions of Autonomous and Adaptive Systems, 7(4), Dec.\n2012. →385.\nStrauss J., Katabi D., and Kaashoek F. A Measurement Study of Available Bandwidth\nEstimation Tools. In 3rd Internet Measurement Conference, pages 39–44, New York,\nNY, 2003. ACM Press. →454.\nSu A.-J., Choffnes D. R., Kuzmanovic A., and Bustamante F. E. Drafting Behind Akamai\n(Travelocity-Based Detouring). In SIGCOMM, page 435–446, 2006. →166.\nSugerman J., Venkitachalam G., and Lim B.-H. Virtualizing I/O Devices on VMware\nWorkstations Hosted Virtual Machine Monitor. In USENIX Annual Technical Confer-\nence, pages 1–14, Berkeley, CA, June 2001. USENIX, USENIX. →132.\nSundararaman B., Buy U., and Kshemkalyani A. D. Clock Synchronization for Wireless\nSensor Networks: A Survey. Ad-Hoc Networks, 3(3):281–323, May 2005. →257.\nSwamidass S. J. and Baldi P.\nMathematical Correction for Fingerprint Similarity\nMeasures to Improve Chemical Retrieval. Journal of Chemical Information and Modeling,\n47(3):952–964, 2007. →559.\nSzymaniak M., Pierre G., and van Steen M. Scalable Cooperative Latency Estimation.\nIn 10th International Conference on Parallel and Distributed Systems, pages 367–376, Los\nAlamitos, CA., July 2004. IEEE, IEEE Computer Society Press. →321.\nSzymaniak M., Presotto D., Pierre G., and van Steen M. Practical Large-Scale Latency\nEstimation. Computer Networks, 52(7):1343–1364, May 2008. →321.\nTaiani F., Fabre J.-C., and Killijian M.-O. A Multi-Level Meta-Object Protocol for\nFault-Tolerance in Complex Architectures. In International Conference on Dependable\nSystems and Networks, pages 270–279, Los Alamitos, CA., June 2005. IEEE Computer\nSociety Press. →436.\nDS 4.01\n \n",
      "page_number": 644
    },
    {
      "number": 65,
      "title": "Segment 65 (pages 668-679)",
      "start_page": 668,
      "end_page": 679,
      "detection_method": "topic_boundary",
      "content": "BIBLIOGRAPHY\n659\nTaleb T., Samdanis K., Mada B., Flinck H., Dutta S., and Sabella D. On Multi-Access\nEdge Computing: A Survey of the Emerging 5G Network Edge Cloud Architecture\nand Orchestration. IEEE Communications Surveys & Tutorials, 19(3):1657–1681, 2017.\n→103.\nTan S.-W., Waters G., and Crawford J. A Survey and Performance Evaluation of\nScalable Tree-based Application Layer Multicast Protocols. Technical Report 9-03,\nUniversity of Kent, UK, July 2003. →235.\nTanenbaum A. and Bos H. Modern Operating Systems. Prentice Hall, Upper Saddle\nRiver, N.J., 5th edition, 2022. →346.\nTanenbaum A., , Feamster N., and Wetherall D. Computer Networks. Prentice Hall,\nUpper Saddle River, N.J., 6th edition, 2021. →183, 508.\nTanisch P. Atomic Commit in Concurrent Computing. IEEE Concurrency, 8(4):34–41,\nOct. 2000. →528.\nTarkoma S. Overlay Networks, Toward Information Networking. CRC Press, Boca Raton,\nFL, 2010. →89.\nTarkoma S. and Kangasharju J. Mobile Middleware: Supporting Applications and Services.\nJohn Wiley, New York, 2009. →47.\nTartalja I. and Milutinovic V. Classifying Software-Based Cache Coherence Solutions.\nIEEE Software, 14(3):90–101, May 1997. →443.\nTel G. Introduction to Distributed Algorithms. Cambridge University Press, Cambridge,\nUK, 2nd edition, 2000. →249, 283.\nTerry D. Replicated Data Management for Mobile Computing. Synthesis Lectures on Data\nManagement. Morgan and Claypool, San Rafael, CA, 2008. →416.\nTerry D., Demers A., Petersen K., Spreitzer M., Theimer M., and Welsh B. Session\nGuarantees for Weakly Consistent Replicated Data. In 3rd International Conference on\nParallel and Distributed Information Systems, pages 140–149, Los Alamitos, CA., Sept.\n1994. IEEE, IEEE Computer Society Press. →416, 420, 421.\nTerry D., Petersen K., Spreitzer M., and Theimer M. The Case for Non-transparent\nReplication: Examples from Bayou. IEEE Data Engineering, 21(4):12–20, Dec. 1998.\n→416.\nThomas R. A Majority Consensus Approach to Concurrency Control for Multiple Copy\nDatabases. ACM Transactions on Database Systems, 4(2):180–209, June 1979. →441.\nTIBCO . TIBCO Rendezvous Concepts, Release 8.3.0. TIBCO Software Inc., Palo Alto, CA,\nJuly 2010. →308.\nTourani R., Misra S., Mick T., and Panwar G. Security, Privacy, and Access Control\nin Information-Centric Networking: A Survey. IEEE Communications Surveys &\nTutorials, 20(1):566–600, 2018. →389.\nTowsley D., Kurose J., and Pingali S. A Comparison of Sender-Initiated and Receiver-\nInitiated Reliable Multicast Protocols. IEEE Journal on Selected Areas in Communication,\n15(3):398–407, Apr. 1997. →518.\nTrivedi K. Probability and Statistics with Reliability, Queuing and Computer Science Applica-\ntions. John Wiley, New York, 2nd edition, 2002. →26.\nTsafrir D. The Context-Switch Overhead Inflicted by Hardware Interrupts (and the\n \nDS 4.01\n\n\n660\nBIBLIOGRAPHY\nEnigma of Do-nothing Loops). In 2007 Workshop on Experimental Computer Science,\nNew York, NY, 2007. ACM Press. →116, 117.\nTsui A. W., Lin W.-C., Chen W.-J., Huang P., and Chu H.-H. Accuracy Performance\nAnalysis between War Driving and War Walking in Metropolitan Wi-Fi Localization.\nIEEE Transations on Mobile Computing, 9(11):1551–1562, 2010. →318.\nTurek J. and Shasha S. The Many Faces of Consensus in Distributed Systems. Computer,\n25(6):8–17, June 1992. →503, 504.\nUlrich A., Holz R., Hauck P., and Carle G. Investigating the OpenPGP Web of Trust. In\nEuropean Symposium on Research in Computer Security, pages 489–507. Springer, 2011.\n→571.\nUmar A. Object-Oriented Client/Server Internet Environments. Prentice Hall, Upper\nSaddle River, N.J., 1997. →81.\nUPnP Forum . UPnP Device Architecture Version 1.1, Oct. 2008. →46.\nUr B., Bees J., Segreti S. M., Bauer L., Christin N., and Cranor L. F.\nDo Users’\nPerceptions of Password Security Match Reality? In 2016CHI Conference on Human\nFactors in Computing Systems, pages 3748–3760. ACM, 2016. →572.\nUrdaneta G., Pierre G., and van Steen M. A Survey of DHT Security Techniques. ACM\nComputing Surveys, 43(2), June 2011. →344, 588.\nUzunov A. V.\nA Survey of Security Solutions for Distributed Publish/Subscribe\nSystems. Computers & Security, 61:94–129, 2016. →315.\nvan der Toorn O., Müller M., Dickinson S., Hesselman C., Sperotto A., and van Rijswijk-\nDeij R. Addressing the Challenges of Modern DNS: A Comprehensive Tutorial.\nComputer Science Review, 45:100469, 2022. →359, 364, 365.\nvan Ede T., Aghakhani H., Spahn N., Bortolameotti R., Cova M., Continella A., van\nSteen M., Peter A., Kruegel C., and Vigna G. DeepCASE: Semi-Supervised Contex-\ntual Analysis of Security Events. In International Symposium on Security and Privacy.\nIEEE, 2022. →612.\nvan Renesse R. and Altinbuken D. Paxos Made Moderately Complex. ACM Computing\nSurveys, 47(3):42:1–42:36, Feb. 2015. →479.\nvan Rijn V. and Rellermeyer J. S. A Fresh Look at the Architecture and Performance\nof Contemporary Isolation Platforms. In Middleware 2021, pages 323–336. ACM/I-\nFIP/USENIX, Dec. 2021. →139.\nvan Steen M. and Ballintijn G. Achieving Scalability in Hierarchical Location Services.\nIn 26th International Computer Software and Applications Conference, pages 899–905,\nLos Alamitos, CA., Aug. 2002. IEEE, IEEE Computer Society Press. →342.\nvan Steen M., Hauck F., Homburg P., and Tanenbaum A. Locating Objects in Wide-Area\nSystems. IEEE Communications Magazine, 36(1):104–109, Jan. 1998. →338.\nVaquero L. M., Rodero-Merino L., Caceres J., and Lindner M. A Break in the Clouds:\nTowards a Cloud Definition. SIGCOMM Computer Communications Review, 39(1):\n50–55, Dec. 2008. →98.\nVasilomanolakis E., Karuppayah S., Mühlhäuser M., and Fischer M. Taxonomy and\nSurvey of Collaborative Intrusion Detection. ACM Computing Surveys, 47(4):1–33,\n2015. →612.\nDS 4.01\n \n\n\nBIBLIOGRAPHY\n661\nVasudevan S., Kurose J. F., and Towsley D. F. Design and Analysis of a Leader Election\nAlgorithm for Mobile Ad Hoc Networks. In 12th International Conference on Network\nProtocols, pages 350–360, Los Alamitos, CA., Oct. 2004. IEEE, IEEE Computer Society\nPress. →294, 297.\nVelazquez M. A Survey of Distributed Mutual Exclusion Algorithms. Technical Report\nCS-93-116, University of Colorado at Boulder, Sept. 1993. →272.\nViotti P. and Vukolic M. Consistency in Nontransactional Distributed Storage Systems.\nACM Computing Surveys, 29(1), June 2016. →395.\nVixie P. What DNS Is Not. Communications of the ACM, 52(12):43–47, Dec. 2009. →369.\nVixie P. Rate-Limiting State. Communications of the ACM, 57(4):40–43, Apr. 2014. →369.\nVogels W. Tracking Service Availability in Long Running Business Activities. In 1st\nInternational Conference on Service Oriented Computing, volume 2910 of Lecture Notes\nin Computer Science, pages 395–408, Berlin, Dec. 2003. Springer-Verlag. →507.\nVogels W. Eventually consistent. Communications of the ACM, 52(1):40–44, Jan. 2009.\n→407.\nVoigt P. and Bussche A.Von dem . The EU General Data Protection Regulation (GDPR), A\nPractical Guide. Springer-Verlag, Berlin, 2017. →553.\nVoorsluys W., Broberg J., Venugopal S., and Buyya R. Cost of Virtual Machine Live\nMigration in Clouds: A Performance Evaluation. In 1st International Conference on\nCloud Computing, volume 5931 of Lecture Notes in Computer Science, pages 254–265,\nBerlin, Dec. 2009. Springer-Verlag. →176, 177.\nVoronkov A., Iwaya L. H., Martucci L. A., and Lindskog S. Systematic Literature\nReview on Usability of Firewall Configuration. ACM Computing Surveys, 50(6):1–35,\n2017. →610.\nVoulgaris S. and van Steen M. VICINITY: A Pinch of Randomness Brings out the\nStructure. In Middleware 2013, volume 8275 of Lecture Notes in Computer Science,\npages 21–40, Berlin, Dec. 2013. ACM/IFIP/USENIX, Springer-Verlag. →301.\nVoulgaris S., Gavidia D., and van Steen. M. CYCLON: Inexpensive Membership Man-\nagement for Unstructured P2P Overlays. Journal of Network and Systems Management,\n13(2):197–217, June 2005. →299, 304.\nVoulgaris S., Rivière E., Kermarrec A.-M., and van Steen M. Sub-2-Sub: Self-Organizing\nContent-Based Publish and Subscribe for Dynamic and Large Scale Collaborative\nNetworks. In 5th International Workshop on Peer-to-Peer Systems, Feb. 2006. →311.\nVu Q., Lupu M., and Ooi B. Peer-to-Peer Computing, Principles and Applications. Springer-\nVerlag, Berlin, 2010. →89.\nVukoli´c M. Quorum Systems: With Applications to Storage and Consensus, volume 3 of\nSynthesis Lectures on Distributed Computing Theory. Morgan & Claypool Publishers,\n2012. →443.\nWaldo J., Wyant G., Wollrath A., and Kendall S. A Note on Distributed Computing.\nIn 2nd Workshop on Mobile Object Systems, volume 1222 of Lecture Notes in Computer\nScience, pages 1–10, Berlin, July 1997. Springer-Verlag. →15.\nWalfish M., Balakrishnan H., , and Shenker S. Untangling the Web from DNS. In 1st\nSymposium on Networked Systems Design and Implementation, pages 225–238, Berkeley,\n \nDS 4.01\n\n\n662\nBIBLIOGRAPHY\nCA, Mar. 2004. USENIX, USENIX. →368.\nWams J. Unified Messaging and Micro-Objects. PhD thesis, VU University Amsterdam,\n2012. →15.\nWelsh M. and Mainland G. Programming Sensor Networks Using Abstract Regions.\nIn 1st Symposium on Networked Systems Design and Implementation, Berkeley, CA, Mar.\n2004. USENIX, USENIX. →49.\nWendell P. and Freedman M. J. Going Viral: Flash Crowds in an Open CDN. In 11th\nInternet Measurement Conference, pages 549–558, New York, NY, 2011. ACM Press.\n→452.\nWerbach K. The Blockchain and the New Architecture of Trust. MIT Press, Cambridge,\nMA., 2018. →592.\nWessels D. Squid: The Definitive Guide. O’Reilly & Associates, Sebastopol, CA., 2004.\n→452.\nWieringa R. and Jonge W.de . Object Identifiers, Keys, and Surrogates–Object Identifiers\nRevisited. Theory and Practice of Object Systems, 1(2):101–114, 1995. →328.\nWierzbicki A. Trust and Fairness in Open, Distributed Systems, volume 298 of Studies in\nComputational Intelligence. Springer-Verlag, Berlin, 2010. →586.\nWiesmann M., Pedone F., Schiper A., Kemme B., and Alonso G. Understanding\nReplication in Databases and Distributed Systems. In 20th International Conference\non Distributed Computing Systems, pages 264–274, Taipei, Taiwan, Apr. 2000. IEEE.\n→395.\nWolff E. Micrservices: Flexible Software Architecture. Addison-Wesley, Reading, MA.,\n2017. →65.\nWollrath A., Riggs R., and Waldo J. A Distributed Object Model for the Java System.\nComputing Systems, 9(4):265–290, Fall 1996. →201.\nWolman A., Voelker G., Sharma N., Cardwell N., Karlin A., and Levy H. On the\nScale and Performance of Cooperative Web Proxy Caching. In 17th Symposium on\nOperating System Principles, pages 16–31, Kiawah Island, SC, Dec. 1999. ACM. →451.\nWool A. Trends in Firewall Configuration Errors: Measuring the Holes in Swiss Cheese.\nIEEE Internet Computing, 14(4):58–65, 2010. →610.\nWright G. and Stevens W. TCP/IP Illustrated, Volume 2: The Implementation. Addison-\nWesley, Reading, MA., 1995. →59.\nXiao Y., Zhang N., Lou W., and Hou Y. T. A Survey of Distributed Consensus Protocols\nfor Blockchain Networks. IEEE Communications Surveys & Tutorials, 22(2):1432–1465,\n2020. →502, 503.\nXu X., Weber I., Staples M., Zhu L., Bosch J., Bass L., Pautasso C., and Rimba P. A\nTaxonomy of Blockchain-based Systems for Architecture Design. In International\nConference on Software Architecture (ICSA), pages 243–252. IEEE, Apr. 2017. →108.\nYang B. and Garcia-Molina H. Designing a Super-Peer Network. In 19th International\nConference on Data Engineering, pages 49–60, Los Alamitos, CA., Mar. 2003. IEEE,\nIEEE Computer Society Press. →95.\nYang K., Zhang K., Jia X., Hasan M. A., and Shen X. Privacy-preserving Attribute-\nKeyword Based Data Publish-Subscribe Service on Cloud Platforms. Information\nDS 4.01\n \n\n\nBIBLIOGRAPHY\n663\nSciences, 387:116–131, 2017. →314, 315.\nYang M., Zhang Z., Li X., and Dai Y. An Empirical Study of Free-Riding Behavior in the\nMaze P2P File-Sharing System. In 4th International Workshop on Peer-to-Peer Systems,\nLecture Notes in Computer Science, Berlin, Feb. 2005. Springer-Verlag. →96.\nYellin D. Competitive Algorithms for the Dynamic Selection of Component Implemen-\ntations. IBM Systems Journal, 42(1):85–97, Jan. 2003. →78.\nYin M., Malkhi D., Reiter M. K., Gueta G. G., and Abraham I. Hotstuff: BFT Consen-\nsus with Linearity and Responsiveness. In Symposium on Principles of Distributed\nComputing, pages 347–356, 2019. →502, 503.\nYousefpour A., Fung C., Nguyen T., Kadiyala K., Jalali F., Niakanlahiji A., Kong J.,\nand Jue J. P. All One Needs to Know About Fog Computing and Related Edge\nComputing Paradigms: A Complete Survey. Journal of Systems Architecture, 98:\n289–330, 2019. →52, 100.\nYu H. and Vahdat A. Efficient Numerical Error Bounding for Replicated Network\nServices. In Abbadi A. E., Brodie M. L., Chakravarthy S., Dayal U., Kamel N.,\nSchlageter G., and Whang K.-Y., editors, 26th International Conference on Very Large\nData Bases, pages 123–133, San Mateo, CA., Sept. 2000. Morgan Kaufman. →446.\nYu H. and Vahdat A. Design and Evaluation of a Conit-Based Continuous Consistency\nModel for Replicated Services. ACM Transactions on Computer Systems, 20(3):239–282,\n2002. →410, 411, 455.\nZarrin J., Aguiar R. L., and Barraca J. P. Resource Discovery for Distributed Computing\nSystems: A Comprehensive Survey. Journal of Parallel and Distributed Computing, 113:\n127–166, 2018. →385.\nZeroC .\nDistributed Programming with Ice.\nZeroC Inc., Brisbane, Australia, 2022.\n→158, 159.\nZhang C., Xie Y., Bai H., Yu B., Li W., and Gao Y. A Survey on Federated Learning.\nKnowledge-Based Systems, 216:106775, 2021a. →169.\nZhang F., Liu G., Fu X., and Yahyapour R. A Survey on Virtual Machine Migration:\nChallenges, Techniques, and Open Issues. IEEE Communications Surveys & Tutorials,\n20(2):1206–1243, 2018. →175, 176.\nZhang J., Ma M., Wang P., and Sun X.dong . Middleware for the Internet of Things: A\nSurvey on Requirements, Enabling Technologies, and Solutions. Journal of Systems\nArchitecture, 117, 2021b. →49.\nZhang Q., Cheng L., and Boutaba R. Cloud Computing: State of the Art and Research\nChallenges. Journal of Internet Services and Applications, 1(1):7–18, May 2010. →99.\nZhang Y., Xia Z., Afanasyev A., and Zhang L. A Note on Routing Scalability in\nNamed Data Networking. In International Conference Communications Workshops (ICC\nWorkshops), pages 1–6, 2019. →387.\nZhao F. and Guibas L. Wireless Sensor Networks. Morgan Kaufman, San Mateo, CA.,\n2004. →49.\nZhu Z. and Afanasyev A. Let’s ChronoSync: Decentralized Dataset State Synchroniza-\ntion in Named Data Networking. In 21st International Conference on Network Protocols,\npages 1–10, 2013. →386.\n \nDS 4.01\n\n\n664\nBIBLIOGRAPHY\nZhuang S. Q., Geels D., Stoica I., and Katz R. H. On Failure Detection Algorithms\nin Overlay Networks. In 24th INFOCOM Conference, Los Alamitos, CA., Mar. 2005.\nIEEE, IEEE Computer Society Press. →507.\nZogg J.-M. GPS Basics. Technical Report GPS-X-02007, UBlox, Mar. 2002. →317.\nZolfaghari B., Srivastava G., Roy S., Nemati H. R., Afghah F., Koshiba T., Razi A., Bibak\nK., Mitra P., and Rai B. K. Content Delivery Networks: State of the Art, Trends, and\nFuture Roadmap. ACM Computing Surveys, 53(2), 2021. →165.\nZwicky E., Cooper S., Chapman D., and Russell D. Building Internet Firewalls. O’Reilly\n& Associates, Sebastopol, CA., 2nd edition, 2000. →609.\nDS 4.01\n \n\n\nGLOSSARY\nBitTorrent: A distributed system for file sharing by which a file is partitioned\ninto blocks and subsequently physically distributed among participants.\nA participant needs to copy and swap blocks with others (called tit-for-\ntat) to eventually gather all blocks to reconstruct the original file.\nBlockchain: An append-only list of blocks of validated transactions. Each\ntransaction and block can be replicated across all processes participating\nin the blockchain as they cannot be changed once published. The list is\nsecured in the sense that any change to any transaction or block cannot\ngo unnoticed.\nConfidentiality: The property that information is disclosed only to authorized\nparties.\nConsistency model (data centric): Describes what processes can expect con-\ncerning read and write operations from and to a logically shared data\nstore that is physically distributed among the processes. In essence, a\nconsistency model tells if and when local write operations are propa-\ngated to other processes, and the effects for local read operations.\nContainer: A special type of virtual machine, generally tailored to support\nonly a specific operating system. A container provides an environment\nto an application suite, essentially mimicking the situation that this suite\nis being executed in isolation on a single machine. Where a virtual\nmachine can host an operating system, a container can host only a suite\nof applications.\nCritical region: A series of instructions to be executed by a process, which\nrequires mutually exclusive access to specified resources.\nDecentralized system: A networked computer system in which processes\nand resources are necessarily spread across multiple computers, usually\ncaused by business constraints, lack of mutual trust, or geographical\nrestrictions.\n665\n\n\n666\nGLOSSARY\nDependable system: A system that provides availability, reliability, safety,\nmaintainability, confidentiality, and integrity.\nDistributed system: A networked computer system in which processes and\nresources are sufficiently spread across multiple computers, usually to\nmeet performance and dependability requirements.\nDistribution transparency: The phenomenon by which a distributed system\nattempts to hide the fact that its processes and resources are physi-\ncally distributed across multiple computers, possibly separated by large\ndistances.\nEvent matching: Typically occurs in publish-subscribe systems, where the\npublication of an event needs to be matched with all relevant subscrip-\ntions. A major problem is to support matching in a scalable manner.\nExtensibility: Characterizes the extent to which a system can be extended\n(often without interrupting operations) with new functionality or com-\nponents while avoiding affecting parts that are independent of those\nextensions.\nFailure, error, fault: A system fails when it does not meet its specifications.\nA failure happens due to some error, such as a programming bug. The\ncause of an error is called a fault.\nFault tolerance: A system is fault tolerant when it can continue to provide its\nservices according to specifications despite the presence of faults that\ninfluence its design, implementation, and execution.\nFaults, errors, failures: A system is said to fail when it cannot meet its speci-\nfications. An error is a mistake that may need lead to a failure, such as a\nprogramming bug. A fault is the cause of an error.\nGroupware: Distributed software to allow multiple users to collaborate from\ndifferent locations through shared whiteboards, shared documents, etc.\nHonest-but-curious: A server that behaves according to some protocol, but\nin the worst case keeps track of all the things it does.\nIntegrity: Ensures that alterations to the various assets of a system can be\nmade only in an authorized way.\nDS 4.01\n \n\n\nGLOSSARY\n667\nInterface Definition Language: A formal language for specifying the inter-\nfaces to various components of a distributed system. An IDL is used\nto generate code for different programming langauges that can subse-\nquently be used to build applications making use of a component.\nInteroperability: Characterizes the extent by which two implementations of\nsystems or components from different manufacturers or development\nteams can co-exist and work together by merely relying on each other’s\nservices as specified by their respective interfaces.\nLeader-election algorithm: A distributed algorithm that is executed among\na group of processes such that, in the end, one of these processes can be\ndesignated as the leader of the group.\nLogical clock: A system in which a group of processes keeps account of in-\nternal events, and also when messages are sent and received, to globally\ndetermine a consistent ordering of events.\nMiddleware: Software that constitutes a distributed system, implementing a\nmyriad of mechanisms independent of any underlying system, as well\nas generally applicable for a wide range of applications.\nMultiparty computation: The means for two or three parties to compute a\nvalue for which the data of those parties is needed, but without the need\nto actually share that data.\nOpen distributed system: A system that offers components that can easily\nbe used by, or integrated into other systems. An open distributed system\nitself will often consist of components that originate from elsewhere.\nPartial failure: A type of failure characteristic for a distributed system. Some\nprocess or resource, is not operating according to expectations, which, in\nturn, may have effects on other parts of the system. However, the system\nas a whole will continue to operate, albeit perhaps in unexpected ways.\nPeer-sampling service: A service that operates in a potentially large dis-\ntributed system, returning a (seemingly) randomly chosen peer from all\navailable peers.\nPerspectives on distributed systems: Due to the fact that a distributed sys-\ntem must meet so many different functional and nonfunctional require-\nments, which, in general, are mututal dependent, taking different per-\nspectives on distributed systems allows for a more focused study. We\n \nDS 4.01\n\n\n668\nGLOSSARY\ndistinguish perspectives on architecture, processes, communication, co-\nordination, naming, consistency and replication, fault tolerance, and\nsecurity.\nPervasive system: Systems consisting of a myriad of devices that are intended\nto blend into our environment naturally. Typical devices include smart-\nphones, smart watches, specific sensors and actuators, camera’s, and so\nforth.\nPortability: Characterizes to what extent an application developed for a dis-\ntributed system A can be executed, without modification, on a different\ndistributed system B that implements the same interfaces as A.\nRemote procedure call: A communication mechanism that essentially mim-\nicks local procedure calls, yet where the execution of the call takes place\nat a remote server. In general, jsut as with local procedure calls, the\ncaller waits until the procedure has been carried out fully.\nScalability: Refers to the extent that a system can scale in terms of its size, in\nterms of how geographically dispersed its components can be without\nseriously negatively affecting performance, or the extent to which a\nsystem can span multiple administrative organizations.\nScaling up or out: Scaling up is the process by which a machine is equipped\nwith more and often more powerful resources so that it can better\naccommodate performance-demanding applications. Scaling out is all\nabout extending a networked computer system with more computers\nand subsequently distributing workloads across the extended set of\ncomputers.\nSeparating policy from mechanism: Where mechanisms in a distributed sys-\ntem facilitate basic functionalities, such as storage, communication,\nprocesses, and so on, policies describe how those facilities are used.\nIn general, separating facilities from the way how they are used is a\ngood design principle, yet may overly complicate the configuration of a\nsystem.\nSoftware architecture: The organization of distributed systems in terms of\nsoftware components and their interaction.\nSystem architecture: The actual realization of a distributed system requires\nthat software components are instantiated and placed on real machines.\nA system architecture is the final instantiation of a software architec-\nture.\nDS 4.01\n \n\n\nGLOSSARY\n669\nTransaction processing monitor: A TP monitor is one of the first general-\npurpose mechanisms built into middleware. It is service that follows a\nstandard protocol for executing a number of subtransactions, such that\n(1) each subtransaction adheres to the ACID properties, but (2) also the\ncollection of subtransactions meets the ACID requirements.\nTrusted Computing Base: The set of all security mechanisms in a (distributed)\ncomputer system that are necessary and sufficient to enforce a security\npolicy.\nVector clocks: A system implementing logical clocks such that the logical\ntime at which an event took place can be used to conclude that an\nevent indeed took place before another event, thus capturing a potential\ncausality between events.\nVirtual machine: In general, a system providing its own interface to operating\nsystems and applications, and implementing that interface for a specific\ninstruction set or operating system. As a consequence, migrating or\nporting code across different architectures or operating systems becomes\neasier as long as the target environment provides the same interface the\nvirtual machine is offering.\nVirtual processor: A counterpart of a physical processor developed in soft-\nware, providing a context in which the set of instructions of the physical\nprocessor are executed. A thread provides a minimal context for concur-\nrent execution of instructions. An (operating system) process, in addition\nprovides much stronger isolation guarantees between processes. For\nexample, a process has its own, protected address space.\n \nDS 4.01\n",
      "page_number": 668
    },
    {
      "number": 66,
      "title": "Segment 66 (pages 680-685)",
      "start_page": 680,
      "end_page": 685,
      "detection_method": "topic_boundary",
      "content": "",
      "page_number": 680
    }
  ],
  "pages": [
    {
      "page_number": 1,
      "content": "D IS TRI B U T ED\nSY ST E MS\nMAARTEN VAN STEEN\nANDREW S. TANENBAUM\n4TH EDITION\nVERSION 01\n",
      "content_length": 90,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 2,
      "content": "Cover art by Max van Steen\n",
      "content_length": 27,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 3,
      "content": "DISTRIBUTED SYSTEMS\nFourth edition\nVersion 4.01\n(January 2023)\nMaarten van Steen\nAndrew S. Tanenbaum\n",
      "content_length": 101,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 5,
      "content": "Copyright © 2023 Maarten van Steen and Andrew S. Tanenbaum\nPublished by Maarten van Steen\nThe first and second edition of this book were previously published by Pearson Education, Inc.\nISBN: 978-90-815406-3-6 (printed version)\nISBN: 978-90-815406-4-3 (digital version)\nEdition: 4. Version: 01 (January 2023)\nAll rights to text and illustrations are reserved by Maarten van Steen and Andrew S. Tanenbaum. This work may\nnot be copied, reproduced, or translated in whole or part without written permission of the publisher, except for\nbrief excerpts in reviews or scholarly analysis. Use with any form of information storage and retrieval, electronic\nadaptation or whatever, computer software, or by similar or dissimilar methods now known or developed in the\nfuture is strictly forbidden without written permission of the publisher.\n",
      "content_length": 831,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 7,
      "content": "To Mariëlle, Max, and Elke\n– MvS\nTo Suzanne, Barbara, Marvin, Aron, Nathan, Olivia, and Mirte\n– AST\n",
      "content_length": 100,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 9,
      "content": "CONTENTS\nPreface\nxi\n1\nIntroduction\n1\n1.1\nFrom networked systems to distributed systems . . . . . . . . .\n3\n1.1.1\nDistributed versus decentralized systems . . . . . . . . .\n3\n1.1.2\nWhy making the distinction is relevant . . . . . . . . . .\n7\n1.1.3\nStudying distributed systems . . . . . . . . . . . . . . . .\n8\n1.2\nDesign goals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n10\n1.2.1\nResource sharing . . . . . . . . . . . . . . . . . . . . . . .\n10\n1.2.2\nDistribution transparency . . . . . . . . . . . . . . . . . .\n11\n1.2.3\nOpenness\n. . . . . . . . . . . . . . . . . . . . . . . . . . .\n15\n1.2.4\nDependability . . . . . . . . . . . . . . . . . . . . . . . . .\n18\n1.2.5\nSecurity\n. . . . . . . . . . . . . . . . . . . . . . . . . . . .\n21\n1.2.6\nScalability . . . . . . . . . . . . . . . . . . . . . . . . . . .\n24\n1.3\nA simple classification of distributed systems . . . . . . . . . . .\n32\n1.3.1\nHigh-performance distributed computing\n. . . . . . . .\n32\n1.3.2\nDistributed information systems . . . . . . . . . . . . . .\n37\n1.3.3\nPervasive systems\n. . . . . . . . . . . . . . . . . . . . . .\n43\n1.4\nPitfalls\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n52\n1.5\nSummary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n53\n2\nArchitectures\n55\n2.1\nArchitectural styles . . . . . . . . . . . . . . . . . . . . . . . . . .\n56\n2.1.1\nLayered architectures\n. . . . . . . . . . . . . . . . . . . .\n57\n2.1.2\nService-oriented architectures . . . . . . . . . . . . . . . .\n62\n2.1.3\nPublish-subscribe architectures . . . . . . . . . . . . . . .\n68\n2.2\nMiddleware and distributed systems . . . . . . . . . . . . . . . .\n73\n2.2.1\nMiddleware organization . . . . . . . . . . . . . . . . . .\n74\n2.2.2\nModifiable middleware\n. . . . . . . . . . . . . . . . . . .\n78\n2.3\nLayered-system architectures . . . . . . . . . . . . . . . . . . . .\n78\n2.3.1\nSimple client-server architecture . . . . . . . . . . . . . .\n79\n2.3.2\nMultitiered Architectures . . . . . . . . . . . . . . . . . .\n80\n2.3.3\nExample: The Network File System . . . . . . . . . . . .\n83\n2.3.4\nExample: The Web . . . . . . . . . . . . . . . . . . . . . .\n85\n2.4\nSymmetrically distributed system architectures\n. . . . . . . . .\n88\n2.4.1\nStructured peer-to-peer systems . . . . . . . . . . . . . .\n90\n2.4.2\nUnstructured peer-to-peer systems . . . . . . . . . . . . .\n92\nv\n",
      "content_length": 2359,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 10,
      "content": "vi\nCONTENTS\n2.4.3\nHierarchically organized peer-to-peer networks . . . . .\n95\n2.4.4\nExample: BitTorrent . . . . . . . . . . . . . . . . . . . . .\n96\n2.5\nHybrid system architectures . . . . . . . . . . . . . . . . . . . . .\n98\n2.5.1\nCloud computing . . . . . . . . . . . . . . . . . . . . . . .\n98\n2.5.2\nThe edge-cloud architecture . . . . . . . . . . . . . . . . . 100\n2.5.3\nBlockchain architectures . . . . . . . . . . . . . . . . . . . 104\n2.6\nSummary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 108\n3\nProcesses\n111\n3.1\nThreads . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 112\n3.1.1\nIntroduction to threads\n. . . . . . . . . . . . . . . . . . . 113\n3.1.2\nThreads in distributed systems . . . . . . . . . . . . . . . 122\n3.2\nVirtualization\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 127\n3.2.1\nPrinciple of virtualization . . . . . . . . . . . . . . . . . . 127\n3.2.2\nContainers . . . . . . . . . . . . . . . . . . . . . . . . . . . 133\n3.2.3\nComparing virtual machines and containers . . . . . . . 138\n3.2.4\nApplication of virtual machines to distributed systems . 139\n3.3\nClients\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 141\n3.3.1\nNetworked user interfaces\n. . . . . . . . . . . . . . . . . 141\n3.3.2\nVirtual desktop environment . . . . . . . . . . . . . . . . 144\n3.3.3\nClient-side software for distribution transparency . . . . 148\n3.4\nServers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 149\n3.4.1\nGeneral design issues\n. . . . . . . . . . . . . . . . . . . . 149\n3.4.2\nObject servers . . . . . . . . . . . . . . . . . . . . . . . . . 154\n3.4.3\nExample: The Apache Web server . . . . . . . . . . . . . 159\n3.4.4\nServer clusters\n. . . . . . . . . . . . . . . . . . . . . . . . 161\n3.5\nCode migration . . . . . . . . . . . . . . . . . . . . . . . . . . . . 167\n3.5.1\nReasons for migrating code . . . . . . . . . . . . . . . . . 167\n3.5.2\nModels for code migration\n. . . . . . . . . . . . . . . . . 171\n3.5.3\nMigration in heterogeneous systems . . . . . . . . . . . . 174\n3.6\nSummary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 177\n4\nCommunication\n181\n4.1\nFoundations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 183\n4.1.1\nLayered Protocols . . . . . . . . . . . . . . . . . . . . . . . 183\n4.1.2\nTypes of Communication\n. . . . . . . . . . . . . . . . . . 190\n4.2\nRemote procedure call . . . . . . . . . . . . . . . . . . . . . . . . 192\n4.2.1\nBasic RPC operation . . . . . . . . . . . . . . . . . . . . . 192\n4.2.2\nParameter passing . . . . . . . . . . . . . . . . . . . . . . 197\n4.2.3\nRPC-based application support . . . . . . . . . . . . . . . 201\n4.2.4\nVariations on RPC\n. . . . . . . . . . . . . . . . . . . . . . 205\n4.3\nMessage-oriented communication\n. . . . . . . . . . . . . . . . . 208\n4.3.1\nSimple transient messaging with sockets . . . . . . . . . 208\n4.3.2\nAdvanced transient messaging . . . . . . . . . . . . . . . 213\nDS 4.01\n \n",
      "content_length": 2983,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 11,
      "content": "CONTENTS\nvii\n4.3.3\nMessage-oriented persistent communication . . . . . . . 220\n4.3.4\nExample: Advanced Message Queuing Protocol (AMQP) 227\n4.4\nMulticast communication\n. . . . . . . . . . . . . . . . . . . . . . 232\n4.4.1\nApplication-level tree-based multicasting . . . . . . . . . 232\n4.4.2\nFlooding-based multicasting\n. . . . . . . . . . . . . . . . 236\n4.4.3\nGossip-based data dissemination . . . . . . . . . . . . . . 240\n4.5\nSummary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 245\n5\nCoordination\n247\n5.1\nClock synchronization . . . . . . . . . . . . . . . . . . . . . . . . 249\n5.1.1\nPhysical clocks\n. . . . . . . . . . . . . . . . . . . . . . . . 250\n5.1.2\nClock synchronization algorithms . . . . . . . . . . . . . 253\n5.2\nLogical clocks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 260\n5.2.1\nLamport’s logical clocks . . . . . . . . . . . . . . . . . . . 260\n5.2.2\nVector clocks\n. . . . . . . . . . . . . . . . . . . . . . . . . 266\n5.3\nMutual exclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . 272\n5.3.1\nOverview\n. . . . . . . . . . . . . . . . . . . . . . . . . . . 272\n5.3.2\nA centralized algorithm . . . . . . . . . . . . . . . . . . . 273\n5.3.3\nA distributed algorithm . . . . . . . . . . . . . . . . . . . 274\n5.3.4\nA token-ring algorithm\n. . . . . . . . . . . . . . . . . . . 276\n5.3.5\nA decentralized algorithm . . . . . . . . . . . . . . . . . . 277\n5.3.6\nExample: Simple locking with ZooKeeper\n. . . . . . . . 280\n5.4\nElection algorithms . . . . . . . . . . . . . . . . . . . . . . . . . . 283\n5.4.1\nThe bully algorithm\n. . . . . . . . . . . . . . . . . . . . . 283\n5.4.2\nA ring algorithm . . . . . . . . . . . . . . . . . . . . . . . 285\n5.4.3\nExample: Leader election in ZooKeeper . . . . . . . . . . 286\n5.4.4\nExample: Leader election in Raft . . . . . . . . . . . . . . 289\n5.4.5\nElections in large-scale systems . . . . . . . . . . . . . . . 290\n5.4.6\nElections in wireless environments . . . . . . . . . . . . . 294\n5.5\nGossip-based coordination . . . . . . . . . . . . . . . . . . . . . . 297\n5.5.1\nAggregation . . . . . . . . . . . . . . . . . . . . . . . . . . 297\n5.5.2\nA peer-sampling service . . . . . . . . . . . . . . . . . . . 298\n5.5.3\nGossip-based overlay construction . . . . . . . . . . . . . 299\n5.5.4\nSecure gossiping . . . . . . . . . . . . . . . . . . . . . . . 303\n5.6\nDistributed event matching . . . . . . . . . . . . . . . . . . . . . 306\n5.6.1\nCentralized implementations . . . . . . . . . . . . . . . . 307\n5.6.2\nSecure publish-subscribe solutions . . . . . . . . . . . . . 313\n5.7\nLocation systems . . . . . . . . . . . . . . . . . . . . . . . . . . . 315\n5.7.1\nGPS: Global Positioning System\n. . . . . . . . . . . . . . 315\n5.7.2\nWhen GPS is not an option . . . . . . . . . . . . . . . . . 317\n5.7.3\nLogical positioning of nodes\n. . . . . . . . . . . . . . . . 318\n5.8\nSummary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 322\n6\nNaming\n325\n \nDS 4.01\n",
      "content_length": 2962,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 12,
      "content": "viii\nCONTENTS\n6.1\nNames, identifiers, and addresses\n. . . . . . . . . . . . . . . . . 326\n6.2\nFlat naming\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 329\n6.2.1\nSimple solutions\n. . . . . . . . . . . . . . . . . . . . . . . 329\n6.2.2\nHome-based approaches . . . . . . . . . . . . . . . . . . . 331\n6.2.3\nDistributed hash tables\n. . . . . . . . . . . . . . . . . . . 333\n6.2.4\nHierarchical approaches . . . . . . . . . . . . . . . . . . . 338\n6.2.5\nSecure flat naming . . . . . . . . . . . . . . . . . . . . . . 343\n6.3\nStructured naming\n. . . . . . . . . . . . . . . . . . . . . . . . . . 344\n6.3.1\nName spaces\n. . . . . . . . . . . . . . . . . . . . . . . . . 344\n6.3.2\nName resolution . . . . . . . . . . . . . . . . . . . . . . . 347\n6.3.3\nThe implementation of a name space\n. . . . . . . . . . . 352\n6.3.4\nExample: The Domain Name System . . . . . . . . . . . 359\n6.3.5\nExample: The Network File System . . . . . . . . . . . . 369\n6.4\nAttribute-based naming\n. . . . . . . . . . . . . . . . . . . . . . . 375\n6.4.1\nDirectory services\n. . . . . . . . . . . . . . . . . . . . . . 375\n6.4.2\nHierarchical implementations: LDAP . . . . . . . . . . . 376\n6.4.3\nDecentralized implementations . . . . . . . . . . . . . . . 380\n6.5\nNamed-data networking . . . . . . . . . . . . . . . . . . . . . . . 385\n6.5.1\nBasics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 385\n6.5.2\nRouting\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . 387\n6.5.3\nSecurity in named-data networking . . . . . . . . . . . . 388\n6.6\nSummary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 389\n7\nConsistency and replication\n391\n7.1\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 392\n7.1.1\nReasons for replication . . . . . . . . . . . . . . . . . . . . 393\n7.1.2\nReplication as scaling technique . . . . . . . . . . . . . . 394\n7.2\nData-centric consistency models\n. . . . . . . . . . . . . . . . . . 395\n7.2.1\nConsistent ordering of operations . . . . . . . . . . . . . 396\n7.2.2\nEventual consistency . . . . . . . . . . . . . . . . . . . . . 406\n7.2.3\nContinuous consistency . . . . . . . . . . . . . . . . . . . 410\n7.3\nClient-centric consistency models . . . . . . . . . . . . . . . . . . 415\n7.3.1\nMonotonic reads . . . . . . . . . . . . . . . . . . . . . . . 417\n7.3.2\nMonotonic writes . . . . . . . . . . . . . . . . . . . . . . . 418\n7.3.3\nRead your writes . . . . . . . . . . . . . . . . . . . . . . . 420\n7.3.4\nWrites follow reads . . . . . . . . . . . . . . . . . . . . . . 421\n7.3.5\nExample: client-centric consistency in ZooKeeper . . . . 422\n7.4\nReplica management . . . . . . . . . . . . . . . . . . . . . . . . . 423\n7.4.1\nFinding the best server location\n. . . . . . . . . . . . . . 424\n7.4.2\nContent replication and placement . . . . . . . . . . . . . 426\n7.4.3\nContent distribution . . . . . . . . . . . . . . . . . . . . . 430\n7.4.4\nManaging replicated objects\n. . . . . . . . . . . . . . . . 434\n7.5\nConsistency protocols\n. . . . . . . . . . . . . . . . . . . . . . . . 437\n7.5.1\nSequential consistency: Primary-based protocols\n. . . . 438\nDS 4.01\n \n",
      "content_length": 3114,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 13,
      "content": "CONTENTS\nix\n7.5.2\nSequential consistency: Replicated-write protocols\n. . . 440\n7.5.3\nCache-coherence protocols\n. . . . . . . . . . . . . . . . . 443\n7.5.4\nImplementing continuous consistency . . . . . . . . . . . 446\n7.5.5\nImplementing client-centric consistency . . . . . . . . . . 448\n7.6\nExample: Caching and replication in the Web\n. . . . . . . . . . 451\n7.7\nSummary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 458\n8\nFault tolerance\n461\n8.1\nIntroduction to fault tolerance . . . . . . . . . . . . . . . . . . . . 462\n8.1.1\nBasic concepts . . . . . . . . . . . . . . . . . . . . . . . . . 463\n8.1.2\nFailure models\n. . . . . . . . . . . . . . . . . . . . . . . . 466\n8.1.3\nFailure masking by redundancy . . . . . . . . . . . . . . 470\n8.2\nProcess resilience . . . . . . . . . . . . . . . . . . . . . . . . . . . 471\n8.2.1\nResilience by process groups . . . . . . . . . . . . . . . . 472\n8.2.2\nFailure masking and replication . . . . . . . . . . . . . . 474\n8.2.3\nConsensus in faulty systems with crash failures . . . . . 475\n8.2.4\nExample: Paxos . . . . . . . . . . . . . . . . . . . . . . . . 479\n8.2.5\nConsensus in faulty systems with arbitrary failures . . . 491\n8.2.6\nConsensus in blockchain systems\n. . . . . . . . . . . . . 502\n8.2.7\nSome limitations on realizing fault tolerance . . . . . . . 503\n8.2.8\nFailure detection . . . . . . . . . . . . . . . . . . . . . . . 506\n8.3\nReliable client-server communication\n. . . . . . . . . . . . . . . 508\n8.3.1\nPoint-to-point communication\n. . . . . . . . . . . . . . . 508\n8.3.2\nRPC semantics in the presence of failures . . . . . . . . . 509\n8.4\nReliable group communication . . . . . . . . . . . . . . . . . . . 515\n8.4.1\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . 515\n8.4.2\nScalability in reliable multicasting . . . . . . . . . . . . . 518\n8.4.3\nAtomic multicast . . . . . . . . . . . . . . . . . . . . . . . 522\n8.5\nDistributed commit . . . . . . . . . . . . . . . . . . . . . . . . . . 528\n8.6\nRecovery . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 536\n8.6.1\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . 536\n8.6.2\nCheckpointing\n. . . . . . . . . . . . . . . . . . . . . . . . 538\n8.6.3\nMessage logging . . . . . . . . . . . . . . . . . . . . . . . 541\n8.7\nSummary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 543\n9\nSecurity\n545\n9.1\nIntroduction to security\n. . . . . . . . . . . . . . . . . . . . . . . 546\n9.1.1\nSecurity threats, policies, and mechanisms . . . . . . . . 547\n9.1.2\nDesign issues . . . . . . . . . . . . . . . . . . . . . . . . . 548\n9.2\nCryptography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 555\n9.2.1\nBasics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 555\n9.2.2\nSymmetric and asymmetric cryptosystems . . . . . . . . 557\n9.2.3\nHash functions . . . . . . . . . . . . . . . . . . . . . . . . 560\n9.2.4\nKey management . . . . . . . . . . . . . . . . . . . . . . . 562\n \nDS 4.01\n",
      "content_length": 2981,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 14,
      "content": "x\nCONTENTS\n9.3\nAuthentication . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 571\n9.3.1\nIntroduction to authentication\n. . . . . . . . . . . . . . . 571\n9.3.2\nAuthentication protocols . . . . . . . . . . . . . . . . . . . 572\n9.4\nTrust in distributed systems . . . . . . . . . . . . . . . . . . . . . 585\n9.4.1\nTrust in the face of Byzantine failures . . . . . . . . . . . 586\n9.4.2\nTrusting an identity\n. . . . . . . . . . . . . . . . . . . . . 586\n9.4.3\nTrusting a system . . . . . . . . . . . . . . . . . . . . . . . 591\n9.5\nAuthorization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 593\n9.5.1\nGeneral issues in access control\n. . . . . . . . . . . . . . 593\n9.5.2\nAttribute-based access control\n. . . . . . . . . . . . . . . 598\n9.5.3\nDelegation . . . . . . . . . . . . . . . . . . . . . . . . . . . 601\n9.5.4\nDecentralized authorization: an example . . . . . . . . . 605\n9.6\nMonitoring . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 609\n9.6.1\nFirewalls . . . . . . . . . . . . . . . . . . . . . . . . . . . . 609\n9.6.2\nIntrusion detection: basics . . . . . . . . . . . . . . . . . . 611\n9.6.3\nCollaborative intrusion detection . . . . . . . . . . . . . . 612\n9.7\nSummary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 613\nIndex\n615\nBibliography\n631\nGlossary\n665\nDS 4.01\n \n",
      "content_length": 1332,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 15,
      "content": "PREFACE\nThis is the fourth edition of “Distributed Systems.” We have stayed close\nto the setup of the third edition, including examples of (part of) existing\ndistributed systems close to where general principles are discussed. For\nexample, we have included material on blockchain systems, and discuss their\nvarious components throughout the book. We have, again, used special boxed\nsections for material that can be skipped at first reading.\nThe text has been thoroughly reviewed, revised, and updated. In particular,\nall the Python code has been updated to Python3, while at the same time\nthe channel package has been almost completely revised and simplified. The\ncoding examples in the book leave out many details for readability, but\nthe complete examples are available through the book’s Website, hosted at\nwww.distributed-systems.net. We have made sure that virtually all examples\ncan be instantly executed through a simple script. However, it will be necessary\nto download and install special packages, such as Redis.\nAs before, the Website also contains slides in PDF and PPT, as well as the\nsources for producing slides using LATEX with the Beamer class. All figures,\nnow including those for tables and coding examples, are available in PDF and\nPNG formats.\nLike the previous edition, the book can be (freely) downloaded, making it\nmuch easier to use hyperlinks where appropriate. At the same time, we are\noffering a printed version through Amazon.com, available at minimal costs.\nThe book being fully digital allows us to incorporate updates when needed.\nWe plan to run updates on a yearly basis, while keeping previous versions\ndigitally available, as well as the original printed version. Running frequent\nupdates is not always the right thing to do from the perspective of teaching, but\nyearly updates and maintaining previous versions seems a good compromise.\nUpdates generally consist of small corrections, the kind that usually pop up\nin errata lists. Next to that, the book now also contains an index section, as\nwell as a glossary section. These are typically sections that generally take a\nhuge time to compile, but are also sections that typically grow as the book\nis being used. Likewise, we may find ways to improve how hyperlinks have\nbeen incorporated. Such matters do not affect the main text, while potentially\nimproving the usability of the digital version.\nxi\n",
      "content_length": 2387,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 16,
      "content": "xii\nPREFACE\nAcknowledgements\nMany teachers and students have helped with spotting the inevitable errors\nin the third edition, and we owe them many thanks, but in any case Michael\nMay, Linh Phan, Juan Abadie, and Christian Zirpins. For the fourth edition,\na handful of colleagues were so kind to review parts of the material. In\nparticular, we wish to thank Armin Stocker, Hermann de Meer, Pim Otte,\nJohan Pouwelse, Michael P. Anderson, Ivo Varenhorst, Aditya Pappu, and\nAlexander Iosup. A special thanks goes to Hein Meling of Stavanger University.\nNot only did he help us tremendously in understanding how Paxos works\n(already for the third edition), we have gratefully adopted, and adapted, his\nLATEX style file for generating message-sequence charts. These figures are now\nmuch more consistent. We thank Max van Steen for designing the cover.\nMaarten van Steen\nAndrew S. Tanenbaum\nDS 4.01\n \n",
      "content_length": 894,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 17,
      "content": "01\nINTRODUCTION\n",
      "content_length": 16,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 18,
      "content": "2\nCHAPTER 1. INTRODUCTION\nThe pace at which computer systems change was, is, and continues to be\noverwhelming. From 1945, when the modern computer era began, until about\n1985, computers were large and expensive. Moreover, lacking a way to connect\nthem, these computers operated independently of one another.\nStarting in the mid-1980s, however, two advances in technology began to\nchange that situation. The first was the development of powerful microproces-\nsors. Initially, these were 8-bit machines, but soon 16-, 32-, and 64-bit CPUs\nbecame common. With powerful multicore CPUs, we now are again facing\nthe challenge of adapting and developing programs to exploit parallelism. In\nany case, the current generation of machines have the computing power of the\nmainframes deployed 30 or 40 years ago, but for 1/1000th of the price or less.\nThe second development was the invention of high-speed computer net-\nworks. Local-area networks or LANs allow thousands of machines within a\nbuilding to be connected in such a way that small amounts of information can\nbe transferred in a few microseconds or so. Larger amounts of data can be\nmoved between machines at rates of billions of bits per second (bps). Wide-area\nnetwork or WANs allow hundreds of millions of machines all over the earth\nto be connected at speeds varying from tens of thousands to hundreds of\nmillions bps and more.\nParallel to the development of increasingly powerful and networked ma-\nchines, we have also been able to witness miniaturization of computer systems,\nwith perhaps the smartphone as the most impressive outcome. Packed with\nsensors, lots of memory, and a powerful multicore CPU, these devices are\nnothing less than full-fledged computers. Of course, they also have network-\ning capabilities. Along the same lines, so-called nano computers have become\nreadily available. These small, single-board computers, often the size of a\ncredit card, can easily offer near-desktop performance. Well-known examples\ninclude Raspberry Pi and Arduino systems.\nAnd the story continues. As digitalization of our society continues, we\nbecome increasingly aware of how many computers are actually being used,\nregularly embedded into other systems such as cars, airplanes, buildings,\nbridges, the power grid, and so on. This awareness is, unfortunately, increased\nwhen such systems suddenly turn out to be hackable.\nFor example, in\n2021, a fuel pipeline in the United States was effectively shut down by a\nransomware attack. In this case, the computer system consisted of a mix\nof sensors, actuators, controllers, embedded computers, servers, etc., all\nbrought together into a single system. What many of us do not realize, is that\nvital infrastructures, such as fuel pipelines, are monitored and controlled by\nnetworked computer systems. Along the same lines, it may be time to start\nrealizing that a modern car is actually an autonomously operating, mobile\nnetworked computer. In this case, instead of the mobile computer being\ncarried by a person, we need to deal with the mobile computer carrying\npeople.\nDS 4.01\n \n",
      "content_length": 3077,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 19,
      "content": "1.1. FROM NETWORKED SYSTEMS TO DISTRIBUTED SYSTEMS\n3\nThe size of a networked computer system may vary from a handful of\ndevices, to millions of computers. The interconnection network may be wired,\nwireless, or a combination of both. Moreover, these systems are often highly\ndynamic, in the sense that computers can join and leave, with the topology\nand performance of the underlying network almost continuously changing.\nIt is difficult to think of computer systems that are not networked. And\nas a matter of fact, most networked computer systems can be accessed from\nany place in the world because they are hooked up to the Internet. Studying\nto understand these systems can easily become exceedingly complex. In this\nchapter, we start with shedding some light on what needs to be understood\nto build up the bigger picture without getting lost.\n1.1\nFrom networked systems to distributed systems\nBefore we dive into various aspects of distributed systems, let us first consider\nwhat distribution, or decentralization, actually entails.\n1.1.1\nDistributed versus decentralized systems\nWhen considering various sources, there are quite a few opinions on dis-\ntributed versus decentralized systems. Often, the distinction is illustrated by\nthree different organizations of networked computer systems, as shown in\nFigure 1.1, where each node represents a computer system and an edge a\ncommunication link between two nodes.\nTo what extent such distinctions are useful remains to be seen, especially\nwhen discussions open on the pros and cons of each organization.\nFor\nexample, it is often stated that centralized organizations do not scale well.\nLikewise, distributed organizations are said to be more robust against failures.\nAs we shall see, none of these claims are generally true.\n(a)\n(b)\n(c)\nFigure 1.1: The organization of a (a) centralized, (b) decentralized, and\n(c) distributed system, according to various popular sources.\nWe take a\ndifferent approach, as figures such as these are really not that meaningful.\n \nDS 4.01\n",
      "content_length": 2024,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 20,
      "content": "4\nCHAPTER 1. INTRODUCTION\nWe take a different approach. If we think of a networked computer system\nas a collection of computers connected in a network, we can ask ourselves\nhow these computers even became connected to each other in the first place.\nThere are roughly two views that one can take.\nThe first, integrative view, is that there was a need to connect existing\n(networked) computer systems to each other. Typically, this happens when\nservices running on a system need to be made available to users and applica-\ntions that were not thought of before. This may happen, for example, when\nintegrating financial services with project management services, as is often the\ncase within a single organization. In the scientific-research domain, we have\nseen efforts to connect a myriad of often expensive resources (special-purpose\ncomputers, supercomputers, very large database systems, etc.) into what came\nto be known as a grid computer.\nThe second, expansive view is that an existing system required an exten-\nsion through additional computers. This view is the one most often related to\nthe field of distributed systems. It entails expanding a system with computers\nto hold resources close to where those resources are needed. An expansion\nmay also be driven by the need to improve dependability: if one computer\nfails, then there are others who can take over. An important type of expansion\nis when a service needs to be made available for remote users and applications,\nfor example, by offering a Web interface or a smartphone application. This\nlast example also shows that the distinction between an integrative and an\nexpansive view is not a clear-cut.\nIn both cases, we see that the networked system runs services, where each\nservice is implemented as a collection of processes and resources spread across\nmultiple computers. The two views lead to a natural distinction between two\ntypes of networked computer systems:\n• A decentralized system is a networked computer system in which pro-\ncesses and resources are necessarily spread across multiple computers.\n• A distributed system is a networked computer system in which pro-\ncesses and resources are sufficiently spread across multiple computers.\nBefore we discuss why this distinction is important, let us look at a few\nexamples of each type of system.\nDecentralized systems are mainly related to the integrative view of net-\nworked computer systems. They come to being because we want to con-\nnect systems, yet may be hindered by administrative boundaries. For exam-\nple, many applications in the artificial-intelligence domain require massive\namounts of data for building reliable predictive models. Normally, data is\nbrought to the high-performance computers that literally train models before\nthey can be used. But when data needs to stay within the perimeter of an\norganization (and there can be many reasons why this is necessary), we need\nto bring the training to the data. The result is known as federated learning,\nDS 4.01\n \n",
      "content_length": 2998,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 21,
      "content": "1.1. FROM NETWORKED SYSTEMS TO DISTRIBUTED SYSTEMS\n5\nand is implemented by a decentralized system, where the need for spreading\nprocesses and resources is dictated by administrative policies.\nAnother example of a decentralized system is that of distributed ledger,\nalso known as a blockchain. In this case, we need to deal with the situation\nthat participating parties do not trust each other enough to set up simple\nschemes for collaboration. Instead, what they do is essentially make transac-\ntions among each other fully public (and verifiable) by an extend-only ledger\nthat keeps records of those transactions. The ledger itself is fully spread across\nthe participants, and the participants are the ones who validate transactions\n(of others) before admitting them to the ledger. The result is a decentralized\nsystem in which processes and resources are, indeed, necessarily spread across\nmultiple computers, in this case due to lack of trust.\nAs a last example of a decentralized system, consider systems that are\nnaturally geographically dispersed. This occurs typically with systems in\nwhich an actual location needs to be monitored, for example, in the case of\na power plant, a building, a specific natural environment, and so on. The\nsystem, controlling the monitors and where decisions are made, may easily\nbe placed somewhere else than the location being monitored. One obvious\nexample is monitoring and controlling of satellites, but also more mundane\nsituations as monitoring and controlling traffic, trains, etc. In these examples,\nthe necessity for spreading processes and resources comes from a spatial\nargument.\nAs we mentioned, distributed systems are mainly related to the expansive\nview of networked computer systems. A well-known example is making use\nof e-mail services, such as Google Mail. What often happens is that a user logs\ninto the system through a Web interface to read and send mails. More often,\nhowever, is that users configure their personal computer (such as a laptop) to\nmake use of a specific mail client. To that end, they need to configure a few\nsettings, such as the incoming and outgoing server. In the case of Google Mail,\nthese are imap.gmail.com and smtp.gmail.com, respectively. Logically, it seems\nas if these two servers will handle all your mail. However, with an estimate\nof close to 2 billion users as of 2022, it is unlikely that only two computers\ncan handle all their e-mails (which was estimated to be more than 300 billion\nper year, that is, some 10,000 mails per second). Behind the scenes, of course,\nthe entire Google Mail service has been implemented and spread across many\ncomputers, jointly forming a distributed system. That system has been set\nup to make sure that so many users can process their mails (i.e., ensures\nscalability), but also that the risk of losing mail because of failures, is minimal\n(i.e., the system ensures fault tolerance). To the user, however, the image of\njust two servers is kept up (i.e., the distribution itself is highly transparent\nto the user). The distributed system implementing an e-mail service, such\nas Google Mail, typically expands (or shrinks) as dictated by dependability\nrequirements, in turn, dependent on the number of its users.\n \nDS 4.01\n",
      "content_length": 3246,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 22,
      "content": "6\nCHAPTER 1. INTRODUCTION\nAn entirely different type of distributed system is formed by the collection\nof so-called Content Delivery Networks, or CDNs for short. A well-known\nexample is Akamai with, in 2022, over 400,000 servers worldwide. We will\ndiscuss the principle working of CDNs later in Chapter 3. What it boils\ndown to, is that the content of an actual Website, is copied and spread across\nvarious servers of the CDN. When visiting a Website, the user is transparently\nredirected to a nearby server that holds all or part of the content of that Website.\nThe choice for which server to direct a user to may depend on many things,\nbut surely when dealing with streaming content, a server is selected for which\ngood performance in terms of latency and bandwidth can be guaranteed.\nThe CDN dynamically ensures that the selected server will have the required\ncontent readily available, as well as update that content when needed, or\nremove it from the server when there are no or very few users to service there.\nMeanwhile, the user knows nothing about what is going on behind the scenes\n(which, again, is a form of distribution transparency). We also see in this\nexample, that content is not copied to all servers, yet only to where it makes\nsense, that is, sufficiently, and for reasons of performance. CDNs also copy\ncontent to multiple servers to provide high levels of dependability.\nAs a final, much smaller distributed system, consider a setup based on a\nNetwork-Attached Storage device, also called a NAS. For domestic use, a\ntypical NAS consists of 2–4 slots for internal hard disks. The NAS operates\nas a file server: it is accessible through a (generally wireless) network for\nany authorized device, and as such can offer services like shared storage,\nautomated backups, streaming media, and so on. The NAS itself can best be\nseen as a single computer optimized for storing files, and offering the ability\nto easily share those files. The latter is important, and together with multiple\nusers, we essentially have a setup of a distributed system. The users will\nbe working with a set of files that are locally (i.e., from their laptop) easily\naccessible (in fact, seemingly integrated into the local file system), while also\ndirectly accessible by and for other users. Again, where and how the shared\nfiles are stored is hidden (i.e., the distribution is transparent). Assuming that\nsharing files is the goal, then we see that indeed a NAS can provide sufficient\nspreading of processes and resources.\nNote 1.1 (More information: Are centralized solutions bad?)\nThere appears to be a stubborn misconception that centralized solutions cannot\nscale. Moreover, they are almost always associated with introducing a single\npoint of failure. Both reasons are often seen to be enough to dismiss centralized\nsolutions as being a good choice when designing distributed systems.\nWhat many people forget is that a difference should be made between logical\nand physical designs. A logically centralized solution can be implemented in a\nhighly scalable distributed manner. An excellent example is the Domain Name\nSystem (DNS), which we discuss extensively in Chapter 6. Logically, DNS is\nDS 4.01\n \n",
      "content_length": 3199,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 23,
      "content": "1.1. FROM NETWORKED SYSTEMS TO DISTRIBUTED SYSTEMS\n7\norganized as a huge tree, where each path from the root to a leaf node represents\na fully qualified name, such as www.distributed-systems.net. It would be a\nmistake to think that the root node is implemented by just a single server. In\nfact, the root node is implemented by 13 different root servers, each server, in\nturn, implemented as a large cluster computer. The physical organization of DNS\nalso shows that the root is not a single point of failure. Being highly replicated, it\nwould take serious efforts to bring that root down and so far, all attempts to do\nso have failed.\nCentralized solutions are not bad just because they seem to be centralized.\nIn fact, as we shall encounter many times throughout this book, (logically, and\neven physically) centralized solutions are often much better than distributed\ncounterparts for the simple reason that there is a single point of failure. It makes\nthem much easier to manage, for example, and certainly in comparison where\nthere may be multiple points of failures. Moreover, that single point of failure\ncan be hardened against many kinds of failures as well as many kinds of security\nattacks. When it comes to being a performance bottleneck, we will also see\nthat many things can be done to ensure that even that cannot be held against\ncentralization.\nIn this sense, let us not forget that centralized solutions have even proven to\nbe extremely scalable and robust. They are called cloud-based solutions. Again,\ntheir implementations can make use of very sophisticated distributed solutions,\nyet even then, we shall see that even those solutions may sometimes need to rely\non a small set of physical machines, if only to guarantee performance.\n1.1.2\nWhy making the distinction is relevant\nWhy do we make this distinction between decentralized and distributed\nsystems? It is important to realize that centralized solutions are generally\nmuch simpler, and also simpler along different criteria. Decentralization,\nthat is, the act of spreading the implementation of a service across multiple\ncomputers because we believe it is necessary, is a decision that needs to be\nconsidered carefully. Indeed, distributed and decentralized solutions are\ninherently difficult:\n• There are many, often unexpected, dependencies that hinder understand-\ning the behavior of these systems.\n• Distributed and decentralized systems suffer almost continuously from\npartial failures: some process or resource, somewhere at one of the\nparticipating computers, is not operating according to expectations.\nDiscovering that failure may actually take some time, while also such\nfailures are preferably masked (i.e., they go unnoticed for users and\napplications), including the recovery from failures.\n \nDS 4.01\n",
      "content_length": 2789,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 24,
      "content": "8\nCHAPTER 1. INTRODUCTION\n• Much related to partial failures is the fact that in many networked\ncomputer systems, participating nodes, processes, resources, and so\non, come and go. This makes these systems highly dynamic, in turn\nrequiring forms of automated management and maintenance, in turn\nincreasing the complexity.\n• The fact that distributed and decentralized systems are networked, used\nby many users and applications, and often cross multiple administra-\ntive boundaries, make them particularly vulnerable to security attacks.\nTherefore, understanding these systems and their behavior, requires\nthat we understand how they can be, and are secured. Unfortunately,\nunderstanding security is not that easy.\nOur distinction is one between sufficiency and necessity for spreading processes\nand resources across multiple computers. Throughout this book, we take\nthe standpoint that decentralization can never be a goal in itself, and that it\nshould focus on the sufficiency for spreading processes and resources across\ncomputers. In principle, the less spreading, the better. Yet at the same time,\nwe need to realize that spreading is sometimes truly necessary, as illustrated\nby the examples of decentralized systems. From this point of sufficiency, the\nbook is truly about distributed systems and where appropriate, we shall speak\nof decentralized systems.\nAlong the same lines, considering that distributed and decentralized\nsystems are inherently complex, it is equally important to consider solutions\nthat are as simple as possible. Therefore, we shall hardly discuss optimizations\nto solutions, firmly believing that the impact of their negative contribution to\nincreased complexity outweighs the importance of their positive contribution\nto an increase of any type of performance.\n1.1.3\nStudying distributed systems\nConsidering that distributed systems are inherently difficult, it is important to\ntake a systematic approach toward studying them. One of our major concerns\nis that there are so many explicit and implicit dependencies in distributed\nsystems. For example, there is no such thing as a separate communication\nmodule, or a separate security module. Our approach is to take a look at\ndistributed systems from a limited number, yet different perspectives. Each\nperspective is considered in a separate chapter.\n• There are many ways in which distributed systems are organized. We\nstart our discussion by taking the architectural perspective: what are\ncommon organizations, what are common styles? The architectural\nperspective will help in getting a first grip on how various components\nof existing systems interact and depend on each other.\nDS 4.01\n \n",
      "content_length": 2672,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 25,
      "content": "1.1. FROM NETWORKED SYSTEMS TO DISTRIBUTED SYSTEMS\n9\n• Distributed systems are all about processes. The process perspective is\nall about understanding the different forms of processes that occur in\ndistributed systems, be they threads, their virtualization of hardware\nprocesses, clients, servers, and so on.\nProcesses form the software\nbackbone of distributed systems, and their understanding is essential\nfor understanding distributed systems.\n• Obviously, with multiple computers at stake, communication between\nprocesses is essential. The communication perspective concerns the\nfacilities that distributed systems provide to exchange data between\nprocesses. It essentially entails mimicking procedure calls across mul-\ntiple computers, high-level message passing with a wealth of semantic\noptions, and various sorts of communication between sets of processes.\n• To make distributed systems work, what happens under the hood on top\nof which applications are executed, is that processes coordinate things.\nThey jointly coordinate, for example, to compensate for the lack of global\nclock, for realizing mutual exclusive access to shared resources, and so\non. The coordination perspective describes a number of fundamental\ncoordination tasks that need to be carried out as part of most distributed\nsystems.\n• To access processes and resources, we need naming.\nIn particular,\nwe need naming schemes that, when used, will lead to the process,\nresources, or whatever other type of entity that is being named. As\nsimple as this may seem, naming not only turns out to be crucial in\ndistributed systems, there are also many ways in which naming is\nsupported. The naming perspective focuses entirely on resolving a\nname to the access point of the named entity.\n• A critical aspect of distributed systems is that they perform well in terms\nof efficiency and in terms of dependability. The key instrument for both\naspects is replicating resources. The only problem with replication is\nthat updates may happen, implying that all copies of a resource need\nto be updated as well. It is here, that keeping up the appearance of a\nnondistributed system becomes challenging. The consistency and repli-\ncation perspective essentially concentrates on the trade-offs between\nconsistency, replication, and performance.\n• We already mentioned that distributed systems are subject to partial\nfailures. The perspective of fault tolerance dives into the means for\nmasking failures and their recovery. It has proven to be one of the\ntoughest perspectives for understanding distributed systems, mainly\nbecause there are so many trade-offs to be made, and also because\ncompletely masking failures and their recovery is provably impossible.\n \nDS 4.01\n",
      "content_length": 2723,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 26,
      "content": "10\nCHAPTER 1. INTRODUCTION\n• As also mentioned, there is no such thing as a nonsecured distributed\nsystem. The security perspective focuses on how to ensure authorized\naccess to resources. To that end, we need to discuss trust in distributed\nsystems, along with authentication, namely verifying a claimed identity.\nThe security perspective comes last, yet later in this chapter we shall\ndiscuss a few basic instruments that are needed to understand the role\nof security in the previous perspectives.\n1.2\nDesign goals\nJust because it is possible to build distributed systems does not necessarily\nmean that it is a good idea. In this section, we discuss four important goals\nthat should be met to make building a distributed system worth the effort. A\ndistributed system should make resources easily accessible; it should hide the\nfact that resources are distributed across a network; it should be open; and it\nshould be scalable.\n1.2.1\nResource sharing\nAn important goal of a distributed system is to make it easy for users (and\napplications) to access and share remote resources. Resources can be virtually\nanything, but typical examples include peripherals, storage facilities, data,\nfiles, services, and networks, to name just a few. There are many reasons for\nwanting to share resources. One obvious reason is that of economics. For\nexample, it is cheaper to have a single high-end reliable storage facility be\nshared than having to buy and maintain storage for each user separately.\nConnecting users and resources also makes it easier to collaborate and\nexchange information, as is illustrated by the success of the Internet with\nits simple protocols for exchanging files, mail, documents, audio, and video.\nThe connectivity of the Internet has allowed geographically widely dispersed\ngroups of people to work together by all kinds of groupware, that is, software\nfor collaborative editing, teleconferencing, and so on, as is illustrated by\nmultinational software-development companies that have outsourced much\nof their code production to Asia, but also the myriad of collaboration tools\nthat became (more easily) available due to the COVID-19 pandemic.\nResource sharing in distributed systems is also illustrated by the success\nof file-sharing peer-to-peer networks like BitTorrent. These distributed sys-\ntems make it simple for users to share files across the Internet. Peer-to-peer\nnetworks are often associated with distribution of media files such as au-\ndio and video. In other cases, the technology is used for distributing large\namounts of data, as in the case of software updates, backup services, and data\nsynchronization across multiple servers.\nSeamless integration of resource-sharing facilities in a networked environ-\nment is also now commonplace. A group of users can simply place files into a\nDS 4.01\n \n",
      "content_length": 2826,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 27,
      "content": "1.2. DESIGN GOALS\n11\nspecial shared folder that is maintained by a third party somewhere on the In-\nternet. Using special software, the shared folder is barely distinguishable from\nother folders on a user’s computer. In effect, these services replace the use of\na shared directory on a local distributed file system, making data available\nto users independent of the organization they belong to, and independent of\nwhere they are. The service is offered for different operating systems. Where\nexactly data are stored is completely hidden from the end user.\n1.2.2\nDistribution transparency\nAn important goal of a distributed system is to hide the fact that its processes\nand resources are physically distributed across multiple computers, possibly\nseparated by large distances. In other words, it tries to make the distribution\nof processes and resources transparent, that is, invisible, to end users and\napplications. As we shall discuss more extensively in Chapter 2, achieving\ndistribution transparency is realized through what is known as middleware,\nsketched in Figure 1.2 (see Gazis and Katsiri [2022] for a first introduction).\nIn essence, what applications get to see is the same interface everywhere,\nwhereas behind that interface, where and how processes and resources are\nand how they are accessed is kept transparent. There are different types of\ntransparency, which we discuss next.\nTypes of distribution transparency\nThe concept of transparency can be applied to several aspects of a distributed\nsystem, of which the most important ones are listed in Figure 1.3. We use the\nterm object to mean either a process or a resource.\nAccess transparency deals with hiding differences in data representation\nand the way that objects can be accessed. At a basic level, we want to hide\ndifferences in machine architectures, but more important is that we reach\nFigure 1.2: Realizing distribution transparency through a middleware layer.\n \nDS 4.01\n",
      "content_length": 1948,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 28,
      "content": "12\nCHAPTER 1. INTRODUCTION\nTransparency\nDescription\nAccess\nHide differences in data representation and how an object is\naccessed\nLocation\nHide where an object is located\nRelocation\nHide that an object may be moved to another location while\nin use\nMigration\nHide that an object may move to another location\nReplication\nHide that an object is replicated\nConcurrency\nHide that an object may be shared by several independent\nusers\nFailure\nHide the failure and recovery of an object\nFigure 1.3: Different forms of transparency in a distributed system (see ISO\n[1995]). An object can be a resource or a process.\nagreement on how data is to be represented by different machines and operat-\ning systems. For example, a distributed system may have computer systems\nthat run different operating systems, each having their own file-naming con-\nventions. Differences in naming conventions, differences in file operations, or\ndifferences in how low-level communication with other processes is to take\nplace, are examples of access issues that should preferably be hidden from\nusers and applications.\nAn important group of transparency types concerns the location of a\nprocess or resource.\nLocation transparency refers to the fact that users\ncannot tell where an object is physically located in the system. Naming\nplays an important role in achieving location transparency. In particular,\nlocation transparency can often be achieved by assigning only logical names\nto resources, that is, names in which the location of a resource is not secretly\nencoded. An example of a such a name is the uniform resource locator\n(URL) https://www.distributed-systems.net/, which gives no clue about\nthe actual location of the Web server where this book is offered. The URL also\ngives no clue whether files at that site have always been at their current location\nor were recently moved there. For example, the entire site may have been\nmoved from one data center to another, yet users should not notice. The latter\nis an example of relocation transparency, which is becoming increasingly\nimportant in the context of cloud computing: the phenomenon by which\nservices are provided by huge collections of remote servers. We return to\ncloud computing in subsequent chapters, and, in particular, in Chapter 2.\nWhere relocation transparency refers to being moved by the distributed\nsystem, migration transparency is offered by a distributed system when it\nsupports the mobility of processes and resources initiated by users, with-\nout affecting ongoing communication and operations. A typical example\nis communication between mobile phones: regardless whether two people\nDS 4.01\n \n",
      "content_length": 2646,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 29,
      "content": "1.2. DESIGN GOALS\n13\nare actually moving, mobile phones will allow them to continue their con-\nversation. Other examples that come to mind include online tracking and\ntracing of goods as they are being transported from one place to another,\nand teleconferencing (partly) using devices that are equipped with mobile\nInternet.\nAs we shall see, replication plays an important role in distributed systems.\nFor example, resources may be replicated to increase availability or to im-\nprove performance by placing a copy close to the place where it is accessed.\nReplication transparency deals with hiding the fact that several copies of a\nresource exist, or that several processes are operating in some form of lockstep\nmode so that one can take over when another fails. To hide replication from\nusers, it is necessary that all replicas have the same name. Consequently,\na system that supports replication transparency should generally support\nlocation transparency as well, because it would otherwise be impossible to\nrefer to replicas at different locations.\nWe already mentioned that an important goal of distributed systems is\nto allow sharing of resources. In many cases, sharing resources is done\ncooperatively, as in the case of communication channels. However, there are\nalso many examples of competitive sharing of resources. For example, two\nindependent users may each have stored their files on the same file server\nor may be accessing the same tables in a shared database. In such cases, it\nis important that each user does not notice that the other is making use of\nthe same resource. This phenomenon is called concurrency transparency.\nAn important issue is that concurrent access to a shared resource leaves that\nresource in a consistent state. Consistency can be achieved through locking\nmechanisms, by which users are, in turn, given exclusive access to the desired\nresource. A more refined mechanism is to make use of transactions, but these\nmay be difficult to implement in a distributed system, notably when scalability\nis an issue.\nLast, but certainly not least, it is important that a distributed system\nprovides failure transparency. This means that a user or application does not\nnotice that some piece of the system fails to work properly, and that the system\nsubsequently (and automatically) recovers from that failure. Masking failures\nis one of the hardest issues in distributed systems and is even impossible\nwhen certain apparently realistic assumptions are made, as we will discuss\nin Chapter 8. The main difficulty in masking and transparently recovering\nfrom failures lies in the inability to distinguish between a dead process and a\npainfully slowly responding one. For example, when contacting a busy Web\nserver, a browser will eventually time out and report that the Web page is\nunavailable. At that point, the user cannot tell whether the server is actually\ndown or that the network is badly congested.\n \nDS 4.01\n",
      "content_length": 2943,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 30,
      "content": "14\nCHAPTER 1. INTRODUCTION\nDegree of distribution transparency\nAlthough distribution transparency is generally considered preferable for any\ndistributed system, there are situations in which blindly attempting to hide\nall distribution aspects from users is not a good idea. A simple example is\nrequesting your electronic newspaper to appear in your mailbox before 7 AM\nlocal time, as usual, while you are currently at the other end of the world\nliving in a different time zone. Your morning paper will not be the morning\npaper you are used to.\nLikewise, a wide-area distributed system that connects a process in San\nFrancisco to a process in Amsterdam cannot be expected to hide the fact\nthat Mother Nature will not allow it to send a message from one process to\nthe other in less than approximately 35 milliseconds. Practice shows that it\nactually takes several hundred milliseconds using a computer network. Signal\ntransmission is not only limited by the speed of light, but also by limited\nprocessing capacities and delays in the intermediate switches.\nThere is also a trade-off between a high degree of transparency and the\nperformance of a system. For example, many Internet applications repeatedly\ntry to contact a server before finally giving up. Consequently, attempting to\nmask a transient server failure before trying another one may slow down the\nsystem as a whole. In such a case, it may have been better to give up earlier,\nor at least let the user cancel the attempts to make contact.\nAnother example is where we need to guarantee that several replicas,\nlocated on different continents, must be consistent all the time. In other words,\nif one copy is changed, that change should be propagated to all copies before\nallowing any other operation. A single update operation may now even take\nseconds to complete, something that cannot be hidden from users.\nFinally, there are situations in which it is not at all obvious that hiding\ndistribution is a good idea. As distributed systems are expanding to devices\nthat people carry around and where the very notion of location and context\nawareness is becoming increasingly important, it may be best to actually expose\ndistribution rather than trying to hide it. An obvious example is making use\nof location-based services, which can often be found on mobile phones, such\nas finding a nearest shop or any nearby friends.\nThere are other arguments against distribution transparency. Recognizing\nthat full distribution transparency is simply impossible, we should ask our-\nselves whether it is even wise to pretend that we can achieve it. It may be much\nbetter to make distribution explicit so that the user and application developer\nare never tricked into believing that there is such a thing as transparency. The\nresult will be that users will much better understand the (sometimes unex-\npected) behavior of a distributed system, and are thus much better prepared\nto deal with this behavior.\nThe conclusion is that aiming for distribution transparency may be a\nnice goal when designing and implementing distributed systems, but that\nDS 4.01\n \n",
      "content_length": 3099,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 31,
      "content": "1.2. DESIGN GOALS\n15\nit should be considered together with other issues such as performance\nand comprehensibility. The price for achieving full transparency may be\nsurprisingly high.\nNote 1.2 (Discussion: Against distribution transparency)\nSeveral researchers have argued that hiding distribution will lead to only further\ncomplicating the development of distributed systems, exactly for the reason that\nfull distribution transparency can never be achieved. A popular technique for\nachieving access transparency is to extend procedure calls to remote servers. How-\never, Waldo et al. [1997] already pointed out that attempting to hide distribution\nby such remote procedure calls can lead to poorly understood semantics, for\nthe simple reason that a procedure call does change when executed over a faulty\ncommunication link.\nAs an alternative, various researchers and practitioners are now arguing for\nless transparency, for example, by more explicitly using message-style commu-\nnication, or more explicitly posting requests to, and getting results from remote\nmachines, as is done on the Web when fetching pages. Such solutions will be\ndiscussed in detail in the next chapter.\nA somewhat radical standpoint was taken by Wams [2012] by stating that\npartial failures preclude relying on the successful execution of a remote service. If\nsuch reliability cannot be guaranteed, it is then best to always perform only local\nexecutions, leading to the copy-before-use principle. According to this principle,\ndata can be accessed only after they have been transferred to the machine of the\nprocess wanting that data. Moreover, modifying a data item should not be done.\nInstead, it can only be updated to a new version. It is not difficult to imagine\nthat many other problems will surface. However, Wams shows that many existing\napplications can be retrofitted to this alternative approach without sacrificing\nfunctionality.\n1.2.3\nOpenness\nAnother important goal of distributed systems is openness. An open dis-\ntributed system is essentially a system that offers components that can easily\nbe used by, or integrated into other systems. At the same time, an open\ndistributed system itself will often consist of components that originate from\nelsewhere.\nInteroperability, composability, and extensibility\nTo be open means that components should adhere to standard rules that\ndescribe the syntax and semantics of what those components have to offer (i.e.,\nwhich service they provide). A general approach is to define services through\ninterfaces using an Interface Definition Language (IDL). Interface definitions\nwritten in an IDL nearly always capture only the syntax of services. In other\nwords, they specify precisely the names of the functions that are available\n \nDS 4.01\n",
      "content_length": 2767,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 32,
      "content": "16\nCHAPTER 1. INTRODUCTION\ntogether with types of the parameters, return values, possible exceptions that\ncan be raised, and so on. The hard part is specifying precisely what those\nservices do, that is, the semantics of interfaces. In practice, such specifications\nare given in an informal way by natural language.\nIf properly specified, an interface definition allows an arbitrary process\nthat needs a certain interface, to talk to another process that provides that\ninterface. It also allows two independent parties to build entirely different\nimplementations of those interfaces, leading to two separate components that\noperate in exactly the same way.\nProper specifications are complete and neutral. Complete means that\neverything that is necessary to make an implementation has indeed been\nspecified. However, many interface definitions are not at all complete, so\nthat it is necessary for a developer to add implementation-specific details.\nJust as important is the fact that specifications do not prescribe what an\nimplementation should look like; they should be neutral.\nAs pointed out in Blair and Stefani [1998], completeness and neutrality are\nimportant for interoperability and portability. Interoperability characterizes\nthe extent by which two implementations of systems or components from\ndifferent manufacturers can co-exist and work together by merely relying\non each other’s services as specified by a common standard. Portability\ncharacterizes to what extent an application developed for a distributed system\nA can be executed, without modification, on a different distributed system B\nthat implements the same interfaces as A.\nAnother important goal for an open distributed system is that it should\nbe easy to configure the system out of different components (possibly from\ndifferent developers). Moreover, it should be easy to add new components or\nreplace existing ones without affecting those components that stay in place.\nIn other words, an open distributed system should also be extensible. For\nexample, in an extensible system, it should be relatively easy to add parts that\nrun on a different operating system, or even to replace an entire file system.\nRelatively simple examples of extensibility are plug-ins for Web browsers, but\nalso those for Websites, such as the ones used for WordPress.\nNote 1.3 (Discussion: Open systems in practice)\nOf course, what we have just described is an ideal situation. Practice shows that\nmany distributed systems are not as open as we would like, and that still a lot\nof effort is needed to put various bits and pieces together to make a distributed\nsystem. One way out of the lack of openness is to simply reveal all the gory\ndetails of a component and to provide developers with the actual source code.\nThis approach is becoming increasingly popular, leading to so-called open-source\nprojects, where large groups of people contribute to improving and debugging\nsystems. Admittedly, this is as open as a system can get, but whether it is the best\nway is questionable.\nDS 4.01\n \n",
      "content_length": 3043,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 33,
      "content": "1.2. DESIGN GOALS\n17\nSeparating policy from mechanism\nTo achieve flexibility in open distributed systems, it is crucial that the system\nbe organized as a collection of relatively small and easily replaceable or\nadaptable components. This implies that we should provide definitions of not\nonly the highest-level interfaces, that is, those seen by users and applications,\nbut also definitions for interfaces to internal parts of the system and describe\nhow those parts interact. This approach is relatively new. Many older and\neven contemporary systems are constructed using a monolithic approach\nin which components are only logically separated but implemented as one,\nhuge program. This approach makes it hard to replace or adapt a component\nwithout affecting the entire system. Monolithic systems thus tend to be closed\ninstead of open.\nThe need for changing a distributed system is often caused by a component\nthat does not provide the optimal policy for a specific user or application.\nAs an example, consider caching in Web browsers. There are many different\nparameters that need to be considered:\nStorage: Where is data to be cached? Typically, there will be an in-memory\ncache next to storage on disk. In the latter case, the exact position in the\nlocal file system needs to be considered.\nExemption: When the cache fills up, which data is to be removed so that\nnewly fetched pages can be stored?\nSharing: Does each browser make use of a private cache, or is a cache to be\nshared among browsers of different users?\nRefreshing: When does a browser check if cached data is still up-to-date?\nCaches are most effective when a browser can return pages without\nhaving to contact the original Website. However, this bears the risk of\nreturning stale data. Note also that refresh rates are highly dependent\non which data is actually cached: whereas timetables for trains hardly\nchange, this is not the case for Web pages showing current highway-\ntraffic conditions, or worse yet, stock prices.\nWhat we need is a separation between policy and mechanism. In the case\nof Web caching, for example, a browser should ideally provide facilities for\nonly storing documents (i.e., a mechanism) and at the same time allow users\nto decide which documents are stored and for how long (i.e., a policy). In\npractice, this can be implemented by offering a rich set of parameters that the\nuser can set (dynamically). When taking this a step further, a browser may\neven offer facilities for plugging in policies that a user has implemented as a\nseparate component.\n \nDS 4.01\n",
      "content_length": 2556,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 34,
      "content": "18\nCHAPTER 1. INTRODUCTION\nNote 1.4 (Discussion: Is a strict separation really what we need?)\nIn theory, strictly separating policies from mechanisms seems to be the way to go.\nHowever, there is an important trade-off to consider: the stricter the separation, the\nmore we need to make sure that we offer the appropriate collection of mechanisms.\nIn practice, this means that a rich set of features is offered, in turn leading to many\nconfiguration parameters. As an example, the popular Firefox browser comes\nwith a few hundred configuration parameters. Just imagine how the configuration\nspace explodes when considering large distributed systems consisting of many\ncomponents. In other words, strict separation of policies and mechanisms may\nlead to highly complex configuration problems.\nOne option to alleviate these problems is to provide reasonable defaults, and\nthis is what often happens in practice. An alternative approach is one in which\nthe system observes its own usage and dynamically changes parameter settings.\nThis leads to what are known as self-configurable systems. Nevertheless, the\nfact alone that many mechanisms need to be offered to support a wide range of\npolicies often makes coding distributed systems very complicated. Hard-coding\npolicies into a distributed system may reduce complexity considerably, but at the\nprice of less flexibility.\n1.2.4\nDependability\nAs its name suggests, dependability refers to the degree that a computer\nsystem can be relied upon to operate as expected. In contrast to single-\ncomputer systems, dependability in distributed systems can be rather intricate\ndue to partial failures: somewhere there is a component failing while the\nsystem as a whole still seems to be living up to expectations (up to a certain\npoint or moment). Although single-computer systems can also suffer from\nfailures that do not appear immediately, having a potentially large collection\nof networked computer systems complicates matters considerably. In fact, one\nshould assume that at any time, there are always partial failures occurring.\nAn important goal of distributed systems is to mask those failures, as well as\nmask the recovery from those failures. This masking is the essence of being\nable to tolerate faults, accordingly referred to as fault tolerance.\nBasic concepts\nDependability is a term that covers several useful requirements for distributed\nsystems, including the following [Kopetz and Verissimo, 1993]:\n• Availability\n• Reliability\n• Safety\n• Maintainability\nDS 4.01\n \n",
      "content_length": 2519,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 35,
      "content": "1.2. DESIGN GOALS\n19\nAvailability is defined as the property that a system is ready to be used\nimmediately. In general, it refers to the probability that the system is operating\ncorrectly at any given moment and is available to perform its functions on\nbehalf of its users. In other words, a highly available system is one that will\nmost likely be working at a given instant in time.\nReliability refers to the property that a system can run continuously\nwithout failure. In contrast to availability, reliability is defined in terms of a\ntime interval instead of an instant in time. A highly reliable system is one\nthat will most likely continue to work without interruption during a relatively\nlong period of time. This is a subtle but important difference when compared\nto availability. If a system goes down on average for one, seemingly random\nmillisecond every hour, it has an availability of more than 99.9999 percent,\nbut is still unreliable. Similarly, a system that never crashes but is shut down\nfor two specific weeks every August has high reliability but only 96 percent\navailability. The two are not the same.\nSafety refers to the situation that when a system temporarily fails to\noperate correctly, no catastrophic event happens. For example, many process-\ncontrol systems, such as those used for controlling nuclear power plants or\nsending people into space, are required to provide a high degree of safety. If\nsuch control systems temporarily fail for only a very brief moment, the effects\ncould be disastrous. Many examples from the past (and probably many more\nyet to come) show how hard it is to build safe systems.\nFinally, maintainability refers to how easily a failed system can be repaired.\nA highly maintainable system may also show a high degree of availability,\nespecially if failures can be detected and repaired automatically. However, as\nwe shall see, automatically recovering from failures is easier said than done.\nTraditionally, fault-tolerance has been related to the following three metrics:\n• Mean Time To Failure (MTTF): The average time until a component\nfails.\n• Mean Time To Repair (MTTR): The average time needed to repair a\ncomponent.\n• Mean Time Between Failures (MTBF): Simply MTTF + MTTR.\nNote that these metrics make sense only if we have an accurate notion of\nwhat a failure actually is. As we will encounter in Chapter 8, identifying the\noccurrence of a failure may actually not be so obvious.\nFaults, errors, failures\nA system is said to fail when it cannot meet its promises. In particular, if a\ndistributed system is designed to provide its users with several services, the\nsystem has failed when one or more of those services cannot be (completely)\nprovided. An error is a part of a system’s state that may lead to a failure. For\n \nDS 4.01\n",
      "content_length": 2790,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 36,
      "content": "20\nCHAPTER 1. INTRODUCTION\nexample, when transmitting packets across a network, it is to be expected that\nsome packets have been damaged when they arrive at the receiver. Damaged\nin this context means that the receiver may incorrectly sense a bit value (e.g.,\nreading a 1 instead of a 0), or may even be unable to detect that something\nhas arrived.\nThe cause of an error is called a fault. Clearly, finding out what caused an\nerror is important. For example, a wrong or bad transmission medium may\neasily cause packets to be damaged. In this case, it is relatively easy to remove\nthe fault. However, transmission errors may also be caused by bad weather\nconditions, such as in wireless networks. Changing the weather to reduce or\nprevent errors is a bit trickier.\nAs another example, a crashed program is clearly a failure, which may\nhave happened because the program entered a branch of code containing\na programming bug (i.e., a programming error). The cause of that bug is\ntypically a programmer. In other words, the programmer is the cause of the\nerror (programming bug), in turn leading to a failure (a crashed program).\nBuilding dependable systems closely relates to controlling faults.\nAs\nexplained by Avizienis et al. [2004], a distinction can be made between pre-\nventing, tolerating, removing, and forecasting faults. For our purposes, the\nmost important issue is fault tolerance, meaning that a system can provide\nits services even in the presence of faults. For example, by applying error-\ncorrecting codes for transmitting packets, it is possible to tolerate, to a certain\nextent, relatively poor transmission lines and reducing the probability that an\nerror (a damaged packet) may lead to a failure.\nFaults are generally classified as transient, intermittent, or permanent.\nTransient faults occur once and then disappear. If the operation is repeated,\nthe fault goes away. A bird flying through the beam of a microwave transmitter\nmay cause lost bits on some network (not to mention a roasted bird). If the\ntransmission times out and is retried, it will probably work the second time.\nAn intermittent fault occurs, then vanishes on its own accord, then reap-\npears, and so on. A loose contact on a connector will often cause an inter-\nmittent fault. Intermittent faults cause a great deal of aggravation because\nthey are difficult to diagnose. Typically, when the fault doctor shows up, the\nsystem works fine.\nA permanent fault is one that continues to exist until the faulty compo-\nnent is replaced. Burnt-out chips, software bugs, and disk-head crashes are\nexamples of permanent faults.\nDependable systems are also required to provide security, especially in\nterms of confidentiality and integrity. Confidentiality is the property that\ninformation is disclosed only to authorized parties, while integrity relates to\nensuring that alterations to various assets can be made only in an authorized\nway. Indeed, can we speak of a dependable system when confidentiality and\nintegrity are not in place? We return to security next.\nDS 4.01\n \n",
      "content_length": 3050,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 37,
      "content": "1.2. DESIGN GOALS\n21\n1.2.5\nSecurity\nA distributed system that is not secure, is not dependable. As mentioned,\nspecial attention is needed to ensure confidentiality and integrity, both of\nwhich are directly coupled to authorized disclosure and access of information\nand resources. In any computer system, authorization is done by checking\nwhether an identified entity has proper access rights. In turn, this means\nthat the system should know it is indeed dealing with the proper entity. For\nthis reason, authentication is essential: verifying the correctness of a claimed\nidentity. Equally important is the notion of trust. If a system can positively\nauthenticate a person, what is that authentication worth if the person cannot\nbe trusted? For this reason alone, proper authorization is important, as it\nmay be used to limit any damage that a person, who could in hindsight not\nbe trusted, can cause. For example, in financial systems, authorization may\nlimit the amount of money a person is allowed to transfer between various\naccounts. We will discuss trust, authentication, and authorization at length in\nChapter 9.\nKey elements needed to understand security\nAn essential technique to making distributed systems secure is cryptography.\nThis is not the place in this book to extensively discuss cryptography (which\nwe also defer until Chapter 9), yet to understand how security fits into various\nperspectives in the following chapters, we informally introduce some of its\nbasic elements.\nKeeping matters simple, security in distributed systems is all about en-\ncrypting and decrypting data using security keys. The easiest way of consid-\nering a security key K is to see it as a function operating on some data data.\nWe use the notation K(data) to express the fact that the key K operates on\ndata.\nThere are two ways of encrypting and decrypting data. In a symmetric\ncryptosystem, encryption and decryption takes place with a single key. Denot-\ning by EK(data) the encryption of data using key EK, and likewise DK(data)\nfor decryption with key DK, then in a symmetric cryptosystem, the same key\nis used for encryption and decryption, i.e.,\nif data = DK(EK(data)) then DK = EK.\nNote that in a symmetric cryptosystem, the key will need to be kept secret by\nall parties that are authorized to encrypt or decrypt data. In an asymmetric\ncryptosystem, the keys used for encryption and decryption are different.\nIn particular, there is a public key PK that can be used by anyone, and a\nsecret key SK that is, as its name suggests, to be kept secret. Asymmetric\ncryptosystems are also called public-key systems.\n \nDS 4.01\n",
      "content_length": 2616,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 38,
      "content": "22\nCHAPTER 1. INTRODUCTION\nEncryption and decryption in public-key systems can be used in two,\nfundamentally different ways. First, if Alice wants to encrypt data that can\nbe decrypted only by Bob, she should use Bob’s public key, PKB, leading\nto the encrypted data PKB(data). Only the holder of the associated secret\nkey can decrypt this information, i.e., Bob, who will apply the operation\nSKB(PKB(data)), which returns data.\nA second, and widely applied use case, is that of realizing digital signa-\ntures. Suppose Alice makes some data available for which it is important that\nany party, but let us assume it is Bob, needs to know for sure that it comes\nfrom Alice. In that case, Alice can encrypt the data with her secret key SKA,\nleading to SKA(data). If it can be assured that the associated public key PKA\nindeed belongs to Alice, then successfully decrypting SKA(data) to data, is\nproof that Alice knows about data: she is the only one holding the secret key\nSKA. Of course, we need to make the assumption that Alice is indeed the only\none who holds SKA. We return to some of these assumptions in Chapter 9.\nAs it turns out, proving that an entity has seen, or knows about some\ndata, returns frequently in secured distributed systems. Practical placement\nof digital signatures is generally more efficient by a hash function. A hash\nfunction H has the property that when operating on some data, i.e., H(data),\nit returns a fixed-length string, regardless of the length of data. Any change\nof data to data∗will lead to a different hash value H(data∗). Moreover, given\na hash value h, it is computationally impossible in practice, to discover the\noriginal data. What this all means, is that for placing a digital signature, Alice\ncomputes sig = SKA(H(data)) as her signature, and tells Bob about data, H\nand sig. Bob, in turn, can then verify that signature by computing PKA(sig)\nand verifying that it matches the value H(data).\nUsing cryptography in distributed systems\nThe application of cryptography in distributed systems comes in many forms.\nBesides its general use for encryption and digital signatures, cryptography\nforms the basis for realizing a secure channel between two communicating\nparties. Such channels basically let two parties know for sure that they are\nindeed communicating to the entities that they expected to communicate with.\nIn other words, a communication channel that supports mutual authentication.\nA practical example of a secure channel is using https when accessing Websites.\nNow, many browsers demand that Websites support this protocol, and at\nthe very least will warn the user when this is not the case. In general, using\ncryptography is necessary to realize authentication (and authorization) in\ndistributed systems.\nCryptography is also used to realize secure distributed data structures.\nA well-known example is that of a blockchain, which is, literally, a chain of\nblocks. The basic idea is simple: hash the data in a block Bi, and place that\nhash value as part of the data in its succeeding block Bi+1. Any change in\nDS 4.01\n \n",
      "content_length": 3072,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 39,
      "content": "1.2. DESIGN GOALS\n23\nBi (for example, as the result of an attack), will require that the attacker also\nchanges the stored hash value in Bi+1. However, because the successor of\nBi+1 contains the hash computed over the data in Bi+1, and thus including\nthe original hash value of Bi, the attacker will also have to change the new has\nvalue of Bi as stored in Bi+1. Yet changing that value, also means changing the\nhash value of Bi+1, and thus the value stored in Bi+2, in turn, requiring that\na new hash value is to be computed for Bi+2, and so on. In other words, by\nsecurely linking blocks into a chain, any successful change to a block requires\nthat all successive blocks be modified as well. These modifications should go\nunnoticed, which is virtually impossible.\nCryptography is also used for another important mechanism in distributed\nsystems: delegating access rights. The basic idea is that Alice may want to\ndelegate some rights to Bob, who, in turn, may want to pass some of those\nrights on to Chuck. Using appropriate means (which we discuss in Chapter 9, a\nservice can securely check that Chuck has indeed been authorized to perform\ncertain operations, without the need for that service to check with Alice\nwhether the delegation is in place. Note that delegation is something we are\nnow used to: many of us delegate access rights that we have as a user to\nspecific applications, such as an e-mail client.\nAn upcoming distributed application of cryptography is so-called multi-\nparty computation: the means for two or three parties to compute a value\nfor which the data of those parties is needed, but without having to actually\nshare that data. An often-used example is computing the number of votes\nwithout having to know who voted for whom.\nWe will see many more examples of security in distributed systems in the\nfollowing chapters. With the brief explanations of the cryptographic basis,\nit should suffice to see how security is applied. We shall consistently use\nthe notations as shown in Figure 1.4. Alternatively, security examples can be\nskipped until having studied Chapter 9.\nNotation\nDescription\nKA,B\nSecret key shared by A and B\nPKA\nPublic key of A\nSKA\nPrivate (secret) key of A\nEK(data)\nEncryption of data using key EK (or key K)\nDK(data)\nDecryption of (encrypted) data using key DK (or key K)\nH(data)\nThe hash of data computed using function H\nFigure 1.4: Notations for cryptosystems used in this book.\n \nDS 4.01\n",
      "content_length": 2437,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 40,
      "content": "24\nCHAPTER 1. INTRODUCTION\n1.2.6\nScalability\nFor many of us, worldwide connectivity through the Internet is as common as\nbeing able to send a package to anyone anywhere around the world. Moreover,\nwhere until recently, we were used to having relatively powerful desktop\ncomputers for office applications and storage, we are now witnessing that\nsuch applications and services are being placed in what has been coined “the\ncloud,” in turn leading to an increase of much smaller networked devices such\nas tablet computers or even cloud-only laptops such as Google’s Chromebook.\nWith this in mind, scalability has become one of the most important design\ngoals for developers of distributed systems.\nScalability dimensions\nScalability of a system can be measured along at least three different dimen-\nsions (see [Neuman, 1994]):\nSize scalability: A system can be scalable regarding its size, meaning that\nwe can easily add more users and resources to the system without any\nnoticeable loss of performance.\nGeographical scalability: A geographically scalable system is one in which\nthe users and resources may lie far apart, but the fact that communication\ndelays may be significant is hardly noticed.\nAdministrative scalability: An administratively scalable system is one that\ncan still be easily managed even if it spans many independent adminis-\ntrative organizations.\nLet us take a closer look at each of these three scalability dimensions.\nSize scalability\nWhen a system needs to scale, very different types of prob-\nlems need to be solved. Let us first consider scaling regarding size. If more\nusers or resources need to be supported, we are often confronted with the\nlimitations of centralized services, although often for very different reasons.\nFor example, many services are centralized in the sense that they are imple-\nmented by a single server running on a specific machine in the distributed\nsystem. In a more modern setting, we may have a group of collaborating\nservers co-located on a cluster of tightly coupled machines physically placed\nat the same location. The problem with this scheme is obvious: the server, or\ngroup of servers, can simply become a bottleneck when it needs to process\nan increasing number of requests. To illustrate how this can happen, let us\nassume that a service is implemented on a single machine. In that case, there\nare essentially three root causes for becoming a bottleneck:\n• The computational capacity, limited by the CPUs\n• The storage capacity, including the I/O transfer rate\nDS 4.01\n \n",
      "content_length": 2532,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 41,
      "content": "1.2. DESIGN GOALS\n25\n• The network between the user and the centralized service\nLet us first consider the computational capacity. Just imagine a service for\ncomputing optimal routes taking real-time traffic information into account. It\nis not difficult to imagine that this may be primarily a compute-bound service,\nrequiring several (tens of) seconds to complete a request. If there is only a\nsingle machine available, then even a modern high-end system will eventually\nrun into problems if the number of requests increases beyond a certain point.\nLikewise, but for different reasons, we will run into problems when having\na service that is mainly I/O bound. A typical example is a poorly designed\ncentralized search engine. The problem with content-based search queries is\nthat we essentially need to match a query against an entire data set. Even\nwith advanced indexing techniques, we may still face the problem of having\nto process a huge amount of data exceeding the main-memory capacity of\nthe machine running the service. As a consequence, much of the processing\ntime will be determined by the relatively slow disk accesses and transfer of\ndata between disk and main memory. Simply adding more or higher-speed\ndisks will prove not to be a sustainable solution as the number of requests\ncontinues to increase.\nFinally, the network between the user and the service may also be the cause\nof poor scalability. Just imagine a video-on-demand service that needs to\nstream high-quality video to multiple users. A video stream can easily require\na bandwidth of 8 to 10 Mbps, meaning that if a service sets up point-to-point\nconnections with its customers, it may soon hit the limits of the network\ncapacity of its own outgoing transmission lines.\nThere are several solutions to attack size scalability, which we discuss\nbelow after having looked into geographical and administrative scalability.\nNote 1.5 (Advanced: Analyzing size scalability)\nFigure 1.5: A simple model of a service as a queuing system.\nSize scalability problems for centralized services can be formally analyzed\nusing queuing theory and making a few simplifying assumptions. At a conceptual\nlevel, a centralized service can be modeled as the simple queuing system shown\nin Figure 1.5: requests are submitted to the service, where they are queued until\nfurther notice. As soon as the process can handle a next request, it fetches it from\nthe queue, does its work, and produces a response. We largely follow Menasce\nand Almeida [2002] in explaining the performance of a centralized service.\n \nDS 4.01\n",
      "content_length": 2567,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 42,
      "content": "26\nCHAPTER 1. INTRODUCTION\nOften, we may assume that the queue has an infinite capacity, meaning that\nthere is no restriction on the number of requests that can be accepted for further\nprocessing. Strictly speaking, this means that the arrival rate of requests is not\ninfluenced by what is currently in the queue or being processed. Assuming that\nthe arrival rate of requests is λ requests per second, and that the processing\ncapacity of the service is µ requests per second, one can compute that the fraction\nof time pk that there are k requests in the system is equal to:\npk =\n\u00001 −λ\nµ\n\u0001\u0000 λ\nµ\n\u0001k\nIf we define the utilization U of a service as the fraction of time that it is busy,\nthen clearly,\nU = ∑\nk>0\npk = 1 −p0 = λ\nµ ⇒pk = (1 −U)Uk\nWe can then compute the average number N of requests in the system as\nN = ∑\nk≥0\nk · pk = ∑\nk≥0\nk · (1 −U)Uk = (1 −U) ∑\nk≥0\nk · Uk = (1 −U)U\n(1 −U)2 =\nU\n1 −U .\nWhat we are truly interested in, is the response time R: how long does it take\nbefore the service to process a request, including the time spent in the queue.\nTo that end, we need the average throughput X. Considering that the service is\n“busy” when at least one request is being processed, and that this then happens\nwith a throughput of µ requests per second, and during a fraction U of the total\ntime, we have:\nX =\nU · µ\n|{z}\nserver at work\n+ (1 −U) · 0\n|\n{z\n}\nserver idle\n= λ\nµ · µ = λ\nUsing Little’s formula [Trivedi, 2002], we can then derive the response time as\nR = N\nX =\nS\n1 −U ⇒R\nS =\n1\n1 −U\nwhere S =\n1\nµ, the actual service time. Note that if U is small, the response-\nto-service time ratio is close to 1, meaning that a request is virtually instantly\nprocessed, and at the maximum speed possible. However, as soon as the utilization\ncomes closer to 1, we see that the response-to-server time ratio quickly increases to\nvery high values, effectively meaning that the system is coming close to a grinding\nhalt. This is where we see scalability problems emerge. From this simple model,\nwe can see that the only solution is bringing down the service time S. We leave it\nas an exercise to the reader to explore how S may be decreased.\nGeographical scalability\nGeographical scalability has its own problems. One\nof the main reasons why it is still difficult to scale existing distributed systems\nDS 4.01\n \n",
      "content_length": 2309,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 43,
      "content": "1.2. DESIGN GOALS\n27\nthat were designed for local-area networks is that many of them are based\non synchronous communication. In this form of communication, a party\nrequesting a service, generally referred to as a client, blocks until a reply is\nsent back from the server implementing the service. More specifically, we often\nsee a communication pattern consisting of many client-server interactions, as\nmay be the case with database transactions. This approach generally works\nfine in LANs, where communication between two machines is often at worst\na few hundred microseconds. However, in a wide-area system, we need to\nconsider that interprocess communication may be hundreds of milliseconds,\nthree orders of magnitude slower. Building applications using synchronous\ncommunication in wide-area systems requires a great deal of care (and not\njust a little patience), notably with a rich interaction pattern between client\nand server.\nAnother problem that hinders geographical scalability is that communica-\ntion in wide-area networks is inherently much less reliable than in local-area\nnetworks. In addition, we generally also need to deal with limited bandwidth.\nThe effect is that solutions developed for local-area networks cannot always\nbe easily ported to a wide-area system. A typical example is streaming video.\nIn a home network, even when having only wireless links, ensuring a stable,\nfast stream of high-quality video frames from a media server to a display is\nquite simple. Simply placing that same server far away and using a standard\nTCP connection to the display will surely fail: bandwidth limitations will\ninstantly surface, but also maintaining the same level of reliability can easily\ncause headaches.\nYet another issue that pops up when components lie far apart is the\nfact that wide-area systems generally have only very limited facilities for\nmultipoint communication. In contrast, local-area networks often support\nefficient broadcasting mechanisms. Such mechanisms have proven to be\nextremely useful for discovering components and services, which is essential\nfrom a management perspective. In wide-area systems, we need to develop\nseparate services, such as naming and directory services, to which queries\ncan be sent. These support services, in turn, need to be scalable as well and\noften no obvious solutions exist as we will encounter in later chapters.\nAdministrative scalability\nFinally, a difficult, and often open, question is\nhow to scale a distributed system across multiple, independent administrative\ndomains. A major problem that needs to be solved is that of conflicting\npolicies regarding resource usage (and payment), management, and security.\nTo illustrate, for many years, scientists have been looking for solutions to share\ntheir (often expensive) equipment in what is known as a computational grid.\nIn these grids, a global decentralized system is constructed as a federation of\nlocal distributed systems, allowing a program running on a computer at an\norganization A to directly access resources at the organization B.\n \nDS 4.01\n",
      "content_length": 3075,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 44,
      "content": "28\nCHAPTER 1. INTRODUCTION\nMany components of a distributed system that reside within a single\ndomain can often be trusted by users that operate within that same domain. In\nsuch cases, system administration may have tested and certified applications,\nand may have taken special measures to ensure that such components cannot\nbe tampered with. In essence, the users trust their system administrators.\nHowever, this trust does not expand naturally across domain boundaries.\nIf a distributed system expands to another domain, two types of security\nmeasures need to be taken.\nFirst, the distributed system has to protect\nitself against malicious attacks from the new domain. For example, users\nfrom the new domain may have only read access to the file system in its\noriginal domain. Likewise, facilities such as expensive image setters or high-\nperformance computers may not be made available to unauthorized users.\nSecond, the new domain has to protect itself against malicious attacks from\nthe distributed system. A typical example is that of downloading programs,\nsuch as in the case of federated learning. Basically, the new domain does not\nknow what to expect from such foreign code. The problem, as we shall see in\nChapter 9, is how to enforce those limitations.\nAs a counterexample of distributed systems spanning multiple adminis-\ntrative domains that apparently do not suffer from administrative scalability\nproblems, consider modern file-sharing peer-to-peer networks. In these cases,\nend users simply install a program implementing distributed search and\ndownload functions and within minutes can start downloading files. Other ex-\namples include peer-to-peer applications for telephony over the Internet such\nas older Skype systems [Baset and Schulzrinne, 2006], and (again older) peer-\nassisted audio-streaming applications such as Spotify [Kreitz and Niemelä,\n2010]. A more modern application (that has yet to prove itself in terms of scal-\nability) are blockchains. What these decentralized systems have in common is\nthat end users, and not administrative entities, collaborate to keep the system\nup and running. At best, underlying administrative organizations such as\nInternet Service Providers (ISPs) can police the network traffic that these\npeer-to-peer systems cause.\nScaling techniques\nHaving discussed some scalability problems brings us to the question of how\nthose problems can generally be solved. In most cases, scalability problems\nin distributed systems appear as performance problems caused by limited\ncapacity of servers and network. Simply improving their capacity (e.g., by\nincreasing memory, upgrading CPUs, or replacing network modules) is often\na solution, referred to as scaling up. When it comes to scaling out, that is,\nexpanding the distributed system by essentially deploying more machines,\nthere are basically only three techniques we can apply: hiding communication\nlatencies, distribution of work, and replication (see also Neuman [1994]).\nDS 4.01\n \n",
      "content_length": 2990,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 45,
      "content": "1.2. DESIGN GOALS\n29\nM\nA\nA\nR\nT\nE\nN\nFIRST NAME\nLAST NAME\nE-MAIL\nServer\nClient\nCheck form\nProcess form\nMAARTEN\nMVS\nVAN-STEEN.NET\n@\nVAN STEEN\n(a)\nFIRST NAME\nLAST NAME\nE-MAIL\nServer\nClient\nCheck form\nProcess form\nMAARTEN\nMVS@VAN-STEEN.NET\nVAN STEEN\nMAARTEN\nVAN STEEN\nMVS@VAN-STEEN.NET\n(b)\nFigure 1.6: The difference between letting (a) a server or (b) a client check\nforms as they are being filled.\nHiding communication latencies\nHiding communication latencies is appli-\ncable in the case of geographical scalability. The basic idea is simple: try to\navoid waiting for responses to remote-service requests as much as possible.\nFor example, when a service has been requested at a remote machine, an\nalternative to waiting for a reply from the server is to do other useful work at\nthe requester’s side. Essentially, this means constructing the requesting appli-\ncation in such a way that it uses only asynchronous communication. When a\nreply comes in, the application is interrupted and a special handler is called\nto complete the previously issued request. Asynchronous communication\ncan often be used in batch-processing systems and parallel applications, in\nwhich independent tasks can be scheduled for execution while another task is\nwaiting for communication to complete. Alternatively, a new thread of control\ncan be started to perform the request. Although it blocks waiting for the reply,\nother threads in the process can continue.\nHowever, there are many applications that cannot make effective use of\nasynchronous communication. For example, in interactive applications when\na user sends a request, she will generally have nothing better to do than to\nwait for the answer. In such cases, a much better solution is to reduce the\noverall communication, for example, by moving part of the computation that\nis normally done at the server to the client process requesting the service. A\ntypical case where this approach works is accessing databases using forms.\nFilling in forms can be done by sending a separate message for each field and\nwaiting for an acknowledgment from the server, as shown in Figure 1.6(a). For\nexample, the server may check for syntactic errors before accepting an entry.\n \nDS 4.01\n",
      "content_length": 2205,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 46,
      "content": "30\nCHAPTER 1. INTRODUCTION\nA much better solution is to ship the code for filling in the form, and possibly\nchecking the entries, to the client, and have the client return a completed\nform, as shown in Figure 1.6(b). This approach of shipping code is widely\nsupported by the Web through JavaScript.\nPartitioning and distribution\nAnother important scaling technique is parti-\ntioning and distribution, which involves taking a component or other resource,\nsplitting it into smaller parts, and subsequently spreading those parts across\nthe system. A good example of partitioning and distribution is the Internet\nDomain Name System (DNS). The DNS name space is hierarchically orga-\nnized into a tree of domains, which are divided into nonoverlapping zones,\nas shown for the original DNS in Figure 1.7. The names in each zone are\nhandled by a single name server. Without going into too many details now\n(we return to DNS extensively in Chapter 6), one can think of each path name\nbeing the name of a host on the Internet, and is thus associated with a network\naddress of that host. Basically, resolving a name means returning the network\naddress of the associated host. Consider, for example, the name flits.cs.vu.nl.\nTo resolve this name, it is first passed to the server of zone Z1 (see Figure 1.7)\nwhich returns the address of the server for zone Z2, to which the rest of the\nname, flits.cs.vu, can be handed. The server for Z2 will return the address of\nthe server for zone Z3, which is capable of handling the last part of the name,\nand will return the address of the associated host.\nint\ncom\nedu\ngov\nmil\norg\nnet\njp\nus\nnl\nsun\neng\nyale\neng\nai\nlinda\nrobot\nacm\njack\njill\nieee\nkeio\ncs\ncs\npc24\nco\nnec\ncsl\noce\nvu\ncs\nflits\nfluit\nac\nGeneric\nCountries\nZ1\nZ2\nZ3\nFigure 1.7: An example of dividing the (original) DNS name space into zones.\nThese examples illustrate how the naming service as provided by DNS, is\ndistributed across several machines, thus avoiding that a single server has to\ndeal with all requests for name resolution.\nAs another example, consider the World Wide Web. To most users, the Web\nappears to be an enormous document-based information system, in which\neach document has its own unique name in the form of a URL. Conceptually,\nDS 4.01\n \n",
      "content_length": 2250,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 47,
      "content": "1.2. DESIGN GOALS\n31\nit may even appear as if there is only a single server. However, the Web\nis physically partitioned and distributed across a few hundreds of millions of\nservers, each handling often a number of Websites, or parts of Websites. The\nname of the server handling a document is encoded into that document’s\nURL. It is only because of this distribution of documents that the Web has\nbeen capable of scaling to its current size. Yet, note that finding out how many\nservers provide Web-based services is virtually impossible: A Website today\nis so much more than a few static Web documents.\nReplication\nConsidering that scalability problems often appear in the form\nof performance degradation, it is generally a good idea to actually replicate\ncomponents or resources, etc., across a distributed system. Replication not\nonly increases availability, but also helps to balance the load between com-\nponents, leading to better performance. Moreover, in geographically widely\ndispersed systems, having a copy nearby can hide much of the communication\nlatency problems mentioned before.\nCaching is a special form of replication, although the distinction between\nthe two is often hard to make or even artificial. As in the case of replication,\ncaching results in making a copy of a resource, generally in the proximity of\nthe client accessing that resource. However, in contrast to replication, caching\nis a decision made by the client of a resource and not by the owner of a\nresource.\nThere is one serious drawback to caching and replication that may ad-\nversely affect scalability. Because we now have multiple copies of a resource,\nmodifying one copy makes that copy different from the others. Consequently,\ncaching and replication leads to consistency problems.\nTo what extent inconsistencies can be tolerated depends on the usage of a\nresource. For example, many Web users find it acceptable that their browser\nreturns a cached document of which the validity has not been checked for\nthe last few minutes. However, there are also many cases in which strong\nconsistency guarantees need to be met, such as in the case of electronic stock\nexchanges and auctions. The problem with strong consistency is that an\nupdate must be immediately propagated to all other copies. Moreover, if two\nupdates happen concurrently, it is often also required that updates are pro-\ncessed in the same order everywhere, introducing a global ordering problem.\nTo make things worse, combining consistency with desirable properties such\nas availability may simply be impossible, as we discuss in Chapter 8.\nReplication therefore often requires some global synchronization mecha-\nnism. Unfortunately, such mechanisms are extremely hard or even impossible\nto implement in a scalable way, if alone because network latencies have a nat-\nural lower bound. Consequently, scaling by replication may introduce other,\ninherently nonscalable solutions. We return to replication and consistency\nextensively in Chapter 7.\n \nDS 4.01\n",
      "content_length": 3004,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 48,
      "content": "32\nCHAPTER 1. INTRODUCTION\nDiscussion\nWhen considering these scaling techniques, one could argue that\nsize scalability is the least problematic from a technical perspective. Often,\nincreasing the capacity of a machine will save the day, although perhaps\nthere is a high monetary cost to pay. Geographical scalability is a much\ntougher problem, as network latencies are naturally bound from below. As\na consequence, we may be forced to copy data to locations close to where\nclients are, leading to problems of maintaining copies consistent. Practice\nshows that combining distribution, replication, and caching techniques with\ndifferent forms of consistency generally leads to acceptable solutions. Finally,\nadministrative scalability seems to be the most difficult problem to solve,\npartly because we need to deal with nontechnical issues, such as politics of or-\nganizations and human collaboration. The introduction and now widespread\nuse of peer-to-peer technology has successfully demonstrated what can be\nachieved if end users are put in control [Lua et al., 2005; Oram, 2001]. How-\never, peer-to-peer networks are obviously not the universal solution to all\nadministrative scalability problems.\n1.3\nA simple classification of distributed systems\nWe have discussed distributed versus decentralized systems, yet it is also use-\nful to classify distributed systems according to what they are being developed\nand used for. We make a distinction between systems that are developed for\n(high performance) computing, for general information processing, and those\nthat are developed for pervasive computing, i.e., for the “Internet of Things.”\nAs with many classifications, the boundaries between these three types are\nnot strict and combinations can easily be thought of.\n1.3.1\nHigh-performance distributed computing\nAn important class of distributed systems is the one used for high-performance\ncomputing tasks. Roughly speaking, one can make a distinction between two\nsubgroups. In cluster computing the underlying hardware consists of a\ncollection of similar compute nodes, interconnected by a high-speed network,\noften alongside a more common local-area network for controlling the nodes.\nIn addition, each node generally runs the same operating system.\nThe situation becomes very different in the case of grid computing. This\nsubgroup consists as decentralized systems that are often constructed as a\nfederation of computer systems, where each system may fall under a different\nadministrative domain, and may be very different when it comes to hardware,\nsoftware, and deployed network technology.\nDS 4.01\n \n",
      "content_length": 2610,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 49,
      "content": "1.3. A SIMPLE CLASSIFICATION OF DISTRIBUTED SYSTEMS\n33\nNote 1.6 (More information: Parallel processing)\nHigh-performance computing more or less started with the introduction of multi-\nprocessor machines. In this case, multiple CPUs are organized in such a way that\nthey all have access to the same physical memory, as shown in Figure 1.8(a). In\ncontrast, in a multicomputer system several computers are connected through\na network and there is no sharing of main memory, as shown in Figure 1.8(b).\nThe shared-memory model turned out to be highly convenient for improving the\nperformance of programs, and it was relatively easy to program.\n(a)\n(b)\nFigure 1.8: A comparison between (a) multiprocessor and (b) multicom-\nputer architectures.\nIts essence is that multiple threads of control are executing at the same time,\nwhile all threads have access to shared data. Access to that data is controlled\nthrough well-understood synchronization mechanisms like semaphores (see Ben-\nAri [2006] or Herlihy et al. [2021] for more information on developing parallel\nprograms). Unfortunately, the model does not easily scale: so far, machines have\nbeen developed in which only a few tens (and sometimes hundreds) of CPUs\nhave efficient access to shared memory. To a certain extent, we are seeing the\nsame limitations for multicore processors.\nTo overcome the limitations of shared-memory systems, high-performance\ncomputing moved to distributed-memory systems. This shift also meant that many\nprograms had to make use of message passing instead of modifying shared data as\na means of communication and synchronization between threads. Unfortunately,\nmessage-passing models have proven to be much more difficult and error-prone\ncompared to the shared-memory programming models. For this reason, there\nhas been significant research in attempting to build so-called distributed shared-\nmemory multicomputers, or simply DSM systems [Amza et al., 1996].\nIn essence, a DSM system allows a processor to address a memory location\nat another computer as if it were local memory. This can be achieved using\nexisting techniques available to the operating system, for example, by mapping\nall main-memory pages of the various processors into a single virtual address\nspace. Whenever a processor A addresses a page located at another processor B,\na page fault occurs at A allowing the operating system at A to fetch the content of\nthe referenced page at B in the same way that it would normally fetch it locally\nfrom disk. At the same time, the processor B would be informed that the page is\ncurrently not accessible.\n \nDS 4.01\n",
      "content_length": 2602,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 50,
      "content": "34\nCHAPTER 1. INTRODUCTION\nMimicking shared-memory systems using multicomputers eventually had to\nbe abandoned because performance could never meet the expectations of pro-\ngrammers, who would rather resort to far more intricate, yet better (predictably)\nperforming message-passing models. An important side effect of exploring the\nhardware-software boundaries of parallel processing is a thorough understanding\nof consistency models, to which we return extensively in Chapter 7.\nCluster computing\nCluster computing systems became popular when the price/performance\nratio of personal computers and workstations improved. At a certain point, it\nbecame financially and technically attractive to build a supercomputer using\noff-the-shelf technology by simply hooking up a collection of relatively simple\ncomputers in a high-speed network. In virtually all cases, cluster computing is\nused for parallel programming, in which a single (compute intensive) program\nis run in parallel on multiple machines. The principle of this organization is\nshown in Figure 1.9.\nThis type of high-performance computing has evolved considerably. As\ndiscussed extensively by Gerofi et al. [2019], the developments of supercom-\nputers organized as clusters have reached a point where we see clusters with\nmore than 100,000 CPUs, with each CPU having 8 or 16 cores. There are mul-\ntiple networks. Most important is a network formed by dedicated high-speed\ninterconnects between the various nodes (in other words, there is often no\nsuch thing as a shared high-speed network for computations). A separate\nmanagement network, as well as nodes, are used to monitor and control\nFigure 1.9: An example of a cluster computing system (adapted from [Gerofi\net al., 2019].)\nDS 4.01\n \n",
      "content_length": 1749,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 51,
      "content": "1.3. A SIMPLE CLASSIFICATION OF DISTRIBUTED SYSTEMS\n35\nthe organization and performance of the system as a whole. In addition, a\nspecial high-performance file system or database is used, again with its own\nlocal, dedicated network. Figure 1.9 does not show additional equipment,\nnotably high-speed I/O as well as networking facilities for remote access and\ncommunication.\nA management node is generally responsible for collecting jobs from users,\nto subsequently distribute the associated tasks among the various compute\nnodes. In practice, several management nodes are used when dealing with\nvery large clusters. As such, a management node actually runs the software\nneeded for the execution of programs and management of the cluster, while\nthe compute nodes are equipped with a standard operating system extended\nwith typical functions for communication, storage, fault tolerance, and so on.\nAn interesting development, as explained in Gerofi et al. [2019], is the\nrole of the operating system. There has been a clear trend to minimize the\noperating system to lightweight kernels, essentially ensuring the least possible\noverhead. A drawback is that such operating systems become highly spe-\ncialized and fine-tuned toward the underlying hardware. This specialization\naffects compatibility, or openness. To compensate, we are now gradually\nseeing so-called multikernel approaches, in which a full-fledged operating\nsystem operates next to a lightweight kernel, thus achieving the best of two\nworlds. This combination is also necessary given increasingly more often, a\nhigh-performance compute node is required to run multiple, independent\njobs simultaneously. At present, 95% of all high-performance computers run\nLinux-based systems; multikernel approaches are developed for multicore\nCPUs, with most cores running a lightweight kernel and the other running\na regular Linux system. In this way, new developments such as contain-\ners (which we discuss in Chapter 3) can also be supported. The effects for\ncomputing performance still needs to be seen.\nGrid computing\nA characteristic feature of traditional cluster computing is its homogeneity.\nIn most cases, the computers in a cluster are largely the same, have the\nsame operating system, and are all connected through the same network.\nHowever, as we just discussed, there is a continuous trend toward more\nhybrid architectures in which nodes are specifically configured for certain\ntasks. This diversity is even more prevalent in grid-computing systems: no\nassumptions are made concerning similarity of hardware, operating systems,\nnetworks, administrative domains, security policies, etc. [Rajaraman, 2016].\nA key issue in a grid-computing system is that resources from different\norganizations are brought together to allow the collaboration of a group of\npeople from different institutions, indeed forming a federation of systems.\nSuch a collaboration is realized in the form of a virtual organization. The\nprocesses belonging to the same virtual organization have access rights to the\n \nDS 4.01\n",
      "content_length": 3053,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 52,
      "content": "36\nCHAPTER 1. INTRODUCTION\nresources that are provided to that organization. Typically, resources consist of\ncompute servers (including supercomputers, possibly implemented as cluster\ncomputers), storage facilities, and databases. In addition, special networked\ndevices such as telescopes, sensors, etc., can be provided as well.\nGiven its nature, much of the software for realizing grid computing evolves\naround providing access to resources from different administrative domains,\nand to only those users and applications that belong to a specific virtual\norganization. For this reason, focus is often on architectural issues. An\narchitecture initially proposed by Foster et al. [2001] is shown in Figure 1.10,\nwhich still forms the basis for many grid computing systems.\nFigure 1.10: A layered architecture for grid computing systems.\nThe architecture consists of four layers. The lowest fabric layer provides\ninterfaces to local resources at a specific site. Note that these interfaces are\ntailored to allow sharing of resources within a virtual organization. Typically,\nthey will provide functions for querying the state and capabilities of a resource,\nalong with functions for actual resource management (e.g., locking resources).\nThe connectivity layer consists of communication protocols for supporting\ngrid transactions that span the usage of multiple resources. For example,\nprotocols are needed to transfer data between resources, or to simply access\na resource from a remote location. In addition, the connectivity layer will\ncontain security protocols to authenticate users and resources. Note that in\nmany cases, human users are not authenticated; instead, programs acting on\nbehalf of the users are authenticated. In this sense, delegating rights from\na user to programs is an important function that needs to be supported in\nthe connectivity layer. We return to delegation when discussing security in\ndistributed systems in Chapter 9.\nThe resource layer is responsible for managing a single resource. It uses the\nfunctions provided by the connectivity layer and calls directly the interfaces\nmade available by the fabric layer. For example, this layer will offer functions\nfor obtaining configuration information on a specific resource, or, in general,\nto perform specific operations such as creating a process or reading data. The\nDS 4.01\n \n",
      "content_length": 2357,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 53,
      "content": "1.3. A SIMPLE CLASSIFICATION OF DISTRIBUTED SYSTEMS\n37\nresource layer is thus seen to be responsible for access control, and hence will\nrely on the authentication performed as part of the connectivity layer.\nThe next layer in the hierarchy is the collective layer. It deals with handling\naccess to multiple resources and typically consists of services for resource\ndiscovery, allocation and scheduling of tasks onto multiple resources, data\nreplication, and so on.\nUnlike the connectivity and resource layer, each\nconsisting of a relatively small, standard collection of protocols, the collective\nlayer may consist of many protocols reflecting the broad spectrum of services\nit may offer to a virtual organization.\nFinally, the application layer consists of the applications that operate\nwithin a virtual organization and which make use of the grid computing\nenvironment.\nTypically, the collective, connectivity, and resource layer form the heart of\nwhat could be called a grid middleware layer. These layers jointly provide\naccess to and management of resources that are potentially dispersed across\nmultiple sites.\nAn important observation from a middleware perspective is that in grid\ncomputing, the notion of a site (or administrative unit) is common. This\nprevalence is emphasized by the gradual shift toward a service-oriented ar-\nchitecture in which sites offer access to the various layers through a collection\nof Web services [Joseph et al., 2004]. This, by now, has led to the definition of\nan alternative architecture known as the Open Grid Services Architecture\n(OGSA) [Foster et al., 2006]. OGSA is based upon the original ideas as for-\nmulated by Foster et al. [2001], yet having gone through a standardization\nprocess makes it complex, to say the least. OGSA implementations generally\nfollow Web service standards.\n1.3.2\nDistributed information systems\nAnother important class of distributed systems is found in organizations\nthat were confronted with a wealth of networked applications, but for which\ninteroperability turned out to be a painful experience. Many of the existing\nmiddleware solutions are the result of working with an infrastructure in which\nit was easier to integrate applications into an enterprise-wide information\nsystem [Alonso et al., 2004; Bernstein, 1996; Hohpe and Woolf, 2004].\nWe can distinguish several levels at which integration can take place. Often,\na networked application simply consists of a server running that application\n(often including a database) and making it available to remote programs,\ncalled clients. Such clients send a request to the server for executing a specific\noperation, after which a response is sent back. Integration at the lowest level\nallows clients to wrap several requests, possibly for different servers, into a\nsingle larger request and have it executed as a distributed transaction. The\nkey idea is that all, or none of the requests are executed.\n \nDS 4.01\n",
      "content_length": 2937,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 54,
      "content": "38\nCHAPTER 1. INTRODUCTION\nAs applications became more sophisticated and were gradually separated\ninto independent components (notably distinguishing database components\nfrom processing components), it became clear that integration should also\ntake place by letting applications communicate directly with each other. This\nhas now led to an industry on enterprise application integration (EAI).\nDistributed transaction processing\nTo clarify our discussion, we concentrate on database applications. In practice,\noperations on a database are carried out in the form of transactions. Pro-\ngramming using transactions requires special primitives that must either be\nsupplied by the underlying distributed system or by the language runtime\nsystem. Typical examples of transaction primitives are shown in Figure 1.11.\nThe exact list of primitives depends on what kinds of objects are being used\nin the transaction [Gray and Reuter, 1993; Bernstein and Newcomer, 2009]. In\na mail system, there might be primitives to send, receive, and forward mail.\nIn an accounting system, they might be quite different. READ and WRITE are\ntypical examples, however. Ordinary statements, procedure calls, and so on,\nare also allowed inside a transaction. In particular, remote procedure calls\n(RPC), that is, procedure calls to remote servers, are often also encapsulated\nin a transaction, leading to what is known as a transactional RPC. We discuss\nRPCs extensively in Section 4.2.\nPrimitive\nDescription\nBEGIN_TRANSACTION\nMark the start of a transaction\nEND_TRANSACTION\nTerminate the transaction and try to commit\nABORT_TRANSACTION\nKill the transaction and restore the old values\nREAD\nRead data from a file, a table, or otherwise\nWRITE\nWrite data to a file, a table, or otherwise\nFigure 1.11: Example primitives for transactions.\nBEGIN_TRANSACTION and END_TRANSACTION are used to delimit the\nscope of a transaction. The operations between them form the body of the\ntransaction. The characteristic feature of a transaction is either all of these\noperations are executed or none are executed. These may be system calls,\nlibrary procedures, or bracketing statements in a language, depending on the\nimplementation.\nThis all-or-nothing property of transactions is one of the four characteristic\nproperties that transactions have. More specifically, transactions adhere to the\nso-called ACID properties:\n• Atomic: To the outside world, the transaction happens indivisibly\n• Consistent: The transaction does not violate system invariants\nDS 4.01\n \n",
      "content_length": 2519,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 55,
      "content": "1.3. A SIMPLE CLASSIFICATION OF DISTRIBUTED SYSTEMS\n39\n• Isolated: Concurrent transactions do not interfere with each other\n• Durable: Once a transaction commits, the changes are permanent\nIn distributed systems, transactions are often constructed as a number of\nsubtransactions, jointly forming a nested transaction as shown in Figure 1.12.\nThe top-level transaction may fork off children that run in parallel with one\nanother, on different machines, to gain performance or simplify programming.\nEach of these children may also execute one or more subtransactions, or fork\noff its own children.\nFigure 1.12: A nested transaction.\nSubtransactions give rise to a subtle, but important, problem. Imagine\nthat a transaction starts several subtransactions in parallel, and one of these\ncommits, making its results visible to the parent transaction. After further\ncomputation, the parent aborts, restoring the entire system to the state it\nhad before the top-level transaction started. Consequently, the results of\nthe subtransaction that committed must nevertheless be undone. Thus, the\npermanence referred to above applies only to top-level transactions.\nSince transactions can be nested arbitrarily deep, considerable administra-\ntion is needed to get everything right. The semantics are clear, however. When\nany transaction or subtransaction starts, it is conceptually given a private copy\nof all data in the entire system for it to manipulate as it wishes. If it aborts,\nits private universe just vanishes, as if it had never existed. If it commits,\nits private universe replaces the parent’s universe. Thus, if a subtransaction\ncommits and then later a new subtransaction is started, the second one sees\nthe results produced by the first one. Likewise, if an enclosing (higher level)\ntransaction aborts, all its underlying subtransactions have to be aborted as\nwell. And if several transactions are started concurrently, the result is as if\nthey ran sequentially in some unspecified order.\nNested transactions are important in distributed systems, for they provide\na natural way of distributing a transaction across multiple machines. They\nfollow a logical division of the work of the original transaction. For example,\na transaction for planning a trip by which three different flights need to be\n \nDS 4.01\n",
      "content_length": 2309,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 56,
      "content": "40\nCHAPTER 1. INTRODUCTION\nreserved can be logically split up into three subtransactions. Each of these\nsubtransactions can be managed separately and independently.\nTP monitor\nServer\nServer\nServer\nClient\napplication\nRequests\nReply\nRequest\nRequest\nRequest\nReply\nReply\nReply\nTransaction\nFigure 1.13: The role of a TP monitor in distributed systems.\nEver since the early days of enterprise middleware systems, the compo-\nnent that handles distributed (or nested) transactions belongs to the core for\nintegrating applications at the server or database level. This component is\ncalled a transaction-processing monitor or TP monitor for short. Its main\ntask is to allow an application to access multiple server/databases by offering\nit a transactional programming model, as shown in Figure 1.13. Essentially,\nthe TP monitor coordinates the commitment of subtransactions following a\nstandard protocol known as distributed commit, which we discuss in detail\nin Section 8.5.\nAn important observation is that applications wanting to coordinate sev-\neral subtransactions into a single transaction do not have to implement this\ncoordination themselves. By simply making use of a TP monitor, this coordi-\nnation is done for them. This is precisely where middleware comes into play:\nit implements services that are useful for many applications, avoiding that\nsuch services have to be reimplemented over and over again by application\ndevelopers.\nEnterprise application integration\nAs mentioned, the more applications became decoupled from the databases\nthey were built upon, the more evident it became that facilities were needed\nto integrate applications independently of their databases. In particular, appli-\ncation components should be able to communicate directly with each other\nand not merely by means of the request/reply behavior that was supported\nby transaction processing systems.\nThis need for interapplication communication led to many communication\nmodels. The main idea was that existing applications could directly exchange\ninformation, as shown in Figure 1.14.\nDS 4.01\n \n",
      "content_length": 2074,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 57,
      "content": "1.3. A SIMPLE CLASSIFICATION OF DISTRIBUTED SYSTEMS\n41\nFigure 1.14: Middleware as a communication facilitator in enterprise applica-\ntion integration.\nSeveral types of communication middleware exist. With remote procedure\ncalls (RPC), an application component can effectively send a request to another\napplication component by doing a local procedure call, which results in the\nrequest being packaged as a message and sent to the callee. Likewise, the\nresult will be sent back and returned to the application as the result of the\nprocedure call.\nAs the popularity of object technology increased, techniques were devel-\noped to allow calls to remote objects, leading to what is known as remote\nmethod invocations (RMI). An RMI is essentially the same as an RPC, except\nthat it operates on objects instead of functions.\nRPC and RMI have the disadvantage that the caller and callee both need\nto be up and running at the time of communication.\nIn addition, they\nneed to know exactly how to refer to each other. This tight coupling is\noften experienced as a serious drawback, and has led to what is known as\nmessage-oriented middleware, or simply MOM. In this case, applications\nsend messages to logical contact points, often described by a subject. Likewise,\napplications can indicate their interest for a specific type of message, after\nwhich the communication middleware will take care that those messages are\ndelivered to those applications. These so-called publish-subscribe systems\nform an important and expanding class of distributed systems.\nNote 1.7 (More information: On integrating applications)\nSupporting enterprise application integration is an important goal for many mid-\ndleware products. In general, there are four ways to integrate applications [Hohpe\nand Woolf, 2004]:\nFile transfer: The essence of integration through file transfer, is that an applica-\ntion produces a file containing shared data that is subsequently read by\n \nDS 4.01\n",
      "content_length": 1952,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 58,
      "content": "42\nCHAPTER 1. INTRODUCTION\nother applications. The approach is technically simple, making it appealing.\nThe drawback, however, is that there are numerous things that need to be\nagreed upon:\n• File format and layout: text, binary, its structure, and so on. Nowadays,\nthe extended markup language (XML) has become popular as its files\nare, in principle, self-describing.\n• File management: where are they stored, how are they named, who is\nresponsible for deleting files?\n• Update propagation: When an application produces a file, there may\nbe several applications that need to read that file to provide the view\nof a single coherent system. As a consequence, sometimes separate\nprograms need to be implemented that notify applications of file\nupdates.\nShared database: Many of the problems associated with integration through files\nare alleviated when using a shared database. All applications will have\naccess to the same data, and often through a high-level database language\nsuch as SQL. Furthermore, it is easy to notify applications when changes\noccur, as triggers are often part of modern databases. There are, however,\ntwo major drawbacks. First, there is still a need to design a common\ndata schema, which may be far from trivial if the set of applications that\nneed to be integrated is not completely known in advance. Second, when\nthere are many reads and updates, a shared database can easily become a\nperformance bottleneck.\nRemote procedure call: Integration through files or a database implicitly as-\nsumes that changes by one application can easily trigger other applications\nto act. However, practice shows that sometimes small changes should\nactually trigger many applications to take actions. In such cases, it is not\nreally the change of data that is important, but the execution of a series of\nactions.\nSeries of actions are best captured through the execution of a procedure\n(which may, in turn, lead to all kinds of changes in shared data). To prevent\nthat every application needs to know all the internals of those actions (as\nimplemented by another application), standard encapsulation techniques\nshould be used, as deployed with traditional procedure calls or object\ninvocations. For such situations, an application can best offer a procedure\nto other applications in the form of a remote procedure call, or RPC. In\nessence, an RPC allows an application A to make use of the information\navailable only to the application B, without giving A direct access to that\ninformation. There are many advantages and disadvantages to remote\nprocedure calls, which are discussed in depth in Chapter 4.\nMessaging: A main drawback of RPCs is that caller and callee need to be up\nand running at the same time in order for the call to succeed. However, in\nmany scenarios, this simultaneous activity is often difficult or impossible\nDS 4.01\n \n",
      "content_length": 2850,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 59,
      "content": "1.3. A SIMPLE CLASSIFICATION OF DISTRIBUTED SYSTEMS\n43\nto guarantee. In such cases, offering a messaging system carrying requests\nfrom the application A to perform an action at the application B, is what\nis needed. The messaging system ensures that eventually the request is\ndelivered, and if needed, that a response is eventually returned as well.\nObviously, messaging is not the panacea for application integration: it also\nintroduces problems concerning data formatting and layout, it requires an\napplication to know where to send a message to, there need to be scenarios\nfor dealing with lost messages, and so on. Like RPCs, we will be discussing\nthese issues extensively in Chapter 4.\nWhat these four approaches tell us, is that application integration will generally\nnot be simple. Middleware (in the form of a distributed system), however, can\nsignificantly help in integration by providing the right facilities such as support\nfor RPCs or messaging. As said, enterprise application integration is an important\ntarget field for many middleware products.\n1.3.3\nPervasive systems\nThe distributed systems discussed so far are largely characterized by their\nstability: nodes are fixed and have a more or less permanent and high-quality\nconnection to a network. To a certain extent, this stability is realized through\nthe various techniques for achieving distribution transparency. For example,\nthere are many ways how we can create the illusion that only occasionally\ncomponents may fail. Likewise, there are all kinds of means to hide the actual\nnetwork location of a node, effectively allowing users and applications to\nbelieve that nodes stay put.\nHowever, matters have changed since the introduction of mobile and\nembedded computing devices, leading to what are generally referred to as\npervasive systems. As its name suggests, pervasive systems are intended\nto blend into our environment naturally. Many of their components are\nnecessarily spread across multiple computers, making them arguably a type of\ndecentralized system in our view. At the same time, most pervasive systems\nhave many components that are sufficiently spread throughout the system, for\nexample, to handle failures and such. In this sense, they are also arguably\ndistributed systems. The seemingly strict separation between decentralized\nand distributed systems is thus seen to be less strict than one could initially\nimagine.\nWhat makes them unique, in comparison to the computing and infor-\nmation systems described so far, is that the separation between users and\nsystem components is much more blurred. There is often no single dedicated\ninterface, such as a screen/keyboard combination. Instead, a pervasive system\nis often equipped with many sensors that pick up various aspects of a user’s\nbehavior. Likewise, it may have a myriad of actuators to provide information\nand feedback, often even purposefully aiming to steer behavior.\n \nDS 4.01\n",
      "content_length": 2926,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 60,
      "content": "44\nCHAPTER 1. INTRODUCTION\nMany devices in pervasive systems are characterized by being small,\nbattery-powered, mobile, and having only a wireless connection, although\nnot all these characteristics apply to all devices. These are not necessarily\nrestrictive characteristics, as is illustrated by smartphones [Roussos et al., 2005]\nand their role in what is now coined as the Internet of Things [Mattern and\nFloerkemeier, 2010; Stankovic, 2014]. Nevertheless, notably, the fact that we\noften need to deal with the intricacies of wireless and mobile communication,\nwill require special solutions to make a pervasive system as transparent or\nunobtrusive as possible.\nIn the following, we make a distinction between three different types of\npervasive systems, although there is considerable overlap between the three\ntypes: ubiquitous computing systems, mobile systems, and sensor networks.\nThis distinction allows us to focus on different aspects of pervasive systems.\nUbiquitous computing systems\nSo far, we have been talking about pervasive systems to emphasize that\nits elements have spread through in many parts of our environment. In a\nubiquitous computing system, we go one step further: the system is pervasive\nand continuously present. The latter means that a user will be continuously\ninteracting with the system, often not even being aware that interaction is\ntaking place. Poslad [2009] describes the core requirements for a ubiquitous\ncomputing system roughly as follows:\n1. (Distribution) Devices are networked, distributed, and accessible trans-\nparently\n2. (Interaction) Interaction between users and devices is highly unobtrusive\n3. (Context awareness) The system is aware of a user’s context to optimize\ninteraction\n4. (Autonomy) Devices operate autonomously without human intervention,\nand are thus highly self-managed\n5. (Intelligence) The system as a whole can handle a wide range of dy-\nnamic actions and interactions\nLet us consider these requirements from a distributed-systems perspective.\nAd. 1: Distribution\nAs mentioned, a ubiquitous computing system is an\nexample of a distributed system: the devices and other computers forming\nthe nodes of a system are simply networked and work together to form\nthe illusion of a single, coherent system. Distribution also comes naturally:\nthere will be devices close to users (such as sensors and actuators), connected\nto computers hidden from view and perhaps even operating remotely in a\nDS 4.01\n \n",
      "content_length": 2462,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 61,
      "content": "1.3. A SIMPLE CLASSIFICATION OF DISTRIBUTED SYSTEMS\n45\ncloud. Most, if not all, of the requirements regarding distribution transparency\nmentioned in Section 1.2.2, should therefore hold.\nAd. 2: Interaction\nWhen it comes to interaction with users, ubiquitous\ncomputing systems differ a lot in comparison to the systems we have been\ndiscussing so far. End users play a prominent role in the design of ubiquitous\nsystems, meaning that special attention needs to be paid to how the interac-\ntion between users and core system takes place. For ubiquitous computing\nsystems, much of the interaction by humans will be implicit, with an implicit\naction being defined as one “that is not primarily aimed to interact with a com-\nputerized system but which such a system understands as input” [Schmidt,\n2000]. In other words, a user could be mostly unaware of the fact that input is\nbeing provided to a computer system. From a certain perspective, ubiquitous\ncomputing can be said to seemingly hide interfaces.\nA simple example is where the settings of a car’s driver’s seat, steering\nwheel, and mirrors are fully personalized. If Bob takes a seat, the system will\nrecognize that it is dealing with Bob and subsequently makes the appropriate\nadjustments. The same happens when Alice uses the car, while an unknown\nuser will be steered toward making his or her own adjustments (to be remem-\nbered for later). This example already illustrates an important role of sensors\nin ubiquitous computing, namely as input devices that are used to identify a\nsituation (a specific person apparently wanting to drive), whose input analysis\nleads to actions (making adjustments). In turn, the actions may lead to natural\nreactions, for example that Bob slightly changes the seat settings. The system\nwill have to take all (implicit and explicit) actions by the user into account\nand react accordingly.\nAd. 3: Context awareness\nReacting to the sensory input, but also the explicit\ninput from users, is more easily said than done. What a ubiquitous computing\nsystem needs to do, is to take the context in which interactions take place\ninto account. Context awareness also differentiates ubiquitous computing\nsystems from the more traditional systems we have been discussing before,\nand is described by Dey and Abowd [2000] as “any information that can be\nused to characterize the situation of entities (i.e., whether a person, place, or\nobject) that are considered relevant to the interaction between a user and an\napplication, including the user and the application themselves.” In practice,\ncontext is often characterized by location, identity, time, and activity: the where,\nwho, when, and what. A system will need to have the necessary (sensory) input\nto determine one or several of these context types. As discussed by Alegre\net al. [2016], developing context-aware systems is difficult, if only for the\nreason that the notion of context is difficult to grasp.\nWhat is important, from a distributed-systems perspective, is that raw\ndata as collected by various sensors is lifted to a level of abstraction that can\nbe used by applications. A concrete example is detecting where a person is,\n \nDS 4.01\n",
      "content_length": 3178,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 62,
      "content": "46\nCHAPTER 1. INTRODUCTION\nfor example in terms of GPS coordinates, and subsequently mapping that\ninformation to an actual location, such as the corner of a street, or a specific\nshop or other known facility. The question is where this processing of sensory\ninput takes place: is all data collected at a central server connected to a\ndatabase with detailed information on a city, or is it the user’s smartphone\nwhere the mapping is done? Clearly, there are trade-offs to be considered.\nDey [2010] discusses more general approaches toward building context-\naware applications. When it comes to combining flexibility and potential\ndistribution, so-called shared data spaces in which processes are decoupled\nin time and space are attractive, yet as we shall see in later chapters, suffer\nfrom scalability problems. A survey on context-awareness and its relation to\nmiddleware and distributed systems is provided by Baldauf et al. [2007].\nAd. 4: Autonomy\nAn important aspect of most ubiquitous computing sys-\ntems is that explicit systems management has been reduced to a minimum. In\na ubiquitous computing environment, there is simply no room for a systems\nadministrator to keep everything up and running. As a consequence, the\nsystem as a whole should be able to act autonomously, and automatically\nreact to changes. This requires a myriad of techniques, of which several will\nbe discussed throughout this book. To give a few simple examples, think of\nthe following:\nAddress allocation: In order for networked devices to communicate, they\nneed an IP address. Addresses can be allocated automatically using pro-\ntocols like the Dynamic Host Configuration Protocol (DHCP) [Droms,\n1997] (which requires a server) or Zeroconf [Guttman, 2001].\nAdding devices: It should be easy to add devices to an existing system. A\nstep towards automatic configuration is realized by the Universal Plug\nand Play protocol (UPnP) [UPnP Forum, 2008]. Using UPnP, devices can\ndiscover each other and make sure that they can set up communication\nchannels between them.\nAutomatic updates: Many devices in a ubiquitous computing system should\nbe able to regularly check through the Internet if their software should\nbe updated. If so, they can download new versions of their components\nand ideally continue where they left off.\nAdmittedly, these are simple examples, but the picture should be clear that\nmanual intervention is to be kept to a minimum. We will be discussing many\ntechniques related to self-management in detail throughout the book.\nAd. 5: Intelligence\nFinally, Poslad [2009] mentions that ubiquitous com-\nputing systems often use methods and techniques from the field of artificial\nDS 4.01\n \n",
      "content_length": 2680,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 63,
      "content": "1.3. A SIMPLE CLASSIFICATION OF DISTRIBUTED SYSTEMS\n47\nintelligence. What this means, is that often a wide range of advanced algo-\nrithms and models need to be deployed to handle incomplete input, quickly\nreact to a changing environment, handle unexpected events, and so on. The\nextent to which this can or should be done in a distributed fashion is cru-\ncial from the perspective of distributed systems. Unfortunately, distributed\nsolutions for many problems in the field of artificial intelligence are yet to\nbe found, meaning that there may be a natural tension between the first\nrequirement of networked and distributed devices, and advanced distributed\ninformation processing.\nMobile computing systems\nAs mentioned, mobility often forms an important component of pervasive\nsystems, and many, if not all aspects that we have just discussed also apply to\nmobile computing. There are several issues that set mobile computing aside\nto pervasive systems in general (see also Adelstein et al. [2005] and Tarkoma\nand Kangasharju [2009]).\nFirst, the devices that form part of a (distributed) mobile system may\nvary widely.\nTypically, mobile computing is done with devices such as\nsmartphones and tablet computers.\nHowever, entirely different types of\ndevices are now using the Internet Protocol (IP) to communicate, placing\nmobile computing in a different perspective. Such devices include remote\ncontrols, pagers, active badges, car equipment, various GPS-enabled devices,\nand so on. A characteristic feature of all these devices is that they use wireless\ncommunication. Mobile implies wireless, so it seems (although there are\nexceptions to the rules).\nSecond, in mobile computing, the location of a device is assumed to change\nover time. A changing location has its effects on many issues. For example, if\nthe location of a device changes regularly, so will perhaps the services that\nare locally available. As a consequence, we may need to pay special attention\nto dynamically discovering services, but also letting services announce their\npresence. In a similar vein, we often also want to know where a device actually\nis. This may mean that we need to know the actual geographical coordinates\nof a device such as in tracking and tracing applications, but it may also require\nthat we can simply detect its network position (as in mobile IP [Perkins, 2010;\nPerkins et al., 2011].\nChanging locations may also have a profound effect on communication.\nFor some time, researchers in mobile computing have been concentrating on\nwhat are known as mobile ad hoc networks, also known as MANETs. The\nbasic idea was that a group of local mobile computers would jointly set up a\nlocal, wireless network and to subsequently share resources and services. The\nidea never really became popular. Along the same lines, there are researchers\nwho believe that end users are willing to share their local resources for another\nuser’s compute, storage, or communication requirements (see, e.g., Ferrer\n \nDS 4.01\n",
      "content_length": 2990,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 64,
      "content": "48\nCHAPTER 1. INTRODUCTION\net al. [2019]). Practice has shown over and over again that voluntarily making\nresources available is not something users are willing to do, even if they have\nresources in abundance. The effect is that in the case of mobile computing,\nwe generally see single mobile devices setting up connections to stationary\nservers. Changing locations then simply means that those connections need\nto be handed over by routers on the path from the mobile device to the\nserver. Mobile computing is then brought back to its essence: a mobile device\nconnected to a server (and nothing else). In practice, this means that mobile\ncomputing is all about mobile devices making use of cloud-based services, as\nsketched in Figure 1.15(a).\n(a)\n(b)\nFigure 1.15: (a) Mobile Cloud Computing versus (b) Mobile Edge Computing.\nDespite the conceptual simplicity of this model of mobile computing, the\nmere fact that so many devices make use of remote services has led to what is\nknown as Mobile Edge Computing, or simply MEC [Abbas et al., 2018], in\ncontrast to Mobile Cloud Computing (MCC). As we shall discuss further in\nChapter 2, (mobile) edge computing, as sketched in Figure 1.15(b), is becoming\nincreasingly important in those cases where latency, but also computational\nissues play a role for the mobile device. Typical example applications that\nrequire short latencies and computational resources include augmented reality,\ninteractive gaming, real-time sports monitoring, and various health applica-\ntions [Dimou et al., 2022]. In these examples, the combination of monitoring,\nanalyses, and immediate feedback in general make it difficult to rely on\nservers that may be placed thousands of miles from the mobile devices.\nDS 4.01\n \n",
      "content_length": 1740,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 65,
      "content": "1.3. A SIMPLE CLASSIFICATION OF DISTRIBUTED SYSTEMS\n49\nSensor networks\nOur last example of pervasive systems is sensor networks. These networks\nin many cases form part of the enabling technology for pervasiveness, and\nwe see that many solutions for sensor networks return in pervasive applica-\ntions. What makes sensor networks interesting from a distributed system’s\nperspective is that they are more than just a collection of input devices. In-\nstead, as we shall see, sensor nodes often collaborate to process the sensed\ndata efficiently in an application-specific manner, making them very different\nfrom, for example, traditional computer networks. Akyildiz et al. [2002] and\nAkyildiz et al. [2005] provide an overview from a networking perspective. A\nmore systems-oriented introduction to sensor networks is given by Zhao and\nGuibas [2004], but also [Hahmy, 2021] will show to be useful.\nA sensor network generally consists of tens to hundreds or thousands of\nrelatively small nodes, each equipped with one or more sensing devices. In\naddition, nodes can often act as actuators [Akyildiz and Kasimoglu, 2004],\na typical example being the automatic activation of sprinklers when a fire\nhas been detected. Many sensor networks use wireless communication, and\nthe nodes are often battery powered.\nTheir limited resources, restricted\ncommunication capabilities, and constrained power consumption demand\nthat efficiency is high on the list of design criteria.\nWhen zooming into an individual node, we see that, conceptually, they\ndo not differ a lot from “normal” computers: above the hardware there is a\nsoftware layer akin to what traditional operating systems offer, including low-\nlevel network access, access to sensors and actuators, memory management,\nand so on.\nNormally, support for specific services is included, such as\nlocalization, local storage (think of additional flash devices), and convenient\ncommunication facilities such as messaging and routing. However, similar to\nother networked computer systems, additional support is needed to effectively\ndeploy sensor network applications. In distributed systems, this takes the form\nof middleware. For sensor networks, we can, in principle, follow a similar\napproach in those cases that sensor nodes are sufficiently powerful and that\nenergy consumption is not a hindrance for running a more elaborate software\nstack. Various approaches are possible (see also [Zhang et al., 2021b]).\nFrom a programming perspective, and extensively surveyed by Mottola\nand Picco [2011], it is important to take the scope of communication primitives\ninto account. This scope can vary between addressing the physical neighbor-\nhood of a node, and providing primitives for systemwide communication.\nIn addition, it may also be possible to address a specific group of nodes.\nLikewise, computations may be restricted to an individual node, a group\nof nodes, or affect all nodes. To illustrate, Welsh and Mainland [2004] use\nso-called abstract regions allowing a node to identify a neighborhood from\nwhere it can, for example, gather information:\n \nDS 4.01\n",
      "content_length": 3096,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 66,
      "content": "50\nCHAPTER 1. INTRODUCTION\n1\nregion\n= k_nearest_region.create(8);\n2\nreading = get_sensor_reading();\n3\nregion.putvar(reading_key, reading);\n4\nmax_id\n= region.reduce(OP_MAXID, reading_key);\nIn line 1, a node first creates a region of its eight nearest neighbors, after which\nit fetches a value from its sensor(s). This reading is subsequently written to\nthe previously defined region to be defined using the key reading_key. In\nline 4, the node checks whose sensor reading in the defined region was the\nlargest, which is returned in the variable max_id.\nWhen considering that sensor networks produce data, one can also focus\non the data-access model. This can be done directly by sending messages to\nand between nodes, or either moving code between nodes to locally access\ndata. More advanced is to make remote data directly accessible, as if variables\nand such were available in a shared data space. Finally, and also quite popular,\nis to let the sensor network provide a view of a single database. Such a\nview is easy to understand when realizing that many sensor networks are\ndeployed for measurement and surveillance applications [Bonnet et al., 2002].\nIn these cases, an operator would like to extract information from (a part of)\nthe network by simply issuing queries such as “What is the northbound traffic\nload on highway 1 at Santa Cruz?” Such queries resemble those of traditional\ndatabases. In this case, the answer will probably need to be provided through\ncollaboration of many sensors along highway 1, while leaving other sensors\nuntouched.\nTo organize a sensor network as a distributed database, there are essentially\ntwo extremes, as shown in Figure 1.16. First, sensors do not cooperate but\nsimply send their data to a centralized database located at the operator’s site.\nThe other extreme is to forward queries to relevant sensors and to let each\ncompute an answer, requiring the operator to aggregate the responses.\nNeither of these solutions is very attractive. The first one requires that\nsensors send all their measured data through the network, which may waste\nnetwork resources and energy. The second solution may also be wasteful,\nas it discards the aggregation capabilities of sensors, which would allow\nmuch fewer data to be returned to the operator. What is needed are facilities\nfor in-network data processing, similar to the previous example of abstract\nregions.\nIn-network processing can be done in numerous ways. One obvious way\nis to forward a query to all sensor nodes along a tree encompassing all nodes\nand to subsequently aggregate the results as they are propagated back to the\nroot, where the initiator is located. Aggregation will take place where two\nor more branches of the tree come together. As simple as this scheme may\nsound, it introduces difficult questions:\n• How do we (dynamically) set up an efficient tree in a sensor network?\n• How does aggregation of results take place? Can it be controlled?\nDS 4.01\n \n",
      "content_length": 2955,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 67,
      "content": "1.3. A SIMPLE CLASSIFICATION OF DISTRIBUTED SYSTEMS\n51\n(a)\n(b)\nFigure 1.16: Organizing a sensor network database, while storing and process-\ning data (a) only at the operator’s site or (b) only at the sensors.\n• What happens when network links fail?\nThese questions have been partly addressed in TinyDB, which implements\na declarative (database) interface to wireless sensor networks [Madden et al.,\n2005]. In essence, TinyDB can use any tree-based routing algorithm. An\nintermediate node will collect and aggregate the results from its children,\nalong with its own findings, and send that toward the root. To make matters\nefficient, queries span a period of time, allowing for careful scheduling of\noperations so that network resources and energy are optimally consumed.\nHowever, when queries can be initiated from different points in the net-\nwork, using single-rooted trees such as in TinyDB may not be efficient enough.\nAs an alternative, sensor networks may be equipped with special nodes where\nresults are forwarded to, as well as the queries related to those results. To give\na simple example, queries and results related to temperature readings may be\ncollected at a different location than those related to humidity measurements.\nThis approach corresponds directly to the notion of publish-subscribe systems.\nThe interesting aspect of sensor networks, as discussed along these lines,\nis that we really need to concentrate on the organization of sensor nodes, and\nnot the sensors themselves. Likewise, many sensor nodes will be equipped\nwith actuators, i.e., devices that directly influence an environment. A typical\n \nDS 4.01\n",
      "content_length": 1635,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 68,
      "content": "52\nCHAPTER 1. INTRODUCTION\nFigure 1.17: A hierarchical view from clouds to devices (adapted from Yousef-\npour et al. [2019]).\nactuator is one that controls the temperature in a room, or switches devices\non or off. By viewing and organizing the network as a distributed system, an\noperator is provided with a higher level of abstraction to monitor and control\na situation.\nCloud, edge, things\nAs may have become clear by now, distributed systems span a huge range of\ndifferent networked computer systems. Many of such systems operate in a\nsetting in which the various computers are connected through a local-area\nnetwork. Yet with the growth of the Internet-of-Things and the connectivity\nwith remote services offered through cloud-based systems, new organizations\nacross wide-area networks are emerging. Figure 1.17 presents this more\nhierarchical approach.\nTypically, higher up the hierarchy we see that typical qualities of dis-\ntributed systems improve: they become more reliable, have more capacity,\nand, in general, perform better. Lower in the hierarchy, we see that location-\nrelated aspects are easier facilitated, as well as performance qualities related to\nlatencies. At the same time, the lower parts show in an increase in the number\nof devices and computers, whereas higher up, the number of computers\nbecomes less.\n1.4\nPitfalls\nIt should be clear by now that developing a distributed system is a formidable\ntask. As we will see many times throughout this book, there are so many\nissues to consider, while it seems that only complexity can be the result.\nDS 4.01\n \n",
      "content_length": 1578,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 69,
      "content": "1.5. SUMMARY\n53\nNevertheless, by following several design principles, distributed systems can\nbe developed that strongly adhere to the goals we set out in this chapter.\nDistributed systems differ from traditional software because components\nare dispersed across a network. Not taking this dispersion into account during\ndesign time is what makes so many systems needlessly complex and results in\nflaws that need to be patched later on. Peter Deutsch, at the time working at\nSun Microsystems, formulated these flaws as the following false assumptions\nthat many make when developing a distributed application for the first time:\n• The network is reliable\n• The network is secure\n• The network is homogeneous\n• The topology does not change\n• Latency is zero\n• Bandwidth is infinite\n• Transport cost is zero\n• There is one administrator\nNote how these assumptions relate to properties that are unique to dis-\ntributed systems: reliability, security, heterogeneity, and topology of the\nnetwork; latency and bandwidth; transport costs; and finally administrative\ndomains. When developing nondistributed applications, most of these issues\nwill most likely not show up.\nMost of the principles we discuss in this book relate immediately to these\nassumptions. In all cases, we will be discussing solutions to problems that\nare caused by the fact that one or more assumptions are false. For example,\nreliable networks simply do not exist and lead to the impossibility of achieving\nfailure transparency. We devote an entire chapter to deal with the fact that\nnetworked communication is inherently insecure. We have already argued\nthat distributed systems need to be open and take heterogeneity into account.\nLikewise, when discussing replication for solving scalability problems, we\nare essentially tackling latency and bandwidth problems. We will also touch\nupon management issues at various points throughout this book.\n1.5\nSummary\nA distributed system is a collection of networked computer systems in which\nprocesses and resources are spread across different computers. We make a\ndistinction between sufficiently and necessarily spread, where the latter relates\nto decentralized systems. This distinction is important to make, as spreading\nprocesses and resources cannot be considered to be a goal by itself. Instead,\n \nDS 4.01\n",
      "content_length": 2319,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 70,
      "content": "54\nCHAPTER 1. INTRODUCTION\nmost choices for coming to a distributed system come from the need to im-\nprove the performance of a single computer system in terms of, for example,\nreliability, scalability, and efficiency. However, considering that most cen-\ntralized systems are still much easier to manage and maintain, one should\nthink twice before deciding to spread processes and resources. There are also\ncases when there is simply no choice, for example when connecting systems\nbelonging to different organizations, or when computers simply operate from\ndifferent locations (as in mobile computing).\nDesign goals for distributed systems include sharing resources and ensur-\ning openness. Increasingly important is designing secure distributed systems.\nIn addition, designers aim at hiding many of the intricacies related to the\ndistribution of processes, data, and control. However, this distribution trans-\nparency not only comes at a performance price, in practical situations it can\nnever be fully achieved. The fact that trade-offs need to be made between\nachieving various forms of distribution transparency is inherent to the design\nof distributed systems, and can easily complicate their understanding. One\nspecific difficult design goal that does not always blend well with achieving\ndistribution transparency is scalability. This is particularly true for geographi-\ncal scalability, in which case hiding latencies and bandwidth restrictions can\nturn out to be difficult. Likewise, administrative scalability, by which a system\nis designed to span multiple administrative domains, may easily conflict with\ngoals for achieving distribution transparency.\nDifferent types of distributed systems exist which can be classified as\nbeing oriented toward supporting computations, information processing, and\npervasiveness. Distributed computing systems are typically deployed for\nhigh-performance applications, often originating from the field of parallel\ncomputing. A field that emerged from parallel processing was initially grid\ncomputing with a strong focus on worldwide sharing of resources, in turn\nleading to what is now known as cloud computing. Cloud computing goes\nbeyond high-performance computing and also supports distributed systems\nfound in traditional office environments, where we see databases playing\nan important role. Typically, transaction processing systems are deployed\nin these environments. Finally, an emerging class of distributed systems is\nwhere components are small, the system is composed in an ad hoc fashion,\nbut most of all is no longer managed through a system administrator. This last\nclass is typically represented by pervasive computing environments, including\nmobile-computing systems as well as sensor-rich environments.\nMatters are further complicated by the fact that many developers initially\nmake assumptions about the underlying network that are fundamentally\nwrong. Later, when assumptions are dropped, it may turn out to be difficult\nto mask unwanted behavior. A typical example is assuming that network\nlatency is not significant. Other pitfalls include assuming that the network is\nreliable, static, secure, and homogeneous.\nDS 4.01\n \n",
      "content_length": 3188,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 71,
      "content": "02\nARCHITECTURES\n",
      "content_length": 17,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 72,
      "content": "56\nCHAPTER 2. ARCHITECTURES\nDistributed systems are often complex pieces of software, of which the\ncomponents are by definition dispersed across multiple machines. To master\ntheir complexity, it is crucial that these systems be properly organized. There\nare different ways on how to view the organization of a distributed system,\nbut an obvious one is to make a distinction between, on the one hand, the\nlogical organization of the collection of software components, and on the other\nhand the actual physical realization.\nThe organization of distributed systems is mostly about the software\ncomponents that constitute the system. These software architectures tell us\nhow the various software components are to be organized and how they\nshould interact. In this chapter, we will first pay attention to some commonly\napplied architectural styles toward organizing (distributed) computer systems.\nAn important goal of distributed systems is to separate applications from\nunderlying platforms by providing a so-called middleware layer. Adopting\nsuch a layer is an important architectural decision, and its main purpose is\nto provide distribution transparency. However, trade-offs need to be made\nto achieve transparency, which has led to various techniques to adjust the\nmiddleware to the needs of the applications that make use of it. We discuss\nsome of the more commonly applied techniques, as they affect the organization\nof the middleware itself.\nThe actual realization of a distributed system requires that we instantiate\nand place software components on real machines. There are many choices\nthat can be made in doing so. The final instantiation of a software architecture\nis also referred to as a system architecture. In this chapter, we will look into\ntraditional centralized architectures in which a single server implements most\nof the software components (and thus functionality), while remote clients\ncan access that server using simple communication means. In addition, we\nconsider decentralized peer-to-peer architectures in which all nodes more or\nless play equal roles. Many real-world distributed systems are often organized\nin a hybrid fashion, combining elements from centralized and decentralized\narchitectures. We discuss several examples that illustrate the complexity of\nmany real-world distributed systems.\n2.1\nArchitectural styles\nWe start our discussion on architectures by first considering the logical or-\nganization of a distributed system into software components, also referred\nto as its software architecture [Bass et al., 2021; Richards and Ford, 2020].\nResearch on software architectures has matured considerably, and it is now\ncommonly accepted that designing or adopting an architecture is crucial for\nthe successful development of large software systems.\nFor our discussion, the notion of an architectural style is important. Such\na style is formulated in terms of components, the way that components are\nDS 4.01\n \n",
      "content_length": 2948,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 73,
      "content": "2.1. ARCHITECTURAL STYLES\n57\nconnected to each other, the data exchanged between components, and finally,\nhow these elements are jointly configured into a system. A component is\na modular unit with well-defined required and provided interfaces that is\nreplaceable within its environment [OMG, 2004]. That a component can be\nreplaced, and, in particular, while a system continues to operate, is important.\nThis is because often it is not an option to shut down a system for maintenance.\nAt best, only parts of it may be put temporarily out of order. Replacing a\ncomponent can be done only if its interfaces remain untouched. In practice, we\nsee that replacing or updating a component means that a part of a system (such\nas a server), runs a regular update and switches to the refreshed components\nonce their installation has finished. Special measures may need to be taken\nwhen a part of the distributed system does need to be restarted to let the\nupdates take effect. Such measures may include having replicated standbys\nthat take over while the partial restart is taking place.\nA somewhat more difficult concept to grasp is that of a connector, which\nis generally described as a mechanism that mediates communication, coordi-\nnation, or cooperation among components [Bass et al., 2021]. For example, a\nconnector can be formed by the facilities for (remote) procedure calls, message\npassing, or streaming data. In other words, a connector allows for the flow of\ncontrol and data between components.\nUsing components and connectors, we can come to various configurations,\nwhich, in turn, have been classified into architectural styles. Several styles\nhave by now been identified, of which the most important ones for distributed\nsystems are:\n• Layered architectures\n• Service-oriented architectures\n• Publish-subscribe architectures\nIn the following, we discuss each of these styles separately. We note in ad-\nvance that in most real-world distributed systems, many styles are combined.\nNotably, following an approach by which a system is subdivided into several\n(logical) layers is such a universal principle that it is generally combined with\nmost other architectural styles.\n2.1.1\nLayered architectures\nThe basic idea for the layered style is simple: components are organized in\na layered fashion where a component at layer Lj can make a downcall to\na component at a lower-level layer Li (with i < j) and generally expects a\nresponse. Only in exceptional cases will an upcall be made to a higher-level\ncomponent. The three common cases are shown in Figure 2.1.\n \nDS 4.01\n",
      "content_length": 2573,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 74,
      "content": "58\nCHAPTER 2. ARCHITECTURES\n(a)\n(b)\n(c)\nFigure 2.1: (a) Pure layered organization. (b) Mixed layered organization.\n(c) Layered organization with upcalls (adopted from [Krakowiak, 2009]).\nFigure 2.1(a) shows a standard organization in which only downcalls to\nthe next lower layer are made. This organization is commonly deployed in\nthe case of network communication.\nIn many situations, we also encounter the organization shown in Fig-\nure 2.1(b). Consider, for example, an application A that makes use of a library\nLOS to interface to an operating system. At the same time, the application uses\na specialized mathematical library Lmath that has been implemented by also\nmaking use of LOS. In this case, referring to Figure 2.1(b), A is implemented at\nlayer N −1, Lmath at layer N −2, and LOS which is common to both of them,\nat layer N −3.\nFinally, a special situation is shown in Figure 2.1(c). In some cases, it\nis convenient to have a lower layer do an upcall to its next higher layer. A\ntypical example is when an operating system signals the occurrence of an\nevent, to which end it calls a user-defined operation for which an application\nhad previously passed a reference (typically referred to as a handle).\nLayered communication protocols\nA well-known and ubiquitously applied layered architecture is that of commu-\nnication-protocol stacks. We will concentrate here on the global picture only\nand defer a detailed discussion to Section 4.1.1.\nIn communication-protocol stacks, each layer implements one or several,\ncommunication services allowing data to be sent from a destination to one\nor several targets. To this end, each layer offers an interface specifying the\nDS 4.01\n \n",
      "content_length": 1686,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 75,
      "content": "2.1. ARCHITECTURAL STYLES\n59\nFigure 2.2: A layered communication-protocol stack, showing the difference\nbetween a service, its interface, and the protocol it deploys.\nfunctions that can be called. In principle, the interface should completely hide\nthe actual implementation of a service. Another important concept in the case\nof communication is that of a (communication) protocol, which describes\nthe rules that parties will follow to exchange information. It is important to\nunderstand the difference between a service offered by a layer, the interface by\nwhich that service is made available, and the protocol that a layer implements\nto establish communication. This distinction is shown in Figure 2.2.\nTo make this distinction clear, consider a reliable, connection-oriented\nservice, which is provided by many communication systems. In this case,\na communicating party first needs to set up a connection to another party\nbefore the two can send and receive messages. Being reliable means that\nstrong guarantees will be given that sent messages will indeed be delivered to\nthe other side, even when there is a high risk that messages may be lost (as,\nfor example, may be the case when using a wireless medium). In addition,\nsuch services generally also ensure that messages are delivered in the same\norder as that they were sent.\nThis kind of service is realized in the Internet by the Transmission Control\nProtocol (TCP). The protocol specifies which messages are to be exchanged for\nsetting up or tearing down a connection, what needs to be done to preserve\nthe ordering of transferred data, and what both parties need to do to detect\nand correct data that was lost during transmission. The service is made\navailable in the form of a relatively simple programming interface, containing\ncalls to set up a connection, send and receive messages, and to tear down\nthe connection again. In fact, there are different interfaces available, often\ndependent on the operating system or programming language used. Likewise,\nthere are many implementations of the protocol and its interfaces. (All the\ngory details can be found in [Stevens, 1994; Wright and Stevens, 1995].)\n \nDS 4.01\n",
      "content_length": 2177,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 76,
      "content": "60\nCHAPTER 2. ARCHITECTURES\nNote 2.1 (Example: Two communicating parties)\nTo make this distinction between service, interface, and protocol more concrete,\nconsider the following two communicating parties, also known as a client and a\nserver, respectively, expressed in Python (note that some code has been removed\nfor clarity).\n1 from socket\nimport *\n2\n3 s = socket(AF_INET, SOCK_STREAM)\n4 (conn, addr) = s.accept()\n# returns new socket and addr. client\n5 while True:\n# forever\n6\ndata = conn.recv(1024)\n# receive data from client\n7\nif not data: break\n# stop if client stopped\n8\nmsg = data.decode()+\"*\"\n# process the incoming data into a response\n9\nconn.send(msg.encode())\n# return the response\n10 conn.close()\n# close the connection\n(a) A simple server\n1 from socket\nimport *\n2\n3 s = socket(AF_INET, SOCK_STREAM)\n4 s.connect((HOST, PORT)) # connect to server (block until accepted)\n5 msg = \"Hello World\"\n# compose a message\n6 s.send(msg.encode())\n# send the message\n7 data = s.recv(1024)\n# receive the response\n8 print(data.decode())\n# print the result\n9 s.close()\n# close the connection\n(b) A client\nFigure 2.3: Two communicating parties.\nIn this example, a server is created that makes use of a connection-oriented\nservice as offered by the socket library available in Python. This service allows\ntwo communicating parties to reliably send and receive data over a connection.\nThe main functions available in its interface are:\n• socket(): to create an object representing the connection\n• accept(): a blocking call to wait for incoming connection requests; if\nsuccessful, the call returns a new socket for a separate connection\n• connect(): to set up a connection to a specified party\n• close(): to tear down a connection\n• send(), recv(): to send and receive data over a connection, respectively\nThe combination of constants AF_INET and SOCK_STREAM is used to specify that\nthe TCP protocol should be used in the communication between the two parties.\nThese two constants can be seen as part of the interface, whereas making use of\nTCP is part of the offered service. How TCP is implemented, or for that matter, any\npart of the communication service, is hidden completely from the applications.\nDS 4.01\n \n",
      "content_length": 2207,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 77,
      "content": "2.1. ARCHITECTURAL STYLES\n61\nFinally, also note that these two programs implicitly adhere to an application-\nlevel protocol: apparently, if the client sends some data, the server will return it.\nIndeed, it operates as an echo server, where the server adds an asterisk to the data\nsent by the client.\nApplication layering\nLet us now turn our attention to the logical layering of applications. Consider-\ning that a large class of distributed applications is targeted toward supporting\nusers or applications access to databases, many people have advocated a\ndistinction between three logical levels, essentially following a layered archi-\ntectural style:\n• The application-interface level\n• The processing level\n• The data level\nIn line with this layering, we see that applications can often be constructed\nfrom roughly three different pieces: a part that handles interaction with a\nuser or some external application, a part that operates on a database or file\nsystem, and a middle part that generally contains the core functionality of the\napplication. This middle part is logically placed at the processing level. In\ncontrast to user interfaces and databases, there are not many aspects common\nto the processing level. Therefore, we shall give several examples to make this\nlevel clearer.\nAs a first example, consider a simple Internet search engine, for example\none dedicated to buying houses. Such search engines appear as seemingly\nsimple Websites through which someone can provide descriptors such as\na city or region, a price range, the type of house, etc. The back end con-\nsists of a huge database of houses currently for sale. The processing layer\ndoes nothing else but transform the provided descriptors into a collection of\ndatabase queries, retrieves the answers and post-processes these answers by,\nfor example, ranking the output by relevance and subsequently generating an\nHTML page. Figure 2.4 shows this organization.\nAs another example, consider the organization of this book’s Website, in\nparticular, the interface that allows someone to get a personalized digital\ncopy of the book in PDF. In this case, the interface consists of a WordPress-\nbased Web server that merely collects the user’s e-mail address (and some\ninformation on exactly which version of the book is being requested). This\ninformation is internally appended to a file requests.txt. The data layer is\nsimple: it merely consists of a collection of LATEX files and figures that jointly\nconstitute the entire book.\n \nDS 4.01\n",
      "content_length": 2507,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 78,
      "content": "62\nCHAPTER 2. ARCHITECTURES\nFigure 2.4: The simplified organization of an Internet search engine for\nhousing, into three different layers.\nMaking a personalized copy consists of embedding the user’s e-mail\naddress into each of the figures. To this end, once every five minutes a\nseparate process is started that takes the list of requests and one-by-one adds\nthe requester’s e-mail address into each bitmapped figure, generates a fresh\ncopy of the book, stores the generated PDF in a special location (accessible\nthrough a unique URL), and sends the requester an e-mail that the copy is\navailable for download. This process continues until all requests have been\nhandled. In this example, we thus see that the processing layer outweighs the\ndata layer or the application-interface layer in terms of computational efforts\nand actions to take.\n2.1.2\nService-oriented architectures\nAlthough the layered architectural style is popular, one of its major drawbacks\nis the often strong dependency between different layers. Good examples\nwhere these potential dependencies have been carefully considered are found\nin designing communication protocol stacks. Bad examples include applica-\ntions that have essentially been designed and developed as compositions of\nexisting components without much concern for the stability of interfaces or\nthe components themselves, let alone the overlap of functionality between\ndifferent components. (A compelling example is given by Kucharski [2020],\nwho describes the dependency on a simple component that pads a given\nstring with zeroes or spaces. The author withdrew the component from the\nNPM library, leaving thousands of programs affected.)\nSuch direct dependencies to specific components have led to an architec-\ntural style reflecting a more loose organization into a collection of separate,\nDS 4.01\n \n",
      "content_length": 1838,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 79,
      "content": "2.1. ARCHITECTURAL STYLES\n63\nindependent entities. Each entity encapsulates a service. Whether they are\ncalled services, objects, or microservices, they have in common that the ser-\nvice is executed as a separate process (or thread). Of course, running separate\nentities does not necessarily lower dependencies in comparison to a layered\narchitectural style.\nObject-based architectural style\nTaking the object-based approach as an example, we have a logical organiza-\ntion as shown in Figure 2.5. In essence, each object corresponds to what we\nhave defined as a component, and these components are connected through\na procedure-call mechanism. In the case of distributed systems, a procedure\ncall can also take place over a network, that is, the calling object need not be\nexecuted on the same machine as the called object. In fact, where exactly the\ncalled object is located can be transparent to the caller: the called object may\nequally well run as a separate process on the same machine.\nFigure 2.5: An object-based architectural style.\nObject-based architectures are attractive because they provide a natural\nway of encapsulating data (called an object’s state) and the operations that can\nbe performed on that data (which are referred to as an object’s methods) into\na single entity. The interface offered by an object conceals implementation\ndetails, essentially meaning that we, in principle, can consider an object\ncompletely independent of its environment. As with components, this also\nmeans that if the interface is clearly defined and left otherwise untouched, an\nobject should be replaceable with one having the same interface.\nThis separation between interfaces and the objects implementing these\ninterfaces allows us to place an interface at one machine, while the object itself\nresides on another machine. This organization, which is shown in Figure 2.6\nis commonly referred to as a distributed object, or every so often a remote\nobject.\nWhen a client binds to a distributed object, an implementation of the\nobject’s interface, called a proxy, is then loaded into the client’s address space.\nA proxy is analogous to a so-called client stub in RPC systems. The only thing\nit does is pack method invocations into messages and unpack reply messages\nto return the result of the method invocation to the client. The actual object\n \nDS 4.01\n",
      "content_length": 2352,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 80,
      "content": "64\nCHAPTER 2. ARCHITECTURES\nServer machine\nObject\nClient machine\nProxy\nSame\ninterface\nas object\nInterface\nState\nMethod\nClient\ninvokes\na method\nNetwork\nSkeleton\ninvokes\nsame method\nat object\nMarshalled invocation\nis passed across network\nClient OS\nServer OS\nServer\nSkeleton\nClient\nFigure 2.6: Common organization of a remote object with client-side proxy.\nresides at a server machine, where it offers the same interface as it does on the\nclient machine. Incoming invocation requests are first passed to a server stub,\nwhich unpacks them to make method invocations at the object’s interface at\nthe server. The server stub is also responsible for packing return values into a\nmessage, and forwarding these reply messages to the client-side proxy.\nThe server-side stub is often referred to as a skeleton as it provides the\nbare means for letting the server middleware access the user-defined objects.\nIn practice, it often contains incomplete code in the form of a language-specific\nclass that needs to be further specialized by the developer.\nA characteristic, but somewhat counterintuitive, feature of most distributed\nobjects is that their state is not distributed: it resides at a single machine. Only\nthe interfaces implemented by the object are made available on other machines.\nSuch objects are also referred to as remote objects. In a general distributed\nobject, the state itself may be physically distributed across multiple machines,\nbut this distribution is also hidden from clients behind the object’s interfaces.\nMicroservice architectural style\nOne could argue that object-based architectures form the foundation of encap-\nsulating services into independent units. Encapsulation is the keyword here:\nthe service as a whole is realized as a self-contained entity, although it can\npossibly make use of other services. By clearly separating various services\nsuch that they can operate independently, we are paving the road toward\nservice-oriented architectures, generally abbreviated as SOAs.\nStimulated by object-oriented designs and inspired by the Unix approach\nin which many, many small and mutually independent programs can be easily\nDS 4.01\n \n",
      "content_length": 2156,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 81,
      "content": "2.1. ARCHITECTURAL STYLES\n65\ncomposed to form larger programs, software architects have been working on\nwhat are called microservices. Essential is that each microservice runs as a\nseparate (network) process. The implementation of a microservice could be\nin the form of a remote object, but this is not a requirement. Furthermore,\ndespite that people speak of microservices, there is no common agreement on\nwhat the size of such a service should be. Most important, however, is that a\nmicroservice truly represents a separate, independent service. In other words,\nmodularization is key to designing microservices [Wolff, 2017].\nNevertheless, size does matter. By already stating that microservices run\nas separate networked processes, we are also given a choice where to place a\nmicroservice. As we shall see later in this chapter, in the advent of edge and\nfog infrastructures, discussions have started on the orchestration of deploying\ndistributed applications across different layers. In other words, where do we\nplace what.\nCoarse-grained service composition\nIn a service-oriented architecture, a distributed application or system is essen-\ntially constructed as a composition of many services. A difference (although\nnot strict) with microservices is that not all of these services may belong to the\nsame administrative organization. We already came across this phenomenon\nwhen discussing cloud computing: it may very well be that an organization\nrunning its business application makes use of storage services offered by a\ncloud provider. These storage services are logically completely encapsulated\ninto a single unit, of which an interface is made available to customers.\nOf course, storage is a rather basic service, but more sophisticated situa-\ntions easily come to mind. Consider, for example, a Web shop selling goods\nsuch as e-books. A simple implementation, following the application layering\nwe discussed previously, may consist of an application for processing orders,\nwhich, in turn, operates on a local database containing the e-books. Order\nprocessing typically involves selecting items, registering and checking the\ndelivery channel (perhaps by making use of e-mail), but also making sure that\na payment takes place. The latter can be handled by a separate service, run by\na different organization, to which a purchasing customer is redirected for the\npayment, after which the e-book organization is notified so that it can com-\nplete the transaction. This example also illustrates that where microservices\nare considered to be relatively small, a general service may be expected to\nbe relatively large. In fact, it is not uncommon to implement a service as a\ncollection of microservices.\nIn this way, we see that the problem of developing a distributed system is\npartly one of service composition, and making sure that those services operate\nin harmony. Indeed, this problem is completely analogous to the enterprise\napplication integration issues discussed in Section 1.3.2.\nCrucial is, and\nremains, that each service offers a well-defined (programming) interface. In\n \nDS 4.01\n",
      "content_length": 3100,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 82,
      "content": "66\nCHAPTER 2. ARCHITECTURES\npractice, this also means that each service offers its own interface, in turn,\npossibly making the composition of services far from trivial.\nResource-based architectures\nAs an increasing number of services became available over the Web and the\ndevelopment of distributed systems through service composition became more\nimportant, researchers started to rethink the architecture of mostly Web-based\ndistributed systems. One of the problems with service composition is that\nconnecting various components can easily turn into an integration nightmare.\nAs an alternative, one can also view a distributed system as a huge collec-\ntion of resources that are individually managed by components. Resources\nmay be added or removed by (remote) applications, and likewise can be\nretrieved or modified. This approach has now been widely adopted for\nthe Web and is known as Representational State Transfer (REST) [Fielding,\n2000]. There are four key characteristics of what are known as RESTful\narchitectures [Pautasso et al., 2008]:\n1. Resources are identified through a single naming scheme\n2. All services offer the same interface, consisting of at most four operations,\nas shown in Figure 2.7\n3. Messages sent to or from a service are fully self-described\n4. After executing an operation at a service, that component forgets every-\nthing about the caller\nThe last property is also referred to as a stateless execution, a concept to\nwhich we return in Chapter 3.\nOperation\nDescription\nPUT\nModify a resource by transferring a new state\nPOST\nCreate a new resource\nGET\nRetrieve the state of a resource in some representation\nDELETE\nDelete a resource\nFigure 2.7: The four operations available in RESTful architectures.\nTo illustrate how RESTful can work in practice, consider a cloud storage\nservice, such as Amazon’s Simple Storage Service (Amazon S3). Amazon\nS3, described in [Murty, 2008] and more recently in [Culkin and Zazon, 2022],\nsupports two resources: objects, which are essentially the equivalent of files,\nand buckets, the equivalent of directories. There is no concept of placing\nbuckets into buckets. An object named ObjectName contained in a bucket\nBucketName is referred to by the following Uniform Resource Identifier (URI):\nDS 4.01\n \n",
      "content_length": 2267,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 83,
      "content": "2.1. ARCHITECTURAL STYLES\n67\nhttps://s3.amazonaws.com/BucketName/ObjectName\nTo create a bucket, or an object for that matter, an application would essentially\nsend a PUT request with the URI of the bucket/object. In principle, the protocol\nthat is used with the service is HTTP. In other words, it is just another HTTP\nrequest, which will subsequently be correctly interpreted by S3. If the bucket\nor object already exists, an HTTP error message is returned.\nSimilarly, to know which objects are contained in a bucket, an application\nwould send a GET request with the URI of that bucket. S3 will return a list of\nobject names, again as an ordinary HTTP response.\nThe RESTful architecture has become popular because of its simplicity.\nPautasso et al. [2008] have compared RESTful services to service-specific\ninterfaces, and, as to be expected, they both have their advantages and dis-\nadvantages. In particular, the simplicity of RESTful architectures can easily\nprohibit easy solutions to intricate communication schemes. One example is\nwhere distributed transactions are needed, which generally requires that ser-\nvices keep track of the state of execution. On the other hand, there are many\nexamples in which RESTful architectures match perfectly a simple integration\nscheme of services, yet where the myriad of service interfaces will complicate\nmatters.\nNote 2.2 (Advanced: On interfaces)\nClearly, a service cannot be made easier or more difficult just because of the\nparticular interface it offers. A service offers functionality, and at best the way\nthat the service is accessed is determined by the interface. Indeed, one could\nargue that the discussion on RESTful versus service-specific interfaces is much\nabout access transparency. To better appreciate why so many people are paying\nattention to this issue, let us zoom in on the Amazon S3 service, which offers a\nREST interface as well as a more traditional interface (referred to as the SOAP\ninterface). The fact that the latter has been deprecated out says a lot.\nBucket operations\nObject operations\nListAllMyBuckets\nPutObjectInline\nCreateBucket\nPutObject\nDeleteBucket\nCopyObject\nListBucket\nGetObject\nGetBucketAccessControlPolicy\nGetObjectExtended\nSetBucketAccessControlPolicy\nDeleteObject\nGetBucketLoggingStatus\nGetObjectAccessControlPolicy\nSetBucketLoggingStatus\nSetObjectAccessControlPolicy\nFigure 2.8: The operations in Amazon’s S3 SOAP interface, by now\ndeprecated.\nThe SOAP interface consists of approximately 16 operations, listed in Fig-\nure 2.8. However, if we were to access Amazon S3 using the Python boto3 library,\nwe would have more than 100 operations available. In contrast, the REST interface\n \nDS 4.01\n",
      "content_length": 2683,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 84,
      "content": "68\nCHAPTER 2. ARCHITECTURES\noffers only very few operations, essentially those listed in Figure 2.7. Where do\nthese differences come from? The answer is, of course, in the parameter space. In\nthe case of RESTful architectures, an application will need to provide all that it\nwants through the parameters it passes by one of the operations. In Amazon’s\nSOAP interface, the number of parameters per operation is generally limited, and\nthis is certainly the case if we were to use the Python boto3 library.\nSticking to principles (so that we can avoid the intricacies of real code), suppose\nthat we have an interface bucket that offers an operation create, requiring an\ninput string such as mybucket, for creating a bucket with name “mybucket.”\nNormally, the operation would be called roughly as follows:\nimport bucket\nbucket.create(\"mybucket\")\nHowever, in a RESTful architecture, the call would need to be essentially encoded\nas a single string, such as\nPUT \"https://mybucket.s3.amazonsws.com/\"\nThe difference is striking. For example, in the first case, many syntactical errors\ncan often already be caught during compile time, whereas in the second case,\nchecking needs to be deferred until runtime.\nSecondly, one can argue that\nspecifying the semantics of an operation is much easier with specific interfaces\nthan with ones that offer only generic operations. On the other hand, with generic\noperations, changes are much easier to accommodate, as they would generally\ninvolve changing the layout of strings that encode what is actually required.\n2.1.3\nPublish-subscribe architectures\nAs systems continue to grow and processes can more easily join or leave, it\nbecomes important to have an architecture in which dependencies between\nprocesses become as loose as possible. A large class of distributed systems\nhave adopted an architecture in which there is a strong separation between\nprocessing and coordination. The idea is to view a system as a collection of\nautonomously operating processes. In this model, coordination encompasses\nthe communication and cooperation between processes. It forms the glue\nthat binds the activities performed by processes into a whole [Gelernter and\nCarriero, 1992].\nCabri et al. [2000] provide a taxonomy of coordination models that can\nbe applied equally to many types of distributed systems. Slightly adapting\ntheir terminology, we make a distinction between models along two different\ndimensions, temporal and referential, as shown in Figure 2.9.\nWhen processes are temporally and referentially coupled, coordination\ntakes place directly, referred to as direct coordination. The referential coupling\ngenerally appears in the form of explicit referencing in communication. For\nexample, a process can communicate only if it knows the name or identifier of\nDS 4.01\n \n",
      "content_length": 2800,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 85,
      "content": "2.1. ARCHITECTURAL STYLES\n69\nTemporally\nTemporally\ncoupled\ndecoupled\nReferentially\nDirect\nMailbox\ncoupled\nReferentially\nEvent-\nShared\ndecoupled\nbased\ndata space\nFigure 2.9: Examples of different forms of coordination.\nthe other processes it wants to exchange information with. Temporal coupling\nmeans that processes that are communicating will both have to be up and\nrunning. In real life, talking over cell phones (and assuming that a cell phone\nhas only one owner), is an example of direct communication.\nA different type of coordination occurs when processes are temporally de-\ncoupled, but referentially coupled, which we refer to as mailbox coordination.\nIn this case, there is no need for two communicating processes to be active\nat the same time to let communication take place. Instead, communication\ntakes place by putting messages in a (possibly shared) mailbox. Because it is\nnecessary to explicitly address the mailbox that will hold the messages that\nare to be exchanged, there is a referential coupling.\nThe combination of referentially decoupled and temporally coupled sys-\ntems form the group of models for event-based coordination. In referentially\ndecoupled systems, processes do not know each other explicitly. The only\nthing a process can do is publish a notification describing the occurrence of an\nevent (e.g., that it wants to coordinate activities, or that it just produced some\ninteresting results). Assuming that notifications come in all sorts and kinds,\nprocesses may subscribe to a specific kind of notification (see also [Mühl et al.,\n2006]). In an ideal event-based coordination model, a published notification\nwill be delivered exactly to those processes that have subscribed to it. However,\nit is generally required that the subscriber is up-and-running at the time the\nnotification was published.\nA well-known coordination model is the combination of referentially and\ntemporally decoupled processes, leading to what is known as a shared data\nspace. The key idea is that processes communicate entirely through tuples,\nwhich are structured data records consisting of several fields, very similar to a\nrow in a database table. Processes can put any type of tuple into the shared\ndata space. To retrieve a tuple, a process provides a search pattern that is\nmatched against the tuples. Any tuple that matches is returned.\nShared data spaces are thus seen to implement an associative search\nmechanism for tuples. When a process wants to extract a tuple from the data\nspace, it specifies (some of) the values of the fields it is interested in. Any\ntuple that matches that specification is then removed from the data space and\npassed to the process.\n \nDS 4.01\n",
      "content_length": 2687,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 86,
      "content": "70\nCHAPTER 2. ARCHITECTURES\nShared data spaces are often combined with event-based coordination: a\nprocess subscribes to certain tuples by providing a search pattern; when a\nprocess inserts a tuple into the data space, matching subscribers are notified. In\nboth cases, we are dealing with a publish-subscribe architecture, and indeed,\nthe key characteristic feature is that processes have no explicit reference to\neach other. The difference between a pure event-based architectural style , and\nthat of a shared data space, is shown in Figure 2.10. We have also shown an\nabstraction of the mechanism by which publishers and subscribers are matched,\nknown as an event bus.\n(a)\n(b)\nFigure 2.10: The (a) event-based and (b) shared data-space architectural style.\nNote 2.3 (Example: Linda tuple spaces)\nTo make matters a bit more concrete, we take a closer look at Linda, a program-\nming model developed in the 1980s [Carriero and Gelernter, 1989]. The shared\ndata space in Linda is known as a tuple space, which supports three operations:\n• in(t): remove a tuple that matches the template t\n• rd(t): obtain a copy of a tuple that matches the template t\n• out(t): add the tuple t to the tuple space\nNote that if a process would call out(t) twice in a row, we would find that two\ncopies of tuple t would have been stored. Formally, a tuple space is therefore\nalways modeled as a multiset. Both in and rd are blocking operations: the caller\nwill be blocked until a matching tuple is found, or has become available.\nConsider a simple microblog application in which messages are tagged with\nthe name of its poster and a topic, followed by a short string. Each message\nis modeled as a tuple <string,string,string> where the first string names the\nposter, the second string represents the topic, and the third one is the actual\ncontent. Assuming that we have created a shared data space called MicroBlog,\nFigure 2.11 shows how Alice and Bob can post messages to that space, and how\nDS 4.01\n \n",
      "content_length": 1981,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 87,
      "content": "2.1. ARCHITECTURAL STYLES\n71\nChuck can pick a (randomly selected) message. We have omitted some code for\nclarity. Note that neither Alice nor Bob knows who will read their postings.\n1 blog = linda.universe._rd((\"MicroBlog\",linda.TupleSpace))[1]\n2\n3 blog._out((\"bob\",\"distsys\",\"I am studying chap 2\"))\n4 blog._out((\"bob\",\"distsys\",\"The linda example’s pretty simple\"))\n5 blog._out((\"bob\",\"gtcn\",\"Cool book!\"))\n(a) Bob’s code for creating a microblog and posting three messages.\n1 blog = linda.universe._rd((\"MicroBlog\",linda.TupleSpace))[1]\n2\n3 blog._out((\"alice\",\"gtcn\",\"This graph theory stuff is not easy\"))\n4 blog._out((\"alice\",\"distsys\",\"I like systems more than graphs\"))\n(b) Alice’s code for creating a microblog and posting two messages.\n1 blog = linda.universe._rd((\"MicroBlog\",linda.TupleSpace))[1]\n2\n3 t1 = blog._rd((\"bob\",\"distsys\",str))\n4 t2 = blog._rd((\"alice\",\"gtcn\",str))\n5 t3 = blog._rd((\"bob\",\"gtcn\",str))\n(c) Chuck reading a message from Bob’s and Alice’s microblog.\nFigure 2.11: A simple example of using a shared data space.\nIn the first line of each code fragment, a process looks up the tuple space\nnamed “MicroBlog.” Bob posts three messages: two on topic distsys, and one on\ngtcn. Alice posts two messages, one on each topic. Chuck, finally, reads three\nmessages: one from Bob on distsys and one on gtcn, and one from Alice on gtcn.\nObviously, there is much room for improvement. For example, we should\nensure that Alice cannot post messages under Bob’s name. However, the important\nissue to note now, is that by providing only tags, a reader such as Chuck will\nbe able to pick up messages without needing to directly reference the poster. In\nparticular, Chuck could also read a randomly selected message on topic distsys\nthrough the statement\nt = blog_rd((str,\"distsys\",str))\nWe leave it as an exercise to the reader to extend the code fragments such that a\nnext message will be selected instead of a random one.\nAn important aspect of publish-subscribe systems is that communication\ntakes place by describing the events that a subscriber is interested in. As a\nconsequence, naming plays a crucial role. We return to naming later, but for\nnow, the important issue is that often, data items are not explicitly identified\nby senders and receivers.\nLet us first assume that events are described by a series of attributes.\nA notification describing an event is said to be published when it is made\n \nDS 4.01\n",
      "content_length": 2429,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 88,
      "content": "72\nCHAPTER 2. ARCHITECTURES\navailable for other processes to read. To that end, a subscription needs to\nbe passed to the middleware, containing a description of the event that the\nsubscriber is interested in. Such a description typically consists of some\n(attribute, value) pairs, which is common for so-called topic-based publish-\nsubscribe systems.\nAs an alternative, in content-based publish-subscribe systems, a sub-\nscription may also consist of (attribute, range) pairs. In this case, the specified\nattribute is expected to take on values within a specified range. Descriptions\ncan sometimes be given using all kinds of predicates formulated over the\nattributes, very similar in nature to SQL-like queries in the case of relational\ndatabases. Obviously, the more expressive a description is allowed to be, the\nmore difficult it will be to test whether an event matches a description.\nWe are now confronted with a situation in which subscriptions need to be\nmatched against notifications, as shown in Figure 2.12. Often, an event actually\ncorresponds to data becoming available. In that case, when matching succeeds,\nthere are two possible scenarios. In the first case, the middleware may decide\nto forward the published notification, along with the associated data, to its\ncurrent set of subscribers, that is, processes with a matching subscription. As\nan alternative, the middleware can also forward only a notification, at which\npoint subscribers can execute a read operation to retrieve the data item.\nFigure 2.12: The principle of exchanging data items between publishers and\nsubscribers.\nIn those cases, in which data associated with an event are immediately\nforwarded to subscribers, the middleware will generally not offer storage\nof data.\nStorage is either explicitly handled by a separate service, or is\nthe responsibility of subscribers. In other words, we have a referentially\ndecoupled, but temporally coupled system.\nThis situation is different when notifications are sent so that subscribers\nneed to explicitly read the associated data. Necessarily, the middleware will\nhave to store data items. In these situations, there are additional operations\nfor data management. It is also possible to attach a lease to a data item such\nthat when the lease expires that the data item is automatically deleted.\nDS 4.01\n \n",
      "content_length": 2331,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 89,
      "content": "2.2. MIDDLEWARE AND DISTRIBUTED SYSTEMS\n73\nEvents can easily complicate the processing of subscriptions. To illustrate,\nconsider a subscription such as “notify when room ZI.1060 is unoccupied and\nthe door is unlocked.” Typically, a distributed system supporting such sub-\nscriptions can be implemented by placing independent sensors for monitoring\nroom occupancy (e.g., motion sensors) and those for registering the status\nof a door lock. Following the approach sketched so far, we would need to\ncompose such primitive events into a publishable data item, to which processes\ncan then subscribe. Event composition turns out to be a difficult task, notably\nwhen the primitive events are generated from sources dispersed across the\ndistributed system.\nClearly, in publish-subscribe systems such as these, the crucial issue is the\nefficient and scalable implementation of matching subscriptions to notifica-\ntions. From the outside, the publish-subscribe architecture provides lots of\npotential for building very large-scale distributed systems due to the strong\ndecoupling of processes. On the other hand, devising scalable implementa-\ntions without losing this independence is not a trivial exercise, notably in\nthe case of content-based publish-subscribe systems. In this sense, although\nmany claim that the publish-subscribe style offers the path toward scalable\narchitectures, the fact is that implementations may easily form a bottleneck,\ncertainly when security and privacy is at stake, as we will discuss in Chapter 9\nand later in Chapter 5.\n2.2\nMiddleware and distributed systems\nTo assist the development of distributed applications, distributed systems are\noften organized to have a separate layer of software that is logically placed on\ntop of the respective operating systems of the computers that are part of the\nFigure 2.13: A distributed system organized in a middleware layer, which\nextends over multiple machines, offering each application the same interface.\n \nDS 4.01\n",
      "content_length": 1984,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 90,
      "content": "74\nCHAPTER 2. ARCHITECTURES\nsystem. This organization is shown in Figure 2.13, leading to what is known\nas middleware [Bernstein, 1996].\nFigure 2.13 shows four networked computers and three applications, of\nwhich application B is distributed across computers 2 and 3. Each application\nis offered the same interface. The distributed system provides the means for\ncomponents of a single distributed application to communicate with each\nother, but also to let different applications communicate. At the same time,\nit hides, as best and reasonably as possible, the differences in hardware and\noperating systems from each application.\nIn a sense, middleware is the same to a distributed system as what an\noperating system is to a computer: a manager of resources offering its ap-\nplications to efficiently share and deploy those resources across a network.\nNext to resource management, it offers services that can also be found in most\noperating systems, including:\n• Facilities for interapplication communication.\n• Security services.\n• Accounting services.\n• Masking of and recovery from failures.\nThe main difference with their operating-system equivalents, is that middle-\nware services are offered in a networked environment. Note also that most\nservices are useful to many applications. In this sense, middleware can also\nbe viewed as a container of commonly used components and functions that\nnow no longer have to be implemented by applications separately.\nNote 2.4 (Historical note: The term middleware)\nAlthough the term middleware became popular in the mid 1990s, it was most\nlikely mentioned for the first time in a report on a NATO software engineering\nconference, edited by Peter Naur and Brian Randell in October 1968 [Naur and\nRandell, 1968]. Indeed, middleware was placed precisely between applications\nand service routines (the equivalent of operating systems).\n2.2.1\nMiddleware organization\nLet us now zoom into the actual organization of middleware. There are two\nimportant types of design patterns that are often applied to the organization of\nmiddleware: wrappers and interceptors. Each targets different problems, yet\naddresses the same goal for middleware: achieving openness (as we discussed\nin Section 1.2.3).\nDS 4.01\n \n",
      "content_length": 2241,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 91,
      "content": "2.2. MIDDLEWARE AND DISTRIBUTED SYSTEMS\n75\nWrappers\nWhen building a distributed system out of existing components, we immedi-\nately bump into a fundamental problem: the interfaces offered by the legacy\ncomponent are most likely not suitable for all applications. In Section 1.3.2 we\ndiscussed how enterprise application integration could be established through\nmiddleware as a communication facilitator, but there we still implicitly as-\nsumed that, in the end, components could be accessed through their native\ninterfaces.\nA wrapper or adapter is a special component that offers an interface\nacceptable to a client application, of which the functions are transformed\ninto those available at the component. In essence, it solves the problem of\nincompatible interfaces (see also Gamma et al. [1994]).\nAlthough originally narrowly defined in the context of object-oriented\nprogramming, in the context of distributed systems wrappers are much more\nthan simple interface transformers. For example, an object adapter is a\ncomponent that allows applications to invoke remote objects, although those\nobjects may have been implemented as a combination of library functions\noperating on the tables of a relational database.\nAs another example, reconsider Amazon’s S3 storage service. As men-\ntioned, there are two types of interfaces available, one adhering to a RESTful\narchitecture, another following a more traditional approach. For the RESTful\ninterface, clients will be using the HTTP protocol, essentially communicating\nwith a traditional Web server which now acts as an adapter to the actual stor-\nage service, by partly dissecting incoming requests and subsequently handing\nthem off to specialized servers internal to S3.\nWrappers have always played an important role in extending systems with\nexisting components. Extensibility, which is crucial for achieving openness,\nused to be addressed by adding wrappers as needed. In other words, if\nan application A managed data that was needed by an application B, one\napproach would be to develop a wrapper specific for B so that it could\nhave access to A’s data. Clearly, this approach does not scale well: with N\napplications we would, in theory, need to develop N × (N −1) = O(N2)\nwrappers.\nAgain, facilitating a reduction of the number of wrappers is typically\ndone through middleware. One way of doing this is implementing a so-\ncalled broker, which is logically a centralized component that handles all\nthe accesses between different applications. An often-used type is a message\nbroker of which we discuss the technicalities in Section 4.3.3. In the case of a\nmessage broker, applications simply send requests to the broker containing\ninformation on what they need. The broker, having knowledge of all relevant\napplications, contacts the appropriate applications, possibly combines and\ntransforms the responses and returns the result to the initial application. In\nprinciple, because a broker offers a single interface to each application, we\n \nDS 4.01\n",
      "content_length": 3003,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 92,
      "content": "76\nCHAPTER 2. ARCHITECTURES\n(a)\n(b)\nFigure 2.14: (a) Requiring each application to have a wrapper for each other\napplication. (b) Reducing the number of wrappers by making use of a broker.\nnow need at most 2N = O(N) wrappers instead of O(N2). This situation is\nsketched in Figure 2.14.\nInterceptors\nConceptually, an interceptor is nothing but a software construct that will\nbreak the usual flow of control and allow other (application specific) code\nto be executed. Interceptors are a primary means for adapting middleware\nto the specific needs of an application. As such, they play an important role\nin making middleware open. To make interceptors generic may require a\nsubstantial implementation effort, as illustrated by Schmidt et al. [2000], and it\nis unclear whether in such cases generality should be preferred over restricted\napplicability and simplicity. Furthermore, often having only limited intercep-\ntion facilities will improve management of the software and the distributed\nsystem as a whole.\nTo make matters concrete, consider interception as supported in many\nobject-based distributed systems. The basic idea is simple: an object A can call\na method that belongs to an object B, while the latter resides on a different\nmachine than A. As we explain in detail later in the book, such a remote-object\ninvocation is carried out in three steps:\n1. Object A is offered a local interface that is the same as the interface\noffered by object B. A calls the method available in that interface.\n2. The call by A is transformed into a generic object invocation, made\npossible through a general object-invocation interface offered by the\nmiddleware at the machine where A resides.\n3. Finally, the generic object invocation is transformed into a message that\nis sent through the transport-level network interface as offered by A’s\nlocal operating system.\nDS 4.01\n \n",
      "content_length": 1869,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 93,
      "content": "2.2. MIDDLEWARE AND DISTRIBUTED SYSTEMS\n77\nFigure 2.15: Using interceptors to handle remote-object invocations.\nThis scheme is shown in Figure 2.15. After the first step, the call B.doit(val)\nis transformed into a generic call, such as invoke(B,&doit,val) with a ref-\nerence to B’s method and the parameters that go along with the call. Now\nimagine that object B is replicated. In that case, each replica should actu-\nally be invoked. This is a clear point where interception can help. What\nthe request-level interceptor will do, is simply call invoke(B,&doit,val) for\neach of the replicas. The beauty of this all is that the object A need not be\naware of the replication of B, but also the object middleware need not have\nspecial components that deal with this replicated call. Only the request-level\ninterceptor, which may be added to the middleware, needs to know about B’s\nreplication.\nIn the end, a call to a remote object will have to be sent over the network.\nIn practice, this means that the messaging interface as offered by the local\noperating system will need to be invoked. At that level, a message-level\ninterceptor may assist in transferring the invocation to the target object. For\nexample, imagine that the parameter val actually corresponds to a huge array\nof data. In that case, it may be wise to fragment the data into smaller parts to\nhave it assembled again at the destination. Such a fragmentation may improve\nperformance or reliability. Again, the middleware need not be aware of this\nfragmentation; the lower-level interceptor will transparently handle the rest of\nthe communication with the local operating system.\n \nDS 4.01\n",
      "content_length": 1650,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 94,
      "content": "78\nCHAPTER 2. ARCHITECTURES\n2.2.2\nModifiable middleware\nWhat wrappers and interceptors offer are means to extend and adapt the\nmiddleware. The need for adaptation comes from the fact that the environment\nin which distributed applications are executed changes continuously. Changes\ninclude those resulting from mobility, a strong variance in the quality-of-\nservice of networks, failing hardware, and battery drainage, among others.\nRather than making applications responsible for reacting to changes, this task\nis placed in the middleware. Moreover, as the size of a distributed system\nincreases, changing its parts can rarely be done by temporarily shutting it\ndown. What is needed is being able to make changes on-the-fly.\nThese strong influences from the environment have brought many de-\nsigners of middleware to consider the construction of adaptive software. We\nfollow Parlavantzas and Coulson [2007] in speaking of modifiable middle-\nware to express that middleware may not only need to be adaptive, but that\nwe should be able to purposefully modify it without bringing it down. In\nthis context, interceptors can be thought of offering a means to adapt the\nstandard flow of control. Replacing software components at runtime is an\nexample of modifying a system. And indeed, perhaps one of the most popular\napproaches toward modifiable middleware is that of dynamically constructing\nmiddleware from components.\nComponent-based design focuses on supporting modifiability through\ncomposition. A system may either be configured statically at design time,\nor dynamically at runtime.\nThe latter requires support for late binding,\na technique that has been successfully applied in programming language\nenvironments, but also for operating systems where modules can be loaded\nand unloaded at will. Automatically selecting the best implementation of\na component during runtime is by now well understood [Yellin, 2003] but\nagain, the process remains complex for distributed systems, especially when\nconsidering that replacement of one component requires to know exactly what\nthe effect of that replacement on other components will be. Often, components\nare less independent as one may think.\nThe bottom line is that to accommodate dynamic changes to the software\nthat makes up middleware, we need at least basic support to load and unload\ncomponents at runtime. In addition, for each component explicit specifications\nof the interfaces it offers, as well the interfaces it requires, are needed. If state\nis maintained between calls to a component, then further special measures\nare needed. By-and-large, it should be clear that organizing middleware to be\nmodifiable requires special attention.\n2.3\nLayered-system architectures\nLet us now take a look at how many distributed systems are actually organized\nby considering where software components are placed. Deciding on software\nDS 4.01\n \n",
      "content_length": 2886,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 95,
      "content": "2.3. LAYERED-SYSTEM ARCHITECTURES\n79\ncomponents, their interaction, and their placement leads to an instance of a\nsoftware architecture, also known as a system architecture [Bass et al., 2021].\nWe start with discussing layered architectures. Other forms follow later.\nDespite the lack of consensus on many distributed systems issues, there\nis one issue that many researchers and practitioners agree upon: thinking in\nterms of clients that request services from servers helps to understand and\nmanage the complexity of distributed systems [Saltzer and Kaashoek, 2009].\nIn the following, we first consider a simple layered organization, followed by\nlooking at multi-layered organizations.\n2.3.1\nSimple client-server architecture\nIn the basic client-server model, processes in a distributed system are divided\ninto two (possibly overlapping) groups. A server is a process implementing\na specific service, for example, a file system service or a database service. A\nclient is a process that requests a service from a server by sending it a request\nand subsequently waiting for the server’s reply. This client-server interaction,\nalso known as request-reply behavior is shown in Figure 2.16.\nFigure 2.16: General interaction between a client C and a server S. C sends\nthe operation oper and waits for the response from S.\nCommunication between a client and a server can be implemented by a\nsimple connectionless protocol when the underlying network is fairly reliable,\nas in many local-area networks. In these cases, when a client requests a service,\nit simply packages a message for the server, identifying the service it wants,\nalong with the necessary input data. The message is then sent to the server.\nThe latter, in turn, will always wait for an incoming request, subsequently\nprocess it, and package the results in a reply message that is then sent to the\nclient.\nUsing a connectionless protocol has the obvious advantage of being effi-\ncient. As long as messages do not get lost or corrupted, the request/reply\nprotocol just sketched works fine. Unfortunately, making the protocol resistant\nto occasional transmission failures is not trivial. The only thing we can do is\npossibly let the client resend the request when no reply message comes in. The\nproblem, however, is that the client cannot detect whether the original request\nmessage was lost, or that transmission of the reply failed. If the reply was lost,\nthen resending a request may result in performing the operation twice. If the\n \nDS 4.01\n",
      "content_length": 2504,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 96,
      "content": "80\nCHAPTER 2. ARCHITECTURES\noperation was something like “transfer $10,000 from my bank account,” then\nclearly, it would have been better that we simply reported an error instead.\nOn the other hand, if the operation was “tell me how much money I have left,”\nit would be perfectly acceptable to resend the request. When an operation\ncan be repeated multiple times without harm, it is said to be idempotent.\nSince some requests are idempotent and others are not, it should be clear that\nthere is no single solution for dealing with lost messages. We defer a detailed\ndiscussion on handling transmission failures to Section 8.3.\nAs an alternative, many client-server systems use a reliable connection-\noriented protocol. Although this solution is not entirely appropriate in a\nlocal-area network due to relatively low performance, it works perfectly fine\nin wide-area systems in which communication is inherently unreliable. For\nexample, virtually all Internet application protocols are based on reliable\nTCP/IP connections. In this case, whenever a client requests a service, it first\nsets up a connection to the server before sending the request. The server\ngenerally uses that same connection to send the reply message, after which\nthe connection is torn down. The trouble may be that setting up and tearing\ndown a connection is relatively costly, especially when the request and reply\nmessages are small.\nThe client-server model has been subject to many debates and controver-\nsies over the years. One of the main issues was how to draw a clear distinction\nbetween a client and a server. Not surprisingly, there is often no clear distinc-\ntion. For example, a server for a distributed database may continuously act as\na client because it is forwarding requests to different file servers responsible\nfor implementing the database tables. In such a case, the database server itself\nonly processes the queries.\n2.3.2\nMultitiered Architectures\nThe distinction into three logical levels, as discussed so far, suggests sev-\neral possibilities for physically distributing a client-server application across\nseveral machines. The simplest organization is to have only two types of\nmachines:\n1. A client machine containing only the programs implementing (part of)\nthe user-interface level\n2. A server machine containing the rest, that is, the programs implementing\nthe processing and data level\nIn this organization everything is handled by the server while the client is\nessentially no more than a dumb terminal, possibly with only a convenient\ngraphical interface. There are, however, many other possibilities. As explained\nin Section 2.1.1, many distributed applications are divided into three layers:\n(1) a user-interface layer, (2) a processing layer, and (3) a data layer. One\nDS 4.01\n \n",
      "content_length": 2785,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 97,
      "content": "2.3. LAYERED-SYSTEM ARCHITECTURES\n81\napproach for organizing clients and servers is then to distribute these layers\nacross different machines, as shown in Figure 2.17 (see also Umar [1997]).\nAs a first step, we make a distinction between only two kinds of machines:\nclient machines and server machines, leading to what is also referred to as a\n(physically) two-tiered architecture.\nUser interface\nUser interface\nUser interface\nApplication\nUser interface\nApplication\nUser interface\nApplication\nDatabase\nn\noit\na\ncilp\np\nA\nn\noit\na\ncilp\np\nA\nn\noit\na\ncilp\np\nA\nDatabase\nDatabase\nDatabase\nDatabase\nDatabase\nUser interface\nClient machine\nServer machine\n(a)\n(b)\n(c)\n(d)\n(e)\nFigure 2.17: Client-server organizations in a two-tiered architecture.\nOne possible organization is to have only the terminal-dependent part\nof the user interface on the client machine, as shown in Figure 2.17(a), and\ngive the applications remote control over the presentation of their data. An\nalternative is to place the entire user-interface software on the client side, as\nshown in Figure 2.17(b). In such cases, we essentially divide the application\ninto a graphical front end, which communicates with the rest of the application\n(residing at the server) through an application-specific protocol. In this model,\nthe front end (the client software) does no processing other than necessary for\npresenting the application’s interface.\nContinuing along this line of reasoning, we may also move part of the\napplication to the front end, as shown in Figure 2.17(c). An example where\nthis makes sense is where the application makes use of a form that needs to\nbe filled in entirely before it can be processed. The front end can then check\nthe correctness and consistency of the form, and where necessary interact\nwith the user. Another example of the organization of Figure 2.17(c), is that of\na word processor in which the basic editing functions execute on the client\nside where they operate on locally cached, or in-memory data, but where the\nadvanced support tools such as checking the spelling and grammar execute\non the server side.\nIn many client-server environments, the organizations shown in Fig-\nure 2.17(d) and Figure 2.17(e) are particularly popular. These organizations\nare used where the client machine is a PC or workstation, connected through\na network to a distributed file system or database. Essentially, most of the\n \nDS 4.01\n",
      "content_length": 2408,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 98,
      "content": "82\nCHAPTER 2. ARCHITECTURES\napplication is running on the client machine, but all operations on files or\ndatabase entries go to the server. For example, many banking applications\nrun on an end-user’s machine, where the user prepares transactions and such.\nOnce finished, the application contacts the database on the bank’s server and\nuploads the transactions for further processing. Figure 2.17(e) represents the\nsituation where the client’s local disk contains part of the data. For example,\nwhen browsing the Web, a client can gradually build a huge cache on local\ndisk of most recent inspected Web pages.\nNote 2.5 (More information: Is there something like the best organization?)\nWe note that there has been a strong trend to move away from the configurations\nshown in Figure 2.17(d) and Figure 2.17(e) in those cases, that client software is\nplaced at end-user machines. Instead, most of the processing and data storage\nis handled at the server side. The reason for this is simple: although client\nmachines do a lot, they are also more problematic to manage. Having more\nfunctionality on the client machine means that a wide range of end users will\nneed to be able to handle that software. This implies that more effort needs to\nbe spent on making software resilient to end-user behavior. In addition, client-\nside software is dependent on the client’s underlying platform (i.e., operating\nsystem and resources), which can easily mean that multiple versions will need\nto be maintained. From a systems-management perspective, having what are\ncalled fat clients is not optimal. Instead, the thin clients as represented by the\norganizations shown in Figure 2.17(a)–(c) are much easier, perhaps at the cost of\nless sophisticated user interfaces and client-perceived performance.\nDoes this mean the end of fat clients? Not in the least. For one thing, there\nare many applications for which a fat-client organization is often still the best. We\nalready mentioned office suites, but also many multimedia applications require\nthat processing is done on the client’s side. Moreover, when end users need\nto operate offline, we see that installing applications will be necessary. Second,\nwith the advent of advanced Web browsing technology, it is now much easier\nto dynamically place and manage client-side software by simply uploading (the\nsometimes very sophisticated) scripts to the client.\nCombined with the fact\nthat this type of client-side software runs in well-defined commonly deployed\nenvironments, and thus that platform dependency is much less of an issue, we\nsee that the counter-argument of management complexity is often no longer\nvalid. This has led to the deployment of virtual desktop environments, which we\ndiscuss further in Chapter 3.\nFinally, note that moving away from fat clients does not imply that we no\nlonger need distributed systems. On the contrary, what we continue to see is\nthat server-side solutions are becoming increasingly more distributed as a single\nserver is being replaced by multiple servers running on different machines. Cloud\ncomputing is a good example in this case: the complete server side is being\nexecuted in data centers, and generally on multiple servers.\nWhen distinguishing only client and server machines as we did so far, we\nmiss the point that a server may sometimes need to act as a client, as shown\nDS 4.01\n \n",
      "content_length": 3362,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 99,
      "content": "2.3. LAYERED-SYSTEM ARCHITECTURES\n83\nin Figure 2.18, leading to a (physically) three-tiered architecture.\nFigure 2.18: An example of an application server AS acting as client for a\ndatabase server DS.\nIn this architecture, traditionally programs that form part of the process-\ning layer are executed by a separate server, but may additionally be partly\ndistributed across the client and server machines. A typical example of where\na three-tiered architecture is used is in transaction processing. A separate\nprocess, called the transaction processing monitor, coordinates all transactions\nacross possibly different data servers.\nAnother, but very different example where we often see a three-tiered\narchitecture is in the organization of Websites. In this case, a Web server\nacts as an entry point to a site, passing requests to an application server\nwhere the actual processing takes place. This application server, in turn,\ninteracts with a database server. We already came across such an organization\nwhen discussing this book’s Website and the facilities for generating and\ndownloading a personalized copy.\n2.3.3\nExample: The Network File System\nMany distributed files systems are organized like client-server architectures,\nwith Sun Microsystem’s Network File System (NFS) being one of the most\nwidely deployed ones for Unix systems [Callaghan, 2000; Haynes, 2015;\nNoveck and Lever, 2020].\nThe basic idea behind NFS is that each file server provides a standardized\nview of its local file system. In other words, it should not matter how that\nlocal file system is implemented; each NFS server supports the same model.\nThis approach has been adopted for other distributed files systems as well.\nNFS comes with a communication protocol that allows clients to access the\nfiles stored on a server, thus allowing a heterogeneous collection of processes,\npossibly running on different operating systems and machines, to share a\ncommon file system.\nThe model underlying NFS and similar systems is that of a remote file\nservice. In this model, clients are offered transparent access to a file system\nthat is managed by a remote server. However, clients are normally unaware\n \nDS 4.01\n",
      "content_length": 2180,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 100,
      "content": "84\nCHAPTER 2. ARCHITECTURES\nof the actual location of files. Instead, they are offered an interface to a file\nsystem that is similar to the interface offered by a conventional local file\nsystem. In particular, the client is offered only an interface containing various\nfile operations, but the server is responsible for implementing those operations.\nThis model is therefore also referred to as the remote access model. It is\nshown in Figure 2.19(a).\nClient\nClient\nFile stays\non server\nServer\nServer\nRequests from\nclient to access\nremote file\n1. File moved to client\n3. When client is done,\nfile is returned to\nserver\n2. Accesses are\ndone on client\nOld file\nNew file\n(a)\n(b)\nFigure 2.19: (a) The remote access model. (b) The upload/download model.\nIn contrast, in the upload/download model a client accesses a file locally\nafter having downloaded it from the server, as shown in Figure 2.19(b) When\nthe client is finished with the file, it is uploaded back to the server again so\nthat it can be used by another client. The Internet’s FTP service can be used\nthis way when a client downloads a complete file, modifies it, and then puts\nit back.\nNFS has been implemented for numerous operating systems, although the\nUnix versions are predominant. For virtually all modern Unix systems, NFS\nis generally implemented following the architecture shown in Figure 2.20.\nA client accesses the file system using the system calls provided by its local\noperating system. However, the local Unix file system interface is replaced\nby an interface to the Virtual File System (VFS), which by now is a de facto\nstandard for interfacing to different (distributed) file systems [Kleiman, 1986].\nVirtually all modern operating systems provide VFS, and not doing so more\nor less forces developers to largely reimplement huge parts of an operating\nsystem when adopting a new file-system structure. With NFS, operations on\nthe VFS interface are either passed to a local file system, or passed to a separate\ncomponent known as the NFS client, which takes care of handling access to\nfiles stored at a remote server. In NFS, all client-server communication is done\nthrough so-called remote procedure calls (RPCs). As mentioned before, an\nRPC is essentially a standardized way to let a client on a machine A make an\nordinary call to a procedure that is implemented on another machine B. We\ndiscuss RPCs extensively in Chapter 4. The NFS client implements the NFS\nfile system operations as remote procedure calls to the server. Note that the\noperations offered by the VFS interface can be different from those offered by\nDS 4.01\n \n",
      "content_length": 2603,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 101,
      "content": "2.3. LAYERED-SYSTEM ARCHITECTURES\n85\nVirtual file system\n(VFS) layer\nVirtual file system\n(VFS) layer\nSystem call layer\nSystem call layer\nNFS client\nRPC client\nstub\nRPC server\nstub\nNFS server\nLocal file\nsystem interface\nLocal file\nsystem interface\nNetwork\nClient\nServer\nFigure 2.20: The basic NFS architecture for Unix systems.\nthe NFS client. The whole idea of the VFS is to hide the differences between\nvarious file systems.\nOn the server side, we see a similar organization. The NFS server is\nresponsible for handling incoming client requests. The RPC component at\nthe server converts incoming requests to regular VFS file operations that\nare subsequently passed to the VFS layer. Again, the VFS is responsible for\nimplementing a local file system in which the actual files are stored.\nAn important advantage of this scheme is that NFS is largely independent\nof local file systems. It does not matter whether the operating system at the\nclient or server uses a Unix file system, a Windows file system, or even an old\nMS-DOS file system. The only important issue is that these file systems are\ncompliant with the file system model offered by NFS. For example, MS-DOS\nwith its short file names cannot be used to implement an NFS server in a fully\ntransparent way.\n2.3.4\nExample: The Web\nThe architecture of Web-based distributed systems is not fundamentally dif-\nferent from other distributed systems. However, it is interesting to see how\nthe initial idea of supporting distributed documents has evolved since its in-\nception in the 1990s. Documents turned from being purely static and passive\nto dynamically generated content. Furthermore, recently, many organizations\nhave begun supporting services instead of just documents.\nSimple Web-based systems\nMany Web-based systems are still organized as relatively simple client-server\narchitectures. The core of a Web site is formed by a process that has access to a\n \nDS 4.01\n",
      "content_length": 1924,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 102,
      "content": "86\nCHAPTER 2. ARCHITECTURES\nlocal file system storing documents. The simplest way to refer to a document\nis by a reference called a uniform resource locator (URL). It specifies where\na document is located by embedding the DNS name of its associated server\nalong with a file name by which the server can look up the document in its\nlocal file system. Furthermore, a URL specifies the application-level protocol\nfor transferring the document across the network.\nA client interacts with Web servers through a browser, which is responsible\nfor properly displaying a document. Furthermore, a browser accepts input\nfrom a user mostly by letting the user select a reference to another document,\nwhich it then subsequently fetches and displays. The communication between\na browser and Web server is standardized: they both adhere to the HyperText\nTransfer Protocol (HTTP). This leads to the overall organization shown in\nFigure 2.21.\nFigure 2.21: The overall organization of a traditional Web site.\nLet us zoom in a bit into what a document actually is. Perhaps the simplest\nform is a standard text file. In that case, the server and browser have barely\nanything to do: the server copies the file from the local file system and\ntransfers it to the browser. The latter, in turn, merely displays the content of\nthe file ad verbatim without further ado.\nMore interesting are Web documents that have been marked up, which is\nusually done in the HyperText Markup Language, or simply HTML. In that\ncase, the document includes various instructions expressing how its content\nshould be displayed, similar to what one can expect from any decent word-\nprocessing system (although those instructions are normally hidden from the\nend user). For example, instructing text to be emphasized is done by the\nfollowing markup:\n<emph>Emphasize this text</emph>\nThere are many more of such markup instructions. The point is that the\nbrowser understands these instructions and will act accordingly when dis-\nplaying the text.\nDS 4.01\n \n",
      "content_length": 2007,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 103,
      "content": "2.3. LAYERED-SYSTEM ARCHITECTURES\n87\nDocuments can contain much more than just markup instructions. In\nparticular, they can have complete programs embedded, of which JavaScript\nis the one most often deployed. In this case, the browser is warned that there\nis some code to execute as in:\n<script type=”text/javascript”>....</script>\nand as long as the browser has an appropriate embedded interpreter for the\nspecified language, everything between “<script>” and “</script>” will be\nexecuted as any other program. The main benefit of including scripts is that\nit allows for much better interaction with the end user, including sending\ninformation back to the server. (The latter, by the way, has always been\nsupported in HTML through forms.)\nMuch more can be said about Web documents, but this is not the place to\ndo so. A good introduction on how to build Web-based applications can be\nfound in [Sebesta, 2015].\nMultitiered architectures\nThe Web started out as the relatively simple two-tiered client-server system\nshown in Figure 2.21. By now, this simple architecture has been extended to\nsupport much more sophisticated means of documents. In fact, one could\njustifiably argue that the term “document” is no longer appropriate. For one,\nmost things that we get to see in our browser has been generated on the spot\nas the result of sending a request to a Web server. Content is stored in a\ndatabase at the server’s side, along with client-side scripts and such, to be\ncomposed on-the-fly into a document which is then subsequently sent to the\nclient’s browser. Documents have thus become completely dynamic.\nOne of the first enhancements to the basic architecture was support for\nsimple user interaction by the Common Gateway Interface or simply CGI.\nCGI defines a standard way by which a Web server can execute a program\ntaking user data as input. Usually, user data come from an HTML form; it\nspecifies the program that is to be executed at the server side, along with\nparameter values that are filled in by the user. Once the form has been\ncompleted, the program’s name and collected parameter values are sent to\nthe server, as shown in Figure 2.22.\nWhen the server sees the request, it starts the program named in the\nrequest and passes it the parameter values. At that point, the program simply\ndoes its work and generally returns the results in the form of a document that\nis sent back to the user’s browser to be displayed.\nCGI programs can be as sophisticated as a developer wants. For example,\nas shown in Figure 2.22 many programs operate on a database local to the\nWeb server. After processing the data, the program generates an HTML\ndocument and returns that document to the server. The server will then pass\nthe document to the client. An interesting observation is that to the server,\n \nDS 4.01\n",
      "content_length": 2810,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 104,
      "content": "88\nCHAPTER 2. ARCHITECTURES\nFigure 2.22: The principle of using server-side CGI programs.\nit appears as if it is asking the CGI program to fetch a document. In other\nwords, the server does nothing but delegate the fetching of a document to an\nexternal program.\nThe main task of a server used to be handling client requests by simply\nfetching documents. With CGI programs, fetching a document could be\ndelegated in such a way that the server would remain unaware of whether\na document had been generated on the fly, or actually read from the local\nfile system. Note that we have just described a two-tiered organization of\nserver-side software.\nHowever, servers nowadays do much more than just fetching documents.\nOne of the most important enhancements is that servers can also process a\ndocument before passing it to the client. In particular, a document may contain\na server-side script, which is executed by the server when the document has\nbeen fetched locally. The result of executing a script is sent along with the\nrest of the document to the client. The script itself is not sent. In other words,\nusing a server-side script changes a document by essentially replacing the\nscript with the results of its execution. To make matters concrete, take a look\nat a simple example of dynamically generating a document. Assume a file is\nstored at the server with the following content:\n<strong> <?php echo $_SERVER[’REMOTE_ADDR’]; ?> </strong>\nThe server will examine the file and subsequently process the PHP code (be-\ntween “<?php” and “?>”) replacing the code with the address of the requesting\nclient. Much more sophisticated settings are possible, such as accessing a\nlocal database and subsequently fetching content from that database to be\ncombined with other dynamically generated content.\n2.4\nSymmetrically distributed system architectures\nMultitiered client-server architectures are a direct consequence of dividing\ndistributed applications into a user interface, processing components, and\nDS 4.01\n \n",
      "content_length": 2008,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 105,
      "content": "2.4. SYMMETRICALLY DISTRIBUTED SYSTEM ARCHITECTURES\n89\ndata-management components. The different tiers correspond directly with\nthe logical organization of applications. In many business environments,\ndistributed processing is equivalent to organizing a client-server application\nas a multitiered architecture. We refer to this type of distribution as vertical\ndistribution. The characteristic feature of vertical distribution is that it is\nachieved by placing logically different components on different machines. The\nterm is related to the concept of vertical fragmentation as used in distributed\nrelational databases, where it means that tables are split columnwise, and\nsubsequently distributed across multiple machines [Özsu and Valduriez, 2020].\nAgain, from a systems-management perspective, having a vertical distri-\nbution can help: functions are logically and physically split across multiple\nmachines, where each machine is tailored to a specific group of functions.\nHowever, vertical distribution is only one way of organizing client-server\napplications. In modern architectures, it is often the distribution of the clients\nand the servers that counts, which we refer to as horizontal distribution. In\nthis type of distribution, a client or server may be physically split up into\nlogically equivalent parts, but each part is operating on its own share of the\ncomplete data set, thus balancing the load. In this section, we will take a look\nat a class of modern system architectures that support horizontal distribution,\nknown as peer-to-peer systems.\nFrom a high-level perspective, the processes that constitute a peer-to-peer\nsystem are all equal. This means that the functions that need to be carried\nout are represented by every process that constitutes the distributed system.\nAs a consequence, much of the interaction between processes is symmetric:\neach process will act as a client and a server at the same time (which is also\nreferred to as acting as a servant).\nGiven this symmetric behavior, peer-to-peer architectures revolve around\nthe question of how to organize the processes in an overlay network [Tarkoma,\n2010]: a network in which the nodes are formed by the processes and the links\nrepresent the possible communication channels (which are often realized as\nTCP connections). A node may not be able to communicate directly with an\narbitrary other node, but is required to send messages through the available\ncommunication channels. Two types of overlay networks exist: those that are\nstructured and those that are not. These two types are surveyed extensively\nin Lua et al. [2005] along with numerous examples. Buford and Yu [2010]\nadditionally includes an extensive list of various peer-to-peer systems. Aberer\net al. [2005] provide a reference architecture that allows for a more formal\ncomparison of the different types of peer-to-peer systems. A survey taken from\nthe perspective of content distribution is provided by Androutsellis-Theotokis\nand Spinellis [2004]. Finally, Buford et al. [2009], Tarkoma [2010] and Vu et al.\n[2010] go beyond the level of surveys and form adequate textbooks for initial\nor further study.\n \nDS 4.01\n",
      "content_length": 3163,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 106,
      "content": "90\nCHAPTER 2. ARCHITECTURES\n2.4.1\nStructured peer-to-peer systems\nAs its name suggests, in a structured peer-to-peer system the nodes (i.e.,\nprocesses) are organized in an overlay that adheres to a specific, deterministic\ntopology: a ring, a binary tree, a grid, etc. This topology is used to efficiently\nlook up data. Characteristic for structured peer-to-peer systems, is that they\nare generally based on using a so-called semantic-free index. What this means\nis that each data item that is to be maintained by the system, is uniquely\nassociated with a key, and that this key is subsequently used as an index. To\nthis end, it is common to use a hash function so that we get:\nkey(data item) = hash(data item’s value).\nThe peer-to-peer system as a whole is now responsible for storing (key,value)\npairs. To this end, each node is assigned an identifier from the same set\nof all possible hash values, and each node is made responsible for storing\ndata associated with a specific subset of keys. In essence, the system is\nthus seen to implement a distributed hash table, generally abbreviated to a\nDHT [Balakrishnan et al., 2003].\nFollowing this approach now reduces the essence of structured peer-to-\npeer systems to being able to look up a data item by its key. That is, the\nsystem provides an efficient implementation of a function lookup that maps a\nkey to an existing node:\nexisting node = lookup(key).\nThis is where the topology of a structured peer-to-peer system plays a crucial\nrole. Any node can be asked to look up a given key, which then boils down to\nefficiently routing that lookup request to the node responsible for storing the\ndata associated with the given key.\nTo clarify these matters, let us consider a simple peer-to-peer system with\na fixed number of nodes, organized into a hypercube. A hypercube is an\nn-dimensional cube. The hypercube shown in Figure 2.23 is four-dimensional.\nIt can be thought of as two ordinary cubes, each with 8 vertices and 12 edges.\nTo expand the hypercube to five dimensions, we would add another set of\ntwo interconnected cubes to the figure, connect the corresponding edges in\nthe two halves, and so on.\nFor this (admittedly naive) system, each data item is associated with one\nof the 16 nodes. This can be achieved by hashing the value of a data item to a\nkey k ∈{0, 1, 2, . . . , 24 −1}. Now suppose that the node with identifier 0111\nis requested to look up the data having key 14, corresponding to the binary\nvalue 1110. In this example, we assume that the node with identifier 1110 is\nresponsible for storing all data items that have key 14. What node 0111 can\nsimply do, is forward the request to a neighbor who is closer to node 1110. In\nthis case, this is either node 0110 or node 1111. If it picks a node 0110, that\nDS 4.01\n \n",
      "content_length": 2785,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 107,
      "content": "2.4. SYMMETRICALLY DISTRIBUTED SYSTEM ARCHITECTURES\n91\nFigure 2.23: A simple peer-to-peer system organized as a four-dimensional\nhypercube.\nnode will then forward the request directly to a node 1110 from where the\ndata can be retrieved.\nNote 2.6 (Example: The Chord system)\nThe previous example illustrates two things: (1) the use of a hashing function to\nidentify the node responsible for storing some data item, and (2) the routing along\nthe topology of a peer-to-peer system when looking up a data item given its key.\nHowever, it is not a very realistic example, if only for the reason that we assumed\nthat the total set of nodes is fixed. Let us therefore consider a more realistic\nexample of a structured peer-to-peer system that is considered as belonging to\nthe foundations for many other such systems.\nIn the Chord system [Stoica et al., 2003] the nodes are logically organized\nin a ring such that a data item with an m-bit key k is mapped to the node with\nthe smallest (again, also m bit) identifier id ≥k. This node is referred to as the\nsuccessor of key k and denoted as succ(k). Keys and identifiers are typically 128\nor 160 bits long. Figure 2.24 shows a much smaller Chord ring, where m = 5 and\nwith nine nodes {1, 4, 9, 11, 14, 18, 20, 21, 28}. The successor of key 7 is equal to\n9. Likewise, succ(5) = 9, but also succ(9) = 9. In Chord, each node maintains\nshortcuts to other nodes. A shortcut appears as a directed edge from one node\nto another. How these shortcuts are constructed is explained in Chapter 6. The\nconstruction is done in such a way that the length of the shortest path between\nany pair of nodes is of order O(log N), where N is the total number of nodes.\nTo look up a key, a node will try to forward the request “as far as possible,” but\nwithout passing it beyond the node responsible for that key. To clarify, suppose\nthat in our example Chord ring, node 9 is asked to look up the node responsible\nfor key 3 (which is node 4). Node 9 has four shortcuts: to nodes 11, 14, 18, and 28,\nrespectively. As the node 28 is the farthest node 9 knows about and still preceding\nthe one responsible for key 3, it will get the lookup request. Node 28 has three\nshortcuts: to nodes 1, 4, and 14, respectively. Note that node 28 has no knowledge\nabout the existence of nodes between nodes 1 and 4. For this reason, the best\nwhat it can do is forward the request to the node 1. The latter knows that its\nsuccessor in the ring is node 4, and thus that this is the node responsible for the\nkey 3, to which it will subsequently forward the request.\n \nDS 4.01\n",
      "content_length": 2574,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 108,
      "content": "92\nCHAPTER 2. ARCHITECTURES\nFigure 2.24: The organization of nodes and data items in Chord.\nNow suppose that a node, with the unique identifier u, wants to join a Chord\noverlay. To that end, it contacts an arbitrary node and requests it to look up u,\nthat is, return the value v= succ(u). At that point, node u will simply need to\ninsert itself between the predecessor of v and v itself, thus becoming the new\npredecessor of v. During this process, shortcuts from u to other nodes will be\nestablished, but also some existing ones previously directed toward v will now be\nadjusted to point to u (again, details are deferred until later chapters). Obviously,\nany data item with key k stored at v but for which succ(k) is now equal to u is\ntransferred from v to u. Leaving is just as simple: node u informs its departure to\nits predecessor and successor, and transfers its data items to succ(u).\nWe return to Chord in more detail in Section 6.2.3 when discussing the\nresolution of random bit strings to network addresses.\n2.4.2\nUnstructured peer-to-peer systems\nStructured peer-to-peer systems attempt to maintain a specific, deterministic\noverlay network. In contrast, in an unstructured peer-to-peer system, each\nnode maintains an ad hoc list of neighbors. The resulting overlay resembles\nwhat is known as a random graph: a graph in which an edge ⟨u, v⟩between\ntwo nodes u and v exists only with a certain probability P[⟨u, v⟩]. Ideally, this\nprobability is the same for all pairs of nodes, but in practice a wide range of\ndistributions is observed.\nIn an unstructured peer-to-peer system, when a node joins, it often contacts\na well-known node to obtain a starting list of other peers in the system. This\nlist can then be used to find more peers, and perhaps ignore others, and so\nDS 4.01\n \n",
      "content_length": 1791,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 109,
      "content": "2.4. SYMMETRICALLY DISTRIBUTED SYSTEM ARCHITECTURES\n93\non. In practice, a node generally changes its local list almost continuously.\nFor example, a node may discover that a neighbor is no longer responsive\nand that it needs to be replaced. There may be other reasons, which we will\ndescribe shortly.\nUnlike structured peer-to-peer systems, looking up data cannot follow a\npredetermined route when lists of neighbors are constructed in an ad hoc\nfashion. Instead, in an unstructured peer-to-peer systems, we really need\nto resort to searching for data [Risson and Moors, 2006]. Let us look at two\nextremes and consider the case in which we are requested to search for specific\ndata (e.g., identified by keywords).\nFlooding: In the case of flooding, an issuing node u simply passes a request\nfor a data item to all its neighbors. A request will be ignored when its\nreceiving node, say v, had seen it before. Otherwise, v searches locally\nfor the requested data item. If v has the required data, it can either\nrespond directly to the issuing node u, or send it back to the original\nforwarder, who will then return it to its original forwarder, and so on. If\nv does not have the requested data, it forwards the request to all of its\nown neighbors.\nObviously, flooding can be expensive, for which reason a request often\nhas an associated time-to-live or TTL value, giving the maximum num-\nber of hops a request is allowed to be forwarded. Choosing the right\nTTL value is crucial: too small means that a request will stay close to the\nissuer and may thus not reach a node having the data. Too large incurs\nhigh communication costs.\nAs an alternative to setting TTL values, a node can also start a search\nwith an initial TTL value of 1, meaning that it will first query only its\nneighbors. If no, or not enough results are returned, the TTL is increased,\nand a new search is initiated.\nRandom walks: At the other end of the search spectrum, an issuing node u\ncan simply try to find a data item by asking a randomly chosen neighbor,\nsay v. If v does not have the data, it forwards the request to one of its\nrandomly chosen neighbors, and so on. The result is known as a random\nwalk [Gkantsidis et al., 2006; Lv et al., 2002]. Obviously, a random walk\nimposes much less network traffic, yet it may take much longer before\na node is reached that has the requested data. To decrease the waiting\ntime, an issuer can simply start n random walks simultaneously. Indeed,\nstudies show that in this case, the time it takes before reaching a node\nthat has the data drops approximately by a factor n. Lv et al. [2002]\nreports that relatively small values of n, such as 16 or 64, turn out to be\neffective.\nA random walk also needs to be stopped. To this end, we can either again\nuse a TTL, or alternatively, when a node receives a lookup request, check\n \nDS 4.01\n",
      "content_length": 2843,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 110,
      "content": "94\nCHAPTER 2. ARCHITECTURES\nwith the issuer whether forwarding the request to another randomly\nselected neighbor is still needed.\nNote that neither method relies on a specific comparison technique to decide\nwhen requested data has been found. For structured peer-to-peer systems,\nwe assumed the use of keys for comparison; for the two approaches just\ndescribed, any comparison technique would suffice.\nBetween flooding and random walks lie policy-based search methods.\nFor example, a node may decide to keep track of peers who responded\npositively, effectively turning them into preferred neighbors for succeeding\nqueries. Likewise, we may want to restrict flooding to fewer neighbors, but in\nany case give preference to neighbors having many neighbors themselves.\nNote 2.7 (Advanced: Flooding versus random walks)\nWhen giving the matter some thought, it may come as a surprise that people have\neven considered a random walk as an alternative way to search. At first instance,\nit would seem like a technique resembling the search for a needle in a haystack.\nHowever, we need to realize that in practice we are dealing with replicated data,\nand even for minimal replication factors and different replication distributions,\nstudies show that deploying random walks is not only effective, it can also be\nmuch more efficient in comparison to flooding.\nTo see why, we closely follow the model described in Lv et al. [2002] and\nCohen and Shenker [2002]. Assume there are a total of N nodes and that each data\nitem is replicated across r randomly chosen nodes. A search consists of repeatedly\nselecting a node at random until the item is found. If P[k] is the probability that\nthe item is found after k attempts, we have\nP[k] = r\nN (1 −r\nN )k−1.\nLet the average search size S be the expected number of nodes that need to be\nprobed before finding the requested data item:\nS =\nN\n∑\nk=1\nk · P[k] =\nN\n∑\nk=1\nk · r\nN (1 −r\nN )k−1 ≈N/r for 1 ≪r ≤N.\nBy simply replicating every data item to each node, S = 1 and it is clear that a\nrandom walk will always outperform flooding even for TTL values of 1. More\nrealistically, however, is to assume that r/N is relatively low, such as 0.1%,\nmeaning that the average search size would be approximately 1000 nodes.\nTo compare this to flooding, assume that each node, on average, forwards a\nrequest to d randomly selected neighbors. After one step, the request will have\narrived at d nodes, each of who will forward it to another d −1 nodes (assuming\nthat the node from where the request came is skipped), and so on. In other words,\nafter k steps, and considering that a node can receive the request more than once,\nwe will have reached (at most) the following number of nodes:\nR(k) = d(d −1)k−1\nDS 4.01\n \n",
      "content_length": 2731,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 111,
      "content": "2.4. SYMMETRICALLY DISTRIBUTED SYSTEM ARCHITECTURES\n95\nVarious studies show that R(k) is a good estimate for the actual number of nodes\nreached, as long as we have only a few number of flooding steps. Of these nodes,\nwe can expect a fraction of r/N to have the requested data item, meaning that\nwhen r\nN · R(k) ≥1, we will most likely have found a node that has the data item.\nTo illustrate, let r/N = 0.001 = 0.1%, which means that S ≈1000. With\nflooding to, on average, d = 10 neighbors, we would require at least 4 flooding\nsteps, reaching some 7290 nodes, which is considerably more than the 1000 nodes\nrequired when using a random walk. Only with d = 33 will we need to contact\napproximately also 1000 nodes in k = 2 flooding steps and having r/N · R(k) ≥1.\nThe obvious drawback of deploying random walks, is that it may take much\nlonger before an answer is returned.\n2.4.3\nHierarchically organized peer-to-peer networks\nNotably in unstructured peer-to-peer systems, locating relevant data items\ncan become problematic as the network grows. The reason for this scalability\nproblem is simple: as there is no deterministic way of routing a lookup request\nto a specific data item, essentially the only technique a node can resort to\nis searching for the request by flooding or randomly walking through the\nnetwork. As an alternative, many peer-to-peer systems have proposed to\nmake use of special nodes that maintain an index of data items.\nThere are other situations in which abandoning the symmetric nature of\npeer-to-peer systems is sensible. Consider a collaboration of nodes that offer\nresources to each other. For example, in a collaborative Content Delivery\nNetwork (CDN), nodes may offer storage for hosting copies of Web documents\nallowing Web clients to access pages nearby, and thus to access them quickly.\nWhat is needed is a means to find out where documents can be stored best.\nIn that case, making use of a broker that collects data on resource usage\nand availability for several nodes that are in each other’s proximity allows\nselecting a node quickly with sufficient resources.\nNodes such as those maintaining an index or acting as a broker are\ngenerally referred to as super peers. As the name suggests, super peers\nare often also organized in a peer-to-peer network, leading to a hierarchical\norganization, as explained in Yang and Garcia-Molina [2003].\nA simple\nexample of such an organization is shown in Figure 2.25. In this organization,\nevery regular peer, now referred to as a weak peer, is connected as a client to\na super peer. All communication from and to a weak peer proceeds through\nthat peer’s associated super peer.\nOften, the association between a weak peer and its super peer is fixed:\nwhenever a weak peer joins the network, it attaches to one of the super peers\nand remains attached until it leaves the network. Obviously, it is expected that\nsuper peers are long-lived processes with high availability. To compensate for\npotential unstable behavior of a super peer, backup schemes can be deployed,\n \nDS 4.01\n",
      "content_length": 3048,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 112,
      "content": "96\nCHAPTER 2. ARCHITECTURES\nFigure 2.25: A hierarchical organization of nodes into a super-peer network.\nsuch as pairing every super peer with another one and requiring weak peers\nto attach to both.\nHaving a fixed association with a super peer may not always be the best\nsolution. For example, in the case of file-sharing networks, it may be better\nfor a weak peer to attach to a super peer that maintains an index of files\nthat the weak peer is currently interested in. In that case, chances are bigger\nthat when a weak peer is looking for a specific file, its super peer will know\nwhere to find it. Garbacki et al. [2010] describe a relatively simple scheme in\nwhich the association between weak peer and strong peer can change as weak\npeers discover better super peers to associate with. In particular, a super peer\nreturning the result of a lookup operation is given preference over other super\npeers.\nAs we have seen, peer-to-peer networks offer a flexible means for nodes\nto join and leave the network. However, with super-peer networks a new\nproblem is introduced, namely how to select the nodes that are eligible to\nbecome super peer. This problem is closely related to the leader-election\nproblem, which we discuss in Section 5.4.\n2.4.4\nExample: BitTorrent\nLet us consider the widely popular BitTorrent file-sharing system [Cohen,\n2003] as an example of a (largely) unstructured peer-to-peer system. BitTorrent\nis a file-downloading system. Its principle working is shown in Figure 2.26.\nThe basic idea is that when an end user is looking for a file, she downloads\nchunks of the file from other users until the downloaded chunks can be as-\nsembled, yielding the complete file. An important design goal was to ensure\ncollaboration. In most file-sharing systems, a significant fraction of partici-\npants merely download files but otherwise contribute close to nothing [Adar\nand Huberman, 2000; Saroiu et al., 2003; Yang et al., 2005], a phenomenon\nreferred to as free riding. To prevent this situation, in BitTorrent a file can\nDS 4.01\n \n",
      "content_length": 2045,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 113,
      "content": "2.4. SYMMETRICALLY DISTRIBUTED SYSTEM ARCHITECTURES\n97\nNode 1\nNode 2\nNode N\ntorrent file\nfor file F\nA BitTorrent\nWeb page or\nsearch engine\nList of nodes\nwith (chunks of)\nfile F\nWeb server\nFile server\nTracker\nClient node\nK out of N nodes\nLookup(F)\nFigure 2.26: The principle working of BitTorrent [adapted with permission\nfrom Pouwelse et al. [2005].\nbe downloaded only when the downloading client is providing content to\nsomeone else.\nTo download a file, a user needs to access a global directory, which is\ngenerally just one of a few well-known Websites. Such a directory contains\nreferences to what are called torrent files. A torrent file contains the informa-\ntion that is needed to download a specific file. In particular, it contains a link\nto what is known as a tracker, which is a server that is keeping an accurate\naccount of active nodes that have (chunks of) the requested file. An active\nnode is one that is currently downloading the file as well. Obviously, there\nwill be many trackers, although there will generally be only a single tracker\nper file (or collection of files).\nOnce the nodes have been identified from where chunks can be down-\nloaded, the downloading node effectively becomes active. At that point, it\nwill be forced to help others, for example by providing chunks of the file it\nis downloading that others do not yet have. This enforcement comes from a\nsimple rule: if a node P notices that a node Q is downloading more than it\nis uploading, P can decide to decrease the rate at which it sends data to Q.\nThis scheme works well, provided P has something to download from Q. For\nthis reason, nodes are often supplied with references to many other nodes,\nputting them in a better position to trade data.\nClearly, BitTorrent combines centralized with decentralized solutions. As\nit turns out, the bottleneck of the system is easily formed by the trackers.\nIn an alternative implementation of BitTorrent, a node also joins a separate\nstructured peer-to-peer system (i.e., a DHT) to assist in tracking file downloads.\nIn effect, a central tracker’s load is now distributed across the participating\nnodes, with each node acting as a tracker for a relatively small set of torrent\nfiles.\nThe original function of the tracker coordinating the collaborative\ndownloading of a file is retained. However, we note that in many BitTorrent\nsystems used today, the tracking functionality has actually been minimized to\na one-time provisioning of peers currently involved in downloading the file.\nFrom that moment on, the newly participating peer will communicate only\n \nDS 4.01\n",
      "content_length": 2592,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 114,
      "content": "98\nCHAPTER 2. ARCHITECTURES\nwith those peers and no longer with the initial tracker. The initial tracker for\nthe requested file is looked up in the DHT through a so-called magnet link.\nWe return to DHT-based lookups in Section 6.2.3.\n2.5\nHybrid system architectures\nReal-world distributed systems are complex in the sense that they combine a\nmyriad of architectures: centralized features are combined with peer-to-peer\nfeatures are combined with hierarchical organizations, etc. The complexity\nis aggravated by the fact that many distributed systems cross organizational\nboundaries, leading to truly decentralized solutions in which even no single\norganization can take responsibility for a system’s operation. In this section,\nwe will take a closer look into these complex, hybrid system architectures.\n2.5.1\nCloud computing\nOrganizations in charge of running data centers have been seeking ways for\nopening up their resources to customers. Eventually, this led to the concept of\nutility computing by which a customer could upload tasks to a data center\nand be charged on a per-resource basis. Utility computing formed the basis\nfor what is now commonly referred to as cloud computing.\nFollowing Vaquero et al. [2008], cloud computing is characterized by an\neasily usable and accessible pool of virtualized resources. Which and how\nresources are used can be configured dynamically, providing the basis for\nscalability: if more work needs to be done, a customer can simply acquire\nmore resources. The link to utility computing is formed by the fact that cloud\ncomputing is generally based on a pay-per-use model in which guarantees are\noffered by customized service-level agreements (SLAs). Keeping it simple,\nclouds are organized into four layers, as shown in Figure 2.27.\nHardware: The lowest layer is formed by the means to manage the necessary\nhardware: processors, routers, but also power and cooling systems. It is\ngenerally implemented at data centers and contains the resources that\ncustomers normally never get to see directly.\nInfrastructure: This is an important layer forming the backbone for most\ncloud computing platforms. It deploys virtualization techniques (dis-\ncussed in Section 3.2) to provide customers an infrastructure consisting\nof virtual storage and computing resources. Indeed, nothing is what\nit seems: cloud computing evolves around allocating and managing\nvirtual storage devices and virtual servers.\nPlatform: One could argue that the platform layer provides to a cloud-\ncomputing customer what an operating system provides to application\ndevelopers, namely the means to easily develop and deploy applications\nDS 4.01\n \n",
      "content_length": 2651,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 115,
      "content": "2.5. HYBRID SYSTEM ARCHITECTURES\n99\nthat need to run in a cloud. In practice, an application developer is\noffered a vendor-specific API, which includes calls to uploading and ex-\necuting a program in that vendor’s cloud. In a sense, this is comparable\nto the Unix exec family of system calls, which take an executable file as\na parameter and pass it to the operating system to be executed.\nFurthermore, like operating systems, the platform layer provides higher-\nlevel abstractions for storage and such. For example, as we discussed,\nthe Amazon S3 storage system [Murty, 2008; Culkin and Zazon, 2022]\nis offered to the application developer in the form of an API allowing\n(locally created) files to be organized and stored in buckets. By storing a\nfile in a bucket, that file is automatically uploaded to the Amazon cloud.\nApplication: Actual applications run in this layer and are offered to users\nfor further customization. Well-known examples include those found\nin office suites (text processors, spreadsheet applications, presentation\napplications, and so on). It is important to realize that these applica-\ntions are again executed in the vendor’s cloud. As before, they can be\ncompared to the traditional suite of applications that are shipped when\ninstalling an operating system.\nCloud-computing providers offer these layers to their customers through\nvarious interfaces (including command-line tools, programming interfaces,\nand Web interfaces), leading to three different types of services:\n• Infrastructure-as-a-Service (IaaS) covering the hardware and infra-\nstructure layer.\n• Platform-as-a-Service (PaaS) covering the platform layer.\n• Software-as-a-Service (SaaS) in which their applications are covered.\nApplication\nInfrastructure\nComputation (VM)\ntorage (block\n)\n, s\n, file\nHardware\nPlatforms\nSoftware framework (Java/Python/.Net)\nStorage (\n)\ndatabases\nInfrastructure\naa Svc\nPlatform\naa Svc\nSoftware\naa Svc\nMS Azure\nGoogle App engine\nAmazon S3\nAmazon EC2\nDatacenters\nCPU, memory, disk, bandwidth\nWeb services, multimedia, business apps\nGoogle docs\nGmail\nYouTube, Flickr\nFigure 2.27: The organization of clouds (adapted from Zhang et al. [2010]).\n \nDS 4.01\n",
      "content_length": 2173,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 116,
      "content": "100\nCHAPTER 2. ARCHITECTURES\nAs of now, making use of clouds is relatively easy, and we discuss in later\nchapters more concrete examples of interfaces to cloud providers.\nAs a\nconsequence, cloud computing as a means for outsourcing local computing\ninfrastructures has become a serious option for many enterprises.\nFrom the perspective of a system architecture, which deals with config-\nuring (micro)services across some infrastructure, one may argue that in the\ncase of cloud computing, we are dealing with a highly advanced client-server\narchitecture. However, let it be noted that the actual implementation of a\nserver is generally completely hidden from the client: it is often unclear where\nthe server actually is, and even whether the server is actually implemented\nin a fully distributed manner (which it often is). To further illustrate this\npoint, the notion of a Function-as-a-Service, or simply Faas, allows a client to\nexecute code without bothering even with starting a server to handle the code\n(see also Shahrad et al. [2019]).\n2.5.2\nThe edge-cloud architecture\nIn the advent of increasingly more network-connected devices and the emer-\ngence of the Internet-of-Things (IoT) many became aware of the fact that we\nmay need more than just cloud computing. Edge computing was born. There\nis a lot to say about edge computing, and much has already been said. And\nas is the case with so many topics in distributed systems, it simply takes a\nfew years before things settle down a bit. In this section, we take a look at\nedge computing from an architectural perspective and will return to various\nelements throughout the book, often without even explicitly mentioning edge\ncomputing. An excellent overview of edge computing is given by Yousefpour\net al. [2019] and the interested reader is referred to that paper to get a better\ngrip on its nomenclature. We deliberately take a simplified and broad view\nof edge computing, using it as a general term for most of the things sitting\nbetween the devices that comprise the Internet-of-Things and the services typi-\ncally offered through cloud computing. In this sense, we follow the discussion\nas presented by Horner [2021].\nAs its name suggests, edge computing deals with the placement of services\n“at the edge” of the network. This edge is often formed by the boundary\nbetween enterprise networks and the actual Internet, for example, as provided\nby an Internet Service Provider (ISP). For example, many universities reside\non a campus consisting of various buildings, each having their own local\nnetwork, in turn connected through a campuswide network. As part of the\ncampus, there may be multiple on-premise services for storage, computing,\nsecurity, lectures, and so on. On-premise means that the local IT department\nis responsible for hosting those services on servers directly hooked up to the\ncampus network. Much of the traffic related to those services will never leave\nthe campus network, and the network together with its servers and services\nform a typical edge infrastructure.\nDS 4.01\n \n",
      "content_length": 3054,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 117,
      "content": "2.5. HYBRID SYSTEM ARCHITECTURES\n101\nAt the same time, such servers may be connected to those of other univer-\nsities and perhaps even making use of, again, other servers. In other words,\ninstead of setting up connections between universities in a peer-to-peer fash-\nion, we also see configurations in which various universities share services\nthrough a logically centralized infrastructure. Such an infrastructure may be\nsituated “in the cloud,” but it may equally well have been set up through a\nregional infrastructure using locally available data centers. As we move closer\nto cloud infrastructures, the term fog computing is often used. We thus see an\noverall picture emerge as the one shown in Figure 2.28, where the boundaries\nbetween cloud and edge are becoming blurred.\nFigure 2.28: A collection of infrastructures involving edge devices, edge\ninfrastructures and cloud infrastructures, and a possible setup between two\nenterprise edge infrastructures, an intermediate edge infrastructure, and a\ncloud infrastructure.\nMany configurations for an edge infrastructure easily come to mind, rang-\ning from infrastructures needed to keep track of your activities, layered\nvideo-streaming infrastructures, gaming infrastructures, etc. What all of these\nhave in common is that there is some smart end device that one way or the\nother needs to (eventually) connect to a service hosted somewhere in the\ncloud. The question then pops up why an edge infrastructure is needed at all.\nLogically, it seems much simpler to just connect to the cloud service directly\nusing existing and often excellent networking facilities. Let us take a critical\nlook at a few arguments.\nLatency and bandwidth\nWhat should have become clear from our examples\nis that edge infrastructures are considered to be close to the end devices.\nCloseness can be measured in terms of latency and often also bandwidth.\nThroughout the decades, bandwidth, or actually lack of bandwidth, has\n \nDS 4.01\n",
      "content_length": 1963,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 118,
      "content": "102\nCHAPTER 2. ARCHITECTURES\nalways been used as an argument for introducing solutions close to specific\ndevices. However, if anything has become clear all this time, is that available\nbandwidth continues to increase, now reaching the point that one should\nseriously question how problematic it actually is, and whether installing\nand maintaining edge infrastructures for having insufficient bandwidth is\na good reason. Nevertheless, there are situations in which closeness to end\ndevices is actually needed to guarantee quality of service. The canonical\nexample is formed by video services: the closer the video sources are, the\nbetter bandwidth guarantees can be given, reducing issues such as jitter.\nMore problematic is when Mother Nature gets in our way. This may easily\nhappen when dealing with latency. It may take 100 ms to reach a cloud,\nrendering many interactive applications quite useless. One such important\napplication is (semi-)autonomous driving. A car will need to continuously\nobserve its environment through a myriad of sensors and react accordingly.\nHaving to coordinate its movements through the cloud is not acceptable from\na real-time aspect alone. This example also illustrates that cars may need to\ndetect each other beyond the capabilities of their sensors, for example, when\nheading toward a junction with clear visibility. In a real-time system, cars may\nbe able to provide their current position to a local edge infrastructure and\nreveal themselves to each other when approaching the junction.\nOther examples in which latency plays a crucial role easily come to mind.\nOvercoming latency is one of the most compelling reasons for developing\nedge infrastructures.\nReliability\nMany argue that cloud connectivity is simply not reliable enough\nfor many applications, for which reason edge infrastructures should be de-\nployed. To what extent this is a valid argument remains to be seen. The fact\nis that for many networked applications, connectivity is generally good and\nreliable, if not excellent. Of course, there are situations in which relying on\n24/7 reliability is not an option. This may be the case for hospitals, factories,\nand other critical settings in general. Yet, in those cases, measures have been\ntraditionally already taken and to what extent edge computing brings in\nanything new is not always clear.\nSecurity and privacy\nFinally, many argue that edge solutions enhance secu-\nrity and privacy. It all depends. One could argue that if a cloud solution is not\nsecure, then there is no reason why an edge solution would be. An implicit\nassumption that many people make is that an edge infrastructure is owned by\na specific organization and operates within the (protected) network bound-\naries of that organization. In that case, it often does indeed become simpler to\nprotect data and operations, yet one should ask whether such protection is\nsufficient. As we shall discuss in Chapter 9, simply trying to protect assets\nby developing a secure wall around an organization does not help against\nDS 4.01\n \n",
      "content_length": 3044,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 119,
      "content": "2.5. HYBRID SYSTEM ARCHITECTURES\n103\ninsider attacks, whether they are intended or not. A same reasoning holds\nfor privacy: if we cannot protect personal data in the cloud, then why would\nan edge infrastructure suffice for privacy? A thorough discussion on the role\nand position of privacy in the edge and edge devices is given by Hong [2017].\nFrom that discussion, it is clear that there is still considerable work to be done.\nHowever, there may be another reason related to security and privacy why\nedge infrastructures are needed. In many cases, organizations are simply not\nallowed, for whatever regulatory reasons, to place data in the cloud or have\ndata be processed by a cloud service. For example, medical records may have\nto be kept on premise on certified servers and with strict audit procedures in\nplace. In this case, an organization will have to resort to maintaining an edge\ninfrastructure.\nIntroducing additional layers between end devices and cloud infrastructures\nopens a whole can of worms compared to the relatively simple situation of\njust having to deal with cloud computing. For the latter, one can argue that\nthe cloud provider to a considerable extent decides where and how a service\nis actually implemented. In practice, we will be dealing with a data center\nin which the (micro)services that make up the entire service are distributed\nacross multiple machines.\nMatters become more intricate in the case of edge computing. In this case,\nthe client organization will now have to make informed decisions on what\nto do where. Which services need to be placed on premise on a local edge\ninfrastructure, and which can be moved to the cloud? To what extent does an\nedge infrastructure offer facilities for virtual resources, akin to the facilities\noffered in cloud computing? Moreover, where we may be able to assume that\ncomputational and storage resources are in abundance when dealing with a\ncloud, this is not necessarily the case for an edge infrastructure. In practice,\nthe latter simply have less hardware resources available, but often also offer\nless flexibility in terms of available platforms.\nBy and large, allocating resources in the case of edge computing appears\nto be much more challenging in comparison to clouds. As summarized\nby Hong and Varghese [2019], we are dealing with limitations when it comes to\nresources, higher degrees of hardware heterogeneity, and much more dynamic\nworkloads, which, when taken together, have led to a higher demand of\norchestration. Moreover, where from a client’s perspective the cloud appears\nto be hiding many of its internal intricacies, this is necessarily no longer the\ncase, making it much more difficult to do the orchestration [Bittencourt et al.,\n2018]. Orchestration boils down to the following (see also Taleb et al. [2017]):\n• Resource allocation: specific services require specific resources. The\nquestion is then to guarantee the availability of the resources required to\nperform a service. Typically, resources amount to CPU, storage, memory,\nand networking facilities.\n \nDS 4.01\n",
      "content_length": 3066,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 120,
      "content": "104\nCHAPTER 2. ARCHITECTURES\n• Service placement: regardless the availability of resources, it is impor-\ntant to decide when and where to place a service. This is notably relevant\nfor mobile applications, for in that case finding the edge infrastructure\nthat is closest to that application may be crucial. A typical use case is\nthat of video conferencing, for which the encoding is often not done on\nthe mobile device, but at an edge infrastructure. In practice, one needs\nto decide at which edges the service should be installed. An extensive\noverview of service placement in the case of edge computing is provided\nby Salaht et al. [2020].\n• Edge selection: related to service placement is deciding which edge\ninfrastructure should be used when the service needs to be offered. It\nmay seem logical to use the edge infrastructure closest to the end device,\nbut all kinds of circumstances may ask for an alternative solution, for\nexample the connectivity of that edge to the cloud provider.\nOther issues play a role as well, but it should be clear by now that the edge-\ncloud architecture is much more demanding than one might initially think it\nto be. Moreover, the different perspectives on how the continuum between end\ndevices and the cloud should be filled with edge components and solutions\nhas still to converge [Antonini et al., 2019].\n2.5.3\nBlockchain architectures\nAn upcoming and much debated type of distributed system is that of so-called\nblockchains. Blockchain systems enable the registration of transactions, for\nwhich reason they are also referred to as distributed ledgers. The latter is\nactually more accurate, with blockchains forming one of different ways for\nimplementing distributed ledgers.\nThe key issue in transaction systems is that a transaction is validated,\neffectuated, and subsequently stored for various auditing purposes. For\nexample, Alice may decide to create a transaction stating that she transfers\n$10 to Bob’s account. Normally, she would go to a bank, where she would\nhave to sign the transaction to prove that she really wants it to be carried\nout. Whether this all happens physically or digitally does not really matter.\nThe bank will check whether she has enough credit, whether Bob is eligible\nfor receiving the money, and assuming everything is fine, will subsequently\ntransfer the money. A record of the transaction is kept for all kinds of auditing\npurposes. Note that transactions in blockchains systems are taken very broad.\nBesides monetary transactions, systems have been developed for registering\nidentification documents, registering resource usage and allocation, electronic\nvoting, and sharing health records, to name a few.\nThe bank operates as a trusted third party. An important design as-\nsumption for blockchains is that participating parties can, in principle, not\nbe trusted. This also excludes having a trusted third party that handles all\nDS 4.01\n \n",
      "content_length": 2913,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 121,
      "content": "2.5. HYBRID SYSTEM ARCHITECTURES\n105\ntransactions. We will return to trust in Section 9.4, and concentrate on the\nimplications lack of trust has for the architecture of a system.\nIn the case of blockchains, we assume there is a (potentially very large)\nset of participants who jointly register transactions among them in a publicly\navailable ledger. In this way, any participant can see what has happened and\nalso verify the validity of a transaction. For example, in a blockchain system\nfor digital coins, each having a unique and unforgeable ID, any participant\nshould be able to check whether a coin has already been spent by checking all\ntransactions that have taken place since the beginning.\nFigure 2.29: The principle operation of a blockchain.\nTo this end, when Alice wants to transfer $10 to Bob, she essentially tells\nall the participants in the blockchain system about this intent, thus allowing\nvolunteers to validate the intended transaction. This is shown as Step 1 in\nFigure 2.29. To avoid having to check every transaction separately one-by-one\nas they are submitted, a validator groups several transactions into a block to\nincrease efficiency, shown as Step 2 in Figure 2.29. If everything goes well, i.e.,\nthe transactions in the block are considered to be valid, the validator securely\nprotects the block against any modifications, and appends the now immutable\nblock to the chain of other blocks with validated transactions. It does so\nby broadcasting the validated block to all participants, shown as Step 3 in\nFigure 2.29.\nAn important observation is that there is logically only a single chain of\nblocks with validated transactions. Each block is immutable, in the sense\nthat if an adversary decides to modify any transaction from any block in that\nchain, the modification can never go unnoticed. Securely protecting blocks of\ntransactions against modifications, but also securely appending a block to an\nexisting list, are well-understood techniques, which we will explain further\n \nDS 4.01\n",
      "content_length": 2015,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 122,
      "content": "106\nCHAPTER 2. ARCHITECTURES\nin Section 9.4.3. The immutability of a block makes it an ideal fit for massive\nreplication: it will never be changed anyway, so someone may just as well store\nit locally to make verification as simple as possible. Effectively, the logically\nsingle chain of immutable blocks may be physically massively replicated\nacross the Internet among all participating parties. This is precisely what\nhappens: each block is broadcast to every participating node in a blockchain,\nas we just explained.\nWhat differentiates so many blockchain systems from each other is de-\nciding on which node(s) may actually carry out validation tasks. In other\nwords, we need to figure out who is allowed to append a block of validated\ntransactions to the existing chain. Appending such a block means that there\nis global consensus on fulfilled transactions. It is therefore important that we\nalso reach consensus on which validator can move ahead. All others will have\nto do their validation over again, as their transactions may be affected by the\nnewly appended ones and thus may need to be revisited.\nDeciding on which validator can move ahead requires (distributed) con-\nsensus. In principle, there are three options:\n1. A centralized solution, in which a trusted third party validates transac-\ntions as before.\n2. A distributed solution, in which a small, preselected group of processes\ntakes over the role of a trusted third party.\n3. A fully decentralized solution, in which, in principle, all participating\nnodes in the blockchain jointly reach consensus without any (distributed)\nthird party.\nThese three options are shown in Figure 2.30. As mentioned, each node\nparticipating in the blockchain is assumed to have a full copy locally available.\nObviously, a centralized architecture for a blockchain does not fit its design\ngoals, which state that there is essentially no place for a trusted third party.\nThe distributed architecture is an interesting one. In this case, there is a\nrelatively small group of nodes that are permissioned to validate transactions.\nFor blockchains, it is important to realize that none of these permissioned\nnodes are assumed to be trusted, yet they are assumed to run a consensus\nprotocol that can withstand malicious behavior. Specifically, if there are n\npermissioned nodes, then it is assumed that at most k ≤(n −1)/3 will fail\nand perhaps act maliciously. One problem with such so-called permissioned\nblockchains is that n is quite limited, in practice, to less than a few tens of\nnodes.\nFinally, in so-called permissionless blockchains all nodes collectively\nparticipate to validate transactions. In practice, this means that all nodes who\nwant to validate transactions are engaged in a process called leader election.\nThe process elected as leader appends a block to the current chain (and is\nDS 4.01\n \n",
      "content_length": 2852,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 123,
      "content": "2.5. HYBRID SYSTEM ARCHITECTURES\n107\n(a) Centralized\n(b) Distributed (permissioned)\n(c) Decentralized (permissionless)\nFigure 2.30: The three different organizations of blockchains: (a) centralized,\n(b) distributed, (c) fully decentralized. Filled nodes represent validators; other\nnodes are participants not engaged in validation.\noften rewarded for that). In practice, not all participating nodes will want to\nact as validator, if only because the leader-election algorithm is costly in terms\nof resources. We return to leader elections in Section 5.4.\nThe architecture of a blockchain system is thus seen to be quite complex. In\na permissioned system, we have a few tens of nodes for validating transactions.\nNone of these nodes needs to be individually trusted beforehand, yet it may\nbe argued that they form a centralized, fault-tolerant distributed group. Trust\n \nDS 4.01\n",
      "content_length": 878,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 124,
      "content": "108\nCHAPTER 2. ARCHITECTURES\nis needed in so far that we need to assume that not too many of those\nnodes act maliciously or collude against any decisions they should make.\nOn the other hand, permissionless blockchains may be viewed as being fully\ndecentralized, but here we see that special measures are needed to guarantee\nsome form of fairness among willing validators. In fact, through the dynamics\nof permissionless blockchains, we often see that, in practice, only a relatively\nfew number of nodes can carry out validation tasks, effectively also leading to\na more centralized system. An overview of the various settings in blockchains\nfrom the perspective of architectures is given by Xu et al. [2017].\n2.6\nSummary\nDistributed systems can be organized in many ways. We can make a dis-\ntinction between software architecture and system architecture. The latter\nconsiders where the components that constitute a distributed system are\nplaced across the various machines. The former is more concerned about the\nlogical organization of the software: how do components interact, in what\nways can they be structured, how can they be made independent, and so on?\nA keyword when talking about architectures is architectural style. A\nstyle reflects the basic principle that is followed in organizing the interaction\nbetween the software components comprising a distributed system. Important\nstyles include layering, service-oriented styles, and styles in which handling\nevents are prominent, exemplified by are known as publish-subscribe styles.\nThere are many organizations of distributed systems. An important class is\nwhere machines are divided into clients and servers. A client sends a request\nto a server, who will then produce a result that is returned to the client. The\nclient-server architecture reflects the traditional way of modularizing software,\nin which a module calls the functions available in another module. By placing\ndifferent components on different machines, we obtain a natural physical\ndistribution of functions across a collection of machines.\nClient-server architectures are often highly centralized. In decentralized\narchitectures, we often see an equal role played by the processes that constitute\na distributed system, also known as peer-to-peer systems. In peer-to-peer\nsystems, the processes are organized into an overlay network, which is a\nlogical network in which every process has a local list of other peers that\nit can communicate with. The overlay network can be structured, in which\ncase deterministic schemes can be deployed for routing messages between\nprocesses. In unstructured networks, the list of peers is more or less random,\nimplying that search algorithms need to be deployed for locating data or other\nprocesses.\nIn hybrid architectures, elements from centralized and decentralized orga-\nnizations are combined. A typical example is that of cloud computing, which\nlogically follows a client-server architecture, but where the server is generally\nDS 4.01\n \n",
      "content_length": 3004,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 125,
      "content": "2.6. SUMMARY\n109\ncompletely distributed across a data center. In the last decade, we have seen a\nstrong emergence of what is known as edge computing. Edge infrastructures\nform several steps between end devices and clouds and are demanding from\nthe view point of organizing and configuring distributed systems. Finally, as\nan example in which decentralization plays a prominent role, the increasing\npopular blockchain architecture illustrates yet another class of hybrid system\narchitectures.\n \nDS 4.01\n",
      "content_length": 502,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 127,
      "content": "03\nPROCESSES\n",
      "content_length": 13,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 128,
      "content": "112\nCHAPTER 3. PROCESSES\nIn this chapter, we take a closer look at how the different types of processes\nplay a crucial role in distributed systems. The concept of a process originates\nfrom the field of operating systems, where it is generally defined as a program\nin execution. From an operating-system perspective, the management and\nscheduling of processes are perhaps the most important issues to deal with.\nHowever, when it comes to distributed systems, other issues turn out to be\nequally or more important.\nWe start with extensively discussing threads and their role in distributed\nsystems. As it turns out, threads play a crucial role in obtaining performance\nin multicore and multiprocessor environments, but also help in structuring\nclients and servers. There are many cases where we see threads being replaced\nby processes and using the underlying operating system for guaranteeing\nprotection and facilitating communication. Nevertheless, when performance\nis at stake, threads continue to play an important role.\nSince a few years, the concept of virtualization has regained much pop-\nularity. Virtualization allows an application, and possibly also its complete\nenvironment including the operating system, to run concurrently with other\napplications, but highly independent of the underlying hardware and plat-\nforms, leading to a high degree of portability. Moreover, virtualization helps\nin isolating failures caused by errors or security problems. It is an important\nconcept for distributed systems, and we pay attention to it in a separate\nsection.\nClient-server organizations are important in distributed systems. In this\nchapter, we take a closer look at typical organizations of both clients and\nservers. We also pay attention to general design issues for servers, including\nthose typically used in object-based distributed systems. A widely used Web\nserver is Apache, to which we pay separate attention. The organization of\nserver clusters remains important, especially when they need to collaboratively\nprovide the illusion of a single system. we will discuss examples of how to\nachieve this perspective, including wide-area servers like PlanetLab.\nAn important issue, especially in wide-area distributed systems, is moving\nprocesses between different machines. Process migration or more specifically,\ncode migration, can help in achieving scalability, but can also help to configure\nclients and servers dynamically. What is actually meant by code migration\nand what its implications are is also discussed in this chapter.\n3.1\nThreads\nAlthough processes form a building block in distributed systems, practice\nindicates that the granularity of processes as provided by the operating\nsystems on which distributed systems are built is not sufficient. Instead, it\nturns out that having a finer granularity in the form of multiple threads of\ncontrol per process makes it much easier to build distributed applications\nDS 4.01\n \n",
      "content_length": 2942,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 129,
      "content": "3.1. THREADS\n113\nand to get better performance. In this section, we take a closer look at the\nrole of threads in distributed systems and explain why they are so important.\nMore on threads and how they can be used to build applications can be found\nin [Lewis and Berg, 1998; Stevens, 1999; Robbins and Robbins, 2003]. Herlihy\nand Shavit [2008] is highly recommended to learn more about multithreaded\nconcurrent programming in general.\n3.1.1\nIntroduction to threads\nTo understand the role of threads in distributed systems, it is important\nto understand what a process is, and how processes and threads relate. To\nexecute a program, an operating system creates a number of virtual processors,\neach one for running a different program. To keep track of these virtual\nprocessors, the operating system has a process table, containing entries to\nstore CPU register values, memory maps, open files, accounting information,\nprivileges, etc. Jointly, these entries form a process context.\nA process context can be viewed as the software analog of the hardware’s\nprocessor context. The latter consists of the minimal information that is\nautomatically stored by the hardware to handle an interrupt, and to later\nreturn to where the CPU left off. The processor context contains at least the\nprogram counter, but sometimes also other register values such as the stack\npointer.\nA process is often defined as a program in execution, that is, a program\nthat is currently being executed on one of the operating system’s virtual\nprocessors. An important issue is that the operating system takes great care\nto ensure that independent processes cannot maliciously or inadvertently\naffect the correctness of each other’s behavior.\nIn other words, the fact\nthat multiple processes may be concurrently sharing the same CPU and\nother hardware resources is made transparent. Usually, the operating system\nrequires hardware support to enforce this separation.\nThis concurrency transparency comes at a price. For example, each time a\nprocess is created, the operating system must create a complete independent\naddress space. Allocation can mean initializing memory segments by, for\nexample, zeroing a data segment, copying the associated program into a text\nsegment, and setting up a stack for temporary data. Likewise, switching\nthe CPU between two processes may require some effort as well. Apart\nfrom saving the data as currently stored in various registers (including the\nprogram counter and stack pointer), the operating system will also have to\nmodify registers of the Memory Management Unit (MMU) and invalidate\naddress translation caches, such as in the Translation Lookaside Buffer (TLB).\nIn addition, if the operating system supports more processes than it can\nsimultaneously hold in main memory, it may have to swap processes between\nmain memory and disk before the actual switch can take place.\n \nDS 4.01\n",
      "content_length": 2890,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 130,
      "content": "114\nCHAPTER 3. PROCESSES\nLike a process, a thread executes its own piece of code, independently\nof other threads. However, in contrast to processes, no attempt is made to\nachieve a high degree of concurrency transparency if this would result in\nperformance degradation. Therefore, a thread system generally maintains only\nthe minimum information to allow a CPU to be shared by several threads. In\nparticular, a thread context often consists of nothing more than the processor\ncontext, along with some other information for thread management. For\nexample, a thread system may keep track of the fact that a thread is currently\nblocked on a mutex variable, so as not to select it for execution. Information\nthat is not strictly necessary to manage multiple threads is generally ignored.\nFor this reason, protecting data against inappropriate access by threads within\na single process is left entirely to application developers. We thus see that a\nprocessor context is contained in a thread context, and that, in turn, a thread\ncontext is contained in a process context.\nThere are two important implications of deploying threads, as we just\nsketched. First, the performance of a multithreaded application need hardly\never be worse than that of its single-threaded counterpart. In fact, often, mul-\ntithreading even leads to a performance gain. Second, because threads are not\nautomatically protected against each other the way processes are, development\nof multithreaded applications requires additional intellectual effort. Proper\ndesign and keeping things simple, as usual, help a lot. Unfortunately, current\npractice does not demonstrate that this principle is equally well understood.\nThread usage in nondistributed systems\nBefore discussing the role of threads in distributed systems, let us first consider\ntheir usage in traditional, nondistributed systems. There are several benefits\nto multithreaded processes that have increased the popularity of using thread\nsystems.\nThe most important benefit comes from the fact that in a single-threaded\nprocess, whenever a blocking system call is executed, the process as a whole is\nblocked. To illustrate, consider an application such as a spreadsheet program,\nand assume that a user continuously and interactively wants to change values.\nAn important property of a spreadsheet program is that it maintains the func-\ntional dependencies between different cells, often from different spreadsheets.\nTherefore, whenever a cell is modified, all dependent cells are automatically\nupdated. When a user changes the value in a single cell, such a modification\ncan trigger a large series of computations. If there is only a single thread of\ncontrol, computation cannot proceed while the program is waiting for input.\nLikewise, it may be difficult to provide input while dependencies are being\ncalculated. The easy solution is to have at least two threads of control: one\nfor handling interaction with the user and one for updating the spreadsheet.\nMeanwhile, a third thread could be used for backing up the spreadsheet to\ndisk while the other two are doing their work.\nDS 4.01\n \n",
      "content_length": 3115,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 131,
      "content": "3.1. THREADS\n115\nAnother advantage of multithreading is that it becomes possible to exploit\nparallelism when executing the program on a multiprocessor or multicore\nsystem. In that case, each thread is assigned to a different CPU or core, while\nshared data are stored in shared main memory. When properly designed,\nsuch parallelism can be transparent: the process will run equally well on a\nuniprocessor system, albeit slower. Multithreading for parallelism is becoming\nincreasingly important with the availability of relatively cheap multiprocessor\nand multicore computers. Such computer systems are typically used for\nrunning servers in client-server applications, but are by now also extensively\nused in devices such as smartphones.\nMultithreading is also useful in the context of large applications. Such\napplications are often developed as a collection of cooperating programs,\neach to be executed by a separate process. This approach is typical for a\nUnix environment. Cooperation between programs is implemented through\ninterprocess communication (IPC) mechanisms. For Unix systems, these\nmechanisms typically include (named) pipes, message queues, and shared\nmemory segments (see also Stevens and Rago [2005]). The major drawback of\nall IPC mechanisms is that communication often requires relatively extensive\ncontext switching, shown at three different points in Figure 3.1.\nProcess A\nProcess B\nOperating system\nS1: Switch from user space\nto kernel space\nS3: Switch from kernel\nspace to user space\nS2: Switch context from\nprocess A to process B\nFigure 3.1: Context switching as the result of IPC.\nBecause IPC requires kernel intervention, a process will generally first\nhave to switch from user mode to kernel mode, shown as S1 in Figure 3.1.\nThis requires changing the memory map in the MMU, as well as flushing the\nTLB. Within the kernel, a process context switch takes place (S2 in the figure),\nafter which the other party can be activated by switching from kernel mode to\nuser mode again (S3 in Figure 3.1). The latter switch again requires changing\nthe MMU map and flushing the TLB.\nInstead of using processes, an application can also be constructed such\nthat different parts are executed by separate threads. Communication between\nthose parts is entirely dealt with by using shared data. Thread switching can\n \nDS 4.01\n",
      "content_length": 2333,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 132,
      "content": "116\nCHAPTER 3. PROCESSES\nsometimes be done entirely in user space, although in other implementations,\nthe kernel is aware of threads and schedules them. The effect can be a dramatic\nimprovement in performance.\nFinally, there is also a pure software engineering reason to use threads:\nmany applications are simply easier to structure as a collection of cooperating\nthreads. Think of applications that need to perform several (more or less\nindependent) tasks, like our spreadsheet example discussed previously.\nNote 3.1 (Advanced: The cost of a context switch)\nThere have been many studies on measuring the performance effects of context\nswitches. As in so many cases with measuring computer systems, finding the\nground truth is not easy. Tsafrir [2007] notes that handling clock ticks has become\nmore or less ubiquitous in operating systems, making it an excellent candidate\nto measure overheads. A clock handler is activated once every T milliseconds by\na clock interrupt. Common values for T range between 0.5 and 20 milliseconds,\ncorresponding to interrupt frequencies of 2000 Hz and 50 Hz, respectively. The\nhandler typically assists in realizing various timing and CPU usage services, sends\nalarm signals, and assists in preempting running tasks for fair CPU sharing. By\nsimply varying the frequency by which the hardware generates an interrupt, one\ncan easily get an impression of the incurred overhead.\nTo measure the performance effects of an interrupt, a distinction is made\nbetween direct overhead and indirect overhead. The direct overhead consists of\nthe time it takes to do the actual context switch, along with the time it takes for\nthe handler to do its work and subsequently switching back to the interrupted\ntask. The indirect overhead is everything else, and is mainly caused by cache\nperturbations (to which we will return shortly). For various Intel processors,\nTsafrir [2007] found that the time to switch context is in the order of 0.5–1\nmicrosecond, and that the handler itself takes in the order of 0.5–7 microseconds\nto do its work, depending strongly on the implementation.\n(a)\n(b)\n(c)\nFigure 3.2: The organization of the cache when dealing with interrupts:\n(a) before the context switch, (b) after the context switch, and (c) after\naccessing block D. (Adapted from Liu and Solihin [2010].)\nHowever, it turns out that the direct overhead is not really that influential. In\na complimentary study, Liu and Solihin [2010] make clear that context switching\ncan greatly perturbate the cache, resulting in a loss of performance in comparison\nto the situation before an interrupt occurred. In fact, for the simple case of clock\nDS 4.01\n \n",
      "content_length": 2656,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 133,
      "content": "3.1. THREADS\n117\ninterrupts, Tsafrir [2007] measured an indirect overhead of approximately 80%.\nTo understand what is going on, consider the data organizations as sketched in\nFigure 3.2. Assume the cache is organized such that a least-recently used block of\ndata is removed from the cache when room is needed for a fresh data block.\nFigure 3.2(a) shows the situation before the interrupt occurs. After the inter-\nrupt has been handled, block D may have been evicted from the cache, leaving a\nhole as shown in Figure 3.2(b). Accessing block D will copy it back into the cache,\npossibly evicting block C, and so on. In other words, even a simple interrupt may\ncause a considerable, and relatively long-lasting reorganization of the cache, in\nturn, affecting the overall performance of an application.\n1 from multiprocessing import Process\n2 from time import *\n3 from random import *\n4\n5 def sleeper(name):\n6\nt = gmtime()\n7\ns = randint(1,20)\n8\ntxt = str(t.tm_min)+’:’+str(t.tm_sec)+’ ’+name+’ is going to sleep for ’+str(s)+’ seconds’\n9\nprint(txt)\n10\nsleep(s)\n11\nt = gmtime()\n12\ntxt = str(t.tm_min)+’:’+str(t.tm_sec)+’ ’+name+’ has woken up’\n13\nprint(txt)\n14\n15 if __name__ == ’__main__’:\n16\np = Process(target=sleeper, args=(’eve’,))\n17\nq = Process(target=sleeper, args=(’bob’,))\n18\np.start(); q.start()\n19\np.join(); q.join()\n(a)\n40:23 eve is going to sleep for 14 seconds\n40:23 bob is going to sleep for 4 seconds\n40:27 bob has woken up\n40:37 eve has woken up\n(b)\nFigure 3.3: (a) A simple example in which two processes are started, and\n(b) the output after a run.\nA simple example in Python\nTo make matters more concrete, let us look at a simple example in Python,\nalso to illustrate the differences between processes and threads. Consider the\ncode shown in Figure 3.3(a), which shows how we start to separate processes\n \nDS 4.01\n",
      "content_length": 1830,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 134,
      "content": "118\nCHAPTER 3. PROCESSES\nin Python using the multiprocessing package. The core of the example is\nformed by the function sleeping which simply puts the calling process to\nsleep for a randomly chosen number of seconds.\n1 from multiprocessing import Process\n2 from threading import Thread\n3\n4 shared_x = random.randint(10,99)\n5\n6 def sleeping(name):\n7\nglobal shared_x\n8\ns = randint(1,20)\n9\nsleep(s)\n10\nshared_x = shared_x + 1\n11\n12 def sleeper(name):\n13\nsleeplist = list()\n14\nfor i in range(3):\n15\nsubsleeper = Thread(target=sleeping, args=(name+’ ’+str(i),))\n16\nsleeplist.append(subsleeper)\n17\n18\nfor s in sleeplist: s.start()\n19\nfor s in sleeplist: s.join()\n(a)\neve sees shared x being 71\n53:21 eve 0 is going to sleep for 20 seconds\nbob sees shared x being 84\n53:21 eve 1 is going to sleep for 15 seconds\n53:21 eve 2 is going to sleep for 3 seconds\n53:21 bob 0 is going to sleep for 8 seconds\n53:21 bob 1 is going to sleep for 16 seconds\n53:21 bob 2 is going to sleep for 8 seconds\n53:24 eve 2 has woken up, seeing shared x being 72\n53:29 bob 0 has woken up, seeing shared x being 85\n53:29 bob 2 has woken up, seeing shared x being 86\n53:36 eve 1 has woken up, seeing shared x being 73\n53:37 bob 1 has woken up, seeing shared x being 87\nbob sees shared x being 87\n53:41 eve 0 has woken up, seeing shared x being 74\neve sees shared x being 74\n(b)\nFigure 3.4: (a) A multithreading example in which two processes are started,\neach with three threads, and (b) the output after a run.\nTo create two processes, we call the operation Process in lines 16 and 17,\nrespectively, to subsequently start each of them. The join operation tells the\nDS 4.01\n \n",
      "content_length": 1644,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 135,
      "content": "3.1. THREADS\n119\nmain process to wait until the newly created processes have finished. A possi-\nble output is shown in Figure 3.3(b), indicating the time in “minutes:seconds”\nformat when each process outputs some text.\nThe differences between threads and processes can be observed when we\nextend our example as shown in Figure 3.4 (where we have left out many\nstatements for recording time and printing text). In this case, we again start\ntwo processes, named eve and bob (the code is the same as lines 15–19 in\nFigure 3.3 and has been omitted for clarity). Each process subsequently\nstarts three threads, each, in turn, executing the function sleeping. The\nmain difference is that there is now a shared variable shared_x. (To keep\nmatters simple, we incorrectly assume that the assignment in line 10 is atomic.\nWe explain atomic operations in detail in Chapter 5). What the output in\nFigure 3.4 shows is that this is a variable shared among the threads in a single\nprocess, but not shared between the two processes eve and bob. In other words,\neach process has its own instance of shared_x.\nThe output also shows that the sleep operation works at the thread level\nas well as the process level. In this case, each thread is suspended for a few\nseconds, yet the process hosting that thread is not blocked when sleep is\ncalled. Instead, another thread is scheduled (who subsequently also calls\nsleep). How this has been implemented is transparent to the programmer.\nLikewise, it is also transparent to what extent different threads are executed\non different cores, if available, of the used CPU. If we had started 1000 threads\nper process, we would still see accurate timing. However, if we would replace\nthe call to sleep with a busy waiting loop, such as in:\nc = s * 26000000\nfor i in range(c):\nx = x + 1.0\nwe would see that the thread execution may be completely serialized per\nprocess, whereas each process would be assigned to a separate core and thus\nrun in parallel. What exactly is done, depends on the underlying operating\nsystem and the used Python runtime system. The standard implementations\nof Python assign all threads within a single process to just one core.\nThread implementation\nThreads are often provided in the form of a thread package. Such a package\ncontains operations to create and destroy threads, as well as operations on\nsynchronization variables such as mutexes and condition variables. There are\nbasically two approaches to implement a thread package. The first approach\nis to construct a thread library that is executed entirely in user space. The\nsecond approach is to have the kernel be aware of threads and schedule them.\nA user-level thread library has several advantages. First, it is cheap to\ncreate and destroy threads. Because all thread administration is kept in the\n \nDS 4.01\n",
      "content_length": 2814,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 136,
      "content": "120\nCHAPTER 3. PROCESSES\nuser’s address space, the price of creating a thread is primarily determined\nby the cost for allocating memory to set up a thread stack. Analogously,\ndestroying a thread mainly involves freeing memory for the stack, which is\nno longer used. Both operations are cheap.\nA second advantage of user-level threads is that switching thread context\ncan often be done in just a few instructions. Basically, only the values of\nthe CPU registers need to be stored and subsequently reloaded with the\npreviously stored values of the thread to which it is being switched. There is\nno need to change memory maps, flush the TLB, do CPU accounting, and so\non. Switching thread context is done when two threads need to synchronize,\nfor example, when entering a section of shared data. However, as discussed in\nNote 3.1, much of the overhead of context switching is caused by perturbing\nmemory caches.\nA major drawback of user-level threads comes from deploying the many-\nto-one threading model: multiple threads are mapped to a single schedulable\nentity. We already saw this with our simple multithreaded Python example\nin Figure 3.4. As a consequence, the invocation of a blocking system call\nwill immediately block the entire process to which the thread belongs, and\nthus also all the other threads in that process. As we explained, threads are\nparticularly useful to structure large applications into parts that could be\nlogically executed at the same time. In that case, blocking on I/O should not\nprevent other parts to be executed in the meantime. For such applications,\nuser-level threads are of no help.\nThese problems can be mostly circumvented by implementing threads in\nthe operating system’s kernel, leading to what is known as the one-to-one\nthreading model in which every thread is a schedulable entity. The price to\npay is that every thread operation (creation, deletion, synchronization, etc.),\nwill have to be carried out by the kernel, requiring a system call. Switching\nthread contexts may now become as expensive as switching process contexts.\nHowever, because the performance of context switching is generally dictated\nby ineffective use of memory caches, and not by the distinction between the\nmany-to-one or one-to-one threading model, many operating systems now\noffer the latter model, if only for its simplicity.\nNote 3.2 (Advanced: Many-to-many threading model)\nAn alternative to the two threading extremes is a hybrid form of user-level and\nkernel-level threads, a so-called many-to-many threading model. In the following,\nwe simplify our terminology and speak of user threads and kernel threads. A\nkernel thread runs in the context of a single process, and there can be several\nkernel threads per process. In addition to managing kernel threads, a runtime\nsystem also offers a user-level thread package, offering applications the usual\noperations for creating and destroying threads. In addition, the package provides\nfacilities for thread synchronization, such as mutexes and condition variables. The\nDS 4.01\n \n",
      "content_length": 3048,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 137,
      "content": "3.1. THREADS\n121\nimportant issue is that the thread package is implemented entirely in user space:\nall operations on threads are carried out without intervention of the kernel.\nThe thread package can be shared by multiple kernel threads, as shown in\nFigure 3.5. This means that each kernel thread can be running its own (user level)\nthread. Multithreaded applications are constructed by creating user and kernel\nthreads, and subsequently assigning each user thread to a kernel thread.\nThe combination of user threads and kernel threads works as follows. The\nthread package has a single routine to schedule the next thread. When creating a\nkernel thread (which is done through a system call), the kernel thread is given its\nown stack, and is instructed to execute the scheduling routine searching for a user\nthread to execute. If there are several kernel threads, then each of them executes\nthe scheduler. The thread table, which is used to keep track of the current set of\nthreads, is thus shared by the kernel threads. Protecting this table to guarantee\nmutually exclusive access is done through mutexes that are implemented entirely\nin user space. In other words, synchronization between kernel threads does not\nrequire any kernel support. A thread table is often implemented as a ready queue.\nFigure 3.5: Combining kernel-level and user-level threads.\nWhen a kernel thread finds a runnable user thread, it switches context to that\nthread. Meanwhile, other kernel threads may be looking for other runnable user\nthreads as well. If a user thread needs to block on a mutex or condition variable,\nit does the necessary administration and eventually calls the scheduling routine.\nWhen another runnable user thread has been found, a context switch is made\nto that thread. The beauty of all this is that the kernel thread executing the user\nthread need not be informed: the context switch is implemented completely in\nuser space and appears to the kernel thread as normal program code.\nNow let us see what happens when a user thread does a blocking system\ncall. In that case, execution changes from user mode to kernel mode, but still\ncontinues in the context of the current kernel thread. At the point where the\ncurrent kernel thread can no longer continue, the operating system may decide to\nswitch context to another kernel thread, which also implies that a context switch\nis made back to user mode. The selected kernel thread will simply continue where\nit had previously left off.\nThere are several advantages to using kernel threads with a user-level thread\npackage. First, creating, destroying, and synchronizing threads is relatively cheap\n \nDS 4.01\n",
      "content_length": 2653,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 138,
      "content": "122\nCHAPTER 3. PROCESSES\nand involves no kernel intervention at all. Second, provided that a process has\nenough kernel threads, a blocking system call will not suspend the entire process.\nThird, there is no need for an application to know about the kernel threads. All it\nsees are user threads. Fourth, kernel threads can be easily used in multiprocessing\nenvironments by executing different kernel threads on different CPUs or different\ncores. This multiprocessing can be hidden entirely from the application.\nThe approach just sketched is actually the general form of combining user\nand kernel threads. This approach has been implemented in the Go program-\nming language [Donovan and Kernighan, 2015]. The libfibre runtime system\ndescribed and evaluated by Karsten and Barghi [2020] is also exemplary for the\nmany-to-many threading model. A slightly different approach can be found in\nArachne [Qin et al., 2018]. Arachne hides the kernel threads from applications,\nbut instead assumes that an application can get full insight in the cores that have\nbeen assigned. It assigns one kernel thread per allocated core. An important\nconsequence is that Arachne does not provide support for blocking I/O calls.\nAs a final note, it is important to realize that using threads is one way\nof organizing simultaneous and concurrent executions within an application.\nIn practice, we often see that applications are constructed as a collection of\nconcurrent processes, jointly making use of the interprocess facilities offered by\nan operating system (see also [Robbins and Robbins, 2003; Stevens, 1999]). A\ngood example of this approach is the organization of the Apache Web server,\nwhich, by default, starts with a handful of processes for handling incoming\nrequests. Each process forms a single-threaded instantiation of the server, yet\nis capable of communicating with other instances through standard means.\nAs argued by Srinivasan [2010], using processes instead of threads has\nthe important advantage of separating the data space: each process works on\nits own part of data and is protected from interference from others through\nthe operating system. The advantage of this separation should not be un-\nderestimated: thread programming is considered to be notoriously difficult\nbecause the developer is fully responsible for managing concurrent access\nto shared data. Using processes, data spaces, in the end, are protected by\nhardware support. If a process attempts to access data outside its allocated\nmemory, the hardware will raise an exception, which is then further processed\nby the operating system. No such support is available for threads concurrently\noperating within the same process.\n3.1.2\nThreads in distributed systems\nAn important property of threads is that they can provide a convenient\nmeans of allowing blocking system calls without blocking the entire process\nin which the thread is running (assuming we do not have a many-to-one\nthreading model). This property makes threads particularly attractive to use\nin distributed systems, as it makes it much easier to express communication\nDS 4.01\n \n",
      "content_length": 3105,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 139,
      "content": "3.1. THREADS\n123\nin the form of maintaining multiple logical connections at the same time.\nWe illustrate this point by taking a closer look at multithreaded clients and\nservers, respectively.\nMultithreaded clients\nTo establish a high degree of distribution transparency, distributed systems\nthat operate in wide-area networks may need to conceal long interprocess\nmessage propagation times. The round-trip delay in a wide-area network can\neasily be in the order of hundreds of milliseconds, or sometimes even seconds.\nThe usual way to hide communication latencies is to initiate communica-\ntion and immediately proceed with something else. A typical example where\nthis happens is in Web browsers. Often, a Web document consists of an HTML\nfile containing plain text along with a collection of images, icons, etc. To fetch\neach element of a Web document, the browser has to set up a TCP/IP con-\nnection, read the incoming data, and pass it to a display component. Setting\nup a connection as well as reading incoming data are inherently blocking\noperations. When dealing with long-haul communication, we also have the\ndisadvantage that the time for each operation to complete may be long.\nA Web browser often starts with fetching the HTML page and subsequently\ndisplays it. To hide communication latencies as much as possible, some\nbrowsers start displaying data while it is still coming in. While the text is\nmade available to the user, including the facilities for scrolling and such, the\nbrowser continues with fetching other files that make up the page, such as\nthe images. The latter are displayed as they are brought in. The user need\nthus not wait until all the components of the entire page are fetched before\nthe page is made available.\nIn effect, it is seen that the Web browser is doing several tasks simulta-\nneously. As it turns out, developing the browser as a multithreaded client\nsimplifies matters considerably. As soon as the main HTML file has been\nfetched, separate threads can be activated to take care of fetching the other\nparts. Each thread sets up a separate connection to the server and pulls\nin the data. Setting up a connection and reading data from the server can\nbe programmed using the standard (blocking) system calls, assuming that\na blocking call does not suspend the entire process. As is also illustrated\nin [Stevens, 1998], the code for each thread is the same and, above all, simple.\nMeanwhile, the user notices only delays in the display of images and such,\nbut can otherwise browse through the document.\nThere is another important benefit to using multithreaded Web browsers,\nin which several connections can be opened simultaneously. In the previous\nexample, several connections were set up to the same server. If that server is\nheavily loaded, or just plain slow, no real performance improvements will be\nnoticed compared to pulling in the files that make up the page strictly one\nafter the other.\n \nDS 4.01\n",
      "content_length": 2948,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 140,
      "content": "124\nCHAPTER 3. PROCESSES\nHowever, often, Web servers have been replicated across multiple machines,\nwhere each server provides the same set of Web documents. The replicated\nservers are located at the same site, and are known under the same name.\nWhen a request for a Web page comes in, the request is forwarded to one of\nthe servers, often using a round-robin strategy or some other load-balancing\ntechnique. When using a multithreaded client, connections may be set up\nto different replicas, allowing data to be transferred in parallel, effectively\nestablishing that the entire Web document is fully displayed in a much shorter\ntime than with a nonreplicated server. This approach is possible only if the\nclient can handle truly parallel streams of incoming data. Threads are ideal\nfor this purpose.\nNote 3.3 (Advanced: Exploiting client-side threads for performance)\nAlthough there are obvious opportunities for using threads to reach high perfor-\nmance, it is interesting to see whether multithreading is effectively exploited. In a\nstudy to see to what extent multiple threads put a multicore processor to work,\nBlake et al. [2010] looked at the execution of various applications on modern\narchitectures. Browsers, like many other client-side applications, are interactive\ninnately, for which reason the expected processor idle time may be quite high. To\nproperly measure to what extent a multicore processor is being used, Blake et al.\nused a metric known as thread-level parallelism (TLP). Let ci denote the fraction\nof time that exactly i threads are being executed simultaneously. Thread-level\nparallelism is then defined as:\nTLP = ∑N\ni=1 i · ci\n1 −c0\nwhere N is the maximum number of threads that (can) execute at the same time.\nIn their study, a typical Web browser at that time had a TLP value between 1.5\nand 2.5, meaning that to effectively exploit parallelism, the client machine should\nhave two or three cores, or likewise, 2–3 processors.\nThese results are interesting when considering that modern Web browsers\ncreate hundreds of threads, and that tens of threads are active at the same time\n(note that an active thread is not necessarily running; it may be blocked waiting for\nan I/O request to complete). We thus see that multithreading is used to organize\nan application, but that this multithreading is not leading to dramatic performance\nimprovements through hardware exploitation. That browsers can be effectively\ndesigned for exploiting parallelism is shown, for example, by Meyerovich and\nBodik [2010]. By adapting existing algorithms, the authors manage to establish\nseveral-fold speedups.\nMultithreaded servers\nAlthough there are important benefits to multithreaded clients, the main use\nof multithreading in distributed systems is found at the server side. Practice\nDS 4.01\n \n",
      "content_length": 2803,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 141,
      "content": "3.1. THREADS\n125\nshows that multithreading not only simplifies server code considerably, but\nalso makes it much easier to develop servers that exploit parallelism to attain\nhigh performance, even on uniprocessor systems. However, with modern\nmulticore processors, multithreading for parallelism is an obvious path to\nfollow.\nTo understand the benefits of threads for writing server code, consider the\norganization of a file server that occasionally has to block waiting for the disk.\nThe file server normally waits for an incoming request for a file operation,\nsubsequently carries out the request, and then sends back the reply. One\npossible, and particularly popular, organization is shown in Figure 3.6. Here,\none thread, the dispatcher, reads incoming requests for a file operation. The\nrequests are sent by clients to a well-known end point for this server. After\nexamining the request, the server chooses an idle (i.e., blocked) worker thread\nand hands it the request.\nFigure 3.6: A multithreaded server organized in a dispatcher/worker model.\nThe worker proceeds by performing a blocking read on the local file system,\nwhich may cause the thread to be suspended until the data are fetched from\ndisk. If the thread is suspended, another thread is selected to be executed. For\nexample, the dispatcher may be selected to acquire more work. Alternatively,\nanother worker thread can be selected that is now ready to run.\nNow consider how the file server might have been written without threads.\nOne possibility is to have it operate as a single thread. The main loop of the\nfile server gets a request, examines it, and carries it out to completion before\ngetting the next one. While waiting for the disk, the server is idle and does\nnot process any other requests. Consequently, requests from other clients\ncannot be handled. In addition, if the file server is running on a dedicated\nmachine, as is commonly the case, the CPU is simply idle while the file server\nis waiting for the disk. The net result is that many fewer requests per time\nunit can be processed. Thus threads gain considerable performance, but each\nthread is programmed sequentially, in the usual way.\nSo far, we have seen two possible designs: a multithreaded file server\n \nDS 4.01\n",
      "content_length": 2252,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 142,
      "content": "126\nCHAPTER 3. PROCESSES\nand a single-threaded file server. A third alternative is to run the server as\na big single-threaded finite-state machine. When a request comes in, the\none and only thread examines it. If it can be satisfied from the in-memory\ncache, fine, but if not, the thread must access the disk. However, instead\nof issuing a blocking disk operation, the thread schedules an asynchronous\n(i.e., nonblocking) disk operation for which it will be later interrupted by the\noperating system. To make this work, the thread will record the status of the\nrequest (namely, that it has a pending disk operation), and continues to see if\nthere were any other incoming requests that require its attention.\nOnce a pending disk operation has been completed, the operating system\nwill notify the thread, who will then, in due time, look up the status of the\nassociated request and continue processing it. Eventually, a response will be\nsent to the originating client, again using a nonblocking call to send a message\nover the network.\nIn this design, the “sequential process” model that we had in the first\ntwo cases is lost. Every time the thread needs to do a blocking operation, it\nneeds to record exactly where it was in processing the request, possibly also\nstoring additional state. Once that has been done, it can start the operation\nand continue with other work. Other work means processing newly arrived\nrequests, or post-processing requests for which a previously started operation\nhas completed. Of course, if there is no work to be done, the thread may\nindeed block. In effect, we are simulating the behavior of multiple threads\nand their respective stacks the hard way. The process is being operated as\na finite-state machine that gets an event and then reacts to it, depending on\nwhat is in it.\nModel\nCharacteristics\nMultithreading\nParallelism, blocking system calls\nSingle-threaded process\nNo parallelism, blocking system calls\nFinite-state machine\nParallelism, nonblocking system calls\nFigure 3.7: Three ways to construct a server.\nIt should now be clear what threads have to offer. They make it possible to\nretain the idea of sequential processes that make blocking system calls and still\nachieve parallelism. Blocking system calls make programming easier as they\nappear as just normal procedure calls. In addition, multiple threads allow for\nparallelism and thus performance improvement. The single-threaded server\nretains the ease and simplicity of blocking system calls, but may severely\nhinder performance in terms of number of requests that can be handled\nper time unit. The finite-state machine approach achieves high performance\nthrough parallelism, but uses nonblocking calls, which are generally hard to\nprogram and thus to maintain. These models are summarized in Figure 3.7.\nDS 4.01\n \n",
      "content_length": 2812,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 143,
      "content": "3.2. VIRTUALIZATION\n127\nAgain, note that instead of using threads, we can also use multiple pro-\ncesses to organize a server (leading to the situation that we actually have a\nmultiprocess server). The advantage is that the operating system can offer\nmore protection against accidental access to shared data. However, if pro-\ncesses need to communicate a lot, we may see a noticeable adverse effect on\nperformance in comparison to using threads.\n3.2\nVirtualization\nThreads and processes can be seen as a way to do more things at the same\ntime. In effect, they allow us to build (pieces of) programs that appear to be\nexecuted simultaneously. On a single-processor (single core) computer, this\nsimultaneous execution is, of course, an illusion. As there is only a single\nCPU, only an instruction from a single thread or process will be executed at\na time. By rapidly switching between threads and processes, the illusion of\nparallelism is created.\nThis separation between having a single CPU and being able to pretend\nthere are more can be extended to other resources as well, leading to what\nis known as resource virtualization. This virtualization has been applied for\nmany decades, but has received renewed interest as (distributed) computer\nsystems have become more commonplace and complex, leading to the sit-\nuation that application software is mostly always outliving its underlying\nsystems software and hardware.\n3.2.1\nPrinciple of virtualization\nIn practice, every (distributed) computer system offers a programming inter-\nface to higher-level software, as shown in Figure 3.8(a). There are many types\nof interfaces, ranging from the basic instruction set as offered by a CPU to the\nvast collection of application programming interfaces that are shipped with\nmany current middleware systems. In its essence, virtualization deals with\nextending or replacing an existing interface to mimic the behavior of another\nsystem, as shown in Figure 3.8(b). We will come to discuss technical details\non virtualization shortly, but let us first concentrate on why virtualization is\nimportant.\nVirtualization and distributed systems\nOne of the most important reasons for introducing virtualization, back in the\n1970s, was to allow legacy software to run on expensive mainframe hardware.\nThe software not only included various applications, but in fact also the\noperating systems they were developed for. This approach toward supporting\nlegacy software has been successfully applied on the IBM 370 mainframes (and\n \nDS 4.01\n",
      "content_length": 2517,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 144,
      "content": "128\nCHAPTER 3. PROCESSES\n(a)\n(b)\nFigure 3.8: (a) General organization between a program, interface, and system.\n(b) General organization of virtualizing system A on top of B.\ntheir successors) that offered a virtual machine to which different operating\nsystems had been ported.\nAs hardware became cheaper, computers became more powerful, and the\nnumber of different operating system flavors was reducing, virtualization\nbecame less of an issue. However, matters have changed again since the\nlate 1990s. First, while hardware and low-level systems software change\nreasonably fast, software at higher levels of abstraction (e.g., middleware and\napplications), are often much more stable. In other words, we are facing\nthe situation that legacy software cannot be maintained in the same pace as\nthe platforms it relies on. Virtualization can help here by porting the legacy\ninterfaces to the new platforms, and thus immediately opening up the latter\nfor large classes of existing programs.\nEqually important is the fact that networking has become completely\npervasive. It is hard to imagine that a modern computer is not connected to\na network. In practice, this connectivity requires that system administrators\nmaintain a large and heterogeneous collection of server computers, each one\nrunning very different applications, which can be accessed by clients. At\nthe same time, the various resources should be easily accessible to these\napplications. Virtualization can help a lot: the diversity of platforms and\nmachines can be reduced by essentially letting each application run on its\nown virtual machine, possibly including the related libraries and operating\nsystem, which, in turn, run on a common platform.\nThis last type of virtualization provides a high degree of portability and\nflexibility. For example, in order to realize content delivery networks that\ncan easily support replication of dynamic content, Awadallah and Rosenblum\n[2002] have argued that management becomes much easier if edge servers\nwould support virtualization, allowing a complete site, including its environ-\nDS 4.01\n \n",
      "content_length": 2097,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 145,
      "content": "3.2. VIRTUALIZATION\n129\nment, to be dynamically copied. These arguments are still valid, and indeed,\nportability is perhaps the most important reason why virtualization plays\nsuch a key role in many distributed systems.\nFinally, an important reason for virtualization is that it provides an ad-\nditional means of isolating code, which is particularly relevant in the case\nof cloud computing. At the same time, virtualization also introduces new\nsecurity threats.\nNote 3.4 (Discussion: Stable software?)\nAlthough there is indeed a lot of legacy software that can benefit from stable\ninterfaces to rapidly changing underlying hardware, it is a mistake to believe that\nthe software for widely available services hardly changes. With the increasing\nshift toward server-side computing in the form of Software-as-a-Service (SaaS),\nmuch software can be maintained for a relatively homogeneous platform, owned\nentirely by the organization offering the associated service. As a consequence,\nmaintaining software products can be much easier, as there is much lesser need\nto distribute changes to potentially millions of customers. In fact, changes may\nrapidly succeed each other following changes in available hardware and platform,\nbut without any client actually noticing downtimes [Barroso et al., 2018].\nTypes of virtualization\nThere are many ways in which virtualization can be realized. An overview\nof these various approaches is described by Smith and Nair [2005a]. A more\nrecent account is described by Bugnion et al. [2017], which provides many\ntechnical details on the realization of various forms of virtualization. To\nunderstand the differences in virtualization, it is important to realize that\ncomputer systems generally offer four different types of interfaces, at three\ndifferent levels:\n1. An interface between the hardware and software, referred to as the in-\nstruction set architecture (ISA), forming the set of machine instructions.\nThis set is divided into two subsets:\n• Privileged instructions, which are allowed to be executed only by\nthe operating system.\n• General instructions, which can be executed by any program.\n2. An interface consisting of system calls as offered by an operating system.\n3. An interface consisting of library calls, generally forming what is known\nas an application programming interface (API). Often, the aforemen-\ntioned system calls are hidden by an API.\nThese different types are shown in Figure 3.9. The essence of virtualization is\nto mimic the behavior of these interfaces.\n \nDS 4.01\n",
      "content_length": 2531,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 146,
      "content": "130\nCHAPTER 3. PROCESSES\nFigure 3.9: Various interfaces offered by computer systems.\nVirtualization can take place in two different ways. First, we can build a\nruntime system that essentially provides an abstract instruction set that is to\nbe used for executing applications. Instructions can be interpreted (as is the\ncase for the Java runtime environment), but could also be emulated, as is done\nfor running Windows applications on Unix platforms. Note that in the latter\ncase, the emulator will also have to mimic the behavior of system calls, which\nhas proven to be generally far from trivial. This type of virtualization, shown\nin Figure 3.10(a), leads to what Smith and Nair [2005a] call a process virtual\nmachine, stressing that virtualization is only for a single process.\n(a)\n(b)\n(c)\nFigure 3.10: (a) A process virtual machine. (b) A native virtual machine\nmonitor. (c) A hosted virtual machine monitor.\nAn alternative approach toward virtualization, shown in Figure 3.10(b),\nis to provide a system that is implemented as a layer shielding the original\nhardware, but offering the complete instruction set of that same (or other\nhardware) as an interface. This leads to what is known as a native virtual\nmachine monitor. It is called native because it is implemented directly on\ntop of the underlying hardware. Note that the interface offered by a virtual\nmachine monitor can be offered simultaneously to different programs. As\nDS 4.01\n \n",
      "content_length": 1446,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 147,
      "content": "3.2. VIRTUALIZATION\n131\na result, it is now possible to have multiple, and different guest operating\nsystems run independently and concurrently on the same platform.\nA native virtual machine monitor will have to provide and regulate access\nto various resources, like external storage and networks. Like any operating\nsystem, this implies that it will have to implement device drivers for those\nresources. Rather than doing all this effort anew, a hosted virtual machine\nmonitor will run on top of a trusted host operating system as shown in Fig-\nure 3.10(c). In this case, the virtual machine monitor can make use of existing\nfacilities provided by that host operating system. It will generally have to be\ngiven special privileges instead of running as a user-level application. Using\na hosted virtual machine monitor is highly popular in modern distributed\nsystems such as data centers and clouds.\nAs argued by Rosenblum and Garfinkel [2005], virtual machines are impor-\ntant in the context of reliability and security for (distributed) systems. As they\nallow for the isolation of a complete application and its environment, a failure\ncaused by an error or security attack need no longer affect a complete machine.\nIn addition, as we also mentioned before, portability is greatly improved as\nvirtual machines provide a further decoupling between hardware and soft-\nware, allowing a complete environment to be moved from one machine to\nanother. We return to migration in Section 3.5.\nNote 3.5 (Advanced: On the performance of virtual machines)\nVirtual machines perform surprisingly well. In fact, many studies show that\nmodern virtual machines perform close to running applications directly on the\nhost operating system. Let us take a closer look at what is going under the hood\nof virtual machines. A detailed and comprehensive account of virtual machines is\nprovided by Smith and Nair [2005b].\nPart of the answer to performance issues is shown in Figure 3.11, which forms\nan extension of Figure 3.10(c): a large part of the code constituting a virtual\nmachine monitor, guest operating system, and application is running natively on\nthe underlying hardware. In particular, all general (i.e., unprivileged) machine\ninstructions are directly executed by the underlying machine.\nThis approach is not new and is founded on research by Popek and Goldberg\n[1974] who formalized the requirements for the efficient execution of virtual\nmachines.\nIn a nutshell, Popek and Goldberg assumed that the underlying\nmachine provided at least two modes of operation (system and user mode), that\na subset of the instructions could be executed only in system mode, and that\nmemory addressing was relative (i.e., a physical address was obtained by adding\na relative address to an offset found in a relocation register). A distinction was\nfurther made between two types of instructions. A privileged instruction is an\ninstruction that is characterized by the fact that if and only if executed in user\nmode, it causes a trap to the operating system. Nonprivileged instructions are\nall other instructions.\n \nDS 4.01\n",
      "content_length": 3094,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 148,
      "content": "132\nCHAPTER 3. PROCESSES\nFigure 3.11: Applications, guest operating system, virtual machine moni-\ntor, and host operating system on a single hardware platform.\nGiven these formal assumptions, Popek and Goldberg defined two classes\nof special instructions. A control-sensitive instruction is one that may affect\nthe configuration of a machine. A typical example is an instruction that affects\nthe memory layout, for example, by changing the memory offset as stored in a\nrelocation register. Another example is instructions that affect the interrupt table,\ncontaining pointers to interrupt handlers.\nA behavior-sensitive instruction is one whose effect is partially determined\nby the context in which it is executed. For example, Intel x86 processors have\ninstructions that may, or may not, affect certain registers depending on whether\nthat instruction is executed in system mode or user mode. An example given\nin [Smith and Nair, 2005b] is that of the POPF instruction, which may set an\ninterrupt-enabled flag, but only when executed in system mode.\nWe now have the following important result:\nFor any conventional computer, a virtual machine monitor may be con-\nstructed if the set of sensitive instructions for that computer is a subset of\nthe set of privileged instructions.\nWhat this says is that as long as sensitive instructions are caught when executed\nin user mode, we can safely run all nonsensitive instructions natively on the\nunderlying hardware. This also means that when designing instruction sets, if\nwe take care that the above requirement is met, we will not be unnecessarily\nobstructing efficient virtualization of that instruction set.\nUnfortunately, not all instruction sets have privileged-only sensitive instruc-\ntions, including perhaps the most popular one, namely the Intel x86 instruction set.\nAs it turns out, this set has 17 sensitive instructions that are not privileged [Robin\nand Irvine, 2000]. In other words, each of these instructions can be executed in\nuser mode without causing a trap to the operating system, yet affect the way\nthat the operating system is managing its resources. In these cases, there are\nessentially two solutions.\nThe first solution is to emulate all instructions. Of course, this would have\na serious adverse effect on performance. To circumvent problems, an approach\nimplemented in VMWare [Sugerman et al., 2001], is to scan the executable and\nto insert code around the nonprivileged sensitive instructions to divert control\nDS 4.01\n \n",
      "content_length": 2494,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 149,
      "content": "3.2. VIRTUALIZATION\n133\nto the virtual machine monitor. There, appropriate emulation will take place, for\nexample, by considering the context in which the instruction was to be executed.\nThe effect is that full virtualization can take place, meaning that execution can\ntake place without changing the guest operating system, nor the application itself.\nAn alternative solution is to apply paravirtualization, which requires the\nguest operating system to be modified. In particular, the guest operating system is\nmodified such that all side effects of running nonprivileged sensitive instructions\nin user mode, which would normally be executed in system mode, are dealt\nwith. For example, code can be rewritten such that these instructions simply no\nlonger occur, or if they do, that their semantics are the same regardless whether\nbeing executed in user or system mode. Paravirtualization has been adopted by\nXen [Barham et al., 2003; Chisnall, 2007].\n3.2.2\nContainers\nVirtual machines offer a means to run applications relying on a specific\noperating environment, including its instruction set and operating system,\nto run independently across different platforms. As we have seen, this may\nrequire significant efforts to ensure portability and performance. However,\noften we see that applications are relatively stable when it comes to the used\ninstruction set and operating system, yet do rely on specific libraries and other\nsupport software. In these cases, what we really want is to allow different\napplications to run side-by-side, yet each uses its own environment of support\nsoftware without even noticing that there be other applications with a different\nenvironment. This is where containers come into the game.1\nA container can be thought of a collection of binaries (also called images)\nthat jointly constitute the software environment for running applications. The\neasiest way to think of a container is what a user would get to see when\nlogging into, for example, a Unix system: it will consist of several standard\ndirectories containing executable programs, libraries, documentation, etc. A\nnaive implementation of a container would be to copy an entire environment\nfor a specific use case and install it as a subdirectory of, say, the root file\nsystem. Using a command such as chroot, the user would then be diverted to\nthat subdirectory and run various applications, with this subdirectory now\nacting as the root. An application would see exactly the libraries and other\ndependencies it needed, while applications in other containers would have\ntheir own view on what the operating system is offering. In this sense, a\ncontainer effectively virtualizes the software environment for an application.\nHowever, this naive implementation is certainly not enough from a virtual-\nization perspective. For one, applications and processes operating in different\n1The material in this section has been inspired by Julia Evans’s wonderful material at\nwizardzines.com.\n \nDS 4.01\n",
      "content_length": 2985,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 150,
      "content": "134\nCHAPTER 3. PROCESSES\ncontainers need to be isolated from each other. Likewise, simply copying an\nentire environment is not very efficient, certainly not because we may expect\nthat many libraries and such are the same across different containers. Finally,\nit is important that an operating system hosting containers has some control\nover the usage of its own resources. All of these aspects are handled in Unix\nenvironments (i.e., notably Linux) through three important mechanisms:\n• Namespaces, by which a collection of processes associated with a con-\ntainer is given their own view of identifiers and such, independent of\nother containers.\n• Union file system, which allows to, literally, combine several file systems\ninto a layered fashion with only the highest layer allowing for write\noperations (and the one being part of a container).\n• Control groups, or simply cgroups, by which resource restrictions can\nbe imposed upon a collection of processes.\nLet us look a bit deeper into each of these mechanisms. Namespaces are\nnecessary for giving a process running inside a container the illusion that it is\non its own. As such, namespaces are important for isolating containers from\neach other. Perhaps the one most illustrative is setting the PID namespace.\nAs every machine has only a single init process (with PID equal to 1), every\ncontainer should see its own “init” process. This is established through the\nUnix unshare command:\nunshare --pid --fork --mount-proc bash\nwill bring the calling process into a new shell in which the command ps -ef\nyields:\nUID\nPID\nPPID\nC STIME TTY\nTIME CMD\nroot\n1\n0\n0 06:27 pts/0\n00:00:00 bash\nroot\n2\n1\n0 06:27 pts/0\n00:00:00 ps -ef\nIndeed, we see that there now seems to be a new collection of processes with\njust one having PID equal to 1. All other processes have become invisible\nwhen working from this new shell.\nAnother important mechanism is efficient sharing of existing file systems.\nMany containers will be based on a common instance of an operating system,\nsay Ubuntu 20.4. Instead of copying that entire environment and installing it\nas a subdirectory as explained above, we can use it as a base layer and stack\nother parts on top of it. For example, we may decide to replace the entire\ncollection of subdirectories that constitute PHP7.4 for an older version by\nsimply stacking those directories on top the ones for version 7.4. The result is\nthat a PHP application will be using the older version. Note that this approach\nis very similar to mounting a file system at a directory dir. Anything that was\nDS 4.01\n \n",
      "content_length": 2568,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 151,
      "content": "3.2. VIRTUALIZATION\n135\ncontained in dir will no longer be visible until the file system is unmounted\nagain. Indeed, taking the union of file systems is done through successive\ncalls to the mount system call, with each layer being mounted in read-only\nmode. Only the top layer can be written to, and will need to be explicitly\nsaved when a running container finishes.\nFinally, to control what a container can actually use, Unix systems offer\ncgroups. In essence, when creating a control group, the collection of processes\nrunning in that group may be restricted to the amount of main memory that\nthey can use, the priority when it comes to using the CPU, etc. In this way,\nthe hosting operating system can prevent that a single container is using too\nmuch of its resources, preventing perhaps other containers to do their work.\nThere are many other things related to isolate containers and properly\nrestrict what processes can do within a container. In the end, a container can\nbe thought of an archive of files that are placed somewhere in a filesystem,\ntogether with a specific stack of common, shared, existing read-only subdi-\nrectories. Processes running inside the context of a container are presented\nwith a view that their context is the only one (through the use of namespaces)\nand they have certain abilities when it comes tot using resources (through\ncgroups, but also restrictions when it comes to, for example, system calls).\nThis view is summarized in Figure 3.12. Besides the material from Julia Evans\nat wizardzines.com, the interested reader is referred to [Pahl et al., 2019] for\nan overview of container technologies.\nFigure 3.12: The organization of a container within a hosting environment.\nNote 3.6 (Example: PlanetLab)\nThere are many examples of container technologies, yet at this point it is interesting\nto look at a specific case where the technology was used for developing a wide-\narea cluster of computers, even before it became popular in the context of cloud\n \nDS 4.01\n",
      "content_length": 2000,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 152,
      "content": "136\nCHAPTER 3. PROCESSES\ncomputing. PlanetLab was a collaborative distributed system in which different\norganizations each donated one or more computers, adding up to a total of\nhundreds of nodes. Together, these computers formed a 1-tier server cluster, where\naccess, processing, and storage could all take place on each node individually.\nManagement of PlanetLab was by necessity almost entirely distributed. The\nproject closed down in 2020.\nGeneral organization\nIn PlanetLab, a participating organization donated one\nor more nodes (i.e., computers) that were subsequently shared among all Plan-\netLab users. Each node was organized as shown in Figure 3.13. There are two\nimportant components [Bavier et al., 2004; Peterson et al., 2006]. The first one\nis the virtual machine monitor (VMM), which is an enhanced Linux operating\nsystem, essentially one capable of supporting containers along the lines sketched\nabove. The enhancements mainly comprise adjustments for supporting the second\ncomponent, namely (Linux) Vservers. A Vserver is essentially a container in\nexecution.\nFigure 3.13: The basic organization of a PlanetLab node.\nThe Linux VMM ensured that Vservers were separated: processes in different\nVservers are executed concurrently and independently, each making use only of\nthe software packages and programs available in their own environment. The\nisolation between processes in different Vservers is strict. For example, two\nprocesses in different Vservers could have the same user ID, but this did not imply\nthat they would stem from the same user. This separation considerably eased\nsupporting users from different organizations that wanted to use PlanetLab as,\nfor example, a testbed to experiment with entirely different distributed systems\nand applications. Note that this separation is precisely the one that is realized\nthrough the unshare command.\nTo support such experimentation, PlanetLab used slices, each slice being\na set of Vservers, each Vserver running on a different node, as illustrated in\nFigure 3.14. A slice can thus be thought of as a virtual server cluster, implemented\nby a collection of containers connected through a wide-area network.\nDS 4.01\n \n",
      "content_length": 2187,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 153,
      "content": "3.2. VIRTUALIZATION\n137\nCentral to managing PlanetLab resources was the node manager. Each node\nhad such a manager, implemented by a separate Vserver, whose only task was to\ncreate other Vservers on the node it managed and to control resource allocation.\nTo create a new slice, each node would also run a slice creation service (SCS),\nwhich, in turn, could contact the node manager requesting it to create a Vserver\nand to allocate resources. The node manager itself could not be contacted directly\nover a network, allowing it to concentrate only on local resource management. In\nturn, the SCS would not accept slice-creation requests from just anybody. Only\nspecific slice authorities were eligible for requesting the creation of a slice. Each\nslice authority would have access rights to a collection of nodes. The simplest\nmodel was that there is only a single, centralized slice authority that is allowed\nto request slice creation on all nodes. In practice, we saw that this slice authority\nwas the one used to get a user up-and-running on PlanetLab.\nFigure 3.14: The principle of a PlanetLab slice, showing sets of associated\nVservers across different nodes.\nKeeping track of resources was done by a resource specification, or rspec for\nshort. An rspec specified a time interval during which certain resources had been\nallocated. Resources include disk space, file descriptors, inbound and outbound\nnetwork bandwidth, transport-level end points, main memory, and CPU usage.\nAn rspec was identified through a globally unique 128-bit identifier known as a\nresource capability (rcap). Given an rcap, the node manager could look up the\nassociated rspec in a local table.\nResources were bound to slices. In other words, to make use of resources, it\nwas necessary to create a slice. Each slice was associated with a service provider,\nwhich can best be seen as an entity having an account on PlanetLab. Every slice\ncould then be identified by a (principal_id, slice_tag) pair, where the principal_id\nidentified the provider and slice_tag being an identifier chosen by the provider.\nVservers\nLet us now turn our attention to PlanetLab’s Vservers, which have\nbeen described and evaluated by Soltesz et al. [2007]. A Vserver was organized\nas a container. The primary task of a Vserver was therefore to merely support a\ngroup of processes and keep that group isolated from processes running under\nthe jurisdiction of another Vserver.\nAn important advantage of the container-based approach toward virtualiza-\ntion, in comparison to running separate guest operating systems, is that resource\nallocation could generally be much simpler. In particular, it was possible to\noverbook resources by allowing for dynamic resource allocation, just as is done\n \nDS 4.01\n",
      "content_length": 2751,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 154,
      "content": "138\nCHAPTER 3. PROCESSES\nwith allocating resources to normal processes. Normally, when using a guest\noperating system, the guest will have to be allocated a fixed number of resources\nin advance (notably main memory). When considering that the nodes provided\nby participating PlanetLab organizations were required to have only a few GByte\nof main memory, it is not hard to imagine that memory would be a scarce re-\nsource. It was therefore necessary to dynamically allocate memory to allow tens\nof containers to be running at the same time on a single node. Vservers were\nideal for this type of resource management; operating systems are much harder\nto support in such cases. Of course, this could not prevent a Vserver from using\ntoo much memory on a busy node. The PlanetLab policy in that case was simple:\nthe Vserver, hogging memory when swap space was almost filled, was reset.\nPlanetLab status\nAlthough the official PlanetLab closed down in 2020, a similar\nsystem is running worldwide as EdgeNet. Not surprisingly, where Vservers were\ncontainers avant-la-lettre, that technology has been replaced in EdgeNet by modern\ncontainer technology, namely Docker in combination with Kubernetes.\n3.2.3\nComparing virtual machines and containers\nEver since containers became popular, mainly caused by their introduction\nthrough Docker, an oftentimes heated debate has been going on what is better:\nvirtual machines or containers? This debate has been hindered through the\nimproper use of terminology, such as lightweight containers versus heavyweight\nvirtual machines, immediately leading to often unsubstantiated performance\nstatements (suggesting that heavyweight means slow). However, life is not so\nsimple and understanding the technology of virtual machines as well as those\nof containers can help in making better judgments on when to use which\ntechnology. In this section, let us take a closer look at one specific, important\naspect: performance. We return to portability later when discussing code\nmigration.\nMeasuring the performance of any system requires looking at a multitude\nof criteria. Obvious ones include CPU and memory usage. Likewise, various\nI/O measurements are needed to get a good insight into how well a system\nis performing, in particular accessing disks and network I/O. On top of\nthis, we need to ask ourselves how measurements are carried out. In other\nwords, which workloads or benchmarks are used to evaluate and compare\nthe performing systems.\nA systematic study on comparing Linux containers (LXC) against Linux\nvirtual machines (KVM) was conducted by Sharma et al. [2016]. If we just look\nat a baseline comparison in which an application is running either within a\ncontainer or on top of a virtual machine, differences can be observed in favor\nof containers, yet these differences are not that big, except when it comes to\nI/O. In that case, we see that virtual machines perform significantly less than\nDS 4.01\n \n",
      "content_length": 2940,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 155,
      "content": "3.2. VIRTUALIZATION\n139\ncontainers. This should not come as a surprise, as notably with traditional I/O,\nthe operating system plays a crucial role: it has to execute many privileged\ninstructions.\nNevertheless, even the obvious may come with surprises. In a more recent\nstudy on comparing different container technologies with virtual-machine\napproaches, van Rijn and Rellermeyer [2021] demonstrate that the differences\nbetween the two may often be close to negligible, even when looking at disk\nand network I/O. There are several reasons for this small difference, but\none is that the host operating system caches results in main memory. In\nother words, when actually performing I/O operations, many subsequent\noperations are performed on in-memory data instead of data that is stored\non disk. This makes benchmarking more difficult, yet also reflects realistic\napplication-driven behavior. Furthermore, when running actual application-\nlevel benchmarks, such as those available for mysql, differences may exist, but\ncan be small. Nevertheless, depending on the actual I/O behavior, the overall\nconclusion is that virtual machines do impose more overhead in comparison\nto containers.\nOf course, it is more natural that several applications run side-by-side. The\nquestion then is to what extent the performance of one application influences\nthat of another. In effect, this aspect boils down to the question how well\nscheduling resources among competitors actually is. In this case, the general\ntrend is that containerization has more difficulty isolating independent appli-\ncations and that scheduling for CPU usage as well as for disk performance is\nhandled better through virtual machines.\nWhat van Rijn and Rellermeyer [2021] and other recent studies show is\nthat over the years many improvements have been made and that there is\nno real need for virtualization techniques to perform significantly slower in\ncomparison to running applications directly on top of the hosting operating\nsystem.\n3.2.4\nApplication of virtual machines to distributed systems\nFrom the perspective of distributed systems, the most important applica-\ntion of virtualization lies in cloud computing. As we already mentioned in\nSection 1.3.1, cloud providers offer roughly three different types of services:\n• Infrastructure-as-a-Service (IaaS) covering the basic infrastructure\n• Platform-as-a-Service (PaaS) covering system-level services\n• Software-as-a-Service (SaaS) containing actual applications\nVirtualization plays a key role in IaaS. Instead of renting out a physical\nmachine, a cloud provider will rent out a virtual machine (monitor) that\nmay, or may not, be sharing a physical machine with other customers. The\nbeauty of virtualization is that it allows for almost complete isolation between\n \nDS 4.01\n",
      "content_length": 2791,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 156,
      "content": "140\nCHAPTER 3. PROCESSES\ncustomers, who will indeed have the illusion that they have just rented a\ndedicated physical machine. Isolation is, however, never complete, if only\nfor the fact that the actual physical resources are shared, in turn leading to\nobservable lower performance.\nTo make matters concrete, let us consider the Amazon Elastic Compute\nCloud, or simply EC2. EC2 allows one to create an environment consisting\nof several networked virtual servers, thus jointly forming the basis of a\ndistributed system.\nTo make life easy, there is a (large) number of pre-\nconfigured machine images available, referred to as Amazon Machine Images,\nor simply AMIs. An AMI is an installable software package consisting of an\noperating-system kernel along with several services. An example of a simple,\nbasic AMI is a LAMP image, consisting of a Linux kernel, the Apache Web\nserver, a MySQL database system, and PHP libraries. More elaborate images\ncontaining additional software are also available, as well as images based on\nother Unix kernels or Windows. In this sense, an AMI is essentially the same\nas a boot disk (although there are a few important differences, to which we\nreturn shortly).\nAn EC2 customer needs to select an AMI, possibly after adapting or\nconfiguring one. An AMI can then be launched, resulting in what is called an\nEC2 instance: the actual virtual machine that can be used to host a customer’s\napplications. An important issue is that a customer will hardly ever know\nexactly where an instance is actually being executed. Obviously, it is running\non a single physical machine, but where that machine is located remains\nhidden. The closest one can get to pinpoint the location where an instance\nshould run is by selecting one of a few regions provided by Amazon (US,\nSouth America, Europe, Asia).\nTo communicate, each instance obtains two IP addresses: a private one that\ncan be used for internal communication between different instances, making\nuse of EC2’s internal networking facilities, and a public IP address allowing\nany Internet clients to contact an instance. The public address is mapped to\nthe private one using standard network-address translation (NAT) technology.\nA simple way to manage an instance is to make use of an SSH connection, for\nwhich Amazon provides the means for generating the appropriate keys.\nThe EC2 environment in which an instance is executed provides different\nlevels of the following services:\n• CPU: allows selecting the number and type of core, including GPUs\n• Memory: defines how much main memory is allocated to an instance\n• Storage: defines how much local storage is allocated\n• Platform: distinguishes between 32-bit or 64-bit architectures\n• Networking: sets the bandwidth capacity that can be used\nDS 4.01\n \n",
      "content_length": 2775,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 157,
      "content": "3.3. CLIENTS\n141\nIn addition, extra resources can be requested, such as an additional networking\ninterface. The local storage that comes with an instance is transient: when\nthe instance stops, all the data stored locally is lost. To prevent data loss, a\ncustomer will need to explicitly save data to a persistent store, for example,\nby making use of Amazon’s Simple Storage Service (S3). An alternative is to\nattach a storage device that is mapped to Amazon’s Elastic Block Store (EBS).\nAgain, this is yet another service, but one that can be used in the form of a\nvirtual block device that is simply mounted as one would mount an additional\nhard disk. When an instance is stopped, all data that was stored on EBS will\npersist. And just as one would expect, an EBS device can be (re)mounted to\nany other instance as well.\nIt should be clear by now that, without having gone into any significant\nlevel of detail, the IaaS as offered by EC2 allows a customer to create a (po-\ntentially large) number of virtual machines, each configured with resources\nas needed, and capable of exchanging messages through an IP network. In\naddition, these virtual machines can be accessed from anywhere over the\nInternet (provided a client has the proper credentials). As such, Amazon\nEC2, like many other IaaS providers, offers the means to configure a com-\nplete distributed system consisting of networked virtual servers and running\ncustomer-supplied distributed applications. At the same time, those customers\nwill not need to maintain any physical machine, which by itself is often al-\nready a huge gain, as we will encounter at several occasions throughout this\ntext. One can indeed argue that virtualization lies at the core of modern cloud\ncomputing.\n3.3\nClients\nIn the previous chapters we discussed the client-server model, the roles of\nclients and servers, and the ways they interact. Let us now take a closer look\nat the anatomy of clients and servers, respectively. We start in this section\nwith a discussion of clients. Servers are discussed in the next section.\n3.3.1\nNetworked user interfaces\nA major task of client machines is to provide the means for users to interact\nwith remote servers. There are roughly two ways in which this interaction can\nbe supported. First, for each remote service, the client machine will have a\nseparate counterpart that can contact the service over the network. A typical\nexample is a calendar running on a user’s smartphone that needs to synchro-\nnize with a remote, possibly shared calendar. In this case, an application-level\nprotocol will handle the synchronization, as shown in Figure 3.15(a).\nA second solution is to provide direct access to remote services by offer-\ning only a convenient user interface. Effectively, this means that the client\nmachine is used only as a terminal with no need for local storage, leading\n \nDS 4.01\n",
      "content_length": 2867,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 158,
      "content": "142\nCHAPTER 3. PROCESSES\nto an application-neutral solution as shown in Figure 3.15(b). In the case of\nnetworked user interfaces, everything is processed and stored at the server.\nThis thin-client approach has received much attention with the increase in\nInternet connectivity and the use of mobile devices. Thin-client solutions are\nalso popular as they ease the task of system management.\n(a)\n(b)\nFigure 3.15: (a) A networked application with its own protocol. (b) A general\nsolution to allow access to remote applications.\nExample: The X window system\nPerhaps one of the oldest and still widely used networked user interfaces is\nthe X Window System. The X Window System, generally referred to simply as\nX, is used to control bit-mapped terminals, which include a monitor, keyboard,\nand a pointing device such as a mouse.\nNext to supporting traditional\nterminals as can be found with desktop computers and workstations, X also\nsupports modern devices such a touchscreens on tablets and smartphones. In\na sense, X can be viewed as that part of an operating system that controls the\nterminal. The heart of the system is formed by what we shall call the X kernel.\nIt contains all the terminal-specific device drivers, and as such, is generally\nhighly hardware dependent.\nThe X kernel offers a relatively low-level interface for controlling the\nscreen, but also for capturing events from the keyboard and mouse. This\nDS 4.01\n \n",
      "content_length": 1425,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 159,
      "content": "3.3. CLIENTS\n143\ninterface is made available to applications as a library called Xlib. Its organi-\nzation is shown in Figure 3.16. Note that Xlib is hardly ever used directly by\napplications, which instead deploy toolkits implemented on top of Xlib.\nFigure 3.16: The basic organization of the X Window System.\nThe interesting aspect of X is that the X kernel and the X applications need\nnot necessarily reside on the same machine. In particular, X provides the X\nprotocol, which is an application-level communication protocol by which an\ninstance of Xlib can exchange data and events with an X kernel. For example,\nXlib can send requests to the X kernel for creating or killing a window, setting\ncolors, and defining the type of cursor to display, among many other requests.\nIn turn, the X kernel will react to local events such as keyboard and mouse\ninput by sending event packets back to Xlib.\nSeveral applications can communicate at the same time with the X kernel.\nThere is one specific application that is given special rights, known as the\nwindow manager. This application can dictate the “look and feel” of the\ndisplay as it appears to the user. For example, the window manager can\nprescribe how each window is decorated with extra buttons, how windows\nare to be placed on the display, and so on. Other applications will have to\nadhere to these rules. In practice, this means that much of the interaction\nbetween an application and an X terminal is redirected through a window\nmanager.\nIt is interesting to note how the X window system actually fits into client-\nserver computing. From what we have described so far, it should be clear\nthat the X kernel receives requests to manipulate the display. It gets these\nrequests from (possibly remote) applications. In this sense, the X kernel acts\nas a server, while the applications play the role of clients. This terminology\nhas been adopted by X, and although strictly speaking it is correct, it can\neasily lead to confusion.\n \nDS 4.01\n",
      "content_length": 1990,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 160,
      "content": "144\nCHAPTER 3. PROCESSES\nThin-client network computing\nObviously, applications manipulate a display using the specific display com-\nmands as offered by X. These commands are generally sent over the network\nwhere they are subsequently executed by the X kernel. By its nature, ap-\nplications written for X should preferably separate application logic from\nuser-interface commands. Unfortunately, this is often not the case. As re-\nported by Lai and Nieh [2002] it turns out that much of the application logic\nand user interaction are tightly coupled, meaning that an application will send\nmany requests to the X kernel for which it will expect a response before being\nable to make a next step. This synchronous behavior may adversely affect\nperformance when operating over a wide-area network with long latencies.\nThere are several solutions to this problem. One is to re-engineer the\nimplementation of the X protocol, as is done with NX [Pinzari, 2003]. An\nimportant part of this work concentrates on bandwidth reduction by reducing\nthe size of X messages. To this end, messages are considered to consist of\na fixed part, which is treated as an identifier, and a variable part. Often,\nmultiple messages will have the same identifier, in which case they will often\ncontain similar data. This property can be used to send only the differences\nbetween messages having the same identifier. By having the sender and\nreceiver maintain identifiers, decoding at the receiver can be readily applied.\nBandwidth reductions up to a factor 1000 have been reported, which allows X\nto also run through low-bandwidth links of only 9600 kbps.\nAs an alternative to using X, researchers and practitioners have also sought\nto let an application completely control the remote display, that is, up to the\npixel level. This approach is also referred to as controlling a remote desktop.\nChanges in the bitmap are then sent over the network to the display, where\nthey are immediately transferred to the local frame buffer. A well-known\nexample of this approach is Virtual Network Computing (VNC) [Richardson\net al., 1998], which has been around ever since the late 1990s. Obviously, letting\nthe application control the display requires sophisticated encoding techniques\nto prevent bandwidth availability to become a problem. For example, consider\ndisplaying a video stream at 30 frames per second on a simple 320 × 240\nscreen. If each pixel is encoded by 24 bits, then without an efficient encoding\nscheme, we would need a bandwidth of approximately 53 Mbps. In practice,\nvarious encoding techniques are used, yet choosing the best one is generally\napplication dependent.\n3.3.2\nVirtual desktop environment\nAs cloud computing further matured, and notably the number of cloud\napplications was growing, it became opportune to actually turn the cloud into\na virtual desktop environment for end users. The only thing needed was\nthe client-side software to access that desktop environment. One of the first\nDS 4.01\n \n",
      "content_length": 2985,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 161,
      "content": "3.3. CLIENTS\n145\nproviders of this model was Google with the introduction of Chrome OS. The\nbasic idea is simple: let the browser provide the local desktop interface. Next\nto the browser, multiple stand-alone applications can be available of which\neach, in principle, eventually operates with a cloud-based counterpart. In this\nsense, the desktop is actually akin to what is offered by modern smartphones.\nWith an increasing trend to transform applications to browser extensions, we\ncan see that the browser is taking over the role of an operating system’s user\ninterface.\nThe anatomy of a Web browser\nTo get a better appreciation of what is going on, let us take a closer look at\nthe anatomy of the Chrome browser, which has been reported to be the most\nwidely used among all browsers.2 The Chrome browser is an intricate piece of\nsoftware consisting of over 25 million lines of code, comparable to the size of\nthe Linux kernel. Where in the beginning the Web consisted of merely simple\nHTML pages, we are now dealing with not only a highly advanced markup\nlanguage, but also an array of tools for interaction and client-side scripting\nlanguages. A high-level overview of how the Chrome browser works is shown\nin Figure 3.17.\nAt the core, we see the resource loader, responsible for fetching content\nfrom a Web server. It generally starts with fetching an HTML file and subse-\nquently, in parallel, sets up connections for other material referenced in that\npage. This is typically done through separate threads. Note that the resource\nloader will need to partially parse the original HTML file to discover which\nother content it needs to fetch. Most of the parsing, however, is done by a\nseparate component that constructs what is known as a Document Object\nModel, or DOM for short. In essence, a DOM is a tree representation of the\nHTML file.\nWhere the DOM can be said to represent structure, actual styling infor-\nmation is provided by a separate document. For example, it may state that\nevery paragraph should be represented in a specific color and in a specific\nfont. This information is parsed separately and essentially added to the DOM,\nleading to a render tree. This tree contains all the information for the next step:\ndetermining exactly where the various elements in the tree will be displayed.\nIn particular, geometric regions need to be computed for different parts of the\nDOM, but also where lines will be broken (and considering language-specific\nissues such as reading text from left to right, or vice versa as is the case with\nHebrew or Arabic. Line breaking, in turn, requires exact computations for\nwhich the styling component will need to take font characteristics into account.\nIt is not difficult to see that the process of determining the layout can become\n2See gs.statcounter.com.\n \nDS 4.01\n",
      "content_length": 2816,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 162,
      "content": "146\nCHAPTER 3. PROCESSES\nHTTP(S)\nWeb server\nResource\nloader\nHTML\nparsing\nStyling\nMake\nlayout\nCompositing\nPainting &\nrasterization\nExecute\nscripts\nImage\nText\nList\nMovie\nHTML files\nCSS files\nScripts\nImages\n...\nUser\ninteraction\nDOM\nRender\ntree\nFigure 3.17: An overview of how the Chrome browser renders a Web page\n(adapted from Pourghassemi [2021]).\nquite complex when, for example, floating images or multiple columns need\nto be rendered.\nOnce the layout has been determined, the painting component, takes the\nlayout instructions and constructs a program consisting of paint operations,\nlike drawRectangle(x,y,height,width). There are many of such operations,\nwhich are subsequently executed by a rasterization process which fills in\nall the details for every pixel on the screen, notably, of course, its color.\nRasterization also takes the embedded images into account (and based on the\ninformation provided by the painting process) ensures that each pixel on an\nembedded image gets properly displayed. What we have not shown explicitly\nin Figure 3.17, is that the DOM is actually decomposed into several layers,\nand that each layer is eventually rasterized separately. As a result, the layers\nneed to be composed into a final image that can be displayed. Meanwhile, the\ncompositor can interact with the user, who may be scrolling through a page.\nLast, yet certainly not least, every browser now has a separate component\nfor handling scripts, that is, executable code. A popular scripting language\nfor client-side Web applications is JavaScript, but increasingly more often we\nalso see WebAssembly codes [Sletten, 2022]. The latter offer performance that\nDS 4.01\n \n",
      "content_length": 1664,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 163,
      "content": "3.3. CLIENTS\n147\ncan be close to executing native code, certainly in combination with actual\ncompilations. The generated code is always restricted to the permissions the\nbrowser has, making it (relatively) safe. The power of being able to run code\ninside a browser cannot be underestimated. It forms the core of giving the\nillusion to an end user that she is indeed running an application on the local\ndesktop. We return to this phenomenon below.\nAlthough we have skipped many details, it should be clear that actually\nrendering a Web page is a highly complex endeavor. Furthermore, it is not\ndifficult to imagine that many of the elements just described, such as raster-\nizing layers, can be done in parallel and perhaps even on special processors,\nsuch a GPU. This is precisely what a modern Web browser does: spawning\nthreads and processes, not only to provide more structure and organization\nto this immense complex software, but also to make sure that the rendering\nas a whole is done efficiently.\nIn fact, modern Web browsers also use processes to protect various parts\nof their code from each other. For example, the whole rendering in Chrome\nis done by a separate process (i.e., the components HTML parsing, styling,\nmaking the layout, painting, and compositing are taken together), while raster-\nization is separated to make use of a possibly available GPU. The rasterization\nprocess communicates with the main process through message passing. More-\nover, every browser tab gets its own renderer process. To improve security,\neach renderer is running in a separate sandbox: a protection mechanism that\nprecludes direct communication with the underlying operating system. We\nreturn to sandboxes when discussing mobile code.\nBrowsers and applications\nAs we already indicated, having a browser is often sufficient for offering a\nvirtual desktop environment. Important is the fact that browsers can execute\nscripts as the client-side part of an otherwise remote application. Such scripts\ncan largely handle everything that is needed to provide the illusion that a\nuser is working on a local machine. This is precisely what Chrome OS offers.\nHowever, things become a bit more complicated when local resources are\ntruly needed for offering a desktop environment. The first type of resources\nthat come to mind are related to media: camera, microphone, speakers, etc.\nMany Web-based applications will ask the user for permission to use those\nresources.\nIt is often also possible to run applications natively on the computer\nhosting the client-side desktop. In essence, this is what happens with modern\nsmartphones. Native applications (also referred to as mobile apps) operate as\nany other locally executing application. Their main advantage over running\nWeb-based applications is that, in principle, a user can work offline. However,\nby simply examining how many mobile apps are useful when there is no\n \nDS 4.01\n",
      "content_length": 2915,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 164,
      "content": "148\nCHAPTER 3. PROCESSES\nnetwork connectivity already illustrates that working offline is not assumed\nto be the default.\nA development that is gradually emerging is that of using Progressive Web\napps (PWA). These applications use the browser as their hosting environment,\nyet appear as an ordinary mobile app. In a nutshell, what a PWA does is move\na lot of the server-side content that is not dependent on (high quality) network\nconnectivity, to the client where it is subsequently cached. The effect is that\nmany of these apps, which can run in the browser or even appear as a mobile\napp (i.e., the browser user interface itself is hidden) can be executed much\nfaster and comparable to that of their mobile-app counterpart. Furthermore,\nbecause much less needs to be communicated with the server, many PWAs\ncan operate well even when the quality of the network is at stake.\nBy and large, we see that virtual desk environments are moving extremely\nthin clients to ones that are hosts to much more functionality, and for which\ncommunication over the Internet has been highly optimized. As we mentioned\nbefore, a major advantage over the traditional fat clients that have mainly\nlocally installed applications is that management of browser-based apps is\nmuch easier: the server can simply upload new parts to the client as needed.\n3.3.3\nClient-side software for distribution transparency\nClient software comprises more than just user interfaces. Often, parts of the\nprocessing and data level in a client-server application are executed on the\nclient side as well. A special class is formed by embedded client software,\nsuch as for automatic teller machines (ATMs), cash registers, barcode readers,\nTV set-top boxes, etc. In these cases, the user interface is a relatively small part\nof the client software, in contrast to the local processing and communication\nfacilities.\nBesides the user interface and other application-related software, client\nsoftware comprises components for achieving distribution transparency.\nIdeally, a client should not be aware that it is communicating with remote\nprocesses. In contrast, distribution is often less transparent to servers for\nreasons of performance and correctness.\nAccess transparency is generally handled through the generation of a\nclient stub from an interface definition of what the server has to offer. The\nstub provides the same interface as the one available at the server, but hides\nthe possible differences in machine architectures, as well as the actual commu-\nnication. The client stub transforms local calls to messages that are sent to the\nserver, and vice versa transforms messages from the server to return values as\none would expect when calling an ordinary procedure.\nThere are different ways to handle location, migration, and relocation\ntransparency . Using a convenient naming system is crucial. Often, coopera-\ntion with client-side software is also important. For example, when a client is\nalready bound to a server, the client can be directly informed when the server\nDS 4.01\n \n",
      "content_length": 3046,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 165,
      "content": "3.4. SERVERS\n149\nchanges location. In this case, the client’s middleware can hide the server’s\ncurrent network location from the user, and also transparently rebind to the\nserver if necessary. At worst, the client’s application may notice a temporary\nloss of performance.\nSimilarly, many distributed systems implement replication transparency\nemploying client-side solutions. For example, imagine a distributed system\nwith replicated servers, Such replication can be achieved by forwarding a\nrequest to each replica, as shown in Figure 3.18. Client-side software can\ntransparently collect all responses and pass a single response to the client\napplication.\nFigure 3.18: Transparent replication of a server using a client-side solution.\nRegarding failure transparency, masking communication failures with\na server is typically done through client middleware. For example, client\nmiddleware can be configured to repeatedly attempt to connect to a server, or\nperhaps try another server after several attempts. There are even situations\nin which the client middleware returns data it had cached during a previous\nsession, as is sometimes done by Web browsers that fail to connect to a server.\nFinally, concurrency transparency can be handled through special inter-\nmediate servers, notably transaction monitors, and requires less support from\nclient software.\n3.4\nServers\nLet us now take a closer look at the organization of servers. In the following\npages, we first concentrate on a number of general design issues for servers,\nfollowed by a discussion on server clusters.\n3.4.1\nGeneral design issues\nA server is a process implementing a specific service on behalf of a collection\nof clients. In essence, each server is organized in the same way: it waits for an\n \nDS 4.01\n",
      "content_length": 1770,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 166,
      "content": "150\nCHAPTER 3. PROCESSES\nincoming request from a client and subsequently ensures that the request is\ntaken care of, after which it waits for the next incoming request.\nConcurrent versus iterative servers\nThere are several ways to organize servers. In the case of an iterative server,\nthe server itself handles the request and, if necessary, returns a response to the\nrequesting client. A concurrent server does not handle the request itself, but\npasses it to a separate thread or another process, after which it immediately\nwaits for the next incoming request. A multithreaded server is an example of\na concurrent server. An alternative implementation of a concurrent server is to\nfork a new process for each new incoming request. This approach is followed\nin many Unix systems. The thread or process that handles the request is\nresponsible for returning a response to the requesting client.\nContacting a server: end points\nAnother issue is where clients contact a server. In all cases, clients send\nrequests to an end point, also called a port, at the machine where the server\nis running. Each server listens to a specific end point. How do clients know\nthe end point of a service? One approach is to globally assign end points for\nwell-known services. For example, servers that handle Internet FTP requests\nalways listen to TCP port 21. Likewise, an HTTP server for the World Wide\nWeb will always listen to TCP port 80. These end points have been assigned\nby the Internet Assigned Numbers Authority (IANA), and are documented\nin [Reynolds and Postel, 1994]. With assigned end points, the client needs to\nfind only the network address of the machine where the server is running.\nName services can be used for that purpose.\nThere are many services that do not require a preassigned end point.\nFor example, a time-of-day server may use an end point that is dynamically\nassigned to it by its local operating system. In that case, a client will first\nhave to look up the end point. One solution is to have a special daemon\nrunning on each machine that runs servers. The daemon keeps track of the\ncurrent end point of each service implemented by a co-located server. The\ndaemon itself listens to a well-known end point. A client will first contact the\ndaemon, request the end point, and then contact the specific server, as shown\nin Figure 3.19(a).\nIt is common to associate an end point with a specific service. However,\nactually implementing each service by means of a separate server may be\na waste of resources. For example, in a typical Unix system, it is common\nto have many servers running simultaneously, with most of them passively\nwaiting until a client request comes in. Instead of having to keep track of so\nmany passive processes, it can be more efficient to have a single superserver\nlistening to each end point associated with a specific service, as shown in\nDS 4.01\n \n",
      "content_length": 2880,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 167,
      "content": "3.4. SERVERS\n151\n(a)\n(b)\nFigure 3.19: (a) Client-to-server binding using a daemon. (b) Client-to-server\nbinding using a superserver.\nFigure 3.19(b). For example, the inetd daemon in Unix listens to a number of\nwell-known ports for Internet services. When a request comes in, the daemon\nforks a process to handle it. That process will exit when finished.\nInterrupting a server\nAnother issue that needs to be considered when designing a server is whether\nand how a server can be interrupted. For example, consider a user who has\njust decided to upload a huge file to an FTP server. Then, suddenly realizing\nthat it is the wrong file, she wants to interrupt the server to cancel further data\ntransmission. There are several ways to do this. One approach that works only\ntoo well in the current Internet (and is sometimes the only alternative) is for\nthe user to abruptly exit the client application (which will automatically break\nthe connection to the server), immediately restart it, and pretend nothing\nhappened. The server will eventually tear down the old connection, thinking\nthe client has probably crashed.\nA much better approach for handling communication interrupts is to\ndevelop the client and server such that it is possible to send out-of-band\ndata, which is data that is to be processed by the server before any other data\nfrom that client. One solution is to let the server listen to a separate control\nend point to which the client sends out-of-band data, while at the same time\nlistening (with a lower priority) to the end point through which the normal\n \nDS 4.01\n",
      "content_length": 1578,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 168,
      "content": "152\nCHAPTER 3. PROCESSES\ndata passes. Another solution is to send out-of-band data across the same\nconnection through which the client is sending the original request. In TCP,\nfor example, it is possible to transmit urgent data. When urgent data are\nreceived at the server, the latter is interrupted (e.g., through a signal in Unix\nsystems), after which it can inspect the data and handle them accordingly.\nStateless versus stateful servers\nA final, important design issue, is whether the server is stateless. A stateless\nserver does not keep information on the state of its clients, and can change its\nown state without having to inform any client [Birman, 2012]. A Web server,\nfor example, is stateless. It merely responds to incoming HTTP requests, which\ncan be either for uploading a file to the server or (most often) for fetching\na file. When the request has been processed, the Web server forgets the\nclient completely. Likewise, the collection of files that a Web server manages\n(possibly in cooperation with a file server), can be changed without clients\nhaving to be informed.\nNote that in many stateless designs, the server actually does maintain\ninformation on its clients, but crucial is the fact that if this information is\nlost, it will not lead to a disruption of the service offered by the server. For\nexample, a Web server generally logs all client requests. This information is\nuseful, for example, to decide whether certain documents should be replicated,\nand where they should be replicated to. Clearly, there is no penalty, other\nthan perhaps in the form of suboptimal performance if the log is lost.\nA particular form of a stateless design is where the server maintains what\nis known as soft state. In this case, the server promises to maintain state on\nbehalf of the client, but only for a limited time. After that time has expired,\nthe server falls back to default behavior, thereby discarding any information it\nkept on account of the associated client. An example of this type of state is\na server promising to keep a client informed about updates, but only for a\nlimited time. Thereafter, the client is required to poll the server for updates.\nSoft-state approaches originate from protocol design in computer networks,\nbut can be equally applied to server design [Clark, 1989; Lui et al., 2004].\nIn contrast, a stateful server generally maintains persistent information\non its clients. This means that the information needs to be explicitly deleted\nby the server. A typical example is a file server that allows a client to keep\na local copy of a file, even for performing update operations. Such a server\nwould maintain a table containing (client, file) entries. Such a table allows the\nserver to keep track of which client currently has the update permissions on\nwhich file, and thus possibly, also the most recent version of that file.\nThis approach can improve the performance of read and write operations\nas perceived by the client. Performance improvement over stateless servers\nis often an important benefit of stateful designs. However, the example also\nillustrates the major drawback of stateful servers. If the server crashes, it has\nDS 4.01\n \n",
      "content_length": 3181,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 169,
      "content": "3.4. SERVERS\n153\nto recover its table of (client, file) entries, or otherwise it cannot guarantee\nthat it has processed the most recent updates on a file. In general, a stateful\nserver needs to recover its entire state as it was just before the crash. Enabling\nrecovery can introduce considerable complexity, as we discuss in Chapter 8.\nIn a stateless design, no special measures need to be taken at all for a crashed\nserver to recover. It simply starts running again, and waits for client requests\nto come in.\nLing et al. [2004] argue that one should actually make a distinction between\n(temporary) session state and permanent state. The example above is typical\nfor session state: it is associated with a series of operations by a single user\nand should be maintained for some time, but not indefinitely. As it turns\nout, session state is often maintained in three-tiered client-server architectures,\nwhere the application server actually needs to access a database server through\na series of queries before being able to respond to the requesting client. The\nissue here is that no real harm is done if session state is lost, provided that\nthe client can simply re-issue the original request. This observation allows for\nsimpler and less reliable storage of state.\nWhat remains for permanent state is typically information maintained\nin databases, such as customer information, keys associated with purchased\nsoftware, etc. However, for most distributed systems, maintaining session state\nalready implies a stateful design requiring special measures when failures do\nhappen and making explicit assumptions about the durability of state stored\nat the server. We will return to these matters when discussing fault tolerance.\nWhen designing a server, the choice for a stateless or stateful design should\nnot affect the services provided by the server. For example, if files have to\nbe opened before they can be read from, or written to, then a stateless server\nshould one way or the other mimic this behavior. A common solution is that\nthe server responds to a read or write request by first opening the referred\nfile, then does the actual read or write operation, and immediately closes the\nfile again.\nIn other cases, a server may want to keep a record of a client’s behavior so\nthat it can more effectively respond to its requests. For example, Web servers\nsometimes offer the possibility to immediately direct a client to its favorite\npages. This approach is possible only if the server has history information on\nthat client. When the server cannot maintain state, a common solution is then\nto let the client send along additional information on its previous accesses. In\nthe case of the Web, this information is transparently stored by the client’s\nbrowser in what is called a cookie, which is a small piece of data containing\nclient-specific information that is of interest to the server. Cookies are never\nexecuted by a browser; they are merely stored and sent to the server when\naccessed a next time.\nThe first time a client accesses a server, the latter sends a cookie along with\nthe requested Web pages back to the browser, after which the browser safely\n \nDS 4.01\n",
      "content_length": 3175,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 170,
      "content": "154\nCHAPTER 3. PROCESSES\ntucks the cookie away. Each subsequent time the client accesses the server, its\ncookie for that server is sent along with the request.\n3.4.2\nObject servers\nLet us take a look at the general organization of object servers needed for\ndistributed objects. The important difference between a general object server\nand other (more traditional) servers is that an object server by itself does not\nprovide a specific service. Specific services are implemented by the objects\nthat reside in the server. Essentially, the server provides only the means to\ninvoke local objects, based on requests from remote clients. As a consequence,\nit is relatively easy to change services by simply adding and removing objects.\nAn object server thus acts as a place where objects live. An object consists\nof two parts: data representing its state and the code for executing its methods.\nWhether these parts are separated, or whether method implementations are\nshared by multiple objects, depends on the object server. Furthermore, there\nare differences in the way an object server invokes its objects. For example,\nin a multithreaded server, each object may be assigned a separate thread, or\na separate thread may be used for each invocation request. These and other\nissues are discussed next.\nFor an object to be invoked, the object server needs to know which code to\nexecute, on which data it should operate, whether it should start a separate\nthread to take care of the invocation, and so on. A simple approach is to\nassume that all objects look alike and that there is only one way to invoke\nan object. Unfortunately, such an approach is generally inflexible and often\nunnecessarily constrains developers of distributed objects.\nA much better approach is for a server to support different policies. Con-\nsider, for example, a transient object: an object that exists only as long as\nits server exists, but possibly for a shorter period of time. An in-memory,\nread-only copy of a file could typically be implemented as a transient object.\nLikewise, a calculator could also be implemented as a transient object. A\nreasonable policy is to create a transient object at the first invocation request\nand to destroy it as soon as no clients are bound to it anymore.\nThe advantage of this approach is that a transient object will need a server’s\nresources only as long as the object is really needed. The drawback is that\nan invocation may take some time to complete because the object needs to\nbe created first. Therefore, an alternative policy is sometimes to create all\ntransient objects at the time the server is initialized, at the cost of consuming\nresources even when no client is making use of the object.\nSimilarly, a server could follow the policy that each of its objects is placed\nin a memory segment of its own. In other words, objects share neither code\nnor data. Such a policy may be necessary when an object implementation\ndoes not separate code and data, or when objects need to be separated for\nsecurity reasons. In the latter case, the server will need to provide special\nDS 4.01\n \n",
      "content_length": 3098,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 171,
      "content": "3.4. SERVERS\n155\nmeasures, or require support from the underlying operating system, to ensure\nthat segment boundaries are not violated.\nThe alternative approach is to let objects at least share their code. For\nexample, a database containing objects that belong to the same class can be\nefficiently implemented by loading the class implementation only once into\nthe server. When a request for an object invocation comes in, the server need\nonly fetch that object’s state and execute the requested method.\nLikewise, there are many policies regarding threading.\nThe simplest\napproach is to implement the server with only a single thread of control.\nAlternatively, the server may have several threads, one for each of its objects.\nWhenever an invocation request comes in for an object, the server passes the\nrequest to the thread responsible for that object. If the thread is currently busy,\nthe request is temporarily queued.\nThe advantage of this approach is that objects are automatically protected\nagainst concurrent access: all invocations are serialized through the single\nthread associated with the object. Neat and simple. Of course, it is also\npossible to use a separate thread for each invocation request, requiring that\nobjects should have already been protected against concurrent access. Inde-\npendent of using a thread per object or thread per method is the choice of\nwhether threads are created on demand or the server maintains a pool of\nthreads. Generally, there is no single best policy. Which one to use depends\non whether threads are available, how much performance matters, etc.\nDecisions on how to invoke an object are commonly referred to as activa-\ntion policies, to emphasize that often the object itself must first be brought\ninto the server’s address space (i.e., activated) before it can actually be in-\nvoked. What is needed then is a mechanism to group objects per policy. Such\na mechanism is sometimes called an object adapter, or alternatively an object\nwrapper. An object adapter can best be thought of as software implementing\na specific activation policy. The main issue, however, is that object adapters\ncome as generic components to assist developers of distributed objects, and\nwhich need only to be configured for a specific policy.\nAn object adapter has one or more objects under its control. Because a\nserver should be capable of simultaneously supporting objects that require\ndifferent activation policies, several object adapters may reside in the same\nserver. When an invocation request is delivered to the server, the request is\nfirst dispatched to the appropriate object adapter, as shown in Figure 3.20.\nAn important observation is that object adapters are unaware of the specific\ninterfaces of the objects they control. Otherwise, they could never be generic.\nThe only issue that is important to an object adapter is that it can extract an\nobject reference from an invocation request, and subsequently dispatch the\nrequest to the referenced object, but now following a specific activation policy.\nAs is also illustrated in Figure 3.20, rather than passing the request directly\nto the object, an adapter hands an invocation request to the server-side stub\n \nDS 4.01\n",
      "content_length": 3209,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 172,
      "content": "156\nCHAPTER 3. PROCESSES\nFigure 3.20: An object server supporting different activation policies.\nof that object. The stub, also called a skeleton, is normally generated from\nthe interface definitions of the object, unmarshals the request and invokes the\nappropriate method.\nAn object adapter can support different activation policies by simply\nconfiguring it at runtime. For example, in CORBA-compliant systems [OMG,\n2001], it is possible to specify whether an object should continue to exist after\nits associated adapter has stopped. Likewise, an adapter can be configured to\ngenerate object identifiers, or to let the application provide one. An adapter\ncan also be configured to operate in single-threaded or multithreaded mode.\nNote that although in Figure 3.20 we have spoken about objects, we\nhave said nothing about what these objects actually are. In particular, it\nshould be stressed that as part of the implementation of such an object the\nserver may (indirectly) access databases or call special library routines. The\nimplementation details are hidden for the object adapter, who communicates\nonly with a skeleton. As such, the actual implementation may have nothing\nto do with what we often see with language-level (i.e., compile-time) objects.\nFor this reason, a different terminology is generally adopted. A servant is the\ngeneral term for a piece of code that forms the implementation of an object.\nExample: The Ice runtime system\nLet us briefly consider the Ice distributed-object system, which has been partly\ndeveloped in response to the intricacies of commercial object-based distributed\nsystems [Henning, 2004]. An object server in Ice is nothing but an ordinary\nprocess that simply starts with initializing the Ice runtime system. The basis\nDS 4.01\n \n",
      "content_length": 1772,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 173,
      "content": "3.4. SERVERS\n157\nof the runtime environment is formed by what is called a communicator. A\ncommunicator is a component that manages several basic resources, of which\nthe most important one is formed by a pool of threads. Likewise, it will\nhave associated dynamically allocated memory, and so on. In addition, a\ncommunicator provides the means for configuring the environment. For\nexample, it is possible to specify maximum message lengths, maximum\ninvocation retries, and so on.\nNormally, an object server would have only a single communicator. How-\never, when different applications need to be fully separated and protected\nfrom each other, a separate communicator (with possibly a different config-\nuration) can be created within the same process. At the very least, such an\napproach would separate the different thread pools so that if one application\nhas consumed all its threads, then this would not affect the other application.\nA communicator is used to create an object adapter, such as shown in\nFigure 3.21. In this example, we start with creating and initializing the runtime\nenvironment, which returns a communicator. Using the communicator, an\nobject adapter is created. In this case, it is instructed to listen for incoming\nTCP connections on port 11000. Note that the adapter is created in the context\nof the just created communicator. We are now in the position to create objects\nand add those to the adapter. In this case, we create two objects, object1\nand object2, respectively. Both are added to the adapter, yet under different\nnames. What we see here, is that the adapter will be listening for incoming\nrequests on a single port, yet will use an object’s name to invoke the proper\nobject. Once the objects have been added, the adapter is activated, meaning\nthat, under the hood, a thread is activated that will start listening for incoming\nrequests.\nOn the client side, we see that two printer objects are created, one for each\nof their server-side counterparts. And, indeed, after starting the server and\nthen the client, the output on the server’s side will match:\nObject1 says: Hello World from printer1!\nObject2 says: Hello World from printer2!\nNote that if we had associated printer2 in line 9 of the client with base1, the\noutput would have been:\nObject1 says: Hello World from printer1!\nObject1 says: Hello World from printer2!\nIn other words, printer2 would have been associated to object1 instead of\nobject2.\nThis code does not yet show much differentiation in activation policies.\nPolicies can be changed by modifying the properties of an adapter. One family\nof properties is related to maintaining an adapter-specific set of threads that\nare used for handling incoming requests. For example, one can specify that\n \nDS 4.01\n",
      "content_length": 2754,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 174,
      "content": "158\nCHAPTER 3. PROCESSES\n1 import sys, Ice\n2 import Demo\n3\n4 class PrinterI(Demo.Printer):\n5\ndef __init__(self, t):\n6\nself.t = t\n7\n8\ndef printString(self, s, current=None):\n9\nprint(self.t, s)\n10\n11 communicator = Ice.initialize(sys.argv)\n12\n13 adapter = communicator.createObjectAdapterWithEndpoints(\"SimpleAdapter\", \"default -p 11000\")\n14 object1 = PrinterI(\"Object1 says:\")\n15 object2 = PrinterI(\"Object2 says:\")\n16 adapter.add(object1, communicator.stringToIdentity(\"SimplePrinter1\"))\n17 adapter.add(object2, communicator.stringToIdentity(\"SimplePrinter2\"))\n18 adapter.activate()\n19\n20 communicator.waitForShutdown()\n(a)\n1 import sys, Ice\n2 import Demo\n3\n4 communicator = Ice.initialize(sys.argv)\n5\n6 base1 = communicator.stringToProxy(\"SimplePrinter1:default -p 11000\")\n7 base2 = communicator.stringToProxy(\"SimplePrinter2:default -p 11000\")\n8 printer1 = Demo.PrinterPrx.checkedCast(base1)\n9 printer2 = Demo.PrinterPrx.checkedCast(base2)\n10 if (not printer1) or (not printer2):\n11\nraise RuntimeError(\"Invalid proxy\")\n12\n13 printer1.printString(\"Hello World from printer1!\")\n14 printer2.printString(\"Hello World from printer2!\")\n15\n16 communicator.waitForShutdown()\n(b)\nFigure 3.21: (a) An example of creating a simple object server in Ice, and (b) a\ncorresponding client (slightly adapted from [ZeroC, 2022]).\nthere should always be only one thread, effectively serializing all accesses to\nobjects that have been added to the adapter.\nIn the example above, an object is created as part of the application, after\nwhich it is added to an adapter. Effectively, this means that an adapter may\nneed to support many objects at the same time, leading to potential scalability\nproblems. An alternative solution is to dynamically load objects into memory\nwhen they are needed. To do this, Ice provides support for special objects\nknown as locators. A locator can be viewed as a special type of servant; it is\nDS 4.01\n \n",
      "content_length": 1914,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 175,
      "content": "3.4. SERVERS\n159\ncalled when the adapter receives an incoming request for an object that has\nnot been explicitly added. In that case, the request is forwarded to the locator,\nwhose job is to further handle the request.\nTo make matters more concrete, suppose a locator is handed a request\nfor an object of which the locator knows that its state is stored in a relational\ndatabase system. Of course, there is no magic here: the locator has been\nprogrammed explicitly to handle such requests. In this case, the object’s\nidentifier may correspond to the key of a record in which that state is stored.\nThe locator will then simply do a lookup on that key, fetch the state, and will\nthen be able to further process the request.\nThere can be more than one locator added to an adapter. In that case,\nthe adapter would keep track of which object identifiers would belong to the\nsame locator. Using multiple locators allows supporting many objects by a\nsingle adapter. Of course, objects (or rather their state) would need to be\nloaded at runtime, but this dynamic behavior would possibly make the server\nitself relatively simple. More examples and detailed information on Ice can be\nfound in [ZeroC, 2022].\n3.4.3\nExample: The Apache Web server\nAn interesting example of a server that balances the separation between\npolicies and mechanisms is the Apache Web server. It is also an extremely\npopular server, estimated to be used to host approximately 25% of all Websites.\nApache is a complex piece of software, and with the numerous enhancements\nto the types of documents that are now offered on the Web, it is important\nthat the server be highly configurable and extensible, and at the same time\nlargely independent of specific platforms.\nMaking the server platform independent is realized by essentially provid-\ning its own basic runtime environment, which is then subsequently imple-\nmented for different operating systems. This runtime environment, known as\nthe Apache Portable Runtime (APR), is a library that provides a platform-\nindependent interface for file handling, networking, locking, threads, and so\non. When extending Apache, portability is largely guaranteed provided that\nonly calls to the APR are made and none to platform-specific libraries.\nFrom a certain perspective, Apache can be considered as a completely gen-\neral server tailored to produce a response to an incoming request. Of course,\nthere are all kinds of hidden dependencies and assumptions by which Apache\nturns out to be primarily suited for handling requests for Web documents.\nFor example, as we mentioned, Web browsers and servers use HTTP as their\ncommunication protocol. HTTP is virtually always implemented on top of\nTCP, for which reason the core of Apache assumes that all incoming requests\nadhere to a TCP-based connection-oriented way of communication. Requests\nbased on UDP cannot be handled without modifying the Apache core.\n \nDS 4.01\n",
      "content_length": 2920,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 176,
      "content": "160\nCHAPTER 3. PROCESSES\nFigure 3.22: The general organization of the Apache Web server.\nOtherwise, the Apache core makes few assumptions on how incoming\nrequests should be handled. Its overall organization is shown in Figure 3.22.\nFundamental to this organization are modules. A module consists of one, or\nseveral, functions that should be called for properly handling a request. This\nraises several questions:\n1. How do we ensure that a function is called in the first place?\n2. How do we ensure that a function is called at the right moment?\n3. How do we prevent that a function is called for a request it was not\nsupposed to handle?\nThe last question is actually the simplest: each function will be called (along\nwith the request), yet each function will return the value DECLINED if the\nrequest was not meant for it.\nGetting a function to be called at all is handled through a hook, which\nis a placeholder for a function. There is a hook for each function, and each\nmodule provides the Apache core with a list of hooks to its functions. By\nstatically or dynamically linking modules to the Apache core, we establish a\nconnection between a hook and its associated function.\nFor example, there is a hook to translate a URL to a local file name. Such a\ntranslation will almost certainly need to be done when processing a request.\nLikewise, there is a hook for writing information to a log, a hook for checking\na client’s identification, a hook for checking access rights, and a hook for\nDS 4.01\n \n",
      "content_length": 1498,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 177,
      "content": "3.4. SERVERS\n161\nchecking which MIME type the request is related to (e.g., to make sure that\nthe request can be properly handled). As shown in Figure 3.22, the hooks\nare processed in a specific order. It is here that we explicitly see that Apache\nenforces a specific flow of control concerning the processing of requests.\nOften, functions can be processed independently of each other: they\noperate in perfect isolation on a request. However, this may not be generally\nthe case, for which Apache distinguishes a number of phases. When hooking\nup a function to Apache, we need to specify whether that function should be\ncalled in the beginning, the middle, or the end of the total request-processing\nflow. If fine-grained control is necessary, one can also specify before or after\nwhich other module a function should be called. However, it is easily seen\nthat trying to develop functions that operate in isolation (and are, in effect,\nstateless) contributes to a modular design.\nMuch more on the Apache Web server can be found in the (by now some-\nwhat outdated) book by Laurie and Laurie [2002], as well as the developer’s\ndocumentation provided by Apache itself.\n3.4.4\nServer clusters\nIn Chapter 1, we briefly discussed cluster computing as one of the many\nappearances of distributed systems. We now take a closer look at the organiza-\ntion of server clusters, along with the salient design issues. We first consider\ncommon server clusters that are organized in local-area networks. A special\ngroup is formed by wide-area server clusters, which we subsequently discuss.\nLocal-area clusters\nSimply put, a server cluster is nothing else but a collection of machines\nconnected through a network, where each machine runs one or more servers.\nThe server clusters that we consider here, are the ones in which the machines\nare connected through a local-area network, often offering high bandwidth\nand low latency.\nGeneral organization\nOften, a server cluster is logically organized into three\ntiers, as shown in Figure 3.23. The first tier consists of a (logical) switch\nthrough which client requests are routed. Such a switch can vary widely. For\nexample, transport-layer switches accept incoming TCP connection requests\nand pass requests on to one of the servers in the cluster. A completely different\nexample is a Web server that accepts incoming HTTP requests, but that partly\npasses requests to application servers for further processing only to later\ncollect results from those servers and return an HTTP response.\nAs in any multitiered client-server architecture, many server clusters also\ncontain servers dedicated to application processing. In cluster computing,\nthese are typically servers running on high-performance hardware dedicated\n \nDS 4.01\n",
      "content_length": 2751,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 178,
      "content": "162\nCHAPTER 3. PROCESSES\nLogical switch\n(possibly multiple)\nApplication/compute servers\nDistributed\nfile/database\nsystem\nClient requests\nDispatched\nrequest\nFirst tier\nSecond tier\nThird tier\nFigure 3.23: The general organization of a three-tiered server cluster.\nto delivering compute power.\nHowever, in the case of enterprise server\nclusters, it may be the case that applications need only run on relatively\nlow-end machines, as the required compute power is not the bottleneck, but\naccess to storage is.\nThis brings us to the third tier, which consists of data-processing servers,\nnotably file and database servers. Again, depending on the usage of the server\ncluster, these servers may be running on specialized machines, configured for\nhigh-speed disk access and having large server-side data caches.\nOf course, not all server clusters will follow this strict separation. It is\nfrequently the case that each machine is equipped with its own local storage,\noften integrating application and data processing in a single server, leading\nto a two-tiered architecture. For example, when dealing with streaming\nmedia using a server cluster, it is common to deploy a two-tiered system\narchitecture, where each machine acts as a dedicated media server [Steinmetz\nand Nahrstedt, 2004].\nWhen a server cluster offers multiple services, different machines may run\ndifferent application servers. As a consequence, the switch will have to be\nable to distinguish services, or otherwise it cannot forward requests to the\nproper machines. As a consequence, we may find that certain machines are\ntemporarily idle, while others are receiving an overload of requests. What\nwould be useful is to temporarily migrate services to idle machines. A solution\nis to use virtual machines, allowing a relatively easy migration of services.\nRequest dispatching\nLet us now take a closer look at the first tier, consisting\nof the switch, also known as the front end. An important design goal for\nserver clusters is to hide the fact that there are multiple servers. In other\nwords, client applications running on remote machines should have no need\nto know anything about the internal organization of the cluster. This access\nDS 4.01\n \n",
      "content_length": 2206,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 179,
      "content": "3.4. SERVERS\n163\ntransparency is invariably offered through a single access point, in turn\nimplemented through some kind of hardware switch such as a dedicated\nmachine.\nThe switch forms the entry point for the server cluster, offering a single\nnetwork address. For scalability and availability, a server cluster may have\nmultiple access points, where each access point is then realized by a separate\ndedicated machine. We consider only the case of a single access point.\nIn practice, we see two types of switches. In the case of transport-layer\nswitches, the switch accepts incoming TCP connection requests, and hands\noff such connections to one of the servers. The client sets up a TCP connection\nsuch that all requests and responses pass through the switch. The switch,\nin turn, will set up a TCP connection with a selected server and pass client\nrequests to that server, and also accept server responses (which it will pass\non to the client). In effect, the switch sits in the middle of a TCP connection\nbetween the client and a selected server, rewriting the source and destination\naddresses when passing TCP segments. This approach is a form of network-\naddress translation (NAT) [Srisuresh and Holdrege, 1999].\nAs an alternative, application-layer switches are used. As its name suggest,\nan application-layer switch operates by inspecting the content of requests\ninstead of just looking at information available in TCP. For example, the\nswitch can inspect the actual URL in case of a Web server. This distinction\nallows for developing server clusters in which dedicated machines can be\nconfigured for handling, for example, video or other media, next to those\nrequiring access to specific databases, etc. In general, the more a switch knows\nabout what is being requested, the better it can decide on which server to\nhandle the request. An obvious drawback of application-layer switches is that\nthey may be slower than transport-layer switches. On the other hand, using\nthe right software and hardware, costs can be kept acceptable low. This is\ndemonstrated, for example, by the nginx server, which has been designed to\nhandle thousands of simultaneous connections and is used for many sites as\nwhat is also called a reverse proxy [DeJonghe, 2022]. Note that the Apache\nWeb server can also be configured as an application-layer switch.\nNote 3.7 (Example: TCP handoff)\nIn the days that request dispatching was relatively expensive, a simple and elegant\nway of ensuring that performance criteria could still be met, was by implementing\nTCP handoff. The idea is a switch can actually hand off the connection to a\nselected server such that all responses are directly communicated to the client\nwithout passing through the switch [Hunt et al., 1997; Pai et al., 1998]. The\nprinciple working is shown in Figure 3.24.\nWhen the switch receives a TCP connection request, it first identifies the best\nserver for handling that request, and forwards the request packet to that server.\nThe server, in turn, will send an acknowledgment back to the requesting client, but\n \nDS 4.01\n",
      "content_length": 3072,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 180,
      "content": "164\nCHAPTER 3. PROCESSES\ninserting the switch’s IP address as the source field of the header of the IP packet\ncarrying the TCP segment. Note that this address rewriting is necessary for the\nclient to continue executing the TCP protocol: it is expecting an answer back from\nthe switch, not from some arbitrary server it has never heard of before. Clearly, a\nTCP-handoff implementation requires operating-system level modifications. TCP\nhandoff is especially effective when responses are much larger than requests, as\nin the case of Web servers.\nFigure 3.24: The principle of TCP handoff.\nIt can already be seen that the switch can play an important role in distributing\nthe load among the various servers. By deciding where to forward a request to,\nthe switch also decides which server is to handle further processing of the request.\nThe simplest load-balancing policy that the switch can follow is round robin: each\ntime it picks the next server from its list to forward a request to. Of course, the\nswitch will have to keep track to which server it handed off a TCP connection, at\nleast until that connection is torn down. As it turns out, maintaining this state\nand handing off subsequent TCP segments belonging to the same TCP connection,\nmay actually slow down the switch.\nWide-area clusters\nWe came across wide-area clusters in our discussion on PlanetLab (see Note 3.6):\nan architecture in which participants contribute some (relatively simple) ma-\nchines for hosting containers that are subsequently “sliced” across as many\nmachines as a client needs. Thereafter, the client is on her own. Much more\nsophisticated and commercially deployed wide-area clusters exist today.\nA straightforward version is seen with cloud providers like Amazon\nand Google, who manage several data centers placed at different locations\nworldwide. As such, they can offer an end user the ability to build a wide-area\ndistributed system consisting of a potentially large collection of networked\nvirtual machines, scattered across the Internet. An important reason for\nwanting such distributed systems is to provide locality: offering data and\nservices that are close to clients. An example where such locality is important\nis streaming media: the closer a video server is located to a client, the easier\nDS 4.01\n \n",
      "content_length": 2296,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 181,
      "content": "3.4. SERVERS\n165\nit becomes to provide high-quality streams. This approach is followed by\nso-called cloud-based Content Delivery Networks, or simply CDNs, which\nwe will discuss shortly.\nAn alternative is to have a single organization place servers across the\nInternet, effectively negotiating with local ISPs to decide how to make use\nof their facilities. This is the approach followed by the Akamai CDN [Dilley\net al., 2002; Nygren et al., 2010], in 2022 having some 400,000 servers spread\nacross 1350 ISPs and more than 135 countries.\nThe general organization of a CDN\nAs CDNs form an important group of\ndistributed systems that make use of wide-area clusters, let us take a closer\nlook at how they are generally organized. We take a simplified view of the\nAkamai organization, shown in Figure 3.25. More information on CDNs\ncan be found in [Passarella, 2012; Stocker et al., 2017] and [Zolfaghari et al.,\n2021]. The basic idea is that there is an origin server that hosts a Website\nwith all its documents. As we will explain in Chapter 6, each document of\nsuch a site is referred to by a URL containing the domain name of the origin\nserver, such as www.example.com. To access a document, the domain name\nneeds to be resolved to a network address, which is done by the Domain\nName System, which we will discuss in detail also in Chapter 6. To have\nthe content of the origin server be hosted by a CDN, Akamai first makes\nsure that the domain name www.example.com is resolved to something like\nwww.example.com.akamai.net, which, in turn, will refer to an edge server that\nis part of the Akamai CDN. To be able to still access the origin server, its\ndomain name will have to be changed to, say, org-www.example.com. The\nprinciple is shown in Figure 3.25.\nThe client first looks up the regular domain name, but is redirected to the\nFigure 3.25: A simplified version of the working of the Akamai CDN.\n \nDS 4.01\n",
      "content_length": 1908,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 182,
      "content": "166\nCHAPTER 3. PROCESSES\nakamai.net resolvers (step 1). The Akamai name resolvers will look up the\nbest edge server to serve the client, and return its network address (step 2).\nThis allows the client to contact the edge server (step 3), who is aware of the\nnew name of the origin server. If the requested content is not in the edge\nserver’s cache, it fetches documents from the origin server (step 4), caches\nthose documents and returns the requested ones to the client. More details\ncan be found in [Su et al., 2006].\nRequest dispatching\nThis example already shows the importance of client-\nrequest redirection. In principle, by properly redirecting clients, a CDN\ncan stay in control when it comes to client-perceived performance, but also\nconsidering global system performance by, for example, avoiding that requests\nare sent to heavily loaded servers.\nThese so-called adaptive redirection\npolicies can be applied when information on the system’s current behavior is\nprovided to the processes that take redirection decisions.\nAn important issue is whether request redirection is transparent to the\nclient or not. In essence, there are only three redirection techniques: TCP\nhandoff, DNS redirection, and HTTP redirection. We discussed TCP handoff\nin Note 3.7. This technique is applicable only for server clusters and does not\nscale to wide-area networks.\nDNS redirection is a transparent mechanism by which the client can be\nkept completely unaware of where documents are located. Akamai’s two-level\nredirection is one example of this technique. We can also directly deploy DNS\nto return one of several addresses. Note, however, that DNS redirection can\nbe applied only to an entire site (or, more specifically, only at the level of a\ndomain name): the name of individual documents does not fit into the DNS\nname space.\nUnfortunately, DNS redirection is not perfect for two reasons. First, a\nclient generally contacts the Domain Name System through a local DNS\nserver that then acts as a proxy for that client. As a consequence, not the\nclient’s IP address, but that of the local DNS server, is used to identify the\nlocation of the client. Mao et al. [2002] have shown that there may be a huge\nadditional communication cost, as the local DNS server is often not that local.\nFurthermore, even when clients are returned several options for selecting\nan edge server, simply picking the first on the list, which is what normally\nhappens, may not be the best choice [Goel et al., 2015].\nSecondly, depending on the scheme that is used for resolving a domain\nname, it may even be the case that the address of the local DNS server is not\neven being used. Instead, it may happen that the DNS server that is deciding\non which IP address to return, may be fooled by the fact that the requester is\nyet another DNS server acting as an intermediate between the original client\nand the deciding DNS server (we will explain the details of this scheme in\nChapter 6. In those cases, locality awareness has been completely lost.\nDS 4.01\n \n",
      "content_length": 3025,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 183,
      "content": "3.5. CODE MIGRATION\n167\nDespite that DNS-based redirection may not always be very accurate, it\nis widely deployed if only for the fact that it is relatively easy to implement\nand also transparent to the client. In addition, there is no need to rely on\nlocation-aware client-side software.\nHTTP redirection, finally, is a nontransparent mechanism. When a client\nrequests a specific document, it may be given an alternative URL as part of\nan HTTP response message, to which it is then redirected. An important\nobservation is that this URL is visible to the client’s browser. In fact, the\nuser may decide to bookmark the referral URL, potentially rendering the\nredirection policy useless.\n3.5\nCode migration\nSo far, we have been mainly concerned with distributed systems in which\ncommunication is limited to passing data. However, there are situations\nin which passing programs, sometimes even while they are being executed,\nsimplifies the design of a distributed system. In this section, we take a detailed\nlook at what code migration actually is.\n3.5.1\nReasons for migrating code\nTraditionally, code migration in distributed systems took place in the form\nof process migration in which an entire process was moved from one node\nto another [Milojicic et al., 2000]. Moving a running process to a different\nmachine is a costly and intricate task, and there had better be a good reason\nfor doing so. Let us first consider why one would even want to migrate code\nfrom one machine to another.\nPerformance\nBy far the most important reason for code migration has always\nbeen performance. The basic idea is that overall system performance can\nbe improved if processes are moved from heavily loaded to lightly loaded\nmachines. Load is often expressed in terms of the CPU queue length or\nCPU utilization, but other performance indicators are used as well. When\ncompleting their survey, Milojicic et al. had already come to the conclusion\nthat process migration was no longer a viable option for improving distributed\nsystems.\nInstead of offloading machines, we can now witness that code is moved\nto make sure that a machine is sufficiently loaded. In particular, migrating\ncomplete virtual machines with their suite of applications to lightly loaded\nmachines to minimize the total number of nodes being used is common\npractice in optimizing energy usage in data centers. Interestingly enough,\nalthough migrating virtual machines may require more resources, the task\nitself is far less intricate than migrating a process, as we discuss below.\n \nDS 4.01\n",
      "content_length": 2541,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 184,
      "content": "168\nCHAPTER 3. PROCESSES\nIn general, load-distribution algorithms by which decisions are made con-\ncerning the allocation and redistribution of tasks regarding a set of machines,\nplay an important role in compute-intensive systems. However, in many\nmodern distributed systems, optimizing computing capacity is less an issue\nthan, for example, trying to minimize communication. Moreover, due to the\nheterogeneity of the underlying platforms and computer networks, perfor-\nmance improvement through code migration is often based on qualitative\nreasoning instead of mathematical models.\nConsider, as an example, a client-server system in which the server man-\nages a huge database. If a client application needs to perform many database\noperations involving large quantities of data, it may be better to ship part\nof the client application to the server and send only the results across the\nnetwork. Otherwise, the network may be swamped with the transfer of data\nfrom the server to the client. In this case, code migration is assuming that it\ngenerally makes sense to process data close to where those data reside.\nThis same reason can be used for migrating parts of the server to the client.\nFor example, in many interactive database applications, clients need to fill in\nforms that are subsequently translated into a series of database operations.\nProcessing the form at the client side, and sending only the completed form\nto the server, can sometimes avoid that a relatively large number of small\nmessages need to cross the network. The result is that the client perceives\nbetter performance, while at the same time the server spends less time on\nform processing and communication. In the case of smartphones, moving\ncode to be executed at the handheld instead of the server may be the only\nviable solution to obtain acceptable performance, both for the client and the\nserver (see Kumar et al. [2013] for a survey on offloading computations).\nSupport for code migration can also help improve performance by ex-\nploiting parallelism, but without the usual intricacies related to parallel pro-\ngramming. A typical example is searching for information in the Web. It is\nrelatively simple to implement a search query in the form of a small mobile\nprogram, called a mobile agent, that moves from site to site. By making\nseveral copies of such a program, and sending each off to different sites, we\nmay be able to achieve a linear speed-up compared to using just a single\nprogram instance. However, Carzaniga et al. [2007] conclude that mobile\nagents have never become successful because they did not really offer an\nobvious advantage over other technologies.\nPrivacy and security\nAnother reason for moving code to where the data is,\nhas to do with security. Recently, the canonical example for this approach\nis found in federated learning. Federated learning comes from the need to\ntrain machine-learning models, notably all kinds of variants of artificial neural\nnetworks. To keep it simple, a neural network consists of a collection of nodes,\norganized as a series of several layers, and having weighted links between\nDS 4.01\n \n",
      "content_length": 3127,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 185,
      "content": "3.5. CODE MIGRATION\n169\nFigure 3.26: The principle of federated learning.\nnodes of successive layers. Each node puts data on its outgoing links, which\nis the result of a (relatively simple) computation that it gets from data on its\nincoming links. Links have an adjustable weight. During a training phase,\nthe weights of the links are gradually computed by feeding the network with\ndata items for which it is known what the network should produce as a result.\nBy systematically adjusting the weights to minimize the difference between\nwhat a network produces and what it should have produced, we eventually\nestablish a final model. That model can then be used on unknown data items,\nfor which we then take the produced result as a given.\nA traditional approach is to collect the training data at a centralized\nlocation, often using specialized high-performance computers to construct\nan acceptable model. Obviously, this could mean that sensitive data, such as\npersonal photo’s and such, needed to be handed out to an organization that\nsomeone may not trust.\nIn such cases, a better approach is to bring the (partially) trained model to\nwhere the data is, and continue training with that local data. This will lead\nto an updated model (i.e., the weights have been further adjusted because of\nusing new data). If several entities are involved in training with local data,\na server can simply collect the different models, aggregate the results, and\nreturn an updated model to the local participants who can then continue\nwith training. This iterative process, sketched in Figure 3.26 stops when the\naggregated model is deemed sufficiently trained and fit for actual use.\nIt must be said that federated learning is easier from a code-migration\nperspective than, e.g., migrating processes. In general, the code involved in a\nneural network is relatively straightforward, which makes it easier to have it\nadopted by a local participant. This has been a high-level view on federated\nlearning, of which a good introduction is given by Zhang et al. [2021a]. As\ndescribed in Lyu et al. [2020], simply doing local training may not be sufficient\nfrom a privacy and security perspective.\n \nDS 4.01\n",
      "content_length": 2187,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 186,
      "content": "170\nCHAPTER 3. PROCESSES\nFlexibility\nThere are other reasons for supporting code migration as well.\nAn important one is that of flexibility. The traditional approach to building\ndistributed applications is to partition the application into different parts, and\ndecide in advance where each part should be executed. This approach, for\nexample, has lead to different multitiered client-server applications discussed\nin Chapter 2.\nHowever, if code can move between different machines, it becomes possible\nto dynamically configure distributed systems. For example, suppose a server\nimplements a standardized interface to a file system. To allow remote clients\nto access the file system, the server makes use of a proprietary protocol.\nNormally, the client-side implementation of the file system interface, which is\nbased on that protocol, would need to be linked with the client application.\nThis approach requires that the software be readily available to the client at\nthe time the client application is being developed.\nAn alternative is to let the server provide the client’s implementation no\nsooner than is strictly necessary, that is, when the client binds to the server.\nAt that point, the client dynamically downloads the implementation, goes\nthrough the necessary initialization steps, and subsequently invokes the server.\nThis principle is shown in Figure 3.27 (we note that the code repository is\ngenerally located as part of the server). This model of dynamically moving\ncode from a remote site does require that the protocol for downloading\nand initializing code is standardized. Furthermore, it is necessary that the\ndownloaded code can be executed on the client’s machine. Typically, scripts\nthat run in a virtual machine embedded in, for example, a Web browser, will\ndo the trick. Arguably, this form of code migration has been key to the success\nof the dynamic Web. These and other solutions are discussed below and in\nlater chapters.\nFigure 3.27: The principle of dynamically configuring a client to communicate\nwith a server.\nThe important advantage of this model of dynamically downloading client-\nside software is that clients need not have all the software preinstalled to talk\nDS 4.01\n \n",
      "content_length": 2207,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 187,
      "content": "3.5. CODE MIGRATION\n171\nto servers. Instead, the software can be moved in as necessary, and likewise,\ndiscarded when no longer needed. Another advantage is that as long as\ninterfaces are standardized, we can change the client-server protocol and its\nimplementation as often as we like. Changes will not affect existing client\napplications that rely on the server.\nThere are, of course, also disadvantages. The most serious one, which\nwe discuss in Chapter 9, has to do with security. Blindly trusting that the\ndownloaded code implements only the advertised interface while accessing\nyour unprotected hard disk and does not send the juiciest parts to heaven-\nknows-who may not always be such a good idea. Fortunately, it is well\nunderstood how to protect the client against malicious, downloaded code.\nNote 3.8 (More information: Moving away from thin-client computing?)\nBy now, there is much more insight and expertise concerning transparent and\nsafe dynamic migration of code to clients. As a result, the trend that we described\nin Note 2.5 of moving toward thin-client computing because managing client-\nside software often turned out to be cumbersome, has been partly reverted. By\ndynamically migrating client-side software, yet keeping the management of that\nsoftware entirely at the server side (or rather, at its owner), having “richer” client-\nside software has become practically feasible. The most important domain where\nwe see this happening is through applications running on smartphones. In fact,\nas soon as, for example, a bug is discovered, and update can take place. It is for\nthis reason why many banks consider it safer to use a mobile app instead of a\nfixed piece of client-side software.\n3.5.2\nModels for code migration\nAlthough code migration suggests that we move only code between machines,\nthe term actually covers a much richer area. Traditionally, communication in\ndistributed systems is concerned with exchanging data between processes.\nCode migration in the broadest sense deals with moving programs between\nmachines, with the intention to have those programs be executed at the target.\nIn some cases, as in process migration, the execution status of a program,\npending signals, and other parts of the environment must be moved as well.\nTo get a better understanding of the different models for code migration,\nwe use a framework proposed by Fuggetta et al. [1998]. In this framework, a\nprocess consists of three segments. The code segment is the part that contains\nthe set of instructions that make up the program that is being executed. The\nresource segment contains references to external resources needed by the\nprocess, such as files, printers, devices, other processes, and so on. Finally, an\nexecution segment is used to store the current execution state of a process,\nconsisting of private data, the stack, and, of course, the program counter.\n \nDS 4.01\n",
      "content_length": 2889,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 188,
      "content": "172\nCHAPTER 3. PROCESSES\nA further distinction can be made between sender-initiated and receiver-\ninitiated migration. In sender-initiated migration, migration is initiated at\nthe machine where the code currently resides or is being executed. Typically,\nsender-initiated migration is done when uploading programs to a compute\nserver. Another example is sending a query, or batch of queries, to a remote\ndatabase server. In receiver-initiated migration, the initiative for code mi-\ngration is taken by the target machine. Java applets are an example of this\napproach.\nReceiver-initiated migration is simpler than sender-initiated migration.\nOften, code migration occurs between a client and a server, where the client\ntakes the initiative for migration. Securely uploading code to a server, as is\ndone in sender-initiated migration, often requires that the client has previ-\nously been registered and authenticated at that server. In other words, the\nserver is required to know all its clients, the reason being is that the client\nwill presumably want access to the server’s resources such as its disk. Pro-\ntecting such resources is essential. In contrast, downloading code, as in the\nreceiver-initiated case, can often be done anonymously. Moreover, the server\nis generally not interested in the client’s resources. Instead, code migration\nto the client is done only for improving client-side performance. To that end,\nonly a limited number of resources need to be protected, such as memory and\nnetwork connections.\nThis brings us to four different paradigms for code mobility, as shown in\nFigure 3.28. Following Fuggetta et al. [1998], we make a distinction between\nsimple client-server computing, remote evaluation, code-on-demand, and\nmobile agents. Figure 3.28 shows the situation at respectively the client and\nthe server, before and after execution of the mobile code.\nIn the case of client-server computing, the code, execution state, and\nresource segment are all located at the server, and after execution, only the\nexecution state at the server is generally modified. This state modification is\ndenoted using an asterisk. With the sender-initiated remote evaluation, the\nclient migrates code to the server where that code is executed and leading\nto a modification of the execution state at the server. Code-on-demand is a\nreceiver-initiated scheme by which the client obtains code from the server,\nwith its execution modifying the client-side execution state and operating on\nthe client’s resources. Finally, mobile agents typically follow a sender-initiated\napproach, moving code as well as execution state from the client to the server,\noperating on both the client’s and the server’s resources. Running a mobile\nagent will generally lead to modification of the associated execution state.\nThe bare minimum for code migration is to provide only weak mobility.\nIn this model, it is possible to transfer only the code segment, along with\nperhaps some initialization data. A characteristic feature of weak mobility\nis that a transferred program is always started anew. This is what happens,\nfor example, with Java applets, which start from the same initial state. In\nDS 4.01\n \n",
      "content_length": 3186,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 189,
      "content": "3.5. CODE MIGRATION\n173\nBefore execution\nAfter execution\nClient\nServer\nClient\nServer\nCS\ncode\nexec\nresource\ncode\nexec*\nresource\nREV\ncode\n−→\nexec\nresource\n−→\ncode\nexec*\nresource\nCoD\nexec\nresource\n←−\ncode\ncode\nexec*\nresource\n←−\nMA\ncode\nexec\nresource\n−→\nresource\nresource\n−→\ncode\nexec*\nresource\nCS: Client-Server\nREV: Remote evaluation\nCoD: Code-on-demand\nMA: Mobile agents\nFigure 3.28: Four different paradigms for code mobility.\nother words, no history from where the migrated code left off at a previous\nlocation is maintained by the underlying middleware. If such history needs to\nbe preserved, it will have to be encoded as part of the mobile application itself.\nThe benefit of weak mobility is its simplicity, as it requires only that the target\nmachine can execute the code segment. In essence, this boils down to making\nthe code portable. We return to these matters when discussing migration in\nheterogeneous systems.\nIn contrast to weak mobility, in systems that support strong mobility\nthe execution segment can be transferred as well. The characteristic feature\nof strong mobility is that a running process can be stopped, subsequently\nmoved to another machine, and then resume execution exactly where it left off.\nClearly, strong mobility is much more general than weak mobility, but also\nmuch more difficult to implement. In particular, when migrating a process,\nthe execution segment generally also contains data that is highly dependent\non a specific implementation of the underlying operating system. For example,\nit may rely on information normally found in the operating system’s process\ntable. As a consequence, migrating to a different operating system, even one\nthat belongs to the same family as the source, may cause plenty of headaches.\n \nDS 4.01\n",
      "content_length": 1767,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 190,
      "content": "174\nCHAPTER 3. PROCESSES\nIn the case of weak mobility, it also makes a difference if the migrated code\nis executed by the target process, or whether a separate process is started.\nFor example, Java applets are simply downloaded by a Web browser and are\nexecuted in the browser’s address space. The benefit of this approach is that\nthere is no need to start a separate process, thereby avoiding interprocess\ncommunication at the target machine. The main drawback, obviously, is that\nthe target process needs to be protected against malicious or inadvertent code\nexecutions, which may be reason enough to isolate the migrated code in a\nseparate process.\nInstead of moving a running process, also referred to as process migration,\nstrong mobility can also be supported by remote cloning. In contrast to\nprocess migration, cloning yields an exact copy of the original process, but\nnow running on a different machine. The cloned process is executed in parallel\nto the original process. In Unix systems, remote cloning takes place by forking\noff a child process and letting that child continue on a remote machine. The\nbenefit of cloning is that the model closely resembles the one that is already\nused in many applications. The only difference is that the cloned process\nis executed on a different machine. In this sense, migration by cloning is a\nsimple way to improve distribution transparency.\n3.5.3\nMigration in heterogeneous systems\nSo far, we have tacitly assumed that the migrated code can be easily executed\nat the target machine. This assumption is in order when dealing with homo-\ngeneous systems. In general, however, distributed systems are constructed\non a heterogeneous collection of platforms, each having their own operating\nsystem and machine architecture.\nThe problems coming from heterogeneity are in many respects the same\nas those of portability. Not surprisingly, solutions are also very similar. For\nexample, at the end of the 1970s, a simple solution to alleviate many of the\nproblems of porting Pascal to different machines was to generate machine-\nindependent intermediate code for an abstract virtual machine [Barron, 1981].\nThat machine, of course, would need to be implemented on many platforms,\nbut it would then allow Pascal programs to be run anywhere. Although this\nsimple idea was widely used for some years, it never really caught on as the\ngeneral solution to portability problems for other languages, notably C.\nAbout 25 years later, code migration in heterogeneous systems is being\ntackled by scripting languages and highly portable languages such as Java\nand Python. In essence, these solutions adopt the same approach as was done\nfor porting Pascal. All such solutions have in common that they rely on a\n(process) virtual machine that either directly interprets source code (as in\nthe case of scripting languages), or otherwise interprets intermediate code\ngenerated by a compiler (as in Java). Being in the right place at the right time\nis also important for language developers.\nDS 4.01\n \n",
      "content_length": 3026,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 191,
      "content": "3.5. CODE MIGRATION\n175\nFurther developments have weakened the dependency on programming\nlanguages. In particular, solutions have been proposed to migrate not only\nprocesses, but to migrate entire computing environments. The basic idea\nis to compartmentalize the overall environment and to provide processes\nin the same part their own view on their computing environment. That\ncompartmentalization takes place in the form of virtual machine monitors\nrunning an operating system and a suite of applications.\nWith virtual machine migration, it becomes possible to decouple a com-\nputing environment from the underlying system and actually migrate it to\nanother machine (see Medina and Garcia [2014] or Zhang et al. [2018] for\noverviews on migration mechanisms for virtual machines). A major advantage\nof this approach is that processes can remain ignorant of the migration itself:\nthey need not be interrupted in their execution, nor should they experience\nany problems with used resources. The latter are either migrating along with\na process, or the way that a process accesses a resource is left unaffected (at\nleast, for that process).\nAs an example, Clark et al. [2005] concentrated on real-time migration of a\nvirtualized operating system, typically something that would be convenient\nin a cluster of servers where a tight coupling is achieved through a single,\nshared local-area network. Under these circumstances, migration involves two\nmajor problems: migrating the entire memory image and migrating bindings\nto local resources.\nAs to the first problem, there are, in principle, three ways to handle\nmigration (which can be combined):\n1. Pushing memory pages to the new machine and resending the ones that\nare later modified during the migration process.\n2. Stopping the current virtual machine; migrate memory, and start the\nnew virtual machine.\n3. Letting the new virtual machine pull in new pages as needed, that is,\nlet processes start on the new virtual machine immediately and copy\nmemory pages on demand.\nThe second option may lead to unacceptable downtime if the migrating\nvirtual machine is running a live service, that is, one that offers continuous\nservice. On the other hand, a pure on-demand approach as represented by\nthe third option may extensively prolong the migration period, but may also\nlead to poor performance because it takes a long time before the working set\nof the migrated processes has been moved to the new machine.\nAs an alternative, Clark et al. [2005] propose to use a pre-copy approach\nwhich combines the first option, along with a brief stop-and-copy phase as\nrepresented by the second option. As it turns out, this combination can lead\nto very low service downtimes.\n \nDS 4.01\n",
      "content_length": 2720,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 192,
      "content": "176\nCHAPTER 3. PROCESSES\nConcerning local resources, matters are simplified when dealing only with\na cluster server. First, because there is a single network, the only thing that\nneeds to be done is to announce the new network-to-MAC address binding, so\nthat clients can contact the migrated processes at the correct network interface.\nFinally, if it can be assumed that storage is provided as a separate tier (like we\nshowed in Figure 3.23), then migrating binding to files is similarly simple, as\nit effectively means reestablishing network connections.\nMatters become more intricate when we need to migrate a virtual machine\nto another data center. Although the transfer of memory can be largely\ndone as before, we do need to actually transfer files to the target data center.\nSomewhat problematic is also the network connectivity: one way or the other\nclients need to be able to continue contacting the virtual machine while, and\nafter, its migration to the new destination. Zhang et al. [2018] mention various\nsolutions. In essence, many of these either boil down to extending the local\nnetwork to the target using techniques such as tunneling, or using techniques\nthat support transparent reassigning of network addresses (meaning that a\nclient uses dynamic rebinding to actual network addresses).\nNote 3.9 (Advanced: On the performance of live virtual machine migration)\nOne potential problem with virtual-machine migration is that it may take consid-\nerable time. This by itself need not be bad, as long as the services that are running\non the migrating virtual machine can continue to operate. An approach used in\npractice was briefly described above. First, memory pages are copied to the target\nmachine, possibly sending updates of pages that were modified while copying\ntook place (remember that copying lots of memory may take tens of seconds, even\nacross a high-speed local network). Second, when most pages have been faithfully\ncopied, the current machine is stopped, the remaining dirty pages are copied to\nthe target, where the now exact copy can be started where the original left off.\nThe downtime in which the remaining dirty pages need to be copied depends\non the applications running on the virtual machine. Clark et al. [2005] report\ndowntimes for specific configurations between 60 milliseconds and less than 4\nseconds. Voorsluys et al. [2009] come to similar values. However, what may be\nmore interesting is to observe what the response time is of the service running\non the virtual machine while the latter is being migrated. The model in this\ncase is that the service continues to operate on the original machine until full\nmigration has completed. However, we cannot ignore that migration itself is a\nresource-intensive operation, requiring considerable processing capacity as well\nas network bandwidth.\nVoorsluys et al. [2009] have observed that a complete migration may actually\ntake tens of seconds, leading to a ten- to twentyfold increase in response time. In\naddition, we need to realize that during the migration, a service will be completely\nunavailable (i.e., unresponsive) for perhaps 4 seconds. The good news is that\nthe response time goes up significantly only after the downtime to complete the\nmigration, as shown in Figure 3.29.\nDS 4.01\n \n",
      "content_length": 3282,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 193,
      "content": "3.6. SUMMARY\n177\nOften, virtual machines are migrated to optimize the usage of actual machines.\nHowever, it may also be desirable to clone a virtual machine, for example because\nthe workload for the current machine is becoming too high. Such cloning is very\nsimilar to using multiple processes in concurrent servers, by which a dispatcher\nprocess creates worker processes to handle incoming requests. This scheme was\nexplained in Figure 3.6 when discussing multithreaded servers.\nFigure 3.29: The effect on the response time of a service while migrating\nits underlying virtual machine. Adapted from Voorsluys et al. [2009].\nWhen cloning for this type of performance, it often makes more sense not to\nfirst copy memory pages, but, in fact, start with as few pages as possible as the\nservice running on the cloned machine will essentially start anew. Note that this\nbehavior is very similar to the usual parent-child behavior we see when forking a\nUnix process. Namely, the child will start with loading its own executable, thereby\neffectively cleaning the memory it inherited from its parent. This analogy inspired\nLagar-Cavilla et al. [2009] to develop an analogous mechanism for forking a virtual\nmachine. However, unlike the mechanism used traditionally for migrating virtual\nmachines, their VM fork copies pages primarily on demand. The result is an\nextremely efficient cloning mechanism.\nIt is thus seen that there is no single best way to place copies of a virtual\nmachine on different physical machines: it very much depends on how and why\na virtual machine is being deployed.\n3.6\nSummary\nProcesses play a fundamental role in distributed systems, as they form a\nbasis for communication between different machines. An important issue\nis how processes are internally organized and, in particular, whether or not\nthey support multiple threads of control. Threads in distributed systems are\nparticularly useful to continue using the CPU when a blocking I/O operation\nis performed. In this way, it becomes possible to build highly efficient servers\nthat run multiple threads in parallel, of which several may be blocking to wait\nuntil disk I/O or network communication completes. In general, threads are\n \nDS 4.01\n",
      "content_length": 2215,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 194,
      "content": "178\nCHAPTER 3. PROCESSES\npreferred over the use of processes when performance is at stake.\nVirtualization has since long been an important field in computer science,\nbut in the advent of cloud computing has regained tremendous attention. Pop-\nular virtualization schemes allow users to run a suite of applications on top\nof their favorite operating system and configure complete virtual distributed\nsystems in the cloud. Impressively enough, performance remains close to run-\nning applications on the host operating system, unless that system is shared\nwith other virtual machines or when the virtual machine is I/O bound. The\nflexible application of virtual machines has led to different types of services\nfor cloud computing, including infrastructures, platforms, and software —\nall running in virtual environments. A special form of virtualization is that\nof containerization, which boils down to providing an application with its\nown environment (notably libraries and specific supporting programs) while\nsharing the same operating system. By sharing the same operating system,\ncontainers generally tend to perform better in the case of I/O-bound appli-\ncations, yet it is fair to say that differences in performance between virtual\nmachines and containers is diminishing.\nOrganizing a distributed application in terms of clients and servers has\nproven to be useful. Client processes generally implement user interfaces,\nwhich may range from simple displays to advanced interfaces that can handle\ncompound documents. Client software is furthermore aimed at achieving\ndistribution transparency by hiding details concerning the communication\nwith servers, where those servers are currently located, and whether servers\nare replicated. In addition, client software is partly responsible for hiding fail-\nures and recovery from failures. An interesting phenomenon is the increasing\npopularity of virtual desktop environments, by which an entire desktop more\nor less runs in the cloud.\nServers are often more intricate than clients, but are nevertheless subject\nto only a relatively few design issues. For example, servers can either be\niterative or concurrent, implement one or more services, and can be stateless\nor stateful. Other design issues deal with addressing services and mechanisms\nto interrupt a server after a service request has been issued and is possibly\nalready being processed.\nSpecial attention needs to be paid when organizing servers into a cluster.\nA common objective is to hide the internals of a cluster from the outside\nworld. This means that the organization of the cluster should be shielded\nfrom applications. To this end, most clusters use a single entry point that\ncan hand off messages to servers in the cluster. A challenging problem is to\ntransparently replace this single entry point by a fully distributed solution.\nAdvanced object servers have been developed for hosting remote objects.\nAn object server provides many services to basic objects, including facilities\nfor storing objects, or to ensure serialization of incoming requests. Another\nimportant role is providing the illusion to the outside world that a collection\nDS 4.01\n \n",
      "content_length": 3169,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 195,
      "content": "3.6. SUMMARY\n179\nof data and procedures operating on that data correspond to the concept of an\nobject. This role is implemented by object adapters. Object-based systems have\ncome to a point where we can build entire frameworks that can be extended\nfor supporting specific applications. Java has proven to provide a powerful\nmeans for setting up more generic services, exemplified by the highly popular\nEnterprise Java Beans concept and its implementation.\nAn exemplary server for Web-based systems is the one from Apache.\nAgain, the Apache server can be seen as a general solution for handling a\nmyriad of HTTP-based queries. By offering the right hooks, we essentially ob-\ntain a flexibly configurable Web server. Apache has served as an example not\nonly for traditional Websites, but also for setting up clusters of collaborative\nWeb servers, even across wide-area networks.\nAn important development is that of content delivery networks in wide-\narea networks, which facilitate accessing data and other resources close to\nclients. An essential component is ensuring that resources from an origin\nserver are copied to the proper edge servers transparently. To this end, the\ncombination of client-request redirection techniques and advanced nearby\ncaching is essential.\nAnother important topic for distributed systems is the migration of code\nbetween different machines. Two important reasons to support code migration\nare increasing performance and flexibility. When communication is expensive,\nwe can sometimes reduce communication by shipping computations from\nthe server to the client, and let the client do as much local processing as\npossible. Flexibility is increased if a client can dynamically download software\nneeded to communicate with a specific server. The downloaded software\ncan be specifically targeted to that server, without forcing the client to have\nit preinstalled. Lately, we see that also privacy and security have become\nreasons for migrating code, as is illustrated by federated learning.\nCode migration brings along problems related to usage of local resources\nfor which it is required that either resources are migrated as well, new bind-\nings to local resources at the target machine are established, or for which\nsystemwide network references are used. Another problem is that code mi-\ngration requires that we take heterogeneity into account. Current practice\nindicates that the best solution to handle heterogeneity is to use virtual ma-\nchines. These can take either the form of process virtual machines as in the\ncase of, for example, Java, or through using virtual machine monitors that\neffectively allow the migration of a collection of processes along with their\nunderlying operating system.\n \nDS 4.01\n",
      "content_length": 2739,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 197,
      "content": "04\nCOMMUNICATION\n",
      "content_length": 17,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 198,
      "content": "182\nCHAPTER 4. COMMUNICATION\nInterprocess communication is at the heart of all distributed systems. It\nmakes no sense to study distributed systems without carefully examining\nthe ways that processes on different machines can exchange information.\nCommunication in distributed systems has traditionally always been based on\nlow-level message passing as offered by the underlying network. Expressing\ncommunication through message passing is more difficult than using prim-\nitives based on shared memory, as available for nondistributed platforms.\nModern distributed systems often consist of thousands or even millions of\nprocesses scattered across a network with unreliable communication, such as\nthe Internet. Unless the primitive communication facilities of computer net-\nworks are replaced by something else, development of large-scale distributed\napplications is extremely difficult.\nIn this chapter, we start by discussing the rules that communicating pro-\ncesses must adhere to, known as protocols, and concentrate on structuring\nthose protocols in the form of layers. We then look at two widely used models\nfor communication: Remote Procedure Call (RPC), and Message-Oriented\nMiddleware (MOM). We also discuss the general problem of sending data to\nmultiple receivers, called multicasting.\nOur first model for communication in distributed systems is the remote\nprocedure call (RPC). An RPC aims at hiding most of the intricacies of message\npassing, and is ideal for client-server applications. However, realizing RPCs\ntransparently is easier said than done. We look at several important details\nthat cannot be ignored, while diving into actually code to illustrate to what\nextent distribution transparency can be realized such that performance is still\nacceptable.\nIn many distributed applications, communication does not follow the\nrather strict pattern of client-server interaction. In those cases, it turns out\nthat thinking in terms of messages is more appropriate. The low-level com-\nmunication facilities of computer networks are in many ways not suitable,\nagain due to their lack of distribution transparency. An alternative is to use a\nhigh-level message-queuing model, in which communication proceeds much\nthe same as in e-mail systems. Message-oriented communication is a subject\nimportant enough to warrant a section of its own. We look at numerous\naspects, including application-level routing.\nFinally, since our understanding of setting up multicast facilities has im-\nproved, novel and elegant solutions for data dissemination have emerged.\nWe pay separate attention to this subject in the last section of this chapter,\ndiscussing traditional deterministic means of multicasting, as well as proba-\nbilistic approaches as used in flooding and gossiping. The latter have been\nreceiving much attention over the past years due to their elegance, reliability,\nand simplicity.\nDS 4.01\n \n",
      "content_length": 2900,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 199,
      "content": "4.1. FOUNDATIONS\n183\n4.1\nFoundations\nBefore we start our discussion on communication in distributed systems, we\nfirst recapitulate some fundamental issues related to communication. In the\nnext section, we briefly discuss network communication protocols, as these\nform the basis for any distributed system. Thereafter, we take a different\napproach by classifying the different types of communication that usually\noccur in distributed systems.\n4.1.1\nLayered Protocols\nDue to the absence of shared memory, all communication in distributed\nsystems is based on sending and receiving (low level) messages.\nWhen\nprocess P wants to communicate with process Q, it first builds a message in\nits own address space. Then it executes a system call that causes the operating\nsystem to send the message over the network to Q. Although this basic\nidea sounds simple enough, to prevent chaos, P and Q have to agree on the\nmeaning of the bits being sent.\nThe OSI reference model\nTo make it easier to deal with the numerous levels and issues involved in\ncommunication, the International Standards Organization (ISO) developed a\nreference model that clearly identifies the various levels involved, gives them\nstandard names, and points out which level should do which job. This model\nis called the Open Systems Interconnection Reference Model [Day and\nZimmerman, 1983] usually abbreviated as ISO OSI or sometimes just the OSI\nmodel. It should be emphasized that the protocols that were developed as part\nof the OSI model were never widely used and are essentially dead. However,\nthe underlying model itself has proved to be quite useful for understanding\ncomputer networks. Although we do not intend to give a full description of\nthis model and all of its implications here, a brief introduction will be helpful.\nFor more details, see [Tanenbaum et al., 2021].\nThe OSI model is designed to allow open systems to communicate. An\nopen system is one that is prepared to communicate with any other open\nsystem by using standard rules that govern the format, contents, and meaning\nof the messages sent and received. These rules are formalized in what are\ncalled communication protocols. To allow a group of computers to commu-\nnicate over a network, they must all agree on the protocols to be used. A\nprotocol is said to provide a communication service. There are two types of\nsuch services. In the case of a connection-oriented service, before exchang-\ning data the sender and receiver first explicitly establish a connection, and\npossibly negotiate specific parameters of the protocol they will use. When\nthey are done, they release (terminate) the connection. The telephone is a\n \nDS 4.01\n",
      "content_length": 2667,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 200,
      "content": "184\nCHAPTER 4. COMMUNICATION\ntypical connection-oriented communication service. With a connectionless\nservices, no setup in advance is needed. The sender just transmits the first\nmessage when it is ready. Dropping a letter in a mailbox is an example of\nmaking use of connectionless communication service. With computers, both\nconnection-oriented and connectionless communication are common.\nFigure 4.1: Layers, interfaces, and protocols in the OSI model.\nIn the OSI model, communication is divided into seven levels or layers, as\nshown in Figure 4.1. Each layer offers one or more specific communication\nservices to the layer above it. In this way, the problem of getting a message\nfrom A to B can be divided into manageable pieces, each of which can be\nsolved independently of the others. Each layer provides an interface to the\none above it. The interface consists of a set of operations that together define\nthe service the layer is prepared to offer. The seven OSI layers are:\nPhysical layer Deals with standardizing how two computers are connected\nand how 0s and 1s are represented.\nData link layer Provides the means to detect and possibly correct transmis-\nsion errors, as well as protocols to keep a sender and receiver in the\nsame pace.\nNetwork layer Contains the protocols for routing a message through a com-\nputer network, as well as protocols for handling congestion.\nTransport layer Mainly contains protocols for directly supporting applica-\ntions, such as those that establish reliable communication, or support\nreal-time streaming of data.\nDS 4.01\n \n",
      "content_length": 1566,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 201,
      "content": "4.1. FOUNDATIONS\n185\nSession layer Provides support for sessions between applications.\nPresentation layer Prescribes how data is represented in a way that is inde-\npendent of the hosts on which communicating applications are running.\nApplication layer Essentially, everything else: e-mail protocols, Web access\nprotocols, file-transfer protocols, and so on.\nWhen a process P wants to communicate with some remote process Q, it\nbuilds a message and passes that message to the application layer as offered\nto it through an interface. This interface will typically appear in the form of a\nlibrary procedure. The application layer software then adds a header to the\nfront of the message and passes the resulting message across the layer 6/7\ninterface to the presentation layer. The presentation layer, in turn, adds its\nown header and passes the result down to the session layer, and so on. Some\nlayers add not only a header to the front, but also a trailer to the end. When\nit hits the bottom, the physical layer actually transmits the message (which\nby now might look as shown in Figure 4.2) by putting it onto the physical\ntransmission medium.\nFigure 4.2: A typical message as it appears on the network.\nWhen the message arrives at the remote machine hosting Q, it is passed\nupward, with each layer stripping off and examining its own header. Finally,\nthe message arrives at the receiver, process Q, which may reply to it using\nthe reverse path. The information in the layer-n header is used for the layer-n\nprotocol.\nIn the OSI model, there are not two layers, but seven, as we saw in\nFigure 4.1. The collection of protocols used in a particular system is called\na protocol suite or protocol stack. It is important to distinguish a reference\nmodel from its actual protocols. As said, the OSI protocols were never popular,\nin contrast to protocols developed for the Internet, such as TCP and IP.\n \nDS 4.01\n",
      "content_length": 1905,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 202,
      "content": "186\nCHAPTER 4. COMMUNICATION\nNote 4.1 (More information: Protocols in the OSI model)\nLet us briefly examine each of the OSI layers in turn, starting at the bottom.\nInstead of giving examples of OSI protocols, where appropriate, we will point out\nsome Internet protocols used in each layer.\nLower-level protocols\nThe three lowest layers of the OSI protocol suite imple-\nment the basic functions that encompass a computer network.\nThe physical layer is concerned with transmitting the 0s and 1s. How many\nvolts to use for 0 and 1, how many bits per second can be sent, and whether\ntransmission can take place in both directions simultaneously are key issues in\nthe physical layer. In addition, the size and shape of the network connector (plug),\nas well as the number of pins and meaning of each, are of concern here.\nThe physical layer protocol deals with standardizing the electrical, optical,\nmechanical, and signaling interfaces so that when one machine sends a 0 bit it is\nactually received as a 0 bit and not a 1 bit. Many physical layer standards have\nbeen developed (for different media), for example, the USB standard for serial\ncommunication lines.\nThe physical layer just sends bits. As long as no errors occur, all is well.\nHowever, real communication networks are subject to errors, so some mechanism\nis needed to detect and correct them. This mechanism is the main task of the data\nlink layer. What it does is to group the bits into units, also called frames, and see\nthat each frame is correctly received.\nThe data link layer does its work by putting a special bit pattern on the start\nand end of each frame to mark them, as well as computing a checksum by adding\nup all the bytes in the frame in a certain way. The data link layer appends the\nchecksum to the frame. When the frame arrives, the receiver recomputes the\nchecksum from the data and compares the result to the checksum following\nthe frame. If the two agree, the frame is considered correct and is accepted. If\nthey disagree, the receiver asks the sender to retransmit it. Frames are assigned\nsequence numbers (in the header), so everyone can tell which is which.\nOn a LAN, there is usually no need for the sender to locate the receiver. It just\nputs the message out on the network and the receiver takes it off. A wide-area\nnetwork, however, consists of numerous machines, each with some number of\nlines to other machines, rather like a large-scale map showing major cities and\nroads connecting them. For a message to get from the sender to the receiver it\nmay have to make a number of hops, at each one choosing an outgoing line to use.\nThe question of how to choose the best path is called routing, and is essentially\nthe primary task of the network layer.\nThe problem is complicated by the fact that the shortest route is not always\nthe best route. What really matters is the amount of delay on a given route, which,\nin turn, is related to the amount of traffic and the number of messages queued up\nfor transmission over the various lines. The delay can thus change over the course\nof time. Some routing algorithms try to adapt to changing loads, whereas others\nare content to make decisions based on long-term averages.\nDS 4.01\n \n",
      "content_length": 3210,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 203,
      "content": "4.1. FOUNDATIONS\n187\nAt present, the most widely used network protocol is the connectionless IP\n(Internet Protocol), which is part of the Internet protocol suite. An IP packet (the\ntechnical term for a message in the network layer) can be sent without any setup.\nEach IP packet is routed to its destination independent of all others. No internal\npath is selected and remembered.\nTransport protocols\nThe transport layer forms the last part of what could be\ncalled a basic network protocol stack, in the sense that it implements all those\nservices that are not provided at the interface of the network layer, but which are\nreasonably needed to build network applications. In other words, the transport\nlayer turns the underlying network into something that an application developer\ncan use.\nPackets can be lost on the way from the sender to the receiver. Although\nsome applications can handle their own error recovery, others prefer a reliable\nconnection. The job of the transport layer is to provide this service. The idea is\nthat the application layer should be able to deliver a message to the transport\nlayer with the expectation that it will be delivered without loss.\nUpon receiving a message from the application layer, the transport layer\nbreaks it into pieces small enough for transmission, assigns each one a sequence\nnumber, and then sends them all. The discussion in the transport layer header\nconcerns which packets have been sent, which have been received, how many\nmore the receiver has room to accept, which should be retransmitted, and similar\ntopics.\nReliable transport connections (which by definition are connection-oriented)\ncan be built on top of connection-oriented or connectionless network services. In\nthe former case all the packets will arrive in the correct sequence (if they arrive at\nall), but in the latter case it is possible for one packet to take a different route and\narrive earlier than the packet sent before it. It is up to the transport layer software\nto put everything back to maintain the illusion that a transport connection is like\na big tube–you put messages into it, and they come out undamaged and in the\nsame order in which they went in. Providing this end-to-end communication\nbehavior is an important aspect of the transport layer.\nThe Internet transport protocol is called TCP (Transmission Control Protocol)\nand is described in detail by Comer [2013]. The combination TCP/IP is now\nused as a de facto standard for network communication. The Internet protocol\nsuite also supports a connectionless transport protocol called UDP (Universal\nDatagram Protocol), which is essentially just IP with some minor additions. User\nprograms that do not need a connection-oriented protocol normally use UDP.\nAdditional transport protocols are regularly proposed. For example, to sup-\nport real-time data transfer, the Real-time Transport Protocol (RTP) has been\ndefined. RTP is a framework protocol in the sense that it specifies packet formats\nfor real-time data without providing the actual mechanisms for guaranteeing\ndata delivery. In addition, it specifies a protocol for monitoring and controlling\ndata transfer of RTP packets [Schulzrinne et al., 2003]. Likewise, the Streaming\nControl Transmission Protocol (SCTP) has been proposed as an alternative to\n \nDS 4.01\n",
      "content_length": 3306,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 204,
      "content": "188\nCHAPTER 4. COMMUNICATION\nTCP [Stewart, 2007]. The main difference between SCTP and TCP is that SCTP\ngroups data into messages, whereas TCP merely moves bytes between processes.\nDoing so may simplify application development.\nHigher-level protocols\nAbove the transport layer, OSI distinguishes three addi-\ntional layers. In practice, only the application layer is ever used. In fact, in the\nInternet protocol suite, everything above the transport layer is grouped together.\nIn the face of middleware systems, we shall see that neither the OSI nor the\nInternet approach is really appropriate.\nThe session layer is essentially an enhanced version of the transport layer. It\nprovides dialog control, to keep track of which party is currently talking, and it\nprovides synchronization facilities. The latter are useful to allow users to insert\ncheckpoints into long transfers, so that in the event of a crash, it is necessary to\ngo back only to the last checkpoint, rather than all the way back to the beginning.\nIn practice, few applications are interested in the session layer, and it is rarely\nsupported. It is not even present in the Internet protocol suite. However, in\nthe context of developing middleware solutions, the concept of a session and\nits related protocols has turned out to be quite relevant, notably when defining\nhigher-level communication protocols.\nUnlike the lower layers, which are concerned with getting the bits from the\nsender to the receiver reliably and efficiently, the presentation layer is concerned\nwith the meaning of the bits. Most messages do not consist of random bit strings,\nbut more structured information such as people’s names, addresses, amounts\nof money, and so on. In the presentation layer, it is possible to define records\ncontaining fields like these and then have the sender notify the receiver that a\nmessage contains a particular record in a certain format. This makes it easier for\nmachines with different internal representations to communicate with each other.\nThe OSI application layer was originally intended to contain a collection of\nstandard network applications such as those for electronic mail, file transfer, and\nterminal emulation. By now, it has become the container for all applications and\nprotocols that in one way or the other do not fit into one of the underlying layers.\nFrom the perspective of the OSI reference model, virtually all distributed systems\nare just applications.\nWhat is missing in this model is a clear distinction between applications,\napplication-specific protocols, and general-purpose protocols. For example, the\nInternet File Transfer Protocol (FTP) [Postel and Reynolds, 1985; Horowitz and\nLunt, 1997] defines a protocol for transferring files between a client and server\nmachine. The protocol should not be confused with the ftp program, which\nis an end-user application for transferring files and which also (not entirely\ncoincidentally) happens to implement the Internet FTP.\nAnother example of a typical application-specific protocol is the HyperText\nTransfer Protocol (HTTP) [Fielding and Reschke, 2014] which is designed to\nremotely manage and handle the transfer of Web pages. The protocol is imple-\nmented by applications such as Web browsers and Web servers. However, HTTP\nis now also used by systems that are not intrinsically tied to the Web. For example,\nDS 4.01\n \n",
      "content_length": 3366,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 205,
      "content": "4.1. FOUNDATIONS\n189\nJava’s object-invocation mechanism can use HTTP to request the invocation of\nremote objects that are protected by a firewall.\nThere are also many general-purpose protocols that are useful to many ap-\nplications, but which cannot be qualified as transport protocols. Often, such\nprotocols fall into the category of middleware protocols.\nMiddleware protocols\nMiddleware is an application that logically lives (mostly) in the OSI application\nlayer, but which contains many general-purpose protocols that warrant their\nown layers, independent of other, more specific applications. Let us briefly\nlook at some examples.\nThe Domain Name System (DNS) [Liu and Albitz, 2006] is a distributed\nservice that is used to look up a network address associated with a name, such\nas the address of a so-called domain name like www.distributed-systems.net.\nIn terms of the OSI reference model, DNS is an application and therefore\nis logically placed in the application layer.\nHowever, it should be quite\nobvious that DNS is offering a general-purpose, application-independent\nservice. Arguably, it forms part of the middleware.\nAs another example, there are various ways to establish authentication,\nthat is, provide proof of a claimed identity. Authentication protocols are\nnot closely tied to any specific application, but instead, can be integrated\ninto a middleware system as a general service.\nLikewise, authorization\nprotocols by which authenticated users and processes are granted access only\nto those resources for which they have authorization, tend to have a general,\napplication-independent nature. Being labeled as applications in the OSI\nreference model, these are clear examples that belong in the middleware.\nDistributed commit protocols establish that in a group of processes, pos-\nsibly spread out across several machines, either all processes carry out a\nparticular operation, or that the operation is not carried out at all. This phe-\nnomenon is also referred to as atomicity and is widely applied in transactions.\nAs it turns out, commit protocols can present an interface independently of\nspecific applications, thus providing a general-purpose transaction service.\nIn such a form, they typically belong to the middleware and not to the OSI\napplication layer.\nAs a last example, consider a distributed locking protocol, by which a\nresource can be protected against simultaneous access by a collection of pro-\ncesses that are distributed across multiple machines. It is not hard to imagine\nthat such protocols can be designed in an application-independent fashion,\nand accessible through a relatively simple, again application-independent\ninterface. As such, they generally belong in the middleware.\nThese protocol examples are not directly tied to communication, yet there\n \nDS 4.01\n",
      "content_length": 2807,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 206,
      "content": "190\nCHAPTER 4. COMMUNICATION\nFigure 4.3: An adapted reference model for networked communication.\nare also many middleware communication protocols. For example, with\na so-called remote procedure call, a process is offered a facility to locally\ncall a procedure that is effectively implemented on a remote machine. This\ncommunication service belongs to one of the oldest types of middleware\nservices and is used for realizing access transparency. In a similar vein, there\nare high-level communication services for setting and synchronizing streams\nfor transferring real-time data, such as needed for multimedia applications.\nAs a last example, some middleware systems offer reliable multicast services\nthat scale to thousands of receivers spread across a wide-area network.\nTaking this approach to layering leads to the adapted and simplified\nreference model for communication, as shown in Figure 4.3. Compared to\nthe OSI model, the session and presentation layer have been replaced by\na single middleware layer that contains application-independent protocols.\nThese protocols do not belong in the lower layers we just discussed. Network\nand transport services have been grouped into communication services as\nnormally offered by an operating system, which, in turn, manages the specific\nlowest-level hardware used to establish communication.\n4.1.2\nTypes of Communication\nIn the remainder of this chapter, we concentrate on high-level middleware\ncommunication services. Before doing so, there are other general criteria\nfor distinguishing (middleware) communication. To understand the various\nalternatives in communication that middleware can offer to applications, we\nview the middleware as an additional service in client-server computing, as\nshown in Figure 4.4. Consider, for example, an e-mail system. In principle, the\ncore of the mail delivery system can be seen as a middleware communication\nservice. Each host runs a user agent allowing users to compose, send, and\nreceive e-mail. A sending user agent passes such mail to the mail delivery\nDS 4.01\n \n",
      "content_length": 2057,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 207,
      "content": "4.1. FOUNDATIONS\n191\nsystem, expecting it, in turn, to eventually deliver the mail to the intended\nrecipient. Likewise, the user agent at the receiver’s side connects to the mail\ndelivery system to see whether any mail has come in. If so, the messages are\ntransferred to the user agent so that they can be read by the user.\nFigure 4.4: Viewing middleware as an intermediate (distributed) service in\napplication-level communication.\nAn e-mail system is a typical example in which communication is persis-\ntent. With persistent communication, a message that has been submitted\nfor transmission is stored by the communication middleware as long as it\ntakes to deliver it to the receiver. In this case, the middleware will store the\nmessage at one or several of the storage facilities shown in Figure 4.4. As\na consequence, it is not necessary for the sending application to continue\nexecution after submitting the message. Likewise, the receiving application\nneed not be executing when the message is submitted.\nIn contrast, with transient communication, a message is stored by the\ncommunication system only as long as the sending and receiving application\nare executing. More precisely, in terms of Figure 4.4, if the middleware cannot\ndeliver a message due to a transmission interrupt, or because the recipient is\ncurrently not active, it will simply be discarded. Typically, all transport-level\ncommunication services offer only transient communication. In this case, the\ncommunication system consists of traditional store-and-forward routers. If a\nrouter cannot deliver a message to the next one or the destination host, it will\nsimply drop the message.\nBesides being persistent or transient, communication can also be asyn-\nchronous or synchronous. The characteristic feature of asynchronous com-\nmunication is that a sender continues immediately after it has submitted its\nmessage for transmission. This means that the message is (temporarily) stored\nimmediately by the middleware upon submission. With synchronous com-\nmunication, the sender is blocked until its request is known to be accepted.\nThere are essentially three points where synchronization can take place. First,\n \nDS 4.01\n",
      "content_length": 2190,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 208,
      "content": "192\nCHAPTER 4. COMMUNICATION\nthe sender may be blocked until the middleware notifies that it will take over\ntransmission of the request. Second, the sender may synchronize until its\nrequest has been delivered to the intended recipient. Third, synchronization\nmay take place by letting the sender wait until its request has been fully\nprocessed, that is, up to the time that the recipient returns a response.\nVarious combinations of persistence and synchronization occur in practice.\nPopular ones are persistence in combination with synchronization at request\nsubmission, which is a common scheme for many message-queuing systems,\nwhich we discuss later in this chapter. Likewise, transient communication\nwith synchronization after the request has been fully processed is also widely\nused. This scheme corresponds with remote procedure calls, which we discuss\nin the following section.\n4.2\nRemote procedure call\nMany distributed systems have been based on explicit message exchange\nbetween processes. However, the operations send and receive do not conceal\ncommunication at all, which is important to achieve access transparency in\ndistributed systems. This problem has long been known, but little was done\nabout it until researchers in the 1980s [Birrell and Nelson, 1984] introduced\nan entirely different way of handling communication. Although the idea is\nrefreshingly simple (once someone has thought of it), the implications are\noften subtle. In this section we will examine the concept, its implementation,\nits strengths, and its weaknesses.\nIn a nutshell, the proposal was to allow programs to call procedures\nlocated on other machines. When a process on a machine A calls a procedure\non a machine B, the calling process on A is suspended, and execution of the\ncalled procedure takes place on B. Information can be transported from the\ncaller to the callee in the parameters and can come back in the procedure\nresult. No message passing at all is visible to the programmer. This method is\nknown as remote procedure call, or often just RPC.\nWhile the basic idea sounds simple and elegant, subtle problems exist. To\nstart with because the calling and called procedures run on different machines,\nthey execute in different address spaces, which causes complications. Parame-\nters and results also have to be passed, which can be complicated, especially\nif the machines are not identical. Finally, either or both machines can crash,\nand each of the possible failures causes different problems. Still, most of these\ncan be dealt with, and RPC is a widely used technique that underlies many\ndistributed systems.\n4.2.1\nBasic RPC operation\nThe idea behind RPC is to make a remote procedure call look as much as\npossible as a local one. In other words, we want RPC to be transparent—the\nDS 4.01\n \n",
      "content_length": 2794,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 209,
      "content": "4.2. REMOTE PROCEDURE CALL\n193\ncalling procedure should not be aware that the called procedure is executing\non a different machine or vice versa. Suppose that a program has access to a\ndatabase that allows it to append data to a stored list, after which it returns a\nreference to the modified list. The operation is made available to a program\nby a routine append:\nnewlist = append(data, dbList)\nIn a traditional (single processor) system, append is extracted from a library\nby the linker and inserted into the object program. In principle, it can be a\nshort procedure, which could be implemented by a few file operations for\naccessing the database.\nEven though append eventually does only a few basic file operations, it\nis called in the usual way, by pushing its parameters onto the stack. The\nprogrammer does not know the implementation details of append, and this is,\nof course, how it is supposed to be.\nNote 4.2 (More information: Conventional procedure calls)\nTo understand how RPC works and some of its pitfalls, it may help to first under-\nstand how a conventional (i.e., single machine) procedure call works. Consider\nthe operation newlist = append(data, dbList);\nWe assume that the purpose of this call is to take a globally defined list object,\nreferred here to as dbList, and append a simple data element to it, represented\nby the variable data. An important observation is that in various programming\nlanguages such as C, dbList is implemented as a reference to a list object (i.e.,\na pointer), whereas data may be represented directly by its value (which we\nassume to be the case here). When calling append, both the representations of data\nand dbList are pushed onto the stack, making those representations accessible\nto the implementation of append. For data, this means the variable follows a\ncall-by-value policy, the policy for dblist is call-by-reference. What happens\nbefore and during the call is shown in Figure 4.5.\n(a)\n(b)\nFigure 4.5: (a) Parameter passing in a local procedure call: the stack before\nthe call to append. (b) The stack while the called procedure is active.\n \nDS 4.01\n",
      "content_length": 2109,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 210,
      "content": "194\nCHAPTER 4. COMMUNICATION\nSeveral things are worth noting. For one, a value parameter, such as data, is\njust an initialized local variable. The called procedure may modify it, but such\nchanges do not affect the original value at the calling side.\nWhen a parameter like dbList is actually a pointer to a variable rather than\nthe value of the variable, something else happens. What is pushed onto the stack\nis the address of the list object as stored in main memory. When the value of data\nis appended to the list, a call to append does modify the list object. The difference\nbetween call-by-value and call-by-reference is quite important for RPC.\nOne other parameter passing mechanism also exists, although it is not used\nin most programming languages. It is called call-by-copy/restore. It consists of\nhaving the variable copied to the stack by the caller, as in call-by-value, and then\ncopied back after the call, overwriting the caller’s original value. Under most\nconditions, this achieves the same effect as call-by-reference, but in some situations,\nsuch as the same parameter being present multiple times in the parameter list,\nthe semantics are different.\nThe decision of which parameter passing mechanism to use is normally made\nby the language designers and is a fixed property of the language. Every so\noften, it depends on the data type being passed. In C, for example, integers and\nother scalar types are always passed by value, whereas arrays are always passed\nby reference. Some Ada compilers use copy/restore for inout parameters, but\nothers use call-by-reference. The language definition permits either choice, which\nmakes the semantics a bit fuzzy. In Python, all variables are passed by reference,\nbut some actually get copied to local variables, thus mimicking the behavior of\ncopy-by-value.\nRPC achieves its transparency analogously. When append is actually a\nremote procedure, a different version of append, called a client stub, is offered\nto the calling client. Like the original one, it, too, is called using a normal\ncalling sequence. However, unlike the original one, it does not perform\nan append operation. Instead, it packs the parameters into a message and\nrequests that message to be sent to the server, as illustrated in Figure 4.6.\nFollowing the call to send, the client stub calls receive, blocking itself until\nthe reply comes back.\nFigure 4.6: The principle of RPC between a client and server program.\nDS 4.01\n \n",
      "content_length": 2451,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 211,
      "content": "4.2. REMOTE PROCEDURE CALL\n195\nWhen the message arrives at the server, the server’s operating system\npasses it to a server stub. A server stub is the server-side equivalent of a client\nstub: it is a piece of code that transforms requests coming in over the network\ninto local procedure calls. Typically, the server stub will have called receive\nand be blocked waiting for incoming messages. The server stub unpacks the\nparameters from the message and then calls the server procedure in the usual\nway. From the server’s perspective, it is as though it is being called directly by\nthe client—the parameters and return address are all on the stack where they\nbelong and nothing seems unusual. The server performs its work and then\nreturns the result to the caller (in this case the server stub) in the usual way.\nWhen the server stub gets control back after the call has completed, it packs\nthe result in a message and calls send to return it to the client. Thereafter, the\nserver stub usually does a call to receive again, to wait for the next incoming\nrequest.\nWhen the result message arrives at the client’s machine, the operating\nsystem passes it through the receive operation, which had been called pre-\nviously, to the client stub, and the client process is subsequently unblocked.\nThe client stub inspects the message, unpacks the result, copies it to its caller,\nand returns in the usual way. When the caller gets control following the call\nto append, all it knows is that it appended some data to a list. It has no idea\nthat the work was done remotely at another machine.\nThis blissful ignorance for the client is the beauty of the whole scheme. As\nfar as it is concerned, remote services are accessed by making ordinary (i.e.,\nlocal) procedure calls, not by calling send and receive. All the details of the\nmessage passing are hidden away in the two library procedures, just as the\ndetails of actually making system calls are hidden away in traditional libraries.\nTo summarize, a remote procedure call occurs in the following steps:\n1. The client procedure calls the client stub in the normal way.\n2. The client stub builds a message and calls the local operating system.\n3. The client’s OS sends the message to the remote OS.\n4. The remote OS gives the message to the server stub.\n5. The server stub unpacks the parameter(s) and calls the server.\n6. The server does the work and returns the result to the stub.\n7. The server stub packs the result in a message and calls its local OS.\n8. The server’s OS sends the message to the client’s OS.\n9. The client’s OS gives the message to the client stub.\n10. The stub unpacks the result and returns it to the client.\nThe first steps are shown in Figure 4.7 for an abstract two-parameter\nprocedure doit(a,b), where we assume that parameter a is of type type1, and\nb of type type2. The net effect of all these steps is to convert the local call by\nthe client procedure to the client stub, to a local call to the server procedure,\n \nDS 4.01\n",
      "content_length": 2989,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 212,
      "content": "196\nCHAPTER 4. COMMUNICATION\nImplementation\nof doit\nClient OS\nServer OS\nClient machine\nServer machine\nClient stub\nClient process\nServer process\n1. Client call to\nprocedure\n2. Stub builds\nmessage\n5. Stub unpacks\nmessage\n6. Stub makes\nlocal call to “doit”\n3. Message is sent\nacross the network\n4. Server OS\nhands message\nto server stub\nServer stub\nr =\na,b\ndoit(\n)\nr =\na,b\ndoit(\n)\nproc: “doit”\ntype1:  val(a)\ntype2:  val(b)\nproc: “doit”\ntype1:  val(a)\ntype2:  val(b)\nproc: “doit”\ntype1:  val(a)\ntype2:  val(b)\nFigure 4.7: The steps involved in calling a remote procedure doit(a,b). The\nreturn path for the result is not shown.\nwithout either client or server being aware of the intermediate steps or the\nexistence of the network.\nNote 4.3 (More information: An example in Python)\nTo make matters concrete, let us consider how a remote procedure call could\nbe implemented for the operation append discussed previously. Take a look at\nthe Python code shown in Figure 4.8 (from which we omit nonessential code\nfragments).\nThe class DBList is a simple representation of a list object, mimicking what one\nwould expect to see in a version that would be found in a database environment.\nThe client stub, represented by the class Client, consists of an implementation\nof append. When called with parameters data and dbList, the following happens.\nThe call is transformed into a tuple (APPEND, data, dbList) containing all the\ninformation the server would need to do its work. The client stub then sends the\nrequest off to the server, and subsequently waits for the response. In the channel\npackage, a recvFrom operation always returns a (sender,message) pair, allowing the\ncaller to identify the process who had sent the message. In our case, when the\nresponse comes in, the client stub finishes the call to append by simply passing\nthe returned message from the server to the program that initially called the stub.\nOn the server side, we see that in the server stub, the server waits for any\nincoming message, and inspects which operation it is required to call. Again, the\nchannel package returns the identifier of the original sender (line 24). Assuming\nthe server received a request to call append, it then simply does a local call to its\nimplementation of append with the appropriate parameters as also found in the\nrequest tuple. The result is then sent back to the identified client.\nNote that an actual client would simply call c.append(...) where c is an\ninstance of the class Client. Indeed, the call truly seems to take place locally.\nDS 4.01\n \n",
      "content_length": 2546,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 213,
      "content": "4.2. REMOTE PROCEDURE CALL\n197\n1 import channel, pickle\n2\n3 class DBList:\n4\ndef append(self, data):\n5\nself.value.extend(data)\n6\nreturn self\n7\n8 class Client:\n9\ndef append(self, data, dbList):\n10\nmsglst = (APPEND, data, dbList)\n# message payload\n11\nself.channel.sendTo(self.server, msglst)\n# send message to server\n12\nmsgrcv = self.channel.recvFrom(self.server) # wait for an incoming message\n13\n14\n# A call to recvFrom returns a [senderID, message] pair\n15\nreturn msgrcv[1]\n# pass returned message to caller\n16\n17 class Server:\n18\ndef append(self, data, dbList):\n19\nreturn dbList.append(data)\n20\n21\ndef run(self):\n22\nwhile True:\n23\nmsgreq = self.channel.recvFromAny() # wait for any request\n24\nclient = msgreq[0]\n# see who is the caller\n25\nmsgrpc = msgreq[1]\n# fetch the actual request\n26\n27\n# At this point, msgreq should have the form (operation, data, list)\n28\nif APPEND == msgrpc[0]:\n# check what is being requested\n29\nresult = self.append(msgrpc[1], msgrpc[2]) # do local call\n30\nself.channel.sendTo(client,result)\n# return response\nFigure 4.8: A simple RPC example for operation append.\n4.2.2\nParameter passing\nThe function of the client stub is to take its parameters, pack them into a\nmessage, and send them to the server stub. While this sounds straightforward,\nit is not quite as simple as it at first appears.\nPacking parameters into a message is called parameter marshaling. Re-\nturning to our append operation, we need to ensure that its two parameters\n(data and dbList) are sent over the network and correctly interpreted by the\nserver. The thing to realize, is that the server will just be seeing a series\nof bytes coming in that constitute the original message sent by the client.\nHowever, no additional information on what those bytes mean is normally\nprovided with the message. Also, we would be facing the same problem again:\nhow should the meta-information be recognized as such by the server?\n \nDS 4.01\n",
      "content_length": 1924,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 214,
      "content": "198\nCHAPTER 4. COMMUNICATION\nBesides this interpretation problem, we also need to handle the case that\nthe placement of bytes in memory may differ between machine architectures.\nIn particular, we need to account for the fact that some machines, such as\nIntel processors, number their bytes from right to left, whereas many others,\nsuch as the older ARM processors, number them the other way (ARM now\nsupports both). The Intel format is called little endian and the (older) ARM\nformat is called big endian. Byte ordering is also important for networking:\nalso here we can witness that machines may use a different ordering when\ntransmitting (and thus receiving) bits and bytes. However, big endian is what\nis normally used for transferring bytes across a network.\nThe solution to this problem is to transform data that is to be sent to a\nmachine- and network-independent format, next to making sure that both\ncommunicating parties expect the same message data type to be transmitted.\nThe latter can typically be solved at the level of programming languages. The\nformer is accomplished by using machine-dependent routines that transform\ndata to and from machine- and network-independent formats.\nMarshaling and unmarshaling is all about this transformation to neutral\nformats and forms an essential part of remote procedure calls.\nNote 4.4 (More information: An example in Python revisited)\n1 import channel, pickle\n2\n3 class Client:\n4\ndef append(self, data, dbList):\n5\nmsglst = (APPEND, data, dbList)\n# message payload\n6\nmsgsnd = pickle.dumps(msglst)\n# wrap call\n7\nself.channel.sendTo(self.server, msgsnd)\n# send request to server\n8\nmsgrcv = self.channel.recvFrom(self.server) # wait for response\n9\nretval = pickle.loads(msgrcv[1])\n# unwrap return value\n10\nreturn retval\n# pass it to caller\n11\n12 class Server:\n13\ndef run(self):\n14\nwhile True:\n15\nmsgreq = self.channel.recvFromAny() # wait for any request\n16\nclient = msgreq[0]\n# see who is the caller\n17\nmsgrpc = pickle.loads(msgreq[1])\n# unwrap the call\n18\nif APPEND == msgrpc[0]:\n# check what is being requested\n19\nresult = self.append(msgrpc[1], msgrpc[2]) # do local call\n20\nmsgres = pickle.dumps(result)\n# wrap the result\n21\nself.channel.sendTo(client,msgres)\n# send response\nFigure 4.9: A simple RPC example for operation append, but now with\nproper marshaling.\nDS 4.01\n \n",
      "content_length": 2328,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 215,
      "content": "4.2. REMOTE PROCEDURE CALL\n199\nIt is not difficult to see that the solution to remote procedure calling as shown\nin Figure 4.8 will not work in general. Only if the client and server are operating\non machines that obey the same byte-ordering rules and have the same machine\nrepresentations for data structures, will the exchange of messages as shown lead\nto correct interpretations. A robust solution is shown in Figure 4.9 (where we\nagain have omitted code for brevity).\nIn this example, we use the Python pickle library for marshaling and unmar-\nshaling data structures. Note that the code hardly changes in comparison to what\nwe have shown in Figure 4.8. The only changes occur just before sending, and\nafter receiving a message. Also note that both client and server are programmed\nto work on the same data structures, as we discussed above.\n(We do note that, behind the scene, whenever a class instance is passed as a\nparameter, Python generally takes care of pickling and later unpickling the instance.\nIn this sense, our explicit use of pickle is, strictly speaking, not necessary.)\nWe now come to a difficult problem: How are pointers, or in general,\nreferences passed? The answer is: only with the greatest of difficulty, if at\nall. A pointer is meaningful only within the address space of the process\nin which it is being used. Getting back to our append example, we stated\nthat the second parameter, dbList, is implemented through a reference to a\nlist stored in a database. If that reference is just a pointer to a local data\nstructure somewhere in the caller’s main memory, we cannot simply pass it\nto the server. The transferred pointer value will most likely be referring to\nsomething entirely different.\nOne solution is just to forbid pointers and reference parameters in general.\nHowever, these are so important that this solution is highly undesirable. In\nfact, it is often not necessary either. First, reference parameters are often used\nwith fixed-sized data types, such as static arrays, or with dynamic data types\nfor which it is easy to compute their size at runtime, such as strings or dynamic\narrays. In such cases, we can simply copy the entire data structure to which the\nparameter is referring, effectively replacing the copy-by-reference mechanism\nby copy-by-value/restore. Although this is semantically not always identical,\nit frequently is good enough. An obvious optimization is that when the client\nstub knows the referred data will be only read, there is no need to copy it\nback when the call has finished. Copy-by-value is thus good enough.\nMore intricate data types can often be supported as well, and certainly if a\nprogramming language supports those data types. For example, a language\nsuch as Python or Java supports user-defined classes, allowing a language\nsystem to provide fully automated marshaling and unmarshaling of those\ndata types. Note, however, that as soon as we are dealing with large, nested,\nor otherwise intricate dynamic data structures, automatic (un)marshaling may\nnot be available, or even desirable.\nThe problem with pointers and references, as discussed so far, is that\nthey make sense only locally: they refer to memory locations that have\n \nDS 4.01\n",
      "content_length": 3215,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 216,
      "content": "200\nCHAPTER 4. COMMUNICATION\nmeaning only to the calling process. Problems can be alleviated by using\nglobal references: references that are meaningful to the calling and the called\nprocess. For example, if the client and the server have access to the same file\nsystem, passing a file handle instead of a pointer may do the trick. There is\none important observation: both processes need to know exactly what to do\nwhen a global reference is passed. In other words, if we consider a global\nreference having an associated data type, the calling and called process should\nhave the same picture of the operations that can be performed. Moreover, both\nprocesses should have agreement on exactly what to do when a file handle\nis passed. Again, these are typically issues that can be solved by proper\nprogramming-language support. We will return to this subject shortly.\nNote 4.5 (Advanced: Parameter passing in object-based systems)\nObject-based systems often use global references. Consider the situation that\nall objects in the system can be accessed from remote machines. In that case,\nwe can consistently use object references as parameters in method invocations.\nReferences are passed by value, and thus copied from one machine to the other.\nWhen a process is given an object reference as the result of a method invocation, it\ncan simply bind to the object referred to when needed later (see also Section 2.1.2).\nUnfortunately, using only distributed objects can be highly inefficient, espe-\ncially when objects are small, such as integers, or worse yet, Booleans. Each\ninvocation by a client that is not co-located in the same server as the object, gener-\nates a request between different address spaces or, even worse, between different\nmachines. Therefore, references to remote objects and those to local objects are\noften treated differently.\nLocal object\nO1\nCopy of O1\nRemote object\nO2\nLocal\nreference L1\nNew local\nreference\nRemote\nreference R1\nRemote\ninvocation with\nL1 and R1 as\nparameters\nCopy of R1 to O2\nMachine A\nMachine B\nMachine C\nClient code with\nRMI to server at C\n(proxy)\nServer code\n(method implementation)\nFigure 4.10: Passing an object by reference or by value.\nWhen invoking a method with an object reference as parameter, that reference\nis copied and passed as a value parameter only when it refers to a remote object.\nIn this case, the object is literally passed by reference. However, when the reference\nrefers to a local object, that is an object in the same address space as the client,\nthe referred object is copied as a whole and passed along with the invocation. In\nDS 4.01\n \n",
      "content_length": 2603,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 217,
      "content": "4.2. REMOTE PROCEDURE CALL\n201\nother words, the object is passed by value.\nThese two situations are illustrated in Figure 4.10 which shows a client pro-\ngram running on a machine A, and a server program on a machine C. The client\nhas a reference to a local object O1 that it uses as a parameter when calling the\nserver program on machine C. In addition, it holds a reference to a remote object\nO2 residing at machine B, which is also used as a parameter. When calling the\nserver, a copy of O1 is passed to the server on machine C, along with only a copy\nof the reference to O2.\nNote that whether we are dealing with a reference to a local object or a\nreference to a remote object can be highly transparent, such as in Java. In Java, the\ndistinction is visible only because local objects are essentially of a different data\ntype than remote objects. Otherwise, both types of references are treated very\nmuch the same (see also [Wollrath et al., 1996]). On the other hand, when using\nconventional programming languages such as C, a reference to a local object can\nbe as simple as a pointer, which can never be used to refer to a remote object.\nThe side effect of invoking a method with an object reference as parameter is\nthat we may be copying an object. Obviously, hiding this aspect is unacceptable\nso that we are consequently forced to make an explicit distinction between local\nand distributed objects. Clearly, this distinction not only violates distribution\ntransparency, but also makes it harder to write distributed applications.\nWe can now also easily explain how global references can be implemented\nwhen using portable, interpreted languages such as Python or Java: use the entire\nclient stub as a reference. The key observation is that a client stub is often just\nanother data structure that is compiled into (portable) bytecode. That compiled\ncode can actually be transferred across the network and executed at the receiver’s\nside. In other words, there is no need for explicit binding anymore; simply\ncopying the client stub to the recipient is enough to allow the latter to invoke the\nassociated server-side object. Of course, it may be necessary to marshall that code\nbefore shipping it to the other machine, although strictly speaking, there is no\nreason why that other machine would work with different layouts.\n4.2.3\nRPC-based application support\nFrom what we have explained so far, it is clear that hiding a remote procedure\ncall requires that the caller and the callee agree on the format of the messages\nthey exchange and that they follow the same steps when it comes to, for\nexample, passing complex data structures. In other words, both sides in an\nRPC should follow the same protocol or the RPC will not work correctly.\nThere are at least two ways in which RPC-based application development can\nbe supported. The first one is to let a developer specify exactly what needs\nto be called remotely, from which complete client-side and server-side stubs\ncan be generated. A second approach is to embed remote procedure calling\nas part of a programming-language environment.\n \nDS 4.01\n",
      "content_length": 3103,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 218,
      "content": "202\nCHAPTER 4. COMMUNICATION\nStub generation\nConsider the function someFunction of Figure 4.11(a). It has three parameters,\na character, a floating-point number, and an array of five integers. Assuming a\nword is four bytes, the RPC protocol might prescribe that we should transmit a\ncharacter in the rightmost byte of a word (leaving the next three bytes empty),\na float as a whole word, and an array as a group of words whose size is\nequal to the array length, preceded by a word giving the length, as shown in\nFigure 4.11(b). Thus given these rules, the client stub for someFunction knows\nthat it must use the format of Figure 4.11(b), and the server stub knows that\nincoming messages for someFunction will have the format of Figure 4.11(b).\nvoid someFunction(char x; float y; int z[5])\n(a)\n(b)\nFigure 4.11: (a) A function. (b) The corresponding message, and the order in\nwhich bytes and words are sent across the network.\nDefining the message format is one aspect of an RPC protocol, but it\nis not sufficient. What we also need is the client and the server to agree\non the representation of simple data structures, such as integers, characters,\nBooleans, etc. For example, the protocol could prescribe that integers are\nrepresented in two’s complement, characters in 16-bit Unicode, and floats in\nthe IEEE standard #754 format, with everything stored in little endian. With\nthis additional information, messages can be unambiguously interpreted.\nWith the encoding rules now pinned down to the last bit, the only thing\nthat remains to be done is that the caller and callee agree on the actual\nexchange of messages. For example, it may be decided to use a connection-\noriented transport service, such as TCP/IP. An alternative is to use an unreli-\nable datagram service and let the client and server implement an error control\nscheme as part of the RPC protocol. In practice, several variants exist, and it\nis up to the developer to indicate the preferred underlying communication\nservice.\nOnce the RPC protocol has been fully defined, the client and server stubs\nneed to be implemented. Fortunately, stubs for the same protocol, but different\nDS 4.01\n \n",
      "content_length": 2155,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 219,
      "content": "4.2. REMOTE PROCEDURE CALL\n203\nprocedures, normally differ only in their interface to the applications. An\ninterface consists of a collection of procedures that can be called by a client,\nand which are implemented by a server. An interface is usually available in\nthe same programming language as the one in which the client or server is\nwritten (although this is, strictly speaking, not necessary). To simplify matters,\ninterfaces are often specified through an Interface Definition Language (IDL).\nAn interface specified in such an IDL is then subsequently compiled into a\nclient stub and a server stub, along with the appropriate compile-time or\nrun-time interfaces. This process is sketched in Figure 4.12.\nFigure 4.12: The principle of generating stubs from an interface definition file.\nThe figure shows the situation for compiled languages, yet it is not hard\nto imagine that a very similar situation holds for interpreted languages. Also\nnote that it is possible that the client and server code are written in different\nlanguages. There is no principal reason why the client side cannot consist of\ncomponents written in, for example, Python, while the server side is written\nin C. Of course, in that case, the box in Figure 4.12 representing common\nincludes will then contain separate files for the client and server, respectively.\nImportant in this scheme is the runtime library: it forms the interface to the\nactual runtime system, constituting the middleware.\nPractice shows that using an interface definition language considerably\nsimplifies client-server applications based on RPCs. Because it is easy to fully\n \nDS 4.01\n",
      "content_length": 1634,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 220,
      "content": "204\nCHAPTER 4. COMMUNICATION\ngenerate client and server stubs, all RPC-based middleware systems offer an\nIDL to support application development. In some cases, using the IDL is even\nmandatory.\nNote 4.6 (More information: Language-based RPC in Python)\nLet us see by an example of how remote procedure calling can be integrated in a\nlanguage. We have been using the Python language for most of our examples, and\nwill continue to do so now as well. In Figure 4.13 we show a simple server for our\nDBList data structure. In this case, it has two exposed operations: exposed_append\nfor appending elements, and exposed_value to display what is currently in the\nlist. We use the Python RPyC package for embedding RPCs.\n1 import rpyc\n2 from rpyc.utils.server import ForkingServer\n3\n4 class DBList(rpyc.Service):\n5\nvalue = [] # Used to build a list of strings\n6\n7\ndef exposed_append(self, data):\n8\nself.value.extend(str(data)) # Extend the list with the data\n9\nreturn self.value\n# Return the current list\n10\n11 class Server:\n12\n# Create a forking server at inititalization time and immediately start it.\n13\n# For each incoming request, the server will spawn another process to handle\n14\n# that request. The process that started the (main) server can simply kill\n15\n# it when it’s time to do so.\n16\ndef __init__(self):\n17\nself.server = ForkingServer(DBList, hostname=SERVER, port=PORT)\n18\n19\ndef start(self):\n20\nself.server.start()\n21\n22 class Client:\n23\ndef run(self):\n24\nconn = rpyc.connect(SERVER, PORT) # Connect to the server\n25\nconn.root.exposed_append(2)\n# Call an exposed operation,\n26\nconn.root.exposed_append(4)\n# and append two elements\n27\nprint(conn.root.exposed_value())\n# Print the result\nFigure 4.13: Embedding RPCs in a language\nThe client is also shown in Figure 4.13. When a connection is made to the\nserver, a new instance of DBList will be created and the client can immediately\nappend values to the list. The exposed operations are called without further ado.\nNote that as the client breaks the connection to the server, the list will be lost.\nIt is a transient object and special measures will need to be taken to make it a\npersistent object.\nDS 4.01\n \n",
      "content_length": 2164,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 221,
      "content": "4.2. REMOTE PROCEDURE CALL\n205\nLanguage-based support\nThe approach described up until now is largely independent of a specific pro-\ngramming language. As an alternative, we can also embed remote procedure\ncalling into a language itself. The main benefit is that application development\noften becomes much simpler. Furthermore, reaching a high degree of access\ntransparency is often simpler, as many issues related to parameter passing\ncan be circumvented altogether.\nA well-known example in which remote procedure calling is fully em-\nbedded is Java, where an RPC is referred to as a remote method invocation\n(RMI). In essence, a client being executed by its own (Java) virtual machine\ncan invoke a method of an object managed by another virtual machine. By\nsimply reading an application’s source code, it may be hard or even impossible\nto see whether a method invocation is to a local or to a remote object.\n4.2.4\nVariations on RPC\nAs in conventional procedure calls, when a client calls a remote procedure, the\nclient will block until a reply is returned. This strict request-reply behavior\nis unnecessary when there is no result to return, or may hinder efficiency\nwhen multiple RPCs need to be performed. In the following, we look at two\nvariations on the RPC scheme we have discussed so far.\nAsynchronous RPC\nTo support situations in which there is simply no result to return to the client,\nRPC systems may provide facilities for what are called asynchronous RPCs.\nWith asynchronous RPCs, the server, in principle, immediately sends a reply\nback to the client the moment the RPC request is received, after which it\nlocally calls the requested procedure. The reply acts as an acknowledgment\nto the client that the server is going to process the RPC. The client will\ncontinue without further blocking as soon as it has received the server’s\nacknowledgment. Figure 4.14(b) shows how client and server interact in the\ncase of asynchronous RPCs. For comparison, Figure 4.14(a) shows the normal\nrequest-reply behavior.\nAsynchronous RPCs can also be useful when a reply will be returned, but\nthe client is not prepared to wait for it and do nothing in the meantime. A\ntypical case is when a client needs to contact several servers independently.\nIn that case, it can send the call requests one after the other, effectively\nestablishing that the servers operate more or less in parallel. After all call\nrequests have been sent, the client can start waiting for the various results to be\nreturned. In cases such as these, it makes sense to organize the communication\nbetween the client and server through an asynchronous RPC combined with a\ncallback, as shown in Figure 4.15. In this scheme, also referred to as deferred\nsynchronous RPC, the client first calls the server, waits for the acceptance,\n \nDS 4.01\n",
      "content_length": 2805,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 222,
      "content": "206\nCHAPTER 4. COMMUNICATION\n(a)\n(b)\nFigure 4.14: (a) The interaction between client and server in a traditional RPC.\n(b) The interaction using asynchronous RPC.\nand continues. When the results become available, the server sends a response\nmessage that leads to a callback at the client’s side. A callback is a user-defined\nfunction that is invoked when a special event happens, such as an incoming\nmessage. A straightforward implementation is to spawn a separate thread and\nlet it block on the occurrence of the event while the main process continues.\nWhen the event occurs, the thread is unblocked and calls the function.\nFigure 4.15: A client and server interacting through a deferred synchronous\nRPC.\nIt should be noted that variants of asynchronous RPCs exist in which the\nclient continues executing immediately after sending the request to the server.\nIn other words, the client does not wait for an acknowledgment of the server’s\nacceptance of the request. We refer to such RPCs as one-way RPCs. The\nproblem with this approach is that when reliability is not guaranteed, the\nclient cannot know for sure whether its request will be processed. We return\nto these matters in Chapter 8. Likewise, in the case of deferred synchronous\nRPC, the client may poll the server to see whether the results are available yet,\ninstead of letting the server calling back the client.\nDS 4.01\n \n",
      "content_length": 1383,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 223,
      "content": "4.2. REMOTE PROCEDURE CALL\n207\nMulticast RPC\nAsynchronous and deferred synchronous RPCs facilitate another alternative\nto remote procedure calls, namely executing multiple RPCs at the same time.\nAdopting the one-way RPCs (i.e., when a server does not tell the client it has\naccepted its call request but immediately starts processing it, while the client\ncontinues just after issuing the RPC), a multicast RPC boils down to sending\nan RPC request to a group of servers. This principle is shown in Figure 4.16.\nIn this example, the client sends a request to two servers, who subsequently\nprocess that request independently and in parallel. When done, the result is\nreturned to the client where a callback takes place.\nFigure 4.16: The principle of a multicast RPC.\nThere are several issues that we need to consider. First, as before, the\nclient application may be unaware of the fact that an RPC is actually being\nforwarded to more than one server. For example, to increase fault tolerance,\nwe may decide to have all operations executed by a backup server who can\ntake over when the main server fails. That a server has been replicated can be\ncompletely hidden from a client application by an appropriate stub. Yet even\nthe stub need not be aware that the server is replicated, for example because\nwe are using a transport-level multicast address.\nSecond, we need to consider what to do with the responses. In particular,\nwill the client proceed after all responses have been received, or wait just for\none? It all depends. When the server has been replicated for fault tolerance,\nwe may decide to wait for just the first response, or perhaps until a majority\nof the servers returns the same result. On the other hand, if the servers have\nbeen replicated to do the same work but on different parts of the input, their\nresults may need to be merged before the client can continue. Again, such\nmatters can be hidden in the client-side stub, yet the application developer\nwill, at the very least, have to specify the purpose of the multicast RPC.\n \nDS 4.01\n",
      "content_length": 2053,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 224,
      "content": "208\nCHAPTER 4. COMMUNICATION\n4.3\nMessage-oriented communication\nRemote procedure calls and remote object invocations contribute to hiding\ncommunication in distributed systems, that is, they enhance access trans-\nparency. Unfortunately, neither mechanism is always appropriate. In particu-\nlar, when it cannot be assumed that the receiving side is executing at the time\na request is issued, alternative communication services are needed. Likewise,\nthe inherent synchronous nature of RPCs, by which a client is blocked until\nits request has been processed, may need to be replaced by something else.\nThat something else is messaging. In this section, we concentrate on\nmessage-oriented communication in distributed systems by first taking a closer\nlook at what exactly synchronous behavior is and what its implications are.\nThen, we discuss messaging systems that assume that parties are executing\nat the time of communication. Finally, we will examine message-queuing\nsystems that allow processes to exchange information, even if the other party\nis not executing at the time communication is initiated.\n4.3.1\nSimple transient messaging with sockets\nMany distributed systems and applications are built directly on top of the\nsimple message-oriented model offered by the transport layer. To better un-\nderstand and appreciate the message-oriented systems as part of middleware\nsolutions, we first discuss messaging through transport-level sockets.\nSpecial attention has been paid to standardizing the interface of the trans-\nport layer to allow programmers to make use of its entire suite of (messaging)\nprotocols through a simple set of operations. Furthermore, standard interfaces\nmake it easier to port an application to a different machine. As an example,\nwe briefly discuss the socket interface as introduced in the 1970s in Berkeley\nUnix, and which has been adopted as a POSIX standard (with only very few\nadaptations).\nConceptually, a socket is a communication end point to which an applica-\ntion can write data that are to be sent out over the underlying network, and\nfrom which incoming data can be read. A socket forms an abstraction over the\nactual port that is used by the local operating system for a specific transport\nprotocol. In the following text, we concentrate on the socket operations for\nTCP, which are shown in Figure 4.17.\nServers generally execute the first four operations, normally in the order\ngiven. When calling the socket operation, the caller creates a new commu-\nnication end point for a specific transport protocol. Internally, creating a\ncommunication end point means that the local operating system reserves\nresources for sending and receiving messages for the specified protocol.\nThe bind operation associates a local address with the newly created socket.\nFor example, a server should bind the IP address of its machine together with\na (possibly well-known) port number to a socket. Binding tells the operating\nDS 4.01\n \n",
      "content_length": 2956,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 225,
      "content": "4.3. MESSAGE-ORIENTED COMMUNICATION\n209\nOperation\nDescription\nsocket\nCreate a new communication end point\nbind\nAttach a local address to a socket\nlisten\nTell operating system what the maximum number of pending\nconnection requests should be\naccept\nBlock caller until a connection request arrives\nconnect\nActively attempt to establish a connection\nsend\nSend some data over the connection\nreceive\nReceive some data over the connection\nclose\nRelease the connection\nFigure 4.17: The socket operations for TCP/IP.\nsystem that the server wants to receive messages only on the specified address\nand port. In the case of connection-oriented communication, the address is\nused to receive incoming connection requests.\nThe listen operation is called only in the case of connection-oriented\ncommunication. It is a nonblocking call that allows the local operating sys-\ntem to reserve enough buffers for a specified maximum number of pending\nconnection requests that the caller is willing to accept.\nA call to accept blocks the caller until a connection request arrives. When\na request arrives, the local operating system creates a new socket with the\nsame properties as the original one, and returns it to the caller. This approach\nwill allow the server to, for example, fork a process that will subsequently\nhandle the actual communication through the new connection. The server can\ngo back and wait for another connection request on the original socket.\nFigure 4.18: Connection-oriented communication pattern using sockets.\nLet us now take a look at the client side. Here, too, a socket must first be\ncreated using the socket operation, but explicitly binding the socket to a local\naddress is not necessary, since the operating system can dynamically allocate\na port when the connection is set up. The connect operation requires that the\ncaller specifies the transport-level address to which a connection request is to\nbe sent. The client is blocked until a connection has been set up successfully,\nafter which both sides can start exchanging information through the send and\nreceive operations. Finally, closing a connection is symmetric when using\n \nDS 4.01\n",
      "content_length": 2149,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 226,
      "content": "210\nCHAPTER 4. COMMUNICATION\nsockets, and is established by having both the client and server call the close\noperation. Although there are many exceptions to the rule, the general pattern\nfollowed by a client and server for connection-oriented communication using\nsockets is as shown in Figure 4.18. Details on network programming using\nsockets and other interfaces in Unix can be found in [Stevens, 1998].\nNote 4.7 (Example: A simple socket-based client-server system)\nAs an illustration of the recurring pattern in Figure 4.18, consider the simple\nsocket-based client-server system shown in Figure 4.19 (see also Note 2.1). We see\nthe server starting by creating a socket, and subsequently binding an address to\nthat socket. It calls the listen operation, and waits for an incoming connection\nrequest.\nWhen the server accepts a connection, the socket library creates a\nseparate connection, conn, which is used to receive data and send a response to\nthe connected client. The server enters a loop receiving and sending messages,\nuntil no more data has been received. It then closes the connection.\n1 from socket\nimport *\n2\n3 class Server:\n4\ndef run(self):\n5\ns = socket(AF_INET, SOCK_STREAM)\n6\ns.bind((HOST, PORT))\n7\ns.listen(1)\n8\n(conn, addr) = s.accept()\n# returns new socket and addr. client\n9\nwhile True:\n# forever\n10\ndata = conn.recv(1024)\n# receive data from client\n11\nif not data: break\n# stop if client stopped\n12\nconn.send(data+b\"*\")\n# return sent data plus an \"*\"\n13\nconn.close()\n# close the connection\n(a)\n1 class Client:\n2\ndef run(self):\n3\ns = socket(AF_INET, SOCK_STREAM)\n4\ns.connect((HOST, PORT)) # connect to server (block until accepted)\n5\ns.send(b\"Hello, world\") # send same data\n6\ndata = s.recv(1024)\n# receive the response\n7\nprint(data)\n# print what you received\n8\ns.send(b\"\")\n# tell the server to close\n9\ns.close()\n# close the connection\n(b)\nFigure 4.19: A simple socket-based client-server system.\nThe client again follows the pattern from Figure 4.18. It creates a socket, and\ncalls connect to request a connection with the server. Once the connection has\nbeen established, it sends a single message, waits for the response, and after\nprinting the result, closes the connection.\nDS 4.01\n \n",
      "content_length": 2211,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 227,
      "content": "4.3. MESSAGE-ORIENTED COMMUNICATION\n211\nNote 4.8 (Advanced: Implementing stubs as global references revisited)\nTo provide a more in-depth insight in the working of sockets, let us look\nat a more elaborate example, namely the use of stubs as global references.\n1 class DBClient:\n2\ndef __sendrecv(self, message):\n# this is a private method\n3\nsock = socket()\n# create a socket\n4\nsock.connect((self.host, self.port))\n# connect to server\n5\nsock.send(pickle.dumps(message))\n# send some data\n6\nresult = pickle.loads(sock.recv(1024)) # receive the response\n7\nsock.close()\n# close the connection\n8\nreturn result\n9\n10\ndef create(self):\n11\nself.listID = self.__sendrecv([CREATE])\n12\nreturn self.listID\n13\n14\ndef getValue(self):\n15\nreturn self.__sendrecv([GETVALUE, self.listID])\n16\n17\ndef appendData(self, data):\n18\nreturn self.__sendrecv([APPEND, data, self.listID])\n(a)\n1 class Server:\n2\nself.setOfLists = {}\n# init: no lists to manage\n3\n4\ndef run(self):\n5\nwhile True:\n6\n(conn, addr) = self.sock.accept() # accept incoming call\n7\ndata = conn.recv(1024)\n# fetch data from client\n8\nrequest = pickle.loads(data)\n# unwrap the request\n9\n10\nif request[0] == CREATE:\n# create a list\n11\nlistID = len(self.setOfLists) + 1\n# allocate listID\n12\nself.setOfLists[listID] = []\n# initialize to empty\n13\nconn.send(pickle.dumps(listID))\n# return ID\n14\n15\nelif request[0] == APPEND:\n# append request\n16\nlistID = request[2]\n# fetch listID\n17\ndata\n= request[1]\n# fetch data to append\n18\nself.setOfLists[listID].append(data) # append it to the list\n19\nconn.send(pickle.dumps(OK))\n# return an OK\n20\n21\nelif request[0] == GETVALUE:\n# read request\n22\nlistID = request[1]\n# fetch listID\n23\nresult = self.setOfLists[listID]\n# get the elements\n24\nconn.send(pickle.dumps(result))\n# return the list\n(b)\nFigure 4.20: Implementing a list server in Python.\n \nDS 4.01\n",
      "content_length": 1826,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 228,
      "content": "212\nCHAPTER 4. COMMUNICATION\nWe return to our example of implementing a shared list, which we now\ndo using a list server, implemented in the form of the Python class shown in\nFigure 4.20(b). Figure 4.20(a) shows the stub implementation of a shared list.\nAgain, we have omitted code for readability.\nThe DBClient class represents a client-side stub that, once marshaled, can be\npassed between processes. It provides three operations associated with a list:\ncreate, getValue, and append, with obvious semantics. A DBClient is assumed to\nbe associated with one specific list as managed by the server. An identifier for\nthat list is returned when the list is created. Note how the (internal) sendrecv\noperation follows the client-side pattern explained in Figure 4.18.\nThe server maintains lists, as shown in Figure 4.20(b).\nIts internal data\nstructure is a setOfLists with each element being a previously created list. The\nserver simply waits for incoming requests, unmarshals the request, and checks\nwhich operation is being requested. Results are sent back to the requesting client\n(which always issues the sendrecv operation implemented as part of DBClient).\nAgain, we see that the server follows the pattern shown in Figure 4.18: it creates\na socket, binds an address to it, informs the operating system to how many\nconnections it should listen, and then waits to accept an incoming connection\nrequest. Once a connection has been established, the server receives data, sends a\nresponse, and closes the connection again.\n1 class Client:\n2\ndef __init__(self, port):\n3\nself.host = ’localhost’\n# this machine\n4\nself.port = port\n# port it will listen to\n5\nself.sock = socket()\n# socket for incoming calls\n6\nself.sock.bind((self.host, self.port)) # bind socket to an address\n7\nself.sock.listen(2)\n# max num connections\n8\n9\ndef sendTo(self, host, port, data):\n10\nsock = socket()\n11\nsock.connect((host, port))\n# connect to server (blocking call)\n12\nsock.send(pickle.dumps(data)) # send some data\n13\nsock.close()\n14\n15\ndef recvAny(self):\n16\n(conn, addr) = self.sock.accept()\n17\nreturn conn.recv(1024)\nFigure 4.20: (c) Implementing a list server in Python: the client.\nTo use a stub as a global reference, we represent each client application by\nthe class Client shown in Figure 4.20(c). The class is instantiated in the same\nprocess running the application (exemplified by the value of self.host), and will\nbe listening on a specific port for messages from other applications, as well as\nthe server. Otherwise, it merely sends and receives messages, coded through the\noperations sendTo and recvAny, respectively.\nNow consider the code shown in Figure 4.20(d), which mimics two client\napplications. The first one creates a new list and appends data to it. Then note\nDS 4.01\n \n",
      "content_length": 2767,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 229,
      "content": "4.3. MESSAGE-ORIENTED COMMUNICATION\n213\nhow dbClient1 is simply sent to the other client. Under the hood, we now know\nthat it is marshaled in the operation sendTo (line 12) of class Client shown in\nFigure 4.20(c).\n1 def client1():\n2\nc1\n= Client(PORTC1)\n# create client\n3\ndbC1 = DBClient(HOSTS,PORTS)\n# create reference\n4\ndbC1.create()\n# create new list\n5\ndbC1.appendData(’Client 1’)\n# append some data\n6\nc1.sendTo(HOSTC2,PORTC2,dbC1)\n# send to other client\n7\n8 def client2():\n9\nc2\n= Client(PORTC2)\n# create a new client\n10\ndata = c2.recvAny()\n# block until data is sent\n11\ndbC2 = pickle.loads(data)\n# receive reference\n12\ndbC2.appendData(’Client 2’)\n# append data to same list\nFigure 4.20: (d) Passing stubs as references.\nThe second client simply waits for an incoming message (line 12), unmarshals\nthe result, knowing that it is a DBClient instance, and subsequently appends some\nmore data to the same list as the one the first client appended data. Indeed, an\ninstance of DBClient is seen to be passed as a global reference, seemingly along\nwith all the operations that go with the associated class.\n4.3.2\nAdvanced transient messaging\nThe standard socket-based approach toward transient messaging is very basic\nand, as such, rather brittle: a mistake is easily made. Furthermore, sockets\nessentially support only TCP or UDP, meaning that any extra facility for\nmessaging needs to be implemented separately by an application programmer.\nIn practice, we do often need more advanced approaches for message-oriented\ncommunication to make network programming easier, to expand beyond the\nfunctionality offered by existing networking protocols, to make better use of\nlocal resources, and so on.\nUsing messaging patterns: ZeroMQ\nOne approach toward making network programming easier is based on the\nobservation that many messaging applications, or their components, can be\neffectively organized according to a few simple communication patterns. By\nsubsequently providing enhancements to sockets for each of these patterns,\nit may become easier to develop a networked, distributed application. This\napproach has been followed in ZeroMQ and documented in [Hintjens, 2013;\nAkgul, 2013].\n \nDS 4.01\n",
      "content_length": 2190,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 230,
      "content": "214\nCHAPTER 4. COMMUNICATION\nLike in the Berkeley approach, ZeroMQ also provides sockets through\nwhich all communication takes place. Actual message transmission gener-\nally takes place over TCP connections, and like TCP, all communication is\nessentially connection-oriented, meaning that a connection will first be set up\nbetween a sender and receiver before message transmission can take place.\nHowever, setting up, and maintaining connections is kept mostly under the\nhood: an application programmer need not bother with those issues. To\nfurther simplify matters, a socket may be bound to multiple addresses, ef-\nfectively allowing a server to handle messages from very different sources\nthrough a single interface. For example, a server can listen to multiple ports\nusing a single blocking receive operation. ZeroMQ sockets can thus support\nmany-to-one communication instead of just one-to-one communication, as is the\ncase with standard Berkeley sockets. To complete the story: ZeroMQ sockets\nalso support one-to-many communication, i.e., multicasting.\nEssential to ZeroMQ is that communication is asynchronous: a sender will\nnormally continue after having submitted a message to the underlying com-\nmunication subsystem. An interesting side effect of combining asynchronous\nwith connection-oriented communication, is that a process can request a con-\nnection setup, and subsequently send a message even if the recipient is not yet\nup-and-running and ready to accept incoming connection requests, let alone\nincoming messages. What happens, of course, is that a connection request and\nsubsequent messages are queued at the sender’s side, while a separate thread\nas part of ZeroMQ’s library will take care that eventually the connection is set\nup and messages are transmitted to the recipient.\nSimplifying matters, ZeroMQ establishes a higher level of abstraction in\nsocket-based communication by pairing sockets: a specific type of socket used\nfor sending messages is paired with a corresponding socket type for receiving\nmessages. Each pair of socket types corresponds to a communication pattern.\nThe three most important communication patterns supported by ZeroMQ are\nrequest-reply, publish-subscribe, and pipeline.\nThe request-reply pattern is used in traditional client-server communi-\ncation, like the ones normally used for remote procedure calls. A client\napplication uses a request socket (of type REQ) to send a request message to a\nserver and expects the latter to respond with an appropriate response. The\nserver is assumed to use a reply socket (of type REP). The request-reply pattern\nsimplifies matters for developers by avoiding the need to call the listen\noperation, as well as the accept operation. Moreover, when a server receives\na message, a subsequent call to send is automatically targeted toward the\noriginal sender. Likewise, when a client calls the recv operation (for receiving\na message) after having sent a message, ZeroMQ assumes the client is wait-\ning for a response from the original recipient. Note that this approach was\neffectively encoded in the local sendrecv operation of Figure 4.20(b), which\nwe discussed in Note 4.8.\nDS 4.01\n \n",
      "content_length": 3172,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 231,
      "content": "4.3. MESSAGE-ORIENTED COMMUNICATION\n215\nNote 4.9 (Example: The request-reply pattern)\nLet us look at a simple programming example to illustrate the request-reply\npattern. Figure 4.21 shows a server that appends an asterisk to a received message.\nAs before, it creates a socket, and binds it to a combination of a protocol (in this\ncase TCP), and a host and port. In our example, the server is willing to accept\nincoming connection requests on two different ports. It then waits for incoming\nmessages. The request-reply pattern effectively ties the receipt of a message to the\nsubsequent response. In other words, when the server calls send, it will transmit\na message to the same client from which it previously had received a message. Of\ncourse, this simplicity can be achieved only if the programmer indeed abides to\nthe request-reply pattern.\n1 import zmq\n2\n3 def server():\n4\ncontext = zmq.Context()\n5\nsocket\n= context.socket(zmq.REP)\n# create reply socket\n6\nsocket.bind(\"tcp://*:12345\")\n# bind socket to address\n7\n8\nwhile True:\n9\nmessage = socket.recv()\n# wait for incoming message\n10\nif not \"STOP\" in str(message):\n# if not to stop...\n11\nreply = str(message.decode())+’*’\n# append \"*\" to message\n12\nsocket.send(reply.encode())\n# send it away (encoded)\n13\nelse:\n14\nbreak\n# break out of loop and end\n15\n16 def client():\n17\ncontext = zmq.Context()\n18\nsocket\n= context.socket(zmq.REQ)\n# create request socket\n19\n20\nsocket.connect(\"tcp://localhost:12345\") # block until connected\n21\nsocket.send(b\"Hello world\")\n# send message\n22\nmessage = socket.recv()\n# block until response\n23\nsocket.send(b\"STOP\")\n# tell server to stop\n24\nprint(message.decode())\n# print result\nFigure 4.21: A ZeroMQ client-server system.\nThe client, also shown in Figure 4.21, creates a socket and connects to the\nassociated server. When it sends a message, it can expect to receive, from that\nsame server, a response. By sending the string “STOP”, it tells the server it is done,\nafter which the server will actually stop.\nInterestingly, the asynchronous nature of ZeroMQ allows one to start the client\nbefore starting the server. An implication is that if, in this example, we would start\nthe server, then a client, and after a while a second client, that the latter will be\nblocked until the server is restarted. Furthermore, note that ZeroMQ does not\nrequire the programmer to specify how many bytes are expected to be received.\nUnlike TCP, ZeroMQ uses messages instead of byte streams.\n \nDS 4.01\n",
      "content_length": 2471,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 232,
      "content": "216\nCHAPTER 4. COMMUNICATION\nIn the case of a publish-subscribe pattern, clients subscribe to specific mes-\nsages that are published by servers. We came across this pattern in Section 2.1.3\nwhen discussing coordination. In effect, only the messages to which the client\nhas subscribed will be transmitted. If a server is publishing messages to which\nno one has subscribed, these messages will be lost. In its simplest form, this\npattern establishes multicasting messages from a server to several clients. The\nserver is assumed to use a socket of type PUB, while each client must use SUB\ntype sockets. Each client socket is connected to the socket of the server. By\ndefault, a client subscribes to no specific message. This means that as long\nas no explicit subscription is provided, a client will not receive a message\npublished by the server.\nNote 4.10 (Example: The publish-subscribe pattern)\nAgain, let us make this pattern more concrete through a simple example. Fig-\nure 4.22 shows an admittedly naive time server that publishes its current, local\ntime, through a PUB socket. The local time is published every five seconds, for any\ninterested client.\n1 import multiprocessing\n2 import zmq, time\n3\n4 def server():\n5\ncontext = zmq.Context()\n6\nsocket = context.socket(zmq.PUB)\n# create a publisher socket\n7\nsocket.bind(\"tcp://*:12345\")\n# bind socket to the address\n8\nwhile True:\n9\ntime.sleep(5)\n# wait every 5 seconds\n10\nt = \"TIME \" + time.asctime()\n11\nsocket.send(t.encode())\n# publish the current time\n12\n13 def client():\n14\ncontext = zmq.Context()\n15\nsocket = context.socket(zmq.SUB)\n# create a subscriber socket\n16\nsocket.connect(\"tcp://localhost:12345\")\n# connect to the server\n17\nsocket.setsockopt(zmq.SUBSCRIBE, b\"TIME\") # subscribe to TIME messages\n18\n19\nfor i in range(5):\n# Five iterations\n20\ntime = socket.recv()\n# receive a message related to subscription\n21\nprint(time.decode())\n# print the result\nFigure 4.22: A multicasting socket-based setup.\nA client is equally simple, as also shown in Figure 4.22. It first creates a SUB\nsocket which it connects to the corresponding PUB socket of the server. To receive\nthe appropriate messages, it needs to subscribe to messages that have TIME as\ntheir tag. In our example, a client will simply print the first five messages received\nfrom the server. Note that we can have as many clients as we want: the server’s\nmessage will be multicasted to all subscribers. Most important in this example, is\nDS 4.01\n \n",
      "content_length": 2462,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 233,
      "content": "4.3. MESSAGE-ORIENTED COMMUNICATION\n217\nthat it illustrates that the only messages received through the SUB socket, are the\nones the client had subscribed to.\nFinally, the pipeline pattern is characterized by the fact that a process\nwants to push out its results, assuming that there are other processes that want\nto pull in those results. The essence of the pipeline pattern is that a pushing\nprocess does not really care which other process pulls in its results: the first\navailable one will do just fine. Likewise, any process pulling in results from\nmultiple other processes will do so from the first pushing process making its\nresults available. The intention of the pipeline pattern is thus seen to keep as\nmany processes working as possible, pushing results through a pipeline of\nprocesses as quickly as possible.\nNote 4.11 (Example: The pipeline pattern)\nAs our last example, consider the following template for keeping a collection\nof worker tasks busy. Figure 4.23 shows the code for a so-called farmer task: a\nprocess producing tasks to be picked up by others. In this example, we simulate\nthe task by letting the producer pick a random number modeling the duration,\nor load, of the work to be done. This workload is then sent to the PUSH socket,\neffectively being queued until another process picks it up.\n1 def producer():\n2\ncontext = zmq.Context()\n3\nsocket\n= context.socket(zmq.PUSH)\n# create a push socket\n4\nsocket.bind(\"tcp://127.0.0.1:12345\")\n# bind socket to address\n5\n6\nwhile True:\n7\nworkload = random.randint(1, 100)\n# compute workload\n8\nsocket.send(pickle.dumps(workload))\n# send workload to worker\n9\ntime.sleep(workload/NWORKERS)\n# balance production by waiting\n10\n11 def worker(id):\n12\ncontext = zmq.Context()\n13\nsocket\n= context.socket(zmq.PULL)\n# create a pull socket\n14\nsocket.connect(\"tcp://localhost:12345\") # connect to the producer\n15\n16\nwhile True:\n17\nwork = pickle.loads(socket.recv())\n# receive work from a source\n18\ntime.sleep(work)\n# pretend to work\nFigure 4.23: A producer-worker pattern.\nSuch other processes are known as worker tasks, of which a sketch is also\ngiven in Figure 4.23. A worker task connects to a single PULL socket. Once it picks\nup some work, it simulates that it is actually doing something by sleeping for\nsome time proportional to the received workload.\n \nDS 4.01\n",
      "content_length": 2321,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 234,
      "content": "218\nCHAPTER 4. COMMUNICATION\nThe semantics of this push-pull pattern is such that the first available worker\nwill pick up work from the producer, and likewise, if there are multiple workers\nready to pick up work, each one of them will be provided with a task. How work\ndistribution is actually done fairly requires some specific attention, which we will\nnot discuss further here.\nThe Message-Passing Interface (MPI)\nWith the advent of high-performance multicomputers, developers have been\nlooking for message-oriented operations that would allow them to easily write\nhighly efficient applications. This means that the operations should be at a\nconvenient level of abstraction (to ease application development), and that\ntheir implementation incurs only minimal overhead. Sockets were deemed\ninsufficient for two reasons. First, they were at the wrong level of abstraction\nby supporting only simple send and receive operations. Second, sockets\nhad been designed to communicate across networks using general-purpose\nprotocol stacks such as TCP/IP. They were not considered suitable for the\nproprietary protocols developed for high-speed interconnection networks,\nsuch as those used in high-performance server clusters. Those protocols\nrequired an interface that could handle more advanced features, such as\ndifferent forms of buffering and synchronization.\nThe result was that most interconnection networks and high-performance\nmulticomputers were shipped with proprietary communication libraries.\nThese libraries offered a wealth of high-level and generally efficient com-\nmunication operations. Of course, all libraries were mutually incompatible, so\nthat application developers now had a portability problem.\nThe need to be hardware and platform independent eventually lead to\nthe definition of a standard for message passing, simply called the Message-\nPassing Interface or MPI. MPI is designed for parallel applications and\nas such is tailored to transient communication. It makes direct use of the\nunderlying network. Furthermore, it assumes that serious failures such as\nprocess crashes or network partitions are fatal and do not require automatic\nrecovery.\nMPI assumes communication takes place within a known group of pro-\ncesses. Each group is assigned an identifier. Each process within a group is\nalso assigned a (local) identifier. A (groupID, processID) pair therefore uniquely\nidentifies the source or destination of a message, and is used instead of a\ntransport-level address. There may be several, possibly overlapping, groups\nof processes involved in a computation and that are all executing at the same\ntime.\nAt the core of MPI are messaging operations to support transient com-\nmunication, of which the most intuitive ones are summarized in Figure 4.25.\nTo understand their semantics, it helps to keep Figure 4.4 in mind, with the\nDS 4.01\n \n",
      "content_length": 2859,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 235,
      "content": "4.3. MESSAGE-ORIENTED COMMUNICATION\n219\nmiddleware formed entirely by an MPI implementation. In particular, the\nmiddleware maintains its own buffers and synchronization is often related to\nwhen the necessary data has been copied from the calling application to the\nmiddleware.\nOperation\nDescription\nMPI_BSEND\nAppend outgoing message to a local send buffer\nMPI_SEND\nSend a message and wait until copied to local or remote\nbuffer\nMPI_SSEND\nSend a message and wait until transmission starts\nMPI_SENDRECV\nSend a message and wait for reply\nMPI_ISEND\nPass reference to outgoing message, and continue\nMPI_ISSEND\nPass reference to outgoing message, and wait until receipt\nstarts\nMPI_RECV\nReceive a message; block if there is none\nMPI_IRECV\nCheck if there is an incoming message, but do not block\nFigure 4.24: Some of the more intuitive message-passing operations of MPI.\nTransient asynchronous communication is supported by the MPI_BSEND\noperation. The sender submits a message for transmission, which is generally\nfirst copied to a local buffer in the MPI runtime system. When the message\nhas been copied, the sender continues. The local MPI runtime system will\nremove the message from its local buffer and take care of transmission as soon\nas a receiver has called a receive operation.\nThere is also a blocking send operation, called MPI_SEND, of which the\nsemantics are implementation dependent. The operation MPI_SEND may either\nblock the caller until the specified message has been copied to the MPI\nruntime system at the sender’s side, or until the receiver has initiated a receive\noperation. Synchronous communication by which the sender blocks until its\nrequest is accepted for further processing is available through the MPI_SSEND\noperation. Finally, the strongest form of synchronous communication is also\nsupported: when a sender calls MPI_SENDRECV, it sends a request to the receiver\nand blocks until the latter returns a reply. Basically, this operation corresponds\nto a normal RPC.\nBoth MPI_SEND and MPI_SSEND have variants that avoid copying messages\nfrom user buffers to buffers internal to the local MPI runtime system. These\nvariants essentially correspond to a form of asynchronous communication.\nWith MPI_ISEND, a sender passes a pointer to the message, after which the MPI\nruntime system takes care of communication. The sender immediately contin-\nues. To prevent overwriting the message before communication completes,\nMPI offers operations to check for completion, or even to block if required.\nAs with MPI_SEND, whether the message has actually been transferred to the\nreceiver or that it has merely been copied by the local MPI runtime system to\nan internal buffer is left unspecified.\n \nDS 4.01\n",
      "content_length": 2713,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 236,
      "content": "220\nCHAPTER 4. COMMUNICATION\nLikewise, with MPI_ISSEND, a sender also passes only a pointer to the MPI\nruntime system. When the runtime system indicates it has processed the\nmessage, the sender is then guaranteed that the receiver has accepted the\nmessage and is now working on it.\nThe operation MPI_RECV is called to receive a message; it blocks the\ncaller until a message arrives. There is also an asynchronous variant, called\nMPI_IRECV, by which a receiver indicates that it is prepared to accept a mes-\nsage. The receiver can check whether a message has indeed arrived, or block\nuntil one does.\nThe semantics of MPI communication operations are not always straight-\nforward, and different operations can sometimes be interchanged without\naffecting the correctness of a program. The official reason why so many differ-\nent forms of communication are supported is that it gives implementers of\nMPI systems enough possibilities for optimizing performance. Cynics might\nsay the committee could not make up its collective mind, so it threw in every-\nthing. By now, MPI is in its fourth version with over 650 operations available.\nBeing designed for high-performance parallel applications, it is perhaps easier\nto understand its diversity. More on MPI can be found in [Gropp et al., 2016].\nThe complete MPI-4 reference can be found in [Message Passing Interface\nForum, 2021].\n4.3.3\nMessage-oriented persistent communication\nWe now come to an important class of message-oriented middleware services,\ngenerally known as message-queuing systems, or just message-oriented\nmiddleware (MOM). Message-queuing systems provide extensive support for\npersistent asynchronous communication. The essence of these systems is that\nthey offer intermediate-term storage capacity for messages, without requiring\neither the sender or receiver to be active during message transmission. An\nimportant difference with sockets and MPI is that message-queuing systems\nare typically targeted to support message transfers that are allowed to take\nminutes instead of seconds or milliseconds.\nMessage-queuing model\nThe basic idea behind a message-queuing system is that applications commu-\nnicate by inserting messages in specific queues. These messages are forwarded\nover a series of communication servers and are eventually delivered to the\ndestination, even if it was down when the message was sent. In practice, most\ncommunication servers are directly connected to each other. In other words, a\nmessage is generally transferred directly to a destination server. In principle,\neach application has its own private queue to which other applications can\nsend messages. A queue can be read only by its associated application, but it\nis also possible for multiple applications to share a single queue.\nDS 4.01\n \n",
      "content_length": 2780,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 237,
      "content": "4.3. MESSAGE-ORIENTED COMMUNICATION\n221\nAn important aspect of message-queuing systems is that a sender is gen-\nerally given only the guarantees that its message will eventually be inserted\nin the recipient’s queue. No guarantees are given about when, or even if\nthe message will actually be read, which is completely determined by the\nbehavior of the recipient.\nThese semantics permit communication to be decoupled in time, as also\ndiscussed in Section 2.1.3. There is thus no need for the receiver to be executing\nwhen a message is being sent to its queue. Likewise, there is no need for the\nsender to be executing the moment its message is picked up by the receiver.\nThe sender and receiver can execute completely independently of each other.\nIn fact, once a message has been deposited in a queue, it will remain there\nuntil it is removed, irrespective of whether its sender or receiver is executing.\nThis gives us four combinations regarding the execution mode of the sender\nand receiver, as shown in Figure 4.25.\nFigure 4.25: Four combinations for loosely coupled communication using\nqueues.\nIn Figure 4.25(a), both the sender and receiver are in execution during\nthe entire transmission of a message. In Figure 4.25(b), only the sender is in\nexecution, while the receiver is passive, that is, in a state in which message\ndelivery is not possible. Nevertheless, the sender can still send messages.\nThe combination of a passive sender and an active receiver is shown in\nFigure 4.25(c). In this case, the receiver can read messages that were sent\nto it, but it is not necessary that their respective senders are in execution\nas well. Finally, in Figure 4.25(d), we see the situation that the system is\nstoring (and possibly transmitting) messages even while sender and receiver\n \nDS 4.01\n",
      "content_length": 1791,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 238,
      "content": "222\nCHAPTER 4. COMMUNICATION\nare passive. One may argue that only if this last configuration is supported,\nthe message-queuing system truly provides persistent messaging.\nMessages can, in principle, contain any data. The only important aspect\nfrom the perspective of middleware is that messages are properly addressed.\nIn practice, addressing is done by providing a systemwide unique name of the\ndestination queue. In some cases, message size may be limited, although it is\nalso possible that the underlying system takes care of fragmenting and assem-\nbling large messages in a way that is completely transparent to applications.\nAn effect of this approach is that the basic interface offered to applications\ncan be simple, as shown in Figure 4.26.\nOperation\nDescription\nPUT\nAppend a message to a specified queue\nGET\nBlock until the specified queue is nonempty, and remove the\nfirst message\nPOLL\nCheck a specified queue for messages, and remove the first.\nNever block\nNOTIFY\nInstall a handler to be called when a message is put into the\nspecified queue\nFigure 4.26: Basic interface to a queue in a message-queuing system.\nThe PUT operation is called by a sender to pass a message to the underlying\nsystem that is to be appended to the specified queue. As we explained, this is a\nnonblocking call. The GET operation is a blocking call by which an authorized\nprocess can remove the longest pending message in the specified queue. The\nprocess is blocked only if the queue is empty. Variations on this call allow\nsearching for a specific message in the queue, for example, using a priority, or\na matching pattern. The nonblocking variant is given by the POLL operation.\nIf the queue is empty, or if a specific message could not be found, the calling\nprocess simply continues.\nFinally, most queuing systems also allow a process to install a handler\nas a callback function, which is automatically invoked whenever a message\nis put into the queue. Arranging this scheme is handled through a NOTIFY\noperation. Callbacks can also be used to automatically start a process that\nwill fetch messages from the queue if no process is currently in execution.\nThis approach is often implemented through a daemon on the receiver’s side\nthat continuously monitors the queue for incoming messages and handles\naccordingly.\nGeneral architecture of a message-queuing system\nLet us now take a closer look at what a general message-queuing system looks\nlike. First, queues are managed by queue managers. A queue manager is\neither a separate process, or is implemented through a library that is linked\nDS 4.01\n \n",
      "content_length": 2586,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 239,
      "content": "4.3. MESSAGE-ORIENTED COMMUNICATION\n223\nwith an application. Secondly, as a rule of thumb, an application can put\nmessages only into a local queue. Likewise, getting a message is possible by\nextracting it from a local queue only. As a consequence, if a queue manager\nQMA handling the queues for an application A runs as a separate process,\nboth processes QMA and A will generally be placed on the same machine, or\nat worst on the same LAN. Also note that if all queue managers are linked\ninto their respective applications, we can no longer speak of a persistent\nasynchronous messaging system.\nIf applications can put messages only into local queues, then clearly each\nmessage will have to carry information concerning its destination. It is the\nqueue manager’s task to make sure that a message reaches its destination.\nThis brings us to several issues.\nIn the first place, we need to consider how the destination queue is ad-\ndressed. Obviously, to enhance location transparency, it is preferable that\nqueues have logical, location-independent names. Assuming that a queue man-\nager is implemented as a separate process, using logical names implies that\neach name should be associated with a contact address, such as a (host,port)-\npair, and that the name-to-address mapping is readily available to a queue\nmanager, as shown in Figure 4.27. In practice, a contact address carries more\ninformation, notably the protocol to be used, such as TCP or UDP. We came\nacross such contact addresses in our examples of advanced sockets in, for\nexample, Note 4.9.\nFigure 4.27: The relationship between queue-level naming and network-level\naddressing.\nA second issue that we need to consider is how the name-to-address\nmapping is actually made available to a queue manager. A common approach\nis to simply implement the mapping as a lookup table and copy that table\nto all managers. Obviously, this leads to a maintenance problem, for every\ntime that a new queue is added or named, many, if not all tables, need to be\nupdated. There are various ways to alleviate such problems, which we will\ndiscuss in Chapter 6.\n \nDS 4.01\n",
      "content_length": 2111,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 240,
      "content": "224\nCHAPTER 4. COMMUNICATION\nThis brings us to a third issue, related to the problems of efficiently\nmaintaining name-to-address mappings. We have implicitly assumed that if a\ndestination queue at manager QMB is known to queue manager QMA, then\nQMA can directly contact QMB to transfer messages. In effect, this means that\n(the contact address of) each queue manager should be known to all others.\nObviously, when dealing with large message-queuing systems, we will have a\nscalability problem. In practice, there are often special queue managers that\noperate as routers: they forward incoming messages to other queue managers.\nIn this way, a message-queuing system may gradually grow into a complete,\napplication-level, overlay network.\nIf only a few routers need to know about the network topology, then a\nsource queue manager need only to know to which adjacent router, say R, it\nshould forward a message, given a destination queue. The router R, in turn,\nmay need to keep track only of its adjacent routers to see where to forward\nthe message to, and so on. Of course, we still need to have name-to-address\nmappings for all queue managers, including the routers, but it is not difficult\nto imagine that such tables can be much smaller and easier to maintain.\nMessage brokers\nAn important application area of message-queuing systems is integrating\nexisting and new applications into a single, coherent distributed information\nsystem. If we assume that communication with an application takes place\nthrough messages, then integration requires that applications can understand\nthe messages they receive. In practice, this requires the sender to have its\noutgoing messages in the same format as that of the receiver, but also that\nits messages adhere to the same semantics as those expected by the receiver.\nSender and receiver essentially need to speak the same language, that is,\nadhere to the same messaging protocol.\nThe problem with this approach is that each time an application A is\nadded to the system having its own messaging protocol, then for each other\napplication B that is to communicate with A we will need to provide the means\nfor converting their respective messages. In a system with N applications, we\nwill thus need N × N messaging-protocol converters.\nAn alternative is to agree on a common messaging protocol, as is done\nwith traditional network protocols. Unfortunately, this approach will generally\nnot work for message-queuing systems. The problem is the level of abstraction\nat which these systems operate. A common messaging protocol makes sense\nonly if the collection of processes that make use of that protocol indeed\nhave enough in common. If the collection of applications that make up a\ndistributed information system is highly diverse (which it often is), then\ninventing a one-size-fits-all solution is simply not going to work.\nIf we focus only on the format and meaning of messages, commonality can\nbe achieved by lifting the level of abstraction, as is done with XML messages.\nDS 4.01\n \n",
      "content_length": 3022,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 241,
      "content": "4.3. MESSAGE-ORIENTED COMMUNICATION\n225\nIn this case, messages carry information on their own organization, and what\nhas been standardized is the way that they can describe their content. As a\nconsequence, an application can provide information on the organization of\nits messages that can be automatically processed. Of course, this information\nis generally not enough: we also need to make sure that the semantics of\nmessages are well understood.\nGiven these problems, the general approach is to learn to live with differ-\nences, and try to provide the means to make conversions as simple as possible.\nIn message-queuing systems, conversions are handled by special nodes in a\nqueuing network, known as message brokers. A message broker acts as an\napplication-level gateway in a message-queuing system. Its main purpose is to\nconvert incoming messages so that they can be understood by the destination\napplication. Note that to a message-queuing system, a message broker is just\nanother application, as shown in Figure 4.28. In other words, a message broker\nis generally not considered to be an integral part of the queuing system.\nFigure 4.28: The general organization of a message broker in a message-\nqueuing system.\nA message broker can be as simple as a reformatter for messages. For\nexample, assume an incoming message contains a table from a database in\nwhich records are separated by a special end-of-record delimiter and fields\nwithin a record have a known, fixed length. If the destination application\nexpects a different delimiter between records, and also expects that fields have\nvariable lengths, a message broker can be used to convert messages to the\nformat expected by the destination.\nIn a more advanced setting, a message broker may act as an application-\nlevel gateway, in which information on the messaging protocol of several\napplications has been encoded. In general, for each pair of applications, we\nwill have a separate subprogram capable of converting messages between the\ntwo applications. In Figure 4.28, this subprogram is drawn as a plugin to\nemphasize that such parts can be dynamically plugged in, or removed from a\nbroker.\n \nDS 4.01\n",
      "content_length": 2168,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 242,
      "content": "226\nCHAPTER 4. COMMUNICATION\nFinally, note that often a message broker is used for advanced enterprise\napplication integration (EAI), as we discussed in Section 1.3.2. In this case,\nrather than (only) converting messages, a broker is responsible for matching\napplications based on the messages that are being exchanged. In such a\npublish-subscribe model, applications send messages in the form of publishing.\nIn particular, they may publish a message on topic X, which is then sent to the\nbroker. Applications that have stated their interest in messages on topic X, that\nis, who have subscribed to those messages, will then receive these messages\nfrom the broker. More advanced forms of mediation are also possible.\nAt the heart of a message broker lies a repository of rules for transforming\na message of one type to another. The problem is defining the rules and\ndeveloping the plugins. Most message-broker products come with sophisti-\ncated development tools, but the bottom line is still that the repository needs\nto be filled by experts. Here we see a perfect example where commercial\nproducts are often misleadingly said to provide “intelligence,” where, in fact,\nthe intelligence is to be found only in the heads of those experts. It may be\nbetter to consistently talk about “advanced” systems (but even then, we often\nsee that this stands for complex or complicated).\nNote 4.12 (More information: A note on message-queuing systems)\nConsidering what we have said about message-queuing systems, it would appear\nthat they have long existed in the form of implementations for e-mail services.\nE-mail systems are generally implemented through a collection of mail servers\nthat store and forward messages on behalf of the users on hosts directly connected\nto the server. Routing is generally left out, as e-mail systems can make direct use\nof the underlying transport services. For example, in the mail protocol for the\nInternet, SMTP [Postel, 1982], a message is transferred by setting up a direct TCP\nconnection to the destination mail server.\nWhat makes e-mail systems special compared to message-queuing systems\nis that they are primarily aimed at providing direct support for end users. This\nexplains, for example, why several groupware applications are based directly\non an e-mail system [Khoshafian and Buckiewicz, 1995]. In addition, e-mail\nsystems may have very specific requirements such as automatic message filtering,\nsupport for advanced messaging databases (e.g., to easily retrieve previously\nstored messages), and so on.\nGeneral message-queuing systems are not aimed at supporting only end users.\nAn important issue is that they are set up to enable persistent communication\nbetween processes, regardless of whether a process is running a user application,\nhandling access to a database, performing computations, and so on. This approach\nleads to a different set of requirements for message-queuing systems than pure e-\nmail systems. For example, e-mail systems generally need not provide guaranteed\nmessage delivery, message priorities, logging facilities, efficient multicasting, load\nbalancing, fault tolerance, and so on for general usage.\nGeneral-purpose message-queuing systems, therefore, have a wide range\nDS 4.01\n \n",
      "content_length": 3242,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 243,
      "content": "4.3. MESSAGE-ORIENTED COMMUNICATION\n227\nof applications, including e-mail, workflow, groupware, and batch processing.\nHowever, as we have stated before, the most important application area is the in-\ntegration of a (possibly widely dispersed) collection of databases and applications\ninto a federated information system [Hohpe and Woolf, 2004]. For example, a\nquery expanding several databases may need to be split into subqueries that are\nforwarded to individual databases. Message-queuing systems assist by providing\nthe basic means to package each subquery into a message and routing it to the\nappropriate database. Other communication facilities we have discussed in this\nchapter are far less appropriate.\n4.3.4\nExample: Advanced Message Queuing Protocol (AMQP)\nAn interesting observation about message-queuing systems is that they have\nbeen developed in part to allow legacy applications to interoperate, yet at\nthe same time we see that when it comes to operations between different\nmessage-queuing systems, we often hit a wall. As a consequence, once an\norganization chooses to use a message-queuing system from manufacturer X,\nthey may have to settle for solutions that only X provides. Message-queuing\nsolutions are thus in large part proprietary solutions. So much for openness.\nIn 2006, a working group was formed to change this situation, which\nresulted in the specification of the Advanced Message-Queuing Protocol,\nor simply AMQP. There are different versions of AMQP, with version 1.0\nbeing the most recent one. There are also various implementations of AMQP,\nnotably of versions before 1.0, which by the time version 1.0 was established,\nhad gained considerable popularity. Because a pre-1.0 version is so different\nfrom the 1.0 version, yet has also a steady user base, we may see various\npre-1.0 AMQP servers exist next to (their undeniably incompatible) 1.0 servers.\nIn this section, we will describe AMQP, but will more or less deliberately\nmix the pre-1.0 and 1.0 versions, sticking to the essentials and spirit of AMQP.\nDetails can be found in the specifications [AMQP Working Group, 2008;\nOASIS, 2012]. Implementations of AMQP include RabbitMQ [Roy, 2018] and\nApache’s ActiveMQ.\nBasics\nAMQP revolves around applications, queue managers, and queues. Taking\nan approach that is common for many networking situations, we make a\ndistinction between AMQP as a messaging service, the actual messaging protocol,\nand, finally, the messaging interface as offered to applications. To this end,\nit is easiest to consider having only a single queue manager, running as a\nsingle, separate server, forming the implementation of AMQP as a service. An\napplication communicates with this queue manager through a local interface.\n \nDS 4.01\n",
      "content_length": 2745,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 244,
      "content": "228\nCHAPTER 4. COMMUNICATION\nFigure 4.29: An overview of a single-server AMQP instance.\nBetween an application and the queue manager, communication proceeds\naccording to the AMQP protocol.\nThis situation is shown in Figure 4.29 and should look familiar. The AMQP\nstub shields the application (as well as the queue manager) from the details\nconcerning message transfer and communication in general. At the same\ntime, it implements a message-queuing interface, allowing the application to\nmake use of AMQP as a message-queuing service. Although the distinction\nbetween AMQP stub and queue manager is made explicit for queue managers,\nthe strictness of the separation is left to an implementation. Nevertheless, if\nnot strict, conceptually there is a distinction between handling queues and\nhandling related communication as we shall make clear shortly.\nAMQP communication\nAMQP allows an application to set up a connection to a queue manager; a\nconnection is a container for a number of one-way channels. Whereas the\nlifetime of a channel can be highly dynamic, connections are assumed to\nbe relatively stable. This difference between connection and channel allows\nfor efficient implementations, notably by using a single transport-layer TCP\nconnection to multiplex many different channels between an application and\na queue manager. In practice, AMQP assumes TCP is used for establishing\nAMQP connections.\nBidirectional communication is established through sessions: a logical\ngrouping of two channels. A connection may have multiple sessions, but note\nthat a channel need not necessarily be part of a session.\nFinally, to actually transfer messages, a link is needed. Conceptually, a\nlink, or rather its end points, keep track of the status of messages that are\nbeing transferred. It thus provides fine-grained flow control between an\napplication and a queue manager, and, indeed, different control policies can\nbe put simultaneously in place for different messages that are transferred\nDS 4.01\n \n",
      "content_length": 1996,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 245,
      "content": "4.3. MESSAGE-ORIENTED COMMUNICATION\n229\nthrough the same session or connection. Flow control is established through\ncredits: a receiver can tell the sender how many messages it is allowed to send\nover a specific link.\nWhen a message is to be transferred, the application passes it to its local\nAMQP stub. As mentioned, each message transfer is associated with one\nspecific link. Message transfer normally proceeds in three steps.\n1. At the sender’s side, the message is assigned a unique identifier and\nis recorded locally to be in an unsettled state. The stub subsequently\ntransfers the message to the server, where the AMQP stub also records it\nas being in an unsettled state. At that point, the server-side stub passes\nit to the queue manager.\n2. The receiving application (in this case the queue manager), is assumed\nto handle the message and normally reports back to its stub that it is\nfinished. The stub passes this information to the original sender, at\nwhich point the message at the original sender’s AMQP stub enters a\nsettled state.\n3. The AMQP stub of the original sender now tells the stub of the original\nreceiver that message transfer has been settled (meaning that the original\nsender will forget about the message from now on). The receiver’s stub\ncan now also discard anything about the message, formally recording it\nas being settled as well.\nNote that because the receiving application can indicate to the underlying\nAMQP communication layer that it is done with a message, AMQP enables\ntrue end-to-end communication reliability. In particular, the application, be\nit a client application or an actual queue manager, can instruct the AMQP\ncommunication layer to keep hold of a message (i.e., a message stays in the\nunsettled state).\nAMQP messaging\nMessaging in AMQP logically takes place at the layer above the one handling\ncommunication. It is here that an application can indicate what needs to be\ndone with a message, but can also see what has happened so far. Messaging\nformally takes place between two nodes, of which there are three types: a\nproducer, a consumer, or a queue. Typically, producer and consumer nodes\nrepresent regular applications, whereas queues are used to store and forward\nmessages. Indeed, a queue manager will typically consist of multiple queue\nnodes. In order for message transfer to take place, two nodes will have to\nestablish a link between them.\nThe receiver can indicate to the sender whether its message was accepted\n(meaning that it was successfully processed), or rejected.\nNote that this\nmeans that a notification is returned to the original sender. AMQP also\n \nDS 4.01\n",
      "content_length": 2629,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 246,
      "content": "230\nCHAPTER 4. COMMUNICATION\n1 import rabbitpy\n2\n3 def producer():\n4\nconnection = rabbitpy.Connection() # Connect to RabbitMQ server\n5\nchannel = connection.channel()\n# Create new channel on the connection\n6\n7\nexchange = rabbitpy.Exchange(channel, ’exchange’) # Create an exchange\n8\nexchange.declare()\n9\n10\nqueue1 = rabbitpy.Queue(channel, ’example1’) # Create 1st queue\n11\nqueue1.declare()\n12\n13\nqueue2 = rabbitpy.Queue(channel, ’example2’) # Create 2nd queue\n14\nqueue2.declare()\n15\n16\nqueue1.bind(exchange, ’example-key’) # Bind queue1 to a single key\n17\nqueue2.bind(exchange, ’example-key’) # Bind queue2 to the same key\n18\n19\nmessage = rabbitpy.Message(channel, ’Test message’)\n20\nmessage.publish(exchange, ’example-key’) # Publish the message using the key\n21\nexchange.delete()\n(a)\n1 import rabbitpy\n2\n3 def consumer():\n4\nconnection = rabbitpy.Connection()\n5\nchannel = connection.channel()\n6\n7\nqueue = rabbitpy.Queue(channel, ’example1’)\n8\n9\n# While there are messages in the queue, fetch them using Basic.Get\n10\nwhile len(queue) > 0:\n11\nmessage = queue.get()\n12\nprint(’Message Q1: %s’ % message.body.decode())\n13\nmessage.ack()\n14\n15\nqueue = rabbitpy.Queue(channel, ’example2’)\n16\n17\nwhile len(queue) > 0:\n18\nmessage = queue.get()\n19\nprint(’Message Q2: %s’ % message.body.decode())\n20\nmessage.ack()\n(b)\nFigure 4.30: A simple (a) producer and (b) consumer for RabbitMQ, adapted\nfrom [Roy, 2018].\nDS 4.01\n \n",
      "content_length": 1409,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 247,
      "content": "4.3. MESSAGE-ORIENTED COMMUNICATION\n231\nsupports fragmentation and assembly of large messages, for which additional\nnotifications are sent.\nOf course, an important aspect of AMQP is its support for persistent\nmessaging. Achieving persistence is handled through several mechanisms.\nFirst, a message can be marked as durable, indicating that the source expects\nany intermediate node, such as a queue, to be able to recover in the case\nof a failure. An intermediate node that cannot guarantee such durability\nwill have to reject a message.\nSecond, a source or target node can also\nindicate its durability: if durable, will it maintain its state, or will it also\nmaintain the (unsettled) state of durable messages? Combining the latter\nwith durable messages effectively establishes reliable message transfer and\npersistent messaging.\nAMQP is truly a messaging protocol in the sense that it does not by itself\nsupport, for example, publish-subscribe primitives. It expects that such issues\nare handled by more advanced, proprietary queue managers, akin to the\nmessage brokers discussed in Section 4.3.3.\nFinally, there is no reason why a queue manager cannot be connected to\nanother queue manager. In fact, it is quite common to organize queue man-\nagers into an overlay network in which messages are routed from producers to\ntheir consumers. AMQP does not specify how the overlay network should be\nconstructed and managed, and, indeed, different providers of AMQP-based\nsystems offer different solutions. Of particular importance is specifying how\nmessages should be routed through the network. The bottom line is that ad-\nministrators will need to do a lot of this specification manually. Only in cases\nwhere overlays have regular structures, such as cycles or trees, it becomes\neasier to provide the necessary routing details.\nAMQP in practice\nOne of the more popular implementations of message brokering is the Rab-\nbitMQ server, extensively described by Roy [2018]. The RabbitMQ server is\nbased on the 0.9 version of AMQP, while also fully supporting version 1.0. An\nimportant difference between these two versions is the use of exchanges. In-\nstead of directly manipulating queues, producers contact an exchange, which,\nin turn, places messages in one or several queues. In essence, an exchange\nallows a producer to use a synchronous or asynchronous RPC to a queue\nmanager. An exchange never stores messages; it simply makes sure that a\nmessage is placed in an appropriate queue.\nTo illustrate this concept, consider Figure 4.30(a) showing a simple pro-\nducer. As mentioned previously, AMQP embeds channels as part of more\ndurable connections, and the first we do is create a means for communicating\nwith the server (we are omitting various details; in this case we establish a\ndefault connection with the server). In the following lines, an exchange is\ncreated within the realm of the server, along with two queues. In Lines 16\n \nDS 4.01\n",
      "content_length": 2940,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 248,
      "content": "232\nCHAPTER 4. COMMUNICATION\nand 17, both queues are bound to the same exchange by a simple key named\nexample-key. After creating a message, the producer tells the exchange that it\nshould publish that message to any queue bound by the specified key.\nAs to be expected, the exchange will place the message in both queues,\nwhich is verified by the simple consumer shown in Figure 4.30(b). In this case,\nthe consumer simply fetches messages from either queue and prints their\ncontent.\nExchanges and queues have many options, for which we refer the inter-\nested reader to Roy [2018]. It is important to note that using systems such\nas RabbitMQ, but also other messaging brokers, one can generally set up\nadvanced overlay networks for application-level message routing. At the same\ntime, maintenance of those networks can easily become a nightmare.\n4.4\nMulticast communication\nAn important topic in communication in distributed systems is the support for\nsending data to multiple receivers, also known as multicast communication.\nFor many years, this topic has belonged to the domain of network protocols,\nwhere numerous proposals for network-level and transport-level solutions\nhave been implemented and evaluated [Janic, 2005; Obraczka, 1998]. A major\nissue in all solutions was setting up the communication paths for information\ndissemination. In practice, this involved a huge management effort, often\nrequiring human intervention. In addition, as long as there is no convergence\nof proposals, ISPs have shown to be reluctant to support multicasting [Diot\net al., 2000].\nWith the advent of peer-to-peer technology, and notably structured overlay\nmanagement, it became easier to set up communication paths. As peer-to-peer\nsolutions are typically deployed at the application layer, various application-\nlevel multicasting techniques have been introduced. In this section, we will\ntake a brief look at these techniques.\nMulticast communication can also be accomplished in other ways than\nsetting up explicit communication paths. As we also explore in this sec-\ntion, gossip-based information dissemination provides simple (yet often less\nefficient) ways for multicasting.\n4.4.1\nApplication-level tree-based multicasting\nThe basic idea in application-level multicasting is that nodes are organized\ninto an overlay network, which is then used to disseminate information to its\nmembers. An important observation is that network routers are not involved\nin group membership. As a consequence, the connections between nodes in\nthe overlay network may cross several physical links, and as such, routing\nmessages within the overlay may not be optimal in comparison to what could\nhave been achieved by network-level routing.\nDS 4.01\n \n",
      "content_length": 2724,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 249,
      "content": "4.4. MULTICAST COMMUNICATION\n233\nA crucial design issue is the construction of the overlay network. In\nessence, there are two approaches [El-Sayed et al., 2003; Hosseini et al., 2007;\nAllani et al., 2009]. First, nodes may organize themselves directly into a tree,\nmeaning that there is a unique (overlay) path between every pair of nodes.\nAn alternative approach is that nodes organize into a mesh network in which\nevery node will have multiple neighbors and, in general, there exist multiple\npaths between every pair of nodes. The main difference between the two is\nthat the latter generally provides higher robustness: if a connection breaks\n(e.g., because a node fails), there will still be an opportunity to disseminate\ninformation without having to immediately reorganize the entire network.\nNote 4.13 (Advanced: Constructing a multicast tree in Chord)\nTo make matters concrete, let us consider a relatively simple scheme for construct-\ning a multicast tree in Chord, which we described in Note 2.6. This scheme was\noriginally proposed for Scribe [Castro et al., 2002b] which is an application-level\nmulticasting scheme built on top of Pastry [Rowstron and Druschel, 2001]. The\nlatter is also a DHT-based peer-to-peer system.\nAssume a node wants to start a multicast session. To this end, it simply\ngenerates a multicast identifier, say, mid which is just a randomly chosen 160-bit\nkey. It then looks up succ(mid), which is the node responsible for that key, and\npromotes it to become the root of the multicast tree that will be used for sending\ndata to interested nodes. To join the tree, a node P simply executes the operation\nlookup(mid) having the effect that a lookup message with the request to join the\nmulticast group mid will be routed from P to succ(mid). The routing algorithm\nitself will be explained in detail in Chapter 6.\nOn its way toward the root, the join request will pass several nodes. Assume\nit first reaches node Q. If Q had never seen a join request for mid before, it will\nbecome a forwarder for that group. At that point, P will become a child of Q\nwhereas the latter will continue to forward the join request to the root. If the next\nnode on the root, say, R is also not yet a forwarder, it will become one and record\nQ as its child and continue to send the join request.\nOn the other hand, if Q (or R) is already a forwarder for mid, it will also record\nthe previous sender as its child (i.e., P or Q, respectively), but there will not be a\nneed to send the join request to the root anymore, as Q (or R) will already be a\nmember of the multicast tree.\nNodes such as P that have explicitly requested to join the multicast tree are, by\ndefinition, also forwarders. The result of this scheme is that we construct a multi-\ncast tree across the overlay network with two types of nodes: pure forwarders that\nact as helpers, and nodes that are also forwarders, but have explicitly requested\nto join the tree. Multicasting is now simple: a node merely sends a multicast\nmessage toward the root of the tree by again executing the lookup(mid) operation,\nafter which that message can be sent along the tree.\nWe note that this high-level description of multicasting in Scribe does not do\ncomplete justice to its original design. The interested reader is encouraged to take\na look at the details, which can be found in [Castro et al., 2002b].\n \nDS 4.01\n",
      "content_length": 3374,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 250,
      "content": "234\nCHAPTER 4. COMMUNICATION\nPerformance issues in overlays\nFrom the high-level description given above, it should be clear that although\nbuilding a tree by itself is not that difficult once we have organized the nodes\ninto an overlay, building an efficient tree may be a different story. Note that\nin our description so far, the selection of nodes that participate in the tree\ndoes not take into account any performance metrics: it is purely based on the\n(logical) routing of messages through the overlay.\nTo understand the problem at hand, take a look at Figure 4.31 which\nshows a small set of five nodes that are organized in a simple overlay network,\nwith the node A forming the root of a multicast tree. The costs for traversing\na physical link are also shown. Now, whenever A multicasts a message to\nthe other nodes, the logical route, i.e., at the level of the overlay, is simply\nA →B →E →D →C. The actual route crosses the network-level links in the\nfollowing order: A →Ra →Rb →B →Rb →Ra →Re →E →Re →Rc →\nRd →D →Rd →Rc →C. It is thus seen that this message will traverse each\nof the links ⟨B, Rb⟩, ⟨Ra, Rb⟩, ⟨E, Re⟩, ⟨Rc, Rd⟩, and ⟨D, Rd⟩twice. The overlay\nnetwork would have been more efficient if we had not constructed overlay links\n⟨B, E⟩, and ⟨D, E⟩, but instead ⟨A, E⟩and ⟨C, E⟩. Such a configuration would\nhave saved the double traversal across physical links ⟨Ra, Rb⟩and ⟨Rc, Rd⟩.\nFigure 4.31: The relation between links in an overlay and network-level routes.\nThe quality of an application-level multicast tree is generally measured\nby three different metrics: link stress, stretch, and tree cost. Link stress is\ndefined per link and counts how often a packet crosses the same link [Chu\net al., 2002]. A link stress greater than 1 comes from the fact that although at a\nlogical level a packet may be forwarded along two different connections, part\nof those connections may actually correspond to the same physical link, as we\nshowed in Figure 4.31.\nThe stretch or relative delay penalty (RDP) measures the ratio of the\ndelay between two nodes in the overlay, and the delay that those two nodes\nwould experience in the underlying network. For example, messages from\nDS 4.01\n \n",
      "content_length": 2192,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 251,
      "content": "4.4. MULTICAST COMMUNICATION\n235\nB to C follow the route B →Rb →Ra →Re →E →Re →Rc →Rd →\nD →Rd →Rc →C in the overlay network, having a total cost of 73 units.\nHowever, messages would have been routed in the underlying network along\nthe path B →Rb →Rd →Rc →C, with a total cost of 47 units, leading to a\nstretch of 1.55. Obviously, when constructing an overlay network, the goal is\nto minimize the aggregated stretch, or similarly, the average RDP measured\nover all node pairs.\nFinally, the tree cost is a global metric, generally related to minimizing\nthe aggregated link costs. For example, if the cost of a link is taken to be the\ndelay between its two end nodes, then optimizing the tree cost boils down\nto finding a minimal spanning tree in which the total time for disseminating\ninformation to all nodes is minimal.\nTo simplify matters somewhat, assume that a multicast group has an\nassociated and well-known node that keeps track of the nodes that have joined\nthe tree. When a new node issues a join request, it contacts this rendezvous\nnode to obtain a (potentially partial) list of members. The goal is to select\nthe best member that can operate as the new node’s parent in the tree. Who\nshould it select? There are many alternatives, and different proposals often\nfollow very different solutions.\nConsider, for example, a multicast group with only a single source. In\nthis case, the selection of the best node is obvious: it should be the source\n(because in that case, we can be assured that the stretch will be equal to 1).\nHowever, in doing so, we would introduce a star topology with the source\nin the middle. Although simple, it is not difficult to imagine the source may\neasily become overloaded. In other words, selection of a node will generally\nbe constrained in such a way that only those nodes may be chosen who\nhave k or fewer neighbors, with k being a design parameter. This constraint\nseverely complicates the tree-establishment algorithm, as a suitable solution\nmay require that part of the existing tree is reconfigured. Tan et al. [2003]\nprovide an extensive overview and evaluation of various solutions to this\nproblem.\nNote 4.14 (Advanced: Switch-trees)\nAs an illustration, let us take a closer look at one specific family, known as switch-\ntrees [Helder and Jamin, 2002]. The basic idea is simple. Assume we already have\na multicast tree with a single source as root. In this tree, a node P can switch\nparents by dropping the link to its current parent in favor of a link to another\nnode. The only constraints imposed on switching links is that the new parent can\nnever be a member of the subtree rooted at P (as this would partition the tree\nand create a loop), and that the new parent will not have too many immediate\nchildren. This last requirement is needed to limit the load of forwarding messages\nby any single node.\nThere are different criteria for deciding to switch parents. A simple one is to\n \nDS 4.01\n",
      "content_length": 2940,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 252,
      "content": "236\nCHAPTER 4. COMMUNICATION\noptimize the route to the source, effectively minimizing the delay when a message\nis to be multicasted. To this end, each node regularly receives information on\nother nodes (we will explain one specific way of doing this below). At that point,\nthe node can evaluate whether another node would be a better parent in terms of\ndelay along the route to the source, and if so, initiates a switch.\nAnother criterion could be whether the delay to the potential other parent\nis lower than to the current parent. If every node takes this as a criterion, then\nthe aggregated delays of the resulting tree should ideally be minimal. In other\nwords, this is an example of optimizing the cost of the tree, as we explained\nabove. However, more information would be needed to construct such a tree, but\nas it turns out, this simple scheme is a reasonable heuristic leading to a good\napproximation of a minimal spanning tree.\nAs an example, consider the case where a node P receives information on\nthe neighbors of its parent. Note that the neighbors consist of P’s grandparent,\nalong with the other siblings of P’s parent. Node P can then evaluate the delays\nto each of these nodes and subsequently choose the one with the lowest delay,\nsay Q, as its new parent. To that end, it sends a switch request to Q. To prevent\nloops from being formed due to concurrent switching requests, a node that has an\noutstanding switch request will simply refuse to process any incoming requests.\nIn effect, this leads to a situation where only completely independent switches\ncan be carried out simultaneously. Furthermore, P will provide Q with enough\ninformation to allow the latter to conclude that both nodes have the same parent,\nor that Q is the grandparent.\nAn important problem that we have not yet addressed is node failure. In the\ncase of switch-trees, a simple solution is proposed: whenever a node notices that\nits parent has failed, it attaches itself to the root. At that point, the optimization\nprotocol can proceed as usual and will eventually place the node at a good point\nin the multicast tree. Experiments described in [Helder and Jamin, 2002] show\nthat the resulting tree is indeed close to a minimal spanning one.\n4.4.2\nFlooding-based multicasting\nSo far, we have assumed that when a message is to be multicasted, it is to\nbe received by every node in the overlay network. Strictly speaking, this\ncorresponds to broadcasting. In general, multicasting refers to sending a\nmessage to a subset of all the nodes, that is, a specific group of nodes. A\nkey design issue when it comes to multicasting is to minimize the use of\nintermediate nodes for which the message is not intended. To make this clear,\nif the overlay is organized as a multi-level tree, yet only the leaf nodes are the\nones who should receive a multicast message, then clearly there may be quite\nsome nodes who need to store and subsequently forward a message that is\nnot meant for them.\nOne simple way to avoid such inefficiency, is to construct an overlay\nnetwork per multicast group. As a consequence, multicasting a message m to a\nDS 4.01\n \n",
      "content_length": 3126,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 253,
      "content": "4.4. MULTICAST COMMUNICATION\n237\ngroup G is the same as broadcasting m to G. The drawback of this solution is\nthat a node belonging to several groups, will, in principle, need to maintain a\nseparate list of its neighbors for each group of which it is a member.\nIf we assume that an overlay corresponds to a multicast group, and thus\nthat we need to broadcast a message, a naive way of doing so is to apply\nflooding. In this case, each node simply forwards a message m to each of its\nneighbors, except to the one from which it received m. Furthermore, if a node\nkeeps track of the messages it received and forwarded, it can simply ignore\nduplicates.\nTo understand the performance of flooding, we model an overlay network\nas a connected undirected graph G = (V, E) with nodes V and links E.\nLet v0 be the node that initiates flooding. In principle, every node other\nnode than v0 will send out the message to its neighbors once, except to the\nneighbor from which it had received the message. We will thus see a total of\nδ(v0) + ∑v∈V−v0(δ(v) −1) messages, with δ(v) the number of neighbors of\nthe node v. For any undirected graph, ∑v∈V δ(v) = 2 · |E|, with |E| denoting\nthe total number of edges. In other words, we will see 2|E| −|V| + 1 messages\nbeing sent, making flooding quite inefficient. Only if G is a tree, will flooding\nbe optimal, for in that case, |E| = |V| −1. In the worst case, when G is fully\nconnected, we have |E| = (|V|\n2 ) leading to an order of |V|2 messages.\nSuppose now that we have no information on the structure of the overlay\nnetwork and that the best we can assume is that it can be represented as\na random graph, which (to keep it simple) is a graph having a probability\npedge that two vertices are joined by an edge, also known as an Erdös-Rényi\ngraph [Erdös and Rényi, 1959]. Note that we are actually considering our\noverlay network to be an unstructured peer-to-peer network, and that we do\nnot have any information on how it is being constructed. With a probability\npedge that two nodes are joined, and a total of (|V|\n2 ) edges, it is not difficult to\nsee that we can expect our overlay to have |E| = 1\n2 · pedge · |V| · (|V| −1) edges.\nTo give an impression of what we are dealing with, Figure 4.32 shows the\nrelationship between the number of nodes and edges for different values of\npedge. As can be seen, the number of edges can easily become large, even for\nsmall values of pedge.\nTo reduce the number of messages, we can also use probabilistic flooding\nas introduced by Banaei-Kashani and Shahab [2003] and formally analyzed\nby Oikonomou and Stavrakakis [2007]. The idea is simple: when a node is\nflooding a message m and needs to forward m to a specific neighbor, it will\ndo so with a probability pflood. The effect can be dramatic: the total number\nof messages sent will drop linearly in pflood. However, there is also a risk:\nthe lower pflood, the higher the chance that not all nodes in the network will\nbe reached. This risk is caused by the simple fact that all neighbors of a\nspecific node Q may have decided not to forward m to Q. If Q has n neighbors,\nthen this can happen roughly with a probability of (1 −pflood)n. Clearly, the\n \nDS 4.01\n",
      "content_length": 3185,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 254,
      "content": "238\nCHAPTER 4. COMMUNICATION\nFigure 4.32: The size of a random overlay as function of the number of nodes.\nnumber of neighbors plays an important role in deciding whether to forward a\nmessage, and, indeed, we can replace the static probability of forwarding with\none that takes the degree of the neighbor into account. This has been further\ndeveloped and analyzed by Sereno and Gaeta [2011]. To give an idea of the\nefficiency of probabilistic broadcasting: in a random network of 10,000 nodes\nand pedge = 0.1, we need only set pflood = 0.01 to establish a more than 50-fold\nreduction in the number of messages sent in comparison to full flooding.\nWhen dealing with a structured overlay, that is, one having a more or less\ndeterministic topology, designing efficient flooding schemes is simpler. As an\nexample, consider an n-dimensional hypercube, shown in Figure 4.33 for the\ncase n = 4, as also discussed in Section 2.4.1.\nFigure 4.33: A simple peer-to-peer, four-dimensional hypercube.\nA simple and efficient broadcast scheme has been designed by Schlosser\net al. [2002] and relies on keeping track of neighbors per dimension. This is\nbest explained by considering that every node in an n-dimensional hypercube\nis represented by a bit string of length n. Each edge in the overlay is labeled\nwith its dimension. For the case n = 4, node 0000 will have as its neighbors\nthe set {0001, 0010, 0100, 1000}. The edge between 0000 and 0001 is labeled\nDS 4.01\n \n",
      "content_length": 1456,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 255,
      "content": "4.4. MULTICAST COMMUNICATION\n239\n“4” corresponding to changing the 4th bit when comparing 0000 to 0001 and\nvice versa. Likewise, the edge ⟨0000, 0100⟩is labeled “2,” and so forth. A node\ninitially broadcasts a message m to all of its neighbors, and tags m with the\nlabel of the edge over which it sends the message. In our example, if node\n1001 broadcasts a message, it will send the following:\n• (m,1) to 0001\n• (m,2) to 1101\n• (m,3) to 1011\n• (m,4) to 1000\nWhen a node receives a broadcast message, it will forward it only along edges\nthat have a higher dimension. In other words, in our example, node 1101 will\nforward m only to nodes 1111 (joined to 1101 by an edge labeled “3”) and\n1100 (joined by an edge with label “4”). Using this scheme, it can be shown\nthat every broadcast requires precisely N −1 messages, where N = 2n, that is\nthe number of nodes in a n-dimensional hypercube. This broadcasting scheme\nis therefore optimal in terms of the number of messages sent.\nNote 4.15 (Advanced: Ring-based flooding)\nFigure 4.34: A Chord ring in which node 9 broadcasts a message.\nA hypercube is a straightforward example of how we can effectively use\nknowledge of the structure of an overlay network to establish efficient flooding. In\nthe case of Chord, we can follow an approach proposed by Ghodsi [2010]. Recall\nthat in Chord each node is identified by a number p, and each resource (typically\n \nDS 4.01\n",
      "content_length": 1410,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 256,
      "content": "240\nCHAPTER 4. COMMUNICATION\na file), is assigned a key k from the same space as used for node identifiers. The\nsuccessor succ(k) of a key k is the node with the smallest identifier p ≥k. Consider\nthe small Chord ring shown in Figure 4.34 and assume that node 9 wants to flood\na message to all other nodes.\nIn our example, node 9 divides the identifier space into four segments (one\nfor each of its neighbors). Node 28 is requested to make sure that the message\nreaches all nodes with identifiers 28 ≤k < 9 (recall that we are applying modulo\narithmetic); node 18 takes care of nodes with identifiers 18 ≤k < 28; node 14 for\n14 ≤k < 18; and 11 for identifiers 11 ≤k < 14.\nNode 28 will subsequently divide the part of the identifier space it is requested\nto handle into two subsegments: one for its neighboring node 1 and another for 4.\nLikewise, node 18, responsible for segment [18, 28) will “split” that segment into\nonly one part: it has only one neighbor to delegate the flood to, and forwards the\nmessage to node 20, telling it that it should handle segment [20, 28).\nIn the last step, only node 20 has work to do. It forwards the message to node\n21, telling it to forward it to nodes known to it in the segment [21, 28). As there\nare no such nodes anymore, the broadcast completes.\nAs in the case of our hypercube example, we see that flooding is done with\nN −1 messages, with N being the number of nodes in the system.\n4.4.3\nGossip-based data dissemination\nAn important technique for disseminating information is to rely on epidemic\nbehavior, also referred to as gossiping. Observing how diseases spread\namong people, researchers have since long investigated whether simple tech-\nniques could be developed for spreading information in very large-scale\ndistributed systems. The main goal of these epidemic protocols is to rapidly\npropagate information among a large collection of nodes using only local infor-\nmation. In other words, there is no central component by which information\ndissemination is coordinated.\nTo explain the general principles of these algorithms, we assume that all\nupdates for a specific data item are initiated at a single node. In this way, we\nsimply avoid write-write conflicts. The following presentation is based on the\nclassical paper by Demers et al. [1987] on epidemic algorithms. An overview\nof epidemic information dissemination can be found in [Eugster et al., 2004].\nInformation dissemination models\nAs the name suggests, epidemic algorithms are based on the theory of epi-\ndemics, which studies the spreading of infectious diseases. In the case of\nlarge-scale distributed systems, instead of spreading diseases, they spread\ninformation. Research on epidemics for distributed systems also aims at an\nentirely different goal: whereas health organizations will do their best to\nprevent infectious diseases from spreading across large groups of people,\nDS 4.01\n \n",
      "content_length": 2902,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 257,
      "content": "4.4. MULTICAST COMMUNICATION\n241\ndesigners of epidemic algorithms for distributed systems will try to “infect”\nall nodes with new information as fast as possible.\nUsing the terminology from epidemics, a node that is part of a distributed\nsystem is called infected if it holds data that it is willing to spread to other\nnodes. A node that has not yet seen this data is called susceptible. Finally, an\nupdated node that is not willing or able to spread its data is said to have been\nremoved. Note that we assume we can distinguish old from new data, for\nexample because it has been timestamped or versioned. In this light, nodes\nare also said to spread updates.\nA popular propagation model is that of anti-entropy. In this model, a\nnode P picks another node Q at random, and subsequently exchanges updates\nwith Q. There are three approaches to exchanging updates:\n1. P only pulls in new updates from Q\n2. P only pushes its own updates to Q\n3. P and Q send updates to each other (i.e., a push-pull approach)\nWhen it comes to rapidly spreading updates, only pushing updates turns\nout to be a bad choice. Intuitively, this can be understood as follows. First,\nnote that in a pure push-based approach, updates can be propagated only by\ninfected nodes. However, if many nodes are infected, the probability of each\none selecting a susceptible node is relatively small. Consequently, chances are\nthat a particular node remains susceptible for a long period simply because\nan infected node does not select it.\nIn contrast, the pull-based approach works much better when many nodes\nare infected. In that case, spreading updates is essentially triggered by suscep-\ntible nodes. Chances are big that such a node will contact an infected one to\nsubsequently pull in the updates and become infected as well.\nIf only a single node is infected, updates will rapidly spread across all\nnodes using either form of anti-entropy, although push-pull remains the best\nstrategy [Jelasity et al., 2007]. Define a round as spanning a period in which\nevery node will have taken the initiative once to exchange updates with a\nrandomly chosen other node. It can then be shown that the number of rounds\nto propagate a single update to all nodes is of the order O(log(N)), where N\nis the number of nodes in the system. This indicates indeed that propagating\nupdates is fast, but above all scalable.\nNote 4.16 (Advanced: An analysis of anti-entropy)\nA simple and straightforward analysis will give some idea on how well anti-\nentropy works. Consider a system with N nodes. One of these nodes initiates the\nspreading of a message m to all other nodes. Let pi denote the probability that a\nnode P has not yet received m after the ith round. We distinguish the following\nthree cases:\n \nDS 4.01\n",
      "content_length": 2758,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 258,
      "content": "242\nCHAPTER 4. COMMUNICATION\n• With a pure pull-based approach, pi+1 = (pi)2: not only had P not yet been\nupdated in the previous round, also P contacts a node that had not yet\nreceived m.\n• With a pure push-based approach, pi+1 = pi · (1 −\n1\nN−1)N(1−pi): again, P\nshould not have been updated in the previous round, but also none of the\nupdated nodes should contact P. The probability that not a single node\ncontacts P is 1 −\n1\nN−1; we can expect that there are N(1 −pi) updated nodes\nin round i.\n• In a push-pull approach, we can simply combine the two: P should not\ncontact an updated node, and should not be contacted by one.\nFigure 4.35: (a) The number of nodes that have not been updated as a\nfunction of the number of dissemination rounds.\nFigure 4.35: (b) Zooming in the differences between the three anti-entropy\napproaches when almost all nodes have been updated.\nFigure 4.35(a) shows how quickly the probability of not yet being updated\ndrops as a function of the number of rounds in a network of 10,000 nodes. After\na slow start, the information is rapidly disseminated. In Figure 4.35(b) we have\nzoomed into what happens in the last number of rounds while also using a log\nscale for the y-axis. Indeed, assuming that nodes are up-and-running all the time,\nDS 4.01\n \n",
      "content_length": 1279,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 259,
      "content": "4.4. MULTICAST COMMUNICATION\n243\nit turns out that an anti-entropy push-pull strategy can be an extremely effective\ndissemination protocol.\nOne specific variant of epidemic protocols is called rumor spreading. It\nworks as follows. If node P has just been updated for a data item x, it contacts\nan arbitrary other node Q and tries to push the update to Q. However, it is\npossible that Q was already updated by another node. In that case, P may\nlose interest in spreading the update any further, say with probability pstop. In\nother words, it then becomes removed.\nRumor spreading is gossiping as we mostly experience it in real life. When\nBob has some hot news to spread around, he may phone his friend Alice,\ntelling her all about it. Alice, like Bob, will be really excited to spread the\nrumor to her friends as well. However, she will become disappointed when\nphoning a friend, say Chuck, only to hear that the news has already reached\nhim. Chances are that she will stop phoning other friends, for what good is it\nif they already know?\nRumor spreading turns out to be an excellent way of rapidly spreading\nnews. However, it cannot guarantee that all nodes will actually be updated [De-\nmers et al., 1987]. In fact, when there are many nodes that participate in the\nepidemics, the fraction s of nodes that will remain ignorant of an update, that\nis, remain susceptible, satisfies the equation:\ns = e−(1/pstop+1)(1−s)\nTo get an idea of what this means, take a look at Figure 4.36, which\nshows s as a function of pstop. Even for high values of pstop we see that the\nfraction of nodes that remains ignorant is relatively low, and always less than\napproximately 0.2. For pstop = 0.20 it can be shown that s = 0.0025. However,\nin those cases when pstop is relatively high, additional measures will need to\nbe taken to ensure that all nodes are updated.\nNote 4.17 (Advanced: Analysis of rumor spreading)\nTo formally analyze the situation for rumor spreading, we let s denote the fraction\nof nodes that have not yet been updated, i.e., the fraction of susceptible nodes.\nLikewise, let i denote the fraction of infected nodes: the ones that have been\nupdated and are still contacting other nodes to spread information. Finally, r\nis the fraction of nodes that have been updated, but have given up, i.e., they\nare passive and no longer play a role in disseminating information. Obviously,\ns + i + r = 1. Using theory from epidemics, it is not difficult to see the following:\n(1)\nds/dt\n=\n−s · i\n(2)\ndi/dt\n=\ns · i −pstop · (1 −s) · i\n⇒\ndi/ds\n=\n−(1 + pstop) +\npstop\ns\n⇒\ni(s)\n=\n−(1 + pstop) · s + pstop · ln(s) + C\n \nDS 4.01\n",
      "content_length": 2614,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 260,
      "content": "244\nCHAPTER 4. COMMUNICATION\nFigure 4.36: The relation between the fraction s of update-ignorant nodes and\nthe probability pstop that a node will stop gossiping once it contacts a node\nthat has already been updated.\nwhere we use the notation i(s) to express i as a function of s. When s = 1, no\nnodes have yet been infected, meaning that i(1) = 0. This allows us to derive that\nC = 1 + pstop, and thus\ni(s) = (1 + pstop) · (1 −s) + pstop · ln(s)\nWe are looking for the situation that there is no more rumor spreading, i.e., when\ni(s) = 0. Having a closed expression for i(s) then leads to\ns = e−(1/pstop+1)(1−s)\nOne of the main advantages of epidemic algorithms is their scalability\nsince the number of synchronizations between processes is relatively small\ncompared to other propagation methods. For wide-area systems, Lin and\nMarzullo [1999] have shown that it makes sense to take the actual network\ntopology into account to achieve better results. In that case, nodes that are\nconnected to only a few other nodes are contacted with a relatively high\nprobability. The underlying assumption is that such nodes form a bridge to\nother remote parts of the network; therefore, they should be contacted as soon\nas possible. This approach is referred to as directional gossiping and comes\nin different variants.\nThis problem touches upon an important assumption that most epidemic\nsolutions make, namely that a node can randomly select any other node to\ngossip with. This implies that, in principle, the complete set of nodes should\nbe known to each member. In a large system, this assumption can never hold,\nand special measures will need to be taken to mimic such properties. We\nreturn to this issue in Section 5.5.2 when we discuss a peer-sampling service.\nDS 4.01\n \n",
      "content_length": 1765,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 261,
      "content": "4.5. SUMMARY\n245\nRemoving data\nEpidemic algorithms are fantastic for spreading updates. However, they have\na rather strange side effect: spreading the deletion of a data item is hard. The\nessence of the problem lies in the fact that deletion of a data item destroys all\ninformation on that item. Consequently, when a data item is simply removed\nfrom a node, that node will eventually receive old copies of the data item and\ninterpret those as updates on something it did not have before.\nThe trick is to record the deletion of a data item as just another update, and\nkeep a record of that deletion. In this way, old copies will not be interpreted\nas something new, but merely treated as versions that have been updated by\na delete operation. The recording of a deletion is done by spreading death\ncertificates.\nOf course, the problem with death certificates is that they should eventually\nbe cleaned up, or otherwise each node will gradually build a huge local\ndatabase of historical information on deleted data items that is otherwise not\nused. Demers et al. [1987] propose to use what are called dormant death\ncertificates. Each death certificate is timestamped when it is created. If it can\nbe assumed that updates propagate to all nodes within a known finite time,\nthen death certificates can be removed after this maximum propagation time\nhas elapsed.\nHowever, to provide hard guarantees that deletions are indeed spread to\nall nodes, only a very few nodes maintain dormant death certificates that are\nnever thrown away. Assume node P has such a certificate for a data item x.\nIf by any chance an obsolete update for x reaches P, P will react by simply\nspreading the death certificate for x again.\n4.5\nSummary\nHaving powerful and flexible facilities for communication between processes\nis essential for any distributed system. In traditional network applications,\ncommunication is often based on the low-level message-passing primitives\noffered by the transport layer. An important issue in middleware systems\nis to offer a higher level of abstraction that will make it easier to express\ncommunication between processes than the support offered by the interface\nto the transport layer.\nOne of the most widely used abstractions is the Remote Procedure Call\n(RPC). The essence of an RPC is that a service is implemented through a\nprocedure, of which the body is executed at a server. The client is offered\nonly the signature of the procedure, that is, the procedure’s name along\nwith its parameters. When the client calls the procedure, the client-side\nimplementation, called a stub, takes care of wrapping the parameter values\ninto a message and sending that to the server. The latter calls the actual\nprocedure and returns the results, again in a message. The client’s stub\n \nDS 4.01\n",
      "content_length": 2789,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 262,
      "content": "246\nCHAPTER 4. COMMUNICATION\nextracts the result values from the return message and passes it back to the\ncalling client application.\nRPCs offer synchronous communication facilities, by which a client is\nblocked until the server has sent a reply.\nAlthough variations of either\nmechanism exist by which this strict synchronous model is relaxed, it turns\nout that general-purpose, high-level message-oriented models are often more\nconvenient.\nIn message-oriented models, the issues are whether communication is\npersistent, and whether communication is synchronous.\nThe essence of\npersistent communication is that a message that is submitted for transmission,\nis stored by the communication system as long as it takes to deliver it. In\nother words, neither the sender nor the receiver needs to be up and running\nfor message transmission to take place.\nIn transient communication, no\nstorage facilities are offered so that the receiver must be prepared to accept\nthe message when it is sent.\nIn asynchronous communication, the sender is allowed to continue imme-\ndiately after the message has been submitted for transmission, possibly before\nit has even been sent. In synchronous communication, the sender is blocked\nat least until a message has been received. Alternatively, the sender may be\nblocked until message delivery has taken place or even until the receiver has\nresponded, as with RPCs.\nMessage-oriented middleware models generally offer persistent asyn-\nchronous communication, and are used where RPCs are not appropriate.\nThey are often used to assist the integration of (widely dispersed) collections\nof databases into large-scale information systems.\nFinally, an important class of communication protocols in distributed\nsystems is multicasting. The basic idea is to disseminate information from\none sender to multiple receivers. We have discussed two different approaches.\nFirst, multicasting can be achieved by setting up a tree from the sender to\nthe receivers. Considering that it is now well understood how nodes can self-\norganize into peer-to-peer system, solutions have also appeared to dynamically\nset up trees in a decentralized fashion. Second, flooding messages across\nthe network is extremely robust, yet requires special attention if we want to\navoid severe waste of resources as nodes may see messages multiple times.\nProbabilistic flooding, by which a node forwards a message with a certain\nprobability, often proves to combine simplicity and efficiency, while being\nhighly effective.\nAnother important class of dissemination solutions deploys epidemic\nprotocols. These protocols have proven to be simple and extremely robust.\nDS 4.01\n \n",
      "content_length": 2663,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 263,
      "content": "05\nCOORDINATION\n",
      "content_length": 16,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 264,
      "content": "248\nCHAPTER 5. COORDINATION\nIn the previous chapters, we have looked at processes and communication\nbetween processes. While communication is important, it is not the entire\nstory. Closely related is how processes cooperate and synchronize with one\nanother. Cooperation is partly supported by naming, which allows processes\nto at least share resources, or entities in general.\nIn this chapter, we mainly concentrate on how processes can synchronize\nand coordinate their actions.\nFor example, it is important that multiple\nprocesses do not simultaneously access a shared resource, such as a file, but\ninstead cooperate in granting each other temporary exclusive access. Another\nexample is that multiple processes may sometimes need to agree on the\nordering of events, such as whether message m1 from process P was sent\nbefore or after message m2 from process Q.\nSynchronization and coordination are two closely related phenomena. In\nprocess synchronization we make sure that one process waits for another to\ncomplete its operation. When dealing with data synchronization, the problem\nis to ensure that two sets of data are the same. When it comes to coordination,\nthe goal is to manage the interactions and dependencies between activities\nin a distributed system [Malone and Crowston, 1994]. From this perspective,\none could state that coordination encapsulates synchronization.\nAs it turns out, coordination in distributed systems is often much more\ndifficult compared to that in uniprocessor or multiprocessor systems. The\nproblems and solutions that are discussed in this chapter are, by their nature,\nrather general, and occur in many situations in distributed systems.\nWe start with a discussion of the issue of synchronization based on actual\ntime, followed by synchronization in which only relative ordering matters\nrather than ordering in absolute time.\nOften, it is important that a group of processes can appoint one process\nas a coordinator, which can be done through election algorithms. We discuss\nvarious election algorithms in a separate section. Before that, we look into\nseveral algorithms for coordinating mutual exclusion to a shared resource. As\na special class of coordination problems, we also dive into location systems,\nby which we place a process in a multidimensional plane. Such placements\nare useful when dealing with very large distributed systems.\nWe also consider three different gossip-based coordination problems: ag-\ngregation, peer sampling, and overlay construction.\nFinally, we already came across publish-subscribe systems, but have not\nyet discussed in any detail how we actually match subscriptions to publica-\ntions. There are many ways to do this, and we look at centralized as well as\ndecentralized implementations.\nDistributed algorithms come in all sorts and flavors and have been devel-\noped for different types of distributed systems. Many examples (and further\nreferences) can be found in Andrews [2000], Cachin et al. [2011], and Fokkink\n[2018]. More formal approaches to a wealth of algorithms can be found in\nDS 4.01\n \n",
      "content_length": 3069,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 265,
      "content": "5.1. CLOCK SYNCHRONIZATION\n249\ntextbooks from Attiya and Welch [2004], Lynch [1996], Santoro [2007], and Tel\n[2000].\n5.1\nClock synchronization\nIn a centralized system, time is unambiguous. When a process wants to know\nthe time, it simply makes a call to the operating system. If process A asks for\nthe time, and then a little later process B asks for the time, the value that B\ngets will be higher than (or possibly equal to) the value A got. It will certainly\nnot be lower. In a distributed system, achieving agreement on time is not\ntrivial.\nJust think, for a moment, about the implications of the lack of global time\non the Unix make program, as a simple example. Normally, in Unix, large\nprograms are split up into multiple source files, so that a change to one source\nfile requires only one file to be recompiled, not all the files. If a program\nconsists of 100 files, not having to recompile everything because one file has\nbeen changed greatly increases the speed at which programmers can work.\nThe way make normally works is simple. When the programmer has\nfinished changing all the source files, she runs make, which examines the times\nat which all the source and object files were last modified. If the source file\ninput.c has time 2151 and the corresponding object file input.o has time\n2150, make knows that input.c has been changed since input.o was created,\nand thus input.c must be recompiled. On the other hand, if output.c has\ntime 2144 and output.o has time 2145, no compilation is needed. Thus make\ngoes through all the source files to find out which ones need to be recompiled\nand calls the compiler to recompile them.\nNow imagine what could happen in a distributed system in which there\nwas no global agreement on time. Suppose that output.o has time 2144 as\nabove, and shortly thereafter output.c is modified but is assigned time 2143\nbecause the clock on its machine is slightly behind, as shown in Figure 5.1.\nMake will not call the compiler. The resulting executable binary program will\nthen contain a mixture of object files from the old sources and the new sources.\nIt may crash, and the programmer will go crazy trying to understand what is\nwrong with the code.\nThere are many more examples where an accurate account of time is\nneeded. The example above can easily be reformulated to file timestamps in\ngeneral. In addition, think of application domains such as financial brokerage,\nsecurity auditing, and collaborative sensing, and it will become clear that\naccurate timing is important. From a different perspective, Najafi et al. [2021]\nargue that accurate timing is essential for most systems research, if only to\nensure that performance measurements can be properly compared. Since\ntime is so basic to the way people think and the effect of not having all the\nclocks synchronized can be so dramatic, it is fitting that we begin our study of\n \nDS 4.01\n",
      "content_length": 2884,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 266,
      "content": "250\nCHAPTER 5. COORDINATION\nFigure 5.1: When each machine has its own clock, an event that occurred after\nanother event may nevertheless be assigned an earlier time.\nsynchronization with the simple question: Would it be possible to synchronize\nall the clocks in a distributed system? The answer is surprisingly complicated.\n5.1.1\nPhysical clocks\nNearly all computers often have several circuits for keeping track of time.\nDespite the widespread use of the word “clock” to refer to these devices,\nthey are not actually clocks in the usual sense. Timer is perhaps a better\nword. A computer timer is usually a precisely machined quartz crystal. When\nkept under tension, quartz crystals oscillate at a well-defined frequency that\ndepends on the kind of crystal, how it is cut, and the amount of tension.\nAssociated with each crystal are two registers, a counter and a holding\nregister. Each oscillation of the crystal decrements the counter by one. When\nthe counter gets to zero, an interrupt is generated and the counter is reloaded\nfrom the holding register. In this way, it is possible to program a timer to\ngenerate an interrupt 60 times a second, or at any other desired frequency.\nEach interrupt is called one clock tick.\nWhen the system is booted and initialized for the very first time, the user is\nasked for the current time zone, or even time, to convert time to the number of\nticks after some known starting date and stored in memory. Most computers\nhave a special battery-backed up CMOS RAM so that the date and time need\nnot be entered on subsequent boots. At every clock tick, the interrupt service\nprocedure adds one to the time stored in memory. In this way, the (software)\nclock is kept up to date.\nWith a single computer and a single clock, it does not matter much if this\nclock is off by a small amount. Since all processes on the machine use the\nsame clock, they will still be internally consistent. For example, if the file\ninput.c has time 2151 and file input.o has time 2150, make will recompile the\nsource file, even if the clock is off by 2 and the true times are 2153 and 2152,\nrespectively. All that really matters are the relative times.\nAs soon as multiple CPUs are introduced, each with its own clock, the sit-\nuation changes radically. Although the frequency at which a crystal oscillator\nruns is usually fairly stable, it is impossible to guarantee that the crystals in\nDS 4.01\n \n",
      "content_length": 2408,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 267,
      "content": "5.1. CLOCK SYNCHRONIZATION\n251\ndifferent computers all run at the same frequency. In practice, when a system\nhas n computers, all n crystals will run at slightly different rates, causing\nthe (software) clocks gradually to get out of sync and give different values\nwhen read out. This difference in time values is called clock skew. As a\nconsequence of this clock skew, programs that expect the time associated\nwith a file, object, process, or message to be correct and independent of the\nmachine on which it was generated (i.e., which clock it used) can fail, as we\nsaw in the make example above.\nIn some systems (e.g., real-time systems), the actual clock time is important.\nUnder these circumstances, external physical clocks are needed. For reasons of\nefficiency and redundancy, multiple physical clocks are generally considered\ndesirable, which yields two problems: (1) how do we synchronize them with\nreal-world clocks, and (2) how do we synchronize the clocks with each other?\nNote 5.1 (More information: Determining real time)\nBefore answering these questions, let us digress slightly to see how time is\nactually measured. It is not nearly as easy as one might think, especially when\nhigh accuracy is required. Since the invention of mechanical clocks in the 17th\ncentury, time has been measured astronomically. Every day, the sun appears to\nrise on the eastern horizon, then climbs to a maximum height in the sky, and\nfinally sinks in the west. The event of the sun’s reaching its highest apparent\npoint in the sky is called the transit of the sun. This event occurs at about noon\neach day. The interval between two consecutive transits of the sun is called the\nsolar day. Since there are 24 hours in a day, each containing 3600 seconds, the\nsolar second is defined as exactly 1/86400th of a solar day. The geometry of the\nmean solar day calculation is shown in Figure 5.2.\nFigure 5.2: Computation of the mean solar day.\n \nDS 4.01\n",
      "content_length": 1939,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 268,
      "content": "252\nCHAPTER 5. COORDINATION\nIn the 1940s, it was established that the period of the earth’s rotation is not\nconstant. The earth is slowing down due to tidal friction and atmospheric drag.\nBased on studies of growth patterns in ancient coral, geologists now believe that\n300 million years ago there were about 400 days per year. The length of the year\n(the time for one trip around the sun) is not thought to have changed; the day has\nsimply become longer. In addition to this long-term trend, short-term variations in\nthe length of the day also occur, probably caused by turbulence deep in the earth’s\ncore of molten iron. These revelations lead astronomers to compute the length\nof the day by measuring a large number of days and taking the average before\ndividing by 86,400. The resulting quantity was called the mean solar second.\nWith the invention of the atomic clock in 1948, it became possible to measure\ntime much more accurately, and independent of the wiggling and wobbling of the\nearth, by counting transitions of the cesium 133 atom. The physicists took over\nthe job of timekeeping from the astronomers and defined the second to be the\ntime it takes the cesium 133 atom to make exactly 9,192,631,770 transitions. The\nchoice of 9,192,631,770 was made to make the atomic second equal to the mean\nsolar second in the year of its introduction. Currently, several laboratories around\nthe world have cesium 133 clocks. Periodically, each laboratory tells the Bureau\nInternational de l’Heure (BIH) in Paris how many times its clock has ticked. The\nBIH averages these to produce International Atomic Time, which is abbreviated\nto TAI. Thus TAI is just the mean number of ticks of the cesium 133 clocks since\nmidnight on Jan. 1, 1958 (the beginning of time) divided by 9,192,631,770.\nAlthough TAI is highly stable and available to anyone who wants to go to the\ntrouble of buying a cesium clock, there is a serious problem with it; 86,400 TAI\nseconds is now about 3 msec less than a mean solar day (because the mean solar\nday is getting longer all the time). Using TAI for keeping time would mean that\nover the course of the years, noon would get earlier and earlier, until it would\neventually occur in the wee hours of the morning. People might notice this and\nwe could have the same kind of situation as occurred in 1582 when Pope Gregory\nXIII decreed that 10 days be omitted from the calendar. This event caused riots in\nthe streets because landlords demanded a full month’s rent and bankers a full\nmonth’s interest, while employers refused to pay workers for the 10 days they did\nnot work, to mention only a few of the conflicts. The Protestant countries, as a\nmatter of principle, refused to have anything to do with papal decrees and did\nnot accept the Gregorian calendar for 170 years.\nBIH solves the problem by introducing leap seconds whenever the discrepancy\nbetween TAI and solar time grows to 800 msec. The use of leap seconds is\nillustrated in Figure 5.3. This correction gives rise to a time system based on\nconstant TAI seconds but which stays in phase with the apparent motion of the\nsun. This time system is known as Coordinated Universal Time abbreviated to\nUTC.\nMost electric power companies synchronize the timing of their 60-Hz or 50-Hz\nclocks to UTC, so when BIH announces a leap second, the power companies raise\ntheir frequency to 61 Hz or 51 Hz for 60 or 50 sec, to advance all the clocks in their\ndistribution area. Since 1 sec is a noticeable interval for a computer, an operating\nsystem that needs to keep accurate time over a period of years must have special\nDS 4.01\n \n",
      "content_length": 3601,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 269,
      "content": "5.1. CLOCK SYNCHRONIZATION\n253\nsoftware to account for leap seconds as they are announced (unless they use the\npower line for time, which is usually too crude). The total number of leap seconds\nintroduced into UTC so far is about 30.\nFigure 5.3: TAI seconds are of constant length, unlike solar seconds. Leap\nseconds are introduced when necessary to keep in phase with the sun.\nThe basis for keeping global time is a called Coordinated Universal Time,\nbut is abbreviated as UTC. UTC is the basis of all modern civil timekeeping\nand is a worldwide standard. To provide UTC to people who need precise\ntime, some 40 shortwave radio stations around the world broadcast a short\npulse at the start of each UTC second. The accuracy of these stations is about\n± 1 msec, but due to random atmospheric fluctuations that can affect the\nlength of the signal path, in practice the accuracy is no better than ± 10\nmilliseconds.\nSeveral earth satellites also offer a UTC service. The Geostationary Oper-\national Environment Satellite can provide UTC accurately to 0.5 msec, and\nsome other satellites do even better. By combining receptions from several\nsatellites, ground timeservers can be built, offering an accuracy of 50 nanosec-\nonds. UTC receivers are commercially available, and many computers are\nequipped with one.\n5.1.2\nClock synchronization algorithms\nIf one machine has a UTC receiver, the goal becomes keeping all the other\nmachines synchronized to it. If no machines have UTC receivers, each machine\nkeeps track of its own time, and the goal is to keep all the machines together\nas well as possible. Many algorithms have been proposed for doing this\nsynchronization. Surveys are provided by Ramanathan et al. [1990], Horauer\n[2004], Shin et al. [2011], and Levesque and Tipper [2016].\nAll clocks are based on some harmonic oscillator: an object that resonates\nat a certain frequency and from which we can subsequently derive time.\nAtomic clocks are based on the transitions of the cesium 133 atom, which is\nnot only very high, but also very constant. Hardware clocks in most computers\nuse a crystal oscillator based on quartz, which is also capable of producing\n \nDS 4.01\n",
      "content_length": 2171,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 270,
      "content": "254\nCHAPTER 5. COORDINATION\na very high, stable frequency, although not as stable as that of atomic clocks.\nA software clock in a computer is derived from that computer’s hardware\nclock. In particular, the hardware clock is assumed to cause an interrupt f\ntimes per second. When this timer goes off, the interrupt handler adds 1 to a\ncounter that keeps track of the number of ticks (interrupts) since some agreed-\nupon time in the past. This counter acts as a software clock C, resonating at\nfrequency F.\nWhen the UTC time is t, denote by Cp(t) the value of the software clock\non machine p. The goal of clock synchronization algorithms is to keep the\ndeviation between the respective clocks of any two machines in a distributed\nsystem, within a specified bound, known as the precision π:\n∀t, ∀p, q : |Cp(t) −Cq(t)| ≤π\nNote that precision refers to the deviation of clocks only between machines\nthat are part of a distributed system. When considering an external reference\npoint, like UTC, we speak of accuracy, aiming to keep it bound to a value α:\n∀t, ∀p : |Cp(t) −t| ≤α\nThe whole idea of clock synchronization is that we keep clocks precise, referred\nto as internal synchronization or accurate, known as external synchronization.\nA set of clocks that are accurate within bound α, will be precise within bound\nπ = 2α. However, being precise does not allow us to conclude anything about\nthe accuracy of clocks.\nIn a perfect world, we would have Cp(t) = t for all p and all t, and\nthus α = π = 0. Unfortunately, hardware clocks, and thus also software\nclocks, are subject to clock drift: because their frequency is not perfect and\naffected by external sources such as temperature, clocks on different machines\nwill gradually start showing different values for time. This is known as\nthe clock drift rate: the difference per unit of time from a perfect reference\nclock. A typical quartz-based hardware clock has a clock drift rate of some\n10−6 seconds per second, or approximately 31.5 seconds per year. Computer\nhardware clocks exist that have much lower drift rates.\nThe specifications of a hardware clock include its maximum clock drift\nrate ρ. If F(t) denotes the actual oscillator frequency of the hardware clock at\ntime t and F its ideal (constant) frequency, then a hardware clock is living up\nto its specifications if\n∀t : (1 −ρ) ≤F(t)\nF\n≤(1 + ρ)\nBy using hardware interrupts we are directly coupling a software clock to the\nhardware clock, and thus also its clock drift rate. In particular, we have that\nCp(t) = 1\nF\nZ t\n0 F(t)dt, and thus: dCp(t)\ndt\n= F(t)\nF\nDS 4.01\n \n",
      "content_length": 2576,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 271,
      "content": "5.1. CLOCK SYNCHRONIZATION\n255\nwhich brings us to our goal, namely keeping the software clock drift rate also\nbounded to ρ:\n∀t : 1 −ρ ≤dCp(t)\ndt\n≤1 + ρ\nSlow, perfect, and fast clocks are shown in Figure 5.4.\nFigure 5.4: The relation between clock time and UTC when clocks tick at\ndifferent rates.\nIf two clocks are drifting from UTC in the opposite direction, at a time\n∆t after they were synchronized, they may be as much as 2ρ · ∆t apart. If\nthe system designers want to guarantee a precision π, that is, that no two\nclocks ever differ by more than π seconds, clocks must be resynchronized\n(in software) at least every π/(2ρ) seconds. The various algorithms differ in\nprecisely how this resynchronization is done.\nNetwork Time Protocol\nA common approach in many protocols, and originally proposed by Cristian\n[1989], is to let clients contact a timeserver. The latter can accurately provide\nthe current time, for example because it is equipped with a UTC receiver\nor an accurate clock. The problem, of course, is that when contacting the\nserver, message delays will have outdated the reported time. The trick is to\nfind a good estimation for these delays. Consider the situation sketched in\nFigure 5.5.\nIn this case, A will send a request to B, timestamped with value T1. B,\nin turn, will record the time of receipt T2 (taken from its own local clock),\nand returns a response timestamped with value T3, and piggybacking the\npreviously recorded value T2. Finally, A records the time of the response’s\narrival, T4. Let us assume that the propagation delays from A to B is roughly\nthe same as B to A, meaning that δTreq = T2 −T1 ≈T4 −T3 = δTres. In that\n \nDS 4.01\n",
      "content_length": 1663,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 272,
      "content": "256\nCHAPTER 5. COORDINATION\nFigure 5.5: Getting the current time from a time server.\ncase, A can estimate its offset relative to B as\nθ = T3 + (T2 −T1) + (T4 −T3)\n2\n−T4 = (T2 −T1) + (T3 −T4)\n2\nOf course, time is not allowed to run backward. If A’s clock is fast, θ < 0,\nmeaning that A should, in principle, set its clock backward. This is not allowed\nas it could cause serious problems, such as an object file compiled just after\nthe clock change having a time earlier than the source which was modified\njust before the clock change.\nSuch a change must be introduced gradually. One way is as follows.\nSuppose that the timer is set to generate 100 interrupts per second. Normally,\neach interrupt would add 10 msec to the time. When slowing down, the\ninterrupt routine adds only 9 msec each time until the correction has been\nmade. Similarly, the clock can be advanced gradually by adding 11 msec at\neach interrupt instead of jumping it forward all at once.\nIn the case of the Network Time Protocol (NTP), this protocol is set up\npairwise between servers. In other words, B will also probe A for its current\ntime. The offset θ is computed as given above, along with the estimation δ for\nthe delay:\nδ = (T4 −T1) −(T3 −T2)\n2\nEight pairs of (θ, δ) values are buffered, finally taking the minimal value\nfound for δ as the best estimation for the delay between the two servers, and\nsubsequently the associated value θ as the most reliable estimation of the\noffset.\nApplying NTP symmetrically should, in principle, also let B adjust its\nclock to that of A. However, if B’s clock is known to be more accurate, then\nsuch an adjustment would be foolish. To solve this problem, NTP divides\nservers into strata. A server with a reference clock such as a UTC receiver or\nan atomic clock, is known to be a stratum-1 server (the clock itself is said to\noperate at stratum 0). When A contacts B, it will adjust only its time if its own\nstratum level is higher than that of B. Moreover, after the synchronization, A’s\nDS 4.01\n \n",
      "content_length": 2010,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 273,
      "content": "5.1. CLOCK SYNCHRONIZATION\n257\nstratum level will become one higher than that of B. In other words, if B is a\nstratum-k server, then A will become a stratum-(k + 1) server if its original\nstratum level was already larger than k. Due to the symmetry of NTP, if A’s\nstratum level was lower than that of B, B will adjust itself to A.\nThere are many important features about NTP, of which many relate to\nidentifying and masking errors, but also security attacks (see, e.g., Malhotra\net al. [2016]). Many security issues, such as also described by Levesque and\nTipper [2016], can be dealt with by establishing a secure channel between a\ntime server and its client. NTP was originally described in [Mills, 1992] and is\nknown to achieve (worldwide) accuracy in the range of 1–50 msec. A detailed\ndescription of NTP can be found in [Mills, 2011].\nClock synchronization in wireless networks\nAn important advantage of more traditional distributed systems is that we can\neasily and efficiently deploy timeservers. Moreover, most machines can contact\neach other, allowing for a relatively simple dissemination of information.\nThese assumptions are no longer valid in many wireless networks, notably\nsensor networks. Nodes are resource constrained, and multihop routing\nis expensive. In addition, it is often important to optimize algorithms for\nenergy consumption. These and other observations have led to the design\nof very different clock synchronization algorithms for wireless networks. In\nthe following, we consider one specific solution. Sivrikaya and Yener [2004]\nprovide a brief overview of other solutions. An extensive survey can be found\nin [Sundararaman et al., 2005].\nReference broadcast synchronization (RBS) is a clock synchronization\nprotocol that is quite different from other proposals [Elson et al., 2002]. First,\nthe protocol does not assume that there is a single node with an accurate\naccount of the actual time available. Instead of aiming to provide all nodes\nUTC time, it aims at merely internally synchronizing the clocks. Second,\nthe solutions we have discussed so far are designed to bring the sender and\nreceiver into sync, essentially following a two-way protocol. RBS deviates\nfrom this pattern by letting only the receivers synchronize, keeping the sender\nout of the loop.\nIn RBS, a sender broadcasts a reference message that allows its receivers\nto adjust their clocks. A key observation is that in a sensor network the\ntime to propagate a signal to other nodes is roughly constant, provided no\nmulti-hop routing is assumed. Propagation time in this case is measured from\nthe moment that a message leaves the network interface of the sender. As a\nconsequence, two important sources of variation in message transfer no longer\nplay a role in estimating delays: the time spent to construct a message, and\nthe time spent to access the network. This principle is shown in Figure 5.6.\nNote that in protocols such as NTP, a timestamp is added to the message\nbefore it is passed on to the network interface. Furthermore, as wireless\n \nDS 4.01\n",
      "content_length": 3056,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 274,
      "content": "258\nCHAPTER 5. COORDINATION\nFigure 5.6: The usual critical path and the one used in RBS in determining\nnetwork delays.\nnetworks are based on a contention protocol, there is generally no saying how\nlong it will take before a message can actually be transmitted. These factors\nof nondeterminism are eliminated in RBS. What remains is the delivery time\nat the receiver, but this time varies considerably less than the network-access\ntime.\nThe idea underlying RBS is simple: when a node broadcasts a reference\nmessage m, each node p simply records the time Tp,m that it received m. Note\nthat Tp,m is read from p’s local clock. Ignoring clock skew, two nodes p and\nq can exchange each other’s delivery times to estimate their mutual, relative\noffset:\nOffset[p, q] = ∑M\nk=1(Tp,k −Tq,k)\nM\nwhere M is the total number of reference messages sent. This information is\nimportant: node p will know the value of q’s clock relative to its own value.\nMoreover, if it simply stores these offsets, there is no need to adjust its own\nclock, which saves energy.\nUnfortunately, clocks can drift apart. The effect is that simply computing\nthe average offset as done above will not work: the last values sent are\nsimply less accurate than the first ones.\nMoreover, as time goes by, the\noffset will presumably increase. Elson et al. [2002] use a simple algorithm to\ncompensate for this: instead of computing an average, they apply standard\nlinear regression to compute the offset as a function:\nOffset[p, q](t) = αt + β\nThe constants α and β are computed from the pairs (Tp,k, Tq,k). This new form\nallows a much more accurate computation of q’s current clock value by node\np, and vice versa.\nDS 4.01\n \n",
      "content_length": 1679,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 275,
      "content": "5.1. CLOCK SYNCHRONIZATION\n259\nNote 5.2 (More information: How important is an accurate account of time?)\nSo why is time such a big deal for distributed systems? As we shall discuss in\nthe remainder of this chapter, reaching consensus on a global ordering of events\nis what we really want, and this can be achieved without any notion of global\nabsolute time. However, as will become clear, alternative methods for distributed\ncoordination do not come easy.\nLife would be much simpler if processes in a distributed system could time-\nstamp their events with infinite precision. Although infinite precision is asking\ntoo much, we can come practically close. Researchers at Google were confronted\nwith the fact that their customers would really like to make use of a globally\ndistributed database that supported transactions. Such a database would need\nto serve massive numbers of clients, rendering the use of, for example, a central\ntransaction processing monitor as we discussed in Section 1.3.2, infeasible. Instead,\nfor their Spanner system, Google decided to implement a true-time service, called\nTrueTime [Corbett et al., 2013]. This service provides three operations:\nOperation\nResult\nTT.now()\nA time interval [Tlwb, Tupb] with Tlwb < Tupb\nTT.after(t)\nTrue if timestamp t has definitely passed\nTT.before(t)\nTrue if timestamp t has definitely not arrived\nThe most important aspect is that Tlwb and Tupb are guaranteed bounds. Of\ncourse, if ϵ = Tupb −Tlwb is large, say 1 hour, then implementing the service\nis relatively easy. Impressively enough, ϵ = 6ms. To achieve this accuracy, the\nTrueTime service makes use of time-master machines of which there are several\nper data center. Time-slave daemons run on every machine in a data center\nand query multiple time masters, including ones from other data centers, very\nsimilar to what we described for NTP. Many time masters are equipped with\naccurate GPS receivers, while many others are independently equipped with\natomic clocks. The result is a collection of time sources with a high degree of\nmutual independence (which is important for reasons of fault tolerance). Using\na version of an algorithm developed by Marzullo and Owicki [1983], outliers\nare kept out of the computations. Meanwhile, the performance of TrueTime is\ncontinuously monitored and “bad” time machines are (manually) removed to give\nat least very high guarantees for the accuracy of the TrueTime service.\nWith a guaranteed accuracy of 6 milliseconds, building a transactional system\nbecomes much easier: transactions can actually be timestamped, even by different\nservers, with the restriction that timestamping may need to be delayed for ϵ\ntime units. More precisely, to know for sure that a transaction has committed,\nreading the resulting data may impose a wait for ϵ units. This is achieved by\npessimistically assigning a timestamp to a transaction that writes data to the\nglobal database and making sure that clients never see any changes before the\nassigned timestamp (which is relatively easy to implement).\nThere are many details to this approach, which can be found in [Corbett\net al., 2013]. As we are still dealing with a time interval, taking more traditional\n \nDS 4.01\n",
      "content_length": 3207,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 276,
      "content": "260\nCHAPTER 5. COORDINATION\nordering mechanisms into account it is possible to improve results, as explained\nby Demirbas and Kulkarni [2013].\n5.2\nLogical clocks\nClock synchronization is naturally related to time, although it may not be\nnecessary to have an accurate account of the real time: it may be sufficient that\nevery node in a distributed system agrees on a current time. We can go one\nstep further. For running make it is adequate that two nodes agree that input.o\nis outdated by a new version of input.c, for example. In this case, keeping\ntrack of each other’s events (such as a producing a new version of input.c) is\nwhat matters. For these algorithms, it is conventional to speak of the clocks as\nlogical clocks.\nIn a seminal paper, Lamport [1978] showed that although clock synchro-\nnization is possible, it need not be absolute. If two processes do not interact,\nit is not necessary that their clocks be synchronized because the lack of syn-\nchronization would not be observable and thus could not cause problems.\nFurthermore, he pointed out that what usually matters is not that all processes\nagree on exactly what time it is, but rather that they agree on the order in which\nevents occur. In the make example, what counts is whether input.c is older or\nnewer than input.o, not their respective absolute creation times.\n5.2.1\nLamport’s logical clocks\nTo synchronize logical clocks, Lamport defined a relation called happens-\nbefore. The expression a →b is read “event a happens before event b” and\nmeans that all processes agree that first event a occurs, then afterward, event b\noccurs. The happens-before relation can be observed directly in two situations:\n1. If a and b are events in the same process, and a occurs before b, then\na →b is true.\n2. If a is the event of a message being sent by one process, and b is the\nevent of the message being received by another process, then a →b is\nalso true. A message cannot be received before it is sent, or even at the\nsame time it is sent, since it takes a finite, nonzero amount of time to\narrive.\nHappens-before is a transitive relation, so if a →b and b →c, then a →c.\nIf two events, x and y, happen in different processes that do not exchange\nmessages (not even indirectly via third parties), then x →y is not true, but\nneither is y →x. These events are said to be concurrent, which simply means\nDS 4.01\n \n",
      "content_length": 2372,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 277,
      "content": "5.2. LOGICAL CLOCKS\n261\nthat nothing can be said (or need be said) about when the events happened or\nwhich event happened first.\nWhat we need is a way of measuring a notion of time such that for every\nevent, a, we can assign it a time value C(a) on which all processes agree.\nThese time values must have the property that if a →b, then C(a) < C(b).\nTo rephrase the conditions we stated earlier, if a and b are two events within\nthe same process and a occurs before b, then C(a) < C(b). Similarly, if a\nis the sending of a message by one process and b is the reception of that\nmessage by another process, then C(a) and C(b) must be assigned in such a\nway that everyone agrees on the values of C(a) and C(b) with C(a) < C(b).\nIn addition, the clock time, C, must always go forward (increasing), never\nbackward (decreasing). Corrections to time can be made by adding a positive\nvalue, never by subtracting one.\nNow let us look at the algorithm Lamport proposed for assigning times\nto events. Consider the three processes depicted in Figure 5.7. The processes\nrun on different machines, each with its own clock. For the sake of argument,\nwe assume that a clock is implemented as a software counter: the counter\nis incremented by a specific value every T time units. However, the value\nby which a clock is incremented differs per process. The clock in process\nP1 is incremented by 6 units, 8 units in process P2, and 10 units in process\nP3, respectively. (Below, we explain that Lamport clocks are, in fact, event\ncounters, which explains why their value may differ between processes.)\n(a)\n(b)\nFigure 5.7: (a) Three processes, each with its own (logical) clock. The clocks\nrun at different rates. (b) Lamport’s algorithm corrects their values.\nAt time 6, process P1 sends message m1 to process P2. How long this\nmessage takes to arrive depends on whose clock you believe. In any event,\nthe clock in process P2 reads 16 when it arrives. If the message carries the\nstarting time, 6, in it, process P2 will conclude that it took 10 ticks to make the\njourney. This value is certainly possible. According to this reasoning, message\nm2 from P2 to P3 takes 16 ticks, again a plausible value.\n \nDS 4.01\n",
      "content_length": 2190,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 278,
      "content": "262\nCHAPTER 5. COORDINATION\nNow consider message m3. It leaves process P3 at 60 and arrives at P2 at\n56. Similarly, message m4 from P2 to P1 leaves at 64 and arrives at 54. These\nvalues are clearly impossible. It is this situation that must be prevented.\nLamport’s solution follows directly from the happens-before relation. Since\nm3 left at 60, it must arrive at 61 or later. Therefore, each message carries\nthe sending time according to the sender’s clock. When a message arrives\nand the receiver’s clock shows a value before the time the message was sent,\nthe receiver fast forwards its clock to be one more than the sending time. In\nFigure 5.7, we see that m3 now arrives at 61. Similarly, m4 arrives at 70.\nLet us formulate this procedure more precisely. At this point, it is impor-\ntant to distinguish three different layers of software, as we already encountered\nin Section 2.2: the network, a middleware layer, and an application layer, as\nshown in Figure 5.8. What follows is typically part of the middleware layer.\nFigure 5.8: The positioning of Lamport’s logical clocks in distributed systems.\nTo implement Lamport’s logical clocks, each process Pi maintains a local\ncounter Ci. These counters are updated according to the following steps [Ray-\nnal and Singhal, 1996]:\n1. Before executing an event (i.e., sending a message over the network,\ndelivering a message to an application, or some other internal event), Pi\nincrements Ci: Ci ←Ci + 1.\n2. When process Pi sends a message m to process Pj, it sets m’s timestamp\nts(m) equal to Ci after having executed the previous step.\n3. Upon the receipt of a message m, process Pj adjusts its own local counter\nas Cj ←max{Cj, ts(m)} after which it then executes the first step and\ndelivers the message to the application.\nIn some situations, an additional requirement is desirable: no two events ever\noccur at the same time. To achieve this goal, we also use the unique process\nidentifier to break ties and use tuples instead of only the counter’s values. For\nexample, an event at time 40 at process Pi will be timestamped as ⟨40, i⟩. If\nwe also have an event ⟨40, j⟩and i < j, then ⟨40, i⟩< ⟨40, j⟩.\nDS 4.01\n \n",
      "content_length": 2163,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 279,
      "content": "5.2. LOGICAL CLOCKS\n263\nNote that by assigning the event time C(a) ←Ci(a) if a happened at\nprocess Pi at time Ci(a), we have a distributed implementation of the global\ntime value we were initially seeking for; we have thus constructed a logical\nclock.\nExample: Totally ordered multicasting\nAs an application of Lamport’s logical clocks, consider the situation in which\na database has been replicated across several sites. For example, to improve\nquery performance, a bank may place copies of an account database in two\ndifferent cities, say New York and San Francisco. A query is always forwarded\nto the nearest copy. The price for a fast response to a query is partly paid in\nhigher update costs because each update operation must be carried out at\neach replica.\nIn fact, there is a more stringent requirement regarding updates. Assume\na customer in San Francisco wants to add $100 to her account, which cur-\nrently contains $1,000. At the same time, a bank employee in New York\ninitiates an update by which the customer’s account is to be increased with\n1 percent interest. Both updates should be carried out at both copies of the\ndatabase. However, due to communication delays in the underlying network,\nthe updates may arrive in the order as shown in Figure 5.9.\nFigure 5.9: Updating a replicated database and leaving it in an inconsistent\nstate.\nThe customer’s update operation is performed in San Francisco before the\ninterest update. In contrast, the copy of the account in the New York replica is\nfirst updated with the 1 percent interest, and after that with the $100 deposit.\nConsequently, the San Francisco database will record a total amount of $1,111,\nwhereas the New York database records $1,110.\nThe problem that we are faced with is that the two update operations\nshould have been performed in the same order at each copy. Although it\nmakes a difference whether the deposit is processed before the interest update\nor the other way around, which order is followed is not essential from a\nconsistency perspective. The important issue is that both copies should be the\n \nDS 4.01\n",
      "content_length": 2092,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 280,
      "content": "264\nCHAPTER 5. COORDINATION\nsame after the updates have taken place. In general, situations such as these\nrequire a totally ordered multicast, that is, a multicast operation by which all\nmessages are delivered in the same order to each receiver. Lamport’s logical\nclocks can be used to implement totally ordered multicasts in a completely\ndistributed fashion.\nConsider a group of processes multicasting messages to each other. Each\nmessage is always timestamped with the current (logical) time of its sender.\nWhen a message is multicasted, it is conceptually also sent to the sender. In\naddition, we assume that messages from the same sender are received in the\norder they were sent, and that no messages are lost.\nWhen a process receives a message, it is put into a local queue, ordered\naccording to its timestamp. The receiver multicasts an acknowledgment to the\nother processes. Note that if we follow Lamport’s algorithm for adjusting local\nclocks, the timestamp of the received message is lower than the timestamp\nof the acknowledgment. The interesting aspect of this approach is that all\nprocesses will eventually have the same copy of the local queue (provided no\nmessages are removed).\nA process can deliver a queued message to the application it is running\nonly when that message is at the head of the queue and has been acknowl-\nedged by each other process. At that point, the message is removed from the\nqueue and handed over to the application; the associated acknowledgments\ncan simply be removed. Because each process has the same copy of the queue,\nall messages are delivered in the same order everywhere. In other words, we\nhave established totally ordered multicasting. We leave it as an exercise to\nthe reader to figure out that it is not strictly necessary that each multicast\nmessage has been explicitly acknowledged. It is sufficient that a process reacts\nto an incoming message, either by returning an acknowledgment or sending\nits own multicast message.\nTotally ordered multicasting is an important vehicle for replicated services,\nwhere the replicas are kept consistent by letting them execute the same\noperations in the same order everywhere. As the replicas essentially follow\nthe same transitions in the same finite state machine, it is also known as state\nmachine replication [Schneider, 1990].\nNote 5.3 (Advanced: Using Lamport clocks to achieve mutual exclusion)\nTo further illustrate the usage of Lamport’s clocks, let us see how we can use the\nprevious algorithm for totally ordered multicasting to establish access to what\nis commonly known as a critical region: a section of code that can be executed\nby at most one process at a time. This algorithm is very similar to the one for\nmulticasting, as essentially all processes need to agree on the order by which\nprocesses are allowed to enter their critical region.\nFigure 5.10(a) shows the code that each process executes when requesting,\nreleasing, or allowing access to the critical region (again, omitting details). Each\nDS 4.01\n \n",
      "content_length": 3017,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 281,
      "content": "5.2. LOGICAL CLOCKS\n265\nprocess maintains a request queue as well as a logical clock. To enter the critical\nregion, a call to requestToEnter is made, which results in inserting an ENTER\nmessage with timestamp (clock,procID) into the local queue and sending that\nmessage to the other processes. The operation cleanupQ essentially sorts the\nqueue. We return to it shortly.\n1 class Process:\n2\ndef __init__(self, chanID, procID, procIDSet):\n3\nself.chan.join(procID)\n4\nself.procID\n= int(procID)\n5\nself.otherProcs.remove(self.procID)\n6\nself.queue\n= []\n# The request queue\n7\nself.clock\n= 0\n# The current logical clock\n8\n9\ndef requestToEnter(self):\n10\nself.clock = self.clock + 1\n# Increment clock value\n11\nself.queue.append((self.clock, self.procID, ENTER)) # Append request to q\n12\nself.cleanupQ()\n# Sort the queue\n13\nself.chan.sendTo(self.otherProcs, (self.clock, self.procID, ENTER)) # Send request\n14\n15\ndef ackToEnter(self, requester):\n16\nself.clock = self.clock + 1\n# Increment clock value\n17\nself.chan.sendTo(requester, (self.clock, self.procID, ACK)) # Permit other\n18\n19\ndef release(self):\n20\ntmp = [r for r in self.queue[1:] if r[2] == ENTER]\n# Remove all ACKs\n21\nself.queue = tmp\n# and copy to new queue\n22\nself.clock = self.clock + 1\n# Increment clock value\n23\nself.chan.sendTo(self.otherProcs, (self.clock, self.procID, RELEASE)) # Release\n24\n25\ndef allowedToEnter(self):\n26\ncommProcs = set([req[1] for req in self.queue[1:]]) # See who has sent a message\n27\nreturn (self.queue[0][1] == self.procID and len(self.otherProcs) == len(commProcs))\nFigure 5.10: (a) Using Lamport’s logical clocks for mutual exclusion.\nWhen a process P receives an ENTER message from process Q, it can simply\nacknowledge that Q can enter its critical region, even if P wants to do so as well.\nIn the latter case, P’s ENTER request will have a lower logical timestamp than the\nACK message sent by P to Q, meaning that P’s request will have been inserted into\nQ’s queue before P’s ACK message.\nFinally, when a process leaves its critical region, it calls release. It cleans up\nits local queue by removing all received ACK messages, leaving only the ENTER\nrequests from other processes. It then multicasts a RELEASE message.\nTo actually enter a critical region, a process will have to repeatedly call\nallowedToEnter and when returned False, will have to block on a next incoming\nmessage. The operation allowedToEnter does what is to be expected: it checks\nif the calling process’s ENTER message is at the head of the queue, and sees if all\nother processes have sent a message as well. The latter is encoded through the set\n \nDS 4.01\n",
      "content_length": 2613,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 282,
      "content": "266\nCHAPTER 5. COORDINATION\ncommProcs, which contains the procIDs of all processes having sent a message by\ninspecting all messages in the local queue from the second position and onwards.\n1\ndef receive(self):\n2\nmsg = self.chan.recvFrom(self.otherProcs)[1]\n# Pick up any message\n3\nself.clock = max(self.clock, msg[0])\n# Adjust clock value...\n4\nself.clock = self.clock + 1\n# ...and increment\n5\nif msg[2] == ENTER:\n6\nself.queue.append(msg)\n# Append an ENTER request\n7\nself.ackToEnter(msg[1])\n# and unconditionally allow\n8\nelif msg[2] == ACK:\n9\nself.queue.append(msg)\n# Append a received ACK\n10\nelif msg[2] == RELEASE:\n11\ndel(self.queue[0])\n# Just remove first message\n12\nself.cleanupQ()\n# And sort and cleanup\nFigure 5.10: (b) Using Lamport’s logical clocks for mutual exclusion:\nhandling incoming requests.\nWhat to do when a message is received is shown in Figure 5.10(b). First,\nthe local clock is adjusted according to the rules for Lamport’s logical clocks\nexplained above. When receiving an ENTER or ALLOW message, that message is\nsimply inserted into the queue. An entry request is always acknowledged, as we\njust explained. When a RELEASE message is received, the original ENTER request is\nremoved. Note that this request is at the head of the queue. Thereafter, the queue\nis cleaned up again.\nAt this point, note that if we would clean up the queue by only sorting it,\nwe may get into trouble. Suppose that processes P and Q want to enter their\nrespective critical regions at roughly the same time, but that P is allowed to go\nfirst based on logical-clock values. P may find Q’s request in its queue, along\nwith ENTER or ALLOW messages from other processes. If its own request is at the\nhead of its queue, P will proceed and enter its critical region. However, Q will\nalso send an ALLOW message to P as well, in addition to its original ENTER message.\nThat ALLOW message may arrive after P had already entered its critical region, but\nbefore ENTER messages from other processes. When Q eventually enters, and leaves\nits critical region, Q’s RELEASE message would result in removing Q’s original\nENTER message, but not the ALLOW message it had previously sent to P. By now,\nthat message is at the head of P’s queue, effectively blocking the entrance to the\ncritical region of other processes in P’s queue. Cleaning up the queue thus also\ninvolves removing old ALLOW messages.\n5.2.2\nVector clocks\nLamport’s logical clocks lead to a situation where all events in a distributed\nsystem are totally ordered with the property that if event a happened before\nevent b, then a will also be positioned in that ordering before b, that is,\nC(a) < C(b).\nDS 4.01\n \n",
      "content_length": 2656,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 283,
      "content": "5.2. LOGICAL CLOCKS\n267\nHowever, with Lamport clocks, nothing can be said about the relationship\nbetween two events a and b by merely comparing their time values C(a)\nand C(b), respectively. In other words, if C(a) < C(b), then this does not\nnecessarily imply that a indeed happened before b. Something more is needed\nfor that.\nTo explain, consider the messages as sent by the three processes shown\nin Figure 5.11. Denote by Tsnd(mi) the logical time at which message mi was\nsent, and likewise, by Trcv(mi) the time of its receipt. By construction, we\nknow that for each message Tsnd(mi) < Trcv(mi). But what can we conclude\nin general from Trcv(mi) < Tsnd(mj) for different messages mi and mj?\nFigure 5.11: Concurrent message transmission using logical clocks.\nIn the case for which mi = m1 and mj = m3, we know that these values\ncorrespond to events that took place at process P2, meaning that m3 was\nindeed sent after the receipt of message m1.\nThis may indicate that the\nsending of message m3 depended on what was received through message m1.\nAt the same time, we also know that Trcv(m1) < Tsnd(m2). However, as far as\nwe can tell from Figure 5.11, the sending of m2 has nothing to do with the\nreceipt of m1.\nThe problem is that Lamport clocks do not capture causality. In practice,\ncausality is captured by means of vector clocks. To better understand where\nthese come from, we follow the explanation as given by Baquero and Preguica\n[2016]. In fact, tracking causality is simple if we assign each event a unique\nname such as the combination of a process ID and a locally incrementing\ncounter: pk is the kth event that happened at process P. The problem then\nboils down to keeping track of causal histories. For example, if two local\nevents happened at process P, then the causal history H(p2) of event p2 is\n{p1, p2}.\nNow assume that process P sends a message to process Q (which is an\nevent at P and thus recorded as pk for some k), and that at the time of arrival\n(an event for Q), the most recent causal history of Q was {q1}. To track\n \nDS 4.01\n",
      "content_length": 2055,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 284,
      "content": "268\nCHAPTER 5. COORDINATION\ncausality, P also sends its most recent causal history (assume it was {p1, p2},\nextended with p3 expressing the sending of the message). Upon arrival, Q\nrecords the event (q2), and merges the two causal histories into a new one:\n{p1, p2, p3, q1, q2}.\nChecking whether an event p causally precedes an event q can be done\nby checking whether H(p) ⊂H(q) (i.e., it should be a proper subset). In fact,\nwith our notation, it even suffices to check whether p ∈H(q), assuming that\nq is always the last local event in H(q).\nThe problem with causal histories, is that their representation is not very\nefficient. However, there is no need to keep track of all successive events from\nthe same process: the last one will do. If we subsequently assign an index to\neach process, we can represent a causal history as a vector, in which the jth\nentry represents the number of events that happened at process Pj. Causality\ncan then be captured by means of vector clocks, which are constructed by\nletting each process Pi maintain a vector VCi with the following two properties:\n1. VCi[i] is the number of events that have occurred so far at Pi. In other\nwords, VCi[i] is the local logical clock at process Pi.\n2. If VCi[j] = k then Pi knows that k events have occurred at Pj. It is thus\nPi’s knowledge of the local time at Pj.\nThe first property is maintained by incrementing VCi[i] at the occurrence of\neach new event that happens at process Pi. The second property is maintained\nby piggybacking vectors along with messages that are sent. In particular, the\nfollowing steps are performed:\n1. Before executing an event (i.e., sending a message over the network,\ndelivering a message to an application, or some other internal event), Pi\nexecutes VCi[i] ←VCi[i] + 1. This is equivalent to recording a new event\nthat happened at Pi.\n2. When process Pi sends a message m to Pj, it sets m’s (vector) timestamp\nts(m) equal to VCi after having executed the previous step (i.e., it also\nrecords the sending of the message as an event that takes place at Pi).\n3. Upon the receipt of a message m, process Pj adjusts its own vector by\nsetting VCj[k] ←max{VCj[k], ts(m)[k]} for each k (which is equivalent\nto merging causal histories), after which it executes the first step (record-\ning the receipt of the message) and then delivers the message to the\napplication.\nNote that if an event a has timestamp ts(a), then ts(a)[i] −1 denotes the\nnumber of events processed at Pi that causally precede a. As a consequence,\nwhen Pj receives a message m from Pi with timestamp ts(m), it knows about\nthe number of events that have occurred at Pi that causally preceded the\nDS 4.01\n \n",
      "content_length": 2671,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 285,
      "content": "5.2. LOGICAL CLOCKS\n269\nsending of m. More important, however, is that Pj is also told how many\nevents at other processes have taken place, known to Pi, before Pi sent message\nm. In other words, timestamp ts(m) tells the receiver how many events in\nother processes have preceded the sending of m, and on which m may causally\ndepend.\nTo see what this means, consider Figure 5.12 which shows three processes.\nIn Figure 5.12(a), P2 sends a message m1 at logical time VC2 = (0, 1, 0) to\nprocess P1. Message m1 thus receives timestamp ts(m1) = (0, 1, 0). Upon\nits receipt, P1 adjusts its logical time to VC1 ←(1, 1, 0) and delivers it. Mes-\nsage m2 is sent by P1 to P3 with timestamp ts(m2) = (2, 1, 0). Before P1\nsends another message, m3, an event happens at P1, eventually leading to\ntimestamping m3 with value (4, 1, 0). After receiving m3, process P2 sends\nmessage m4 to P3, with timestamp ts(m4) = (4, 3, 0).\n(a)\n(b)\nFigure 5.12: Capturing potential causality when exchanging messages.\nNow consider the situation shown in Figure 5.12(b). Here, we have delayed\nsending message m2 until after message m3 has been sent, and after the\nevent had taken place. It is not difficult to see that ts(m2) = (4, 1, 0), while\nts(m4) = (2, 3, 0). Compared to Figure 5.12(a), we have the following situation:\n \nDS 4.01\n",
      "content_length": 1304,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 286,
      "content": "270\nCHAPTER 5. COORDINATION\nSituation\nts(m2)\nts(m4)\nts(m2)\nts(m2)\nConclusion\n<\n>\nts(m4)\nts(m4)\nFigure 5.12(a)\n(2, 1, 0)\n(4, 3, 0)\nYes\nNo\nm2 may causally precede m4\nFigure 5.12(b)\n(4, 1, 0)\n(2, 3, 0)\nNo\nNo\nm2 and m4 may conflict\nWe use the notation ts(a) < ts(b) if and only if for all k, ts(a)[k] ≤ts(b)[k]\nand there is at least one index k′ for which ts(a)[k′] < ts(b)[k′]. Thus, by using\nvector clocks, process P3 can detect whether m4 may be causally dependent\non m2, or whether there may be a potential conflict. Note, by the way, that\nwithout knowing the actual information contained in messages, it is not\npossible to state with certainty that there is indeed a causal relationship, or\nperhaps a conflict.\nNote 5.4 (Advanced: Enforcing causal communication)\nUsing vector clocks, it is now possible to ensure that a message is delivered only\nif all messages that may have causally preceded it have been received as well. To\nenable such a scheme, we will assume that messages are multicast within a group\nof processes. Note that this causally ordered multicasting is weaker than totally\nordered multicasting. Specifically, if two messages are not in any way related to\neach other, we do not care in which order they are delivered to applications. They\nmay even be delivered in different order at different locations.\nFor enforcing causal message delivery, we assume that clocks are adjusted\nonly when sending and delivering messages (note, again, that messages are not\nadjusted when they are received by a process, but only when they are delivered\nto an application). In particular, only upon sending a message, will process Pi\nincrement VCi[i] by 1. Only when it delivers a message m with timestamp ts(m),\nwill it adjust VCi[k] to max{VCi[k], ts(m)[k]} for each k.\nNow suppose that Pj receives a message m from Pi with (vector) timestamp\nts(m). The delivery of the message to the application layer will then be delayed\nuntil the following two conditions are met:\n1. ts(m)[i] = VCj[i] + 1\n2. ts(m)[k] ≤VCj[k] for all k ̸= i\nThe first condition states that m is the next message that Pj was expecting from\nprocess Pi. The second condition states that Pj has delivered all the messages that\nhave been delivered by Pi when it sent message m. Note that there is no need for\nprocess Pj to delay the delivery of its own messages.\nAs an example, consider three processes P1, P2, and P3 as shown in Figure 5.13.\nAt local time (1, 0, 0), P1 multicasts message m to the other two processes. Note\nthat ts(m) = (1, 0, 0). Its receipt and subsequent delivery by P2, will bring the\nlogical clock at P2 to (1, 0, 0), effectively indicating that it has received one message\nfrom P1, has itself sent no message so far, and has not yet delivered a message\nfrom P3. P2 then decides to multicast m∗, at updated time (1, 1, 0), which arrives\nat P3 sooner than m.\nDS 4.01\n \n",
      "content_length": 2856,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 287,
      "content": "5.2. LOGICAL CLOCKS\n271\nFigure 5.13: Enforcing causal communication.\nWhen comparing the timestamp of m with its current time, which is (0, 0, 0),\nP3 concludes that it is still missing a message from P1 which P2 apparently had\ndelivered before sending m∗. P3 therefore, decides to postpone the delivery of m∗\n(and will also not adjust its local, logical clock). Later, after m has been received\nand delivered by P3, which brings its local clock to (1, 0, 0), P3 can deliver message\nm∗and also update its clock.\nA note on ordered message delivery\nSome middleware systems, notably ISIS\nand its successor Horus [Birman and van Renesse, 1994], provide support for\ntotally ordered and causally ordered (reliable) multicasting. There has been some\ncontroversy whether such support should be provided as part of the message-\ncommunication layer, or whether applications should handle ordering (see, e.g.,\nCheriton and Skeen [1993]; Birman [1994]). Matters have not been settled, but\nmore important is that the arguments still hold today.\nThere are two main problems with letting the middleware deal with message\nordering. First, because the middleware cannot tell what a message actually\ncontains, only potential causality is captured. For example, two messages from the\nsame sender that are completely independent will always be marked as causally\nrelated by the middleware layer. This approach is overly restrictive and may lead\nto efficiency problems.\nA second problem is that not all causality may be captured. Consider some\ndigital chat room. Suppose Alice posts a message. If she then phones Bob telling\nabout what she just wrote, Bob may post another message as a reaction without\nhaving seen Alice’s posting. In other words, there is a causality between Bob’s\nposting and that of Alice due to external communication. This causality is not\ncaptured by the chat room system.\nIn essence, ordering issues, like many other application-specific communi-\ncation issues, can be adequately solved by looking at the application for which\ncommunication is taking place. This is also known as the end-to-end principle in\nsystems design [Saltzer et al., 1984]. A drawback of having only application-level\nsolutions is that a developer is forced to concentrate on issues that do not immedi-\nately relate to the core functionality of the application. For example, ordering may\n \nDS 4.01\n",
      "content_length": 2372,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 288,
      "content": "272\nCHAPTER 5. COORDINATION\nnot be the most important problem when developing a messaging system such\nas the one for a chat room. In that case, having an underlying communication\nlayer handle ordering may turn out to be convenient. We will come across the\nend-to-end argument several times.\n5.3\nMutual exclusion\nFundamental to distributed systems is the concurrency and collaboration\namong multiple processes. In many cases, this also means that processes\nwill need to simultaneously access the same resources. To prevent that such\nconcurrent accesses corrupt the resource, or make it inconsistent, solutions are\nneeded to grant mutual exclusive access by processes. In this section, we take\na look at some important and representative distributed algorithms that have\nbeen proposed. Surveys of distributed algorithms for mutual exclusion are\nprovided by Saxena and Rai [2003] and Velazquez [1993]. Various algorithms\nare also presented in [Kshemkalyani and Singhal, 2008].\n5.3.1\nOverview\nDistributed mutual exclusion algorithms can be classified into two different\ncategories. In token-based solutions mutual exclusion is achieved by passing\na special message between the processes, known as a token. There is only one\ntoken available, and who ever has that token is allowed to access the shared\nresource. When finished, the token is passed on to a next process. If a process\nhaving the token is not interested in accessing the resource, it passes it on.\nToken-based solutions have a few important properties. First, depending\non how the processes are organized, they can fairly easily ensure that every\nprocess will get a chance at accessing the resource. In other words, they pro-\nvide guarantees for safety by avoiding what is known as starvation. Second,\ndeadlocks by which several processes are indefinitely waiting for each other\nto proceed, can easily be avoided, contributing to their simplicity. The main\ndrawback of token-based solutions is a rather serious one: when the token\nis lost (e.g. because the process holding it crashed), an intricate distributed\nprocedure needs to be started to ensure that a new token is created, but above\nall, that it is also the only token.\nAs an alternative, many distributed mutual exclusion algorithms follow\na permission-based approach. In this case, a process wanting to access the\nresource first requires the permission from other processes. There are many\nways toward granting such permission and in the sections that follow we will\nconsider a few of them.\nDS 4.01\n \n",
      "content_length": 2518,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 289,
      "content": "5.3. MUTUAL EXCLUSION\n273\n5.3.2\nA centralized algorithm\nA straightforward way to achieve mutual exclusion in a distributed system is\nto simulate how it is done in a one-processor system. One process is elected\nas the coordinator. Whenever a process wants to access a shared resource, it\nsends a request message to the coordinator stating which resource it wants to\naccess and asking for permission. If no other process is currently accessing\nthat resource, the coordinator sends back a reply granting permission, as\nshown in Figure 5.14(a). When the reply arrives, the requester can go ahead.\n(a)\n(b)\n(c)\nFigure 5.14: (a) Process P1 asks for permission to access a shared resource. Per-\nmission is granted. (b) Process P2 asks permission to access the same resource,\nbut receives no reply. (c) When P1 releases the resource, the coordinator\nreplies to P2.\nNow suppose that another process, P2 in Figure 5.14(b) asks for permission\nto access the resource. The coordinator knows that a different process is\nalready at the resource, so it cannot grant permission. The exact method used\nto deny permission is system dependent. In Figure 5.14(b) the coordinator just\nrefrains from replying, thus blocking process P2, which is waiting for a reply.\nAlternatively, it could send a reply saying “permission denied.” Either way, it\nqueues the request from P2 for the time being and waits for more messages.\nWhen process P1 is finished with the resource, it sends a message to the\ncoordinator releasing its exclusive access, as shown in Figure 5.14(c). The\ncoordinator takes the first item off the queue of deferred requests and sends\nthat process a grant message. If the process was still blocked (i.e., this is\nthe first message to it), it unblocks and accesses the resource. If an explicit\nmessage has already been sent denying permission, the process will have to\npoll for incoming traffic or block later. Either way, when it sees the grant, it\ncan go ahead as well.\nIt is easy to see that the algorithm guarantees mutual exclusion: the\ncoordinator lets only one process at a time access the resource. It is also fair,\nsince requests are granted in the order in which they are received. No process\never waits forever (no starvation). The scheme is easy to implement, too, and\nrequires only three messages per use of resource (request, grant, release). Its\nsimplicity makes it an attractive solution for many practical situations.\n \nDS 4.01\n",
      "content_length": 2433,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 290,
      "content": "274\nCHAPTER 5. COORDINATION\nThe centralized approach also has shortcomings. The coordinator is a\nsingle point of failure, so if it crashes, the entire system may go down. If\nprocesses normally block after making a request, they cannot distinguish a\ndead coordinator from “permission denied” since in both cases no message\ncomes back. In addition, in a large system, a single coordinator can become a\nperformance bottleneck. Nevertheless, the benefits coming from its simplicity\noften outweigh the potential drawbacks. Moreover, distributed solutions are\nnot necessarily better, as we illustrate next.\n5.3.3\nA distributed algorithm\nUsing Lamport’s logical clocks, and inspired by Lamport’s original solution\nfor distributed mutual exclusion (which we discussed in Note 5.3), Ricart and\nAgrawala [1981] provided the following algorithm. Their solution requires a\ntotal ordering of all events in the system. That is, for any pair of events, such\nas messages, it must be unambiguous which one actually happened first.\nThe algorithm works as follows. When a process wants to access a shared\nresource, it builds a message containing the name of the resource, its process\nnumber, and the current (logical) time. It then sends the message to all other\nprocesses, conceptually including itself. The sending of messages is assumed\nto be reliable; that is, no message is lost.\nWhen a process receives a request message from another process, the\naction it takes depends on its own state regarding the resource named in the\nmessage. Three different cases have to be clearly distinguished:\n• If the receiver is not accessing the resource and does not want to access\nit, it sends back an OK message to the sender.\n• If the receiver already has access to the resource, it simply does not reply.\nInstead, it queues the request.\n• If the receiver wants to access the resource as well but has not yet done\nso, it compares the timestamp of the incoming message with the one\ncontained in the message that it has sent everyone. The lowest one wins.\nIf the incoming message has a lower timestamp, the receiver sends back\nan OK message. If its own message has a lower timestamp, the receiver\nqueues the incoming request and sends nothing.\nAfter sending out requests asking permission, a process sits back and waits\nuntil everyone else has given permission. As soon as all the permissions are\nin, it may go ahead. When it is finished, it sends OK messages to all processes\nin its queue and deletes them all from the queue. If there is no conflict, it\nclearly works. However, suppose that two processes try to access the resource\nsimultaneously, as shown in Figure 5.15(a).\nProcess P0 sends everyone a request with timestamp 8, while at the same\ntime, process P2 sends everyone a request with timestamp 12. P1 is not\nDS 4.01\n \n",
      "content_length": 2801,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 291,
      "content": "5.3. MUTUAL EXCLUSION\n275\n(a)\n(b)\n(c)\nFigure 5.15: (a) Two processes want to access a shared resource at the same\nmoment. (b) P0 has the lowest timestamp, so it wins. (c) When process P0 is\ndone, it sends an OK also, so P2 can now go ahead.\ninterested in the resource, so it sends OK to both senders. Processes P0 and\nP2 both see the conflict and compare timestamps. P2 sees that it has lost,\nso it grants permission to P0 by sending OK. Process P0 now queues the\nrequest from P2 for later processing and accesses the resource, as shown\nin Figure 5.15(b). When it is finished, it removes the request from P2 from\nits queue and sends an OK message to P2, allowing the latter to go ahead,\nas shown in Figure 5.15(c). The algorithm works because in the case of a\nconflict, the lowest timestamp wins and everyone agrees on the ordering of\nthe timestamps.\nWith this algorithm, mutual exclusion is guaranteed without deadlock or\nstarvation. If the total number of processes is N, then the number of messages\nthat a process needs to send and receive before it can enter its critical region\nis 2 · (N −1): N −1 request messages to all other processes, and subsequently\nN −1 OK messages, one from each other process. A critical region is a series\nof instructions to be executed by a process, which requires mutually exclusive\naccess.\nUnfortunately, this algorithm has N points of failure.\nIf any process\ncrashes, it will fail to respond to requests. This silence will be interpreted\n(incorrectly) as denial of permission, thus blocking all subsequent attempts by\nall processes to enter any of their respective critical regions. The algorithm can\nbe patched up as follows. When a request comes in, the receiver always sends\na reply, either granting or denying permission. Whenever either a request or a\nreply is lost, the sender times out and keeps trying until either a reply comes\nback or the sender concludes that the destination is dead. After a request is\ndenied, the sender should block, waiting for a subsequent OK message.\nAnother problem with this algorithm is that either a multicast commu-\nnication primitive must be used, or each process must maintain the group\nmembership list itself, including processes entering the group, leaving the\ngroup, and crashing. The method works best with small groups of processes\n \nDS 4.01\n",
      "content_length": 2324,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 292,
      "content": "276\nCHAPTER 5. COORDINATION\nthat never change their group memberships. Finally, note that all processes are\ninvolved in all decisions concerning accessing the shared resource, which may\nimpose a burden on processes running on resource-constrained machines.\nVarious minor improvements are possible to this algorithm. For example,\ngetting permission from everyone is overkill. All that is needed is a method to\nprevent two processes from accessing the resource at the same time. The algo-\nrithm can be modified to grant permission when it has collected permission\nfrom a simple majority of the other processes, rather than from all of them.\n5.3.4\nA token-ring algorithm\nAn entirely different approach to deterministically achieving mutual exclusion\nin a distributed system is illustrated in Figure 5.16. In software, we construct\nan overlay network in the form of a logical ring in which each process is\nassigned a position in the ring. All that matters is that each process knows\nwho is next in line after itself.\nFigure 5.16: An overlay network constructed as a logical ring with a token\ncirculating between its members.\nWhen the ring is initialized, process P0 is given a token.\nThe token\ncirculates around the ring. Assuming there are N processes, the token is\npassed from process Pk to process P(k+1) mod N in point-to-point messages.\nWhen a process acquires the token from its neighbor, it checks to see if it\nneeds to access the shared resource. If so, the process goes ahead, does all the\nwork it needs to, and releases the resources. After it has finished, it passes\nthe token along the ring. It is not permitted to enter the resource immediately\nagain using the same token.\nIf a process is handed the token by its neighbor and is not interested in the\nresource, it just passes the token along. As a consequence, when no processes\nneed the resource, the token just circulates around the ring.\nThe correctness of this algorithm is easy to see. Only one process has the\ntoken at any instant, so only one process can actually get to the resource. Since\nthe token circulates among the processes in a well-defined order, starvation\ncannot occur. Once a process decides it wants to have access to the resource,\nat worst it will have to wait for every other process to use the resource.\nThis algorithm has its own problems. If the token is ever lost, for example\nbecause its holder crashes or due to a lost message containing the token, it\nmust be regenerated. In fact, detecting that it is lost may be difficult, since the\nDS 4.01\n \n",
      "content_length": 2534,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 293,
      "content": "5.3. MUTUAL EXCLUSION\n277\namount of time between successive appearances of the token on the network\nis unbounded. The fact that the token has not been spotted for an hour does\nnot mean that it has been lost; somebody may still be using it.\nThe algorithm also runs into trouble if a process crashes, but recovery is\nrelatively easy. If we require a process receiving the token to acknowledge\nreceipt, a dead process will be detected when its neighbor tries to give it\nthe token and fails. At that point, the dead process can be removed from\nthe group, and the token holder can throw the token over the head of the\ndead process to the next member down the line, or the one after that, if\nnecessary. Of course, doing so requires that everyone maintains the current\nring configuration.\n5.3.5\nA decentralized algorithm\nLet us take a look at a fully decentralized solution. Lin et al. [2004] propose to\nuse a voting algorithm. Each resource is assumed to be replicated N times.\nEvery replica has its own coordinator for controlling the access by concurrent\nprocesses.\nHowever, whenever a process wants to access the resource, it will simply\nneed to get a majority vote from m > N/2 coordinators. We assume that\nwhen a coordinator does not give permission to access a resource (which it\nwill do when it had granted permission to another process), it will tell the\nrequester.\nThe assumption is that when a coordinator crashes, it recovers quickly\nbut will have forgotten any vote it gave before it crashed. Another way of\nviewing this is that a coordinator resets itself at arbitrary moments. The risk\nthat we are taking is that a reset will make the coordinator forget that it had\npreviously granted permission to some process to access the resource. As a\nconsequence, it may incorrectly grant this permission again to another process\nafter its recovery.\nLet p = ∆t/T be the probability that a coordinator resets during a time\ninterval ∆t, while having a lifetime of T. The probability P[k] that k out of m\ncoordinators reset during the same interval is then\nP[k] =\n\u0012m\nk\n\u0013\npk(1 −p)m−k\nIf f coordinators reset, then the correctness of the voting mechanism will be\nviolated when we have more than m other coordinators think it is okay to\nallocate the resource, that is, when N −(m −f ) ≥m, or, in other words, when\nf ≥2m −N. The probability that such a violation occurs is ∑m\nk=2m−N P[k]. To\ngive an impression of what this could mean, Figure 5.17 shows the probability\nof violating correctness for different values of N, m, and p. Note that we\ncompute p by considering the number of seconds per hour that a coordinator\nresets, and also taking this value to be the average time needed to access\n \nDS 4.01\n",
      "content_length": 2696,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 294,
      "content": "278\nCHAPTER 5. COORDINATION\na resource. Our values for p are considered to be (very) conservative. The\nconclusion is that, in general, the probability of violating correctness can be\nso low that it can be neglected in comparison to other types of failure.\nN\nm\np\nViolation\n8\n5\n3 sec/hour\n< 10−5\n8\n6\n3 sec/hour\n< 10−11\n16\n9\n3 sec/hour\n< 10−4\n16\n12\n3 sec/hour\n< 10−21\n32\n17\n3 sec/hour\n< 10−4\n32\n24\n3 sec/hour\n< 10−43\nN\nm\np\nViolation\n8\n5\n30 sec/hour\n< 10−3\n8\n6\n30 sec/hour\n< 10−7\n16\n9\n30 sec/hour\n< 10−2\n16\n12\n30 sec/hour\n< 10−13\n32\n17\n30 sec/hour\n< 10−2\n32\n24\n30 sec/hour\n< 10−27\nFigure 5.17: Violation probabilities for various parameter values of decentral-\nized mutual exclusion.\nTo implement this scheme, we can use a system in which a resource is\nreplicated N times. Assume that the resource is known under its unique\nname rname. We can then assume that the ith replica is named rnamei which\nis then used to compute a unique key using a known hash function. As a\nconsequence, every process can generate the N keys given a resource’s name,\nand subsequently look up each node responsible for a replica (and controlling\naccess to that replica) using some commonly used naming system.\nIf permission to access the resource is denied (i.e., a process gets less\nthan m votes), it is assumed that it will back off for some randomly chosen\ntime, and make a next attempt later. The problem with this scheme is that if\nmany nodes want to access the same resource, it turns out that the utilization\nrapidly drops. In that case, there are so many nodes competing to get access\nthat eventually no one can get enough votes, leaving the resource unused. A\nsolution to solve this problem can be found in [Lin et al., 2004].\nNote 5.5 (More information: A comparison of the mutual-exclusion algorithms)\nA brief comparison of the mutual exclusion algorithms we have looked at is\ninstructive. In Figure 5.18 we have listed the algorithms and two performance\nproperties: the number of messages required for a process to access and release a\nshared resource, and the delay before access can occur (assuming messages are\npassed sequentially over a network).\nIn the following, we assume only point-to-point messages (or, equivalently,\ncount a multicast to N processes as N messages).\n• The centralized algorithm is simplest and also most efficient. It requires\nonly three messages to enter and leave a critical region: a request, a grant\nto enter, and a release to exit.\nDS 4.01\n \n",
      "content_length": 2458,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 295,
      "content": "5.3. MUTUAL EXCLUSION\n279\n• The distributed algorithm requires N −1 request messages, one to each of\nthe other processes, and an additional N −1 grant messages, for a total of\n2(N −1).\n• With the token ring algorithm, the number is variable. If every process\nconstantly wants to enter a critical region, then each token pass will result\nin one entry and exit, for an average of one message per critical region\nentered. At the other extreme, the token may sometimes circulate for hours\nwithout anyone being interested in it. In this case, the number of messages\nper entry into a critical region is unbounded.\n• The decentralized case requires sending N messages to coordinators, and\nanother N responses. If it does not get a majority, it will have to release\n(at most) N/2 votes. If it did get enough votes, it will have to send an\nadditional N release messages later on. A process may need to go through\nk ≥1 attempts.\nMessages per\nDelay before entry\nAlgorithm\nentry/exit\n(in message times)\nCentralized\n3\n2\nDistributed\n2(N −1)\n2(N −1)\nToken ring\n1, . . . , ∞\n0, . . . , N −1\nDecentralized\n2kN + (k −1)N/2 + N, k = 1, 2, . . .\n2kN + (k −1)N/2\nFigure 5.18: A comparison of four mutual exclusion algorithms.\nThe delay from the moment a process needs to enter a critical region until its\nactual entry also varies. For a worst-case analysis, we assume that messages are\nsent one after the other (i.e., there are never two or more messages in transit at\nthe same time), and that message transfer time is roughly the same everywhere.\nDelay can then be expressed in message transfer time units, or simply MTTU.\nUnder these assumptions, when the time using a resource is short, the dominant\nfactor in the delay is determined by the total number of messages sent through\nthe system before access can be granted. When resources are used for a long\nperiod of time, the dominant factor is waiting for everyone else to take their turn.\nIn Figure 5.18 we show the former case.\n• It takes only two MTTUs to enter a critical region in the centralized case,\ncaused by a request message and the subsequent grant message sent by the\ncoordinator.\n• The distributed algorithm requires sending N −1 request messages, and\nreceiving another N −1 grant messages, adding up to 2(N −1) MTTUs.\n• For the token ring, the delay varies from 0 MTTU (in case the token had\njust arrived) to N −1 (for when the token had just departed).\n• In the case of decentralized, the delay is dependent on the number of times\na process needed to return the (minority of) votes. With having to go\nthrough k ≥1 attempts, a process may see 2kN + (k −1)N/2 MTTUs.\n \nDS 4.01\n",
      "content_length": 2623,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 296,
      "content": "280\nCHAPTER 5. COORDINATION\nVirtually all algorithms suffer badly in the event of crashes. Special measures\nand additional complexity must be introduced to avoid having a crash bring down\nthe entire system. It is somewhat ironic that distributed algorithms are generally\nmore sensitive to crashes than centralized ones. In this sense, it should not come\nas a surprise that, indeed, centralized mutual exclusion is widely applied: it\nis simple to understand the behavior, and relatively easy to increase the fault\ntolerance of the centralized server.\n5.3.6\nExample: Simple locking with ZooKeeper\nFor many practical reasons, mutual exclusion in distributed systems is often\ndone with a centralized coordinator, not in the least because the behavior of\nthese solutions is much easier to understand than many other noncentralized\nversions. Let us briefly look at a system that is designed for coordination tasks\nin distributed systems, and which is by now also widely deployed. ZooKeeper\nwas developed to provide facilities for supporting various coordination tasks,\nincluding locking, leader election, monitoring, to name but just a few. It\nhas been designed for scalability and fault tolerance. For our purposes now,\nwe concentrate only on a relatively simple setup, namely to support locking\nthrough a single server. ZooKeeper’s fault tolerance aspects are discussed in\nChapter 8. The system was first described in [Hunt et al., 2010], to be later\nfollowed up with a practical description by Junqueira and Reed [2014].\nZooKeeper basics\nAs mentioned, ZooKeeper is designed to facilitate different coordination\nfunctions. An important design principle is its lack of blocking primitives:\nclients send messages to the ZooKeeper service and, in principle, are always\nimmediately returned a response. In the case of locking, this means that a\nclient will, for example, be informed whether it was able to grab a lock. If the\nlock could not be acquired, a new attempt will be necessary, as we discuss\nshortly.\nTo facilitate a range of coordination functions, ZooKeeper maintains a\nnamespace, organized as a tree. Operations on the tree are simple: creating\nand deleting nodes, as well as reading and updating the data contained in a\nnode (if any). A partial update of a node is not possible: all the node’s data\nwill be overwritten in the case of an update. In addition, a client can check\nwith the server whether a node exists. At this point, it should be become clear\nhow one could implement a locking service in ZooKeeper: to acquire a lock,\nsimply let a process create a special node, say lock, but have that operation\nfail if the node already exists. Releasing a lock is done by merely deleting the\nnode lock. We return to some important details below.\nDS 4.01\n \n",
      "content_length": 2760,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 297,
      "content": "5.3. MUTUAL EXCLUSION\n281\nThere are two types of nodes in ZooKeeper. Persistent nodes need to\nbe created and deleted explicitly. In contrast, ephemeral nodes are created\nexplicitly, but are automatically removed if the connection with the creating\nclient closes (perhaps because of a failure), or expires. Of course, an ephemeral\nnode can also be explicitly deleted.\nAn important consequence of not supporting blocking operations, is that a\nclient will have to regularly check the status of the namespace: have nodes\nbeen added or removed, have nodes in the namespace been changed? However,\npolling is generally not considered to be very efficient. To this end, ZooKeeper\nsupports a notification mechanism by which a client can subscribe to a change\nin a node or a branch in the tree. When a change happens, the client receives\na message.\nThere are a few things that need to be considered to make this all work.\nFirst, suppose a client subscribes to changes at a specific node after having\nread the state of that node. If the node is updated twice in a row, we want\nto prevent that the client sees the second update before being notified, as the\nnotification dealt with changes to the previous state, i.e., the state after the first\nupdate took place.\nSecond, it should be clear that there can be a lot of concurrency among\ncompeting clients. As we shall discuss in detail in Chapter 7, problematic are,\nin particular, the situations in which one client C1 reads data to subsequently\ndecide to update that data. If, between the read and intended update another\nclient C2 performs an update, client C1 may now request an update based on\nout-of-date information. Such intended updates can be prevented by using\nversion numbers, as shown in Figure 5.19.\nFigure 5.19: Preventing updates based on out-of-date information through\nversions (based on [Junqueira and Reed, 2014].\nWe use the notation W(n, k)a to denote the request to write the value a to\nnode n, under the assumption that its current version is k. R(n, k) denotes that\nthe current version of node n is k. The operation R(n) tells that a client wants\nto read the current value of node n, and R(n, k)a means that the value a from\n \nDS 4.01\n",
      "content_length": 2196,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 298,
      "content": "282\nCHAPTER 5. COORDINATION\nnode n is returned with its current version k. In Figure 5.19 we see that client\nC1 writes value a to node n, assuming its version is 1. If no write has ever\ntaken place, this assumption is correct. The ZooKeeper service (ZK) returns\nthe new version number, namely 2.\nMeanwhile, client C2 issues a read request for node n and is returned the\npreviously written value a having version number 2. C2 decides to update\nn, assuming its current version is still 2, by means of the write operation\nW(n, 2)b. ZooKeeper accepts the write, and returns the new version number\n3. This concurrent update places C1 in the position that its intended write\noperation W(n, 2)c will fail: ZooKeeper states that its assumption about the\nversion number is incorrect. The best what C1 could do is read n again to see\nif it still wants to update the node.\nClearly, each client may need to try several times before an update actually\ntakes place. This may not always seem so efficient, yet this approach ensures\nthat data maintained by ZooKeeper is at least consistent with what clients\nexpect it to be. As mentioned, we will return to consistency in much more\ndetail in Chapter 7.\nA ZooKeeper locking protocol\nImplementing a lock using ZooKeeper is now fairly straightforward. ZooKeeper\nuses the same path notation for nodes as in Unix file systems. That means\nthat we can create a node /lock at the root of the tree. The existence of that\nnode means that a client has successfully acquired the lock. Releasing the lock\nis simply done by deleting node /lock.\nAny client wanting to create the same node will receive the message that\nthe node already exists and thus that the operation failed. Capturing such\nexceptions is at the core of blocking a client until /lock is removed. When the\nnode already exists, the client will request ZooKeeper to send a notification\nwhen the node is deleted. Until that moment, the client simply waits (i.e.,\nlocally blocks) until notified, after which it tries to create the node again.\nThere are many subtleties to deal with. For example, a decent locking\nmechanism should allow a client to bail out after several attempts. Likewise,\nif a client who has created /lock crashes before deleting it again, we need to\nmake sure that ZooKeeper will delete the node. Furthermore, we will find\nourselves in an unfortunate race when the following happens:\n1. A client C1 creates a node /lock.\n2. A client C2 wants to acquire the lock but is notified that the associated\nnode already exists.\n3. Before C2 subscribes to a notification, C1 releases the lock, i.e., deletes\n/lock.\n4. Client C2 subscribes to changes to /lock and blocks locally.\nDS 4.01\n \n",
      "content_length": 2682,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 299,
      "content": "5.4. ELECTION ALGORITHMS\n283\nThis is analogous to the situation we described before: C2 should be\nable to subscribe to changes based on the existence of /lock. In other words,\nwhen performing the fourth step, C2 should be immediately notified that the\nsituation has already changed since it last visited the tree. These subtleties are\nhandled by ZooKeeper.\n5.4\nElection algorithms\nMany distributed algorithms require one process to act as coordinator, initiator,\nor otherwise perform some special role. In general, it does not matter which\nprocess takes on this special responsibility, but one of them has to do it. In\nthis section, we will look at algorithms for electing a coordinator. We will\noften also speak of a leader election.\nIf all processes are the same, with no distinguishing characteristics, there is\nno way to select one of them to be special. Consequently, we will assume that\neach process P has a unique identifier id(P). In general, election algorithms\nattempt to locate the process with the highest identifier and designate it as\ncoordinator. The algorithms differ in the way they locate the coordinator.\nFurthermore, we also assume that every process knows the identifier of\nevery other process. In other words, each process has complete knowledge of\nthe process group in which a coordinator must be elected. What the processes\ndo not know is which ones are currently up and which ones are currently\ndown. The goal of an election algorithm is to ensure that when an election\nstarts, it concludes with all processes agreeing on whom the new coordinator\nis to be. There are many algorithms and variations, of which several important\nones are discussed in the textbooks by Tel [2000] and Lynch [1996].\n5.4.1\nThe bully algorithm\nA well-known solution for electing a coordinator is the bully algorithm de-\nvised by Garcia-Molina [1982]. In the following, we consider N processes\n{P0, . . . , PN−1} and let id(Pk) = k. When any process notices that the coordi-\nnator is no longer responding to requests, it initiates an election. A process,\nPk, holds an election as follows:\n1. Pk sends an ELECTION message to all processes with higher identifiers:\nPk+1, Pk+2, . . . , PN−1.\n2. If no one responds, Pk wins the election and becomes coordinator.\n3. If one of the higher-ups answers, it takes over and Pk’s job is done.\nAt any moment, a process can get an ELECTION message from one of its\nlower-numbered colleagues. When such a message arrives, the receiver sends\nan OK message back to the sender to indicate that it is alive and will take\n \nDS 4.01\n",
      "content_length": 2561,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 300,
      "content": "284\nCHAPTER 5. COORDINATION\n(a)\n(b)\n(c)\n(d)\n(e)\nFigure 5.20: The bully election algorithm. (a) Process 4 holds an election. (b)\nProcesses 5 and 6 respond, telling 4 to stop. (c) Now 5 and 6 each hold an\nelection. (d) Process 6 tells 5 to stop. (e) Process 6 wins and tells everyone.\nover. The receiver then holds an election, unless it is already holding one.\nEventually, all processes give up but one, and that one is the new coordinator.\nIt announces its victory by sending all processes a message telling them that\nstarting immediately it is the new coordinator.\nIf a process that was previously down comes back up, it holds an election.\nIf it happens to be the highest-numbered process currently running, it will\nwin the election and take over the coordinator’s job. Thus the biggest guy in\ntown always wins, hence the name “bully algorithm.”\nIn Figure 5.20 we see an example of how the bully algorithm works. The\ngroup consists of eight processes, with identifiers numbered from 0 to 7.\nDS 4.01\n \n",
      "content_length": 1002,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 301,
      "content": "5.4. ELECTION ALGORITHMS\n285\nPreviously, process P7 was the coordinator, but it has just crashed. Process\nP4 is the first one to notice this, so it sends ELECTION messages to all the\nprocesses higher than it, namely P5, P6, and P7, as shown in Figure 5.20(a).\nProcesses P5 and P6 both respond with OK, as shown in Figure 5.20(b). Upon\ngetting the first of these responses, P4 knows that its job is over, knowing that\neither one of P5 or P6 will take over and become coordinator. Process P4 just\nsits back and waits to see who the winner will be (although at this point it\ncan make a pretty good guess).\nIn Figure 5.20(c) both P5 and P6 hold elections, each one sending messages\nonly to those processes with identifiers higher than itself. In Figure 5.20(d),\nP6 tells P5 that it will take over. At this point, P6 knows that P7 is dead and\nthat it (P6) is the winner. If there is state information to be collected from disk\nor elsewhere to pick up where the old coordinator left off, P6 must now do\nwhat is needed. When it is ready to take over, it announces the takeover by\nsending a COORDINATOR message to all running processes. When P4 gets\nthis message, it can now continue with the operation it was trying to do when\nit discovered that P7 was dead, but using P6 as the coordinator this time. In\nthis way, the failure of P7 is handled, and the work can continue.\nIf process P7 is ever restarted, it will send all the others a COORDINATOR\nmessage and bully them into submission.\n5.4.2\nA ring algorithm\nConsider the following election algorithm that is based on the use of a (logical)\nring. Unlike some ring algorithms, this one does not use a token. We assume\nthat each process knows who its successor is. When any process notices that\nthe coordinator is not functioning, it builds an ELECTION message containing\nits own process identifier and sends the message to its successor. If the\nsuccessor is down, the sender skips over the successor and goes to the next\nmember along the ring, or the one after that, until a running process is located.\nAt each step along the way, the sender adds its own identifier to the list in the\nmessage, effectively making itself a candidate to be elected as coordinator.\nEventually, the message gets back to the process that started it all. That pro-\ncess recognizes this event when it receives an incoming message containing its\nown identifier. At that point, the message type is changed to COORDINATOR\nand circulated once again, this time to inform everyone else who the coordi-\nnator is (the list member with the highest identifier) and who the members of\nthe new ring are. When this message has circulated once, it is removed and\neveryone goes back to work.\nIn Figure 5.21 we see what happens if two processes, P3 and P6, discover\nsimultaneously that the previous coordinator, process P7, has crashed. Each\nof these builds an ELECTION message and each of them starts circulating its\nmessage, independent of the other one. Eventually, both messages will go all\nthe way around, and both P3 and P6 will convert them into COORDINATOR\n \nDS 4.01\n",
      "content_length": 3078,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 302,
      "content": "286\nCHAPTER 5. COORDINATION\nFigure 5.21: Election algorithm using a ring. The solid line shows the election\nmessages initiated by P6; the dashed one those by P3.\nmessages, with exactly the same members and in the same order. When both\nhave gone around again, both will be removed. It does no harm to have extra\nmessages circulating; at worst it consumes a little bandwidth, but this is not\nconsidered wasteful.\n5.4.3\nExample: Leader election in ZooKeeper\nLet us look at a practical example of how leader election takes place in a\ndistributed system. As mentioned, ZooKeeper is logically centralized coordi-\nnation service. In Section 5.3.6 we considered a simple setup with just a single\nZooKeeper server. In practice, we see that ZooKeeper maintains a (relatively\nsmall) set of servers, forming what is called an ensemble. For a client, an\nensemble appears as just a single server. For ZooKeeper, this ensemble is\nalso coordinated by a single server, called the leader. The other servers are\ncalled followers and essentially act as up-to-date standbys for whenever the\nleader malfunctions. In that case, one of the followers will be elected as the\nnew leader. From the client’s perspective, a malfunctioning leader is mostly\ninvisible: as soon as one of the standbys has taken over the role of leader,\neverything proceeds as if nothing happened. We return to many details of\nsuch fault-tolerant behavior in Chapter 8, but for now, let us dive a bit deeper\ninto how the server in a ZooKeeper ensemble choose their leader.\nIt is important to note that a leader-election algorithm within a ZooKeeper\nensemble is fundamentally different from devising a leader-election algorithm\nby means of ZooKeeper. The first deals with the implementation of ZooKeeper\nas a coordination service; the second with using ZooKeeper as a coordination\nservice, perhaps as part of the implementation of a larger distributed system.\nWhich leader-election algorithm is used within a ZooKeeper ensemble is\nnot that important, as long as, in the end, a single leader is chosen and enough\nfollowers are running as up-to-date standbys. Enough in this case means that\na majority of the servers that form an ensemble are operating properly. For\nnow, we will simply assume this to be the case.\nDS 4.01\n \n",
      "content_length": 2271,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 303,
      "content": "5.4. ELECTION ALGORITHMS\n287\nThe default election algorithm in an implementation of ZooKeeper is\na simple version of bullying and works as follows [Junqueira and Reed,\n2014]. Each server s in the ensemble has an identifier id(s), as well as a\nmonotonically increasing counter tx(s) of the latest transaction it handled.\nThink of a transaction as a series of operations the server has executed, such\nas the combination of adding a node and registering that it should send a client\na notification when anything changes. Typically, the leader of the ensemble\nwill have performed the transaction on its own, locally stored, namespace and\ninstructed its followers to do so as well on their respective local copy of that\nnamespace.\nWhen a follower s believes something is wrong with the leader (e.g., it\nsuspects that the leader crashed), it sends out an ELECTION message to all\nother servers, along with the pair (voteID,voteTX). For this first message,\nit sets voteID to id(s) and voteTX to tx(s). During an election, each server s\nmaintains two variables. The first, leader(s), records the identifier of the server\nthat s believes may turn out to be the final leader, and is initialized to id(s).\nThe second, lastTX(s) is what s has learned to be the most recent transaction,\ninitially being its own value, namely id(s).\nWhen a server s∗receives (voteID,voteTX), it proceeds as follows:\n• If lastTX(s∗) < voteTX, then s∗just received more up-to-date informa-\ntion on the most recent transaction. In that case, it sets\n– leader(s∗) ←voteID\n– lastTX(s∗) ←voteTX\n• If lastTX(s∗) = voteTX and leader(s∗) < voteID, then s∗knows as much\nabout the most recent transaction as what it was just sent, but its per-\nspective on which server will be the next leader needs to be update:\n– leader(s∗) ←voteID\nEach time a server s∗receives a (voteID,voteTX) message, it may update its\nown information on whom it suspects to be the next leader. If s∗believes it\nshould be the next leader, and has not sent out a message stating this, it will\nbroadcast the pair (id(s∗),tx(s∗)). Under the assumption that communication is\nreliable, this broadcast alone should do the job. Typically, s∗will send out a\nmessage stating that it is the leader, when either initiating an election, or when\nreceiving a message with a lower voteTX than its own tx(s∗), or receiving a\nmessage with an up-to-date value for voteTX, but with a smaller voteID than\nid(s∗). Once a leader has been elected, all servers will make sure that they\nsynchronize on the latest transaction.\n \nDS 4.01\n",
      "content_length": 2541,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 304,
      "content": "288\nCHAPTER 5. COORDINATION\nNote 5.6 (Advanced: ZooKeeper leader election in Python)\n1 class Process:\n2\ndef __init__(self, chanID, procID, procIDSet, initTX):\n3\nself.txID\n= initTX\n# Your own most recent transaction\n4\nself.leader\n= self.procID\n# Who you believe may become leader\n5\nself.lastTX\n= self.txID\n# What is the most recent transaction\n6\nself.noleader\n= False\n# Are you still in the race for leader?\n7\n8\ndef receive(self):\n9\nwhile True:\n10\nmsg\n= self.chan.recvFrom(self.otherProcs)\n11\nsender, payload = msg[0], msg[1]\n12\nif payload[0] == ELECTION: # A process started an election\n13\nvoteID, voteTX = payload[1], payload[2]\n14\n15\nif self.lastTX < voteTX: # You’re not up to date on most recent transaction\n16\nself.leader = voteID\n# Record the suspected leader\n17\nself.lastTX = voteTX\n# As well as the likely most recent transaction\n18\n19\nelif (self.lastTX == voteTX) and (self.leader < voteID): # Wrong leader\n20\nself.leader = voteID\n# Update your suspected leader\n21\n22\nelif (self.procID > voteID) and (self.txID >= voteTX) and (not self.noleader):\n23\n# At this point, you may very well be the new leader (having a sufficiently\n24\n# high process identifier as well as perhaps the most recent transaction).\n25\n# No one has told you so far that you could not be leader. Tell the others.\n26\nself.chan.sendTo(self.otherProcs, (LEADER, self.procID, self.txID))\n27\n28\nif payload[0] == LEADER:\n29\n# Check if the sender should indeed be leader\n30\nif ((self.lastTX < payload[2]) or\n31\n((self.lastTX == payload[2]) and (self.leader <= payload[1]))):\n32\n# The sender is more up-to-date than you, or is equally up-to-date but\n33\n# has a higher process identifier. Declare yourself follower.\n34\nself.chan.sendTo(sender, (FOLLOWER, self.procID))\n35\nelse:\n36\n# Sender is wrong: you have information that the sender based its decision\n37\n# on outdated information\n38\nself.chan.sendTo(sender, (NOLEADER))\nFigure 5.22: A simplified version of ZooKeeper’s leader election for an\nensemble of servers.\nComing to the conclusion that one of the servers in a ZooKeeper ensemble is\nnow indeed the new leader, can be a bit tricky. One way is to let a server come to\nthe conclusion that it may never become a leader in the current round, in which\ncase it tells the alleged leader that it will become a follower. This means that as\nsoon as a server has collected enough followers, it can promote itself to leader.\nIn ZooKeeper, this happens when a server has a majority of the other servers in\nthe ensemble as followers. If we take an oversimplified approach by assuming\nDS 4.01\n \n",
      "content_length": 2560,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 305,
      "content": "5.4. ELECTION ALGORITHMS\n289\nthat messages are never lost, nor do servers crash during an election, a leader is\nelected when all other servers are its followers. The code is shown in Figure 5.22\n(again, omitting many details).\n5.4.4\nExample: Leader election in Raft\nAs another example of a leader-election algorithm that is in practical use, let\nus take a look at Raft [Ongaro and Ousterhout, 2014]. We will return to Raft\nin Chapter 8 when discussing consensus algorithms and focus here only on\nhow it selects a leader.\nRaft operates in a setting in which a handful of known replicated servers\n(typically five) collaborate by ensuring that each server executes the same set\nof operations, and all in the same order. To this end, one of the servers is\nelected as leader to tell the others what the exact order is of those operations.\nThe protocol assumes that messages may be lost and that servers may crash.\nEach server can be in one of three states: follower, candidate, or leader.\nFurthermore, the protocol operates in terms, where during each term there\nis exactly one leader, although it could have perhaps crashed. Each term is\nnumbered, starting with 0. The leader is assumed to regularly send out a\nmessage, either containing information on an operation that should be carried\nout, or otherwise a heartbeat message to tell the other servers that their leader\nis still up and running.\nEach server initially starts in the follower state (that is, there is initially no\nleader). Adopting the terminology from Howard et al. [2015], after a follower\ntimeout, a following server concludes that the leader may have crashed (which,\nby the way, may be a false conclusion). As a result, it enters the candidate state\nand starts an election, volunteering to be the new leader. An election starts\nwith a broadcast to all other servers, along with increasing the term number\nby 1. At that point, three situations may happen.\n1. A candidate may receive a message from an alleged leader. If that server\nindicates it is operating in the same term as the candidate server, the\nlatter will become follower again for the current term.\n2. When a following server receives an election message for the first time\n(in a new term), it simply votes for the candidate and ignores any other\nelection messages (for that new term). Therefore, a candidate server can\nalso receive a vote. If it has a majority of votes (i.e., more than half of the\nservers, including itself), it promotes itself as leader for the new term.\n3. As long as there is no alleged leader, or not enough votes have been\nreceived, the candidate server waits until a candidate timeout happens.\nAt that point, the candidate server will simply start a new election (and\nagain, for a next term).\n \nDS 4.01\n",
      "content_length": 2753,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 306,
      "content": "290\nCHAPTER 5. COORDINATION\nOf course, if all servers enter the candidate state, we bear the risk of\nindefinitely not being able to cast enough votes for a single server. A simple\nsolution is to slightly vary the follower timeout and candidate timeout on a\nper-server basis. The result is that, generally, there is only a single candidate\nfor the new term, allowing each other server to vote for that candidate and\nbecome a follower. As soon as a server becomes leader, it will send out a\nheartbeat message to the rest.\n5.4.5\nElections in large-scale systems\nMany leader-election algorithms apply to only relatively small distributed\nsystems. In such cases, the various nodes exchange information among each\nother, often through several rounds, to eventually collectively decide on the\nnew leader. In Chapter 8, we shall see that this collective decision-making can\ntake place even when a fraction of the participating nodes exhibits noncon-\nforming behavior, as in the case of security attacks or faults. The problem\nof electing a leader becomes rather nasty when there are potentially many\nprocesses to choose from. This is the case, for example, in permissionless\nblockchains.\nProof of work\nA relatively simple, yet by now heavily criticized solution, is to have the\ncandidates run a computational race, referred to as proof of work. Running\nsuch a race, which is done by solving a computational puzzle, should be\nknown to be possible, yet difficult. The first process solving the puzzle, wins,\nand may proceed as leader to append a block of validated transactions to the\nexisting blockchain.\nThe type of problem used for blockchains is based on what is known as\nhashing. As introduced in Section 1.2.5, a hash function takes as input a\n(possibly large) data set and produces a fixed-length string of bits, typically\nof length 1024 or 2048, called a hash. A cryptographically well-defined hash\nfunction has several important properties [Ferguson and Schneier, 2003]:\n1. Computing the hash of a given data set is relatively easy, i.e., it does not\nrequire significant computational efforts.\n2. However, given a specific hash, it is computationally very difficult to\nfind a corresponding data set with the same associated hash.\n3. With very high probability, any two different input data sets will lead\nto two seemingly unrelated, different hashes. Even if the two data sets\nare minimally different, their associated hashes will most likely be very\ndifferent.\nDS 4.01\n \n",
      "content_length": 2471,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 307,
      "content": "5.4. ELECTION ALGORITHMS\n291\nThe third property is used to securely protect blocks of validated transac-\ntions against adversarial modifications: even the change of a single bit will\nnot go unnoticed. Combined with the second property, it becomes virtually\nimpossible to modify a block meaningfully, such that the modified block’s\nhash is the same as the original block’s hash.\nTo set up a race between validators, each validator computes the hash of\nits block of validated transactions. Note again that a hash is technically just\na fixed-length string of bits. We denote the computed hash over a block a\ndigest. The validator is then required to find an additional bit string, called\na nonce, such that the hash computed over the digest and the nonce when\ntaken together produces a bit string with a predetermined number of leading\nzeroes. Given property 2 of hash functions, we know that it is computationally\nvery difficult to find a data set that matches a given hash. In our case, we have\nas input the hash of the block of validated transactions (i.e., the digest), and\nare now required to find a bit string (i.e., nonce) that, taken together with the\ndigest, has an associated hash that starts with a given number of zeroes. This\nis computationally very difficult. In essence, each validator simply needs to\ngo through a most likely lengthy trial-and-error process of generating a nonce\nand checking whether that nonce, combined with the digest, will lead to the\nrequired result.\nBy controlling how many leading zeroes that the outcome should have,\nwe essentially control the difficulty of the computations. For example, with\njust 1 leading zero, there is a 50% chance that a generated nonce will lead to\nthe desired result. Demanding 2 leading zeroes reduces this probability to\n25%, 3 leading zeroes to 12.5%, and so forth. With 64 leading zeroes, which\nis common practice, the chance that an arbitrarily chosen nonce will do the\ntrick is a mere 0.0000 0000 0000 0000 05% (that is, 17 zeroes after the decimal\ndot). Put differently, a validator will on average need to check about 18 billion\nbillion nonces to find one that leads to the desired result. Using dedicated\nsupercomputers, this takes about 10 minutes. It would take an average laptop\nabout 100 years.\nWith increasing hardware capacity, the time it takes to find a nonce will\ndrop. For this reason, the difficulty of finding a nonce is deliberately con-\ntrolled in such a way that a race will have an expected duration. For Bitcoin\nsystems, a popular application of blockchains, the duration is approximately\n10 minutes. If races tend to become shorter, then the difficulty for finding a\nnonce is increased. If races turn out to be too lengthy, the difficulty is lowered.\nAdjusting the difficulty is done by regularly computing the average time it\ntook to run the race over the last 2000 blocks of transactions, or so. The\nadjustment of the difficulty is done by all validators using the same globally\nknown method, and is therefore done in a completely decentralized manner.\nThere is a reason for properly setting the expected duration of a race.\nSuppose we have very lengthy races. This means that validators would have\n \nDS 4.01\n",
      "content_length": 3201,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 308,
      "content": "292\nCHAPTER 5. COORDINATION\nto do a lot of work to find a proper nonce. The good part of the story is that\nthe chance that two validators find a nonce at more or less the same time is\nrelatively small (although this depends, of course, on how many validators\nparticipate in the race). As a consequence, the chance that there will be only\none winner who will have enough time to successfully broadcast its victory to\nall others is relatively high.\nThe downside of the story, however, is that with lengthy races, the transac-\ntion processing capacity may be too low. Suppose that we have a race duration\nof 10 minutes and an average number of 2500 transactions per block (which\nare common values for Bitcoin). This means that, effectively, the system can\nhandle about 4 transactions per second. Increasing the number of transactions\nper block is an obvious path to follow, yet even such improvements still lead\nto low rates in comparison to many centralized solutions with a fixed, trusted\nthird party validating transactions.\nOn the other hand, assume we would have very short-lasting races. In that\ncase, two validators may more easily concurrently find a proper nonce, both\nwill declare victory, append their block to the blockchain (which was already\nmassively replicated), and before other validators had the chance to stop their\nwork, we would find ourselves with different copies of the same blockchain.\nThere are different ways to correct for these concurrent versions of what is\nsupposed to be a single blockchain, but obviously, it comes at the price of\ninvalidating potentially many transactions, and rolling back to a valid state.\nOf course, the advantage of a smaller race duration is that, in principle, we\ncan handle more transactions per time unit.\nProof of stake\nAs a reaction to the waste of computational resources found in proof-of-work\nsystems, much effort has been spent on alternative leader-election algorithms\nfor permissionless blockchains. An important class is formed by so-called\nproof-of-stake systems. Leaving out many details, as well as the many variants\nof such systems, the basic principle is as follows. An easy-to-read overview of\nthe principles of proof-of-stake leader election is provided by Nguyen et al.\n[2019].\nFirst, we need to make the assumption that each transaction as recorded\nin a blockchain has one or more associated tokens. Moreover, at each moment,\neach token has exactly one owner. This is typically the case with mone-\ntary transactions, where a token is associated with a digital coin. Because\nblockchains are fully readable by any participant, we may also assume that\ntokens may be passed between owners, and that, indeed, copying a token and\nassociating it with multiple owners cannot go undetected. How this can be\nrealized is discussed in Section 9.4.3. Each token will, therefore, have only a\nsingle owner. Second, we make also make the (realistic) assumption that for\nDS 4.01\n \n",
      "content_length": 2939,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 309,
      "content": "5.4. ELECTION ALGORITHMS\n293\na given blockchain, there are a total of N tokens, which may vary over time\ndepending on the application for which a blockchain is being used.\nA simple leader-election process for blockchains then consists of a function\nthat generates a random number k between 1 and N. That number is used\nas an index of the kth token, of which the owner becomes the next leader.\nThe function used to generate a random number is public, meaning that any\nparticipant can execute it to determine k. Obviously, the more tokens a process\nP owns, the higher the probability that P will be elected as leader.\nThe simplicity of this algorithm and the fact that there are still so many\nrace-based blockchains, indicates that there are many issues to deal with\nbefore proof-of-stake solutions can actually work. To understand, we need to\nrealize that with proof of work, there is a price to pay to become leader, namely\nusing considerable computational resources. If that price is compensated by\na reward (namely a transaction fee), we have some sort of balance. In many\nproof-of-stake systems, there may also be a reward, but there is no price\nto be paid in advance for becoming a leader. As a result, these systems\nare generally more vulnerable to security attacks, for example, by letting\nparticipants generate invalid transactions that will disrupt the work of honest\nleaders.\nLeader election in blockchains is part of reaching consensus on the status\nof a blockchain. We return to these matters in Section 8.2.6.\nNote 5.7 (Advanced: Selecting superpeers)\nMany leader-election algorithms often concentrate on the selection of only a single\nnode. There are situations when several nodes should actually be selected, such\nas in the case of super peers in peer-to-peer networks, which we discussed in\nSection 2.4.3.\nThe following requirements need to be met for super-peer selection (see\nalso [Lo et al., 2005]):\n1. Normal nodes should have low-latency access to super peers.\n2. Super peers should be evenly distributed across the overlay network.\n3. There should be a predefined portion of super peers relative to the total\nnumber of nodes in the overlay network.\n4. Each super peer should not need to serve more than a fixed number of\nnormal nodes.\nFortunately, these requirements are relatively easy to meet in most peer-to-\npeer systems, given the fact that the overlay network is either structured (as in\nDHT-based systems), or randomly unstructured (as, for example, can be realized\nwith gossip-based solutions). Let us take a look at solutions proposed by Lo et al.\n[2005].\nIn the case of DHT-based systems, the basic idea is to reserve a fraction of\nthe identifier space for super peers. In a DHT-based system, each node receives\na random and uniformly assigned m-bit identifier. Now suppose we reserve the\n \nDS 4.01\n",
      "content_length": 2830,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 310,
      "content": "294\nCHAPTER 5. COORDINATION\nfirst (i.e., leftmost) k bits to identify super peers. For example, if we need N\nsuperpeers, then the first ⌈log2(N)⌉bits of any key can be used to identify these\nnodes.\nTo explain, assume we have a (small) Chord system with m = 8 and k = 3.\nWhen looking up the node responsible for a specific key K, we can first decide\nto route the lookup request to the node responsible for the pattern K ∧11100000\nwhich is then treated as the superpeer. (We use the binary operator “∧” to denote\na bitwise and.) Note that each node with identifier ID can check whether it is a\nsuper peer by looking up ID ∧11100000 to see if this request is routed to itself.\nProvided node identifiers are uniformly assigned to nodes, it can be seen that\nwith a total of N nodes the number of super peers is, on average, equal to 2k−mN.\nFigure 5.23: Moving tokens in a two-dimensional space using repulsion\nforces.\nA different approach is based on positioning nodes in an m-dimensional\ngeometric space. In this case, assume we need to place N super peers evenly\nthroughout the overlay. The basic idea is simple: a total of N tokens are spread\nacross N randomly chosen nodes. No node can hold more than one token. Each\ntoken represents a repelling force by which another token is inclined to move\naway. The net effect is that if all tokens exert the same repulsion force, they will\nmove away from each other and spread themselves evenly in the geometric space.\nThis approach requires that nodes holding a token learn about other tokens. To\nthis end, we can use a gossiping protocol, by which a token’s force is disseminated\nthroughout the network. If a node discovers that the total forces that are acting\non it exceed a threshold, it will move the token in the direction of the combined\nforces, as shown in Figure 5.23. When a token is held by a node for a given\namount of time, that node will promote itself to superpeer.\n5.4.6\nElections in wireless environments\nTraditional election algorithms are generally based on assumptions that are\nnot realistic in wireless environments. For example, they assume that message\npassing is reliable and that the topology of the network does not change.\nThese assumptions are false in most wireless environments, especially when\ndealing with mobile devices.\nOnly few protocols for elections have been developed that work in mobile\nenvironments. Vasudevan et al. [2004] propose a solution that can handle\nDS 4.01\n \n",
      "content_length": 2450,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 311,
      "content": "5.4. ELECTION ALGORITHMS\n295\nfailing nodes and partitioning networks. An important property of their\nsolution is that the best leader can be elected rather than just a random one as\nwas more or less the case in the previously discussed solutions. Their protocol\nworks as follows. To simplify our discussion, we concentrate only on ad hoc\nnetworks and ignore that nodes can actually move. This may be the case, for\nexample, in sensor networks.\nConsider such a wireless ad hoc network. To elect a leader, any node in the\nnetwork, called the source, can initiate an election by sending an ELECTION\nmessage to its immediate neighbors (i.e., the nodes in its range). When a\nnode receives an ELECTION for the first time, it designates the sender as its\nparent, and subsequently sends out an ELECTION message to all its immediate\nneighbors, except for the parent. When a node receives an ELECTION message\nfrom a node besides its parent, it merely acknowledges the receipt.\nWhen node R has designated node Q as its parent, it forwards the\nELECTION message to its immediate neighbors (excluding Q) and waits for\nacknowledgments to come in before acknowledging the ELECTION message\nfrom Q. This waiting has an important consequence. First, note that neighbors\nwho have already selected a parent will immediately respond to R. More\nspecifically, if all neighbors already have a parent, R is a leaf node and will be\nable to report back to Q quickly. In doing so, it will also report information\nsuch as its battery lifetime and other resource capacities.\nThis information will later allow Q to compare R’s capacities to that of\nother downstream nodes, and select the best eligible node for leadership. Of\ncourse, Q had sent an ELECTION message only because its own parent P had\ndone so as well. In turn, when Q eventually acknowledges the ELECTION\nmessage previously sent by P, it will pass the most eligible node to P as well.\nIn this way, the source will eventually get to know which node is best to be\nselected as leader, after which it will broadcast this information to the rest.\nThis process is illustrated in Figure 5.24. Nodes have been labeled a to\nj, along with their capacity. Node a initiates an election by broadcasting\nan ELECTION message to nodes b and j, as shown in Figure 5.24(b) After\nthat step, ELECTION messages are propagated to all nodes, ending with the\nsituation shown in Figure 5.24(e), where we have omitted the last broadcast\nby nodes f and i. From there on, each node reports to its parent the node\nwith the best capacity, as shown in Figure 5.24(f). For example, when node g\nreceives the acknowledgments from its children e and h, it will notice that h\nis the best node, propagating [h, 8] to its own parent, node b. In the end, the\nsource will note that h is the best leader and will broadcast this information\nto all other nodes.\nWhen multiple elections are initiated, each node will decide to join only\none election. To this end, each source tags its ELECTION message with a\nunique identifier. Nodes will participate only in the election with the highest\nidentifier, stopping any running participation in other elections.\n \nDS 4.01\n",
      "content_length": 3153,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 312,
      "content": "296\nCHAPTER 5. COORDINATION\n(a)\n(b)\n(c)\n(d)\n(e)\n(f)\nFigure 5.24: Election algorithm in a wireless network, with node a as the\nsource. (a) Initial network. (b)–(e) The build-tree phase (last broadcast step by\nnodes f and i not shown). (f) Reporting of best node to source.\nDS 4.01\n \n",
      "content_length": 282,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 313,
      "content": "5.5. GOSSIP-BASED COORDINATION\n297\nWith some minor adjustments, the protocol can be shown to operate also\nwhen the network partitions, and when nodes join and leave. The details can\nbe found in Vasudevan et al. [2004].\n5.5\nGossip-based coordination\nAs a next topic in coordination, we take a look at a few important examples\nin which gossiping is deployed. In the following, we look at aggregation,\nlarge-scale peer sampling, and overlay construction, respectively.\n5.5.1\nAggregation\nLet us take a look at some interesting applications of epidemic protocols. We\nalready mentioned spreading updates, which is perhaps the most widely de-\nployed application. In the same light, gossiping can be used to discover nodes\nthat have a few outgoing wide-area links, to subsequently apply directional\ngossiping.\nAnother interesting application area is simply collecting, or actually aggre-\ngating information [Jelasity et al., 2005]. Consider the following information\nexchange. Every node Pi initially chooses an arbitrary number, say vi. When\nnode Pi contacts node Pj, they each update their value as:\nvi, vj ←(vi + vj)/2\nObviously, after this exchange, both Pi and Pj will have the same value. In\nfact, it is not difficult to see that eventually all nodes will have the same\nvalue, namely the average of all initial values. Propagation speed is again\nexponential.\nWhat use does computing the average have? Consider the situation that\nall nodes Pi have set vi to zero, except for P1 who has set v1 to 1:\nvi ←\n(\n1\nif i = 1\n0\notherwise\nIf there are N nodes, then eventually each node will compute the average,\nwhich is 1/N. As a consequence, every node Pi can estimate the size of the\nsystem as being 1/vi.\nComputing the average may be difficult when nodes regularly join and\nleave the system. One practical solution to this problem is to introduce epochs.\nAssuming that node P1 is stable, it simply starts a new epoch now and then.\nWhen node Pi sees a new epoch for the first time, it resets its own variable vi\nto zero and starts computing the average again.\nOf course, other results can also be computed. For example, instead of\nhaving a fixed node such as P1 start the computation of the average, we\n \nDS 4.01\n",
      "content_length": 2204,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 314,
      "content": "298\nCHAPTER 5. COORDINATION\ncan easily pick a random node as follows. Every node Pi initially sets vi\nto a random number from the same interval, say (0, 1], and also stores it\npermanently as mi. Upon an exchange between nodes Pi and Pj, each change\ntheir value to:\nvi, vj ←max{vi, vj}\nEach node Pi for which mi < vi will lose the competition for being the initiator\nin starting the computation of the average. In the end, there will be a single\nwinner. Of course, although it is easy to conclude that a node has lost, it is\nmuch more difficult to decide that it has won, as it remains uncertain whether\nall results have come in. The solution to this problem is to be optimistic: a\nnode always assumes it is the winner until proven otherwise. At that point, it\nsimply resets the variable it is using for computing the average to zero. Note\nthat by now, several computations (in our example, computing a maximum\nand computing an average) may be executing simultaneously.\n5.5.2\nA peer-sampling service\nAn important aspect in epidemic protocols is the ability of a node P to choose\nanother node Q at random from all available nodes in the network. When\ngiving the matter some thought, we may actually have a serious problem:\nif the network consists of thousands of nodes, how can P ever pick one of\nthese nodes at random without having a complete overview of the network?\nFor smaller networks, one could often resort to a central service that had\nregistered every participating node. Obviously, this approach can never scale\nto large networks.\nA solution is to construct a fully decentralized peer-sampling service, or\nPSS for short. As it turns out, and somewhat counter-intuitive, a PSS can be\nbuilt using an epidemic protocol. As explored by Jelasity et al. [2007], each\nnode maintains a list of c neighbors, where, ideally, each of these neighbors\nrepresents a randomly chosen live node from the current set of nodes. This\nlist of neighbors is also referred to as a partial view. There are many ways to\nconstruct such a partial view. In the solution of Jelasity et al., it is assumed that\nnodes regularly exchange entries from their partial view. Each entry identifies\nanother node in the network, and has an associated age that indicates how old\nthe reference to that node is. Two threads are used, as shown in Figure 5.25.\nThe different selection operations are specified as follows:\n• selectPeer: Randomly select a neighbor from the local partial view\n• selectToSend: Select some other entries from the partial view, and add\nto the list intended for the selected neighbor.\n• selectToKeep: Add received entries to the partial view, remove repeated\nitems, and shrink the view to c items.\nDS 4.01\n \n",
      "content_length": 2699,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 315,
      "content": "5.5. GOSSIP-BASED COORDINATION\n299\n1 selectPeer(&Q);\n2 selectToSend(&bufs);\n3 sendTo(Q, bufs);\n4\n5 receiveFrom(Q, &bufr);\n6 selectToKeep(p_view, bufr);\n−→\n←−\n1\n2\n3 receiveFromAny(&P, &bufr);\n4 selectToSend(&bufs);\n5 sendTo(P, bufs);\n6 selectToKeep(p_view, bufr);\n(a)\n(b)\nFigure 5.25: Communication between the (a) active and (b) passive thread in\na peer-sampling service.\nThe active thread takes the initiative to communicate with another node. It\nselects that node from its current partial view. It continues by constructing a\nlist containing c/2 + 1 entries, including an entry identifying itself. The other\nentries are taken from the current partial view. After sending the list to the\nselected neighbor, it waits for a response.\nThat neighbor, meanwhile, will also have constructed a list through the\npassive thread shown in Figure 5.25(b) whose activities strongly resemble that\nof the active thread.\nThe crucial point is the construction of a new partial view. This view, for\ncontacting as well as for the contacted peer, will contain exactly c entries, part\nof which will come from the received list. In essence, there are two ways to\nconstruct the new view. First, the two nodes may decide to discard the entries\nthat they had sent to each other. Effectively, this means that they will swap\npart of their original views. The second approach is to discard as many old\nentries as possible (meaning, in practice, that after every gossiping round, the\nage of each entry in every partial view is incremented by one).\nAs it turns out, as long as peers regularly run the exchange algorithm just\ndescribed, selecting a random peer from a thus dynamically changing partial\nview, is statistically indistinguishable from randomly selecting a peer from\nthe entire network. Of course, selecting a peer from a partial view should\noccur at approximately the same frequency as the refreshing of partial views.\nWe have thus constructed a fully decentralized gossip-based peer-sampling\nservice. A simple and often-used implementation of a peer-sampling service\nis Cyclon [Voulgaris et al., 2005].\n5.5.3\nGossip-based overlay construction\nAlthough it would seem that structured and unstructured peer-to-peer sys-\ntems form strict independent classes, this need actually not be the case (see\nalso Castro et al. [2005]). One key observation is that by carefully exchanging\nand selecting entries from partial views, it is possible to construct and main-\ntain specific topologies of overlay networks. This topology management is\nachieved by adopting a two-layered approach, as shown in Figure 5.26.\n \nDS 4.01\n",
      "content_length": 2593,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 316,
      "content": "300\nCHAPTER 5. COORDINATION\nFigure 5.26: A two-layered approach for constructing and maintaining specific\noverlay topologies using techniques from unstructured peer-to-peer systems.\nThe lowest layer constitutes an unstructured peer-to-peer system in which\nnodes periodically exchange entries of their partial views with the aim to\nprovide a peer-sampling service. Accuracy in this case refers to the fact that\nthe partial view should be filled with entries referring to randomly selected\nlive nodes.\nThe lowest layer passes its partial view to the higher layer, where an\nadditional selection of entries takes place. This then leads to a second list\nof neighbors corresponding to the desired topology. Jelasity and Kermarrec\n[2006] propose to use a ranking function by which nodes are ordered according\nto some criterion relative to a given node. A simple ranking function is to\norder a set of nodes by increasing distance from a given node P. In that case,\nnode P will gradually build up a list of its nearest neighbors, provided the\nlowest layer continues to pass randomly selected nodes.\nAs an illustration, consider a logical grid of size N × N with a node placed\non each point of the grid. Every node is required to maintain a list of c\nnearest neighbors, where the distance between a node at (a1, a2) and (b1, b2)\nis defined as d1 + d2, with di = min(N −|ai −bi|, |ai −bi|). If the lowest layer\nperiodically executes the protocol as outlined in Figure 5.25, the topology that\nwill evolve is a two-dimensional torus, shown in Figure 5.27. In this example,\nN = 50 and we show the results after first initializing each list with random\nentries. Figure 5.27(b) shows the results after five rounds of exchanges, while\nthe final result, shown in Figure 5.27(c) is achieved after 20 rounds.\nNote 5.8 (Advanced:Gossip-based overlay construction in Python)\nTo better appreciate and understand the construction of overlay networks through\ngossiping, let us see what a concrete implementation in Python would look like.\nAs we have mentioned, the principle is simple: we have two separate layers\nand each node is responsible for exchanging links with selected neighbors. A\nstraightforward implementation would seem to be to use a separate thread per\nlayer, as suggested in Figure 5.26. However, such a choice will instantly lead to\npotential deadlock problems. Suppose node A decides to exchange links with\nDS 4.01\n \n",
      "content_length": 2410,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 317,
      "content": "5.5. GOSSIP-BASED COORDINATION\n301\n(a)\n(b)\n(c)\nFigure 5.27: Generating a torus overlay network using a two-layered unstruc-\ntured peer-to-peer system.\nnode B, but B has chosen another node, say C for exchanging links. If C chooses A\nfor exchanging links, we may have a deadlock if these three nodes first collectively\nchoose their respective neighbor for exchanging links, and then collectively wait\nfor that neighbor to respond.\nThe general solution to this problem is to essentially avoid synchronous\nrequest-response behavior, but instead to use asynchronous, persistent com-\nmunication. In other words, we let the middleware store a message before it\nis delivered, after which the sender can continue doing other things. This type\nof communication is precisely supported by the channel package used for many\nof our Python examples. The outline of the code is shown in Figure 5.28. (The\ncomplete code is readily available as accompanying online material for the book.)\nNote that for each layer, the approach is essentially always the same: select a\npeer, decide on the links to exchange, and send that information asynchronously\nto the selected peer. Thereafter, a node that initiated an exchange will have to\nwait for a response. When that comes in, it merely needs to update its own view.\n(There are many subtleties that need to be considered, which we will discuss\nshortly.) In principle, there will be a regular call to maintainViews(), if only to\nensure that a node will also react to incoming exchange requests. Note that in our\nsolution, we simply let a node ignore an incoming exchange request when it has\nan outstanding initiated exchange itself. Ignoring a request is done by telling the\ninitiating node to give up its own attempt. Although this approach will prevent\ndeadlocks, it bears the risk that no exchange will take place at all.\nAs mentioned, the actual code for handling gossip-based overlay construction\ninvolves more than what we have shown in Figure 5.28. Crucial are the criteria\nfor selecting a neighboring peer, as well as the selection of links to exchange. As\nexplained by Voulgaris and van Steen [2013], there are several things that can be\ndone to speed up convergence of the overlay in comparison to random choices.\nAt the same time, including random choices is essential to achieve convergence to\nthe requested overlay.\nIn the first place, at the top layer for constructing the overlay, links should\nbe exchanged that make most sense for the receiving peer. In our example, this\n \nDS 4.01\n",
      "content_length": 2524,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 318,
      "content": "302\nCHAPTER 5. COORDINATION\nmeans that when a node A sends links to a node B, it should select the ones to\nneighbors that are closest to B. Furthermore, B should not return links that A had\njust sent: it is much better that A learns about new nodes first.\n1 def maintainViews():\n2\nfor viewType in [viewOverlay, viewPSS]: # For each view, do the same\n3\npeer[viewType] = None\n4\nif time to maintain viewType: # This viewType needs to be updated\n5\npeer[viewType] = selectPeer(viewType)\n# Select a peer\n6\nlinks = selectLinks(viewType, peer[viewType])\n# Select links\n7\nsendTo(peer[viewType], Request[viewType], links) # Send links asynchronously\n8\n9\nwhile True:\n10\nblock = (peer[viewOverlay] != None) or (peer[viewPSS] != None)\n11\nsender, msgType, msgData = recvFromAny(block) # Block if expecting something\n12\n13\nif msg == None: # All work has been done, simply return from the call\n14\nreturn\n15\n16\nfor viewType in [viewOverlay, viewPSS]: # For each view, do the same\n17\nif msgType == Response[viewType]:\n# Response to previously sent links\n18\nupdateOwnView(viewType, msgData) # Just update the own view\n19\n20\nelif msgType == Request[viewType]: # Request for exchanging links\n21\nif peer[viewType] == None:\n# No outstanding exchange request\n22\nlinks = selectLinks(viewType, sender)\n# Select links\n23\nsendTo(sender, Response[viewType], links) # Send them asynchronously\n24\nupdateOwnView(viewType,msgData)\n# Update own view\n25\nelse: # This node already has a pending exchange request, ignore this one\n26\nsendTo(sender, IgnoreRequest[viewType])\n27\n28\nelif msgType == IgnoreRequest[viewType]: # Request has been denied, give up\n29\npeer[viewType] = None\nFigure 5.28: Pseudocode in Python for implementing a gossip-based\napproach toward overlay construction.\nMoreover, when A selects a peer, we should try to prevent selecting one with\nwhich a recent exchange has taken place. In other words, A should try to maximize\ndiversity in selecting a peer. This diversity can be obtained by selecting peers\nin a round-robin fashion. This approach also has the benefit that in a dynamic\nnetwork, nodes that have left are guaranteed to be discovered quickly and can\nthus be removed from a view.\nIf we were to use only the top layer, the greediness of exchanging only\nbest links may lead to a situation that a collection of nodes will jointly form\na closed set within the network: jointly, they are referring to each other and\nas such, may be missing out on better nodes. This is the reason introducing\nrandomness is essential, and why we need to incorporate information from the\nlower random overlay in the selection process of the higher structured overlay.\nDS 4.01\n \n",
      "content_length": 2647,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 319,
      "content": "5.5. GOSSIP-BASED COORDINATION\n303\nThis aspect is completely analogous to getting stuck in a local optimum when\noptimizing through hill-climbing procedures. What is needed is to introduce\nsome randomness to ensure that indeed a global optimum will eventually be\nreached.\n5.5.4\nSecure gossiping\nGossiping is an attractive means for coordination. However, the speed by\nwhich a large collection of nodes manages to synchronize, is also an inherent\nvulnerability. The time it takes to exchange and disseminate proper informa-\ntion is also the time it takes to spread false information. This is perhaps best\nillustrated by means of an example. Consider a peer-sampling service for\nsome large network. Assume that each node maintains a partial view of size c,\nand that, on average, c/2 references to neighboring nodes are exchanged. Let\nus also assume that there are c colluding attackers. Their behavior is simple:\neach attacker also maintains a partial view, but when returning c/2 references,\nonly references to other colluding attackers are returned. The effect is that,\ngradually, the partial view of each benign node in the network is polluted by\nreferences to the attackers, to the extent that each partial view contains only\nreferences to attackers.\nFigure 5.29: The speed by which a hub attack can take effect.\nThe effect can be dramatic. Figure 5.29 shows the speed by which partial\nviews are fully polluted, that is, each contains references only to attackers.\nIn this example, we consider a network of 100,000 nodes, a partial view size\nof 30, and only 30 attackers. After less than 300 rounds, all benign nodes\nhave fully polluted partial views. Also note that, completely consistent with\nthe push-pull behavior of epidemic protocols, it may take a while before any\nserious effect is seen. However, as soon as a few hundred nodes are completely\n \nDS 4.01\n",
      "content_length": 1862,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 320,
      "content": "304\nCHAPTER 5. COORDINATION\npolluted, they increasingly contribute to contaminating the rest of the nodes,\nand so on.\nIt can be argued that there is no standard security measure that can combat\nthese kinds of attacks. For example, even with using secure channels by which\nboth parties have genuinely authenticated each other, there is no reason to\nassume that both of them will also behave as they should. In other words,\nauthentication provides no guarantees for trust. In the case of gossiping\nsystems, security often comes in the form of trying to detect and prevent\nmalicious behavior. For our example, the question is how can a benign node\ncan detect that it is under attack, and which countermeasures can it take to\nmitigate the effects of an attack?\nA solution in the case of peer sampling, and developed by Jesi et al. [2010],\nworks as follows. The essence is to discover if there are nodes that behave\nbadly. The attack we just described is characterized by the fact that, eventually,\nmany nodes will be referencing a very small of set of nodes. In terms of\ngraphs, this means that the indegree of some nodes is extraordinarily high,\nwhile for most nodes, their indegree will be low, and actually 0. An indegree\nof 0 means that a node is unknown to any other node in the network.\nWhen using Cyclon [Voulgaris et al., 2005] as the peer-sampling service,\nwe know that the indegrees follow a normal distribution, as shown in Fig-\nure 5.30(a). In this example, the y-axis shows the fraction of nodes with a\nspecific indegree value. Even with a mere 30 colluding attackers, we already\nsee that after 10 rounds, the indegree distribution has started to becoming\nwider and shifting to the left, as shown in Figure 5.30(b). This continues,\nand after 40 rounds (Figure 5.30(e)), we already have that about 15% of all\nnodes have an indegree of 0. (Note that for Figure 5.29, we were counting\nthe number of nodes that were referencing only attacking nodes, which is\ndifferent from measuring indegrees. An attacked node can still be referenced\nby others.) Finally, after less than 300 rounds, virtually all nodes have an\nindegree of 0; the attackers have now full control over the entire network.\nFigure 5.30 also gives us a hint toward a solution. As explained by Jesi et al.\n[2010], each node can gather statistics on which nodes are being referenced.\nIf certain nodes are gradually being referenced unusually more often than\nothers, then something fishy may be going on. There are a few issues we\nneed to deal with. First, spreading of “bad” links can be so efficient, that\nwe need to consider that once a benign node has come to the conclusion\nthat it has identified an attacker, it may already be too late. Second, we also\nwant to prevent that every benign node has to build up complete knowledge\nof the entire network, partly also because attackers have to be identified\nquickly. Third, attackers do not want to be caught, i.e., be recognized as acting\nmaliciously, as they collectively do need some time to be successful.\nNotably the last aspect, not wanting to be caught, provides a solution to\nmitigating an attack. In essence, a benign node can force an attacker to behave\nDS 4.01\n \n",
      "content_length": 3190,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 321,
      "content": "5.5. GOSSIP-BASED COORDINATION\n305\n(a)\n(b)\n(c)\n(d)\n(e)\n(f)\nFigure 5.30: The development of the indegree distribution at several stages of\na peer-sampling service under attack. Each x-axis shows the indegree, and\nthe y-axis the fraction of nodes with that degree.\n \nDS 4.01\n",
      "content_length": 273,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 322,
      "content": "306\nCHAPTER 5. COORDINATION\naccording to the rules. What happens is that when a benign node initiates\nan exchange of links with a selected node, it will process the returned links\neither for updating its own partial view, or for gathering statistics (it may do\nboth, but this may not be on par with efficient resource usage). Moreover, to\naccelerate the process of discovering attackers, a node will initiate several link\nexchanges simultaneously (and, in the end, process only one of the replies). A\nmalicious node is now faced with a dilemma: always returning references to\nits colluders will quickly reveal the attackers. The only thing that it can do, is\noccasionally play by the rules and return links to other, benign nodes. As it\nturns out, this dilemma is enough to force the attackers to behave decently\nenough, effectively rendering an attack useless. Note that this procedure will\nalso be applied when an attacker initiates an exchange: the recipient can decide\nto use the links passed to it for updating its statistics on indegrees, as well as\nuse it for running the exchange protocol. The attacker will, however, never\nknow whether the recipient is going to collect statistics. To fly under the radar,\nit will have to behave according to the rules of the game enough in order not\nto be caught. The details can be found in [Jesi et al., 2010].\nThere are many other types of attacks possible. For example, attackers\nmay decide to initiate information exchange at a much higher frequency than\nspecified by the protocol. With a push-based approach, this may result in\nattackers rapidly polluting values of benign nodes, which are then further\ndisseminated. Mousazadeh and Ladani [2015] come to the conclusion that for\nsuch attacks, in principle, only pulling should be allowed (as the benign nodes\nwill then collectively dictate the pace at which information is disseminated).\nLikewise, in the case of aggregation, attackers may deliberately return\nincorrect values. To illustrate, suppose that when collectively computing the\naverage value as we described in Section 5.5.1, an attacker A always returns its\nown value vA. Every node vi communicating with A will therefore compute\nvi ←(vi + vA)/2\nwhich gradually converges to the value vA. In all these cases, attacks can\nbe mitigated only by trying to detect if a node is not behaving according to\nthe protocol. That detection mechanism, of course, should be known to the\nattacker, while at the same time will be effective if it forces an attacker to try\nto go ahead unnoticed. In turn, if well designed, the mechanism will force\nthe attacker to actually behave well, or at least to the extent that any possible\ndamage remains limited. More on how these data-injection attacks work and\ncan be mitigated, are described by Gentz et al. [2016].\n5.6\nDistributed event matching\nLet us now draw our attention to distributed event matching. Event matching,\nor more precisely, notification filtering, is at the heart of publish-subscribe\nsystems. The problem boils down to the following:\nDS 4.01\n \n",
      "content_length": 3049,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 323,
      "content": "5.6. DISTRIBUTED EVENT MATCHING\n307\n• A process specifies through a subscription S in which events it is inter-\nested.\n• When a process publishes a notification N on the occurrence of an event,\nthe system needs to see if S matches N.\n• In the case of a match, the system should send the notification N, possibly\nincluding the data associated with the event that took place, to the\nsubscriber.\nAs a consequence, we need to facilitate at least two things: (1) matching\nsubscriptions against events, and (2) notifying a subscriber in the case of a\nmatch. The two can be separated, but this need not always be the case. In the\nfollowing, we assume the existence of a function match(S, N) which returns\ntrue when subscription S matches the notification N, and false otherwise. As\nwe argue below, publish-subscribe systems turn out to face difficult scalability\nproblems when the matching function cannot be easily distributed across\nmultiple servers. This is often the case when subscriptions can be expressive,\nas in content-based publish-subscribe systems.\nWe discuss scalability of\ndistributed event matching separately below.\nAnother, rather nasty problem, is combining security and privacy while\nkeeping publishers and subscribers mutually unaware of each other, but also\nensuring that servers have only enough information available to perform\ntheir matching function. In this sense, it may seem that the goals of publish-\nsubscribe systems, and those of secure distributed systems conflict. We return\nto this issue below as well.\n5.6.1\nCentralized implementations\nA simple, naive implementation of event matching is to have a fully centralized\nserver that handles all subscriptions and notifications. In such a scheme, a\nsubscriber simply submits a subscription, which is subsequently stored. When\na publisher submits a notification, that notification is checked against each\nand every subscription, and when a match is found, the notification is copied\nand forwarded to the associated subscriber.\nObviously, this is not a very scalable solution. Nevertheless, provided\nthe matching can be done efficiently and the server itself has enough pro-\ncessing power, the solution is feasible for many cases. For example, using\na centralized server is the canonical solution for implementing Linda tuple\nspaces. Likewise, many publish-subscribe systems that run within a single\ndepartment or organization can be implemented through a central server.\nImportant, in these cases, is that the matching function can be implemented\nefficiently. In practice, this is often the case when dealing with topic-based\nfiltering: matching then resorts to checking for equality of attribute values.\n \nDS 4.01\n",
      "content_length": 2687,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 324,
      "content": "308\nCHAPTER 5. COORDINATION\nNote that a simple way to scale up a centralized implementation, is to de-\nterministically divide the work across multiple servers. A standard approach\nis to make use of two functions, as explained by Baldoni et al. [2009]:\n• a function sub2node(S), which takes a subscription S and maps it to a\nnonempty subset of servers\n• a function not2node(N), which takes a notification N and maps it to a\nnonempty subset of servers.\nThe servers to which sub2node(S) is mapped are called the rendezvous nodes\nfor S.\nLikewise, sub2node(N) are the rendezvous nodes for N.\nThe only\nconstraint that needs to be satisfied, is that for any subscription S and matching\nnotification N, sub2node(S) ∩not2node(N) ̸= ∅. In other words, there must be\nat least one server that can handle the subscription when there is a matching\nnotification. In practice, this constraint is satisfied by topic-based publish-\nsubscribe systems by using a hashing function on the names of the topics.\nThe idea of having a central server can be extended by distributing the\nmatching across multiple servers and dividing the work. The servers, generally\nreferred to as brokers, are organized into an overlay network. The issue then\nbecomes how to route notifications to the appropriate set of subscribers. A\nstraightforward way to make sure that notifications reach their subscribers, is\nto deploy flooding. There are essentially two approaches. First, we store each\nsubscription at every broker, while publishing notifications only at a single\nbroker. The latter will handle identifying the matching subscriptions and\nsubsequently copy and forward the notification. The alternative is to store a\nsubscription only at one broker, while broadcasting notifications to all brokers.\nIn that case, matching is distributed across the brokers, which may lead to a\nmore balanced workload among the brokers.\nNote 5.9 (Example: TIB/Rendezvous)\nFlooding notifications is used in TIB/Rendezvous, of which the basic archi-\ntecture is shown in Figure 5.31 [TIBCO]. In this approach, a notification is\na message tagged with a compound keyword describing its content, such as\nnews.comp.os.books. A subscriber provides (parts of) a keyword, or indicating the\nmessages it wants to receive, such as news.comp. ∗.books. These keywords are\nsaid to indicate the subject of a message.\nFundamental to its implementation is the use of broadcasting common in\nlocal-area networks, although it also uses more efficient communication facilities\nwhen possible. For example, if it is known exactly where a subscriber resides,\npoint-to-point messages will generally be used. Each host on such a network will\nrun a rendezvous daemon, which takes care that messages are sent and delivered\naccording to their subject. Whenever a message is published, it is multicasted to\neach host on the network running a rendezvous daemon. Typically, multicasting\nDS 4.01\n \n",
      "content_length": 2910,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 325,
      "content": "5.6. DISTRIBUTED EVENT MATCHING\n309\nis implemented using the facilities offered by the underlying network, such as\nIP-multicasting or hardware broadcasting.\nNetwork\nMulticast message on B to subscribers\nMulticast message\non A to subscribers\nSubj: A\nPubl. on A\nRV\ndaemon\nRV lib\nSubs. to A\nRV\ndaemon\nRV lib\nSubj: B\nRV\ndaemon\nRV lib\nSubs. to A\nPubl. on B\nRV\ndaemon\nRV lib\nSubs. to A\nSubs. to B\nRV\ndaemon\nRV lib\nSubs. to B\nFigure 5.31: The principle of a publish/subscribe system as implemented\nin TIB/Rendezvous.\nProcesses that subscribe to a subject pass their subscription to their local\ndaemon. The daemon constructs a table of (process, subject), entries and whenever\na message on subject S arrives, the daemon simply checks in its table for local\nsubscribers, and forwards the message to each one. If there are no subscribers for\nS, the message is discarded immediately.\nWhen using multicasting as is done in TIB/Rendezvous, there is no reason\nwhy subscriptions cannot be elaborate and be more than string comparison, as\nis currently the case. The crucial observation here is that because messages are\nforwarded to every node anyway, the potentially complex matching of published\ndata against subscriptions can be done entirely locally without further network\ncommunication needed.\nWhen subscriptions are allowed to be more expressive, scalability may\neasily become a problem. In practice, expressive subscriptions take the form\nof (attribute,value) pairs in which a value returns as an expression on the\npossible values for the specified attribute. Examples include range values\n(“1 ≤x < 10”), containment (“x ∈{red, blue}”), prefix and suffix expressions\n(“url.startswith(“https”)”), etc. More complicated expressions including\ncombinations of conjunctions and disjunctions are, in theory, also possible,\nthus gradually resembling what one would find in SQL queries for databases.\nIt is not hard to imagine that expressive subscriptions can be handled by\ncentralized brokers, but when scalability is at stake, we may need to limit\nexpressiveness altogether to the point that we find ourselves looking at topic-\nbased event matching.\nOne way out that has been explored is combining peer-to-peer networks\nand publish-subscribe systems, as described in Kermarrec and Triantafillou\n[2013]. As the authors show, there is no simple general solution, and most\nsolutions often have very specific limitations.\n \nDS 4.01\n",
      "content_length": 2415,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 326,
      "content": "310\nCHAPTER 5. COORDINATION\nSelective routing\nIf we consider that publish-subscribe is all about routing messages between\npublishers and subscribers, one thought is to install specific filters in an overlay\nnetwork that effectively ignore paths toward nodes that are not interested in\nwhat is being published. In other words, instead of flooding a network with\neither subscriptions or publications, we apply selective routing, as proposed\nby Carzaniga et al. [2004]. Consider a publish-subscribe system consisting\nof N brokers to which clients (i.e., applications) can send subscriptions and\nretrieve notifications. Carzaniga et al. propose a two-layered routing scheme,\nin which the lowest layer consists of a shared broadcast tree connecting the\nN brokers. There are various ways for setting up such a tree, ranging from\nnetwork-level multicast support to application-level multicast trees, as we\ndiscussed in Chapter 4. Here, we also assume that such a tree has been set\nup with the N brokers as end nodes, along with a collection of intermediate\nnodes forming routers. Note that the distinction between a server and a router\nis only a logical one: a single machine may host both kinds of processes.\n(a)\n(b)\nFigure 5.32: A first approach toward content-based routing in which brokers\n(a) first broadcast subscriptions to later (b) forward notifications only to\nrelevant brokers.\nEvery broker broadcasts its subscriptions to all other brokers, as shown\nin Figure 5.32(a). As a result, every broker will be able to compile a list of\n(subject, destination) pairs. Then, whenever a process publishes a notification\nN, its associated broker prepends the destination brokers to that message and\nforwards the notification to the others, shown in Figure 5.32(b). When the\nmessage reaches a router, the latter can use the list to decide on the paths that\nthe message should follow, as shown in Figure 5.32.\nWe can now refine the capabilities of routers for deciding where to forward\nnotifications. To that end, each broker broadcasts its subscription across the\nnetwork so that routers can compose routing filters. For example, assume\nthat node 3 in Figure 5.32 subscribes to notifications for which an attribute a\nlies in the range [0, 3], but that node 4 wants messages with a ∈[2, 5]. In this\nDS 4.01\n \n",
      "content_length": 2300,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 327,
      "content": "5.6. DISTRIBUTED EVENT MATCHING\n311\ncase, router R2 will create a routing filter as a table with an entry for each of\nits outgoing links (in this case three: one to node 3, one to node 4, and one\ntoward router R1), as shown in Figure 5.33.\nInterface\nFilter\nTo node 3\na ∈[0, 3]\nTo node 4\na ∈[2, 5]\nToward router R1\n(unspecified)\nFigure 5.33: A partially filled routing table.\nMore interesting is what happens at router R1.\nIn this example, the\nsubscriptions from nodes 3 and 4 dictate that any notification with a lying in\nthe interval [0, 3] ∪[2, 5] = [0, 5] should be forwarded along the path to router\nR2, and this is precisely the information that R1 will store in its table. It is\nnot difficult to imagine that more intricate subscription compositions can be\nsupported.\nThis simple example also illustrates that whenever a node leaves the\nsystem, or when it is no longer interested in specific notifications, it should\ncancel its subscription and essentially broadcast this information to all routers.\nThis cancellation, in turn, may lead to adjusting various routing filters. Late\nadjustments will at worst lead to unnecessary traffic, as notifications may be\nforwarded along paths for which there are no longer subscribers. Nevertheless,\ntimely adjustments are needed to keep performance at an acceptable level.\nGossiping\nSelective routing may help to avoid broadcasting notifications to all routers,\nbut ultimately, it may still not be enough to reach acceptable scalable solutions.\nAnother approach is based on gossiping. The basic idea is that subscribers\ninterested in the same notifications form their own overlay network (which\nis constructed through gossiping as we describe further below), so that once\na notification is published, it merely needs to be routed to the appropriate\noverlay. For the latter, a random walk can be deployed. This approach is\nfollowing in TERA [Baldoni et al., 2007].\nA more sophisticated approach toward combining gossiping and event\nmatching is followed in Sub-2-Sub [Voulgaris et al., 2006]. It is still one\nof the very few content-based approaches that combines scalability with\nexpressiveness of subscriptions.\nConsider a publish-subscribe system in\nwhich data items can be described by N attributes a1, . . . , aN whose value\ncan be directly mapped to a floating-point number. Such values include, for\nexample, floats, integers, enumerations, Booleans, and strings. A subscription\nS takes the form of a tuple of (attribute, value/range) pairs, such as\nS = ⟨a1 →3.0, a4 →[0.0, 0.5)⟩\n \nDS 4.01\n",
      "content_length": 2539,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 328,
      "content": "312\nCHAPTER 5. COORDINATION\nIn this example, S specifies that a1 should be equal to 3.0, and a4 should lie in\nthe interval [0.0, 0.5). Other attributes are allowed to take on any value. For\nclarity, assume that every node i enters only one subscription Si.\nNote that each subscription Si actually specifies a subset Si in the N-\ndimensional space of floating-point numbers. Such a subset is also called a\nhyperspace. For the system as a whole, notifications that fall in the union\nS = ∪Si of these hyperspaces are the only ones of interest. The whole idea is\nto automatically partition S into M disjoint hyperspaces S1, . . . , SM such that\neach falls completely in one of the subscription hyperspaces Si, and together\nthey cover all subscriptions. More formally, we have that:\n(Sm ∩Si ̸= ∅) ⇒(Sm ⊆Si)\nSub-2-Sub keeps M minimal in the sense that there is no partitioning with\nfewer parts Sm. To this end, for each hyperspace Sm, it registers exactly those\nnodes i for which Sm ⊆Si. In that case, when a notification is published, the\nsystem need merely find the Sm to which the associated event belongs, from\nwhich point it can forward the notification to the appropriate nodes.\nTo this end, nodes regularly exchange subscriptions through gossiping. If\ntwo nodes i and j notice that their respective subscriptions intersect, that is,\nSij ≡Si ∩Sj ̸= ∅they will record this fact and keep references to each other.\nIf they discover a third node k with Sijk ≡Sij ∩Sk ̸= ∅, the three of them\nwill connect to each other so that a notification N from Sijk can be efficiently\ndisseminated. Note that if Sij −Sijk ̸= ∅, nodes i and j will maintain their\nmutual references, but now associate it strictly with Sij −Sijk.\nIn essence, what we are seeking is a means to cluster nodes into M different\ngroups, such that nodes i and j belong to the same group if and only if their\nsubscriptions Si and Sj intersect. Moreover, nodes in the same group should\nbe organized into an overlay network that allows efficient dissemination of a\ndata item in the hyperspace associated with that group. This situation for a\nsingle attribute is sketched in Figure 5.34.\nHere, we see a total of seven nodes, in which the horizontal line for node\ni indicates its range of interest for the value of the single attribute. Also\nshown is the grouping of nodes into disjoint ranges of interests in values of\nthe attribute. For example, nodes 3, 4, 7, and 10 will be grouped together\nrepresenting the interval [16.5, 21.0]. Any data item with a value in this range\nshould be disseminated to only these four nodes.\nTo construct these groups, the nodes are organized into a gossip-based\nunstructured network. Each node maintains a list of references to other\nneighbors (i.e., a partial view), which it periodically exchanges with one of\nits neighbors. Such an exchange allows a node to learn about random other\nnodes in the system. Every node keeps track of the nodes it discovers with\noverlapping interests (i.e., with an intersecting subscription).\nAt a certain moment, every node i will generally have references to other\nnodes with overlapping interests. As part of exchanging information with a\nDS 4.01\n \n",
      "content_length": 3171,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 329,
      "content": "5.6. DISTRIBUTED EVENT MATCHING\n313\nFigure 5.34: Grouping nodes for supporting range queries in a gossip-based\npublish-subscribe system.\nnode j, node i orders these nodes by their identifiers and selects the one with\nthe lowest identifier i1 > j, such that its subscription overlaps with that of\nnode j, that is, Sj,i1 ≡Si1 ∩Sj ̸= ∅.\nThe next one to be selected is i2 > i1 such that its subscription also overlaps\nwith that of j, but only if it contains elements not yet covered by node i1. In\nother words, we should have that Sj,i1,i2 ≡(Si2 −Sj,i1) ∩Sj ̸= ∅. This process\nis repeated until all nodes that have an overlapping interest with node i have\nbeen inspected, leading to an ordered list i1 < i2 < · · · < in. Note that a node\nik is in this list because it covers a region R of common interest to node i and j\nnot yet jointly covered by nodes with a lower identifier than ik. In effect, node\nik is the first node that node j should forward a notification to that falls in this\nunique region R. This procedure can be expanded to let node i construct a\nbidirectional ring. Such a ring is also shown in Figure 5.34.\nWhenever a notification N is published, it is disseminated as quickly\nas possible to any node that is interested in it. As it turns out, with the\ninformation available at every node finding a node i interested in N is simple.\nFrom there on, node i need simply forward N along the ring of subscribers for\nthe particular range that N falls into. To speed up dissemination, shortcuts\nare maintained for each ring as well.\n5.6.2\nSecure publish-subscribe solutions\nA characteristic feature of publish-subscribe systems is that publishers and\nsubscribers are referentially decoupled, and possibly also temporally decou-\npled. Notably, referential decoupling means that in a secure system messages\nshould be able to flow from a publisher to subscribers while guaranteeing\nmutual anonymity. To guarantee confidentiality and integrity of messages,\ncommunicating parties usually set up a secure channel, but such an approach\nwould break the party’s anonymity.\n \nDS 4.01\n",
      "content_length": 2080,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 330,
      "content": "314\nCHAPTER 5. COORDINATION\nA simple solution is to let a (possibly distributed) broker handle messages.\nThe broker would handle all the matching and storage, if necessary. Obviously,\nsuch a broker would need to be trusted. Yet, it is not obvious at all that such\ntrust is justified. For example, many publish-subscribe services are offered by\nthird parties operating in a cloud setting. It is often unclear to which extent\nthey can actually provide guarantees when it comes to protecting data. In\naddition, messages may often contain information that should definitely not,\noften even by law, be revealed to third parties, such as medical records.\nWe now seem to have several clashing requirements. First, for any publish-\nsubscribe system, we need to ensure that the communicating parties remain\nreferentially decoupled, that is, we need to guarantee mutual anonymity. Not\nknowing where messages come from imposes integrity issues: how can we be\nsure the messages have not been tampered with? Second, we cannot simply\nassume that brokers can be trusted. Facing confidentiality issues, we then\ncannot allow them to see (all of) the content of messages, yet this may impose\nserious routing problems. But there is more: if we cannot trust brokers, how\ncan we ensure availability in the sense that subscribers, entitled to specific\nmessages, actually receive those messages? Equally important is to ensure\nthat messages are not delivered to unauthorized subscribers. Cui et al. [2021]\nalso address an additional requirement: assuming there are colluders in place,\nbrokers should not learn about the interests of innocent subscribers.\nThese problems are not unique to publish-subscribe systems, and have\nbecome more prevalent with the advent of cloud-based services. The key\nquestion is how to let a third party search through data to make decisions,\nyet without revealing that data. This is also known as searchable encryp-\ntion [Bosch et al., 2014]. For publish-subscribe systems, an important tech-\nnique is to conduct secure keyword search. Boneh et al. [2004] introduced\nPublic Key Encryption with Keyword Search, generally known as PEKS. We\nwill explain only the principle of PEKS without going into the cryptographic\ndetails.\nIn PEKS, a message is accompanied by a collection of keywords. To that\nend, using a public key PK, a message m and its n keywords KW1, . . . , KWn\nare stored at a server as the message m∗:\nm∗= [PK(m)|PEKS(PK, KW1)|PEKS(PK, KW2)| · · · |PEKS(PK, KWn)]\nFor each keyword KWi a trapdoor TKWi is generated: TW(m∗) will return true\nif W ∈{KW1, . . . , KWn} and false otherwise.\nUsing PEKS, we can now set up a cloud-based publish-subscribe system\nwith (conceptually) a single broker that resides in the cloud. Such a scheme is\ndescribed in [Yang et al., 2017] and sketched in Figure 5.35. We note we have\ndeliberately simplified matters significantly to focus on the essentials.\nAn important role is played by the key authority: a trusted third party that\ngenerates keys for publishers and subscribers. In our example, it provides the\nDS 4.01\n \n",
      "content_length": 3069,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 331,
      "content": "5.7. LOCATION SYSTEMS\n315\nFigure 5.35: The principle of privacy-preserving publish-subscribe.\npublisher with a key PK that can be used for encrypting the publication m. In\naddition, the key is used for constructing the encrypted tags KW∗\ni = PEKS(PK,\nKWi). Likewise, each subscriber is given a secret key SK that it can use to\ngenerate a trapdoor TW to be used by the broker to see whether the tag W\nis associated with the publication m. If there is a match, the broker returns\nPK(m) which can then be decrypted using SK.\nOur simplified scheme misses many important details, for which we refer\nthe interested reader to Yang et al. [2017]. The authors assume that the broker\nis honest-but-curious and does not collude with publishers or subscribers.\nHonest-but-curious means that the server will behave according to the specifi-\ncations, but may keep track of everything it does and use that information.\nCui et al. [2021] describe a system that drops the assumption on collusion, and\nis one of the few known publish-subscribe systems that can handle colluding\nbrokers. An overview of the security issues in publish-subscribe systems is\ngiven by Uzunov [2016]. For a good overview on preserving confidentiality,\nwe refer to Onica et al. [2016]. The authors also come to the conclusion that\nsecurity becomes easier if brokers can be trusted. Otherwise, good support\nfor operating on encrypted data is needed.\n5.7\nLocation systems\nWhen looking at large distributed systems that are dispersed across a wide-\narea network, it is often necessary to take proximity into account. Just imagine\na distributed system organized as an overlay network in which two processes\nare neighbors in the overlay network, but are actually placed far apart in\nthe underlying network. If these two processes communicate a lot, it may\nhave been better to ensure that they are also physically placed in each other’s\nproximity. In this section, we take a look at location-based techniques to\ncoordinate the placement of processes and their communication.\n5.7.1\nGPS: Global Positioning System\nLet us start by considering how to determine your geographical position\nanywhere on Earth. This positioning problem is by itself solved through\na highly specific, dedicated distributed system, namely GPS, which is an\n \nDS 4.01\n",
      "content_length": 2291,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 332,
      "content": "316\nCHAPTER 5. COORDINATION\nacronym for Global Positioning System. GPS is a satellite-based distributed\nsystem that was launched in 1978. Although it initially was used mainly for\nmilitary applications, it by now has found its way to many civilian applications,\nnotably for traffic navigation. However, many more application domains exist.\nFor example, modern smartphones now allow owners to track each other’s\nposition. This principle can easily be applied to tracking other things as well,\nincluding pets, children, cars, boats, and so on.\nGPS uses up to 72 satellites, each circulating in an orbit at a height of\napproximately 20,000 km. Each satellite has up to four atomic clocks, which\nare regularly calibrated from special stations on Earth. A satellite continuously\nbroadcasts its position, and time stamps each message with its local time. This\nbroadcasting allows every receiver on Earth to accurately compute its own\nposition using, in principle, only four satellites. To explain, let us first assume\nthat all clocks, including the receiver’s, are synchronized.\nTo compute a position, consider first the two-dimensional case, as shown\nin Figure 5.36, in which three satellites are drawn, along with the circles\nrepresenting points at the same distance from each respective satellite. We see\nthat the intersection of the three circles is a unique point.\nFigure 5.36: Computing a node’s position in a two-dimensional space.\nThis principle of intersecting circles can be expanded to three dimensions,\nmeaning that we need to know the distance to four satellites to determine the\nlongitude, latitude, and altitude of a receiver on Earth. This positioning is\nall fairly straightforward, but determining the distance to a satellite becomes\ncomplicated when we move from theory to practice. There are at least two\nimportant real-world facts that we need to take into account:\n1. It takes a while before data on a satellite’s position reaches the receiver.\n2. The receiver’s clock is generally not in sync with that of a satellite.\nDS 4.01\n \n",
      "content_length": 2045,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 333,
      "content": "5.7. LOCATION SYSTEMS\n317\nAssume that the timestamp from a satellite is completely accurate. Let\n∆r denote the deviation of the receiver’s clock from the actual time. When a\nmessage is received from satellite Si with timestamp Ti, then the measured\ndelay ∆i by the receiver consists of two components: the actual delay, along\nwith its own deviation:\n∆i = (Tnow −Ti) + ∆r\nwhere Tnow is the actual current time. As signals travel with the speed of light,\nc, the measured distance ˜di to satellite Si is equal to c · ∆i. With\ndi = c · (Tnow −Ti)\nbeing the real distance between the receiver and satellite Si, the measured\ndistance can be rewritten to ˜di = di + c · ∆r. The real distance is now computed\nas:\n˜di −c · ∆r =\nq\n(xi −xr)2 + (yi −yr)2 + (zi −zr)2\nwhere xi, yi, and zi denote the coordinates of satellite Si. What we see now is\na system of quadratic equations with four unknowns (xr, yr, zr, and also ∆r).\nWe thus need four reference points (i.e., satellites) to find a unique solution\nthat will also give us ∆r. A GPS measurement will thus also give an account\nof the actual time.\nSo far, we have assumed that measurements are perfectly accurate. Of\ncourse, they are not. There are many sources of errors, starting with the\nfact that the atomic clocks in the satellites are not always in perfect sync, the\nposition of a satellite is not known precisely, the receiver’s clock has a finite\naccuracy, the signal propagation speed is not constant (as signals appear to\nslow down when entering, e.g., the ionosphere), and so on. On average, this\nleads to an error of some 5–10 meters. Special modulation techniques, as\nwell as special receivers, are needed to improve accuracy. Using so-called\ndifferential GPS, by which corrective information is sent through wide-area\nlinks, accuracy can be further improved. More information can be found in\n[LaMarca and de Lara, 2008], as well as an excellent overview by Zogg [2002].\n5.7.2\nWhen GPS is not an option\nA major drawback of GPS is that it generally cannot be used indoors. For that\npurpose, other techniques are necessary. An increasingly popular technique\nis to make use of the numerous WiFi access points available. The basic idea\nis simple: if we have a database of known access points along with their\ncoordinates, and we can estimate our distance to an access point, then with\nonly three detected access points, we should be able to compute our position.\nOf course, it really is not that simple at all.\nA major problem is determining the coordinates of an access point. A\npopular approach is to do this through war driving: using a WiFi-enabled\n \nDS 4.01\n",
      "content_length": 2613,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 334,
      "content": "318\nCHAPTER 5. COORDINATION\ndevice along with a GPS receiver, someone drives or walks through an area\nand records observed access points. An access point can be identified through\nits SSID or its MAC-level network address.\nAn access point AP should\nbe detected at several locations before its coordinates can be estimated. A\nsimple method is to compute the centroid: assume we have detected AP at\nN different locations {⃗x1, ⃗x2, . . . , ⃗xN}, where each location ⃗xi consists of a\n(latitude, longitude)-pair as provided by the GPS receiver. We then simply\nestimate AP’s location ⃗xAP as\n⃗xAP = ∑N\ni=1 ⃗xi\nN\n.\nAccuracy can be improved by taking the observed signal strength into account,\nand giving more weight to a location with relatively high observed signal\nstrength than to a location where only a weak signal was detected. In the end,\nwe obtain an estimation of the coordinates of the access point. The accuracy\nof this estimation is strongly influenced by:\n• the accuracy of each GPS detection point ⃗xi\n• the fact that an access point has a nonuniform transmission range\n• the number of sampled detection points N.\nStudies show that estimates of the coordinates of an access point may be\ntens of meters off from the actual location (see, e.g., Kim et al. [2006] or\nTsui et al. [2010]). Moreover, access points come and go at a relatively high\nrate. Nevertheless, locating and positioning access points is widely popular,\nexemplified by the open-access Wigle database which is populated through\ncrowdsourcing.1\n5.7.3\nLogical positioning of nodes\nInstead of trying to find the absolute location of a node in a distributed system,\nan alternative is to use a logical, proximity-based location. In geometric\noverlay networks each node is given a position in an m-dimensional geometric\nspace, such that the distance between two nodes in that space reflects a real-\nworld performance metric. Computing such a position is the core business of a\nNetwork Coordinates System, or simply NCS, which are surveyed by Donnet\net al. [2010]. The simplest, and most applied example, is where distance\ncorresponds to internode latency. In other words, given two nodes P and Q,\nthen the distance ˆd(P, Q) reflects how long it would take for a message to\ntravel from P to Q and vice versa. We use the notation ˆd to denote distance in\na system where nodes have been assigned coordinates.\nThere are many applications of geometric overlay networks. Consider the\nsituation where a Website at server O has been replicated to multiple servers\n1See wigle.net.\nDS 4.01\n \n",
      "content_length": 2550,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 335,
      "content": "5.7. LOCATION SYSTEMS\n319\nS1, . . . , SN on the Internet, as typically happens with a Content Delivery\nNetwork (CDN). When a client C requests a page from O, the CDN may\ndecide to redirect that request to the server closest to C, that is, the one that\nwill give the best response time. If the geometric location of C is known, as\nwell as those of each replica server, the CDN can then simply pick that server\nSi for which ˆd(C, Si) is minimal.\nAnother example is optimal replica placement. Consider again a CDN that\nhas gathered the positions of clients for one of its major customers. If the CDN\nwere to replicate content to N servers, it can compute the N best positions\nwhere to place replicas such that the average client-to-replica response time is\nminimal. Performing such computations is almost trivially feasible if clients\nand servers have geometric positions that reflect internode latencies.\nAs a last example, consider position-based routing (see, e.g., [Popescu\net al., 2012] or [Bilal et al., 2013]). In such schemes, a message is forwarded\nto its destination using only positioning information. For example, a naive\nrouting algorithm to let each node forward a message to the neighbor closest\nto the destination. Although it can be easily shown that this specific algorithm\nneed not converge, it illustrates that only local information is used to decide.\nThere is no need to propagate link information or such to all nodes in the\nnetwork, as is the case with conventional routing algorithms.\nCentralized positioning\nPositioning a node in an m-dimensional geometric space requires m + 1\ndistance measures to nodes with known positions. Assuming that node P\nwants to compute its own position, it contacts three other nodes with known\npositions and measures its distance to each of them. Contacting only one node\nwould tell P about the circle it is located on; contacting only two nodes would\ntell it about the position of the intersection of two circles (which generally\nconsists of two points); a third node would subsequently allow P to compute\nits actual location.\nNode P can compute its own coordinates (xP, yP) by solving the three\nquadratic equations with the two unknowns xP and yP:\n˜di =\nq\n(xi −xP)2 + (yi −yP)2\n(i = 1, 2, 3)\nHere, we use ˜d to denote measured, or estimated distance. As said, ˜di generally\ncorresponds to measuring the latency between P and the node at (xi, yi). This\nlatency can be estimated as being half the round-trip delay, but it should\nbe clear that its value will be different over time. The effect is a different\npositioning whenever P would want to recompute its position. Moreover, if\nother nodes would use P’s current position to compute their own coordinates,\nthen it should be clear that the error in positioning P will affect the accuracy\nof the positioning of other nodes.\n \nDS 4.01\n",
      "content_length": 2838,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 336,
      "content": "320\nCHAPTER 5. COORDINATION\nIt should also be clear that measured distances between a set of nodes\nwill generally not even be consistent. For example, assume we are computing\ndistances in a one-dimensional space, as shown in Figure 5.37. In this example,\nwe see that although R measures its distance to Q as 2.0, and ˜d(P, Q) has been\nmeasured to be 1.0, when R measures ˜d(P, R) it finds 2.8, which is clearly\ninconsistent with the other two measurements.\nFigure 5.37: Inconsistent distance measurements in a one-dimensional space.\nFigure 5.37 also suggests how this situation can be improved. In our simple\nexample, we could solve the inconsistencies by merely computing positions\nin a two-dimensional space. This by itself, however, is not a general solution\nwhen dealing with many measurements. In fact, considering that Internet\nlatency measurements may violate the triangle inequality, it is generally\nimpossible to resolve inconsistencies completely. The triangle inequality states\nthat in a geometric space, for any arbitrary three nodes P, Q, and R it must\nalways be true that\nd(P, R) ≤d(P, Q) + d(Q, R).\nThere are various ways to approach these issues. One common approach,\nproposed by Ng and Zhang [2002], is to use N special nodes L1, . . . , LN, known\nas landmarks. Landmarks measure their pairwise latencies ˜d(Li, Lj) and\nsubsequently let a central node compute the coordinates for each landmark.\nTo this end, the central node seeks to minimize the following aggregated error\nfunction:\nN\n∑\ni=1\nN\n∑\nj=i+1\n\u0012 ˜d(Li, Lj) −ˆd(Li, Lj)\n˜d(Li, Lj)\n\u00132\nwhere, again, ˆd(Li, Lj) corresponds to the distance after nodes Li and Lj have\nbeen positioned.\nThe hidden parameter in minimizing the aggregated error function is the\ndimension m. Obviously, we have that N > m, but nothing prevents us from\nchoosing a value for m that is much smaller than N. In that case, a node P\nmeasures its distance to each of the N landmarks and computes its coordinates\nby minimizing\nN\n∑\ni=1\n\u0012 ˜d(Li, P) −ˆd(Li, P)\n˜d(Li, P)\n\u00132\nDS 4.01\n \n",
      "content_length": 2021,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 337,
      "content": "5.7. LOCATION SYSTEMS\n321\nAs it turns out, with well-chosen landmarks, m can be as small as 6 or 7, with\nˆd(P, Q) being no more than a factor 2 different from the actual latency d(P, Q)\nfor arbitrary nodes P and Q [Szymaniak et al., 2004; 2008].\nDecentralized positioning\nAnother way to tackle this problem is to view the collection of nodes as a huge\nsystem in which nodes are attached to each other through springs. In this\ncase, | ˜d(P, Q) −ˆd(P, Q)| indicates to what extent nodes P and Q are displaced\nrelative to the situation in which the system of springs would be at rest. By\nletting each node (slightly) change its position, it can be shown that the system\nwill eventually converge to an optimal organization in which the aggregated\nerror is minimal. This approach is followed in Vivaldi, described in [Dabek\net al., 2004a].\nIn a system with N nodes P1, . . . , PN, Vivaldi aims at minimizing the\nfollowing aggregated error:\nN\n∑\ni=1\nN\n∑\nj=1\n| ˜d(Pi, Pj) −ˆd(Pi, Pj)|2\nwhere ˜d(Pi, Pj) is the measured distance (i.e., latency) between nodes Pi and\nPj, and ˆd(Pi, Pj) the distance computed from the network coordinates of each\nnode. Let ⃗xi denote the coordinates of node Pi. In a situation that each node\nis placed in a geometric space, the force that node Pi exerts on node Pj is\ncomputed as:\n⃗Fij =\n\u0000 ˜d(Pi, Pj) −ˆd(Pi, Pj)\n\u0001 × u(⃗xi −⃗xj)\nwith u(⃗xi −⃗xj) denoting the unit vector in the direction of ⃗xi −⃗xj. In other\nwords, if Fij > 0, node Pi will push Pj away from itself, and will otherwise\npull it toward itself. Node Pi now repeatedly executes the following steps:\n1. Measure the latency ˜dij to node Pj, and also receive Pj’s coordinates ⃗xj.\n2. Compute the error e = ˜d(Pi, Pj) −ˆd(Pi, Pj)\n3. Compute the direction ⃗u = u(⃗xi −⃗xj).\n4. Compute the force vector Fij = e · ⃗u\n5. Adjust own position by moving along the force vector: ⃗xi ←⃗xi + δ · ⃗u.\nA crucial element is the choice of δ: too large and the system will oscillate;\ntoo small and convergence to a stable situation will take a long time. The\ntrick is to have an adaptive value, which is large when the error is large as\nwell, but small when only small adjustments are needed. Details can be found\nin [Dabek et al., 2004a].\n \nDS 4.01\n",
      "content_length": 2217,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 338,
      "content": "322\nCHAPTER 5. COORDINATION\n5.8\nSummary\nStrongly related to communication between processes is the issue of how\nprocesses in distributed systems synchronize. Synchronization is all about\ndoing the right thing at the right time. A problem in distributed systems, and\ncomputer networks in general, is that there is no notion of a globally shared\nclock. In other words, processes on different machines have their own idea of\nwhat time it is.\nThere are various ways to synchronize clocks in a distributed system,\nbut all methods are essentially based on exchanging clock values, while\nconsidering the time it takes to send and receive messages. Variations in\ncommunication delays, and the way those variations are dealt with, largely\ndetermine the accuracy of clock synchronization algorithms.\nKnowing the absolute time is often not necessary. What counts is that\nrelated events at different processes happen in the correct order. Lamport\nshowed that by introducing a notion of logical clocks, it is possible for a\ncollection of processes to reach global agreement on the correct ordering of\nevents. In essence, each event e, such as sending or receiving a message,\nis assigned a globally unique logical timestamp C(e) such that when event\na happened before b, C(a) < C(b). Lamport timestamps can be extended\nto vector timestamps: if C(a) < C(b), we even know that event a causally\npreceded b.\nAn important class of synchronization algorithms is that of distributed\nmutual exclusion. These algorithms ensure that in a distributed collection\nof processes, at most one process at a time has access to a shared resource.\nDistributed mutual exclusion can easily be achieved if we make use of a\ncoordinator that keeps track of whose turn it is. Fully distributed algorithms\nalso exist, but have the drawback that they are generally more susceptible to\ncommunication and process failures.\nSynchronization between processes often requires that one process acts\nas a coordinator. In those cases where the coordinator is not fixed, it is\nnecessary that processes in a distributed computation decide on who is\ngoing to be that coordinator. Such a decision is taken by election algorithms.\nElection algorithms are primarily used in cases where the coordinator can\ncrash. However, they can also be applied for the selection of superpeers in\npeer-to-peer systems.\nThe most important aspect in gossip-based coordination is being able to\nselect another peer randomly from an entire overlay. As it turns out, we can\nimplement such a peer-sampling service using gossiping, by ensuring that the\npartial view is refreshed regularly and randomly. Combining peer sampling\nwith a selective replacement of entries in a partial view allows us to efficiently\nconstruct structured overlay networks.\nParticularly challenging when it comes to coordination is distributed event\nmatching, which sits at the core of publish-subscribe systems. Relatively\nDS 4.01\n \n",
      "content_length": 2929,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 339,
      "content": "5.8. SUMMARY\n323\nsimple is the case when we have a central implementation where matching\nsubscriptions against notifications can be done by essentially doing one-to-one\ncomparisons. However, as soon as we aim at distributing the load, we are\nfaced with the problem of deciding beforehand which node is responsible for\nwhich part of the subscriptions, without knowing what kind of notifications\nto expect. This is particularly problematic for content-based matching, which,\nin the end, requires advanced filtering techniques to route notifications to the\nproper subscribers.\nRelated to these synchronization problems is positioning nodes in a ge-\nometric overlay. The basic idea is to assign each node coordinates from an\nm-dimensional space such that the geometric distance can be used as an\naccurate measure for the latency between two nodes. The method of assigning\ncoordinates strongly resembles the one applied in determining the location\nand time in GPS.\n \nDS 4.01\n",
      "content_length": 970,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 341,
      "content": "06\nNAMING\n",
      "content_length": 10,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 342,
      "content": "326\nCHAPTER 6. NAMING\nNames play an important role in all computer systems. They are used\nto sharing resources, to uniquely identify entities, to refer to locations, and\nmore. An important issue with naming is that a name can be resolved to the\nentity it refers to. Name resolution thus allows a process to access the named\nentity. To resolve names, it is necessary to implement a naming system. The\ndifference between naming in distributed systems and nondistributed systems\nlies in the way naming systems are implemented.\nIn a distributed system, the implementation of a naming system is itself\noften distributed across multiple machines. How this distribution is done\nplays a key role in the efficiency and scalability of the naming system. In this\nchapter, we concentrate on three different, important ways that names are\nused in distributed systems.\nFirst, we consider so-called flat-naming systems. In such systems, entities\nare referred to by an identifier that, in principle, has no meaning at all. In\naddition, flat names bear no structure, implying that we need special mecha-\nnisms to trace the location of such entities. We discuss various approaches,\nranging from distributed hash tables to hierarchical location services.\nIn practice, humans prefer to use readable names. Such names are of-\nten structured, as is well known from the way Web pages are referred to.\nStructured names allow for a highly systematic way of finding the server\nresponsible for the named entity, as exemplified by the Domain Name System.\nWe discuss the general principles, as well as scalability issues.\nFinally, humans often prefer to describe entities through various charac-\nteristics, leading to a situation in which we need to resolve a description\nusing the attributes assigned to an entity. As we shall see, this type of name\nresolution is notoriously difficult, especially with searching.\nName resolution and routing are closely related to each other. Normally,\nwe look up an address given a name, to subsequently access the named entity\nthrough its address. As an alternative to looking up an address, researchers\nhave been exploring how a name can be directly used to route toward the\nentity, to subsequently return a copy of its associated data. This so-called\nnamed-based routing is gradually maturing as an alternative for a future\nInternet. We discuss it briefly in this chapter.\n6.1\nNames, identifiers, and addresses\nA name in a distributed system is a string of bits or characters that is used to\nrefer to an entity. An entity in a distributed system, can be practically any-\nthing. Typical examples include resources such as hosts, printers, disks, and\nfiles. Other well-known examples of entities that are often explicitly named\nare processes, users, mailboxes, Web pages, graphical windows, messages,\nnetwork connections, and so on.\nDS 4.01\n \n",
      "content_length": 2851,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 343,
      "content": "6.1. NAMES, IDENTIFIERS, AND ADDRESSES\n327\nEntities can be operated on. For example, a resource such as a printer\noffers an interface containing operations for printing a document, requesting\nthe status of a print job, and the like. Furthermore, an entity such as a network\nconnection may provide operations for sending and receiving data, setting\nquality-of-service parameters, requesting the status, and so forth.\nTo operate on an entity, it is necessary to access it, for which we need an\naccess point. An access point is yet another, but special, kind of entity in a\ndistributed system. The name of an access point is called an address. The\naddress of an access point of an entity is also simply called an address of that\nentity.\nAn entity can offer more than one access point.\nAs a comparison, a\ntelephone can be viewed as an access point of a person, whereas the phone\nnumber corresponds to an address. Indeed, many people have several phone\nnumbers, each number corresponding to a point where they can be reached.\nIn a distributed system, a typical example of an access point is a host running\na specific server, with its address formed by the combination of, for example,\nan IP address and port number (i.e., the server’s transport-level address).\nAn entity may change its access points over time. For example, when a\nmobile computer moves to another location, it is often assigned a different\nIP address than the one it had before. Likewise, when a person changes jobs,\nthere is likely a change in phone numbers as well. Similarly, changing your\nInternet Service Provider, often means changing an e-mail address.\nAn address is thus just a special kind of name: it refers to an access point\nof an entity. Because an access point is tightly associated with an entity, it\nwould seem convenient to use the address of an access point as a regular\nname for the associated entity. Nevertheless, this is hardly ever done, as such\nnaming is generally very inflexible and often human unfriendly.\nFor example, it is not uncommon to regularly reorganize a distributed\nsystem so that a specific server is now running on a different host than it did\npreviously. The old machine on which the server used to be running may be\nreassigned to a different server. In other words, an entity may easily change\nan access point, or an access point may be reassigned to a different entity. If\nan address is used to refer to an entity, we will have an invalid reference the\ninstant the access point changes or is reassigned to another entity. Therefore,\nit is much better to let a service be known by a separate name independent of\nthe address of the associated server.\nLikewise, if an entity offers more than one access point, it is not clear which\naddress to use as a reference. For instance, many organizations distribute their\nWeb service across several servers. If we would use the addresses of those\nservers as a reference for the Web service, it is not obvious which address\nshould be chosen as the best one. Again, a much better solution is to have a\nsingle name for the Web service, independent of the addresses of the different\nWeb servers.\n \nDS 4.01\n",
      "content_length": 3144,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 344,
      "content": "328\nCHAPTER 6. NAMING\nThese examples illustrate that a name for an entity that is independent of\nits addresses is often much easier and more flexible to use. Such a name is\ncalled location independent.\nIn addition to addresses, there are other types of names that deserve\nspecial treatment, such as names that are used to uniquely identify an entity.\nA true identifier is a name that has the following properties [Wieringa and\nde Jonge, 1995]:\n1. An identifier refers to at most one entity.\n2. Each entity is referred to by at most one identifier.\n3. An identifier always refers to the same entity (i.e., it is never reused).\nBy using identifiers, it becomes much easier to unambiguously refer to\nan entity. For example, assume two processes each refer to an entity by an\nidentifier. To check if the processes are referring to the same entity, it is\nsufficient to test if the two identifiers are equal. Such a test would not be\nsufficient if the two processes were using regular, nonunique, nonidentifying\nnames. For example, the name “John Smith” cannot be taken as a unique\nreference to just a single person.\nLikewise, if an address can be reassigned to a different entity, we cannot\nuse an address as an identifier. Consider again the use of phone numbers,\nwhich are reasonably stable in the sense that a phone number will often for\nsome time refer to the same person or organization. However, using a phone\nnumber as an identifier will not work, as it can be, and often is, reassigned\nover time. Consequently, Bob’s new bakery may be receiving phone calls for\nAlice’s old antique store for a long time. In this case, it would have been better\nto use a true identifier for Alice instead of her phone number.\nAddresses and identifiers are two important types of names that are each\nused for very different purposes. In many computer systems, addresses and\nidentifiers are represented in machine-readable form only, that is, in the form\nof bit strings. For example, an Ethernet address is essentially a random string\nof 48 bits. Likewise, memory addresses are typically represented as 32-bit or\n64-bit strings.\nAnother important type of name is that which is tailored to be used by\nhumans, also referred to as human-friendly names. In contrast to addresses\nand identifiers, a human-friendly name is generally represented as a character\nstring. These names appear in many different forms. For example, files in\nUnix systems have character-string names that can generally be as long as 255\ncharacters, and which are defined entirely by the user. Similarly, DNS names\nare represented as relatively simple case-insensitive character strings.\nHaving names, identifiers, and addresses brings us to the central theme of\nthis chapter: how do we resolve names and identifiers to addresses? As we\nshall see, there are essentially two approaches. In the first one, we maintain\nDS 4.01\n \n",
      "content_length": 2877,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 345,
      "content": "6.2. FLAT NAMING\n329\na (generally distributed) table of (name, address) pairs. This is the approach\nfollowed by naming systems such as DNS, which we discuss extensively in\nthis chapter. In the second approach, a name is resolved by routing the request\ngradually to the name’s associated address, or even directly to an access point.\nTypically, this is the approach followed in structured peer-to-peer systems,\nbut also in what is known as information-centric networking (which we\nalso discuss later in this chapter). It is interesting to note that in such cases\nthe boundaries between name resolution and message routing are starting\nto blur, as was noted by Shoch [1978] already almost 50 years ago. In fact,\nwe will challenge the need for name-to-address resolution when discussing\nnamed-data networking. To stay in historical perspective, it is then also\ninteresting to note how certain discussions become topical again: in a sense,\nnaming and resolving a name to an address is precisely what is referred to\nas the identifier-location split (see also Ramirez et al. [2014] and Feng et al.\n[2017]).\nIn the following sections, we will consider four different classes of naming\nsystems. First, we will take a look at how identifiers can be resolved to\naddresses. In this case, we will also see an example where name resolution\nis actually indistinguishable from message routing. After that, we consider\nhuman-friendly names and then descriptive names (i.e., entities that are\ndescribed by a collection of names). Finally, we pay attention to named-based\nnetworking.\n6.2\nFlat naming\nAbove, we explained that identifiers are convenient to uniquely represent enti-\nties. Often, identifiers are simply random bit strings, which we conveniently\nrefer to as unstructured, or flat names. An important property of such a name\nis that it does not contain any information whatsoever on how to locate the\naccess point of its associated entity. In the following, we will take a look at\nhow flat names can be resolved, or, equivalently, how we can locate an entity\nwhen given only its identifier.\n6.2.1\nSimple solutions\nWe first consider two simple solutions for locating an entity: broadcasting and\nforwarding pointers. Both solutions are mainly applicable only to local-area\nnetworks. Nevertheless, in that environment, they often do the job well,\nmaking their simplicity particularly attractive.\nBroadcasting\nConsider a distributed system built on a computer network that offers efficient\nbroadcasting facilities.\nTypically, such facilities are offered by local-area\n \nDS 4.01\n",
      "content_length": 2567,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 346,
      "content": "330\nCHAPTER 6. NAMING\nnetworks, in which all machines are connected to a single cable or the logical\nequivalent thereof. Also, local-area wireless networks fall into this category.\nLocating an entity in such an environment is simple: a message containing\nthe identifier of the entity is broadcasted to each machine, and each machine is\nrequested to check whether it has that entity. Only the machines that can offer\nan access point for the entity send a reply message containing the address of\nthat access point.\nThis principle is used in the Internet Address Resolution Protocol (ARP) to\nfind the data-link address of a machine when given only an IP address [Plum-\nmer, 1982]. In essence, a machine broadcasts a packet on the local-network\nasking who is the owner of a given IP address. When the message arrives at\na machine, the receiver checks whether it should listen to the requested IP\naddress. If so, it sends a reply packet containing, for example, its Ethernet\naddress.\nBroadcasting becomes inefficient when the network grows. Not only is\nnetwork bandwidth wasted by request messages, but, more seriously, too\nmany hosts may be interrupted by requests they cannot answer. One possible\nsolution is to switch to multicasting, by which only a restricted group of hosts\nreceives the request. Ethernet networks support data-link level multicasting\ndirectly in hardware.\nMulticasting can also be used to locate entities in point-to-point networks.\nFor example, the Internet supports network-level multicasting by allowing\nhosts to join a specific multicast group. Such groups are identified by a\nmulticast address. When a host sends a message to a multicast address, the\nnetwork layer provides a best-effort service to deliver that message to all\ngroup members. Efficient implementations for multicasting on the Internet\nare discussed in Deering and Cheriton [1990] and Deering et al. [1996].\nA multicast address can be used as a general location service for multiple\nentities. Consider an organization where each employee has his or her own\nmobile computer. When such a computer connects to the locally available\nnetwork, it is dynamically assigned an IP address. In addition, it joins a\nspecific multicast group. When a process wants to locate a computer A, it\nsends a “where is A?” request to the multicast group. If A is connected, it\nresponds with its current IP address.\nAnother way to use a multicast address is to associate it with a replicated\nentity, and to use multicasting to locate the nearest replica. When sending\na request to the multicast address, each replica responds with its current\n(normal) IP address. A crude way to select the nearest replica is to choose the\none whose reply comes in first, but as it turns out, selecting a nearest replica\nis generally not that easy.\nDS 4.01\n \n",
      "content_length": 2806,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 347,
      "content": "6.2. FLAT NAMING\n331\nForwarding pointers\nAnother approach to locating mobile entities is to make use of forwarding\npointers [Fowler, 1985]. The principle is simple: when an entity moves from\nA to B, it leaves behind in A a reference to its new location at B. The main\nadvantage of this approach is its simplicity: as soon as an entity has been\nlocated, for example by using a traditional naming service, a client can look\nup the current address by following the chain of forwarding pointers.\nThere are also drawbacks. First, if no special measures are taken, a chain\nfor a highly mobile entity can become so long that locating that entity is\nprohibitively expensive. Second, all intermediate locations in a chain will have\nto maintain their part of the chain of forwarding pointers as long as needed.\nA third (and related) drawback is the vulnerability to broken links. As soon\nas any forwarding pointer is lost, the entity can no longer be reached. An\nimportant issue is, therefore, to keep chains relatively short, and to ensure\nthat forwarding pointers are robust.\n6.2.2\nHome-based approaches\nA popular approach to supporting mobile entities in large-scale networks is\nto introduce a home location, which keeps track of the current location of\nan entity. Special techniques may be applied to safeguard against network or\nprocess failures. In practice, the home location is often chosen to be the place\nwhere an entity was created.\nThe home-based approach is used as a fall-back mechanism for location\nservices based on forwarding pointers. Another example where the home-\nbased approach is followed is in Mobile IP [Perkins et al., 2011]. Each mobile\nhost uses a fixed IP address. All communication to that IP address is initially\ndirected to the mobile host’s home agent. This home agent is located on the\nlocal-area network corresponding to the network address contained in the\nmobile host’s IP address. In the case of IPv6, it is realized as a network-layer\ncomponent. Whenever the mobile host moves to another network, it requests\na temporary address that it can use for communication. This care-of address\nis registered at the home agent.\nWhen the home agent receives a packet for the mobile host, it looks up the\nhost’s current location. If the host is on the current local network, the packet\nis simply forwarded. Otherwise, it is tunneled to the host’s current location,\nthat is, wrapped as data in an IP packet and sent to the care-of address. At the\nsame time, the sender of the packet is informed of the host’s current location.\nThis principle is shown in Figure 6.1 Note that the IP address is effectively\nused as an identifier for the mobile host.\nAn important aspect is that this whole mechanism is largely hidden for\napplications. In other words, the original IP address associated with the\nmobile host can be used by an application without further ado. Client-side\n \nDS 4.01\n",
      "content_length": 2894,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 348,
      "content": "332\nCHAPTER 6. NAMING\nsoftware that is part of the application-independent communication layer will\nhandle the redirection to the target’s current location. Likewise, at the target’s\nlocation, a message that has been tunneled will be unpacked and handed\nto the application on the mobile host as if it were using its original address.\nIndeed, Mobile IP establishes a high degree of location transparency.\nHost's current location\nClient's\nlocation\n1. Send packet to host at its home\n2. Return address\nof current location\n3. Tunnel packet to\ncurrent location\n4. Send successive packets\nto current location\nHost's home\nlocation\nFigure 6.1: The principle of Mobile IP.\nFigure 6.1 also illustrates a drawback of home-based approaches in large-\nscale networks. To communicate with a mobile entity, a client first has to\ncontact the home, which may be at an entirely different location than the\nentity itself. The result is an increase in communication latency.\nAnother drawback of the home-based approach is the use of a fixed home\nlocation. For one thing, it must be ensured that the home location always\nexists. Otherwise, contacting the entity will become impossible. Problems\nare aggravated when a long-lived entity decides to move permanently to an\nentirely different part of the network than where its home is located. In that\ncase, it would have been better if the home could have moved along with the\nhost.\nA solution to this problem is to register the home at a traditional naming\nservice and to let a client first look up the location of the home. Because the\nhome location can be assumed to be relatively stable, that location can be\neffectively cached after it has been looked up.\nDS 4.01\n \n",
      "content_length": 1696,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 349,
      "content": "6.2. FLAT NAMING\n333\n6.2.3\nDistributed hash tables\nLet us now take a closer look at how to resolve an identifier to the address of\nthe associated entity. We have already mentioned distributed hash tables a\nnumber of times, but have deferred discussion on how they actually work. In\nthis section, we correct this situation by first considering the Chord system as\nan easy-to-explain DHT-based system.\nGeneral mechanism\nMany DHT-based systems have been developed in the past decade, with the\nChord system [Stoica et al., 2003] being a typical representative. Chord uses\nan m-bit identifier space to assign randomly chosen identifiers to nodes as\nwell as keys to specific entities. The latter can be virtually anything: files,\nprocesses, etc. The number m of bits is usually 128 or 160, depending on\nwhich hash function is used. An entity with key k falls under the jurisdiction\nof the node with the smallest identifier id ≥k. This node is referred to as\nthe successor of k and denoted as succ(k). To keep our notation simple and\nconsistent, in the following, we refer to a node with identifier p as node p.\nThe main issue in DHT-based systems is to efficiently resolve a key k to\nthe address of succ(k). A naive approach is to let each node p keep track of\nthe successor succ(p + 1). In that case, whenever a node p receives a request\nto resolve key k, it will simply forward the request to its successor, unless\npred(p) < k ≤p, in which case node p should return its own address to\nthe process that initiated the resolution of key k. A lookup request would,\non average, need to travel half of the ring. Obviously, this approach is not\nscalable. Keeping track of the predecessor and forwarding a request in that\ndirection will cut the expected number of hops by only 50%, which is not by\nfar good enough.\nInstead of this linear approach toward key lookup, each Chord node\nmaintains a finger table containing s ≤m entries. If FTp denotes the finger\ntable of node p, then\nFTp[i] = succ(p + 2i−1)\nPut in other words, the ith entry points to the first node succeeding p by at\nleast 2i−1 units. Note that these references are actually shortcuts to existing\nnodes in the identifier space, where the short-cutted distance from node p\nincreases exponentially as the index in the finger table increases. To look up a\nkey k, node p will then immediately forward the request to node q with index\nj in p’s finger table where:\nq = FTp[j] ≤k < FTp[j + 1]\nor q = FTp[1] when p < k < FTp[1]. (For clarity, we ignore modulo arith-\nmetic.) Note that when the finger-table size s is equal to 1, a Chord lookup\ncorresponds to naively traversing the ring linearly, as we just discussed.\n \nDS 4.01\n",
      "content_length": 2674,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 350,
      "content": "334\nCHAPTER 6. NAMING\nFigure 6.2: Resolving key 26 from node 1 and key 12 from node 28 in a Chord\nsystem.\nTo illustrate this lookup, consider resolving k = 26 from node 1 as shown in\nFigure 6.2. First, node 1 will look up k = 26 in its finger table to discover that\nthis value is larger than FT1[5], meaning that the request will be forwarded\nto node 18 = FT1[5]. Node 18, in turn, will select node 20, as FT18[2] ≤k <\nFT18[3]. Finally, the request is forwarded from node 20 to node 21 and from\nthere to node 28, which is responsible for k = 26. At that point, the address\nof node 28 is returned to node 1 and the key has been resolved. For similar\nreasons, when node 28 is requested to resolve the key k = 12, a request will\nbe routed as shown by the dashed line in Figure 6.2.\nIt should come as no surprise that a lookup will generally require O(log(N))\nsteps, with N being the number of nodes in the system. The result of a simple\nexperiment by which we look up k = p −1 starting at node p, yet initially\nignore p’s predecessor, is shown in Figure 6.3. Note that, by ignoring p’s\npredecessor at the first lookup step, we need to effectively go to a node at\ndistance roughly 2i−1 for decreasing values of i.\nDS 4.01\n \n",
      "content_length": 1220,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 351,
      "content": "6.2. FLAT NAMING\n335\nFigure 6.3: The length of a lookup path as function of the size of a Chord ring.\nIn large distributed systems, the collection of participating nodes can be\nexpected to change all the time. Not only will nodes join and leave voluntarily,\nwe also need to consider the case of nodes failing (and thus effectively leaving\nthe system), to later recover again (at which point they rejoin).\nJoining a DHT-based system such as Chord is relatively simple. Suppose\nnode p wants to join. It simply contacts an arbitrary node in the existing\nsystem and requests a lookup for succ(p + 1).\nOnce this node has been\nidentified, p can insert itself into the ring. Likewise, leaving can be just as\nsimple. Note that nodes also keep track of their predecessor.\nObviously, the complexity comes from keeping the finger tables up-to-date.\nMost important is that for every node q, FTq[1] is correct as this entry refers\nto the next node in the ring, that is, the successor of q + 1. To achieve this goal,\neach node q regularly runs a simple procedure that contacts succ(q + 1) and\nrequests to return pred(succ(q + 1)). If q = pred(succ(q + 1)) then q knows its\ninformation is consistent with that of its successor. Otherwise, if q’s successor\nhas updated its predecessor, then apparently a new node p had entered the\nsystem, with q < p ≤succ(q + 1), so that q will adjust FTq[1] to p. At that\npoint, it will also check whether p has recorded q as its predecessor. If not,\nanother adjustment of FTq[1] is needed.\nSimilarly, to update a finger table, node q simply needs to find the successor\nfor k = q + 2i−1 for each entry i. Again, this can be done by issuing a request\nto resolve succ(k).\nIn Chord, such requests are issued regularly using a\nbackground process.\nLikewise, each node q will regularly check whether its predecessor is alive.\nIf the predecessor has failed, the only thing that q can do is record the fact by\nsetting pred(q) to “unknown.” On the other hand, when node q is updating\nits link to the next known node in the ring, and finds that the predecessor of\nsucc(q + 1) has been set to “unknown,” it will simply notify succ(q + 1) that\n \nDS 4.01\n",
      "content_length": 2161,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 352,
      "content": "336\nCHAPTER 6. NAMING\nit suspects it to be the predecessor. By and large, these simple procedures\nensure that a Chord system is generally consistent, only perhaps except for a\nfew nodes. The details can be found in [Stoica et al., 2003].\nNote 6.1 (Advanced: Chord in Python)\nCoding Chord in Python is relatively simple.\nAgain, omitting many of the\nnonessential coding details, the core of the behavior of a Chord node can be\ndescribed as shown in Figure 6.4. The function finger(i) with succNode(i)\ncomputes succ(i) for the given node. All nodes known to a specific Chord node\nare collected in a local set nodeSet, which is sorted by node identifier. The node\nfirst looks up its own position in this set, and that of its right-hand neighbor.\nThe operation inbetween(k,l,u) computes if k ∈[l, u), taking modulo arithmetic\ninto account. Computing inbetween(k,l+1,u+1) is therefore the same as testing\nwhether k ∈(l, u]. We thus see that finger(i) returns the largest existing node\nidentifier, less or equal to i.\n1 class ChordNode:\n2\n3\ndef __succNode(self, key):\n4\nif (key <= self.nodeSet[0] or\n5\nkey > self.nodeSet[len(self.nodeSet)-1]): # key is in segment for which\n6\nreturn self.nodeSet[0]\n# this node is responsible\n7\nfor i in range(1,len(self.nodeSet)):\n8\nif (key <= self.nodeSet[i]):\n# key is in segment for which\n9\nreturn self.nodeSet[i]\n# node (i+1) may be responsible\n10\n11\ndef __finger(self, i):\n12\nreturn self.__succNode((self.nodeID + pow(2,i-1)) % self.MAXPROC) # succ(p+2^(i-1))\n13\n14\ndef __recomputeFingerTable(self):\n15\nself.FT[0]\n= self.nodeSet[(self.nodeInd - 1)%len(self.nodeSet)] # Predecessor\n16\nself.FT[1:] = [self.__finger(i) for i in range(1,self.nBits+1)]\n# Successors\n17\nself.FT.append(self.nodeID)\n# This node\n18\n19\ndef __localSuccNode(self, key):\n20\nif self.__inbetween(key, self.FT[0]+1, self.nodeID+1):\n# key in (pred,self]\n21\nreturn self.nodeID\n# this node is responsible\n22\nelif self.__inbetween(key, self.nodeID+1, self.FT[1]):\n# key in (self,FT[1]]\n23\nreturn self.FT[1]\n# successor responsible\n24\nfor i in range(1, self.nBits+2):\n# go through rest of FT\n25\nif self.__inbetween(key, self.FT[i], self.FT[(i+1)]): # key in [FT[i],FT[i+1])\n26\nreturn self.FT[i]\n# FT[i] is responsible\nFigure 6.4: The essence of a Chord node expressed in Python.\nEvery time a node learns about a new node in the system (or discovers that\none has left), it simply adjusts the local nodeSet and recomputes its finger table\nby calling recomputeFingerTable. The finger table itself is implemented as a local\ntable FT, with FT[0] pointing to the node’s predecessor and FT[nBits+1] to the\nDS 4.01\n \n",
      "content_length": 2604,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 353,
      "content": "6.2. FLAT NAMING\n337\nnode itself, where nBits is the number of bits used for node identifiers and keys.\nThe core of what a node does during a lookup is encoded in localSuccNode(k).\nWhen handed a key k, it will either return itself, its immediate successor FT[1],\nor go through the finger table to search the entry satisfying FT[i] ≤k < FT[i+1].\nThe code does not show what is done with the returned value (which is a node\nidentifier), but typically in an iterative scheme, the referenced node will be contacted\nto continue looking up k, unless the node had returned itself as the one being\nresponsible for k. When deploying a recursive scheme, the node itself contacts the\nreferenced node.\nExploiting network proximity\nOne of the potential problems with systems such as Chord is that requests\nmay be routed erratically across the Internet. For example, assume that\nnode 1 in Figure 6.2 is placed in Amsterdam, The Netherlands; node 18\nin San Diego, California; node 20 in Amsterdam again; and node 21 in\nSan Diego. The result of resolving key 26 will then incur three wide-area\nmessage transfers, which arguably could have been reduced to at most one.\nTo minimize these pathological cases, designing a DHT-based system requires\ntaking the underlying network into account.\nCastro et al. [2002a] distinguish three different ways for making a DHT-\nbased system aware of the underlying network. In the case of topology-based\nassignment of node identifiers the idea is to assign identifiers such that two\nnearby nodes will have identifiers that are also close to each other. It is not\ndifficult to imagine that this approach may impose severe problems in the\ncase of relatively simple systems such as Chord. In the case where node\nidentifiers are sampled from a one-dimensional space, mapping a logical ring\nto the Internet is far from trivial. Moreover, such a mapping can easily expose\ncorrelated failures: nodes on the same enterprise network will have identifiers\nfrom a relatively small interval. When that network becomes unreachable, we\nsuddenly have a gap in the otherwise uniform distribution of identifiers.\nWith proximity routing, nodes maintain a list of alternatives to forward\na request to. For example, instead of having only a single successor, each\nnode in Chord could equally well keep track of r successors. In fact, this\nredundancy can be applied for every entry in a finger table. For node p, FTp[i]\nnormally points to the first node in the range [p + 2i−1, p + 2i −1]. Whenever\nit needs to look up a key k, it tries to prevent “overshooting” by passing the\nrequest to a node q with k < q without knowing for sure if there is a node q′\nwith k ≤q′ < q. For this reason, p passes k to the node known to p with the\nlargest identifier smaller or equal to k.\nHowever, there is no reason why p cannot keep track of r nodes in range\n[p + 2i−1, p + 2i −1]: each node q in this range can be used to route a lookup\nrequest for a key k as long as q ≤k. In that case, when choosing to forward\n \nDS 4.01\n",
      "content_length": 3007,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 354,
      "content": "338\nCHAPTER 6. NAMING\na lookup request, a node can pick one of the r successors that is closest to\nitself while making sure not to “overshoot.” An additional advantage of\nhaving multiple successors for every table entry is that node failures need not\nimmediately lead to failures of lookups, as multiple routes can be explored.\nFinally, in proximity neighbor selection the idea is to optimize routing\ntables such that the nearest node is selected as neighbor. This selection works\nonly when there are more nodes to choose from. In Chord, this is normally\nnot the case. However, in other protocols such as Pastry [Rowstron and\nDruschel, 2001], when a node joins, it receives information about the current\noverlay from multiple other nodes. This information is used by the new node\nto construct a routing table. Obviously, when there are alternative nodes\nto choose from, proximity neighbor selection will allow the joining node to\nchoose the best one.\nNote that it may not be that easy to draw a line between proximity routing\nand proximity neighbor selection. In fact, when Chord is modified to include\nr successors for each finger table entry, proximity neighbor selection resorts\nto identifying the closest r neighbors, which comes very close to proximity\nrouting, as we just explained [Dabek et al., 2004b].\n6.2.4\nHierarchical approaches\nWe now discuss a general approach to a hierarchical location scheme, includ-\ning a number of optimizations. The approach we present is based on the\nGlobe location service [van Steen et al., 1998]. A detailed description can be\nfound in [Ballintijn, 2003]. This is a general-purpose location service that is\nrepresentative of many hierarchical location services proposed for what are\ncalled Personal Communication Systems, of which a general overview can be\nfound in Pitoura and Samaras [2001].\nIn a hierarchical scheme, a network is divided into a collection of domains.\nThere is a single top-level domain that spans the entire network. Each domain\ncan be subdivided into multiple, smaller subdomains. A lowest-level domain,\ncalled a leaf domain, typically corresponds to a local-area network in a\ncomputer network or a cell in a mobile telephone network. The general\nassumption is that within a smaller domain, the average time it takes to\ntransfer a message from one node to another is less than in a large domain.\nEach domain D has an associated directory node dir(D) that keeps track\nof the entities in that domain. This leads to a tree of directory nodes. The\ndirectory node of the top-level domain, called the root (directory) node, knows\nabout all entities. This general organization of a network into domains and\ndirectory nodes is illustrated in Figure 6.5\nTo keep track of the whereabouts of an entity, each entity currently located\nin a domain D is represented by a location record in the directory node\ndir(D). A location record for entity E in the directory node N for a leaf\ndomain D contains the entity’s current address in that domain. In contrast,\nDS 4.01\n \n",
      "content_length": 3016,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 355,
      "content": "6.2. FLAT NAMING\n339\nFigure 6.5: Hierarchical organization of a location service into domains, each\nhaving an associated directory node.\nthe directory node N′ for the next higher-level domain D′ that contains D,\nwill have a location record for E containing only a pointer to N. Likewise,\nthe parent node of N′ will store a location record for E containing only a\npointer to N′. Consequently, the root node will have a location record for each\nentity, where each location record stores a pointer to the directory node of the\nnext lower-level subdomain where that record’s associated entity is currently\nlocated.\nAn entity may have multiple addresses, for example if it is replicated.\nIf an entity has an address in leaf domain D1 and D2 respectively, then the\ndirectory node of the smallest domain containing both D1 and D2, will have\ntwo pointers, one for each subdomain containing an address. This leads to\nthe general organization of the tree as shown in Figure 6.6.\nFigure 6.6: An example of storing information of an entity having two ad-\ndresses in different leaf domains.\n \nDS 4.01\n",
      "content_length": 1088,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 356,
      "content": "340\nCHAPTER 6. NAMING\nLet us now consider how a lookup operation proceeds in such a hierarchi-\ncal location service. As is shown in Figure 6.7, client,nt wishing to locate an\nentity E, issues a lookup request to the directory node of the leaf domain D in\nwhich the client resides. If the directory node does not store a location record\nfor the entity, then the entity is currently not located in D. Consequently, the\nnode forwards the request to its parent. Note that the parent node represents\na larger domain than its child. If the parent also has no location record for E,\nthe lookup request is forwarded to a next level higher, and so on.\nFigure 6.7: Looking up a location in a hierarchically organized location service.\nAs soon as the request reaches a directory node M that stores a location\nrecord for entity E, we know that E is somewhere in the domain dom(M)\nrepresented by node M. In Figure 6.7, M is shown to store a location record\ncontaining a pointer to one of its subdomains. The lookup request is then\nforwarded to the directory node of that subdomain, which in turn forwards\nit further down the tree, until the request finally reaches a leaf node. The\nlocation record stored in the leaf node will contain the address of E in that\nleaf domain. This address can then be returned to the client that initially\nrequested the lookup to take place.\nAn important observation regarding hierarchical location services is that\nthe lookup operation exploits locality. In principle, the entity is searched\nin a gradually increasing ring centered around the requesting client. The\nsearch area is expanded each time the lookup request is forwarded to a next\nhigher-level directory node. In the worst case, the search continues until the\nrequest reaches the root node. Because the root node has a location record\nfor each entity, the request can then simply be forwarded along a downward\npath of pointers to one of the leaf nodes.\nUpdate operations exploit locality similarly, as shown in Figure 6.8. Con-\nsider an entity E that has created a replica in a leaf domain D for which it\nneeds to insert its address. The insertion is initiated at the leaf node dir(D)\nDS 4.01\n \n",
      "content_length": 2174,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 357,
      "content": "6.2. FLAT NAMING\n341\n(a)\n(b)\nFigure 6.8: (a) An insert request is forwarded to the first node that knows\nabout entity E. (b) A chain of forwarding pointers to the leaf node is created.\nof D which immediately forwards the insert request to its parent. The parent\nwill forward the insert request as well, until it reaches a directory node M that\nalready stores a location record for E.\nNode M will then store a pointer in the location record for E, referring to\nthe child node from where the insert request was forwarded. At that point,\nthe child node creates a location record for E, containing a pointer to the next\nlower-level node from where the request came. This process continues until\nwe reach the leaf node from which the insert was initiated. The leaf node,\nfinally, creates a record with the entity’s address in the associated leaf domain.\nInserting an address as just described leads to installing the chain of\npointers in a top-down fashion, starting at the lowest-level directory node\nthat has a location record for entity E. An alternative is to create a location\n \nDS 4.01\n",
      "content_length": 1087,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 358,
      "content": "342\nCHAPTER 6. NAMING\nrecord before passing the insert request to the parent node. In other words,\nthe chain of pointers is constructed from the bottom up. The advantage of\nthe latter is that an address becomes available for lookups as soon as possible.\nConsequently, if a parent node is temporarily unreachable, the address can\nstill be looked up within the domain represented by the current node.\nA delete operation is analogous to an insert operation. When an address\nfor an entity E in a leaf domain D needs to be removed, the directory node\ndir(D) is requested to remove that address from its location record for E. If\nthat location record becomes empty, that is, it contains no other addresses\nfor E in D, the record can be removed. In that case, the parent node of dir(D)\nwants to remove its pointer to dir(D). If the location record for E at the parent\nnow also becomes empty, that record should be removed as well and the next\nhigher-level directory node should be informed. Again, this process continues\nuntil a pointer is removed from a location record that remains nonempty\nafterward or until the root is reached.\nNote 6.2 (Advanced: Scalability issues)\nOne question that immediately comes to mind is whether the hierarchical ap-\nproach just described can actually scale. A seemingly obvious design flaw, is\nthat the root node needs to keep track of all identifiers. However, it is important\nto make a distinction between a logical design and its physical implementation.\nLet us make this distinction here and see how we can actually come to a highly\nscalable implementation of a hierarchical location service.\nTo this end, we assume that each entity is assigned a unique identifier uniform\nat random from a large space of m-bit identifiers, just as in Chord. Furthermore,\nlet us assume that there are a total of N physical hosts {H1, H2, . . . , HN} that can\naccommodate the lookup service, spread across the Internet. Each host is capable\nof running one or more location servers. Typically, two servers running on the\nsame host will represent two nodes at different levels of the logical tree. Let Dk(A)\ndenote the domain at level k that contains address A, with k = 0 denoting the\nroot domain. Likewise, let LSk(E, A) denote the unique location server in Dk(A)\nresponsible for keeping track of the whereabouts of the entity E.\nWe can now make a distinction between a logical root and its implementation.\nLet Dk = {Dk,1, Dk,2, . . . , Dk,Nk} denote the Nk domains at level k, with, obviously,\nN0 = |D0| = 1. For each level k, the set of hosts is partitioned into Nk subsets,\nwith each host running a location server representing exactly one of the domains\nDk,i from Dk. This principle is shown in Figure 6.9.\nIn this example, we consider a simple tree with four levels and nine hosts.\nThere are two level-1 domains, four level-2 domains, and eight leaf domains. We\nalso show a tree for one specific entity E: any contact address associated with E\nwill be stored in one of the eight level-3 location servers, depending, of course,\non the domain to which that address belongs. The root location server for E is\nrunning on host H3. Note that this host also runs a leaf-level location server for E.\nAs explained by van Steen and Ballintijn [2002], by judiciously choosing which\nhost should run a location server for E, we can combine the principle of local\nDS 4.01\n \n",
      "content_length": 3377,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 359,
      "content": "6.2. FLAT NAMING\n343\noperations (which is good for geographical scalability) and full distribution of\nhigher level servers (which is good for size scalability).\nFigure 6.9: The principle of distributing logical location servers over\nphysical hosts.\n6.2.5\nSecure flat naming\nFlat names do not contain any information on how to resolve a name to the\nentity it is referring to. As a consequence, one needs to, in principle, entirely\nrely on the name-resolution process to eventually access the associated entity.\nIf the name-resolution process cannot be trusted, there is no reason to believe\nthat any response can be trusted as well. There are then, essentially, two\napproaches to follow: (1) secure the name-resolution process, or (2) secure the\nidentifier-to-entity association. Let us first take a look at this last option.\nSecuring the identifier-to-entity association is what happens in a so-called\nself-certifying name. As a general principle, we can compute an identifier\nfrom an entity by simply using a hash function:\nid(entity) = hash(data associated with the entity).\nThe crux is, of course, which associated data is used. In the case of nonmodifi-\nable entities, such as read-only files, a client can simply check that it received\nthe correct file by separately computing the hash over the file and comparing\nit to the identifier it used for looking up that file. Of course, to make this\nwork, the client would need to know which hash function to use along with\nperhaps other information.\nIn practice, entities are modified, such as when dealing with mobile objects.\nIn that case, the entity is the current address of the object. What we need\nto know, for sure, is that the returned address is indeed the one that can\nbe used for accessing the object. Likewise, when dealing with modifiable\nfiles, the returned information should allow the client to check that it is\n \nDS 4.01\n",
      "content_length": 1887,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 360,
      "content": "344\nCHAPTER 6. NAMING\nindeed accessing the correct file. Omitting various details, a scheme proposed\nin [Dannewitz et al., 2010] is to have\nid(entity) = public key(entity).\nA client will be returned the associated entity, along with additional data\nthat will allow it to verify that it is indeed dealing with the correct entity.\nFor example, the additional data could contain a signed digest of the entity,\neffectively forming a signature of the entity’s owner. If necessary, the returned\ninformation could also contain a certificate stating the validity of the public\nkey that has been used as an identifier.\nBy securing the identifier-to-entity binding, it becomes less important to\ntrust the name-resolution process. The worse that can now happen is that the\nprocess returns false or no entities. However, whatever it returns, the client\nwill be able to verify its correctness. Trust is now degraded to providing a\ndecent service.\nSecuring the name-resolution process is more involved, yet equally impor-\ntant, if only to guarantee proper reliability (we will return to the relationship\nbetween security and reliability in Chapter 8). For lookup services such as\nthose for mobile IP or hierarchical location services, we need to ensure that\nreturned (intermediate) answers make sense. We will discuss this in the\nnext section when zooming into Secure DNS. As mentioned before, securing\nDHT-based systems has proved to be rather problematic. There are several\nproblems to deal with, yet the most important ones deal with addressing\nSybil and eclipse attacks, as also discussed in Section 9.4.2. The bottom line\nis that robustness for DHT-based systems comes largely from ensuring that a\nnode identifier is genuine: it belongs to exactly one owner, and this fact can\nbe verified. In practice, this means that a centralized authority should be used\nfor handing out identifiers [Urdaneta et al., 2011].\n6.3\nStructured naming\nFlat names are good for machines, but are generally not very convenient\nfor humans to use. As an alternative, naming systems generally support\nstructured names that are composed from simple, human-readable names.\nNot only file naming, but also host naming on the Internet, follows this\napproach. In this section, we concentrate on structured names and the way\nthat these names are resolved to addresses.\n6.3.1\nName spaces\nNames are commonly organized into what is called a name space. Name\nspaces for structured names can be represented as a labeled, directed graph\nwith two types of nodes. A leaf node represents a named entity and has\nDS 4.01\n \n",
      "content_length": 2571,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 361,
      "content": "6.3. STRUCTURED NAMING\n345\nthe property that it has no outgoing edges. A leaf node generally stores\ninformation on the entity it is representing–for example, its address–so that a\nclient can access it. Alternatively, it can store the state of that entity, such as in\nthe case of file systems in which a leaf node actually contains the complete\nfile it is representing. We return to the contents of nodes below.\nIn contrast to a leaf node, a directory node has a number of outgoing\nedges, each labeled with a name, as shown in Figure 6.10 Each node in a\nnaming graph is considered as yet another entity in a distributed system, and,\nin particular, has an associated identifier. A directory node stores a table in\nwhich an outgoing edge is represented as a pair (node identifier, edge label).\nSuch a table is called a directory table.\nFigure 6.10: A general naming graph with a single root node.\nThe naming graph shown in Figure 6.10 has one node, namely n0, which\nhas only outgoing and no incoming edges. Such a node is called the root\n(node) of the naming graph. Although it is possible for a naming graph to\nhave several root nodes, for simplicity, many naming systems have only one.\nEach path in a naming graph can be referred to by the sequence of labels\ncorresponding to the edges in that path, such as N:[label1, label2, ..., labeln],\nwhere N refers to the first node in the path. Such a sequence is called a path\nname. If the first node in a path name is the root of the naming graph, it is\ncalled an absolute path name. Otherwise, it is called a relative path name.\nIt is important to realize that names are always organized in a name space.\nAs a consequence, a name is always defined relative only to a directory node.\nIn this sense, the term “absolute name” is somewhat misleading. Likewise,\nthe difference between global and local names can often be confusing. A\nglobal name is a name that denotes the same entity, no matter where that\nname is used in a system. In other words, a global name is always interpreted\nregarding the same directory node. In contrast, a local name is a name whose\ninterpretation depends on where that name is being used. Put differently,\na local name is essentially a relative name whose directory in which it is\ncontained is (implicitly) known.\n \nDS 4.01\n",
      "content_length": 2293,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 362,
      "content": "346\nCHAPTER 6. NAMING\nThis description of a naming graph comes close to what is implemented\nin many file systems. However, instead of writing the sequence of edge\nlabels to represent a path name, path names in file systems are generally\nrepresented as a single string in which the labels are separated by a special\nseparator character, such as a slash (“/”). This character is also used to indicate\nwhether a path name is absolute. For example, in Figure 6.10 instead of using\nn0:[home, steen, mbox], that is, the actual path name, it is common practice to\nuse its string representation “/home/steen/mbox.” Note also that when there\nare several paths that lead to the same node, that node can be represented by\ndifferent path names. For example, node n5 in Figure 6.10 can be referred to\nby “/home/steen/keys” as well as “/keys.” The string representation of path\nnames can be equally well applied to naming graphs other than those used for\nonly file systems. In Plan 9 [Pike et al., 1995], all resources, such as processes,\nhosts, I/O devices, and network interfaces, are named in the same fashion as\ntraditional files. This approach is analogous to implementing a single naming\ngraph for all resources in a distributed system.\nThere are many ways to organize a name space. As we mentioned, most\nname spaces have only a single root node. Often, a name space is also strictly\nhierarchical, in the sense that the naming graph is organized as a tree. This\nmeans that each node, except the root, has exactly one incoming edge; the\nroot has no incoming edges. As a consequence, each node also has exactly\none associated (absolute) path name.\nThe naming graph shown in Figure 6.10 is an example of directed acyclic\ngraph. In such an organization, a node can have more than one incoming\nedge, but the graph is not permitted to have a cycle. There are also name\nspaces that do not have this restriction.\nNote 6.3 (More information: Implementing the Unix naming graph)\nTo make matters more concrete, consider the way that files in a traditional Unix\nfile system are named. In a naming graph for Unix a directory node represents a\nfile directory, whereas a leaf node represents a file. There is a single root directory,\nrepresented in the naming graph by the root node. The implementation of the\nnaming graph is an integral part of the complete implementation of the file system.\nThat implementation consists of a contiguous series of blocks from a logical disk,\ngenerally divided into a boot block, a superblock, a series of index nodes (called\ninodes), and file data blocks. See also [Silberschatz et al., 2019] or [Tanenbaum\nand Bos, 2022]. This organization is shown in Figure 6.11.\nThe boot block is a special block of data and instructions that are automatically\nloaded into main memory when the system is booted. The boot block is used to\nload the operating system into main memory.\nThe superblock contains information on the entire file system, such as its size,\nwhich blocks on disk are not yet allocated, which inodes are not yet used, and so\non. Inodes are referred to by an index number, starting at number zero, which is\nreserved for the inode representing the root directory.\nDS 4.01\n \n",
      "content_length": 3191,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 363,
      "content": "6.3. STRUCTURED NAMING\n347\nFigure 6.11: The general organization of the Unix file system implementa-\ntion on a logical disk of contiguous disk blocks.\nEach inode contains information on where the data of its associated file can\nbe found on disk. In addition, an inode contains information on its owner, time\nof creation and last modification, protection, and the like. Consequently, when\ngiven the index number of an inode, it is possible to access its associated file.\nEach directory is implemented as a file as well. This is also the case for the root\ndirectory, which contains a mapping between file names and index numbers of\ninodes. It is thus seen that the index number of an inode corresponds to a node\nidentifier in the naming graph.\n6.3.2\nName resolution\nName spaces offer a convenient mechanism for storing and retrieving infor-\nmation about entities through names. More generally, given a path name, it\nshould be possible to look up any information stored in the node referred to\nby that name. The process of looking up a name is called name resolution.\nTo explain how name resolution works, let us consider a path name such\nas N:[label1, label2, ..., labeln]. Resolution of this name starts at node N of the\nnaming graph, where the name label1 is looked up in the directory table, and\nwhich returns the identifier of the node to which label1 refers. Resolution then\ncontinues at the identified node by looking up the name label2 in its directory\ntable, and so on. Assuming that the named path actually exists, resolution\nstops at the last node referred to by labeln, by returning that node’s content.\nNote 6.4 (More information: The Unix naming graph again)\nA name lookup returns the identifier of a node, from where the name resolution\nprocess continues. In particular, it is necessary to access the directory table of\nthe identified node. Consider again a naming graph for a Unix file system. As\nmentioned, a node identifier is implemented as the index number of an inode.\nAccessing a directory table means that first the inode has to be read to find out\nwhere the actual data are stored on disk, and then subsequently to read the data\nblocks containing the directory table.\n \nDS 4.01\n",
      "content_length": 2199,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 364,
      "content": "348\nCHAPTER 6. NAMING\nClosure mechanism\nName resolution can take place only if we know how and where to start. In\nour example, the starting node was given, and we assumed we had access to its\ndirectory table. Knowing how and where to start name resolution is generally\nreferred to as a closure mechanism. Essentially, a closure mechanism deals\nwith selecting the initial node in a name space, from which name resolution\nis to start [Radia, 1989]. What makes closure mechanisms sometimes hard\nto understand is that they are necessarily partly implicit and may be very\ndifferent when comparing them to each other.\nConsider, for example, the string “00312059837784”. Many people will not\nknow what to do with these numbers, unless they are told that the sequence\nis a telephone number. That information is enough to start the resolution\nprocess, in particular, by entering the number at a device for making phone\ncalls. The telephone system subsequently does the rest.\nAs another example, consider the use of global and local names in dis-\ntributed systems. A typical example of a local name is an environment variable.\nFor example, in Unix systems, the variable named HOME is used to refer to\nthe home directory of a user. Each user has their own copy of this variable,\nwhich is initialized to the global, systemwide name corresponding to the\nuser’s home directory. The closure mechanism associated with environment\nvariables ensure that the name of the variable is properly resolved by looking\nit up in a user-specific table.\nNote 6.5 (More information: The Unix naming graph and its closure mechanism)\nName resolution in the naming graph for a Unix file system makes use of the fact\nthat the inode of the root directory is the first inode in the logical disk representing\nthe file system. Its actual byte offset is calculated from the values in other fields\nof the superblock, together with hard-coded information in the operating system\nitself on the internal organization of the superblock.\nTo make this point clear, consider the string representation of a file name,\nsuch as /home/steen/mbox. To resolve this name, it is necessary to already\nhave access to the directory table of the root node of the appropriate naming\ngraph. Being a root node, the node itself cannot have been looked up unless it\nis implemented as a different node in another naming graph, say G. But in that\ncase, it would have been necessary to already have access to the root node of G.\nConsequently, resolving a file name requires that some mechanism has already\nbeen implemented by which the resolution process can start.\nIn this respect, observe how the closure mechanism works in the case of\ncontainers: the chroot command is used to make applications within a specific\ncontainer see a different root than those in another container. In other words, each\ncontainer offers its own naming graph to the contained applications, whereas the\noperating system hosting the containers provides a closure to properly start name\nresolution independent of each other.\nDS 4.01\n \n",
      "content_length": 3045,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 365,
      "content": "6.3. STRUCTURED NAMING\n349\nLinking and mounting\nStrongly related to name resolution is the use of aliases. An alias is another\nname for the same entity. An environment variable is an example of an alias.\nIn terms of naming graphs, there are basically two different ways to implement\nan alias. The first approach is to simply allow multiple absolute paths names\nto refer to the same node in a naming graph. This approach is illustrated in\nFigure 6.10, in which the node n5 can be referred to by two different path\nnames. In Unix terminology, both path names /keys and /home/steen/keys\nin Figure 6.12 are called hard links to node n5.\nThe second approach is to represent an entity by a leaf node, say N, but\ninstead of storing the address or state of that entity, the node stores an absolute\npath name. When first resolving an absolute path name that leads to N, name\nresolution will return the path name stored in N, at which point it can continue\nwith resolving that new path name. This principle corresponds to the use of\nsymbolic links in Unix file systems, and is illustrated in Figure 6.12 In this\nexample, the path name /home/steen/keys, which refers to a node containing\nthe absolute path name /keys, is a symbolic link to node n5.\nFigure 6.12: The concept of a symbolic link explained in a naming graph.\nName resolution as described so far takes place completely within a single\nname space. However, name resolution can also be used to merge different\nname spaces transparently. Let us first consider a mounted file system. In\nterms of our naming model, a mounted file system corresponds to letting a\ndirectory node store the identifier of a directory node from a different name\nspace, which we refer to as a foreign name space. The directory node storing\nthe node identifier is called a mount point. Accordingly, the directory node in\nthe foreign name space is called a mounting point. Normally, the mounting\npoint is the root of a name space. During name resolution, the mounting point\nis looked up and resolution proceeds by accessing its directory table.\nThe principle of mounting can be generalized to other name spaces as\nwell. In particular, what is needed is a directory node that acts as a mount\n \nDS 4.01\n",
      "content_length": 2222,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 366,
      "content": "350\nCHAPTER 6. NAMING\npoint and stores all the necessary information for identifying and accessing\nthe mounting point in the foreign name space. This approach is followed in\nmany distributed file systems.\nConsider a collection of name spaces that is distributed across different\nmachines. In particular, each name space is implemented by a different server,\neach possibly running on a separate machine. Consequently, if we want to\nmount a foreign name space NS2 into a name space NS1, it may be necessary\nto communicate over a network with the server of NS2, as that server may be\nrunning on a different machine than the server for NS1. To mount a foreign\nname space in a distributed system requires at least the following information:\n1. The name of an access protocol.\n2. The name of the server.\n3. The name of the mounting point in the foreign name space.\nNote that each of these names needs to be resolved. The name of an access\nprotocol needs to be resolved to the implementation of a protocol by which\ncommunication with the server of the foreign name space can take place. The\nname of the server needs to be resolved to an address where that server can\nbe reached. As the last part in name resolution, the name of the mounting\npoint needs to be resolved to a node identifier in the foreign name space.\nIn nondistributed systems, none of the three points may actually be needed.\nFor example, in Unix there is no access protocol and no server. Also, the name\nof the mounting point is not necessary, as it is simply the root directory of the\nforeign name space.\nThe name of the mounting point is to be resolved by the server of the\nforeign name space. However, we also need name spaces and implementations\nfor the access protocol and the server name. One possibility is to represent\nthe three names listed above as a URL.\nTo make matters concrete, consider a situation in which a user with\na laptop computer wants to access files that are stored on a remote file\nserver. The client machine and the file server are both configured with the\nNetwork File System (NFS). In particular, to allow NFS to work across\nthe Internet, a client can specify exactly which file it wants to access by\nmeans of an NFS URL, for example, nfs://flits.cs.vu.nl/home/steen. This URL\nnames a file (which happens to be a directory) called /home/steen on an NFS\nfile server flits.cs.vu.nl, which can be accessed by a client through the NFS\nprotocol [Haynes, 2015; Noveck and Lever, 2020].\nThe name nfs is a well-known name, in the sense that worldwide agreement\nexists on how to interpret that name. Given that we are dealing with a URL,\nthe name nfs will be resolved to an implementation of the NFS protocol. The\nserver name is resolved to its address using DNS, which is discussed in a\nlater section. As we said, /home/steen is resolved by the server of the foreign\nname space.\nDS 4.01\n \n",
      "content_length": 2869,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 367,
      "content": "6.3. STRUCTURED NAMING\n351\nFigure 6.13: Mounting remote name spaces through a specific protocol.\nThe organization of a file system on the client machine is partly shown in\nFigure 6.13 The root directory has a number of user-defined entries, including\na subdirectory called /remote. This subdirectory is intended to include mount\npoints for foreign name spaces, such as the user’s home directory at VU\nUniversity. To this end, a directory node named /remote/vu is used to store\nthe URL nfs://flits.cs.vu.nl/home/steen.\nNow consider the name /remote/vu/mbox. This name is resolved by\nstarting in the root directory on the client’s machine and continues until the\nnode /remote/vu is reached. The process of name resolution then continues\nby returning the URL nfs://flits.cs.vu.nl/home/steen, in turn leading the client\nmachine to contact the file server flits.cs.vu.nl through the NFS protocol, and\nto subsequently access directory /home/steen. Name resolution can then be\ncontinued by reading the file named mbox in that directory, after which the\nresolution process stops.\nDistributed systems that allow mounting a remote file system as just\ndescribed allow a client machine to, for example, execute the following com-\nmands (assume the client machine is named horton):\nhorton$ cd /remote/vu\nhorton$ ls -l\nwhich subsequently lists the files in the directory /home/steen on the remote\nfile server. The beauty of all this is that the user is spared the details of the\n \nDS 4.01\n",
      "content_length": 1475,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 368,
      "content": "352\nCHAPTER 6. NAMING\nactual access to the remote server. Ideally, only some loss in performance is\nnoticed compared to accessing locally available files. In effect, to the client it\nappears that the name space rooted on the local machine, and the one rooted\nat /home/steen on the remote machine, form a single name space.\nNote 6.6 (More information: Mounting across a network in Unix)\nThere are many ways in which mounting across a network can take place. One\npractical solution and adopted by many small-scale distributed systems, is to\nsimply assign fixed IP addresses to machines and subsequently offer mounting\npoints to clients. Consider the following example. Suppose we have a Unix\nmachine named coltrane using the private address 192.168.2.3, storing a collection\nof music files under the local directory /audio. This directory can be exported as a\nmounting point, and as a consequence can be imported by another machine.\nLet quandar be such a machine, and suppose it wants to mount the collection\nof audio files at the local mount point /home/maarten/Music. The following\ncommand will do the job (assuming the correct privileges have been set):\nquandar$ mount -t nfs 192.168.2.3:/audio /home/maarten/Music\nFrom that moment on, all files available on coltrane in its directory /audio can be\naccessed by quandar in the directory /home/maarten/Music. The beauty of this\nscheme is that once mounted, there is no need to think of remote access anymore\n(until something fails, of course).\n6.3.3\nThe implementation of a name space\nA name space forms the heart of a naming service, that is, a service that\nallows users and processes to add, remove, and look up names. A naming\nservice is implemented by name servers. If a distributed system is restricted\nto a local-area network, it is often feasible to implement a naming service by\nonly a single name server. However, in large-scale distributed systems with\nmany entities, possibly spread across a large geographical area, it is necessary\nto distribute the implementation of a name space over multiple name servers.\nName space distribution\nName spaces for a large-scale, possibly worldwide distributed system, are\nusually organized hierarchically. As before, assume such a name space has\nonly a single root node. To effectively implement such a name space, it\nis convenient to partition it into logical layers. Cheriton and Mann [1989]\ndistinguish the following three layers.\nThe global layer is formed by highest-level nodes, that is, the root node\nand other directory nodes logically close to the root, namely its children.\nNodes in the global layer are often characterized by their stability, in the\nsense that directory tables are rarely changed. Such nodes may represent\nDS 4.01\n \n",
      "content_length": 2740,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 369,
      "content": "6.3. STRUCTURED NAMING\n353\norganizations, or groups of organizations, for which names are stored in the\nname space.\nThe administrational layer is formed by directory nodes that, together, are\nmanaged within a single organization. A characteristic feature of the directory\nnodes in the administrational layer is that they represent groups of entities\nthat belong to the same organization or administrational unit. For example,\nthere may be a directory node for each department in an organization, or a\ndirectory node from which all hosts can be found. Another directory node\nmay be used as the starting point for naming all users, and so forth. The\nnodes in the administrational layer are relatively stable, although changes\ngenerally occur more frequently than to nodes in the global layer.\nFinally, the managerial layer consists of nodes that may typically change\nregularly. For example, nodes representing hosts in the local network belong\nto this layer. For the same reason, the layer includes nodes representing shared\nfiles, such as those for libraries or binaries. Another important class of nodes\nincludes those that represent user-defined directories and files. In contrast\nto the global and administrational layer, the nodes in the managerial layer\nare maintained not only by system administrators, but also by individual end\nusers of a distributed system.\norg\nnet\njp\nus\nnl\noracle\neng\nyale\neng\nai\nlinda\nrobot\nacm\njack\njill\nieee\nkeio\ncs\ncs\npc24\nco\nnec\ncsl\nuva\nvu\ncs\nftp\nwww\nac\ncom\nedu\ngov\nmil\npub\nglobule\nindex.htm\nMana-\ngerial\nlayer\nAdminis-\ntrational\nlayer\nGlobal\nlayer\nZone\nFigure 6.14: An example partitioning of the DNS name space, including\nInternet-accessible files, into three layers.\nTo make matters more concrete, Figure 6.14 shows an example of the\npartitioning of part of the DNS name space, including the names of files within\n \nDS 4.01\n",
      "content_length": 1858,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 370,
      "content": "354\nCHAPTER 6. NAMING\nan organization that can be accessed through the Internet, for example, Web\npages and transferable files. The name space is divided into nonoverlapping\nparts, called zones in DNS [Mockapetris, 1987a;b]. A zone is a part of the\nname space that is implemented by a separate name server. Some of these\nzones are illustrated in Figure 6.14.\nIf we take a look at availability and performance, name servers in each\nlayer have to meet different requirements. High availability is especially\ncritical for name servers in the global layer. If a name server fails, a large\npart of the name space will be unreachable because name resolution cannot\nproceed beyond the failing server.\nPerformance is somewhat subtle. Due to the low rate of change of nodes\nin the global layer, the results of lookup operations generally remain valid for\na long time. Consequently, those results can be effectively cached (i.e., stored\nlocally) by the clients. The next time the same lookup operation is performed,\nthe results can be retrieved from the client’s cache instead of letting the name\nserver return the results. As a result, name servers in the global layer do\nnot have to respond quickly to a single lookup request. On the other hand,\nthroughput may be important, especially in large-scale systems with millions\nof users.\nThe availability and performance requirements for name servers in the\nglobal layer can be met by replicating servers, with client-side caching. Up-\ndates in this layer generally do not have to come into effect immediately,\nmaking it much easier to keep replicas consistent.\nAvailability for a name server in the administrational layer is primarily\nimportant for clients in the same organization as the name server. If the name\nserver fails, many resources within the organization become unreachable\nbecause they cannot be looked up. On the other hand, it may be less important\nthat resources in an organization are temporarily unreachable for users outside\nthat organization.\nRegarding performance, name servers in the administrational layer have\nsimilar characteristics as those in the global layer. Because changes to nodes\ndo not occur all that often, caching lookup results can be highly effective,\nmaking performance less critical. However, in contrast to the global layer,\nthe administrational layer should take care that lookup results are returned\nwithin a few milliseconds, either directly from the server or from the client’s\nlocal cache. Likewise, updates should generally be processed quicker than\nthose of the global layer. For example, it is unacceptable that an account for a\nnew user takes hours to become effective.\nThese requirements can often be met by using relatively powerful machines\nto run name servers. In addition, client-side caching should be applied,\ncombined with replication, for increased overall availability.\nAvailability requirements for name servers at the managerial level are\ngenerally less demanding.\nIn particular, it often suffices to use a single\nDS 4.01\n \n",
      "content_length": 3024,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 371,
      "content": "6.3. STRUCTURED NAMING\n355\nmachine to run name servers at the risk of temporary unavailability. However,\nperformance is crucial: operations must take place immediately. Because\nupdates occur regularly, client-side caching is often less effective.\nIssue\nGlobal\nAdministrational\nManagerial\nGeographical scale\nWorldwide\nOrganization\nDepartment\nNumber of nodes\nFew\nMany\nVast numbers\nResponsiveness to lookups\nSeconds\nMilliseconds\nImmediate\nUpdate propagation\nLazy\nImmediate\nImmediate\nNumber of replicas\nMany\nNone or few\nNone\nClient-side caching\nYes\nYes\nSometimes\nFigure 6.15: A comparison between name servers for implementing nodes\nfrom a large-scale name space partitioned into a global layer, an administra-\ntional layer, and a managerial layer.\nA comparison between name servers at different layers is shown in Fig-\nure 6.15. In distributed systems, name servers in the global and administra-\ntional layer are the most difficult to implement. Difficulties are caused by\nreplication and caching, which are needed for availability and performance,\nbut which also introduce consistency problems. Some of the problems are\naggravated by the fact that caches and replicas are spread across a wide-area\nnetwork, which may introduce long communication delays during lookups.\nImplementation of name resolution\nThe distribution of a name space across multiple name servers affects the\nimplementation of name resolution. To explain the implementation of name\nresolution in large-scale name services, we assume for the moment that name\nservers are not replicated and that no client-side caches are used.\nEach\nclient has access to a local name resolver, which is responsible for ensuring\nthat the name resolution process is carried out. Referring to Figure 6.14,\nassume the (absolute) path name root:[nl, vu, cs, ftp, pub, globe, index.html] is to\nbe resolved. Using a URL notation, this path name would correspond to\nftp://ftp.cs.vu.nl/pub/globe/index.html. There are now two ways to imple-\nment name resolution.\nIn iterative name resolution, a name resolver hands over the complete\nname to the root name server. It is assumed that the address where the root\nserver can be contacted is well known. The root server will resolve the path\nname as far as it can, and return the result to the client. In our example, the\nroot server can resolve only the label nl, for which it will return the address of\nthe associated name server.\nAt that point, the client passes the remaining path name (i.e., nl:[vu, cs, ftp,\npub, globe, index.html]) to that name server. This server can resolve only the\n \nDS 4.01\n",
      "content_length": 2585,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 372,
      "content": "356\nCHAPTER 6. NAMING\nlabel vu, and returns the address of the associated name server, along with\nthe remaining path name vu:[cs, ftp, pub, globe, index.html].\nThe client’s name resolver will then contact this next name server, which\nresponds by resolving the label cs, and subsequently also ftp, returning the\naddress of the FTP server along with the path name ftp:[pub, globe, index.html].\nThe client then contacts the FTP server, requesting it to resolve the last part of\nthe original path name. The FTP server will subsequently resolve the labels\npub, globe, and index.html, and transfer the requested file (in this case using\nFTP). This process of iterative name resolution is shown in Figure 6.16. (The\nnotation #[cs] is used to indicate the address of the server responsible for\nhandling the node referred to by [cs].)\nFigure 6.16: The principle of iterative name resolution.\nIn practice, the last step, namely contacting the FTP server and requesting\nit to transfer the file with path name ftp:[pub, globe, index.html], is carried out\nseparately by the client process. In other words, the client would normally\nhand only the path name root:[nl, vu, cs, ftp] to the name resolver, from which\nit would expect the address where it can contact the FTP server, as is also\nshown in Figure 6.16\nAn alternative to iterative name resolution is to use recursion during name\nresolution. Instead of returning each intermediate result to the client’s name\nresolver, with recursive name resolution, a name server passes the result to\nthe next name server it finds. So, for example, when the root name server finds\nthe address of the name server implementing the node named nl, it requests\nthat name server to resolve the path name nl:[vu, cs, ftp, pub, globe, index.html].\nUsing recursive name resolution as well, this next server will resolve the\ncomplete path and eventually return the file index.html to the root server,\nwhich, in turn, will pass that file to the client’s name resolver.\nDS 4.01\n \n",
      "content_length": 1995,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 373,
      "content": "6.3. STRUCTURED NAMING\n357\nRecursive name resolution is shown in Figure 6.17. As in iterative name\nresolution, the last step (contacting the FTP server and asking it to transfer\nthe indicated file) is generally carried out as a separate process by the client.\nFigure 6.17: The principle of recursive name resolution.\nThe main drawback of recursive name resolution is that it puts a higher\nperformance demand on each name server. Basically, a name server is required\nto handle the complete resolution of a path name, although it may do so in\ncooperation with other name servers. This additional burden is generally\nso high that name servers in the global layer of a name space support only\niterative name resolution.\nThere are two important advantages to recursive name resolution. The first\nadvantage is that caching results is more effective compared to iterative name\nresolution. The second advantage is that communication costs may be reduced.\nTo explain these advantages, assume that a client’s name resolver will accept\npath names referring only to nodes in the global or administrational layer\nof the name space. To resolve that part of a path name that corresponds to\nnodes in the managerial layer, a client will separately contact the name server\nreturned by its name resolver, as we discussed above.\nRecursive name resolution allows each name server to gradually learn\nthe address of each name server responsible for implementing lower-level\nnodes. As a result, caching can be effectively used to enhance performance.\nFor example, when the root server is requested to resolve the path name\nroot:[nl, vu, cs, ftp], it will eventually get the address of the name server imple-\nmenting the node referred to by that path name. To come to that point, the\nname server for the nl node has to look up the address of the name server for\nthe vu node, whereas the latter has to look up the address of the name server\nhandling the cs node.\nBecause changes to nodes in the global and administrational layer do not\noccur often, the root name server can effectively cache the returned address.\n \nDS 4.01\n",
      "content_length": 2098,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 374,
      "content": "358\nCHAPTER 6. NAMING\nMoreover, because the address is also returned, by recursion, to the name\nserver responsible for implementing the vu node and to the one implementing\nthe nl node, it might as well be cached at those servers too.\nLikewise, the results of intermediate name lookups can also be returned\nand cached. For example, the server for the nl node will have to look up the\naddress of the vu node server. That address can be returned to the root server\nwhen the nl server returns the result of the original name lookup. A complete\noverview of the resolution process, and the results that can be cached by each\nname server, is shown in Figure 6.18.\nServer\nShould\nLooks up\nPasses to\nReceives\nReturns\nfor node\nresolve\nchild\nand caches\nto requester\ncs\n[ftp]\n#[ftp]\n—\n—\n#[ftp]\nvu\n[cs, ftp]\n#[cs]\n[ftp]\n#[ftp]\n#[cs]\n#[cs, ftp]\nnl\n[vu, cs, ftp]\n#[vu]\n[cs, ftp]\n#[cs]\n#[vu]\n#[cs, ftp]\n#[vu, cs]\n#[vu, cs, ftp]\nroot\n[nl, vu, cs, ftp] #[nl]\n[vu, cs, ftp]\n#[vu]\n#[nl]\n#[vu, cs]\n#[nl, vu]\n#[vu, cs, ftp]\n#[nl, vu, cs]\n#[nl, vu, cs, ftp]\nFigure 6.18: Recursive name resolution of [nl, vu, cs, ftp]. Name servers cache\nintermediate results for subsequent lookups.\nThe main benefit of this approach is that, eventually, lookup operations\ncan be handled quite efficiently. For example, suppose that another client later\nrequests resolution of the path name root:[nl, vu, cs, flits]. This name is passed\nto the root, which can immediately forward it to the name server for the cs\nnode, and request it to resolve the remaining path name cs:[flits].\nWith iterative name resolution, caching is necessarily restricted to the\nclient’s name resolver. Consequently, if a client A requests the resolution of a\nname, and another client B later requests that same name to be resolved, name\nresolution will have to pass through the same name servers as was done for\nclient A. As a compromise, many organizations use a local, intermediate name\nserver that is shared by all clients. This local name server handles all naming\nrequests and caches results. Such an intermediate server is also convenient\nfrom a management point of view. For example, only that server needs to\nknow where the root name server is located; other machines do not require\nthis information.\nThe second advantage of recursive name resolution is that it is often\ncheaper regarding communication. Again, consider the resolution of the path\nname root:[nl, vu, cs, ftp] and assume the client is located in San Francisco.\nAssuming that the client knows the address of the server for the nl node,\nDS 4.01\n \n",
      "content_length": 2553,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 375,
      "content": "6.3. STRUCTURED NAMING\n359\nwith recursive name resolution, communication follows the route from the\nclient’s host in San Francisco to the nl server in The Netherlands, shown\nas R1 in Figure 6.19 From there on, communication is subsequently needed\nbetween the nl server and the name server of VU University on the campus in\nAmsterdam, The Netherlands. This communication is shown as R2. Finally,\ncommunication is needed between the vu server and the name server in the\nComputer Science Department, shown as R3. The route for the reply is the\nsame, but in the opposite direction. Clearly, communication costs are dictated\nby the message exchange between the client’s host and the nl server.\nIn contrast, with iterative name resolution, the client’s host has to commu-\nnicate separately with the nl server, the vu server, and the cs server, of which\nthe total costs may be roughly three times that of recursive name resolution.\nThe arrows in Figure 6.19 labeled I1, I2, and I3 show the communication path\nfor iterative name resolution.\nFigure 6.19: The comparison between recursive and iterative name resolution\nregarding communication costs.\n6.3.4\nExample: The Domain Name System\nOne of the largest distributed naming services in use today is the Internet\nDomain Name System (DNS). DNS is primarily used for looking up IP\naddresses of hosts and mail servers. In the following pages, we concentrate\non the organization of the DNS name space and the information stored in its\nnodes. Also, we take a closer look at the actual implementation of DNS. More\ninformation can be found in [Mockapetris, 1987a;b] and [Liu and Albitz, 2006].\nAn excellent tutorial on DNS is provided by van der Toorn et al. [2022].\nThe DNS name space\nThe DNS name space is hierarchically organized as a rooted tree. A label is\na case-insensitive string made up of alphanumeric characters. A label has\na maximum length of 63 characters; the length of a complete path name is\n \nDS 4.01\n",
      "content_length": 1953,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 376,
      "content": "360\nCHAPTER 6. NAMING\nrestricted to 255 characters. The string representation of a path name consists\nof listing its labels, starting with the rightmost one, and separating the labels\nby a dot (“.”). The root is represented by a dot. So, for example, the path\nname root:[nl, vu, cs, flits], is represented by the string “flits.cs.vu.nl.”, which\nincludes the rightmost dot to indicate the root node. We generally omit this\ndot for readability.\nBecause each node in the DNS name space has exactly one incoming edge\n(except for the root node, which has no incoming edges), the label attached to\na node’s incoming edge is also used as the name for that node. A subtree is\ncalled a domain; a path name to its root node is called a domain name. Note\nthat, just like a path name, a domain name can be either absolute or relative.\nThe contents of a node is formed by a collection of resource records.\nThere are different types of resource records. The major ones are shown in\nFigure 6.20.\nType\nRefers to\nDescription\nSOA\nZone\nHolds info on the represented zone\nA\nHost\nIP addr. of host this node represents\nMX\nDomain\nMail server to handle mail for this node\nSRV\nDomain\nServer handling a specific service\nNS\nZone\nName server for the represented zone\nCNAME\nNode\nSymbolic link\nPTR\nHost\nCanonical name of a host\nHINFO\nHost\nInfo on this host\nTXT\nAny kind\nAny info considered useful\nFigure 6.20: The most important types of resource records forming the con-\ntents of nodes in the DNS name space.\nA node in the DNS name space will often represent several entities at the\nsame time. For example, a domain name such as vu.nl is used to represent\na domain and a zone. In this case, the domain is implemented by means of\nseveral (nonoverlapping) zones.\nAn SOA (start of authority) resource record contains information such as\nan e-mail address of the system administrator responsible for the represented\nzone, the name of the host where data on the zone can be fetched, and so on.\nAn A (address) record, represents a particular host on the Internet. The A\nrecord contains an IP address for that host to allow communication. If a host\nhas several IP addresses, as is the case with multi-homed machines, the node\nwill contain an A record for each address.\nAnother type of record is the MX (mail exchange) record, which is like a\nsymbolic link to a node representing a mail server. For example, the node\nrepresenting the domain cs.vu.nl has an MX record that used to contain the\nDS 4.01\n \n",
      "content_length": 2465,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 377,
      "content": "6.3. STRUCTURED NAMING\n361\nname zephyr.cs.vu.nl which refers to a mail server. That server would handle\nall incoming mail addressed to users in the cs.vu.nl domain. There may be\nseveral MX records stored in a node.\nRelated to MX records are SRV records, which contain the name of a server\nfor a specific service. The service itself is identified through a name along with\nthe name of a protocol. For example, the Web server in the cs.vu.nl domain\ncould be named using an SRV record, such as website.cs.vu.nl. This record\nwould then refer to the actual name of the server (which is soling.cs.vu.nl).\nAn important advantage of SRV records is that clients need no longer know\nthe DNS name of the host providing a specific service. Instead, only service\nnames need to be standardized, after which the providing host can be looked\nup.\nNodes that represent a zone, contain one or more NS (name server) records.\nLike MX records, an NS record contains the name of a name server that\nimplements the zone represented by the node. In principle, each node in\nthe name space can store an NS record referring to the name server that\nimplements it. However, as we discuss below, the implementation of the\nDNS name space is such that only nodes representing zones need to store NS\nrecords.\nDNS distinguishes aliases from what are called canonical names. Each\nhost is assumed to have a canonical, or primary name. An alias is implemented\nusing a node storing a CNAME record containing the canonical name of a host.\nThe name of the node storing such a record is thus the same as a symbolic\nlink, as was shown in Figure 6.12.\nDNS maintains an inverse mapping of IP addresses to host names using\nPTR (pointer) records. To accommodate the lookups of host names when\ngiven only an IP address, DNS maintains a domain named in-addr.arpa, which\ncontains nodes that represent Internet hosts and which are named by the IP\naddress of the represented host. For example, host www.cs.vu.nl once had\nIP address 130.37.20.20. DNS creates a node named 20.20.37.130.in-addr.arpa,\nwhich is used to store the canonical name of that host (which happens to be\nsoling.cs.vu.nl in a PTR record).\nFinally, an HINFO (host info) record is used to store additional information\non a host, such as its machine type and operating system. Similarly, TXT\nrecords are used for any other kind of data that a user finds useful to store\nabout the entity represented by the node.\nDNS implementation\nIn essence, the DNS name space can be divided into a global layer and an\nadministrational layer, as shown in Figure 6.14. The managerial layer, which\nis generally formed by local file systems, is formally not part of DNS, and is\ntherefore also not managed by it.\n \nDS 4.01\n",
      "content_length": 2717,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 378,
      "content": "362\nCHAPTER 6. NAMING\nEach zone is implemented by a name server, which is virtually always\nreplicated for availability. Updates for a zone are normally handled by the\nprimary name server. Updates take place by modifying the DNS database\nlocal to the primary server. Secondary name servers do not access the database\ndirectly, but, instead, request the primary server to transfer its content. The\nlatter is called a zone transfer in DNS terminology.\nA DNS database is implemented as a (small) collection of files, of which\nthe most important one contains all the resource records for all the nodes in a\nparticular zone. This approach allows nodes to be simply identified through\ntheir domain name, by which the notion of a node identifier reduces to an\n(implicit) index into a file.\nNote 6.7 (More information: An example DNS database)\nTo better understand these implementation issues, Figure 6.21 shows a small part\nof the file that contains most of the information for a previous organization of the\ncs.vu.nl domain. Note that we have deliberately chosen an outdated version for\nsecurity reasons. The file has been edited for readability. It shows the content\nof several nodes that used to be part of the cs.vu.nl domain, where each node is\nidentified through its domain name.\nIn this example, the node cs.vu.nl represents the domain as well as the zone.\nIts SOA resource record contains specific information on the validity of this file,\nwhich will not concern us further. There are four name servers for this zone,\nreferred to by their canonical host names in the NS records. The TXT record is\nused to give some additional information on this zone, but cannot be automatically\nprocessed by any name server. Furthermore, there is a single mail server that can\nhandle incoming mail addressed to users in this domain. The number preceding\nthe name of a mail server specifies a selection priority. A sending mail server\nshould always first attempt to contact the mail server with the lowest number.\nThe host star.cs.vu.nl operates as a name server for this zone. Name servers\nare critical to any naming service. What can be seen about this name server\nis that additional robustness has been created by giving two separate network\ninterfaces, each represented by a separate A resource record. In this way, the\neffects of a broken network link can be somewhat alleviated, as the server will\nremain accessible.\nThe next four lines (for zephyr.cs.vu.nl) give the necessary information about\none of the department’s mail servers. Note that this mail server is also backed up\nby another mail server, whose path is tornado.cs.vu.nl.\nThe next six lines show a typical configuration in which the department’s\nWeb server, as well as the department’s FTP server, are implemented by a single\nmachine, called soling.cs.vu.nl. By executing both servers on the same machine\n(and essentially using that machine only for Internet services and not anything\nelse), system management becomes easier. For example, both servers will have\nthe same view of the file system, and for efficiency, part of the file system may be\nimplemented on soling.cs.vu.nl. This approach is often applied in the case of Web\nand FTP services.\nDS 4.01\n \n",
      "content_length": 3210,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 379,
      "content": "6.3. STRUCTURED NAMING\n363\nThe following two lines show information on one of the department’s server\nclusters at that time. In this case, it tells us that the address 130.37.198.0 is\nassociated with the host name vucs-das1.cs.vu.nl.\nName\nRecord type\nRecord value\ncs.vu.nl.\nSOA\nstar.cs.vu.nl. hostmaster.cs.vu.nl.\n2005092900 7200 3600 2419200 3600\ncs.vu.nl.\nTXT\n“VU University - Computer Science”\ncs.vu.nl.\nMX\n1 mail.few.vu.nl.\ncs.vu.nl.\nNS\nns.vu.nl.\ncs.vu.nl.\nNS\ntop.cs.vu.nl.\ncs.vu.nl.\nNS\nsolo.cs.vu.nl.\ncs.vu.nl.\nNS\nstar.cs.vu.nl.\nstar.cs.vu.nl.\nA\n130.37.24.6\nstar.cs.vu.nl.\nA\n192.31.231.42\nstar.cs.vu.nl.\nMX\n1 star.cs.vu.nl.\nstar.cs.vu.nl.\nMX\n666 zephyr.cs.vu.nl.\nstar.cs.vu.nl.\nHINFO\n“Sun” “Unix”\nzephyr.cs.vu.nl.\nA\n130.37.20.10\nzephyr.cs.vu.nl.\nMX\n1 zephyr.cs.vu.nl.\nzephyr.cs.vu.nl.\nMX\n2 tornado.cs.vu.nl.\nzephyr.cs.vu.nl.\nHINFO\n“Sun” “Unix”\nftp.cs.vu.nl.\nCNAME\nsoling.cs.vu.nl.\nwww.cs.vu.nl.\nCNAME\nsoling.cs.vu.nl.\nsoling.cs.vu.nl.\nA\n130.37.20.20\nsoling.cs.vu.nl.\nMX\n1 soling.cs.vu.nl.\nsoling.cs.vu.nl.\nMX\n666 zephyr.cs.vu.nl.\nsoling.cs.vu.nl.\nHINFO\n“Sun” “Unix”\nvucs-das1.cs.vu.nl.\nPTR\n0.198.37.130.in-addr.arpa.\nvucs-das1.cs.vu.nl.\nA\n130.37.198.0\ninkt.cs.vu.nl.\nHINFO\n“OCE” “Proprietary”\ninkt.cs.vu.nl.\nA\n192.168.4.3\npen.cs.vu.nl.\nHINFO\n“OCE” “Proprietary”\npen.cs.vu.nl.\nA\n192.168.4.2\nlocalhost.cs.vu.nl.\nA\n127.0.0.1\nFigure 6.21: An excerpt from an (old) DNS database for the zone cs.vu.nl.\nThe next four lines show information on two major printers connected to the\nlocal network. Note that addresses in the range 192.168.0.0 to 192.168.255.255\nare private: they can be accessed only from inside the local network and are\ninaccessible from an arbitrary Internet host.\nBecause the cs.vu.nl domain was implemented as a single zone, Figure 6.21\ndoes not include references to other zones.\nThe way to refer to nodes in a\nsubdomain that are implemented in a different zone is shown in Figure 6.22.\nWhat needs to be done is to specify a name server for the subdomain by simply\n \nDS 4.01\n",
      "content_length": 1992,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 380,
      "content": "364\nCHAPTER 6. NAMING\ngiving its domain name and IP address. When resolving a name for a node that\nlies in the cs.vu.nl domain, name resolution will continue at a certain point by\nreading the DNS database stored by the name server for the cs.vu.nl domain.\nName\nRecord type\nRecord value\ncs.vu.nl.\nNS\nsolo.cs.vu.nl.\ncs.vu.nl.\nNS\nstar.cs.vu.nl.\ncs.vu.nl.\nNS\nns.vu.nl.\ncs.vu.nl.\nNS\ntop.cs.vu.nl.\nns.vu.nl.\nA\n130.37.129.4\ntop.cs.vu.nl.\nA\n130.37.20.4\nsolo.cs.vu.nl.\nA\n130.37.20.5\nstar.cs.vu.nl.\nA\n130.37.24.6\nstar.cs.vu.nl.\nA\n192.31.231.42\nFigure 6.22: Part of the description for the vu.nl domain which contains\nthe cs.vu.nl domain.\nModern DNS\nFollowing the terminology from van der Toorn et al. [2022], we speak of\nthe modern DNS to refer to the current-day implementation of DNS. There\nare a number of changes to the DNS implementation that are important for\nunderstanding its behavior. The presentation so far, roughly assumes that that\napplications contact a local DNS resolver, and that this resolver subsequently\ncontacts various name servers, as shown in Figure 6.23(a). The bounding\nboxes with dashed lines represent the borders of the organization where the\nclients, resolver, and name servers belong to, respectively. In the traditional\nsetup, the clients contact the local DNS resolver, which can be thought of as\nconnected to the same local network, or the one from the local ISP. The name\nservers each belong to a different organization.\nIn the modern DNS, we see three phenomena. First, many organizations\nwill make use of an external DNS resolver. We explained in Section 3.4.4 that\nservices like CDNs use the client’s address to select a nearby server when\nresolving a URL. However, the address that the CDN service gets is not that\nof the client, but of the DNS resolver that the client uses. Clearly, if the DNS\nresolver is not close to the client, then a CDN may make a poor decision on\nselecting a nearby server. This problem can be mitigated if the local DNS\nresolver allows the client (or the requesting host) to also specify its own IP\naddress. In that case, a CDN DNS name server can use that address to select\nthe best server to eventually redirect the client to [Contavalli et al., 2016].\nSecond, is that many clients, and notably browsers, may actually bypass\nany configuration of their local organization and directly contact the DNS\nDS 4.01\n \n",
      "content_length": 2367,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 381,
      "content": "6.3. STRUCTURED NAMING\n365\n(a)\n(b)\nFigure 6.23: (a) The traditional organization of the implementation of DNS and\n(b) the modern organization that has already been partly realized (adapted\nfrom [van der Toorn et al., 2022]).\nresolver of their own choice. Of course, there is nothing wrong with this, yet\nit makes it much harder to measure what is happening with DNS requests\nfrom an organization’s perspective, especially if the client-to-resolver com-\nmunication is also encrypted. In addition, the drawback of using an external\nresolver for redirecting requests to a nearby server also holds in this case.\nThe third phenomenon is that increasingly fewer organizations are running\ntheir own DNS servers. Instead, the name-resolution process is outsourced to\nthird parties. In a sense, this means that the DNS is becoming increasingly\nless decentralized [Moura et al., 2020]. It is yet unclear what the consequences\nare of this centralization, but considering the many discussions on the role\nof the Big Tech companies, striving for spreading the DNS across multiple\norganizations may not be a bad idea.\nAs with so many (public) naming and lookup services, we need to provide\nthe means for checking the validity of an answer. DNS is in the sense no\nexception. Moreover, being one of the most used and even necessary services\non the Internet, securing the DNS is crucial. At the same time, when we\nrealize that the DNS is becoming more centralized and end users are actually\nsubmitting a lot of information on how they make use of the Internet using\ntheir DNS queries, we also need to consider protecting the privacy of end\nusers. Let us look briefly into these two subjects. A systematic overview of\nsecurity and privacy issues in DNS is provided by Khormali et al. [2021].\n \nDS 4.01\n",
      "content_length": 1784,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 382,
      "content": "366\nCHAPTER 6. NAMING\nSecuring DNS responses\nDiscussions on facilitating the validation of DNS\nresponses started already in the 1990s. At present, we see that in a vast major-\nity of countries worldwide, all top-level domains support what is known as\nDNSSEC, i.e., DNS Security extensions. DNSSEC is, in principle, a straight-\nforward system by which resource records are signed by the organization\nowning a zone. To this end, DNS needed to be extended in two ways. The\nfirst, obvious one, is that new fields needed to be added to the set of records\nfor containing signatures and keys. Second, and quite important, is that larger\nqueries and responses had to be supported than what traditional UDP mes-\nsages would allow. The original DNS completely relied on fitting everything\ninto 512-byte packets. Using so-called extension mechanisms for DNS allows\nfor the acceptance of DNS queries and responses beyond 512 bytes [Damas\net al., 2013].\nThe basic idea is simple. First, resource records of the same type are\ngrouped into a separate set, which is then subsequently signed. So, for\nexample, a zone will contain a separate set with all its IPv4 addresses, a\nseparate set for all its IPv6 addresses, its name servers, and so on. The public\nkey associated with the secret key used for signing a set of resource records\nis also added to a zone. At that point, any client receiving a set of resource\nrecords can check that set against the provided signature. To recall, this means\nthat the set of resource records is hashed, and the hashed value is encrypted\nwith the secret key of the zone owner. When receiving the set, the client\nhashes it as well, and decrypts the version that was also in the response.\nWhen the two match, the client will believe the returned records are valid.\nOf course, the client will need to trust that the provided public key, known\nas a zone-signing key is valid. To this end, all the provided zone-signing keys\nare grouped again into a separate set, which is subsequently signed using yet\nanother secret key. The associated public key is known as the key-signing\nkey. What happens is that a hash of the key-signing key is stored, and signed\nby the parent domain. The parent domain, of course, signs this hash with\nthe secret key associated with its zone-signing key, which, in turn, is signed\nwith the secret key associated with the parent’s key-signing key. In this way,\nwe establish a trust chain all the way to the root. This scheme of signing in\nDNSSEC is shown in Figure 6.24.\nWe show part of the zone information available at three different levels,\nincluding the root level (level 0). For the lowest level, we show only one specific\nset of resource records RR. The zone at each level k includes information\nconcerning which hash function HZk is used for signing records, or HKk for\nsigning a zone-signing key. We use the notation SKZk to denote the secret key\nassociated with the (public) key ZSKk and, likewise, SKKk for the secret key\nassociated with the key-signing key KSKk. Knowing HZ2 and ZSK2 will allow\na client to verify the signature SKZ2(HZ2(RR)) by checking\nZSK2(SKZ2(HZ2(RR))) ?= HZ2(RR)\nDS 4.01\n \n",
      "content_length": 3145,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 383,
      "content": "6.3. STRUCTURED NAMING\n367\nFigure 6.24: The relation between various resource records and keys in\nDNSSEC across three levels.\nIf the client wants to be sure that the public zone-signing key ZSK2 is in order,\nit needs to get information from the parent zone, i.e., the zone at level 1. At\nthat level, the zone owner has stored a signed hash value SKZ1(HZ1(KSK2)),\neffectively allowing anyone to validate the key-signing key KSK2 and the use\nof its associated secret key SKK2 that was used for signing ZSK2. Obviously,\nthe parent zone would never store such information without having going\nthrough a process of ensuring that its child zone is indeed properly owned\nand operating as it should.\nProtecting DNS users\nIn general, one can state that information stored in\nDNS is public: it can be viewed as a huge open database that allows us\nto resolve human-friendly names to addresses and other data. However,\nwhat a client is asking from the DNS is, in principle, no one else’s business.\nThat means that queries should be kept confidential. There are roughly two\nincreasingly often supported protection mechanisms deployed in the modern\nDNS.\nFirst, systems today allow applications to set up a secure channel to a\nremote DNS resolver through TLS, mostly by that application’s local resolver,\nwhich runs on the local operating system. We discuss TLS in Section 9.3.2. In\neffect, having DNS over TLS prevents a third party from discovering to which\nWebsites an application is actually referring. Obviously, both the local DNS\nresolver and the remote resolver need to be trusted not to leak information,\nand are sufficiently protected against attacks. Note that facilitating DNS over\nTLS requires that a resolver uses a specific port (in this case, port 853).\nSecond, many modern browsers support issuing DNS queries over HTTPS.\nIn this case, the browser is configured to directly access a remote DNS resolver\nthat supports DNS over HTTPS. As HTTPS runs over TLS, this mechanism\nessentially offers the same protection as DNS over TLS. A major difference, of\ncourse, is that DNS queries are now completely handled out of the control of\nlocal administrators. This also means that local policies concerning allowing\nor denying access to certain sites are bypassed, for better or for worse.\nUsing DNS over either TLS or HTTPS is already an improvement over\n \nDS 4.01\n",
      "content_length": 2358,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 384,
      "content": "368\nCHAPTER 6. NAMING\nhaving no confidentiality concerning DNS queries, yet it may not be suffi-\ncient. Name resolution as explained so far, and illustrated in Figure 6.16 and\nFigure 6.17, shows that the entire path is sent to a name server. Of course,\nthe queries between name servers can also be protected, yet a more efficient\nand generally sufficient protection mechanism is to let a name server ask for\nresolving only the relevant part of a path. So, for example, instead of asking\nto return an answer for ftp.cs.vu.nl (and get the address for the name server\nhandling the nl domain), a resolver asks the root server to resolve .nl. We omit\na few important details (such as how does the resolver know whether multiple\ncomponents in a path are handled by the same name server), yet it can be\nseen that simply limiting a query can indeed help in attaining confidentiality.\nNote 6.8 (Advanced: Decentralized versus hierarchical DNS implementations)\nThe implementation of DNS we described so far is the standard one. It follows\na hierarchy of servers with 13 well-known root nodes and ending in millions of\nservers at the leaves (but read on). An important observation is that higher-level\nnodes receive many more requests than lower-level nodes. Only by caching the\nname-to-address bindings of these higher levels, it becomes possible to avoid\nsending requests to them and thus swamping them.\nThese scalability problems can, in principle, be avoided altogether with fully\ndecentralized solutions. In particular, we can compute the hash of a DNS name,\nand subsequently take that hash as a key value to be looked up in a distributed\nhash table or a hierarchical location service with a fully partitioned root node.\nThe obvious drawback of this approach is that we lose the structure of the original\nname. This loss may prevent efficient implementations of, for example, finding all\nchildren in a specific domain.\nAs argued by Walfish et al. [2004], when there is a need for many names,\nusing identifiers as a semantic-free way of accessing data will allow different\nsystems to make use of a single naming system. The reason is simple: by now,\nit is well understood how a huge collection of (flat) names can be efficiently\nsupported. What needs to be done is to maintain the mapping of identifier-to-\nname information, where in this case a name may come from the DNS space,\nbe a URL, and so on. Using identifiers can be made easier by letting users or\norganizations use a strict local name space. The latter is completely analogous to\nmaintaining a private setting of environment variables on a computer.\nNevertheless, stating that a decentralized implementation of DNS will cir-\ncumvent many of its scalability problems is too simple. In a comparative study,\nPappas et al. [2006] showed that there are many trade-offs to consider and that\nthe current, hierarchical design of DNS is not so bad for at least two reasons:\n• In a hierarchical design, not all nodes are equal and in the case of DNS,\nnotably the higher-level nodes are engineered differently.\nFor example,\ndespite that there are officially 13 root nodes, each of these nodes is highly\ndistributed and replicated for performance and availability. To illustrate,\nthe root node provided by RIPE NCC is implemented at some 25 different\nDS 4.01\n \n",
      "content_length": 3303,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 385,
      "content": "6.3. STRUCTURED NAMING\n369\nsites (all using the same IP address), each implemented as a highly robust\nand replicated server cluster.\nAgain, we see the important difference between a logical and physical\ndesign. Exploiting this difference is crucial for the operation of a distributed\nsystem such as DNS. However, in virtually all DHT-based systems, making\nthis distinction can be much more difficult when dealing with a logical\nnaming hierarchy, as all names are necessarily treated to be equal. In such\ncases, it becomes much more difficult to engineer the system so that, for\nexample, top-level domains are separated out by special (physical) nodes.\nOf course, the obvious drawback of not having all nodes being equal, is that\nspecial measures need to be taken to protect the more important parts of a\nsystem against abuse. We have already mentioned that top-level nodes in\nDNS are implemented as distributed and replicated servers (clusters), but\nalso that an associated server will not provide recursive name resolution.\nSuch implementation decisions are necessary also from a perspective of\nrobustness.\n• DNS caches are highly effective and driven almost entirely by the local\ndistribution of queries: if a domain D is queried often at a server S, then the\nreferences for name servers of D will be cached at S. The behavior at another\nserver S′ is determined by what is queried at S′. This important feature has\nbeen confirmed in a more recent study that also shows how difficult it can\nbe to understand the effectiveness of caching and the locality principles of\nDNS resolvers. In particular, an ISP’s DNS resolver may be very effective in\nredirecting traffic to content that is localized in that ISP [Ager et al., 2010].\nIn contrast, caching and replication in DHT-based systems generally does\nnot show such principles of locality: results are simply cached at nodes on\nthe return path of a lookup and have very little to do with the fact that a\nlookup was locally initiated at a specific node in the DHT, or a resolver for\nwhich the local ISP can assist in looking up content.\nThe fact remains that replacing DNS by a decentralized implementation is not\nnecessarily a good idea. DNS as it stands today, is a well-engineered system that\nis difficult to beat when it comes to performance and robustness (see Vixie [2009],\nVixie [2014], but also Allman [2020]).\n6.3.5\nExample: The Network File System\nAs another, and very different example, consider naming in NFS. The funda-\nmental idea underlying the NFS naming model is to provide clients complete\ntransparent access to a remote file system as maintained by a server. This\ntransparency is achieved by letting a client be able to mount a remote file\nsystem into its own local file system, as shown in Figure 6.25.\nInstead of mounting an entire file system, NFS allows clients to mount\nonly part of a file system, as also shown in Figure 6.25. A server is said to\n \nDS 4.01\n",
      "content_length": 2930,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 386,
      "content": "370\nCHAPTER 6. NAMING\nNetwork\nClient A\nClient B\nServer\nvu\nme\nremote\nwork\nbin\nbin\nmbox\nmbox\nmbox\nExported directory\nmounted by client\nExported directory\nmounted by client\nusers\nsteen\nFigure 6.25: Mounting (part of) a remote file system in NFS.\nexport a directory when it makes that directory and its entries available to\nclients. An exported directory can be mounted into a client’s local name space.\nThis design approach has a serious implication: in principle, users do not\nshare name spaces. As shown in Figure 6.25 the file named /remote/vu/mbox\nat client A is named /work/me/mbox at client B. A file’s name therefore\ndepends on how clients organize their own local name space, and where\nexported directories are mounted. The drawback of this approach in a dis-\ntributed file system is that sharing files becomes much harder. For example,\nAlice cannot tell Bob about a file using the name she assigned to that file, for\nthat name may have an entirely different meaning in Bob’s name space of\nfiles.\nThere are several ways to solve this problem, but the most common one\nis to provide each client with a name space that is partly standardized. For\nexample, each client may be using the local directory /usr/bin to mount a\nfile system containing a standard collection of programs that are available to\neveryone. Likewise, the directory /local may be used as a standard to mount\na local file system that is located on the client’s host.\nAn NFS server can itself mount directories that are exported by other\nservers. However, it is not allowed to export those directories to its own\nclients. Instead, a client will have to explicitly mount such a directory from\nthe server that maintains it, as shown in Figure 6.26. This restriction comes\npartly from simplicity. If a server could export a directory that it mounted\nfrom another server, it would have to return special file handles that include\nan identifier for a server. NFS does not support such file handles.\nTo explain this point in more detail, assume that the server A hosts a file\nsystem FSA from which it exports the directory /packages. This directory\ncontains a subdirectory /draw that acts as a mount point for a file system\nDS 4.01\n \n",
      "content_length": 2196,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 387,
      "content": "6.3. STRUCTURED NAMING\n371\nNetwork\nClient\nServer B\nServer A\nExported directory\ncontains imported\nsubdirectory\nClient needs to\nexplicitly import\nsubdirectory from\nserver B\nClient\nimports\ndirectory\nfrom\nserver A\nServer A\nimports\ndirectory\nfrom\nserver B\nbin\ndraw\ndraw\ninstall\ninstall\ninstall\npackages\nFigure 6.26: Mounting nested directories from multiple servers in NFS.\nFSB that is exported by the server B and mounted by A. Let A also export\n/packages/draw to its own clients, and assume that a client has mounted\n/packages into its local directory /bin as shown in Figure 6.26.\nIf name resolution is iterative, then to resolve the name /bin/draw/install,\nthe client contacts server A when it has locally resolved /bin and requests A to\nreturn a file handle for directory /draw. In that case, server A should return a\nfile handle that includes an identifier for server B, as only B can resolve the\nrest of the path name, in this case /install. As we have said, this kind of name\nresolution is not supported by NFS.\nName resolution in earlier versions of NFS is strictly iterative, in the sense\nthat only a single file name at a time can be looked up. In other words,\nresolving a name such as /bin/draw/install requires three separate calls to the\nNFS server. Moreover, the client is fully responsible for implementing the\nresolution of a path name. NFSv4 also supports recursive name lookups. In\nthis case, a client can pass a complete path name to a server and request that\nserver to resolve it.\nThere is another peculiarity with NFS name lookups that has been solved\nwith the most recent version (NFSv4). Consider a file server hosting several\nfile systems. With the strict iterative name resolution, whenever a lookup is\ndone for a directory on which another file system was mounted, the lookup\nwould return the file handle of the directory. Subsequently, reading that\ndirectory would return its original content, not that of the root directory of the\nmounted file system.\n \nDS 4.01\n",
      "content_length": 1986,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 388,
      "content": "372\nCHAPTER 6. NAMING\nTo explain, assume that in our previous example that both file systems FSA\nand FSB are hosted by a single server. If the client has mounted /packages into\nits local directory /bin, then looking up the file name draw at the server would\nreturn the file handle for draw. A subsequent call to the server for listing\nthe directory entries of draw by readdir would then return the list of directory\nentries that were originally stored in FSA in subdirectory /packages/draw. Only\nif the client had also mounted file system FSB, would it be possible to properly\nresolve the path name draw/install relative to /bin.\nNFSv4 solves this problem by allowing lookups to cross mount points at a\nserver. In particular, lookup returns the file handle of the mounted directory\ninstead of that of the original directory. The client can detect that the lookup\nhas crossed a mount point by inspecting the file system identifier of the looked\nup file. If required, the client can locally mount that file system as well.\nA file handle is a reference to a file within a file system. It is independent\nof the name of the file it refers to. A file handle is created by the server that is\nhosting the file system and is unique regarding all file systems exported by\nthe server. It is created when the file is created. The client is kept ignorant of\nthe actual content of a file handle; it is completely opaque. File handles were\n32 bytes in NFS version 2, but were variable up to 64 bytes in version 3 and\n128 bytes in version 4. Of course, the length of a file handle is not opaque.\nIdeally, a file handle is implemented as a true identifier for a file relative to\na file system. For one thing, this means that as long as the file exists, it should\nhave one and the same file handle. This persistence requirement allows a\nclient to store a file handle locally once the associated file has been looked up\nthrough its name. One benefit is performance: as most file operations require\na file handle instead of a name, the client can avoid having to look up a name\nrepeatedly before every file operation. Another benefit of this approach is that\nthe client can now access the file regardless which (current) name it has.\nBecause a file handle can be locally stored by a client, it is also important\nthat a server does not reuse a file handle after deleting a file. Otherwise, a\nclient may mistakenly access the wrong file when it uses its locally stored file\nhandle.\nNote that the combination of iterative name lookups and not letting a\nlookup operation allow crossing a mount point introduces a problem with\ngetting an initial file handle. To access files in a remote file system, a client\nwill need to provide the server with a file handle of the directory where the\nlookup should take place, along with the name of the file or directory that is\nto be resolved. NFSv3 solves this problem through a separate mount protocol,\nby which a client actually mounts a remote file system. After mounting, the\nclient is passed back the root file handle of the mounted file system, which it\ncan subsequently use as a starting point for looking up names.\nIn NFSv4, this problem is solved by providing a separate operation\nputrootfh that tells the server to solve all file names relative to the root file\nDS 4.01\n \n",
      "content_length": 3296,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 389,
      "content": "6.3. STRUCTURED NAMING\n373\nhandle of the file system it manages. The root file handle can be used to\nlook up any other file handle in the server’s file system. This approach has\nthe additional benefit that there is no need for a separate mount protocol.\nInstead, mounting can be integrated into the regular protocol for looking up\nfiles. A client can simply mount a remote file system by requesting the server\nto resolve names relative to the file system’s root file handle using putrootfh.\nNote 6.9 (Advanced: Automounting)\nAs we mentioned, the NFS naming model essentially provides users with their\nown name space. Sharing in this model may become difficult if users name the\nsame file differently. One solution to this problem is to provide each user with a\nlocal name space that is partly standardized, and subsequently mounting remote\nfile systems the same for each user.\nAnother problem with the NFS naming model has to do with deciding when a\nremote file system should be mounted. Consider a large system with thousands\nof users. Assume that each user has a local directory /home that is used to mount\nthe home directories of other users. For example, Alice’s home directory may\nbe locally available to her as /home/alice, although the actual files are stored on\na remote server. This directory can be automatically mounted when Alice logs\ninto her workstation. In addition, she may have access to Bob’s public files by\naccessing Bob’s directory through /home/bob.\nThe question, however, is whether Bob’s home directory should also be\nmounted automatically when Alice logs in. The benefit of this approach would be\nthat the whole business of mounting file systems would be transparent to Alice.\nHowever, if this policy were followed for every user, logging in could incur a lot\nof communication and administrative overhead. In addition, it would require\nthat all users are known in advance. A much better approach is to transparently\nmount another user’s home directory on demand, that is, when it is first needed.\nOn-demand mounting of a remote file system (or actually an exported direc-\ntory) is handled in NFS by an automounter, which runs as a separate process\non the client’s machine. The principle underlying an automounter is relatively\nsimple. Consider a simple automounter implemented as a user-level NFS server\non a Unix operating system. (For other implementations, see [Callaghan, 2000]).\nAssume that for each user, the home directories of all users are available\nthrough the local directory /home, as described above. When a client machine\nboots, the automounter starts with mounting this directory. The effect of this local\nmount is that whenever a program attempts to access /home, the Unix kernel will\nforward a lookup operation to the NFS client, which, in this case, will forward the\nrequest to the automounter in its role as NFS server, as shown in Figure 6.27.\nFor example, suppose that Alice logs in. The login program will attempt to\nread the directory /home/alice to find information such as login scripts. The\nautomounter will thus receive the request to look up subdirectory /home/alice,\nfor which reason it first creates a subdirectory /alice in /home. It then looks up\nthe NFS server that exports Alice’s home directory to subsequently mount that\ndirectory in /home/alice. At that point, the login program can proceed.\n \nDS 4.01\n",
      "content_length": 3364,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 390,
      "content": "374\nCHAPTER 6. NAMING\nhome\nusers\nalice\nalice\nServer machine\nNFS client\nAutomounter\nLocal file system interface\n1. Lookup \"/home/alice\"\n2. Create subdir \"alice\"\n4. Mount subdir \"alice\"\nfrom server\n3. Mount request\nClient machine\nFigure 6.27: A simple automounter for NFS.\nThe problem with this approach is that the automounter will have to be\ninvolved in all file operations to guarantee transparency. If a referenced file is not\nlocally available because the corresponding file system has not yet been mounted,\nthe automounter will have to know. In particular, it will need to handle all read\nand write requests, even for file systems that have already been mounted. This\napproach may incur a large performance problem. It would be better to have\nthe automounter only mount and unmount directories, and otherwise, stay out\nof the loop. A simple solution is to let the automounter mount directories in a\nspecial subdirectory, and install a symbolic link to each mounted directory. This\napproach is shown in Figure 6.28.\nFigure 6.28: Using symbolic links with automounting.\nIn our example, the user home directories are mounted as subdirectories of\n/tmp_mnt. When Alice logs in, the automounter mounts her home directory\nin /tmp_mnt/home/alice and creates a symbolic link /home/alice that refers to\nthat subdirectory. In this case, whenever Alice executes a command such as ls\n–l /home/alice the NFS server that exports Alice’s home directory is contacted\ndirectly without further involvement of the automounter.\nDS 4.01\n \n",
      "content_length": 1521,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 391,
      "content": "6.4. ATTRIBUTE-BASED NAMING\n375\n6.4\nAttribute-based naming\nFlat and structured names generally provide a unique and location-independent\nway of referring to entities. Moreover, structured names have been partly\ndesigned to provide a human-friendly way to name entities so that they can be\nconveniently accessed. In most cases, it is assumed that the name refers to only\na single entity. However, location independence and human friendliness are\nnot the only criterion for naming entities. In particular, as more information\nis being made available, it becomes important to effectively search for entities.\nThis approach requires that a user can provide merely a description of what\nshe is looking for.\nThere are many ways in which descriptions can be provided, but a popular\none in distributed systems is to describe an entity in terms of (attribute, value)\npairs, generally referred to as attribute-based naming. In this approach,\nan entity is assumed to have an associated collection of attributes. Each\nattribute says something about that entity. By specifying which values a\nspecific attribute should have, a user essentially constrains the set of entities\nthat she is interested in. It is up to the naming system to return one or more\nentities that meet the user’s description. In this section, we take a closer look\nat attribute-based naming systems.\n6.4.1\nDirectory services\nAttribute-based naming systems are also known as directory services, whereas\nsystems that support structured naming are generally called naming systems.\nWith directory services, entities have a set of associated attributes that can be\nused for searching. In some cases, the choice of attributes can be relatively\nsimple. For example, in an e-mail system, messages can be tagged with\nattributes for the sender, recipient, subject, and so on. However, even in the\ncase of e-mail, matters become difficult when other types of descriptors are\nneeded, as is illustrated by the difficulty of developing filters that will allow\nonly certain messages (based on their descriptors) to be passed through.\nWhat it all boils down to is that designing an appropriate set of attributes\nis not trivial. In most cases, attribute design has to be done manually. Even if\nthere is consensus on the set of attributes to use, practice shows that setting\nthe values consistently by a diverse group of people is a problem by itself, as\nmany will have experienced when accessing music and video databases on\nthe Internet.\nTo alleviate some of these problems, research has been conducted on\nunifying the ways that resources can be described. In the context of distributed\nsystems, one particularly relevant development is the Resource Description\nFramework (RDF). Fundamental to the RDF model is that resources are\ndescribed as triplets consisting of a subject, a predicate, and an object. For\nexample, (Person, name, Alice) describes a resource referred to as Person whose\n \nDS 4.01\n",
      "content_length": 2940,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 392,
      "content": "376\nCHAPTER 6. NAMING\nname is Alice. In RDF, each subject, predicate, or object can be a resource itself.\nThis means that Alice may be implemented as a reference to a file that can\nbe subsequently retrieved. In the case of a predicate, such a resource could\ncontain a textual description of that predicate. Resources associated with\nsubjects and objects can be anything. References in RDF are essentially URLs.\nIf resource descriptions are stored, it becomes possible to query that\nstorage in a way that is common for many attribute-based naming systems.\nFor example, an application could ask for the information associated with a\nperson named Alice. Such a query would return a reference to the person\nresource associated with Alice. This resource can then subsequently be fetched\nby the application.\nIn this example, the resource descriptions are stored at a central location.\nThere is no reason why the resources should reside at the same location as\nwell. However, not having the descriptions in the same place may incur a\nserious performance problem. Unlike structured naming systems, looking up\nvalues in an attribute-based naming system essentially requires an exhaustive\nsearch through all descriptors. (Various techniques can be applied to avoid\nsuch exhaustive searches, an obvious one being indexing.) When considering\nperformance, an exhaustive search may be less of a problem within a single,\nnondistributed data store, but simply sending a search query to hundreds of\nservers that jointly implement a distributed data store is generally not such\na good idea. In the following, we will take a look at different approaches to\nsolving this problem in distributed systems.\n6.4.2\nHierarchical implementations: LDAP\nA common approach to tackling distributed directory services is to combine\nstructured naming with attribute-based naming. This approach has been\nwidely adopted, for example, in Microsoft’s Active Directory service and other\nsystems. Many of these systems use, or rely on the Lightweight Directory\nAccess Protocol commonly referred simply as LDAP. The LDAP directory\nservice has been derived from OSI’s X.500 directory service. As with many OSI\nservices, the quality of their associated implementations hindered widespread\nuse, and simplifications were needed to make it useful. Detailed information\non LDAP can be found in [Arkills, 2003].\nConceptually, an LDAP directory service consists of a number of records,\nusually referred to as directory entries. A directory entry is comparable\nto a resource record in DNS. Each record is made up of a collection of (at-\ntribute, value) pairs, where each attribute has an associated type. A distinction\nis made between single-valued attributes and multiple-valued attributes. The\nlatter typically represent arrays and lists. As an example, a simple direc-\ntory entry identifying the network addresses of some general servers from\nFigure 6.22 is shown in Figure 6.28.\nDS 4.01\n \n",
      "content_length": 2943,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 393,
      "content": "6.4. ATTRIBUTE-BASED NAMING\n377\nAttribute\nAbbr.\nValue\nCountry\nC\nNL\nLocality\nL\nAmsterdam\nOrganization\nO\nVU University\nOrganizationalUnit\nOU\nComputer Science\nCommonName\nCN\nMain server\nMail_Servers\n–\n137.37.20.3, 130.37.24.6, 137.37.20.10\nFTP_Server\n–\n130.37.20.20\nWWW_Server\n–\n130.37.20.20\nFigure 6.29: A simple example of an LDAP directory entry using LDAP\nnaming conventions.\nIn our example, we have used a naming convention described in the\nLDAP standards, which applies to the first five attributes. The attributes\nOrganization and OrganizationUnit describe, respectively, the organization and\nthe department associated with the data that are stored in the record. Likewise,\nthe attributes Locality and Country provide additional information on where\nthe entry is stored. The CommonName attribute is often used as an (ambiguous)\nname to identify an entry within a limited part of the directory. For example,\nthe name “Main server” may be enough to find our example entry given the\nspecific values for the other four attributes Country, Locality, Organization, and\nOrganizationalUnit. In our example, only attribute Mail_Servers has multiple\nvalues associated with it. All other attributes have only a single value.\nThe collection of all directory entries in an LDAP directory service is\ncalled a directory information base (DIB). An important aspect of a DIB\nis that each record is uniquely named so that it can be looked up. Such a\nglobally unique name appears as a sequence of naming attributes in each\nrecord. Each naming attribute is called a relative distinguished name, or\nRDN for short. In our example in Figure 6.29 the first five attributes are\nall naming attributes. Using the conventional abbreviations for representing\nnaming attributes in LDAP, as shown in Figure 6.29, the attributes Country,\nOrganization, and OrganizationalUnit could be used to form the name\n/C = NL/O = VU University/OU = Computer Science\nwhich is globally unique, analogous to the DNS name nl.vu.cs.\nAs in DNS, the use of globally unique names by listing RDNs in sequence,\nleads to a hierarchy of the collection of directory entries, which is referred to\nas a directory information tree (DIT). A DIT essentially forms the naming\ngraph of an LDAP directory service, in which each node represents a directory\nentry. In addition, a node may also act as a directory in the traditional sense,\nin that there may be several children for which the node acts as parent. To\nexplain, consider the naming graph, as partly shown in Figure 6.30. (Recall\nthat labels are associated with edges.)\n \nDS 4.01\n",
      "content_length": 2577,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 394,
      "content": "378\nCHAPTER 6. NAMING\n(a)\nAttribute\nValue\nAttribute\nValue\nLocality\nAmsterdam\nLocality\nAmsterdam\nOrganization\nVUUniversity\nOrganization\nVUUniversity\nOrganizationalUnit\nComputerScience\nOrganizationalUnit\nComputerScience\nCommonName\nMainserver\nCommonName\nMainserver\nHostName\nstar\nHostName\nzephyr\nHostAddress\n192.31.231.42\nHostAddress\n137.37.20.10\n(b)\nFigure 6.30: (a) Part of a directory information tree. (b) Two directory entries\nhaving HostName as RDN.\nThe node N corresponds to the directory entry shown in Figure 6.29. At\nthe same time, this node acts as a parent to a number of other directory\nentries that have an additional naming attribute HostName that is used as an\nRDN. For example, such entries may be used to represent hosts as shown in\nFigure 6.30.\nA node in an LDAP naming graph can thus simultaneously represent a\ndirectory in the traditional sense, as we discussed previously, as well as an\nLDAP record. This distinction is supported by two different lookup operations.\nThe read operation is used to read a single record given its path name in the\nDIT. In contrast, the list operation is used to list the names of all outgoing\nedges of a given node in the DIT. Each name corresponds to a child node of\nthe given node. Note that the list operation does not return any records; it\nmerely returns names. In other words, calling read with as input the name\n/C = NL/O = VU University/OU = Computer Science/CN = Main server\nwill return the record shown in Figure 6.30, whereas calling list will return\nthe names star and zephyr from the entries shown in Figure 6.30 as well as the\nnames of other hosts that have been registered in a similar way.\nDS 4.01\n \n",
      "content_length": 1664,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 395,
      "content": "6.4. ATTRIBUTE-BASED NAMING\n379\nImplementing an LDAP directory service proceeds in much the same way\nas implementing a naming service, such as DNS, except that LDAP supports\nmore lookup operations, as we will discuss shortly. When dealing with a large-\nscale directory, the DIT is usually partitioned and distributed across several\nservers, known as directory service agents (DSA). Each part of a partitioned\nDIT thus corresponds to a zone in DNS. Likewise, each DSA behaves very\nmuch the same as a normal name server, except that it implements a number\nof typical directory services, such as advanced search operations.\nClients are represented by what are called directory user agents, or simply\nDUA. A DUA is similar to a name resolver in structured-naming services. A\nDUA exchanges information with a DSA according to a standardized access\nprotocol.\nWhat makes an LDAP implementation different from a DNS implementa-\ntion are the facilities for searching through a DIB. In particular, facilities are\nprovided to search for a directory entry given a set of criteria that attributes\nof the searched entries should meet. For example, suppose that we want a list\nof all main servers at VU University. Using the notation defined in Smith and\nHowes [2006], such a list can be returned using a search operation like\nsearch(“(C=NL)(O=VU University)(OU=*)(CN=Main server)”)\nIn this example, we have specified that the place to look for main servers\nis the organization named VU_University in country NL, but that we are not\ninterested in a particular organizational unit. However, each returned result\nshould have the CN attribute equal to Main_server.\nAs we already mentioned, searching in a directory service is generally an\nexpensive operation. For example, to find all main servers at VU University\nrequires searching all entries at each department and combining the results\nin a single answer. In other words, we will generally need to access several\nleaf nodes of a DIT in order to get an answer. In practice, this also means that\nseveral DSAs need to be accessed. In contrast, naming services can often be\nimplemented in such a way that a lookup operation requires accessing only a\nsingle leaf node.\nThis whole setup of LDAP can be taken one step further by allowing\nseveral trees to co-exist, while also being linked to each other.\nThis ap-\nproach is followed in Microsoft’s Active Directory leading to a forest of LDAP\ndomains [Allen and Lowe-Norris, 2003]. Obviously, searching in such an\norganization can be overwhelmingly complex. To circumvent some of the\nscalability problems, Active Directory usually assumes there is a global index\nserver (called a global catalog) that can be searched first. The index will\nindicate which LDAP domains need to be searched further.\nAlthough LDAP by itself already exploits hierarchy for scalability, it is\ncommon to combine LDAP with DNS. For example, every tree in LDAP needs\nto be accessible at the root (known in Active Directory as a domain controller).\n \nDS 4.01\n",
      "content_length": 3011,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 396,
      "content": "380\nCHAPTER 6. NAMING\nThe root is often known under a DNS name, which, in turn, can be found\nthrough an appropriate SRV record, as we explained above.\n6.4.3\nDecentralized implementations\nNotably with the advent of peer-to-peer systems, researchers have also been\nlooking for solutions for decentralized attribute-based naming systems. In\nparticular, peer-to-peer systems are often used to store files. Initially, files\ncould not be searched—they could only be looked up by their key. However,\nhaving the possibility to search for a file based on descriptors can be extremely\nconvenient, where each descriptor is nothing but an (attribute, value) pair.\nObviously, querying every node in a peer-to-peer system to see if it contains\na file matching one or more of such pairs, is infeasible. What we need is a\nmapping of (attribute, value) pairs to index servers, which, in turn, point to\nfiles matching those pairs.\nUsing a distributed index\nLet us first look at the situation of building a (distributed) index. The basic\nidea is that a search query is formulated as a list of (attribute, value) pairs, just\nas in the case of our LDAP examples. The result should be a list of (references\nto) entities that match all pairs. In the case of a peer-to-peer system storing\nfiles, a list of keys to relevant files may be returned, after which the client can\nlook up each of those files using the returned keys.\nA straightforward approach toward a distributed index is the following.\nAssume there are d different attributes. In that case, we can use a server for\neach of the d attributes, where a server for attribute A maintains a set of (E,val)\npairs for each entity E that has the value val for attribute A. A search query\nsuch as\nsearch(“(Country=NL)(Organization=VU University)\n(OrganizationalUnit=*)(CommonName=Main server)”)\nwould be sent to the servers for Country, Organization, and CommonName,\nrespectively, after which the client would need to see which entities occur in\nall three sets as returned by the servers. To prevent that a server needs to\nmaintain a large set of entities, the set for each server can be further partitioned\nand distributed across several subservers, each subserver associated with the\nsame attribute.\nMore precisely, if we have a set of attributes {a1, . . . , aN}, then for each\nattribute ak we associate a set Sk = {Sk\n1, . . . , Sknk} of nk servers. Assuming that\nan attribute ak takes values from a set Rk, we construct a global mapping F\nsuch that\nF(ak, v) = Sk\nj with Sk\nj ∈Sk and v ∈Rk\nDS 4.01\n \n",
      "content_length": 2531,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 397,
      "content": "6.4. ATTRIBUTE-BASED NAMING\n381\nIn this example, the server Sk\nj would keep track of each key associated with a\nfile having ak = v. The beauty of this scheme is its simplicity. If L(ak, v) is the\nset of keys returned by the server F(ak, v), then a query can be formulated as\na logical expression such as\n\u0000F(a1, v1) ∧F(a2, v2)\n\u0001 ∨F(a3, v3)\nwhich can then be processed on the client side by constructing the set\n\u0000L(a1, v1) ∩L(a2, v2)\n\u0001 ∪L(a3, v3)\nUnfortunately, there are important drawbacks to this scheme. First, any\nquery involving k attributes requires contacting k index servers, which may\nincur significant communication costs. Furthermore, and related, is that the\nclient is required to process the sets returned by the index servers. Just\nimagine that each file has two attributes firstName and lastName, respectively,\nand that a client is looking for the file owned by Pheriby Smith. Now, although\nPheriby may be quite unique for a first name, Smith definitely is not. However,\nour poor client will have to receive perhaps millions of keys of files for which\nlastName = Smith, while there may actually be only a handful of files for\nwhich firstName = Pheriby. Thirdly, although this scheme does allow leaving\ncertain attributes unspecified (by simply not mentioning them in the query),\nit does not easily support range queries, such as, price = [1000 −−2500].\nSpace-filling curves\nA common approach to implementing decentralized attribute-based naming\nsystems is to use what are known as space-filling curves. The basic idea is to\nmap the N-dimensional space covered by the N attributes {a1, . . . , aN} into a\nsingle dimension, and then use, for example, a simple hashing technique to\ndistribute the resultant space among index servers. One of the key issues is to\nhave (attribute, value) pairs that are “close” to each other be handled by the\nsame index server.\nLet us make matters concrete and look into one popular case, namely\nHilbert space-filling curves (see, for example, [Lawder and King, 2000]). These\nare easiest to explain by looking at only two dimensions, that is, considering\nonly two distinct attributes. The possible values that each attribute can have\ncorresponds to one axis in a two-dimensional space. Without loss of generality,\nwe assume that each attribute takes on values in the interval [0, 1). As a first\napproximation of the square, we divide it into four quadrants, as shown in\nFigure 6.31(a). All data values (x, y) with 0 ≤x, y < 0.5 are associated with\nindex 0. Values (x, y) with 0.5 ≤x, y < 1.0 are associated with index 2.\nWe can repeat this procedure recursively for each subsquare: divide it\ninto four smaller squares and connect the smaller squares through a single\nline. Using rotation and reflection, we make sure that this line can be nicely\n \nDS 4.01\n",
      "content_length": 2799,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 398,
      "content": "382\nCHAPTER 6. NAMING\n(a)\n(b)\nFigure 6.31: Reducing a two-dimensional space to a single dimension through\na Hilbert space-filling curve of (a) order 1, and (b) order 4.\nconnected to the one in the previously neighboring larger subsquare (which\nhas also been divided into smaller squares). To illustrate, where Figure 6.31(a)\nshows a Hilbert curve of order 1, Figure 6.31(b) shows a curve of order 4 with\n256 indices. In general, a Hilbert curve of order k connects 22k subsquares,\nand thus has also 22k indices.\nThere are various ways in which we can\nsystematically draw a curve through a two-dimensional space that has been\npartitioned into equally sized squares. Furthermore, the process can be easily\nexpanded to higher dimensions, as explained by Sagan [1994] and Bader\n[2013].\nAn important property of space-filling curves is that they preserve locality:\ntwo indices that are close to each other on the curve correspond to two\npoints that are also close to each other in the multidimensional space. (Note\nthat the reverse is not always true: two points close to each other in the\nmultidimensional space need not necessarily lie close to each other on the\ncurve.)\nTo complete the story, several things need to be done. First, attribute values\nneed to be indexed. Assume that we are dealing with a total of N possible\nattributes {a1, . . . , aN}, and that each entity assigns a value to each of these N\nattributes (possibly including the equivalent of a “don’t care” value). To keep\nmatters simple, we assume that each attribute value is normalized to a value\nin the interval [0, 1). Then clearly, an entity E having the tuple of values (v1,\n. . . , vN) is associated with a real-valued coordinate in an N-dimensional space,\nin turn uniquely associated with an N-dimensional subsquare as we discussed\nfor the two-dimensional case. The center of such a subsquare corresponds to\nan index on the associated Hilbert space-filling curve, and is now the index\nassociated with the entity E. Of course, multiple entities whose associated\nDS 4.01\n \n",
      "content_length": 2043,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 399,
      "content": "6.4. ATTRIBUTE-BASED NAMING\n383\ncoordinates fall in the same subsquare will all have the same index. If we want\nto avoid such collisions as much as possible, we need to use high-ordered\nspace-filling curves. Orders of 32 or 64 are not uncommon.\nSecond, we also need to be able to search for entities. The principle of\nsearching for entities based on their attribute values should now be clear.\nSuppose we were looking for files whose two attribute values a1 and a2 lie\nin intervals [v1\nl , v1u) and [v2\nl , v2u), respectively (with vi\nl < viu). Clearly, this\ndelineates a rectangular region through which the curve passes, and all files\nindexed by those segments of the curve that intersect with that region match\nthe search criterion. We therefore need an operation that returns a series of\ncurve-related indices given a region (expressed in terms of subsquares) in\nthe associated N-dimensional space. Such an operation is clearly dependent\non which space-filling curve has been used, but interestingly, need not be\ndependent on actual entities.\nFinally, we need to maintain (references to) the entities associated with\nindices. One approach, used in the Squid system [Schmidt and Parashar,\n2008], is to use a Chord ring. In Squid, the index space is chosen to be the\nsame as that of the Chord ring, that is, both use m-bit identifiers. Then clearly,\nthe Chord node responsible for index i will store (references to) the entities\nindexed by i.\nNote 6.10 (Example: The SWORD system)\nDecentralized implementations of attribute-based naming systems have received\na lot of attention. The ones based on space-filling curves are relatively popular,\nbut several alternatives have been proposed as well. As an example, we discuss a\nsolution adopted in the SWORD resource discovery system [Albrecht et al., 2008].\nIn SWORD, (attribute, value) pairs are first transformed into a key for a DHT.\nThese pairs always contain a single value; only queries may contain value ranges\nfor attributes. When computing the key (by means of a hash) the name of the\nattribute and its value are kept separate. Specific bits in the key will identify the\nattribute name, while others identify its value. In addition, the key will contain\na number of random bits to guarantee uniqueness among all keys that need to\nbe generated. In this way, the space of attributes is conveniently partitioned: if\nn bits are reserved to code attribute names, 2n different server groups can be\nused, one group for each attribute name. Likewise, by using m bits to encode\nvalues, a further partitioning per server group can be applied to store specific\n(attribute, value) pairs. DHTs are used only for distributing attribute names.\nFor each attribute name, the possible range of its value is partitioned into\nsubranges and a single server is assigned to each subrange. To explain, consider\na resource description with two attributes: a1 taking values in the range [1..10]\nand a2 taking values in the range [101...200]. Assume there are two servers for\na1: S11 takes care of recording values of a1 in [1..5], and S12 for values in [6..10].\nLikewise, server S21 records values for a2 in range [101..150] and server S22\nfor values in [151..200]. Then, when an entity E has associated attribute values\n \nDS 4.01\n",
      "content_length": 3262,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 400,
      "content": "384\nCHAPTER 6. NAMING\n(a1 = 7, a2 = 175), server S12 and server S22 will maintain a copy of, or a reference\nto E.\nThe advantage of this scheme is that range queries can be easily supported.\nWhen a query is issued to return resources that have a2 lying between 165 and 189,\nthe query can be forwarded to the server S22 who can then return the resources\nthat match the query range. The drawback, however, is that updates need to be\nsent to multiple servers. Moreover, it is not immediately clear how well the load is\nbalanced between the various servers. In particular, if certain range queries turn\nout to be very popular, specific servers will receive a high fraction of all queries.\nSummarizing remarks\nThere are indeed many ways of supporting attribute-\nbased naming systems in a decentralized fashion. The essence in all cases is to\nassign attributes to servers so that clients know where to direct their queries,\nyet at the same time make sure that there is a balance in the load for the set of\nservers. In this light, supporting range queries requires special attention, if\nonly to decide which server will be responsible for which subrange.\nIn practice, we see that when dealing with N attributes, many systems\nmodel the collection of (attribute, value) pairs as an N-dimensional space in\nwhich each entity is represented by a unique point in that space. Conceptually,\na search addresses a subspace and leads to identifying the servers responsible\nfor that subspace. In the simplest case, we assign each attribute to one server,\nleading to O(N) servers. In this scheme, a query addressing k attributes needs\nto be sent to k servers, while the querying client needs to combine the results.\nWe have discussed this case previously. The problem is to divide the ranges\nper attribute among subservers such that we have a reasonable balance of the\nworkload. A solution to this problem is discussed in [Bharambe et al., 2004].\nInstead of letting a client combine results, we can let servers collaborate. To\nthis end, the N-dimensional space is divided into subspaces by splitting each\ndimension d into nd intervals. This splitting leads to a total of n1 × · · · × nN\nsubspaces, where each subspace is assigned to a separate server. Even with\nnd = 2 for each dimension, we will face a total of O(2N) servers. Using\nspace-filling curves, we can reduce the number of dimensions to one, and use\na separate technique for deciding which N-dimensional subspace is served\nby which server. Practice indicates that load balancing may become an issue.\nAn alternative solution in which the number of dimensions is still reduced,\nbut larger than one, while also maintaining load balancing, has been built\ninto HyperDex [Escriva et al., 2012]. The authors also address the problem of\nreplication and consistency in case the naming system at the same time stores\nthe entities which it indexes. In that case, whenever a server indexes an entity\nE, it will have to be copied to the respective server.\nAttribute-based naming is particularly relevant for distributed systems\nwhen it comes to resource discovery and selection. An interesting case is\nDS 4.01\n \n",
      "content_length": 3139,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 401,
      "content": "6.5. NAMED-DATA NETWORKING\n385\ndescribed by Stratan et al. [2012]. Again, the attribute space is modeled by an\nN-dimensional space in which each resource is associated with a coordinate.\nIn this situation, each resource maintains a link to another resource, but one\nthat is responsible for a subspace of exponentially increasing size. The net\neffect is that each resource needs to have only a fixed number of neighbors,\nwhile routing a query to the relevant subspace, takes only a linear number\nof steps. The organization is akin to the use of finger tables in Chord. An\nextensive overview of resource discovery in distributed systems is discussed\nby Zarrin et al. [2018].\n6.5\nNamed-data networking\nIn our discussion so far, we have made a distinction between names, identifiers,\nand addresses. In particular, we have argued that a name needs to be resolved\nto an address, to access the named entity (recall that we referred to an address\nas the name of an entity’s access point). At least on one occasion, we dropped\nthis name-resolution process, namely when discussing how an identifier as\nused in Chord, or other DHTs, could be directly used to route a lookup\nrequest to a specific node. Let us now challenge the need for name-to-address\nresolution by taking a closer look into Information-centric networking, or\nsimply ICN [Ahlgren et al., 2012]. In particular, we concentrate on its perhaps\nmost popular form, namely named-data networking (NDN).\n6.5.1\nBasics\nNamed-data networking revolves around the principle that applications are\nnot really interested to know where an entity is stored, but rather that they can\nget a copy to access it locally when needed. To this end, much research has\nbeen spent since approximately 2007 on designing an alternative to the host-\nbased addressing schemes that are common in today’s Internet. In particular,\nthe main idea is that an application can retrieve an entity from the network\nby using that entity’s name. The network takes that name as input, and\nsubsequently routes a request to an appropriate location where the entity is\nstored, to return a copy to the requester. In effect, NDN takes over the role of\nIP in a future architecture of the Internet, as illustrated in Figure 6.32.\nAn important consequence of this organization is that instead of first\nresolving a name to an address, and then routing a request toward that\naddress, the name of an entity is directly used to fetch the associated data.\nWe already came across this scheme when discussing how a lookup request\nin DHTs, based on a unique key associated with an entity, is routed toward a\nnode responsible for that key.\nIn NDN, names are assumed to be structured. For example, this chapter\nmay be referred to as\n \nDS 4.01\n",
      "content_length": 2734,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 402,
      "content": "386\nCHAPTER 6. NAMING\nFigure 6.32: The role of NDN in comparison to IP when viewing the Internet\nprotocol stack as an hourglass (slightly adapted from [Afanasyev et al., 2018]).\n/distributed-systems.net/books/Distributed Systems/4/01/Naming\nindicating the book at distributed-systems.net entitled Distributed Systems, its\n4th edition, version 01, and, in particular, the chapter called Naming. This\nimmediately raises the question how users and applications can and should\nname entities. One way or the other, the name, or naming scheme, of an\nentity should be globally known, and otherwise it becomes impossible to\nfetch the data associated with a name. Likewise, globally available entities\nshould have globally unique names. How this naming is realized is outside\nthe scope of NDN. A general overview and introduction to NDN can be found\nin [Afanasyev et al., 2018] and [Saxena et al., 2016].\nNote that named-data networking assumes that data cannot be modified\nwithout generating a new name. Without this assumption, efficiency may be\nat stake, as caching by routers becomes by far less effective (as we describe\nshortly). This may seem to be a drawback, yet as long as a user knows that\nupdates may be available, she can always ask for the latest version. There\nare various ways to achieve this. For example, when sending out a request\nfor named data, a source may respond with the required data, but also with\nadditional information that an update is available (and may even send that\nupdate along with the originally requested data). An example of how such\nschemes can be deployed for keeping up-to-date in a chat conversation is\ndescribed in [Zhu and Afanasyev, 2013].\nTo better facilitate updates, named-data networking provides separate\nsynchronization protocols, which are surveyed in [Moll et al., 2021]. In essence,\nall these protocols allow the owner of named data to announce updates to\ninterested parties, thus essentially sending a multicast message within an\nNDN network. Depending on what is actually announced, a recipient may\nsubsequently decide to fetch the update through an explicit request (which,\nagain, is a name for the updated data).\nDS 4.01\n \n",
      "content_length": 2173,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 403,
      "content": "6.5. NAMED-DATA NETWORKING\n387\n6.5.2\nRouting\nFor our discussion, perhaps the most interesting part of NDN is how to realize\nrouting and forwarding of requests for named data. Initially, one might think\nthat with seemingly arbitrary structured names routing may be inherently\nsubject to serious scalability problems, for how to find content on the Internet\nby using just its name? When giving the matter some thought, the problem is\nfundamentally not very different when deploying IP addresses, for how would\none find the access point associated with the IPv4 address 145.100.190.243, or\nthe IPv6 address 2001:610:508:108:192:87:108:15 (both belong to surf.nl)?\nAs argued by Zhang et al. [2019], there is really no difference and a decision\nneeds to be made on which part of a name or address (i.e., a prefix) should be\nannounced within a global routing substrate, just as is currently done with\nIPv4 addresses with BGP routers. Once a named packet has found its way\ninto an organization’s network, specific techniques can be used to forward it\nto places where the associated content can be found.\nReturning to our example name, for\ndistributed-systems.net/books/Distributed Systems/4/01/Naming\nwe could decide to use /distributed-systems.net as a global prefix that should\nbe used at the level of BGP routers for globally routing requests to an organi-\nzation’s network responsible for that prefix. Within that network, we can use\nthe rest of the name to search for the associated content. Special NDN routers\nwill be needed for this purpose, which we explain next.\nAn NDN router, shown in Figure 6.33, consists of three elements:\n1. A content store is essentially a cache for keeping data associated with a\n(previously looked up) name. If a named request enters a router, and\nthe named data is in this cache, the router immediately returns that data\nto the requester, as shown in Figure 6.33(a).\n2. A pending interest table is nothing but a table that keeps track of a\n(name,interface) pair: if a request for data named N arrived through\ninterface I of the router, then (N,I) is stored. This will allow a router to\nreturn a response whenever the associated data arrives at the router. As\nshown in Figure 6.33(b), if data enters the router but there is no (longer\nany) interest, the router can decide to drop the data.\n3. A forwarding information base tells the router what to do when it\ncannot serve a request, as shown in Figure 6.33(a). For example, the\nrequest may be flooded to all neighboring routers, a random walk may be\ninitiated, or, perhaps for whatever reason, the request may be dropped.\nAgain, note that these decisions are fundamentally not different from\nrouting using IPv4 or IPv6 address.\n \nDS 4.01\n",
      "content_length": 2717,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 404,
      "content": "388\nCHAPTER 6. NAMING\n(a)\n(b)\nFigure 6.33: The proposed general organization of an NDN router when (a) a\nrequest flows in to the router and (b) the data is returned from another router\nor the source.\nWhen a request forwarded by a router eventually returns a response, the\nrouter will look up whether there was a pending request, send it through the\nassociated interface, and clear the entry in the pending interest table. Also,\nthe router may decide to store the returned content in its content store for\nfuture requests, as also shown in Figure 6.33(b).\nThis design opens many opportunities for routing optimizations, including\ndecisions on what to cache, when to evict data from the content store, how\nand to whom to forward requests, and so on. Practice will have to show\nwhether named-data networking can indeed form a (partial) replacement of\nthe current IP-based Internet.\n6.5.3\nSecurity in named-data networking\nThere are various aspects related to security in named-data networking. Be-\nsides secure naming, a weak aspect of any naming system is that the name\nservers and routers need to be protected as well. There are numerous threats\nto the NDN routers, which in the end all boil down to effectively attempting to\ndisrupt the service. A complete overview of the various threats and possible\nDS 4.01\n \n",
      "content_length": 1312,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 405,
      "content": "6.6. SUMMARY\n389\nsolutions is provided by Tourani et al. [2018] to which we refer the interested\nreader. Here, analogous to our discussion on secure DNS, we briefly discuss\nsecure naming.\nSecure naming is all about ensuring that the provided name is unforgeably\nlinked to the content it refers to. The simplest way of doing this, is by including\na signed digest of that content into the name, similar to self-certifying names,\nas we discussed in Section 6.2.5. Assuming additional information is available\nto the recipient of the named data, such as information on which hash function\nhas been used, as well as the public key (perhaps including its certificate), the\nrecipient can verify that the returned content is indeed associated with the\nname.\n6.6\nSummary\nNames are used to refer to entities. Essentially, there are three types of names.\nAn address is the name of an access point associated with an entity, also\nsimply called the address of an entity. An identifier is another type of name.\nIt has three properties: each entity is referred to by exactly one identifier, an\nidentifier refers to only one entity, and is never assigned to another entity.\nFinally, human-friendly names are targeted to be used by humans, and as such\nare represented as character strings. Given these types, we make a distinction\nbetween flat naming, structured naming, and attribute-based naming.\nSystems for flat naming essentially need to resolve an identifier to the\naddress of its associated entity. This locating of an entity can be done in\ndifferent ways. The first approach is to use broadcasting or multicasting. The\nidentifier of the entity is broadcast to every process in the distributed system.\nThe process offering an access point for the entity responds by providing an\naddress for that access point. Obviously, this approach has limited scalability.\nA second approach is to use forwarding pointers. Each time an entity\nmoves to a next location, it leaves behind a pointer telling where it will be\nnext. Locating the entity requires traversing the path of forwarding pointers.\nTo avoid large chains of pointers, it is important to reduce chains periodically\nA third approach is to allocate a home to an entity. Each time an entity\nmoves to another location, it informs its home where it is. Locating an entity\nproceeds by first asking its home for the current location.\nA fourth approach is to organize all nodes into a structured peer-to-peer\nsystem, and systematically assign nodes to entities, taking their respective\nidentifiers into account. By subsequently devising a routing algorithm by\nwhich lookup requests are moved toward the node responsible for a given\nentity, efficient and robust name resolution is possible.\nA fifth approach is to build a hierarchical search tree. The network is\ndivided into nonoverlapping domains. Domains can be grouped into higher-\nlevel (nonoverlapping) domains, and so on. There is a single top-level domain\n \nDS 4.01\n",
      "content_length": 2957,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 406,
      "content": "390\nCHAPTER 6. NAMING\nthat covers the entire network. Each domain at every level has an associated\ndirectory node. If an entity is located in a domain D, the directory node of the\nnext higher-level domain will have a pointer to D. A lowest-level directory\nnode stores the address of the entity. The top-level directory node knows\nabout all entities.\nStructured names are easily organized in a name space. A name space\ncan be represented by a naming graph in which a node represents a named\nentity and the label on an edge represents the name under which that entity\nis known. A node having multiple outgoing edges represents a collection of\nentities and is also known as a context node or directory. Large-scale naming\ngraphs are often organized as rooted acyclic directed graphs.\nNaming graphs are convenient to organize human-friendly names in a\nstructured way. An entity can be referred to by a path name. Name resolution\nis the process of traversing the naming graph by looking up the components\nof a path name, one at a time. A large-scale naming graph is implemented by\ndistributing its nodes across multiple name servers. When resolving a path\nname by traversing the naming graph, name resolution continues at the next\nname server as soon as a node is reached, implemented by that server.\nMore problematic are attribute-based naming schemes in which entities are\ndescribed by a collection of (attribute, value) pairs. Queries are also formulated\nas such pairs, essentially requiring an exhaustive search through all descriptors.\nSuch a search is feasible only when the descriptors are stored in a single\ndatabase. However, alternative solutions have been devised by which the pairs\nare mapped onto DHT-based systems, essentially leading to a distribution of\nthe collection of entity descriptors. Using space-filling curves, we can then\nmake different nodes responsible for different values of an attribute, which\nhelps in effectively distributing the load among the nodes in the case of search\noperations.\nInstead of making the distinction between the name and an address of\nan entity, researchers have been exploring the possibility of routing requests\ndirectly based on an entity’s name, similar to using an identifier when looking\nup information in a peer-to-peer system. In so-called named-data networks,\nan application systematically fetches (read only) data by providing a name. In\nthe end, the network returns the associated data instead of an address of the\naccess point.\nDS 4.01\n \n",
      "content_length": 2497,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 407,
      "content": "07\nCONSISTENCY\nAND\nREPLICATION\n",
      "content_length": 31,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 408,
      "content": "392\nCHAPTER 7. CONSISTENCY AND REPLICATION\nAn important issue in distributed systems is the replication of data. Data\nare generally replicated to enhance reliability or improve performance. One\nof the major problems is keeping replicas consistent. Informally, this means\nthat when one copy is updated, we need to ensure that the other copies are\nupdated as well; otherwise the replicas will no longer be the same. In this\nchapter, we take a detailed look at what consistency of replicated data actually\nmeans, and the various ways that consistency can be achieved.\nWe start with a general introduction discussing why replication is useful\nand how it relates to scalability. We then continue by focusing on what consis-\ntency actually means. An important class of what are known as consistency\nmodels assumes that multiple processes simultaneously access shared data.\nConsistency for these situations can be formulated regarding what processes\ncan expect when reading and updating the shared data, knowing that others\nare accessing that data as well.\nConsistency models for shared data are often hard to implement efficiently\nin large-scale distributed systems. Moreover, often simpler models can be\nused, which are also often easier to implement. One specific class is formed\nby client-centric consistency models, which concentrate on consistency from\nthe perspective of a single (possibly mobile) client. Client-centric consistency\nmodels are discussed in a separate section.\nConsistency is only half of the story.\nWe also need to consider how\nconsistency is actually implemented. There are essentially two, more or less\nindependent, issues we need to consider. First, we start with concentrating on\nmanaging replicas, which considers not only the placement of replica servers,\nbut also how content is distributed to these servers.\nThe second issue is how replicas are kept consistent.\nIn most cases,\napplications require a strong form of consistency. Informally, this means that\nupdates are to be propagated more or less immediately between replicas.\nThere are various alternatives for implementing strong consistency, which are\ndiscussed in a separate section. Also, attention is paid to caching protocols,\nwhich form a special case of consistency protocols.\nBeing arguably the largest distributed system, we pay separate attention\nto caching and replication in Web-based systems, notably looking at content\ndelivery networks as well as edge-server caching techniques.\n7.1\nIntroduction\nIn this section, we start with discussing the important reasons for wanting to\nreplicate data in the first place. We concentrate on replication as a technique\nfor achieving scalability, and motivate why reasoning about consistency is so\nimportant.\nDS 4.01\n \n",
      "content_length": 2747,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 409,
      "content": "7.1. INTRODUCTION\n393\n7.1.1\nReasons for replication\nThere are two primary reasons for replicating data. First, data are replicated\nto increase the reliability of a system. If a file system has been replicated,\nit may be possible to continue working after one replica crashes by simply\nswitching to one of the other replicas. Also, by maintaining multiple copies,\nit becomes possible to provide better protection against corrupted data. For\nexample, imagine there are three copies of a file, and every read and write\noperation is performed on each copy. We can safeguard ourselves against a\nsingle, failing write operation, by considering the value that is returned by at\nleast two copies as being the correct one.\nThe other reason for replicating data is performance. Replication for\nperformance is important when a distributed system needs to scale in terms\nof size or in terms of the geographical area it covers. Scaling regarding size\noccurs, for example, when an increasing number of processes needs to access\ndata that are managed by a single server. In that case, performance can be\nimproved by replicating the server and subsequently dividing the workload\namong the processes accessing the data.\nScaling regarding a geographical area may also require replication. The\nbasic idea is that by placing a copy of data in proximity of the process using\nthem, the time to access the data decreases. As a consequence, the performance\nas perceived by that process increases. This example also illustrates that the\nbenefits of replication for performance may be hard to evaluate. Although a\nclient process may perceive better performance, it may also be the case that\nmore network bandwidth is now consumed keeping all replicas up to date.\nIf replication helps to improve reliability and performance, who could be\nagainst it? Unfortunately, there is a price to be paid when data are replicated.\nThe problem with replication is that having multiple copies may lead to\nconsistency problems. Whenever a copy is modified, that copy becomes\ndifferent from the rest. Consequently, modifications have to be carried out on\nall copies to ensure consistency. Exactly when and how those modifications\nneed to be carried out determines the price of replication.\nTo understand the problem, consider improving access times to Web pages.\nIf no special measures are taken, fetching a page from a remote Web server\nmay sometimes even take seconds to complete. To improve performance,\nWeb browsers often locally store a copy of a previously fetched Web page\n(i.e., they cache a Web page). If a user requires that page again, the browser\nautomatically returns the local copy. The access time as perceived by the user,\nis excellent. However, if the user always wants to have the latest version of a\npage, she may be in for bad luck. The problem is that if the page has been\nmodified in the meantime, modifications will not have been propagated to\ncached copies, making those copies out-of-date.\nOne solution to the problem of returning a stale copy to the user is to\nforbid the browser to keep local copies in the first place, effectively letting the\n \nDS 4.01\n",
      "content_length": 3138,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 410,
      "content": "394\nCHAPTER 7. CONSISTENCY AND REPLICATION\nserver be fully in charge of replication. However, this solution may still lead\nto poor access times if no replica is placed near the user. Another solution is\nto let the Web server invalidate or update each cached copy, but this requires\nthat the server keeps track of all caches and sending them messages. This,\nin turn, may degrade the overall performance of the server. We return to\nperformance versus scalability issues below.\nIn the following, we will mainly concentrate on replication for performance.\nReplication for reliability is discussed in Chapter 8.\n7.1.2\nReplication as scaling technique\nReplication and caching for performance are widely applied as scaling tech-\nniques. Scalability issues generally appear in the form of performance prob-\nlems. Placing copies of data close to the processes using them can improve\nperformance through reduction of access time, and thus solve scalability\nproblems.\nA possible trade-off that needs to be made is that keeping copies up to date\nmay require more network bandwidth. Consider a process P that accesses\na local replica N times per second, whereas the replica itself is updated M\ntimes per second. Assume that an update completely refreshes the previous\nversion of the local replica. If N ≪M, that is, the access-to-update ratio is\nvery low, we have the situation where many updated versions of the local\nreplica will never be accessed by P, rendering the network communication\nfor those versions useless. In this case, it may have been better not to install\na local replica close to P, or to apply a different strategy for updating the\nreplica.\nA more serious problem, however, is that keeping multiple copies con-\nsistent may itself be subject to serious scalability problems. Intuitively, a\ncollection of copies is consistent when the copies are always the same. This\nmeans that a read operation performed at any copy will always return the\nsame result. Consequently, when an update operation is performed on one\ncopy, the update should be propagated to all copies before a subsequent\noperation takes place, no matter at which copy that operation is initiated or\nperformed.\nThis type of consistency is sometimes informally (and imprecisely) re-\nferred to as tight consistency, as provided by what is also called synchronous\nreplication. (In Section 7.2, we will provide precise definitions of consistency\nand introduce a range of consistency models.) The key idea is that an update\nis performed at all copies as a single atomic operation, or transaction. Unfor-\ntunately, implementing atomicity involving many replicas that may be widely\ndispersed across a large-scale network is inherently difficult when operations\nare also required to complete quickly.\nDifficulties come from the fact that we need to synchronize all replicas. In\nessence, this means that all replicas first need to reach agreement on when\nDS 4.01\n \n",
      "content_length": 2923,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 411,
      "content": "7.2. DATA-CENTRIC CONSISTENCY MODELS\n395\nexactly an update is to be performed locally. For example, replicas may need\nto decide on a global ordering of operations using Lamport timestamps, or\nlet a coordinator assign such an order. Global synchronization simply takes\na lot of communication time, especially when replicas are spread across a\nwide-area network.\nWe are now faced with a dilemma. On the one hand, scalability problems\ncan be alleviated by applying replication and caching, leading to improved per-\nformance. On the other hand, to keep all copies consistent generally requires\nglobal synchronization, which is inherently costly in terms of performance.\nThe cure may be worse than the disease.\nOften, the only real solution is to relax the consistency constraints. In\nother words, if we can relax the requirement that updates need to be executed\nas atomic operations, we may be able to avoid (instantaneous) global syn-\nchronizations, and may thus gain performance. The price paid is that copies\nmay not always be the same everywhere. As it turns out, to what extent\nconsistency can be relaxed depends highly on the access and update patterns\nof the replicated data, as well as on the purpose for which those data are used.\nThere is a range of consistency models and many ways to implement\nmodels through what are called distribution and consistency protocols. Ap-\nproaches to classifying consistency and replication can be found in [Gray et al.,\n1996; Wiesmann et al., 2000; Aguilera and Terry, 2016], and [Viotti and Vukolic,\n2016].\n7.2\nData-centric consistency models\nTraditionally, consistency has been discussed in the context of read and write\noperations on shared data, available through (distributed) shared memory, a\n(distributed) shared database, or a (distributed) file system. Here, we use the\nbroader term data store. A data store may be physically distributed across\nmultiple machines. In particular, each process that can access data from the\nstore is assumed to have a local (or nearby) copy available of the entire store.\nWrite operations are propagated to the other copies, as shown in Figure 7.1. A\ndata operation is classified as a write operation when it changes the data, and\nis otherwise classified as a read operation.\nA (date centric) consistency model is essentially a contract between pro-\ncesses and the data store. It says that if processes agree to obey certain rules,\nthe store promises to work correctly. Normally, a process that performs a read\noperation on a data item, expects the operation to return a value that shows\nthe results of the last write operation on that data.\nLacking a global clock, it is difficult to define precisely which write opera-\ntion is the last one. As an alternative, we need to provide other definitions,\nleading to a range of consistency models. Each model effectively restricts the\nvalues that a read operation on a data item can return. As is to be expected,\n \nDS 4.01\n",
      "content_length": 2946,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 412,
      "content": "396\nCHAPTER 7. CONSISTENCY AND REPLICATION\nFigure 7.1: The general organization of a logical data store, physically dis-\ntributed and replicated across multiple processes.\nthe ones with major restrictions are easy to use, for example when developing\napplications, whereas those with minor restrictions are generally considered\nto be difficult to use in practice. The trade-off is, of course, that the easy-to-use\nmodels do not perform nearly as well as the difficult ones. Such is life.\n7.2.1\nConsistent ordering of operations\nThere is a huge body of work on data-centric consistency models from the\npast decades. An important class of models comes from the field of parallel\nprogramming.\nConfronted with the fact that in parallel and distributed\ncomputing multiple processes will need to share resources and access these\nresources simultaneously, researchers have sought to express the semantics\nof concurrent accesses when shared resources are replicated. The models\nthat we discuss here all deal with consistently ordering operations on shared,\nreplicated data.\nSequential consistency\nIn the following, we will use a special notation in which we draw the opera-\ntions of a process along a time axis. The time axis is always drawn horizontally,\nwith time increasing from left to right. We use the notation Wi(x)a to denote\nthat process Pi writes value a to data item x. Similarly, Ri(x)b represents the\nfact that process Pi reads x and is returned the value b. We assume that each\ndata item has an initial value NIL. When there is no confusion about which\nprocess is accessing data, we omit the index from the symbols W and R.\nAs an example, in Figure 7.2 P1 does a write to a data item x, modifying\nits value to a. Note that, according to our system model the operation W1(x)a\nis first performed on a copy of the data store that is local to P1, and only then\nis it propagated to the other local copies. In our example, P2 later reads the\nvalue NIL, and some time after that a (from its local copy of the store). What\nDS 4.01\n \n",
      "content_length": 2030,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 413,
      "content": "7.2. DATA-CENTRIC CONSISTENCY MODELS\n397\nFigure 7.2: Behavior of two processes operating on the same data item. The\nhorizontal axis is time.\nwe are seeing here is that it took some time to propagate the update of x to\nP2, which is perfectly acceptable.\nSequential consistency is an important data-centric consistency model,\nwhich was first defined by Lamport [1979] in the context of shared memory\nfor multiprocessor systems. A data store is said to be sequentially consistent\nwhen it satisfies the following condition:\nThe result of any execution is the same as if the (read and write) operations\nby all processes on the data store were executed in some sequential order\nand the operations of each individual process appear in this sequence in\nthe order specified by its program.\nWhat this definition means is that when processes run concurrently on\n(possibly) different machines, any valid interleaving of read and write op-\nerations is acceptable behavior, but all processes see the same interleaving of\noperations. Note that nothing is said about time; that is, there is no reference\nto the “most recent” write operation on a data item. Also, a process “sees”\nthe writes from all process, but only through its own reads.\nThat time does not play a role can be seen from Figure 7.3. Consider four\nprocesses operating on the same data item x. In Figure 7.3(a) process P1 first\nperforms W1(x)a on x. Later (in absolute time), process P2 also performs\na write operation W2(x)b, by setting the value of x to b. However, both\nprocesses P3 and P4 first read value b, and later value a. In other words,\nthe write operation W2(x)b of process P2 appears to have taken place before\nW1(x)a of P1.\n(a)\n(b)\nFigure 7.3: (a) A sequentially consistent data store. (b) A data store that is not\nsequentially consistent.\nIn contrast, Figure 7.3(b) violates sequential consistency because not all\nprocesses see the same interleaving of write operations. In particular, to\n \nDS 4.01\n",
      "content_length": 1964,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 414,
      "content": "398\nCHAPTER 7. CONSISTENCY AND REPLICATION\nprocess P3, it appears as if the data item has first been changed to b, and later\nto a. On the other hand, P4 will conclude that the final value is b.\nProcess P1\nProcess P2\nProcess P3\nx ←1;\ny ←1;\nz ←1;\nprint(y,z);\nprint(x,z);\nprint(x,y);\nFigure 7.4: Three concurrently executing processes.\nTo make the notion of sequential consistency more concrete, consider\nthree concurrently executing processes P1, P2, and P3, shown in Figure 7.4\n(taken from [Dubois et al., 1988]). The data items in this example are formed\nby the three integer variables x, y, and z, which are stored in a (possibly\ndistributed) shared sequentially consistent data store. We assume that each\nvariable is initialized to 0. In this example, an assignment corresponds to a\nwrite operation, whereas a print statement corresponds to a simultaneous read\noperation of its two arguments. All statements are assumed to be indivisible.\nVarious interleaved execution sequences are possible. With six indepen-\ndent statements, there are potentially 720 (6!) possible execution sequences,\nalthough some of these violate program order. Consider the 120 (5!) sequences\nthat begin with x ←1. Half of these have print(x,z) before y ←1 and\nthus violate program order. Half also have print(x,y) before z ←1 and\nalso violate program order. Only 1/4 of the 120 sequences, or 30, are valid.\nAnother 30 valid sequences are possible starting with y ←1 and another 30\ncan begin with z ←1, for a total of 90 valid execution sequences. Four of\nthese are shown in Figure 7.5.\nExecution 1\nExecution 2\nExecution 3\nExecution 4\nP1:\nx ←1;\nP1:\nx ←1;\nP2:\ny ←1;\nP2:\ny ←1;\nP1:\nprint(y,z);\nP2:\ny ←1;\nP3:\nz ←1;\nP1:\nx ←1;\nP2:\ny ←1;\nP2:\nprint(x,z);\nP3:\nprint(x,y);\nP3:\nz ←1;\nP2:\nprint(x,z);\nP1:\nprint(y,z);\nP2:\nprint(x,z);\nP2:\nprint(x,z);\nP3:\nz ←1;\nP3:\nz ←1;\nP1:\nx ←1;\nP1:\nprint(y,z);\nP3:\nprint(x,y);\nP3:\nprint(x,y);\nP1:\nprint(y,z);\nP3:\nprint(x,y);\nPrints: 001011\nPrints: 101011\nPrints: 010111\nPrints: 111111\nSignature: 0 0 1 0 1 1\nSignature: 1 0 1 0 1 1\nSignature: 1 1 0 1 0 1\nSignature: 1 1 1 1 1 1\n(a)\n(b)\n(c)\n(d)\nFigure 7.5: Four valid execution sequences for the processes of Figure 7.4. The\nvertical axis is time.\nIn Figure 7.5(a) the three processes are run in order, first P1, then P2,\nthen P3. The other three examples demonstrate different, but equally valid,\ninterleaving of the statements in time. Each of the three processes prints\nDS 4.01\n \n",
      "content_length": 2429,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 415,
      "content": "7.2. DATA-CENTRIC CONSISTENCY MODELS\n399\ntwo variables. Since the only values each variable can take on are the initial\nvalue (0), or the assigned value (1), each process produces a 2-bit string. The\nnumbers after Prints are the actual outputs that appear on the output device.\nIf we concatenate the output of P1, P2, and P3 in that order, we get a 6-bit\nstring that characterizes a particular interleaving of statements. This is the\nstring listed as the Signature in Figure 7.5. Below, we will characterize each\nordering by its time-independent signature rather than by its printout.\nNot all 64 signature patterns are allowed. As a trivial example, 00 00 00 is\nnot permitted because that would imply that the print statements ran before\nthe assignment statements, violating the requirement that statements are\nexecuted in program order. A more subtle example is 00 10 01. The first two\nbits, 00, mean that y and z were both 0 when P1 did its printing. This situation\noccurs only when P1 executes both statements before P2 or P3 starts. The next\ntwo bits, 10, mean that P2 must run after P1 has started but before P3 has\nstarted. The last two bits, 01, mean that P3 must complete before P1 starts, but\nwe have already seen that P1 must go first. Therefore, 00 10 01 is not allowed.\nIn short, the 90 different valid statement orderings produce a variety of\ndifferent program results (less than 64, though) that are allowed under the\nassumption of sequential consistency. The contract between the processes and\nthe distributed shared data store is that the processes must accept all of these\nas valid results. In other words, the processes must accept the four results\nshown in Figure 7.5 and all the other valid results as proper answers, and\nmust work correctly if any of them occurs. A program that works for some of\nthese results and not for others violates the contract with the data store and is\nincorrect.\nThis example also shows that sequential consistency is not easy to under-\nstand at first sight. In the following note, we zoom more into the intricacies.\nNote 7.1 (Advanced: The importance and intricacies of sequential consistency)\nThere is no doubt that sequential consistency is an important model. In essence, of\nall consistency models that exist and have been developed, it is the easiest one to\nunderstand when developing concurrent and parallel applications. This is because\nthe model matches our expectations best when we let several programs operate\non shared data simultaneously.\nAt the same time, implementing sequential\nconsistency is far from trivial [Adve and Boehm, 2010]. To illustrate, consider the\nexample involving two variables x and y, shown in Figure 7.6.\nFigure 7.6: Both x and y are each handled in a sequentially consistent\nmanner, but taken together, sequential consistency is violated.\nIf we just consider the write and read operations on x, the fact that P1 reads\n \nDS 4.01\n",
      "content_length": 2912,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 416,
      "content": "400\nCHAPTER 7. CONSISTENCY AND REPLICATION\nthe value a is perfectly consistent. The same holds for the operation R2(y)b by\nprocess P2. However, when taken together, there is no way that we can order the\nwrite operations on x and y such that we can have R1(x)a and R2(y)b (note that\nwe need to keep the ordering as executed by each process):\nOrdering of operations\nResult\nW1(x)a; W1(y)a; W2(y)b; W2(x)b\nR1(x)b\nR2(y)b\nW1(x)a; W2(y)b; W1(y)a; W2(x)b\nR1(x)b\nR2(y)a\nW1(x)a; W2(y)b; W2(x)b; W1(y)a\nR1(x)b\nR2(y)a\nW2(y)b; W1(x)a; W1(y)a; W2(x)b\nR1(x)b\nR2(y)a\nW2(y)b; W1(x)a; W2(x)b; W1(y)a\nR1(x)b\nR2(y)a\nW2(y)b; W2(x)b; W1(x)a; W1(y)a\nR1(x)a\nR2(y)a\nIn terms of transactions, the operations carried out by P1 and P2 are not serializ-\nable. Our example shows that sequential consistency is not compositional: when\nhaving data items that are each kept sequentially consistent, their composition\nas a set need not be so [Herlihy et al., 2021]. The problem of noncompositional\nconsistency can be solved by assuming linearizability. This is best explained\nby making a distinction between the start and completion of an operation, and\nassuming that it may take some time. Linearizability [Herlihy and Wing, 1991]\nstates that:\nEach operation should appear to take effect instantaneously at some moment\nbetween its start and completion.\nReturning to our example, Figure 7.7 shows the same set of write operations, but\nwe have now also indicated when they take place: the shaded area designates\nthe time the operation is being executed. Linearizability states that the effect of\nan operation should take place somewhere during the interval indicated by the\nshaded area. In principle, this means that at the time of completion of a write\noperation, the results should be propagated to the other data stores.\nFigure 7.7: An example of taking linearizable sequential consistency into\naccount, with only one possible outcome for x and y.\nWith that in mind, the possibilities for properly ordering become limited:\nOrdering of operations\nResult\nW1(x)a; W2(y)b; W1(y)a; W2(x)b\nR1(x)b\nR2(y)a\nW1(x)a; W2(y)b; W2(x)b; W1(y)a\nR1(x)b\nR2(y)a\nW2(y)b; W1(x)a; W1(y)a; W2(x)b\nR1(x)b\nR2(y)a\nW2(y)b; W1(x)a; W2(x)b; W1(y)a\nR1(x)b\nR2(y)a\nIn particular, W2(y)b is completed before W1(y)a starts, so that y will have the\nvalue a. Likewise, W1(x)a completes before W2(x)b starts, so that x will have\nDS 4.01\n \n",
      "content_length": 2370,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 417,
      "content": "7.2. DATA-CENTRIC CONSISTENCY MODELS\n401\nvalue b. It should not come as a surprise that implementing linearizability on\na many-core architecture may impose serious performance problems. Yet at the\nsame time, it eases programmability considerably, so a trade-off needs to be made.\nCausal consistency\nThe causal consistency model [Hutto and Ahamad, 1990] represents a weak-\nening of sequential consistency in that it makes a distinction between events\nthat are potentially causally related and those that are not. We already came\nacross causality when discussing vector timestamps in the previous chapter.\nIf event b is caused or influenced by an earlier event a, causality requires that\neveryone else first see a, then see b.\nConsider a simple interaction using a distributed shared database. Suppose\nthat process P1 writes a data item x. Then P2 reads x and writes y. Here, the\nreading of x and the writing of y are potentially causally related because the\ncomputation of y may have depended on the value of x as read by P2 (i.e., the\nvalue written by P1).\nOn the other hand, if two processes spontaneously and simultaneously\nwrite two different data items, these are not causally related. Operations that\nare not causally related are said to be concurrent.\nFor a data store to be considered causally consistent, it is necessary that\nthe store obeys the following condition:\nWrites that are potentially causally related must be seen by all processes\nin the same order. Concurrent writes may be seen in a different order on\ndifferent machines.\nAs an example of causal consistency, consider Figure 7.8. Here we have an\nevent sequence that is allowed with a causally consistent store, but which is\nforbidden with a sequentially consistent store or a strictly consistent store.\nThe thing to note is that the writes W2(x)b and W1(x)c are concurrent, so it is\nnot required that all processes see them in the same order.\nFigure 7.8: This sequence is allowed with a causally consistent store, but not\nwith a sequentially consistent store.\nNow consider a second example. In Figure 7.9(a) we have W2(x)b poten-\ntially depending on W1(x)a because writing the value b into x may be a result\n \nDS 4.01\n",
      "content_length": 2189,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 418,
      "content": "402\nCHAPTER 7. CONSISTENCY AND REPLICATION\nof a computation involving the previously read value by R2(x)a. The two\nwrites are causally related, so all processes must see them in the same order.\nTherefore, Figure 7.9(a) is incorrect. On the other hand, in Figure 7.9(b) the\nread has been removed, so W1(x)a and W2(x)b are now concurrent writes.\nA causally consistent store does not require concurrent writes to be globally\nordered, so Figure 7.9(b) is correct. Note that Figure 7.9(b) reflects a situation\nthat would not be acceptable for a sequentially consistent store.\n(a)\n(b)\nFigure 7.9: (a) A violation of a causally consistent store. (b) A correct sequence\nof events in a causally consistent store.\nImplementing causal consistency requires keeping track of which processes\nhave seen which writes. There are many subtle issues to consider. To illustrate,\nassume we replace W2(x)b in Figure 7.9(a) with W2(y)b, and likewise R3(x)b\nwith R3(y)b, respectively. This situation is shown in Figure 7.10.\nFigure 7.10: A slight modification of Figure 7.9(a). What should R3(x) or R4(y)\nreturn?\nLet us first look at operation R3(x). Process P3 executes this operation\nafter R3(y)b. We know at this point for sure that W(x)a happened before W(y)b.\nIn particular, W(x)a →R(x)a →W(y)b, meaning that if we are to preserve\ncausality, reading x after reading b from y can return only a. If the system\nreturned NIL to P3 it would violate the preservation of causal relationships.\nDS 4.01\n \n",
      "content_length": 1477,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 419,
      "content": "7.2. DATA-CENTRIC CONSISTENCY MODELS\n403\nWhat about R4(y)? Could it return the initial value of y, namely NIL? The\nanswer is affirmative: although we have the formal happened-before relationship\nW(x)a →W(y)b, without having read b from y, process P4 can still justifiably\nobserve that W(x)a took place independently of the initialization of y.\nImplementation wise, preserving causality introduces some interesting\nquestions. Consider, for example, the middleware underlying process P3\nfrom Figure 7.10. At the point that this middleware returns the value b from\nreading y, it must know about the relationship W(x)a →W(y)b. In other\nwords, when the most recent value of y was propagated to P3’s middleware,\nat the very least, metadata on y’s dependency should have been propagated\nas well. Alternatively, the propagation may have also been done together\nwith updating x at P3’s node. By-and-large, the bottom line is that we need a\ndependency graph of which operation is dependent on which other operations.\nSuch a graph may be pruned at the moment that dependent data is also locally\nstored.\nGrouping operations\nMany consistency models are defined at the level of elementary read and write\noperations. This level of granularity is for historical reasons: these models\nhave initially been developed for shared-memory multiprocessor systems and\nwere actually implemented at the hardware level.\nThe fine granularity of these consistency models often does not match the\ngranularity as provided by applications. What we see there is that concurrency\nbetween programs sharing data is generally kept under control through syn-\nchronization mechanisms for mutual exclusion and transactions. Effectively,\nwhat happens is that at the program level, read and write operations are\nbracketed by the pair of operations ENTER_CS and LEAVE_CS. A process\nthat has successfully executed ENTER_CS will be ensured that all the data\nin its local store is up-to-date. At that point, it can safely execute a series of\nread and write operations on that store, and subsequently wrap things up by\ncalling LEAVE_CS. Data and instructions between ENTER_CS and LEAVE_CS\nis denoted as a critical region.\nIn essence, what happens is that within a program, the data that are\noperated on by a series of read and write operations are protected against\nconcurrent accesses that would lead to seeing something else than the result\nof executing the series as a whole. Put differently, the bracketing turns the\nseries of read and write operations into an atomically executed unit, thus\nraising the level of granularity.\nTo reach this point, we do need to have precise semantics concerning the\noperations ENTER_CS and LEAVE_CS. These semantics can be formulated\nin terms of shared synchronization variables, or simply locks. A lock has\nshared data items associated with it, and each shared data item is associated\nwith at most one lock. In the case of coarse-grained synchronization, all\n \nDS 4.01\n",
      "content_length": 2959,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 420,
      "content": "404\nCHAPTER 7. CONSISTENCY AND REPLICATION\nshared data items would be associated to just a single lock. Fine-grained\nsynchronization is achieved when each shared data item has its own unique\nlock. Of course, these are just two extremes of associating shared data to a\nlock. When a process enters a critical region, it should acquire the relevant\nlocks, and likewise when it leaves the critical region, it releases these locks.\nEach lock has a current owner, namely, the process that last acquired it. A\nprocess not currently owning a lock but wanting to acquire it has to send a\nmessage to the current owner asking for ownership and the current values of\nthe data associated with that lock. While having exclusive access to a lock, a\nprocess is allowed to perform read and write operations. It is also possible for\nseveral processes to simultaneously have nonexclusive access to a lock, meaning\nthat they can read, but not write, the associated data. Of course, nonexclusive\naccess can be granted if and only if there is no other process having exclusive\naccess.\nWe now demand that the following criteria are met [Bershad et al., 1993]:\n• Acquiring a lock can succeed only when all updates to its associated\nshared data have completed.\n• Exclusive access to a lock can succeed only if no other process has\nexclusive or nonexclusive access to that lock.\n• Nonexclusive access to a lock is allowed only if any previous exclusive\naccess has been completed, including updates to the lock’s associated\ndata.\nNote that we are effectively demanding that the usage of locks is linearized,\nadhering to sequential consistency. Figure 7.11 shows an example of what\nis known as entry consistency. We associate a lock with each data item\nseparately. We use the notation L(x) as an abbreviation for acquiring the lock\nfor x, that is, locking x. Likewise, U(x) stands for releasing the lock on x, or\nunlocking it. In this case, P1 locks x, changes x once, after which it locks y.\nProcess P2 also acquires the lock for x but not for y so that it will read value a\nfor x, but may read NIL for y. However, because process P3 first acquires the\nlock for y, it will read the value b when y was unlocked by P1. It is important\nto note here that each process has a copy of a variable, but that this copy\nneed not be instantly or automatically updated. When locking or unlocking a\nvariable, a process is explicitly telling the underlying distributed system that\nthe copies of that variable need to be synchronized. A simple read operation\nwithout locking may thus result in reading a local value that is effectively\nstale.\nOne of the programming problems with entry consistency is properly\nassociating data with locks. One straightforward approach is to explicitly\ntell the middleware which data will be accessed, as is generally done by\ndeclaring which database tables will be affected by a transaction. In an object-\nDS 4.01\n \n",
      "content_length": 2906,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 421,
      "content": "7.2. DATA-CENTRIC CONSISTENCY MODELS\n405\nFigure 7.11: A valid event sequence for entry consistency.\nbased approach, we could associate a unique lock with each declared object,\neffectively serializing all invocations to such objects.\nNote 7.2 (More information: Consistency models, serializability, transactions)\nComing to this point, the consistency models may at first sight appear to be\noverwhelming. Yet, despite their seemingly complexity, there are strong analogies\nwith models that many of us are used to. In particular, let us consider transactions.\nAs discussed in Section 1.3.2, transactions effectively group a series of read and\nwrite operations such that it is guaranteed that these operations are executed in\nthe order of their appearance in the transaction. Moreover, when considering\na collection of transactions that simultaneously operate on a data set, then the\nfinal values of that data set can be explained by one specific ordering of those\ntransactions.\nThe keyword here is serializability: can we order the execution of operations\nthat comprise the transactions in such a way that the final result matches a serial\nexecution of the transactions? Consider the example shown in Figure 7.12. It is\nimportant to note that it is not necessary to know what is exactly being computed,\nbut instead, only that we are dealing with read and write operations. In this sense,\neach transaction Ti can be represented as the series ⟨Wi(x); Ri(x); Wi(x)⟩.\nBEGIN_TRANSACTION\nBEGIN_TRANSACTION\nBEGIN_TRANSACTION\nx = 0\nx = 0\nx = 0\nx = x + 1\nx = x + 2\nx = x + 3\nEND_TRANSACTION\nEND_TRANSACTION\nEND_TRANSACTION\nTransaction T1\nTransaction T2\nTransaction T3\nFigure 7.12: Three transactions.\nTo ensure consistency, the underlying transaction system will have to devise\nlegal schedules: orderings of the read and write operations from the three\ntransactions such that the final result corresponds to a serial execution of those\ntransactions. Consider the four schedules shown in Figure 7.13.\nBoth schedules S1 and S2 produce the result x == 3. This result can be\nexplained by assuming that the scheduler executed the transactions in the order\nT1 →T2 →T3. This ordering happens to match S1, but not S2, yet that is\nnot relevant. Likewise, S3 is an illegal schedule, having the final result x == 5.\nSchedule S4 is interesting: the final result is x == 3, but that is only because of a\ncoincidence. As the scheduler sees only (read and) write operations, and not the\n \nDS 4.01\n",
      "content_length": 2470,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 422,
      "content": "406\nCHAPTER 7. CONSISTENCY AND REPLICATION\neffects of write operations, scheduling the operations x = x + 1 and then x = x + 2\nis illegal.\nTime −→\nS1\nx = 0\nx = x + 1\nx = 0\nx = x + 2\nx = 0\nx = x + 3\nLegal\nS2\nx = 0\nx = 0\nx = x + 1\nx = x + 2\nx = 0\nx = x + 3\nLegal\nS3\nx = 0\nx = 0\nx = x + 1\nx = 0\nx = x + 2\nx = x + 3\nIllegal\nS4\nx = 0\nx = 0\nx = x + 3\nx = 0\nx = x + 1\nx = x + 2\nIllegal\nFigure 7.13: Various schedules from the transactions shown in Figure 7.12.\nNote that what we have just described corresponds to entry consistency.\nTransactions consisting of only a single operation are, from a consistency point of\nview, analogous to sequential consistency.\nConsistency versus coherence\nAt this point, it is useful to clarify the difference between two closely related\nconcepts. The models we have discussed so far, all deal with the fact that a\nnumber of processes execute read and write operations on a set of data items.\nA consistency model describes what can be expected regarding that set when\nmultiple processes concurrently operate on that data. The set is then said to\nbe consistent if it adheres to the rules described by the model.\nWhere data consistency is concerned with a set of data items, coher-\nence models describe what can be expected to hold for only a single data\nitem [Cantin et al., 2005]. In this case, we assume that a data item is replicated;\nit is said to be coherent when the various copies abide to the rules as defined\nby its associated consistency model. A popular model is that of sequential\nconsistency, but now applied to only a single data item. In effect, it means\nthat in the case of concurrent writes, all processes will eventually see the same\norder of updates taking place.\n7.2.2\nEventual consistency\nTo what extent processes actually operate in a concurrent fashion, and to\nwhat extent consistency needs to be guaranteed, may vary. There are many\nexamples in which concurrency appears only in a restricted form. For exam-\nple, in many database systems, most processes hardly ever perform update\noperations; they mostly read data from the database. Only one, or very few,\nprocesses perform update operations. The question then is how fast updates\nshould be made available to only-reading processes. In the advent of globally\noperating content delivery networks, developers often choose to propagate\nupdates slowly, implicitly assuming that most clients are always redirected to\nthe same replica and will therefore never experience inconsistencies.\nDS 4.01\n \n",
      "content_length": 2492,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 423,
      "content": "7.2. DATA-CENTRIC CONSISTENCY MODELS\n407\nAnother example is the Web. In virtually all cases, Web pages are updated\nby a single authority, such as a webmaster or the actual owner of the page.\nThere are normally no write-write conflicts to resolve. On the other hand, to\nimprove efficiency, browsers and Web proxies are often configured to keep a\nfetched page in a local cache and to return that page upon the next request.\nAn important aspect of both types of Web caches is that they may return\nout-of-date Web pages. In other words, the cached page that is returned to\nthe requesting client is an older version compared to the one available at\nthe actual Web server. As it turns out, many users find this inconsistency\nacceptable (to a certain degree), as long as they have access only to the same\ncache. In effect, they remain unaware of the fact that an update had taken\nplace, just as in the previous case of content delivery networks.\nYet another example, is a worldwide naming system such as DNS. The DNS\nname space is partitioned into domains, where each domain is assigned to a\nnaming authority, which acts as owner of that domain. Only that authority is\nallowed to update its part of the name space. Consequently, conflicts resulting\nfrom two operations that both want to perform an update on the same data\n(i.e., write-write conflicts), never occur. The only situation that needs to be\nhandled are read-write conflicts, in which one process intends to update a\ndata item while another is concurrently attempting to read that item. As it\nturns out, also in this case it is often acceptable to propagate an update in\na lazy fashion, meaning that a reading process will see an update only after\nsome time has passed since the update took place.\nThese examples can be viewed as cases of (large scale) distributed and\nreplicated databases that tolerate a relatively high degree of inconsistency.\nThey have in common that if no updates take place for a long time, all replicas\nwill gradually become consistent, that is, have the same data stored. This\nform of consistency is called eventual consistency [Vogels, 2009].\nData stores that are eventually consistent thus have the property that\nlacking write-write conflicts, all replicas will converge toward identical copies\nof each other. Eventual consistency essentially requires only that updates\nare guaranteed to propagate to all replicas. Write-write conflicts are often\nrelatively easy to solve when assuming that only a small group of processes\ncan perform updates. In practice, we often also see that in the case of conflicts,\none specific write operation is (globally) declared as “winner,” overwriting\nthe effects of any other conflicting write operation. Eventual consistency is\ntherefore often cheap to implement.\nNote 7.3 (Advanced: Making eventual consistency stronger)\nEventual consistency is a relatively easy model to understand, but equally im-\nportant is the fact that it is also relatively easy to implement. Nevertheless, it\nis a weak-consistency model with its own peculiarities. Consider a calendar\nshared between Alice, Bob, and Chuck. A meeting M has two attributes: a pro-\nDS 4.01\n",
      "content_length": 3158,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 424,
      "content": "408\nCHAPTER 7. CONSISTENCY AND REPLICATION\nposed starting time and a set of people who have confirmed their attendance.\nWhen Alice proposes to start meeting M at time T, and assuming no one else\nhas confirmed attendance, she executes the operation WA(M)[T, {A}]. When\nBob confirms his attendance, he will have read the tuple [T, {A}] and update M\naccordingly: WB(M)[T, {A, B}]. In our example two meetings M1 and M2 need to\nbe planned.\nAssume the sequence of events\nWA(M1)[T1, {A}] →RB(M1)[T1, {A}] →\nWB(M1)[T1, {A, B}] →WB(M2)[T2, {B}].\nIn other words, Bob confirms his attendance at M1 and then immediately proposes\nto schedule M2 at T2. Unfortunately, Chuck concurrently proposes to schedule M1\nat T3 when Bob confirms he can attend M1 at T1. Formally, using the symbol “∥”\nto denote concurrent operations, we have,\nWB(M1)[T1, {A, B}] ∥WC(M1)[T3, {C}].\nUsing our usual notation, these operations can be illustrated as shown in Fig-\nure 7.14.\nFigure 7.14: The situation of updating two meetings M1 and M2.\nEventual consistency may lead to very different scenarios. There are a number\nof write-write conflicts, but in any case, eventually [T2, {B}] will be stored for\nmeeting M2, as the result of the associated write operation by Bob. For the value\nof meeting M1 there are different options. In principle, we have three possible\noutcomes: [T1, {A}], [T1, {A, B}], and [T3, {C}]. Assuming we can maintain some\nnotion of a global clock, it is not very likely that WA(M1)[T1, {A}] will prevail.\nHowever, the two write operations WB(M1)[T1, {A, B}] and WC(M1)[T3, {C}] are\ntruly in conflict. In practice, one of them will win, presumably through a decision\nby a central coordinator.\nResearchers have been seeking to combine eventual consistency with stricter\nguarantees on ordering.\nBailis et al. [2013] propose to use a separate layer\nthat operates on top of an eventually consistent, distributed store. This layer\nimplements causal consistency, of which it has been formerly proven that it is\nthe best attainable consistency in the presence of network partitioning [Mahajan\net al., 2011]. In our example, we have only one chain of dependencies:\nWA(M1)[T1, {A}] →RB(M1)[T1, {A}] →\nWB(M1)[T1, {A, B}] →WB(M2)[T2, {B}].\nDS 4.01\n \n",
      "content_length": 2227,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 425,
      "content": "7.2. DATA-CENTRIC CONSISTENCY MODELS\n409\nAn important observation is that with causal consistency in place, once a pro-\ncess reads [T2, {B}] for meeting M2, obtaining the value for M1 returns ei-\nther [T1, {A, B}] or [T3, {C}], but certainly not [T1, {A}].\nThe reason is that\nWB(M1)[T1, {A, B}] immediately precedes WB(M2)[T2, {B}], and at worse may\nhave been overwritten by WC(M1)[T3, {C}]. Causal consistency rules out that the\nsystem could return [T1, {A}].\nHowever, eventual consistency may overwrite previously stored data items.\nIn doing so, dependencies may be lost. To make this point clear, it is impor-\ntant to realize that in practice, an operation at best keeps track of the immedi-\nate preceding operation it depends on. As soon as Wc(M1)[T3, {C}] overwrites\nWB(M1)[T1, {A, B}] (and propagates to all replicas), we also break the chain of\ndependencies\nWA(M1)[T1, {A}] →RB(M1)[T1, {A}] →· · · →WB(M2)[T2, {B}]\nwhich\nwould\nnormally\nprevent\nWA(M1)[T1, {A}]\never\novertaking\nWB(M1)[T1, {A, B}] and any operation depending on it.\nAs a consequence,\nmaintaining causal consistency requires that we do maintain a history of\ndependencies, instead of just keeping track of immediately preceding operations.\nAssuming that write-write conflicts hardly occur is generally not realistic.\nAs mentioned, improvements can be made by grouping operations and using\nlocks. What this entails, is that processes need to coordinate their actions by\nmaking use of mutual-exclusion mechanisms. For many large-scale systems,\ncoordination among processes has turned out to form a real performance\nbottleneck. Note that we are dealing here with coordination for consistency.\nAlleviating potential bottleneck problems then boils down to bringing down\ncoordination, or weakening consistency requirements. At least two approaches\nhave been, by now, reasonably well explored, and are gradually finding their\nway into practical solutions.\nThe first one, referred to as strong eventual consistency, ensures that\nif there are conflicting updates, that nevertheless the replicas where those\nupdates have taken place, are in the same state. Note that this is indeed\nstronger than (weak) eventual consistency, as in that case, nothing is specified\nwhat to do when the same replicated data item is updated by two different\nprocesses, except that the conflict may be reported. The seminal paper by\nShapiro et al. [2011] introduced the Conflict-Free Replicated Data Type, or\nsimply CRDT. A CRDT is a data type that can be replicated at many different\nsites, yet most importantly, can be updated in a concurrent fashion without\nfurther coordination. Of course, the meaning of concurrent updates may be\ndifferent per type. For example, in the case of a variable for which the last\nupdate wins, its implementation will need to keep track of dependencies. A\ncrude, but perhaps acceptable semantics, is that a good approximation of the\nactual time when an update is initiated is considered (e.g., using NTP), along\n \nDS 4.01\n",
      "content_length": 2991,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 426,
      "content": "410\nCHAPTER 7. CONSISTENCY AND REPLICATION\nwith some random number to come to a deterministic choice when several\nupdates happen within the same small time span. An alternative is to keep\nall updates so that a final decision can be made at application level. Many of\nsuch examples are discussed by Preguica [2018]. Kleppmann and Beresford\n[2017] describe how CRDTs can be implemented to support data structures in\nwhich no update is lost. In effect, it boils down to keeping all updates while at\nthe same time avoiding clear duplicates, and maintaining clear dependencies.\nThe second approach is to move away from data-centric consistency and\nto look at program consistency. Again motivated by the observation that\ncoordination for consistency may be extremely costly, the question arises if and\nwhere coordination is truly necessary. Program consistency is all about the\nquestion whether a program produces the expected outcome, despite various\nkinds of anomalies that may occur (like race conditions). A key observation is\nthat of problem monotonicity:\nA problem P is monotonic if for any input sets S and T, P(S) ⊆P(T).\nThe basic idea behind a monotonic problem is that it can come to a (partial)\nsolution even if certain input information is missing.\nIn other words, a\nprogram solving a monotonic problem can start with incomplete information,\nbut is guaranteed not to have to roll back when missing information becomes\navailable. A typical example of such a problem is filling a (digital) shopping\ncart: operations can be performed in any order by any server. Indeed, there\nis no write-write conflict. However, if we also need to support the removal\nof items, we bump into a problem. In this case, monotonicity can help if we\nsplit the add and delete operations into two different sets, and let each of\nthem simply grow to a final state. In this case, we need to coordinate only\nwhen each set has converged to a final state. The difference between what\nhas been added and what has been deleted is what needs to be coordinated\nto reach consistency. Further details on program consistency can be found\nin [Hellerstein and Alvaro, 2020].\n7.2.3\nContinuous consistency\nThere is no such thing as the best solution to replicating data. Replicating data\nposes consistency problems that cannot be solved efficiently in a general way.\nOnly if we loosen consistency can there be hope for attaining efficient solutions.\nUnfortunately, there are also no general rules for loosening consistency: exactly\nwhat can be tolerated is highly dependent on applications.\nThere are different ways for applications to specify what inconsistencies\nthey can tolerate. Yu and Vahdat [2002] take a general approach by distin-\nguishing three independent axes for defining inconsistencies: deviation in\nnumerical values between replicas, deviation in staleness between replicas,\nand deviation with respect to the ordering of update operations. They refer to\nthese deviations as forming continuous consistency ranges.\nDS 4.01\n \n",
      "content_length": 3002,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 427,
      "content": "7.2. DATA-CENTRIC CONSISTENCY MODELS\n411\nMeasuring inconsistency in terms of numerical deviations can be used\nby applications for which the data have numerical semantics. One obvious\nexample is the replication of records containing stock market prices. In this\ncase, an application may specify that two copies should not deviate more than\n$0.02, which would be an absolute numerical deviation. Alternatively, a relative\nnumerical deviation could be specified, stating that two copies should differ by\nno more than, for example, 0.5%. In both cases, we would see that if a stock\ngoes up (and one of the replicas is immediately updated) without violating\nthe specified numerical deviations, the replicas would still be considered to\nbe mutually consistent.\nNumerical deviation can also be understood in terms of the number of\nupdates that have been applied to a given replica, but have not yet been seen\nby others. For example, a Web cache may not have seen a batch of operations\ncarried out by a Web server. In this case, the associated deviation in the value\nis also referred to as its weight.\nStaleness deviations relate to the last time a replica was updated. For some\napplications, it can be tolerated that a replica provides old data as long as it is\nnot too old. For example, weather reports typically stay reasonably accurate\nover some time, say a few hours. In such cases, a main server may receive\ntimely updates, but may decide to propagate updates to the replicas only once\nin a while.\nFinally, there are classes of applications in which the ordering of updates\nis allowed to be different at the various replicas, as long as the differences\nremain bounded. One way of looking at these updates is that they are applied\ntentatively to a local copy, awaiting global agreement from all replicas. As\na consequence, some updates may need to be rolled back and applied in a\ndifferent order before becoming permanent. Intuitively, ordering deviations\nare much harder to grasp than the other two consistency metrics.\nThe notion of a conit\nTo define inconsistencies, Yu and Vahdat introduce a consistency unit, ab-\nbreviated to conit. A conit specifies the unit over which consistency is to\nbe measured. For example, in our stock-exchange example, a conit could\nbe defined as a record representing a single stock. Another example is an\nindividual weather report.\nTo give an example of a conit, and at the same time illustrate numerical\nand ordering deviations, consider the situation of keeping track of a fleet of\ncars. In particular, the fleet owner is interested in knowing how much she\npays on average for gas. To this end, whenever a driver tanks gasoline, she\nreports the amount of gasoline that has been tanked (recorded as g), the price\npaid (recorded as p), and the total distance since the last time she tanked\n(recorded by the variable d). Technically, the three variables g, p, and d form a\nconit. This conit is replicated across two servers, as shown in Figure 7.15, and\n \nDS 4.01\n",
      "content_length": 2994,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 428,
      "content": "412\nCHAPTER 7. CONSISTENCY AND REPLICATION\na driver regularly reports her gas usage to one of the servers by separately\nupdating each variable (without further considering the car in question).\nThe task of the servers is to keep the conit “consistently” replicated. To\nthis end, each replica server maintains a two-dimensional vector clock. We\nuse the notation ⟨T, R⟩to express an operation that was carried out by replica\nR at (its) logical time T.\nFigure 7.15: An example of keeping track of consistency deviations.\nIn this example, we see two replicas that operate on a conit containing the\ndata items g, p, and d from our example. All variables are assumed to have\nbeen initialized to 0. Replica A received the operation\n⟨5, B⟩: g ←g + 45\nfrom replica B. We have shaded this operation gray to indicate that A has\ncommitted this operation to its local store. In other words, it has been made\npermanent and cannot be rolled back. Replica A also has three tentative\nupdate operations listed: ⟨8, A⟩, ⟨9, A⟩, and ⟨10, A⟩, respectively. In terms of\ncontinuous consistency, the fact that A has three tentative operations pending\nto be committed is referred to as an order deviation of, in this case, value 3.\nAnalogously, with in total three operations of which two have been committed,\nB has an order deviation of 1.\nFrom this example, we see that A’s logical clock value is now 11. Because\nthe last operation from B that A had received had timestamp 5, the vector\nclock at A will be (11, 5), where we assume the first component of the vector\nis used for A and the second for B. Along the same lines, the logical clock at\nB is (0, 8).\nThe numerical deviation at a replica R consists of two components: the\nnumber of operations at all other replicas that have not yet been seen by\nDS 4.01\n \n",
      "content_length": 1789,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 429,
      "content": "7.2. DATA-CENTRIC CONSISTENCY MODELS\n413\nR, along with the sum of corresponding missed values (more sophisticated\nschemes are, of course, also possible). In our example, A has not yet seen\noperations ⟨6, B⟩and ⟨7, B⟩with a total value of 70 + 412 units, leading to a\nnumerical deviation of (2, 482). Likewise, B is still missing the three tentative\noperations at A, with a total summed value of 686, bringing B’s numerical\ndeviation to (3, 686).\nUsing these notions, it becomes possible to specify specific consistency\nschemes. For example, we may restrict order deviation by specifying an\nacceptable maximal value. Likewise, we may want two replicas to never nu-\nmerically deviate by more than 1000 units. Having such consistency schemes\ndoes require that a replica knows how much it is deviating from other replicas,\nimplying that we need separate communication to keep replicas informed.\nThe underlying assumption is that such communication is much less expen-\nsive than communication to keep replicas synchronized. Admittedly, it is\nquestionable if this assumption also holds for our example.\nNote 7.4 (Advanced: On the granularity of conits)\nThere is a trade-off between maintaining fine-grained and coarse-grained conits.\nIf a conit represents a lot of data, such as a complete database, then updates are\naggregated for all the data in the conit. As a consequence, this may bring replicas\nsooner in an inconsistent state. For example, assume that in Figure 7.16 two\nreplicas may differ in no more than one outstanding update. In that case, when\nthe data items in Figure 7.16 have each been updated once at the first replica, the\nsecond one will need to be updated as well. This is not the case when choosing\na smaller conit, as shown in Figure 7.16 There, the replicas are still considered\nto be up-to-date. This problem is particularly important when the data items\ncontained in a conit are used completely independently, in which case they are\nsaid to falsely share the conit.\n(a)\n(b)\nFigure 7.16: Choosing the appropriate granularity for a conit. (a) Two\nupdates lead to update propagation. (b) No update propagation is needed.\nUnfortunately, making conits small is not a good idea, for the simple reason\nthat the total number of conits that need to be managed grows as well. In other\nwords, there is an overhead related to managing the conits that needs to be\nconsidered. This overhead, in turn, may adversely affect overall performance,\nwhich also has to be considered.\n \nDS 4.01\n",
      "content_length": 2491,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 430,
      "content": "414\nCHAPTER 7. CONSISTENCY AND REPLICATION\nAlthough, from a conceptual point of view, conits form an attractive means\nfor capturing consistency requirements, there are two important issues that\nneed to be dealt with before they can be put to practical use. First, to enforce\nconsistency, we need to have protocols. Protocols for continuous consistency\nare discussed later in this chapter.\nA second issue is that program developers must specify the consistency\nrequirements for their applications. Practice indicates that obtaining such\nrequirements may be extremely difficult. Programmers are generally not used\nto handling replication, let alone understanding what it means to provide\ndetailed information on consistency. Therefore, it is mandatory that there are\nsimple and easy-to-understand programming interfaces.\nNote 7.5 (Advanced: Programming conits)\nContinuous consistency can be implemented as a toolkit which appears to pro-\ngrammers as just another library that they link with their applications. A conit is\nsimply declared alongside an update of a data item. For example, the fragment of\npseudocode\nAffectsConit(ConitQ, 1, 1);\nappend message m to queue Q;\nstates that appending a message to queue Q belongs to a conit named ConitQ.\nLikewise, operations may now also be declared as being dependent on conits:\nDependsOnConit(ConitQ, 4, 0, 60);\nread message m from head of queue Q;\nIn this case, the call to DependsOnConit() specifies that the numerical deviation,\nordering deviation, and staleness should be limited to the values 4, 0, and 60\n(seconds), respectively. This can be interpreted as that there should be at most\n4 unseen update operations at other replicas, there should be no tentative local\nupdates, and the local copy of Q should have been checked for staleness no more\nthan 60 seconds ago. If these requirements are not fulfilled, the underlying\nmiddleware will attempt to bring the local copy of Q to a state such that the read\noperation can be carried out.\nThe question, of course, is how does the system know that Q is associated\nwith ConitQ? For practical reasons, we can avoid explicit declarations of conits\nand concentrate only on the grouping of operations. The data to be replicated is\ncollectively considered belonging together. By subsequently associating a write\noperation with a named conit, and likewise for a read operation, we tell the\nmiddleware layer when to start synchronizing the entire replica. Indeed, there may\nbe a considerable amount of false sharing in such a case. If false sharing needs\nto be avoided, we would have to introduce a separate programming construct to\nexplicitly declare conits.\nDS 4.01\n \n",
      "content_length": 2658,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 431,
      "content": "7.3. CLIENT-CENTRIC CONSISTENCY MODELS\n415\n7.3\nClient-centric consistency models\nData-centric consistency models aim at providing a systemwide consistent\nview on a data store. An important assumption is that concurrent processes\nmay be simultaneously updating the data store, and that it is necessary to\nprovide consistency in the face of such concurrency. For example, in the case\nof object-based entry consistency, the data store guarantees that when an\nobject is called, the calling process is provided with a copy of the object that\nreflects all changes to the object that have been made so far, possibly by other\nprocesses. During the call, it is also guaranteed that no other process can\ninterfere, that is, mutual exclusive access is provided to the calling process.\nBeing able to handle concurrent operations on shared data while maintain-\ning strong consistency is fundamental to distributed systems. For performance\nreasons, strong consistency may be guaranteed only when processes use mech-\nanisms such as transactions or synchronization variables. Along the same\nlines, it may be impossible to guarantee strong consistency, and weaker forms\nneed to be accepted, such as causal consistency with eventual consistency.\nIn this section, we take a look at a special class of distributed data stores.\nThe data stores we consider are characterized by the lack of simultaneous\nupdates, or when such updates happen, it is assumed that they can be\nrelatively easily resolved. Most operations involve reading data. These data\nstores offer a weak consistency model, such as eventual consistency. By\nintroducing special client-centric consistency models, it turns out that many\ninconsistencies can be hidden in a relatively cheap way.\nFigure 7.17: The principle of a mobile user accessing different replicas of a\ndistributed database.\n \nDS 4.01\n",
      "content_length": 1844,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 432,
      "content": "416\nCHAPTER 7. CONSISTENCY AND REPLICATION\nEventually, consistent data stores generally work fine as long as clients\nalways access the same replica. However, problems arise when different\nreplicas are accessed over a short period of time. This is best illustrated\nby considering a mobile user accessing a distributed database, as shown in\nFigure 7.17.\nThe mobile user, say, Alice, accesses the database by connecting to one\nof the replicas in a transparent way. In other words, the application running\non Alice’s mobile device is unaware on which replica it is actually operating.\nAssume Alice performs several update operations and then disconnects again.\nLater, she accesses the database again, possibly after moving to a different\nlocation or by using a different access device. At that point, she may be\nconnected to a different replica than before, as shown in Figure 7.17. However,\nif the updates performed previously have not yet been propagated, Alice\nwill notice inconsistent behavior. In particular, she would expect to see all\npreviously made changes, but instead, it appears as if nothing at all has\nhappened.\nThis example is typical for eventually consistent data stores and is caused\nby the fact that users may sometimes operate on different replicas, while\nupdates have not been fully propagated. The problem can be alleviated by\nintroducing client-centric consistency. In essence, client-centric consistency\nprovides guarantees for a single client concerning the consistency of accesses\nto a data store by that client. No guarantees are given concerning concurrent\naccesses by different clients. If Bob modifies data that is shared with Alice\nbut which is stored at a different location, we may easily create write-write\nconflicts. Moreover, if neither Alice nor Bob access the same location for some\ntime, such conflicts may take a long time before they are discovered.\nClient-centric consistency models originate from the work on Bayou and,\nmore general, from mobile-data systems (see, for example, Terry et al. [1994],\nTerry et al. [1998], or Terry [2008]). Bayou is a database system developed\nfor mobile computing, where it is assumed that network connectivity is\nunreliable and subject to various performance problems. Wireless networks\nand networks that span large areas, such as the Internet, fall into this category.\nBayou essentially distinguishes four different consistency models. To ex-\nplain these models, we again consider a data store that is physically distributed\nacross multiple machines. When a process accesses the data store, it generally\nconnects to the locally (or nearest) available copy, although, in principle, any\ncopy will do just fine. All read and write operations are performed on that\nlocal copy. Updates are eventually propagated to the other copies.\nClient-centric consistency models are described using the following no-\ntations. Let xi denote the version of data item x. The version xi is the result\nof a series of write operations that took place since initialization, its write\nset WS(xi). By appending write operations to thatseries, series we obtain\nanother version xj and say that xj follows from xi. We use the notation W(xi; xj)\nDS 4.01\n \n",
      "content_length": 3199,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 433,
      "content": "7.3. CLIENT-CENTRIC CONSISTENCY MODELS\n417\nto indicate that xj follows from xi. If we do not know if xj follows from xi, we\nuse the notation W(xi|xj).\n7.3.1\nMonotonic reads\nThe first client-centric consistency model is that of monotonic reads.\nA\n(distributed) data store is said to provide monotonic-read consistency if the\nfollowing condition holds:\nIf a process reads the value of a data item x, any successive read operation\non x by that process will always return that same value or a more recent\nvalue.\nIn other words, monotonic-read consistency guarantees that once a process\nhas seen a value of x, it will never see an older version of x.\nAs an example where monotonic reads are useful, consider a distributed\ne-mail database. In such a database, each user’s mailbox may be distributed\nand replicated across multiple machines. Mail can be inserted in a mailbox\nat any location. However, updates are propagated in a lazy (i.e., on demand)\nfashion. Only when a copy needs certain data for consistency are those data\npropagated to that copy. Suppose a user reads her mail in San Francisco.\nAssume that only reading mail does not affect the mailbox, that is, messages\nare not removed, stored in subdirectories, or even tagged as having already\nbeen read, and so on. When the user later flies to New York and opens her\nmailbox again, monotonic-read consistency guarantees that the messages that\nwere in the mailbox in San Francisco will also be in the mailbox when it is\nopened in New York.\nUsing a notation similar to that for data-centric consistency models,\nmonotonic-read consistency can be graphically represented as shown in Fig-\nure 7.18. Rather than showing processes along the vertical axis, we now show\nlocal data stores, in our example L1 and L2. A write or read operation is in-\ndexed by the process that executed the operation, that is, W1(x)a denotes that\nprocess P1 wrote value a to x. As we are not interested in specific values\nof shared data items, but rather their versions, we use the notation W1(x2)\nto indicate that process P1 produces version x2 without knowing anything\nabout other versions. W2(x1; x2) indicates that process P2 is responsible for\nproducing version x2 that follows from x1. Likewise, W2(x1|x2) denotes that\nprocess P2 producing version x2 concurrently to version x1 (and thus poten-\ntially introducing a write-write conflict). R1(x2) simply means that P1 reads\nversion x2.\nIn Figure 7.18(a) process P1 first performs a write operation on x at L1,\nproducing version x1 and later reads this version. At L2 process P2 first\nproduces version x2, following from x1. When process P1 moves to L2 and\nreads x again, it finds a more recent value, but one that at least took its\nprevious write into account.\n \nDS 4.01\n",
      "content_length": 2751,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 434,
      "content": "418\nCHAPTER 7. CONSISTENCY AND REPLICATION\n(a)\n(b)\nFigure 7.18: The read operations performed by a single process P at two\ndifferent local copies of the same data store. (a) A monotonic-read consistent\ndata store. (b) A data store that does not provide monotonic reads.\nFigure 7.18(b) shows a situation in which monotonic-read consistency is\nviolated. After process P1 has read x1 at L1, it later performs the operation\nR1(x2) at L2. However, the preceding write operation W2(x1|x2) by process\nP2 at L2 is known to produce a version that does not follow from x1. As a\nconsequence, P1’s read operation at L2 is known not to include the effect of\nthe write operations when it performed R1(x1) at location L1.\n7.3.2\nMonotonic writes\nIn many situations, it is important that write operations are propagated in\nthe correct order to all copies of the data store. This property is expressed\nin monotonic-write consistency. In a monotonic-write consistent store, the\nfollowing condition holds:\nA write operation by a process on a data item x is completed before any\nsuccessive write operation on x by the same process.\nMore formally, if we have two successive operations Wk(xi) and Wk(xj) by\nprocess Pk, then, regardless where Wk(xj) takes place, we also have Wk(xi; xj).\nThus, completing a write operation means that the copy on which a successive\noperation is performed reflects the effect of a previous write operation by\nthe same process, no matter where that operation was initiated. In other\nwords, a write operation on a copy of item x is performed only if that copy\nhas been brought up to date through any preceding write operation by that\nsame process, which may have taken place on other copies of x. If need be,\nthe new write must wait for old ones to finish.\nNote that monotonic-write consistency resembles data-centric FIFO consis-\ntency. The essence of FIFO consistency is that write operations by the same\nprocess are performed in the correct order everywhere. This ordering con-\nstraint also applies to monotonic writes, except that we are now considering\nconsistency only for a single process, instead of for a collection of processes.\nBringing a copy of x up to date need not be necessary when each write\noperation completely overwrites the present value of x. However, write opera-\ntions are often performed on only part of the state of a data item. Consider, for\nDS 4.01\n \n",
      "content_length": 2385,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 435,
      "content": "7.3. CLIENT-CENTRIC CONSISTENCY MODELS\n419\nexample, a software library. Often, updating such a library is done by replac-\ning one or more functions, leading to a next version. With monotonic-write\nconsistency, guarantees are given that if an update is performed on a copy of\nthe library, all preceding updates will be performed first. The resulting library\nwill then indeed become the most recent version and will include all updates\nthat have led to previous versions of the library.\nMonotonic-write consistency is shown in Figure 7.19. In Figure 7.19(a)\nprocess P1 performs a write operation on x at L1, presented as the operation\nW1(x1). Later, P1 performs another write operation on x, but this time at\nL2, shown as W1(x2; x3). The version produced by P1 at L2 follows from an\nupdate by process P2, in turn based on version x1. The latter is expressed\nby the operation W2(x1; x2). To ensure monotonic-write consistency, it is\nnecessary that the previous write operation at L1 has already been propagated\nto L2, and possibly updated.\n(a)\n(b)\n(c)\n(d)\nFigure 7.19: The write operations performed at two different local copies\nof the same data store. (a) A monotonic-write consistent data store. (b) A\ndata store that does not provide monotonic-write consistency. (c) Again, no\nconsistency as W2(x1|x2) and thus also W1(x1|x3). (d) Consistent as W1(x1; x3)\nalthough x1 has apparently overwritten x2.\nIn contrast, Figure 7.19(b) shows a situation in which monotonic-write\nconsistency is not guaranteed. Compared to Figure 7.19(a), what is missing is\nthe propagation of x1 to L2 before another version of x is produced, expressed\nby the operation W2(x1|x2). In this case, process P2 produced a concurrent\nversion to x1, after which process P1 simply produces version x3, but again\nconcurrently to x1. Only slightly more subtle, but still violating monotonic-\nwrite consistency, is the situation sketched in Figure 7.19(c). Process P1 now\nproduces version x3 which follows from x2. However, because x2 does not\nincorporate the write operations that led to x1, that is, W2(x1|x2), we also have\nW1(x1|x3).\nAn interesting case is shown in Figure 7.19(d). The operation W2(x1|x2)\nproduces version x2 concurrently to x1. However, later, process P1 produces\nversion x3, but apparently based on the fact that version x1 had become\n \nDS 4.01\n",
      "content_length": 2331,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 436,
      "content": "420\nCHAPTER 7. CONSISTENCY AND REPLICATION\navailable at L2. How and when x1 was transferred to L2 is left unspecified,\nbut in any case a write-write conflict was created with version x2 and resolved\nin favor of x1. A consequence is that the situation shown in Figure 7.19(d)\nfollows the rules for monotonic-write consistency. Note, however, that any\nsubsequent write by process P2 at L2 (without having read version x1) will\nimmediately violate consistency again. How such a violation can be prevented\nis left as an exercise to the reader.\nNote that, by the definition of monotonic-write consistency, write opera-\ntions by the same process are performed in the same order as they are initiated.\nA somewhat weaker form of monotonic writes is one in which the effects of a\nwrite operation are seen only if all preceding writes have been carried out as\nwell, but perhaps not in the order in which they have been originally initiated.\nThis consistency is applicable in those cases in which write operations are\ncommutative, so that ordering is really not necessary. Details are found in\n[Terry et al., 1994].\n7.3.3\nRead your writes\nA data store is said to provide read-your-writes consistency, if the following\ncondition holds:\nThe effect of a write operation by a process on data item x will always be\nseen by a successive read operation on x by the same process.\nIn other words, a write operation is always completed before a successive\nread operation by the same process, no matter the location where that read\noperation takes place.\nThe absence of read-your-writes consistency is sometimes experienced\nwhen updating Web documents and subsequently viewing the effects. Update\noperations frequently take place through a standard editor or word processor,\nperhaps embedded as part of a content management system, which then saves\nthe new version on a file system that is shared by the Web server. The user’s\nWeb browser accesses that same file, possibly after requesting it from the\nlocal Web server. However, once the file has been fetched, either the server or\nthe browser often caches a local copy for subsequent accesses. Consequently,\nwhen the Web page is updated, the user will not see the effects if the browser\nor the server returns the cached copy instead of the original file. Read-your-\nwrites consistency can guarantee that if the editor and browser are integrated\ninto a single program, the cache is invalidated when the page is updated, so\nthat the updated file is fetched and displayed.\nSimilar effects occur when updating passwords. For example, to enter a\ndigital library on the Web, it is often necessary to have an account with an\naccompanying password. However, changing a password may take some time\nto come into effect, with the result that the library may be inaccessible to the\nuser for a few minutes. The delay can be caused because a separate server\nDS 4.01\n \n",
      "content_length": 2883,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 437,
      "content": "7.3. CLIENT-CENTRIC CONSISTENCY MODELS\n421\nis used to manage passwords, and it may take some time to subsequently\npropagate (encrypted) passwords to the various servers that constitute the\nlibrary.\nFigure 7.20(a) shows a data store that provides read-your-writes consis-\ntency. Note that Figure 7.20(a) is very similar to Figure 7.18(a), except that\nconsistency is now determined by the last write operation by process P1,\ninstead of its last read.\n(a)\n(b)\nFigure 7.20: (a) A data store that provides read-your-writes consistency. (b) A\ndata store that does not.\nIn Figure 7.20(a) process P1 performed a write operation W1(x1) and\nlater a read operation at a different local copy. Read-your-writes consistency\nguarantees that the effects of the write operation can be seen by the succeeding\nread operation. This is expressed by W2(x1; x2), which states that a process P2\nproduced a new version of x, yet one based on x1. In contrast, in Figure 7.20(b)\nprocess P2 produces a version concurrently to x1, expressed as W2(x1|x2).\nThis means that the effects of the previous write operation by process P1 have\nnot been propagated to L2 at the time x2 was produced. When P1 reads x2, it\nwill not see the effects of its own write operation at L1.\n7.3.4\nWrites follow reads\nThe last client-centric consistency model is one in which updates are propa-\ngated as the result of previous read operations. A data store is said to provide\nwrites-follow-reads consistency, if the following holds.\nA write operation by a process on a data item x following a previous read\noperation on x by the same process is guaranteed to take place on the same\nor a more recent value of x that was read.\nIn other words, any successive write operation by a process on a data item\nx will be performed on a copy of x that is up to date with the value most\nrecently read by that process.\nWrites-follow-reads consistency can be used to guarantee that users of a\nnetwork newsgroup see a posting of a reaction to an article only after they\nhave seen the original article [Terry et al., 1994]. To understand the problem,\nassume that a user first reads an article A. Then, she reacts by posting a\nresponse B. By requiring writes-follow-reads consistency, B will be written\nto any copy of the newsgroup only after A has been written as well. Note\n \nDS 4.01\n",
      "content_length": 2316,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 438,
      "content": "422\nCHAPTER 7. CONSISTENCY AND REPLICATION\nthat users who only read articles need not require any specific client-centric\nconsistency model. The writes-follows-reads consistency assures that reactions\nto articles are stored at a local copy only if the original is stored there as well.\n(a)\n(b)\nFigure 7.21: (a) A writes-follow-reads consistent data store. (b) A data store\nthat does not provide writes-follow-reads consistency.\nThis consistency model is shown in Figure 7.21. In Figure 7.21(a), process\nP2 reads version x1 at local copy L1. This version of x was previously pro-\nduced at L1 by process P1 through the operation W1(x1). That version was\nsubsequently propagated to L2, and used by another process P3 to produce a\nnew version x2, expressed as W3(x1; x2). When process P2 later updates its\nversion of x after moving to L2, it is known that it will operate on a version that\nfollows from x1, expressed as W2(x2; x3). Because we also have W3(x1; x2), we\nknown that W1(x1; x3).\nThe situation shown in Figure 7.21(b) is different. Process P3 produces a\nversion x2 concurrently to that of x1. As a consequence, when P2 updates x\nafter reading x1, it will be updating a version it had not read before. Writes-\nfollow-reads consistency is then violated.\n7.3.5\nExample: client-centric consistency in ZooKeeper\nAn interesting example in which we see elements of data-centric and client-\ncentric consistency combined, is the model provided by ZooKeeper [Hunt\net al., 2010]. First, ZooKeeper guarantees that update operations are serializ-\nable and keep precedence. What this means, is that the state of ZooKeeper can\nalways be explained by some linear ordering in the execution of all submitted\nupdate operations, while preserving monotonic writes. In other words, while\nmultiple clients can concurrently update ZooKeeper’s state, the final result\ncan be understood by some interleaving of those updates while the ordering\nof operations as submitted per client is preserved. In addition, ZooKeeper\nguarantees monotonic reads. It does not, however, guarantee read-your-writes\nor writes-follow-read consistency.\nA simple perspective is to consider ZooKeeper as a collection of servers,\nwhile each client is connected to its own specific server. There is one, fixed\nprimary server to which all write operations are forwarded, and processed\nin the order as submitted by their respective clients. Read operations are\nexecuted by the server to which the client is connected (and in the order as\nsubmitted by that client). Nothing, however, is said about when the primary\nDS 4.01\n \n",
      "content_length": 2577,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 439,
      "content": "7.4. REPLICA MANAGEMENT\n423\nFigure 7.22: The consistency model of ZooKeeper explained through a naive\nimplementation.\nserver brings the other servers up to date. In other words, a client is left in\nthe dark concerning when it will see its own updates, or concurrent updates\nfrom other clients. This model is sketched in Figure 7.22.\nAssume that P1 first submits the operation W(x)a and then W(x)b. Process\nP2 submits the operation W(x)c. What is important is that monotonic writes\nare supported. In our example, the primary server receives the three write\noperations and decides to forward the operations W(x)a, W(x)c, and W(x)b\nin that order to the other stores. We have not specified when these operations\nare submitted or actually performed. Important is that this order needs to be\nobeyed.\nIf P1 submits read requests R(x), it may first read the initial value NIL,\nand then subsequently R(x)a and later R(x)c (and eventually, it will be able to\nread only R(x)b). Likewise, P2 may initially read NIL and later the final value\nR(x)b. Note that both P1 and P2 may read NIL even after having submitted\ntheir respective write operations. This demonstrates that ZooKeeper does\nnot provide read-your-writes consistency. Also, even if P1 had first read\nNIL and then submitted W(x)a; W(x)b, it may still read R(x)c if its latest\nwrite operation (R(x)b) had not yet been processed. This demonstrates that\nZooKeeper also does not provide writes-follow-reads consistency.\n7.4\nReplica management\nA key issue for any distributed system that supports replication is to decide\nwhere and when replicas should be placed, and subsequently which mech-\nanisms to use for keeping the replicas consistent. The placement problem\nitself should be split into two subproblems: that of placing replica servers, and\nthat of placing content. The difference is subtle and the two issues are often\nnot clearly separated. Replica-server placement is concerned with finding the\nbest locations to place a server that can host (part of) a data store. Content\n \nDS 4.01\n",
      "content_length": 2037,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 440,
      "content": "424\nCHAPTER 7. CONSISTENCY AND REPLICATION\nplacement deals with finding the best servers for placing content. Note that\nthis often means that we are looking for the optimal placement of only a single\ndata item. Obviously, before content placement can take place, replica servers\nwill have to be placed first.\n7.4.1\nFinding the best server location\nWhere perhaps over a decade ago one could be concerned about where to\nplace an individual server, matters have changed considerably with the advent\nof the many large-scale data centers located across the Internet. Likewise, con-\nnectivity continues to improve, making precisely locating servers less critical.\nThere are various ways to compute the best placement of replica servers,\nbut virtually all boil down to an optimization problem in which the best K\nout of N locations need to be selected (K < N). These problems are known\nto be computationally complex and can be solved only through heuristics.\nImportant in this respect is to decide on the criteria to even judge on a “best”\nsolution. In an extensive overview, Sahoo et al. [2017] distinguish cost-related\ncriteria and network-related criteria. Typical network-related criteria are\nlatencies between a server and its clients, the available bandwidth, the (logical)\ndistance as discussed in Section 5.7.3, and hop count. Of course, combinations\nare possible as well.\nBy now, there are many (often theoretical) models for deciding on the\nplacement of replica servers. Sahoo et al. [2017] classify these models as shown\nin Figure 7.23.\nMain class\nSubclass\nQoS Aware\nOptimized QoS\nBounded QoS\nConsistency Aware\nPeriodic update\nAperiodic update\nExpiration-based update\nCache-based update\nEnergy\nOthers\nFigure 7.23: Taxonomy of replica-placement algorithms (adapted from [Sahoo\net al., 2017]).\nLet us take a closer look at these different classes. When considering\nQuality of Service, that is QoS, server placement is decided by optimizing\nfor some or more QoS parameters. QoS is generally expressed in terms of\none or more of the network-related parameters. In the case of bounded QoS,\nsolutions are sought that guarantee a value of a certain QoS parameter, for\nexample, guaranteed bandwidth.\nDS 4.01\n \n",
      "content_length": 2206,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 441,
      "content": "7.4. REPLICA MANAGEMENT\n425\nAs mentioned, QoS awareness requires solving a computationally difficult\nproblem, meaning in practice that we need to resort to heuristics, and thus\napproximations of optimal values. This is generally not a problem, considering\nthat the QoS parameters itself may be rather imprecise. Consider, for example,\naccurately measuring latency between a client (end user) and a replica server.\nAs discussed in Section 5.7.3, this is by itself not an easy problem to solve\nwhen we cannot simply access that client. The best one can hope for, is\nthat an existing server is often enough connected to a client to get some idea\nof latencies. The same problem occurs for other parameters, in particular,\nbandwidth. As a consequence, we can try to accurately optimize on QoS, but\nwhen the basic input values are already very difficult to measure accurately,\noptimizations can quickly become quite theoretical. Quick-and-dirty heuristics\nmay be enough, yet we will need to take their results with a grain of salt.\nConsistency-aware algorithms take an entirely different approach. The\nbasic assumption is that there is an existing network for which we can decide\nwhere to place replica servers. Placement of servers will then involve costs\nfor keeping replicated content up to date. Those costs can be expressed in\nterms of when updates take place, as well as how. We return to these matters\nlater in Section 7.4.3 where we discuss replica management. The four different\nsubclasses deal with deciding on when updates are propagated to the replica\nserver (periodically, instantly, or only after some time), or from where (is a\nreplica server going to check the main server, or is it going to see whether a\nnearby server has an update). Again, we see that many theoretical models\nhave been developed to optimize consistency-aware algorithms, yet in this\ncase, such optimizations rely heavily on knowledge concerning read and\nupdate patterns. In practice, such knowledge is not readily available and may\neven be hard to get, let alone when it comes to predicting future patterns.\nEnergy-aware algorithms also assume an existing network to which clients\nconnect.\nPlacement of a replica server is then decided based on energy\nconsumption. To keep it simple, placing a server at a specific node and\nkeeping it up and running when there are only few clients, may be costly\nin terms of energy. The server in that case does not have enough work\nto do, while its idle time does consume energy.\nAnother criterion is to\ndecide on placement at nodes that support energy efficiency, for example,\nby switching between different power modes. Finally, placement may also\nbe influenced by optimizing the distribution of work (measured in terms of\nenergy consumption) among more or less replica servers, given that we know\nthe various access patterns of a set of clients. As before, we see that much\nneeds to be known about those patterns, as well as the capacities and facilities\nof the network, to make practically sensible decisions.\nFinally, there are other classes for deciding on replica-server placement.\nSahoo et al. have concentrated on server placement for CDNs. Such dis-\ntributed systems are spread across many organizations (formally known as\n \nDS 4.01\n",
      "content_length": 3258,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 442,
      "content": "426\nCHAPTER 7. CONSISTENCY AND REPLICATION\nAutonomous Systems, that is, an organization in charge of a separate network\nwithin the Internet). Replica-server placement then also involves monetary\ncosts that need to be negotiated with those organizations. Likewise, placement\ndecisions can be based on the connectivity of clients to a specific autonomous\nsystem, along with the costs in terms of QoS parameters or monetary costs.\nFurther details can be found in [Sahoo et al., 2017].\n7.4.2\nContent replication and placement\nWhen it comes to content replication and placement, three different types of\nreplicas can be distinguished, logically organized as shown in Figure 7.24.\nPermanent\nreplicas\nServer-initiated replicas\nClient-initiated replicas\nClients\nClient-initiated replication\nServer-initiated replication\nFigure 7.24: The logical organization of different kinds of copies of a data\nstore into three concentric rings.\nPermanent replicas\nPermanent replicas can be considered as the initial set of replicas that con-\nstitute a distributed data store. Often, the number of permanent replicas is\nsmall. Consider, for example, a Website. Distribution of a Website generally\ncomes in one of two forms. The first kind of distribution is one in which the\nfiles that constitute a site are replicated across a limited number of servers at\na single location. Whenever a request comes in, it is forwarded to one of the\nservers, for instance, using a round-robin strategy.\nThe second form of distributed Websites is what is called mirroring. In\nthis case, a Website is copied to a limited number of servers, called mirror\nsites, which are geographically spread across the Internet. Often, clients\nsimply choose one of the various mirror sites from a list offered to them, or\nare transparently forwarded to one of the mirrors. Mirrored Websites have in\ncommon with cluster-based Websites that there are only a few replicas, which\nare more or less statically configured.\nSimilar static organizations also appear with distributed databases [Kemme\net al., 2010; Özsu and Valduriez, 2020]. Again, the database can be distributed\nDS 4.01\n \n",
      "content_length": 2127,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 443,
      "content": "7.4. REPLICA MANAGEMENT\n427\nand replicated across a number of servers that together form a cluster of\nservers, often referred to as a shared-nothing architecture, emphasizing that\nneither disks nor main memory are shared by processors. Alternatively, a\ndatabase is distributed and possibly replicated across a number of geograph-\nically dispersed sites. This architecture is generally deployed in federated\ndatabases [Sheth and Larson, 1990; Azevedo et al., 2020].\nServer-initiated replicas\nIn contrast to permanent replicas, server-initiated replicas are copies of a\ndata store that exist to enhance performance, and created at the initiative of\nthe (owner of the) data store. Consider, for example, a Web server placed in\nNew York. Normally, this server can handle incoming requests effortlessly,\nbut it may happen that over a couple of days a sudden burst of requests\ncome in from an unexpected location far from the server. In that case, it may\nbe worthwhile to install a number of temporary replicas in regions where\nrequests are coming from.\nWeb hosting has often been taken over by Content Delivery Networks, and\nfor good reasons. Most important is that Web pages are no longer just a simple\ncollection of static pages, but combine databases with static and dynamic\ncontent. As a result, replication needs to be much more sophisticated than\njust pushing pages to specific locations. We outlined the principal operation\nof a CDN in Section 3.4.4. Important is that, in general, replication is on\ndemand. The CDN notices that requests are coming from a client, the client is\ndirected to a nearest replica server, and that server checks to see whether it\nhas the requested content cached locally. Obviously, there are many options\nconcerning decisions on where to redirect the client to, and also when and\nwhich content to actually store. For our discussion here, despite that content\nis replicated to a server because of a client request, because the CDN is in\ncontrol when it comes to the aforementioned decisions, it is still appropriate\nto speak of server-initiated replication. That the initiative has been delegated\nto a CDN is less important.\nNote 7.6 (More information: An example of dynamic Web-content placement)\nThe problem of dynamically placing replicas has since long been addressed in\nWeb hosting services (and by now in content delivery networks). Historically,\nthese services offered an often relatively static collection of servers spread across\nthe Internet that maintained and provided access to Web files belonging to third\nparties. To provide optimal facilities, such hosting services dynamically replicated\nfiles to servers where those files are needed to enhance performance, that is, close\nto demanding (groups of) clients.\nGiven that the replica servers are already in place, deciding where to place\ncontent is not that difficult. An early case toward dynamic replication of files in\nthe case of a Web hosting service is described by Rabinovich et al. [1999]. The\n \nDS 4.01\n",
      "content_length": 3004,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 444,
      "content": "428\nCHAPTER 7. CONSISTENCY AND REPLICATION\nalgorithm is designed to support Web pages, for which reason it assumes that\nupdates are relatively rare compared to read requests. Using files as the unit of\ndata, the algorithm works as follows.\nThe algorithm for dynamic replication takes two issues into account. First,\nreplication can take place to reduce the load on a server. Second, specific files\non a server can be migrated or replicated to servers placed in the proximity of\nclients that issue many requests for those files. In the following, we concentrate\nonly on this second issue. We also omit a number of details, which can be found\nin [Rabinovich et al., 1999].\nFigure 7.25: Counting access requests from different clients.\nEach server keeps track of access counts per file, and where access requests\ncome from. In particular, when a client C enters the service, it does so through\na server close to it. If client C1 and client C2 share the same closest server P, all\naccess requests for file F at server Q from C1 and C2 are jointly registered at Q as\na single access count cntQ(P, F). This situation is shown in Figure 7.25.\nWhen the number of requests for a specific file F at server S drops below a\ndeletion threshold del(S, F), that file can be removed from S. As a consequence,\nthe number of replicas of that file is reduced, possibly leading to higher work\nloads at other servers. Special measures are taken to ensure that at least one copy\nof each file continues to exist.\nA replication threshold rep(S, F), which is always chosen higher than the\ndeletion threshold, indicates that the number of requests for a specific file is so\nhigh that it may be worthwhile replicating it on another server. If the number of\nrequests lies somewhere between the deletion and replication threshold, the file\nis allowed to be only migrated. In other words, in that case, it is important to at\nleast keep the number of replicas for that file the same.\nWhen a server Q decides to reevaluate the placement of the files it stores, it\nchecks the access count for each file. If the total number of access requests for F\nat Q drops below the deletion threshold del(Q, F), it will delete F unless it is the\nlast copy. Furthermore, if for some server P, cntQ(P, F) exceeds more than half of\nthe total requests for F at Q, server P is requested to take over the copy of F. In\nother words, server Q will attempt to migrate F to P.\nMigration of file F to server P may not always succeed, for example because P\nis already heavily loaded or is out of disk space. In that case, Q will attempt to\nDS 4.01\n \n",
      "content_length": 2593,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 445,
      "content": "7.4. REPLICA MANAGEMENT\n429\nreplicate F on other servers. Of course, replication can take place only if the total\nnumber of access requests for F at Q exceeds the replication threshold rep(Q, F).\nServer Q checks all other servers in the Web hosting service, starting with the one\nfarthest away. If, for some server R, cntQ(R, F) exceeds a certain fraction of all\nrequests for F at Q, an attempt is made to replicate F to R.\nWhat we have just described is an alternative to simply caching content at a\nreplica server when a client request comes in, as we described for content delivery\nnetworks. There is no fundamental reason why the algorithm for copying and\nmigration of content cannot be applied in CDNs as well.\nClient-initiated replicas\nAn important kind of replica is the one initiated by a client. Client-initiated\nreplicas are more commonly known as client caches. In essence, a cache is a\nlocal storage facility that is used by a client to temporarily store a copy of the\ndata it has just requested. In principle, managing the cache is left entirely to\nthe client. The data store from where the data had been fetched has nothing to\ndo with keeping cached data consistent. However, there are many occasions\nin which the client can rely on participation from the data store to inform it\nwhen cached data has become stale.\nClient caches are used only to improve access times to data. Normally,\nwhen a client wants access to some data, it connects to the nearest copy of the\ndata store from where it fetches the data it wants to read, or to where it stores\nthe data it had just modified. When most operations involve only reading\ndata, performance can be improved by letting the client store requested data\nin a nearby cache. Such a cache could be located on the client’s machine, or\non a separate machine in the same local-area network as the client. The next\ntime that same data needs to be read, the client can simply fetch it from this\nlocal cache. This scheme works fine as long as the fetched data have not been\nmeanwhile modified.\nData are generally kept in a cache for a limited amount of time, for example,\nto prevent extremely stale data from being used, or simply to make room\nfor other data. Whenever requested data can be fetched from the local cache,\na cache hit is said to have occurred. To improve the number of cache hits,\ncaches can be shared between clients. The underlying assumption is that a\ndata request from client C1 may also be useful for a request from another\nnearby client C2.\nWhether this assumption is correct depends very much on the type of data\nstore. For example, in traditional file systems, data files are rarely shared at all\n(see, e.g., Muntz and Honeyman [1992] and Blaze [1993]) rendering a shared\ncache useless. Likewise, it turns out that using Web caches to share data\nhas been losing ground, partly also because of the improvement in network\n \nDS 4.01\n",
      "content_length": 2902,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 446,
      "content": "430\nCHAPTER 7. CONSISTENCY AND REPLICATION\nand server performance. Instead, server-initiated replication schemes are\nbecoming more effective.\nPlacement of client caches is relatively simple: a cache is normally placed\non the same machine as its client, or otherwise on a machine shared by clients\non the same local-area network. However, in some cases, extra levels of\ncaching are introduced by system administrators by placing a shared cache\nbetween a number of departments or organizations, or even placing a shared\ncache for an entire region such as a province or country.\nYet another approach is to place (cache) servers at specific points in a\nwide-area network and let a client locate the nearest server. When the server is\nlocated, it can be requested to hold copies of the data the client was previously\nfetching from somewhere else [Noble et al., 1999].\n7.4.3\nContent distribution\nReplica management also deals with propagation of (updated) content to the\nrelevant replica servers. There are various trade-offs to make.\nState versus operations\nAn important design issue concerns what is actually to be propagated. Basi-\ncally, there are three possibilities:\n• Propagate only a notification of an update.\n• Transfer data from one copy to another.\n• Propagate the update operation to other copies.\nPropagating a notification is what invalidation protocols do. In an invali-\ndation protocol, other copies are informed that an update has taken place\nand that the data they contain are no longer valid. The invalidation may\nspecify which part of the data store has been updated, so that only part of\na copy is actually invalidated. The important issue is that no more than a\nnotification is propagated. Whenever an operation on an invalidated copy is\nrequested, that copy generally needs to be updated first, depending on the\nspecific consistency model that is to be supported.\nThe main advantage of invalidation protocols is that they use little network\nbandwidth. The only information that needs to be transferred is a specification\nof which data are no longer valid. Such protocols generally work best when\nthere are many update operations compared to read operations, that is, the\nread-to-write ratio is relatively small.\nConsider, for example, a data store in which updates are propagated by\nsending the modified data to all replicas. If the size of the modified data is\nlarge, and updates occur frequently compared to read operations, we may\nhave the situation that two updates occur after one another without any read\nDS 4.01\n \n",
      "content_length": 2539,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 447,
      "content": "7.4. REPLICA MANAGEMENT\n431\noperation being performed between them. Consequently, propagation of the\nfirst update to all replicas is effectively useless, as it will be overwritten by\nthe second update. Instead, sending a notification that the data have been\nmodified would have been more efficient.\nTransferring the modified data among replicas is the second alternative,\nand is useful when the read-to-write ratio is relatively high. In that case, the\nprobability that an update will be effective in the sense that the modified data\nwill be read before the next update takes place is high. Instead of propagating\nmodified data, it is also possible to log the changes and transfer only those\nlogs to save bandwidth. In addition, transfers are often aggregated in the\nsense that multiple modifications are packed into a single message, thus\nsaving communication overhead.\nThe third approach is not to transfer any data modifications at all, but\nto tell each replica which update operation it should perform (and sending\nonly the parameter values that those operations need). This approach, also\nreferred to as active replication, assumes that each replica is represented\nby a process capable of “actively” keeping its associated data up to date by\nperforming operations [Schneider, 1990]. The main benefit of active replication\nis that updates can often be propagated at minimal bandwidth costs, provided\nthe size of the parameters associated with an operation are relatively small.\nMoreover, the operations can be of arbitrary complexity, which may allow\nfurther improvements in keeping replicas consistent. On the other hand, more\nprocessing power may be required by each replica, especially in those cases\nwhen operations are relatively complex.\nPull versus push protocols\nAnother design issue is whether updates are pulled or pushed. In a push-\nbased approach, also referred to as server-based protocols, updates are\npropagated to other replicas without those replicas even asking for the updates.\nPush-based approaches are often used between permanent and server-initiated\nreplicas, but can also be used to push updates to client caches. Server-based\nprotocols are generally applied when strong consistency is required.\nThis need for strong consistency is related to the fact that permanent and\nserver-initiated replicas, as well as large shared caches, are often shared by\nmany clients, which, in turn, mainly perform read operations. Consequently,\nthe read-to-update ratio at each replica is relatively high. In these cases, push-\nbased protocols are efficient in the sense that every pushed update can be\nexpected to be of use for at least one, but perhaps more readers. In addition,\npush-based protocols make consistent data immediately available when asked\nfor.\nIn contrast, in a pull-based approach, a server or client requests another\nserver to send it any updates it has at that moment. Pull-based protocols, also\ncalled client-based protocols, are often used by client caches. For example, a\n \nDS 4.01\n",
      "content_length": 3015,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 448,
      "content": "432\nCHAPTER 7. CONSISTENCY AND REPLICATION\ncommon strategy applied to Web caches is first to check whether cached data\nitems are still up-to-date. When a cache receives a request for items that are\nstill locally available, the cache checks with the original Web server, whether\nthose data items have been modified since they were cached. In the case of\na modification, the modified data are first transferred to the cache, and then\nreturned to the requesting client. If no modifications took place, the cached\ndata are returned. In other words, the client polls the server to see whether\nan update is needed. A similar approach is followed in content delivery\nnetworks where a replica server caches content, yet checks with the origin\nserver whether updates are available before delivering its (cached) content to\nthe actual client (i.e., end user). Note that in this respect, the replica server\nacts as a client to the origin server.\nA pull-based approach is efficient when the read-to-update ratio is rela-\ntively low. This is often the case with (nonshared) client caches, which have\nonly one client. However, even when a cache is shared by many clients, a\npull-based approach may also be efficient when the cached data items are\nrarely shared. The main drawback of a pull-based strategy in comparison to a\npush-based approach is that the response time increases in the case of a cache\nmiss.\nWhen comparing push-based and pull-based solutions, there are a number\nof trade-offs to be made, as shown in Figure 7.26. For simplicity, consider a\nclient-server system consisting of a single, nondistributed server, and a number\nof client processes, each having their own cache. We make no distinction\nbetween clients at end users (such as Web browsers), or clients within, for\nexample, a content delivery network (such as replica servers).\nIssue\nPush-based\nPull-based\nState at server\nList of client replicas and caches\nNone\nMessages sent\nUpdate (and possibly fetch update\nlater)\nPoll and update\nResponse time\nat client\nImmediate (or fetch-update time)\nFetch-update\ntime\nFigure 7.26: A comparison between push-based and pull-based protocols in\nthe case of multiple-client, single-server systems.\nAn important issue is that in push-based protocols, the server needs to\nkeep track of all client caches, be they at end users or replica servers. Apart\nfrom the fact that stateful servers are often less fault tolerant, keeping track\nof all such caches may introduce a considerable overhead at the server. For\nexample, in a push-based approach, a Web server may easily need to keep\ntrack of tens of thousands of client caches. Each time a Web page is updated,\nthe server will have to go through its list of client caches holding a copy of that\npage and subsequently propagate the update. Worse yet, if a client purges a\nDS 4.01\n \n",
      "content_length": 2821,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 449,
      "content": "7.4. REPLICA MANAGEMENT\n433\npage due to lack of space, it has to inform the server, leading to even more\ncommunication.\nThe messages that need to be sent between a client and the server also\ndiffer. In a push-based approach, the only communication is that the server\nsends updates to each client. When updates are only invalidations, additional\ncommunication is needed by a client to fetch the modified data. In a pull-\nbased approach, a client will have to poll the server, and, if necessary, fetch\nthe modified data.\nFinally, the response time at the client is also different. When a server\npushes modified data to the client caches, it is clear that the response time at\nthe client side is zero. When invalidations are pushed, the response time is\nthe same as in the pull-based approach, and is determined by the time it takes\nto fetch the modified data from the server.\nThese trade-offs have lead to a hybrid form of update propagation based\non leases. In the case of replica management, a lease is a promise by the\nserver that it will push updates to the client for a specified time. When a\nlease expires, the client is forced to poll the server for updates and pull in the\nmodified data if necessary. An alternative is that a client requests a new lease\nfor pushing updates when the previous lease expires.\nLeases, originally introduced by Gray and Cheriton [1989], provide a\nconvenient mechanism for dynamically switching between a push-based\nand pull-based strategy. Consider the following lease system that allows\nthe expiration time to be dynamically adapted depending on different lease\ncriteria, described in [Duvvuri et al., 2003]. We distinguish the following three\ntypes of leases. (Note that in all cases, updates are pushed by the server as\nlong as the lease has not expired.)\nFirst, age-based leases are given out on data items depending on the last\ntime the item was modified. The underlying assumption is that data that\nhave not been modified for a long time can be expected to remain unmodified\nfor some time yet to come. This assumption has shown to be reasonable\nin the case of, for example, Web-based data and regular files. By granting\nlong-lasting leases to data items that are expected to remain unmodified, the\nnumber of update messages can be strongly reduced compared to the case\nwhere all leases have the same expiration time.\nAnother lease criterion is how often a specific client requests its cached\ncopy to be updated. With renewal-frequency-based leases, a server will hand\nout a long-lasting lease to a client whose cache often needs to be refreshed.\nOn the other hand, a client that asks only occasionally for a specific data item\nwill be handed a short-term lease for that item. The effect of this strategy is\nthat the server essentially keeps track only of those clients where its data are\npopular; moreover, those clients are offered a high degree of consistency.\nThe last criterion is that of state-space overhead at the server. When\nthe server realizes that it is gradually becoming overloaded, it lowers the\n \nDS 4.01\n",
      "content_length": 3061,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 450,
      "content": "434\nCHAPTER 7. CONSISTENCY AND REPLICATION\nexpiration time of new leases it hands out to clients. The effect of this state-\nbased lease strategy is that the server needs to keep track of fewer clients as\nleases expire more quickly. In other words, the server dynamically switches\nto a more stateless mode of operation, thereby expecting to offload itself so\nthat it can handle requests more efficiently. The obvious drawback is that it\nmay need to do more work when the read-to-update ratio is high.\nUnicasting versus multicasting\nRelated to pushing or pulling updates is deciding whether unicasting or\nmulticasting should be used. In unicast communication, when a server that is\npart of the data store sends its update to N other servers, it does so by sending\nN separate messages, one to each server. With multicasting, the underlying\nnetwork takes care of sending a message efficiently to multiple receivers.\nOften, it is cheaper to use available multicasting facilities. An extreme\nsituation is when all replicas are located in the same local-area network\nand that hardware broadcasting is available. In that case, broadcasting or\nmulticasting a message is no more expensive than a single point-to-point\nmessage. Unicasting updates would then be less efficient.\nMulticasting can often be efficiently combined with a push-based approach\nto propagating updates. When the two are carefully integrated, a server that\ndecides to push its updates to a number of other servers simply uses a single\nmulticast group to send its updates. In contrast, with a pull-based approach, it\nis generally only a single client or server that requests its copy to be updated.\nIn that case, unicasting may be the most efficient solution.\n7.4.4\nManaging replicated objects\nAs we mentioned, data-centric consistency for distributed objects comes\nnaturally in the form of entry consistency. Recall that in this case, the goal\nis to group operations on shared data using synchronization variables (e.g.,\nin the form of locks). As objects naturally combine data and the operations\non that data, locking objects during an invocation serializes access and keeps\nthem consistent.\nAlthough conceptually associating a lock with an object is simple, it does\nnot necessarily provide a proper solution when an object is replicated. There\nare two issues that need to be solved for implementing entry consistency. The\nfirst one is that we need a means to prevent concurrent execution of multiple\ninvocations on the same object. In other words, when any method of an\nobject is being executed, no other methods may be executed. This requirement\nensures that access to the internal data of an object is indeed serialized. Simply\nusing local locking mechanisms will ensure this serialization.\nThe second issue is that in the case of a replicated object, we need to ensure\nthat all changes to the replicated state of the object are the same. In other\nDS 4.01\n \n",
      "content_length": 2922,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 451,
      "content": "7.4. REPLICA MANAGEMENT\n435\nwords, we need to make sure that no two independent method invocations\ntake place on different replicas at the same time. This requirement implies\nthat we need to order invocations such that each replica sees all invocations\nin the same order. We describe a few general solutions in Section 7.5.\nOften, designing replicated objects is done by first designing a single object,\npossibly protecting it against concurrent access through local locking, and\nsubsequently replicating it. The role of middleware is to ensure that if a client\ninvokes a replicated object, the invocation is passed to the replicas and handed\nto the their respective object servers in the same order everywhere. However,\nwe also need to ensure that all threads in those servers process those requests\nin the correct order as well. The problem is sketched in Figure 7.27.\nMiddleware\nLocal OS\nThreads\nUnordered requests\nTotally ordered\nrequests\nMiddleware\nLocal OS\nThreads\nThread\nscheduler\nDeterministic\nthread scheduling\nUnordered requests\nObject\nComputer 1\nComputer 2\nT1\n1\nT2\n1\nT2\n2\nT1\n2\nReplica\nFigure 7.27: Deterministic thread scheduling for replicated object servers.\nMultithreaded (object) servers simply pick up an incoming request, pass\nit on to an available thread, and wait for the next request to come in. The\nserver’s thread scheduler subsequently allocates the CPU to runnable threads.\nOf course, if the middleware has done its best to provide a total ordering\nfor request delivery, the thread schedulers should operate in a deterministic\nfashion in order not to mix the ordering of method invocations on the same\nobject. In other words, If threads T1\n1 and T2\n1 from Figure 7.27 handle the\nsame incoming (replicated) invocation request, they should both be scheduled\nbefore T1\n2 and T2\n2, respectively.\nSimply scheduling all threads deterministically is not necessary. In prin-\nciple, if we already have totally ordered request delivery, we need only to\nensure that all requests for the same replicated object are handled in the order\nthey were delivered. Such an approach would allow invocations for different\nobjects to be processed concurrently, and without further restrictions from the\nthread scheduler. Only few systems exist that support such concurrency.\n \nDS 4.01\n",
      "content_length": 2286,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 452,
      "content": "436\nCHAPTER 7. CONSISTENCY AND REPLICATION\nOne approach, described by Basile et al. [2002], ensures that threads\nsharing the same (local) lock are scheduled in the same order on every replica.\nAt the basics lies a primary-based scheme in which one of the replica servers\ntakes the lead in determining, for a specific lock, which thread goes first.\nAn improvement that avoids frequent communication between servers is\ndescribed in [Basile et al., 2003]. Note that threads that do not share a lock\ncan thus operate concurrently on each server.\nOne drawback of this scheme is that it operates at the level of the under-\nlying operating system, meaning that every lock needs to be managed. By\nproviding application-level information, a huge improvement in performance\ncan be made by identifying only those locks that are required for serializing\naccess to replicated objects (see Taiani et al. [2005]).\nNote 7.7 (Advanced: Replicated invocations)\nAnother problem that needs to be solved is that of replicated invocations. Con-\nsider an object A calling another object B as shown in Figure 7.28. Object B is\nassumed to call yet another object C. If B is replicated, each replica of B will,\nin principle, call C independently. The problem is that C is now called multiple\ntimes instead of only once. If the called method on C results in the transfer of\n$100,000, then clearly, someone is, sooner or later, going to complain.\nFigure 7.28: The problem of replicated object invocations.\nThere are not many general-purpose solutions to solve the problem of repli-\ncated invocations. One solution is to simply forbid it [Maassen et al., 2001],\nwhich makes sense when performance is at stake. However, when replicating for\nfault tolerance, the following solution proposed by Mazouni et al. [1995] may be\ndeployed. Their solution is independent of the replication policy, that is, the exact\ndetails of how replicas are kept consistent. The essence is to provide a replication-\naware communication layer on top of which (replicated) objects execute. When\na replicated object B invokes another replicated object C, the invocation request\nis first assigned the same, unique identifier by each replica of B. At that point, a\ncoordinator of the replicas of B forwards its request to all the replicas of object C,\nDS 4.01\n \n",
      "content_length": 2305,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 453,
      "content": "7.5. CONSISTENCY PROTOCOLS\n437\nwhile the other replicas of B hold back their copy of the invocation request, as\nshown in Figure 7.29. The result is that only a single request is forwarded to each\nreplica of C.\nThe same mechanism is used to ensure that only a single reply message is\nreturned to the replicas of B. This situation is shown in Figure 7.29. A coordinator\nof the replicas of C notices it is dealing with a replicated reply message that has\nbeen generated by each replica of C. However, only the coordinator forwards that\nreply to the replicas of object B, while the other replicas of C hold back their copy\nof the reply message.\n(a)\n(b)\nFigure 7.29: (a) Forwarding an invocation request from a replicated object\nto another replicated object. (b) Returning a reply from one replicated\nobject to another.\nWhen a replica of B receives a reply message for an invocation request it had\neither forwarded to C or held back because it was not the coordinator, the reply is\nthen handed to the actual object.\nIn essence, the scheme just described is based on using multicast communica-\ntion, but preventing that the same message is multicast by different replicas. As\nsuch, it is essentially a sender-based scheme. An alternative solution is to let a\nreceiving replica detect multiple copies of incoming messages belonging to the\nsame invocation, and to pass only one copy to its associated object. Details of this\nscheme are left as an exercise.\n7.5\nConsistency protocols\nWe now concentrate on the actual implementation of consistency models\nby taking a look at several consistency protocols. A consistency protocol\ndescribes an implementation of a specific consistency model. We follow the\norganization of our discussion on consistency models by first taking a look at\ndata-centric models, followed by protocols for client-centric models.\n \nDS 4.01\n",
      "content_length": 1853,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 454,
      "content": "438\nCHAPTER 7. CONSISTENCY AND REPLICATION\n7.5.1\nSequential consistency: Primary-based protocols\nIn practice, we see that distributed applications generally follow consistency\nmodels that are relatively easy to understand. These models include those for\nbounding staleness deviations, and to a lesser extent also those for bounding\nnumerical deviations. When it comes to models that handle consistent order-\ning of operations, sequential consistency, notably those in which operations\ncan be grouped through locking or transactions, are popular.\nAs soon as consistency models become slightly difficult to understand for\napplication developers, we see that they are ignored even if performance could\nbe improved. The bottom line is that if the semantics of a consistency model\nare not intuitively clear, application developers will have a hard time building\ncorrect applications. Simplicity is appreciated (and perhaps justifiably so).\nIn the case of sequential consistency, it turns out that primary-based\nprotocols prevail. In these protocols, each data item x in the data store has an\nassociated primary, which is responsible for coordinating write operations on\nx. A distinction can be made whether the primary is fixed at a remote server\nor if write operations can be carried out locally after moving the primary to\nthe process where the write operation is initiated.\nRemote-write protocols\nThe simplest primary-based protocol that supports replication is the one in\nwhich all write operations need to be forwarded to a fixed single server.\nRead operations can be carried out locally. Such schemes are also known\nas primary-backup protocols [Budhijara et al., 1993]. A primary-backup\nprotocol works as shown in Figure 7.30. A process wanting to perform a write\noperation on data item x, forwards that operation to the primary server for\nx. The primary performs the update on its local copy of x, and subsequently\nforwards the update to the backup servers. Each backup server performs\nthe update as well, and sends an acknowledgment to the primary. When all\nbackups have updated their local copy, the primary sends an acknowledgment\nto the initial process, which, in turn, informs the client.\nA potential performance problem with this scheme is that it may take a\nrelatively long time before the process that initiated the update is allowed to\ncontinue. In effect, an update is implemented as a blocking operation. An\nalternative is to use a nonblocking approach. As soon as the primary has\nupdated its local copy of x, it returns an acknowledgment. After that, it tells\nthe backup servers to perform the update as well. Nonblocking primary-\nbackup protocols are discussed in [Budhiraja and Marzullo, 1992].\nThe main problem with nonblocking primary-backup protocols has to do\nwith fault tolerance. In a blocking scheme, the client process knows for sure\nthat the update operation is backed up by several other servers. This is not\nDS 4.01\n \n",
      "content_length": 2945,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 455,
      "content": "7.5. CONSISTENCY PROTOCOLS\n439\nFigure 7.30: The principle of a primary-backup protocol.\nthe case with a nonblocking solution. The advantage, of course, is that write\noperations may speed up considerably.\nPrimary-backup protocols provide a straightforward implementation of\nsequential consistency, as the primary can order all incoming writes in a\nglobally unique order. Evidently, all processes see all write operations in\nthe same order, no matter which backup server they use to perform read\noperations. Also, with blocking protocols, processes will always see the effects\nof their most recent write operation (note that this cannot be guaranteed with\na nonblocking protocol without taking special measures).\nLocal-write protocols\nA variant of primary-backup protocols is one in which the primary copy\nmigrates between processes that wish to perform a write operation.\nAs\nbefore, whenever a process wants to update a data item x, it locates the\nprimary copy of x, and subsequently moves it to its own location, as shown in\nFigure 7.31. The main advantage of this approach is that multiple, successive\nwrite operations can be carried out locally, while reading processes can still\naccess their local copy. However, such an improvement can be achieved only\nif a nonblocking protocol is followed by which updates are propagated to the\nreplicas after the primary has finished with locally performing the updates.\nThis primary-backup local-write protocol can also be applied to mobile\ncomputers that can operate in disconnected mode. Before disconnecting, the\nmobile computer becomes the primary server for each data item it expects to\nupdate. While being disconnected, all update operations are carried out locally,\nwhile other processes can still perform read operations (but no updates).\n \nDS 4.01\n",
      "content_length": 1798,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 456,
      "content": "440\nCHAPTER 7. CONSISTENCY AND REPLICATION\nFigure 7.31: Primary-backup protocol in which the primary migrates to the\nprocess wanting to perform an update.\nLater, when connecting again, updates are propagated from the primary to\nthe backups, bringing the data store in a consistent state again.\nAs a last variant of this scheme, nonblocking local-write primary-based\nprotocols are also used for distributed file systems in general. In this case, there\nmay be a fixed central server through which normally all write operations\ntake place, as in the case of remote-write primary backup. However, the server\ntemporarily allows one of the replicas to perform a series of local updates,\nas this may considerably speed up performance. When the replica server is\ndone, the updates are propagated to the central server, from where they are\nthen distributed to the other replica servers.\n7.5.2\nSequential consistency: Replicated-write protocols\nIn replicated-write protocols, write operations can be carried out at multiple\nreplicas instead of only one, as in the case of primary-based replicas. A\ndistinction can be made between active replication, in which an operation is\nforwarded to all replicas, and consistency protocols based on majority voting.\nActive replication\nIn active replication, each replica has an associated process that carries out\nupdate operations.\nIn contrast to other protocols, updates are generally\npropagated through the write operation that causes the update. In other\nwords, the operation is sent to each replica. However, it is also possible to\nsend the update.\nDS 4.01\n \n",
      "content_length": 1592,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 457,
      "content": "7.5. CONSISTENCY PROTOCOLS\n441\nOne problem with active replication is that operations need to be carried\nout in the same order everywhere. Consequently, what is needed is a totally\nordered multicast mechanism.\nA practical approach to accomplish total\nordering is by a central coordinator, also called a sequencer. One approach\nis to first forward each operation to the sequencer, which assigns it a unique\nsequence number and subsequently forwards the operation to all replicas.\nOperations are carried out in the order of their sequence number.\nNote 7.8 (Advanced: Achieving scalability)\nNote that using a sequencer may easily introduce scalability problems. In fact, if\ntotally ordered multicasting is needed, a combination of symmetric multicasting\nusing Lamport timestamps [Lamport, 1978] and sequencers may be necessary.\nSuch a solution is described by Rodrigues et al. [1996]. The essence of that solution\nis to have multiple sequencers multicast update operations to each other and\norder the updates using Lamport’s total-ordering mechanism, as described in\nChapter 5. Nonsequencing processes are grouped such that each group uses\na single sequencer. Any nonsequencing process sends update requests to its\nsequencer and waits until it receives an acknowledgment that its request has been\nprocessed (i.e., multicast to the other sequencers in a totally ordered fashion).\nObviously, there is a trade-off between the number of processes that act as\nsequencer and those that do not, as well as the choice of processes to act as\nsequencer. As it turns out, this trade-off depends very much on the application\nand, in particular, the relative update rate at each process.\nQuorum-based protocols\nA different approach to supporting replicated writes is to use voting, as\noriginally proposed by Thomas [1979] and generalized by Gifford [1979].\nThe basic idea is to require clients to request and acquire the permission of\nmultiple servers before either reading or writing a replicated data item.\nAs a simple example of how the algorithm works, consider a distributed\nfile system and suppose that a file is replicated on N servers. We could make\na rule stating that to update a file, a client must first contact at least half the\nservers plus one (a majority) and get them to agree to do the update. Once\nthey have agreed, the file is changed and a new version number is associated\nwith the new file. The version number is used to identify the version of the\nfile and is the same for all the newly updated files.\nTo read a replicated file, a client must also contact at least half the servers\nplus one and ask them to send the version numbers associated with the file.\nIf all the version numbers are the same, this must be the most recent version\nbecause an attempt to update only the remaining servers would fail because\nthere are not enough of them.\nFor example, if there are five servers and a client determines that three of\nthem have version 8, it is impossible that the other two have version 9. After\n \nDS 4.01\n",
      "content_length": 3014,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 458,
      "content": "442\nCHAPTER 7. CONSISTENCY AND REPLICATION\nall, any successful update from version 8 to version 9 requires getting three\nservers to agree to it, not just two.\nWhen quorum-based replication was originally introduced, a somewhat\nmore general scheme was proposed. In it, to read a file of which N replicas\nexist, a client needs to assemble a read quorum, an arbitrary collection of any\nNR servers, or more. Similarly, to modify a file, a write quorum of at least\nNW servers is required. The values of NR and NW are subject to the following\ntwo constraints:\n1. NR + NW > N\n2. NW > N/2\nThe first constraint is used to prevent read-write conflicts, whereas the\nsecond prevents write-write conflicts. Only after the appropriate number of\nservers has agreed to participate can a file be read or written.\nTo see how this algorithm works, consider Figure 7.32(a) which has NR = 3\nand NW = 10. Imagine that the most recent write quorum consisted of the\n10 servers C through L. All of these get the new version and the new version\nnumber. Any subsequent read quorum of three servers will have to contain at\nleast one member of this set. When the client looks at the version numbers, it\nwill know which is most recent and take that one.\n(a)\n(b)\n(c)\nFigure 7.32: Three examples of the voting algorithm. The gray areas denote a\nread quorum; the white ones a write quorum. Servers in the intersection are\ndenoted in boldface. (a) A correct choice of read and write set. (b) A choice\nthat may lead to write-write conflicts. (c) A correct choice, known as ROWA\n(read one, write all).\nIn Figure 7.32 we see two more examples. In Figure 7.32(b) a write-write\nconflict may occur because NW ≤N/2. In particular, if one client chooses\n{A, B, C, E, F, G} as its write set and another client chooses {D, H, I, J, K, L} as\nits write set, then clearly we will run into trouble, as the two updates will\nboth be accepted without detecting that they actually conflict.\nThe situation shown in Figure 7.32(c) is especially interesting because it\nsets NR to one, making it possible to read a replicated file by finding any copy\nand using it. The price paid for this good read performance, however, is that\nDS 4.01\n \n",
      "content_length": 2183,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 459,
      "content": "7.5. CONSISTENCY PROTOCOLS\n443\nwrite updates need to acquire all copies. This scheme is generally referred to\nas Read-One, Write-All, (ROWA).\nQuorum-based replication has been an active field of research and an\ninspiration for various protocols. However, in practice, we often see primary-\nbased protocols at work (to which we return in Chapter 8). Jalote [1994]\nprovides a good overview of various quorum-based protocols. A more formal\nintroduction is given by Merideth and Reiter [2010], whereas many formal\ndetails and analyses of different protocols are described in [Vukoli´c, 2012].\n7.5.3\nCache-coherence protocols\nCaches form a special case of replication, in the sense that they are generally\ncontrolled by clients instead of servers. However, cache-coherence protocols,\nwhich ensure that a cache is consistent with the server-initiated replicas are,\nin principle, not very different from the consistency protocols discussed so far.\nThere has been much research in the design and implementation of caches,\nespecially in the context of shared-memory multiprocessor systems. Many\nsolutions are based on support from the underlying hardware, for example,\nby assuming that snooping or efficient broadcasting can be done. In the\ncontext of middleware-based distributed systems that are built on top of\ngeneral-purpose operating systems, software-based solutions to caches are\nmore interesting. In this case, two separate criteria are often maintained to\nclassify caching protocols (see also Min and Baer [1992], Lilja [1993], or Tartalja\nand Milutinovic [1997]).\nFirst, caching solutions may differ in their coherence detection strategy,\nthat is, when inconsistencies are actually detected.\nIn static solutions, a\ncompiler is assumed to perform the necessary analysis before execution, and\nto determine which data may actually lead to inconsistencies because they may\nbe cached. The compiler simply inserts instructions that avoid inconsistencies.\nDynamic solutions are typically applied in the distributed systems studied\nin this book. In these solutions, inconsistencies are detected at runtime. For\nexample, a check is made with the server to see whether the cached data have\nbeen modified since they were cached.\nIn the case of distributed databases, dynamic detection-based protocols\ncan be further classified by considering exactly when, during a transaction,\nthe detection is done. Franklin et al. [1997] distinguish the following three\ncases. First, when during a transaction a cached data item is accessed, the\nclient needs to verify whether that data item is still consistent with the version\nstored at the (possibly replicated) server. The transaction cannot proceed to\nuse the cached version until its consistency has been definitively validated.\nA second, optimistic, approach is to let the transaction proceed while\nverification is taking place. In this case, it is assumed that the cached data\nwere up-to-date when the transaction started. If that assumption later proves\nto be false, the transaction will have to abort.\n \nDS 4.01\n",
      "content_length": 3049,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 460,
      "content": "444\nCHAPTER 7. CONSISTENCY AND REPLICATION\nThe third approach is to verify whether the cached data are up-to-date only\nwhen the transaction commits. In effect, the transaction just starts operating\non the cached data and hopes for the best. After all the work has been done,\naccessed data are verified for consistency. When stale data were used, the\ntransaction is aborted.\nAnother design issue for cache-coherence protocols is the coherence en-\nforcement strategy, which determines how caches are kept consistent with the\ncopies stored at servers. The simplest solution is to disallow shared data to be\ncached at all. Instead, shared data are kept only at the servers, which maintain\nconsistency using one of the primary-based or replication-write protocols\ndiscussed above. Clients are allowed to cache only private data. Obviously,\nthis solution can offer only limited performance improvements.\nWhen shared data can be cached, there are two approaches to enforce\ncache coherence. The first is to let a server send an invalidation to all caches\nwhenever a data item is modified. The second is to simply propagate the\nupdate. Most caching systems use one of these two schemes. Dynamically\nchoosing between sending invalidations or updates is sometimes supported\nin client-server databases.\nFinally, we also need to consider what happens when a process modifies\ncached data. When read-only caches are used, update operations can be\nperformed only by servers, which subsequently follow some distribution\nprotocol to ensure that updates are propagated to caches. Often, a pull-based\napproach is followed. In this case, a client detects that its cache is stale, and\nrequests a server for an update.\nAn alternative approach is to allow clients to directly modify the cached\ndata, and forward the update to the servers.\nThis approach is followed\nin write-through caches, which are often used in distributed file systems.\nIn effect, write-through caching is similar to a primary-based local-write\nprotocol in which the client’s cache has become a temporary primary. To\nguarantee (sequential) consistency, it is necessary that the client has been\ngranted exclusive write permissions, or otherwise write-write conflicts may\noccur.\nWrite-through caches potentially offer improved performance over other\nschemes, as all operations can be carried out locally. Further enhancements\ncan be made if we delay the propagation of updates by allowing multiple\nwrites to take place before informing the servers. This leads to what is known\nas a write-back cache, which is, again, mainly applied in distributed file\nsystems.\nNote 7.9 (Example: Client-side caching in NFS)\nAs a practical example, consider the general caching model in NFS as shown in\nFigure 7.33. Each client can have a memory cache that contains data previously\nDS 4.01\n \n",
      "content_length": 2819,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 461,
      "content": "7.5. CONSISTENCY PROTOCOLS\n445\nread from the server. In addition, there may also be a disk cache that is added as\nan extension to the memory cache, using the same consistency parameters.\nFigure 7.33: Client-side caching in NFS.\nTypically, clients cache file data, attributes, file handles, and directories. Dif-\nferent strategies exist to handle consistency of the cached data, cached attributes,\nand so on. Let us first take a look at caching file data.\nNFSv4 supports two different approaches for caching file data. The simplest\napproach is when a client opens a file and caches the data it obtains from the\nserver as the result of various read operations. In addition, write operations can\nbe carried out in the cache as well. When the client closes the file, NFS requires\nthat if modifications have taken place, the cached data must be flushed back\nto the server. This approach corresponds to implementing session semantics as\ndiscussed earlier.\nOnce (part of) a file has been cached, a client can keep its data in the cache\neven after closing the file. Also, several clients on the same machine can share a\nsingle cache. NFS requires that whenever a client opens a previously closed file\nthat has been (partly) cached, the client must immediately revalidate the cached\ndata. Revalidation takes place by checking when the file was last modified and\ninvalidating the cache in case it contains stale data.\nIn NFSv4 a server may delegate some of its rights to a client when a file is\nopened. Open delegation takes place when the client machine is allowed to\nlocally handle open and close operations from other clients on the same machine.\nNormally, the server is in charge of checking whether opening a file should\nsucceed, for example because share reservations need to be considered. With\nopen delegation, the client machine is sometimes allowed to make such decisions,\navoiding the need to contact the server.\nFor example, if a server has delegated the opening of a file to a client that\nrequested write permissions, file locking requests from other clients on the same\nmachine can also be handled locally. The server will still handle locking requests\nfrom clients on other machines, by simply denying those clients access to the file.\nNote that this scheme does not work in the case of delegating a file to a client that\nrequested only read permissions. In that case, whenever another local client wants\nto have write permissions, it will have to contact the server; it is not possible to\nhandle the request locally.\nAn important consequence of delegating a file to a client is that the server\n \nDS 4.01\n",
      "content_length": 2610,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 462,
      "content": "446\nCHAPTER 7. CONSISTENCY AND REPLICATION\nneeds to be able to recall the delegation, for example, when another client on a\ndifferent machine needs to obtain access rights to the file. Recalling a delegation\nrequires that the server can do a callback to the client, as illustrated in Figure 7.34.\nFigure 7.34: Using the NFSv4 callback mechanism to recall file delegation.\nA callback is implemented in NFS using its underlying RPC mechanisms.\nNote, however, that callbacks require that the server keeps track of clients to which\nit has delegated a file. Here, we see another example where an NFS server cannot\nbe implemented in a stateless manner. Note, however, that the combination of\ndelegation and stateful servers may lead to various problems in the presence of\nclient and server failures. For example, what should a server do when it had\ndelegated a file to a now unresponsive client?\nClients can also cache attribute values, but are largely left on their own when\nit comes to keeping cached values consistent. In particular, attribute values of the\nsame file cached by two different clients may be different unless the clients keep\nthese attributes mutually consistent. Modifications to an attribute value should\nbe immediately forwarded to the server, thus following a write-through cache\ncoherence policy.\nA similar approach is followed for caching file handles (or rather, the name-\nto-file handle mapping) and directories. To mitigate the effects of inconsistencies,\nNFS uses leases on cached attributes, file handles, and directories. After some\ntime has elapsed, cache entries are thus automatically invalidated and revalidation\nis needed before they are used again.\n7.5.4\nImplementing continuous consistency\nAs part of their work on continuous consistency, Yu and Vahdat [2000] have\ndeveloped a number of protocols to tackle the three forms of continuous\nconsistency. In the following, we briefly consider a number of solutions,\nomitting details for clarity.\nBounding numerical deviation\nWe first concentrate on one solution for keeping the numerical deviation\nwithin bounds. Again, our purpose is not to go into all the details for each\nprotocol, but rather to give the general idea. Details for bounding numerical\ndeviation can be found in [Yu and Vahdat, 2000].\nDS 4.01\n \n",
      "content_length": 2288,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 463,
      "content": "7.5. CONSISTENCY PROTOCOLS\n447\nWe concentrate on writes to a single data item x. Each write W(x) has an\nassociated value that represents the numerical value by which x is updated,\ndenoted as val(W(x)), or simply val(W).\nFor simplicity, we assume that\nval(W) > 0. Each write W is initially submitted to one out of the N available\nreplica servers, in which case that server becomes the write’s origin, denoted\nas origin(W). If we consider the system at a specific moment we will see\nseveral submitted writes that still need to be propagated to all servers. To this\nend, each server Si will keep track of a log Li of writes that it has performed\non its own local copy of x.\nLet TW[i, j] be the effect of performing the writes executed by server Si\nthat originated from server Sj:\nTW[i, j] = ∑{val(W)|origin(W) = Sj and W ∈Li}\nNote that TW[i, i] represents the aggregated writes submitted to Si. Our\ngoal is for any time t, to let the current value vi of x at server Si deviate\nwithin bounds from the actual value v of x. This actual value is completely\ndetermined by all submitted writes. That is, if v0 is the initial value of x, then\nv = v0 +\nN\n∑\nk=1\nTW[k, k]\nand\nvi = v0 +\nN\n∑\nk=1\nTW[i, k]\nNote that vi ≤v. Let us concentrate only on absolute deviations. In particular,\nfor every server Si, we associate an upper bound δi such that we need to\nenforce:\nv −vi ≤δi\nWrites submitted to a server Si will need to be propagated to all other servers.\nThere are different ways in which this can be done, but typically an epidemic\nprotocol will allow rapid dissemination of updates. In any case, when a server\nSi propagates a write originating from Sj to Sk, the latter will be able to learn\nabout the value TW[i, j] at the time the write was sent. In other words, Sk can\nmaintain a view TWk[i, j] of what it believes Si will have as value for TW[i, j].\nObviously,\n0 ≤TWk[i, j] ≤TW[i, j] ≤TW[j, j]\nThe whole idea is that when a server Sk notices that Si has not been staying in\nthe right pace with the updates that have been submitted to Sk, it forwards\nwrites from its log to Si.\nThis forwarding effectively advances the view\nTWk[i, k] that Sk has of TW[i, k], making the deviation TW[i, k] −TWk[i, k]\nsmaller. In particular, Sk advances its view on TW[i, k] when an application\nsubmits a new write that would increase TW[k, k] −TWk[i, k] beyond δi/(N −\n1). We leave it as an exercise to the reader to show that advancement always\nensures that v −vi ≤δi.\n \nDS 4.01\n",
      "content_length": 2456,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 464,
      "content": "448\nCHAPTER 7. CONSISTENCY AND REPLICATION\nBounding staleness deviations\nThere are many ways to keep the staleness of replicas within specified bounds.\nOne simple approach is to let the server Sk keep a real-time vector clock\nRVCk where RVCk[i] = ti means that Sk has seen all writes that have been\nsubmitted to Si up to time ti. In this case, we assume that each submitted\nwrite is timestamped by its origin server, with ti denoting the time local to Si.\nIf the clocks between the replica servers are loosely synchronized, then an\nacceptable protocol for bounding staleness would be the following. Whenever\nthe server Sk notes that tk −RVCk[i] is about to exceed a specified limit, it\nsimply starts pulling in writes that originated from Si with a timestamp later\nthan RVCk[i].\nNote that in this case, a replica server is responsible for keeping its copy\nof x up to date regarding writes that have been issued elsewhere. In contrast,\nwhen maintaining numerical bounds, we followed a push approach by letting\nan origin server keep replicas up to date by forwarding writes. The problem\nwith pushing writes in the case of staleness is that no guarantees can be given\nfor consistency when it is unknown in advance what the maximal propagation\ntime will be. This situation is somewhat improved by pulling in updates, as\nmultiple servers can help to keep a server’s copy of x up to date.\nBounding ordering deviations\nRecall that ordering deviations in continuous consistency are caused by the\nfact that a replica server tentatively applies updates that have been submitted\nto it. As a result, each server will have a local queue of tentative writes for\nwhich the actual order in which they are to be applied to the local copy of\nx still needs to be determined. The deviation is bounded by specifying the\nmaximal length of the queue of tentative writes.\nAs a consequence, detecting when ordering consistency needs to be en-\nforced is simple: when the length of this local queue exceeds a specified\nmaximal length. At that point, a server will no longer accept any newly\nsubmitted writes, but will instead attempt to commit tentative writes by nego-\ntiating with other servers in which order its writes should be executed. We\nthus have to enforce a globally consistent ordering of tentative writes.\n7.5.5\nImplementing client-centric consistency\nFor our last topic on consistency protocols, let us draw our attention to imple-\nmenting client-centric consistency. Implementing client-centric consistency is\nrelatively straightforward if performance issues are ignored.\nIn a naive implementation of client-centric consistency, each write opera-\ntion W is assigned a globally unique identifier. Such an identifier is assigned\nby the server to which the write had been submitted. We refer to this server\nas the origin of W. Then, for each client, we keep track of two sets of writes.\nDS 4.01\n \n",
      "content_length": 2882,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 465,
      "content": "7.5. CONSISTENCY PROTOCOLS\n449\nThe read set for a client consists of the writes relevant for the read operations\nperformed by a client. Likewise, the write set consists of the (identifiers of\nthe) writes performed by the client.\nMonotonic-read consistency is implemented as follows. When a client\nwants to perform a read operation at a server, that server is handed the client’s\nread set to check whether all the identified writes have taken place locally.\nIf not, it contacts the other servers to ensure that it is brought up to date\nbefore carrying out the read operation. Alternatively, the read operation is\nforwarded to a server where the write operations have already taken place.\nAfter the read operation is performed, the write operations that have taken\nplace at the selected server and which are relevant for the read operation are\nadded to the client’s read set.\nNote that it should be possible to determine exactly where the write\noperations identified in the read set have taken place. For example, the write\nidentifier could include the identifier of the server to which the operation was\nsubmitted. That server is required to, for example, log the write operation so\nthat it can be replayed at another server. In addition, write operations should\nbe performed in the order they were submitted. Ordering can be achieved by\nletting the client generate a globally unique sequence number that is included\nin the write identifier. If each data item can be modified only by its owner,\nthe latter can supply the sequence number.\nMonotonic-write consistency is implemented analogous to monotonic\nreads. Whenever a client initiates a new write operation at a server, the\nserver is handed over the client’s write set. (Again, the size of the set may be\nprohibitively large in the face of performance requirements. An alternative\nsolution is discussed below.) It then ensures that the identified write opera-\ntions are performed first and in the correct order. After performing the new\noperation, that operation’s write identifier is added to the write set. Note\nthat bringing the current server up to date with the client’s write set may\nintroduce a considerable increase in the client’s response time, since the client\nthen waits for the operation to fully complete.\nLikewise, read-your-writes consistency requires that the server where the\nread operation is to be performed has seen all the write operations in the\nclient’s write set. The writes can simply be fetched from other servers before\nthe read operation is actually executed, although this may lead to a poor\nresponse time. Alternatively, the client-side software can search for a server\nwhere the identified write operations in the client’s write set have already\nbeen performed.\nFinally, writes-follow-reads consistency can be implemented by first bring-\ning the selected server up to date with the write operations in the client’s read\nset, and then later adding the identifier of the write operation to the write set,\nalong with the identifiers in the read set (which have now become relevant\nfor the write operation just performed).\n \nDS 4.01\n",
      "content_length": 3114,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 466,
      "content": "450\nCHAPTER 7. CONSISTENCY AND REPLICATION\nNote 7.10 (Advanced: Improving efficiency)\nIt is easy to see that the read set and write set associated with each client can\nbecome very large. To keep these sets manageable, a client’s read and write\noperations are grouped into sessions. A session is typically associated with an\napplication: it is opened when the application starts and is closed when it exits.\nHowever, sessions may also be associated with applications that are temporarily\nexited, such as user agents for e-mail. Whenever a client closes a session, the sets\nare simply cleared. Of course, if a client opens a session that it never closes, the\nassociated read and write sets can still become very large.\nThe main problem with a naive implementation lies in the representation of\nthe read and write sets. Each set consists of a number of identifiers for write\noperations. Whenever a client forwards a read or write request to a server, a set\nof identifiers is handed to the server as well to see whether all write operations\nrelevant to the request have been carried out by that server.\nThis information can be more efficiently represented by vector timestamps\nas follows. First, whenever a server accepts a new write operation W, it assigns\nthat operation a globally unique identifier along with a timestamp ts(W). A\nsubsequent write operation submitted to that server is assigned a higher-valued\ntimestamp. Each server Si maintains a vector timestamp WVCi, where WVCi[j] is\nequal to the timestamp of the most recent write operation originating from Sj that\nhas been processed by Si.\nFor clarity, assume that for each server, writes from Sj are processed in the\norder that they were submitted. Whenever a client issues a request to perform\na read or write operation O at a specific server, that server returns its current\ntimestamp along with the results of O. Read and write sets are subsequently\nrepresented by vector timestamps. More specifically, for each session A, we\nconstruct a vector timestamp SVCA with SVCA[i] set equal to the maximum\ntimestamp of all write operations in A that originate from server Si:\nSVCA[j] = max{ts(W)|W ∈A and origin(W) = Sj}\nIn other words, the timestamp of a session always represents the latest write\noperations that have been seen by the applications that are being executed as part\nof that session. The compactness is obtained by representing all observed write\noperations originating from the same server through a single timestamp.\nAs an example, suppose a client, as part of session A, logs in at server Si. To\nthat end, it passes SVCA to Si. Assume that SVCA[j] > WVCi[j]. What this means\nis that Si has not yet seen all the writes originating from Sj that the client has\nseen. Depending on the required consistency, server Si may now have to fetch\nthese writes before being able to consistently report back to the client. Once the\noperation has been performed, server Si will return its current timestamp WVCi.\nAt that point, SVCA is adjusted to:\nSVCA[j] ←max{SVCA[j], WVCi[j]}\nAgain, we see how vector timestamps can provide an elegant and compact way of\nrepresenting history in a distributed system.\nDS 4.01\n \n",
      "content_length": 3170,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 467,
      "content": "7.6. EXAMPLE: CACHING AND REPLICATION IN THE WEB\n451\n7.6\nExample: Caching and replication in the Web\nThe Web is arguably the largest distributed system ever built. Originating from\na relatively simple client-server architecture, it is now a sophisticated system\nconsisting of many techniques to ensure stringent performance and availability\nrequirements. These requirements have led to numerous proposals for caching\nand replicating Web content. Where the original schemes (which are still\nlargely deployed) have been targeted toward supporting static content, much\neffort has also been put into supporting dynamic content, that is, supporting\ndocuments that are generated on-the-spot as the result of a request, as well as\nthose containing scripts and such. An overview of traditional Web caching\nand replication is provided by Rabinovich and Spastscheck [2002].\nClient-side caching in the Web generally occurs at two places. In the first\nplace, most browsers are equipped with a relatively simple caching facility.\nWhenever a document is fetched, it is stored in the browser’s cache, from\nwhere it is loaded the next time. In the second place, a client’s site often runs a\nWeb proxy. A Web proxy accepts requests from local clients and passes these\nto Web servers. When a response comes in, the result is passed to the client.\nThe advantage of this approach is that the proxy can cache the result and\nreturn that result to another client, if necessary. In other words, a Web proxy\ncan implement a shared cache. With so many documents being generated\non the fly, the server generally provides the document in pieces, instructing\nthe client to cache only those parts that are not likely to change when the\ndocument is requested a next time.\nIn addition to caching at browsers and proxies, ISPs generally also place\ncaches in their networks. Such schemes are mainly used to reduce network\ntraffic (which is good for the ISP) and to improve performance (which is\ngood for end users). However, with multiple caches along the request path\nfrom client to server, there is a risk of increased latencies when caches do not\ncontain the requested information.\nNote 7.11 (Advanced: Cooperative caching)\nAs an alternative to building hierarchical caches, one can also organize caches\nfor cooperative deployment, as shown in Figure 7.35. In cooperative caching or\ndistributed caching, whenever a cache miss occurs at a Web proxy, the proxy\nfirst checks a number of neighboring proxies to see if one of them contains the\nrequested document. If such a check fails, the proxy forwards the request to the\nWeb server responsible for the document. In more traditional settings, this scheme\nis primarily deployed with Web caches belonging to the same organization or\ninstitution.\nA study by Wolman et al. [1999] shows that cooperative caching may be effec-\ntive for only relatively small groups of clients (in the order of tens of thousands\nof users). However, such groups can also be serviced by using a single proxy\ncache, which is much cheaper in terms of communication and resource usage.\n \nDS 4.01\n",
      "content_length": 3084,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 468,
      "content": "452\nCHAPTER 7. CONSISTENCY AND REPLICATION\nHowever, in a study from a decade later, Wendell and Freedman [2011] show that\nin a highly decentralized system, cooperative caching actually turned out to be\nhighly effective. These studies do not necessarily contradict each other: in both\ncases, the conclusion is that the effect of cooperative caching depends highly on\nthe demands from clients.\nA comparison between hierarchical and cooperative caching by Rodriguez\net al. [2001] makes clear that there are various trade-offs to make. For example,\nbecause cooperative caches are generally connected through high-speed links,\nthe transmission time needed to fetch a document is much lower than for a\nhierarchical cache. Also, as is to be expected, storage requirements are less strict\nfor cooperative caches than hierarchical ones.\nWeb\nproxy\nWeb\nserver\nWeb\nproxy\nWeb\nproxy\nCache\nCache\nCache\nClient\nClient\nClient\nClient\nClient\nClient\nClient\nClient\nClient\n2. Ask neighboring proxy caches\n1. Look in\nlocal cache\nHTTP Get request\n3. Forward request\nto Web server\nFigure 7.35: The principle of cooperative caching.\nDifferent cache-consistency protocols have been deployed in the Web.\nTo guarantee that a document returned from the cache is consistent, some\nWeb proxies first send a conditional HTTP get request to the server with an\nadditional If-Modified-Since request header, specifying the last modification\ntime associated with the cached document. Only if the document has been\nchanged since that time, will the server return the entire document. Otherwise,\nthe Web proxy can simply return its cached version to the requesting local\nclient, which corresponds to a pull-based protocol.\nUnfortunately, this strategy requires that the proxy contacts a server for\neach request. To improve performance at the cost of weaker consistency, the\nwidely used Squid Web proxy [Wessels, 2004] assigns an expiration time Texpire\nthat depends on how long ago the document was last modified when it is\ncached. In particular, if Tlast_modified is the last modification time of a document\n(as recorded by its owner), and Tcached is the time it was cached, then\nTexpire = α(Tcached −Tlast_modified) + Tcached\nDS 4.01\n \n",
      "content_length": 2196,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 469,
      "content": "7.6. EXAMPLE: CACHING AND REPLICATION IN THE WEB\n453\nwith α = 0.2 (this value has been derived from practical experience). Until\nTexpire, the document is considered valid, and the proxy will not contact the\nserver. After the expiration time, the proxy requests the server to send a fresh\ncopy, unless it had not been modified. We note that Squid also allows the\nexpiration time to be bounded by a minimum and a maximum time.\nAs an alternative to a pull-based protocol is that the server notifies proxies\nthat a document has been modified by sending an invalidation. The problem\nwith this approach for Web proxies is that the server may need to keep track\nof many proxies, inevitably leading to a scalability problem. However, by\ncombining leases and invalidations, the state to be maintained at the server\ncan be kept within acceptable bounds. Note that this state is largely dictated\nby the expiration times set for leases: the lower, the less caches a server needs\nto keep track of. Nevertheless, invalidation protocols for Web proxy caches are\nhardly ever applied. A comparison of Web caching consistency policies can\nbe found in [Cao and Ozsu, 2002]. Their conclusion is that letting the server\nsend invalidations can outperform any other method in terms of bandwidth\nand perceived client latency, while maintaining cached documents consistent\nwith those at the origin server.\nFinally, we should also mention that much research has been conducted to\nfind out what the best cache replacement strategies are. Numerous proposals\nexist, but by-and-large, simple replacement strategies such as evicting the\nleast recently used object work well enough. An in-depth survey of replace-\nment strategies is presented by Podling and Boszormenyi [2003]; Ali et al.\n[2011] provide a more recent overview, which also includes Web prefetching\ntechniques.\nAs the importance of the Web continues to increase as a vehicle for organi-\nzations to present themselves and to directly interact with end users, we see\na shift between maintaining the content of a Web site and making sure that\nthe site is easily and continuously accessible. This distinction has paved the\nway for Content Delivery Networks (CDN). The main idea underlying these\nCDNs is that they act as a Web hosting service, providing an infrastructure\nfor distributing and replicating the Web documents of multiple sites across\nthe Internet. The size of the infrastructure can be impressive. As mentioned\nbefore, as of 2022, Akamai is reported to have over 400,000 servers worldwide.\nThe sheer size of a CDN requires that hosted documents are automatically\ndistributed and replicated. In most cases, a large-scale CDN is organized\nsimilar to a feedback-control loop, as shown in Figure 7.36 and which is\ndescribed extensively in [Sivasubramanian et al., 2004b].\nThere are essentially three different kinds of aspects related to replication\nin Web hosting systems: metric estimation, adaptation triggering, and taking\nappropriate measures. The latter can be subdivided into replica placement de-\ncisions, consistency enforcement, and client-request routing. In the following,\nwe briefly pay attention to each of these.\n \nDS 4.01\n",
      "content_length": 3176,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 470,
      "content": "454\nCHAPTER 7. CONSISTENCY AND REPLICATION\nFigure 7.36: The general organization of a CDN as a feedback-control system.\nAn interesting aspect of CDNs is that they need to make a trade-off between\nmany aspects when it comes to hosting replicated content. For example, access\ntimes for a document may be optimal if a document is massively replicated,\nbut at the same time this incurs a financial cost, as well as a cost in terms of\nbandwidth usage for disseminating updates. By and large, there are many\nproposals for estimating how well a CDN is performing. These proposals can\nbe grouped into several classes.\nFirst, there are latency metrics, by which the time is measured for an action,\nfor example, fetching a document, to take place. Trivial as this may seem,\nestimating latencies becomes difficult when, for example, a process deciding\non the placement of replicas needs to know the delay between a client and\nsome remote server. Typically, an algorithm for globally positioning nodes as\ndiscussed in Section 5.7.3 will need to be deployed.\nInstead of estimating latency, it may be more important to measure the\navailable bandwidth between two nodes. This information is particularly\nimportant when large documents have to be transferred, as in that case, the\nresponsiveness of the system is largely dictated by the time that a document\ncan be transferred. There are various tools for measuring available bandwidth,\nbut in all cases it turns out that accurate measurements can be difficult to\nattain (see also Strauss et al. [2003], Shriram and Kaur [2007], Chaudhari and\nBiradar [2015], and Atxutegi et al. [2016]).\nAnother class consists of spatial metrics, which mainly consist of measuring\nthe distance between nodes in terms of the number of network-level routing\nhops, or hops between autonomous systems. Again, determining the number\nof hops between two arbitrary nodes can be very difficult, and may also not\neven correlate with latency [Huffaker et al., 2002]. Moreover, simply looking\nat routing tables is not going to work when low-level techniques such as\nMulti-Protocol Label Switching (MPLS) are deployed. MPLS circumvents\nDS 4.01\n \n",
      "content_length": 2152,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 471,
      "content": "7.6. EXAMPLE: CACHING AND REPLICATION IN THE WEB\n455\nnetwork-level routing by using virtual-circuit techniques to immediately and\nefficiently forward packets to their destination (see also Guichard et al. [2005]).\nPackets may thus follow entirely different routes than advertised in the tables\nof network-level routers.\nA third class is formed by network usage metrics, which most often entails\nconsumed bandwidth. Computing consumed bandwidth in terms of the\nnumber of bytes to transfer is generally easy. However, to do this correctly,\nwe need to consider how often the document is read, how often it is updated,\nand how often it is replicated.\nConsistency metrics tell us to what extent a replica is deviating from its mas-\nter copy. We already discussed extensively how consistency can be measured\nin the context of continuous consistency [Yu and Vahdat, 2002].\nFinally, financial metrics form another class for measuring how well a CDN\nis doing. Although not technical at all, considering that most CDN operate\non a commercial basis, it is clear that often financial metrics will be decisive.\nMoreover, the financial metrics are closely related to the actual infrastructure of\nthe Internet. For example, most commercial CDNs place servers at the edge of\nthe Internet, meaning that they hire capacity from ISPs directly servicing end\nusers. At this point, business models become intertwined with technological\nissues, an area that is not at all well understood. There is only few material\navailable on the relation between financial performance and technological\nissues [Janiga et al., 2001].\nFrom these examples, it should become clear that simply measuring the\nperformance of a CDN, or even estimating its performance, may by itself be\nan extremely complex task. In practice, for commercial CDNs the issue that\nreally counts is whether they can meet the service-level agreements that have\nbeen made with customers. These agreements are often formulated simply in\nterms of how quickly customers are to be serviced. It is then up to the CDN\nto make sure that these agreements are met.\nAnother question that needs to be addressed is when and how adaptations\nare to be triggered. A simple model is to periodically estimate metrics and\nsubsequently take measures as needed. This approach is often seen in practice.\nSpecial processes located at the servers collect information and periodically\ncheck for changes.\nAn interesting aspect of this scheme is the simplicity by which consistency\nof documents can be enforced. Clearly, whenever a main document is changed,\na client will always be able to fetch it from the origin server. In the case of\nembedded documents, a different approach needs to be followed as these\ndocuments are, in principle, fetched from a nearby replica server. To this end,\na URL for an embedded document not only refers to a special host name that\neventually leads to a CDN DNS server, but also contains a unique identifier\nthat is changed every time the embedded document changes. In effect, this\nidentifier changes the name of the embedded document. As a consequence,\n \nDS 4.01\n",
      "content_length": 3103,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 472,
      "content": "456\nCHAPTER 7. CONSISTENCY AND REPLICATION\ndatabase\nSchema\nSchema\nServer\nServer\nquery\nresponse\nfull/partial data replication\nquery templates\ncache\ncache\ncopy\nClient\nEdge-server side\nOrigin-server side\nFigure 7.37: Alternatives for caching and replication with Web applications.\nwhen the client is redirected to a specific CDN server, that server will not find\nthe named document in its cache and will thus fetch it from the origin server.\nThe old document will eventually be evicted from the server’s cache as it is\nno longer referenced.\nUp to this point, we have mainly concentrated on caching and replicating\nstatic Web content. In practice, we see that the Web is increasingly offering\nmore dynamically generated content, but that it is also expanding toward\noffering services that can be called by remote applications. Also in these situa-\ntions we see that caching and replication can help considerably in improving\nthe overall performance, although the methods to reach such improvements\nare more subtle than what we discussed so far (see also Conti et al. [2005]).\nWhen considering improving performance of Web applications through\ncaching and replication, matters are complicated by the fact that several so-\nlutions can be deployed, with no single one standing out as the best. Let us\nconsider the edge-server situation as sketched in Figure 7.37 (see also Sivasub-\nramanian et al. [2007]). In this case, we assume a CDN in which each hosted\nsite has an origin server that acts as the authoritative site for all read and\nupdate operations. An edge server is used to handle client requests, and has\nthe ability to store (partial) information as also kept at an origin server.\nRecall that in an edge-server architecture, Web clients request data through\nan edge server, which, in turn, gets its information from the origin server\nassociated with the specific Website referred to by the client. As also shown in\nFigure 7.37 we assume that the origin server consists of a database from which\nresponses are dynamically created. Although we have shown only a single\nWeb server, it is common to organize each server according to a multitiered\narchitecture, as we discussed before. An edge server can now be roughly\norganized along the following lines.\nDS 4.01\n \n",
      "content_length": 2264,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 473,
      "content": "7.6. EXAMPLE: CACHING AND REPLICATION IN THE WEB\n457\nFirst, to improve performance, we can decide to apply full replication of\nthe data stored at the origin server. This scheme works well whenever the\nupdate ratio is low and when queries require an extensive database search.\nAs mentioned above, we assume that all updates are carried out at the origin\nserver, which takes responsibility for keeping the replicas and the edge servers\nin a consistent state. Read operations can thus take place at the edge servers.\nHere, we see that replicating for performance will fail when the update ratio\nis high, as each update will incur communication over a wide-area network to\nbring the replicas into a consistent state. As shown by Sivasubramanian et al.\n[2004a], the read-to-update ratio is the determining factor to what extent the\norigin database in a wide-area setting should be replicated.\nAnother case for full replication is when queries are generally complex. In\nthe case of a relational database, this means that a query requires that multiple\ntables need to be searched and processed, as is generally the case with a join\noperation. Opposed to complex queries are simple ones that generally require\naccess to only a single table to produce a response. In the latter case, partial\nreplication by which only a subset of the data is stored at the edge server may\nsuffice.\nAn alternative to partial replication is to make use of content-aware caches.\nThe basic idea in this case is that an edge server maintains a local database\nthat is now tailored to the type of queries that can be handled at the origin\nserver. To explain, in a full-fledged database system a query will operate\non a database in which the data has been organized into tables such that,\nfor example, redundancy is minimized. Such databases are also said to be\nnormalized.\nIn such databases, any query that adheres to the data schema can, in\nprinciple, be processed, although perhaps at considerable costs. With content-\naware caches, an edge server maintains a database that is organized according\nto the structure of queries. What this means is that queries are assumed to\nadhere to a limited number of templates, effectively meaning that the different\nkinds of queries that can be processed is restricted. In these cases, whenever\na query is received, the edge server matches the query against the available\ntemplates, and subsequently looks in its local database to compose a response,\nif possible. If the requested data is not available, the query is forwarded to\nthe origin server, after which the response is cached before returning it to the\nclient.\nIn effect, what the edge server is doing is checking whether a query can be\nanswered with the data that is stored locally. This is also referred to as a query\ncontainment check. Note that such data was stored locally as responses to\npreviously issued queries. This approach works best when queries tend to be\nrepeated.\nPart of the complexity of content-aware caching comes from the fact\nthat the data at the edge server needs to be kept consistent. To this end,\n \nDS 4.01\n",
      "content_length": 3097,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 474,
      "content": "458\nCHAPTER 7. CONSISTENCY AND REPLICATION\nthe origin server needs to know which records are associated with which\ntemplates, so that any update of a record, or any update of a table, can be\nproperly addressed by, for example, sending an invalidation message to the\nappropriate edge servers. Another source of complexity comes from the fact\nthat queries still need to be processed at edge servers. In other words, there is\nnonnegligible computational power needed to handle queries. Considering\nthat databases often form a performance bottleneck in Web servers, alternative\nsolutions may be needed. Finally, caching results from queries that span\nmultiple tables (i.e., when queries are complex) such that a query containment\ncheck can be carried out effectively is not trivial. The reason is that the\norganization of the results may be very different from the organization of the\ntables on which the query operated.\nThese observations lead us to a third solution, namely content-blind\ncaching. The idea of content-blind caching is simple: when a client submits\na query to an edge server, the server first computes a unique hash value for\nthat query. Using this hash value, it subsequently looks in its cache whether it\nhas processed this query before. If not, the query is forwarded to the origin\nand the result is cached before returning it to the client. If the query had been\nprocessed before, the previously cached result is returned to the client.\nThe main advantage of this scheme is the reduced computational effort\nthat is required from an edge server in comparison to the database approaches\ndescribed above. However, content-blind caching can be wasteful in terms of\nstorage, as the caches may contain much more redundant data in comparison\nto content-aware caching or database replication. Note that such redundancy\nalso complicates the process of keeping the cache up-to-date, as the origin\nserver may need to keep an accurate account of which updates can potentially\naffect cached query results. These problems can be alleviated when assuming\nthat queries can match only a limited set of predefined templates, as we\ndiscussed above.\n7.7\nSummary\nThere are primarily two reasons for replicating data: improving the reliability\nof a distributed system and improving performance. Replication introduces\na consistency problem: whenever a replica is updated, that replica becomes\ndifferent from the others. To keep replicas consistent, we need to propagate\nupdates in such a way that temporary inconsistencies are not noticed. Unfor-\ntunately, doing so may severely degrade performance, especially in large-scale\ndistributed systems.\nThe only solution to this problem is to relax consistency somewhat. Dif-\nferent consistency models exist. For continuous consistency, the goal is to\nset bounds to numerical deviation between replicas, staleness deviation, and\ndeviations in the ordering of operations.\nDS 4.01\n \n",
      "content_length": 2920,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 475,
      "content": "7.7. SUMMARY\n459\nNumerical deviation refers to the value by which replicas may be different.\nThis type of deviation is highly application dependent, but can, for example,\nbe used in replication of stocks. Staleness deviation refers to the time by\nwhich a replica is still considered to be consistent, despite that updates may\nhave taken place some time ago. Staleness deviation is often used for Web\ncaches. Finally, ordering deviation refers to the maximum number of tentative\nwrites that may be outstanding at any server without having synchronized\nwith the other replica servers.\nConsistent ordering of operations has since long formed the basis for\nmany consistency models. Many variations exist, but only a few seem to\nprevail among application developers. Sequential consistency essentially\nprovides the semantics that programmers expect in concurrent programming:\nall write operations are seen by everyone in the same order.\nLess used,\nbut still relevant, is causal consistency, which reflects that operations that\nare potentially dependent on each other are carried out in the order of that\ndependency.\nWeaker consistency models consider series of read and write operations.\nIn particular, they assume that each series is appropriately “bracketed” by ac-\ncompanying operations on synchronization variables, such as locks. Although\nthis requires explicit effort from programmers, these models are generally\neasier to implement efficiently than, for example, pure sequential consistency.\nAs opposed to these data-centric models, researchers in the field of dis-\ntributed databases for mobile users have defined a number of client-centric\nconsistency models. Such models do not consider the fact that data may be\nshared by several users, but instead, concentrate on the consistency that an\nindividual client should be offered. The underlying assumption is that a client\nconnects to different replicas in the course of time, but that such differences\nshould be made transparent. In essence, client-centric consistency models\nensure that whenever a client connects to a new replica, that replica is brought\nup to date with the data that had been manipulated by that client before, and\nwhich may reside at other replica sites.\nTo propagate updates, different techniques can be applied. A distinction\nneeds to be made concerning what is exactly propagated, to where updates are\npropagated, and by whom propagation is initiated. We can decide to propagate\nnotifications, operations, or state. Likewise, not every replica always needs to\nbe updated immediately. Which replica is updated at which time depends\non the distribution protocol. Finally, a choice can be made whether updates\nare pushed to other replicas, or that a replica pulls in updates from another\nreplica.\nConsistency protocols describe specific implementations of consistency\nmodels. Regarding sequential consistency and its variants, a distinction can\nbe made between primary-based protocols and replicated-write protocols. In\nprimary-based protocols, all update operations are forwarded to a primary\n \nDS 4.01\n",
      "content_length": 3078,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 476,
      "content": "460\nCHAPTER 7. CONSISTENCY AND REPLICATION\ncopy that subsequently ensures the update is properly ordered and forwarded.\nIn replicated-write protocols, an update is forwarded to several replicas at the\nsame time. In that case, correctly ordering operations often becomes more\ndifficult.\nWe pay separate attention to caching and replication in the Web and,\nrelated, content delivery networks. As it turns out, using existing servers and\nservices, much of the techniques discussed before can be readily implemented\nusing appropriate redirection techniques. Particularly challenging is caching\ncontent when databases are involved, as in those cases, much of what a\nWeb server returns is dynamically generated. However, even in those cases,\nby carefully administrating what has already been cached at the edge, it is\npossible to invent highly efficient and effective caching schemes.\nDS 4.01\n \n",
      "content_length": 889,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 477,
      "content": "08\nFAULT\nTOLERANCE\n",
      "content_length": 19,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 478,
      "content": "462\nCHAPTER 8. FAULT TOLERANCE\nA characteristic feature of distributed systems that distinguishes them from\nsingle-machine systems is the notion of partial failure: part of the system is\nfailing while the remaining part continues to operate, and seemingly correctly.\nAn important goal in distributed-systems design is to construct the system\nin such a way that it can automatically recover from partial failures without\nseriously affecting the overall performance. In particular, whenever a failure\noccurs, the system should continue to operate in an acceptable way while\nrepairs are being made. In other words, a distributed system is expected to be\nfault tolerant.\nIn this chapter, we take a closer look at techniques to achieve fault toler-\nance. After providing some general background, we will first look at process\nresilience through process groups. In this case, multiple identical processes\ncooperate, providing the appearance of a single logical process, to ensure that\none or more of them can fail without a client noticing. A specifically difficult\npoint in process groups is reaching consensus among the group members\non which a client-requested operation is to perform. By now, Paxos is a\ncommonly adopted, yet relatively intricate algorithm. We take two approaches\nin explaining Paxos. One that builds on how the protocol can be logically\nviewed as it is now, and one that gradually builds it up from scratch. The latter\nmay help to understand many of its design decisions. We also pay extensive\nattention to the case in which servers may not just crash, but actually produce\nfaulty results that cannot be immediately recognized as being faulty.\nAchieving fault tolerance and reliable communication are strongly related.\nNext to reliable client-server communication, we pay attention to reliable\ngroup communication and notably atomic multicasting. In the latter case,\na message is delivered to all nonfaulty processes in a group, or to none.\nHaving atomic multicasting makes development of fault-tolerant solutions\nmuch easier.\nAtomicity is a property that is important in many applications. In this\nchapter, we look into what are known as distributed commit protocols by\nwhich a group of processes is conducted to either jointly commit their local\nwork, or collectively abort and return to a previous system state.\nFinally, we will examine how to recover from a failure. In particular, we\nconsider when and how the state of a distributed system should be saved to\nallow recovery to that state later on.\n8.1\nIntroduction to fault tolerance\nFault tolerance has been subject to much research in computer science. In\nthis section, we start with presenting the basic concepts related to processing\nfailures, followed by a discussion of failure models. The key technique for\nhandling failures is redundancy, which is also discussed. For more general\nDS 4.01\n \n",
      "content_length": 2870,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 479,
      "content": "8.1. INTRODUCTION TO FAULT TOLERANCE\n463\ninformation on fault tolerance in distributed systems, see, for example Jalote\n[1994]; Shooman [2002] or Koren and Krishna [2007].\n8.1.1\nBasic concepts\nTo understand the role of fault tolerance in distributed systems, we first need\nto take a closer look at what it actually means for a distributed system to\ntolerate faults. Being fault tolerant is strongly related to what are called\ndependable systems. Dependability is a term that covers a number of useful\nrequirements for distributed systems, including the following [Kopetz and\nVerissimo, 1993]:\n• Availability\n• Reliability\n• Safety\n• Maintainability\nAvailability is defined as the property that a system is ready to be used\nimmediately. In general, it refers to the probability that the system is operating\ncorrectly at any given moment, and is available to perform its functions on\nbehalf of its users. In other words, a highly available system is one that will\nmost likely be working at a given instant in time.\nReliability refers to the property that a system can run continuously without\nfailure. In contrast to availability, reliability is defined in terms of a time\ninterval, instead of an instant in time. A highly reliable system is one that will\nmost likely continue to work without interruption during a relatively long\nperiod of time. This is a subtle but important difference when compared to\navailability. If a system goes down on average for one, seemingly random\nmillisecond every hour, it has an availability of more than 99.9999 percent,\nbut is still unreliable. Similarly, a system that never crashes but is shut down\nfor two specific weeks every August, has high reliability but only 96 percent\navailability. The two are not the same.\nSafety refers to the situation that when a system temporarily fails to\noperate correctly, no catastrophic event happens. For example, many process-\ncontrol systems, such as those used for controlling nuclear power plants or\nsending people into space, are required to provide a high degree of safety. If\nsuch control systems temporarily fail for only a very brief moment, the effects\ncould be disastrous. Many examples from the past (and probably many more\nyet to come) show how hard it is to build safe systems.\nFinally, maintainability refers to how easily a failed system can be repaired.\nA highly maintainable system may also show a high degree of availability,\nespecially if failures can be detected and repaired automatically. However,\nas we shall see later in this chapter, automatically recovering from failures is\neasier said than done.\n \nDS 4.01\n",
      "content_length": 2608,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 480,
      "content": "464\nCHAPTER 8. FAULT TOLERANCE\nNote 8.1 (More information: Traditional metrics)\nWe can be a bit more precise when it comes to describing availability and reliability.\nFormally, the availability A(t) of a component in the time interval [0, t) is defined\nas the average fraction of time that the component has been functioning correctly\nduring that interval. The long-term availability A of a component is defined as\nA(∞).\nLikewise, the reliability R(t) of a component in the time interval [0, t) is\nformally defined as the conditional probability that it has been functioning cor-\nrectly during that interval, given that it was functioning correctly at time T = 0.\nFollowing Pradhan [1996], to establish R(t) we consider a system of N identical\ncomponents. Let N0(t) denote the number of correctly operating components at\ntime t and N1(t) the number of failed components. Then, clearly,\nR(t) = N0(t)\nN\n= 1 −N1(t)\nN\n=\nN0(t)\nN0(t) + N1(t)\nThe rate at which components are failing can be expressed as the derivative\ndN1(t)/dt. Dividing this by the number of correctly operating components at\ntime t gives us the failure rate function z(t):\nz(t) =\n1\nN0(t)\ndN1(t)\ndt\nFrom\ndR(t)\ndt\n= −1\nN\ndN1(t)\ndt\nit follows that\nz(t) =\n1\nN0(t)\ndN1(t)\ndt\n= −\nN\nN0(t)\ndR(t)\ndt\n= −\n1\nR(t)\ndR(t)\ndt\nIf we make the simplifying assumption that a component does not age (and thus\nessentially has no wear-out phase), its failure rate will be constant, i.e., z(t) = z,\nimplying that\ndR(t)\ndt\n= −zR(t)\nBecause R(0) = 1, we obtain\nR(t) = e−zt\nIn other words, if we ignore aging of a component, we see that a constant failure\nrate leads to a reliability following an exponential distribution, having the form\nshown in Figure 8.1.\nDS 4.01\n \n",
      "content_length": 1707,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 481,
      "content": "8.1. INTRODUCTION TO FAULT TOLERANCE\n465\nFigure 8.1: The reliability of a component having a constant failure rate.\nTraditionally, fault-tolerance has been related to the following three metrics:\n• Mean Time To Failure (MTTF): The average time until a component fails.\n• Mean Time To Repair (MTTR): The average time needed to repair a\ncomponent.\n• Mean Time Between Failures (MTBF): Simply MTTF + MTTR.\nNote that\nA = MTTF\nMTBF =\nMTTF\nMTTF + MTTR\nAlso, these metrics make sense only if we have an accurate notion of what a failure\nactually is. As we will encounter later, identifying the occurrence of a failure may\nactually not be so obvious.\nOften, dependable systems are also required to provide a high degree of\nsecurity, especially when it comes to issues such as integrity. We will discuss\nsecurity extensively in the next chapter.\nA system is said to fail when it does not meet its promises. In particular,\nif a distributed system is designed to provide its users with a number of\nservices, the system has failed when one or more of those services cannot be\n(completely) provided. An error is a part of a system’s state that may lead\nto a failure. For example, when transmitting packets across a network, it is\nto be expected that some packets have been damaged when they arrive at\nthe receiver. Damaged in this context means that the receiver may incorrectly\nsense a bit value (e.g., reading a 1 instead of a 0), or may even be unable to\ndetect that something has arrived.\nThe cause of an error is called a fault. Clearly, finding out what caused an\nerror is important. For example, a wrong or bad transmission medium may\neasily cause packets to be damaged. In this case, it is relatively easy to remove\nthe fault. However, transmission errors may also be caused by bad weather\nconditions, such as in wireless networks. Changing the weather to reduce or\nprevent errors is a bit trickier.\nAs another example, a crashed program is clearly a failure, which may\nhave happened because the program entered a branch of code containing\na programming bug (i.e., a programming error). The cause of that bug is\n \nDS 4.01\n",
      "content_length": 2117,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 482,
      "content": "466\nCHAPTER 8. FAULT TOLERANCE\ntypically a programmer. In other words, the programmer is the cause of the\nerror (programming bug), in turn leading to a failure (a crashed program).\nBuilding dependable systems closely relates to controlling faults.\nAs\nexplained by Avizienis et al. [2004], a distinction can be made between pre-\nventing, tolerating, removing, and forecasting faults. For our purposes, the\nmost important issue is fault tolerance, meaning that a system can provide\nits services even in the presence of faults. For example, by applying error-\ncorrecting codes for transmitting packets, it is possible to tolerate, to a certain\nextent, relatively poor transmission lines and reducing the probability that an\nerror (a damaged packet) may lead to a failure.\nFaults are generally classified as transient, intermittent, or permanent.\nTransient faults occur once and then disappear. If the operation is repeated,\nthe fault goes away. A bird flying through the beam of a microwave transmitter\nmay cause lost bits on some network. If the transmission times out and is\nretried, it will probably work the second time.\nAn intermittent fault occurs, then vanishes of its own accord, then reap-\npears, and so on. A loose contact on a connector will often cause an inter-\nmittent fault. Intermittent faults cause a great deal of aggravation because\nthey are difficult to diagnose. Typically, when the fault doctor shows up, the\nsystem works fine.\nA permanent fault is one that continues to exist until the faulty compo-\nnent is replaced. Burnt-out chips, software bugs, and disk-head crashes are\nexamples of permanent faults.\n8.1.2\nFailure models\nA system that fails is not adequately providing the services it was designed for.\nIf we consider a distributed system as a collection of servers that communicate\nwith one another and with their clients, not adequately providing services\nmeans that servers, communication channels, or possibly both, are not doing\nwhat they are supposed to do. However, a malfunctioning server itself may\nnot always be the fault we are looking for. If such a server depends on other\nservers to adequately provide its services, the cause of an error may need to\nbe searched for somewhere else.\nSuch dependency relations appear in abundance in distributed systems. A\nfailing disk may make life difficult for a file server that is designed to provide\na highly available file system. If such a file server is part of a distributed\ndatabase, the proper working of the entire database may be at stake, as only\npart of its data may be accessible.\nTo get a better grasp on how serious a failure actually is, several classifica-\ntion schemes have been developed. One such scheme is shown in Figure 8.2,\nand is based on schemes described by Cristian [1991] and Hadzilacos and\nToueg [1993].\nDS 4.01\n \n",
      "content_length": 2819,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 483,
      "content": "8.1. INTRODUCTION TO FAULT TOLERANCE\n467\nType of failure\nDescription of server’s behavior\nCrash failure\nHalts, but is working correctly until it halts\nOmission failure\nFails to respond to incoming requests\nReceive omission\nFails to receive incoming messages\nSend omission\nFails to send messages\nTiming failure\nResponse lies outside a specified time interval\nResponse failure\nResponse is incorrect\nValue failure\nThe value of the response is wrong\nState-transition failure\nDeviates from the correct flow of control\nArbitrary failure\nMay produce arbitrary responses at arbitrary times\nFigure 8.2: Different types of failures.\nA crash failure occurs when a server prematurely halts, but was working\ncorrectly until it stopped. An important aspect of crash failures is that once\nthe server has halted, nothing is heard from it anymore. A typical example of\na crash failure is an operating system that comes to a grinding halt, and for\nwhich there is only one solution: reboot it. Many personal computer systems\n(be they desktop computers or laptops) suffer from crash failures so often that\npeople have come to expect them to be normal. Consequently, moving the\nreset button, for example, from the back of a cabinet to the front was done\nfor good reason. Perhaps one day it can be moved to the back again, or even\nremoved altogether.\nAn omission failure occurs when a server fails to respond to a request.\nSeveral things might go wrong. In the case of a receive-omission failure,\npossibly the server never got the request in the first place. Note that it may\nwell be the case that the connection between a client and a server has been\ncorrectly established, but that there was no thread listening for incoming\nrequests. Also, a receive-omission failure will generally not affect the current\nstate of the server, as the server is unaware of any message sent to it.\nLikewise, a send-omission failure happens when the server has done its\nwork, but somehow fails in sending a response. Such a failure may happen,\nfor example, when a send buffer overflows while the server was not prepared\nfor such a situation. Note that, in contrast to a receive-omission failure, the\nserver may now be in a state reflecting that it has just completed a service for\nthe client. As a consequence, if the sending of its response fails, the server has\nto be prepared for the client to reissue its previous request.\nOther types of omission failures not related to communication may be\ncaused by software errors such as infinite loops or improper memory manage-\nment, by which the server is said to “hang.”\nAnother class of failures is related to timing. Timing failures occur when\nthe response lies outside a specified real-time interval. For example, in the\ncase of streaming videos, providing data too soon may easily cause trouble for\na recipient if there is not enough buffer space to hold all the incoming data.\n \nDS 4.01\n",
      "content_length": 2898,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 484,
      "content": "468\nCHAPTER 8. FAULT TOLERANCE\nMore common, however, is that a server responds too late, in which case a\nperformance failure is said to occur.\nA serious type of failure is a response failure, by which the server’s\nresponse is simply incorrect. Two kinds of response failures may happen.\nIn the case of a value failure, a server simply provides the wrong reply to a\nrequest. For example, a search engine that systematically returns Web pages\nnot related to any of the search terms used, has failed.\nThe other type of response failure is known as a state-transition failure.\nThis kind of failure happens when the server reacts unexpectedly to an\nincoming request. For example, if a server receives a message it cannot\nrecognize, a state-transition failure happens if no measures have been taken\nto handle such messages. In particular, a faulty server may incorrectly take\ndefault actions it should never have initiated.\nThe most serious are arbitrary failures, also known as Byzantine failures.\nIn effect, when arbitrary failures occur, clients should be prepared for the\nworst. In particular, a server may be producing output it should never have\nproduced, but which cannot be detected as being incorrect. Byzantine failures\nwere first analyzed by Pease et al. [1980] and Lamport et al. [1982]. We return\nto such failures below.\nNote 8.2 (More information: Omission and commission failures)\nIt has become somewhat of a habit to associate the occurrence of Byzantine\nfailures with maliciously operating processes. The term “Byzantine” refers to the\nByzantine Empire, a time (330–1453) and place (the Balkans and modern Turkey)\nin which endless conspiracies, intrigue, and untruthfulness were alleged to be\ncommon in ruling circles.\nHowever, it may not be possible to detect whether an act was actually benign or\nmalicious. Is a networked computer running a poorly engineered operating system\nthat adversely affects the performance of other computers acting maliciously? In\nthis sense, it is better to make the following distinction, which effectively excludes\njudgment:\n• An omission failure occurs when a component fails to take an action that\nit should have taken.\n• A commission failure occurs when a component takes an action that it\nshould not have taken.\nThis difference, introduced by Mohan et al. [1983], also illustrates that a separation\nbetween dependability and security may at times be pretty difficult to make.\nMany of the aforementioned cases deal with the situation that a process\nP no longer perceives any actions from another process Q. However, can P\nconclude that Q has indeed come to a halt? To answer this question, we need\nto make a distinction between two types of distributed systems:\nDS 4.01\n \n",
      "content_length": 2718,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 485,
      "content": "8.1. INTRODUCTION TO FAULT TOLERANCE\n469\n• In an asynchronous system, no assumptions about process execution\nspeeds or message delivery times are made. The consequence is that\nwhen process P no longer perceives any actions from Q, it cannot\nconclude that Q crashed. Instead, it may just be slow, or its messages\nmay have been lost.\n• In a synchronous system, process execution speeds and message-delivery\ntimes are bounded. This also means that when Q shows no more activity\nwhen it is expected to do so, process P can rightfully conclude that Q\nhas crashed.\nUnfortunately, pure synchronous systems exist only in theory. On the other\nhand, simply stating that every distributed system is asynchronous also does\nnot do justice to what we see in practice, and we would be overly pessimistic in\ndesigning distributed systems under the assumption that they are necessarily\nasynchronous. Instead, it is more realistic to assume that a distributed system\nis partially synchronous: most of the time it behaves as a synchronous system,\nyet there is no bound on the time that it behaves in an asynchronous fashion.\nIn other words, asynchronous behavior is an exception, meaning that we can\nnormally use timeouts to conclude that a process has indeed crashed, but that\noccasionally such a conclusion is false. In practice, this means that we will\nhave to design fault-tolerant solutions that can withstand incorrectly detecting\nthat a process halted.\nIn this context, halting failures can be classified as follows, from the least\nto the most severe (see also Cachin et al. [2011]). We let process P attempt to\ndetect that process Q has failed.\n• Fail-stop failures refer to crash failures that can be reliably detected.\nThis may occur when assuming nonfaulty communication links and\nwhen the failure-detecting process P can place a worst-case delay on\nresponses from Q.\n• Fail-noisy failures are like fail-stop failures, except that P will only\neventually come to the correct conclusion that Q has crashed. This means\nthat there may be some a priori unknown time in which P’s detections\nof the behavior of Q are unreliable.\n• When dealing with fail-silent failures, we assume that communication\nlinks are nonfaulty, but that process P cannot distinguish crash failures\nfrom omission failures.\n• Fail-safe failures cover the case of dealing with arbitrary failures by\nprocess Q, yet these failures are benign: they cannot do any harm.\n• Finally, when dealing with fail-arbitrary failures, Q may fail in any\npossible way; failures may be unobservable in addition to being harmful\nto the otherwise correct behavior of other processes.\n \nDS 4.01\n",
      "content_length": 2632,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 486,
      "content": "470\nCHAPTER 8. FAULT TOLERANCE\nClearly, having to deal with fail-arbitrary failures is the worst that can happen.\nAs we shall discuss shortly, we can design distributed systems in such a way\nthat they can even tolerate these types of failures.\n8.1.3\nFailure masking by redundancy\nIf a system is to be fault tolerant, the best it can do is to try to hide the\noccurrence of failures from other processes. The key technique for masking\nfaults is to use redundancy. Three kinds are possible: information redundancy,\ntime redundancy, and physical redundancy (see also Johnson [1995]). With\ninformation redundancy, extra bits are added to allow recovery from garbled\nbits. For example, a Hamming code can be added to transmitted data to\nrecover from noise on the transmission line.\nWith time redundancy, an action is performed, and then, if need be, it is\nperformed again. Transactions use this approach. If a transaction aborts, it\ncan be redone with no harm because nothing has yet been finalized. Another\nwell-known example is retransmitting a request to a server when lacking an\nexpected response. Time redundancy is especially helpful when the faults are\ntransient or intermittent.\nWith physical redundancy, extra equipment or processes are added to\nmake it possible for the system as a whole to tolerate the loss or malfunction-\ning of some components. Physical redundancy can thus be done either in\nhardware or in software. For example, extra processes can be added to the\nsystem, so that if a few of them crash, the system can still function correctly. In\nother words, by replicating processes, a high degree of fault tolerance may be\nachieved. We return to this type of software redundancy later in this chapter.\nNote 8.3 (More information: Triple modular redundancy)\nIt is illustrative to see how redundancy has been applied in the design of electronic\ndevices. Consider, for example, the circuit of Figure 8.3(a). Here signals pass\nthrough devices A, B, and C, in sequence. If one of them is faulty, the final result\nwill probably be incorrect.\nIn Figure 8.3(b), each device is replicated three times. Following each stage\nin the circuit is a triplicated voter. Each voter is a circuit that has three inputs\nand one output. If two or three of the inputs are the same, the output is equal to\nthat input. If all three inputs are different, the output is undefined. This kind of\ndesign is known as triple modular redundancy (TMR).\nSuppose that element A2 fails. Each of the voters, V1, V2, and V3 gets two\ngood (identical) inputs and one rogue input, and each of them outputs the correct\nvalue to the second stage. In essence, the effect of A2 failing is completely masked\nso that the inputs to B1, B2, and B3 are the same as they would have been had no\nfault occurred.\nDS 4.01\n \n",
      "content_length": 2782,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 487,
      "content": "8.2. PROCESS RESILIENCE\n471\n(a)\n(b)\nFigure 8.3: Triple modular redundancy.\nNow consider what happens if B3 and C1 are also faulty, in addition to A2.\nThese effects are also masked, so the three final outputs are still correct.\nAt first, it may not be obvious why three voters are needed at each stage.\nAfter all, one voter could also detect and pass the majority view. However, a\nvoter is also a component and can be faulty. Suppose, for example, that voter\nV1 malfunctions. The input to B1 will then be wrong, but as long as everything\nelse works, B2 and B3 will produce the same output and V4, V5, and V6 will all\nproduce the correct result into stage three. A fault in V1 is effectively no different\nfrom a fault in B1. In both cases B1 produces incorrect output, but in both cases,\nit is voted down later, and the final result is still correct.\nAlthough not all fault-tolerant distributed systems use TMR, the technique is\nvery general, and should give a clear feeling for what a fault-tolerant system is, as\nopposed to a system whose individual components are highly reliable but whose\norganization cannot tolerate faults (i.e., operate correctly even in the presence of\nfaulty components). Of course, TMR can be applied recursively, for example, to\nmake a chip highly reliable by using TMR inside it, unknown to the designers\nwho use the chip, possibly in their own circuit containing multiple copies of the\nchips along with voters.\n8.2\nProcess resilience\nNow that the basic issues of fault tolerance have been discussed, let us\nconcentrate on how fault tolerance can actually be achieved in distributed\nsystems. The first topic we discuss is protection against process failures,\nwhich is achieved by replicating processes into groups. In the following pages,\nwe consider the general design issues of process groups and discuss what\na fault-tolerant group actually is. Also, we look at how to reach consensus\nwithin a process group when one or more of its members cannot be trusted to\ngive correct answers.\n \nDS 4.01\n",
      "content_length": 2023,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 488,
      "content": "472\nCHAPTER 8. FAULT TOLERANCE\n8.2.1\nResilience by process groups\nThe key approach to tolerating a faulty process is to organize several identical\nprocesses into a group. The key property that all groups have is that when a\nmessage is sent to the group itself, all members of the group receive it. In this\nway, if one process in a group fails, hopefully some other process can take\nover for it [Guerraoui and Schiper, 1997].\nProcess groups may be dynamic. New groups can be created, and old\ngroups can be destroyed. A process can join a group or leave one during\nsystem operation. A process can be a member of several groups at the same\ntime. Consequently, mechanisms are required for managing groups and group\nmembership.\nThe purpose of introducing groups is to allow a process to deal with\ncollections of other processes as a single abstraction. Thus, a process P can\nsend a message to a group Q = {Q1, . . . , QN} of servers without having to\nknow who they are, how many there are, or where they are, which may\nchange from one call to the next. To P, the group Q appears to be a single,\nlogical process.\nGroup organization\nAn important distinction between different groups has to do with their internal\nstructure. In some groups, all processes are equal, i.e., we have a flat group.\nThere is no distinctive leader and all decisions are made collectively. Typically,\nmany peer-to-peer systems operate in this way. An alternative organization\nis that of a hierarchical group. For example, one process is the coordinator\nand all the others are workers. In this model, when a request for work is\ngenerated, either by an external client or by one of the workers, it is sent to\nthe coordinator. The coordinator then decides which worker is best suited to\ncarry it out, and forwards it there. More complex hierarchies are also possible,\nof course. The Domain Name System can be argued to operate as a (indeed,\nquite complex) hierarchical group. Simpler organizations include primary-\nbased backup schemes, as we discussed in Section 7.5.1. These communication\npatterns within groups are illustrated in Figure 8.4.\nEach of these organizations has its own advantages and disadvantages.\nThe flat group is symmetrical and has no single point of failure. If one of\nthe processes crashes, the group simply becomes smaller, but can otherwise\ncontinue. A disadvantage is that decision-making may be more complicated.\nFor example, to decide anything, a vote often has to be taken, incurring some\ndelay and overhead.\nThe hierarchical group has the opposite properties. Loss of the coordinator\nbrings the entire group to a grinding halt, but as long as it is running, it\ncan make decisions without bothering everyone else. In practice, when the\ncoordinator in a hierarchical group fails, its role will need to be taken over and\nDS 4.01\n \n",
      "content_length": 2823,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 489,
      "content": "8.2. PROCESS RESILIENCE\n473\n(a)\n(b)\nFigure 8.4: Communication in a (a) flat group and in a (b) hierarchical group.\none of the workers is elected as new coordinator. We discussed leader-election\nalgorithms in Section 5.4.\nMembership management\nWhen group communication is present, some method is required for creating\nand deleting groups, as well as for allowing processes to join and leave groups.\nOne possible approach is to have a group server to which all these requests\ncan be sent. The group server can then maintain a complete database of all the\ngroups and their exact membership. This method is straightforward, efficient,\nand fairly easy to implement. Unfortunately, it shares a major disadvantage\nwith many (physically) centralized solutions: a single point of failure. If the\ngroup server crashes, group management ceases to exist. Probably most or\nall groups will have to be reconstructed from scratch, possibly terminating\nwhatever work was going on.\nThe opposite approach is to manage group membership in a distributed\nway. For example, if (reliable) multicasting is available, an outsider can send a\nmessage to all group members announcing its wish to join the group.\nIdeally, to leave a group, a member just sends a goodbye message to\neveryone. In the context of fault tolerance, assuming fail-stop failure semantics,\nis generally not appropriate. The trouble is, there is no polite announcement\nthat a process crashes, as there is when a process leaves voluntarily. The other\nmembers have to discover this experimentally by noticing that the crashed\nmember no longer responds to anything. Once it is certain that the crashed\nmember is really down (and not just slow), it can be removed from the group.\nAnother knotty issue is that leaving and joining have to be synchronous\nwith data messages being sent. In other words, starting at the instant that a\nprocess has joined a group, it must receive all messages sent to that group.\n \nDS 4.01\n",
      "content_length": 1956,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 490,
      "content": "474\nCHAPTER 8. FAULT TOLERANCE\nSimilarly, as soon as a process has left a group, it must not receive any more\nmessages from the group, and the other members must not receive any more\nmessages from it. One way of making sure that a join or leave is integrated\ninto the message stream at the right place is to convert this operation into a\nsequence of messages sent to the whole group.\nOne final issue relating to group membership is what to do if so many\nprocesses go down that the group can no longer function at all. Some protocol\nis needed to rebuild the group. Invariably, some process will have to take the\ninitiative to start the ball rolling, but what happens if two or three try at the\nsame time? The protocol must be able to withstand this. Again, coordination\nthrough, for example, a leader-election algorithm may be needed.\n8.2.2\nFailure masking and replication\nProcess groups are part of the solution for building fault-tolerant systems.\nIn particular, having a group of identical processes allows us to mask one\nor more faulty processes in that group. In other words, we can replicate\nprocesses and organize them into a group to replace a single (vulnerable)\nprocess with a (fault tolerant) group. As discussed in the previous chapter,\nthere are two ways to approach such replication: by means of primary-based\nprotocols, or through replicated-write protocols.\nPrimary-based replication in the case of fault tolerance generally appears\nin the form of a primary-backup protocol. In this case, a group of processes\nis organized in a hierarchical fashion, in which a primary coordinates all write\noperations. In practice, the primary is fixed, although its role can be taken\nover by one of the backups if need be. In effect, when the primary crashes,\nthe backups execute some election algorithm to choose a new primary.\nReplicated-write protocols are used in the form of active replication, as\nwell as by quorum-based protocols. These solutions correspond to organizing\na collection of identical processes into a flat group. The main advantage is\nthat such groups have no single point of failure, at the cost of distributed\ncoordination.\nAn important issue with using process groups to tolerate faults is how\nmuch replication is needed.\nTo simplify our discussion, let us consider\nonly replicated-write systems. A system is said to be k-fault tolerant if it\ncan survive faults in k components and still meet its specifications. If the\ncomponents, say processes, fail silently, then having k + 1 of them is enough\nto provide k-fault tolerance. If k of them simply stop, then the answer from\nthe other one can be used.\nOn the other hand, if processes exhibit arbitrary failures, continuing to\nrun when faulty and sending out erroneous or random replies, a minimum of\n2k + 1 processes is needed to achieve k-fault tolerance. In the worst case, the k\nfailing processes could accidentally (or even intentionally) generate the same\nDS 4.01\n \n",
      "content_length": 2945,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 491,
      "content": "8.2. PROCESS RESILIENCE\n475\nreply. However, the remaining k + 1 will also produce the same answer, so\nthe client or voter can just believe the majority.\nNow suppose that in a k-fault tolerant group, a single process fails. The\ngroup as a whole is still living up to its specifications, namely that it can\ntolerate the failure of up to k of its members (of which one has just failed). But\nwhat happens if more than k members fail? In that case, all bets are off and\nwhatever the group does, its results, if any, cannot be trusted. Another way of\nlooking at this is that the process group, in its appearance of mimicking the\nbehavior of a single, robust process, has failed.\n8.2.3\nConsensus in faulty systems with crash failures\nAs mentioned, in terms of clients and servers, we have adopted a model in\nwhich a potentially considerable collection of clients now send commands to\na group of processes that jointly behave as a single, highly robust process. To make\nthis work, we need to make an important assumption:\nIn a fault-tolerant process group, each nonfaulty process executes the\nsame commands, in the same order, as every other nonfaulty process.\nFormally, this means that the group members need to reach consensus on\nwhich command to execute. If failures cannot happen, reaching consensus\nis easy. For example, we can use Lamport’s totally ordered multicasting, as\ndescribed in Section 5.2.1. Or, to keep it simple, using a centralized sequencer\nthat hands out a sequence number to each command that needs to be executed\nwill do the job as well. Unfortunately, life is not without failures, and reaching\nconsensus among a group of processes under more realistic assumptions turns\nout to be tricky.\nFlooding-based consensus\nTo illustrate the problem at hand, let us assume we have a group of processes\nP = {P1, . . . , Pn} operating under fail-stop failure semantics. In other words,\nwe assume that crash failures can be reliably detected among the group\nmembers. Typically, a client contacts a group member requesting it to execute\na command. Every group member maintains a list of proposed commands:\nsome which it received directly from clients; others which it received from its\nfellow group members. We can reach consensus using the following approach,\nadopted from Cachin et al. [2011], and referred to as flooding consensus.\nConceptually, the algorithm operates in rounds. In each round, a process Pi\nsends its list of proposed commands it has seen so far to every other process\nin P. At the end of a round, each process merges all received proposed\ncommands into a new list, from which it then will deterministically select the\ncommand to execute, if possible. It is important to realize that the selection\nalgorithm is the same for all processes. In other words, if all process have the\n \nDS 4.01\n",
      "content_length": 2811,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 492,
      "content": "476\nCHAPTER 8. FAULT TOLERANCE\nsame list, they will all select the same command to execute (and remove that\ncommand from their list).\nIt is not difficult to see that this approach works as long as processes do\nnot fail. Problems start when a process Pi detects, during round r, that, say,\nprocess Pk has crashed. To make this concrete, assume we have a process\ngroup of four processes {P1, . . . , P4} and that P1 crashes during round r.\nAlso, assume that P2 receives the list of proposed commands from P1 before\nit crashes, but that P3 and P4 do not (in other words, P1 crashes before it got\na chance to send its list to P3 and P4). This situation is sketched in Figure 8.5.\nFigure 8.5: Reaching consensus through flooding in the presence of crash\nfailures. Adopted from Cachin et al. [2011].\nAssuming that all processes knew who was a group member at the begin-\nning of round r, P2 is ready to decide on which command to execute when\nit receives the respective lists of the other members: it has all commands\nproposed so far. Not so for P3 and P4. For example, P3 may detect that P1\ncrashed, but it does not know if either P2 or P4 had already received P1’s\nlist. From P3’s perspective, if there is another process that did receive P1’s\nproposed commands, that process may then make a different decision than\nitself. As a consequence, the best that P3 can do is postpone its decision\nuntil the next round. The same holds for P4 in this example. A process will\ndecide to move to a next round when it has received a message from every\nnonfaulty process. This assumes that each process can reliably detect the\ncrashing of another process, for otherwise it would not be able to decide who\nthe nonfaulty processes are.\nBecause process P2 received all commands, it can indeed decide and can\nsubsequently broadcast that decision to the others. Then, during the next\nround r + 1, processes P3 and P4 will also be able to decide: they will decide\nto execute the same command selected by P2.\nTo understand why this algorithm is correct, it is important to realize that\na process will move to a next round without having made a decision, only\nwhen it detects that another process has failed. In the end, this means that in\nthe worst case at most one nonfaulty process remains, and this process can\nDS 4.01\n \n",
      "content_length": 2299,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 493,
      "content": "8.2. PROCESS RESILIENCE\n477\nsimply decide whatever proposed command to execute. Again, note that we\nare assuming reliable failure detection.\nBut then, what happens when the decision by process P2 that it sent to P3\nwas lost? In that case, P3 can still not make a decision. Worse, we need to\nmake sure that it makes the same decision as P2 and P4. If P2 did not crash,\nwe can assume that a retransmission of its decision will save the day. If P2 did\ncrash, this will also be detected by P4 who will then subsequently rebroadcast\nits decision. Meanwhile, P3 has moved to a next round, and after receiving\nthe decision by P4, will terminate its execution of the algorithm.\nA more realistic approach: Raft\nLet us now take a look at a consensus protocol that operates under crash-\nfailure semantics, or actually, a fail-noisy failure model: a process will even-\ntually correctly conclude that another process has crashed. Raft, described\nby Ongaro and Ousterhout [2014] was developed in reaction to the inherent\nintricacies of a famous consensus protocol, Paxos (which we discuss further\nbelow). In this section, we will stick to the essence of Raft, thereby even\nsimplifying a few matters to focus entirely on understanding how and why it\nworks.\nIn Raft, we typically have a group of some five replicated servers. We\nassume the set of servers is fixed (although Raft allows servers to join and\nleave the group). Each server maintains a log of operations, some of which\nhave already been executed (i.e., committed), as well as pending operations.\nConsensus is expressed in terms of these logs: committed operations have\nthe same position in each of the respective server’s logs. One of the servers\noperates as a leader and decides on the order in which pending operations\nare to be committed. In essence, Raft is a primary-backup protocol, with the\nprimary acting as leader and the backups as followers. We discussed Raft’s\nleader-election algorithm in Section 5.4.4.\nA client always sends an operation request to the leader (possibly after\nhaving been redirected by one of the followers). That means that the leader\nis fully aware of all pending requests. Each client request for executing\nan operation o is appended to the leader’s log, in the form of a tuple ⟨o,\nt, k⟩in which t is the term under which the current leader serves, and k\nthe index of o in the leader’s log.\nTo recall, after electing a next leader,\nthe term for new operations will be t + 1. Let c be the index of the most\nrecently committed operation. Raft guarantees that operations that have been\nregistered as committed, have been performed by a majority of the servers,\nand that the result has been returned to the original client.\nAssume the leader has a log of length n, is operating in term t, and receives\na request for executing operation o. In that case, it appends ⟨o, t, n + 1⟩and\nconceptually sends its entire log to all the other servers, along with the current\nvalue of c. Again conceptually, each following server copies the entire log, and\n \nDS 4.01\n",
      "content_length": 3030,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 494,
      "content": "478\nCHAPTER 8. FAULT TOLERANCE\nreturns an acknowledgement to the leader, while ensuring that all operations\nup to and including index c have been executed. Note that operation o cannot\nyet be committed by a follower.\nAs soon as the leader receives a majority of acknowledgements, it executes\no, returns the result (if any, but at least an acknowledgement) to the client,\nand sets c to n + 1. The next time it communicates with the other servers,\nit also sends c so that each of them can commit operations, in particular,\no. It is important to note that in this scheme, the leader is indeed in full\ncontrol: its state (as expressed by its log), is to be seen as the collective\nstate of the server group. Of course, in reality, the leader will send only the\ntuple ⟨o, t, n + 1⟩, where it will be appended to the local log of the respective\nfollowers. In this sense, the protocol essentially follows the one described in\nSection 7.5.1 (except that clients always send a request to the primary, and\nnot through a follower). More important, however, is that by stating that the\nleader, conceptually speaking, sends the entire log, it overwrites the log of its\nfollowers. If the leader receives no acknowledgement from one of its followers,\nit will simply repeat sending the log until acknowledged.\nSuppose the leader crashes. In that case, a new one is elected as described\nin Section 5.4.4, and this new leader’s log is the collective state of the server\ngroup. There is only one problem: if that log misses committed operations,\nthen it is not representative for what the majority of servers has decided on.\nFor this reason, during an election, a server S will not vote for a candidate\nserver S′ if it turns out that S’s log is more up to date, than that of S′.\nOversimplifying matters somewhat, a log is more up to date when it contains\nmore committed operations (meaning that S′ has missed several commits\nalready done by a majority of other servers), or when it contains operations\nfrom more recent terms (meaning that S′ has missed elections). Assuming\nthat the new leader will have executed all the committed operations, its state\nwill therefore be the same as that of the previous leader before it crashed.\nHowever, do note that the new leader may not necessarily have received all\npending requests. From a consensus point of view, this is not a problem. To\navoid missing any client requests, Raft does assume that when a client does\nnot receive a response from the server, it will resubmit its original request.\nWhat if the leader crashed after executing o1 (because there was a majority\nof servers), yet did not have a chance to inform (all of) the other servers?\nFirst, note that the new leader will have a log that is at least a subset of the\nlogs of a majority of the remaining servers, in terms of committed operations\n(otherwise it would have never been elected as new leader). When handling a\nnew operation o2, broadcasting its log to the other servers, and receiving an\nacknowledgement from a majority, it can not only commit o2, but now also o1.\nThis situation is shown in Figure 8.6. First, note that server S5 will be brought\nup to date about operation o1 as soon as the new leader tells about o2. After\nreceiving enough acknowledgements, the leader can go ahead and commit o1\nDS 4.01\n \n",
      "content_length": 3302,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 495,
      "content": "8.2. PROCESS RESILIENCE\n479\nC2\nS5\nS4\nLEADER\nS3\nLEADER\nS2\nS1\nC1\n⟨o1⟩\n⟨APP, o1, 1, 1⟩\n⟨ACK, o1⟩\n⟨ACK, o1⟩\n⟨ACK, o1⟩\no1\n⟨o2⟩\n⟨APP, o2, 2, 2⟩\n⟨ACK, o2⟩\n⟨ACK, o2⟩\n⟨ACK, o2⟩\no1 o2\n⟨HB, 2⟩\no1\no1\no1\nFigure 8.6: The situation when a leader crashes after executing an operation\nbut before being able to tell other servers that the operation has been commit-\nted.\n(as well as o2). All other servers can commit o1 as soon as they know that the\nleader did so as well.\nWe have skipped a number of details, notably details related to the fact\nthat the leader does not send entire logs, but only operation requests. For\none, this means that after an election, servers may be missing operations, or\ncould have extraneous operations, or both. Bringing the logs of followers into\na consistent state with the new leader requires some attention, which can be\nignored by assuming that entire logs are sent. These, and other details, are\nfound in Ongaro and Ousterhout [2014] and Ongaro [2014].\n8.2.4\nExample: Paxos\nDiscussing consensus in the presence of crash failures cannot be decently done\nwithout discussing Paxos. It was originally published in 1989 as a technical\nreport by Leslie Lamport, but it took about a decade before someone decided\nthat it may not be such a bad idea to disseminate it through a regular scientific\nchannel [Lamport, 1998]. The original publication is not easy to understand,\nexemplified by other publications that aim at explaining it [Lampson, 1996;\nPrisco et al., 1997; Lamport, 2001; van Renesse and Altinbuken, 2015]. In\nfact, it is generally agreed that Paxos is not only quite difficult to explain and\nunderstand, but that these intricacies have led to implementations that actually\ndiffer from the original protocol.\nThese intricacies formed an important\nmotivation for developing Raft, which we explained above.\n \nDS 4.01\n",
      "content_length": 1839,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 496,
      "content": "480\nCHAPTER 8. FAULT TOLERANCE\nEssential Paxos\nThe assumptions under which Paxos operates are rather weak:\n• The distributed system is partially synchronous (in fact, it may even be\nasynchronous).\n• Communication between processes may be unreliable, meaning that\nmessages may be lost, duplicated, or reordered.\n• Messages that are corrupted can be detected as such (and thus subse-\nquently ignored).\n• All operations are deterministic: once an execution is started, it is known\nexactly what it will do.\n• Processes may exhibit crash failures, but not arbitrary failures, nor do\nprocesses collude.\nBy-and-large, these are realistic assumptions for many practical distributed\nsystems.\nWe first roughly follow the explanation given by Lamport [2001] and Kirsch\nand Amir [2008]. The algorithm operates as a network of logical processes, of\nwhich there are different types. First, there are clients that request a specific\noperation to be executed. At the server side, each client is represented by a\nsingle proposer, which attempts to have a client’s request accepted. Normally,\na single proposer has been designated as being the leader, and drives the\nprotocol toward reaching consensus.\nWhat we need to establish is that a proposed operation is accepted by an\nacceptor. If a majority of acceptors accepts the same proposal, the proposal is\nsaid to be chosen. However, what is chosen still needs to be learned. To this\nend, we will have a number of learner processes, each of which will execute a\nchosen proposal once it has been informed by a majority of acceptors.\nIt is important to note that a single proposer, acceptor, and learner form a\nsingle physical process, running on a single machine that the client commu-\nnicates with, as shown in Figure 8.7. We thus assume that if, for example, a\nproposer crashes, then the physical process that it is part of will have crashed.\nBy replicating this server, we aim at obtaining fault tolerance in the presence\nof crash failures.\nThe basic model is that the leading proposer receives requests from clients,\none at a time. A nonleading proposer forwards any client request to the leader.\nThe leading proposer sends its proposal to all acceptors, telling each to accept\nthe requested operation. Each acceptor will subsequently broadcast a learn\nmessage. If a learner receives the same learn message from a majority of\nacceptors, it knows that consensus has been reached on which operation to\nexecute, and will execute it.\nDS 4.01\n \n",
      "content_length": 2475,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 497,
      "content": "8.2. PROCESS RESILIENCE\n481\nFigure 8.7: The organization of Paxos into different logical processes.\nThere are at least two specific issues that need further attention. First, not\nonly do the servers need to reach consensus on which operation to execute,\nwe also need to make sure that each of them actually executes it. In other\nwords, how do we know for sure that a majority of the nonfaulty servers will\ncarry out the operation? There is essentially only one way out: have learn\nmessages be retransmitted. However, to make this work, an acceptor will have\nto log its decisions (in turn requiring a mechanism for purging logs). Because\nwe are assuming globally ordered proposal timestamps (as explained shortly),\nmissing messages can be easily detected, and also accepted operations will\nalways be executed in the same order by all learners.\nAs a general rule, the server hosting the leading proposer will also inform\nthe client when its requested operation has been executed. If another process\nhad taken over the lead, then it will also handle the response to the client.\nThis brings us to the second important issue: a failing leader. Life would\nbe easy if the failure of a leader would be reliably detected, after which a\nnew leader would be elected, and later, the recovering leader would instantly\nnotice that the world around it had changed. Unfortunately, life is not so easy.\nPaxos has been designed to tolerate proposers who still believe they are in the\nlead. The effect is that proposals may be sent out concurrently by different\nproposers (each believing to be the leader). We therefore need to make sure\nthat these proposals can be distinguished from one another to ensure that the\nacceptors handle only the proposals from the current leader.\nNote that relying on a leading proposer implies that any practical im-\nplementation of Paxos will need to be accompanied by a leader-election\nalgorithm. In principle, that algorithm can operate independently of Paxos,\nbut is normally part of it.\n \nDS 4.01\n",
      "content_length": 2014,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 498,
      "content": "482\nCHAPTER 8. FAULT TOLERANCE\nTo distinguish concurrent proposals from different proposers, each pro-\nposal p has a uniquely associated (logical) timestamp ts(p). How uniqueness\nis achieved is left to an implementation, but we will describe some of the\ndetails shortly. Let oper(p) denote the operation associated with proposal p.\nThe trick is to allow multiple proposals to be accepted, but that each of these\naccepted proposals has the same associated operation. This can be achieved\nby guaranteeing that if a proposal p is chosen, then any proposal with a higher\ntimestamp will also have the same associated operation. In other words, we\nrequire that\np is chosen ⇒for all p′ with ts(p′) > ts(p) : oper(p′) = oper(p)\nOf course, for p to be chosen, it needs to be accepted. That means that we\ncan guarantee our requirement when guaranteeing that if p is chosen, then\nany higher-timestamped proposal accepted by any acceptor, has the same\nassociated operation as p. However, this is not sufficient, for suppose that\nat a certain moment, a proposer simply sends a new proposal p′, with the\nhighest timestamp so far, to an acceptor A that had not received any proposal\nbefore. Note that this may indeed happen according to our assumptions\nconcerning message loss and multiple proposers, each believing to be in the\nlead. In absence of any other proposals, A will simply accept p′. To prevent\nthis situation from happening, we thus need to guarantee that\nIf proposal p is chosen, then any higher-timestamped proposal issued by a\nproposer, has the same associated operation as p.\nWhen explaining the Paxos algorithm below, we will indeed see that a pro-\nposer may need to adopt an operation coming from acceptors in favor of its\nown. This will happen after a leading proposer had failed, but its proposed\noperation had already made it to a majority of the acceptors.\nThe processes collectively formally ensure safety, in the sense that only\nproposed operations will be learned, and that at most one operation will be\nlearned at a time. In general, a safety property asserts that nothing bad will\nhappen. Furthermore, Paxos ensures conditional liveness in the sense that if\nenough processes remain up-and-running, then a proposed operation will\neventually be learned (and thus executed). Liveness, which tells us that\neventually something good will happen, is not guaranteed in Paxos, unless\nsome adaptations are made. We return to liveness in Note 8.4.\nThere are now two phases, each, in turn, consisting of two subphases.\nDuring the first phase, the leading proposer interacts with acceptors to get\na requested operation accepted for execution. The first phase is needed to\nrule out any trouble caused by different proposers, each believing they are\nthe leader. The best that can happen is that an individual acceptor promises\nto consider the proposer’s operation and ignore other requests. The worst is\nthat the proposer was too late and that it will be asked to adopt some other\nDS 4.01\n \n",
      "content_length": 2989,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 499,
      "content": "8.2. PROCESS RESILIENCE\n483\nproposer’s request instead. Apparently, a leadership change had taken place\nand there may be former requests that need to be handled first.\nIn the second phase, the acceptors will have informed proposers about the\npromises they have made. The leading proposer essentially takes up a slightly\ndifferent role by promoting a single operation to the one to be executed, and\nsubsequently telling the acceptors.\nPhase 1a (prepare): The goal of this phase is that a proposer P who believes\nit is the leader and is proposing operation o, tries to get its proposal\ntimestamp anchored, in the sense that any lower timestamp failed, or that\no had also been previously proposed (i.e., with some lower proposal\ntimestamp). To this end, P broadcasts its proposal to the acceptors.\nFor the operation o, the proposer selects a proposal number m higher\nthan any of its previously selected numbers. This leads to a proposal\ntimestamp t = (m, i) where i is the (numerical) process identifier of P.\nNote that\n(m, i) < (n, j) ⇔(m < n) or (m = n and i < j)\nThis timestamp for a proposal p is an implementation of the previously\nmentioned timestamp ts(p). Proposer P sends prepare(t) to all accep-\ntors (but note that messages may be lost). In doing so, it is (1) asking the\nacceptors to promise not to accept any proposals with a lower proposal\ntimestamp, and (2) to inform it about an accepted proposal, if any, with\nthe highest timestamp less than t. If such a proposal exists, the proposer\nwill adopt it.\nPhase 1b (promise): An acceptor A may receive multiple proposals. Assume\nit receives prepare(t) from P. There are three cases to consider:\n(1) t is the highest proposal timestamp received from any proposer so\nfar. In that case, A will return promise(t) to P stating that A will\nignore any future proposals with a lower timestamp.\n(2) If t is the highest timestamp so far, but another proposal (t′, o′) had\nalready been accepted, A also returns (t′, o′) to P. This will allow P\nto decide on the final operation that needs to be accepted.\n(3) In all other cases, do nothing: there is apparently another proposal\nwith a higher timestamp that is being processed.\nOnce the first phase has been completed, the leading proposer P knows what\nthe acceptors have promised. Essentially, the leading proposer knows that all\nacceptors have agreed on the same operation. This will put P into a position\nto tell the acceptors that they can go ahead. This is needed because although\nthe leading proposer knows on which operation consensus has been reached,\nthis consensus is not known to the others. Again, we assume that P received\n \nDS 4.01\n",
      "content_length": 2641,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 500,
      "content": "484\nCHAPTER 8. FAULT TOLERANCE\na response from a majority of acceptors (whose respective responses may be\ndifferent).\nPhase 2a (accept): There are two cases to consider:\n(1) If P does not receive any accepted operation from any of the ac-\nceptors, it will forward its own proposal for acceptance by sending\naccept(t, o) to all acceptors.\n(2) Otherwise, it was informed about another operation o′, which it will\nadopt and forward for acceptance. It does so by sending accept(t,\no′), where t is P’s proposal timestamp and o′ is the operation with\nproposal timestamp highest among all accepted operations that\nwere returned by the acceptors in Phase 1b.\nPhase 2b (learn): Finally, if an acceptor receives accept(t, o′), but did not\npreviously send a promise with a higher proposal timestamp, it will ac-\ncept operation o′, and tell all learners to execute o′ by sending learn(o′).\nAt that point, the acceptor can forget about o′. A learner L receiving\nlearn(o′) from a majority of acceptors, will execute the operation o′.\nWe now also know that a majority of learners share the same idea on\nwhich operation to execute.\nIt is important to realize that this description of Paxos indeed captures only its\nessence: using a leading proposer to drive the acceptors toward the execution\nof the same operation. When it comes to practical implementations, much\nmore needs to be done (and more than we are willing to describe here). An\nexcellent description of what it means to realize Paxos has been written by\nKirsch and Amir [2008]. Another write-up on its practical implications can be\nfound in [Chandra et al., 2007].\nUnderstanding Paxos\nTo properly understand Paxos, but also many other consensus algorithms, it\nis useful to see how its design could have evolved. We say “could have,” as\nthe evolution of the algorithm has never been documented. The following\ndescription is largely based on work described by Meling and Jehl [2013]1. As\nour starting point, we consider a server that we wish to make more robust. By\nnow, we know that this can be achieved through replication and making sure\nthat all commands submitted by clients are executed by all servers in the same\norder. The simplest situation is to add one server, thus creating a group of two\nprocesses, say S1 and S2. Also, to make sure that all commands are executed\nin the same order, we appoint one process to be a sequencer, which increments\nand associates a unique timestamp with every submitted command. Servers\n1Special credits go to Hein Meling for helping us better understand what Paxos is all about.\nDS 4.01\n \n",
      "content_length": 2573,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 501,
      "content": "8.2. PROCESS RESILIENCE\n485\nare required to execute commands according to their timestamp. In Paxos,\nsuch a server is referred to as the leader. We can also consider it to be a\nprimary server, with the other acting as a backup server.\nWe assume that a client broadcasts its requested command to all servers.\nIf a server notices it is missing a command, it can rely on the other server\nto forward it when necessary. We will not describe how this happens, but\nsilently assume that all commands are stored at the servers and that we merely\nneed to make sure that the servers agree on which command to execute next.\nAs a consequence, all remaining communication between servers consists of\ncontrol messages. To make this point clear, consider the situation sketched in\nFigure 8.8. (In what follows, we use subscripts to designate processes, and\nsuperscripts to designate operations and states.)\nFigure 8.8: Two clients communicating with a 2-server process group.\nIn this example, server S1 is the leader and as such will hand out time-\nstamps to submitted requests. Client C1 has submitted command o1 while C2\nsubmitted o2. S1 instructs S2 to execute operation o2 with timestamp 1, and\nlater operation o1 with timestamp 2. After processing a command, a server\nwill return the result to the associated client. We designate this using the\nnotation ⟨σj\ni ⟩, where i is the index of the reporting server, and j the state it\nwas in, expressed as the sequence of operations it has carried out. In our\nexample, client C1 will thus see the results ⟨σ21\n1 ⟩and ⟨σ21\n2 ⟩, meaning that each\nserver has executed o1 after executing o2.\nIn Paxos, when a leader associates a timestamp with an operation, it does\nso by sending an accept message to the other server(s). As we assume that\nmessages may be lost, a server accepting an operation o does so by telling\nthe leader it has learned the operation by returning a learn(o) message.\nWhen the leader does not notice that operation o has been learned, it simply\nretransmits an accept(o, t) message, with t being the original timestamp. Note\nthat in our description, we are skipping the phase of coming to agreement on\nthe operation to be carried out: we assume the leader has decided and now\nneeds to reach consensus on executing that operation.\n \nDS 4.01\n",
      "content_length": 2287,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 502,
      "content": "486\nCHAPTER 8. FAULT TOLERANCE\nCompensating for a lost message is relatively easy, but what happens when\nalso a server crashes? Let us first assume that a crash can be reliably detected.\nConsider the situation sketched in Figure 8.9(a). The issue, of course, is that\nserver S2 will never have learned (about) operation o1. This situation can be\nprevented by demanding that a server may execute an operation only if it\nknows that the other server has learned the operation as well, as illustrated in\nFigure 8.9(b).\n(a)\n(b)\nFigure 8.9: (a) What may happen when the leader crashes in combination\nwith a lost accept, and (b) the solution, namely demanding that the other\nserver has learned the operation as well before executing it.\nIt is not difficult to see that with a larger process group, we can get into the\nsame situation as in Figure 8.9(a). Simply consider a group of three servers\n{S1, S2, S3} with S1 being the leader. If its accept(o1, t) message to S3 is lost,\nyet it knows that S2 has learned o1, then it should still not execute o1 until\nit has also received a learn(o1) message from S3. This situation is shown in\nFigure 8.10.\nLet us consider the three-server case and imagine what would happen\nif learn(o1) returned by S2 would not make it to S1. Of course, S1 would\nDS 4.01\n \n",
      "content_length": 1290,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 503,
      "content": "8.2. PROCESS RESILIENCE\n487\nFigure 8.10: The situation when dealing with three servers, of which two\ncrash. In this case, S1 should have waited with executing operation o1 until it\nhad received learn(o1) from S3, but also S2 should wait until it knows that\nS3 has learned about o1.\nnot execute o1, but otherwise we would still be in trouble: S2 will execute o1\nwhile S3 would take over leadership and execute o2 without ever knowing\nthat o1 had already been processed. In other words, also S2 must wait with\nthe execution of o1 until it knows that S3 has learned that operation. This\nbrings us to the following:\nIn Paxos, a server S cannot execute an operation o until it has received a\nlearn(o) from all other nonfaulty servers.\nUp to this point, we have assumed that a process can reliably detect that\nanother process has crashed. In practice, this is not the case. As we will\ndiscuss more extensively shortly, a standard approach toward failure detection\nis to set a timeout on expected messages. For example, each server is required\nto send a message declaring it is still alive, and at the same time the other\nservers set timeouts on the expected receipt of such messages. If a timeout\nexpires, the sender is suspected to have failed. In a partially synchronous or\nfully asynchronous system, there is essentially no other solution. However,\nthe consequence is that a failure may be falsely detected, as the delivery of\nsuch “I’m alive” messages may have simply been delayed or lost.\nLet us assume that Paxos has realized a failure detection mechanism, but\nthat the two servers falsely conclude that the other has failed, as shown in\nFigure 8.11. The problem is clear: each may now independently decide to\nexecute their operation of choice, leading to divergent behavior. It is at this\npoint that we need to introduce an extra server, and demand that a server\ncan execute an operation only if it is certain that a majority will execute that\noperation. Note, that in the three-server case, execution of operation o by\n \nDS 4.01\n",
      "content_length": 2031,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 504,
      "content": "488\nCHAPTER 8. FAULT TOLERANCE\nserver S can take place as soon as S has received at least one (other) learn(o)\nmessage. Together with the sender of that message, S will form a majority.\nFigure 8.11: The situation in the case of false failure detections.\nWe have now come to a point where it should be clear that Paxos requires\nat least three replicated servers {S1, S2, S3} to operate correctly. Let us concen-\ntrate on the situation that one of these servers crashes. We make the following\nassumptions.\n• Initially, S1 is the leader.\n• A server can reliably detect it has missed a message. The latter can\nbe realized, for example, through timestamps in the form of strictly\nincreasing sequence numbers. Whenever a server notices it has missed\na message, it can then simply request a retransmission and catch up\nbefore continuing.\n• When a new leader needs to be elected, the remaining servers follow a\nstrictly deterministic algorithm. For example, we can safely assume that\nif S1 crashes, then S2 will become leader. Likewise, if S2 crashes, S3 will\ntake over, and so on.\n• Clients may receive duplicate responses, but besides being required to\nrecognize duplicates, form no further part of the Paxos protocol. In\nother words, a client cannot be asked to help the servers to resolve a\nsituation.\nUnder these circumstances, no matter when one of S2 or S3 crashes, Paxos\nwill behave correctly. Of course, we are still demanding that execution of an\noperation can take place only if a server knows that a majority will execute\nthat operation.\nSuppose now that S1 in its role as leader, crashes after the execution of\noperation o1. The worst that can happen in this case is that S3 is completely\nignorant of the situation until the new leader, S2 tells it to accept operation o2.\nNote that this is announced through an accept(o2, 2) message such that the\nDS 4.01\n \n",
      "content_length": 1863,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 505,
      "content": "8.2. PROCESS RESILIENCE\n489\ntimestamp t = 2 will alert S3 that it missed a previous accept message. S3 will\ntell so to S2, who can then retransmit accept(o1, 1), allowing S3 to catch up.\nLikewise, if S2 missed accept(o1, 1), but did detect that S1 crashed, it\nwill eventually either send accept(o1, 1) or accept(o2, 1) to S3 (i.e., in both\ncases using timestamp t = 1, which was previously used by S1). Again, S3\nhas enough information to get S2 on the right track again. If S2 had sent\naccept(o1, 1), S3 can simply tell S2 that it already learned o1. In the other\ncase, when S2 sends accept(o2, 1), S3 will inform S2 that it apparently missed\noperation o1. We conclude that when S1 crashes after executing an operation,\nPaxos behaves correctly.\nSo, what can happen if S1 crashes immediately after having sent accept(o1,\n1) to the other two servers? Suppose again that S3 is completely ignorant of\nthe situation because messages are lost, until S2 has taken over leadership\nand announces that o2 should be accepted. Like before, S3 can tell S2 that\nit (i.e., S3) missed operation o1, so that S2 can help S3 to catch up. If S2\nmisses messages, but does detect that S1 crashed, then as soon as it takes over\nleadership and proposes an operation, it will be using a stale timestamp. This\nwill trigger S3 to inform S2 that it missed operation o1, which saves the day.\nAgain, Paxos is seen to behave correctly.\nC2\nS3\nS2\nLEADER\nS1\nLEADER\nC1\n⟨o1⟩\n⟨o2⟩\n⟨ACC, o1, 1⟩\n⟨ACC, o2, 2⟩\n⟨LRN, o2⟩\ndrop leadership\no2\n⟨σ2\n3⟩\nconfusion\nFigure 8.12: Why incorporating the ID of the current leader is needed: S2\nfalsely concludes that S1 has crashed.\nProblems may arise with false detections of crashes. Consider the sit-\nuation sketched in Figure 8.12. We see that the accept messages from S1\nare considerably delayed and that S2 falsely detects S1 having crashed. S2\ntakes over leadership and sends accept(o2, 1), i.e., with a timestamp t = 1.\nHowever, when finally accept(o1, 1) arrives, S3 cannot do anything: this is\nnot a message it is expecting. Note that, in principle, S3 does not check who\nis the current leader. The only thing it knows is that it is itself not the leader.\n \nDS 4.01\n",
      "content_length": 2173,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 506,
      "content": "490\nCHAPTER 8. FAULT TOLERANCE\nPrecisely for this reason, it does not expect an accept message with the same\ntimestamp as before. Things change, however, if it does know who the current\nleader is, in combination with a deterministic leader election. In that case,\nit could safely reject accept(o1, 1), knowing that by now S2 has taken over,\nand even perhaps retransmit learn(o2) to S1. A (perhaps previously sent)\nlearn(o2) message received by S1 will allow S1 to conclude that leadership\nhad been taken over. We conclude that the leader should include its ID in an\naccept message.\nWe have covered almost all cases and have thus far shown that Paxos\nbehaves correctly. Unfortunately, although being correct, the algorithm can\nstill come to a grinding halt. Consider the situation illustrated in Figure 8.13.\nWhat we are seeing here is that because the learn messages returned by S3\nare lost, neither S1 nor S2 will ever be able to know what S3 actually executed:\ndid it learn (and execute) accept(o1, 1) before or after learning accept(o2,\n1), or perhaps it learned neither operation? A solution to this problem is\ndiscussed in Note 8.4.\nC2\nS3\nS2\nLEADER\nS1\nLEADER\nC1\n⟨o1⟩\n⟨o2⟩\n⟨ACC, S1, o1, 1⟩\n⟨LRN, o1⟩\no1\n⟨σ1\n3⟩\n⟨ACC, S2, o2, 1⟩\n⟨LRN, o2⟩\no2\n⟨σ12\n3 ⟩\nFigure 8.13: When Paxos can make no further progress.\nNote 8.4 (Advanced: Making progress in Paxos)\nUp to this point, we have discussed the development of Paxos such that safety is\nensured. Safety essentially means that nothing bad will happen, or, put differently,\nthat the behavior of the algorithm is correct. To also ensure that eventually\nsomething good will happen, generally referred to as liveness of an algorithm, we\nneed to do a bit more. In particular, we need to get out of the situation sketched\nin Figure 8.13.\nThe real problem with this situation is that the servers have no consensus on\nwhom the leader is. Once S2 decides it should take over leadership, it needs to\nensure that any outstanding operations initiated by S1 have been properly dealt\nwith. In other words, it has to ensure that its own leadership is not hindered\nDS 4.01\n \n",
      "content_length": 2105,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 507,
      "content": "8.2. PROCESS RESILIENCE\n491\nby operations that have not yet been completed by all nonfaulty processes. If\nleadership is taken over too quickly and a new operation is proposed, a previous\noperation that has been executed by at least one server may not get a chance to be\nexecuted by all servers first.\nTo this end, Paxos enforces an explicit leadership takeover, and this is where\nthe role of proposers come from. When a server crashes, the next one in line\nwill need to take over (recall that Paxos assumes a deterministic leader-election\nalgorithm), but also ensure that any outstanding operations are dealt with. This ex-\nplicit takeover is implemented by broadcasting a proposal message: propose(Si),\nwhere Si is the next server to be leader. When server Sj receives this message,\nit replies with a promise(oj, tj) message, containing the most recently executed\noperation oj and its corresponding timestamp tj. Note that Si is particularly\ninterested in the most recent operation o∗executed by a majority of servers. By\n“adopting” this operation from the (apparently crashed) server S∗that had origi-\nnally proposed its acceptance, Si can effectively complete what S∗could not due\nto its failure.\nThere are two obvious optimizations to this procedure. The first one is not\nthat servers return the most recently executed operation, but the most recently\nlearned operation that is still waiting to be executed, if any. Furthermore, because\nit may be that the collection of servers has no more pending operations, Si can\nalso suggest a next operation oi when initially proposing to take over leadership,\ngiving rise to a propose(Si, oi) message. In essence, this is the situation we\ndescribed earlier, yet now it should be clear where the idea of proposals actually\ncomes from.\nWhen Si receives a majority of promises for operation o∗, and the highest\nreturned timestamp is t∗, it broadcasts accept(Si, o∗, t∗), which is essentially a\nretransmission of the last operation proposed before Si took over leadership. If no\nsuch o∗exists, Si will propose to accept its own operation oi.\n8.2.5\nConsensus in faulty systems with arbitrary failures\nSo far, we assumed that replicas were subject to only crash failures, in which\ncase a process group needs to consist of 2k + 1 servers to survive k crashed\nmembers. An important assumption in these cases, is that a process does\nnot collude with another process, or, more specifically, is consistent in its\nmessages to others. The situations shown in Figure 8.14 should not happen.\nIn the first case, we see that process P2 is forwarding a different value or\noperation than it is supposed to. Referring to Paxos, this could mean that a\nprimary tells the backups that not operation o had been accepted, but instead\npropagates a different operation o′. In the second case, P1 is telling different\nthings to different processes, such as having a leader sending operation o to\nsome backups, and at the same time operation o′ to others. Again, we note\nthat this need not be malicious actions, but simply omission or commission\nfailures.\n \nDS 4.01\n",
      "content_length": 3081,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 508,
      "content": "492\nCHAPTER 8. FAULT TOLERANCE\n(a)\n(b)\nFigure 8.14: A process in a replicated group acting inconsistently: (a) not\nforwarding properly, and (b) telling different things to different processes.\nIn this section, we take a look at reaching consensus in a fault-tolerant\nprocess group in which k members can fail, assuming arbitrary failures.\nIn particular, we will show that we need at least 3k + 1 members to reach\nconsensus under these failure assumptions.\nConsider a process group consisting of n members, of which one has been\ndesignated to be the primary, P, and the remaining n −1 to be the backups\nB1, . . . , Bn−1. We make the following assumptions:\n• A client sends a value v ∈{T, F} to the primary, where v stands for\neither true or false.\n• Messages may be lost, but this can be detected.\n• Messages cannot be corrupted without that being detected (and thus\nsubsequently ignored).\n• A receiver of a message can reliably detect its sender.\nTo achieve what is known as Byzantine agreement, we need to satisfy the\nfollowing two requirements:\nBA1: Every nonfaulty backup process stores the same value.\nBA2: If the primary is nonfaulty, then every nonfaulty backup process stores\nexactly what the primary had sent.\nNote that if the primary is faulty, BA1 tells us that the backups may store\nthe same, but different (and thus wrong) value than the one initially sent by\nthe client. Furthermore, it should be clear that if the primary is not faulty,\nsatisfying BA2 implies that BA1 is also satisfied.\nWhy having 3k processes is not enough\nTo see why having only 3k processes is not enough to reach consensus, let\nus consider the situation in which we want to tolerate the failure of a single\nprocess, that is, k = 1. Consider Figure 8.15, which is essentially an extension\nof Figure 8.14.\nDS 4.01\n \n",
      "content_length": 1800,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 509,
      "content": "8.2. PROCESS RESILIENCE\n493\n(a)\n(b)\nFigure 8.15: Impossibility to reach consensus with 3 processes and trying to\ntolerate a single arbitrarily failing process.\nIn Figure 8.15(a), we see that the faulty primary P is sending two different\nvalues to the backups B1 and B2, respectively. To reach consensus, both\nbackup processes forward the received value to the other, leading to a second\nround of message exchanges. At that point, B1 and B2 each have received the\nset of values {T, F}, from which it is impossible to draw a conclusion.\nLikewise, we cannot reach consensus when wrong values are forwarded.\nIn Figure 8.15(b), the primary P and backup B2 operate correctly, but B1 is\nnot. Instead of forwarding the value T to process B2, it sends the incorrect\nvalue F. The result is that B2 will now have seen the set of values {T, F}\nfrom which it cannot draw any conclusions. In other words, P and B2 cannot\nreach consensus. More specifically, B2 can not decide what to store so that we\ncannot satisfy requirement BA2.\nNote 8.5 (Advanced: The case where k > 1 and n ≤3k)\nGeneralizing this situation to other values of k is not that difficult. As explained\nby Kshemkalyani and Singhal [2008], we can use a simple reduction scheme.\nAssume that there is a solution for the case where k ≥1 and n ≤3k. Partition the\nn processes Q1, . . . , Qn into three disjoint sets S1, S2, and S3, together containing\nall processes. Moreover, let each set Sk have less or equal than n/3 members.\nFormally, this means that\n• S1 ∩S2 = S1 ∩S3 = S2 ∩S3 = ∅\n• S1 ∪S2 ∪S3 = {Q1, . . . , Qn}\n• for each Si, |Si| ≤n/3\nNow consider a situation in which three processes Q∗\n1, Q∗\n2, and Q∗\n3 simulate the\nactions that take place in and between the processes of S1, S2, and S3, respectively.\nIn other words, if a process in S1 sends a message to another process in S2, then\nQ∗\n1 will send a same message to Q2. The same holds for process communication\nwithin a group. Assume that Q∗\n1 is faulty, yet Q∗\n2 and Q∗\n3 are not. All processes\nsimulated by Q∗\n1 are now assumed to be faulty, and will thus lead to incorrect\n \nDS 4.01\n",
      "content_length": 2095,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 510,
      "content": "494\nCHAPTER 8. FAULT TOLERANCE\n(a)\n(b)\nFigure 8.16: Reaching consensus with four processes, of which one may fail\narbitrarily.\nmessages being sent to Q∗\n2 and Q∗\n3, respectively. Not so for Q∗\n2 (and Q∗\n3): all\nmessages coming from processes in S2 (and S3, respectively) are assumed to be\ncorrect. Because n ≤3k and for each set Si we have that |Si| ≤n/3, at most n/3\nof the simulated processes Q1, . . . , Qn are faulty. In other words, we are satisfying\nthe condition for which we assumed that there would be a general solution.\nWe can now come to a contradiction, for if there would exist a solution for\nthe general case, then the processes Q∗\n1, Q∗\n2, and Q∗\n3 could simulate this solution,\nwhich would then also be a solution for the special case that n = 3 and k = 1. Yet,\nwe just proved that this cannot be so, leading to a contradiction. We conclude that\nour assumption that there is a general solution for k ≥1 and n ≤3k is false.\nWhy having 3k + 1 processes is enough\nLet us now focus on the case in which we have a group of 3k + 1 processes.\nOur goal is to show that we can establish a solution in which k group members\nmay suffer from fail-arbitrary failures, yet the remaining nonfaulty processes\nwill still reach consensus. Again, we first concentrate on the case n = 4, k = 1.\nConsider Figure 8.16, which shows a situation with one primary P and three\nbackup processes B1, B2, and B3.\nIn Figure 8.16(a) we have sketched the situation in which the primary P is\nDS 4.01\n \n",
      "content_length": 1485,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 511,
      "content": "8.2. PROCESS RESILIENCE\n495\nfaulty and is providing inconsistent information to its backups. In our solution,\nthe processes will forward what they receive to the others. During the first\nround, P sends T to B1, F to B2, and T to B3, respectively. Each of the backups\nthen sends what they have to the others. With only the primary failing, this\nmeans that after two rounds, each of the backups will have received the set of\nvalues {T, T, F}, meaning that they can reach consensus on the value T.\nWhen we consider the case that one of the backups fails, we get the\nsituation sketched in Figure 8.16(b). Assume that the (nonfaulty) primary\nsends T to all the backups, yet B2 is faulty. Where B1 and B3 will send out T\nto the other backups in a second round, the worst that B2 may do is send out\nF, as shown in the figure. Despite this failure, B1 and B3 will come to the same\nconclusion, namely that P had sent out T, thereby meeting our requirement\nBA2 as stated before.\nNote 8.6 (Advanced: The case where k > 1 and n = 3k + 1)\nAs a sketch toward a general solution, consider the more intricate case in which\nn = 7 and k = 2. We let the primary P send out a value v0. Using a similar\nnotation as found in [Kshemkalyani and Singhal, 2008], we proceed as follows.\nNote that we effectively use the index 0 to denote the primary P (think of P being\nequal to a special backup process B0).\n1. We let P send v0 to the six backups. Backup Bi stores the received value\nas vi,0⟨⟩. This notation indicates that the value was received by process Bi,\nthat it was sent by P = B0, and that the value of v0 was directly sent to Bi\nand not through another process (using the notation ⟨⟩). So, for example,\nB4 will store v0 in v4,0⟨⟩.\n2. Each backup Bi, in turn, will send vi,0⟨⟩to every one of the other five\nbackups, which is stored by Bj as vj,i⟨0⟩. This notation indicates that the\nvalue is stored at Bj, was sent by Bi, but that it originated from P = B0\n(through the notation ⟨0⟩). Looking at B4 again, it will receive values from\nB1, B2, B3, B5, and B6. For example, B2 will send v2,0⟨⟩, which is then\nstored as v4,2⟨0⟩by B4. Likewise, B4 will also store v4,1⟨0⟩, v4,3⟨0⟩, v4,5⟨0⟩,\nand v4,6⟨0⟩.\n3. Suppose that Bi now has the value vi,j⟨0⟩. Again, it will send out this value\nto all processes except P = B0, Bj, and Bi (i.e., itself). If Bk receives vi,j⟨0⟩\nfrom Bi, it stores this received value in vk,i⟨j, 0⟩. Indeed, by then v0 will\nhave traveled the path P →Bj →Bi →Bk. For example, in the previous\nround, B2 will have stored v2,1⟨0⟩, which it eventually sends to B4, who, in\nturn, will store it as v4,2⟨1, 0⟩. Note at this point, that B4 can send out this\nvalue only to processes B3, B5, and B6. There is no use in sending it out to\nother processes.\n4. Continuing this line of thought, assume that Bi has value vi,j⟨k, 0⟩, which\nit sends out to the three remaining processes not equal to P = B0, Bk, Bj,\nand Bi (itself). Returning to B4, eventually, B4 will also receive a similar\nmessage from, say, B3, such as v3,2⟨5, 0⟩: the value v0 initially sent to B5,\n \nDS 4.01\n",
      "content_length": 3061,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 512,
      "content": "496\nCHAPTER 8. FAULT TOLERANCE\nwhich then forwarded it to B2, who, in turn, sent it to B3. B4 will store that\nvalue as v4,3⟨2, 5, 0⟩. That value can be sent only to B1 and B6, after which\nonly a single round is left.\nOnce all these messages have been sent, each backup can start moving out of the\nrecursion again. Note that in the above scheme we have effectively constructed a\ntree, rooted at value v0 with six child nodes (representing the six backups). Each\nof these nodes, in turn, will have five children of its own, and so on. In total, there\nwill be 6! = 720 leaf nodes. Each path from the root to a leaf node is encoded by\nthe value stored at that leaf node, such as v4,1⟨6, 5, 3, 2, 0⟩. This leaf node will have\na single parent (namely B1 storing v1,6⟨5, 3, 2, 0⟩), in turn with a single sibling (B4\nstoring v4,6⟨5, 3, 2, 0⟩).\nFigure 8.17: Rounds of broadcasting v0 to the backups, by P and the\nbackups B1, . . . , B6.\nWe can now let each backup start computing estimates of v0, that is, a value\nthat it believes v0 should be. To this end, we assume that each (nonfaulty) process\nexecutes the same procedure majority() that selects a unique value from a given\nset of inputs. In practice, this will be the majority among the input set. If there\nis no majority, a default value is chosen. To give a few examples, also shown in\nFigure 8.17:\nw4,1⟨5, 3, 2, 0⟩\n←\nmajority(v4,1⟨5, 3, 2, 0⟩, v6,4⟨1, 5, 3, 2, 0⟩)\nw6,1⟨5, 3, 2, 0⟩\n←\nmajority(v6,1⟨5, 3, 2, 0⟩, v4,6⟨1, 5, 3, 2, 0⟩)\nw1,4⟨5, 3, 2, 0⟩\n←\nmajority(v1,4⟨5, 3, 2, 0⟩, v6,1⟨4, 5, 3, 2, 0⟩)\nw6,4⟨5, 3, 2, 0⟩\n←\nmajority(v6,4⟨5, 3, 2, 0⟩, v1,6⟨4, 5, 3, 2, 0⟩)\nw1,6⟨5, 3, 2, 0⟩\n←\nmajority(v1,6⟨5, 3, 2, 0⟩, v4,1⟨6, 5, 3, 2, 0⟩)\nw4,6⟨5, 3, 2, 0⟩\n←\nmajority(v4,6⟨5, 3, 2, 0⟩, v1,4⟨6, 5, 3, 2, 0⟩)\nDS 4.01\n \n",
      "content_length": 1759,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 513,
      "content": "8.2. PROCESS RESILIENCE\n497\nIn turn, B1, B4, and B6 can compute estimates like:\nw1,5⟨3, 2, 0⟩\n←\nmajority(v1,5⟨3, 2, 0⟩, w4,1⟨5, 3, 2, 0⟩, w6,1⟨5, 3, 2, 0⟩\nw4,5⟨3, 2, 0⟩\n←\nmajority(v4,5⟨3, 2, 0⟩, w1,4⟨5, 3, 2, 0⟩, w6,4⟨5, 3, 2, 0⟩\nw6,5⟨3, 2, 0⟩\n←\nmajority(v6,5⟨3, 2, 0⟩, w1,6⟨5, 3, 2, 0⟩, w4,6⟨5, 3, 2, 0⟩\nAnd from there, B5 can continue, for example, with:\nw5,3⟨2, 0⟩\n←\nmajority(v5,3⟨2, 0⟩, w1,5⟨3, 2, 0⟩, w4,5⟨3, 2, 0⟩, w6,5⟨3, 2, 0⟩)\nThis process continues until, eventually, B2 from Figure 8.17 will be able to execute\nw2,0⟨⟩←majority(v2,0⟨⟩, w1,2⟨0⟩, w3,2⟨0⟩, w4,2⟨0⟩, w5,2⟨0⟩, w6,2⟨0⟩)\nand reach the final outcome.\nLet us now see why this scheme actually works. We denote by BAP(n,k)\nthe above sketched protocol to reach consensus. BAP(n,k) starts by having the\nprimary send out its value v0 to the n −1 backups. In the case the primary\noperates correctly, each of the backups will indeed receive v0. If the primary is\nfaulty, some backups receive v0 while others receive v0 (i.e., the opposite of v0).\nBecause we assume a backup Bi cannot know whether the primary is working\ncorrectly, it will have to check with the other backups.\nWe therefore let Bi\nrun the protocol again, but in this case, with value vi,0⟨⟩and with a smaller\nprocess group, namely {B1, . . . , Bi−1, Bi+1, . . . , Bn}. In other words, Bi executes\nBAP(n-1,k-1) with a total of n −2 other processes. Note that at this point there\nare n −1 instances of BAP(n-1,k-1) being executed in parallel.\nIn the end, we see that these executions result in each backup Bi taking the\nmajority of n −1 values:\n• One value comes from the primary: vi,0⟨⟩\n• n −2 values come from the other backups, in particular, Bi is dealing with\nthe values vi,1⟨⟩, . . . , vi,i−1⟨⟩, vi,i+1⟨⟩, . . . , vi,n−1⟨⟩.\nHowever, because Bi cannot trust a received value vi,j⟨⟩, it will have to check that\nvalue with the other n −2 backups: B1, . . . , Bi−1, Bi+1, . . . , Bj−1, Bj+1, . . . , Bn−1.\nThis leads to the execution of BAP(n-2,k-2), of which a total of n −2 instances\nwill be running in parallel. This story continues, and eventually, a backup process\nwill need to run BAP(n-k,0), which simply returns the value sent by the primary,\nafter which we can move up the recursion as described above.\nWith this general scheme, we can now see why the protocol is correct. Fol-\nlowing Koren and Krishna [2007], we use induction on k to prove that BAP(n,k)\nmeets the requirements BA1 and BA2 for n ≥3k + 1 and for all k ≥0.\nFirst, consider the case k = 0. In other words, we assume that there are no\nfaulty processes. In that case, whatever the primary sends to the backups, that\nvalue will be consistently propagated throughout the system, and no other value\nwill ever pop up. In other words, for any n, BAP(n,0) is correct. Now consider\nthe case k > 0.\nFirst, consider the case that the primary is operating correctly. Without loss of\ngenerality, we can assume the primary sends out T. All the backups receive the\n \nDS 4.01\n",
      "content_length": 2961,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 514,
      "content": "498\nCHAPTER 8. FAULT TOLERANCE\nsame value, namely T. Each backup will then run BAP(n-1,k-1). By induction,\nwe know that each of these instances will be executed correctly. This means that\nfor any nonfaulty backup B, all the other nonfaulty backups will store the value\nthat was sent by B, namely T. Each nonfaulty backup receives, in total, n −1\nvalues, of which n −2 come from other backups. Of those n −2, at most k values\nmay be wrong (i.e., F). With k ≤(n −1)/3, this means that every nonfaulty\nbackup receives at least 1 + (n −2) −(n −1)/3 = (2n −2)/3 values T. Because\n(2n −2)/3 > n/3 for all n > 2, this means that every nonfaulty backup can take\na correct majority vote on the total number of received values, thus satisfying\nrequirement BA2.\nLet us now consider the case that the primary is faulty, meaning that at most\nk −1 backups may operate incorrectly as well. The primary is assumed to send\nout any value it likes. There are a total of n −1 backups, of which at most k −1\nare faulty. Each backup runs BAP(n-1,k-1) and by, induction, each one of these\ninstances is executed correctly. In particular, for every nonfaulty backup B, all\nthe other nonfaulty backups will vote for the value sent by B. This means that\nall nonfaulty backups will have the same vector of n −2 results from their fellow\nbackups. Any difference between two nonfaulty backups can be caused only by\nthe fact that the primary sent something else to each of them. As a result, when\napplying majority() to those complete vectors, the result for each backup will be\nthe same, so that requirement BA1 is met.\nExample: Practical Byzantine Fault Tolerance\nByzantine fault tolerance was for long more or less an exotic topic, partly\nbecause it turned out that combining safety, liveness, and practical performance\nwas difficult to achieve. It was around 2000 that Barbara Liskov and Miguel\nCastro managed to come up with a practical implementation of a protocol\nfor replicating servers that could handle arbitrary failures. Let us briefly take\na look at their solution, which has been coined Practical Byzantine Fault\nTolerance, or simply PBFT [Castro and Liskov, 2002]. To better understand\nhow the protocol works, it may help to also consult Liskov [2010].\nLike Paxos, PBFT makes only a few assumptions about its environment. It\nmakes no assumptions about the behavior of replica servers: a faulty server\nis assumed to exhibit arbitrary behavior. Likewise, messages may be lost,\ndelayed, and received out of order. However, a message’s sender is assumed\nto be identifiable (which is achieved by having messages signed, as we discuss\nin Section 9.2.3). Under these assumptions, and as long as no more than k\nservers fail, it can be proven that PBFT is safe, meaning that a client will always\nreceive a correct answer. If we can additionally assume synchrony, meaning\nthat message delays and response times are bounded, it also provides liveness.\nIn practice, this means that PBFT assumes a partially synchronous model, in\nwhich unbounded delays are an exception, for example, caused by an attack.\nDS 4.01\n \n",
      "content_length": 3086,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 515,
      "content": "8.2. PROCESS RESILIENCE\n499\nTo understand the algorithm, let us take a step back and partly review\nwhat we have discussed so far on establishing a k-fault-tolerant process group.\nAn essential issue is that such a group behaves as a single, central server. As\na consequence, under the assumption of having only crash failures, when a\nclient sends a request, it should expect k + 1 identical answers. If a server had\ncrashed, fewer responses would be returned, but they would be the same.\nThe first problem that we need to solve is that concurrent requests are all\nhandled in the same order. To this end, PBFT adopts a primary-backup model\nwith a total of 3k + 1 replica servers. To keep matters simple, let us assume for\nnow that the primary is nonfaulty. In that case, a client C sends a request to\nexecute operation o to the primary (denoted as P in Figure 8.18). The primary\nhas a notion of the current collection of nonfaulty replica servers, expressed in\nterms of a view v, which is simply a number. The primary assigns a timestamp\nt to o, which is then incremented to be used for a subsequent request. The\nprimary subsequently sends a (signed) pre-prepare message pre-prepare(t, v,\no) to the backups (denoted as Bi in Figure 8.18). We assume that backup B2 is\nfaulty, indicated by the dashed line used for its messages.\nFigure 8.18: The different phases in PBFT. C is the client, P is the primary, and\nB1, B2, B3 are the backups. We assume that B2 is faulty.\nA (nonfaulty) backup will accept to pre-prepare if it is in v and has never\naccepted an operation with timestamp t in v before. Each backup that accepts\nto pre-prepare sends an (again signed) message prepare(t, v, o) to the others,\nincluding the primary. A key observation is that when a nonfaulty replica\nserver S has logged 2k messages prepare(t, v, o) (including its own) that all\nmatch the pre-prepare message S itself received by the primary (i.e., all have\nthe same value for t, v, and o, respectively), there is consensus among the\nnonfaulty servers on the order of which operation goes first. To see why,\nlet a prepare certificate PC(t, v, o) denote a certificate that is based on such\na set of 2k + 1 messages. Let PC(t, v, o′) be another prepare certificate with\n \nDS 4.01\n",
      "content_length": 2247,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 516,
      "content": "500\nCHAPTER 8. FAULT TOLERANCE\nthe same values for t and v respectively, but with a different operation o′.\nBecause each prepare certificate is based on 2k + 1 values from a total of 3k + 1\nreplica servers, the intersection of two certificates will necessarily be based on\nmessages from a subset of at least k + 1 servers. Of this subset, we know that\nthere is at least one nonfaulty server, which will have sent the same prepare\nmessage. Hence, o = o′.\nIn Figure 8.18, notice that, regardless what B2 sends (or does not send),\nthe two other nonfaulty backups, namely B1 and B2, will each have logged\nthree (2k + 1, with k = 1) messages for the tuple ⟨t, v, o⟩: the original message\nfrom P, their own message, and the same message from the other backup. At\nthat point, there is consensus to execute o, and not some other operation. We\ncan then move on to the next phase.\nThe next phase for a replica server starts when it has a prepare certificate: it\ncommits to the operation by broadcasting commit(t, v, o) to the other members\nin v. Each server S, in turn, collects 2k of such commit messages from other\nservers, leading to a commit certificate to execute operation o. At that point, it\nexecutes o and sends a response to the client. Again, with its own message and\nthe 2k other messages, S knows that there is consensus among the nonfaulty\nservers on which operation to actually execute now. In Figure 8.18, we see\nthat for the primary, as well as the backups B1 and B3, there are indeed again\nthree messages that state the same: we can execute o. Each server knows that\nthere are at least two other servers besides itself that will indeed execute o,\nand it is therefore good to go. What B2 had sent is not relevant: it will not\naffect the decision of the others.\nThe client collects all the results and takes as the answer the response that\nis returned by at least k + 1 replicas, of which it knows that there is at least\none nonfaulty replica server contributing to that answer. Again notice that\nin Figure 8.18, regardless what B2 tells the client about which operation B2\nhad executed, the client can safely assume that its requested operation was\nexecuted by a majority of the servers.\nSo far, so good. However, we also need to deal with the situation that\nthe primary fails. If a backup detects that the primary fails, it broadcasts\na view-change message for view v + 1. What we wish to establish is that a\nrequest that was still being processed at the time the primary failed, will\neventually get executed once and only once by all nonfaulty servers. To this end,\nwe first need to ensure that there are no two commit certificates with the same\ntimestamp that have different associated operations, regardless the view that\neach of them is associated with. This situation can be prevented by having\na quorum of 2k + 1 commit certificates just as before, but this time based on\nprepare certificates. In other words, we want to regenerate commit certificates,\nbut now for the new view, and only to make sure that a nonfaulty server is\nnot missing any operation. In this respect, note that we may be generating a\ncertificate for an operation that a server S had already executed (which can be\nDS 4.01\n \n",
      "content_length": 3209,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 517,
      "content": "8.2. PROCESS RESILIENCE\n501\nobserved by looking at timestamps), but that certificate will be ignored by S\nas long as it keeps an account of its execution history.\nA backup server will broadcast a (signed) message view-change(v + 1, P),\nwith P being the set of its prepare certificates. (Note that we ignore garbage\ncollecting issues.) PBFT includes a deterministic function primary(w) known\nto all backups that returns who the next primary will be given a view w.\nThis new primary will wait until it has a total of 2k + 1 view-change messages,\nleading to a view-change certificate X of prepare certificates. The new primary\nthen broadcasts new-view(v + 1, X, O), where O consists of new pre-prepare\nmessages constructed according to one of the following situations:\n• pre-prepare(t, v + 1, o) ∈O if the prepare certificate PC(t, v′, o) ∈X\nsuch that there is no prepare certificate PC(t, v′′, o′) with v′′ > v′,\n• pre-prepare(t, v + 1, none) ∈O if there is no prepare certificate\nPC(t, v′, o′) ∈X.\nWhat happens is that any outstanding, pre-prepared operation from a previous\nview is moved to the new view, but considering only the most recent view\nthat led to the installment of the current new view. In this sense, the new\nprimary effectively sends out appropriate new pre-prepare messages, based\non what the other backups had already committed to in their prepare phase.\nSimplifying matters a bit, each backup will check O and X to make sure\nthat all operations are indeed authentic and broadcast prepare messages for\nall pre-prepare messages in O. We are then back into the situation shown in\nFigure 8.18, but now with one of the backups operating as primary, all the\nother original backups operating as nonfaulty servers, and the old primary\noperating as a faulty backup.\nWe have skipped many elements of PBFT that deal with its correctness\nand above all its efficiency. For example, we did not touch upon garbage\ncollecting logs or efficient ways of authenticating messages. Such details\ncan be found in [Castro and Liskov, 2002].\nA description of a wrapper\nthat will allow the incorporation of Byzantine fault tolerance with legacy\napplications is described in [Castro et al., 2003]. Notably the performance\nof Byzantine fault tolerance has been subject to much research, leading to\nmany new protocols (see, for example, Zyzzyva [Kotla et al., 2009] and\nAbstract [Guerraoui et al., 2010]), yet even these new proposals often rely on\nthe original PBFT implementation. That there is still room for improvement\nwhen actually using PBFT for developing robust applications is discussed by\nChondros et al. [2012]. For example, PBFT assumes static membership (i.e.,\nclients and servers are known to each other in advance), but also assumes that\na replica server’s memory acts as a stable, persistent storage.\nThese and other shortcomings along with the inherent complexity of\nByzantine fault tolerance have formed a hurdle for widespread use of PBFT.\nInterestingly, attention for PBFT returned in the advent of permissioned\n \nDS 4.01\n",
      "content_length": 3032,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 518,
      "content": "502\nCHAPTER 8. FAULT TOLERANCE\nblockhains, being one of the few alternatives that could offer a consenus\nprotocol in a public network. New research was initiated to address short-\ncomings, notably the relatively small number of participants that PBFT can\nmaximally handle. An important development has been HotStuff [Yin et al.,\n2019], which effectively provides a much more efficient view change than in\nPBFT, significantly contributing to the scalability of the protocol.\n8.2.6\nConsensus in blockchain systems\nComing to this point, let us return to the much debated blockchain systems.\nIn particular, let us zoom in a bit into what consensus entails in these systems.\nFollowing the approach presented by Xiao et al. [2020], we can distinguish\nfour requirements for blockchain consensus:\n1. Agreement: All nonfaulty nodes agree on the acceptance of a block of\ntransactions and its position in the blockchain, or agree that it should be\ndiscarded.\n2. Integrity: Each nonfaulty node sees the same blocks of accepted trans-\nactions, and the same positions of these blocks in the blockchain.\n3. Termination: Every nonfaulty node either discards or accepts a transac-\ntion, as contained within a block, to be part of the blockchain.\n4. Validity: If every node receives the same validated block, it should be\naccepted for the blockchain.\nThe first two requirements are at the core of safety: the blockchain does what\nit is supposed to do (i.e., nothing bad happens). The last two can be argued\nto deal with liveness: eventually everything turns out to be good. For our\npresent discussion, reaching agreement is crucial.\nFor permissionless blockchains, we see that leader election is important:\nonce a leader has been elected, we can essentially ensure agreement by letting\nthe leader decide on the block that is to be appended to the blockchain.\nAs we discuss in Section 9.4.3, guaranteeing the integrity of a blockchain\ncan be established using well-known cryptographic techniques. The only\nproblem with leader elections happens if two or more leaders are elected,\nwhich may happen when the declaration of a winner does not reach its\ncompetitor in time. In such a case, two processes will start to append blocks\nto a chain, effectively leading to two branches. A common solution is that\nonce a participant discovers it is reading from the smallest branch, it ignores\nthat branch completely and makes sure that it gets the blocks from the longer\nbranch.\nFor permissioned blockchains, a common solution is to adopt PBFT. In\nother words, the decision to append blocks to an existing chain is handled\nby a relatively small fault-tolerant group of processes (who need not trust\nDS 4.01\n \n",
      "content_length": 2679,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 519,
      "content": "8.2. PROCESS RESILIENCE\n503\neach other). Because PBFT is a relatively costly and nonscalable solution,\nalternatives have been designed, with HotStuff [Yin et al., 2019] playing a\nprominent role as experiments showed that the number of replica servers\ncould go up beyond 100.\nXiao et al. [2020] provides an excellent overview of the various consensus\nprotocols for blockchains, along with a discussion on the many trade-offs to\nbe made.\n8.2.7\nSome limitations on realizing fault tolerance\nOrganizing replicated processes into a group helps to increase fault tolerance.\nHowever, what should have become clear by now is that there is a price to\npay, namely a potential loss of performance. In the solutions discussed so far,\nprocesses in a fault-tolerant group may need to exchange numerous messages\nbefore reaching a decision. The Byzantine agreement protocol is an excellent\nillustration of how tightly coupled processes may be. The question that comes\nto mind is whether realizing specific forms of fault tolerance, like being able\nto withstand arbitrary failures, is always possible.\nOn reaching consensus\nAs we mentioned, if a client can base its decisions through a voting mechanism,\nwe can tolerate that k out of 2k + 1 processes are lying about their result. The\nassumption we are making, however, is that processes do not team up to\nproduce a wrong result. In general, matters become more intricate if we\ndemand that a process group reaches consensus, which is needed in many\ncases. There are three requirements for reaching consensus [Fischer et al.,\n1985]:\n• Processes produce the same output value\n• Every output value must be valid\n• Every process must eventually provide output\nSome examples where reaching consensus is necessary include electing a\ncoordinator, deciding whether to commit a transaction, and dividing up tasks\namong workers. When the communication and processes are all perfect,\nreaching consensus is often straightforward, but when they are not, problems\narise.\nThe general goal of distributed consensus algorithms is to have all the\nnonfaulty processes reach consensus on some issue, and to establish that\nconsensus within a finite number of steps. The problem is complicated by the\nfact that different assumptions about the underlying system require different\nsolutions, assuming solutions even exist. Turek and Shasha [1992] distinguish\nthe following cases:\n \nDS 4.01\n",
      "content_length": 2399,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 520,
      "content": "504\nCHAPTER 8. FAULT TOLERANCE\n1. Synchronous versus asynchronous systems. Rephrasing our description\nsomewhat, a system is synchronous if and only if the processes are\nknown to operate in a lock-step mode. Formally, this means that there\nshould be some constant c ≥1, such that if any process has taken c + 1\nsteps, every other process has taken at least 1 step.\n2. Communication delay is bounded or not. Delay is bounded if and\nonly if we know that every message is delivered with a globally and\npredetermined maximum time.\n3. Message delivery is ordered (in real time) or not. In other words, we\ndistinguish the situation where messages from the different senders are\ndelivered in the order that they were sent in real global time, from the\nsituation in which we do not have such guarantees.\n4. Message transmission is done through unicasting or multicasting.\nAs it turns out, reaching consensus is possible only for the situations\nshown in Figure 8.19. In all other cases, it can be shown that no solution exists.\nNote that most distributed systems in practice assume that processes behave\nasynchronously, message transmission is unicast, and communication delays\nare unbounded. As a consequence, we need to make use of ordered (reliable)\nmessage delivery, such as provided by TCP. And again, in practical situations\nwe assume synchronous behavior to be the default, but take into account that\nthere may be unbounded delays as well. Figure 8.19 illustrates the nontrivial\nnature of distributed consensus when processes may fail.\nProcess behavior\nCommun. delay\nBounded\nUnbounded\nBounded\nUnBounded\nUnicast\nMulticast\nUnicast\nMulticast\nMessage ordering\nSynchronous\n✓\n✓\n✓\n✓\n✓\n✓\nAsynchronous\n✓\n✓\nMessage transmission\n\u001a\n\u001a\nUnordered\nz\n}|\n{\nOrdered\nz\n}|\n{\nFigure 8.19: Circumstances under which distributed consensus can be reached.\nReaching consensus may not be possible. Fischer et al. [1985] proved that\nif messages cannot be guaranteed to be delivered within a known, finite time,\nno consensus is possible if even one process is faulty (albeit if that one process\nfails silently). The problem with such systems is that arbitrarily slow processes\nare indistinguishable from crashed ones (i.e., you cannot tell the dead from\nthe living). These and other theoretical results are surveyed by Barborak et al.\n[1993] and Turek and Shasha [1992].\nDS 4.01\n \n",
      "content_length": 2349,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 521,
      "content": "8.2. PROCESS RESILIENCE\n505\nIt should also be noted that the schemes described so far assume that nodes\nare either Byzantine, or collaborative. The latter cannot always be simply\nassumed when processes are from different administrative domains. In that\ncase, they will more likely exhibit rational behavior, for example, by reporting\ntimeouts when doing so is cheaper than executing an update operation. How\nto deal with these cases is not trivial. A first step toward a solution is captured\nin the form of BAR fault tolerance, which stands for Byzantine, Altruism,\nand Rationality. BAR fault tolerance is described in Aiyer et al. [2005] and\nClement et al. [2008].\nConsistency, availability, and partitioning\nStrongly related to the conditions under which consensus can (not) be reached,\nis when consistency can be reached. Consistency in this case means that when\nwe have a process group to which a client is sending requests, that the\nresponses returned to that client are correct. We are dealing with a safety\nproperty: a property that asserts that nothing bad will happen. For our\npurposes, the types of operations we consider are those that seem to be\nexecuted in a clearly defined order by a single, centralized server. By now, we\nknow better: these operations are executed by a process group to withstand\nthe failures of k group members.\nWe introduced process groups to improve fault tolerance, and, more\nspecifically, to improve availability. Availability is typically a liveness property:\neventually, something good will happen. In terms of our process groups, we\naim to eventually get a (correct) response to every request issued by a client.\nBeing consistent in responses while also being highly available is not an\nunreasonable requirement for services that are part of a distributed system.\nUnfortunately, we may be asking too much.\nIn practical situations, our underlying assumption that the processes in a\ngroup can indeed communicate with each other may be false. Messages may\nbe lost; a group may be partitioned due to a faulty network. In 2000, Eric\nBrewer posed an important theorem which was later proven to be correct by\nGilbert and Lynch [2002]:\nCAP Theorem: Any networked system providing shared data can provide\nonly two of the following three properties:\n• C: consistency, by which a shared and replicated data item appears\nas a single, up-to-date copy\n• A: availability, by which updates will always be eventually executed\n• P: Tolerant to the partitioning of process group (e.g., because of a\nfailing network).\nIn other words, in a network subject to communication failures, it is impossible\nto realize an atomic read/write shared memory that guarantees a response to\nevery request [Gilbert and Lynch, 2012].\n \nDS 4.01\n",
      "content_length": 2747,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 522,
      "content": "506\nCHAPTER 8. FAULT TOLERANCE\nThis has now become known as the CAP theorem, first published as [Fox\nand Brewer, 1999]. As explained by Brewer [2012], one way of understanding\nthe theorem is to think of two processes unable to communicate because of a\nfailing network. Allowing one process to accept updates leads to inconsistency,\nso that we can only have properties {A, P}. If the illusion of consistency is\nto be provided while the two processes cannot communicate, then one of the\ntwo processes will have to pretend to be unavailable, implying having only\n{C, P}. However, only if the two processes can communicate, is it possible to\nmaintain both consistency and high availability, meaning that we have only\n{C, A}, but no longer property P.\nNote also the relationship with reaching consensus; in fact, where con-\nsensus requires proving that processes produce the same output, providing\nconsistency is weaker. This also means that if achieving CAP is impossible,\nthen so is consensus.\nFor some time, many people thought that the CAP theorem actually told\nus we were dealing with a practical horrendous situation. However, the CAP\ntheorem is all about reaching a trade-off between safety and liveness, based on\nthe observation that obtaining both in an inherently unreliable system cannot\nbe achieved. Practical distributed systems are inherently unreliable. What\nBrewer and his colleagues observed is that in practical distributed systems,\none simply has to make a choice to proceed, although another process cannot\nbe reached. In other words, we need to do something when a partition\nmanifests itself through high latency. What this means, is that we need to\nlook at the distributed application at hand to see how we can salvage the\nseemingly impossibility implications of the CAP theorem.\nThe bottom line when it seems that partitioning is taking place, is to\nproceed (tolerating partitions in favor of either consistency or availability),\nwhile simultaneously starting a recovery procedure that can mitigate the\neffects of potential inconsistencies. Exactly deciding on how to proceed is\napplication-dependent: in many cases having duplicate keys in a database\ncan easily be fixed (implying that we should tolerate an inconsistency), while\nduplicate transfers of large sums of money may not (meaning that we should\ndecide to tolerate lower availability). One can argue that the CAP theorem\nessentially moves designers of distributed systems from theoretical solutions\nto engineering solutions. The interested reader is referred to [Brewer, 2012] to\nsee how such a move can be made.\n8.2.8\nFailure detection\nIt may have become clear from our discussions so far that to properly mask\nfailures, we generally need to detect them as well. Failure detection is one\nof the cornerstones of fault tolerance in distributed systems. What it all boils\ndown to is that for a group of processes, nonfaulty members should be able\nDS 4.01\n \n",
      "content_length": 2933,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 523,
      "content": "8.2. PROCESS RESILIENCE\n507\nto decide who is still a member, and who is not. In other words, we need to\nbe able to detect when a member has failed.\nWhen it comes to detecting process failures, there are essentially only two\nmechanisms. Either processes actively send “are you alive?” messages to each\nother (for which they obviously expect an answer), or passively wait until\nmessages come in from different processes. The latter approach makes sense\nonly when it can be guaranteed that there is enough communication.\nThere is a huge body of theoretical work on failure detectors. What it,\nin the end, all boils down to is that a timeout mechanism is used to check\nwhether a process has failed. If a process P probes another process Q to see if\nit has failed, P is said to suspect Q to have crashed if Q has not responded\nwithin some time.\nNote 8.7 (More information: On perfect failure detectors)\nIt should be clear that in a synchronous distributed system, a suspected crash\ncorresponds to a known crash. In practice, however, we will be dealing with\npartially synchronous systems. In that case, it makes more sense to assume\neventually perfect failure detectors. In this case, a process P will suspect another\nprocess Q to have crashed after t time units have elapsed and still Q did not\nrespond to P’s probe. However, if Q later does send a message that is (also)\nreceived by P, P will (1) stop suspecting Q, and (2) increase the timeout value t.\nNote that if Q does crash (and does not recover), P will continue to suspect Q.\nIn real settings, there are problems with using probes and timeouts. For\nexample, due to unreliable networks, simply stating that a process has failed\nbecause it does not return an answer to a probe message may be wrong. In\nother words, it is easy to generate false positives. If a false positive has the\neffect that a perfectly healthy process is removed from a membership list,\nthen clearly we are doing something wrong. Another serious problem is that\ntimeouts are just plain crude. As noticed by Birman [2012], there is hardly\nany work on building proper failure detection subsystems that take more into\naccount than only the lack of a reply to a single message. This statement is\neven more evident when looking at industry-deployed distributed systems.\nThere are various issues that need to be considered when designing a\nfailure-detection subsystem (see also Zhuang et al. [2005]). For example, fail-\nure detection can take place through gossiping in which each node regularly\nannounces to its neighbors that it is still up and running. As we mentioned,\nan alternative is to let nodes actively probe each other.\nFailure detection can also be done as a side effect of regularly exchanging\ninformation with neighbors, as is the case with gossip-based information dis-\nsemination (which we discussed in Chapter 4). This approach was essentially\nalso adopted in Obduro [Vogels, 2003]: processes periodically gossip their\nservice availability. This information is gradually disseminated through the\n \nDS 4.01\n",
      "content_length": 3041,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 524,
      "content": "508\nCHAPTER 8. FAULT TOLERANCE\nnetwork. Eventually, every process will know about every other process, but\nmore importantly, will have enough information locally available to decide\nwhether a process has failed or not. A member for which the availability\ninformation is old, will presumably have failed.\nAnother important issue is that a failure detection subsystem should\nideally be able to distinguish network failures from node failures. One way of\ndealing with this problem is not to let a single node decide whether one of its\nneighbors has crashed. Instead, when noticing a timeout on a probe message,\na node requests other neighbors to see whether they can reach the presumed\nfailing node. Of course, positive information can also be shared: if a node is\nstill alive, that information can be forwarded to other interested parties (who\nmay be detecting a link failure to the suspected node).\nThis brings us to another key issue: when a member failure is detected,\nhow should other nonfaulty processes be informed? One simple, and some-\nwhat radical approach is the following. In FUSE [Dunagan et al., 2004],\nprocesses can be joined in a group that spans a wide-area network. The group\nmembers create a spanning tree that is used for monitoring member failures.\nMembers send ping messages to their neighbors. When a neighbor does not\nrespond, the pinging node immediately switches to a state in which it will\nalso no longer respond to pings from other nodes. By recursion, it is seen that\na single node failure is rapidly promoted to a group failure notification.\n8.3\nReliable client-server communication\nOften, fault tolerance in distributed systems concentrates on faulty processes.\nHowever, we also need to consider communication failures. Most of the\nfailure models discussed previously apply equally well to communication\nchannels. In particular, a communication channel may exhibit crash, omission,\ntiming, and arbitrary failures. In practice, when building reliable communica-\ntion channels, the focus is on masking crash and omission failures. Arbitrary\nfailures may occur in the form of duplicate messages, resulting from the fact\nthat in a computer network messages may be buffered for a relatively long\ntime, and are reinjected into the network after the original sender has already\nissued a retransmission (see, for example, Tanenbaum et al. [2021]).\n8.3.1\nPoint-to-point communication\nIn many distributed systems, reliable point-to-point communication is es-\ntablished by making use of a reliable transport protocol, such as TCP. TCP\nmasks omission failures, which occur in the form of lost messages, by using\nacknowledgments and retransmissions. Such failures are completely hidden\nfrom a TCP client.\nHowever, crash failures of connections are not masked. A crash failure\nmay occur when (for whatever reason) a TCP connection is abruptly broken so\nDS 4.01\n \n",
      "content_length": 2877,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 525,
      "content": "8.3. RELIABLE CLIENT-SERVER COMMUNICATION\n509\nthat no more messages can be transmitted through the channel. In most cases,\nthe client is informed that the channel has crashed by raising an exception.\nThe only way to mask such failures is to let the distributed system attempt\nto automatically set up a new connection, by simply resending a connection\nrequest. The underlying assumption is that the other side is still, or again,\nresponsive to such requests.\n8.3.2\nRPC semantics in the presence of failures\nLet us now take a closer look at client-server communication when using\nhigh-level communication facilities such as remote procedure calls (RPCs).\nThe goal of RPC is to hide communication by making remote procedure calls\nlook just like local ones. With a few exceptions, so far we have come fairly\nclose. Indeed, as long as both client and server are functioning perfectly, RPC\ndoes its job well. The problem comes about when errors occur. It is then that\nthe differences between local and remote calls are not always easy to mask.\nTo structure our discussion, let us distinguish between five different classes\nof failures that can occur in RPC systems, as follows:\n1. The client is unable to locate the server.\n2. The request message from the client to the server is lost.\n3. The server crashes after receiving a request.\n4. The reply message from the server to the client is lost.\n5. The client crashes after sending a request.\nEach of these categories poses different problems and requires different solu-\ntions.\nClient cannot locate the server\nTo start with, it can happen that the client cannot locate a suitable server. All\nservers might be down, for example. Alternatively, suppose that the client is\ncompiled using a particular version of the client stub, and the binary is not\nused for a considerable period of time. Meanwhile, the server evolves and a\nnew version of the interface is installed; new stubs are generated and put into\nuse. When the client is eventually run, the binder will be unable to match\nit up with a server and will report failure. While this mechanism is used to\nprotect the client from accidentally trying to talk to a server that may not\nagree with it in terms of what parameters are required or what it is supposed\nto do, the problem remains of how should this failure be dealt with.\nOne possible solution is to have the error raise an exception. In some\nlanguages, (e.g., Java), programmers can write special procedures that are\ninvoked upon specific errors, such as division by zero. In C, signal handlers\n \nDS 4.01\n",
      "content_length": 2558,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 526,
      "content": "510\nCHAPTER 8. FAULT TOLERANCE\ncan be used for this purpose. In other words, we could define a new signal\ntype SIGNOSERVER, and allow it to be handled in the same way as other\nsignals.\nThis approach, too, has drawbacks. To start with, not every language has\nexceptions or signals. Another point is that having to write an exception\nor signal handler destroys the transparency we have been trying to achieve.\nSuppose that you are a programmer, and you are requested to write the append\nprocedure. You smile and tell her it will be written, tested, and documented\nin five minutes. Then she mentions that you also have to write an exception\nhandler as well, just in case the procedure is not there today. At this point, it\nis pretty hard to maintain the illusion that remote procedures are no different\nfrom local ones, since writing an exception handler for “Cannot locate server”\nwould be a rather unusual request in a nondistributed system.\nLost request messages\nThe second item on the list is dealing with lost request messages. This is\nthe easiest one to deal with: just have the operating system or client stub\nstart a timer when sending the request. If the timer expires before a reply or\nan acknowledgment comes back, the message is sent again. If the message\nwas truly lost, the server will not be able to tell the difference between the\nretransmission and the original, and everything will work fine. Unless, of\ncourse, so many request messages are lost that the client gives up and falsely\nconcludes that the server is down, in which case we are back to “Cannot\nlocate server.” If the request was not lost, the only thing we need to do is let\nthe server be able to detect it is dealing with a retransmission. Unfortunately,\ndoing so is not so simple, as we explain when discussing lost replies.\nServer crashes\nThe next failure on the list is a server crash. The normal sequence of events\nat a server is shown in Figure 8.20(a). A request arrives, is carried out, and a\nreply is sent. Now consider Figure 8.20(b). A request arrives and is carried\nout, just as before, but the server crashes before it can send the reply. Finally,\nlook at Figure 8.20(c). Again a request arrives, but this time the server crashes\nbefore it can even be carried out. And, of course, no reply is sent back.\nThe annoying part of Figure 8.20 is that the correct treatment differs for (b)\nand (c). In (b) the system has to report failure back to the client (e.g., raise an\nexception), whereas in (c) it can just retransmit the request. The problem is\nthat the client’s operating system cannot tell which is which. All it knows is\nthat its timer has expired.\nThree schools of thought exist on what to do here [Spector, 1982]. One\nphilosophy is to wait until the server reboots (or let the client’s middleware\ntransparently rebind to a new server) and try the operation again. The idea is\nDS 4.01\n \n",
      "content_length": 2880,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 527,
      "content": "8.3. RELIABLE CLIENT-SERVER COMMUNICATION\n511\n(a)\n(b)\n(c)\nFigure 8.20: A server in client-server communication. (a) The normal case.\n(b) Crash after execution. (c) Crash before execution.\nto keep trying until a reply has been received, then give it to the client. This\ntechnique is called at-least-once semantics and guarantees that the RPC has\nbeen carried out at least one time, but possibly more.\nThe second philosophy gives up immediately and reports back failure.\nThis approach is called at-most-once semantics and guarantees that the RPC\nhas been carried out at most one time, but possibly not at all.\nThe third philosophy is to guarantee nothing. When a server crashes, the\nclient gets no help and no promises about what happened. The RPC may\nhave been carried out anywhere from zero to many times. The main virtue of\nthis scheme is that it is easy to implement.\nNone of these are terribly attractive. What one would like is exactly-once\nsemantics, but in general, there is no way to arrange this. Imagine that\nthe remote operation consists of processing a document, such as producing\na number of PDF files from LATEX and other sources. The server sends a\ncompletion message to the client when the document has been completely\nprocessed. Also assume that when a client issues a request, it receives an\nacknowledgment that the request has been delivered to the server. There are\ntwo strategies the server can follow. It can either send a completion message\njust before it actually tells the document processor to do its work, or after the\ndocument has been processed.\nAssume that the server crashes and subsequently recovers. It announces\nto all clients that it has just crashed but is now up and running again. The\nproblem is that the client does not know whether its request to process a\ndocument will actually have been carried out.\nThere are four strategies the client can follow. First, the client can decide\nto never reissue a request, at the risk that the document will not be processed.\nSecond, it can decide to always reissue a request, but this may lead to the\ndocument being processed twice (which may easily incur a significant amount\nof work when dealing with intricate documents). Third, it can decide to\nreissue a request only if it did not yet receive an acknowledgment that its\nrequest had been delivered to the server. In that case, the client is counting\non the fact that the server crashed before the request could be delivered.\nThe fourth and last strategy is to reissue a request only if it has received an\n \nDS 4.01\n",
      "content_length": 2545,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 528,
      "content": "512\nCHAPTER 8. FAULT TOLERANCE\nacknowledgment for the request. With two strategies for the server, and four\nfor the client, there are a total of eight combinations to consider. Unfortunately,\nas it turns out, no combination is satisfactory: it can be shown that for any\ncombination either the request is lost forever, or carried out twice.\nNote 8.8 (Advanced: Why fully transparent server recovery is impossible)\nTo explain about server recovery, note that there are three events that can happen\nat the server: send the completion message (M), complete the processing of\nthe document (P), and crash (C). Note that crashing during the processing of a\ndocument is considered the same as crashing before its completion. These events\ncan occur in six different orderings:\n1. M →P →C: A crash occurs after sending the completion message and\nprocessing the document.\n2. M →C(→P): A crash happens after sending the completion message, but\nbefore the document could be (completely) processed.\n3. P →M →C: A crash occurs after sending the completion message and\nprocessing the document.\n4. P →C(→M): The document was processed, after which a crash occurs\nbefore the completion message could be sent.\n5. C(→P →M): A crash happens before the server could complete the\nprocessing of the document.\n6. C(→M →P): A crash happens before the server could even do anything.\nThe parentheses indicate an event that can no longer happen because the server\nalready crashed. Figure 8.21 shows all possible combinations. As can be readily\nverified, there is no combination of client strategy and server strategy that will\nwork correctly under all possible event sequences. The bottom line is that the\nclient can never know whether the server crashed just before or after having the\ntext printed.\nReissue strategy\nAlways\nNever\nOnly when ACKed\nOnly when not ACKed\nClient\nStrategy M →P\nMPC\nMC(P)\nC(MP)\nDUP\nOK\nOK\nOK\nZERO\nZERO\nDUP\nOK\nZERO\nOK\nZERO\nOK\nServer\nStrategy P →M\nPMC\nPC(M)\nC(PM)\nDUP\nDUP\nOK\nOK\nOK\nZERO\nDUP\nOK\nZERO\nOK\nDUP\nOK\nServer\nOK\n=\nDocument processed once\nDUP\n=\nDocument processed twice\nZERO\n=\nDocument not processed at all\nFigure 8.21: Different combinations of client and server strategies in the\npresence of server crashes. Events between brackets never take place\nbecause of a previous crash.\nIn short, the possibility of server crashes radically changes the nature of RPC\nand clearly distinguishes single-processor systems from distributed ones. In the\nDS 4.01\n \n",
      "content_length": 2450,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 529,
      "content": "8.3. RELIABLE CLIENT-SERVER COMMUNICATION\n513\nformer case, a server crash also implies a client crash, so recovery is neither\npossible nor necessary. In the latter we can and should take action.\nLost reply messages\nLost replies can also be difficult to deal with. The obvious solution is just to\nrely on a timer again that has been set by the client’s operating system. If no\nreply is forthcoming within a reasonable period, just send the request once\nmore. The trouble with this solution is that the client is not really sure why\nthere was no answer. Did the request or reply get lost, or is the server merely\nslow? It may make a difference.\nIn particular, some operations can safely be repeated as often as necessary\nwith no damage being done. A request such as asking for the first 1024\nbytes of a file has no side effects and can be executed as often as necessary\nwithout any harm being done. A request that has this property is said to be\nidempotent.\nNow consider a request to a banking server asking to transfer money from\none account to another. If the request arrives and is carried out, but the reply\nis lost, the client will not know this and will retransmit the message. The\nbank server will interpret this request as a new one, and will carry it out too.\nTwice the amount of money will be transferred. Transferring money is not\nidempotent.\nOne way of solving this problem is to try to structure all the requests in\nan idempotent way. In practice, however, many requests (e.g., transferring\nmoney) are inherently nonidempotent, so something else is needed. Another\nmethod is to have the client assign each request a sequence number. By\nhaving the server keep track of the most recently received sequence number\nfrom each client that is using it, the server can tell the difference between\nan original request and a retransmission and can refuse to carry out any\nrequest a second time. However, the server will still have to send a response\nto the client. Note that this approach does require that the server maintains\nadministration on each client. Furthermore, it is not clear how long to maintain\nthis administration. An additional safeguard is to have a bit in the message\nheader that is used to distinguish initial requests from retransmissions (the\nidea being that it is always safe to perform an original request; retransmissions\nmay require more care).\nClient crashes\nThe final item on the list of failures is the client crash. What happens if a\nclient sends a request to a server to do some work and crashes before the\nserver replies? At this point a computation is active and no parent is waiting\nfor the result. Such a computation is called an orphan (computation).\n \nDS 4.01\n",
      "content_length": 2697,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 530,
      "content": "514\nCHAPTER 8. FAULT TOLERANCE\nOrphan computations can cause a variety of problems that can interfere\nwith normal operation of the system. As a bare minimum, they waste pro-\ncessing power. They can also lock files or otherwise tie up valuable resources.\nFinally, if the client reboots and does the RPC again, but the reply from the\norphan comes back immediately afterward, confusion can result. Note that,\nin this case, we are essentially dealing with the problem of guaranteeing\nat-most-once semantics and bringing the client back into a state just before it\ncrashed. As we will explain later, checkpointing just before sending a request,\nand restoring the client to the checkpointed state will solve many problems\nwith orphan computations. In essence, it boils down to let the orphan do its\nwork, and properly restoring the client.\nYet, what can be done about orphans? Four solutions have been pro-\nposed [Nelson, 1981]. First, before a client stub sends an RPC message, it\nmakes a log entry telling what it is about to do. The log is kept on disk or some\nother medium that survives crashes. After a reboot, the log is checked and the\norphan is explicitly killed off. This solution is called orphan extermination,\nan admittedly not very empathically sounding name.\nThe disadvantage of this scheme is the expense of writing a disk record\nfor every RPC. Furthermore, it may not even work, since orphans themselves\nmay do RPCs, thus creating grandorphans or further descendants that are\ndifficult or impossible to locate. Finally, the network may be partitioned, for\nexample because of a failed gateway, making it impossible to kill them, even\nif they can be located. All in all, this is not a promising approach, and, in\ngeneral, will need to be avoided due to its complexity.\nWith the second solution, called reincarnation, all these problems can\nbe solved without the need to write disk records. The way it works is to\ndivide time up into sequentially numbered epochs. When a client recovers,\nit broadcasts a message to all machines declaring the start of a new epoch.\nWhen such a broadcast comes in, all remote computations are killed. Of\ncourse, if the network is partitioned, some orphans may survive. Fortunately,\nhowever, when they report back, their replies will contain an obsolete epoch\nnumber, making them easy to detect.\nThe third solution is a variant on this idea, but somewhat less Draconian.\nIt is called gentle reincarnation. When an epoch broadcast comes in, each\nmachine checks to see if it has any remote computations running locally, and\nif so, tries its best to locate their owners. Only if the owners cannot be located\nanywhere is the computation killed.\nIn the fourth solution, called expiration, each RPC is given a standard\namount of time, T, to do the job. If it cannot finish, it must explicitly ask for\nanother quantum. Of course, this is quite a nuisance. On the other hand, if\nafter a crash the client waits a time T before rebooting, all orphans are sure to\nbe gone. The problem to be solved here is choosing a reasonable value of T in\nthe face of RPCs with wildly differing requirements.\nDS 4.01\n \n",
      "content_length": 3131,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 531,
      "content": "8.4. RELIABLE GROUP COMMUNICATION\n515\nIn practice, all of these methods are crude and undesirable. Worse yet,\nkilling an orphan may have unforeseen consequences. For example, suppose\nthat an orphan has obtained locks on one or more files or database records.\nIf the orphan is suddenly killed, these locks may remain forever. Also, an\norphan may have already made entries in various remote queues to start\nup other processes at some future time, so even killing the orphan may not\nremove all traces of it. Conceivably, it may even have started again, with\nunforeseen consequences. Orphan elimination is discussed in more detail\nby Panzieri and Shrivastava [1988].\nAs mentioned, the best solution is often not to do anything special, but\nattempt to restore the client to a state in which it can handle any response\nfrom its previously orphaned computation. This brings us to checkpointing\nand message logging, which we discuss in Section 8.6.\n8.4\nReliable group communication\nConsidering how important process resilience by replication is, it is not\nsurprising that reliable multicast services are important as well. Such services\nguarantee that messages are delivered to all members in a process group.\nUnfortunately, reliable multicasting turns out to be surprisingly tricky. In\nthis section, we take a closer look at the issues involved in reliably delivering\nmessages to a process group.\n8.4.1\nIntroduction\nLet us first define what reliable group communication actually is. Intuitively,\nit means that a message that is sent to a process group should be delivered\nto each member of that group. If we separate the logic of handling messages\nfrom the core functionality of a group member, we can conveniently make the\ndistinction between receiving messages and delivering messages, as illustrated\nin Figure 8.22. A message is received by a message-handling component,\nwhich, in turn, delivers a message to the component containing the core\nfunctionality of a group member. Informally, a message that is received by\nprocess P will also be delivered by P.\nAs an example, ensuring that messages from the same sender are delivered\nin the same order as they were sent, is typically taken care of by a message-\nhandling component.\nLikewise, providing reliable message-passing is a\nfeature that can and should be separated from the core functionality of a group\nmember, and is typically implemented by a message-handling component (if\nnot by the underlying operating system).\nWith this separation between receiving and delivering messages, we can\nbe more precise about what reliable group communication means. Let us\nmake a distinction between reliable communication in the presence of faulty\nprocesses, and reliable communication when processes are assumed to operate\n \nDS 4.01\n",
      "content_length": 2771,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 532,
      "content": "516\nCHAPTER 8. FAULT TOLERANCE\nFigure 8.22: The distinction between receiving and delivering messages.\ncorrectly. In the first case, group communication is considered to be reliable\nwhen it can be guaranteed that a message is received by and subsequently\ndelivered to all nonfaulty group members.\nThe tricky part here is that agreement should be reached on what the\ngroup actually looks like before a message can be delivered. If a sender\nintended to have a message delivered by each member of a group G, but that,\nfor whatever reason, at the time of delivery we actually have another group\nG′ ̸= G, we should ask ourselves whether the message can be delivered.\nThe situation becomes simpler if we can ignore consensus on group mem-\nbership. In particular, let us first assume that a sending process has a list of\nintended recipients. In that case, it can simply deploy reliable transport-level\nprotocols such as TCP and, one by one, sends its message to each recipient. If\na receiving process fails, the message may be resent later when the process\nrecovers, or ignored altogether (for example, because the sender had left the\ngroup). In case a group member is expected to send a response, even if it\nis just an acknowledgement, communication can be speeded up by separat-\ning the sending of a request from receiving a response, as illustrated by the\nmessage sequence charts in Figure 8.23.\nMost transport layers offer reliable point-to-point channels; they rarely\noffer reliable communication to a group of processes. The best they offer is to\nlet a process set up a point-to-point connection to each other process it wants\nto communicate with. When process groups are relatively small, this approach\nto establishing reliability is a straightforward and practical solution. On the\nother hand, we can often assume that the underlying communication system\ndoes offer unreliable multicasting, meaning that a multicast message may be\nlost part way and delivered by some, but not all, of the intended receivers.\nDS 4.01\n \n",
      "content_length": 2019,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 533,
      "content": "8.4. RELIABLE GROUP COMMUNICATION\n517\n(a)\n(b)\nFigure 8.23: (a) A sender sends out requests, but waits for a response before\nsending out the next one. (b) Requests are sent out in parallel, after which the\nsender waits for incoming responses.\nA simple solution to reach reliable group communication is shown in\nFigure 8.24. The sending process assigns a sequence number to each message\nit multicasts and stores the message locally in a history buffer. Assuming\nthe receivers are known to the sender, the sender simply keeps the message\nin its history buffer until each receiver has returned an acknowledgement.\nA receiver can suspect it is missing a message m with sequence number s\nwhen it has received messages with sequence numbers higher than s. In that\ncase, it returns a negative acknowledgement to the sender, requesting for a\nretransmission of m.\nThere are various design trade-offs to be made. For example, to reduce\nthe number of messages returned to the sender, acknowledgements could\npossibly be piggybacked with other messages. Also, retransmitting a message\ncan be done using point-to-point communication to each requesting process,\nor using a single multicast message sent to all processes. General issues on\nreliable multicasting are discussed by Popescu et al. [2007]. A survey and\noverview of reliable multicasting in the context of publish/subscribe systems,\nwhich is also relevant here, is provided by Esposito et al. [2013].\n \nDS 4.01\n",
      "content_length": 1455,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 534,
      "content": "518\nCHAPTER 8. FAULT TOLERANCE\n(a)\n(b)\nFigure 8.24: A solution for reliable multicasting. (a) Message transmission.\n(b) Reporting feedback.\n8.4.2\nScalability in reliable multicasting\nThe main problem with the reliable multicast scheme just described is that\nit cannot support large numbers of receivers. If there are N receivers, the\nsender must be prepared to accept at least N acknowledgements. With many\nreceivers, the sender may be swamped with such feedback messages, which is\nalso referred to as a feedback implosion. When replicating processes for fault\ntolerance, this situation is not likely to occur as process groups are relatively\nsmall. When replicating for performance, we have a different case. Moreover,\nwe may then also need to take into account that the receivers are spread across\na wide-area network.\nOne solution to the problem of a feedback implosion is not to have re-\nceivers acknowledge the receipt of a message. Instead, a receiver returns a\nfeedback message only to inform the sender it is missing a message. Return-\ning only such negative acknowledgements can be shown to generally scale\nbetter [Towsley et al., 1997], but no hard guarantees can be given that feedback\nimplosions will never happen.\nAnother problem with returning only negative acknowledgements is that\nthe sender will, in theory, be forced to keep a message in its history buffer\nforever. Because the sender can never know if a message has been correctly\ndelivered to all receivers, it should always be prepared for a receiver requesting\nDS 4.01\n \n",
      "content_length": 1543,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 535,
      "content": "8.4. RELIABLE GROUP COMMUNICATION\n519\nthe retransmission of an old message. In practice, the sender will remove a\nmessage from its history buffer after some time has elapsed to prevent the\nbuffer from overflowing. However, removing a message is done at the risk of\na request for a retransmission not being honored.\nSeveral proposals for scalable, reliable multicasting exist. A comparison\nbetween different schemes can be found in [Levine and Garcia-Luna-Aceves,\n1998]. We now briefly discuss two very different approaches that are represen-\ntative of many existing solutions.\nThe key issue to scalable solutions for reliable multicasting is to reduce\nthe number of feedback messages that are returned to the sender. A popular\nmodel that has been applied to several wide-area applications is feedback\nsuppression.\nThis scheme underlies the Scalable Reliable Multicasting\n(SRM) protocol developed by Floyd et al. [1997] and works as follows.\nFirst, in SRM, receivers never acknowledge the successful delivery of a\nmulticast message, but instead, report only when they are missing a mes-\nsage. How message loss is detected is left to the application. Only negative\nacknowledgements are returned as feedback. Whenever a receiver notices that\nit missed a message, it multicasts its feedback to the rest of the group.\nMulticasting feedback allows another group member to suppress its own\nfeedback. Suppose several receivers missed message m. Each of them will\nneed to return a negative acknowledgement to the sender, S, so that m can\nbe retransmitted. However, if we assume that retransmissions are always\nmulticast to the entire group, it is sufficient that only a single request for\nretransmission reaches S.\nFor this reason, a receiver R that did not receive message m schedules a\nfeedback message with some random delay. That is, the request for retrans-\nmission is not sent until some random time has elapsed. If, in the meantime,\nanother request for retransmission for m reaches R, R will suppress its own\nfeedback, knowing that m will be retransmitted shortly. In this way, ideally,\nonly a single feedback message will reach S, which in turn subsequently\nretransmits m. This scheme is shown in Figure 8.25.\nFeedback suppression has shown to scale reasonably well, and has been\nused as the underlying mechanism for a number of collaborative Internet\napplications, such as a shared whiteboard.\nHowever, the approach also\nintroduces a number of serious problems. First, ensuring that only one request\nfor retransmission is returned to the sender requires a reasonably accurate\nscheduling of feedback messages at each receiver. Otherwise, many receivers\nwill still return their feedback at the same time. Setting timers accordingly in\na group of processes that is dispersed across a wide-area network is not that\neasy.\nAnother problem is that multicasting feedback also interrupts those pro-\ncesses to which the message has been successfully delivered. In other words,\nother receivers are forced to receive and process messages that are useless\n \nDS 4.01\n",
      "content_length": 3053,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 536,
      "content": "520\nCHAPTER 8. FAULT TOLERANCE\nFigure 8.25: Several receivers have scheduled a request for retransmission, but\nthe first retransmission request leads to the suppression of others.\nto them.\nThe only solution to this problem is to let receivers that have\nnot received message m join a separate multicast group for m, as explained\nby Kasera et al. [1997]. Unfortunately, this solution requires that groups can\nbe managed in a highly efficient manner, which is hard to accomplish in a\nwide-area system. A better approach is therefore to let receivers that tend to\nmiss the same messages team up and share the same multicast channel for\nfeedback messages and retransmissions. Details on this approach are found\nin [Liu et al., 1998].\nTo enhance the scalability of SRM, it is useful to let receivers assist in local\nrecovery. In particular, if a receiver to which message m has been successfully\ndelivered, receives a request for retransmission, it can decide to multicast m\neven before the retransmission request reaches the original sender. Further\ndetails can be found in [Floyd et al., 1997] and [Liu et al., 1998].\nFeedback suppression as just described is basically a nonhierarchical so-\nlution. However, achieving scalability for large groups of receivers requires\nthat hierarchical approaches are adopted. A solution is shown in Figure 8.26.\nThe group of receivers is partitioned into a number of subgroups, which\nare subsequently organized into a tree. Within each subgroup, any reliable\nmulticasting scheme that works for small groups can be used. Each subgroup\nappoints a local coordinator, which represents that group in the multicast tree.\nA link in the tree between two nodes corresponds to a reliable connection\nbetween the coordinators of the respective subgroups.\nWhen a process S in group G wants to send a message, it simply uses the\nreliable multicast scheme for G to reach all its members, including the group’s\ncoordinator, say C. C, in turn, will forward the message to its neighboring\ncoordinators. As a general rule, a coordinator will forward an incoming\nmessage m to all its neighboring coordinators, except the one from which it\nreceived m. In addition, a coordinator will reliably multicast the incoming\nmessage to all members of the subgroup it represents, and notably also handle\nretransmissions for that group.\nDS 4.01\n \n",
      "content_length": 2347,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 537,
      "content": "8.4. RELIABLE GROUP COMMUNICATION\n521\nIn an ACK-based scheme, if coordinator C of group G sends a message\nm to coordinator C′ of another, neighboring group G′, it will keep m in its\nhistory buffer at least until C′ has sent an acknowledgement. In a NACK-\nbased scheme, only if G′ detects it has missed m (and thus also all members\nof G′, and all coordinators to which G′ would have forwarded m), it will send\na nack message to C. It is thus seen that a single ack or nack message from a\ncoordinator, aggregates many feedback control messages from other processes,\nleading to a much more scalable, reliable multicasting scheme. Scalability\nis further improved by letting a coordinator handle the retransmissions to\nneighboring coordinators, to which it had forwarded a message.\nFigure 8.26: The essence of hierarchical reliable multicasting. Each local\ncoordinator forwards the message to its neighboring coordinators in the tree\nand later handles retransmission requests.\nNote that the nonhierarchical feedback control which we discussed before\ncan be used to improve the scalability of a single multicast group. Together\nwith hierarchical feedback control, we would combine relatively large reliable-\nmulticast subgroups into potentially large trees, thus being able to support\nreliable multicasting for large groups of processes.\nThe main problem with hierarchical solutions is the construction and\nmanagement of the tree: how are subgroups formed, which processes are\nappointed to be coordinator, and how are the subgroups organized in a tree.\nIn many cases, a tree needs to be constructed dynamically. Unfortunately,\ntraditional network-level solutions provide almost no adequate services for\ntree management. For this reason, application-level multicasting solutions as\nwe discussed in Section 4.4.1 have gained popularity.\nFinally, let us briefly consider gossip-based multicasting schemes, in par-\nticular the following push-pull anti-entropy scheme that we discussed exten-\nsively in Section 4.4.3.\nIn this scheme, a node P picks another node Q at random, and subsequently\nexchanges updates with Q. In other words, P pushes updates that Q has not\n \nDS 4.01\n",
      "content_length": 2165,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 538,
      "content": "522\nCHAPTER 8. FAULT TOLERANCE\nseen before to Q, and pulls in any updates that Q has, but which were missed\nby P. After the exchange, both processes have the same data. Clearly, this\nscheme is already inherently robust, for if the communication between P\nand Q fails for whatever reason, P will simply pick some other node to\nexchange updates.\nThe net effect is that the speed by which an update\npropagates through the system slows down, but the reliability is affected only\nin extreme cases. Nevertheless, this slowdown is considered important for\nsome applications. In this light, the comparison between traditional tree-based\nmulticasting and gossip-based multicasting for the purpose of aggregation as\ndiscussed by Nyers and Jelasity [2015] may be of interest.\n8.4.3\nAtomic multicast\nLet us now return to the situation in which we need to achieve reliable\nmulticasting in the presence of process failures. In particular, what is often\nneeded in a distributed system is the guarantee that a message is delivered to\neither all (nonfaulty) group members or to none. This is also known as the\natomic multicast problem, to which we return with greater precision below.\nTo see why atomicity is so important, consider a replicated database con-\nstructed as an application on top of a distributed system. The distributed\nsystem offers reliable multicasting facilities. In particular, it allows the con-\nstruction of process groups to which messages can be reliably sent. The\nreplicated database is therefore constructed as a group of processes, one\nprocess for each replica. Update operations are always multicasted to all\nreplicas and subsequently performed locally. We are thus assuming that an\nactive-replication protocol is being used.\nTo keep matters simple, assume a client contacts a replica P and requests\nit to perform an update. The replica does so by multicasting the update to\nthe other group members. Unfortunately, before the multicast completes,\nP crashes, leaving the rest of the group in a difficult position: some group\nmembers will have received the update request; others will not. If the members\nwho have received the request, deliver it to the database, then obviously\nwe will have an inconsistent replicated database. Some replicas will have\nprocessed the update, others will not. This situation needs to be avoided, and\nwe should either have that the update is delivered to all nonfaulty members, or\nto none. The former case reflects that P crashed after completing the multicast,\nwhile the latter represents P crashing before it even got a chance to request\nthe update.\nBoth these situations are fine, and correspond to the case in which a client\ncommunicates with a single server that is allowed to crash. If a number\nof the group members would execute the update, while others would not,\ndistribution transparency is at stake, but even worse, the client would not\nknow what to make of the situation.\nDS 4.01\n \n",
      "content_length": 2933,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 539,
      "content": "8.4. RELIABLE GROUP COMMUNICATION\n523\nVirtual synchrony\nReliable multicast in the presence of process failures can be accurately defined\nin terms of process groups and changes to group membership. As we did\nearlier, we make a distinction between receiving and delivering a message. In\nparticular, we again adopt a model in which the distributed system consists\nof message-handling components, as was shown in Figure 8.22. A received\nmessage is locally buffered in this component until it can be delivered to the\napplication, which is logically placed as a group member at a higher layer.\nThe whole idea of atomic multicasting is that a multicast message m is\nuniquely associated with a list of processes that should deliver it. This delivery\nlist corresponds to a group view, namely, the view on the set of processes\ncontained in the group, which the sender had at the time message m was\nmulticasted. An important observation is that each process on that list has the\nsame view. In other words, they should all agree that m should be delivered\nby each one of them and by no other process.\nNow suppose that message m is multicasted at the time its sender, say\nP, has group view G.\nFurthermore, assume that while the multicast is\ntaking place, another process Q joins or leaves the group. This change in\ngroup membership is naturally announced to all processes in G. Stated\nsomewhat differently, a view change takes place by multicasting a message\nvc announcing the joining or leaving of Q.\nWe now have two multicast\nmessages simultaneously in transit: m and vc. What we need to guarantee\nis that m is either delivered by all processes in G before any one executes\nthe view change as specified by vc, or m is not delivered at all. Note that\nthis requirement is comparable to totally ordered multicasting, which we\ndiscussed in Section 5.2.1.\nA question that quickly comes to mind is that if m is not delivered by\nany process, how can we speak of a reliable multicast protocol? In principle,\nthere is only one case in which delivery of m is allowed to fail: when the\ngroup membership change is the result of the sender P of m crashing. In that\ncase, either all remaining (nonfaulty) members of G should deliver m before\nagreeing P is no longer member of the group, or none should deliver m. As\nmentioned before, the latter corresponds to the situation that P is considered\nto have crashed before it had a chance to send m.\nThis stronger form of reliable multicast guarantees that a message multicast\nto group view G is delivered by each nonfaulty process in G. If the sender of\nthe message crashes during the multicast, the message is either delivered to\nall remaining processes, or ignored by each of them. Such a reliable multicast\nis said to be virtually synchronous [Birman and Joseph, 1987].\nTo illustrate these matters, consider the four processes shown in Figure 8.27.\nAt a certain moment, we have a group consisting of S1, S2, S3, and S4. After\nsome messages have been multicast, S3 crashes. However, before crashing,\nit succeeded in multicasting a message to processes S2 and S4, but not to S1.\n \nDS 4.01\n",
      "content_length": 3111,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 540,
      "content": "524\nCHAPTER 8. FAULT TOLERANCE\nFigure 8.27: The principle of virtual synchronous multicast.\nVirtual synchrony in this case guarantees that the message is not delivered\nat all, effectively establishing the situation that the message was never sent\nbefore S3 crashed.\nAfter S3 has been removed from the group, communication proceeds\nbetween the remaining group members. Later, when S3 recovers, it can join\nthe group again, after its state has been brought up to date.\nThe principle of virtual synchrony comes from the fact that all multicasts\ntake place between view changes. Put somewhat differently, a view change\nacts as a barrier across which no multicast can pass. In a sense, it is comparable\nto the use of a synchronization variable in distributed data stores, as discussed\nin the Chapter 7. All multicasts that are in transit while a view change\ntakes place are completed before the view change comes into effect. The\nimplementation of virtual synchrony is not trivial, as we discuss below.\nMessage Ordering\nVirtual synchrony allows an application developer to think about multicasts\nas taking place in epochs that are separated by group membership changes.\nHowever, nothing has yet been said concerning the ordering of multicasts. In\ngeneral, four different orderings are distinguished:\n1. Unordered multicasts\n2. FIFO-ordered multicasts\n3. Causally ordered multicasts\n4. Totally ordered multicasts\nA reliable, unordered multicast is a virtually synchronous multicast\nin which no guarantees are given concerning the order in which received\nmessages are delivered by different processes. (Note that reliable multicasting\nis still about realizing the all-or-nothing property when it comes to delivering\nDS 4.01\n \n",
      "content_length": 1719,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 541,
      "content": "8.4. RELIABLE GROUP COMMUNICATION\n525\nmessages to group members.) To explain, assume that reliable multicasting is\nsupported by a library providing a send and a receive primitive. The receive\noperation blocks the caller until a message can be delivered.\nEvent order\nProcess P1\nProcess P2\nProcess P3\n1\nsends m1\nreceives m1\nreceives m2\n2\nsends m2\nreceives m2\nreceives m1\nFigure 8.28: Three communicating processes in the same group. The ordering\nof events per process is shown along the vertical axis.\nNow suppose a sender P1 multicasts two messages to a group, while two\nother processes in that group are waiting for messages to arrive, as shown\nin Figure 8.28. Assuming that processes do not crash or leave the group\nduring these multicasts, it is possible that the message-handling component\nat P2 first receives message m1 and then m2. Because there are no message-\nordering constraints, the messages may be delivered in the order that they are\nreceived. In contrast, the message-handling component at P3 may first receive\nmessage m2 followed by m1, and delivers these two in this same order to the\nhigher-level application of P3.\nIn the case of reliable FIFO-ordered multicasts, the message-handling\ncomponent layer is forced to deliver incoming messages from the same process\nin the same order as they have been sent. Consider the communication within\na group of four processes, as shown in Figure 8.29. With FIFO ordering,\nthe only thing that matters is that message m1 is always delivered before\nm2, and, likewise, that message m3 is always delivered before m4. This rule\nhas to be obeyed by all processes in the group. In other words, when the\ncommunication layer at P3 receives m2 first, it will wait with delivery to P3\nuntil it has received and delivered m1.\nEvent order\nProcess P1\nProcess P2\nProcess P3\nProcess P4\n1\nsends m1\nreceives m1\nreceives m3\nsends m3\n2\nsends m2\nreceives m3\nreceives m1\nsends m4\n3\nreceives m2\nreceives m2\n4\nreceives m4\nreceives m4\nFigure 8.29: Four processes in the same group with two different senders, and\na possible delivery order of messages under FIFO-ordered multicasting.\nHowever, there is no constraint regarding the delivery of messages sent\nby different processes. In other words, if process P2 receives m1 before m3, it\nmay deliver the two messages in that order. Meanwhile, process P3 may have\nreceived m3 before receiving m1. FIFO ordering states that P3 may deliver m3\nbefore m1, although this delivery order is different from that of P2.\n \nDS 4.01\n",
      "content_length": 2498,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 542,
      "content": "526\nCHAPTER 8. FAULT TOLERANCE\nFinally, reliable causally ordered multicast delivers messages so that\npotential causality between different messages is preserved. In other words, if\na message m1 causally precedes another message m2, regardless of whether\nthey were multicasted by the same sender, then the communication layer\nat each receiver will always deliver m2 after it has received and delivered\nm1. Note that causally ordered multicasts can be implemented using vector\ntimestamps, as discussed in Chapter 5.\nBesides these three orderings, there may be the additional constraint that\nmessage delivery is to be totally ordered as well. Totally ordered delivery\nmeans that regardless of whether message delivery is unordered, FIFO or-\ndered, or causally ordered, it is required additionally that when messages are\ndelivered, they are delivered in the same order to all group members.\nFor example, with the combination of FIFO and totally ordered multicast,\nprocesses P2 and P3 in Figure 8.29 may both first deliver message m3 and\nthen message m1. However, if P2 delivers m1 before m3, while P3 delivers m3\nbefore delivering m1, they would violate the total-ordering constraint. Note\nthat FIFO ordering should still be respected. In other words, m2 should be\ndelivered after m1 and, accordingly, m4 should be delivered after m3.\nVirtually synchronous reliable multicasting offering totally ordered de-\nlivery of messages is called atomic multicasting. It encompasses the all-\nor-nothing property discussed before (i.e., all members have the message\ndelivered to, or none of them do), yet atomic multicasting also requires a to-\ntally ordered delivery of messages. With the three different message ordering\nconstraints discussed above, this leads to six forms of reliable multicasting, as\nshown in Figure 8.30 [Hadzilacos and Toueg, 1993].\nMulticast\nBasic message ordering\nTO delivery?\nReliable multicast\nNone\nNo\nFIFO multicast\nFIFO-ordered delivery\nNo\nCausal multicast\nCausal-ordered delivery\nNo\nAtomic multicast\nNone\nYes\nFIFO atomic multicast\nFIFO-ordered delivery\nYes\nCausal atomic multicast\nCausal-ordered delivery\nYes\nFigure 8.30: Six different versions of virtually synchronous reliable multicast-\ning and considering totally ordered delivery.\nNote 8.9 (Advanced: Implementing virtual synchrony)\nLet us now consider a possible implementation of a virtually synchronous reliable\nmulticast. An example of such an implementation appears in Isis, a fault-tolerant\ndistributed system that has been in practical use in industry for several years. We\nwill focus on some of the implementation issues of this technique as described in\nBirman et al. [1991].\nDS 4.01\n \n",
      "content_length": 2666,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 543,
      "content": "8.4. RELIABLE GROUP COMMUNICATION\n527\nReliable multicasting in Isis makes use of available reliable point-to-point com-\nmunication facilities of the underlying network, in particular, TCP. Multicasting a\nmessage m to a group of processes is implemented by reliably sending m to each\ngroup member. As a consequence, although each transmission is guaranteed to\nsucceed, there are no guarantees that all group members receive m. In particular,\nthe sender may fail before having transmitted m to each member.\nBesides reliable point-to-point communication, Isis also assumes that messages\nfrom the same source are received by a communication layer in the order they\nwere sent by that source. In practice, this requirement is solved by using TCP\nconnections for point-to-point communication.\nThe main problem that needs to be solved is to guarantee that all messages\nsent to view G are delivered to all nonfaulty processes in G before the next group\nmembership change takes place. The first issue that needs to be taken care of\nis making sure that each process in G has received all messages that were sent\nto G. Note that because the sender of a message m to G may have failed before\ncompleting its multicast, there may indeed be processes in G that will never\nreceive m. Because the sender has crashed, these processes should get m from\nsomewhere else.\nThe solution to this problem is to let every process in G keep m until it knows\nfor sure that all members in G have received it. If m has been received by all\nmembers in G, m is said to be stable. Only stable messages are allowed to be\ndelivered. To ensure stability, it is sufficient to select an arbitrary live process in\nG and request it to send m to all other processes in G.\n(a)\n(b)\n(c)\nFigure 8.31: (a) Process 4 notices that process 7 has crashed and sends a\nview change. (b) Process 6 sends out all its unstable messages, followed by\na flush message. (c) Process 6 installs the new view when it has received\na flush message from everyone else.\nTo be more specific, assume the current view is Gi, but that it is necessary\nto install the next view Gi+1. Without loss of generality, we assume that Gi and\nGi+1 differ by at most one process. A process P notices the view change when\nit receives a view-change message. Such a message may come from the process\nwanting to join or leave the group, or from a process that had detected the failure\n \nDS 4.01\n",
      "content_length": 2406,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 544,
      "content": "528\nCHAPTER 8. FAULT TOLERANCE\nof a process in Gi that is now to be removed, as shown in Figure 8.31(a).\nWhen a process P receives the view-change message for Gi+1, it first forwards\na copy of any unstable message from Gi it still has to every process in Gi+1, and\nsubsequently marks it as being stable. Recall that Isis assumes point-to-point\ncommunication is reliable, so that forwarded messages are never lost. Such\nforwarding guarantees that all messages in Gi that have been received by at least\none process are received by all nonfaulty processes in Gi. Note that it would also\nhave been sufficient to elect a single coordinator to forward unstable messages.\nTo indicate that P no longer has any unstable messages and that it is prepared\nto install Gi+1 as soon as the other processes can do that as well, it multicasts a\nflush message for Gi+1, as shown in Figure 8.31(b). After P has received a flush\nmessage for Gi+1 from each other process, it can safely install the new view, as\nshown in Figure 8.31(c).\nWhen a process Q receives a message m while Q still believes the current\nview is Gi, it delivers m taking any additional message-ordering constraints into\naccount. If it had already received m, it considers the message to be a duplicate\nand discards it.\nBecause process Q will eventually receive the view-change message for Gi+1,\nit will also first forward any of its unstable messages and subsequently wrap\nthings up by sending a flush message for Gi+1. Note that due to the assumed\nFIFO-message ordering as provided by the underlying communication layer, a\nflush message from a process is always received after the receipt of an unstable\nmessage from that same process.\nThe major flaw in the protocol described so far is that it cannot deal with\nprocess failures while a new view change is being announced. In particular, it\nassumes that until the new view Gi+1 has been installed by each member in\nGi+1, no process in Gi+1 will fail (which would lead to a next view Gi+2). This\nproblem is solved by announcing view changes for any view Gi+k even while\nprevious changes have not yet been installed by all processes. The details are\nrather intricate, yet the principle should be clear.\n8.5\nDistributed commit\nThe atomic multicasting problem discussed in the previous section is an\nexample of a more general problem, known as distributed commit. The\ndistributed commit problem involves having an operation being performed\nby each member of a process group, or none at all. In the case of reliable\nmulticasting, the operation is the delivery of a message. With distributed\ntransactions, the operation may be the commit of a transaction at a single site\nthat takes part in the transaction. Other examples of distributed commit, and\nhow it can be solved, are discussed by Tanisch [2000].\nDistributed commit is often established by a coordinator. In a simple\nscheme, this coordinator tells all other processes that are also involved, called\nparticipants, whether to (locally) perform the operation in question. This\nDS 4.01\n \n",
      "content_length": 3037,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 545,
      "content": "8.5. DISTRIBUTED COMMIT\n529\nscheme is referred to as a one-phase commit protocol. It has the obvious\ndrawback that if one of the participants cannot actually perform the operation,\nthere is no way to tell the coordinator. For example, in the case of distributed\ntransactions, a local commit may not be possible because this would violate\nconcurrency control constraints.\nIn practice, more sophisticated schemes are needed, the most common one\nbeing the two-phase commit protocol, which we discuss in detail below. The\nmain drawback of this protocol is that it cannot generally efficiently handle\nthe failure of the coordinator. To that end, a three-phase protocol has been\ndeveloped, which we discuss separately in Note 8.11.\nThe original two-phase commit protocol (2PC) is due to Gray [1978].\nWithout loss of generality, consider a distributed transaction involving the\nparticipation of a number of processes, each running on a different machine.\nAssuming that no failures occur, the protocol consists of the following two\nphases, each consisting of two steps (see also Bernstein and Newcomer [2009]):\n1. The coordinator sends a vote-request message to all participants.\n2. When a participant receives a vote-request message, it returns either a\nvote-commit message to the coordinator, telling the coordinator that it\nis prepared to locally commit its part of the transaction, or otherwise, a\nvote-abort message.\n3. The coordinator collects all votes from the participants. If all participants\nhave voted to commit the transaction, then so will the coordinator. In that\ncase, it sends a global-commit message to all participants. However,\nif one participant had voted to abort the transaction, the coordinator\nwill also decide to abort the transaction and multicasts a global-abort\nmessage.\n4. Each participant that voted for a commit waits for the final reaction\nby the coordinator. If a participant receives a global-commit mes-\nsage, it locally commits the transaction. Otherwise, when receiving a\nglobal-abort message, the transaction is locally aborted as well.\nThe first phase is the voting phase, and consists of steps 1 and 2. The second\nphase is the decision phase, and consists of steps 3 and 4. These four steps\nare shown as finite state diagrams in Figure 8.32.\nSeveral problems arise when this basic 2PC protocol is used in a system\nwhere failures occur. First, note that the coordinator as well as the participants\nhave states in which they block waiting for incoming messages. Consequently,\nthe protocol can easily fail when a process crashes, as other processes may be\nindefinitely waiting for a message from that process. For this reason, timeout\nmechanisms are used. These mechanisms are explained next.\nWhen taking a look at the finite state machines in Figure 8.32, it can be seen\nthat there are a total of three states in which either a coordinator or participant\n \nDS 4.01\n",
      "content_length": 2896,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 546,
      "content": "530\nCHAPTER 8. FAULT TOLERANCE\n(a)\n(b)\nFigure 8.32: (a) The finite state machine for the coordinator in 2PC. (b) The\nfinite state machine for a participant.\nis blocked waiting for an incoming message. First, a participant may be\nwaiting in its INIT state for a vote-request message from the coordinator.\nIf that message is not received after some time, the participant will simply\ndecide to locally abort the transaction, and thus send a vote-abort message\nto the coordinator.\nLikewise, the coordinator can be blocked in state WAIT, waiting for the\nvotes of each participant. If not all votes have been collected after a cer-\ntain period of time, the coordinator should vote for an abort as well, and\nsubsequently send global-abort to all participants.\nFinally, a participant can be blocked in state READY, waiting for the global\nvote as sent by the coordinator. If that message is not received within a given\ntime, the participant cannot simply decide to abort the transaction. Instead,\nit must find out which message the coordinator actually sent. The simplest\nsolution to this problem is to let each participant block until the coordinator\nrecovers again.\nA better solution is to let a participant P contact another participant Q to\nsee if it can decide from Q’s current state what it should do. For example,\nsuppose that Q had reached state COMMIT.\nThis is possible only if the\ncoordinator had sent a global-commit message to Q just before crashing.\nApparently, this message had not yet been sent to P. Consequently, P may\nnow also decide to locally commit. Likewise, if Q is in state ABORT, P can\nsafely abort as well.\nNow suppose that Q is still in state INIT. This situation can occur when\nthe coordinator has sent vote-request to all participants, but this message\nhas reached P (which subsequently responded with a vote-commit message),\nbut has not reached Q. In other words, the coordinator had crashed while\nmulticasting vote-request. In this case, it is safe to abort the transaction:\nboth P and Q can make a transition to state ABORT.\nThe most difficult situation occurs when Q is also in state READY, waiting\nfor a response from the coordinator. In particular, if it turns out that all\nDS 4.01\n \n",
      "content_length": 2210,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 547,
      "content": "8.5. DISTRIBUTED COMMIT\n531\nparticipants are in state READY, no decision can be taken. The problem\nis that although all participants are willing to commit, they still need the\ncoordinator’s vote to reach the final decision. Consequently, the protocol\nblocks until the coordinator recovers. The various options are summarized in\nFigure 8.33.\nState of Q\nAction by P\nCOMMIT\nMake transition to COMMIT\nABORT\nMake transition to ABORT\nINIT\nMake transition to ABORT\nREADY\nContact another participant\nFigure 8.33: Actions taken by a participant P when residing in state READY\nand having contacted another participant Q.\nTo ensure that a process can actually recover, it is necessary that it saves\nits state to persistent storage. For example, if a participant was in state INIT,\nit can safely decide to locally abort the transaction when it recovers, and then\ninform the coordinator. Likewise, when it had already taken a decision such\nas when it crashed while being in either state COMMIT or ABORT, it is to\nrecover to that state again, and retransmit its decision to the coordinator.\nProblems arise when a participant crashed while residing in state READY.\nIn that case, when recovering, it cannot decide on its own what it should do\nnext, that is, commit or abort the transaction. Consequently, it is forced to\ncontact other participants to find what it should do, analogous to the situation\nwhen it times out while residing in state READY as described above.\nThe coordinator has only two critical states it needs to keep track of. When\nit starts the 2PC protocol, it should record that it is entering state WAIT so\nthat it can possibly retransmit the vote-request message to all participants\nafter recovering. Likewise, if it had come to a decision in the second phase, it\nis sufficient if that decision has been recorded so that it can be retransmitted\nwhen recovering.\nIt may thus be possible that a participant will need to block until the\ncoordinator recovers. This situation occurs when all participants have received\nand processed the vote-request message from the coordinator, while mean-\nwhile, the coordinator crashed. In that case, participants cannot cooperatively\ndecide on the final action to take. For this reason, 2PC is also referred to as a\nblocking commit protocol.\nThere are several solutions to avoid blocking. One solution is to use a\nmulticast primitive, by which a receiver immediately multicasts a received\nmessage to all other processes [Babaoglu and Toueg, 1993]. It can be shown\nthat this approach allows a participant to reach a final decision, even if the\ncoordinator has not yet recovered. Another solution is to use three instead of\ntwo phases, as we discuss in Note 8.11.\n \nDS 4.01\n",
      "content_length": 2709,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 548,
      "content": "532\nCHAPTER 8. FAULT TOLERANCE\nNote 8.10 (Advanced: 2PC outlined in Python)\nAn outline of the actions that are executed by the coordinator is given in Fig-\nure 8.34. The coordinator starts by multicasting a vote-request to all participants\nto collect their votes. It subsequently records that it is entering the WAIT state,\nafter which it waits for incoming votes from participants.\nIf not all votes have been collected, but no more votes are received within\na given time interval prescribed in advance, the coordinator assumes that one\nor more participants have failed. Consequently, it should abort the transaction\nand multicasts a global-abort to the (remaining) participants. Likewise, if only\na single participant decides to abort the transaction, the coordinator will have\nto call off the transaction. If all participants vote to commit, global-commit is\nfirst logged and subsequently sent to all processes. Otherwise, the coordinator\nmulticasts a global-abort (after recording it in the local log).\n1 class Coordinator:\n2\ndef run(self):\n3\nyetToReceive = list(self.participants)\n4\nself.log.info(’WAIT’)\n5\nself.chan.sendTo(self.participants, VOTE_REQUEST)\n6\nwhile len(yetToReceive) > 0:\n7\nmsg = self.chan.recvFrom(self.participants, BLOCK, TIMEOUT)\n8\nif msg == -1 or (msg[1] == VOTE_ABORT):\n9\nself.log.info(’ABORT’)\n10\nself.chan.sendTo(self.participants, GLOBAL_ABORT)\n11\nreturn\n12\nelse: # msg[1] == VOTE_COMMIT\n13\nyetToReceive.remove(msg[0])\n14\nself.log.info(’COMMIT’)\n15\nself.chan.sendTo(self.participants, GLOBAL_COMMIT)\nFigure 8.34: The steps taken by the coordinator in a 2PC protocol.\nAfter receiving a vote request, the participant does its work. All bets are\noff if its work failed, but otherwise, it will vote for committing the transaction.\nIt records its decision in a local log and informs the coordinator by sending a\nvote-commit message. The participant must then wait for the global decision.\nAssuming this decision (which again should come from the coordinator) comes in\non time, it is simply written to the local log, after which it can be carried out (the\nlatter is not shown in the code).\nFigure 8.35 shows the steps taken by a participant. First, the process waits for\na vote request from the coordinator. If no message comes in, the transaction is\nsimply aborted. Apparently, the coordinator had failed.\nHowever, if the participant times out while waiting for the coordinator’s\ndecision to come in, it executes a termination protocol by first multicasting a\ndecision-request message to the other processes, after which it subsequently\nblocks while waiting for a response. When a decisive response comes in (possibly\nfrom the coordinator, which is assumed to eventually recover), the participant\nDS 4.01\n \n",
      "content_length": 2731,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 549,
      "content": "8.5. DISTRIBUTED COMMIT\n533\nwrites the decision to its local log and handles accordingly. Any request from\nanother participant for the final decision is left unanswered as long as that decision\nis not known.\n1 class Participant:\n2\ndef run(self):\n3\nself.log.info(’INIT’)\n4\nmsg = self.chan.recvFrom(self.coordinator, BLOCK, TIMEOUT)\n5\nif msg == -1:\n# Crashed coordinator - give up entirely\n6\ndecision = LOCAL_ABORT\n7\nelse: # Coordinator will have sent VOTE_REQUEST\n8\ndecision = self.do_work()\n9\nif decision == LOCAL_ABORT:\n10\nself.chan.sendTo(self.coordinator, VOTE_ABORT)\n11\nself.log.info(’LOCAL_ABORT’)\n12\nelse: # Ready to commit, enter READY state\n13\nself.log.info(’READY’)\n14\nself.chan.sendTo(self.coordinator, VOTE_COMMIT)\n15\nmsg = self.chan.recvFrom(self.coordinator, BLOCK, TIMEOUT)\n16\nif msg == -1: # Crashed coordinator - check the others\n17\nself.log.info(’NEED_DECISION’)\n18\nself.chan.sendTo(self.participants, NEED_DECISION)\n19\nwhile True:\n20\nmsg = self.chan.recvFromAny()\n21\nif msg[1] in [GLOBAL_COMMIT, GLOBAL_ABORT, LOCAL_ABORT]:\n22\ndecision = msg[1]\n23\nbreak\n24\nelse: # Coordinator came to a decision\n25\ndecision = msg[1]\n26\nif decision == GLOBAL_COMMIT:\n27\nself.log.info(’COMMIT’)\n28\nelse: # decision in [GLOBAL_ABORT, LOCAL_ABORT]:\n29\nself.log.info(’ABORT’)\n30\nwhile True: # Help any other participant when coordinator crashed\n31\nmsg = self.chan.recvFrom(self.participants)\n32\nif msg[1] == NEED_DECISION:\n33\nself.chan.sendTo([msg[0]], decision)\nFigure 8.35: The steps taken by a participant process in 2PC.\nWe keep every participant up-and-running after it decided to either commit\nor abort. It can then assist other participants in need of a decision after detecting\nthat the coordinator had crashed. To this end, a participant blocks on incoming\nmessages and returns its own decision when asked for. Note that we are actually\nproviding an implementation that supports partially synchronous behavior: we\nassume that timeouts can be applied as a mechanism to detect failures, but take\ninto account that we may have mistakenly concluded that a server crashed.\nOf course, the final, now endless loop should eventually terminate. To that\nend, we need a mechanism to detect that all processes have indeed come to a\ndecision. We leave it as an exercise to the reader for designing such a detector.\n \nDS 4.01\n",
      "content_length": 2318,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 550,
      "content": "534\nCHAPTER 8. FAULT TOLERANCE\nNote 8.11 (Advanced: Three-phase commit)\nA problem with the two-phase commit protocol is that when the coordinator has\ncrashed, participants may not be able to reach a final decision. Consequently,\nparticipants may need to remain blocked until the coordinator recovers. Skeen\n[1981] developed a variant of 2PC, called the three-phase commit protocol (3PC),\nthat avoids blocking processes in the presence of fail-stop crashes. Although 3PC\nis widely referred to in the literature, it is not applied often in practice, as the\nconditions under which 2PC blocks rarely occur. We discuss the protocol, as\nit provides further insight into solving fault-tolerance problems in distributed\nsystems.\nLike 2PC, 3PC is also formulated in terms of a coordinator and a number of\nparticipants. Their respective finite state machines are shown in Figure 8.36. The\nessence of the protocol is that the states of the coordinator and each participant\nsatisfy the following two conditions:\n1. There is no single state from which it is possible to make a transition directly\nto either a COMMIT or an ABORT state.\n2. There is no state in which it is not possible to make a final decision, and\nfrom which a transition to a COMMIT state can be made.\nIt can be shown that these two conditions are necessary and sufficient for a commit\nprotocol to be nonblocking [Skeen and Stonebraker, 1983].\n(a)\n(b)\nFigure 8.36: (a) The finite state machine for the coordinator in 3PC. (b) The\nfinite state machine for a participant.\nThe coordinator in 3PC starts with sending a vote-request message to all\nparticipants, after which it waits for incoming responses. If any participant\nvotes to abort the transaction, the final decision will be to abort as well, so\nthe coordinator sends global-abort. However, when the transaction can be\ncommitted, a prepare-commit message is sent. Only after each participant has\nacknowledged it is now prepared to commit, will the coordinator send the final\nglobal-commit message by which the transaction is actually committed.\nAgain, there are only a few situations in which a process is blocked while\nwaiting for incoming messages. First, if a participant is waiting for a vote request\nDS 4.01\n \n",
      "content_length": 2224,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 551,
      "content": "8.5. DISTRIBUTED COMMIT\n535\nfrom the coordinator while residing in state INIT, it will eventually make a\ntransition to state ABORT, thereby assuming that the coordinator has crashed.\nThis situation is identical to that in 2PC. Analogously, the coordinator may be in\nstate WAIT, waiting for the votes from participants. On a timeout, the coordinator\nwill conclude that a participant crashed, and will thus abort the transaction by\nmulticasting a global-abort message.\nNow suppose the coordinator is blocked in state PRECOMMIT. On a timeout,\nit will conclude that one of the participants had crashed, but that participant\nis known to have voted for committing the transaction. Consequently, the co-\nordinator can instruct the operational participants to commit by multicasting a\nglobal-commit message. In addition, it relies on a recovery protocol for the\ncrashed participant to commit its part of the transaction when it comes up again.\nA participant P may block in the READY state or in the PRECOMMIT state.\nOn a timeout, P can conclude only that the coordinator has failed so that it now\nneeds to find out what to do next. As in 2PC, if P contacts any other participant\nthat is in state COMMIT (or ABORT), P should move to that state as well. In\naddition, if all participants are in state PRECOMMIT, the transaction can be\ncommitted.\nAgain analogous to 2PC, if another participant Q is still in the INIT state,\nthe transaction can safely be aborted. It is important to note that Q can be in\nstate INIT only if no other participant is in state PRECOMMIT. A participant\ncan reach PRECOMMIT only if the coordinator had reached state PRECOMMIT\nbefore crashing, and has thus received a vote to commit from each participant. In\nother words, no participant can reside in state INIT while another participant is in\nstate PRECOMMIT.\nIf each of the participants that P can contact is in state READY (and they\ntogether form a majority), the transaction should be aborted. The point to note\nis that another participant may have crashed and will later recover. However,\nneither P, nor any other of the operational participants knows what the state of\nthe crashed participant will be when it recovers. If the process recovers to state\nINIT, then deciding to abort the transaction is the only correct decision. At worst,\nthe process may recover to state PRECOMMIT, but in that case, it cannot do any\nharm to still abort the transaction.\nThis situation is the major difference with 2PC, where a crashed participant\ncould recover to a COMMIT state while all the others were still in state READY.\nIn that case, the remaining operational processes could not reach a final decision\nand would have to wait until the crashed process recovered. With 3PC, if any\noperational process is in its READY state, no crashed process will recover to a state\nother than INIT, ABORT, or PRECOMMIT. For this reason, surviving processes\ncan always come to a final decision.\nFinally, if the processes that P can reach are in state PRECOMMIT (and they\nform a majority), then it is safe to commit the transaction. Again, it can be shown\nthat in this case, all other processes will either be in state READY or at least,\nwill recover to state READY, PRECOMMIT, or COMMIT when they had crashed.\nMore on 3PC can be found in [Bernstein et al., 1987].\n \nDS 4.01\n",
      "content_length": 3317,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 552,
      "content": "536\nCHAPTER 8. FAULT TOLERANCE\n8.6\nRecovery\nSo far, we have mainly concentrated on algorithms that allow us to tolerate\nfaults. However, once a failure has occurred, it is essential that the process\nwhere the failure happened can recover to a correct state. In what follows, we\nfirst concentrate on what it actually means to recover to a correct state, and\nsubsequently when and how the state of a distributed system can be recorded\nand recovered to, through checkpointing and message logging.\n8.6.1\nIntroduction\nFundamental to fault tolerance is the recovery from an error. Recall that an\nerror is that part of a system that may lead to a failure. The whole idea of\nerror recovery is to replace an erroneous state with an error-free state. There\nare essentially two forms of error recovery.\nIn backward recovery, the main issue is to bring the system from its\npresent erroneous state back into a previously correct state. To do so, it will\nbe necessary to record the system’s state from time to time, and to restore\nsuch a recorded state when things go wrong. Each time (part of) the system’s\npresent state is recorded, a checkpoint is said to be made.\nAnother form of error recovery is forward recovery. In this case, when the\nsystem has entered an erroneous state, instead of moving back to a previous,\ncheckpointed state, an attempt is made to bring the system to a correct new\nstate from which it can continue to execute. The main problem with forward\nerror recovery mechanisms is that it has to be known in advance which errors\nmay occur. Only in that case, it is possible to correct those errors and move to\na new state.\nThe distinction between backward and forward error recovery is easily\nexplained when considering the implementation of reliable communication.\nThe common approach to recover from a lost packet is to let the sender\nretransmit that packet. In effect, packet retransmission establishes that we\nattempt to go back to a previous, correct state, namely the one in which the\npacket that was lost is being sent. Reliable communication through packet\nretransmission is therefore an example of applying backward error recovery\ntechniques.\nAn alternative approach is to use a method known as erasure correction.\nIn this approach, a missing packet is constructed from other, successfully\ndelivered packets. For example, in an (n, k)-block erasure code, a set of k\nsource packets is encoded into a set of n encoded packets, such that any set of k\nencoded packets is enough to reconstruct the original k source packets. Typical\nvalues are k = 16 or k = 32, and k < n ≤2k (see, for example, Rizzo [1997]). If\nnot enough packets have yet been delivered, the sender will have to continue\ntransmitting packets until a previously lost packet can be constructed. Erasure\ncorrection is a typical example of a forward error recovery approach.\nDS 4.01\n \n",
      "content_length": 2859,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 553,
      "content": "8.6. RECOVERY\n537\nBy and large, backward error recovery techniques are widely applied as a\ngeneral mechanism for recovering from failures in distributed systems. The\nmajor benefit of backward error recovery is that it is a generally applicable\nmethod independent of any specific system or process. In other words, it\ncan be integrated into (the middleware layer) of a distributed system as a\ngeneral-purpose service.\nHowever, backward error recovery also introduces some problems [Singhal\nand Shivaratri, 1994]. First, restoring a system or process to a previous state\nis generally a relatively costly operation in terms of performance. As will be\ndiscussed in succeeding sections, much work generally needs to be done to\nrecover from, for example, a process crash or site failure. A potential way out\nof this problem is to devise very cheap mechanisms by which components are\nsimply rebooted.\nSecond, because backward error recovery mechanisms are independent of\nthe distributed application for which they are actually used, no guarantees\ncan be given that once recovery has taken place, the same or similar failure\nwill not happen again. If such guarantees are needed, handling errors often\nrequires that the application gets into the loop of recovery. In other words,\nfull-fledged failure transparency can generally not be provided by backward\nerror recovery mechanisms.\nFinally, although backward error recovery requires checkpointing, some\nstates can simply never be rolled back to. For example, once a (possibly\nmalicious) person has taken the $1,000 that suddenly came rolling out of the\nincorrectly functioning automated teller machine, there is only a small chance\nthat money will be stuffed back in the machine. Likewise, recovering to a\nprevious state in most Unix systems after having enthusiastically typed\n/bin/rm -fr *\nbut from the wrong working directory, may turn a few people pale. Some\nthings are simply irreversible.\nCheckpointing allows the recovery to a previous, correct state. However,\ntaking a checkpoint is often a costly operation and may have a severe perfor-\nmance penalty. As a consequence, many fault-tolerant distributed systems\ncombine checkpointing with message logging. In this case, after a check-\npoint has been taken, a process logs its messages before sending them off\n(called sender-based logging). An alternative solution is to let the receiving\nprocess first log an incoming message before delivering it to the application\nit is executing. This scheme is also referred to as receiver-based logging.\nWhen a receiving process crashes, it is necessary to restore the most recently\ncheckpointed state, and from there on replay the messages that have been sent.\nConsequently, combining checkpoints with message logging makes it possible\nto restore a state that lies beyond the most recent checkpoint without the cost\nof checkpointing.\nIn a system where only checkpointing is used, processes will be restored\n \nDS 4.01\n",
      "content_length": 2955,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 554,
      "content": "538\nCHAPTER 8. FAULT TOLERANCE\nto a checkpointed state. From there on, their behavior may be different from\nit was before the failure occurred. For example, because communication times\nare not deterministic, messages may now be delivered in a different order,\nin turn leading to different reactions by the receivers. However, if message\nlogging takes place, an actual replay of the events that happened since the\nlast checkpoint takes place. Such a replay makes it easier to interact with the\noutside world.\nFor example, consider the case that a failure occurred because a user\nprovided erroneous input. If only checkpointing is used, the system would\nhave to take a checkpoint before accepting the user’s input in order to recover\nto the same state. With message logging, an older checkpoint can be used, after\nwhich a replay of events can take place up to the point that the user should\nprovide input. In practice, the combination of having fewer checkpoints and\nmessage logging is more efficient than having to take many checkpoints.\nElnozahy et al. [2002] provide a survey of checkpointing and logging in\ndistributed systems. Various algorithmic details can be found in Chow and\nJohnson [1997].\n8.6.2\nCheckpointing\nIn a fault-tolerant distributed system, backward error recovery requires that\nthe system regularly saves its state2.\nIn particular, we need to record a\nconsistent global state, also called a distributed snapshot. In a distributed\nsnapshot, if a process P has recorded the receipt of a message, then there\nshould also be a process Q that has recorded the sending of that message.\nAfter all, it must have come from somewhere.\nFigure 8.37: A recovery line.\nTo recover after a process or system failure requires that we construct a\nconsistent global state from local states as saved by each process. In particular,\nit is best to recover to the most recent distributed snapshot, also referred to\nas a recovery line. In other words, a recovery line corresponds to the most\nrecent consistent collection of checkpoints, as shown in Figure 8.37.\n2We assume that each process has access to a local, reliable storage.\nDS 4.01\n \n",
      "content_length": 2136,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 555,
      "content": "8.6. RECOVERY\n539\nCoordinated checkpointing\nIn coordinated checkpointing all processes synchronize to jointly write their\nstate to local storage. The main advantage of coordinated checkpointing is\nthat the saved state is automatically globally consistent. A simple solution\nis to use a two-phase blocking protocol. A coordinator first multicasts a\ncheckpoint-request message to all processes.\nWhen a process receives\nsuch a message, it takes a local checkpoint, queues any subsequent message\nhanded to it by the application it is executing, and acknowledges to the\ncoordinator that it has taken a checkpoint. When the coordinator has received\nan acknowledgment from all processes, it multicasts a checkpoint-done\nmessage to allow the (blocked) processes to continue.\nIt is easy to see that this approach will indeed lead to a globally consis-\ntent state because no incoming message will ever be registered as part of a\ncheckpoint. This is because any message that follows a request for taking\na checkpoint is not considered to be part of the local checkpoint. At the\nsame time, outgoing messages (as handed to the checkpointing process by\nthe application it is running), are queued locally until the checkpoint-done\nmessage is received.\nAn improvement to this algorithm is to send a checkpoint request only to\nthose processes that depend on the recovery of the coordinator, and ignore the\nother processes. A process is dependent on the coordinator if it has received a\nmessage that is directly or indirectly causally related to a message that the\ncoordinator had sent since the last checkpoint. This leads to the notion of an\nincremental snapshot.\nTo take an incremental snapshot, the coordinator sends a checkpoint\nrequest only to those processes it had sent a message to since it last took a\ncheckpoint. When a process P receives such a request, it forwards the request\nto all those processes to which P itself had sent a message since the last\ncheckpoint, and so on. A process forwards the request only once. When all\nprocesses have been identified, a second multicast is used to actually trigger\ncheckpointing and to let the processes continue where they had left off.\nIndependent checkpointing\nNow consider the case in which each process simply records its local state\nfrom time to time in an uncoordinated fashion. To discover a recovery line,\nrequires that each process is rolled back to its most recently saved state. If\nthese local states jointly do not form a distributed snapshot, further rolling\nback is necessary. This process of a cascaded rollback may lead to what is\ncalled the domino effect and is shown in Figure 8.38.\nWhen process P2 crashes, we need to restore its state to the most recently\nsaved checkpoint. As a consequence, process P1 will also need to be rolled\nback. Unfortunately, the two most recently saved local states do not form a\n \nDS 4.01\n",
      "content_length": 2873,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 556,
      "content": "540\nCHAPTER 8. FAULT TOLERANCE\nFigure 8.38: The domino effect.\nconsistent global state: the state saved by P2 indicates the receipt of a message\nm, but no other process can be identified as its sender. Consequently, P2 needs\nto be rolled back to an earlier state.\nHowever, the next state to which P2 is rolled back also cannot be used as\npart of a distributed snapshot. In this case, P1 will have recorded the receipt\nof message m∗, but there is no recorded event of this message being sent. It is\ntherefore necessary to also roll P1 back to a previous state. In this example, it\nturns out that the recovery line is actually the initial state of the system.\nAs processes take local checkpoints independent of each other, this method\nis also referred to as independent checkpointing. Its implementation requires\nthat dependencies are recorded in such a way that processes can jointly roll\nback to a consistent global state. To that end, let CPi(m) denote the mth\ncheckpoint taken by process Pi. Also, let INTi(m) denote the interval between\ncheckpoints CPi(m −1) and CPi(m).\nWhen process Pi sends a message in interval INTi(m), it piggybacks the\npair (i, m) to the receiving process. When process Pj receives a message in in-\nterval INTj(n), along with the pair of indices (i, m), it records the dependency\nINTi(m) →INTj(n). Whenever Pj takes checkpoint CPj(n), it additionally\nsaves this dependency to its local storage, along with the rest of the recovery\ninformation that is part of CPj(n).\nNow suppose that at a certain moment, process Pi is required to roll back\nto checkpoint CPi(m −1). To ensure global consistency, we need to ensure\nthat all processes that have received messages from Pi and that were sent in\ninterval INTi(m), are rolled back to a checkpointed state preceding the receipt\nof such messages. In particular, process Pj in our example, will need to be\nrolled back at least to checkpoint CPj(n −1). If CPj(n −1) does not lead to a\nglobally consistent state, further rolling back may be necessary.\nCalculating the recovery line requires an analysis of the interval dependen-\ncies recorded by each process when a checkpoint was taken. It turns out that\nsuch calculations are fairly complex. In addition, as it turns out, it is often\nnot the coordination between processes that is the dominating performance\nfactor, but the overhead as the result of having to save the state to local stable\nstorage. Therefore, coordinated checkpointing, which is much simpler than\nindependent checkpointing, is often more popular, and will presumably stay\nso even when systems grow to much larger sizes [Elnozahy and Plank, 2004]\nDS 4.01\n \n",
      "content_length": 2641,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 557,
      "content": "8.6. RECOVERY\n541\n8.6.3\nMessage logging\nConsidering that checkpointing can be an expensive operation, techniques\nhave been sought to reduce the number of checkpoints, but still enable re-\ncovery. One such technique is logging messages. The basic idea underlying\nmessage logging is that if the transmission of messages can be replayed, we\ncan still reach a globally consistent state, but without having to restore that\nstate from local storage. Instead, a checkpointed state is taken as a starting\npoint, and all messages that have been sent since are simply retransmitted\nand handled accordingly.\nThis approach works fine under the assumption of what is called a piece-\nwise deterministic execution model. In such a model, the execution of each\nprocess is assumed to take place as a series of intervals in which events take\nplace. These events are the same as those discussed in the context of Lam-\nport’s happened-before relationship in Section 5.2.1. For example, an event\nmay be the execution of an instruction, the sending of a message, and so on.\nEach interval in the piecewise deterministic model is assumed to start with\na nondeterministic event, such as the receipt of a message. However, from\nthat moment on, the execution of the process is completely deterministic. An\ninterval ends with the last event before a nondeterministic event occurs.\nIn effect, an interval can be replayed with a known result, that is, in a\ncompletely deterministic way, provided it is replayed, starting with the same\nnondeterministic event as before. Consequently, if we record all nondeter-\nministic events in such a model, it becomes possible to completely replay the\nentire execution of a process in a deterministic way.\nConsidering that message logs are necessary to recover from a process\ncrash so that a globally consistent state is restored, it becomes important to\nknow precisely when messages are to be logged. Following the approach\ndescribed by Alvisi and Marzullo [1998], it turns out that many existing\nmessage-logging schemes can be easily characterized if we concentrate on\nhow they deal with orphan processes.\nAn orphan process is a process that survives the crash of another process,\nbut whose state is inconsistent with the crashed process after its recovery. As\nan example, consider the situation shown in Figure 8.39. Process Q receives\nmessages m1 and m2 from process P and R, respectively, and subsequently\nsends a message m3 to R. However, in contrast to all other messages, message\nm2 is not logged. If process Q crashes and later recovers again, only the logged\nmessages required for the recovery of Q are replayed, in our example, m1.\nBecause m2 was not logged, its transmission will not be replayed, meaning\nthat the transmission of m3 may also not take place.\nHowever, the situation after the recovery of Q is inconsistent with that\nbefore its recovery. In particular, R holds a message (m3) that was sent before\nthe crash, but whose receipt and delivery do not take place when replaying\nwhat had happened before the crash. This should obviously be avoided.\n \nDS 4.01\n",
      "content_length": 3084,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 558,
      "content": "542\nCHAPTER 8. FAULT TOLERANCE\nFigure 8.39: Incorrect replay of messages after recovery, leading to an orphan\nprocess R.\nNote 8.12 (Advanced: Characterizing message-logging schemes)\nTo characterize different message-logging schemes, we follow the approach de-\nscribed by Alvisi and Marzullo [1998]. Each message m is considered to have a\nheader that contains all information necessary to retransmit m, and to properly\nhandle it. For example, each header will identify the sender and the receiver, but\nalso a sequence number to recognize it as a duplicate. In addition, a delivery\nnumber may be added to decide when exactly it should be handed over to the\nreceiving application.\nA message is said to be stable if it can no longer be lost, for example because\nit has been written to reliable, local storage. Stable messages can thus be used for\nrecovery by replaying their transmission.\nEach message m leads to a set DEP(m) of processes that depend on the\ndelivery of m. In particular, DEP(m) consists of those processes to which m has\nbeen delivered. In addition, if another message m∗is causally dependent on\nthe delivery of m, and m∗has been delivered to a process Q, then Q will also\nbe contained in DEP(m). Note that m∗is causally dependent on the delivery of\nm, if it was sent by the same process that previously delivered m, or which had\ndelivered another message that was causally dependent on the delivery of m.\nThe set COPY(m) consists of those processes that have a copy of m, but have\nnot (yet) reliably stored it. When a process Q delivers message m, it also becomes\na member of COPY(m). Note that COPY(m) consists of those processes that could\nhand over a copy of m that can be used to replay the transmission of m. If all\nthese processes crash, replaying the transmission of m is clearly not feasible.\nUsing these notations, it is now easy to define precisely what an orphan\nprocess is. Let FAIL denote the collection of crashed processes, and assume Q is\none of the survivors. Q is an orphan process if there is a message m, such that\nQ is contained in DEP(m), while at the same time every process in COPY(m) has\ncrashed. More formally:\nQ is orphaned ⇔∃m : Q ∈DEP(m) and COPY(m) ⊆FAIL\nIn other words, an orphan process appears when it is dependent on m, but there\nDS 4.01\n \n",
      "content_length": 2288,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 559,
      "content": "8.7. SUMMARY\n543\nis no way to replay m’s transmission.\nTo avoid orphan processes, we thus need to ensure that if each process in\nCOPY(m) crashed, then no surviving process is left in DEP(m). In other words, all\nprocesses in DEP(m) should have crashed as well. This condition can be enforced\nif we can guarantee that whenever a process becomes a member of DEP(m), it also\nbecomes a member of COPY(m). In other words, whenever a process becomes\ndependent on the delivery of m, it will keep a copy of m.\nThere are essentially two approaches that can now be followed. The first\napproach is represented by what are called pessimistic logging protocols. These\nprotocols take care that for each nonstable message m, there is at most one process\ndependent on m. In other words, pessimistic logging protocols ensure that each\nnonstable message m is delivered to at most one process. Note that as soon as m\nis delivered to, say, process P, P becomes a member of COPY(m).\nThe worst that can happen is that process P crashes without m ever having\nbeen logged. With pessimistic logging, P is not allowed to send any messages\nafter the delivery of m without first having ensured that m has been written to\nreliable storage. Consequently, no other processes will ever become dependent on\nthe delivery of m to P, without having the possibility of replaying the transmission\nof m. In this way, orphan processes are always avoided.\nIn contrast, in an optimistic logging protocol, the actual work is done after\na crash occurs. In particular, assume that for some message m, each process in\nCOPY(m) has crashed. In an optimistic approach, any orphan process in DEP(m)\nis rolled back to a state in which it no longer belongs to DEP(m). Clearly, optimistic\nlogging protocols need to keep track of dependencies, which complicates their\nimplementation.\nAs pointed out by Elnozahy et al. [2002], pessimistic logging is so much\nsimpler than optimistic approaches, that it is the preferred way of message\nlogging in practical distributed systems design.\n8.7\nSummary\nFault tolerance is an important subject in distributed systems design. Fault\ntolerance is defined as the characteristic by which a system can mask the\noccurrence and recovery from failures. In other words, a system is fault\ntolerant if it can continue to operate in the presence of failures.\nSeveral types of failures exist. A crash failure occurs when a process\nsimply halts. An omission failure occurs when a process does not respond to\nincoming requests. When a process responds too soon or too late to a request,\nit is said to exhibit a timing failure. Responding to an incoming request, but in\nthe wrong way, is an example of a response failure. The most difficult failures\nto handle are those by which a process exhibits any kind of failure, called\narbitrary or Byzantine failures.\nRedundancy is the key technique needed to achieve fault tolerance. When\napplied to processes, the notion of process groups becomes important. A\n \nDS 4.01\n",
      "content_length": 2981,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 560,
      "content": "544\nCHAPTER 8. FAULT TOLERANCE\nprocess group consists of a number of processes that closely cooperate to\nprovide a service. In fault-tolerant process groups, one or more processes\ncan fail without affecting the availability of the service the group implements.\nOften, it is necessary that communication within the group be highly reliable,\nand adheres to stringent ordering and atomicity properties to achieve fault\ntolerance.\nThe real problem is that members of a process group need to reach consen-\nsus in the presence of various failures. Paxos is by now a well-established and\nhighly robust consensus algorithm. By using 2k + 1 servers, it can establish\nk-fault tolerance. However, we need a total of 3k + 1 servers if it is needed to\ndeal with arbitrary failures.\nReliable group communication, also called reliable multicasting, comes\nin different forms. As long as groups are relatively small, it turns out that\nimplementing reliability is feasible. However, as soon as large groups have to\nbe supported, scalability of reliable multicasting becomes problematic. The\nkey issue in achieving scalability is to reduce the number of feedback messages\nby which receivers report the (un)successful receipt of a multicasted message.\nMatters become worse when atomicity is to be provided. In atomic mul-\nticast protocols, it is essential that each group member has the same view\nconcerning to which members a multicasted message has been delivered.\nAtomic multicasting can be precisely formulated in terms of a virtual syn-\nchronous execution model. In essence, this model introduces boundaries\nbetween which group membership does not change and which messages are\nreliably transmitted. A message can never cross a boundary.\nGroup membership changes are an example where each process needs to\nagree on the same list of members. Such agreement can be reached through a\ncommit protocol, of which the two-phase commit protocol is the most widely\napplied. In a two-phase commit protocol, a coordinator first checks whether\nall processes agree to perform the same operation (i.e., whether they all agree\nto commit), and in a second round, multicasts the outcome of that poll. A\nthree-phase commit protocol is used to handle the crash of the coordinator\nwithout having to block all processes to reach agreement until the coordinator\nrecovers.\nRecovery in fault-tolerant systems is invariably achieved by checkpointing\nthe state of the system on a regular basis.\nCheckpointing is completely\ndistributed. Unfortunately, taking a checkpoint is an expensive operation.\nTo improve performance, many distributed systems combine checkpointing\nwith message logging. By logging the communication between processes,\nit becomes possible to replay the execution of the system after a crash has\noccurred.\nDS 4.01\n \n",
      "content_length": 2794,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 561,
      "content": "09\nSECURITY\n",
      "content_length": 12,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 562,
      "content": "546\nCHAPTER 9. SECURITY\nWhat makes a distributed system secure? Answering this question can\neasily fill entire books, and can certainly not be fully addressed in a single\nchapter. One of the challenges in making systems secure is that we need to\naddress a negative goal [Saltzer and Kaashoek, 2009]: we need to protect a\nsystem against all unauthorized actions. Proving or demonstrating that this\ngoal has been reached is generally (close to) impossible. Much easier is to\nshow that a positive goal has been accomplished, for example, showing that\nAlice can log in to a system.\nIn this chapter, we aim to provide a brief introduction into secure dis-\ntributed systems. We do so by mainly concentrating on two important mecha-\nnisms: authentication and authorization. Authentication is all about ensuring\nthat you are dealing with people and devices that have been properly identi-\nfied before providing access to a system. Authorization is all about ensuring\nthat identified entities, having access to the system, can perform only those\noperations they are allowed to execute.\nYet, authentication and authorization are not enough. It is equally impor-\ntant to ensure that operations are carried out correctly: have they affected data\nin a way that may leave the system in an inconsistent state, has the request to\nexecute an operation not been tampered with, etc.? This aspect of ensuring\nintegrity, or at the very least identifying that integrity has been affected, is\nessential for any secure system and will be discussed as well.\nThis brings us to perhaps one of the most discussed topics in the last\ndecade: confidentiality, or, to keep it simple, ensuring that information is kept\nprivate. Achieving confidentiality time and again turns out to be a difficult\nsubject, not in the least because keeping information private depends so much\non the context of that information. For example, in the European’s General\nData Protection Regulation (GDPR) it is stated that without explicit consent,\nno data set should allow for the identification of an individual. However,\nrealizing this otherwise indisputable reasonable requirement turns out to\nbe technically a very demanding task in general, yet solutions for specific\nsituations have been developed. Understanding the context turns out to be\nimportant, and as we shall see in this chapter, this actually holds for many\nsituations when trying to secure a distributed system.\nRealizing security mechanisms and establishing confidentiality and in-\ntegrity relies heavily on cryptography, which is a huge field in itself. Never-\ntheless, explaining the basic principles of cryptographic protocols necessary\nfor distributed systems is actually not too difficult and are also discussed in\nthis chapter.\n9.1\nIntroduction to security\nWe start our description of security in distributed systems by taking a look\nat some general security issues. First, it is necessary to define what a secure\nDS 4.01\n \n",
      "content_length": 2945,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 563,
      "content": "9.1. INTRODUCTION TO SECURITY\n547\nsystem is. We distinguish security policies from security mechanisms. Our\nsecond concern is to consider some general design issues for secure systems.\nFinally, we briefly discuss some cryptographic algorithms, which play a key\nrole in the design of security protocols.\n9.1.1\nSecurity threats, policies, and mechanisms\nSecurity in a computer system is strongly related to the notion of dependability.\nInformally, a dependable computer system is one that we justifiably trust\nto deliver its services [Laprie, 1995].\nDependability includes availability,\nreliability, safety, and maintainability. However, if we are to put our trust in a\ncomputer system, then confidentiality and integrity should also be considered.\nConfidentiality refers to the property that information is disclosed only\nto authorized parties.\nIntegrity is the characteristic that alterations to a\nsystem’s assets can be made only in an authorized way, ensuring accuracy\nand completeness during the lifetime of assets. In other words, improper\nalterations in a secure computer system should be detectable and recoverable.\nMajor assets of any computer system are its hardware, software, and data (see\nalso Beckers et al. [2015]).\nAnother way of looking at security in computer systems is that we attempt\nto protect the services and data it offers against security threats. Follow-\ning Saltzer and Kaashoek [2009] we distinguish the following three broad\nclasses of threats:\n1. Unauthorized information disclosure\n2. Unauthorized information modification\n3. Unauthorized denial of use\nIn all these cases, we explicitly mention unauthorized actions: actions taken by\npeople, software, or devices (and generally as a combination) that are, simply\nput, not allowed, or have not been intended to be allowed. To what extent\nallowing or disallowing actions has been sufficiently expressed or enforced is\nless important for qualifying a security threat as such: the intent is sufficient\nfor now.\nEach of these three classes of threats relate directly to confidentiality,\nintegrity, and availability, respectively.\nSimply stating that a system should be able to protect itself against all\npossible security threats is not the way to actually build a secure system.\nWhat is first needed is a description of security requirements, that is, a\nsecurity policy.\nA security policy describes precisely which actions the\nentities in a system are allowed to take and which ones are prohibited. Entities\ninclude users, services, data, machines, and so on. We will not go into the\nmany aspects of formulating security policies. A good introduction is given\nby Bishop [2019]. Once a security policy has been laid down, it becomes\n \nDS 4.01\n",
      "content_length": 2718,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 564,
      "content": "548\nCHAPTER 9. SECURITY\npossible to concentrate on the security mechanisms by which a policy can be\nenforced. We distinguish the following four important security mechanisms:\n1. Encryption\n2. Authentication\n3. Authorization\n4. Monitoring and auditing\nEncryption is fundamental to computer security. Encryption allows us to\ntransform data into something an attacker cannot understand. In other words,\nencryption provides a means to implement data confidentiality. In addition,\nencryption allows us to check whether data have been modified. It thus also\nprovides support for integrity checks.\nAuthentication is used to verify the claimed identity of a user, client,\nserver, host, device, and so on. In the case of clients, the basic premise is that\nbefore a service starts to perform any work on behalf of a client, the service\nmust learn the client’s identity (unless the service is available to all). Typically,\nusers are still authenticated through passwords, but there are many other\nways to authenticate clients.\nAfter a client has been authenticated, it is necessary to check whether\nthat client is authorized to perform the action requested. Access to records\nin a medical database is a typical example. Depending on who accesses the\ndatabase, permission may be granted to read records, to modify certain fields\nin a record, or to add or remove a record.\nMonitoring and auditing tools are used to trace accesses to assets, such\nas which clients are accessing or have accessed what, and in which way. It\nhas become increasingly important to not just record what has happened, but\nto continuously monitor what is going on in a system with the aim to detect\nany unauthorized intrusions. With the rise of advanced machine-learning\ntechniques, we are witnessing increasingly sophisticated intrusion detection\nsystems, which we shall discuss further in Section 9.6. Although auditing does\nnot really provide any protection against security threats, audit logs can be\nextremely useful for the analysis of a security breach, and subsequently taking\nmeasures against intruders. For this reason, attackers are generally keen not\nto leave any traces that could eventually lead to exposing their identity. In\nthis sense, logging accesses makes attacking sometimes a riskier business.\n9.1.2\nDesign issues\nSecurity principles\nA distributed system, or any computer system for that matter, must provide se-\ncurity services by which a wide range of security policies can be implemented.\nThere are a number of important design issues that need to be considered\nDS 4.01\n \n",
      "content_length": 2558,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 565,
      "content": "9.1. INTRODUCTION TO SECURITY\n549\nwhen implementing general-purpose security services. Various design princi-\nples have been devised over the years, starting with the influential list of eight\nsuch principles by Saltzer and Schroeder [1975]. Almost 40 years later, Smith\n[2012] concluded that many still thrive:\n• Fail-safe defaults\n• Open design\n• Separation of privilege\n• Least privilege\n• Least common mechanism\nFail-safe defaults are assuming that any set of defaults will generally not\nbe changed. Perhaps the most infamous example is the initial (user,password)\ncombination “(admin, admin)” or something similar, for edge devices. In many\ncases, the password is never changed, making edge devices the source of\ncountless security breaches. This principle states that defaults should already\nguarantee a good degree of protection. In particular, access decisions should\nbe based on permissions, not exclusions. For edge devices, it could mean\nthat each should be shipped with a default, unique strong password (which\nhas become common practice by now when purchasing and installing a new\nmodem, for example).\nThe principle of open design is all about not applying security by obscurity:\nit is essential that every aspect of a distributed system is open for review.\nEveryone should be able to see which mechanisms are being used, how they\nare being used, how they have been implemented, etc. An obvious problem\nwith this principle for modern distributed systems, is that many of them\nhave become so immense complex that a mere inspection of design and\nimplementation is no longer a guarantee for openness. Good documentation\nnext to the continuous focus on keeping systems and their components as\nsimple as possible are key. Unfortunately, simplicity is increasingly becoming\nmore of an ideal state than something that most engineers can realize.\nSeparation of privilege is about ensuring that truly critical aspects of a\nsystem can never be fully controlled by just a single entity. A top-secret file\nmay need to be double encrypted, with keys in the hands of two different\npeople. Likewise, shutting down critical services may need to be controlled\nby two authorized administrators, each having their own keys to push the\n(digital) button.\nThe principle of least privilege states that a process should operate with\nthe fewest possible privileges. As a practical example, in Unix systems, most\nprocesses (and thus users) cannot execute operations that are intended to\nbe executed by the root. It is therefore needed to explicitly execute the sudo\noperation, after which one would normally need to provide a password in\norder to gain administrative rights.\n \nDS 4.01\n",
      "content_length": 2672,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 566,
      "content": "550\nCHAPTER 9. SECURITY\nFinally, the least common mechanism refers to designing systems in\nsuch a way that if multiple components require the same mechanism, then\nthey should all be offered the same implementation of that mechanism. An\nimportant motivation for this principle is that maintenance and simplicity is\nmuch easier to achieve with a single implementation than having a mechanism\nspread across the system, possibly with different implementations. A typical\nexample of this approach is that all users have access to the same library\n(implementation).\nSaltzer and Schroeder [1975] also mentioned three other principles, in-\ncluding economy of mechanism, complete mediation, and psychological\nacceptability. Economy of mechanism means making systems as simple as\npossible. Although this is still an excellent goal, achieving it is often close to\nimpossible considering how modern distributed systems are, literally, com-\nposed. Nevertheless, it also sometimes seems that designers have let go of this\nprinciple entirely. Accepting that systems can become complex in an almost\nuncontrolled fashion does not mean, however, that striving for simplicity\nshould be abandoned.\nComplete mediation means that every access to every object must be\nchecked when it comes to whether it is allowed. With the complex, distributed\nnature of modern systems, it has become extremely difficult to even figure\nout how and where an adversary has entered a system.\nFinally, psychological acceptance often translates to building the appro-\npriate user interfaces so that people can do only the right thing. It has a\nlot to do with building a mental model of how a system is operating, and\nsubsequently operate according to that model. Smith [2012] may be correct in\nstating that this aspect is receiving more attention than before, but that further\nadvancements are simply hindered by costs. This may change, however, as or-\nganizations are increasingly becoming aware of how vulnerable they are, only\nbecause their employees find it so difficult to work with modern information\nsystems.\nLayering of security mechanisms\nAn important issue in designing secure systems is to decide at which level\nsecurity mechanisms should be placed. A level in this context is related to\nthe logical organization of a system into a number of layers. For example,\ncomputer networks are often organized into layers following some reference\nmodel, as we discussed in Section 4.1.1. In Section 2.2, we introduced the\norganization of distributed systems consisting of separate layers for appli-\ncations, middleware, operating system services, and the operating system\nkernel. Combining the two organizations leads roughly to what is shown in\nFigure 9.1.\nTypically, what we have shown as low-level protocols encompass general\nnetwork-security solutions. An often-used solution is to set up a virtual\nDS 4.01\n \n",
      "content_length": 2872,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 567,
      "content": "9.1. INTRODUCTION TO SECURITY\n551\nFigure 9.1: The logical organization of a distributed system into several layers.\nprivate network, generally abbreviated to VPN. In essence, a VPN sets up a\ntunnel between two remote local networks, or between a host and a remote\nnetwork. The effect is that a computer on one network seems to be directly\nconnected to the remote network. Although not strictly necessary, a VPN\nnormally encrypts all traffic between its end points and operates at the level\nof the data link layer or the network layer, as we discussed in Section 4.1.1.\nGoing higher up the network stack, a well-known example is the transport-\nlayer security (TLS) service, which can be used to securely send messages\nacross a TCP connection. TLS forms the standard approach for secure commu-\nnication with Websites employing HTTPS. HTTPS establishes an authenticated\nconnection to a Website through which all data exchanged between a client\nand the server is encrypted.\nWhere VPNs and secure Website communication can be considered as\noperating at the level of networking protocols, this is less obvious for protocols\nsuch as SSH. The Secure Shell Protocol (SSH) is used to establish a secure\nremote login. As such, one can argue that it operates as an operating-system\nservice. Unlike HTTPS (which formally operates at the application level in\nterms of networking stacks), SSH comes with its own security protocol and\ndoes not rely on a transport-layer security service.\nOne of the main reasons for introducing middleware was to offer services\nthat are useful for a wide range of distributed applications, while at the same\nbeing independent of specific operating systems. One example that we will\ndiscuss in detail later is that of an authentication service such as Kerberos.\nThe service is indeed independent of a specific operating system (Kerberos\nhas been implemented for a wide range of operating systems, including\nWindows, many Unix versions, and other non-Unix systems). Other examples\nof secure middleware services include secure RPC, secure Web servers (think\nof WordPress), as well as a range of secure databases.\nFinally, an approach that is increasingly being adopted is developing end-\nto-end application-level security. In these cases, all secure communication\n \nDS 4.01\n",
      "content_length": 2288,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 568,
      "content": "552\nCHAPTER 9. SECURITY\nwithin the distributed application is handled by the application itself. There is\nno reliance on middleware security services. A well-known example is formed\nby modern user-messaging services like WhatsApp, Signal, and Telegram. Like-\nwise, distributed applications that, for example, make use of cloud storage\nservices, may be configured to first encrypt any data before sending it off to\nthe cloud, as is done with BoxCryptor.\nWhat these examples illustrate is that there are choices to be made con-\ncerning where and which security mechanisms will be deployed. Obviously,\napplication-level security need generally not rely on lower-level security guar-\nantees, yet the price to pay is that all mechanisms need to be deployed and\nmaintained by the application itself. This is not always the best choice, as it\ndoes make sense to separate application functionality from what is needed\nregarding security. Just imagine automating your own backup services for\na collection of remote computers. Making use of available operating-system\nlevel services for secure execution of remote commands and file transfers\nmakes life a lot easier.\nTrusted Computing Base\nDependencies between services regarding trust lead to the notion of a trusted\ncomputing base (TCB). A TCB is the set of all security mechanisms in a\n(distributed) computer system that are necessary and sufficient to enforce\na security policy, and that thus need to be trusted [Committee on National\nSecurity Systems, 2015]. The TCB encompasses firmware, hardware, software,\nas well as humans. The smaller the TCB, the better. The idea is that if the\nTCB can be clearly identified, we at least know what to concentrate on when\nscrutinizing a computer system to state that it is secure.\nIdentifying the TCB means identifying the modules that need to be trusted,\nand those that do not. Unfortunately, identifying the trusted modules is not\nthat simple, nor is it even that simple to design a system such that there is\nalways a clear distinction between trusted and untrusted modules.\nFor example, it is clear that a program needing administrative privileges\nto be executed will be part of the TCB, for the simple reason that if that\nprogram is compromised, an attacker may be able to do much more than\nwhat that program was designed for. But what about a Web-based service\nthat facilitates storage on a local server, such as ownCloud? Such a service\nis typically implemented as a collection of scripts that are executed by a\nprocess spawned by the Apache server. The spawned process runs entirely\nwithout any special privileges, yet the collection of scripts also include code for\nadding and removing users (separate from the users known to the underlying\noperating system). Are the set of scripts that make up this service to be trusted\nor not? Or more specifically, which scripts from this set are to be trusted?\nClearly, the answer to this question depends on the security specifications\nfor, in this case, the ownCloud service. If the policy states that users should be\nDS 4.01\n \n",
      "content_length": 3061,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 569,
      "content": "9.1. INTRODUCTION TO SECURITY\n553\nfully separated, then the scripts for user management and access control will\nneed to be inspected, but also the dependency of those scripts (and perhaps\nothers) on other modules that ownCloud depends on (such as a mysql database\nand the Apache server).\nThe ownCloud example illustrates that it may not be that easy to separate\ntrusted from untrusted modules, especially when no security policy has been\nexplicitly specified, or is perhaps otherwise incomplete. The same may hold\nwhen designing for security. For example, often we assume a so-called honest-\nbut-curious server: a server that behaves according to some protocol, but in\nthe worst case keeps track of all the things it does [Goldreich, 2009]. Making\nsuch an assumption may be fine, but what measures have been taken that\njustify such an assumption? Equally important, are those measures sufficient?\nWhen components or modules are complex, it may be very difficult to establish\nwhether a module actually satisfies its specifications and to what extent we\nmay need to classify it as trusted or not.\nPrivacy\nIf there is one thing clear when it comes to designing for secure distributed\nsystems, then it is the role of data. In this era of data and notably the effect\nit has on the personal lives of many, protecting privacy has become a major\nissue for distributed systems. Privacy and confidentiality are closely related,\nyet are different. Following Francis [2008], one could state that privacy is\ninvaded, whereas confidentiality is breached. Important is to recognize that\njust ensuring confidentiality, that is, data and information is not disclosed in\nany unauthorized manner, is not enough to guarantee privacy. In this light,\none can understand why Nissenbaum [2010] states that the right to privacy is\nabout “a right to appropriate flow of personal information.” In other words,\ncontrolling who gets to see what, when, and how. This also implies, for\nexample, that a person should be able to stop and revoke a flow of personal\ninformation.\nDiscussions on how to design distributed systems that meet such privacy\nrequirements have only recently started to mature. One approach is to con-\ncentrate on ownership, such as done in Solid [Sambra et al., 2016], which\nessentially puts control on personal information at a single person. To what\nextent this will be sufficient remains to be seen. A point of debate is whether\nownership by itself is sufficient to provide the necessary privacy guarantees.\nAnother approach is to look at what regulations state and to what extent\nit is possible to design systems that comply to those regulations. Impor-\ntant in this respect is the General Data Protection Regulation, or simply\nGDPR [Voigt and Von dem Bussche, 2017], which was installed in 2016. The\nGDPR is a comprehensive set of regulations aiming to protect personal data.\nAs with many regulations, it is yet unclear to what extent one can develop a\ntruly GDPR-compliant distributed system, but it can be argued that making\n \nDS 4.01\n",
      "content_length": 3032,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 570,
      "content": "554\nCHAPTER 9. SECURITY\na system GDPR-compliant after the fact may be much more difficult, if not\nimpossible.\nLike Solid, Schwarzkopf et al. [2019] follow an approach in which a user\nhas a separate, privately owned and controlled database with personal in-\nformation, denoted as a shard. Acknowledging that the real challenge lies\nin keeping track of how personal information flows into other systems, the\nauthors argue for designing a distributed system by considering it to consist\nof as being a large dataflow computation. A user can contribute her shard\nto the system, but equally remove it and along with that removal, revoke\nparticipation in all related data flows.\nAs an example, consider a collection of users, each maintaining their own\nshard. A shard represents a user’s contributions to an online social network\nwith three elements:\n• Some personal information, such as name, organization, etc.\n• A set of connections, each connection referring to another shard.\n• A set of posts, as is common in many social networks, often as a reaction\nto another post.\nAn application can be developed that builds a tree consisting of posts and\nreactions to posts. The development of that tree starts with a single, new\npost P and implements the function react taking the original post P and a\n(dynamic) list of reactions R1, R2, . . . , Rn as input. Each reaction is, of course,\nalso a post and can be reacted to. When Alice at a certain point decides she\nwants to completely withdraw from the discussion, she can simply withdraw\nher post(s), leading to a new tree. All reactions to her posts may necessarily\nbe removed as well, as each of her posts operates as the root of a branch. This\ncan be done automatically, assuming that the function react is continuously\nupdated on its inputs, and we assume that removal of the post that led to\nreactions, recursively leads to the removal of the entire branch.\nMore intricate examples are described by Agarwal et al. [2022], yet the\nessence is that removal of an element as part of a dataflow leads to an update\nof that flow but without the personal information represented by that element.\nThe example above also illustrates that we may not be out of the woods yet,\nfor what happens if Alice is explicitly mentioned in one of the reactions? In\nother words, more needs to be done to ensure that all references to Alice and\nher posts are indeed removed.\nThis example already illustrates that taking a database perspective may\nhelp in designing GDPR-compliant systems. Shastri et al. [2020] show that\nsuch a perspective may indeed be fruitful, yet the real challenge is maintaining\na large amount of metadata, as shown in Figure 9.2. The authors come to\nthe conclusion that extending databases so that a system can meet GDPR\nrequirements is doable from a functional point of view, but has serious adverse\neffect on performance and, in turn, on the scalability of solutions.\nDS 4.01\n \n",
      "content_length": 2924,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 571,
      "content": "9.2. CRYPTOGRAPHY\n555\nGDPR regulation\nImpact on database systems\nAttributes\nActions\nCollect data for explicit purposes\nPurpose\nMetadata indexing\nDo not store data indefinitely\nTTL\nTimely deletion\nInform customers about GDPR\nmetadata associated with their data\nPurpose, TTL,\nOrigin, Sharing\nMetadata indexing\nAllow customers to access their data\nPerson id\nMetadata indexing\nAllow customers to erase their data\nTTL\nTimely deletion\nDo not use data for objected reasons\nObjections\nMetadata indexing\nAllow customers to withdraw from\nalgorithmic decision-making\nAutomated\ndecisions\nMetadata indexing\nSafeguard and restrict access to data\nAccess control\nDo not grant unlimited access to data\nAccess control\nAudit operations on personal data\nAudit trail\nMonitor and log\nImplement appropriate data security\nEncryption\nShare audit trails from affected\nsystems\nAudit trail\nMonitor and log\nFigure 9.2: The effects on (distributed) databases when designing for GDPR\ncompliance (adapted from [Shastri et al., 2020]).\n9.2\nCryptography\nLet us now draw attention to an essential mechanism in developing secure\ndistributed systems, namely the application of cryptographic solutions. In\nthe following, we first pay attention to some basic cryptographic functions,\nincluding symmetric and asymmetric cryptosystems, and secure hashing, to\nthen continue with managing security.\n9.2.1\nBasics\nFundamental to security in distributed systems is the use of cryptographic\ntechniques. The basic idea of applying these techniques is simple. Consider a\nsender S wanting to transmit message m to a receiver R. To protect the message\nagainst security threats, the sender first encrypts it into an unintelligible\nmessage m′, and subsequently sends m′ to R. R, in turn, must decrypt the\nreceived message into its original form m.\nEncryption and decryption are accomplished by using cryptographic meth-\nods parameterized by keys, as shown in Figure 9.3. The original form of the\nmessage that is sent is called the plaintext, shown as P in Figure 9.3. The\nencrypted form is referred to as the ciphertext, illustrated as C.\nTo describe the various security protocols that are used in building security\nservices for distributed systems, it is useful to have a notation to relate\n \nDS 4.01\n",
      "content_length": 2250,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 572,
      "content": "556\nCHAPTER 9. SECURITY\nFigure 9.3: Intruders and eavesdroppers in communication.\nplaintext, ciphertext, and keys. Following common notational conventions, we\nwill use C = EK(P) to denote that the ciphertext C is obtained by encrypting\nthe plaintext P using key EK. Likewise, P = DK(C) is used to express the\ndecryption of the ciphertext C using key DK, resulting in the plaintext P.\nReturning to our example shown in Figure 9.3, while transferring a mes-\nsage as ciphertext C, there are three different attacks that we need to protect\nagainst, and for which encryption helps. First, an intruder may intercept the\nmessage without either the sender or receiver being aware that eavesdropping\nis happening. Of course, if the transmitted message has been encrypted in\nsuch a way that it cannot be easily decrypted without having the proper key,\ninterception is useless: the intruder will see only unintelligible data. (By the\nway, the fact alone that a message is being transmitted may sometimes be\nenough for an intruder to draw conclusions. For example, if during a world\ncrisis, the amount of traffic into the White House suddenly drops dramati-\ncally while the amount of traffic going into a certain mountain in Colorado\nincreases, there may be useful information in knowing that.)\nThe second type of attack that needs to be dealt with is that of modifying\nthe message. Modifying plaintext is easy; modifying ciphertext that has been\nproperly encrypted is much more difficult because the intruder will first have\nto decrypt the message before it can be meaningfully modified. In addition,\nthe intruder will also have to properly encrypt it again, or otherwise the\nreceiver may notice that the message has been tampered with.\nThe third type of attack is when an intruder inserts encrypted messages\ninto the communication system, attempting to make R believe these messages\ncame from S. Again, encryption can help protect against such attacks. Note\nthat if an intruder can modify messages, she can also insert messages.\nThe art and science of devising algorithms for cryptographic systems has\na long and fascinating history [Kahn, 1967], and building secure systems is\nDS 4.01\n \n",
      "content_length": 2178,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 573,
      "content": "9.2. CRYPTOGRAPHY\n557\noften surprisingly difficult. It is beyond the scope of this book to discuss any\nof these algorithms in detail. Information on cryptographic algorithms can be\nfound in [Ferguson et al., 2010] and [Smart, 2016].\n9.2.2\nSymmetric and asymmetric cryptosystems\nThere is a fundamental distinction between different cryptographic systems,\nbased on whether the encryption and decryption key are the same. In a\nsymmetric cryptosystem, the same key is used to encrypt and decrypt a\nmessage:\nif P = DK(EK(P)) then DK = EK.\nSymmetric cryptosystems are also referred to as secret-key or shared-key\nsystems because the sender and receiver are required to share the same key,\nand to ensure that protection works, this shared key must be kept secret; no\none else is allowed to see the key. We will use the notation KA,B to denote a\nkey shared by A and B.\nIn an asymmetric cryptosystem, the keys for encryption and decryption\nare different, but together form a unique pair. In other words, there is a\nseparate key EK for encryption and one for decryption, DK, such that\nif P = DK(EK(P)) then DK ̸= EK.\nOne of the keys in an asymmetric cryptosystem is kept private; the other is\nmade public. For this reason, asymmetric cryptosystems are also referred to\nas public-key systems. In what follows, we use the notation PKA to denote a\npublic key belonging to A, and SKA as its corresponding private (i.e., secret)\nkey.\nWhich one of the encryption or decryption keys that is actually made\npublic depends on how the keys are used. For example, if Alice wants to send\na confidential message m to Bob, she should use Bob’s public key to encrypt\nthe message. Because Bob is the only one holding the associated and private\ndecryption key, he is also the only person who can decrypt the message:\nif m is to be kept private: C = PKB(m).\nOn the other hand, suppose that Bob wants to know for sure that the message\nhe just received actually came from Alice.\nIn that case, Alice can keep\nher encryption key private to encrypt the messages she sends. If Bob can\nsuccessfully decrypt a message using Alice’s public key (and the plaintext\nin the message has enough information to make it meaningful to Bob), he\nknows that message must have come from Alice because the decryption key\nis uniquely tied to the encryption key:\nif m is to be authenticated: C = SKA(m).\nWe return to digitally signing messages shortly.\n \nDS 4.01\n",
      "content_length": 2409,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 574,
      "content": "558\nCHAPTER 9. SECURITY\nAn aspect of asymmetric cryptosystems that is becoming increasingly\nimportant is that of homomorphic encryption. What it boils down to is that\nwhen using homomorphic encryption, mathematical operations on plaintext\ncan also be performed on the corresponding ciphertext. In particular, if x and\ny are two numbers, then\nEK(x) ⋆EK(y) = EK(x ⋆y)\nwhere “⋆” is some mathematical operation, typically an addition or multiplica-\ntion. The importance of homomorphic encryption cannot be underestimated.\nBy now, we understand what it takes to store data safely on a remote, un-\ntrusted server: simply encrypt it with a public key before sending it to the\nserver. This is what tools such as BoxCryptor do. However, whenever stored\ndata needs to be operated on, servers generally require that the data is avail-\nable as plaintext. Homomorphic encryption changes that: a server can apply\noperations on encrypted data and the result (also automatically encrypted\nwith the same key) can be safely stored as well, or used in other computations.\nThere is only one problem with homomorphic encryption: its general form\n(known as full homomorphic encryption or simply FHE) is performance-\nwise slow. FHE supports addition and multiplication, which is enough to\nimplement any mathematical operation. Currently, FHE implementations are\noften too slow to be generally applicable. In contrast, there are also partial\nhomomorphic encryption (PHE) schemes, which support either addition\nor multiplication, for which efficient implementations exist. However, PHE\nschemes do require often very specific applications. For a good overview of\nhomomorphic encryption, see Acar et al. [2018].\nNote 9.1 (Example: Counting pedestrians over time and space)\nAs a practical and advanced example of how homomorphic encryption can be\napplied, consider the following. In many cities, it has become common practice to\nmonitor pedestrian behavior by simply picking up Wi-Fi signals from carry-on\ndevices, notably Wi-Fi–enabled smartphones. Most of these signals are network\npackets carrying the unique MAC address of the device. By extracting the MAC\naddress as a device identifier, it becomes possible to track movements. That by\nitself need not necessarily be a problem, but without having explicit consent from\na device owner, it is simply a serious infringement of privacy.\nInterestingly, many cities are not interested in actually tracking individuals.\nThey are interested in simple questions such as how many people moved from\none location to another, or what is the average time that people stayed at a specific\nlocation. Such questions are easy to answer when you know the identifier of\na device, yet become much more difficult when keeping those identifiers long\nenough to come to an answer, is simply forbidden.\nStanciu et al. [2020] propose a solution that allows to count devices over\ntime and space without the need to keep device identifiers. A setup consists\nof a collection of sensors, each sensor essentially being a Wi-Fi–packet sniffer.\nDS 4.01\n \n",
      "content_length": 3048,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 575,
      "content": "9.2. CRYPTOGRAPHY\n559\nDuring a short epoch (typically a few minutes), a sensor picks up Wi-Fi packets,\nextracts MAC addresses, and subsequently stores (a pseudonymized version) of\neach MAC address in a so-called Bloom filter. A Bloom filter is a vector of m\nbits, initially all set to 0 [Bloom, 1970]. Using a collection of k hash functions,\nan element x is added to a Bloom filter by setting the position hi(x) to 1 for\neach of the k hash functions. Each element is thus represented as an m-bit vector\nconsisting of exactly k bits set to 1. More elements are added by performing a\nbitwise OR operation each time an element is added.\nA Bloom filter has the important property that one cannot retrieve the elements\nof the set it represents other than by exhaustively testing for all possible elements.\nIn other words, a Bloom filter supports only membership tests. To check if x is in\na set A represented by the Bloom filter BF, one needs to check if every position\nhi(x) has been set to 1:\nx ∈A only if\nk\n∏\ni=i\nBF[hi(x)] = 1\nCounting is possible by a simple estimation n∗of the number of elements in a\nBloom filter [Swamidass and Baldi, 2007]:\nn∗= −m\nk ln(1 −X\nm )\nwhere X is the number of nonzero elements in the Bloom filter.\nCounting the number of devices that were at one location and later at another,\nthen resorts to taking the intersection of two Bloom filters and estimating the size\nof the intersection. Likewise, checking how many people stayed at a location for\na specific, long time, amounts to constructing intersections of Bloom filters and\nestimating the size. In all cases, there is, strictly speaking, no need to test for\nmembership.\nHowever, using Bloom filters in the clear is not safe: a simple brute-force\nattack can easily give a very good impression of detected devices, and thus also\nthe ability to track devices. Of course, when the Bloom filters are encrypted, de-\ntecting actual devices becomes more difficult. Moreover, computing intersections\nshould preferably be done on encrypted Bloom filters. Fortunately, computing\nan intersection is nothing else but constructing a Bloom filter through a bitwise\nAND operation, which is equivalent to a multiplication of 0’s and 1’s. Specifically,\nif we need to compute the intersection of two Bloom filters A and B, we do so\nusing their homomorphically encrypted versions and compute:\n∀i : PK(A ⊙B)[i] = PK(A[i]) · PK(B[i])\nwhere “⊙” represents an elementwise multiplication of two vectors. The basic\nidea is that a third party, say Alice, who needs the value of a count provides a\npublic key PK by which each sensor homomorphically encrypts the entries of its\nBloom filters. Note that if a value p is encrypted, leading to p1 = PK(p), and that\nsame value is encrypted a next time, leading to p2 = PK(p), the two encrypted\n \nDS 4.01\n",
      "content_length": 2802,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 576,
      "content": "560\nCHAPTER 9. SECURITY\nvalues will be different: p1 ̸= p2 and an observer will not be able to distinguish\nthe two underlying values to be the same.\nAn encrypted filter can be handed out to a separate server without disclosing\nany detections. That server also computes intersections, but completely ignorant\nof the results, for the simple reason that it cannot decrypt any of the filters. The\nonly thing the server does is shuffle the elements of any (computed) Bloom filter\nbefore handing it to Alice, who owns the private key SK associated with PK. This\nshuffling is important: when Alice decrypts the result, she will have a Bloom\nfilter that has nothing to do with the original, unshuffled Bloom filter. One might\nsay that it represents a completely random set of detections. The only thing in\ncommon with the original filter is the number of nonzero elements, from which\nshe can then estimate the size and thus the number of detections. This number is\nthe only information that Alice can get from the server’s response.\n9.2.3\nHash functions\nOne final application of cryptography in distributed systems, is the use of\nhash functions. A hash function H takes a message m of arbitrary length as\ninput and produces a bit string h having a fixed length as output:\nh = H(m) with length of h fixed.\nA hash h is somewhat comparable to the extra bits that are appended to a\nmessage in communication systems to allow for error detection, such as a\ncyclic-redundancy check (CRC). A well-known application is securely storing\npasswords: instead of storing a password pw, we keep only H(pw). Then,\nwhen Alice logs in with a password pw′, we need merely check if H(pw) =\nH(pw′).\nHash functions that are used in cryptographic systems, also known as\ntrapdoors, have a number of essential properties. First, they are one-way\nfunctions, meaning that it is computationally infeasible to find the input\nm that corresponds to a known output h. On the other hand, computing h\nfrom m is easy. Second, they have the weak collision resistance property,\nmeaning that given an input m and its associated output h = H(m), it is\ncomputationally infeasible to find another, different input m′ ̸= m, such\nthat H(m) = H(m′). Finally, cryptographic hash functions also have the\nstrong collision resistance property, which means that, when given only H,\nit is computationally infeasible to find any two different input values m and\nm′, such that H(m) = H(m′). In this way, an attacker will need to guess\npasswords instead of simply stealing or trying to derive them what is already\nknown.\nSimilar properties must apply to any encryption function E and the keys\nthat are used. For any encryption function EK, it should be computationally\ninfeasible to find the key EK when given the plaintext P and associated\nDS 4.01\n \n",
      "content_length": 2790,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 577,
      "content": "9.2. CRYPTOGRAPHY\n561\nciphertext C = EK(P). Likewise, analogous to collision resistance, when given\na plaintext P and a key EK, it should be effectively impossible to find another\nkey EK′ such that EK(P) = EK′(P).\nDigital signatures\nLet us now take a look at an often-used application of hash functions, namely\nplacing digital signatures as part of sending messages. Consider the situation\nin which Bob has just sold Alice a collector’s item of some vinyl record for\n$500. The whole deal was done through e-mail. In the end, Alice sends Bob a\nmessage confirming that she will buy the record for $500. There are at least\ntwo issues that need to be taken care of regarding the integrity of the message.\n1. Alice needs to be assured that Bob will not maliciously change the\n$500 mentioned in her message into something higher, and claim she\npromised more than $500.\n2. Bob needs to be assured that Alice cannot deny ever having sent the\nmessage, for example because she had second thoughts.\nThese two issues can be dealt with if Alice digitally signs the message in\nsuch a way that her signature is uniquely tied to its content. The unique\nassociation between a message and its signature prevents that modifications to\nthe message will go unnoticed. In addition, if Alice’s signature can be verified\nto be genuine, she cannot later repudiate the fact that she signed the message.\nThere are several ways to place digital signatures. One popular form is to\nuse a public-key cryptosystem. When Alice sends a message m to Bob, she\nencrypts it with her private key SKA, and sends it off to Bob. If she also wants\nto keep the message content a secret, she can use Bob’s public key and send\nPKB(m, SKA(m)), which combines m and the version signed by Alice:\nAlice: send C = PKB([m, sig]) with sig = SKA(m).\nWhen Bob receives the ciphertext C, he decrypts it with his private key SKB\nand uses Alice’s public key to verify the signature:\nBob: receive and decrypt [m, sig] = SKB(C) and verify m = PKA(sig).\nIf Bob can be assured that the public key is indeed owned by Alice, then\ndecrypting the signed version of m and successfully comparing it to m can\nmean only that it came from Alice. Alice is protected against any malicious\nmodifications to m by Bob because Bob will always have to prove that the\nmodified version of m was also signed by Alice. In other words, the decrypted\nmessage alone essentially never counts as proof. It is also in Bob’s own interest\nto keep the signed version of m to protect himself against repudiation by Alice.\nAn issue with the scheme just described is that Alice encrypts the entire\nmessage with her private key. Such an encryption may be costly in terms of\n \nDS 4.01\n",
      "content_length": 2689,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 578,
      "content": "562\nCHAPTER 9. SECURITY\nprocessing requirements and is actually unnecessary. Recall that we need to\nuniquely associate a signature with only a specific message. A cheaper and\narguably more elegant scheme is to use a message digest.\nA message digest is a fixed-length bit string h that has been computed\nfrom an arbitrary-length message m through a cryptographic hash function H.\nIf m is changed to m′, its hash H(m′) will be different from h = H(m) so that\nit can easily be detected that a modification has taken place.\nTo digitally sign a message, Alice can first compute a message digest and\nsubsequently encrypt the digest with her private key. The encrypted digest is\nsent along with the message to Bob:\nAlice: send [m, sig] with sig = SKA(H(m)).\nWhen Bob receives the message and its encrypted digest, he need merely\ndecrypt the digest with Alice’s public key, and separately calculate the message\ndigest. If the digest calculated from the received message and the decrypted\ndigest match, Bob knows the message has been signed by Alice:\nBob: receive [m, sig], compute h′ = H(m) and verify h′ = PKA(sig).\nNote that the message itself is sent as plaintext: everyone is allowed to read it.\nIf confidentiality is required, then the message should also be encrypted with\nBob’s public key.\nThere are still a number of problems with both schemes, although the\nprotocols are correct. First, the validity of Alice’s signature holds only as\nlong as Alice’s private key remains a secret. If Alice wants to bail out of\nthe deal even after sending Bob her confirmation, she could claim that her\nprivate key was stolen before the message was sent. We will later describe\nhow blockchains may help in keeping a decentralized account of transactions,\nsuch as those between Alice and Bob.\nAnother problem occurs when Alice decides to change her private key.\nDoing so may in itself be not such a bad idea, as changing keys from time to\ntime generally helps against intrusion. However, once Alice has changed her\nkey, her statement sent to Bob, becomes worthless. What may be needed in\nsuch cases is a central authority that keeps track of when keys are changed, in\naddition to using timestamps when signing messages. We look at this issue\nnext; Figure 9.4 summarizes the notations and abbreviations we use in the\nmathematical expressions throughout this book.\n9.2.4\nKey management\nSo far, we have described cryptographic protocols in which we (implicitly)\nassumed that various keys are readily available. For example, in the case of\npublic-key cryptosystems, we assumed that a sender of a message had the\npublic key of the receiver at its disposal so that it could encrypt the message\nDS 4.01\n \n",
      "content_length": 2681,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 579,
      "content": "9.2. CRYPTOGRAPHY\n563\nNotation\nDescription\nKA,B\nSecret key shared by A and B\nPKA\nPublic key of A\nSKA\nPrivate (secret) key of A\nEK(P)\nEncryption of plaintext P using key EK (or key K)\nDK(C)\nDecryption of ciphertext C using key DK (or key K)\nH(m)\nThe hash of m computed using function H\n[m]A\nThe message m digitally signed by A\nFigure 9.4: Notations used in this chapter.\nto ensure confidentiality. Likewise, when verifying the signature of a message,\nthe receiver will need to have the public key of the sender. In both these\nexamples, we also need to be sure that the public key being used actually\nbelongs to the presumed owner.\nHowever, establishing and distributing keys is not a trivial matter. For\nexample, digitally distributing secret keys without using encryption is out of\nthe question and there are cases where we even have to resort to out-of-band\nmethods. Also, mechanisms are needed to revoke keys, that is, prevent a key\nfrom being used after it has been compromised or invalidated.\nKey establishment\nHow are keys actually established? Let us take a look at a simple and widely\ndeployed approach for automatically establishing remote secure connections\nthrough SSH. As we mentioned, SSH allows a person to securely log in to\na remote computer. We can also use SSH to let a user alice at computer\nA log in as user bob at computer B using a (public, private)-key pair. An\nactual authentication protocol will be described later; here we are interested\nin establishing and distributing keys in the SSH system using the openSSL\nframework.\nFirst, Alice needs to generate a (public, private)-key pair, which can be\ndone as follows:1\nssh-keygen -f a\nThis will generate two keys: a private key contained in the file a and a\ncorresponding public key in the file a.pub. The file a will be stored in a special\ndirectory (namely in .ssh in Alice’s home directory). The file a.pub will have\nto be transferred to computer B, which can be done as follows:\n1We are deliberately taking an extremely simple example that works in practice yet is not\nvery sophisticated.\n \nDS 4.01\n",
      "content_length": 2074,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 580,
      "content": "564\nCHAPTER 9. SECURITY\nssh-copy-id -i a bob@B\nWe assume that B is the actual computer name that can be used when Alice\nwould normally log in to B as user bob. It is important to note that Alice is\nassumed to know the password of Bob at B. The ssh-copy-id command will\nask for Bob’s password at B before completing the transfer. If successful, the\nfile a.pub will be appended to a special file in the .ssh directory in the home\ndirectory of user bob at B. From that moment on, Alice can simply log in to B\nthrough the command\nssh bob@B\nwhere she will no longer be asked for a password.\nThis simple example illustrates two important issues. First, security keys\nare simply generated through programs such as ssh-keygen and stored in files\nthat can be distributed as any other file (or should be kept secret and properly\nprotected against unauthorized access). Second, we can easily distribute keys\nprovided we have the authorization to do so. That authorization can come from\nknowing a password, but there are other means as well, as we discuss shortly.\nInterestingly, in lack of authorization (and thus authentication), we would\nneed to rely on the receiving party to trust the claimed ownership of the keys.\nWe return to trust below.\nLet us move on to a more sophisticated example and consider how session\nkeys can be established. As it name suggests, a session key is a temporary\nshared secret key that is used during a single communication session between\ntwo parties. A session typically consists of a series of message exchanges.\nWhen the session ends, the session key is discarded and never used again.\nAs we shall also explain later, an important reason for using session keys is\nthat one should use long-lasting keys, be they shared, public, or private as\nlittle as possible: the more data that is used for encrypting or decrypting data,\nthe easier it becomes to discover the keys used. Two ways immediately come\nto mind, by which Alice and Bob can agree on establishing a session key. In\na symmetric cryptosystem and assuming that Alice and Bob already have a\nlong-lasting shared secret key KA,B, Alice could decide to generate a session\nkey sk and send it to Bob as the message\nAlice: send m = KA,B(sk).\nLikewise, in an asymmetric cryptosystem, Alice could encrypt the key with\nBob’s public key:\nAlice: send m = PKB(sk).\nAfter that, sk can be used for encrypting and decrypting messages for as long\nas the session lasts.\nBoth methods require that the communicating parties already have the\nmeans available to send and receive encrypted messages. In other words,\nsome form of key establishment and distribution must have taken place before.\nDS 4.01\n \n",
      "content_length": 2660,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 581,
      "content": "9.2. CRYPTOGRAPHY\n565\nAn elegant scheme that is widely applied for establishing a shared key\nacross an insecure channel is the Diffie-Hellman key exchange [Diffie and\nHellman, 1976]. The protocol works as follows. Suppose that Alice and Bob\nwant to establish a shared secret key. The first requirement is that they agree\non two large numbers, p and g that are subject to a number of mathematical\nproperties (which we do not discuss here). Both p and g can be made public;\nthere is no need to hide them from outsiders. Alice picks a large random\nnumber, say x, which she keeps secret. Likewise, Bob picks his own secret\nlarge number, say y. At this point, there is enough information to construct a\nshared secret key, as shown in Figure 9.5.\nFigure 9.5: The principle of Diffie-Hellman key exchange.\nAlice starts by sending gx mod p to Bob, along with p and g. It is impor-\ntant to note that this information can be sent as plaintext, as it is virtually\nimpossible to compute x given gx mod p. When Bob receives the message,\nhe subsequently calculates (gx mod p)y which is mathematically equal to\ngxy mod p. In addition, he sends gy mod p to Alice, who can then compute\n(gy mod p)x = gxy mod p. Consequently, both Alice and Bob, and only those\ntwo, will now have the shared secret key gxy mod p. Note that neither of them\nneeded to make their private number (x and y, respectively), known to the\nother. Diffie-Hellman can also be viewed as a public-key cryptosystem. In the\ncase of Alice, x is her private key, whereas gx mod p is her public key.\nIn practice, Alice will not send p and g to Bob, but first negotiate which\nso-called Diffie-Hellman group they will use. In essence, the choice of group\ndefines p and g, but also exactly which cryptographic algorithm to use. In\nour example, we have used gx mod p, yet an alternative is to use a so-called\nelliptic curve.\nIt is also relevant to note that in practice, Alice and Bob will regularly\nchange their respective private keys. In particular, new values for x and y may\nbe chosen for each new communication session between Alice and Bob, in\nwhich case we speak of ephemeral Diffie-Hellman key exchange. As we shall\nsee, the Diffie-Hellman key exchange has shown to be a powerful security\nmechanism throughout many practical situations. In the following note, we\ndiscuss another example of its application.\n \nDS 4.01\n",
      "content_length": 2368,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 582,
      "content": "566\nCHAPTER 9. SECURITY\nNote 9.2 (Advanced: Computing while keeping data private)\nIn many distributed systems, we see that security comes almost as an afterthought:\ndesigners focus on providing functionality to later adjust the system to meet\nspecific security requirements. For long, it has been thought that functionality\nmay actually suffer from imposing security (or privacy) demands, yet it is unclear\nto what extent there is actually a tradeoff to consider [Rowe et al., 2012]. Let us\nlook at an increasingly popular technique that makes use of Diffie-Hellman key\nexchange.\nAs also mentioned in our discussion on privacy, an important challenge that\nmany distributed systems will need to face is to deal with enormous amounts of\ndata while preserving privacy. A particular case is when private data is essential\nto compute important statistics. A simple example is computing who has the\nhighest salary among a number of people without anyone having to reveal their\nsalary. Along the same lines, we may wish to compute the number of votes cast\nfor a specific candidate without revealing who voted for whom.\nWhat we are dealing with is known as (secure) multiparty computations\n(MPC). For a long time, it has been a field of cryptography that was difficult to put\ninto practice for its low performance, but the last decade has shown impressively\nbetter implementations that make MPC a practical tool for secure distributed\ncomputations. At the same time, one may need to devise application-specific\nsolutions for the simple reason that there are too many parties to make general\ntools practically feasible. We will discuss an example in which resource constraints\ndemand an alternative solution.\nIt is beyond the scope of this chapter to go into any significant depth con-\ncerning MPC; the interested reader is referred to Evans et al. [2018] for a good\nintroduction. Let us first consider an important building block for MPC, namely\noblivious transfer. In this case, we assume Alice has n secret messages m1, . . . , mn,\nwhile Bob is interested (and allowed) to know only one of those messages. Which\nspecific message he wants to know should be kept secret to Alice, while at the\nsame time all other messages should be kept secret to Bob. Assume Bob wishes\nto know the ith message. In that case, he generates a number Q that Alice, in turn,\nuses to generate a total of n different keys PK1, . . . , PKn to encrypt each message:\nm∗\ni = PKi(mi)\nBob, meanwhile, uses Q to generate a decryption key SKi that matches only PKi.\nClearly, when Bob receives the set of encrypted messages m∗\n1, . . . , m∗n there will be\nonly a single message that he can decrypt, namely m∗\ni . Using SKi any attempt to\ndecrypt m∗\nj (with i ̸= j) will fail.\nAn important assumption for this scheme to work, is that having only Q,\nBob cannot successfully generate any decryption key SKj for PKj. For the case\nthat n = 2, there is an elegant, simple protocol that achieves this, based on a\nDiffie-Hellman key exchange [Chou and Orlandi, 2015]. The protocol is shown\nin Figure 9.6 (note that all computations are assumed to take place in Zp, that is,\nmodulo p).\nDS 4.01\n \n",
      "content_length": 3147,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 583,
      "content": "9.2. CRYPTOGRAPHY\n567\nFigure 9.6: A simple 1-out-of-2 oblivious transfer.\nIn the protocol, besides having his own private key y, Bob also has a choice for\nan additional binary parameter, denoted here as c. The value of c determines what\nBob will do in response to the initial message from Alice. Assume first that c = 0,\nin which case Bob will choose Q = gy. This is, actually, the regular Diffie-Hellman\nkey exchange: Bob computes BK = gxy, while Alice also computes AK1 = gxy,\nafter which she encrypts m1 using the now shared secret key gxy = BK. Alice also\ncomputes AK2 = gxy−x2, yet using BK is useless. Moreover, because Bob does not\nhave x, computing gxy−x2 is computationally infeasible.\nNow assume that c = 1, so that Bob sets Q = gx+y. Alice computes AK1 =\ngx2+xy and AK2 = (gxgy/gx)x = gxy. In other words, we now see that BK = AK2\nallowing Bob to successfully decrypt only message m∗\n2. He will never get to know\nm∗\n1, while Alice in this setup will also never know which message Bob was able\nto decrypt.\nTo illustrate how oblivious transfer is used in MPC, suppose we have two\nparties P1 and P2 who need to compute a function F(a, b) on two input values:\na secret a known only to P1 and a secret b known only to P2. For simplicity,\nlet us also assume that a ∈X and b ∈Y and that both X and Y are finite, i.e.,\neach contains only a finite number of elements. In that case, we can construct a\nmatrix F of size |X| · |Y| with F[i, j] = F(xi, yj) for each pair (xi, yj) ∈X × Y. The\nproblem we want to solve is to let both P1 and P2 compute F(a, b) yet the other\nshould not be able to discover b or a, respectively.\nTo this end, P1 generates |X| · |Y| unique key pairs (Ki, Kj) and encrypts each\nentry of the table F, leading to a table F∗[i, j] = Ki(Kj(F(xi, xj))). Assume that a\ncorresponds to the ith element of X (i.e., a = xi). P1 then sends F∗and Ki to P2,\nbut not before having permuted all its elements. In addition, it sends Q using a\n1-out-of-|Y| oblivious transfer. Assume that b = yj. Using Q, P2 can construct\nthe key Kj, and only the key Kj that allows it to decrypt F∗[i, j], corresponding\nto F(a, b). All other entries will remain a secret to P2, while at the same time, P1\nwill not know about b = yj.\nNote that permuting the table before sending it to P2 is essential, for oth-\nerwise a and b could be looked up. Also, we assume that P2 can recognize\nthat it decrypted the correct entry, for how would it otherwise know that the\ndecrypted value makes sense? This recognition can be done by adding some extra\ninformation, such as a specific bit string that pops up after successful decryption.\n \nDS 4.01\n",
      "content_length": 2627,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 584,
      "content": "568\nCHAPTER 9. SECURITY\nKey distribution\nOne of the more difficult parts in key management is the actual distribution\nof initial keys. In a symmetric cryptosystem, the initial shared secret key must\nbe communicated along a secure channel: a communication channel that, in\nprinciple, provides mutual authentication of the two communicating parties,\nas well as confidentiality for the messages that are exchanged, as shown in\nFigure 9.7. We will return to secure channels later in this chapter. If there\nare no keys available to Alice and Bob to set up such a secure channel, it is\nnecessary to distribute the key out-of-band. In other words, Alice and Bob\nwill have to get in touch with each other using some other communication\nchannel.\n(a)\n(b)\nFigure 9.7:\n(a) Secret-key distribution.\n(b) Public-key distribution (see\nalso [Menezes et al., 1996]).\nIn the case of a public-key cryptosystem, we need to distribute the public\nkey in such a way that the receivers can be sure that the key is indeed paired\nto a claimed private key. In other words, as shown in Figure 9.7, although\nthe public key itself may be sent as plaintext, it is necessary that the channel\nDS 4.01\n \n",
      "content_length": 1169,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 585,
      "content": "9.2. CRYPTOGRAPHY\n569\nthrough which it is sent can provide authentication. The private key, of course,\nneeds to be sent across a secure channel, providing authentication as well as\nconfidentiality.\nWhen it comes to key distribution, the authenticated distribution of public\nkeys is perhaps the most interesting. In practice, public-key distribution takes\nplace by public-key certificates. Such a certificate consists of a public key\ntogether with a string identifying the entity to which that key is associated.\nThe entity could be a user, but also a host or some special device. The public\nkey and identifier have together been signed by a certification authority, and\nthis signature has been placed on the certificate as well. (The identity of\nthe certification authority is naturally part of the certificate.) Signing takes\nplace by a private key SKCA that belongs to the certification authority. The\ncorresponding public key PKCA is assumed to be well known. For example,\nthe public keys of various certification authorities are built into most Web\nbrowsers and shipped with the binaries.\nUsing a public-key certificate works as follows. Assume that a client wishes\nto ascertain that the public key found in the certificate, indeed belongs to the\nidentified entity. It then uses the public key of the associated certification\nauthority to verify the certificate’s signature. If the signature on the certificate\nmatches the (public key, identifier)-pair, the client accepts that the public key\nindeed belongs to the identified entity.\nIt is important to note that by accepting the certificate as being in order, the\nclient actually trusts that the certificate has not been forged. In particular, the\nclient must assume that the public key PKCA indeed belongs to the associated\ncertification authority. If in doubt, it should be possible to verify the validity\nof PKCA through another certificate coming from a different, possibly more\ntrusted certification authority.\nNote 9.3 (More information: Lifetime of certificates)\nAn important issue concerning certificates is their longevity. First, let us consider\nthe situation in which a certification authority hands out lifelong certificates.\nEssentially, what the certificate then states is that the public key will always be\nvalid for the entity identified by the certificate. Clearly, such a statement is not\nwhat we want. If the private key of the identified entity is ever compromised, no\nunsuspecting client should ever be able to use the public key (let alone malicious\nclients). In that case, we need a mechanism to revoke the certificate by making it\npublicly known that the certificate is no longer valid.\nThere are several ways to revoke a certificate. One common approach is with a\ncertificate revocation list (CRL) published regularly by the certification authority.\nWhenever a client checks a certificate, it will have to check the CRL to see whether\nthe certificate has been revoked or not. This means that the client will at least have\nto contact the certification authority each time a new CRL is published. Note that\nif a CRL is published daily, it also takes a day to revoke a certificate. Meanwhile, a\n \nDS 4.01\n",
      "content_length": 3182,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 586,
      "content": "570\nCHAPTER 9. SECURITY\ncompromised certificate can be falsely used until it is published on the next CRL.\nConsequently, the time between publishing CRLs cannot be too long.\nAn alternative approach is to restrict the lifetime of each certificate. The valid-\nity of a certificate automatically expires after some time. If, for whatever reason,\nthe certificate should be revoked before it expires, the certification authority can\nstill publish it on a CRL. However, this approach will still force clients to check\nthe latest CRL whenever verifying a certificate.\nA final extreme case is to reduce the lifetime of a certificate to nearly zero. In\neffect, this means that certificates are no longer used; instead, a client will always\nhave to contact the certification authority to check the validity of a public key.\nAs a consequence, the certification authority must be continuously online and\ncapable of handling potentially continuous streams of validity checks.\nIn practice, certificates are handed out with restricted lifetimes, after which\nthey need to be renewed. Depending on the application, renewal may require\nmanual intervention, akin to renewing automatically expired passwords. In other\ncases, such as identifying Web servers, renewal can also be done completely\nautomatically as essentially a check of the existence of a specific file at a spe-\ncific location suffices. The latter happens with the Let′s Encrypt system for TLS\ncertificates.\nUsing certification authorities is one way of ensuring that a public key\nis valid in the sense of claimed ownership. However, it can easily come\nwith administrative hassle. Also, making use of certification authorities is\nno guarantee that certificates are correct: there have been cases in which the\nownership of a public key was systematically not properly established, and\nalso certification authorities are known to have been subject to successful\nattacks.\nAs an alternative, systems have been developed relying on developing a\nweb of trust. A well-known example comes from its initiator, Phil Zimmerman,\nthe developer of the Pretty Good Privacy (PGP) system, which has been\naround ever since the 1990s [Garfinkel, 1995]. The key idea, when developing\na web of trust, is that groups of people get to together and exchange their\npublic keys. At that point, one establishes the true ownership of a public\nkey. In particular, Alice may digitally sign Bob’s public key PKbob, effectively\nendorsing that the public key belongs to Bob. Other people will also endorse\nBob’s public key (and that of many others during the meeting). The result\nis that anyone who trusts the ownership of Alice’s public key, that is, trusts\nthe signature attached to Bob’s public key, has no reason not to believe that\nPKbob is indeed owned by Bob.\nIn a more sophisticated setup, one can also attach a weight to Alice’s\nsignature. For example, if Chuck believes Alice to be somewhat sloppy when it\ncomes to signing other people’s public key, he may decide to wait until he has\nseen at least k > 1 people in his web of trust who have signed Bob’s public key\nas well before deciding that PKbob is genuinely owned by Bob. An important\nDS 4.01\n \n",
      "content_length": 3172,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 587,
      "content": "9.3. AUTHENTICATION\n571\nquestion is whether Chuck, in turn, could ever endorse Bob’s key without ever\nhaving truly established his identity. With automatic endorsements, we open\nthe floor to digital attacks of all sorts, including ones in which an attacker\nbehaves well for a long time to strike hard only after considerable trust has\nbeen established. For this reason, the big question with a web of trust is how\nquickly, and with which confidence, can we actually disseminate trustworthy\ncertificates? It has been a topic of much research, yet after all these years there\nis no consensus to what extent webs of trust can operate on a large scale. In\nthis sense, Ulrich et al. [2011] draw interesting conclusions from a practical\nanalysis of that web: its core is formed by mutually connected (and endorsed)\nrelationships, yet is relatively small. In particular, many users are connected\nto each other and that core through relatively few and often long paths. Such\npaths make it much harder to establish trust in a robust way.\n9.3\nAuthentication\nWe continue our discussion by looking at authentication. After discussing\nsome of the basics, we concentrate on various authentication protocols, the\nuse of an authentication service, and how various aspects come together when\nsetting up a secure communication channel.\n9.3.1\nIntroduction to authentication\nAs we mentioned before, authentication is all about verifying the claimed\nidentity of a person, a software component, a device, and so on. In the follow-\ning, we shall use the generic term “client” for any of these types of entities.\nFollowing Stallings [2017], we distinguish four means of authentication:\n1. Authentication based on what a client knows, such as a password or a\npersonal identification number.\n2. Authentication based on what a client has, such as an ID card, cell\nphone, or software token.\n3. Authentication based on what a client is, i.e., static biometrics such as a\nfingerprint or facial characteristics.\n4. Authentication based on what a client does, i.e., dynamic biometrics\nsuch as voice patterns or typing patterns.\nIn the case of single-factor authentication, only one of the four means of\nauthentication is used. In practice, this means that clients are asked to enter\nsomething they know, such as a password. However, we have also come across\nsingle-factor authentication based on what a client has, namely a software\ntoken in the case of automatically logging in within the SSH framework using\na (private,public)-key pair. With modern cell phones, it is by now also common\n \nDS 4.01\n",
      "content_length": 2567,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 588,
      "content": "572\nCHAPTER 9. SECURITY\nto make use of what a client is, typically, face recognition or fingerprints.\nSingle-factor authentication based on dynamic biometrics is less common.\nIt is safe to say that humans are generally not good at all when it comes to\nmanaging passwords (see, for example, a study by Ur et al. [2016] that shows\nthat users are generally not even aware of how bad their passwords are). In\nthis light, we have been seeing increasingly more multi-factor authentication\nschemes being used. A common one is to use a cell phone that a user has\nregistered with a service. When logging into a system using a password or\nPIN, the user is asked to acknowledge the login through that cell phone, or\neven provide additional information like a number sent by the service to that\nphone, a PIN code, or have a fingerprint scanned and verified (in which case\nwe sometimes speak of additional electronic authentication).\nAn important observation is that, in general, authentication takes place\nonly once: when a client wants access to a service. However, this one-time\nauthentication for the duration of a session is often not good enough to\nguarantee that the service is dealing with the client it originally authenticated.\nThe simplest example is when someone is helping out, but for a different\naccount. Alice logs in, and grants Bob access from the same computer. Of\ncourse, this may be fine if Alice trusts Bob (and the service trusts Alice enough\nto allow for these type of take-overs to happen), but the situation becomes\ndifferent if Alice is forced by Bob to let him into the system. In such cases,\ncontinuous authentication is needed: the client is not only authenticated\nwhen requesting access at the beginning of a session, but also during the\nentire session.\nContinuous authentication is not new, yet with the availability of powerful\ninternet-of-things devices, new scenarios have been considered [Ayeswarya\nand Norman, 2019; Gonzalez-Manzano et al., 2019]. For example, if a user\ncan be continuously authenticated, it becomes possible to monitor different\nsituations, such as safely driving a vehicle, or ensuring that a room is opti-\nmized for a specific person. When ensuring that logins are not handed off to\nunauthorized people, as just described, it may help to see if a personalized\ndevice is still close to the computer accessing the service. Jakubeit et al. [2022]\ndescribe a situation in which the location of a user is fingerprinted based on\nWi-Fi signals to see whether the client is at a known location from which it\nwas previously authenticated. If not, a second authentication factor may be\nexplicitly required from the client.\n9.3.2\nAuthentication protocols\nBefore going into the details of various authentication protocols, it is worth-\nwhile noting that authentication and message integrity cannot do without\neach other. Consider, for example, a distributed system that supports authen-\ntication of two communicating parties, but does not provide mechanisms to\nensure message integrity. In such a system, Bob may know for sure that Alice\nDS 4.01\n \n",
      "content_length": 3080,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 589,
      "content": "9.3. AUTHENTICATION\n573\nis the sender of a message m. However, if Bob cannot be given guarantees that\nm has not been modified during transmission, what use is it to him to know\nthat Alice sent (the original version of) m?\nLikewise, suppose that only message integrity is supported, but no mecha-\nnisms exist for authentication. When Bob receives a message stating that he\nhas just won $1,000,000 in the lottery, how happy can he be if he cannot verify\nthat the message was sent by the organizers of that lottery?\nConsequently, authentication and message integrity should go together. In\nmany protocols, the combination works roughly as follows. Again, assume\nthat Alice and Bob want to communicate, and that Alice takes the initiative in\nsetting up a channel. Alice starts by sending a message to Bob, or otherwise to\na trusted third party, who will help set up the channel. Once the channel has\nbeen set up, Alice knows for sure that she is talking to Bob, and Bob knows\nfor sure he is talking to Alice, they can exchange messages.\nTo subsequently ensure integrity of the data messages that are exchanged\nafter authentication has taken place, it is common practice to use secret-key\ncryptography through session keys. As we explained, a session key is a shared\n(secret) key that is used to encrypt messages for integrity and possibly also\nconfidentiality. Such a key is generally used only for as long as the channel\nexists. When the channel is closed, its associated session key is destroyed. We\nreturn to session keys below.\nAuthentication based on a shared secret key\nLet us start by taking a look at an authentication protocol based on a secret key\nthat is already shared between Alice and Bob. How the two actually managed\nto obtain a shared key securely is not essential for now. In the description\nof the protocol, Alice and Bob are abbreviated by A and B, respectively, and\ntheir shared key is denoted as KA,B. The protocol takes a common approach\nwhereby one party challenges the other to a response that can be correct only\nif the other knows the shared secret key. Such solutions are also known as\nchallenge-response protocols.\nIn the case of authentication based on a shared secret key, the protocol\nproceeds as shown in Figure 9.8. First, Alice sends her identity to Bob (message\n1), indicating that she wants to set up a communication channel between the\ntwo. Bob subsequently sends a challenge RB to Alice, shown as message 2.\nSuch a challenge could take the form of a random number. Alice is required to\nencrypt the challenge with the secret key KA,B that she shares with Bob, and\nreturn the encrypted challenge to Bob. This response is shown as message 3\nin Figure 9.8 containing KA,B(RB).\nWhen Bob receives the response KA,B(RB) to his challenge RB, he can\ndecrypt the message using the shared key again to see if it contains RB. If\nso, he then knows that Alice is on the other side, for who else could have\nencrypted RB with KA,B in the first place? In other words, Bob has now\n \nDS 4.01\n",
      "content_length": 3008,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 590,
      "content": "574\nCHAPTER 9. SECURITY\nFigure 9.8: Authentication based on a shared secret key.\nverified that he is indeed talking to Alice. However, note that Alice has not\nyet verified that it is indeed Bob on the other side of the channel. Therefore,\nshe sends a challenge RA (message 4), which Bob responds to by returning\nKA,B(RA), shown as message 5. When Alice decrypts it with KA,B and sees\nher RA, she knows she is talking to Bob.\nNote 9.4 (Advanced: On the design of security protocols)\nOne of the difficult issues in security is designing protocols that actually work.\nTo illustrate how easily things can go wrong, consider an “optimization” of the\nauthentication protocol in which the number of messages has been reduced from\nfive to three, as shown in Figure 9.9. The basic idea is that if Alice eventually\nwants to challenge Bob anyway, she might as well send a challenge along with\nher identity when setting up the channel. Likewise, Bob returns his response to\nthat challenge, along with his own challenge, in a single message.\nFigure 9.9: Authentication based on a shared secret key, but using three\ninstead of five messages.\nUnfortunately, this protocol no longer works. It can easily be defeated by what\nis known as a reflection attack. To explain how such an attack works, consider an\nintruder called Chuck, whom we denote as C in our protocols. Chuck’s goal is to\nset up a channel with Bob so that Bob believes he is talking to Alice. Chuck can\nestablish this if he responds correctly to a challenge sent by Bob, for instance, by\nreturning the encrypted version of a number that Bob sent. Without knowledge\nDS 4.01\n \n",
      "content_length": 1623,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 591,
      "content": "9.3. AUTHENTICATION\n575\nof KA,B, only Bob can do such an encryption, and this is precisely what Chuck\ntricks Bob into doing.\nFigure 9.10: The reflection attack.\nThe attack is illustrated in Figure 9.10 Chuck starts out by sending a message\ncontaining Alice’s identity A, along with a challenge RC. Bob returns his challenge\nRB and the response KA,B(RC) in a single message. At that point, Chuck would\nneed to prove he knows the secret key by returning KA,B(RB) to Bob. Unfortu-\nnately, he does not have KA,B. Instead, what he does is attempt to set up a second\nchannel to let Bob do the encryption for him.\nTherefore, Chuck sends A and RB in a single message as before, but now\npretends that he wants a second channel. This is shown as message 3 in Figure 9.10\nBob, not recognizing that he, himself, had used RB before as a challenge, responds\nwith KA,B(RB) and another challenge RB2, shown as message 4. At that point,\nChuck has KA,B(RB) and finishes setting up the first session by returning message\n5 containing the response KA,B(RB), which was originally requested from the\nchallenge sent in message 2.\nAs explained by Kaufman et al. [2003], one of the mistakes made during the\nadaptation of the original protocol was that the two parties in the new version of\nthe protocol were using the same challenge in two different runs of the protocol.\nA better design is to always use different challenges for the initiator and for the\nresponder. For example, if Alice always uses an odd number and Bob an even\nnumber, Bob would have recognized that something fishy was going on when\nreceiving RB in message 3 in Figure 9.10. (Unfortunately, this solution is subject\nto other attacks, notably the one known as the “man-in-the-middle-attack,” which\nis explained in [Ferguson et al., 2010].) In general, letting the two parties setting\nup a secure channel doing a number of things identically is not a good idea.\nAnother principle that is violated in the adapted protocol is that Bob gave\naway valuable information in the form of the response KA,B(RC) without knowing\nfor sure to whom he was giving it. This principle was not violated in the original\nprotocol, in which Alice first needed to prove her identity, after which Bob was\nwilling to pass her encrypted information.\nThere are many principles that developers of cryptographic protocols have\ngradually come to learn over the years. One important lesson is that designing\nsecurity protocols that do what they are supposed to do is often much harder\nthan it looks. Also, tweaking an existing protocol to improve its performance,\n \nDS 4.01\n",
      "content_length": 2587,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 592,
      "content": "576\nCHAPTER 9. SECURITY\ncan easily affect its correctness. More on design principles for protocols can be\nfound in [Abadi and Needham, 1996] with a more recent analysis in [Fiebig\net al., 2018].\nAuthentication using a key distribution center\nOne of the problems with using a shared secret key for authentication is\nscalability. If a distributed system contains N hosts, and each host is required\nto share a secret key with each of the other N −1 hosts, the system as a whole\nneeds to manage N(N −1)/2 keys, and each host has to manage N −1 keys.\nFor large N, this will lead to problems. An alternative is to use a centralized\napproach by a key distribution center (KDC). This KDC shares a secret key\nwith each of the hosts, but no pair of hosts is required to have a shared secret\nkey as well. In other words, using a KDC requires that we manage N keys\ninstead of N(N −1)/2, which is clearly an improvement.\nIf Alice wants to set up a secure channel with Bob, she can do so through a\n(trusted) KDC. The whole idea is that the KDC hands out a key to both Alice\nand Bob that they can use for communication, shown in Figure 9.11.\nFigure 9.11: The principle of using a Key Distribution Center (KDC).\nAlice first sends a message to the KDC, telling it that she wants to talk to\nBob. The KDC returns a message containing a shared secret key KA,B that\nshe can use. The message is encrypted with the secret key KA,KDC that Alice\nshares with the KDC. In addition, the KDC sends KA,B also to Bob, but now\nencrypted with the secret key KB,KDC it shares with Bob.\nThe main drawback of this approach is that Alice may want to start setting\nup a secure channel with Bob even before Bob had received the shared key\nfrom the KDC. In addition, the KDC is required to get Bob into the loop by\npassing him the key. These problems can be circumvented if the KDC just\npasses KB,KDC(KA,B) back to Alice, and lets her take care of connecting to Bob.\nThis leads to the protocol shown in Figure 9.12. The message KB,KDC(KA,B) is\nalso known as a ticket. It is Alice’s job to pass this ticket to Bob. Note that Bob\nis still the only one who can make sensible use of the ticket, as he is the only\none besides the KDC who knows how to decrypt the information it contains.\nDS 4.01\n \n",
      "content_length": 2253,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 593,
      "content": "9.3. AUTHENTICATION\n577\nFigure 9.12: Using a ticket and letting Alice set up a connection to Bob.\nNote 9.5 (Advanced: The Needham-Schroeder protocol)\nThe protocol shown in Figure 9.12 is actually a variant of a well-known example\nof an authentication protocol using a KDC, known as the Needham-Schroeder\nauthentication protocol, named after its inventors [Needham and Schroeder,\n1978]. The Needham-Schroeder protocol, shown in Figure 9.13 is a so-called\nmultiway challenge-response protocol and works as follows.\nWhen Alice wants to set up a secure channel with Bob, she sends a request to\nthe KDC containing a challenge RA, along with her identity A and, of course, that\nof Bob. The KDC responds by giving her the ticket KB,KDC(KA,B), along with the\nsecret key KA,B that she can subsequently share with Bob.\nFigure 9.13: The Needham-Schroeder authentication protocol.\nThe challenge RA1 that Alice sends to the KDC along with her request to set\nup a channel to Bob is also known as a nonce. A nonce is a random number that\nis used only once, such as one chosen from a very large set. The main purpose of\na nonce is to uniquely relate two messages to each other, in this case message 1\nand message 2. In particular, by including RA1 again in message 2, Alice will\nknow for sure that message 2 is sent as a response to message 1, and that it is not,\nfor example, a replay of an older message.\nTo understand the problem at hand, assume that we did not use nonces, and\nthat Chuck has stolen one of Bob’s old keys, say Kold\nB,KDC. In addition, Chuck has\nintercepted an old response KA,KDC(B, KA,B, Kold\nB,KDC(A, KA,B)) that the KDC had\nreturned to a previous request from Alice to talk to Bob. Meanwhile, Bob will\n \nDS 4.01\n",
      "content_length": 1719,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 594,
      "content": "578\nCHAPTER 9. SECURITY\nhave negotiated a new shared secret key with the KDC. However, Chuck patiently\nwaits until Alice again requests to set up a secure channel with Bob. At that point,\nhe replays the old response, and fools Alice into making her believe she is talking\nto Bob because he can decrypt the ticket and prove he knows the shared secret key\nKA,B. Clearly this is unacceptable and must be defended against. By including a\nnonce, such an attack is impossible because replaying an older message (having a\ndifferent nonce) will immediately be discovered.\nMessage 2 also contains B, the identity of Bob. By including B, the KDC pro-\ntects Alice against the following attack. Suppose that B was left out of message 2.\nIn that case, Chuck could modify message 1 by replacing the identity of Bob with\nhis own identity, say C. The KDC would then think Alice wants to set up a secure\nchannel to Chuck, and responds accordingly. As soon as Alice intends to contact\nBob, Chuck intercepts the message and fools Alice into believing she is talking\nto Bob. By copying the identity of the other party from message 1 to message 2,\nAlice will immediately detect that her request had been modified.\nAfter the KDC has passed the ticket to Alice, the secure channel between Alice\nand Bob can be set up. Alice starts with sending message 3, which contains the\nticket to Bob, and a challenge RA2 encrypted with the shared key KA,B that the\nKDC had just generated. Bob then decrypts the ticket to find the shared key, and\nreturns a response RA2 −1 along with a challenge RB for Alice.\nThe following remark regarding message 4 is in order. In general, by returning\nRA2 −1 and not just RA2, Bob not only proves he knows the shared secret key, but\nalso that he has actually decrypted the challenge. Again, this ties message 4 to\nmessage 3 in the same way that the nonce RA tied message 2 to message 1. The\nprotocol is thus more protected against replays. However, in this special case, it\nwould have been sufficient to just return KA,B(RA2, RB), for the simple reason that\nthis message has not yet been used anywhere in the protocol before. KA,B(RA2, RB)\nalready proves that Bob has been capable of decrypting the challenge sent in\nmessage 3. Message 4 as shown in Figure 9.13 is due to historical reasons.\nThe Needham-Schroeder protocol as presented here still has the weak point\nthat if Chuck ever got a hold of an old key Kold\nA,B, he could replay message 3 and\nget Bob to set up a channel. Bob will then believe he is talking to Alice, while,\nin fact, Chuck is at the other end. In this case, we need to relate message 3 to\nmessage 1, that is, make the key dependent on the initial request from Alice to set\nup a channel with Bob. The solution is shown in Figure 9.14.\nThe trick is to incorporate a nonce in the request sent by Alice to the KDC.\nHowever, the nonce has to come from Bob: this assures Bob that whoever wants\nto set up a secure channel with him, will have gotten the appropriate information\nfrom the KDC. Therefore, Alice first requests Bob to send her a nonce RB1,\nencrypted with the key shared between Bob and the KDC. Alice incorporates this\nnonce in her request to the KDC, which will then subsequently decrypt it and\nput the result in the generated ticket. In this way, Bob will know for sure that the\nsession key is tied to the original request from Alice to talk to Bob.\nDS 4.01\n \n",
      "content_length": 3392,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 595,
      "content": "9.3. AUTHENTICATION\n579\nFigure 9.14: Protection against malicious reuse of a previously generated\nsession key in the Needham-Schroeder protocol.\nAuthentication using public-key cryptography\nLet us now look at authentication with a public-key cryptosystem that does\nnot require a KDC. Again, consider the situation that Alice wants to set\nup a secure channel to Bob, and that both are in the possession of each\nother’s public key. A typical authentication protocol based on public-key\ncryptography is shown in Figure 9.15 which we explain next.\nFigure 9.15: Mutual authentication in a public-key cryptosystem.\nAlice starts with sending a challenge RA to Bob encrypted with his public\nkey PKB. It is Bob’s job to decrypt the message and return the challenge to\nAlice. Because Bob is the only person that can decrypt the message (using\nthe private key that is associated with the public key Alice used), Alice will\nknow that she is talking to Bob. Note again that it is important that Alice is\nguaranteed to be using Bob’s public key, and not the public key of someone\nimpersonating Bob.\nWhen Bob receives Alice’s request to set up a channel, he returns the\ndecrypted challenge, along with his own challenge RB to authenticate Alice.\nIn addition, he generates a session key KA,B that can be used for further\ncommunication. Bob’s response to Alice’s challenge, his own challenge, and\n \nDS 4.01\n",
      "content_length": 1390,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 596,
      "content": "580\nCHAPTER 9. SECURITY\nthe session key are put into a message encrypted with the public key PKA\nbelonging to Alice, shown as message 2 in Figure 9.15. Only Alice will be\ncapable of decrypting this message using her private key SKA.\nAlice, finally, returns her response to Bob’s challenge using the session\nkey KA,B generated by Bob. In that way, she will have proven that she could\ndecrypt message 2, and thus that she is actually Alice to whom Bob is talking.\nThe need for session keys\nDuring the establishment of a secure channel, after the authentication phase\nhas completed, the communicating parties generally use a unique shared\nsession key for confidentiality. The session key is safely discarded when\nthe channel is no longer used. An alternative would have been to use the\nsame keys for confidentiality as those that are used for setting up the secure\nchannel. However, there are a number of important benefits to using session\nkeys [Kaufman et al., 2003].\nFirst, when a key is used often, it becomes easier to reveal it. In a sense,\ncryptographic keys are subject to “wear and tear” just like ordinary keys.\nThe basic idea is that if an intruder can intercept a lot of data that has been\nencrypted using the same key, it becomes possible to mount attacks to find\ncertain characteristics of the keys used, and possibly reveal the plaintext or\nthe key itself. For this reason, it is much safer to use the authentication keys\nas little as possible. In addition, such keys are often exchanged using some\nrelatively time-expensive out-of-band mechanism, such as regular mail or\ntelephone. Exchanging keys that way should be kept to a minimum.\nAnother important reason for generating a unique key for each secure\nchannel is to ensure protection against replay attacks, as we have come across\npreviously a number of times. By using a unique session key each time a\nsecure channel is set up, the communicating parties are at least protected\nagainst replaying an entire session. To protect replaying individual messages\nfrom a previous session, additional measures are generally needed, such as\nincluding timestamps or sequence numbers as part of the message content.\nSuppose that message integrity and confidentiality were achieved by using\nthe same key used for session establishment. In that case, whenever the key\nis compromised, an intruder may be able to decrypt messages transferred\nduring an old conversation, clearly not a desirable feature. Instead, it is much\nsafer to use per-session keys because if such a key is compromised, at worst,\nonly a single session is affected. Messages sent during other sessions stay\nconfidential.\nRelated to this last point is that Alice may want to exchange some confi-\ndential data with Bob, but she does not trust him so much that she would\nprovide him information in the form of data that have been encrypted with\nlong-lasting keys. She may want to reserve such keys for highly confidential\nDS 4.01\n \n",
      "content_length": 2949,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 597,
      "content": "9.3. AUTHENTICATION\n581\nmessages that she exchanges with parties she really trusts. In such cases,\nusing a relatively cheap session key to talk to Bob is sufficient.\nBy and large, authentication keys are often established in such a way that\nreplacing them is relatively expensive. Therefore, the combination of such\nlong-lasting keys with the much cheaper and more temporary session keys is\noften a good choice for implementing secure channels for exchanging data.\nExample of an authentication service: Kerberos\nIt should be clear by now that incorporating security into distributed systems\nis not trivial. Problems are caused by the fact that the entire system must be\nsecure; if some part is insecure, the whole system may be compromised. To\nassist the construction of distributed systems that can enforce a myriad of\nsecurity policies, a number of supporting systems have been developed that\ncan be used as a basis for further development. An important system that is\nwidely used is Kerberos [Steiner et al., 1988; Kohl et al., 1994]\nKerberos was developed at M.I.T. and is based on the Needham-Schroeder\nauthentication protocol. A detailed description of the Kerberos system can\nbe found in [Neuman et al., 2005] whereas practical information on running\nKerberos is described by Garman [2003]. A publicly available implementation\nof Kerberos, known as Shishi, is described in [Josefsson, 2015].\nKerberos can be viewed as a security system that assists clients in setting\nup a secure channel with any server that is part of a distributed system.\nSecurity is based on shared secret keys. There are two different components.\nThe authentication server (AS) is responsible for handling a login request\nfrom a user. The AS authenticates a user and provides a key that can be used\nto set up secure channels with servers. Setting up secure channels is handled\nby a ticket-granting service (TGS). The TGS hands out special messages,\nknown as tickets, that are used to convince a server that the client is really\nwho it claims to be.\nLet us take a look at how Alice logs onto a distributed system that uses\nKerberos and how she can set up a secure channel with server Bob. We\nassume that Alice has previously been registered at the distributed system, so\nthat there already exists a shared secret key KA,AS between her and the authen-\ntication server. That key is assumed to be derived from Alice’s password. For\nexample, assuming a character-string password, we can take a cryptographic\nhash of that password as the secret key. Of course, we do need to ensure that\nthe secret key is protected against unauthorized access. For Alice to log onto\nthe system, she can use any workstation available. The workstation sends her\nname in plaintext to the AS, which returns a session key KA,TGS and a ticket\nthat she will need to hand over to the TGS.\nThe ticket that is returned by the AS contains the identity of Alice, along\nwith a generated secret key that Alice and the TGS can use to communicate\nwith each other. The ticket itself will be handed over to the TGS by Alice.\n \nDS 4.01\n",
      "content_length": 3073,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 598,
      "content": "582\nCHAPTER 9. SECURITY\nTherefore, it is important that no one but the TGS can read it. For this reason,\nthe ticket is encrypted with the secret key KAS,TGS shared between the AS\nand the TGS.\nFigure 9.16: Authentication in Kerberos.\nThis part of the login procedure is shown as messages 1, 2, and 3 in\nFigure 9.16, respectively. Message 1 is not really a message, but corresponds\nto Alice typing in her login name at a workstation. Message 2 contains that\nname and is sent to the AS. Message 3 contains the session key KA,TGS and\nthe ticket KAS,TGS(A, KA,TGS). To ensure privacy, message 3 is encrypted with\nthe secret key KA,AS shared between Alice and the AS.\nWhen the workstation receives the response from the AS, it prompts Alice\nfor her password (shown as message 4), which it uses subsequently to generate\nthe shared key KA,AS. Note that this approach not only has the advantage that\nAlice’s password is never sent as plaintext across the network, but also that the\nworkstation does not even have to temporarily store it. Moreover, as soon as\nit has derived the shared key KA,AS from that password, the workstation will\nfind the session key KA,TGS, and can forget about Alice’s password altogether\n(as well as the shared secret KA,AS).\nAfter this part of the authentication has taken place, Alice can consider\nherself logged into the system through the current workstation. The ticket\nreceived from the AS is stored temporarily (typically for 8–24 hours), and\nwill be used for accessing remote services. Of course, if Alice leaves her\nworkstation, she should destroy any cached tickets. If she wants to talk to Bob,\nshe requests the TGS to generate a session key for Bob, shown as message 6 in\nFigure 9.16. The fact that Alice has the ticket KAS,TGS(A, KA,TGS) proves that\nshe is Alice. The TGS responds with a session key KA,B, again encapsulated\nin a ticket that Alice will later have to pass to Bob.\nMessage 6 also contains a timestamp, t, encrypted with the secret key\nshared between Alice and the TGS. This timestamp is used to prevent Chuck\nfrom maliciously replaying message 6 again, and trying to set up a channel to\nBob. The TGS will verify the timestamp before returning a ticket to Alice. If it\nDS 4.01\n \n",
      "content_length": 2223,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 599,
      "content": "9.3. AUTHENTICATION\n583\ndiffers more than a few minutes from the current time, the request for a ticket\nis rejected.\nThis scheme establishes what is known as single sign-on. As long as\nAlice does not change workstations, there is no need for her to authenticate\nherself to any other server that is part of the distributed system. This feature\nis important when having to deal with many services that are spread across\nmultiple machines.\nIn principle, servers in a way have delegated client\nauthentication to the AS and TGS, and will accept requests from any client\nthat has a valid ticket. Of course, services such as remote login will require that\nthe associated user has an account, but this is independent of authentication\nthrough Kerberos.\nFigure 9.17: Setting up a secure channel in Kerberos.\nSetting up a secure channel with Bob is now straightforward, and is shown\nin Figure 9.17. First, Alice sends to Bob a message containing the ticket she\ngot from the TGS, along with an encrypted timestamp. When Bob decrypts\nthe ticket, he notices that Alice is talking to him because only the TGS could\nhave constructed the ticket. He also finds the secret key KA,B, allowing him to\nverify the timestamp. At that point, Bob knows he is talking to Alice and not\nsomeone maliciously replaying message 1. By responding with KA,B(t + 1),\nBob proves to Alice that he is indeed Bob.\nExample of a secure channel: HTTP over TLS\nLet us now look at an often-used protocol suite for setting up a secure channel:\nthe Transport Layer Security protocol, or simply TLS. The protocol suite\ncomes in a number of flavors, originating from the Secure Socket Layer\nprotocol that was designed in 1994. The most recent version is TLS 1.3,\nspecified in [Rescorla et al., 2018]. TLS is generally best known for its use in\nsecuring the connection to a Web server when using HTTP, also known as\nHTTPS. In this case, HTTP is secured by setting up a secure channel between\na client and the Web server using TLS in combination with TCP.\nUnderstanding TLS can be quite difficult, mainly for two reasons. First,\nTLS 1.3 needs to be backward compatible with previous versions (at least\nthe ones that have not been deprecated). Second, the two communicating\nparties need to go through a negotiation phase to decide precisely how they\nare actually going to use TLS. The latter starts with agreeing on the version,\nbut also includes agreements on which cryptosystems (called cipher suites)\n \nDS 4.01\n",
      "content_length": 2463,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 600,
      "content": "584\nCHAPTER 9. SECURITY\nto use. TLS 1.3 simplifies matters in comparison to its predecessors in that it\nlimits the options. We are going to ignore all kinds of extra information that\nis sent during the negotiation phase and stick to the core of the protocol.\nAs mentioned, TLS 1.3 limits the choices for client and server when it\ncomes to using cipher suites. Let us assume that a client wants to set up\na secure channel based on ephemeral Diffie-Hellman key exchange, using\none of the possible Diffie-Hellman groups, say G. For example, G could be\nffdhe2048 which corresponds to g = 2 and p equal to\np = 22048 −21984 + (⌊21918 ∗e⌋+ 560316) ∗264 −1\nwhere e denotes the base of the natural logarithm (i.e., e ≈2.718281).\nFigure 9.18: The principle of setting up a secure channel using TLS 1.3.\nThe client starts with choosing a private key x as explained when intro-\nducing Diffie-Hellman key exchange. By choice of G, the client computes a\ncorresponding public key PKDH\nC\n= gx mod p. The client continues by sending\na client-hello message to the server. This message contains at least the\npublic key PKDH\nC , a nonce RC and G:\nClient: sends client-hello = [PKDH\nC , RC, G]\nThe server, assuming it accepts G, also chooses a private key y and gener-\nates its associated public key PKDH\nS\n= gy mod p. It subsequently returns a\nserver-hello message:\nServer: responds server-hello = [PKDH\nS , RS]\nDS 4.01\n \n",
      "content_length": 1402,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 601,
      "content": "9.4. TRUST IN DISTRIBUTED SYSTEMS\n585\nNote that at this point, the client has no guarantees that it is actually com-\nmunicating with the intended server. The only thing the two have essentially\ncommunicated are generated public keys. These keys can be used to compute\na shared secret key SKDH\nC,S = gxy mod p. As a next step, the client and the\nserver first each compute the following hash:\nMAC = H([PKDH\nC , RC, G, PKDH\nS , RS])\nwhere H is the SHA256 hashing function [Eastlake and Hansen, 2011]. In other\nwords, MAC is the 256-bit hash obtained by concatenating the client-hello\nand server-hello messages. MAC and SKDH are then used to generate the\nfinal shared secret session key SK∗\nC,S = f (MAC, SKDH\nC,S) where f is a so-called\nkey-derivation function. From this moment on, the communication between\nthe client and the server is kept private, i.e., encrypted with the shared secret\nkey SK∗\nC,S. The server then continues with authenticating itself. To that end,\nwe assume it can provide a certificate containing a public key PKS signed by\nthe certification authority CA. The server encrypts all its communication with\nthe client using SK∗\nC,S:\nServer sends SK∗\nC,S([PKS, sigCA]) with sigCA = SKCA(PKS)\nAt this point, the client can authenticate the server. Applications running on\ntop of TLS could, in principle, rely entirely on the use of the shared secret key\nSK∗\nC,S while keeping the communication private. Better is to generate keys\nthat the application-level protocol can use, independent of what is being used\nby the TLS connection. To that end, both client and server each compute a\nshared secret key from the information exchanged so far:\nAMAC = H([PKDH\nC , RC, G, PKDH\nS , RS, PKS, sigCA])\nthat is, essentially the concatenation of the messages client-hello and\nserver-hello, along with the certificate and again hashed using H = SHA256.\nThe final application-level shared secret key is computed as SK∗∗\nC,S = f (AMAC,\nSK∗\nC,S). A summary of what we have just discussed is shown in Figure 9.18.\n9.4\nTrust in distributed systems\nFundamental to authentication is that a process can prove to be who it claims\nto be. Once that proof has been given, the question arises how good that proof\nactually is. One can argue that this is where trust starts to play: does the\nreceiver of the proof accept that proof to be sufficient to provide the process\naccess to the system? Yet trust as facilitated or implemented in distributed\nsystems extends beyond just authentication, as witnessed by the vast interest\nin distributed ledger systems such as those implemented by blockchains.\nThe issue of trust has also become more prominent with the increase of\n \nDS 4.01\n",
      "content_length": 2667,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 602,
      "content": "586\nCHAPTER 9. SECURITY\n(semi-)automated decision-making procedures that have been installed in\nnumerous information systems and that directly affect the lives of many\nhuman beings. Making unjustified decisions does not help in building trust,\nand many such decisions have been made, and are presumably still being\nmade. Perhaps most problematic are the situations in which one needs to\ntrust decision-making without understanding the underlying process, as is\ngenerally inherently the case when applying machine-learning techniques.\nIn this section, we will zoom into matters of trust, yet will stay close to\ntechnical issues relevant for the design and implementation of distributed\nsystems. Wierzbicki [2010] discusses trust in a broader context while still\nlinking it strongly to information systems. A recent survey on trust and\nreputation models for information systems is provided by Braga et al. [2018].\n9.4.1\nTrust in the face of Byzantine failures\nBefore we take a more explicit look at trust, it is worthwhile considering its\nrelation to failure models. Trust becomes an issue when there is a dependency\nof one process P on another process Q and a possibility that the latter no\nlonger behaves according to what P expects. More specifically:\nTrust is the assurance that one entity holds that another will perform\nparticular actions according to a specific expectation.\nThis definition, by Bursell [2022], can be refined in many ways, yet will do\nfor now. The point is that when expectations have been made explicit, i.e.,\nspecified, there may be no need to talk about trust anymore. If we take a look\nat Byzantine failures within process groups, the underlying assumption is that\nthere may be processes from which we cannot expect anything anymore: they\nmay be behaving correctly or incorrectly, but we have no means of always\ncorrectly detecting whether they are living up to their specifications.\nThe interesting aspect of Byzantine failure models is that we can let go of\ntrust and develop solutions in which there is no need to trust the individual\nprocesses. The only thing that matters is that the process group lives up to its\nspecifications, that is, with a group size of n processes, at most k ≤(n −1)/3\nwill go rogue. Such a group can still reach a correct agreement among the\nnonfaulty processes. If the group cannot meet its specifications, for example,\nbecause of too many faulty processes, all bets are off.\n9.4.2\nTrusting an identity\nLet us start by looking at a rather nasty issue when accepting incoming\nrequests from a source without bothering about further authentication. This\nsituation is not unusual: it constantly happens in many decentralized peer-\nto-peer systems. The problem we need to face is that of a so-called Sybil\nattack [Douceur, 2002]. The essence of this attack is that in distributed systems,\nDS 4.01\n \n",
      "content_length": 2851,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 603,
      "content": "9.4. TRUST IN DISTRIBUTED SYSTEMS\n587\nwe generally rely on the fact that when presented with a logical identity, there\nis just a single associated physical entity. In other words, we rely on the\nfollowing three properties, as also discussed in Section 6.1:\n1. An identifier refers to at most one entity\n2. Each entity is referred to by at most one identifier.\n3. An identifier always refers to the same entity (i.e., it is never reused).\nIn the case of a Sybil attack, these assumptions are violated: an attacker simply\ncreates multiple identities and joins the system separately with each of these\nidentities to subsequently stage a specific attack. The general principle of a\nSybil attack can be elegantly summarized as shown in Figure 9.19.\n1 H = set of honest nodes\n2 S = set of Sybil nodes\n3 A = Attacker node\n4 d = minimal fraction of Sybil nodes needed for an attack\n5\n6 while True:\n7\ns = A.createNode()\n# create a Sybil node\n8\nS.add(s)\n# add it to the set S\n9\n10\nh = random.choice(H)\n# pick an arbitrary honets node\n11\ns.connectTo(h)\n# connect the new sybil node to h\n12\n13\nif len(S) / len(H) > d:\n# enough sybil nodes for...\n14\nA.attack()\n# ...an attack\nFigure 9.19: The principle of a Sybil attack (adopted from [Iqbal and Matule-\nviˇcius, 2021].\nA typical example of a Sybil attack is when operating a decentralized\npeer-to-peer network such as Chord or Kademlia. An attacker simply creates\nmultiple logical nodes that join the network. As the attacker has full control\nover these nodes, from a security perspective, they are viewed as a collection\nof colluders. In particular, there is no reason to assume that they behave as\nexpected. For example, together, they can easily launch a denial-of-service\nattack by not forwarding lookup requests. If the attacker has control over a\nsufficient number of nodes, it is with high probability that any lookup request\nwill need to go through a malicious node. Likewise, the colluding nodes can\njoin in attacking the content stored in a network, if only to delete files they\nare collectively responsible for. Even in the face of using file replication, such\na behavior may easily lead to permanent loss of data.\nAs another example of a Sybil attack, consider the aforementioned web of\ntrust. If we allowed automatic endorsement of public keys, i.e., having Chuck\nendorse the public key of Bob without an out-of-band checking that the key\n \nDS 4.01\n",
      "content_length": 2400,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 604,
      "content": "588\nCHAPTER 9. SECURITY\nis really owned by Bob, we may find ourselves in the following situation.\nNote that the web of trust is essentially based on reputation: assuming Chuck\ndoes not entirely trust Alice when it comes to validating the public key of\nBob, he may decide to also consider the validations from k > 1 others before\naccepting the validity of Bob’s public key. Yet, with automatic endorsement,\nAlice could launch a Sybil attack by simply cloning her efforts by installing\nmany nodes claiming they have validated Bob’s public key. If k of these nodes\nare consulted by Chuck, then Chuck will believe the key indeed belongs to\nBob. There is no harm in this, unless Alice had stolen Bob’s private key and\nis now trying to act as Bob. Without automatic endorsement, such an attack\nwould be much more difficult to realize.\nClosely related to a Sybil attack is the so-called eclipse attack. In this case,\na collection of colluding nodes will try to isolate a node from the network.\nWe showed in Section 5.5.4, how with almost minimal effort a gossip-based\nservice can be brought to a grinding halt before benevolent nodes may even\nsuspect that something fishy is going on. That service is based on continuously\nexchanging randomly chosen links with neighbors in an attempt to maintain\nan overlay network that resembles a random graph. The links are chosen\nfrom a relatively small list that is local to each node in the network. An\nexchanged link replaces the link in this local list. In an eclipse attack, a\nnumber of colluding nodes never return randomly chosen links, but only\nlinks to their fellow colluders. The effect is devastating: within only relatively\nfew exchanges by all nodes in the network, the malicious links will have\ncontaminated the local lists to the extent that each local list contains only links\nto the colluding nodes. At that point, the colluders have full control over the\nnetwork (see also Jesi et al. [2007]).\nThe simple way out in both cases is to use a centralized certification\nauthority: whenever Alice connects to Bob, she will have to prove to be the\nholder of the digital identity associated with her. A certificate signed by a\ntrusted authority should, in principle, do the job. Suppose the certification\nauthority is not (sufficiently) trusted. This may happen, for example because\nthe certification authority is not known enough. In that case, we may rely on\na trust chain, by which the public key PKCA that is used to sign the certificate\nis accompanied by its own certificate, signed by another certification authority,\nsay CA∗. If the public key PKCA∗is not trusted, then we can repeat the\nprocedure by having that key be accompanied by another certificate signed by\nyet another certification authority CA∗∗, and so on. However, in the end, the\nrecipient will have to trust the certification authority at the end of this chain.\nPreventing Sybil attacks: blockchain solutions\nLevine et al. [2006] and later Urdaneta et al. [2011] have looked at Sybil attacks\nin decentralized networks. Both come to the conclusion, as also already stated\nby Douceur [2002] that these attacks are almost impossible to prevent without\nDS 4.01\n \n",
      "content_length": 3171,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 605,
      "content": "9.4. TRUST IN DISTRIBUTED SYSTEMS\n589\nmaking use of a trusted authority. All other decentralized solutions up to that\npoint could at best discourage Sybil attacks, but not prevent them. However,\naccepting a centralized, trusted party in an otherwise decentralized system is\nsomething that many find difficult to accept. Yet, if we could devise a system\nthat would make having multiple identities unattractive, then maybe a trusted\nparty may not be necessary. This is where permissionless blockchains come\ninto play.\nLaunching multiple identities is attractive if the attacker knows that there\nis substantial gain in doing so compared to the price to pay for maintaining\nmultiple identities. But the price is high when, for example, an identity\nis assumed to throw in considerable resources to be able to act. This is\nprecisely what is expected in proof-of-work (PoW) blockchain systems. In\nPoW systems, validators of a block of transactions are engaged in a race,\nrequiring considerable computational resources. There is no incentive for an\nattacker to launch another identity for the same physical node, as that identity\nwill need to compete as well.\nHaving to run computational races is arguably a bad design choice for any\ndistributed system. In an attempt to still prevent Sybil attacks but avoiding\ncomputational races, designers of blockchain systems have been investigating\nproof-of-stake (PoS) solutions [Nguyen et al., 2019]. In this case, those nodes\nfor making decisions on validating transactions are selected according to how\nmuch stake they have in the system. Assuming stakes are expressed as certain\ntokens (such as digital coins), each token is indexed, after which a search is\nmade for the owner of that indexed token. Obviously, the more tokens a node\nhas, the higher the chance of being selected for decision-making. Again, we\nsee that simply creating multiple identities is not rewarding, as each of these\nidentities will need to obtain tokens before being able to act.\nNone of these blockchain solutions are without security problems (see\nSaad et al. [2020] and Li et al. [2020] for extensive overviews). Yet from the\nperspective of preventing Sybil attacks, one can argue that they do their job\nwell.\nSybil-resistant accounting mechanisms\nWhen trust in central authorities within a distributed system drops, we need\nto resort to decentralized solutions. The fundamental problem is that Alice\nhas no reason whatsoever to trust Bob a priori whenever the two get in touch\nand one needs the other to engage in a transaction of some sort. A common\nsolution is to build a reputation system by which Bob can prove to Alice that\nhe is trustworthy. At the same time, such a system should be resistant to a\nSybil attack, as we illustrated in the web-of-trust model.\nAs part of their work on building robust blockchain systems, Otte et al.\n[2020] introduced an accounting mechanism by which a node Q can show\nthat it has already done considerable work to convince node P to let it do\n \nDS 4.01\n",
      "content_length": 3006,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 606,
      "content": "590\nCHAPTER 9. SECURITY\nsome work for P. The benefit for Q, of course, is that its own performed work\nfurther increases so that it may later use that to ask others to work for it. The\nNetFlow accounting mechanism introduced by Otte et al. is based on earlier\nwork by Seuken and Parkes [2014]. Interesting for our current discussion is\nthat this decentralized accounting mechanism is resistant to Sybil attacks.\nThe basic idea is that each node P in the network maintains a list of nodes\nthat are interested in doing work for P, called the choice set of P, denoted\nas choice(P). Which node is selected from choice(P) depends on that node’s\nreputation, expressed in terms of work done for others.\nTo this end, P maintains a view of what nodes in the network have done\nso far for each other. The view is necessarily subjective: it may be incomplete\n(because P has no knowledge of all the participating nodes) and it may be\ninaccurate. In any case, P does know what it has done for others, and also\nwhat others have done for P. This information is enough for P to compute a\ncapacity cap(Q) for any node Q ∈choice(P):\ncap(Q) = max{MF(Q, P) −MF(P, Q), 0}\nwhere MF(P, Q) is the value of the maximum flow from P to Q, i.e., the\namount of work that P has, or could have contributed to work done for Q,\nincluding the work done by others. For example, if node R directly contributed\n3 units of work for Q, and R had processed 7 units for P, then P indirectly may\nhave contributed 3 units of work for Q, yet through R. The reasoning is that R\nmay never have been able to work for Q if not for the work it did for P. The\ncapacity of node Q from P’s perspective, is thus the result of the work Q has\ndirectly and indirectly done for P, minus the work P has done for Q. When\npositive, one could say that P “owes” Q some work to do. These capacities\nare then used in maximum-flow computations that result in reputation scores\nfor each node.\nNow let us consider a Sybil attack by a node Q ∈choice(P). To that end,\nQ creates n Sybil nodes Q∗\n1, . . . , Q∗n. We denote Q = Q∗\n0 as just another Sybil.\nFirst, note that for any work contributed by a Sybil Q∗\ni to another Sybil Q∗\nj\nto cause an increase in cap(Q∗\ni ), at least two conditions need to hold: (1) Q∗\nj\nneeds to have contributed work to some honest node R and (2) that node\nR needs to have contributed (indirectly) to P. What this means, is that Q\ncan successfully launch an attack only if it had already performed work for\nhonest nodes. Furthermore, the attack makes sense only if Q expects that\nother, honest nodes will contribute work to Q, and that this work is more\nthan Q’s total contributions to its Sybils. This can happen if the total capacity\nTcap(Q) of the Sybils can grow, with\nTcap(Q) =\nn\n∑\nk=0\ncap(Q∗\nk)\nNow assume that a unit of work is contributed by P to one of the Sybils, say\nQ∗\ni . In that case, MF(P, Q∗\ni ) increases by 1 unit, so that cap(Q∗\ni ) drops by 1\nDS 4.01\n \n",
      "content_length": 2932,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 607,
      "content": "9.4. TRUST IN DISTRIBUTED SYSTEMS\n591\nunit, and so does Tcap(Q). This may continue until Tcap(Q) = 0, at which\npoint P will direct its attention to other nodes and ignore any of the Sybils\nuntil their joint capacity has grown, notably because other honest nodes have\ncontributed work to those Sybils.\nHaving the Sybils perform work for each other does not help: if Q∗\ni\nperforms a unit of work for Q∗\nj , then cap(Q∗\ni ) goes up by 1 unit, yet cap(Q∗\nj )\ngoes down by 1, leaving Tcap(Q) unaffected. The only way that Tcap(Q) can\ngo up without P contributing work to one of the Sybils, is if some other honest\nnode R contributes work. If P is unaware of R, then P will not know about this\nwork and keep Tcap(Q) the same. In other words, Q cannot benefit from work\nit does for R to trick P into contributing work to one of its Sybils, including\nitself. However, if P does know about R, we can expect that both will have the\nsame perspective on the value of Tcap(Q). As a consequence, R will act the\nsame as P: it will contribute work to one of the Sybils until Tcap(Q) drops to\n0. At that point, Q is where it stood before the attack: empty-handed and in\nneed of a node willing to let it do some work.\nThis rather intuitive reasoning shows that a proper accounting mechanism\n(in the case of NetFlow based on maximum flows in a network) is actually\nSybil resistant. A precise and formal reasoning can be found in [Stannat et al.,\n2021]. Also, [Otte, 2016] will be useful in understanding some underlying\ndetails of NetFlow that we have purposefully omitted here.\n9.4.3\nTrusting a system\nAn important claimed feature of many blockchain systems is that they can\noperate without the need for a trusted third party (i.e., they are completely\ndecentralized), in addition to the fact that there is also no need to trust any\nof the individual participants. To understand this reasoning, we need to\nseparate the blockchain from the way it is maintained. The latter is strongly\ndetermined by the consensus protocol that is executed to figure out which\nblock of validated transactions can be appended to the current blockchain. The\nformer has everything to do with the transparency and protection of essentially\na read-only distributed ledger. This is where ensuring data integrity is crucial.\nRecall that a blockchain is literally a chain of blocks, with each block\nconsisting of a number of validated transactions. When it comes to ensuring\ndata integrity, we need a means to be able to detect that the current blockchain\nhas not been tampered with, i.e., ensuring that any change to the current\nchain cannot go unnoticed and thus be flagged as an attack.\nThe principle of a blockchain is shown in Figure 9.20. The first block,\ncalled the genesis block, contains the number 0x00000000 which is effectively\na null pointer. Important is that each block contains a number of transactions\nand a hash value over the data contained in the block. That hash value is\ncopied to the successor in the chain, and also serves as input to the hash value\nof the succeeding block. This cryptographic linking between two blocks is\n \nDS 4.01\n",
      "content_length": 3113,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 608,
      "content": "592\nCHAPTER 9. SECURITY\nFigure 9.20: The principle of a blockchain.\nimportant. Suppose that block Bi has hash value hi and its successor, Bi+1\nhas hash value hi+1. Obviously, any change of block Bi will invalidate hi. An\nattacker may compute a new hash value, say h∗\ni , but this value will have to\nbe propagated to block Bi+1, in turn invalidating hi+1. In other words, an\nattack can be successful only if all blocks succeeding Bi are modified as well.\nConsidering that a blockchain is assumed to be a read-only data structure, it\nwill most likely have been massively replicated. Changing the chain while\ngoing unnoticed is deemed to be too difficult, to say the least.\nA transaction can, in principle, take any form. Important is that a transac-\ntion has been validated, for example because signatures of the parties involved\nin the transaction have been verified as well as the content of the transaction.\nWhat this validation entails is thus specific to the application of a blockchain.\nAs a simple example, consider an e-voting system that is implemented\nusing a blockchain.\nIn such a system, voters are assumed to have been\nregistered (and verified that they are entitled to vote). Registration entails\nthat a voter receives a single token that is to be used for voting. When Alice\nwants to cast her vote, she can essentially engage in a transaction with her\nfavorite candidate, say Bob, and transfer the token to Bob. The latter is the\nactual transaction. Validating that transaction means, for example, that the\nentire chain needs to be checked to see whether that token had not been used\nbefore. Of course, e-voting through blockchains violates some of its claimed\nadvantages, such as being fully decentralized.\nE-voting by making use of blockchains is also illustrative in the face of\ntrust. Although one can set up a system with a tamper-proof and verifiable\ndistributed ledger, may not be enough to warrant trust. In the case of e-voting,\nPark et al. [2021] are clear: blockchains suffer from the same problems as\nany electronic voting system. What it then boils down to is that one needs to\ntrust that the distributed system has been properly implemented and secured\nagainst attacks.\nAs also argued by Werbach [2018], it is not just that one needs to trust\nthe correctness of the implementation of a system, but also that it functions\nDS 4.01\n \n",
      "content_length": 2358,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 609,
      "content": "9.5. AUTHORIZATION\n593\nas intended. In the case of blockchains, an upcoming phenomenon is the\nuse of smart contracts: programs that are automatically executed when\ncertain conditions are met within a block. This can be as simple as sending\na notification to Alice and Bob when their transaction made it to the chain,\nbut could also entail automatically engaging new transactions. Even if such\ncontracts can be proven to be correct given a specification, the question is\nwhether the specification meets intentions. Practice in law shows that humans\nare not always that good at transforming intentions into specifications (or\nregulations).\nFinally, the claim that (permissionless) blockchains do not require trust in\neach participating entity, but that only the ledger needs to be trusted, may\nnot stand so firm. In practice, there are intermediaries who offer services to\nend users for making use of blockchain applications, if only to make it easy\nfor people to participate. Those intermediaries, and the systems they use,\nwill need to be trusted. In many ways, blockchain systems and any other\ndistributed system share a lot when it comes to trusting a system.\nFor an extensive and in-depth discussion on trust in computer systems,\nwe refer the interested reader to Bursell [2022].\n9.5\nAuthorization\nWe now concentrate on providing an entity proper access to a system’s\nresources after that entity has been authenticated.\n9.5.1\nGeneral issues in access control\nTo understand the various issues involved in access control, the simple model\nshown in Figure 9.21 is generally adopted. It consists of subjects that issue a\nrequest to access an object. An object is very much like the objects we have\nbeen discussing so far. It can be thought of as encapsulating its own state and\nimplementing the operations on that state. The operations of an object that\nsubjects can request to be carried out are made available through interfaces.\nSubjects can best be thought of as being processes acting on behalf of users,\nbut can also be objects that need the services of other objects in order to carry\nout their work.\nFigure 9.21: General model of controlling access to objects.\n \nDS 4.01\n",
      "content_length": 2178,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 610,
      "content": "594\nCHAPTER 9. SECURITY\nControlling the access to an object is all about protecting the object against\ninvocations by subjects that are not allowed to have specific (or even any) of the\nmethods carried out. Also, protection may include object management issues,\nsuch as creating, renaming, or deleting objects. Protection is often enforced\nby a program called a reference monitor. A reference monitor records which\nsubject may do what, and decides whether a subject is allowed to have a\nspecific operation carried out. This monitor is called (e.g., by the underlying\ntrusted operating system) each time an object is invoked. Consequently, it is\ncritical that the reference monitor is itself tamperproof: an attacker must not\nbe able to fool around with it.\nAccess control policies\nWhen considering the protection of an application, there are essentially three\napproaches that can be followed, as shown in Figure 9.22. The first approach\nis to concentrate directly on the protection of the data that is associated with\nthe application. By direct, we mean that irrespective of the various operations\nthat can possibly be performed, the primary concern is to ensure data integrity.\nTypically, this type of protection occurs in database systems in which various\nintegrity constraints can be formulated that are automatically checked each\ntime a data item is modified (see, for example, Doorn and Rivero [2002]).\nThe second approach is to concentrate on protection by specifying exactly\nwhich operations may be performed, and by whom, when certain data or\nresources are to be accessed. In this case, the focus of control is strongly\nrelated to access control mechanisms, which we discuss extensively later\nin this chapter. For example, in an object-based system, it may be decided\nto specify for each method that is made available which specific clients are\npermitted to invoke that method. Alternatively, access control methods can be\napplied to an entire interface offered by an object, or to the entire object itself.\nThis approach thus allows for various granularities of access control.\nA third approach is to focus directly on users by taking measures by which\nonly specific people, or their proxies in the case of, for example, delegation,\nhave access to the application, irrespective of the operations they want to carry\nout. For example, Alice may have been given read access to a specific file, but\nno write access. On the other hand, Bob may be allowed to change the file,\nor even delete it. Again, combinations of these three approaches are possible\nand occur in practice.\nIn general, we can distinguish several access control policies. A common\ndistinction is often made into the following four types:\n1. Mandatory access control\n2. Discretionary access control\n3. Role-based access control\nDS 4.01\n \n",
      "content_length": 2809,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 611,
      "content": "9.5. AUTHORIZATION\n595\n(a)\n(b)\n(c)\nFigure 9.22: Three approaches for protection against security threats. (a) Pro-\ntection against invalid operations, (b) Protection against unauthorized opera-\ntions. (c) Protection against unauthorized callers.\n4. Attribute-based access control\nPerhaps conceptually the simplest access control policy is that of Mandatory\nAccess Control (MAC). In this case, access control policies are decided beyond\nthe control of an individual: a central administration defines who gets access\nto what. In the context of military security, data is typically labeled according\nto some level of secrecy, ranging from “public access” to “top secret.” Only\nif Alice has been assigned the appropriate confidentiality level, will she get\naccess to data up to that level. Although conceptually simple, mandatory\naccess control can be quite difficult from a security-management perspective.\nEasier and generally more common in many distributed systems is to\nmake use of Discretionary Access Control (DAC). In this case, the owner of\nan object (such as a file) is entitled to change access rights (such as read, write,\nor execute), but also who may have access to that object. Typically, in Unix\nsystems a distinction is made between the owner, a group, and the world.\nMAC and DAC are often seen to be combined.\nAs a next step, we can make objects in a distributed system less dependent\non owners, but instead concentrate on how they are supposed to be used by\nlooking at the roles of people. This leads to what is known as Role-based\n \nDS 4.01\n",
      "content_length": 1557,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 612,
      "content": "596\nCHAPTER 9. SECURITY\nAccess Control (RBAC) [Ferraiolo et al., 2007]. The essence of RBAC is\nthat users are not authorized based on their identity, but based on the role\nthey have within an organization. For example, within a university, we can\ndistinguish roles such as teacher, student, project controller, data steward,\ngroup leader, dean, etc. When Alice is authenticated, she will also be linked\nto a role, which may need to be indicated at the time she logs into the system.\nThen, in the associated role, she will have been granted various access rights\nto specific objects.\nMore recently, attention is being paid to Attribute-based Access Control\n(ABAC) [Hu et al., 2014; 2015]. In ABAC, attributes of users and of objects they\nwant to access are considered for deciding on the specific access rule. ABAC\nallows for much finer-grained access control in comparison to RBAC. For\nexample, not all teachers at a university may be allowed access to the exam\nresults of all students. Instead, one may want to formulate the constraint that\nonly teachers of the Distributed Systems course have read access to grades\nfrom students enrolled in that course. Likewise, only the formal leader of the\ngroup on Pervasive Systems may be entitled to read the yearly review reports\nfrom members in that group, except the ones of the full professors. We will\nreturn to ABAC later in this chapter.\nAccess control matrix\nA common approach to modeling the access rights of subjects with respect to\nobjects is to construct an access control matrix. Each subject is represented\nby a row in this matrix; each object is represented by a column. If the matrix\nis denoted M, then an entry M[s, o] lists precisely which operations subject s\ncan request to be carried out on object o. In other words, whenever a subject s\nrequests to perform the operation m on object o, the reference monitor should\ncheck if m is listed in M[s, o]. If m is not listed in M[s, o], the execution of the\noperation fails.\nConsidering that a system may easily need to support thousands of users\nand millions of objects that require protection, implementing an access control\nmatrix as a true matrix, is not the way to go. Many entries in the matrix will\nbe empty: a single subject will generally have access to relatively few objects.\nTherefore, other, more efficient ways are followed to implement an access\ncontrol matrix.\nOne widely applied approach is to have each object maintain a list of the\naccess rights of subjects that want to access the object. In essence, this means\nthat the matrix is distributed column-wise across all objects, and that empty\nentries are left out. This type of implementation leads to what is called an\naccess control list (ACL). Each object is assumed to have its own associated\nACL.\nAnother approach is to distribute the matrix row-wise by giving each sub-\nject a list of capabilities it has for each object. A capability thus corresponds\nDS 4.01\n \n",
      "content_length": 2941,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 613,
      "content": "9.5. AUTHORIZATION\n597\nto an entry in the access control matrix. Not having a capability for a specific\nobject means that the subject has no access rights for that object.\nA capability can be compared to a ticket: its holder is given certain rights\nthat are associated with that ticket. It is also clear that a ticket should be\nprotected against modifications by its holder. One approach that is particu-\nlarly suited in distributed systems, is to protect (a list of) capabilities with a\nsignature.\nThe difference between how ACLs and capabilities are used to protect the\naccess to an object is shown in Figure 9.23. Using ACLs, when a client sends\na request to a server, the server’s reference monitor will check whether it\nknows the client and if that client is known and allowed to have the requested\noperation carried out, as shown in Figure 9.23(a).\n(a)\n(b)\nFigure 9.23: Comparison between ACLs and capabilities for protecting objects.\n(a) Using an ACL. (b) Using capabilities.\nWhen using capabilities, a client simply sends its request to the server.\nThe server is not necessarily interested in whether it knows the client; the\ncapability may say enough. However, such an approach does not prevent a\nclient to pass its capability to another program. This is precisely the problem\nof delegation that we discussed before. Therefore, in practice, the client will\none way or the other have been registered at the server, while the capability\nis simply bound to that specific client. At that point, the server need only\ncheck whether the capability is valid (i.e., belongs to the client) and whether\nthe requested operation is listed in the capability. This approach to protecting\nobjects using capabilities is shown in Figure 9.23(b).\n \nDS 4.01\n",
      "content_length": 1747,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 614,
      "content": "598\nCHAPTER 9. SECURITY\n9.5.2\nAttribute-based access control\nLet us concentrate a bit more on an emerging type of access control, namely the\none based on attributes. Attribute-based access control (ABAC) is a powerful\naccess control policy that can viewed as superseding other policies. Yet, ABAC\nstill has a long way to go when it comes to its adoption in distributed systems,\nas also explained by Servos and Osborn [2017] who investigated the various\nissues and challenges that ABAC is facing.\nBasic model\nIn essence, ABAC assumes that access policies are described in terms of\nattributes and their values. Attributes can belong to many things, including\nusers, objects, and also the current state of a distributed system. To make\nthings concrete, let us consider ABAC for a university setting. We could then\nhave the following:\n• User attributes may include name, data of birth, current roles, home\naddress, department, qualifiers obtained, contract status, etc. Depending\non the role (e.g., teacher or student), a different set of attributes may be\nrelevant.\n• Object attributes can be anything, such as creator, last-modified time,\nversion number, file type, file size, but also information related to its\ncontent, such as the student or course associated with the object.\n• Environmental attributes describe the current state of the system in\nwhich access is requested, including date and time, current workload,\nmaintenance status, storage properties, available services, and such.\n• Connection attributes provide information on the current session, for ex-\nample an IP address, session duration, available bandwidth and latency\nestimates, type and strength of security used, and so on.\n• Finally, administrative attributes may reflect global policies, including\nminimal security settings, general access regulations, and maximum\nsession durations, to name a few.\nExample: The Policy Machine\nTo make matters concrete, let us look at an example system for attribute-based\naccess control, namely the Policy Machine, described in [Ferraiolo et al.,\n2011; 2015]. The architecture of the Policy Machine is a simple client-server\nmodel, where a centralized server maintains a database of (attribute,value)\npairs associated with users, applications, operations, and objects. At the client\nside, a small support program is used to communicate with the server, notably\nfor handling the access privileges of client-side applications. Obviously, the\nserver and the client-side support program need to be trusted to work as\nDS 4.01\n \n",
      "content_length": 2529,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 615,
      "content": "9.5. AUTHORIZATION\n599\nspecified. Essential to the Policy Machine is the expression of access control\nrules. To that end, a distinction is made between assignments, prohibitions,\nand obligations.\nAn assignment is simply telling the system that a user u has an associated\nattribute ua: u is said to be assigned to ua, denoted as u →ua. Likewise, an\nobject o can be assigned to an object attribute oa. In the same fashion, an\nattribute can be assigned to another attribute. For example, if ua1 →ua2, then\nall users associated with ua1 will also be associated with ua2. Assignments\nthus essentially yield sets: if u →ua, then u ∈ua.\nIn a similar vein, user attributes can be assigned to operation sets, and\noperation sets can be assigned to object attributes. This leads to triplets of the\nform allowed(ua, ops, oa) which expresses that a user u can perform operation\nop on object o only if u ∈ua, op ∈ops, o ∈oa.\nA prohibition expresses what users or applications are not allowed to\ndo. In particular, a user can be denied certain operations of certain objects,\nexpressed as denied(u, ops, os) with ops a set of operations and os a set of\nobjects. To ensure that operations are truly restricted to a given set of objects,\nthat is, denied to all other objects, the Policy Machine supports expressions\ndenied(u, ops, ¬os). In other words, if u requests to perform operation op ∈ops\non an object o ̸∈os, the Policy Machine will deny that request.\nFinally, an obligation is used to automatically take actions when certain\nevents happen. A simple example is denying a user to copy information from\none set of files to another:\nwhen u reads f ∈fs then denied(u, {write}, ¬fs).\nThis is an interesting example in the sense that it forms the basis for preventing\ninformation leakage. We have mentioned only a part of what can be expressed\nby the Policy Machine, yet it should be clear that attribute-based access control\nis by itself a powerful approach for expressing many kinds of access control\npolicies. Interestingly, the Policy Machine can also be used for MAC, DAC,\nand RBAC.\nThe simplest case is perhaps RBAC. By simple assignments such as Alice →\nTeachers we effectively assign the role of teacher to Alice. Alice can be assigned\nother roles as well, but the important aspect is that the system will take those\nroles as its starting point for access control.\nWe do note that advanced\nRBAC schemes require more sophisticated assignments in terms of the Policy\nMachine, yet the principle should be clear.\nWhen it comes to mandatory access control (MAC), the basic idea is that\none can introduce a notion of security levels L1, . . . , Ln where L1 denotes the\nlowest and Ln the highest level of security. More concrete, if Alice has access\nto “top secret” documents, she should also have access to “secret” documents.\nThe idea is straightforward: each object is assigned to an appropriate object\nsecurity-level attribute, such as OLi. Likewise, each user is assigned to a\n \nDS 4.01\n",
      "content_length": 2977,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 616,
      "content": "600\nCHAPTER 9. SECURITY\nuser security-level attribute, such as ULj. Moreover, each user security-level\nattribute ULi is assigned to ULi−1 indicating that all users assigned to ULi have\nthe same rights as users at a less secure level, represented by the user attribute\nULi−1.\nThe real issue with MAC is that we need to prevent information leaking\nfrom higher levels to lower levels. As before, this can be prevented by the\nobligation\nwhen u reads f ∈OLi then denied(u, {write}, ¬{∪n\nk=iOLk}).\nSo, for example, if we have five security levels, then anyone who reads a\ndocument from level OL3, cannot write to documents at level {OL1, OL2} or\nequivalently cannot write to documents not in {OL3, OL4, OL5}.\nFinally, let us have a look at discretionary access (DAC). The essence of\nDAC is that each object has an owner, and that this owner can actually set\naccess rights for others. For example, in Unix systems, a user alice belonging\nto a group teachers can set read, write and execute access rights for herself,\nmembers of the group teachers, and anyone else. A user with administrative\nprivileges (typically, the root user) can additionally assign objects to users and\ngroups. Some simple examples illustrate these principles.\nalice$ chmod u=rw,g=r,o= document\nexpresses that user alice changes the rights for herself to read (r) and write (w)\ndocument, yet allows members of the group to which document has been as-\nsigned to only read the file, while anyone else has no access rights whatsoever.\nLikewise,\nroot# chown alice:teachers document\ntells us that the user root assigns ownership of document to user alice and\ngroup teachers.\nFollowing Ferraiolo et al. [2011], one can create a unique user attribute per\nuser. So, Alice would be known to the system by assigning her to the user\nattribute alice. Likewise, each group is represented by a user attribute, and\nwe could, for example, perform the assignment alice →teachers. Following\nUnix conventions, we create an object attribute alice home which represents\nthe home directory of user alice. The trick is to make sure that Alice is entitled\nto execute an appropriate set of administrative commands, but also to ensure\nthat the results match the DAC model. For example, we would need Alice\nto allow to create objects within the home directory. This can be done by\nassigning a create operation to the object attribute alice home and installing\nthe obligation\nwhen alice performs create(o) at alice home then o →alice home.\nDS 4.01\n \n",
      "content_length": 2487,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 617,
      "content": "9.5. AUTHORIZATION\n601\nWhen considering the Unix DAC model, in which (almost) everything is a file,\nwe also need to consider creating objects that represent a subdirectory. Again,\nbeing a directory can be expressed in terms of an object attribute, and typically\neach directory object will need to be associated with a parent directory. In\ngeneral, we may thus have:\nwhen alice performs create(o) at directory then o →directory.\nThese examples also illustrate that expressing a DAC model in an ABAC\nmodel requires careful consideration of all the operations and elements of\nthe specific DAC model at hand. In fact, being able to accurately and com-\npletely expressing other models in terms of attribute-based access control is\nconsidered to be one of the open challenges [Servos and Osborn, 2017].\n9.5.3\nDelegation\nNow consider the following problem. A user Alice makes use of an e-mail\nservice provider who stores her mailbox somewhere within that provider’s\norganization. Typically, she is required to log in to the provider through her\nWeb browser, after which she gets to see an appropriate interface for handling\nher mail. However, Alice would prefer to use her own favorite mail client,\nwhich is installed on her laptop. The core question is how to allow that mail\nclient to act on behalf of Alice? In other words, the mail client would need\nto get access to Alice’s mailbox, and allow her to then retrieve new mail,\nread mail, send mail, and so on. In essence, Alice would like to delegate her\naccess rights to the mail client, and in such a way that the mail client can also\nautomatically log in and do its work.\nDelegation of access rights is an important technique for implementing\nprotection in computer systems and distributed systems, in particular. The\nbasic idea is simple: by passing certain access rights from one process to\nanother, it becomes easier to distribute work between several processes without\nadversely affecting the protection of resources. In the case of distributed\nsystems, processes may run on different machines and even within different\nadministrative domains. Delegation can avoid much overhead, as protection\ncan often be handled locally.\nThere are several ways to implement delegation. The least favorable one\nis to hand over the user credentials directly to an application. In fact, doing\nso would be a bad idea: there is, in general, no reason to trust an application\nor the machine it is running on. A much better and general approach, as\ndescribed by Neuman [1993] and implemented in the Kerberos system, is to\nmake use of a proxy. A proxy in the context of security in computer systems\nis a token that allows its owner to operate with the same or restricted rights\nand privileges as the subject that granted the token. A process (or user for\nthat matter) can create a proxy with at best the same rights and privileges it\nhas itself. If a process creates a new proxy based on one it currently has, the\n \nDS 4.01\n",
      "content_length": 2954,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 618,
      "content": "602\nCHAPTER 9. SECURITY\nderived proxy will have at least the same restrictions as the original one, and\npossibly more.\nBefore considering a general scheme for delegation, consider the following\ntwo approaches. First, delegation is relatively simple if Alice knows everyone.\nIf she wants to delegate rights to Bob, she merely needs to construct a certifi-\ncate saying “Alice says Bob has rights R,” such as [A, B, R]A (i.e., the message\ncontaining the identifiers A of Alice and B of Bob, along with the specified\naccess right R, and subsequently signed by Alice). If Bob wants to pass some\nof these rights to Chuck, he will ask Chuck to contact Alice and ask her for an\nappropriate certificate.\nIn a second case, Alice can simply construct a certificate saying, “The\nbearer of this certificate has rights R.” However, in this case, we need to\nprotect the certificate against illegal copying. Neuman’s scheme handles this\ncase, as well as avoiding the issue that Alice needs to know everyone to whom\nrights have to be delegated. Note that in this case, she does trust Bob in\ndelegating rights to Chuck. In practice, this means that the user Alice trusts\nthe application to which she delegated some rights, to correctly and justifiably\ndelegate some of those rights to another application (she may not even be\naware of). One obvious way to prevent further delegation is to ensure that it\nis not specified as part of Bob’s rights. The service that hands out a delegation\ncertificate for Bob, will check whether he actually is authorized to do so.\nA proxy in Neuman’s scheme has two parts, as illustrated in Figure 9.24.\nLet A be the process that created the proxy. The first part of the proxy is\na set C = {R, PKproxy}, consisting of a set R of access rights that have been\ndelegated by A, along with a publicly known part of a secret that is used to\nauthenticate the holder of the certificate. We will explain the use of PKproxy\nbelow. The certificate carries the signature sig(A, C) of A, to protect it against\nmodifications. The second part contains the other part of the secret, denoted\nas SKproxy. It is essential that SKproxy is protected against disclosure when\ndelegating rights to another process.\nFigure 9.24: The general structure of a proxy as used for delegation.\nAnother way of looking at the proxy is as follows. If Alice wants to\ndelegate some of her rights to Bob, she makes a list of rights (R) that Bob\ncan exercise. By signing the list, she prevents Bob from tampering with it.\nHowever, having only a signed list of rights is often not enough. If Bob would\nlike to exercise his rights, he may have to prove that he actually got the list\nDS 4.01\n \n",
      "content_length": 2664,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 619,
      "content": "9.5. AUTHORIZATION\n603\nfrom Alice and did not, for example, steal it from someone else. Therefore,\nAlice comes up with a very nasty question (PKproxy) that only she knows the\nanswer to (SKproxy). Anyone can easily verify the correctness of the answer\nwhen given the question. The question is appended to the list before Alice\nadds her signature.\nWhen delegating some of her rights, Alice gives the signed list of rights,\nalong with the nasty question, to Bob. She also gives Bob the answer, ensuring\nthat no one can intercept it. Bob now has a list of rights, signed by Alice,\nwhich he can hand over to, say, Chuck, when necessary. Chuck will ask him\nthe nasty question at the bottom of the list. If Bob knows the answer to it,\nChuck will know that Alice had indeed delegated the listed rights to Bob.\nAn important property of this scheme is that Alice need not be consulted.\nIn fact, Bob may decide to pass on (some of) the rights on the list to Dave. In\ndoing so, he will also tell Dave the answer to the question, so that Dave can\nprove the list was handed over to him by someone entitled to it. Alice never\nneeds to know about Dave at all.\nA protocol for delegating and exercising rights is shown in Figure 9.25.\nAssume that Alice and Bob share a secret key KA,B that can be used for\nencrypting messages they send to each other. Then, Alice first sends Bob\nthe certificate [R, PKproxy]A, signed by Alice. There is no need to encrypt this\nmessage: it can be sent as plaintext. Only the private part of the secret needs\nto be encrypted, shown as KA,B(SKproxy) in message 1.\nFigure 9.25: Using a proxy to delegate and prove ownership of access rights.\nNow suppose that Bob wants to carry out an operation at a specific server.\nAlso, assume that Alice is authorized to have that operation carried out, and\nthat she has delegated those rights to Bob. Therefore, Bob hands over his\ncredentials to the server in the form of the signed certificate [R, PKproxy]A.\nAt that point, the server will be able to verify that C has not been tampered\nwith: any modification to the list of rights, or the nasty question will be\nnoticed because both have been jointly signed by Alice. However, the server\ndoes not know yet whether Bob is the rightful owner of the certificate. To\nverify this, the server must use the secret that came with [R, PKproxy]A. To that\nend, the server sends Bob a nonce (which is just an arbitrarily chosen string)\nN, encrypted with PKproxy. By decrypting PKproxy(N) and returning N, Bob\nproves he knows the secret and is thus the rightful holder of the certificate.\n \nDS 4.01\n",
      "content_length": 2587,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 620,
      "content": "604\nCHAPTER 9. SECURITY\nNote 9.6 (More information: OAuth (Open Authorization))\nDelegation is, in principle, fairly straightforward.\nYet, it has already taken\nmany years to come to a practical scheme that was acceptable by many players.\nAlso, solutions that are designed by multiple parties coming from different\norganizations tend not to be examples of simplicity, to say the least. This is\ncertainly true for Open Authorization, generally known as OAuth. Nevertheless,\nOAuth is by now an important delegation protocol used by many organizations\nincluding Amazon, Google, Facebook, Microsoft, and Twitter. Its main purpose\nis to grant an application access to resources that are normally accessible to a\nuser only through a Web interface. A typical example is that of using a local mail\nclient, which acts on behalf of its owner, as described previously.\nLet us take a closer look at the OAuth 2.1 framework, which distinguishes\nfour different roles:\n• A resource owner, which is typically an end user, such as Alice who\nnormally accesses her mail through her provider’s Web service.\n• A client, which is an application that one would like to act on behalf of the\nresource owner, such as an e-mail client.\n• A resource server, in practice forming some kind of Web interface through\nwhich a person like Alice would normally first authenticate herself after\nwhich she can access and manage her mail.\n• An authorization server, forming the core entity when it comes to handing\nout certificates to a client on behalf of a resource owner.\nThe client application will have to be known at the authorization server\nthrough some separately executed registration process (which can also take place\nas part of the delegation process). The result is that the client receives its own,\nunique identifier, say cid. When Alice wants her application to operate on her\nbehalf when it comes to a list R of rights, the application sends\nClient: send [cid, R,H(S)]\nin which the hash of a temporary secret S is sent, computed with the hash\nfunction H. As its name suggests, the secret S is (for now) known only to the\nclient application. In the message above, we omit some additional information,\nsuch as details of the hash function, as well as some other options.\nIf Alice is not yet logged in to the authorization server, she will be required to\ndo so and confirm that the client application is entitled to the rights as expressed\nby R. At that point, the client receives a temporary authorization code AC from\nthe server, which it should use to get the final access token. The client then sends\na request for that token:\nClient: sends [cid, AC, S].\nBy sending the secret S to the authorization server, the latter can check that it is\ndealing with the same client application as before, as it simply needs to compute\nH(S) that was sent with the previous message from that application. Note that\nby now, the authorization server has verified that Alice indeed wants to delegate\nDS 4.01\n \n",
      "content_length": 2969,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 621,
      "content": "9.5. AUTHORIZATION\n605\naccess rights to the client. The client simply needs to prove that it is the same\none that initiated the delegation request. If all is verified, the authorization server\nreturns an access token AT to the client.\nIt should be clear that an access token is precious data: it gives the client\napplication the same rights as Alice would have when going directly to the\nresource server. Therefore, the access token is communicated through a secure\nchannel, and is also stored securely on the machine hosting the client (such as\nAlice’s laptop). Likewise, one way or the other the client will have to authenticate\nitself, which is determined at registration time. There are different ways OAuth 2.1\nsupports authentication, a simple one being the scheme by which the client has\na private key and the server keeps the associated public key, as we explained\npreviously, when discussing SSH.\nOAuth 2.1 distinguishes two types of access tokens. The first one is essentially\njust an identifier that the resource server can use to check the access rights of the\nclient application. It does so by passing the token to the authorization server and\nretrieving those rights. This scheme requires that the resource server contacts the\nauthorization server every time the client wants to perform an operation.\nThe second type takes the form of a (signed) certificate: it contains all the\naccess rights of the client as granted by Alice. Those rights will hold until the\ncertificate expires (and indeed, with this type of access token, there is an associated\nexpiration time).\nWe have given a very concise description of OAuth 2.1, omitting many details\nand many of its options. The specification of OAuth 2.0 is found in [Hardt et al.,\n2012]. There are also several books that explain how to set up clients and servers\nso that they adhere to the framework (see, e.g., Parecki [2020] and Boyd [2012]).\n9.5.4\nDecentralized authorization: an example\nSo far, we have been discussing various authentication and authorization\nsolutions, of which many have in common that there is a centralized compo-\nnent where permissions are checked and granted (or denied). For example,\nKerberos deploys a centralized authentication server and a centralized ticket-\ngranting service. Likewise, when dealing with delegation, a client application\ngenerally needs to be registered at an authorization server to receive a capa-\nbility to perform certain operations at a service, or that the service can check\nthe permissions at the authorization server. Each of these types of centralized\nservices will have been made robust through replication using protocols such\nas Paxos or Byzantine Fault Tolerance. Also, using straightforward workload-\nbalancing schemes, we can relatively easily scale out servers. For example, we\nmay decide that all requests coming from applications with an ID less than\nsome value K go to server #1, while the requests from other applications go to\nserver #2.\nThe situation becomes more difficult when we decentralize a service\nacross multiple administrative units, such as across different departments or\n \nDS 4.01\n",
      "content_length": 3125,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 622,
      "content": "606\nCHAPTER 9. SECURITY\norganizations. We then bump into the problem of administrative scalabil-\nity [Neuman, 1994]. In this section, we take a look at a scalable decentralized\nauthorization service, called WAVE, specifically developed to operate across\nmultiple organizations. WAVE is a good example of some of the things we\nneed to deal with when scaling out across administrative domains. Detailed\ninformation on WAVE can be found in [Andersen, 2019; Andersen et al., 2019].\nGraph-based authorization\nFundamental to the WAVE framework is the application of graph-based\nauthorization. In this scheme, a global, possibly worldwide directed graph\nis maintained. Each vertex represents an entity that is capable of granting\nor receiving permissions. For example, a vertex may represent Alice’s home\ndirectory (where she has the right to, for example, create and delete files, and\nset various permissions, including giving Bob access to some files). A vertex\ncould also represent a department in charge of a collection of applications, an\nonline cloud service that offers various resources, and so on. Each entity has a\ncollection of public keys, from which a hash is derived that serves as a means\nto look up those keys. The collection of associated private keys is, of course,\nkept secret by the party represented by the entity. The key pairs are used for\nvarious protections and signatures that we describe below.\nEach directed edge represents a delegation of permissions from one entity\n(the issuer) to another (the subject). For example, Alice can, as an issuer,\ndelegate specific file permissions to Bob, the subject. In WAVE, an edge\nrepresents an attestation. Permissions are always granted on resources, such\nas files, database (records), devices, and so on. An entity B gathers proof of its\nright to operate on a resource owned by A by showing that there is a directed\npath in the graph from A to B.\nTo this end, WAVE uses a policy mechanism called an RTree, which stands\nfor resource tree. Keeping it simple, a resource is denoted by a URI such\nas user-entity/music/albums/popular/band/. The first element in the URI is\nparticularly important: it identifies the entity responsible for the resource\nand the one which is responsible for all permissions. Each resource has\nan associated collection of permissions, which is part of an RTree.\nThe\nidentification of a resource, a specification of granted permissions on that\nresource, a duration for which the grant is valid, and possible restrictions on\nfurther delegation add up to an RTree statement. An attestation will then\nroughly consist of:\n• The hash of the issuer and that of the subject.\n• Identifiers of where information on issuer and subject can be found.\n• A set of RTree statements.\n• A signature of the issuer.\nDS 4.01\n \n",
      "content_length": 2791,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 623,
      "content": "9.5. AUTHORIZATION\n607\nThere is more related to an attestation, which we describe below. Andersen\n[2019] shows that with these basic ingredients, graph-based authorization can\nbe used to emulate DAC and RBAC models.\nThere are two important issues that need to be dealt with. First, the\ngraph needs to be stored and maintained in a scalable and fully decentralized\nfashion. Second, delegating permissions is one thing, but letting the whole\nworld know that Alice delegated specific permissions to Bob is maybe not\nsuch a good idea. In other words, there is data that needs to be protected. Let\nus next look into these issues.\nDecentralized storage\nIt is important to realize that the authorization service need, essentially,\nstore information only on resources and attestations. Moreover, there should\npreferably be no reason at all to trust the storage: the less, the better. As we\nstated before, there is increasingly more interest in using distributed systems\nin which the individual participating parties need not be trusted. Instead, one\nrelies on the fact that the system ensures that the provided information can be\ntrusted. This is precisely what happens in distributed ledgers implemented\nas blockchains. A similar reasoning is applied in WAVE: assuming that each\nentity is responsible for its own resources, then the party represented by that\nentity need not be trusted, as long as the information it provides is reliable.\nIn essence, only availability of relevant information is required. With this in\nmind, Andersen [2019] formulated the following minimal requirements for\nstorage:\n1. Proof of monotonicity: A storage operates as an unforgeable append-\nonly log.\n2. Proof of inclusion: When an object is added or retrieved, it must exist\nin storage.\n3. Proof of nonexistence: When an object does not exist, the storage should\nstate so.\n4. Proof of nonequivocation: The storage offers the same view to every\nclient.\nTogether, these requirements ensure the integrity of the global authorization\ngraph. Note that these requirements come very close to what blockchain-based\ndistributed ledgers offer.\nAssuming that these requirements can be met, we may also assume that\neach entity offers its own local storage. In this way, scalability should, in\nprinciple, be easy to realize as long as an application can indeed identify the\nlocation where that entity’s information is stored. Including global identifiers\nalong with proper name resolution as provided through DNS should do the\n \nDS 4.01\n",
      "content_length": 2498,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 624,
      "content": "608\nCHAPTER 9. SECURITY\ntrick. Of course, bundling multiple entities so that they make use of the same\nphysical storage may be required for reaching certain efficiency goals, yet it\nshould be clear that size scalability is not fundamentally hindered by letting\neach entity have its own storage. We will subsequently speak of an entity\nstore.\nAgain, keeping things simple, every entity store essentially maintains an\nappend-only operation log. Every time an object is appended to the log, it is\ncryptographically bound to its predecessor, very much like the secure linking\nin blockchains. In addition, the hash value of the appended object is securely\nappended to a separate map log, which is subsequently returned to the client\nperforming the operation on the entity store.\nWhen a client wants to retrieve on object (such as an attestation), it provides\nthe entity store with the appropriate object identifier (namely its hash value)\nand its most recent version of the map log. Suppose the object has indeed\nbeen logged. The store will return (1) the object, (2) a proof that the object\nexisted in the operation log (by returning a chain of hashes), (3) that the hash\nassociated with the object is part of the map log, and (4) that the current map\nlog is consistent with the one the client provided. Along the same lines, if the\nobject does not exist, the store simply returns nil and proves that the object\nwas not in the operation log by demonstrating that the hash value can never\nbe part of the map log.\nMeanwhile, separate processes regularly audit an entity store by recon-\nstructing the operation log and checking its consistency with what is in the\nstore. The scheme we just described is incomplete. More information can be\nfound in [Andersen, 2019].\nData protection\nFinally, let us see how data, and in particular attestations, can be protected.\nAgain, we concentrate on only the simplest case of WAVE, called structural\nsecurity. Assume A creates and attestation att for B. It appends the decryption\nkey SKatt\nA to the message, but not after encrypting it with an appropriate public\nkey PKatt\nB (as we shall see shortly, adding the decryption key by A, and only\nA, is strictly speaking not necessary):\nA sends: PKatt\nB ([att|SKatt\nA ]\n|\n{z\n}\nm1\n))\nLet us now also assume that B creates an attestation att′ for C that is\nderived from att. For example, if att allowed B to write to a specific file and\nto pass on read permissions to others, B may allow C to read the file. No one\nbut A, B, and C should know about this: it is simply no one else’s business.\nHowever, in order for C to read the file, it will have to prove it may do so.\nDS 4.01\n \n",
      "content_length": 2653,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 625,
      "content": "9.6. MONITORING\n609\nWhen B creates att′, it sends the following to C:\nB sends: PKatt′\nC ([att′|m1|SKatt\nB ]\n|\n{z\n}\nm2\n)\nBeing able to decrypt this message, C will find att′, m1, and SKatt\nB . Having\nSKatt\nB , it can decrypt m1 revealing att. Note that there is no reason for either\nA or B to be online: C has all the information it needs to prove it is allowed\nto read the file. It should now also be clear that having A also send SKatt\nA\nis not necessary. We include it to show the systematic approach of chaining\nattestations such that a node on a path can reveal all necessary attestations in\na reverse order. Note, by the way, that this scheme strongly resembles the way\nthat delegation is handled in Kerberos.\n9.6\nMonitoring\nAn important security aspect of any system is to check that policies are\nsufficient, correctly implemented, and enforced. It would be naive to assume\nthat this is always the case. For this reason alone, it is important to keep track\nof what is going on in a distributed system so that proper measures can be\ntaken when needed. A passive way of keeping track is to simply log special\nevents: when do users sign in to a system, when and which applications\naccess specific resources, and so on. Logging is important to understand what\nto do after the fact, yet will not help when the damage has been done. In\nthis section, we take a closer look at an increasingly more important aspect\nof monitoring for security, namely intrusion detection, which is all about\ndetecting unauthorized activities. As intrusion detection is often tied to a\nsingle computer, we only briefly discuss the basics to subsequently concentrate\non distributed monitoring. We start our discussion by having a look at an\nalmost ubiquitous intrusion-detection system, namely firewalls.\n9.6.1\nFirewalls\nBefore we take a look at the basics of intrusion detection, consider a common\napproach to ensuring that intruders stay out: using a firewall [Cheswick and\nBellovin, 2000; Zwicky et al., 2000]. Firewalls form one of the most often\nused protection mechanisms in networked systems. Essentially, a firewall\ndisconnects any part of a distributed system from the outside world, as shown\nin Figure 9.26. All outgoing, but especially all incoming packets are routed\nthrough a special computer and inspected before they are passed through.\nUnauthorized traffic is discarded and not allowed to continue. An important\nissue is that the firewall itself should be heavily protected against any kind of\nsecurity threat: it should never fail. Equally important is that the rules that\nprescribe what can pass through are consistent and establish what is intended.\n \nDS 4.01\n",
      "content_length": 2657,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 626,
      "content": "610\nCHAPTER 9. SECURITY\nFigure 9.26: A common implementation of a firewall.\nAs reported by Wool [2010] and Voronkov et al. [2017], properly configuring a\nfirewall is a considerable challenge.\nFirewalls essentially come in two different flavors that are often combined.\nAn important type of firewall is a packet-filtering gateway. This type of\nfirewall operates as a router and makes decisions whether to pass a network\npacket based on the source and destination address as contained in the\npacket’s header. Typically, the packet-filtering gateway shown on the outside\nLAN in Figure 9.26 would protect against incoming packets, whereas the one\non the inside LAN would filter outgoing packets. For example, to protect an\ninternal Web server against requests from hosts that are not on the internal\nnetwork, a packet-filtering gateway could decide to drop all incoming packets\naddressed to the Web server.\nMore subtle is the situation in which a company’s network consists of\nmultiple local-area networks. Each LAN can be protected using a packet-\nfiltering gateway, which is configured to pass incoming traffic only if it\noriginated from a host on one of the other LANs. In this way, a private virtual\nnetwork can be set up.\nThe other type of firewall is an application-level gateway. In contrast to a\npacket-filtering gateway, which inspects only the header of network packets,\nthis type of firewall actually inspects the content of an incoming or outgoing\nmessage. A typical example is a mail gateway that discards incoming or\noutgoing mail exceeding a certain size. More sophisticated mail gateways\nexist that are, for example, capable of filtering spam e-mail.\nAnother example of an application-level gateway is one that allows external\naccess to a digital library server, but will supply only abstracts of documents.\nIf an external user wants more, an electronic payment protocol is started.\nUsers inside the firewall have direct access to the library service.\nA special kind of application-level gateway is what is known as a proxy\ngateway. This type of firewall works as a front end to a specific kind of\napplication, and ensures that only those messages are passed that meet certain\ncriteria. Consider, for example, surfing the Web. Many Web pages contain\nDS 4.01\n \n",
      "content_length": 2272,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 627,
      "content": "9.6. MONITORING\n611\nscripts or applets that are to be executed in a user’s browser. To prevent such\ncode to be downloaded to the inside LAN, all Web traffic could be directed\nthrough a Web proxy gateway. This gateway accepts regular HTTP requests,\neither from inside or outside the firewall. In other words, it appears to its\nusers as a normal Web server. However, it filters all incoming and outgoing\ntraffic, either by discarding certain requests and pages, or modifying pages\nwhen they contain executable code.\nIt should be clear that firewalls have important limitations when consid-\nered as a general-purpose security mechanism. As they operate on network\ntraffic, they generally cannot handle authentication and authorization for\nspecific resources. That also means that once an intruder has found a way\nto bypass the rules of a firewall, all bets are off that the firewall can protect\nthe internal network. For example, if an attacker manages to take over an\naccount, all unauthorized accesses will go unnoticed by the firewall. Instead,\nother detection mechanisms need to be in place to discover unusual or even\nunauthorized behavior.\n9.6.2\nIntrusion detection: basics\nIntrusion detection systems generally come in two flavors. In signature-\nbased intrusion detection systems (SIDS) patterns of known network-level\nintrusions have been collected against which a new pattern is matched. If\nthere is a match, security operators are warned that an intrusion may be\ntaking place. Patterns typically consist of a (collection of) specific network\npackets. What can easily complicate discovering patterns is when a pattern\nspans a series of network packets, intertwined with regular traffic. Most\nproblematic with a SIDS is when no pattern is yet available, which typically\nhappens with new, unknown attacks, such as zero-day attacks: attacks based\non vulnerabilities that have not yet been made public [Bilge and Dumitra¸s,\n2012]. The increase of zero-day attacks has rendered SIDS less useful.\nMore important are the anomaly-based intrusion detection systems\n(AIDS). As it name suggests, an AIDS assumes that we can model or extract\ntypical behavior to subsequently detect nontypical, or anomalous behavior.\nAnomaly-based detection relies heavily on modern artificial-intelligence tech-\nnologies, and notably machine learning. To this end, an AIDS will first have to\ngo through a training phase and collect data that reflects typical, nonmalicious\nbehavior. Once appropriate data sets have been collected and a detection\nmodel has been constructed based on that data (such as decision trees, specific\nneural networks, or classifiers), a test phase starts by taking new data and\nletting the model decide on anomalies.\nAn important problem with an AIDS is minimizing so-called false negatives:\nflagging an anomaly as typical behavior. Doing so means that the model\nis missing events that should have been reported to a security operator. To\nminimize false negatives, many systems follow a pessimistic approach and\n \nDS 4.01\n",
      "content_length": 3025,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 628,
      "content": "612\nCHAPTER 9. SECURITY\nflag behavior as being anomalous, in turn leading to many false positives. The\nresult of many false positives is that security operators become weary of all\nthe alerts [Hassan et al., 2019]. Combatting the number of false positives\nwhile still ensuring a very low number of false negatives has proven to be a\ndifficult challenge requiring advanced techniques (see, for example, van Ede\net al. [2022]).\nThere is much more to say about intrusion detection systems. Khraisat\net al. [2019] provide a recent overview; a good introduction is provided by\nBhuyan et al. [2014].\n9.6.3\nCollaborative intrusion detection\nWhen considering large-scale distributed systems, it is clear that there cannot\nbe a single point where monitoring can take place that allows to build a\ncomplete picture of all events that may indicate that the system is under\nattack. This is where a collaborative intrusion detection system (CIDS)\nbecomes relevant. In essence, a CIDS is a collection of intrusion detection\nsystems that share detections and analyses. Each of the IDS is considered to\nbe positioned somewhere in the system. How a CIDS can be organized is\ndiscussed in [Vasilomanolakis et al., 2015], along with examples of existing\nsystems. Here, we concentrate on the effects of such organizations when it\ncomes to successfully detecting intrusions.\nTo this end, and inspired by Cordero et al. [2015], consider a collection of\nsensors that may be spread across a distributed system, each sensor measuring\ndata potentially related to intrusions. For example, a sensor may be one\nthat logs events related to a specific Web application, or one that captures\nnetwork traffic at a specific node in the system. We assume that sensors can,\nin principle, not only collect data, but perform analyses and detect intrusions.\nSensors are grouped into communities. Each community has a community\nhead, which is responsible for collecting the data from the other members in\nits community, as well as conducting analyses on that data and detecting any\nintrusions. Communities may overlap: a sensor may be a member of multiple\ncommunities, in which case it will also report to multiple community heads.\nIn a way, each community can be viewed as a single IDS.\nThe basic idea is that community heads exchange information with each\nother. If this does not happen, nor do any two communities have a sensor\nin common, then we are simply dealing with a collection of isolated IDSs. A\ncommon configuration is to let communities be disjunct, yet all community\nheads report to the same, single entity, leading to what is known as a centralized\nCIDS. More interesting is the configuration in which the community heads\nare organized into some kind of peer-to-peer network, i.e., a distributed CIDS.\nWhy is this setup interesting? As mentioned, from the perspective of\nintrusion detection, it is important to minimize false negatives, while not\nmissing out on actual intrusions, that is, true positives. To be more specific, the\nDS 4.01\n \n",
      "content_length": 3013,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 629,
      "content": "9.7. SUMMARY\n613\nperformance of an IDS is generally measured along the following metrics. We\ndenote by TP the true positives: detections that have been correctly flagged\nas belonging to an intrusion. TN are true negatives: detections that have been\ncorrectly flagged as belonging to authorized behavior. False positives (FP) are\ndetections that are incorrectly labeled as belonging to an intrusion, while false\nnegatives (FN) denote missed intrusion detections. The whole idea is then to\nconfigure the sensors into communities such that accuracy and precision are\nmaximized, with:\nAccuracy:\nACC\n=\nTP + TN\nTP + TN + FP + FN\nPrecision:\nPRE\n=\nTP\nTP + FP\nAn aspect that was further investigated in [Cordero et al., 2015] is to\nhave sensors be member of multiple communities. As a result, some sensors\nmay report their findings to multiple community heads. The question then\nbecomes how to configure the CIDS as a whole in terms of the number of\ncommunities, their sizes, and the sensors reporting to multiple community\nheads. One can expect that in a centralized setup (in particular, with just a\nsingle community and all sensors reporting to a single, centralized entity),\naccuracy and precision are best. This is indeed the case, but obviously, we\nmay have a serious scalability problem when dealing with a large system.\nIn the experiments reported by Cordero et al. [2015], having large com-\nmunities tends to lead to higher accuracy and precision, whereas it is also\nimportant to keep the total number of communities as low as scalability\npermits. Accuracy and precision also benefit from having overlapping com-\nmunities, effectively meaning that sensor findings are considered by multiple\ncommunity heads, to be later combined into the final detections.\nTo what extent the reported experiments are conclusive for other settings\nremains to be seen. However, the approach does give a means to think about\nhow to organize a CIDS while taking scalability and performance into account.\nTypically, running various experiments with different datasets will be needed\nto find a satisfactory configuration.\n9.7\nSummary\nSecurity plays an essential role in distributed systems. A distributed system\nshould provide the mechanisms that allow a variety of different security\npolicies to be enforced. Developing and properly applying those mechanisms\ngenerally makes security a difficult engineering exercise.\nSecure distributed systems are built around at least five design principles:\n(1) having fail-safe defaults, (2) offering designs and implementations that\nare open, (3) providing a separation of privileges, (4) providing only those\n \nDS 4.01\n",
      "content_length": 2637,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 630,
      "content": "614\nCHAPTER 9. SECURITY\nprivileges that are needed, and (5) minimizing redundancy of mechanisms\nand their implementations. Furthermore, we see that it is important to provide\nmechanisms at different layers in a distributed system, ranging from the lower\nlevels of operating systems to layers in which applications are running. In this\nsense, understanding what exactly the trusted computing base entails of a\nsystem is important, as this base that needs to meet all security requirements.\nFinally, and increasingly important, is that distributed systems provide\nprivacy where needed. Guaranteeing that privacy is protected is easier said\nthan done, but the fact that regulations are more firmly installed, such as the\nGDPR, contributes to the awareness that systems should be designed and\ndeveloped with security and privacy built in from the start.\nEssential to realizing secure distributed systems is the understanding and\napplication of cryptography. Next to symmetric and asymmetric cryptosys-\ntems, we see increasingly more cryptographic mechanisms come into practical\nuse due to efficient implementations. Notably homomorphic encryption\nschemes and multiparty computations are gradually seeing their way into\ndistributed systems, mainly because they allow for untrusted third parties,\nsuch as operating in the cloud, to do computations without having to reveal\nsensitive data.\nOne could argue that security in distributed systems largely boils down\nto realizing authentication and authorization.\nAuthentication deals with\nverifying claim identities. Authorization deals with protecting resources in\nsuch a way that only processes that have the proper access rights can actually\naccess and use those resources. Access control always take place after a\nprocess has been authenticated. It is important to realize that having being\nable to verify an identity is not enough for establishing trust.\nAs distributed systems scale out to multiple organizations, we see a de-\nmand for solutions that need to rely less on trusting the individual parties\ninvolved in an application. This is one of the reasons why blockchain-based\nsystems have grown in popularity, yet whether blockchain-based solutions\ncan be taken as a general solution for handling lack of trust remains to be\nseen. Often, simpler and more efficient application-specific solutions may do\nthe job, and perhaps even better.\nBesides cryptography, authentication, and authorization, it is important\nto continuously monitor what is going on in a distributed system. Advances\nin intrusion detection systems have led to using often advanced machine-\nlearning techniques for detecting anomalous behavior. An open question is\nhow such systems can be effectively scaled out to distributed settings.\nMany existing designs of distributed systems have incorporated security\nand privacy as an afterthought, often also because one may easily think that\nsecurity and functionality demand a tradeoff to be made. However, there\nis ample evidence that such a tradeoff is not necessary, provided security is\nconsidered from the start of a design.\nDS 4.01\n \n",
      "content_length": 3101,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 631,
      "content": "INDEX\n2PC, see Distributed commit, two-\nphase protocol\n3PC, see Distributed commit, three-\nphase protocol\nABAC, see Access control, attribute\nbased\nAbstract regions, 49\nAcces control\nlist, 596\nAccess control, 595\nattribute-based, 596, 598\ndiscretionary, 595, 599,600\nmandatory, 595, 599\nmatrix, 596\npolicy, 595\nrole based, 595, 599\nAccess point, 9\nAccess transparency, see Distribu-\ntion transparency\nAccuracy, 613\nACL, see Access control, list\nActivation policies, 155\nActive Directory, 376, 379\nActuator, 43, 51\nAdapter, 75\nAdaptive redirection policy, 166\nAddress Resolution Protocol, 330\nAdvanced Message-Queuing Pro-\ntocol, 227\nchannel, 228\nconnection, 228\nexchange, 231\nlink, 228,229\nnode, 229\nsession, 228\nAIDS, see Intrusion Detection Sys-\ntem, anomaly based\nAkamai, 6, 165, 453\norigin server, 165\nAmazon\nElastic Block Store, 141\nElastic Compute Cloud, 140\nMachine Image, 140\nSimple Storage Service, 66,67,\n75\nAmazon AMI, see Amazon, Machine\nImage\nAmazon S3, see Amazon, Simple\nStorage Service, 99\nbucket, 99\nAMQP, see Advanced Message-Queuing\nProtocol\nApache, 122, 159, 552\nhook, 160\nmodule, 160\nPortable Runtime, 159\nApache APR, see Apache, Portable\nRuntime\nAPI, see Application programming\ninterface\nApplication layer, 188\nApplication programming interface,\n129\nApplication-layer switch, 163\nArchitectural perspective, 8\nArchitectural style, 56\nARP, see Address resolution proto-\ncol\nAsynchronous system, 469\nAtomicity, 189\n615\n",
      "content_length": 1439,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 632,
      "content": "616\nINDEX\nAuthentication, 10, 21, 189\nAuthorization, 21, 189\ngraph-based, 606\nAutonomous System, 426\nAvailability, see Dependability, avail-\nability\nBackup server, 485\nBig endian, 198\nBitcoin, 291\nBits-per-second, 2\nBitTorrent, 10, 96\nmagnet link, 98\ntorrent file, 97\ntracker, 97\nBlockchain, 5, 22, 104\ngenesis block, 591\npermissioned, 106, 501,502\npermissionless, 106, 290, 502,\n589\nProof of Stake, 292, 589\nProof of Work, 290, 589\nsmart contract, 593\nBroadcasting, 236\nBrowser, 86\nByzantine agreement, 492\nByzantine failure, 468\nCache, 393, 407, 429\ncache hit, 429\ncoherence detection, 443\ncoherence enforcement, 444\ncoherence protocol, 443\ncontent aware, 457\ncontent blind, 458\ncooperative cache, 451\ndistributed cache, 451\nNetwork File System, 444\nWeb, 451\nwrite back, 444\nwrite through, 444\nCallback, 205\nCAP theorem, 506\nCapability, 596\nCausal history, 267\nCausality, 267\nCDN, see Content Delivery Network\nCGI, see Common Gateway Inter-\nface\nCgroups, 135\nChallenge-response protocol, 573\nchallenge, 573, 579\nmultiway, 577\nnonce, 577\nCheckpointing\ncoordinated, 539\ndistributed snapshot, 538\ndomino effect, 539\nindependent, 539,540\nrecovery line, 538\nChecksum, 186\nChord, 91, 233, 294, 333\nfinger table, 333\nflooding, 239\nforwarder, 233\nsuccessor, 91\nChrome OS, 145\nCIDS, see Intrusion Detection Sys-\ntem, collaborative\nClient, 27, 37, 60, 79\nfat, 82\nthin, 82, 142\nClient stub, 148, 194\nClient-server computing, 27, 172\nClock\naccuracy, 254\nclock drift rate, 254\ndrift, 254\nexternal synchronization, 254\ninternal synchronization, 254\nprecision, 254\nskew, 251\nsynchronization, 254\ntick, 250\nClosure mechanism, 348\ncontainer, 348\nCloud computing, 12, 98\nDS 4.01\n \n",
      "content_length": 1665,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 633,
      "content": "INDEX\n617\nCluster computing, 32, 34\nCode segment, 171\nCode-on-demand, 172\nCoherence model, 406\nCollaborative Intrusion Detection\nSystem, see Intrusion De-\ntection System, collabora-\ntive\nCommon Gateway Interface, 87\nCommunication\nasynchronous, 191, 214, 301\nasysnchronous, 219\npersistent, 191, 231, 301\nsynchronous, 27, 191\ntransient, 191, 219\nCommunication pattern, 214\npipeline, 217\npublish-subscribe, 216\nrequest-reply, 214\nCommunication perspective, 9\nCommunication protocol, 59, 183\nstack, 58\nCommunication service, 58, 183\nComputational grid, 27\nComputer timer, 250\ncounter, 250\nholding register, 250\nConcurrency transparency, see Dis-\ntribution transparency\nConcurrent operations, 260, 401\nConfidentiality, 20, 313\nConflict-Free Replicated Data Type,\n409\nConit, see Consistency unit\nConnection-oriented service, 60, 183\nConnectionless service, 184\nConsensus, 475\nflooding, 475\nPaxos, 477, 479\nPaxos, accept message, 485\nPaxos, acceptor, 480\nPaxos, client, 480\nPaxos, leader, 480, 485\nPaxos, learned message, 485\nPaxos, learner, 480\nPaxos, proposal message, 491\nPaxos, proposal timestamp, 483\nPaxos, proposer, 480, 491\nRaft, 289, 477\nRaft, follower, 477\nRaft, leader, 477\nRaft, leader election, 289\nRaft, log, 477\nRaft, term, 289, 477\nConsistency, 31\nConsistency and replication perspec-\ntive, 9\nConsistency model, 406\ncausal consistency, 401, 408\nclient centric, 415,416, 448\ncompositional, 400\ncontinuous consistency, 410, 446\ndata centric, 395\nentry consistency, 404, 415, 434\neventual consistency, 407\nlinearizable, 400\nmonotonic read, 417\nmonotonic write, 418\nprogram consistency, 410\nread your writes, 420\nschedule, 405\nsequential consistency, 397\nserializable, 400, 405, 422\nstrong eventual consistency, 409\nwrites-follow-reads, 421\nConsistency protocol, 437\nprimary based, 438,439, 474\nprimary-backup, 438\nquorum based, 441\nread quorum, 442\nreplicated-write, 440\nwrite quorum, 442\nConsistency unit, 411\ndeclaration, 414\nfalse share, 413\nContact address, 223\n \nDS 4.01\n",
      "content_length": 1982,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 634,
      "content": "618\nINDEX\nContainer, 133, 348\nContent Delivery Network, 6, 95,\n165, 319, 425, 427, 453\nContext awareness, 45\nCookie, 153\nCoordinated Universal Time, 252,253\nCoordination, 68, 248\ndirect, 68\nevent-based, 69\nmailbox, 69, 221\nreferentially coupled, 68, 313\ntemporally coupled, 68, 221,\n313\nCoordination perspective, 9\nCopy-before-use, 15\nCRDT, see Conflict-Free Replicated\nData Type\nCritical region, 264, 266, 275, 403\nCRL, see Cryptosystem, certificate\nrevocation list\nCryptosystem\nassymmetric, 21\nasymmetric, 557\ncertificate revocation, 569\ncertification authority, 569\ncertification revocation list, 569\npublic-key certificate, 569\npublic-key system, 21, 557, 568\nsecret-key system, 557\nsession key, 564, 579,580\nshared-key system, 557\nsymmetric, 21, 557\nCyclon, 304\nDAC, see Access control, discretionary\nData link layer, 186\nframe, 186\nData store, 395\nData synchronization, 248\nDeadlock, 272\nDecentralization, 3, 7\nDecentralized system, 4\nDecryption, 555\nDelegation, 601\nDependability, 18, 463\navailability, 19, 463,464\navailability, long-term, 464\nconfidentiality, 547\nintegrity, 547\nmaintainability, 19, 463\nreliability, 19, 463,464\nsafety, 19, 272, 463\nDetection\nfalse negative, 613\nfalse positive, 613\ntrue negative, 613\ntrue positive, 613\nDHCP, see Dynamic Host Configu-\nration Protocol\nDHT, see Distributed hash table\nDifferential GPS, 317\nDiffie-Hellman group, 565\nDiffie-Hellman key exchange, 565,566\nephemeral, 565\nDigital signature, 22, 561\nDirected acyclic graph, 346\nDirectory node, 345\nlocation record, 338\nroot, 338\nDirectory table, 345\nDispatcher, 125\nDistribtion\nhorizontal, 89\nDistributed commit, 40, 189, 528\nblocking protocol, 531\none-phase protocol, 529\nthree-phase protocl, 534\ntwo-phase protocol, 529\nDistributed consensus, 106\nDistributed hash table, 90\nDistributed ledger, 5, 104\nDistributed object, 63\nDistributed shared memory, 33\nDistributed system, 4\nDistributed transaction, 37\nDistribution, 3\nvertical, 89\nDS 4.01\n \n",
      "content_length": 1948,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 635,
      "content": "INDEX\n619\nDistribution transparency, 6, 11, 148\naccess transparency, 11, 15, 67,\n148\nconcurrency transparency, 13,\n149\nfailure transparency, 13, 149\nlocation transparency, 12, 148,\n332\nmigration transparency, 12, 148\nrelocation transparency, 12, 148\nreplication transparency, 13, 149\nDNS, see Domain Name System,\n359\ndomain name, 189\nDNSSEC, see Domain Name Sys-\ntem, security extension\nDocument Object Model, 145\nDOM, see Document Object Model\nDomain, 338\nDomain name, 165\nDomain Name System, 6, 165, 189,\n359,360, 472\ncanonical name, 361\ndomain, 30\nkey-signing key, 366\nresource record, 360\nsecurity extension, 366\nzone, 30, 354\nzone transfer, 362\nzone-signing key, 366\nEnd point, 150\nEnd-to-end principle, 271, 551\nEnterprise application integration,\n38, 75, 226\nEpidemic behavior, 240\nanti-entropy, 241, 521\ninfected, 241\nremoved, 241\nround, 241\nrumor spreading, 243\nsusceptible, 241\nEpidemic protocol, 240, 297\ndeath certificate, 245\ndormant death certificate, 245\nErdös-Rényi graph, 237\nError, 19, 465\nEvent bus, 70\nEvent counter, 261\nExecution segment, 171\nExtended markup language, 42, 224\nExtensible, 16\nFaaS, see Function-as-a-Service\nFail, 19\nFailure, 465\narbitrary, 468\ncommission, 468\ncommunication, 508\ncrash, 467\nexception handling, 509\nfail arbitrary, 469\nfail noisy, 469\nfail safe, 469\nfail silent, 469\nfail stop, 469\nomission, 467,468\nperformance, 468\nreceive omission, 467\nresponse, 468\nsend omission, 467\ntiming, 467\nFailure detection, 506\neventually perfect, 507\nsuspect, 507\nDowncall, 57\nDSM, see Distributed shared mem-\nory\nDynamic Host Configuration Pro-\ntocol, 46\nEAI, see Enterprise application in-\ntegration\nEBS, see Amazon, Elastic Block Store \nEclipse attack, 344, 588\nEdge computing, 100, 456\ninfrastructure, 100 \norchestration, 103 \nEncapsulation, 63,64\n \nDS 4.01\n",
      "content_length": 1795,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 636,
      "content": "620\nINDEX\nFailure rate function, 464\nFailure transparency, see Distribu-\ntion transparency\nFarmer task, 217\nFault, 20, 465\nintermittent, 20, 466\npermanent, 20, 466\ntransient, 20, 466\nFault tolerance, 5, 18, 20, 466\nByzantine, Altruism, Rational-\nity (BAR), 505\nFault-tolerance perspective, 9\nFederated learning, 4, 168\nFHE, see Security mechanism, full\nhomomorphic encryption\nFile Transfer Protocol, 188\nFirewall, 609\napplication-level gateway, 610\npacket-filtering gateway, 610\nproxy gateway, 610\nFog computing, 101\nFree riding, 96\nFront end, 162\nFTP, see File Transfer Protocol\nFunction-as-a-Service, 100\nGDPR, see General Data Protection\nRegulation\nGeneral Data Protection Regulation,\n553\nGentle reincarnation, 514\nGlobal Positioning System, 316\nGoogle Mail, 5\nGossiping, 240, 297, 311\nData-injection attack, 306\ndirectional, 244, 297\npartial view, 298, 312\nGPS, see Global Positioning System\nGrid computer, 4\nGrid computing, 32, 35\napplication layer, 37\ncollective layer, 37\nconnectivity layer, 36\nfabric layer, 36\nresource layer, 36\nGroupware, 10\nHappens-before relation, 260\nHash function, 22, 290, 560\ndigest, 291\nnonce, 291\nstrong collision resistance, 560\ntrapdoor, 560\nweak collision resistance, 560\nHonest-but-curious, 315, 553\nHTML, see HyperText Markup Lan-\nguage\nHTTP, see HyperText Transfer Pro-\ntocol\nHTTPS, see HyperText Transfer Pro-\ntocol, secure, 583\nHypercube, 90\nHyperspace, 312\nHyperText Markup Language, 86\nHyperText Transfer Protocol, 86, 188\nsecure, 367, 551\nIaaS, see Infrastructure-as-a-Service,\n139\nIANA, see Internet Assigned Num-\nbers Authority\nICN, see Information-centric network-\ning\nIdempotent operation, 80, 513\nIdentifier-location split, 329\nIDL, see Interface Definition Lan-\nguage\nImplicit action, 45\nIn-network data processing, 50\nIncremental snapshot, 539\nInformation-centric networking, see\nNamed-data networking,\n385\nInfrastructure-as-a-Service, 99, 139\nInstruction\nbehavior-sensitive, 132\ncontrol-sensitive, 132\nnonprivileged, 131\nDS 4.01\n \n",
      "content_length": 1985,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 637,
      "content": "INDEX\n621\nprivileged, 131\nInstruction set architecture, 129\nIntegrity, 20, 313\nInterceptor, 76\nmessage-level, 77\nrequest-level, 77\nInterface, 15, 184\nInterface Definition Language, 15,\n203\nInternational Atomic Time, 252\nInternet Assigned Numbers Author-\nity, 150\nInternet of Things, 44\nInternet Protocol, 187\nInternet Service Provider, 28, 100\nInternet-of-Things, 100\nInteroperability, 16\nInterprocess communication, 115\nInterrupt\ndirect overhead, 116\nindirect overhead, 116\nIntruder, 556\nIntrusion detection, 609\nIntrusion Detection System\nanomaly-based, 611\ncollaborative, 612\ncommunity, 612\nsignature-based, 611\nIoT, see Internet-of-Things\nIP, see Internet Protocol\nIPC, see Interprocess communica-\ntion\nISA, see Instruction set architecture\nISP, see Internet Service Provider,\nsee Internet Service Provider\nJavaScript, 87, 146\nKDC, see Key distribution center\nKerberos, 551, 581, 605\nauthentication service, 581\nticket-granting service, 581\nKey distribution center, 576\nsingle sign-on, 583\nticket, 576, 581\nKey-derivation function, 585\nLAMP, 140\nLAN, see Local-area network\nLandmark, 320\nLDAP, see Lightweight Directory\nAccess Protocol\nLeader election, 96, 106, 283\nbully algorithm, 283\nring algorithm, 285\nLeaf domain, 338\nLease, 72, 433\nage-based, 433\nrenewal-frequency based, 433\nstate-based, 434\nLightweight Directory Access Pro-\ntocol, 376\ndirectory information base, 377\ndirectory information tree, 377\ndirectory service agent, 379\ndirectory user agent, 379\nrelative distinguished name, 377\nLinda, 70, 307\nLittle endian, 198\nLiveness property, 482, 490, 502,\n505\nLocal-area network, 2\nLocation transparency, see Distribu-\ntion transparency\nLock, 403, 434\nLogical clock, 260, 263\nMAC, see Access control, manda-\ntory\nMaintainability, see Dependability,\nmaintainability\nMANET, see Mobile ad hoc network\nMCC, see Mobile Cloud Comput-\ning\nMean Time Between Failures, 19,\n465\nMean Time To Failure, 19, 465\nMean Time To Repair, 19, 465\n \nDS 4.01\n",
      "content_length": 1950,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 638,
      "content": "622\nINDEX\nMEC, see Mobile Edge Computing\nMechanism, 17\nMemory Management Unit, 113\nMesh network, 233\nMessage broker, 75, 95, 225, 308\nMessage digest, 562\nMessage logging, 537, 542\noptimistic, 543\npessimistic, 543\nreceiver based, 537\nsender based, 537\nMessage transfer time unit, 279\nMessage-oriented middleware, 41,\n220\nrouter, 224\nMessage-Passing Interface, 218\nMessage-queuing system, 220\nMicroservice, 65\nMiddleware, 11, 74\nmodifiable, 78\nMigration\nreceiver initiated, 172\nsender initiated, 172\nMigration transparency, see Distri-\nbution transparency\nMMU, see Memory Management\nUnit\nMobile ad hoc network, 47\nMobile agent, 168, 172\nMobile Cloud Computing, 48\nMobile computing, 47\nMobile Edge Computing, 48\nMobile host\ncare-of-address, 331\nhome agent, 331\nMOM, see Message-oriented mid-\ndleware\nMPC, see Multiparty computation\nMPI, see Message-Passing Interface\nMPLS, see Multi-Protocol Label Switch-\ning\nMTBF, see Mean Time Between Fail-\nures\nMTTF, see Mean Time To Failure\nMTTR, see Mean Time To Repair\nMTTU, see Message transfer time\nunit\nMulti-Protocol Label Switching, 454\nMulticasting, 232, 236\napplication-level, 232\natomic, 522, 526\ncausally ordered, 270, 526\nfeedback implosion, 518\nfeedback suppression, 519\nFIFO-ordered, 525\nflooding, 237\ngroup view, 523\nlink stress, 234\nprobabilistic flooding, 237\nrelative delay penalty, 234\nstretch, 234\ntotally ordered, 264, 523, 526\ntree cost, 235\nunordered, 524\nview change, 523\nMulticomputer, 33\nMultiparty computation, 23, 566\noblivious transfer, 566\nMultiprocessor, 33\nMutual exclusion, 189\npermission-based, 272\ntoken based, 272\nName\nalias, 349\nglobal, 345\nlocal, 345\nName resolution, 347\nautomounting, 373\nfile handle, 371,372\niterative, 355\nrecursive, 356\nName resolver, 355\nName space, 344\nabsolute path name, 345\nadministrational layer, 353\ndirectory node, 345\nDS 4.01\n \n",
      "content_length": 1832,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 639,
      "content": "INDEX\n623\nforeign, 349\nglobal layer, 352\nhard link, 349\nleaf node, 344\nmanagerial layer, 353\nmount point, 349\nmounting, 349, 369\nmounting point, 349\npath name, 345\nrelative path name, 345\nroot node, 345\nUnix, 346, 348\nNamed-data networking, 329, 385\ncontent store, 387\nforwarding information base,\n387\npending interest table, 387\nNaming\naccess point, 327\naddress, 327\nattribute-based, 375\ndirectory service, 375\nflat name, 329\nhome location, 331\nhuman-friendly name, 328\nidentifier, 328\nindex server, 380\nlocation independent, 328\nnaming system, 375\nNetFlow, 590\nchoice set, 590\nNetwork Coordinates System, 318\nNetwork File System, 83, 350, 369,\n445\nexport directory, 370\nNFS client, 84\nNFS server, 85\nopen delegation, 445\nNetwork layer, 186\npacket, 187\nNetwork Time Protocol, 256\nreference clock, 256\nstartum server, 256\nNetwork-address translation, 140,\n163\nNetwork-Attached Storage, 6\nNetworked computer system, 2\nexpansive view, 4\nintegrative view, 4\nNFS, see Network File System\nNode, 89\nNonce, 603\nNotification, 69\nNotification filtering, 306\nNTP, see Network Time Protocol\nOAuth, see Open Authorization\nObject\ninterface, 63\nmethod, 63\npersistent, 204\nstate, 63\ntransient, 204\nObject adapter, 75, 155\nObject wrapper, 155\nOGSA, see Open Grid Services Ar-\nchitecture\nOne-way function, 560\nOpen Authorization, 604\naccess token, 604\nauthorization code, 604\nOpen Grid Services Architecture,\n37\nNaming graph\nsymbolic link, 349\nNaming perspective, 9\nNaming service, 30\nNano computers, 2\nNAS, see Network-Attached Stor-\nage\nNAT, see Network-address transla-\ntion\nNCS, see Network Coordinates Sys-\ntem\nNDN, see Named-data networking \nNeedham-Schroeder authentication\nprotocol, 577, 581\n \nDS 4.01\n",
      "content_length": 1693,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 640,
      "content": "624\nINDEX\nOpen Systems Interconnection Ref-\nerence Model, 183\nOpenness, 15\nOrchestration, 65\nOrder deviation, 412\nOrphan computation, 513, 541\nexpiration, 514\nextermination, 514\ngrandorphan, 514\nreincarnation, 514\nOSI, see Open Systems Interconnec-\ntion Reference Model\nOut-of-band data, 151\nOverlay network, 89, 224, 231, 299,\n308, 310,311, 315\ngeometric, 318\nPaaS, see Platform-as-a-Service, 139\nParallel processing, 33\nParameter marshaling, 197\nParameter passing\ncall-by-copy/restore, 194\ncall-by-reference, 193\ncall-by-value, 193\nobject reference, 200\nParavirtualization, 133\nPartial failure, 7, 18\nPartially synchronous, 469\nPaxos, see Consensus, Paxos\nPBFT, see Practical Byzantine Fault\nTolerance\nPeer-sampling service, 244, 298, 300,\n303\nPeer-to-peer search\nflooding, 93\npolicy-based, 94\nrandom walk, 93,94, 311\nPeer-to-peer system, 89\nstructured, 90\nunstructured, 92\nPEKS, see Public Key Encryption\nwith Keyword Search\nPervasive system, 43\nPGP, see Pretty Good Privacy\nPHE, see Security mechanism, par-\ntial homomorphic encryp-\ntion\nPhysical layer, 186\nPiecewise deterministic execution\nmodel, 541\nPlanetLab, 136\nPlatform-as-a-Service, 99, 139\nPlugin, 225\nPolicy, 17\nPolicy Machine, 598\nassignment, 599\nobligation, 599\nprohibition, 599\nPort, 150\nPortability, 16\nPoS, see Blockchain, proof of stake\nPosition-based routing, 319\nPoW, see Blockchain, proof of work\nPractical Byzantine Fault Tolerance,\n498\ncommit certificate, 500\nprepare certificate, 499\nview, 499\nview-change certificate, 501\nPrecision, 613\nPresentation layer, 188\nPretty Good Privacy, 570\nPrimary server, 485\nProblem monotonicity, 410\nProcess, 113\ncontext, 113\nprocess table, 113\nProcess group, 472\nflat, 472\ngroup server, 473\nhierarchical, 472\nk-fault tolerant, 474\nProcess migration, 167\nProcess perspective, 9\nProcess synchronization, 248\nProcessor context, 113\nProgressive Web app, 148\nDS 4.01\n \n",
      "content_length": 1874,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 641,
      "content": "INDEX\n625\nProtocol stack, 185\nProtocol suite, 185\nProximity neighbor selection, 338\nProximity routing, 337\nPSS, see Peer-sampling service\nPublic key, 21\nPublic Key Encryption with Key-\nword Search, 314\nPublish, 69, 71\nPublish-subscribe, 41, 226, 306\ncontent-based, 72\nmatching, 72\nmessage subject, 308\nrouting filter, 310\ntopic-based, 72\nPWA, see Progressive Web app\nQoS, see Quality of Service\nQuality of Service, 424\nQuery containment check, 457\nQueue manager, 222\nRabbitMQ, 231\nRaft, see Consensus, Raft\nRandom graph, 92, 237\nRBAC, see Access control, role based\nRBS, see Reference Broadcast Syn-\nchronization\nRDF, see Resource Description Frame-\nwork\nRDP, see Relative delay penalty\nRead-One, Write-All, 443\nRead-write conflict, 407\nReal-time Transport Protocol, 187\nRecovery\nbackward, 536\ncheckpointing, 536\nerasure correction, 536\nforward, 536\nRedundancy\ninformation, 470\nphysical, 470\ntime, 470\ntriple modular, 470\nReference Broadcast Synchroniza-\ntion, 257\nReference monitor, 594\nReflection attack, 574\nReliability, see Dependability, relia-\nbility\nRelocation transparency, see Distri-\nbution transparency\nRemote desktop, 144\nRemote evaluation, 172\nRemote file service, 83\nremote access model, 84\nupload/download model, 84\nRemote method invocation, 41, 205\nRemote object, 63,64\nbinding to, 63\nproxy, 63\nskeleton, 64\nRemote procedure call, 38, 41,42,\n84, 190, 192\nasynchronous, 205, 231\nat-least-once semantics, 511\nat-most-once semantics, 511\nclient stub, 63\ndeferred synchronous, 205\nexactly-once semantics, 511\nfailure, 509\nmulticast, 207\none-way, 206\nsynchronous, 231\nRendezvous node, 235, 308\nReplicated object invocation, 436\nReplication\nactive, 431, 440, 474\nclient initiated, 429\ninvalidation protocol, 430\nmirror site, 426\nmirroring, 426\npartial, 457\npermanent replica, 426\nquorum based, 474\nsequencer, 441\nserver initiated, 427\n \nDS 4.01\n",
      "content_length": 1855,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 642,
      "content": "626\nINDEX\nshared nothing, 427\nupdate protocol, client-based,\n431\nupdate protocol, pull-based, 431\nupdate protocol, push-based,\n431\nupdate protocol, server-based,\n431\nReplication transparency, see Distri-\nbution transparency\nRepresentational State Transfer, 66\nRequest-reply, 79\nResource Description Framework,\n375\nResource segment, 171\nResource sharing, 10\nResource virtualization, 127\nREST, see Representational State Trans-\nfer\nRESTful architecture, 66\nReverse proxy, 163\nRMI, see Remote method invoca-\ntion\nRouting, 186\nROWA, see Read-One, Write-All\nRPC, see Remote procedure call\nRTP, see Real-Time Transport Proto-\ncol\nSaaS, see Software-as-a-Service, 139\nSafety, see Dependability, safety\nSafety property, 482, 490, 502, 505\nSandbox, 147\nScalability\nadministrative, 24, 27\nanalysis of size scalability, 25\ngeographical, 24, 26\nsize, 24\nScalable Reliable Multicasting, 519\nScaling out, 28\nScaling technique\nasynchronous communication,\n29\ncaching, 31\nhide latency, 29\npartitioning and distribution,\n30\nreplication, 31\nScaling up, 28\nSCS, see Vserver, slice creation ser-\nvice\nSCTP, see Streaming Control Trans-\nmission Protocol\nSearchable encryption, 314\nSecret key, 21\nSecure channel, 22, 568\nSecure Shell Protocol, 551\nSecure Socket Layer, 583\nSecurity\nproxy, 601\nSecurity key, 21\nSecurity mechanism, 548\nauthentication, 548, 571\nauthentication, continuous, 572\nauthentication, electronic, 572\nauthentication, multi-factor, 572\nauthentication, single-factor, 571\nauthorization, 548\ndecryption, 21\nencryption, 21, 548, 555\nencryption, ciphertext, 555\nencryption, plaintext, 555\nfull homomorphic encryption,\n558\nhomomorphic encryption, 558\npartial homomorphic encryp-\ntion, 558\nSecurity perspective, 10\nSecurity policy, 547\nSecurity principle, 549\nfail-safe defaults, 549\nleast common mechanism, 550\nleast privilege, 549\nopen design, 549\nseparation of privilege, 549\nSecurity threat, 547\nSelective routing, 310\nDS 4.01\n \n",
      "content_length": 1925,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 643,
      "content": "INDEX\n627\nSelf-certifying name, 343\nSelf-configurable system, 18\nSensor, 43\nSensor network, 49, 295\nServant, 89, 156\nServer, 24, 27, 60, 79\nconcurrent, 150\niterative, 150\npermanent state, 153\nsession state, 153\nsoft state, 152\nstateful, 152\nstateless, 152\nServer stub, 195\nServer-side script, 88\nService-level agreement, 98\nService-oriented architecture, 37, 64\nSession key, 573\nSession layer, 188\nShard, 554\nShared data space, 46, 69\nattribute, 71\ntuple, 69\nSIDS, see Intrusion Detection Sys-\ntem, signature based\nSLA, see Service-level agreement\nSmartphone, 2\nSOA, see Service-oriented architec-\nture\nSocket, 208\nSocket interface, 208\nSoftware architecture, 56\ncomponent, 57\nconnector, 57\nevent based, 70\ninterface, 57,58\nlayered, 57, 61\nmicroservice, 63\nobject, 63\npublish-subscribe, 70\nservice, 63\nshared data space, 70\nSoftware-as-a-Service, 99, 129, 139\nSpace-filling curve, 381\nSpanner, 259\nSRM, see Scalable Reliable Multi-\ncasting\nSSH, see Secure Shell Protocol\nStarvation, 272\nState machine replication, 264\nStateless execution, 66\nStreaming Control Transmission Pro-\ntocol, 187\nStrong mobility, 173\nSubscribe, 69, 72\nSuccessor, 333\nSuper peer, 95, 293\nSuperserver, 150\nSwitch tree, 235\nSybil attack, 344, 586\nSynchronization variable, see Lock\nSynchronous, 504\nSynchronous system, 469\nSystem architecture, 56, 79\nthree-tiered, 83\ntwo-tiered, 81\nSystem calls, 129\nTAI, see International Atomic Time\nTCB, see Trusted Computing Base\nTCP, see Transmission Control Pro-\ntocol, 187\nTCP handoff, 163\nThread\ncontext, 114\nmany-to-many model, 120\nmany-to-one model, 120, 122\none-to-one model, 120\nThread-level parallelism, 124\nTIB/Rendezvous, 308\nrendezvous daemon, 308\nTime\nleap second, 252\nmean solar second, 252\nsolar day, 251\nsolar second, 251\ntransit sun, 251\n \nDS 4.01\n",
      "content_length": 1776,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 644,
      "content": "628\nINDEX\nTime-to-live, 93\nTLB, see Translation Lookaside Buffer\nTLP, see Thread-level parallelism\nTLS, see Transport Layer Security\nTMR, see Redundancy, triple mod-\nular\nTopology-based identifier, 337\nTP monitor, see Transaction-processing\nmonitor\nTransaction, 38\nACID, 38\nnested, 39\nTransaction-processing monitor, 40\nTransactional RPC, 38\nTransient object, 154\nTranslation Lookaside Buffer, 113\nTransmission Control Protocol, 59,\n187\nTransport layer, 187\nTransport Layer Security, 551, 583\nTransport-layer switch, 163\nTrap, 131\nTrapdoor, 314\nTriangle inequality, 320\nTrueTime, 259\nTrust, 10, 21, 304, 586\nTrust chain, 366, 588\nTrusted Computing Base, 552\nTrusted third party, 104\nTTL, see Time-to-live\nTunnel, 551\nTuple space, 70\nUbiquitous computing system, 44\nUDP, see Universal Datagram Pro-\ntocol\nUniform Resource Identifier, 66\nUniform Resource Locator, 12, 86\nUniversal Datagram Protocol, 187\nUniversal Plug and Play protocol,\n46\nUnix\nnamespaces, 134\nUpcall, 57\nhandle, 58\nUPnP, see Universal Plug and Play\nprotocol\nURI, see Uniform Resource Identi-\nfier\nURL, see Uniform Resource Locator\nUTC, see Coordinated Universal Time,\n253\nUtility computing, 98\nUtilization, 26\nVector clock, 267,268\nVFS, see Virtual File System\nVirtual desktop environment, 82,\n144\nVirtual File System, 84\nVirtual machine monitor\nhosted, 131\nnative, 130\nVirtual Network Computing, 144\nVirtual organization, 35\nVirtual private network, 550\nVirtual synchrony, 523\nflush message, 528\nstable message, 527\nVirtualization, 127\nguest operating system, 131\nhost operating system, 131\nprocess virtual machine, 130\nvirtual processor, 113\nVM fork, 177\nVNC, see Virtual Network Comput-\ning\nVPN, see Virtual private network\nVserver, 136\nnode manager, 137\nservice provider, 137\nslice, 136\nslice authority, 137\nslice creation service, 137\nWAN, see Wide-area network\nWar driving, 317\nWAVE, 606\nDS 4.01\n \n",
      "content_length": 1871,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 645,
      "content": "INDEX\n629\nattestation, 606\nentity store, 608\nissuer, 606\nmap log, 608\noperation log, 608\nresource, 606\nRTree, 606\nRTree statement, 606\nstructural security, 608\nsubject, 606\nWeak mobility, 172\nWeak peer, 95\nWeb of trust, 570, 587\nWebAssembly, 146\nWide-area network, 2\nWindow manager, 143\nWorker task, 217\nWorker thread, 125\nWrapper, 75\nWrite set, 416\nWrite-write conflict, 407\nX kernel, 142\nX protocol, 143\nX Window System, 142\nXML, see Extended markup language\nZeroconf, 46\nZeroMQ, 213\nZooKeeper, 280, 286, 422\nensemble, 286\n \nDS 4.01\n",
      "content_length": 535,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 647,
      "content": "BIBLIOGRAPHY\nAbadi M. and Needham R. Prudent Engineering Practice for Cryptographic Protocols.\nIEEE Transactions on Software Engineering, 22(1):6–15, Jan. 1996. →576.\nAbbas N., Zhang Y., Taherkordi A., and Skeie T. Mobile Edge Computing: A Survey.\nIEEE Internet of Things Journal, 5(1):450–465, 2018. →48.\nAberer K., Alima L. O., Ghodsi A., Girdzijauskas S., Hauswirth M., and Haridi S. The\nEssence of P2P: A Reference Architecture for Overlay Networks. In 5th International\nConference on Peer-to-Peer Computing, pages 11–20, Los Alamitos, CA., Aug. 2005.\nIEEE, IEEE Computer Society Press. →89.\nAcar A., Aksu H., Uluagac A. S., and Conti M. A Survey on Homomorphic Encryption\nSchemes: Theory and Implementation. ACM Computing Surveys, 51(4):1–35, 2018.\n→558.\nAdar E. and Huberman B. A. Free Riding on Gnutella. Hewlett Packard, Information\nDynamics Lab, Jan. 2000. →96.\nAdelstein F., Gupta S., Richard G., and Schwiebert L. Fundamentals of Mobile and\nPervasive Computing. McGraw-Hill, New York, NY, 2005. →47.\nAdve S. V. and Boehm H.-J. Memory Models: A Case for Rethinking Parallel Languages\nand Hardware. Communications of the ACM, 53(8):90–101, Aug. 2010. →399.\nAfanasyev A., Burke J., Refaei T., Wang L., Zhang B., and Zhang L. A Brief Introduction\nto Named Data Networking. In IEEE Military Communications Conference (MILCOM),\npages 1–6, 2018. →386.\nAgarwal A., George M., Jeyaraj A., and Schwarzkopf M. Retrofitting GDPR Compliance\nonto Legacy Databases. Proceedings of the VLDB Endowment, 15(4):958–970, Dec. 2022.\n→554.\nAger B., Mühlbauer W., Smaragdakis G., and Uhlig S. Comparing DNS Resolvers in\nthe Wild. In 10th Internet Measurement Conference, pages 15–21, New York, NY, 2010.\nACM Press. →369.\nAguilera M. and Terry D. The Many Faces of Consistency. Data Engineering, page 3,\n2016. →395.\nAhlgren B., Dannewitz C., Imbrenda C., Kutscher D., and Ohlman B. A Survey of\nInformation-centric Networking. IEEE Communications Magazine, 50(7):26–36, July\n2012. →385.\nAiyer A., Alvisi L., Clement A., Dahlin M., and Martin J.-P. BAR Fault Tolerance for\nCooperative Services. In 20th Symposium on Operating System Principles, pages 45–58,\nNew York, NY, Oct. 2005. ACM, ACM Press. →505.\nAkgul F. ZeroMQ. Packt Publishing, Birmingham, UK, 2013. →213.\n631\n",
      "content_length": 2257,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 648,
      "content": "632\nBIBLIOGRAPHY\nAkyildiz I. F. and Kasimoglu I. H. Wireless Sensor and Actor Networks: Research\nChallenges. Ad Hoc Networks, 2:351–367, 2004. →49.\nAkyildiz I. F., Su W., Sankarasubramaniam Y., and Cayirci E. A Survey on Sensor\nNetworks. IEEE Communications Magazine, 40(8):102–114, Aug. 2002. →49.\nAkyildiz I. F., Wang X., and Wang W. Wireless Mesh Networks: A Survey. Computer\nNetworks, 47(4):445–487, Mar. 2005. →49.\nAlbrecht J., Oppenheimer D., Vahdat A., and Patterson D. A. Design and Implemen-\ntation Trade-Offs for Wide-Area Resource Discovery. ACM Transactions on Internet\nTechnology, 8(4):1–44, 2008. →383.\nAlegre U., Augusto J. C., and Clark T. Engineering Context-Aware Systems and\nApplications: A Survey. Journal of Systems and Software, 117:55–83, 2016. →45.\nAli W., Shamsuddin S. M., and Ismail A. S. A Survey of Web Caching and Prefetching.\nInternational Journal of Advances in Soft Computing and Its Applications, 3(1):18–44, 2011.\n→453.\nAllani M., Garbinato B., and Pedone F. Application Layer Multicast. In Garbinato B.,\nMirando H., and Rodrigues L., editors, Middleware for Network Eccentric and Mobile\nApplications, pages 191–214. Springer-Verlag, Berlin, 2009. →233.\nAllen R. and Lowe-Norris A. Windows 2000 Active Directory. O’Reilly & Associates,\nSebastopol, CA., 2nd edition, 2003. →379.\nAllman M. Putting DNS in Context. In Internet Measurement Conference, page 309–316,\n2020. →369.\nAlonso G., Casati F., Kuno H., and Machiraju V. Web Services: Concepts, Architectures\nand Applications. Springer-Verlag, Berlin, 2004. →37.\nAlvisi L. and Marzullo K. Message Logging: Pessimistic, Optimistic, Causal, and Opti-\nmal. IEEE Transactions on Software Engineering, 24(2):149–159, Feb. 1998. →541, 542.\nAMQP Working Group . AMQP, Protocol specification, Version 0-9-1, Nov. 2008.\n→227.\nAmza C., Cox A., Dwarkadas S., Keleher P., Lu H., Rajamony R., Yu W., and\nZwaenepoel W. TreadMarks: Shared Memory Computing on Networks of Worksta-\ntions. Computer, 29(2):18–28, Feb. 1996. →33.\nAndersen M. P. Decentralized Authorization with Private Delegation. Ph.D., University of\nCalifornia, Berkeley, 2019. →606, 607, 608.\nAndersen M. P., Kumar S., AbdelBaky M., Fierro G., Kolb J., Kim H.-S., Culler D. E.,\nand Popa R. A. WAVE: A Decentralized Authorization Framework with Transitive\nDelegation. In 28th USENIX Security Symposium, pages 1375–1392, 2019. →606.\nAndrews G. Foundations of Multithreaded, Parallel, and Distributed Programming. Addison-\nWesley, Reading, MA., 2000. →248.\nAndroutsellis-Theotokis S. and Spinellis D. A Survey of Peer-to-Peer Content Distribu-\ntion Technologies. ACM Computing Surveys, 36(4):335–371, Dec. 2004. →89.\nAntonini M., Vecchio M., and Antonelli F. Fog Computing Architectures: A Reference\nfor Practitioners. IEEE Internet of Things Magazine, 2(3):19–25, 2019. →104.\nArkills B. LDAP Directories Explained: An Introduction and Analysis. Addison-Wesley,\nReading, MA., 2003. →376.\nDS 4.01\n \n",
      "content_length": 2932,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 649,
      "content": "BIBLIOGRAPHY\n633\nAttiya H. and Welch J. Distributed Computing Fundamentals, Simulations, and Advanced\nTopics. John Wiley, New York, 2nd edition, 2004. →249.\nAtxutegi E., Liberal F., Saiz E., and Ibarrola E. Toward Standardized Internet Speed\nMeasurements for End Users: Current Technical Constraints. IEEE Communications\nMagazine, 54(9):50–57, Sept. 2016. →454.\nAvizienis A., Laprie J.-C., Randell B., and Landwehr C. Basic Concepts and Taxonomy\nof Dependable and Secure Computing. IEEE Transactions on Dependable and Secure\nComputing, 1(1):11–33, Jan. 2004. →20, 466.\nAwadallah A. and Rosenblum M.\nThe vMatrix: A Network of Virtual Machine\nMonitors for Dynamic Content Distribution. In 7th Web Caching Workshop, Aug. 2002.\n→128.\nAyeswarya S. and Norman J.\nA Survey on Different Continuous Authentication\nSystems. International Journal of Biometrics, 11(1):67–99, 2019. →572.\nAzevedo L. G., Souza Soares E. F.de , Souza R., and Moreno M. F. Modern Federated\nDatabase Systems: An Overview.\nIn 25th International Conference on Enterprise\nInformation Systems, pages 276–283, May 2020. →427.\nBabaoglu O. and Toueg S. Non-Blocking Atomic Commitment. In Mullender S., editor,\nDistributed Systems, pages 147–168. Addison-Wesley, Wokingham, 2nd edition, 1993.\n→531.\nBader M. Space-Filling Curves, An Introduction with Applications in Scientific Computing.\nSpringer-Verlag, Berlin, 2013. →382.\nBailis P., Ghodsi A., Hellerstein J. M., and Stoica I. Bolt-on Causal Consistency. In\nSIGMOD International Conference on Management Of Data, pages 761–772, New York,\nNY, 2013. ACM, ACM Press. →408.\nBalakrishnan H., Kaashoek M. F., Karger D., Morris R., and Stoica I. Looking up Data\nin P2P Systems. Communications of the ACM, 46(2):43–48, Feb. 2003. →90.\nBaldauf M., Dustdar S., and Rosenberg F. A Survey on Context-aware Systems. Int. J.\nAd Hoc Ubiquitous Comput., 2:263–277, June 2007. →46.\nBaldoni R., Beraldi R., Quema V., Querzoni L., and Tucci-Piergiovanni S. TERA: Topic-\nbased Event Routing for Peer-to-Peer Architectures. In International Conference on\nDistributed Event-Based Systems, pages 2–13, New York, NY, 2007. ACM Press. →311.\nBaldoni R., Querzoni L., Tarkoma S., and Virgillito A. Distributed Event Routing in\nPublish/Subscribe Communication Systems: a Survey. In Garbinato B., Miranda H.,\nand Rodrigues L., editors, Middleware for Network Eccentric and Mobile Applications,\npages 219–244. Springer-Verlag, Berlin, 2009. →308.\nBallintijn G. Locating Objects in a Wide-area System. PhD thesis, Vrije Universiteit\nAmsterdam, 2003. →338.\nBanaei-Kashani F. and Shahab C. Criticality-based Analysis and Design of Unstructured\nPeer-to-Peer Networks as “Complex Systems”. In 3rd International Symposium on\nCluster Computing and the Grid, pages 351–356, Los Alamitos, CA., May 2003. IEEE,\nIEEE Computer Society Press. →237.\nBaquero C. and Preguica N. Why Logical Clocks Are Easy. Communications of the ACM,\n59(4):43–47, Mar. 2016. →267.\n \nDS 4.01\n",
      "content_length": 2942,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 650,
      "content": "634\nBIBLIOGRAPHY\nBarborak M., Malek M., and Dahbura A. The Consensus Problem in Fault-Tolerant\nComputing. ACM Computing Surveys, 25(2):171–220, June 1993. →504.\nBarham P., Dragovic B., Fraser K., Hand S., Harris T., Ho A., Neugebar R., Pratt I., and\nWarfield A. Xen and the Art of Virtualization. In 19th Symposium on Operating System\nPrinciples, pages 164–177, New York, NY, Oct. 2003. ACM, ACM Press. →133.\nBarron D. Pascal – The Language and its Implementation. John Wiley, New York, 1981.\n→174.\nBarroso L., Hölze U., and Ranganathan P. The Datacenter as a Computer: An Intro-\nduction to the Design of Warehouse-Scale Machines. Synthesis Lectures on Computer\nArchitectures. Morgan and Claypool, San Rafael, CA, 3rd edition, 2018. →129.\nBaset S. and Schulzrinne H. An Analysis of the Skype Peer-to-Peer Internet Telephony\nProtocol. In 25th INFOCOM Conference, pages 1–11, Los Alamitos, CA., Apr. 2006.\nIEEE, IEEE Computer Society Press. →28.\nBasile C., Whisnant K., Kalbarczyk Z., and Iyer R. K.\nLoose Synchronization of\nMultithreaded Replicas. In 21st Symposium on Reliable Distributed Systems, pages\n250–255, Los Alamitos, CA., 2002. IEEE, IEEE Computer Society Press. →436.\nBasile C., Kalbarczyk Z., and Iyer R. K. A Preemptive Deterministic Scheduling\nAlgorithm for Multithreaded Replicas. In International Conference on Dependable\nSystems and Networks, pages 149–158, Los Alamitos, CA., June 2003. IEEE Computer\nSociety Press. →436.\nBass L., Clements P., and Kazman R. Software Architecture in Practice. Addison-Wesley,\nReading, MA., 4th edition, 2021. →56, 57, 79.\nBavier A., Bowman M., Chun B., Culler D., Karlin S., Muir S., Peterson L., Roscoe\nT., Spalink T., and Wawrzoniak M. Operating System Support for Planetary-Scale\nNetwork Services. In 1st Symposium on Networked Systems Design and Implementation,\npages 245–266, Berkeley, CA, Mar. 2004. USENIX, USENIX. →136.\nBeckers K., Heisel M., and Hatebur D. Pattern and Security Requirements. Springer-\nVerlag, Berlin, 2015. →547.\nBen-Ari M. Principles of Concurrent and Distributed Programming. Prentice Hall, Engle-\nwood Cliffs, N.J., 2nd edition, 2006. →33.\nBernstein P. Middleware: A Model for Distributed System Services. Communications of\nthe ACM, 39(2):87–98, Feb. 1996. →37, 74.\nBernstein P. and Newcomer E. Principles of Transaction Processing. Morgan Kaufman,\nSan Mateo, CA., 2nd edition, 2009. →38, 529.\nBernstein P., Hadzilacos V., and Goodman N. Concurrency Control and Recovery in\nDatabase Systems. Addison-Wesley, Reading, MA., 1987. →535.\nBershad B., Zekauskas M., and Sawdon W. The Midway Distributed Shared Memory\nSystem. In COMPCON, pages 528–537. IEEE, 1993. →404.\nBharambe A. R., Agrawal M., and Seshan S. Mercury: Supporting Scalable Multi-\nAttribute Range Queries. In SIGCOMM, pages 353–366, New York, NY, Aug. 2004.\nACM Press. →384.\nBhuyan M. H., Bhattacharyya D. K., and Kalita J. K. Network Anomaly Detection:\nMethods, Systems and Tools. IEEE Communications Surveys & Tutorials, 16(1):303–336,\nDS 4.01\n \n",
      "content_length": 2989,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 651,
      "content": "BIBLIOGRAPHY\n635\n2014. →612.\nBilal S. M., Bernardos C. J., and Guerrero C. Position-based Routing in Vehicular\nNetworks: A Survey. Journal of Network and Computer Applications, 36(2):685–697,\nMar. 2013. →319.\nBilge L. and Dumitra¸s T. Before We Knew It: An Empirical Study of Zero-day Attacks\nin the Real World. In Conference on Computer and Communications Security, pages\n833–844, 2012. →611.\nBirman K. Guide to Reliable Distributed Systems: Building High-Assurance Applications\nand Cloud-Hosted Services. Springer-Verlag, Berlin, 2012. →152, 507.\nBirman K. A Response to Cheriton and Skeen’s Criticism of Causal and Totally Ordered\nCommunication. Operating Systems Review, 28(1):11–21, Jan. 1994. →271.\nBirman K. and Joseph T. Reliable Communication in the Presence of Failures. ACM\nTransactions on Computer Systems, 5(1):47–76, Feb. 1987. →523.\nBirman K. and van Renesse R., editors. Reliable Distributed Computing with the Isis\nToolkit. IEEE Computer Society Press, Los Alamitos, CA., 1994. →271.\nBirman K., Schiper A., and Stephenson P. Lightweight Causal and Atomic Group\nMulticast. ACM Transactions on Computer Systems, 9(3):272–314, Aug. 1991. →526.\nBirrell A. and Nelson B. Implementing Remote Procedure Calls. ACM Transactions on\nComputer Systems, 2(1):39–59, Feb. 1984. →192.\nBishop M. Computer Security: Art and Science. Addison-Wesley, Reading, MA., 2nd\nedition, 2019. →547.\nBittencourt L., Immich R., Sakellariou R., Fonseca N., Madeira E., Curado M., Villas L.,\nDaSilva L., Lee C., and Rana O. The Internet of Things, Fog and Cloud continuum:\nIntegration and challenges. Internet of Things, 3-4:134–155, 2018. →103.\nBlair G. and Stefani J.-B. Open Distributed Processing and Multimedia. Addison-Wesley,\nReading, MA., 1998. →16.\nBlake G., Dreslinski R. G., Mudge T., and Flautner K. Evolution of Thread-Level\nParallelism in Desktop Applications. SIGARCH Computer Architecture News, 38(3):\n302–313, 2010. →124.\nBlaze M. Caching in Large-Scale Distributed File Systems. PhD thesis, Department of\nComputer Science, Princeton University, Jan. 1993. →429.\nBloom B. H. Space/time Trade-offs in Hash Coding with Allowable Errors. Communi-\ncations of the ACM, 13(7):422–426, 1970. →559.\nBoneh D., Crescenzo G. D., Ostrovsky R., and Persiano G. Public Key Encryption with\nKeyword Search. In International Conference Theory and Applications of Cryptographic\nTechniques, volume 3027 of Lecture Notes in Computer Science, pages 506–522, Berlin,\n2004. Springer-Verlag. →314.\nBonnet P., Gehrke J., and Seshadri P. Towards Sensor Database Systems. In 2nd\nInternational Conference on Mobile Data Management, volume 1987 of Lecture Notes in\nComputer Science, pages 3–14, Berlin, Jan. 2002. Springer-Verlag. →50.\nBosch C., Hartel P., Jonker W., and Peter A. A Survey of Provably Secure Searchable\nEncryption. ACM Computing Surveys, 47(2), Aug. 2014. →314.\nBoyd R. Getting Started with OAuth 2.0. O’Reilly & Associates, Sebastopol, CA., 2012.\n \nDS 4.01\n",
      "content_length": 2948,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 652,
      "content": "636\nBIBLIOGRAPHY\n→605.\nBraga D. D. S., Niemann M., Hellingrath B., and Neto F. B. D. L. Survey on Compu-\ntational Trust and Reputation Models. ACM Computing Surveys, 51(5):1–40, 2018.\n→586.\nBrewer E. CAP Twelve Years Later: How the \"Rules\" Have Changed. Computer, 45(2):\n23–29, Feb. 2012. →506.\nBudhijara N., Marzullo K., Schneider F., and Toueg S. The Primary-Backup Ap-\nproach. In Mullender S., editor, Distributed Systems, pages 199–216. Addison-Wesley,\nWokingham, 2nd edition, 1993. →438.\nBudhiraja N. and Marzullo K. Tradeoffs in Implementing Primary-Backup Protocols.\nTechnical Report TR 92-1307, Department of Computer Science, Cornell University,\n1992. →438.\nBuford J. and Yu H. Peer-to-Peer Networking and Applications: Synopsis and Research\nDirections. In Shen et al. [2010], pages 3–45. →89.\nBuford J., Yu H., and Lua E. P2P Networking and Applications. Morgan Kaufman, San\nMateo, CA., 2009. →89.\nBugnion E., Nieh J., and Tsafrir D. Hardware and Software Support for Virtualization.\nSynthesis Lectures on Computer Architecture. Morgan and Claypool, San Rafael,\nCA, 2017. →129.\nBursell M. Trust in Computer Systems and The Cloud. John Wiley, New York, 2022.\n→586, 593.\nCabri G., Leonardi L., and Zambonelli F. Mobile-Agent Coordination Models for\nInternet Applications. Computer, 33(2):82–89, Feb. 2000. →68.\nCachin C., Guerraoui R., and Rodrigues L. Introduction to Reliable and Secure Distributed\nProgramming. Springer-Verlag, Berlin, 2nd edition, 2011. →248, 469, 475, 476.\nCallaghan B. NFS Illustrated. Addison-Wesley, Reading, MA., 2000. →83, 373.\nCantin J., Lipasti M., and Smith J. The Complexity of Verifying Memory Coherence\nand Consistency. IEEE Transactions on Parallel and Distributed Systems, 16(7):663–671,\nJuly 2005. →406.\nCao L. and Ozsu T. Evaluation of Strong Consistency Web Caching Techniques. World\nWide Web, 5(2):95–123, June 2002. →453.\nCarriero N. and Gelernter D. Linda in Context. Communications of the ACM, 32(4):\n444–458, 1989. →70.\nCarzaniga A., Rutherford M. J., and Wolf A. L. A Routing Scheme for Content-Based\nNetworking. In 23rd INFOCOM Conference, Los Alamitos, CA., Mar. 2004. IEEE,\nIEEE Computer Society Press. →310.\nCarzaniga A., Picco G. P., and Vigna G. Is Code Still Moving Around? Looking Back\nat a Decade of Code Mobility. In 29th International Conference on Software Engineering\n(ICSE) (companian), pages 9–20, Los Alamitos, CA., 2007. IEEE Computer Society\nPress. →168.\nCastro M. and Liskov B. Practical Byzantine Fault Tolerance and Proactive Recovery.\nACM Transactions on Computer Systems, 20(4):398–461, Nov. 2002. →498, 501.\nCastro M., Druschel P., Hu Y. C., and Rowstron A.\nTopology-aware Routing in\nDS 4.01\n \n",
      "content_length": 2670,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 653,
      "content": "BIBLIOGRAPHY\n637\nStructured Peer-to-Peer Overlay Networks.\nTechnical Report MSR-TR-2002-82,\nMicrosoft Research, Cambridge, UK, June 2002a. →337.\nCastro M., Druschel P., Kermarrec A.-M., and Rowstron A. Scribe: A Large-Scale and\nDecentralized Application-Level Multicast Infrastructure. IEEE Journal on Selected\nAreas in Communication, 20(8):100–110, Oct. 2002b. →233.\nCastro M., Rodrigues R., and Liskov B. BASE: Using Abstraction to Improve Fault\nTolerance. ACM Transactions on Computer Systems, 21(3):236–269, Aug. 2003. →501.\nCastro M., Costa M., and Rowstron A. Debunking Some Myths about Structured\nand Unstructured Overlays. In 2nd Symposium on Networked Systems Design and\nImplementation, Berkeley, CA, Mar. 2005. USENIX, USENIX. →299.\nChandra T., Griesemer R., and Redstone J. Paxos Made Live: An Engineering Perspec-\ntive. In 26th Symposium on Principles of Distributed Computing, pages 398–407, New\nYork, NY, Aug. 2007. ACM, ACM Press. →484.\nChaudhari S. S. and Biradar R. C. Survey of Bandwidth Estimation Techniques in\nCommunication Networks. Wireless Personal Communications, 83(2):1425–1476, 2015.\n→454.\nCheriton D. and Mann T. Decentralizing a Global Naming Service for Improved\nPerformance and Fault Tolerance. ACM Transactions on Computer Systems, 7(2):\n147–183, May 1989. →352.\nCheriton D. and Skeen D. Understanding the Limitations of Causally and Totally\nOrdered Communication. In 14th Symposium on Operating System Principles, pages\n44–57. ACM, Dec. 1993. →271.\nCheswick W. and Bellovin S. Firewalls and Internet Security. Addison-Wesley, Reading,\nMA., 2nd edition, 2000. →609.\nChisnall D. The Definitive Guide to the Xen Hypervisor. Prentice Hall, Englewood Cliffs,\nN.J., 2007. →133.\nChondros N., Kokordelis K., and Roussopoulos M. On the Practicality of Practical\nByzantine Fault Tolerance. In Middleware 2012, volume 7662 of Lecture Notes in\nComputer Science, pages 436–455, Berlin, 2012. ACM/IFIP/USENIX, Springer-Verlag.\n→501.\nChou T. and Orlandi C. The Simplest Protocol for Oblivious Transfer. In International\nConference Cryptology and Information Security in Latin America, volume 9230 of Lecture\nNotes in Computer Science, pages 40–58, 2015. →566.\nChow R. and Johnson T. Distributed Operating Systems and Algorithms. Addison-Wesley,\nReading, MA., 1997. →538.\nChu Y., Rao S. G., Seshan S., and Zhang H. A Case for End System Multicast. IEEE\nJournal on Selected Areas in Communication, 20(8):1456–1471, Oct. 2002. →234.\nClark C., Fraser K., Hand S., Hansen J. G., Jul E., Limpach C., Pratt I., and Warfield A.\nLive Migration of Virtual Machines. In 2nd Symposium on Networked Systems Design\nand Implementation, Berkeley, CA, May 2005. USENIX, USENIX. →175, 176.\nClark D. The Design Philosophy of the DARPA Internet Protocols. In SIGCOMM,\npages 106–114, New York, NY, Sept. 1989. ACM, ACM Press. →152.\nClement A., Li H., Napper J., Martin J.-P., Alvisi L., and Dahlin M. BAR primer. In\n \nDS 4.01\n",
      "content_length": 2924,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 654,
      "content": "638\nBIBLIOGRAPHY\nInternational Conference on Dependable Systems and Networks, pages 287–296, 2008.\n→505.\nCohen B. Incentives Build Robustness in Bittorrent. In 1st Workshop on Economics of\nPeer-to-Peer Systems, June 2003. →96.\nCohen E. and Shenker S. Replication Strategies in Unstructured Peer-to-Peer Networks.\nIn SIGCOMM, pages 177–190, New York, NY, Aug. 2002. ACM, ACM Press. →94.\nComer D. Internetworking with TCP/IP, Volume I: Principles, Protocols, and Architecture.\nPrentice Hall, Upper Saddle River, N.J., 6th edition, 2013. →187.\nCommittee on National Security Systems . (CNSS) Glossary. Technical Report 4009,\nApr. 2015. →552.\nContavalli C., van der Gaast W., Lawrence D., and Kumari W. Client Subnet in DNS\nQueries. RFC 7871, May 2016. →364.\nConti M., Gregori E., and Lapenna W. Content Delivery Policies in ReplicatedWeb\nServices: Client-Side vs. Server-Side. Cluster Computing, 8:47–60, Jan. 2005. →456.\nCorbett J. C., Dean J., Epstein M., Fikes A., Frost C., Furman J. J., Ghemawat S., Gubarev\nA., Heiser C., Hochschild P., Hsieh W., Kanthak S., Kogan E., Li H., Lloyd A., Melnik\nS., Mwaura D., Nagle D., Quinlan S., Rao R., Rolig L., Saito Y., Szymaniak M., Taylor\nC., Wang R., and Woodford D. Spanner: Google’s Globally Distributed Database.\nACM Transactions on Computer Systems, 31(3):8:1–8:22, Aug. 2013. →259.\nCordero C. G., Vasilomanolakis E., Mühlhäuser M., and Fischer M. Community-based\nCollaborative Intrusion Detection. In International Conference on Security and Privacy\nin Communication Systems, pages 665–681. Springer, 2015. →612, 613.\nCristian F. Probabilistic Clock Synchronization. Distributed Computing, 3:146–158, 1989.\n→255.\nCristian F. Understanding Fault-Tolerant Distributed Systems. Communications of the\nACM, 34(2):56–78, Feb. 1991. →466.\nCui S., Belguith S., De Alwis P., Asghar M. R., and Russello G. Collusion Defender:\nPreserving Subscribers’ Privacy in Publish and Subscribe Systems. IEEE Transactions\non Dependable and Secure Computing, 18(3):1051–1064, 2021. →314, 315.\nCulkin J. and Zazon M. AWS Cookbook, Recipes for Success on AWS. O’Reilly & Associates,\nSebastopol, CA., 2022. →66, 99.\nDabek F., Cox R., Kaashoek F., and Morris R. Vivaldi: A Decentralized Network\nCoordinate System. In SIGCOMM, New York, NY, Aug. 2004a. ACM, ACM Press.\n→321.\nDabek F., Li J., Sit E., Robertson J., Kaashoek M. F., and Morris R. Designing a dht for\nlow latency and high throughput. In 1st Symposium on Networked Systems Design and\nImplementation, pages 85–98, Berkeley, CA, Mar. 2004b. USENIX, USENIX. →338.\nDamas J., Graff M., and Vixie P. Extension Mechanisms for DNS (EDNS(0)). RFC 6891,\nApr. 2013. →366.\nDannewitz C., Golic J., Ohlman B., and Ahlgren B. Secure Naming for a Network of\nInformation. In 29th INFOCOM Conference Workshops, pages 1–6, Los Alamitos, CA.,\n2010. IEEE Computer Society Press. →344.\nDay J. and Zimmerman H. The OSI Reference Model. Proceedings of the IEEE, 71(12):\nDS 4.01\n \n",
      "content_length": 2939,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 655,
      "content": "BIBLIOGRAPHY\n639\n1334–1340, Dec. 1983. →183.\nDeering S. and Cheriton D. Multicast Routing in Datagram Internetworks and Extended\nLANs. ACM Transactions on Computer Systems, 8(2):85–110, May 1990. →330.\nDeering S., Estrin D., Farinacci D., Jacobson V., Liu C.-G., and Wei L.\nThe PIM\nArchitecture for Wide-Area Multicast Routing. IEEE/ACM Transactions on Networking,\n4(2):153–162, Apr. 1996. →330.\nDeJonghe D. NGINX Cookbook. O’Reilly & Associates, Sebastopol, CA., 2nd edition,\n2022. →163.\nDemers A., Greene D., Hauser C., Irish W., Larson J., Shenker S., Sturgis H., Swinehart\nD., and Terry D. Epidemic Algorithms for Replicated Database Maintenance. In\n6th Symposium on Principles of Distributed Computing, pages 1–12. ACM, Aug. 1987.\n→240, 243, 245.\nDemirbas M. and Kulkarni S. Beyond TrueTime: Using Augmented Time for Improving\nGoogle Spanner. In 7th International Workshop on Large Scale Distributed Systems and\nMiddleware, New York, NY, 2013. ACM Press. →260.\nDey A. Context-Aware Computing. In Krumm J., editor, Ubiquitous Computing Funda-\nmentals, pages 321–352. CRC Press, Boca Raton, FL, 2010. →46.\nDey A. and Abowd G. Towards a Better Understanding of Context and Contex-\nAwareness. In Workshop on the What, Who, Where, When, Why and How of Context-\nAwareness, New York, NY, Apr. 2000. ACM, ACM Press. →45.\nDiffie W. and Hellman M. New Directions in Cryptography. IEEE Transactions on\nInformation Theory, IT-22(6):644–654, Nov. 1976. →565.\nDilley J., Maggs B., Parikh J., Prokop H., Sitaraman R., and Weihl B. Globally Dis-\ntributed Content Delivery. IEEE Internet Computing, 6(5):50–58, Sept. 2002. →165.\nDimou A., Iliopoulos C., Polytidou E., Dhurandher S. K., Papadimitriou G., and\nNicopolitidis P. A Comprehensive Review on Edge Computing: Focusing on Mobile\nUsers. In Nicopolitidis P., Misra S., Yang L. T., Zeigler B., and Ning Z., editors,\nAdvances in Computing, Informatics, Networking and Cybersecurity, number 289 in\nLecture Notes in Networks and Systems, pages 121–152. Springer-Verlag, Berlin,\n2022. →48.\nDiot C., Levine B., Lyles B., Kassem H., and Balensiefen D. Deployment Issues for the\nIP Multicast Service and Architecture. IEEE Network, 14(1):78–88, Jan. 2000. →232.\nDonnet B., Gueye B., and Kaafar M. A Survey on Network Coordinates Systems,\nDesign, and Security. IEEE Communications Surveys & Tutorials, 12(4), Dec. 2010.\n→318.\nDonovan A. A. and Kernighan B. W. The Go Programming Language. Addison-Wesley,\nReading, MA., 2015. →122.\nDoorn J. H. and Rivero L. C., editors. Database Integrity: Challenges and Solutions. Idea\nGroup, Hershey, PA, 2002. →594.\nDouceur J. R. The Sybil Attack. In 1st International Workshop on Peer-to-Peer Systems,\nvolume 2429 of Lecture Notes in Computer Science, pages 251–260, Berlin, Mar. 2002.\nSpringer-Verlag. → 586, 588.\nDroms R. Dynamic Host Configuration Protocol. RFC 2161, Apr. 1997. → 46.\n \nDS 4.01\n",
      "content_length": 2870,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 656,
      "content": "640\nBIBLIOGRAPHY\nDubois M., Scheurich C., and Briggs F.\nSynchronization, Coherence, and Event\nOrdering in Multiprocessors. Computer, 21(2):9–21, Feb. 1988. →398.\nDunagan J., Harvey N. J. A., Jones M. B., Kostic D., Theimer M., and Wolman A.\nFUSE: Lightweight Guaranteed Distributed Failure Notification. In 6th Symposium\non Operating System Design and Implementation, Berkeley, CA, Dec. 2004. USENIX,\nUSENIX. →508.\nDuvvuri V., Shenoy P., and Tewari R. Adaptive Leases: A Strong Consistency Mecha-\nnism for the World Wide Web. IEEE Transactions on Knowledge and Data Engineering,\n15(5):1266–1276, Sept. 2003. →433.\nEastlake D. and Hansen T. Us Secure Hash Algorithms (SHA and SHA-based HMAC\nand HKDF), May 2011. →585.\nEl-Sayed A., Roca V., and Mathy L. A Survey of Proposals for an Alternative Group\nCommunication Service. IEEE Network, 17(1):46–51, Jan. 2003. →233.\nElnozahy E., Alvisi L., Wang Y.-M., and Johnson D. A Survey of Rollback-Recovery\nProtocols in Message-Passing Systems. ACM Computing Surveys, 34(3):375–408, Sept.\n2002. →538, 543.\nElnozahy E. N. and Plank J. S. Checkpointing for Peta-Scale Systems: A Look into the\nFuture of Practical Rollback-Recovery. IEEE Transactions on Dependable and Secure\nComputing, 1(2):97–108, Apr. 2004. →540.\nElson J., Girod L., and Estrin D. Fine-Grained Network Time Synchronization using Ref-\nerence Broadcasts. In 5th Symposium on Operating System Design and Implementation,\npages 147–163, Berkeley, CA, Dec. 2002. USENIX, USENIX. →257, 258.\nErdös P. and Rényi A. On Random Graphs. Publicationes Mathematicae, 6:290–297, 1959.\n→237.\nEscriva R., Wong B., and Sirer E. G. HyperDex: A Distributed, Searchable Key-value\nStore. In SIGCOMM, pages 25–36, New York, NY, 2012. ACM Press. →384.\nEsposito C., Cotroneo D., and Russo S. On Reliability in Publish/Subscribe Services.\nComputer Networks, X(0):xxx, 2013. →517.\nEugster P., Guerraoui R., Kermarrec A.-M., and Massoulié L. Epidemic Information\nDissemination in Distributed Systems. Computer, 37(5):60–67, May 2004. →240.\nEvans D., Kolesnikov V., and Rosulek M. A Pragmatic Introduction to Secure Multi-Party\nComputation. NOW Publishers, Boston, MA; Delft, NL, 2018. →566.\nFeng B., Zhang H., Zhou H., and Yu S.\nLocator/Identifier Split Networking: A\nPromising Future Internet Architecture. IEEE Communications Surveys & Tutorials, 19\n(4):2927–2948, 2017. →329.\nFerguson N. and Schneier B. Practical Cryptography. John Wiley, New York, 2003.\n→290.\nFerguson N., Schneier B., and Kohno T. Cryptography Engineering: Design Principles and\nPractical Applications. John Wiley, New York, 2010. →557, 575.\nFerraiolo D., Kuhn D. R., and Chandramouli R. Role-based Access Control. Artech house,\n2nd edition, 2007. →596.\nFerraiolo D., Atluri V., and Gavrila S. The Policy Machine: A Novel Architecture\nand Framework for Access Control Policy Specification and Enforcement. Journal of\nDS 4.01\n \n",
      "content_length": 2878,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 657,
      "content": "BIBLIOGRAPHY\n641\nSystems Architecture, 57(4):412–424, 2011. →598, 600.\nFerraiolo D., Gavrila S., and Jansen W. Policy Machine: Features, Architecture, and\nSpecification.\nTechnical Report NISTIR 7987, Revision 1, National Institute of\nStandards and Technology (NIST), Oct. 2015. →598.\nFerrer A. J., Marquès J. M., and Jorba J. Towards the Decentralised Cloud: Survey\non Approaches and Challenges for Mobile, Ad hoc, and Edge Computing. ACM\nComputing Surveys, 51(6):1–36, 2019. →47.\nFiebig T., Lichtblau F., Streibelt F., Krüger T., Lexis P., Bush R., and Feldmann A.\nLearning from the Past: Designing Secure Network Protocols. In Cybersecurity Best\nPractices, pages 585–613. Springer-Verlag, Berlin, 2018. →576.\nFielding R. Architectural Styles and the Design of Network-based Software Architectures.\nPh.d., University of California, Irvine, 2000. →66.\nFielding R. and Reschke J. Hypertext Transfer Protocol (HTTP/1.1): Message Syntax\nand Routing. RFC 7230, June 2014. →188.\nFischer M., Lynch N., and Patterson M. Impossibility of Distributed Consensus with\none Faulty Processor. Journal of the ACM, 32(2):374–382, Apr. 1985. →503, 504.\nFloyd S., Jacobson V., McCanne S., Liu C.-G., and Zhang L. A Reliable Multicast\nFramework for Light-weight Sessions and Application Level Framing. IEEE/ACM\nTransactions on Networking, 5(6):784–803, Dec. 1997. →519, 520.\nFokkink W. Distributed Algorithms: An Intuitive Approach. MIT Press, Cambridge, MA.,\n2nd edition, 2018. →248.\nFoster I., Kesselman C., and Tuecke S. The Anatomy of the Grid, Enabling Scalable\nVirtual Organizations. Journal of Supercomputer Applications, 15(3):200–222, Fall 2001.\n→36, 37.\nFoster I. and others . The Open Grid Services Architecture, Version 1.5. GGF Informa-\ntional Document GFD-I.080, June 2006. →37.\nFowler R. Decentralized Object Finding Using Forwarding Addresses. Ph.D., University of\nWashington, Seattle, 1985. →331.\nFox A. and Brewer E. Harvest, Yield, and Scalable Tolerant Systems. In 7th Worksop-\nWorkshop on Hot Topics in Operating Systems (HotOS), pages 174–178, Los Alamitos,\nCA., Mar. 1999. IEEE, IEEE Computer Society Press. →506.\nFrancis L. P. Privacy and Confidentiality: The Importance of Context. The Monist, 91\n(1):52–67, 2008. →553.\nFranklin M. J., Carey M. J., and Livny M. Transactional Client-Server Cache Consistency:\nAlternatives and Performance. ACM Transactions on Database Systems, 22(3):315–363,\nSept. 1997. →443.\nFuggetta A., Picco G. P., and Vigna G. Understanding Code Mobility. IEEE Transactions\non Software Engineering, 24(5):342–361, May 1998. →171, 172.\nGamma E., Helm R., Johnson R., and Vlissides J. Design Patterns, Elements of Reusable\nObject-Oriented Software. Addison-Wesley, Reading, MA., 1994. →75.\nGarbacki P., Epema D., and van Steen M.\nThe Design and Evaluation of a Self-\nOrganizing Super-Peer Network. IEEE Transactions on Computers, 59(3):317–331, Mar.\n2010. →96.\n \nDS 4.01\n",
      "content_length": 2897,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 658,
      "content": "642\nBIBLIOGRAPHY\nGarcia-Molina H. Elections in a Distributed Computing System. IEEE Transactions on\nComputers, 31(1):48–59, Jan. 1982. →283.\nGarfinkel S. PGP: Pretty Good Privacy. O’Reilly & Associates, Sebastopol, CA., 1995.\n→570.\nGarman J. Kerberos: The Definitive Guide. O’Reilly & Associates, Sebastopol, CA., 2003.\n→581.\nGazis A. and Katsiri E. Middleware 101: What to Know Now and for the Future. ACM\nQueue, 20(1):10–23, feb 2022. →11.\nGelernter D. and Carriero N. Coordination Languages and their Significance. Commu-\nnications of the ACM, 35(2):96–107, Feb. 1992. →68.\nGentz R., Wu S. X., Wai H.-T., Scaglione A., and Leshem A. Data Injection Attacks in\nRandomized Gossiping. IEEE Transactions on Signal and Information Processing over\nNetworks, 2(4):523–538, 2016. →306.\nGerofi B., Ishikawa Y., Riesen R., and Wisniewski R. W., editors. Operating Systems\nfor Supercomputers and High Performance Computing. Springer-Verlag, Berlin, 2019.\n→34, 35.\nGhodsi A. Multicast and Bulk Lookup in Structured Overlay Networks. In Shen et al.\n[2010], pages 933–958. →239.\nGifford D. Weighted Voting for Replicated Data. In 7th Symposium on Operating System\nPrinciples, pages 150–162. ACM, Dec. 1979. →441.\nGilbert S. and Lynch N. Brewer’s Conjecture and the Feasibility of Consistent, Available,\nPartition-tolerant Web Services. ACM SIGACT News, 33(2):51–59, June 2002. →505.\nGilbert S. and Lynch N. Perspectives on the CAP Theorem. Computer, 45(2):30–35, Feb.\n2012. →505.\nGkantsidis C., Mihail M., and Saberi A. Random Walks in Peer-to-Peer Networks:\nAlgorithms and Evaluation. Performance Evaluation, 63:241–263, Mar. 2006. →93.\nGoel U., Wittie M. P., and Steiner M. Faster Web through Client-Assisted CDN Server\nSelection. In 14th International Conference on Computer Communications and Networks,\npages 1–10, 2015. →166.\nGoldreich O. Foundations of Cryptography: Volume 2, Basic Applications. Cambridge\nUniversity Press, Cambridge, UK, 2009. →553.\nGonzalez-Manzano L., Fuentes J. M. D., and Ribagorda A. Leveraging User-related\nInternet of Things for Continuous Authentication: A Survey. ACM Computing\nSurveys, 52(3):1–38, 2019. →572.\nGray C. and Cheriton D. Leases: An Efficient Fault-Tolerant Mechanism for Distributed\nFile Cache Consistency. In 12th Symposium on Operating System Principles, pages\n202–210, New York, NY, Dec. 1989. ACM, ACM Press. →433.\nGray J. Notes on Database Operating Systems. In Bayer R., Graham R., and Seegmuller\nG., editors, Operating Systems: An Advanced Course, volume 60 of Lecture Notes in\nComputer Science, pages 393–481. Springer-Verlag, Berlin, 1978. →529.\nGray J. and Reuter A. Transaction Processing: Concepts and Techniques. Morgan Kaufman,\nSan Mateo, CA., 1993. →38.\nGray J., Helland P., O’Neil P., and Sashna D. The Dangers of Replication and a Solution.\nDS 4.01\n \n",
      "content_length": 2804,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 659,
      "content": "BIBLIOGRAPHY\n643\nIn SIGMOD International Conference on Management Of Data, pages 173–182, Montreal,\nJune 1996. ACM. →395.\nGropp W., Lusk E., and Skjellum A. Using MPI-2, Portable Parallel Programming with the\nMessage-Passing Interface. MIT Press, Cambridge, MA., 3rd edition, 2016. →220.\nGuerraoui R. and Schiper A. Software-Based Replication for Fault Tolerance. Computer,\n30(4):68–74, Apr. 1997. →472.\nGuerraoui R., Kneževi´c N., Quéma V., and Vukoli´c M. The next 700 bft protocols. In\n5th EuroSys (European Conference on Computer Systems), pages 363–376, New York,\nNY, 2010. ACM Press. →501.\nGuichard J., Faucheur F. L., and Vasseur J.-P. Definitive MPLS Network Designs. Cisco\nPress, Indianapolis, IN, 2005. →455.\nGuttman E. Autoconfiguration for IP Networking: Enabling Local Communication.\nIEEE Internet Computing, 5:81–86, 2001. →46.\nHadzilacos V. and Toueg S. Fault-Tolerant Broadcasts and Related Problems. In\nMullender S., editor, Distributed Systems, pages 97–145. Addison-Wesley, Wokingham,\n2nd edition, 1993. →466, 526.\nHahmy H. Concepts, Applications, Experimentation and Analysis of Wireless Sensor Networks.\nSpringer-Verlag, Berlin, 2nd edition, 2021. →49.\nHardt D. and others . The OAuth 2.0 Authorization Framework. RFC 6746, Oct. 2012.\n→605.\nHassan W. U., Guo S., Li D., Chen Z., Jee K., Li Z., and Bates A. Nodoze: Combatting\nThreat Alert Fatigue with Automated Provenance Triage. In Symposium on Network\nand Distributed System Security, 2019. →612.\nHaynes T. Network File System (NFS) Version 4 Protocol. RFC 7530, Mar. 2015.\n→83, 350.\nHelder D. A. and Jamin S. End-Host Multicast Communication Using Switch-Trees\nProtocols. In 2nd International Symposium on Cluster Computing and the Grid, pages 419–\n424, Los Alamitos, CA., May 2002. IEEE, IEEE Computer Society Press. →235, 236.\nHellerstein J. M. and Alvaro P. Keeping CALM: When Distributed Consistency is Easy.\nCommunications of the ACM, 63(9):72–81, Sept. 2020. →410.\nHenning M. A New Approach to Object-Oriented Middleware. IEEE Internet Computing,\n8(1):66–75, Jan. 2004. →156.\nHerlihy M. and Shavit N. The Art of Multiprocessor Programming. Morgan Kaufman,\nSan Mateo, CA., 2008. →113.\nHerlihy M. and Wing J. Linearizability: A Correctness Condition for Concurrent\nObjects. ACM Transactions on Programming Languages and Systems, 12(3):463–492, July\n1991. →400.\nHerlihy M., Shavit N., Luchangco V., and Spear M. The Art of Multiprocessor Program-\nming. Morgan Kaufman, San Mateo, CA., 2nd edition, 2021. →33, 400.\nHintjens P. ZeroMQ. O’Reilly & Associates, Sebastopol, CA., 2013. →213.\nHohpe G. and Woolf B. Enterprise Integration Patterns: Designing, Building, and Deploying\nMessaging Solutions. Addison-Wesley, Reading, MA., 2004. →37, 41, 227.\n \nDS 4.01\n",
      "content_length": 2735,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 660,
      "content": "644\nBIBLIOGRAPHY\nHong C.-H. and Varghese B. Resource Management in Fog/Edge Computing: A\nSurvey on Architectures, Infrastructure, and Algorithms. ACM Computing Surveys,\n52(5), 2019. →103.\nHong J. The Privacy Landscape of Pervasive Computing. IEEE Pervasive Computing, 16\n(3):40–48, 2017. →103.\nHorauer M. Clock Synchronization in Distributed Systems. Ph.D., University of Vienna,\nDepartment of Computer Science, Feb. 2004. →253.\nHorner L. J. Edge Strategies in Industry: Overview and Challenges. IEEE Transactions\non Network and Service Management, 18(3):2825–2831, 2021. →100.\nHorowitz M. and Lunt S. FTP Security Extensions. RFC 2228, Oct. 1997. →188.\nHosseini M., Ahmed D., Shirmohammadi S., and Georganas N.\nA Survey of\nApplication-Layer Multicast Protocols. IEEE Communications Surveys & Tutorials, 9\n(3):58–74, 2007. →233.\nHoward H., Schwarzkopf M., Madhavapeddy A., and Crowcroft J. Raft Refloated: Do\nWe Have Consensus? Operating Systems Review, 49(1):12–21, jan 2015. →289.\nHu V. C., Ferraiolo D., Kuhn R., Schnitzer A., Sandlin K., Miller R., and Scarfone K.\nGuide to Attribute Based Access Control (ABAC) Definition and Considerations.\nTechnical Report NIST 800-162, National Institute of Standards and Technology, Jan.\n2014. →596.\nHu V. C., Kuhn D. R., Ferraiolo D. F., and Voas J. Attribute-Based Access Control.\nComputer, 48(2):85–88, 2015. →596.\nHuffaker B., Fomenkov M., Plummer D. J., Moore D., and Claffy K. Distance Metrics\nin the Internet. In International Telecommunications Symposium, Los Alamitos, CA.,\nSept. 2002. IEEE, IEEE Computer Society Press. →454.\nHunt G., Nahum E., and Tracey J. Enabling Content-Based Load Distribution for\nScalable Services. Technical report, IBM T.J. Watson Research Center, May 1997.\n→163.\nHunt P., Konar M., Junqueira F. P., and Reed B. ZooKeeper: Wait-free Coordination for\nInternet-scale Systems. In USENIX Annual Technical Conference, 2010. →280, 422.\nHutto P. and Ahamad M. Slow Memory: Weakening Consistency to Enhance Concur-\nrency in Distributed Shared Memories. In 10th International Conference on Distributed\nComputing Systems, pages 302–311, Paris, France, May 1990. IEEE. →401.\nIqbal M. and Matuleviˇcius R. Exploring Sybil and Double-Spending Risks in Blockchain\nSystems. IEEE Access, 9:76153–76177, 2021. →587.\nISO . Open Distributed Processing Reference Model - Part 2: Foundations. International\nStandard ISO/IEC IS 10746-2, 1995. →12.\nJakubeit P., Peter A., and van Steen M. The Measurable Environment as Nonintrusive\nAuthentication Factor on the Example of WiFi Beacon Frames. In 5th International\nWorkshop on Emerging Technologies for Authorization and Authentication, Sept. 2022.\n→572.\nJalote P. Fault Tolerance in Distributed Systems. Prentice Hall, Englewood Cliffs, N.J.,\n1994. →443, 463.\nJanic M. Multicast in Network and Application Layer. Ph.d., Delft University of Technology,\nDS 4.01\n \n",
      "content_length": 2867,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 661,
      "content": "BIBLIOGRAPHY\n645\nThe Netherlands, Oct. 2005. →232.\nJaniga M. J., Dibner G., and Governali F. J. Internet Infrastructure: Content Delivery.\nGoldman Sachs Global Equity Research, Apr. 2001. →455.\nJelasity M. and Kermarrec A.-M. Ordered Slicing of Very Large-Scale Overlay Networks.\nIn 6th International Conference on Peer-to-Peer Computing, pages 117–124, Los Alamitos,\nCA., Sept. 2006. IEEE Computer Society Press. →300.\nJelasity M., Montresor A., and Babaoglu O.\nGossip-based Aggregation in Large\nDynamic Networks. ACM Transactions on Computer Systems, 23(3):219–252, Aug. 2005.\n→297.\nJelasity M., Voulgaris S., Guerraoui R., Kermarrec A.-M., and van Steen M. Gossip-\nbased Peer Sampling. ACM Transactions on Computer Systems, 25(3), Aug. 2007.\n→241, 298.\nJesi G., Montresor A., and van Steen M. Secure Peer Sampling. Computer Networks, 54\n(12):2086–2098, Aug. 2010. →304, 306.\nJesi G.-P., Hales D., and van Steen M. Identifying Malicious Peers Before It’s Too Late:\nA Decentralized Secure Peer Sampling Service. In 1st International Conference on\nSelf-Adaptive and Self-Organizing Systems, Los Alamitos, CA., June 2007. IEEE, IEEE\nComputer Society Press. →588.\nJohnson B. An Introduction to the Design and Analysis of Fault-Tolerant Systems. In\nPradhan D., editor, Fault-Tolerant Computer System Design, pages 1–87. Prentice Hall,\nUpper Saddle River, N.J., 1995. →470.\nJosefsson S. Shishi – Kerberos 5 Implementation. Samurai Media Limited, Wickford, UK,\n2015. →581.\nJoseph J., Ernest M., and Fellenstein C. Evolution of grid computing architecture and\ngrid adoption models. IBM Systems Journal, 43(4):624–645, Apr. 2004. →37.\nJunqueira F. and Reed B. ZooKeeper. O’Reilly & Associates, Sebastopol, CA., 2014.\n→280, 281, 287.\nKahn D. The Codebreakers. Macmillan, New York, 1967. →556.\nKarsten M. and Barghi S. User-level Threading: Have Your Cake and Eat It Too. In\nInternational Conference on Measurements and Modeling of Computer Systems, volume 4.\nACM, Mar. 2020. →122.\nKasera S., Kurose J., and Towsley D. Scalable Reliable Multicast Using Multiple Multi-\ncast Groups. In International Conference on Measurements and Modeling of Computer\nSystems, pages 64–74, Seattle, WA, June 1997. ACM. →520.\nKaufman C., Perlman R., and Speciner M. Network Security: Private Communication in a\nPublic World. Prentice Hall, Englewood Cliffs, N.J., 2nd edition, 2003. →575, 580.\nKemme B., Jimenez Peris R., and Patino-Martinez M. Replicated Databases. Synthesis\nLectures on Computer Architectures. Morgan and Claypool, San Rafael, CA, 2010.\n→426.\nKermarrec A.-M. and Triantafillou P. XL Peer-to-peer Pub/Sub Systems. ACM Comput-\ning Surveys, 46(2):16:1–16:45, Nov. 2013. →309.\nKhormali A., Park J., Alasmary H., Anwar A., Saad M., and Mohaisen D. Domain\nName System Security and Privacy: A Contemporary Survey. Computer Networks,\n \nDS 4.01\n",
      "content_length": 2828,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 662,
      "content": "646\nBIBLIOGRAPHY\n185, 2021. →365.\nKhoshafian S. and Buckiewicz M. Introduction to Groupware, Workflow, and Workgroup\nComputing. John Wiley, New York, 1995. →226.\nKhraisat A., Gondal I., Vamplew P., and Kamruzzaman J. Survey of Intrusion Detection\nSystems: Techniques, Datasets and Challenges. Cybersecurity, 2(1):1–22, 2019. →612.\nKim M., Fielding J. J., and Kotz D. Risks of Using AP Locations Discovered Through\nWar Driving. In 4th International Conference Pervasive Computing, volume 3968 of\nLecture Notes in Computer Science, pages 67–82, Berlin, May 2006. Springer-Verlag.\n→318.\nKirsch J. and Amir Y. Paxos for System Builders. Technical Report CNDS-2008-2, John\nHopkins University, Mar. 2008. →480, 484.\nKleiman S. Vnodes: an Architecture for Multiple File System Types in UNIX. In\nSummer Technical Conference, pages 238–247, Atlanta, GA, June 1986. USENIX. →84.\nKleppmann M. and Beresford A. R. A Conflict-Free Replicated JSON Datatype. IEEE\nTransactions on Parallel and Distributed Systems, 28(10):2733–2745, Oct. 2017. →410.\nKohl J., Neuman B., and T’so T. The Evolution of the Kerberos Authentication System.\nIn Brazier F. and Johansen D., editors, Distributed Open Systems, pages 78–94. IEEE\nComputer Society Press, Los Alamitos, CA., 1994. →581.\nKopetz H. and Verissimo P. Real Time and Dependability Concepts. In Mullender\nS., editor, Distributed Systems, pages 411–446. Addison-Wesley, Wokingham, 2nd\nedition, 1993. →18, 463.\nKoren I. and Krishna C. M. Fault-Tolerant Systems. Morgan Kaufman, San Mateo, CA.,\n2007. →463, 497.\nKotla R., Alvisi L., Dahlin M., Clement A., and Wong E.\nZyzzyva: Speculative\nByzantine Fault Tolerance. ACM Transactions on Computer Systems, 27(4), Dec. 2009.\n→501.\nKrakowiak S. Middleware Architecture with Patterns and Frameworks. Creative Commons,\n2009. →58.\nKreitz G. and Niemelä F. Spotify – Large Scale, Low Latency, P2P Music-on-Demand\nStreaming. In 10th International Conference on Peer-to-Peer Computing, pages 266–275,\nLos Alamitos, CA., Aug. 2010. IEEE, IEEE Computer Society Press. →28.\nKshemkalyani A. and Singhal M. Distributed Computing, Principles, Algorithms, and\nSystems. Cambridge University Press, Cambridge, UK, 2008. →272, 493, 495.\nKucharski A. The Rules of Contagion, Why Things Spread – And Why They Stop. Profile\nBooks, 2020. →62.\nKumar K., Liu J., Lu Y.-H., and Bhargava B. A Survey of Computation Offloading for\nMobile Systems. Mobile Networks and Applications, 18(1):129–140, 2013. →168.\nLagar-Cavilla H. A., Whitney J. A., Scannell A. M., Patchin P., Rumble S. M., Lara E.de ,\nBrudno M., and Satyanarayanan M. SnowFlock: Rapid Virtual Machine Cloning for\nCloud Computing. In 4th EuroSys (European Conference on Computer Systems), pages\n1–12, New York, NY, 2009. ACM Press. →177.\nLai A. and Nieh J. Limits of Wide-Area Thin-Client Computing. In International\nConference on Measurements and Modeling of Computer Systems, pages 228–239, New\nDS 4.01\n \n",
      "content_length": 2918,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 663,
      "content": "BIBLIOGRAPHY\n647\nYork, NY, June 2002. ACM, ACM Press. →144.\nLaMarca A. and Lara E.de . Location Systems: An Introduction to the Technology Behind\nLocation Awareness. Morgan & Claypool, San Rafael, CA, 2008. →317.\nLamport L. The Part-Time Parliament. ACM Transactions on Computer Systems, 16(2):\n133–169, May 1998. →479.\nLamport L. Paxos Made Simple. ACM SIGACT News, 32(4):51–58, Dec. 2001. →479, 480.\nLamport L. Time, Clocks, and the Ordering of Events in a Distributed System. Commu-\nnications of the ACM, 21(7):558–565, July 1978. →260, 441.\nLamport L. How to Make a Multiprocessor Computer that Correctly Executes Mul-\ntiprocessor Programs. IEEE Transactions on Computers, C-29(9):690–691, Sept. 1979.\n→397.\nLamport L., Shostak R., and Paese M.\nThe Byzantine Generals Problem.\nACM\nTransactions on Programming Languages and Systems, 4(3):382–401, July 1982. →468.\nLampson B. How to Build a Highly Available System using Consensus. In Babaoglu\nO. and Marzullo K., editors, 12th International Workshop on Distributed Algorithms,\nvolume 1151 of Lecture Notes in Computer Science, pages 1–17, Berlin, Oct. 1996.\nSpringer-Verlag. →479.\nLaprie J.-C. Dependability – Its Attributes, Impairments and Means. In Randell B.,\nLaprie J.-C., Kopetz H., and Littlewood B., editors, Predictably Dependable Computing\nSystems, pages 3–24. Springer-Verlag, Berlin, 1995. →547.\nLaurie B. and Laurie P. Apache: The Definitive Guide. O’Reilly & Associates, Sebastopol,\nCA., 3rd edition, 2002. →161.\nLawder J. and King P. Querying Multi-dimensional Data Indexed Using Hilbert\nSpace-Filling Curve. ACM Sigmod Record, 30(1):19–24, Mar. 2000. →381.\nLevesque M. and Tipper D.\nA Survey of Clock Synchronization Over Packet-\nSwitched Networks.\nIEEE Communications Surveys & Tutorials, 18(4):2926–2947,\n2016. →253, 257.\nLevine B. and Garcia-Luna-Aceves J. A Comparison of Reliable Multicast Protocols.\nACM Multimedia Systems Journal, 6(5):334–348, 1998. →519.\nLevine B. N., Shields C., and Margolin N. B. A Survey of Solutions to the Sybil Attack.\nTechnical report, University of Massachusetts Amherst, Amherst, MA, 2006. →588.\nLewis B. and Berg D. J.\nMultithreaded Programming with Pthreads.\nPrentice Hall,\nEnglewood Cliffs, N.J., 2nd edition, 1998. →113.\nLi X., Jiang P., Chen T., Luo X., and Wen Q. A Survey on the Security of Blockchain\nSystems. Future Generation Computer Systems, 107:841–853, 2020. →589.\nLilja D. Cache Coherence in Large-Scale Shared-Memory Multiprocessors: Issues and\nComparisons. ACM Computing Surveys, 25(3):303–338, Sept. 1993. →443.\nLin M.-J. and Marzullo K. Directional Gossip: Gossip in a Wide-Area Network. In\nProceedings 3rd European Dependable Computing Conf., volume 1667 of Lecture Notes in\nComputer Science, pages 364–379. Springer-Verlag, Berlin, Sept. 1999. →244.\nLin S.-D., Lian Q., Chen M., , and Zhang Z. A Practical Distributed Mutual Exclusion\nProtocol in Dynamic Peer-to-Peer Systems. In 3rd International Workshop on Peer-to-\nPeer Systems, volume 3279 of Lecture Notes in Computer Science, pages 11–21, Berlin,\n \nDS 4.01\n",
      "content_length": 3040,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 664,
      "content": "648\nBIBLIOGRAPHY\nFeb. 2004. Springer-Verlag. →277, 278.\nLing B. C., Kiciman E., and Fox A. Session State: Beyond Soft State. In 1st Symposium\non Networked Systems Design and Implementation, pages 295–308, Berkeley, CA, Mar.\n2004. USENIX, USENIX. →153.\nLiskov B. From viewstamped Replication to Byzantine Fault Tolerance. In Charron-\nBost B., Pedone F., and Schiper A., editors, Replication, Theory and Practice, volume\n5959 of Lecture Notes in Computer Science, chapter 5, pages 121–149. Springer-Verlag,\nBerlin, 2010. →498.\nLiu C. and Albitz P. DNS and BIND. O’Reilly & Associates, Sebastopol, CA., 5th\nedition, 2006. →189, 359.\nLiu C.-G., Estrin D., Shenker S., and Zhang L. Local Error Recovery in SRM: Compari-\nson of Two Approaches. IEEE/ACM Transactions on Networking, 6(6):686–699, Dec.\n1998. →520.\nLiu F. and Solihin Y. Understanding the Behavior and Implications of Context Switch\nMisses. ACM Transactions on Architecture and Code Optimization, 7(4):21:1–21:28, Dec.\n2010. →116.\nLo V., Zhou D., Liu Y., GauthierDickey C., and Li J. Scalable Supernode Selection in\nPeer-to-Peer Overlay Networks. In 2nd Workshop on Hot Topics in Peer-to-Peer Systems\n(HotP2P), pages 18–27, Los Alamitos, CA., July 2005. IEEE Computer Society Press.\n→293.\nLua E., Crowcroft J., Pias M., Sharma R., and Lim S. A Survey and Comparison of\nPeer-to-Peer Overlay Network Schemes. IEEE Communications Surveys & Tutorials, 7\n(2):22–73, Apr. 2005. →32, 89.\nLui J., Misra V., and Rubenstein D. On the Robustness of Soft State Protocols. In 12th\nInternational Conference on Network Protocols, pages 50–60, Los Alamitos, CA., Oct.\n2004. IEEE, IEEE Computer Society Press. →152.\nLv Q., Cao P., Cohen E., Li K., and Shenker S. Search and Replication in Unstructured\nPeer-to-Peer Networks. In 16th International Conference on Supercomputing, pages\n84–95, New York, NY, June 2002. ACM, ACM Press. →93, 94.\nLynch N. Distributed Algorithms. Morgan Kaufman, San Mateo, CA., 1996. →249, 283.\nLyu L., Yu H., Zhao J., and Yang Q. Threats to Federated Learning, volume 12500 of\nLecture Notes in Artificial Intelligence, pages 3–16. Springer Nature, Cham, 2020.\n→169.\nMaassen J., Kielmann T., and Bal H. E. Parallel Application Experience with Replicated\nMethod Invocation. Concurrency & Computation: Practice and Experience, 13(8-9):\n681–712, 2001. →436.\nMadden S. R., Franklin M. J., Hellerstein J. M., and Hong W. TinyDB: An Acquisitional\nQuery Processing System for Sensor Networks.\nACM Transactions on Database\nSystems, 30(1):122–173, 2005. →51.\nMahajan P., Alvisi L., and Dahlin M.\nConsistency, availability, and convergence.\nTechnical Report TR-11-22, University of Texas at Austin, May 2011. →408.\nMalhotra A., Cohen I. E., Brakke E., and Goldberg S. Attacking the Network Time\nProtocol. In Symposium on Network and Distributed System Security, Feb. 2016. →257.\nDS 4.01\n \n",
      "content_length": 2846,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 665,
      "content": "BIBLIOGRAPHY\n649\nMalone T. and Crowston K. The Interdisciplinary Study of Coordination. ACM\nComputing Surveys, 26(1):87–119, Mar. 1994. →248.\nMao Z. M., Cranor C. D., Douglis F., Rabinovich M., Spatscheck O., and Wang J. A\nPrecise and Efficient Evaluation of the Proximity between Web Clients and their\nLocal DNS Servers. In USENIX Annual Technical Conference, pages 229–242, Berkeley,\nCA, June 2002. USENIX, USENIX. →166.\nMarzullo K. and Owicki S. Maintaining The Time in a Distributed System. In 2nd\nSymposium on Principles of Distributed Computing, pages 295–305, New York, NY, 1983.\nACM, ACM Press. →259.\nMattern F. and Floerkemeier C. From the Internet of Computers to the Internet of Things,\npages 242–259. Springer-Verlag, Berlin, 2010. →44.\nMazouni K., Garbinato B., and Guerraoui R. Building Reliable Client-Server Software\nUsing Actively Replicated Objects. In Graham I., Magnusson B., Meyer B., and\nNerson J.-M., editors, Technology of Object Oriented Languages and Systems, pages\n37–53. Prentice Hall, Englewood Cliffs, N.J., 1995. →436.\nMedina V. and Garcia J. A Survey of Migration Mechanisms of Virtual Machines. ACM\nComputing Surveys, 46(3):30, Jan. 2014. →175.\nMeling H. and Jehl L. Tutorial Summary: Paxos Explained from Scratch. In 17th\nInternational Conference on Principles of Distributed Systems, pages 1–10. Springer, 2013.\n→484.\nMenasce D. and Almeida V. Capacity Planning for Web Services. Prentice Hall, Englewood\nCliffs, N.J., 2002. →25.\nMenezes A. J., Oorschot P. C.van , and Vanstone S. A. Handbook of Applied Cryptography.\nCRC Press, Boca Raton, 3rd edition, 1996. →568.\nMerideth M. G. and Reiter M. K. Selected Results from the Latest Decade of Quorum\nSystems Research, pages 185–206. Springer-Verlag, Berlin, 2010. →443.\nMessage Passing Interface Forum . MPI: A Message-Passing Interface Standard, version\n4.0. Technical report, University of Tenness, Knoxville, June 2021. →220.\nMeyerovich L. A. and Bodik R. Fast and Parallel Webpage Layout. In 19th International\nWorld Wide Web Conference, pages 711–720, New York, NY, 2010. ACM Press. →124.\nMills D.\nNetwork Time Protocol (version 3): Specification, Implementation, and\nAnalysis. RFC 1305, July 1992. →257.\nMills D. L. Computer Network Time Synchronization: The Network Time Protocol on Earth\nand in Space. CRC Press, Boca Raton, FL, 2nd edition, 2011. →257.\nMilojicic D., Douglis F., Paindaveine Y., Wheeler R., and Zhou S. Process Migration.\nACM Computing Surveys, 32(3):241–299, Sept. 2000. →167.\nMin S. L. and Baer J.-L. Design and Analysis of a Scalable Cache Coherence Scheme\nBased on Clocks and Timestamps. IEEE Transactions on Parallel and Distributed\nSystems, 3(1):25–44, Jan. 1992. →443.\nMockapetris P. Domain Names - Concepts and Facilities. RFC 1034, Nov. 1987a.\n→354, 359.\nMockapetris P. Domain Names - Implementation and Specification. RFC 1035, Nov.\n1987b. →354, 359.\n \nDS 4.01\n",
      "content_length": 2879,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 666,
      "content": "650\nBIBLIOGRAPHY\nMohan C., Strong R., and Finkelstein S. Method for Distributed Transaction Commit\nand Recovery using Byzantine Agreement within Clusters of Processors. In 2nd\nSymposium on Principles of Distributed Computing, pages 89–103, New York, NY, 1983.\nACM Press. →468.\nMoll P., Shang W., Yu Y., Afanasyev A., and Zhang L. A Survey of Distributed Dataset\nSynchronization in Named Data Networking. Technical Report NDN-0053, UCLA,\nMay 2021. →386.\nMottola L. and Picco G. P. Programming Wireless Sensor Networks: Fundamental\nConcepts and State of the Art. ACM Computing Surveys, 43(3):19:1–19:51, Apr. 2011.\n→49.\nMoura G. C. M., Castro S., Hardaker W., Wullink M., and Hesselman C. Clouding up\nthe Internet: How Centralized is DNS Traffic Becoming? In Internet Measurement\nConference, page 42–49, 2020. →365.\nMousazadeh M. and Ladani B. T. Gossip-based Data Aggregation in Hostile Environ-\nments. Computer Communications, 62:1–12, 2015. →306.\nMühl G., Fiege L., and Pietzuch P. Distributed Event-Based Systems. Springer-Verlag,\nBerlin, 2006. →69.\nMuntz D. and Honeyman P. Multi-level Caching in Distributed File Systems. In Winter\nTechnical Conference, pages 305–313, San Francisco, CA, Jan. 1992. USENIX. →429.\nMurty J. Programming Amazon Web Services. O’Reilly & Associates, Sebastopol, CA.,\n2008. →66, 99.\nNajafi A., Tai A., and Wei M. Systems Research is Running out of Time. In Workshop\non Hot Topics in Operating Systems (HotOS), page 65–71, 2021. →249.\nNaur P. and Randell B. Report on the NATO Software Engineering Conference 1968.\nTechnical report, Scientific Affairs Division NATO, Brussels, Belgium, Oct. 1968.\n→74.\nNeedham R. and Schroeder M. Using Encryption for Authentication in Large Networks\nof Computers. Communications of the ACM, 21(12):993–999, Dec. 1978. →577.\nNelson B. Remote Procedure Call. Ph.D., Carnegie-Mellon University, 1981. →514.\nNeuman B. Proxy-Based Authorization and Accounting for Distributed Systems.\nIn 13th International Conference on Distributed Computing Systems, pages 283–291,\nPittsburgh, May 1993. IEEE. →601.\nNeuman B. Scale in Distributed Systems. In Casavant T. and Singhal M., editors,\nReadings in Distributed Computing Systems, pages 463–489. IEEE Computer Society\nPress, Los Alamitos, CA., 1994. →24, 28, 606.\nNeuman C., Yu T., Hartman S., and Raeburn K. The Kerberos Network Authentication\nService. RFC 4120, July 2005. →581.\nNg E. and Zhang H. Predicting Internet Network Distance with Coordinates-Based\nApproaches. In 21st INFOCOM Conference, Los Alamitos, CA., June 2002. IEEE, IEEE\nComputer Society Press. →320.\nNguyen C. T., Hoang D. T., Nguyen D. N., Niyato D., Nguyen H. T., and Dutkiewicz E.\nProof-of-Stake Consensus Mechanisms for Future Blockchain Networks: Fundamen-\ntals, Applications and Opportunities. IEEE Access, 7:85727–85745, 2019. →292, 589.\nDS 4.01\n \n",
      "content_length": 2828,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 667,
      "content": "BIBLIOGRAPHY\n651\nNissenbaum H. Privacy in Context. Stanford University Press, Stanford, CA, 2010.\n→553.\nNoble B., Fleis B., and Kim M. A Case for Fluid Replication. In NetStore’99, Seattle,\nWA, Oct. 1999. →430.\nNoveck D. and Lever C. Network File System (NFS) Version 4 Minor Verion 1 Protocol.\nRFC 8881, Aug. 2020. →83, 350.\nNyers L. and Jelasity M. A Comparative Study of Spanning Tree and Gossip Protocols\nfor Aggregation. Concurrency & Computation: Practice and Experience, 2015. →522.\nNygren E., Sitaraman R. K., and Sun J. The Akamai Network: A Platform for High-\nPerformance Internet Applications. Operating Systems Review, 44(3):2–19, July 2010.\n→165.\nOASIS . AMQP, Protocol specification, Version 1.0, Oct. 2012. →227.\nObraczka K. Multicast Transport Protocols: A Survey and Taxonomy. IEEE Communi-\ncations Magazine, 36(1):94–102, Jan. 1998. →232.\nOikonomou K. and Stavrakakis I. Performance Analysis of Probabilistic Flooding\nUsing Random Graphs. In World of Wireless, Mobile and Multimedia Networks, 2007.\nWoWMoM 2007. IEEE International Symposium on a, pages 1–6, June 2007.\ndoi:\n10.1109/WOWMOM.2007.4351694. →237.\nOMG . The Common Object Request Broker: Architecture and Specification, revision\n2.4.2. OMG Document formal/00-02-33, Object Management Group, Framingham,\nMA, Feb. 2001. →156.\nOMG . UML 2.0 Superstructure Specification. OMG Document ptc/04-10-02, Object\nManagement Group, Framingham, MA, Oct. 2004. →57.\nOngaro D. Consensus: Bridging Theory AND Practice. Ph.D., Stanford University, Aug.\n2014. →479.\nOngaro D. and Ousterhout J. In Search of an Understandable Consensus Algorithm.\nIn USENIX Annual Technical Conference, pages 305–319, Berkeley, CA, June 2014.\nUSENIX, USENIX. →289, 477, 479.\nOnica E., Felber P., Mercier H., and Riviere E. Confidentiality-Preserving Publish/Sub-\nscribe: A Survey. ACM Computing Surveys, 49(2), June 2016. →315.\nOram A., editor. Peer-to-Peer: Harnessing the Power of Disruptive Technologies. O’Reilly &\nAssociates, Sebastopol, CA., 2001. →32.\nOtte P. Sybil-resistant Trust Mechanisms in Distributed Systems. Msc, Delft University\nof Technology, Dec. 2016. →591.\nOtte P., Vos M.de , and Pouwelse J. TrustChain: A Sybil-resistant Scalable Blockchain.\nFuture Generation Computer Systems, 107:770–780, 2020. →589, 590.\nÖzsu T. and Valduriez P. Principles of Distributed Database Systems. Springer-Verlag,\nBerlin, 4th edition, 2020. →89, 426.\nPahl C., Brogi A., Soldani J., and Jamshidi P.\nCloud Container Technologies: A\nState-of-the-Art Review. IEEE Transactions on Cloud Computing, 7(3):677–692, 2019.\n→135.\nPai V., Aron M., Banga G., Svendsen M., Druschel P., Zwaenepoel W., and Nahum\nE. Locality-Aware Request Distribution in Cluster-Based Network Servers. In\n \nDS 4.01\n",
      "content_length": 2729,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 668,
      "content": "652\nBIBLIOGRAPHY\n8th International Conference on Architectural Support for Programming Languages and\nOperating Systems, pages 205–216, New York, NY, Oct. 1998. ACM, ACM Press.\n→163.\nPanzieri F. and Shrivastava S. Rajdoot: A Remote Procedure Call Mechanism with\nOrphan Detection and Killing. IEEE Transactions on Software Engineering, 14(1):30–37,\nJan. 1988. →515.\nPappas V., Massey D., Terzis A., and Zhang L. A Comparative Study of the DNS\nDesign with DHT-Based Alternatives. In 25th INFOCOMConference, Los Alamitos,\nCA., May 2006. IEEE, IEEE Computer Society Press. →368.\nParecki A. OAuth 2.0 Simplified: A Guide to Building OAuth 2.0 Servers. Lulu Press, Inc,\n2020. →605.\nPark S., Specter M., Narula N., and Rivest R. L. Going From Bad to Worse: From\nInternet Voting to Blockchain Voting. Journal of Cybersecurity, 7(1):1–15, 2021. →592.\nParlavantzas N. and Coulson G. Designing and Constructing Modifiable Middleware\nusing Component Frameworks. IET Software, 1(4):113–126, Aug. 2007. →78.\nPassarella A. A Survey on Content-centric Technologies for the Current Internet: CDN\nand P2P Solutions. Computer Communications, 35(1):1–32, 2012. →165.\nPautasso C., Zimmermann O., and Leymann F. Restful Web Services vs. \"Big\" Web\nServices: Making the Right Architectural Decision. In 17th International World Wide\nWeb Conference, pages 805–814, New York, NY, Aug. 2008. ACM Press. →66, 67.\nPease M., Shostak R., and Lamport L. Reaching Agreement in the Presence of Faults.\nJournal of the ACM, 27(2):228–234, Apr. 1980. →468.\nPerkins C. IP Mobility Support in IPv4, Revised. RFC 5944, Nov. 2010. →47.\nPerkins C., Johnson D., and Arkko J. Mobility Support in IPv6. RFC 6275, July 2011.\n→47, 331.\nPeterson L., Bavier A., Fiuczynski M. E., and Muir S. Experiences Building PlanetLab.\nIn 7th Symposium on Operating System Design and Implementation, pages 351–366,\nBerkeley, CA, Nov. 2006. USENIX, USENIX. →136.\nPike R., Presotto D., Dorward S., Flandrena B., Thompson K., Trickey H., and Winter-\nbottom P. Plan 9 from Bell Labs. Computing Systems, 8(3):221–254, Summer 1995.\n→346.\nPinzari G. NX X Protocol Compression. Technical Report D-309/3-NXP-DOC, NoMa-\nchine, Rome, Italy, Sept. 2003. →144.\nPitoura E. and Samaras G. Locating Objects in Mobile Computing. IEEE Transactions\non Knowledge and Data Engineering, 13(4):571–592, July 2001. →338.\nPlummer D. An Ethernet Address Resolution Protocol. RFC 826, Nov. 1982. →330.\nPodling S. and Boszormenyi L. A Survey of Web Cache Replacement Strategies. ACM\nComputing Surveys, 35(4):374–398, Dec. 2003. →453.\nPopek G. J. and Goldberg R. P. Formal Requirements for Virtualizable Third Generation\nArchitectures. Communications of the ACM, 17(7):412–421, July 1974. →131, 132.\nPopescu A., Constantinescu D., Erman D., and Ilie D. A Survey of Reliable Multicast\nCommunication. In 3rd Conference on Next Generation Internet Networks, pages 111–\n118, May 2007. →517.\nDS 4.01\n \n",
      "content_length": 2906,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 669,
      "content": "BIBLIOGRAPHY\n653\nPopescu A. M., Tudorache G. I., Peng B., and Kemp A. H. Surveying Position Based\nRouting Protocols for Wireless Sensor and Ad-hoc Networks. International Journal on\nCommunication Networks and Information Security, 4(1):41–67, Apr. 2012. →319.\nPoslad S. Ubiquitous Computing: Smart Devices, Environments and Interactions. John\nWiley, New York, 2009. →44, 46.\nPostel J. Simple Mail Transfer Protocol. RFC 821, Aug. 1982. →226.\nPostel J. and Reynolds J. File Transfer Protocol. RFC 995, Oct. 1985. →188.\nPourghassemi B. Adaptive Tools for Performance Analysis of Large-scale Applications. Phd,\nUniversity of California at Irvine, 2021. →146.\nPouwelse J. A., Garbacki P., Epema D. H. J., and Sips H. J. The Bittorrent P2P File-\nSharing System: Measurements and Analysis. In 4th International Workshop on\nPeer-to-Peer Systems, volume 3640 of Lecture Notes in Computer Science, pages 205–216,\nBerlin, Feb. 2005. Springer-Verlag. →97.\nPradhan D. Fault-Tolerant Computer System Design. Prentice Hall, Englewood Cliffs,\nN.J., 1996. →464.\nPreguica N. Conflict-Free Replicated Data Types: An Overview. arXiv:1806.10254,\n2018. →410.\nPrisco R. D., Lampson B., and Lynch N. Revisiting the Paxos Algorithm. In Mavroni-\ncolas M. and Tsigas P., editors, 11th International Workshop on Distributed Algorithms,\nvolume 1320 of Lecture Notes in Computer Science. Springer-Verlag, Berlin, Sept. 1997.\n→479.\nQin H., Li Q., Speiser J., Kraft P., and Ousterhout J. Arachne: Core-Aware Thread\nManagement. In 13th Symposium on Operating System Design and Implementation,\npages 145–161. USENIX, Oct. 2018. →122.\nRabinovich M. and Spastscheck O. Web Caching and Replication. Addison-Wesley,\nReading, MA., 2002. →451.\nRabinovich M., Rabinovich I., Rajaraman R., and Aggarwal A. A Dynamic Object\nReplication and Migration Protocol for an Internet Hosting Service. In 19th Interna-\ntional Conference on Distributed Computing Systems, pages 101–113, Austin, TX, June\n1999. IEEE. →427, 428.\nRadia S. Names, Contexts, and Closure Mechanisms in Distributed Computing Environments.\nPh.D., University of Waterloo, Ontario, 1989. →348.\nRajaraman V. Grid Computing. Resonance, 21(5):401–415, 2016. →35.\nRamanathan P., Shin K., and Butler R. Fault-Tolerant Clock Synchronization in Dis-\ntributed Systems. Computer, 23(10):33–42, Oct. 1990. →253.\nRamirez W., Masip-Bruin X., Yannuzzi M., Serral-Gracia R., Martinez A., and Siddiqui\nM. A Survey and Taxonomy of ID/Locator Split Architectures. Computer Networks,\n60:13–33, 2014. →329.\nRaynal M. and Singhal M. Logical Time: Capturing Causality in Distributed Systems.\nComputer, 29(2):49–56, Feb. 1996. →262.\nRescorla E. and others . The Transport Layer Security (TLS) Protocol Version 1.3. RFC\n8446, Aug. 2018. → 583.\nReynolds J. and Postel J. Assigned Numbers. RFC 1700, Oct. 1994. → 150.\n \nDS 4.01\n",
      "content_length": 2823,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 670,
      "content": "654\nBIBLIOGRAPHY\nRicart G. and Agrawala A. An Optimal Algorithm for Mutual Exclusion in Computer\nNetworks. Communications of the ACM, 24(1):9–17, Jan. 1981. →274.\nRichards M. and Ford N. Fundamentals of Software Architecture. O’Reilly & Associates,\nSebastopol, CA., 2020. →56.\nRichardson T., Stafford-Fraser Q., Wood K. R., and Hopper A.\nVirtual Network\nComputing. IEEE Internet Computing, 2(1):33–38, Jan. 1998. →144.\nRisson J. and Moors T. Survey of Research towards Robust Peer-to-Peer Networks:\nSearch Methods. Computer Networks, 50(17):3485–3521, 2006. →93.\nRizzo L. Effective Erasure Codes for Reliable Computer Communication Protocols.\nSIGCOMM Computer Communications Review, 27(2):24–36, Apr. 1997. →536.\nRobbins K. and Robbins S. UNIX Systems Programming. Prentice Hall, Englewood\nCliffs, N.J., 2003. →113, 122.\nRobin J. S. and Irvine C. E. Analysis of the Intel Pentium’s Ability to Support a\nSecure Virtual Machine Monitor. In 9th USENIX Security Symposium, pages 129–144,\nBerkeley, CA, 2000. USENIX. →132.\nRodrigues L., Fonseca H., and Verissimo P. Totally Ordered Multicast in Large-Scale\nSystems. In 16th International Conference on Distributed Computing Systems, pages\n503–510, Hong Kong, May 1996. IEEE. →441.\nRodriguez P., Spanner C., and Biersack E. Analysis of Web Caching Architecture:\nHierarchical and Distributed Caching. IEEE/ACM Transactions on Networking, 21(4):\n404–418, Aug. 2001. →452.\nRosenblum M. and Garfinkel T. Virtual Machine Monitors: Current Technology and\nFuture Trends. Computer, 38(5):39–47, May 2005. →131.\nRoussos G., Marsh A. J., and Maglavera S. Enabling Pervasive Computing with Smart\nPhones. IEEE Pervasive Computing, 4(2):20–26, Apr. 2005. →44.\nRowe F., Baskerville R., and Wolff F.-C. Functionality vs. Security in IS: Tradeoff or\nEquilibrium? In 33rd International Conference on Information Systems, 2012. →566.\nRowstron A. and Druschel P.\nPastry: Scalable, Distributed Object Location and\nRouting for Large-Scale Peer-to-Peer Systems. In Middleware 2001, volume 2218 of\nLecture Notes in Computer Science, pages 329–350, Berlin, Nov. 2001. Springer-Verlag.\n→233, 338.\nRoy G.\nRabbitMQ in Depth.\nManning Publications, Shelter Island, NY, 2018.\n→227, 230, 231, 232.\nSaad M., Spaulding J., Njilla L., Kamhoua C., Shetty S., Nyang D., and Mohaisen\nD. Exploring the Attack Surface of Blockchain: A Comprehensive Survey. IEEE\nCommunications Surveys & Tutorials, 22(3):1977–2008, 2020. →589.\nSagan H. Space-Filling Curves. Springer-Verlag, Berlin, 1994. →382.\nSahoo J., Salahuddin M. A., Glitho R., Elbiaze H., and Ajib W. A Survey on Replica\nServer Placement Algorithms for Content Delivery Networks. IEEE Communications\nSurveys & Tutorials, 19(2):1002–1026, 2017. →424, 425, 426.\nSalaht F. A., Desprez F., and Lebre A. An Overview of Service Placement Problem in\nFog and Edge Computing. ACM Computing Surveys, 53(3), June 2020. →104.\nSaltzer J. and Kaashoek M. Principles of Computer System Design, An Introduction.\nDS 4.01\n \n",
      "content_length": 2968,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 671,
      "content": "BIBLIOGRAPHY\n655\nMorgan Kaufman, San Mateo, CA., 2009. →79, 546, 547.\nSaltzer J. and Schroeder M. The Protection of Information in Computer Systems.\nProceedings of the IEEE, 63(9):1278–1308, Sept. 1975. →549, 550.\nSaltzer J., Reed D., and Clark D. End-to-End Arguments in System Design. ACM\nTransactions on Computer Systems, 2(4):277–288, Nov. 1984. →271.\nSambra A. V., Mansour E., Hawke S., Zereba M., Greco N., Ghanem A., Zagidulin\nD., Aboulnaga A., and Berners-Lee T. Solid: A Platform for Decentralized Social\nApplications based on Linked Data. MIT CSAIL & Qatar Computing Research Institute,\nTech. Rep., 2016. →553.\nSantoro N. Design and Analysis of Distributed Algorithms. John Wiley, New York, 2007.\n→249.\nSaroiu S., Gummadi P. K., and Gribble S. D. Measuring and Analyzing the Character-\nistics of Napster and Gnutella Hosts. ACM Multimedia Systems, 9(2):170–184, Aug.\n2003. →96.\nSaxena D., Raychoudhury V., Suri N., Becker C., and Cao J. Named data networking:\nA survey. Computer Science Review, 19:15–55, 2016. →386.\nSaxena P. and Rai J. A Survey of Permission-based Distributed Mutual Exclusion\nAlgorithms. Computer Standards and Interfaces, 25(2):159–181, May 2003. →272.\nSchlosser M., Sintek M., Decker S., and Nejdl W. HyperCuP – Hypercubes, Ontologies,\nand Efficient Search on Peer-to-Peer Networks. In 1st International Workshop on\nAgents and Peer-to-Peer Computing, volume 2530 of Lecture Notes in Computer Science,\npages 112–124, Berlin, July 2002. Springer-Verlag. →238.\nSchmidt A. Implicit Human Computer Interaction Through Context. Personal and\nUbiquitous Computing, 4(2-3):191–199, June 2000. →45.\nSchmidt C. and Parashar M. Squid: Enabling Search in DHT-based systems. Journal of\nParallel and Distributed Computing, 68:962–975, 2008. →383.\nSchmidt D., Stal M., Rohnert H., and Buschmann F. Pattern-Oriented Software Archi-\ntecture – Patterns for Concurrent and Networked Objects. John Wiley, New York, 2000.\n→76.\nSchneider F. Implementing Fault-Tolerant Services Using the State Machine Approach:\nA Tutorial. ACM Computing Surveys, 22(4):299–320, Dec. 1990. →264, 431.\nSchulzrinne H., Casner S., Frederick R., and Jacobson V. RTP: A Transport Protocol for\nReal-Time Applications. RFC 3550, July 2003. →187.\nSchwarzkopf M., Kohler E., Frans Kaashoek M., and Morris R. Position: GDPR\nCompliance by Construction. In Gadepally V., Mattson T., Stonebraker M., Wang\nF., Luo G., Laing Y., and Dubovitskaya A., editors, Heterogeneous Data Management,\nPolystores, and Analytics for Healthcare (DMAH 2019, Poly 2019), volume 11721 of\nLecture Notes in Computer Science, pages 39–53, Berlin, 2019. Springer-Verlag. →554.\nSebesta R. Programming the World Wide Web. Addison-Wesley, Reading, MA., 8th\nedition, 2015. →87.\nSereno M. and Gaeta R. Generalized Probabilistic Flooding in Unstructured Peer-to-\nPeer Networks. IEEE Transactions on Parallel and Distributed Systems, 22(12):2055–2062,\n2011. ISSN 1045-9219. →238.\n \nDS 4.01\n",
      "content_length": 2939,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 672,
      "content": "656\nBIBLIOGRAPHY\nServos D. and Osborn S. L. Current Research and Open Problems in Attribute-based\nAccess Control. ACM Computing Surveys, 49(4):1–45, 2017. →598, 601.\nSeuken S. and Parkes D. C. Sybil-proof Accounting Mechanisms with Transitive Trust.\nIn International Joint Conference on Autonomous Agents and Multiagent Systems, pages\n205–212. ACM, 2014. →590.\nShahrad M., Balkind J., and Wentzlaff D. Architectural Implications of Function-as-\na-Service Computing. In Annual IEEE/ACM International Symposium on Microar-\nchitecture, page 1063–1075, New York, NY, USA, 2019. Association for Computing\nMachinery. →100.\nShapiro M., Preguiça N., Baquero C., and Zawirski M. Conflict-Free Replicated Data\nTypes. In 13th International Conference Stabilization, Safety, and Security of Distributed\nSystems, page 386–400, Berlin, 2011. Springer-Verlag. →409.\nSharma P., Chaufournier L., Shenoy P., and Tay Y. Containers and Virtual Machines at\nScale: A Comparative Study. In Middleware 2016, pages 1–13. ACM/IFIP/USENIX,\nDec. 2016. →138.\nShastri S., Banakar V., Wasserman M., Kumar A., and Chidambaram V. Understanding\nand Benchmarking the Impact of GDPR on Database Systems. Proceedings of the\nVLDB Endowment, 13(7):1064–1077, mar 2020. →554, 555.\nShen X., Yu H., Buford J., and Akon M., editors. Handbook of Peer-to-Peer Networking.\nSpringer-Verlag, Berlin, 2010. →636, 642.\nSheth A. P. and Larson J. A. Federated Database Systems for Managing Distributed,\nHeterogeneous, and Autonomous Databases. ACM Computing Surveys, 22(3):183–236,\nSept. 1990. →427.\nShin M., Park M., Oh D., Kim B., and Lee J. Survey on the Clock Synchronization\nSchemes for Propagation Delay Measurement. International Journal of Advanced\nScience and Technology, 35:139–140, Oct. 2011. →253.\nShoch J. Internetwork Naming, Addressing, and Routing. In 17th International Computer\nConference, pages 72–79, Los Alamitos, CA., 1978. IEEE, IEEE Computer Society\nPress. →329.\nShooman M. L. Reliability of Computer Systems and Networks: Fault Tolerance, Analysis,\nand Design. John Wiley, New York, 2002. →463.\nShriram A. and Kaur J. Empirical Evaluation of Techniques for Measuring Available\nBandwidth. In 26th INFOCOM Conference, pages 2162–2170, Los Alamitos, CA., 2007.\nIEEE, IEEE Computer Society Press. →454.\nSilberschatz A., Galvin P., and Gagne G. Operating System Concepts. John Wiley, New\nYork, 10th edition, 2019. →346.\nSinghal M. and Shivaratri N. Advanced Concepts in Operating Systems: Distributed,\nDatabase, and Multiprocessor Operating Systems. McGraw-Hill, New York, 1994. →537.\nSivasubramanian S., Pierre G., and van Steen M. Replicating Web Applications On-\nDemand. In 1st International Conference on Services Computing, pages 227–236, Los\nAlamitos, CA., Sept. 2004a. IEEE, IEEE Computer Society Press. →457.\nSivasubramanian S., Szymaniak M., Pierre G., and van Steen M. Replication for Web\nHosting Systems. ACM Computing Surveys, 36(3):1–44, Sept. 2004b. →453.\nDS 4.01\n \n",
      "content_length": 2948,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 673,
      "content": "BIBLIOGRAPHY\n657\nSivasubramanian S., Pierre G., van Steen M., and Alonso G. Analysis of Caching and\nReplication Strategies for Web Applications. IEEE Internet Computing, 11(1):60–66,\nJan. 2007. →456.\nSivrikaya F. and Yener B. Time Synchronization in Sensor Networks: A Survey. IEEE\nNetwork, 18(4):45–50, July 2004. →257.\nSkeen D. Nonblocking Commit Protocols. In SIGMOD International Conference on\nManagement Of Data, pages 133–142. ACM, 1981. →534.\nSkeen D. and Stonebraker M. A Formal Model of Crash Recovery in a Distributed\nSystem. IEEE Transactions on Software Engineering, SE-9(3):219–228, Mar. 1983. →534.\nSletten B. WebAssembly: The Definitive Guide. O’Reilly & Associates, Sebastopol, CA.,\n2022. →146.\nSmart N. P. Cryptography Made Simple. Springer-Verlag, Berlin, 2016. →557.\nSmith J. and Nair R. The Architecture of Virtual Machines. Computer, 38(5):32–38, May\n2005a. →129, 130.\nSmith J. and Nair R. Virtual Machines: Versatile Platforms for Systems and Processes.\nMorgan Kaufman, San Mateo, CA., 2005b. →131, 132.\nSmith M. and Howes T. Lightweight Directory Access Protocol (LDAP): String Repre-\nsentation of Search Filters. RFC 4515, June 2006. →379.\nSmith R. E. A Contemporary Look at Saltzer and Schroeder’s 1975 Design Principles.\nIEEE Security & Privacy, 10(6):20–25, 2012. →549, 550.\nSoltesz S., Pötzl H., Fiuczynski M. E., Bavier A., and Peterson L. Container-Based\nOperating System Virtualization: A Scalable, High-Performance Alternative to\nHypervisors.\nIn 2nd EuroSys (European Conference on Computer Systems), pages\n275–287, New York, NY, Mar. 2007. ACM, ACM Press. →137.\nSpector A. Performing Remote Operations Efficiently on a Local Computer Network.\nCommunications of the ACM, 25(4):246–260, Apr. 1982. →510.\nSrinivasan S. Kilim: A Server Framework with Lightweight Actors, Isolation Types and\nZero-Copy Messaging. Ph.d., University of Cambridge, Computer Laboratory, Feb.\n2010. →122.\nSrisuresh P. and Holdrege M. IP Network Address Translator (NAT) Terminology and\nConsiderations. RFC 2663, Aug. 1999. →163.\nStallings W. Crypotgraphy and Network Security. Pearson Education, Englewood Cliffs,\nN.J., 7th edition, 2017. →571.\nStanciu V., van Steen M., Peter A., and Dobre C. Privacy-Preserving Crowd Sensing and\nAnalytics. In 17th International Conference Mobile and Ubiquitous Systems: Computing,\nNetworking, and Services, 12 2020. →558.\nStankovic J. A. Research Directions for the Internet of Things. IEEE Internet of Things\nJournal, 1(1):3–9, Feb. 2014. →44.\nStannat A., Ileri C. U., Gijswijt D., and Pouwelse J. Achieving Sybil-proofness in\nDistributed Work Systems. In International Joint Conference on Autonomous Agents and\nMultiagent Systems, pages 1263–1271, 2021. →591.\nSteiner J., Neuman C., and Schiller J. Kerberos: An Authentication Service for Open\nNetwork Systems. In Winter Technical Conference, pages 191–202. USENIX, 1988.\n \nDS 4.01\n",
      "content_length": 2876,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 674,
      "content": "658\nBIBLIOGRAPHY\n→581.\nSteinmetz R. and Nahrstedt K. Multimedia Systems. Springer-Verlag, Berlin, 2004.\n→162.\nStevens W. TCP/IP Illustrated, Volume 1: The Protocols. Addison-Wesley, Reading, MA.,\n1994. →59.\nStevens W. UNIX Network Programming – Networking APIs: Sockets and XTI. Prentice\nHall, Englewood Cliffs, N.J., 2nd edition, 1998. →123, 210.\nStevens W. UNIX Network Programming – Interprocess Communication. Prentice Hall,\nEnglewood Cliffs, N.J., 2nd edition, 1999. →113, 122.\nStevens W. and Rago S. Advanced Programming in the UNIX Environment. Addison-\nWesley, Reading, MA., 2nd edition, 2005. →115.\nStewart R. Stream Control Transmission Protocol. RFC 4960, Sept. 2007. →188.\nStocker V., Smaragdakis G., Lehr W., and Bauer S.\nThe Growing Complexity of\nContent Delivery Networks: Challenges and Implications for the Internet Ecosystem.\nTelecommunications Policy, 41(10):1003–1016, 2017. →165.\nStoica I., Morris R., Liben-Nowell D., Karger D. R., Kaashoek M. F., Dabek F., and\nBalakrishnan H. Chord: A Scalable Peer-to-peer Lookup Protocol for Internet Appli-\ncations. IEEE/ACM Transactions on Networking, 11(1):17–32, Feb. 2003. →91, 333, 336.\nStratan C., Sacha J., Napper J., Costa P., and Pierre G.\nThe XtreemOS Resource\nSelection Service. ACM Transactions of Autonomous and Adaptive Systems, 7(4), Dec.\n2012. →385.\nStrauss J., Katabi D., and Kaashoek F. A Measurement Study of Available Bandwidth\nEstimation Tools. In 3rd Internet Measurement Conference, pages 39–44, New York,\nNY, 2003. ACM Press. →454.\nSu A.-J., Choffnes D. R., Kuzmanovic A., and Bustamante F. E. Drafting Behind Akamai\n(Travelocity-Based Detouring). In SIGCOMM, page 435–446, 2006. →166.\nSugerman J., Venkitachalam G., and Lim B.-H. Virtualizing I/O Devices on VMware\nWorkstations Hosted Virtual Machine Monitor. In USENIX Annual Technical Confer-\nence, pages 1–14, Berkeley, CA, June 2001. USENIX, USENIX. →132.\nSundararaman B., Buy U., and Kshemkalyani A. D. Clock Synchronization for Wireless\nSensor Networks: A Survey. Ad-Hoc Networks, 3(3):281–323, May 2005. →257.\nSwamidass S. J. and Baldi P.\nMathematical Correction for Fingerprint Similarity\nMeasures to Improve Chemical Retrieval. Journal of Chemical Information and Modeling,\n47(3):952–964, 2007. →559.\nSzymaniak M., Pierre G., and van Steen M. Scalable Cooperative Latency Estimation.\nIn 10th International Conference on Parallel and Distributed Systems, pages 367–376, Los\nAlamitos, CA., July 2004. IEEE, IEEE Computer Society Press. →321.\nSzymaniak M., Presotto D., Pierre G., and van Steen M. Practical Large-Scale Latency\nEstimation. Computer Networks, 52(7):1343–1364, May 2008. →321.\nTaiani F., Fabre J.-C., and Killijian M.-O. A Multi-Level Meta-Object Protocol for\nFault-Tolerance in Complex Architectures. In International Conference on Dependable\nSystems and Networks, pages 270–279, Los Alamitos, CA., June 2005. IEEE Computer\nSociety Press. →436.\nDS 4.01\n \n",
      "content_length": 2912,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 675,
      "content": "BIBLIOGRAPHY\n659\nTaleb T., Samdanis K., Mada B., Flinck H., Dutta S., and Sabella D. On Multi-Access\nEdge Computing: A Survey of the Emerging 5G Network Edge Cloud Architecture\nand Orchestration. IEEE Communications Surveys & Tutorials, 19(3):1657–1681, 2017.\n→103.\nTan S.-W., Waters G., and Crawford J. A Survey and Performance Evaluation of\nScalable Tree-based Application Layer Multicast Protocols. Technical Report 9-03,\nUniversity of Kent, UK, July 2003. →235.\nTanenbaum A. and Bos H. Modern Operating Systems. Prentice Hall, Upper Saddle\nRiver, N.J., 5th edition, 2022. →346.\nTanenbaum A., , Feamster N., and Wetherall D. Computer Networks. Prentice Hall,\nUpper Saddle River, N.J., 6th edition, 2021. →183, 508.\nTanisch P. Atomic Commit in Concurrent Computing. IEEE Concurrency, 8(4):34–41,\nOct. 2000. →528.\nTarkoma S. Overlay Networks, Toward Information Networking. CRC Press, Boca Raton,\nFL, 2010. →89.\nTarkoma S. and Kangasharju J. Mobile Middleware: Supporting Applications and Services.\nJohn Wiley, New York, 2009. →47.\nTartalja I. and Milutinovic V. Classifying Software-Based Cache Coherence Solutions.\nIEEE Software, 14(3):90–101, May 1997. →443.\nTel G. Introduction to Distributed Algorithms. Cambridge University Press, Cambridge,\nUK, 2nd edition, 2000. →249, 283.\nTerry D. Replicated Data Management for Mobile Computing. Synthesis Lectures on Data\nManagement. Morgan and Claypool, San Rafael, CA, 2008. →416.\nTerry D., Demers A., Petersen K., Spreitzer M., Theimer M., and Welsh B. Session\nGuarantees for Weakly Consistent Replicated Data. In 3rd International Conference on\nParallel and Distributed Information Systems, pages 140–149, Los Alamitos, CA., Sept.\n1994. IEEE, IEEE Computer Society Press. →416, 420, 421.\nTerry D., Petersen K., Spreitzer M., and Theimer M. The Case for Non-transparent\nReplication: Examples from Bayou. IEEE Data Engineering, 21(4):12–20, Dec. 1998.\n→416.\nThomas R. A Majority Consensus Approach to Concurrency Control for Multiple Copy\nDatabases. ACM Transactions on Database Systems, 4(2):180–209, June 1979. →441.\nTIBCO . TIBCO Rendezvous Concepts, Release 8.3.0. TIBCO Software Inc., Palo Alto, CA,\nJuly 2010. →308.\nTourani R., Misra S., Mick T., and Panwar G. Security, Privacy, and Access Control\nin Information-Centric Networking: A Survey. IEEE Communications Surveys &\nTutorials, 20(1):566–600, 2018. →389.\nTowsley D., Kurose J., and Pingali S. A Comparison of Sender-Initiated and Receiver-\nInitiated Reliable Multicast Protocols. IEEE Journal on Selected Areas in Communication,\n15(3):398–407, Apr. 1997. →518.\nTrivedi K. Probability and Statistics with Reliability, Queuing and Computer Science Applica-\ntions. John Wiley, New York, 2nd edition, 2002. →26.\nTsafrir D. The Context-Switch Overhead Inflicted by Hardware Interrupts (and the\n \nDS 4.01\n",
      "content_length": 2810,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 676,
      "content": "660\nBIBLIOGRAPHY\nEnigma of Do-nothing Loops). In 2007 Workshop on Experimental Computer Science,\nNew York, NY, 2007. ACM Press. →116, 117.\nTsui A. W., Lin W.-C., Chen W.-J., Huang P., and Chu H.-H. Accuracy Performance\nAnalysis between War Driving and War Walking in Metropolitan Wi-Fi Localization.\nIEEE Transations on Mobile Computing, 9(11):1551–1562, 2010. →318.\nTurek J. and Shasha S. The Many Faces of Consensus in Distributed Systems. Computer,\n25(6):8–17, June 1992. →503, 504.\nUlrich A., Holz R., Hauck P., and Carle G. Investigating the OpenPGP Web of Trust. In\nEuropean Symposium on Research in Computer Security, pages 489–507. Springer, 2011.\n→571.\nUmar A. Object-Oriented Client/Server Internet Environments. Prentice Hall, Upper\nSaddle River, N.J., 1997. →81.\nUPnP Forum . UPnP Device Architecture Version 1.1, Oct. 2008. →46.\nUr B., Bees J., Segreti S. M., Bauer L., Christin N., and Cranor L. F.\nDo Users’\nPerceptions of Password Security Match Reality? In 2016CHI Conference on Human\nFactors in Computing Systems, pages 3748–3760. ACM, 2016. →572.\nUrdaneta G., Pierre G., and van Steen M. A Survey of DHT Security Techniques. ACM\nComputing Surveys, 43(2), June 2011. →344, 588.\nUzunov A. V.\nA Survey of Security Solutions for Distributed Publish/Subscribe\nSystems. Computers & Security, 61:94–129, 2016. →315.\nvan der Toorn O., Müller M., Dickinson S., Hesselman C., Sperotto A., and van Rijswijk-\nDeij R. Addressing the Challenges of Modern DNS: A Comprehensive Tutorial.\nComputer Science Review, 45:100469, 2022. →359, 364, 365.\nvan Ede T., Aghakhani H., Spahn N., Bortolameotti R., Cova M., Continella A., van\nSteen M., Peter A., Kruegel C., and Vigna G. DeepCASE: Semi-Supervised Contex-\ntual Analysis of Security Events. In International Symposium on Security and Privacy.\nIEEE, 2022. →612.\nvan Renesse R. and Altinbuken D. Paxos Made Moderately Complex. ACM Computing\nSurveys, 47(3):42:1–42:36, Feb. 2015. →479.\nvan Rijn V. and Rellermeyer J. S. A Fresh Look at the Architecture and Performance\nof Contemporary Isolation Platforms. In Middleware 2021, pages 323–336. ACM/I-\nFIP/USENIX, Dec. 2021. →139.\nvan Steen M. and Ballintijn G. Achieving Scalability in Hierarchical Location Services.\nIn 26th International Computer Software and Applications Conference, pages 899–905,\nLos Alamitos, CA., Aug. 2002. IEEE, IEEE Computer Society Press. →342.\nvan Steen M., Hauck F., Homburg P., and Tanenbaum A. Locating Objects in Wide-Area\nSystems. IEEE Communications Magazine, 36(1):104–109, Jan. 1998. →338.\nVaquero L. M., Rodero-Merino L., Caceres J., and Lindner M. A Break in the Clouds:\nTowards a Cloud Definition. SIGCOMM Computer Communications Review, 39(1):\n50–55, Dec. 2008. →98.\nVasilomanolakis E., Karuppayah S., Mühlhäuser M., and Fischer M. Taxonomy and\nSurvey of Collaborative Intrusion Detection. ACM Computing Surveys, 47(4):1–33,\n2015. →612.\nDS 4.01\n \n",
      "content_length": 2885,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 677,
      "content": "BIBLIOGRAPHY\n661\nVasudevan S., Kurose J. F., and Towsley D. F. Design and Analysis of a Leader Election\nAlgorithm for Mobile Ad Hoc Networks. In 12th International Conference on Network\nProtocols, pages 350–360, Los Alamitos, CA., Oct. 2004. IEEE, IEEE Computer Society\nPress. →294, 297.\nVelazquez M. A Survey of Distributed Mutual Exclusion Algorithms. Technical Report\nCS-93-116, University of Colorado at Boulder, Sept. 1993. →272.\nViotti P. and Vukolic M. Consistency in Nontransactional Distributed Storage Systems.\nACM Computing Surveys, 29(1), June 2016. →395.\nVixie P. What DNS Is Not. Communications of the ACM, 52(12):43–47, Dec. 2009. →369.\nVixie P. Rate-Limiting State. Communications of the ACM, 57(4):40–43, Apr. 2014. →369.\nVogels W. Tracking Service Availability in Long Running Business Activities. In 1st\nInternational Conference on Service Oriented Computing, volume 2910 of Lecture Notes\nin Computer Science, pages 395–408, Berlin, Dec. 2003. Springer-Verlag. →507.\nVogels W. Eventually consistent. Communications of the ACM, 52(1):40–44, Jan. 2009.\n→407.\nVoigt P. and Bussche A.Von dem . The EU General Data Protection Regulation (GDPR), A\nPractical Guide. Springer-Verlag, Berlin, 2017. →553.\nVoorsluys W., Broberg J., Venugopal S., and Buyya R. Cost of Virtual Machine Live\nMigration in Clouds: A Performance Evaluation. In 1st International Conference on\nCloud Computing, volume 5931 of Lecture Notes in Computer Science, pages 254–265,\nBerlin, Dec. 2009. Springer-Verlag. →176, 177.\nVoronkov A., Iwaya L. H., Martucci L. A., and Lindskog S. Systematic Literature\nReview on Usability of Firewall Configuration. ACM Computing Surveys, 50(6):1–35,\n2017. →610.\nVoulgaris S. and van Steen M. VICINITY: A Pinch of Randomness Brings out the\nStructure. In Middleware 2013, volume 8275 of Lecture Notes in Computer Science,\npages 21–40, Berlin, Dec. 2013. ACM/IFIP/USENIX, Springer-Verlag. →301.\nVoulgaris S., Gavidia D., and van Steen. M. CYCLON: Inexpensive Membership Man-\nagement for Unstructured P2P Overlays. Journal of Network and Systems Management,\n13(2):197–217, June 2005. →299, 304.\nVoulgaris S., Rivière E., Kermarrec A.-M., and van Steen M. Sub-2-Sub: Self-Organizing\nContent-Based Publish and Subscribe for Dynamic and Large Scale Collaborative\nNetworks. In 5th International Workshop on Peer-to-Peer Systems, Feb. 2006. →311.\nVu Q., Lupu M., and Ooi B. Peer-to-Peer Computing, Principles and Applications. Springer-\nVerlag, Berlin, 2010. →89.\nVukoli´c M. Quorum Systems: With Applications to Storage and Consensus, volume 3 of\nSynthesis Lectures on Distributed Computing Theory. Morgan & Claypool Publishers,\n2012. →443.\nWaldo J., Wyant G., Wollrath A., and Kendall S. A Note on Distributed Computing.\nIn 2nd Workshop on Mobile Object Systems, volume 1222 of Lecture Notes in Computer\nScience, pages 1–10, Berlin, July 1997. Springer-Verlag. →15.\nWalfish M., Balakrishnan H., , and Shenker S. Untangling the Web from DNS. In 1st\nSymposium on Networked Systems Design and Implementation, pages 225–238, Berkeley,\n \nDS 4.01\n",
      "content_length": 3054,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 678,
      "content": "662\nBIBLIOGRAPHY\nCA, Mar. 2004. USENIX, USENIX. →368.\nWams J. Unified Messaging and Micro-Objects. PhD thesis, VU University Amsterdam,\n2012. →15.\nWelsh M. and Mainland G. Programming Sensor Networks Using Abstract Regions.\nIn 1st Symposium on Networked Systems Design and Implementation, Berkeley, CA, Mar.\n2004. USENIX, USENIX. →49.\nWendell P. and Freedman M. J. Going Viral: Flash Crowds in an Open CDN. In 11th\nInternet Measurement Conference, pages 549–558, New York, NY, 2011. ACM Press.\n→452.\nWerbach K. The Blockchain and the New Architecture of Trust. MIT Press, Cambridge,\nMA., 2018. →592.\nWessels D. Squid: The Definitive Guide. O’Reilly & Associates, Sebastopol, CA., 2004.\n→452.\nWieringa R. and Jonge W.de . Object Identifiers, Keys, and Surrogates–Object Identifiers\nRevisited. Theory and Practice of Object Systems, 1(2):101–114, 1995. →328.\nWierzbicki A. Trust and Fairness in Open, Distributed Systems, volume 298 of Studies in\nComputational Intelligence. Springer-Verlag, Berlin, 2010. →586.\nWiesmann M., Pedone F., Schiper A., Kemme B., and Alonso G. Understanding\nReplication in Databases and Distributed Systems. In 20th International Conference\non Distributed Computing Systems, pages 264–274, Taipei, Taiwan, Apr. 2000. IEEE.\n→395.\nWolff E. Micrservices: Flexible Software Architecture. Addison-Wesley, Reading, MA.,\n2017. →65.\nWollrath A., Riggs R., and Waldo J. A Distributed Object Model for the Java System.\nComputing Systems, 9(4):265–290, Fall 1996. →201.\nWolman A., Voelker G., Sharma N., Cardwell N., Karlin A., and Levy H. On the\nScale and Performance of Cooperative Web Proxy Caching. In 17th Symposium on\nOperating System Principles, pages 16–31, Kiawah Island, SC, Dec. 1999. ACM. →451.\nWool A. Trends in Firewall Configuration Errors: Measuring the Holes in Swiss Cheese.\nIEEE Internet Computing, 14(4):58–65, 2010. →610.\nWright G. and Stevens W. TCP/IP Illustrated, Volume 2: The Implementation. Addison-\nWesley, Reading, MA., 1995. →59.\nXiao Y., Zhang N., Lou W., and Hou Y. T. A Survey of Distributed Consensus Protocols\nfor Blockchain Networks. IEEE Communications Surveys & Tutorials, 22(2):1432–1465,\n2020. →502, 503.\nXu X., Weber I., Staples M., Zhu L., Bosch J., Bass L., Pautasso C., and Rimba P. A\nTaxonomy of Blockchain-based Systems for Architecture Design. In International\nConference on Software Architecture (ICSA), pages 243–252. IEEE, Apr. 2017. →108.\nYang B. and Garcia-Molina H. Designing a Super-Peer Network. In 19th International\nConference on Data Engineering, pages 49–60, Los Alamitos, CA., Mar. 2003. IEEE,\nIEEE Computer Society Press. →95.\nYang K., Zhang K., Jia X., Hasan M. A., and Shen X. Privacy-preserving Attribute-\nKeyword Based Data Publish-Subscribe Service on Cloud Platforms. Information\nDS 4.01\n \n",
      "content_length": 2772,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 679,
      "content": "BIBLIOGRAPHY\n663\nSciences, 387:116–131, 2017. →314, 315.\nYang M., Zhang Z., Li X., and Dai Y. An Empirical Study of Free-Riding Behavior in the\nMaze P2P File-Sharing System. In 4th International Workshop on Peer-to-Peer Systems,\nLecture Notes in Computer Science, Berlin, Feb. 2005. Springer-Verlag. →96.\nYellin D. Competitive Algorithms for the Dynamic Selection of Component Implemen-\ntations. IBM Systems Journal, 42(1):85–97, Jan. 2003. →78.\nYin M., Malkhi D., Reiter M. K., Gueta G. G., and Abraham I. Hotstuff: BFT Consen-\nsus with Linearity and Responsiveness. In Symposium on Principles of Distributed\nComputing, pages 347–356, 2019. →502, 503.\nYousefpour A., Fung C., Nguyen T., Kadiyala K., Jalali F., Niakanlahiji A., Kong J.,\nand Jue J. P. All One Needs to Know About Fog Computing and Related Edge\nComputing Paradigms: A Complete Survey. Journal of Systems Architecture, 98:\n289–330, 2019. →52, 100.\nYu H. and Vahdat A. Efficient Numerical Error Bounding for Replicated Network\nServices. In Abbadi A. E., Brodie M. L., Chakravarthy S., Dayal U., Kamel N.,\nSchlageter G., and Whang K.-Y., editors, 26th International Conference on Very Large\nData Bases, pages 123–133, San Mateo, CA., Sept. 2000. Morgan Kaufman. →446.\nYu H. and Vahdat A. Design and Evaluation of a Conit-Based Continuous Consistency\nModel for Replicated Services. ACM Transactions on Computer Systems, 20(3):239–282,\n2002. →410, 411, 455.\nZarrin J., Aguiar R. L., and Barraca J. P. Resource Discovery for Distributed Computing\nSystems: A Comprehensive Survey. Journal of Parallel and Distributed Computing, 113:\n127–166, 2018. →385.\nZeroC .\nDistributed Programming with Ice.\nZeroC Inc., Brisbane, Australia, 2022.\n→158, 159.\nZhang C., Xie Y., Bai H., Yu B., Li W., and Gao Y. A Survey on Federated Learning.\nKnowledge-Based Systems, 216:106775, 2021a. →169.\nZhang F., Liu G., Fu X., and Yahyapour R. A Survey on Virtual Machine Migration:\nChallenges, Techniques, and Open Issues. IEEE Communications Surveys & Tutorials,\n20(2):1206–1243, 2018. →175, 176.\nZhang J., Ma M., Wang P., and Sun X.dong . Middleware for the Internet of Things: A\nSurvey on Requirements, Enabling Technologies, and Solutions. Journal of Systems\nArchitecture, 117, 2021b. →49.\nZhang Q., Cheng L., and Boutaba R. Cloud Computing: State of the Art and Research\nChallenges. Journal of Internet Services and Applications, 1(1):7–18, May 2010. →99.\nZhang Y., Xia Z., Afanasyev A., and Zhang L. A Note on Routing Scalability in\nNamed Data Networking. In International Conference Communications Workshops (ICC\nWorkshops), pages 1–6, 2019. →387.\nZhao F. and Guibas L. Wireless Sensor Networks. Morgan Kaufman, San Mateo, CA.,\n2004. →49.\nZhu Z. and Afanasyev A. Let’s ChronoSync: Decentralized Dataset State Synchroniza-\ntion in Named Data Networking. In 21st International Conference on Network Protocols,\npages 1–10, 2013. →386.\n \nDS 4.01\n",
      "content_length": 2886,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 680,
      "content": "664\nBIBLIOGRAPHY\nZhuang S. Q., Geels D., Stoica I., and Katz R. H. On Failure Detection Algorithms\nin Overlay Networks. In 24th INFOCOM Conference, Los Alamitos, CA., Mar. 2005.\nIEEE, IEEE Computer Society Press. →507.\nZogg J.-M. GPS Basics. Technical Report GPS-X-02007, UBlox, Mar. 2002. →317.\nZolfaghari B., Srivastava G., Roy S., Nemati H. R., Afghah F., Koshiba T., Razi A., Bibak\nK., Mitra P., and Rai B. K. Content Delivery Networks: State of the Art, Trends, and\nFuture Roadmap. ACM Computing Surveys, 53(2), 2021. →165.\nZwicky E., Cooper S., Chapman D., and Russell D. Building Internet Firewalls. O’Reilly\n& Associates, Sebastopol, CA., 2nd edition, 2000. →609.\nDS 4.01\n \n",
      "content_length": 682,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 681,
      "content": "GLOSSARY\nBitTorrent: A distributed system for file sharing by which a file is partitioned\ninto blocks and subsequently physically distributed among participants.\nA participant needs to copy and swap blocks with others (called tit-for-\ntat) to eventually gather all blocks to reconstruct the original file.\nBlockchain: An append-only list of blocks of validated transactions. Each\ntransaction and block can be replicated across all processes participating\nin the blockchain as they cannot be changed once published. The list is\nsecured in the sense that any change to any transaction or block cannot\ngo unnoticed.\nConfidentiality: The property that information is disclosed only to authorized\nparties.\nConsistency model (data centric): Describes what processes can expect con-\ncerning read and write operations from and to a logically shared data\nstore that is physically distributed among the processes. In essence, a\nconsistency model tells if and when local write operations are propa-\ngated to other processes, and the effects for local read operations.\nContainer: A special type of virtual machine, generally tailored to support\nonly a specific operating system. A container provides an environment\nto an application suite, essentially mimicking the situation that this suite\nis being executed in isolation on a single machine. Where a virtual\nmachine can host an operating system, a container can host only a suite\nof applications.\nCritical region: A series of instructions to be executed by a process, which\nrequires mutually exclusive access to specified resources.\nDecentralized system: A networked computer system in which processes\nand resources are necessarily spread across multiple computers, usually\ncaused by business constraints, lack of mutual trust, or geographical\nrestrictions.\n665\n",
      "content_length": 1802,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 682,
      "content": "666\nGLOSSARY\nDependable system: A system that provides availability, reliability, safety,\nmaintainability, confidentiality, and integrity.\nDistributed system: A networked computer system in which processes and\nresources are sufficiently spread across multiple computers, usually to\nmeet performance and dependability requirements.\nDistribution transparency: The phenomenon by which a distributed system\nattempts to hide the fact that its processes and resources are physi-\ncally distributed across multiple computers, possibly separated by large\ndistances.\nEvent matching: Typically occurs in publish-subscribe systems, where the\npublication of an event needs to be matched with all relevant subscrip-\ntions. A major problem is to support matching in a scalable manner.\nExtensibility: Characterizes the extent to which a system can be extended\n(often without interrupting operations) with new functionality or com-\nponents while avoiding affecting parts that are independent of those\nextensions.\nFailure, error, fault: A system fails when it does not meet its specifications.\nA failure happens due to some error, such as a programming bug. The\ncause of an error is called a fault.\nFault tolerance: A system is fault tolerant when it can continue to provide its\nservices according to specifications despite the presence of faults that\ninfluence its design, implementation, and execution.\nFaults, errors, failures: A system is said to fail when it cannot meet its speci-\nfications. An error is a mistake that may need lead to a failure, such as a\nprogramming bug. A fault is the cause of an error.\nGroupware: Distributed software to allow multiple users to collaborate from\ndifferent locations through shared whiteboards, shared documents, etc.\nHonest-but-curious: A server that behaves according to some protocol, but\nin the worst case keeps track of all the things it does.\nIntegrity: Ensures that alterations to the various assets of a system can be\nmade only in an authorized way.\nDS 4.01\n \n",
      "content_length": 1993,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 683,
      "content": "GLOSSARY\n667\nInterface Definition Language: A formal language for specifying the inter-\nfaces to various components of a distributed system. An IDL is used\nto generate code for different programming langauges that can subse-\nquently be used to build applications making use of a component.\nInteroperability: Characterizes the extent by which two implementations of\nsystems or components from different manufacturers or development\nteams can co-exist and work together by merely relying on each other’s\nservices as specified by their respective interfaces.\nLeader-election algorithm: A distributed algorithm that is executed among\na group of processes such that, in the end, one of these processes can be\ndesignated as the leader of the group.\nLogical clock: A system in which a group of processes keeps account of in-\nternal events, and also when messages are sent and received, to globally\ndetermine a consistent ordering of events.\nMiddleware: Software that constitutes a distributed system, implementing a\nmyriad of mechanisms independent of any underlying system, as well\nas generally applicable for a wide range of applications.\nMultiparty computation: The means for two or three parties to compute a\nvalue for which the data of those parties is needed, but without the need\nto actually share that data.\nOpen distributed system: A system that offers components that can easily\nbe used by, or integrated into other systems. An open distributed system\nitself will often consist of components that originate from elsewhere.\nPartial failure: A type of failure characteristic for a distributed system. Some\nprocess or resource, is not operating according to expectations, which, in\nturn, may have effects on other parts of the system. However, the system\nas a whole will continue to operate, albeit perhaps in unexpected ways.\nPeer-sampling service: A service that operates in a potentially large dis-\ntributed system, returning a (seemingly) randomly chosen peer from all\navailable peers.\nPerspectives on distributed systems: Due to the fact that a distributed sys-\ntem must meet so many different functional and nonfunctional require-\nments, which, in general, are mututal dependent, taking different per-\nspectives on distributed systems allows for a more focused study. We\n \nDS 4.01\n",
      "content_length": 2287,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 684,
      "content": "668\nGLOSSARY\ndistinguish perspectives on architecture, processes, communication, co-\nordination, naming, consistency and replication, fault tolerance, and\nsecurity.\nPervasive system: Systems consisting of a myriad of devices that are intended\nto blend into our environment naturally. Typical devices include smart-\nphones, smart watches, specific sensors and actuators, camera’s, and so\nforth.\nPortability: Characterizes to what extent an application developed for a dis-\ntributed system A can be executed, without modification, on a different\ndistributed system B that implements the same interfaces as A.\nRemote procedure call: A communication mechanism that essentially mim-\nicks local procedure calls, yet where the execution of the call takes place\nat a remote server. In general, jsut as with local procedure calls, the\ncaller waits until the procedure has been carried out fully.\nScalability: Refers to the extent that a system can scale in terms of its size, in\nterms of how geographically dispersed its components can be without\nseriously negatively affecting performance, or the extent to which a\nsystem can span multiple administrative organizations.\nScaling up or out: Scaling up is the process by which a machine is equipped\nwith more and often more powerful resources so that it can better\naccommodate performance-demanding applications. Scaling out is all\nabout extending a networked computer system with more computers\nand subsequently distributing workloads across the extended set of\ncomputers.\nSeparating policy from mechanism: Where mechanisms in a distributed sys-\ntem facilitate basic functionalities, such as storage, communication,\nprocesses, and so on, policies describe how those facilities are used.\nIn general, separating facilities from the way how they are used is a\ngood design principle, yet may overly complicate the configuration of a\nsystem.\nSoftware architecture: The organization of distributed systems in terms of\nsoftware components and their interaction.\nSystem architecture: The actual realization of a distributed system requires\nthat software components are instantiated and placed on real machines.\nA system architecture is the final instantiation of a software architec-\nture.\nDS 4.01\n \n",
      "content_length": 2232,
      "extraction_method": "PyMuPDF_fallback"
    },
    {
      "page_number": 685,
      "content": "GLOSSARY\n669\nTransaction processing monitor: A TP monitor is one of the first general-\npurpose mechanisms built into middleware. It is service that follows a\nstandard protocol for executing a number of subtransactions, such that\n(1) each subtransaction adheres to the ACID properties, but (2) also the\ncollection of subtransactions meets the ACID requirements.\nTrusted Computing Base: The set of all security mechanisms in a (distributed)\ncomputer system that are necessary and sufficient to enforce a security\npolicy.\nVector clocks: A system implementing logical clocks such that the logical\ntime at which an event took place can be used to conclude that an\nevent indeed took place before another event, thus capturing a potential\ncausality between events.\nVirtual machine: In general, a system providing its own interface to operating\nsystems and applications, and implementing that interface for a specific\ninstruction set or operating system. As a consequence, migrating or\nporting code across different architectures or operating systems becomes\neasier as long as the target environment provides the same interface the\nvirtual machine is offering.\nVirtual processor: A counterpart of a physical processor developed in soft-\nware, providing a context in which the set of instructions of the physical\nprocessor are executed. A thread provides a minimal context for concur-\nrent execution of instructions. An (operating system) process, in addition\nprovides much stronger isolation guarantees between processes. For\nexample, a process has its own, protected address space.\n \nDS 4.01\n",
      "content_length": 1585,
      "extraction_method": "PyMuPDF_fallback"
    }
  ]
}