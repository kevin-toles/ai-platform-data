{
  "metadata": {
    "title": "Fluent Python 2nd",
    "source_file": "Fluent Python 2nd_metadata.json"
  },
  "chapters": [
    {
      "chapter_number": 4,
      "title": "A Pythonic Card Deck                                                                                                    5",
      "start_page": 7,
      "end_page": 8,
      "summary": "Data Structures\n1. The Python Data Model.\nWhat’s New in This Chapter                                                                                          4\nA Pythonic Card Deck                                                                                                    5\nEmulating Numeric Types                                                                                          9\nBoolean Value of a Custom Type                                                                            13\nChapter Summary                                                                                                          18\n2. An Array of Sequences.\nWhat’s New in This Chapter                                                                                        22\nList Comprehensions and Generator Expressions                                                   25\nArrays                                                                                                                           59\nChapter Summary                                                                                                          70\nWhat’s New in This Chapter                                                                                        78",
      "keywords": [
        "Sequences",
        "Methods",
        "List",
        "Missing",
        "Pattern Matching",
        "Chapter Summary",
        "Matching",
        "Comprehensions",
        "List Comprehensions",
        "Unpacking",
        "Mappings",
        "Special Methods",
        "Immutable Lists",
        "Table of Contents",
        "Overview"
      ],
      "concepts": [
        "list",
        "methods",
        "mappings",
        "unpacking",
        "types",
        "sequences",
        "data",
        "slicing",
        "slices",
        "value"
      ],
      "similar_chapters": [
        {
          "book": "Fluent Python 2nd",
          "chapter": 13,
          "title": "",
          "score": 0.729,
          "base_score": 0.579,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 118,
          "title": "",
          "score": 0.715,
          "base_score": 0.565,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 3,
          "title": "",
          "score": 0.712,
          "base_score": 0.562,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 1,
          "title": "",
          "score": 0.704,
          "base_score": 0.554,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 11,
          "title": "",
          "score": 0.664,
          "base_score": 0.514,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "new chapter",
          "chapter summary",
          "summary",
          "comprehensions",
          "chapter"
        ],
        "semantic": [],
        "merged": [
          "new chapter",
          "chapter summary",
          "summary",
          "comprehensions",
          "chapter"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.4135214629169701,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:09.219697+00:00"
      }
    },
    {
      "chapter_number": 118,
      "title": "Character Issues                                                                                                           118",
      "start_page": 9,
      "end_page": 9,
      "summary": "collections.OrderedDict                                                                                            95\ncollections.ChainMap                                                                                                95\ncollections.Counter                                                                                                    96\nPractical Consequences of How dict Works                                                            102\nPractical Consequences of How Sets Work                                                             107\nSet Operations                                                                                                          107\nSet Operations on dict Views                                                                                     110\nUtility Functions for Normalized Text Matching                                               143",
      "keywords": [
        "Unicode",
        "Practical Consequences",
        "Versus Bytes",
        "Text",
        "Versus",
        "Bytes",
        "collections.OrderedDict",
        "collections.ChainMap",
        "collections.Counter",
        "shelve.Shelf",
        "Set Operations",
        "Consequences",
        "Views",
        "Encoding",
        "Immutable Mappings"
      ],
      "concepts": [
        "text",
        "sets",
        "encode",
        "encoding",
        "bytes",
        "normalizing",
        "normalized",
        "functions",
        "collections",
        "views"
      ],
      "similar_chapters": [
        {
          "book": "Fluent Python 2nd",
          "chapter": 13,
          "title": "",
          "score": 0.716,
          "base_score": 0.566,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 4,
          "title": "",
          "score": 0.715,
          "base_score": 0.565,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 5,
          "title": "",
          "score": 0.65,
          "base_score": 0.5,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 1,
          "title": "",
          "score": 0.623,
          "base_score": 0.473,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 3,
          "title": "",
          "score": 0.569,
          "base_score": 0.419,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "consequences",
          "collections",
          "set operations",
          "practical consequences",
          "collections ordereddict"
        ],
        "semantic": [],
        "merged": [
          "consequences",
          "collections",
          "set operations",
          "practical consequences",
          "collections ordereddict"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.35194619877304056,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:09.219733+00:00"
      }
    },
    {
      "chapter_number": 364,
      "title": "Object Representations                                                                                               364",
      "start_page": 13,
      "end_page": 13,
      "summary": "Classes and Protocols\nVector Class Redux                                                                                                     365\nVector: A User-Defined Sequence Type                                                                  398\nVector Take #1: Vector2d Compatible                                                                     399\nProtocols and Duck Typing                                                                                       402\nVector Take #2: A Sliceable Sequence                                                                      403\nVector Take #3: Dynamic Attribute Access                                                             407\nVector Take #5: Formatting                                                                                       418",
      "keywords": [
        "Part III",
        "Vector",
        "III",
        "Chapter Summary",
        "Protocols",
        "Part",
        "Summary",
        "Reading",
        "Pythonic Object",
        "slots",
        "Attributes",
        "Sequences",
        "Typing",
        "Vector Class Redux",
        "Pythonic"
      ],
      "concepts": [
        "vector",
        "sequences",
        "classes",
        "attributes",
        "saving",
        "savings",
        "type",
        "typing",
        "pythonic",
        "python"
      ],
      "similar_chapters": [
        {
          "book": "Fluent Python 2nd",
          "chapter": 11,
          "title": "",
          "score": 0.673,
          "base_score": 0.523,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 13,
          "title": "",
          "score": 0.644,
          "base_score": 0.494,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 4,
          "title": "",
          "score": 0.642,
          "base_score": 0.492,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 1,
          "title": "",
          "score": 0.63,
          "base_score": 0.48,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 12,
          "title": "",
          "score": 0.607,
          "base_score": 0.607,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "vector",
          "protocols",
          "iii",
          "summary",
          "class redux"
        ],
        "semantic": [],
        "merged": [
          "vector",
          "protocols",
          "iii",
          "summary",
          "class redux"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.3962477329455499,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:09.219761+00:00"
      }
    },
    {
      "chapter_number": 488,
      "title": "The super() Function                                                                                                  488",
      "start_page": 14,
      "end_page": 14,
      "summary": "Subclassing an ABC                                                                                                 447\nSubclassing an ABC                                                                                                 458\nA Virtual Subclass of an ABC                                                                                460\nStructural Typing with ABCs                                                                                 464\nDesigning a Static Protocol                                                                                     474\nThe numbers ABCs and Numeric Protocols                                                       478\nABCs Are Mixins Too                                                                                             502\nMultiple Inheritance in Tkinter                                                                             507",
      "keywords": [
        "Inheritance",
        "ABC Syntax Details",
        "Protocol",
        "ABC",
        "ABCs",
        "Static Protocols",
        "Goose Typing",
        "Static",
        "Standard Library",
        "Checkable Static Protocols",
        "Subclassing",
        "Classes",
        "Multiple Inheritance",
        "Syntax Details",
        "ABC Syntax"
      ],
      "concepts": [
        "protocols",
        "subclass",
        "classes",
        "abc",
        "abcs",
        "inheritance",
        "typing",
        "types",
        "multiple",
        "function"
      ],
      "similar_chapters": [
        {
          "book": "Fluent Python 2nd",
          "chapter": 14,
          "title": "",
          "score": 0.679,
          "base_score": 0.529,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 364,
          "title": "",
          "score": 0.551,
          "base_score": 0.401,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 11,
          "title": "",
          "score": 0.542,
          "base_score": 0.392,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 21,
          "title": "",
          "score": 0.537,
          "base_score": 0.387,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 13,
          "title": "",
          "score": 0.531,
          "base_score": 0.381,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "abc",
          "static",
          "abcs",
          "inheritance",
          "subclassing"
        ],
        "semantic": [],
        "merged": [
          "abc",
          "static",
          "abcs",
          "inheritance",
          "subclassing"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.30524848716956304,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:09.219787+00:00"
      }
    },
    {
      "chapter_number": 1,
      "title": "introduces the Python Data Model and explains why the special meth‐",
      "start_page": 23,
      "end_page": 38,
      "summary": "Chapter 1 introduces the Python Data Model and explains why the special meth‐\nSpecial methods are covered in more detail throughout the book.\nchapters in this part cover the use of collection types: sequences, mappings, and\nHere we talk about functions as first-class objects in the language: what that\nof callables in Python, function attributes, introspection, parameter annotations,\nand the new nonlocal declaration in Python 3.\nLike any Object-Oriented (OO) language, Python\nChapter 18 includes a significant example\nattribute access works at a lower level in Python using descriptors.\nsubtle issues that lead to the advanced tools of the final chapter: class decorators\nOften we’ll use the interactive Python console to explore the language and libraries.\nOne of the standard Python testing packages, doctest, works by simulating console\ndoctest to check most of the code in this book, including the console listings.\ndon’t need to use or even know about doctest to follow along: the key feature of\ndoctests is that they look like transcripts of interactive Python console sessions, so\nliar with doctest, take a look at its documentation and this book’s example code\nfind that you can verify the correctness of most of the code in the book by typing\npython3 -m doctest example_script.py or pytest in the command shell of your\ntive about Python and other languages.\nCovering new features—like type hints, data classes, and pattern matching—made\nexample code repository is on GitHub. Conventions Used in This Book\nUsing Code Examples\nent Python code repository on GitHub at https://fpy.li/code.\nIf you have a technical question or a problem using the code examples, please send\nwith this book, you may use it in your programs and documentation.\nFor example, writing a program that uses several chunks of code from\nexample code does not require permission.\nexample code from this book into your product’s documentation does require\nincludes the title, author, publisher, and ISBN, e.g., “Fluent Python, 2nd ed., by\nIf you feel your use of code examples falls outside fair use or the permission given\nWe have a web page for this book, where we list errata, examples, and any additional\nbook.\nFor news and information about our books and courses, visit http://oreilly.com.\nI did not expect updating a Python book five years later to be such a major undertak‐\nwhole book.\nThe insights and suggestions of every one of them made the book better and more\nOf course, everyone who helped me understand Python and write the first edition\nI love teaching Python because it\nme idiomatic Python and are models of clarity, accuracy, and depth in technical writ‐\nMartelli and Ravenscroft were also technical reviewers of this book, along with Len‐\nteam has at least 15 years of Python experience, with many contributions to high-\nimpact Python projects in close contact with other developers in the community.\nincluding the Atlas development and support team (Atlas is the O’Reilly book pub‐\nlishing platform, which I was fortunate to use to write this book).\nbook.\nPython and Neanderthals.\nweb wave, I was able to start making a living with Python in 1998.\nI have too many gurus in the wider Python community to list them all, but besides\nnew and better ways to teach Python.\nThe Python Data Model\nAfter working with Python for a\nHowever, if you learned another object-oriented language before Python, you may\nthing we call Pythonic.\nThe iceberg is called the Python Data Model, and it is the API\nthat we use to make our own objects play well with the most idiomatic language\nYou can think of the data model as a description of Python as a framework.\nWhen using a framework, we spend a lot of time coding methods that are called by\nThe same happens when we leverage the Python Data Model to build\nThe Python interpreter invokes special methods to perform basic object\nobj[key] is supported by the __getitem__ special method.\nWe implement special methods when we want our objects to support and interact\n“Lexical Analysis” chapter of The Python Language Reference warns\nthe Python Data Model, which is quite stable.\n• Special methods supporting asynchronous programming and other new features,\n• Figure 1-2 showing the use of special methods in “Collection API” on page 14,\nPython 3.6.\nChapter 1: The Python Data Model\nA Pythonic Card Deck\nA deck as a sequence of playing cards\nCard = collections.namedtuple('Card', ['rank', 'suit'])\nWe use namedtuple to build classes of objects that\nexample, we use it to provide a nice representation for the cards in the deck, as shown\nCard(rank='7', suit='diamonds')\nA Pythonic Card Deck \nFirst, like any standard Python collection, a deck responds to the len() function by\nCard(rank='2', suit='spades')\nCard(rank='A', suit='hearts')\nShould we create a method to pick a random card?\nPython already has a\nCard(rank='3', suit='hearts')\nCard(rank='K', suit='spades')\nCard(rank='2', suit='clubs')\nWe’ve just seen two advantages of using special methods to leverage the Python Data\n• Users of your classes don’t have to memorize arbitrary method names for stan‐\n• It’s easier to benefit from the rich Python standard library and avoid reinventing\nBecause our __getitem__ delegates to the [] operator of self._cards, our deck\nCard(rank='4', suit='spades')]\nChapter 1: The Python Data Model\nJust by implementing the __getitem__ special method, our deck is also iterable:\n>>> for card in deck:  # doctest: +ELLIPSIS\nCard(rank='2', suit='spades')\nCard(rank='3', suit='spades')\nCard(rank='4', suit='spades')\n>>> for card in reversed(deck):  # doctest: +ELLIPSIS\nCard(rank='A', suit='hearts')\nCard(rank='K', suit='hearts')\nCard(rank='Q', suit='hearts')\nWhenever possible, I extracted the Python console listings in this\n>>> Card('Q', 'hearts') in deck\n>>> Card('7', 'beasts') in deck\nreturn rank_value * len(suit_values) + suit_values[card.suit]\nA Pythonic Card Deck \n>>> for card in sorted(deck, key=spades_high):  # doctest: +ELLIPSIS\nCard(rank='2', suit='clubs')\nCard(rank='2', suit='diamonds')\nCard(rank='2', suit='hearts')\nCard(rank='A', suit='diamonds')\nCard(rank='A', suit='hearts')\nCard(rank='A', suit='spades')\nimplementing the special methods __len__ and __getitem__, our FrenchDeck\nbehaves like a standard Python sequence, allowing it to benefit from core language\nobject, self._cards.\nthe Python interpreter, and not by you.\nPython calls the __len__ method you implemented.\nPython variable-sized collections\nChapter 1: The Python Data Model",
      "keywords": [
        "Python Data Model",
        "Python",
        "Python Data",
        "Card",
        "Book",
        "Data Model",
        "Special methods",
        "Pythonic Card Deck",
        "suit",
        "rank",
        "Deck",
        "Data",
        "methods",
        "Card Deck",
        "code"
      ],
      "concepts": [
        "python",
        "pythonic",
        "card",
        "chapters",
        "classes",
        "methods",
        "preface",
        "language",
        "collection",
        "collections"
      ],
      "similar_chapters": [
        {
          "book": "Fluent Python 2nd",
          "chapter": 13,
          "title": "",
          "score": 0.873,
          "base_score": 0.723,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 9,
          "title": "",
          "score": 0.748,
          "base_score": 0.598,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 11,
          "title": "",
          "score": 0.744,
          "base_score": 0.594,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 21,
          "title": "",
          "score": 0.734,
          "base_score": 0.584,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 4,
          "title": "",
          "score": 0.704,
          "base_score": 0.554,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "card",
          "suit",
          "rank",
          "card rank",
          "rank suit"
        ],
        "semantic": [],
        "merged": [
          "card",
          "suit",
          "rank",
          "card rank",
          "rank suit"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.4976711987775257,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:09.219816+00:00"
      }
    },
    {
      "chapter_number": 17,
      "title": "In the next sections, we’ll see some of the most important uses of special methods:",
      "start_page": 39,
      "end_page": 41,
      "summary": "use of special methods through another simple example.\nHow Special Methods Are Used \nExample of two-dimensional vector addition; Vector(2, 4) + Vector(2, 1)\n>>> v1 = Vector(2, 4)\n>>> v2 = Vector(2, 1)\nVector(4, 5)\n>>> v = Vector(3, 4)\nVector(9, 12)\nExample 1-2 is a Vector class implementing the operations just described, through\nthe use of the special methods __repr__, __abs__, __add__, and __mul__.\n>>> v1 = Vector(2, 4)\n>>> v2 = Vector(2, 1)\nVector(4, 5)\n>>> v = Vector(3, 4)\nVector(9, 12)\nclass Vector:\nreturn f'Vector({self.x!r}, {self.y!r})'\nHow Special Methods Are Used ",
      "keywords": [
        "special methods",
        "vector",
        "special",
        "methods",
        "special method call",
        "abs",
        "call",
        "Emulating numeric types",
        "Vector class",
        "two-dimensional vector",
        "vector addition",
        "method call",
        "dimensional vectors",
        "iter",
        "built-in"
      ],
      "concepts": [
        "vectors",
        "abs",
        "methods",
        "implementing",
        "implement",
        "snippet",
        "console",
        "types",
        "addition",
        "returns"
      ],
      "similar_chapters": [
        {
          "book": "Fluent Python 2nd",
          "chapter": 16,
          "title": "",
          "score": 0.726,
          "base_score": 0.576,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 12,
          "title": "",
          "score": 0.675,
          "base_score": 0.525,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 364,
          "title": "",
          "score": 0.347,
          "base_score": 0.347,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 10,
          "title": "",
          "score": 0.336,
          "base_score": 0.336,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 13,
          "title": "",
          "score": 0.325,
          "base_score": 0.325,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "vector",
          "vector vector",
          "special methods",
          "special",
          "methods"
        ],
        "semantic": [],
        "merged": [
          "vector",
          "vector vector",
          "special methods",
          "special",
          "methods"
        ]
      },
      "topic_id": 1,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.28097143117840523,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:09.219836+00:00"
      }
    },
    {
      "chapter_number": 16,
      "title": "As implemented, Example 1-2 allows multiplying a Vector by a",
      "start_page": 42,
      "end_page": 43,
      "summary": "return bool(abs(self))\nreturn Vector(x, y)\nreturn Vector(self.x * scalar, self.y * scalar)\nIn both cases, the methods create and return a new instance of Vector, and\nIn the following sections, we discuss the other special methods in Vector.\nThe __repr__ special method is called by the repr built-in to get the string represen‐\ncode __str__ because the implementation inherited from the object class calls\nmethod tend to implement __str__ and not __repr__.\nimplement one of these special methods in Python, choose\nAlthough Python has a bool type, it accepts any object in a Boolean context, such as\nIf __bool__ is not implemented, Python tries to invoke x.__len__(), and\nOtherwise bool returns True.\nOur implementation of __bool__ is conceptually simple: it returns False if the mag‐\nusing bool(abs(self)) because __bool__ is expected to return a Boolean.\n__bool__ methods, it is rarely necessary to call bool() explicitly, because any object\nNote how the special method __bool__ allows your objects to follow the truth value",
      "keywords": [
        "Vector",
        "special methods",
        "bool",
        "Python",
        "other.y return Vector",
        "repr",
        "special",
        "methods",
        "return Vector",
        "str",
        "Boolean",
        "object",
        "self.x",
        "self.y",
        "String"
      ],
      "concepts": [
        "python",
        "methods",
        "string",
        "returned",
        "vector",
        "implemented",
        "implement",
        "called",
        "boolean",
        "formatting"
      ],
      "similar_chapters": [
        {
          "book": "Fluent Python 2nd",
          "chapter": 12,
          "title": "",
          "score": 0.734,
          "base_score": 0.584,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 17,
          "title": "",
          "score": 0.726,
          "base_score": 0.576,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 10,
          "title": "",
          "score": 0.44,
          "base_score": 0.44,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 11,
          "title": "",
          "score": 0.419,
          "base_score": 0.419,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 1,
          "title": "",
          "score": 0.412,
          "base_score": 0.412,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "vector",
          "bool",
          "__bool__",
          "return vector",
          "return"
        ],
        "semantic": [],
        "merged": [
          "vector",
          "bool",
          "__bool__",
          "return vector",
          "return"
        ]
      },
      "topic_id": 1,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.3835610002767789,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:09.219862+00:00"
      }
    },
    {
      "chapter_number": 13,
      "title": "The goal of this brief section is to give",
      "start_page": 44,
      "end_page": 56,
      "summary": "Figure 1-2 documents the interfaces of the essential collection types in the language.\na panoramic view of Python’s most important collection interfaces, showing how\nthey are built from special methods.\nEach of the top ABCs has a single special method.\nPython 3.6) unifies the three essential interfaces that every collection should\nChapter 1: The Python Data Model\nPython does not require concrete classes to actually inherit from any of these ABCs. Any class that implements __len__ satisfies the Sized interface.\n• Sequence, formalizing the interface of built-ins like list and str\n• Set, the interface of the set and frozenset built-in types\nSince Python 3.7, the dict type is officially “ordered,” but that only\nAll the special methods in the Set ABC implement infix operators.\nspecial method.\nThe next two chapters will cover standard library sequences, mappings, and sets in\nNow let’s consider the major categories of special methods defined in the Python\nOverview of Special Methods\nThe “Data Model” chapter of The Python Language Reference lists more than 80 spe‐\nTable 1-1 shows special method names, excluding those used to implement infix\nmethods such as __anext__ (added in Python 3.5), and the class customization hook,\nOverview of Special Methods \nSpecial method names (operators excluded)\nInfix and numerical operators are supported by the special methods listed in\nmul__, added in Python 3.5 to support the use of @ as an infix operator for matrix\nSpecial method names and symbols for operators\nChapter 1: The Python Data Model\nPython calls a reversed operator special method on the second\nChapter 16 explains reversed operators and augmented assignment\n“How Special Methods Are Used” on page 8, I described how len(x) runs very fast\nwhen x is an instance of a built-in type.\nNo method is called for the built-in objects of\nand diverse types as str, list, memoryview, and so on.\nIn other words, len is not called as a method because it gets special treatment as part\nof the Python Data Model, just like abs.\nBut thanks to the special method __len__,\nmethod call syntax one might expect in an object-oriented lan‐\nyou get as s.count(x), for any sequence s.\nBy implementing special methods, your objects can behave like the built-in types,\nenabling the expressive coding style the community considers Pythonic.\nA basic requirement for a Python object is to provide usable string representations of\nThat is why the special methods __repr__ and __str__ exist in the data model.\ncommon uses of the special methods.\nsequence types is the subject of Chapter 2.\nImplementing your own sequences will be\nThanks to operator overloading, Python offers a rich selection of numeric types, from\nThe use and implementation of the majority of the remaining special methods of the\nPython Data Model are covered throughout this book.\nThe “Data Model” chapter of The Python Language Reference is the canonical source\nPython Data Model is one example.\nChapter 1: The Python Data Model\nWhat the Python documentation calls the “Python Data Model,” most authors would\nsay is the “Python object model.” Martelli, Ravenscroft, and Holden’s Python in a\nbooks covering the Python Data Model, but they refer to it as the “object model.” On\neral in a specific computer programming language.” This is what the Python Data\nfavors that term when referring to the Python object model, and because it is the title\nof the chapter of The Python Language Reference most relevant to our discussions.\nmention it because the term metaobject protocol is useful to think about the Python\neasier to implement in a dynamic language like Python, and some frameworks do it.\nChapter 1: The Python Data Model\nAn Array of Sequences\nof sequences, built-in tuple and mapping types, structure by indentation, strong\nPython inherited from ABC the uniform handling of sequences.\nUnderstanding the variety of sequences available in Python saves us from reinventing\nport and leverage existing and future sequence types.\niar list to the str and bytes types added in Python 3.\nsequences appear in Chapter 4.\nAlso, the idea here is to cover sequence types that are\nCreating your own sequence types is the subject of Chapter 12.\n• List comprehensions and the basics of generator expressions\n• Specialized sequence types, like arrays and queues\n• New diagram and description of the internals of sequences, contrasting contain‐\nThe standard library offers a rich selection of sequence types implemented in C:\nContainer sequences\nlist, tuple, and collections.deque.\nChapter 2: An Array of Sequences\nA container sequence holds references to the objects it contains, which may be of any\ntype, while a flat sequence stores the value of its contents in its own memory space,\nnot as distinct Python objects.\nPython object, possibly holding references to other Python objects, like that two-item\nlist.\nIn contrast, the Python array is a single object, holding a C language array of three\nEvery Python object in memory has a header with metadata.\nsimplest Python object, a float, has a value field and two metadata\nAnother way of grouping sequence types is by mutability:\nFor example, list, bytearray, array.array, and collections.deque.\nFigure 2-2 helps visualize how mutable sequences inherit all methods from immuta‐\nble sequences, and implement several additional methods.\nsequence types do not actually subclass the Sequence and MutableSequence abstract\n>>> issubclass(tuple, abc.Sequence)\nThey are helpful to extrapolate what you know about one sequence type to others.\nThe most fundamental sequence type is the list: a mutable container.\nChapter 2: An Array of Sequences\nA quick way to build a sequence is using a list comprehension (if the target is a list)\nFor brevity, many Python programmers refer to list comprehen‐\nBuild a list of Unicode code points from a string, using a listcomp\nAnybody who knows a little bit of Python can read Example 2-1.\nThe code in Example 2-1 is building up a list.\nIn Python 3, list comprehensions, generator expressions, and their siblings set and\nChapter 2: An Array of Sequences",
      "keywords": [
        "Python Data Model",
        "Python",
        "Python Data",
        "Data Model",
        "Python object model",
        "special methods",
        "Python object",
        "Python Language Reference",
        "sequences",
        "Model",
        "sequence types",
        "list",
        "methods",
        "special",
        "Data"
      ],
      "concepts": [
        "python",
        "pythonic",
        "sequence",
        "list",
        "abcs",
        "abc",
        "types",
        "typing",
        "operator",
        "operation"
      ],
      "similar_chapters": [
        {
          "book": "Fluent Python 2nd",
          "chapter": 1,
          "title": "",
          "score": 0.873,
          "base_score": 0.723,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 11,
          "title": "",
          "score": 0.768,
          "base_score": 0.618,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 21,
          "title": "",
          "score": 0.748,
          "base_score": 0.598,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 3,
          "title": "",
          "score": 0.743,
          "base_score": 0.593,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 4,
          "title": "",
          "score": 0.729,
          "base_score": 0.579,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "python",
          "model",
          "sequence",
          "data model",
          "sequences"
        ],
        "semantic": [],
        "merged": [
          "python",
          "model",
          "sequence",
          "data model",
          "sequences"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.5039485425779106,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:09.219890+00:00"
      }
    },
    {
      "chapter_number": 5,
      "title": "presents",
      "start_page": 62,
      "end_page": 88,
      "summary": "However, in a match/case\neach item in the passport tuple to the corresponding slot in the format string in the\nThose are two examples of tuple unpacking.\nabout unpacking not only tuples, but sequences and iterables in\nNow let’s consider the tuple class as an immutable variant of the list class.\nTuples as Immutable Lists\nThe Python interpreter and standard library make extensive use of tuples as immuta‐\nA tuple uses less memory than a list of the same length, and it allows Python\nWhen the last item in b is changed, b and a become different:\nTuples with mutable items can be a source of bugs.\nIf you want to determine explicitly if a tuple (or any object) has a fixed value, you can\nTuples Are Not Just Immutable Lists \nDespite this caveat, tuples are widely used as immutable lists.\n• To evaluate a tuple literal, the Python compiler generates bytecode for a tuple\n• The references to the items in a tuple are stored in an array in the tuple struct,\nComparing Tuple and List Methods\nWhen using a tuple as an immutable variation of list, it is good to know how similar\nAs you can see in Table 2-1, tuple supports all list methods that do\nMethods and attributes found in list or tuple (methods implemented by object\nlist\ntuple  \nlist\nInsert element e before the item at position p\nSort items in place with optional keyword arguments key and\nNow let’s switch to an important subject for idiomatic Python programming: tuple,\nlist, and iterable unpacking.\nUnpacking Sequences and Iterables\nfrom an iterable to a tuple of variables, as you can see in this example:\nUnpacking Sequences and Iterables \nThe preceding code shows another use of unpacking: allowing functions to return\nAs another example, the\nAnother way of using just some of the items when unpacking is to use the * syntax, as\nUnpacking with * in Function Calls and Sequence Literals\niterable unpacking, best summarized in “What’s New In Python 3.5”.\nThe * can also be used when defining list, tuple, or set literals, as shown in these\nexamples from “What’s New In Python 3.5”:\nFinally, a powerful feature of tuple unpacking is that it works with nested structures.\nThe target of an unpacking can use nesting, e.g., (a, b, (c, d)).\nExample 2-8.\nUnpacking nested tuples to access the longitude\nUnpacking Sequences and Iterables \nBy assigning the last field to a nested tuple, we unpack the coordinates.\nThe target of an unpacking assignment can also be a list, but good use cases are rare.\nsingle-item tuples must be written with a trailing comma.\nNow let’s study pattern matching, which supports even more powerful ways to\nunpack sequences.\nPattern Matching with Sequences\nThe most visible new feature in Python 3.10 is pattern matching with the match/case\ntern matching over different chapters, depending on the pattern\n“Pattern Matching in lis.py: A Case Study” on page 669.\nHere is a first example of match/case handling sequences.\nExample 2-9.\nThe expression after the match keyword is the subject.\nPython will try to match to the patterns in each case clause.\nThis pattern matches any subject that is a sequence with three items.\nThis matches any subject with two items, the first being 'NECK'.\nThis will match a subject with three items starting with 'LED'.\nitems does not match, Python proceeds to the next case.\nAnother sequence pattern starting with 'LED', now with five items—including\nPattern Matching with Sequences \nOn the surface, match/case may look like the switch/case statement from the C lan‐\nten with match/case.\nExample 2-10.\nThe subject of this match is record— i.e., each of the tuples in metro_areas.\nIn general, a sequence pattern matches the subject if:\n1. The subject is a sequence and;\n2. The subject and the pattern have the same number of items and;\n3. Each corresponding item matches, including nested items.\nFor example, the pattern [name, _, _, (lat, lon)] in Example 2-10 matches a\nsequence with four items, and the last item must be a two-item sequence.\nSequence patterns may be written as tuples or lists or any combination of nested\ntuples and lists, but it makes no difference which syntax you use: in a sequence pat‐\nlist with a nested 2-tuple just to avoid repeating brackets or parentheses in\nExample 2-10.\nA sequence pattern can match instances of most actual or virtual subclasses of collec\nces in the context of match/case.\nA match subject of one of those\nsequences could cause bugs due to unintended matches.\nwant to treat an object of those types as a sequence subject, convert\nFor example, see tuple(phone) in the\nmatch tuple(phone):\nIn the standard library, these types are compatible with sequence patterns:\nUnlike unpacking, patterns don’t destructure iterables that are not sequences (such as\nThe _ symbol is special in patterns: it matches any single item in that position, but it\nis never bound to the value of the matched item.\nPattern Matching with Sequences \nFor example, the\nfollowing pattern matches the same nested sequence structure as the previous exam‐\nple, but the first item must be an instance of str, and both items in the 2-tuple must\ncheck: the preceding pattern will match a four-item sequence in\nUsing arbitrary classes in patterns is covered in “Pattern Matching\nOn the other hand, if we want to match any subject sequence starting with a str, and\nThe *_ matches any number of items, without binding them to a variable.\n*extra instead of *_ would bind the items to extra as a list with 0 or more items.\nThe optional guard clause starting with if is evaluated only if the pattern matches,\nand can reference variables bound in the pattern, as in Example 2-10:\nThe nested block with the print statement runs only if the pattern matches and the\nmatch with a single case can make code simpler.\nsum has a collection of case/match examples, including one that\nThe next example shows how pattern match‐\nPattern Matching Sequences in an Interpreter\nto showcase pattern matching.\ncode—which uses if/elif and unpacking—with a rewrite using match/case.\nparenthesized expressions and returns Python lists.\nHere are two examples:\nThe second example is defining a function\nSee “Pattern Matching in lis.py: A Case Study” on page 669 to learn more about how\nonly the sequence patterns.\nPattern Matching with Sequences \nExample 2-11.\nMatching patterns without match/case\nNote how each elif clause checks the first item of the list, and then unpacks the list,\npattern matching, but he wrote that code originally for Python 2 (though it now\nUsing match/case in Python ≥ 3.10, we can refactor evaluate as shown in\nExample 2-12.\nExample 2-12.\nPattern matching with match/case—requires Python ≥ 3.10\nmatch exp:\ncase ['define', Symbol() as name, value_exp]:  \nMatch if subject is a two-item sequence starting with 'quote'.\nMatch if subject is a four-item sequence starting with 'if'.\nMatch if subject is a sequence of three or more items starting with 'lambda'.\nMatch if subject is a three-item sequence starting with 'define', followed by an\nIn this example, if exp doesn’t match\nWith pattern matching, we can add more checks and still keep it readable.\nexample, in the 'define' pattern, the original code does not ensure that name is an\nHowever, that matches any value in the parms position, including the first 'x' in this\nparameters for the function, and it must be a list even if it has only one element.\nmay also be an empty list, if the function takes no parameters—like Python’s ran\nIn Example 2-12, I made the 'lambda' pattern safer using a nested sequence pattern:\nPattern Matching with Sequences \nIn a sequence pattern, * can appear only once per sequence.\nThe define keyword is followed by a list with the name of the new function and zero\nAfter that list comes the function body with one or more\nI’d place that case after the other define case in Example 2-12.\nthe define cases is irrelevant in this example because no subject can match both of\nthese patterns: the second element must be a Symbol in the original define case, but\nit must be a sequence starting with a Symbol in the define shortcut for function\ntax without the help of pattern matching in Example 2-11.\nPattern matching is an example of declarative programming: the code describes\nSequence pattern\nI hope this refactoring of Norvig’s evaluate with pattern matching convinced you\nthat match/case can make your code more readable and safer.\nWe’ll see more of lis.py in “Pattern Matching in lis.py: A Case\nStudy” on page 669, when we’ll review the complete match/case\nThis concludes our first tour of unpacking, destructuring, and pattern matching with\nsequences.\nEvery Python programmer knows that sequences can be sliced using the s[a:b] syn‐\nA common feature of list, tuple, str, and all sequence types in Python is the sup‐\nWhy Slices and Ranges Exclude the Last Item\nThe Pythonic convention of excluding the last item in slices and ranges works well\nrange(3) and my_list[:3] both produce three items.\nFor example:\nstride or step c, causing the resulting slice to skip items.\ntive, returning items in reverse.\noperator, and it produces a slice object: slice(a, b, c).\nmenting your own sequence types, knowing about slice objects is useful because it\nExample 2-13.\n>>> ITEM_TOTAL = slice(55, None)\nExample 2-22\nExcept for memoryview, the built-in sequence types in Python are one-dimensional, so\nthey support only one index or slice, and not a tuple of them.6\nas a shortcut when slicing arrays of many dimensions; for example,\nsyntactic features exist to support user-defined types and extensions such as NumPy. Slices are not just useful to extract information from sequences; they can also be used\n>>> l = list(range(10))\nble object, even if it has just one item.\nUsing + and * with Sequences\nPython programmers expect that sequences support + and *.\nsequence of that same type is created as result of the concatenation.\nAgain, a new sequence is created:\nBeware of expressions like a * n when a is a sequence containing\nFor example,\nThe best way of doing so is with a list comprehension, as in Example 2-14.\nExample 2-14.\nCreate a list of three lists of three items each.\nExample 2-15.\nUsing + and * with Sequences \nOn the other hand, the list comprehension from Example 2-14 is equivalent to this\nIn the case of mutable sequences (e.g.,\nlist, bytearray, array.array), a will be changed in place (i.e., the effect will be sim‐\nAfter multiplication, the list is the same object, with new items appended.\nUsing + and * with Sequences \nappending new items, the interpreter has to copy the whole target sequence to create\nExample 2-16.\nB. TypeError is raised with the message 'tuple' object does not support item\nExample 2-17.\nTypeError: 'tuple' object does not support item assignment\nof the tuple t from Example 2-17.\nExample 2-18.\nUsing + and * with Sequences \nThis succeeds if TOS refers to a mutable object (it’s a list, in\nExample 2-17).\nThis fails if s is immutable (the t tuple in Example 2-17).\n• Avoid putting mutable items in tuples.\nsubject to another essential operation with sequences: sorting.\nThe list.sort method sorts a list in place—that is, without making a copy.\nNone to remind us that it changes the receiver11 and does not create a new list.\nan important Python API convention: functions or methods that change an object in\ndom.shuffle(s) function, which shuffles the mutable sequence s in place, and\nmethods that return new objects (e.g., all str methods) can be cas‐\nIn contrast, the built-in function sorted creates a new list and returns it.\nany iterable object as an argument, including immutable sequences and generators\nIf True, the items are returned in descending order (i.e., by reversing the compar‐\nA one-argument function that will be applied to each item to produce its sorting\nFor example, when sorting a list of strings, key=str.lower can be used\nThe default is the identity function (i.e., the items themselves are\nHere are a few examples to clarify the use of these functions and keyword arguments.\nThe examples also demonstrate that Python’s sorting algorithm is stable (i.e., it pre‐\nThis produces a new list of strings sorted alphabetically.13\nA new list of strings, now sorted by length.\nThis sorts the list in place, and returns None (which the console omits).\njust lists or tuples.\nPython programmers sometimes overuse the list type because it\nFor example, if you are processing large lists of\ndevoted to alternatives to lists and tuples.",
      "keywords": [
        "Pattern Matching",
        "Sequences",
        "Python",
        "list",
        "Pattern",
        "sequence pattern",
        "tuple",
        "case",
        "items",
        "Sequences list tuple",
        "Pattern Matching Sequences",
        "match",
        "unpacking",
        "Unpacking Sequences",
        "Array of Sequences"
      ],
      "concepts": [
        "python",
        "pythonic",
        "cases",
        "sequences",
        "list",
        "examples",
        "match",
        "matches",
        "slices",
        "sliced"
      ],
      "similar_chapters": [
        {
          "book": "Fluent Python 2nd",
          "chapter": 13,
          "title": "",
          "score": 0.653,
          "base_score": 0.503,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 118,
          "title": "",
          "score": 0.65,
          "base_score": 0.5,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 4,
          "title": "",
          "score": 0.63,
          "base_score": 0.48,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 3,
          "title": "",
          "score": 0.628,
          "base_score": 0.478,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 11,
          "title": "",
          "score": 0.606,
          "base_score": 0.456,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "match",
          "pattern",
          "sequence",
          "tuple",
          "items"
        ],
        "semantic": [],
        "merged": [
          "match",
          "pattern",
          "sequence",
          "tuple",
          "items"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.36674660671166376,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:09.219920+00:00"
      }
    },
    {
      "chapter_number": 3,
      "title": "For the remainder of this chapter, we discuss mutable sequence types that can replace",
      "start_page": 89,
      "end_page": 188,
      "summary": "The list type is flexible and easy to use, but depending on specific requirements,\nFor example, an array saves a lot of memory when you need\nadding and removing items from opposite ends of a list, it’s good to know that a\nlection (e.g., item in my_collection), consider using a set for\nSets\nbut they are not sequences because the ordering of set items is\nIf a list only contains numbers, an array.array is a more efficient replacement.\nArrays support all mutable sequence operations (including .pop, .insert,\nA Python array is as lean as a C array.\ntype used to store each item in the array.\narray('b'), then each item will be stored in a single byte and interpreted as an inte‐\nAnd Python will not\nlet you put any number that does not match the type for the array.\nExample 2-19 shows creating, saving, and loading an array of 10 million floating-\n>>> floats = array('d', (random() for i in range(10**7)))  \n>>> floats2 = array('d')  \nImport the array type.\nCreate an array of double-precision floats (typecode 'd') from any iterable object\nimages, Python has the bytes and bytearray types discussed in Chapter 4.\nMethods and attributes found in list or array (deprecated array methods and\nAppend items from byte sequence interpreted as packed machine values\nAppend n items from binary file f interpreted as packed machine values\nInsert element e before the item at position p\nLength in bytes of each array item\nRemove and return item at position p (default: last)\nSort items in place with optional keyword arguments key and\nReturn items as packed machine values in a bytes object\nReturn items as numeric objects in a list\nOne-character string identifying the C type of the items\nAs of Python 3.10, the array type does not have an in-place sort\nmethod like list.sort().\nIf you need to sort an array, use the\nTo keep a sorted array sorted while adding items to it, use the\nThe built-in memoryview class is a shared-memory sequence type that lets you handle\nA memoryview is essentially a generalized NumPy array structure in Python itself\nExample 2-20 shows how to create alternate views on the same array of 6 bytes, to\nhow to change a single byte of an item in an array of 16-bit integers.\nChanging the value of a 16-bit integer array item by poking one of its\nmemv sees the same 5 items in the array.\nFor advanced array and matrix operations, NumPy is the reason why Python became\nImport NumPy, after installing (it’s not in the Python standard library).\nPython 3.3).\nLoad the data as a memory-mapped file into another array; this allows efficient\ntools such as the Pandas—which implements efficient array types that can hold non‐\nto a completely different set of replacements for the plain old list: queues.\nThe optional maxlen argument sets the maximum number of items allowed in\nAppending to a deque that is full (len(d) == d.maxlen) discards items from the\nTable 2-4 compares the methods that are specific to list and deque (removing those\nNote that deque implements most of the list methods, and adds a few that are spe‐\nMethods implemented in list or deque (those that are also implemented by\nInsert element e before the item at position p\nSort items in place with optional keyword arguments key and\nBesides deque, other Python standard library packages implement queues:\nan item from the queue, which is useful to throttle the number of live threads.\nPython sequences are often categorized as mutable or immutable, but it is also useful\nUnfortunately, Python has no foolproof immutable container sequence type: even\n“immutable” tuples can have their values changed when they contain mutable items\nmany contexts, and some of its use cases appeared in Python 3.5 with PEP 448—\ninitialize lists of lists containing immutable items.\nBeyond lists and tuples, the Python standard library provides array.array.\nvince yourself or others that pattern matching is good for Python, read the 22-page\ngier’s open access book From Python to NumPy. Vectorized operations apply mathe‐\nPython.\nnice Pythonic class using a generator method, into a lean and mean function calling a\nTo learn how to use deque (and other collections), see the examples and practical rec‐\nPython that are not sequences, like dict and set.\nIntroductory Python texts emphasize that lists can contain objects of mixed types, but\nin practice that feature is not very useful: we put items in a list to process them later,\nwhich implies that all items should support at least some operation in common (i.e.,\nple, you can’t sort a list in Python 3 unless the items in it are comparable:\nUnlike lists, tuples often hold items of different types.\nThe optional key argument of list.sort, sorted, max, and min is a great idea.\nIt is also more efficient because the key\nBy the way, using key we can sort a mixed bag of numbers and number-like strings.\n>>> sorted(l, key=str)\nPython is basically dicts wrapped in loads of syntactic sugar.\nWe use dictionaries in all our Python programs.\nrectly because the dict type is a fundamental part of Python’s implementation.\n__builtins__.__dict__ stores all built-in types, objects, and functions.\nBecause of their crucial role, Python dicts are highly optimized—and continue to get\nHash tables are the engines behind Python’s high-performance dicts.\nOther built-in types based on hash tables are set and frozenset.\nIn particular, Python sets implement all the fundamental operations from set\n• Modern syntax to build and handle dicts and mappings, including enhanced\n• Common methods of mapping types\n• Special handling for missing keys\n• Variations of dict in the standard library\n• The set and frozenset types\n• Implications of hash tables in the behavior of sets and dictionaries\nMost changes in this second edition cover new features related to mapping types:\n• “Modern dict Syntax” on page 78 covers enhanced unpacking syntax and different\ndicts since Python 3.9.\nmatch/case, since Python 3.10.\ndifferences between dict and OrderedDict—considering that dict keeps the key\n• New sections on the view objects returned by dict.keys, dict.items, and\ndict.values: “Dictionary Views” on page 101 and “Set Operations on dict Views”\nThe underlying implementation of dict and set still relies on hash tables, but the\ndict code has two important optimizations that save memory and preserve the inser‐\ntion order of the keys in dict.\nuse in set, which is simpler to understand.\n• The memory optimization that preserves key insertion order\nin dict instances (since Python 3.6).\n• The key-sharing layout for dictionaries holding instance\ntion implemented in Python 3.3).\nOthers require Python 3.9 (like the | operator) or Python 3.10 (like match/\nSince Python 2.7, the syntax of listcomps and genexps was adapted to dict compre‐\ncomprehension) builds a dict instance by taking key:value pairs from any iterable.\nExample 3-1 shows the use of dict comprehensions to build two dictionaries from\nExamples of dict comprehensions\n{'Bangladesh': 880, 'Brazil': 55, 'China': 86, 'India': 91, 'Indonesia': 62,\n'Japan': 81, 'Nigeria': 234, 'Pakistan': 92, 'Russia': 7, 'United States': 1}\n{55: 'BRAZIL', 62: 'INDONESIA', 7: 'RUSSIA', 1: 'UNITED STATES'}\nAn iterable of key-value pairs like dial_codes can be passed directly to the dict\n…here we swap the pairs: country is the key, and code is the value.\nsee the value mapped to x in the example.\nPython 3.9 supports using | and |= to merge mappings.\nare also the set union operators.\nThe | operator creates a new mapping:\nTo update an existing mapping in place, use |=.\nA type implemented via Python/C API is also eligible if a specific\n“Motivation” section of PEP 584—Add Union Operators To dict\nThe match/case statement supports subjects that are mapping objects.\nmappings look like dict literals, but they can match instances of any actual or virtual\nhints in get_creators make it clear that it takes a dict and returns a list.\ndef get_creators(record: dict) -> list:\nMatch any mapping with 'type': 'book', 'api' :2, and an 'authors' key\nReturn the items in the sequence, as a new list.\nMatch any mapping with 'type': 'book', 'api' :1, and an 'author' key\nAny other mapping with 'type': 'book' is invalid, raise ValueError.\nMatch any mapping with 'type': 'movie' and a 'director' key mapped to a\n• Have case clauses to handle invalid records of a specific type (e.g., 'book'), as\nThere is no need to use **extra to match extra key-value pairs, but if you want to\nother mappings where key lookups via __getitem__ (i.e., d[key]) succeed because\nceeds only if the subject already has the required keys at the top of the match\npattern matching always uses the d.get(key, sentinel) method\nStandard API of Mapping Types\ndescribing the interfaces of dict and similar types.\n>>> my_dict = {}\n>>> isinstance(my_dict, abc.Mapping)\nStandard API of Mapping Types \n2 The Python Glossary entry for “hashable” uses the term “hash value” instead of hash code.\nbecause that is a concept often discussed in the context of mappings, where items are made of keys and val‐\nwhether a function argument is of the concrete dict type, because\nthen alternative mapping types can be used.\nTo implement a custom mapping, it’s easier to extend collections.UserDict, or to\nsulate the basic dict in their implementation, which in turn is built on a hash table.\nTherefore, they all share the limitation that the keys must be hashable (the values\nneed not be hashable, only the keys).\nThe hash code of an object may be different depending on the version of Python, the\nUser-defined types are hashable by default because their hash code is their id(), and\nNow let’s review the API of the most commonly used mapping types in Python: dict,\nStandard API of Mapping Types \nMethods of the mapping types dict, collections.defaultdict, and collec\ndict\ndel d[k]—remove item with\nkey k\nNew mapping from keys in iterable,\nGet item with key k, return\nd[k]—get item with key k\nd.items()\nGet iterator over keys\nd.keys()\nGet view over keys\nlen(d)—number of items\nd.__missing__(k)\nfind the key\ndict merging d1 and d2 (Python\nd1 with d2 (Python ≥ 3.9)\nitem as (key, value) b\niterator for keys from last to first\nreversed union operator (Python ≥\ndict\nIf k in d, return d[k]; else set\nd[k] = default and return it\nUpdate d with items from mapping\nor iterable of (key, value) pairs\nd.values()\na default_factory is not a method, but a callable attribute set by the end user when a defaultdict is instantiated.\nsupported in dict or defaultdict as recently as Python 3.10b3.\nThe way d.update(m) handles its first argument m is a prime example of duck typing:\nit first checks whether m has a keys method and, if it does, assumes it is a mapping.\nOtherwise, update() falls back to iterating over m, assuming its items are (key,\nThe constructor for most Python mappings uses the logic of update()\niterable object producing (key, value) pairs.\nwe need to update the value of an item in place.\nIn line with Python’s fail-fast philosophy, dict access with d[k] raises an error when\nk is not an existing key.\nto d[k] whenever a default value is more convenient than handling KeyError.\nConsider a script to index text, producing a mapping where each key is a word, and\nthe value is a list of positions where that word occurs, as shown in Example 3-3.\nStandard API of Mapping Types \ndemonstration of dict.setdefault, as shown in our Example 3-5.\nExample 3-4 is a suboptimal script written to show one case where dict.get is not\nthe best way to handle a missing key.\nindex0.py uses dict.get to fetch and update a list of word occurrences\n\"\"\"Build an index mapping word -> list of occurrences\"\"\"\nfor word in sorted(index, key=str.upper):      \n5 This is an example of using a method as a first-class function, the subject of Chapter 7.\nIn the key= argument of sorted, I am not calling str.upper, just passing a refer‐\nence to that method so the sorted function can use it to normalize the words for\nindex.py uses dict.setdefault to fetch and update a list of word\n\"\"\"Build an index mapping word -> list of occurrences\"\"\"\nfor word in sorted(index, key=str.upper):\nGet the list of occurrences for word, or set it to [] if not found; setdefault\nmy_dict.setdefault(key, []).append(new_value)\nif key not in my_dict:\nmy_dict[key] = []\nmy_dict[key].append(new_value)\nStandard API of Mapping Types \nA related issue, handling missing keys on any lookup (and not only when inserting),\nAutomatic Handling of Missing Keys\nSometimes it is convenient to have mappings that return some made-up value when a\nmissing key is searched.\nping type and add a __missing__ method.\ndefaultdict: Another Take on Missing Keys\nA collections.defaultdict instance creates items with a default value on demand\nwhenever a missing key is searched using d[k] syntax.\nExample 3-6 uses default\ndict to provide another elegant solution to the word index task from Example 3-5.\nproduce a default value whenever __getitem__ is passed a nonexistent key argument.\nFor example, given a defaultdict created as dd = defaultdict(list), if 'new-key'\n2. Inserts the list into dd using 'new-key' as key.\n\"\"\"Build an index mapping word -> list of occurrences\"\"\"\nfor word in sorted(index, key=str.upper):\nmissing value, which in this case is an empty list that is then assigned to\nIf no default_factory is provided, the usual KeyError is raised for missing keys.\nFor example, if dd is a defaultdict, and k is a missing key,\nUnderlying the way mappings deal with missing keys is the aptly named __missing__\nThis method is not defined in the base dict class, but dict is aware of it: if\nyou subclass dict and provide a __missing__ method, the standard dict.__geti\nSuppose you’d like a mapping where keys are converted to str when looked up.\nExample 3-7 shows how such a mapping would work.\nAutomatic Handling of Missing Keys \nTests for item retrieval using `d[key]` notation::\nTests for item retrieval using `d.get(key)` notation::\nA better way to create a user-defined mapping type is to subclass\nHere we subclass dict just to show that __miss\ning__ is supported by the built-in dict.__getitem__ method.\nclass StrKeyDict0(dict):  \ndef __missing__(self, key):\nreturn self[str(key)]  \nreturn self[key]  \nThe get method delegates to __getitem__ by using the self[key] notation; that\nSearch for unmodified key (the instance may contain non-str keys), then for a\nstr built from the key.\nWithout that test, our __missing__ method would work OK for any key k—str or\nIn the last line of __missing__, self[str(key)]\nwould call __getitem__, passing that str key, which in turn would call __missing__\nThe __contains__ method is also needed for consistent behavior in this example,\nbecause the operation k in d calls it, but the method inherited from dict does not\n__contains__: we do not check for the key in the usual Pythonic way—k in my_dict\nA search like k in my_dict.keys() is efficient in Python 3 even for very large map‐\npings because dict.keys() returns a view, which is similar to a set, as we’ll see in\n“Set Operations on dict Views” on page 110.\nthe .keys method.\nAutomatic Handling of Missing Keys \nI had a specific reason to use self.keys() in the __contains__ method in\nA subclass of dict implementing only __missing__ and no other method.\ncase, __missing__ may be called only on d[k], which will use the __getitem__\nA minimal subclass of abc.Mapping implementing __missing__ and the required\nabc.Mapping subclass with __getitem__ calling __missing__\nA minimal subclass of abc.Mapping implementing __missing__ and the required\nabstract methods, including an implementation of __getitem__ that calls __miss\nThe __missing__ method is triggered in this class for missing key lookups\nimplements __getitem__, get, and __contains__, then you can make those methods\nshow that you must be careful when subclassing standard library mappings to use\nSo far we have covered the dict and defaultdict mapping types, but the standard\nIn this section is an overview of mapping types included in the standard library,\nNow that the built-in dict also keeps the keys ordered since Python 3.6, the most\n• The regular dict was designed to be very good at mapping operations.\nthan dict.\nA ChainMap instance holds a list of mappings that can be searched as one.\nand succeeds as soon as the key is found in one of those mappings.\n>>> d1 = dict(a=1, b=3)\n>>> d2 = dict(a=2, b=4, c=6)\nA mapping that holds an integer count for each key.\nUpdating an existing key adds to\ntallies, and other useful methods such as most_common([n]), which returns an\nordered list of tuples with the n most common items and their counts; see the docu‐\nCounter({'a': 10, 'z': 3, 'b': 2, 'r': 2, 'c': 1, 'd': 1})\nNote that the 'b' and 'r' keys are tied in third place, but ct.most_common(3) shows\nTo use collections.Counter as a multiset, pretend each key is an element in the set,\nand the count is the number of occurrences of that element in the set.\nof string keys to Python objects serialized in the pickle binary format.\n• Keys and values are saved whenever a new value is assigned to a key.\nPython’s pickle is easy to use in the simplest cases, but has several\nIt’s better to create a new mapping type by extending collections.UserDict rather\nthan dict.\nto make sure that any keys added to the mapping are stored as str.\n7 The exact problem with subclassing dict and other built-ins is covered in “Subclassing Built-In Types Is\nNote that UserDict does not inherit from dict, but uses composition: it has an inter‐\nnal dict instance, called data, which holds the actual items.\n(Example 3-8), but it does more: it stores all keys as str, avoiding unpleasant sur‐\nprises if the instance is built or updated with data containing nonstring keys.\nStrKeyDict always converts nonstring keys to str on insertion, update,\ndef __missing__(self, key):  \nreturn self[str(key)]\nreturn str(key) in self.data  \ndef __setitem__(self, key, item):\nself.data[str(key)] = item   \nthe instance from other mappings, from iterables of (key, value) pairs, and\nBecause it uses self[key] = value to add items, it ends up\nimplemented exactly like StrKeyDict0.get (see the Python source code).\nDict and preserves the keys as they are provided, before the trans‐\nalone module (03-dict-set/transformdict.py in the Fluent Python\nThe mapping types provided by the standard library are all mutable, but you may\ndict\nThe dict instance methods .keys(), .values(), and .items() return instances of\nclasses called dict_keys, dict_values, and dict_items, respectively.\nods that returned lists duplicating data already in the target dict, and they also\nExample 3-11 shows some basic operations supported by all dictionary views.\nThe .values() method returns a view of the values in a dict\n>>> d = dict(a=10, b=20, c=30)\ndict_values([10, 20, 30])  \nTypeError: 'dict_values' object is not subscriptable\n>>> d['z'] = 99\ndict_values([10, 20, 30, 99])\nThe classes dict_keys, dict_values, and dict_items are internal: they are not avail‐\nto one of them, you can’t use it to create a view from scratch in Python code:\nTypeError: cannot create 'dict_values' instances\nThe dict_values class is the simplest dictionary view—it implements only the\nods, dict_keys and dict_items implement several set methods, almost as many as\nAfter we cover sets, we’ll have more to say about dict_keys and\ndict_items in “Set Operations on dict Views” on page 110.\nThe hash table implementation of Python’s dict is very efficient, but it’s important to\n• Keys must be hashable objects.\n• Item access by key is very fast.\nA dict may have millions of keys, but Python can\nlocate a key directly by computing the hash code of the key and deriving an index\n• Key ordering is preserved as a side effect of a more compact memory layout for\narray of pointers to the items.8 Compared to that, a hash table needs to store\nmore data per entry, and Python needs to keep at least one-third of the hash table\nin Python 3.3, instances of a class can share a common hash table, stored with the\nThat common hash table is shared by the __dict__ of each new instance that\nEach instance __dict__ can then hold only its own attribute values as a sim‐\ncreate a new hash table just for the __dict__ of that one instance (which was the\nSets are not new in Python, but are still somewhat underused.\nThe set type and its\nIn this book, I use the word “set” to refer both to set and frozen\nset.\nWhen talking specifically about the set class, I use constant\nA set is a collection of unique objects.\n>>> list(set(l))\nfirst occurrence of each item, you can now use a plain dict to do it,\n>>> dict.fromkeys(l).keys()\ndict_keys(['spam', 'eggs', 'bacon'])\n>>> list(dict.fromkeys(l).keys())\nSet elements must be hashable.\nThe set type is not hashable, so you can’t build a set\nIn addition to enforcing uniqueness, the set types implement many set operations as\ninfix operators, so, given two sets a and b, a | b returns their union, a & b computes\nof set operations can reduce both the line count and the execution time of Python\nThanks to set intersection (the & operator) you can code that\nCount occurrences of needles in a haystack, both of type set\nExample 3-12 requires that both be sets.\neither the needles or the haystack is already a set, the alternatives in Example 3-14\nset and frozenset built-in types provide a rich API to create new sets or, in the case\nDon’t forget that to create an empty set, you should use the con‐\nIn Python 3, the standard string representation of sets always uses the {…} notation,\nexcept for the empty set:\n<class 'set'>\nset()\nous, import the dis function from the dis module and use it to disassemble the bytecodes for a set literal—\nPython has to look up the set name to fetch the constructor, then build a list, and\nPython runs a specialized BUILD_SET bytecode.10\nSet comprehensions (setcomps) were added way back in Python 2.7, together with the\nBuild set of characters with codes from 32 to 255 that have the word 'SIGN' in\nThe set and frozenset types are both implemented with a hash table.\n• Set elements must be hashable objects.\nA set may have millions of elements, but an\n• Sets have a significant memory overhead, compared to a low-level array pointers\n• Adding elements to a set may change the order of existing elements.\nSet Operations\nsets.\nTable 3-2 shows the math set operators that have corresponding operators or meth‐\nthe target set (e.g., &=, difference_update, etc.).\nexample, to produce the union of four collections, a, b, c, and d,\nyou can call a.union(b, c, d), where a must be a set, but b, c,\nand d can be iterables of any type that produce hashable items.\nyou need to create a new set with the union of four iterables,\ninstead of updating an existing set, you can write {*a, *b, *c,\n*d} since Python 3.5 thanks to PEP 448—Additional Unpacking\nMathematical set operations: these methods either produce a new set or update\nPython\nsets built from iterables it, etc.\nUnion of s and all sets built from iterables\nPython\ns updated with union of s and all sets built\nall sets built from iterables it, etc.\nand all sets built from iterables it, etc.\nTable 3-3 lists set predicates: operators and methods that return True or False.\nSet comparison operators and methods that return a bool\nPython operator\ns is a subset of the z set\ns is a proper subset of the z set\ns is a superset of the z set\ns is a proper superset of the z set\nIn addition to the operators and methods derived from math set theory, the set types\nimplement other methods of practical use, summarized in Table 3-4.\nAdditional set methods\nset\nSet Operations on dict Views\nTable 3-5 shows that the view objects returned by the dict methods .keys()\nMethods implemented by frozenset, dict_keys, and dict_items\nfrozenset dict_keys\ndict_items\nfrozenset dict_keys\ndict_items\nIn particular, dict_keys and dict_items implement the special methods to support\nthe powerful set operators & (intersection), | (union), - (difference), and ^ (symmet‐\nFor example, using & is easy to get the keys that appear in two dictionaries:\n>>> d1 = dict(a=1, b=2, c=3, d=4)\n>>> d2 = dict(b=20, d=40, e=50)\n>>> d1.keys() & d2.keys()\nNote that the return value of & is a set.\nEven better: the set operators in dictionary\n>>> d1.keys() & s\n>>> d1.keys() | s\n{'a', 'c', 'b', 'd', 'i', 'e'}\nA dict_items view only works as a set if all values in the dict are\nAttempting set operations on a dict_items view with an\nOn the other hand, a dict_keys view can always be used as a set,\nUsing set operators with views will save a lot of loops and ifs when inspecting the\nLet Python’s efficient implementation in C\nSet Operations on dict Views \nBeyond the basic dict, the standard library offers handy, ready-to-use specialized\nWith the new dict implementation, OrderedDict is not as useful as before,\ncific characteristics that dict doesn’t have, such as taking into account key ordering\nTwo powerful methods available in most mappings are setdefault and update.\nsetdefault method can update items holding mutable values—for example, in a\ndict of list values—avoiding a second search for the same key.\nallows bulk insertion or overwriting of items from any other mapping, from iterables\nproviding (key, value) pairs, and from keyword arguments.\nalso use update internally, allowing instances to be initialized from mappings, itera‐\nSince Python 3.9, we can also use the |= operator to\nupdate a mapping, and the | operator to create a new one from the union of two\nA clever hook in the mapping API is the __missing__ method, which lets you cus‐\ntomize what happens when a key is not found when using the d[k] syntax that\nThe collections.abc module provides the Mapping and MutableMapping abstract\nbase classes as standard interfaces, useful for runtime type checking.\nProxyType from the types module creates an immutable façade for a mapping\nThere are also ABCs for Set and\nhead of the Python 2 .keys(), .values(), and .items() methods that built lists\nIn addition, the dict_keys and\ndict_items classes support the most useful operators and methods of frozenset.\nincludes examples and practical recipes with several mapping types.\nThe Python\nwho wants to create a new mapping type or grok the logic of the existing ones.\nfact that some tools and libraries assume the ordering of dict keys is irrelevant—his\nPEP 3106—Revamping dict.keys(), .values() and .items() is where Guido van Rossum",
      "keywords": [
        "Python",
        "dict",
        "key",
        "Sets",
        "items",
        "array",
        "keys",
        "mapping",
        "mapping types",
        "List",
        "Python standard library",
        "type",
        "missing",
        "missing keys",
        "Set Operations"
      ],
      "concepts": [
        "python",
        "pythonic",
        "key",
        "keys",
        "examples",
        "sets",
        "mappings",
        "map",
        "type",
        "typing"
      ],
      "similar_chapters": [
        {
          "book": "Fluent Python 2nd",
          "chapter": 13,
          "title": "",
          "score": 0.743,
          "base_score": 0.593,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 4,
          "title": "",
          "score": 0.712,
          "base_score": 0.562,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 5,
          "title": "",
          "score": 0.628,
          "base_score": 0.478,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 11,
          "title": "",
          "score": 0.598,
          "base_score": 0.448,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 6,
          "title": "",
          "score": 0.571,
          "base_score": 0.421,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "key",
          "dict",
          "set",
          "keys",
          "mapping"
        ],
        "semantic": [],
        "merged": [
          "key",
          "dict",
          "set",
          "keys",
          "mapping"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.3687645666922079,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:09.219964+00:00"
      }
    },
    {
      "chapter_number": 8,
      "title": "and more advanced",
      "start_page": 203,
      "end_page": 230,
      "summary": "Every instance field must be annotated with a type.\nThe reference instance field is annotated with a type and a default value.\nClasses built by typing.NamedTuple don’t have any methods beyond those that col\nonly difference is the presence of the __annotations__ class attribute—which Python\ntake a brief look at them before resuming our exploration of data class builders.\nmost common types used to annotate fields of data classes.\n>>> class Coordinate(typing.NamedTuple):\nIf you type the code of Example 5-9 in a Python module, it will run and display a\nto create an instance must be of type float, but the assignment to trash uses a str\nBoth typing.NamedTuple and @dataclass use the syntax of variable annotations\nattributes in class statements.\nbut in the context of defining a data class, these types are more likely to be useful:\n• A concrete class, for example, str or FrenchDeck\n• A parameterized collection type, like list[int], tuple[str, float], etc.\nChapter 5: Data Class Builders\n• typing.Optional, for example, Optional[str]—to declare a field that can be a\nclass declaration, that value will become the default for that attribute if the corre‐\n__annotations__ dictionary that typing.NamedTuple and @dataclass then use to\nenhance the class.\nWe’ll start this exploration with a simple class in Example 5-10, so that we can later\nmeaning/demo_plain.py: a plain class with type hints\nclass DemoPlainClass:\nnamed a is created in the class.\nb is saved as an annotation, and also becomes a class attribute with value 1.1.\nc is just a plain old class attribute, not an annotation.\n{'a': <class 'int'>, 'b': <class 'float'>}\nAttributeError: type object 'DemoPlainClass' has no attribute 'a'\nrecord the type hints that appear in the source code—even in a plain class.\nIt doesn’t become a class attribute because no\nvalue is bound to it.6 The b and c are stored as class attributes because they are bound\nand o.c will retrieve the class attributes with values 1.1 and 'spam'—that’s just nor‐\nNow let’s examine a class built with typing.NamedTuple (Example 5-11), using the\nsame attributes and annotations as DemoPlainClass from Example 5-10.\nmeaning/demo_nt.py: a class built with typing.NamedTuple\nclass DemoNTClass(typing.NamedTuple):\na becomes an annotation and also an instance attribute.\nb is another annotation, and also becomes an instance attribute with default\nc is just a plain old class attribute; no annotation will refer to it.\n{'a': <class 'int'>, 'b': <class 'float'>}\nChapter 5: Data Class Builders\ning.NamedTuple creates a and b class attributes.\nThe c attribute is just a plain class\nThe a and b class attributes are descriptors—an advanced feature covered in Chap‐\nPython retrieves it from the class, as usual.\nInspecting a class decorated with dataclass\nmeaning/demo_dc.py: a class decorated with @dataclass\nclass DemoDataClass:\na becomes an annotation and also an instance attribute controlled by a\nb is another annotation, and also becomes an instance attribute with a descriptor\nc is just a plain old class attribute; no annotation will refer to it.\n{'a': <class 'int'>, 'b': <class 'float'>}\nAttributeError: type object 'DemoDataClass' has no attribute 'a'\nunless the class is frozen.\nBut b and c exist as class attributes, with b holding the\ndefault value for the b instance attribute, while c is just a class attribute that will not\nAgain, a and b are instance attributes, and c is a class attribute we get via the instance.\nChapter 5: Data Class Builders\nNow the dc instance has a c attribute—but that does not change the c class attribute.\ncan have their own attributes that don’t appear in the class.7\nclass.FrozenInstanceError—a subclass of AttributeError—when the user attempts to set or delete a field.\nProtects against accidental changes to the class instances.\nAllows sorting of instances of the data class.\nPEP 557—Data Classes has this to say about unsafe_hash:\nAlthough not recommended, you can force Data Classes to create a __hash__ method\nclasses.dataclass documentation.\nFurther customization of the generated data class can be done at a field level.\nClass attributes are often used as default attribute values for\ninstances, including in data classes.\nAnd @dataclass uses the default values in the\nChapter 5: Data Class Builders\ntype hints to generate parameters with defaults for __init__.\nclass rejects the class definition in Example 5-13.\ndataclass/club_wrong.py: this class raises ValueError\nclass ClubMember:\nclass ClubMember:\nValueError: mutable default <class 'list'> for field guests is not allowed:\nclass ClubMember:\nIn the guests field of Example 5-14, instead of a literal list, the default value is set by\ncalling the dataclasses.field function with default_factory=list.\nThe default_factory parameter lets you provide a function, class, or any other call‐\ninstance of the data class is created.\nits own list—instead of all instances sharing the same list from the class, which is\nIt’s good that @dataclass rejects class definitions with a list\nclass ClubMember:\nThe new syntax list[str] is a parameterized generic type: since Python 3.9, the list\nized list type hint in Python 3.8 or earlier, you must import the\nclass definitions.\nChapter 5: Data Class Builders\na dataclass._MISSING_TYPE is a sentinel value indicating the option was not provided.\nclass ClubMember:\nassigns them—or their default values, if missing—to the instance attributes that are\ninstance fields.\nCommon use cases for __post_init__ are validation and computing field values\nvalue for guests (in our case, the factory is the list class).\nChapter 5: Data Class Builders\nclass HackerClubMember(ClubMember):                         \ncls = self.__class__                                \nall_handles is a class attribute.\nhandle is an instance field of type str with an empty string as its default value;\nGet the class of the instance.\nTyped Class Attributes\nhackerclub.py:37: error: Need type annotation for \"all_handles\"\n(hint: \"all_handles: Set[<type>] = ...\")\nPython 3.9 so I can use set—and avoid importing Set from typing.\ntantly, if we add a type hint like set[…] to all_handles, @dataclass will find that\nannotation and make all_handles an instance field.\ncode a class variable with a type hint, we need to use a pseudotype named typ\nand also declare it a class attribute.\nall_handles is a class attribute of type set-of-str, with an empty set as its default\nTo code that annotation, we must import ClassVar from the typing module.\nThe @dataclass decorator doesn’t care about the types in the annotations, except in\ntwo cases, and this is one of them: if the type is ClassVar, an instance field will not be\nThe other case where the type of the field is relevant to @dataclass is when declaring\nSometimes you may need to pass arguments to __init__ that are not instance fields.\numentation is a data class that has a field initialized from a database, and the database\nclass C:\nChapter 5: Data Class Builders\nIt will not be set as an instance attribute, and the\ndataclasses.fields function will not list it.\nered all three data class builders in parallel.\nOften, classes built with @dataclass will have more fields than the very short exam‐\nclass example.\nThe standard defines 15 optional fields; the Resource class in Example 5-19 uses 8 of\ndataclass/resource.py: code for Resource, a class based on Dublin Core\nclass Resource:\nThis Enum will provide type-safe values for the Resource.type field.\nThe type field default is ResourceType.BOOK.\ndataclass/resource.py: code for Resource, a class based on Dublin Core\nChapter 5: Data Class Builders\nThis example uses dataclass.fields to get the names of the data class fields.\nimplemented in the Resource class from Example 5-19\ncls = self.__class__\nPython’s data class builders.\nData Class as a Code Smell\nWhether you implement a data class by writing all the code yourself or leveraging\nThese are classes that have fields, getting and setting methods for fields, and nothing\nmuch detail by other classes.\npost is very relevant to our discussion because he uses data class as one example of a\nData classes (classes with all data and no behavior) are\nthis class.\nsomething that really has class.\nChapter 5: Data Class Builders\nin the same code unit: a class.\nThat’s why Fowler’s refactorings to deal with a data class involve\nsense to have a data class with little or no behavior.\nData Class as Scaffolding\nWith time, the class should get its own methods,\ninstead of relying on methods of other classes to operate on its instances.\nData Class as Intermediate Representation\nA data class can be useful to build records about to be exported to JSON or some\nPython’s data class builders all provide a method or function to con‐\nIn this scenario, the data class instances should be handled as immutable objects—\nData Class as a Code Smell \nmatching with classes was too important to wait until Part II of the book.\nto know how to use classes than to define classes.\nPattern Matching Class Instances\nClass patterns are designed to match class instances by type and—optionally—by\nThe subject of a class pattern can be any class instance, not only instances\nof data classes.10\nThere are three variations of class patterns: simple, keyword, and positional.\nSimple Class Patterns\nWe’ve already seen an example with simple class patterns used as subpatterns in “Pat‐\nThe syntax for class patterns looks like a constructor invocation.\nclass pattern that matches float values without binding a variable (the case body can\nChapter 5: Data Class Builders\nIn those classes, the variable that looks like a constructor argument—e.g., the x in\nIf the class is not one of those nine blessed built-ins, then the argument-like variables\nrepresent patterns to be matched against attributes of an instance of that class.\nKeyword Class Patterns\nTo understand how to use keyword class patterns, consider the following City class\nCity class and a few instances\nclass City(typing.NamedTuple):\nPattern Matching Class Instances \nPositional class patterns are more convenient in some cases, but they require explicit\nPositional Class Patterns\nof Asian cities, using a positional class pattern:\nThe pattern City('Asia') matches any City instance where the first attribute value\nChapter 5: Data Class Builders\nWhat makes City or any class work with positional patterns is the presence of a spe‐\ncial class attribute named __match_args__, which the class builders in this chapter\nThis is the value of __match_args__ in the City class:\n__match_args__ for a class we’ll create without the help of a class builder.\nThe main topic of this chapter was the data class builders collections.namedtuple,\nclasses from descriptions provided as arguments to a factory function, or from class\nname, and providing a _fields class attribute listing the field names as a tuple of\nhow to extract instance data as a dict, how to get the names and default values of\nattributes in a class statement, using the notation introduced in Python 3.6 with\nplain class and in classes built by typing.NamedTuple and @dataclass.\ndefault_factory option of the dataclasses.field function.\nimportant in the context of data classes.\nin the same class.\nPython’s standard documentation for the data class builders we covered is very good,\nFor @dataclass in particular, most of PEP 557—Data Classes was copied into the\nWhere is it not appropriate to use Data Classes?\ndata classes in Python 3.7”.\nincludes Smith’s most important API decision: the use of a class decorator instead of\nChapter 5: Data Class Builders\nanother data class generator.\nRegarding data class as a code smell, the best source I found was Martin Fowler’s\nThe website Refactoring Guru also has a description of the data class code smell.\nstandard way to declare instance attributes in a class.\nThe second line lists the names of the instance attributes x and y.\nIf there were class\nPython has always offered an easy way to declare class attributes, if they have an ini‐\nBut instance attributes are much more common, and Python coders have\nfunctions or methods of other classes.\nFirst, when you use @dataclass, type hints are not optional.\nSecond, the PEP 526 syntax for annotating instance and class attributes reverses the\nclass block was a class attribute (methods are class attributes, too).\nand @dataclass, any attribute declared at the top level with a type hint becomes an\ninstance attribute:\nclass Spam:\nclass Spam:\nclass Spam:\nrepeat = 99  # class attribute!\nFinally, if you want to annotate that class attribute with a type, you can’t use regular\ntypes because then it will become an instance attribute.\nclass Spam:\nclass HackerClubMember:\nChapter 5: Data Class Builders\nprefix is a class attribute (as they always",
      "keywords": [
        "data class builders",
        "data class",
        "class attribute",
        "class builders",
        "data",
        "Type Hints",
        "type",
        "dataclass class",
        "Class patterns",
        "dataclass",
        "attribute",
        "dataclass class Spam",
        "instance",
        "data classes",
        "instance attribute"
      ],
      "concepts": [
        "classes",
        "type",
        "typing",
        "typed",
        "examples",
        "python",
        "handle",
        "handled",
        "instances",
        "attribute"
      ],
      "similar_chapters": [
        {
          "book": "Fluent Python 2nd",
          "chapter": 11,
          "title": "",
          "score": 0.714,
          "base_score": 0.564,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 1,
          "title": "",
          "score": 0.676,
          "base_score": 0.526,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 13,
          "title": "",
          "score": 0.661,
          "base_score": 0.511,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 14,
          "title": "",
          "score": 0.655,
          "base_score": 0.505,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 21,
          "title": "",
          "score": 0.654,
          "base_score": 0.504,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "class",
          "data class",
          "data",
          "dataclass",
          "attribute"
        ],
        "semantic": [],
        "merged": [
          "class",
          "data class",
          "data",
          "dataclass",
          "attribute"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.39040266065974544,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:09.219990+00:00"
      }
    },
    {
      "chapter_number": 6,
      "title": "Object References, Mutability,",
      "start_page": 231,
      "end_page": 269,
      "summary": "Object References, Mutability,\ndistinction between objects and their names.\nA name is not the object; a name is a\nWe then discuss the concepts of object identity, value, and aliasing.\nReferences and function parameters are our\nmutable arguments passed by clients of our functions.\nselection of tricks that Python plays with immutable objects.\nI added an example of using is to test for a sentinel object, and a warning about\nstanding of reference variables in object-oriented languages.\nnames attached to objects.\nVariables a and b hold references to the same list, not copies of the list\nChapter 6: Object References, Mutability, and Recycling\nattaches the label b to the object that already has the label a.\nables, it makes much more sense to say that the variable is assigned to an object, and\nAfter all, the object is created before the assignment.\nbind”: Python’s assignment statement x = … binds the x name to the object created\nAnd the object must exist before a name can be\nVariables are bound to objects only after the objects are created\nfirst: that’s where the object is created or retrieved.\nvariable on the left is bound to the object, like a label stuck to it.\nBecause variables are mere labels, nothing prevents an object from having several\ncharles and lewis refer to the same object\nChapter 6: Object References, Mutability, and Recycling\ncharles and lewis are bound to the same object; alex is bound to a sepa‐\nrate object of equal value.\nExample 6-4 implements and tests the alex object depicted in Figure 6-2.\nalex refers to an object that is a replica of the object assigned to charles.\nThe objects compare equal because of the __eq__ implementation in the dict\nBut they are distinct objects.\ntwo variables bound to the same object.\ncharles: these variables are bound to distinct objects.\nThe objects bound to alex and\nIn The Python Language Reference, “3.1.\nObjects, values and types” states:\nAn object’s identity never changes once it has been created; you may think of it as the\nobject’s address in memory.\nThe is operator compares the identity of two objects; the\nid() function returns an integer representing its identity.\nThe real meaning of an object’s ID is implementation dependent.\nreturns the memory address of the object, but it may be something else in another\nlabel, and it will never change during the life of the object.\nIn practice, we rarely use the id() function while programming.\nmost often done with the is operator, which compares the object IDs, so our code\npoint to separate objects.\nThe == operator compares the values of objects (the data they hold), while is com‐\nWhile programming, we often care more about values than object identities, so ==\nSentinel objects are another\nobject:\nChapter 6: Object References, Mutability, and Recycling\nEND_OF_DATA = object()\nThe __eq__ method inherited from object compares object IDs, so it\nmeaningful implementations that actually take into account the values of the object\nUsually we are more interested in object equality than identity.\nreferences to objects.2 If the referenced items are mutable, they may change even if\nnot extend to the referenced objects.\nof changes to a mutable object referenced in it.\nAlthough distinct objects, t1 and t2 compare equal, as expected.\nneed to copy an object.\nA copy is an equal object with a different ID.\nBut if an object\ncontains other objects, should the copy also duplicate the inner objects, or is it OK to\nThe easiest way to copy a list (or most built-in mutable collections) is to use the built-\nChapter 6: Object References, Mutability, and Recycling\nlist(l1) creates a copy of l1.\n…but refer to two different objects.\nFor lists and other mutable sequences, the shortcut l2 = l1[:] also makes a copy.\nIn Example 6-6, we create a shallow copy of a list containing another list and a tuple,\nand then make changes to see how they affect the referenced objects.\nFor a mutable object like the list referred by l2[1], the operator += changes the\nl1 and l2 are no longer the same object.\ninner list object [66, 55, 44] and tuple (7, 8, 9).\nThe output of Example 6-6 is Example 6-7, and the final state of the objects is depic‐\nChapter 6: Object References, Mutability, and Recycling\nFinal state of l1 and l2: they still share references to the same list object,\nDeep and Shallow Copies of Arbitrary Objects\nmake deep copies (i.e., duplicates that do not share references of embedded objects).\nThe copy module provides the deepcopy and copy functions that return deep and\nshallow copies of arbitrary objects.\nTo illustrate the use of copy() and deepcopy(), Example 6-8 defines a simple class,\nNow, in the interactive Example 6-9, we will create a bus object (bus1) and two\nlist object, because bus2 is a shallow copy of bus1.\nbus3 is a deep copy of bus1, so its passengers attribute refers to another list.\nObjects may\nThe deepcopy function remembers the objects already copied to handle cyclic refer‐\nChapter 6: Object References, Mutability, and Recycling\nFor example, objects may refer\nThe sharing of objects through aliases also explains how parameter passing works in\nPython, and the problem of using mutable types as parameter defaults.\nFunction Parameters as References\nmeans that each formal parameter of the function gets a copy of each reference in the\nThe result of this scheme is that a function may change any mutable object passed as\na parameter, but it cannot change the identity of those objects (i.e., it cannot alto‐\nExample 6-11 shows a simple function using\nAs we pass numbers, lists, and tuples to the function, the\nA function may change any mutable object it receives\nFunction Parameters as References \nAnother issue related to function parameters is the use of mutable values for defaults,\nOptional parameters with default values are a great feature of Python function defini‐\nyou should avoid mutable objects as default values for parameters.\ndefault list object, which is initially empty.\nChapter 6: Object References, Mutability, and Recycling\nwe are actually mutating the default list, which is an attribute of the function\nobject.\nbus1 starts with a two-passenger list.\nbus2 starts empty, so the default empty list is assigned to self.passengers.\nbus3 also starts empty, again the default list is assigned.\nThe problem: bus2.passengers and bus3.passengers refer to the same list.\nBut bus1.passengers is a distinct list.\nFunction Parameters as References \nthe default values become attributes of the function object.\na mutable object, and you change it, the change will affect every future call of the\nfunction.\nobject and see the ghost students haunting its __defaults__ attribute:\nChapter 6: Object References, Mutability, and Recycling\nFunction Parameters as References \nMake a copy of the passengers list, or convert it to a list if it’s not one.\nment object by simply assigning it to an instance variable in your\nChapter 6: Object References, Mutability, and Recycling\n—“Data Model” chapter of The Python Language Reference\nThe second surprising fact is that del deletes references, not objects.\ngarbage collector may discard an object from memory as an indirect result of del, if\nthe deleted variable was the last reference to the object.\ncause the number of references to an object to reach zero, causing its destruction.\nCreate object [1, 2] and bind a to it.\nBind b to the same [1, 2] object.\nRebinding b to a different object removes the last remaining reference to [1, 2].\nNow the garbage collector can discard that object.\nter of The Python Language Reference.\nEssentially, each object keeps count of how many references point to it.\nthat refcount reaches zero, the object is immediately destroyed: CPython calls the\n__del__ method on the object (if defined) and then frees the memory allocated to the\nobject.\ndetect groups of objects involved in reference cycles—which may be unreachable\nobject.\nTo demonstrate the end of an object’s life, Example 6-16 uses weakref.finalize to\nregister a callback function to be called when an object is destroyed.\nWatching the end of an object when no more references point to it\nThis function must not be a bound method of the object about to be destroyed or\nRegister the bye callback on the object referred by s1.\nThe .alive attribute is True before the finalize object is called.\nAs discussed, del did not delete the object, just the s1 reference to it.\nChapter 6: Object References, Mutability, and Recycling\nreturn value is the same object.” I thought I knew everything about tuples before writing this book.\nThe point of Example 6-16 is to make explicit that del does not delete objects, but\nYou may be wondering why the {1, 2, 3} object was destroyed in Example 6-16.\nAfter all, the s1 reference was passed to the finalize function, which must have held\nWeak references to an object do not\nobject from being garbage collected.\nreference to the same object.\nidentical immutable objects are the same or are copies.\nt1 and t2 are bound to the same object.\nobject, and not a copy at all, as Example 6-18 shows.5\nString literals may create shared objects\nt1 and t3 are equal, but not the same object.\nChapter 6: Object References, Mutability, and Recycling\n7 Actually the type of an object may be changed by merely assigning a different class to its __class__ attribute,\nEvery Python object has an identity, a type, and a value.\nOnly the value of an object\nIf two variables refer to immutable objects that have equal values (a == b is True), in\nobject, because the value of an immutable object does not change, with one excep‐\nlection holds references to mutable items, then its value may actually change when\nWhat never changes in an immutable collection are the identities of the objects\nhold hashable elements, and the value of hashable objects cannot ever change, by\nThe fact that variables hold references has many practical consequences in Python\n• Augmented assignment with += or *= creates new objects if the lefthand variable\nis bound to an immutable object, but may modify a mutable object in place.\n• Assigning a new value to an existing variable does not change the object previ‐\nent object.\nIf that variable was the last reference to the previous object, that object\nany mutable object received as an argument.\nexcept making local copies or using immutable objects (e.g., passing a tuple\n• Using mutable objects as default values for function parameters is dangerous\nIn CPython, objects are discarded as soon as the number of references to them rea‐\nIn some situations, it may be useful to hold a reference to an object that will not—by\nitself—keep an object alive.\nThe “Data Model” chapter of The Python Language Reference starts with a clear\nexplanation of object identities and values.\nas no objects are collected that are still reachable.\nChapter 6: Object References, Mutability, and Recycling\nThe CPython 3.4 garbage collector improved handling of objects with a __del__\nmethod, as described in PEP 442—Safe object finalization.\nEqual Treatment to All Objects\nbut for objects (not primitive types), the Java == compares references, and not object\nThe == operator compares object values; is compares refer‐\ncompares object IDs, so the fallback is that every instance of a user-defined class is\nThis chapter would not be necessary if all Python objects were immutable.\nare dealing with unchanging objects, it makes no difference whether variables hold\nthe actual objects or references to shared objects.\nIf a == b is true, and neither object\nObject\nidentity becomes important only when objects are mutable.\nPython, however, is not a functional language, much less a pure one.\nuser-defined classes are mutable by default in Python—as in most object-oriented\nWhen creating your own objects, you have to be extra careful to make\nEvery attribute of the object must also be\nobject IDs go, but the value of a tuple may change if it holds a mutable object.\nMutable objects are also the main reason why programming with threads is so hard\nObject Destruction and Garbage Collection\nThere is no mechanism in Python to directly destroy an object, and this omission is\nand it is able to dispose of unreachable objects kept alive by reference cycles.\nposal of objects with zero references.\nThat code is safe because the reference count of the file object will be zero after the\nthe object representing it in memory.\nChapter 6: Object References, Mutability, and Recycling\nguages are call by value (the function gets a copy of the argument) and call by refer‐\nIn Python, the function gets a copy\nenced objects may be changed, if they are mutable, but their identity cannot.\nbecause the function gets a copy of the reference in an argument, rebinding it in the\nFunctions as Objects\nFunctions as First-Class Objects\nI have never considered Python to be heavily influenced by functional languages, no\nsuch as C and Algol 68 and although I had made functions first-class objects, I didn’t\nview Python as a functional programming language.\nFunctions in Python are first-class objects.\nIntegers, strings, and dictionaries are other examples of first-class objects in Python\nHaving functions as first-class objects is an essential feature of\ntions as objects.\n“functions as first-class objects.” It’s not ideal because it implies an\nIn Python, all functions are first-class.\nof function objects that were too low-level and distracted from the\nNow let’s see why Python functions are full-fledged objects.\nTreating a Function Like an Object\nThe console session in Example 7-1 shows that Python functions are objects.\ncreate a function, call it, read its __doc__ attribute, and check that the function object\nitself is an instance of the function class.\nCreate and test a function, then read its __doc__ and check its type\nChapter 7: Functions as First-Class Objects\n<class 'function'>\n__doc__ is one of several attributes of function objects.\nfactorial is an instance of the function class.\nthe function.\nExample 7-2 shows the “first class” nature of a function object.\n<function factorial at 0x...>\n<map object at 0x...>\nTreating a Function Like an Object \nFor example, to sort a list of words by length, pass the len function as the\nChapter 7: Functions as First-Class Objects\nsubstitute is now a generator expression (in Python 2, these functions returned lists,\nThe reduce function was demoted from a built-in in Python 2 to the functools\nfunction.\nfunction.\nThe lambda keyword creates an anonymous function within a Python expression.\nHowever, the simple syntax of Python limits the body of lambda functions to be pure\nChapter 7: Functions as First-Class Objects\nThe best use of anonymous functions is in the context of an argument list for a\nExample 7-4 rewritten with lambda, without defining a reverse function.\nfunctions are rarely useful in Python.\nobject just like the def statement.\nThat is just one of several kinds of callable objects\nThe Nine Flavors of Callable Objects\nThe call operator () may be applied to other objects besides functions.\nwhether an object is callable, use the callable() built-in function.\nThe Nine Flavors of Callable Objects \nWe’ll see an example of this in “Flexible Object Creation with __new__” on page 843.\nthere is no new operator in Python, calling a class is like calling a function.2\nthey return a generator object.\ncoroutine object.\nother callables in that their return values are never application data, but objects that\ntions and asynchronous generator functions return objects that only work with the\nChapter 7: Functions as First-Class Objects\nto determine whether an object is callable is to use the callable()\nWe now move on to building class instances that work as callable objects.\nNot only are Python functions real objects, but arbitrary Python objects may also be",
      "keywords": [
        "Object",
        "Python",
        "Object References",
        "Python Language Reference",
        "function",
        "References",
        "functions",
        "function object",
        "list",
        "Python functions",
        "Python objects",
        "function parameters",
        "mutable object",
        "First-Class Objects",
        "Callable Objects"
      ],
      "concepts": [
        "object",
        "examples",
        "functions",
        "functional",
        "python",
        "pythonic",
        "references",
        "refer",
        "referred",
        "list"
      ],
      "similar_chapters": [
        {
          "book": "Fluent Python 2nd",
          "chapter": 9,
          "title": "",
          "score": 0.675,
          "base_score": 0.525,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 11,
          "title": "",
          "score": 0.637,
          "base_score": 0.487,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 1,
          "title": "",
          "score": 0.625,
          "base_score": 0.475,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 8,
          "title": "",
          "score": 0.608,
          "base_score": 0.458,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 5,
          "title": "",
          "score": 0.604,
          "base_score": 0.454,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "object",
          "objects",
          "references",
          "function",
          "object references"
        ],
        "semantic": [],
        "merged": [
          "object",
          "objects",
          "references",
          "function",
          "object references"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.39124873827158857,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:09.220015+00:00"
      }
    },
    {
      "chapter_number": 9,
      "title": "Now let’s explore the powerful syntax Python offers to declare function parameters",
      "start_page": 270,
      "end_page": 281,
      "summary": "a function, and the callable() built-in recognizes it as a callable object:\nA class implementing __call__ is an easy way to create function-like objects that\nThe functional approach to creating functions with internal state is to use closures.\nNow let’s explore the powerful syntax Python offers to declare function parameters\nOne of the best features of Python functions is the extremely flexible parameter han‐\nmappings into separate arguments when we call a function.\nChapter 7: Functions as First-Class Objects\ntag generates HTML elements; a keyword-only argument class_ is used\nto pass “class” attributes as a workaround because class is a keyword in Python\nThe tag function can be invoked in many ways, as Example 7-10 shows.\nSome of the many ways of calling the tag function from Example 7-9\nThe class_ parameter can only be passed as a keyword argument.\nPrefixing the my_tag dict with ** passes all its items as separate arguments,\nKeyword-only arguments are a feature of Python 3.\nTo specify keyword-only arguments when defining a function,\nSince Python 3.8, user-defined function signatures may specify positional-only\nThis feature always existed for built-in functions, such as divmod(a, b),\nTo define a function requiring positional-only parameters, use / in the parameter list.\nbuilt-in function:\nChapter 7: Functions as First-Class Objects\nFor example, consider the tag function from Example 7-9.\nparameter to be positional only, we can add a / after it in the function signature, like\nin a functional style.\nPackages for Functional Programming\nAlthough Guido makes it clear that he did not design Python to be a functional pro‐\ngramming language, a functional coding style can be used to good extent, thanks to\nfirst-class functions, pattern matching, and the support of packages like operator\nOften in functional programming it is convenient to use an arithmetic operator as a\nfunction.\nthere is no equivalent function for multiplication.\na function to multiply two items of the sequence.\nFactorial implemented with reduce and an anonymous function\nPackages for Functional Programming \nThe operator module provides function equivalents for dozens of operators so you\ndon’t have to code trivial functions like lambda a, b: a*b.\nAnother group of one-trick lambdas that operator replaces are functions to pick\nare factories that build custom functions to do that.\nExample 7-13 shows a common use of itemgetter: sorting a list of tuples by the\nEssentially, itemgetter(1) creates a function that, given a collection, returns the\nIf you pass multiple index arguments to itemgetter, the function it builds will return\nChapter 7: Functions as First-Class Objects\nA sibling of itemgetter is attrgetter, which creates functions to extract object\nPackages for Functional Programming \nHere is a partial list of functions defined in operator (names starting with _ are omit‐\nit is mutable; if not, the function works like the one without the i prefix: it simply\nOf the remaining operator functions, methodcaller is the last we will cover.\nsomewhat similar to attrgetter and itemgetter in that it creates a function on the\nThe function it creates calls a method by name on the object given as argument,\nChapter 7: Functions as First-Class Objects\nneed to use the str.upper as a function, you can just call it on the str class and pass\ncation to freeze some arguments, like the functools.partial function does.\nThe functools module provides several higher-order functions.\nThis is useful to adapt a function that takes\nUsing partial to use a two-argument function where a one-argument\nCreate new triple function from mul, binding the first positional argument to 3.\nUse triple with map; mul would not work with map in this example.\nA more useful example involves the unicode.normalize function that we saw in\nfunction to do so, as in Example 7-17.\nPackages for Functional Programming \nBuilding a convenient Unicode normalizing function with partial\nExample 7-18 shows the use of partial with the tag function from Example 7-9, to\nDemo of partial applied to the function tag from Example 7-9\n<function tag at 0x10206d1e0>  \n>>> picture = partial(tag, 'img', class_='pic-frame')  \nfunctools.partial(<function tag at 0x10206d1e0>, 'img', class_='pic-frame')  \n<function tag at 0x10206d1e0>\nCreate the picture function from tag by fixing the first positional argument\nwith 'img' and the class_ keyword argument with 'pic-frame'.\nChapter 7: Functions as First-Class Objects\nThe functools.partialmethod function does the same job as partial, but is\nThe functools module also includes higher-order functions designed to be used as\nfunction decorators, such as cache and singledispatch, among others.\nfunctions are covered in Chapter 9, which also explains how to implement custom\nThe goal of this chapter was to explore the first-class nature of functions in Python.\nThe main ideas are that you can assign functions to variables, pass them to other\nHigher-order functions, a staple of functional programming, are common in Python.\nmonly used higher-order functions in the language.\nCallables come in nine different flavors since Python 3.6, from the simple functions\nLastly, we covered some functions from the operator module and functools.par\nThe next chapters continue our exploration of programming with function objects.\nChapter 8 is devoted to type hints in function parameters and return values.\nA great introduction to functional programming in Python is A.\n“Python Functional Programming HOWTO”.\nReflecting on the question “Is Python a functional language?”, I created one of my\nIs Python a Functional Language?\nChapter 7: Functions as First-Class Objects\nEven if it was not Guido’s goal, endowing Python with first-class functions opened\nthe door to functional programming.\nIn his post, “Origins of Python’s Functional\nFunctions like map, filter, and reduce first appeared in Lisp, the original functional\ntion of functional programming idioms in Python is the lack of tail-call elimination,\nSo there you have it: Python is not, by design, a functional language—whatever that\nPython just borrows a few good ideas from functional languages.\nThe Problem with Anonymous Functions\nBeyond the Python-specific syntax constraints, anonymous functions have a serious",
      "keywords": [
        "Python",
        "function",
        "functions",
        "Functional Programming",
        "arguments",
        "tag",
        "functional",
        "argument",
        "tag function",
        "Python Functional Programming",
        "positional argument",
        "programming",
        "functional language",
        "parameters",
        "operator"
      ],
      "concepts": [
        "function",
        "functional",
        "examples",
        "argument",
        "arguments",
        "python",
        "classes",
        "useful",
        "uses",
        "chapters"
      ],
      "similar_chapters": [
        {
          "book": "Fluent Python 2nd",
          "chapter": 1,
          "title": "",
          "score": 0.748,
          "base_score": 0.598,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 10,
          "title": "",
          "score": 0.69,
          "base_score": 0.54,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 13,
          "title": "",
          "score": 0.683,
          "base_score": 0.533,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 6,
          "title": "",
          "score": 0.675,
          "base_score": 0.525,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 11,
          "title": "",
          "score": 0.669,
          "base_score": 0.519,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "function",
          "functional",
          "tag",
          "functions",
          "functional programming"
        ],
        "semantic": [],
        "merged": [
          "function",
          "functional",
          "tag",
          "functions",
          "functional programming"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.4166956187638115,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:09.220047+00:00"
      }
    },
    {
      "chapter_number": 21,
      "title": "252",
      "start_page": 282,
      "end_page": 333,
      "summary": "Type Hints in Functions\nIt should also be emphasized that Python will remain a dynamically typed language,\nand the authors have no desire to ever make type hints mandatory, even by\nType hints are the biggest change in the history of Python since the unification of\ntypes and classes in Python 2.2, released in 2001.\nHowever, type hints do not benefit\nPEP 484—Type Hints introduced syntax and semantics for explicit type declarations\nthem, the cost of learning type hints is likely higher—unless they already know a\nlanguage with static types, subtyping, and generics.\nPython’s default dynamic typing is\nThis chapter focuses on Python’s type hints in function signatures.\nexplores type hints in the context of classes, and other typing module features.\n• A hands-on introduction to gradual typing with Mypy\n• Type hinting variadic parameters (*args, **kwargs)\n• Limitations and downsides of type hints and static typing\nType hints appeared in Python 3.5 after I wrapped up\nAbout Gradual Typing\nPEP 484 introduced a gradual type system to Python.\nThe Mypy type checker itself started as a language: a gradually typed dia‐\nA gradual type system:\nthe type of an object.\nDoes not catch type errors at runtime\nType hints are used by static type checkers, linters, and IDEs to raise warnings.\nChapter 8: Type Hints in Functions\n2 A just-in-time compiler like the one in PyPy has much better data than type hints: it monitors the Python\nprogram as it runs, detects the concrete types in use, and generates optimized machine code for those\nconcrete types.\n3 For example, recursive types are not supported as of July 2021—see typing module issue #182, Define a JSON\ntype and Mypy issue #731, Support recursive types.\nThe best usability feature of gradual typing is that annotations are always optional.\nadd type hints that satisfy a type checker.\ntype hints and ship it!\nule where you use type hints, and you can add special comments to make the type\nCode without type hints should naturally be accepted\nGradual Typing in Practice\nLet’s see how gradual typing works in practice, starting with a simple function and\ngradually adding type hints to it, guided by Mypy.\nThere are several Python type checkers compatible with PEP 484,\nno type hints and still provide useful advice.\nGradual Typing in Practice \nshow_count from messages.py without type hints\nTo begin type checking, I run the mypy command on the messages.py module:\nmessages_test.py without type hints\nChapter 8: Type Hints in Functions\nNow let’s add type hints, guided by Mypy.\ndefinition that does not have type hints for all its parameters and for its return value.\nmessages.py:14: error: Function is missing a type annotation\nmessages_test.py:10: error: Function is missing a type annotation\nmessages_test.py:15: error: Function is missing a return type annotation\nFor the first steps with gradual typing, I prefer to use another option: --disallow-\nNow I can add just the return type to show_count in messages.py:\nmessages.py:14: error: Function is missing a type annotation\nNow I can gradually add type hints function by function, without getting warnings\nGradual Typing in Practice \nDon’t forget to add the return type hint to the test function, otherwise\nChapter 8: Type Hints in Functions\nHere is one typing mistake that Python does not catch.\ncolors.py:24: error: Function is missing a type\nThe type hint for the color argument should be color: str.\nespecially in complicated type hints.\ntype hint for that particular parameter.\nGradual Typing in Practice \nso there is no type conflict.\nfrom typing import Optional\nRemember: at runtime, type hints are ignored.\nNote that we need to import Optional from the typing module.\ntypes, it’s good practice to use the syntax from typing import X to reduce the length\nOptional[str] just means: the type\nTypes Are Defined by Supported Operations\nthat type is a set of values and a set of functions that one can apply to these values.\nChapter 8: Type Hints in Functions\n4 Python doesn’t provide syntax to control the set of possible values for a type—except in Enum types.\nNumPy offers uint8, int16, and other machine-oriented numeric types, but in the Python\nFor example, from the point of view of applicable operations, what are the valid types\nPlease ignore the missing return type for\nnow, let’s focus on the parameter type:\nA type checker will reject that code.\nIf you tell Mypy that x is of type abc.Sequence, it\nstr, tuple, list, array, etc., as well as numbers, because at runtime the type hints\nfor the declared type: x: abc.Sequence.\nDuck typing\nObjects have types, but variables (including\nTypes Are Defined by Supported Operations \n5 Duck typing is an implicit form of structural typing, which Python ≥ 3.8 also supports with the introduction\nof typing.Protocol.\nNominal typing\nand variables have types.\nBut objects only exist at runtime, and the type checker\nannotated with type hints.\nChapter 8: Type Hints in Functions\nalert has no type hints, so the type checker ignores it.\nalert_duck takes one argument of type Duck.\nalert_bird takes one argument of type Bird.\nType checking birds.py with Mypy, we see a problem:\nJust by analyzing the source code, Mypy sees that alert_bird is problematic: the type\nhint declares the birdie parameter with type Bird, but the body of the function calls\nValid call, because alert has no type hints.\nTypes Are Defined by Supported Operations \nDuck typing FTW!\nAt runtime, Python doesn’t care about declared types.\nIt uses duck typing only.\nwoody.py:5: error: Argument 1 to \"alert_duck\" has incompatible type \"Bird\";\nChapter 8: Type Hints in Functions\nMypy could not detect this error because there are no type hints in alert.\ntype \"Bird\"; expected \"Duck\".\nNominal typing\nThe value of type hints is questionable in the tiny examples that fit\nand increasing portions of their Python codebases type checked in\nwithout proper type hints.\nWe’ll see a good way to add type hints to double() when we reach\ntypes to know.\nTypes Are Defined by Supported Operations \nTypes Usable in Annotations\nPretty much any Python type can be used in type hints, but there are restrictions and\nThis section covers all the major types you can use with annotations:\n• typing.Any\n• Simple types and classes\n• typing.Optional and typing.Union\n• typing.Callable\n• typing.NoReturn—a good way to end this list\nThe Any Type\ntype.\nWhen a type checker sees an untyped function like this:\nThat means the x argument and the return value can be of any type, including differ‐\nent types.\nThis function also accepts arguments of every type, because every type is a subtype-of\nChapter 8: Type Hints in Functions\nHowever, a type checker will reject this function:\ndouble_object.py:2: error: Unsupported operand types for * (\"object\" and \"int\")\nTypes Usable in Annotations \nf2(o1)  # type error\nment declared of type Any. 3.\nAny is consistent-with every type: you can always pass an object of type Any where\nan argument of another type is expected.\nChapter 8: Type Hints in Functions\ndef f4():  # implicit return type: `Any`\nModern type checkers in Python and other\nlanguages don’t require type annotations everywhere because they\ncan infer the type of many expressions.\nration to know that x is an int, as long as it can find type hints for\nNow we can explore the rest of the types used in annotations.\nSimple Types and Classes\nSimple types like int, float, str, and bytes may be used directly in type hints.\nAbstract base classes are also useful in type hints.\ntypes int, float, and complex: they are direct subclasses of object.\nTypes Usable in Annotations \nOptional and Union Types\nfrom typing import Optional\nmeans the type of plural may be str or None.\nIt’s less typing, and there’s no need to import\nOptional or Union from typing.\nfor the type hint of the plural parameter of show_count:\nfrom typing import Union\nIf possible, avoid creating functions that return Union types, as they put an extra bur‐\nden on the user—forcing them to check the type of the returned value at runtime to\nChapter 8: Type Hints in Functions\nUnion[] requires at least two types.\nSo this type hint:\nUnion is more useful with types that are not consistent among themselves.\ndifferent types in a list.\nFor example, a list can be parameterized to constrain the type of the elements in it,\ntokenize with type hints for Python ≥ 3.9\nIn Python ≥ 3.9, it means that tokenize returns a list where every item is of type\nTypes Usable in Annotations \na list of objects of any type.\nstandard library accepting generic type hints.\nlections that use the simplest form of generic type hint, container[item]:\nThe tuple and mapping types support more complex type hints, as we’ll see in their\nrently, Python’s static type system is not up to this challenge.\nLegacy Support and Deprecated Collection Types\ntokenize with type hints for Python ≥ 3.7\ntokenize with type hints for Python ≥ 3.5\nfrom typing import List\nChapter 8: Type Hints in Functions\nTo provide the initial support for generic type hints, the authors of PEP 484 created\nfull list, visit the typing documentation.\nSome collection types and their type hint equivalents\nType hint equivalent\ntyping.List\ntyping.Set\ntyping.FrozenSet\ntyping.Deque\ntyping.MutableSequence\ntyping.Sequence\ntyping.AbstractSet\ntyping.MutableSet\nto improve the usability of generic type hints.\ntion warnings will not be issued by the Python interpreter because type checkers\nshould flag the deprecated types when the checked program targets Python 3.9 or\n4. Remove those redundant generic types in the first version of Python released five\nTypes Usable in Annotations \nTuple Types\nThere are three ways to annotate tuple types:\nIf you’re using a tuple as a record, use the tuple built-in and declare the types of the\nFor example, the type hint would be tuple[str, float, str] to accept a tuple with\ntype hints.\nFor Python < 3.9, import and use typing.Tuple in type hints.\nChapter 8: Type Hints in Functions\nTo annotate a tuple with many fields, or specific types of tuple your code uses in\nfrom typing import NamedTuple\nstuff is a tuple of unspecified length with objects of any type.\nTypes Usable in Annotations \nNote the return type:\nbuilt-in dict and the mapping types in collections and collections.abc accept\nFor earlier versions, you must use typing.Dict and\nChapter 8: Type Hints in Functions\nBesides a dict[] type hint, this example has three features appearing for the first\nWithout the hint, Mypy says: Need type\nannotation for 'index' (hint: \"index: dict[<type>, <type>] = ...\").\nTypes Usable in Annotations \nstr type, with values of different types depending on the keys.\nPython 3.9—and not concrete types.\nChapter 8: Type Hints in Functions\nparameter type hints, instead of dict (or typing.Dict in legacy code).\ntype hint for color_map is abc.Mapping.\nfunction is always a concrete object, so the return type hint should be a concrete type,\nUnder the entry of typing.List, the Python documentation says:\nUseful for annotating return types.\nis preferred to use an abstract collection type such as Sequence or Iterable.\ncollections, as well as built-in collections, support generic type hint notation like\nType Hinting Generics In Standard Collections.\nTo wrap up our discussion of ABCs in type hints, we need to talk about the numbers\nType Hierarchy for Numbers.\nTypes Usable in Annotations \nnumbers ABCs and dictates that the built-in types complex, float, and int should\npage 478, in Chapter 13, which is devoted to contrasting protocols and ABCs. In practice, if you want to annotate numeric arguments for static type checking, you\n1. Use one of the concrete types int, float, or complex—as recommended by PEP\n2. Declare a union type like Union[float, Decimal, Fraction].\nMeanwhile, let’s get to one of the most useful ABCs for type hints: Iterable.\nThe typing.List documentation I just quoted recommends Sequence and Iterable\nfor function parameter type hints.\ncan find the necessary type hints in the\nChapter 8: Type Hints in Functions\nFromTo is a type alias: I assigned tuple[str, str] to FromTo, to make the signa‐\nand easier to type check.\nfrom typing import TypeAlias\nTypes Usable in Annotations \nLike Sequence, Iterable is best used as a parameter type.\ntype.\nA function should be more precise about the concrete type it returns.\nments of type T, and an int.\nIt returns a list of elements of the same type T, picked\nfrom typing import TypeVar\nHere are two examples of why I used a type variable in sample:\n• If called with a tuple of type tuple[int, ...]—which is consistent-with\nSequence[int]—then the type parameter is int, so the return type is list[int].\nChapter 8: Type Hints in Functions\n• If called with a str—which is consistent-with Sequence[str]—then the type\nparameter is str, so the return type is list[str].\nThe authors of PEP 484 wanted to introduce type hints by adding\nthe typing module and not changing anything else in the language.\ntype notation as special use of [].\nThat’s why the typing.TypeVar\nTypes Usable in Annotations \nfrom typing import TypeVar\nWhen it first appears in the signature, the type parameter T can be any type.\nTypeVar accepts extra positional arguments to restrict the type parameter.\nimprove the signature of mode to accept specific number types, like this:\nfrom typing import TypeVar\nChapter 8: Type Hints in Functions\nNow the problem is that the type of the returned item is Hashable: an ABC that\nfrom typing import TypeVar\nTypes Usable in Annotations \nThe typing module includes a predefined TypeVar named AnyStr. It’s defined like\nof the given type.\nNow, on to typing.Protocol, a new feature of Python 3.8 that can support more\nPythonic use of type hints.\nHowever, in the context of type hints,\na type checker can verify.\nIn Python, a protocol definition is written as a typing.Protocol subclass.\nIt’s up to the type checker to find the\nChapter 8: Type Hints in Functions\ntop function with an undefined T type parameter\nTypes Usable in Annotations \nSo the T type parameter in Example 8-19 should be limited to types that implement\nIn Example 8-18 we needed a type parameter that implemented __hash__, so\nnow there is no suitable type in typing or abc to use, so we need to create it.\nExample 8-20 shows the new SupportsLessThan type, a Protocol.\ncomparable.py: definition of a SupportsLessThan Protocol type\nfrom typing import Protocol, Any\nwith matching type signatures.\nfrom typing import TypeVar\nChapter 8: Type Hints in Functions\n16 Without this type hint, Mypy would infer the type of series as Generator[Tuple[builtins.int, buil\nfrom typing import TYPE_CHECKING  \nif TYPE_CHECKING:  \nreveal_type(series)  \nreveal_type(expected)\nreveal_type(result)\n# intentional type error\nif TYPE_CHECKING:\nreveal_type(series)\nExplicit type declaration for the series variable, to make the Mypy output easier\nreveal_type() cannot be called at runtime, because it is not a regular function\nTypes Usable in Annotations \nshowing the inferred type of the argument.\nThe preceding tests pass—but they would pass anyway, with or without type hints in\nAs of Mypy 0.910 (July 2021), the output of reveal_type does not\ntypes instead.\nFor example, I did not use typing.Iterator but\nRevealed type is \"typing.Iterator[Tuple[builtins.int, builtins.str]]\" \nRevealed type is \"builtins.list[Tuple[builtins.int, builtins.str]]\"\nRevealed type is \"builtins.list[Tuple[builtins.int, builtins.str]]\" \nRevealed type is \"builtins.list[builtins.object*]\" \nValue of type variable \"LT\" of \"top\" cannot be \"object\"  \nIn test_top_tuples, reveal_type(series) shows it is an Iterator[tuple[int,\nwanted: given the type of series, the result is list[tuple[int, str]].\nIn test_top_objects_error, reveal_type(series) shows it is list[object*].\nMypy puts a * after any type that was inferred: I did not annotate the type of\nMypy flags the error that this test intentionally triggers: the element type of the\nIterable series cannot be object (it must be of type SupportsLessThan).\ndeclaration to be consistent-with a protocol type.\nChapter 8: Type Hints in Functions\ning (static duck typing).\nstatic duck typing: the solution to annotate the series parameter of top was to say\nmethod.” Python’s duck typing always allowed us to say that implicitly, leaving static\ntype checkers clueless.\nNow we can make duck typing explicit for static type checkers.\nThere’s more to see about typing.Protocol.\nexplains how to declare overloaded function signatures with @typing.overload, and\nincludes an extensive example using typing.Protocol and a bounded TypeVar. typing.Protocol makes it possible to annotate the double func‐\ntions, the collections.abc module provides the Callable type, available in the typ\nA Callable type is parameterized like\nTypes Usable in Annotations \nsame parameter and return types as input.\nThe input signature is consistent-with this Callable type hint:\nThere is no syntax to annotate optional or keyword argument types.\nIf you need a type hint to match a function with a flexible signature, replace the\ntyping concept: variance.\nVariance in Callable types\nis to contrast two Callable annotations: one with a return type, the other with a\nparameter type.\nChapter 8: Type Hints in Functions\nMypy flags this line because display_wrong is incompatible with the type hint in\nThis means that Callable is covariant on the return type\nTypes Usable in Annotations \nbecause the subtype-of relationship of the types int and float is in the same direc‐\ntion as the relationship of the Callable types that use them as return types.\nOn the other hand, it’s a type error to provide a callback that takes a int argument\nAlthough int is subtype-of float, in the parameterized Callable type the relation‐\nTherefore we say that Callable is contravariant on the declared parameter types.\nNow we get to the last special type we’ll cover in this chapter.\nThis is a special type used only to annotate the return type of functions that never\nThe type of __status is object,\nChapter 8: Type Hints in Functions\nfrom typing import Optional\nNote the type hint *content: str for the arbitrary positional parameters; this means\nall those arguments must be of type str.\nThe type hint for the arbitrary keyword arguments is **attrs: str in this example,\ntherefore the type of attrs inside the function will be dict[str, str].\ntype hint like **attrs: float, the type of attrs in the function would be\nIf the attrs parameter must accept values of different types, you’ll need to use a\nfrom typing import Optional\nTo close this chapter, let’s briefly consider the limits of type hints and the static type\nImperfect Typing and Strong Testing\nTools report type errors on code that is correct.\nTools don’t report type errors on code that is incorrect.\n• Type checkers lag behind Python releases, rejecting or even crashing while ana‐\nFor example, type hints are unable to ensure “quantity must be an integer > 0” or\nautomated tests catch many bugs that are beyond the reach of type hints.\nyou can write in Python, you can test in Python—with or without type hints.\nChapter 8: Type Hints in Functions\nThis wraps up our coverage of Python’s type hints for now.\ntype casting, and more.\nMeanwhile, type hints will make guest appearances in several\ntool that actually reads the type hints, so we developed an annotated function guided\nother statically typed languages.\nMany of the types we covered are related to familiar Python object\ntypes, such as collections, tuples, and callables—extended to support generic notation\ntype system.\nPython’s duck-typed core and the nominal typing that allows static type checkers to\nWhile covering some of these types, we experimented with Mypy to see type checking\nerrors and inferred types with the help of Mypy’s magic reveal_type() function.\nType hints are a complex and evolving topic.\nall Python code should have type hints—as I’ve seen in public sermons by typing\nOur BDFL19 emeritus led this push toward type hints in Python, so it’s only fair that\nI wouldn’t like a version of Python where I was morally obligated to add type hints all\nI really do think that type hints have their place but there are also plenty of\nType hints should be used whenever unit tests are worth writing.\ning, tests and type hints are not helpful.\nGábor’s post is one of the best introductions to Python’s type hints that I found,\npages about Python typing in general—not just about the Mypy tool itself.\nChapter 8: Type Hints in Functions\nthing you do to learn, tinker, and enjoy, you probably don’t need type hints any more\nI worry about the effect type hints will have on Python coding style.\nI agree that users of most APIs benefit from type hints.\nOverload” on page 521 that it takes 14 lines of type hints to properly annotate it—not\ncounting a typing.Protocol and a few TypeVar definitions to support those type\nI think that libraries with Pythonic APIs are the least likely to take up this typing sys‐\nChapter 8: Type Hints in Functions\ntype hint coverage?\nwith type hints.\nWhile there are benefits to type hints, there is also a price to pay.\nWe lose some of the expressive power of Python if we insist on type checking every‐\nbeyond comprehension for type checkers.\nFor some projects and contexts, type hints just don’t make sense.\npolicy about the use of type hints must have exceptions.\nDuck Typing FTW\nBefore PEP 544, this whole idea of type hints seemed utterly unPythonic to me.\nvery glad to see typing.Protocol land in Python.\ntype parameters, and became “generic.”\nChapter 8: Type Hints in Functions",
      "keywords": [
        "Type Hints",
        "Type",
        "Python",
        "Hints",
        "generic type hints",
        "type checker",
        "Types Usable",
        "type hints function",
        "return type",
        "parameter type hints",
        "add type hints",
        "Mypy",
        "function",
        "str",
        "Python type"
      ],
      "concepts": [
        "type",
        "typed",
        "typing",
        "functions",
        "function",
        "functionality",
        "examples",
        "python",
        "pythonic",
        "importing"
      ],
      "similar_chapters": [
        {
          "book": "Fluent Python 2nd",
          "chapter": 14,
          "title": "",
          "score": 0.914,
          "base_score": 0.764,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 13,
          "title": "",
          "score": 0.748,
          "base_score": 0.598,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 1,
          "title": "",
          "score": 0.734,
          "base_score": 0.584,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 11,
          "title": "",
          "score": 0.72,
          "base_score": 0.57,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 9,
          "title": "",
          "score": 0.658,
          "base_score": 0.508,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "type",
          "type hints",
          "hints",
          "typing",
          "types"
        ],
        "semantic": [],
        "merged": [
          "type",
          "type hints",
          "hints",
          "typing",
          "types"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.4307867444706388,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:09.220074+00:00"
      }
    },
    {
      "chapter_number": 10,
      "title": "Understanding how decorators actually work required covering the difference",
      "start_page": 366,
      "end_page": 392,
      "summary": "egy design pattern in Chapter 10.\nfunctions (a.k.a. multimethods) using decorators.\nThe designer of any language with first-class functions faces this issue: being a first-\nclass object, a function is defined in a certain scope but may be invoked in other\ndynamic scope, if a function uses free variables, the programmer has to know its\nJohn McCarthy when he created Lisp, the first language to have first-class functions.\nexample of higher-order Lisp functions was broken because of it.\nlanguages with first-class functions, because it requires the support of closures.\nPython Decorators and the Decorator Design Pattern\nPython function decorators fit the general description of decorator given by Gamma\nin Design Patterns: “Attach additional responsibilities to an object dynamically.\nDecorators provide a flexible alternative to subclassing for extending functionality.”\ndesign pattern, but an analogy can be made.\nIn the design pattern, Decorator and Component are abstract classes.\nQuoting from Design Patterns:\nIn Python, the decorator function plays the role of a concrete Decorator subclass,\nand the inner function it returns is a decorator instance.\nthe function to be decorated, which is analogous to the component in the design pat‐\nNote that I am not suggesting that function decorators should be used to implement\nthe decorator pattern in Python programs.\nuations, in general the decorator pattern is best implemented with classes to represent\n1 From a slide in the talk “Root Cause Analysis of Some Faults in Design Patterns,” presented by Ralph Johnson\nDesign Patterns with First-Class Functions\n—Ralph Johnson, coauthor of the Design Patterns classic1\nYou don’t need to know design patterns to follow this chapter.\nexplain the patterns used in the examples.\nThe use of design patterns in programming was popularized by the landmark book\nDesign Patterns: Elements of Reusable Object-Oriented Software (Addison-Wesley) by\nof Four.” The book is a catalog of 23 patterns consisting of arrangements of classes\nAlthough design patterns are language independent, that does not mean every pat‐\n2 Quoted from page 4 of Design Patterns.\nlanguages, we might have included design patterns called “Inheritance,” “Encapsula‐\nstates that 16 out of the 23 patterns in the original Design Patterns book become\nIn particular, in the context of languages with first-class functions, Norvig\nsuggests rethinking the classic patterns known as Strategy, Command, Template\nimplementation of Strategy using functions as objects, removing a lot of boilerplate\nStrategy is a good example of a design pattern that can be simpler in Python if you\nleverage functions as first-class objects.\nimplement Strategy using the “classic” structure described in Design Patterns.\nplifies the Strategy pattern.\nChapter 10: Design Patterns with First-Class Functions\nUML class diagram for order discount processing implemented with the\nStrategy design pattern.\nThe Strategy pattern is summarized like this in Design Patterns:\n• Customers with 1,000 or more fidelity points get a global 5% discount per order.\nThe UML class diagram for the Strategy pattern is depicted in Figure 10-1.\ncontext is an Order, which is configured to apply a promotional discount accord‐\nIn our example, this role is played by an abstract class called Promotion.\nDesign Patterns, the concrete strategy is chosen by the client of the context class.\nmotional discount strategy and pass it to the Order constructor.\nstrategy is outside the scope of the pattern.\nImplementation of the Order class with pluggable discount strategies\nclass Order(NamedTuple):  # the Context\nChapter 10: Design Patterns with First-Class Functions\nclass Promotion(ABC):  # the Strategy: an abstract base class\ndef discount(self, order: Order) -> Decimal:\nclass FidelityPromo(Promotion):  # first Concrete Strategy\ndef discount(self, order: Order) -> Decimal:\nclass BulkItemPromo(Promotion):  # second Concrete Strategy\ndef discount(self, order: Order) -> Decimal:\nclass LargeOrderPromo(Promotion):  # third Concrete Strategy\ndef discount(self, order: Order) -> Decimal:\nNote that in Example 10-1, I coded Promotion as an abstract base class (ABC) to use\nthe @abstractmethod decorator and make the pattern more explicit.\nSample usage of Order class with different promotions applied\nExample 10-1 works perfectly well, but the same functionality can be implemented\nwith less code in Python by using functions as objects.\nChapter 10: Design Patterns with First-Class Functions\nFunction-Oriented Strategy\nEach concrete strategy in Example 10-1 is a class with a single method, discount.\nrefactoring of Example 10-1, replacing the concrete strategies with simple functions\nOrder class.3\nOrder class with discount strategies implemented as functions\nclass Order:  # the Context\npromotion: Optional[Callable[['Order'], Decimal]] = None  \ndef fidelity_promo(order: Order) -> Decimal:  \ndef bulk_item_promo(order: Order) -> Decimal:\ndef large_order_promo(order: Order) -> Decimal:\nOrder argument and returns a Decimal.\nEach strategy is a function.\nChapter 10: Design Patterns with First-Class Functions\nIn the Order class, promotion is not a method.\nSample usage of Order class with promotions as functions\n>>> Order(joe, cart, fidelity_promo)  \n>>> Order(ann, cart, fidelity_promo)\n>>> Order(joe, banana_cart, bulk_item_promo)  \n>>> Order(joe, long_cart, large_order_promo)\n>>> Order(joe, cart, large_order_promo)\nTo apply a discount strategy to an Order, just pass the promotion function as an\nA different promotion function is used here and in the next test.\nobject with each new order: the functions are ready to use.\n4 See page 323 of Design Patterns.\nIt is interesting to note that in Design Patterns, the authors suggest: “Strategy objects\nrequire all the pieces of the Strategy and Flyweight design patterns combined.\nA function is more lightweight than an instance of a user-defined class,\nand there is no need for Flyweight because each strategy function is created just once\nNow that we have implemented the Strategy pattern with functions, other possibili‐\nThe best_promo function applies all discounts and returns the largest\n>>> Order(joe, long_cart, best_promo)  \n>>> Order(joe, banana_cart, best_promo)  \n>>> Order(ann, cart, best_promo)  \nChapter 10: Design Patterns with First-Class Functions\nbest_promo selected the larger_order_promo for customer joe.\nHere joe got the discount from bulk_item_promo for ordering lots of bananas.\nfunctions\ndef best_promo(order: Order) -> Decimal:  \npromos: list of the strategies implemented as functions.\nbest_promo takes an instance of Order as argument, as do the other *_promo\nfunctions.\nUsing a generator expression, we apply each of the functions from promos to the\nExample 10-6 is straightforward: promos is a list of functions.\nthe idea that functions are first-class objects, it naturally follows that building data\ncould lead to a subtle bug: to add a new promotion strategy, we need to code the\nfunction and remember to add it to the promos list, or else the new promotion will\nmatically find the other available *_promo functions.\nfrom strategy import Order\ndef best_promo(order: Order) -> Decimal:              \nImport the promotion functions so they are available in the global namespace.6\nput all the strategy functions there, except for best_promo.\nIn Example 10-8, the only significant change is that the list of strategy functions\nChapter 10: Design Patterns with First-Class Functions\nfrom strategy import Order\ndef best_promo(order: Order) -> Decimal:\nExample 10-8 works regardless of the names given to the functions; all that matters is\nthat the promotions module contains only functions that calculate discounts given\nate a function with a different signature in the promotions module, then best_promo\nA more explicit alternative to dynamically collecting promotional discount functions\nDecorator-Enhanced Strategy Pattern\nRecall that our main issue with Example 10-6 is the repetition of the function names\nin their definitions and then in the promos list used by the best_promo function to\nsomeone may add a new promotional strategy function and forget to manually add it\nDecorator-Enhanced Strategy Pattern \nThe promos list is filled by the Promotion decorator\nPromotion = Callable[[Order], Decimal]\ndef best_promo(order: Order) -> Decimal:\nPromotion is a registration decorator: it returns the promo function unchanged,\nChapter 10: Design Patterns with First-Class Functions\nAny function decorated by @promotion will be added to promos.\n• The promotion strategy functions don’t have to use special names—no need for\n• The @promotion decorator highlights the purpose of the decorated function, and\n• Promotional discount strategies may be defined in other modules, anywhere in\nIn the next section, we discuss Command—another design pattern that is sometimes\nimplemented via single-method classes when plain functions would do.\nThe Command Pattern\nCommand is another design pattern that can be simplified by the use of functions\npattern.\nCommand design pattern.\nThe Command Pattern \nfrom Design Patterns, each invoker is a menu item in a graphical application, and the\nQuoting from Design Patterns, “Commands are an object-oriented replacement for\nChapter 10: Design Patterns with First-Class Functions\n7 “Root Cause Analysis of Some Faults in Design Patterns,” presented by Johnson at IME-USP, November 15,\nThis concludes our rethinking of the Command pattern with first-class functions.\nAs Peter Norvig pointed out a couple of years after the classic Design Patterns book\nfeatures of the Lisp and Dylan languages, in particular, first-class functions, our focus\nversary of Design Patterns: Elements of Reusable Object-Oriented Software, Ralph\npatterns as end-points instead of steps in the design process.”7 In this chapter, we\nused the Strategy pattern as a starting point: a working solution that we could sim‐\nplify using first-class functions.\nmenting callbacks in Python than mimicking the Strategy or the Command patterns\nas described by Gamma, Helm, Johnson, and Vlissides in Design Patterns.\ntoring of Strategy and the discussion of Command in this chapter are examples of a\nfunctions as first-class objects.\nImplementing the Visitor Pattern,” in the Python Cookbook, 3rd ed.,\nOn the general topic of design patterns, the choice of readings for the Python pro‐\nLearning Python Design Patterns, by Gennadiy Zlobin (Packt), is the only book that I\n(100 pages) and covers 8 of the original 23 design patterns.\nlevel Python books in the market, and its final chapter, “Useful Design Patterns,”\npresents several of the classic patterns from a Pythonic perspective.\nAlex Martelli has given several talks about Python design patterns.\nThere are many books about design patterns in the context of Java, but among them\nfirst-class functions in Java, making some of the examples closer to code we’d write in\nFor a fresh look at patterns from the point of view of a dynamic language with duck\ntyping and first-class functions, Design Patterns in Ruby by Russ Olsen (Addison-\nclass functions (and other dynamic features) make several of the original design pat‐\nThe introduction of the original Design Patterns book by Gamma et al.\nChapter 10: Design Patterns with First-Class Functions\nThe application of patterns to design originated with the architect Christopher\nPython has first-class functions and first-class types, features that Norvig claims affect\ndesign patterns to language features is not an exact science.\nthe original design patterns are useful in any implementation language.\nthat the “classic” 23 patterns from Design Patterns apply to “classic” Java very well in\nThe Python bibliography about design patterns is very thin, compared to that of Java,\nbe written about design patterns in the context of this language.\npatterns.\nChapter 10: Design Patterns with First-Class Functions",
      "keywords": [
        "Design Patterns",
        "Python Design Patterns",
        "order",
        "Patterns",
        "Decorator Design Pattern",
        "decimal",
        "design",
        "Strategy Pattern",
        "Strategy design pattern",
        "Strategy",
        "Python",
        "Design Patterns book",
        "functions",
        "Order total",
        "Command design pattern"
      ],
      "concepts": [
        "function",
        "functions",
        "functional",
        "decorator",
        "decorated",
        "decorates",
        "python",
        "pythonic",
        "classes",
        "patterns"
      ],
      "similar_chapters": [
        {
          "book": "Fluent Python 2nd",
          "chapter": 9,
          "title": "",
          "score": 0.69,
          "base_score": 0.54,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 1,
          "title": "",
          "score": 0.671,
          "base_score": 0.521,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 13,
          "title": "",
          "score": 0.579,
          "base_score": 0.429,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 18,
          "title": "",
          "score": 0.575,
          "base_score": 0.425,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 21,
          "title": "",
          "score": 0.574,
          "base_score": 0.424,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "design",
          "design patterns",
          "patterns",
          "strategy",
          "order"
        ],
        "semantic": [],
        "merged": [
          "design",
          "design patterns",
          "patterns",
          "strategy",
          "order"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.3746986438875539,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:09.220101+00:00"
      }
    },
    {
      "chapter_number": 11,
      "title": "A Pythonic Object",
      "start_page": 393,
      "end_page": 393,
      "summary": "A Pythonic Object\nThanks to the Python Data Model, your user-defined types can behave as naturally as\nduck typing: you just implement the methods needed for your objects to behave as\nbuild user-defined classes that behave as real Python objects.\nspecial methods that are commonly seen in Python objects of many different types.",
      "keywords": [
        "blog post",
        "Python",
        "Pythonic",
        "Python Data Model",
        "objects",
        "Python objects",
        "Martijn Faassen",
        "behave",
        "Faassen",
        "Pythonic Object",
        "implement",
        "Faassen ’s blog",
        "built-in",
        "classes",
        "Python Data"
      ],
      "concepts": [
        "pythonic",
        "python",
        "methods",
        "chapters",
        "format",
        "classes",
        "typing",
        "framework",
        "bytes",
        "mini"
      ],
      "similar_chapters": [
        {
          "book": "Fluent Python 2nd",
          "chapter": 13,
          "title": "",
          "score": 0.768,
          "base_score": 0.618,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 14,
          "title": "",
          "score": 0.755,
          "base_score": 0.605,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 1,
          "title": "",
          "score": 0.744,
          "base_score": 0.594,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 21,
          "title": "",
          "score": 0.72,
          "base_score": 0.57,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 8,
          "title": "",
          "score": 0.714,
          "base_score": 0.564,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "faassen",
          "behave",
          "pythonic object",
          "python",
          "python data"
        ],
        "semantic": [],
        "merged": [
          "faassen",
          "behave",
          "pythonic object",
          "python",
          "python data"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.46904908927975997,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:09.220126+00:00"
      }
    },
    {
      "chapter_number": 12,
      "title": "The evolution of the example will be paused to discuss two conceptual topics:",
      "start_page": 394,
      "end_page": 512,
      "summary": "• Make an object hashable for use in sets and as dict keys\nWe’ll do all that as we develop Vector2d, a simple two-dimensional Euclidean vector\nThis code will be the foundation of an N-dimensional vector class in\nIt’s a small change because f-strings support the same formatting mini-\nlanguage as the format() built-in and the str.format() method, so any previously\nimplemented __format__ methods simply work with f-strings.\nobjects: __bytes__ and __format__.\nstr.format() method.\nplays of objects using special formatting codes.\nexample, and __format__ after that.\nVector Class Redux\nwe’ll use a Vector2d class similar to the one we saw in Chapter 1.\nfrom a Vector2d instance.\nVector2d instances have several representations\n>>> v1 = Vector2d(3, 4)\n>>> x, y = v1  \nVector2d(3.0, 4.0)\nVector Class Redux \nThe components of a Vector2d can be accessed directly as attributes (no getter\nThe repr of a Vector2d emulates the source code for constructing the instance.\nVector2d supports comparison with ==; this is useful for testing.\nabs uses the __abs__ method to return the magnitude of the Vector2d.\nbool uses the __bool__ method to return False for a Vector2d of zero magni‐\nVector2d from Example 11-1 is implemented in vector2d_v0.py (Example 11-2).\ncode is based on Example 1-2, except for the methods for the + and * operations,\nWe’ll add the method for == since it’s useful for\nAt this point, Vector2d uses several special methods to provide operations\nvector2d_v0.py: methods so far are all special methods\nclass Vector2d:\nreturn (i for i in (self.x, self.y))  \nclass_name = type(self).__name__\nreturn '{}({!r}, {!r})'.format(class_name, *self)  \nreturn math.hypot(self.x, self.y)  \ntypecode is a class attribute we’ll use when converting Vector2d instances to/\n__iter__ makes a Vector2d iterable; this is what makes unpacking work (e.g, x,\nrepr; because Vector2d is iterable, *self feeds the x and y components to\nVector Class Redux \nMethod __eq__ in Example 11-2 works for Vector2d operands but\nalso returns True when comparing Vector2d instances to other\nSince we can export a Vector2d as bytes, naturally we need a method that imports a\nfind that array.array has a class method named .frombytes that suits our purpose\nclass method for Vector2d in vector2d_v1.py (Example 11-3).\nPart of vector2d_v1.py: this snippet shows only the frombytes class\nmethod, added to the Vector2d definition in vector2d_v0.py (Example 11-2)\nclass.\nNo self argument; instead, the class itself is passed as the first argument—con‐\nExample 11-3 shows its use: to define a method that\noperates on the class and not on instances.\nis called, so it receives the class itself as the first argument, instead of an instance.\nthod, and recommends the blog post “The Definitive Guide on How to Use Static, Class or Abstract Methods\nThe f-strings, the format() built-in function, and the str.format() method delegate\nnotation, used in f-strings and the str.format() method (includ‐\nThe Format Specification Mini-Language is extensible because each class gets to\ntime module use the same format codes in the strftime() functions and in their\n__format__ methods.\nthe str.format() method:\nIf a class has no __format__, the method inherited from object returns\n>>> v1 = Vector2d(3, 4)\n>>> format(v1)\n>>> format(v1, '.3f')\n>>> v1 = Vector2d(3, 4)\n>>> format(v1)\n>>> format(v1, '.2f')\n>>> format(v1, '.3e')\nExample 11-5 implements __format__ to produce the displays just shown.\nVector2d.__format__ method, take #1\n# inside the Vector2d class\ndef __format__(self, fmt_spec=''):\ncomponents = (format(c, fmt_spec) for c in self)  \nreturn '({}, {})'.format(*components)  \nUse the format built-in to apply the fmt_spec to each vector component, build‐\nPlug the formatted strings in the formula '(x, y)'.\ntude, and we’ll code a simple angle method using the math.atan2() function to get\n# inside the Vector2d class\nreturn math.atan2(self.y, self.x)\nVector2d.__format__ method, take #2, now with polar coordinates\ndef __format__(self, fmt_spec=''):\nreturn outer_fmt.format(*components)  \nOtherwise, use x, y components of self for rectangular coordinates.\nGenerate iterable with components as formatted strings.\n>>> format(Vector2d(1, 1), 'p')\n>>> format(Vector2d(1, 1), '.3ep')\n>>> format(Vector2d(1, 1), '0.5fp')\nVector2d hashable, so we can build sets of vectors, or use them as dict keys.\n>>> v1 = Vector2d(3, 4)\nTo make a Vector2d hashable, we must implement __hash__ (__eq__ is also\nWe also need to make vector instances immutable,\nWe’ll do that by making the x and y components read-only properties in\nvector2d_v3.py: only the changes needed to make Vector2d immutable\nclass Vector2d:\nreturn self.__x  \nreturn (i for i in (self.x, self.y))  \n# remaining methods: same as previous Vector2d\nThe getter method is named after the public property it exposes: x.\nJust return self.__x.\nEvery method that just reads the x, y components can stay as it was, reading the\npublic properties via self.x and self.y instead of the private attribute, so this\nVector.x and Vector.y are examples of read-only properties.\nhashes of the object attributes that are also used in the __eq__ method, because\nvector2d_v3.py: implementation of hash\n# inside class Vector2d:\nreturn hash((self.x, self.y))\nWith the addition of the __hash__ method, we now have hashable vectors:\n>>> v1 = Vector2d(3, 4)\n>>> v2 = Vector2d(3.1, 4.2)\nprotect the instance attributes to create a hashable type.\nSo far, Vector2d instances are compatible with keyword class patterns—covered in\ndef keyword_pattern_demo(v: Vector2d) -> None:\ncase Vector2d(x=0, y=0):\ncase Vector2d(x=0):\nTo make Vector2d work with positional patterns, we need to add a class attribute\nnamed __match_args__ , listing the instance attributes in the order they will be used\nclass Vector2d:\ndef positional_pattern_demo(v: Vector2d) -> None:\ncase Vector2d(x, y) if x==y:\nThe __match_args__ class attribute does not need to include all public instance\nattributes.\nExample 11-11 is a consolidated, full listing of vector2d_v3.py, including the doctests\nvector2d_v3.py: the full monty\nA two-dimensional vector class\n>>> v1 = Vector2d(3, 4)\n>>> x, y = v1\nVector2d(3.0, 4.0)\nTest of ``.frombytes()`` class method:\n>>> v1_clone = Vector2d.frombytes(bytes(v1))\nVector2d(3.0, 4.0)\n>>> format(v1)\n>>> format(v1, '.2f')\n>>> format(v1, '.3e')\n>>> format(Vector2d(1, 1), 'p')  # doctest:+ELLIPSIS\n>>> format(Vector2d(1, 1), '.3ep')\n>>> format(Vector2d(1, 1), '0.5fp')\nAttributeError: can't set attribute 'x'\n>>> v1 = Vector2d(3, 4)\n>>> v2 = Vector2d(3.1, 4.2)\nclass Vector2d:\nreturn self.__x\nreturn (i for i in (self.x, self.y))\nclass_name = type(self).__name__\nreturn '{}({!r}, {!r})'.format(class_name, *self)\nreturn hash((self.x, self.y))\nreturn math.hypot(self.x, self.y)\nreturn math.atan2(self.y, self.x)\ndef __format__(self, fmt_spec=''):\nreturn outer_fmt.format(*components)\nAs coded in Example 11-11, Vector2d is a didactic example with a laundry list of spe‐\nclass.\nConsider this scenario: someone wrote a class named Dog that uses a mood instance\nExample 11-12 shows the result in the Vector2d class from Example 11-7.\nPrivate attribute names are “mangled” by prefixing the _ and the class\n>>> v1 = Vector2d(3, 4)\n{'_Vector2d__y': 4.0, '_Vector2d__x': 3.0}\n>>> v1._Vector2d__x\nVector2d by writing v1._Vector2d__x = 7.\njust one underscore prefix to “protect” attributes by convention (e.g., self._x).\nused in attribute names, but it’s a very strong convention among Python program‐\nmers that you should not access such attributes from outside the class.8 It’s easy to\nself._x is widespread, but calling that a “protected” attribute is not so common.\nTo conclude: the Vector2d components are “private” and our Vector2d instances are\nWe’ll now come back to our Vector2d class.\nattribute (not a method) that affects the internal storage of an object, with potentially\nBy default, Python stores the attributes of each instance in a dict named __dict__.\nBut if you define a class attribute named __slots__ holding a sequence of\nattribute names, Python uses an alternative storage model for the instance attributes:\nthe attributes named in __slots__ are stored in a hidden array or references that use\nThe Pixel class uses __slots__\nAttributeError: 'Pixel' object has no attribute '__dict__'\nAttributeError: 'Pixel' object has no attribute 'color'\nSet the p.x and p.y attributes normally.\nSecond effect: trying to set an attribute not listed in __slots__ raises\nIf you set attribute x (named in the __slots__ of the base class Pixel)…\nclass.\nAttributeError: 'ColorPixel' object has no attribute '__dict__'\nYou can set the attributes declared in the __slots__ of this class and super‐\nclasses, but no other.\n__slots__ list, your instances will keep attributes named in __slots__ in the per-\ninstance array of references, but will also support dynamically created attributes,\nAnother special per-instance attribute that you may want to keep is __weakref__,\namong the attributes named in __slots__.\nExample 11-16 shows the implementation of __slots__ in Vector2d.\nvector2d_v3_slots.py: the __slots__ attribute is the only addition to\nVector2d\nclass Vector2d:\nIn contrast, __slots__ lists the names of the instance attributes, which in this\na module with a Vector2d class variant as command-line argument, and uses a list\ncomprehension to build a list with 10,000,000 instances of Vector2d.\nshown in Example 11-17, I use vector2d_v3.Vector2d (from Example 11-7); in the\nmem_test.py creates 10 million Vector2d instances using the class\n$ time python3 mem_test.py vector2d_v3\nSelected Vector2d type: vector2d_v3.Vector2d\nCreating 10,000,000 Vector2d instances\n$ time python3 mem_test.py vector2d_v3_slots\nSelected Vector2d type: vector2d_v3_slots.Vector2d\nCreating 10,000,000 Vector2d instances\nreduced to 551 MiB when Vector2d has a __slots__ attribute.\nI designed the Vector2d class just to provide\nThe __slots__ class attribute may provide significant memory savings if properly\n• Instances will only be able to have the attributes listed in __slots__, unless you\n• Classes using __slots__ cannot use the @cached_property decorator, unless\nThe last topic in this chapter has to do with overriding a class attribute in instances\nOverriding Class Attributes\nA distinctive feature of Python is how class attributes can be used as default values for\ninstance attributes.\nIn Vector2d there is the typecode class attribute.\nin the __bytes__ method, but we read it as self.typecode by design.\ntor2d instances are created without a typecode attribute of their own, self.type\ncode will get the Vector2d.typecode class attribute by default.\nBut if you write to an instance attribute that does not exist, you create a new instance\nattribute—e.g., a typecode instance attribute—and the class attribute by the same\nshadowing the class attribute by the same name.\nThe default Vector2d.typecode is 'd', meaning each vector component will be rep‐\ntypecode of a Vector2d instance to 'f' prior to exporting, each component will be\nWe are discussing adding a custom instance attribute, therefore\nExample 11-18 uses the Vector2d implementation without\nCustomizing an instance by setting the typecode attribute that was\n>>> from vector2d_v3 import Vector2d\n>>> v1 = Vector2d(1.1, 2.2)\nOverriding Class Attributes \nSet typecode to 'f' in the v1 instance.\nVector2d.typecode is unchanged; only the v1 instance uses typecode 'f'.\nIf you want to change a class attribute, you must set it on the class directly, not\nBecause class attributes are public, they are\n>>> from vector2d_v3 import Vector2d\n>>> class ShortVector2d(Vector2d):  \nclass attribute.\nThis example also explains why I did not hardcode the class_name in Vector2d.\n# inside class Vector2d:\nclass_name = type(self).__name__\nreturn '{}({!r}, {!r})'.format(class_name, *self)\nIf I had hardcoded the class_name, subclasses of Vector2d like ShortVector2d would\na custom formatting code, exposing read-only attributes, and supporting hash() to\nThe aim of this chapter was to demonstrate the use of special methods and conven‐\nIs vector2d_v3.py (shown in Example 11-11) more Pythonic than vector2d_v0.py\nThe Vector2d class in vector2d_v3.py certainly exhibits\nBut whether the first or the last Vector2d implementation is\ngrammers to use, then it’s reasonable to implement special methods supporting\nPython special methods and coding conventions.\n• String/bytes representation methods: __repr__, __str__, __format__, and\n• Methods for reducing an object to a number: __abs__, __bool__, and __hash__\nstrings used with the str.format() method.\nthe instance attributes.\nattribute in Vector2d.\nThe last topic we covered was the overriding of a class attribute accessed via the\nWe did that first by creating an instance attribute,\nyou from the drudgery of implementing object protocols (aka dunder methods).\ncally equip your classes with several special methods.\nIn this chapter, we saw every special method related to object representation, except\nIn the initial versions of Vector2d, the x and y attributes were public, as are all\nPython instance and class attributes by default.\npair of variables, it’s also desirable to write my_vector.x and my_vector.y to get each\nWhen we felt the need to avoid accidental updates to the x and y attributes, we imple‐\ntor.x and my_vector.y. This shows that we can always start our classes in the simplest possible way, with\nof the code that already interacts with our objects through the names (e.g., x and y)\nwithout breaking all code that uses those attributes.\nIn Python, we can simply use public attributes, knowing we can change\nTo prove my point, I like to show this Java class (Example 11-20).\nanother class\nIn this chapter, we will create a class to represent a multidimensional Vector class—a\nVector will\n• Proper slicing support, producing new Vector instances\nstore the components in an array of floats, and will implement the methods needed\nimplementation of Vector that is compatible with our earlier Vector2d class—except\nHaving said that, the Vector class in this chapter is a didactic example and we’ll not\nChapter 12: Special Methods for Sequences\nVector Take #1: Vector2d Compatible\nHowever, by design, the Vector constructor is not compatible with the Vector2d\nExample 12-1 shows some ways of instantiating our new Vector\n>>> Vector([3.1, 4.2])\nVector([3.1, 4.2])\n>>> Vector((3, 4, 5))\nVector([3.0, 4.0, 5.0])\nVector([0.0, 1.0, 2.0, 3.0, 4.0, ...])\n(e.g., Vector2d(3, 4)) passed and produced the same result with a two-component\nVector([3, 4]).\nWhen a Vector has more than six components, the string pro‐\nExample 12-2 lists the implementation of our first version of Vector (this example\nvector_v1.py: derived from vector2d_v1.py\nclass Vector:\nVector Take #1: Vector2d Compatible \n1 The iter() function is covered in Chapter 17, along with the __iter__ method.\nreturn iter(self._components)  \nreturn f'Vector({components})'\nThe self._components instance “protected” attribute will hold an array with the\nVector components.\nUse reprlib.repr() to get a limited-length representation of self._components\nChapter 12: Special Methods for Sequences\nBuild a bytes object directly from self._components.\nBy the way, we could have subclassed Vector from Vector2d, but I chose not to do it\nexample of a class implementing the sequence protocol.\nVector Take #1: Vector2d Compatible \ncreate a fully functional sequence type in Python; you just need to implement the\nin Python entails just the __len__ and __getitem__ methods.\nThe FrenchDeck class in Example 12-3 takes advantage of many Python facilities\nChapter 12: Special Methods for Sequences\ning), Python 3.8 supports protocol classes: typing constructs, which\nclass.\nWe’ll now implement the sequence protocol in Vector, initially without proper sup‐\neasy if you can delegate to a sequence attribute in your object, like our self._compo\nclass Vector:\nreturn len(self._components)\nreturn self._components[index]\n>>> v1 = Vector([3, 4, 5])\n>>> v7 = Vector(range(7))\nslice of a Vector was also a Vector instance and not an array.\nTo make Vector produce slices as Vector instances, we can’t just delegate the slicing\nChapter 12: Special Methods for Sequences\nInspecting the attributes of the slice class\n<class 'slice'>\nIn Example 12-5, calling dir(slice) reveals an indices attribute, which turns out to\nIn our Vector code, we’ll not need the slice.indices() method because when we\nExample 12-6 lists the two methods needed to make Vector behave as a sequence:\nPart of vector_v2.py: __len__ and __getitem__ methods added to\nVector class from vector_v1.py (see Example 12-2)\nreturn len(self._components)\nreturn cls(self._components[key])  \nreturn self._components[index]  \n…get the class of the instance (i.e., Vector) and…\n…invoke the class to build another Vector instance from a slice of the\nThe operator.index() function calls the __index__ special method.\nand the special method were defined in PEP 357—Allowing Any Object to be Used\nChapter 12: Special Methods for Sequences\nOnce the code in Example 12-6 is added to the Vector class, we have proper slicing\nTests of enhanced Vector.__getitem__ from Example 12-6\n>>> v7 = Vector(range(7))\nVector([1.0, 2.0, 3.0])\nVector([6.0])\nA slice index creates a new Vector.\nVector Take #3: Dynamic Attribute Access\n>>> v = Vector(range(10))\nVector Take #3: Dynamic Attribute Access \n3 Although __match_args__ exists to support pattern matching in Python 3.10, setting this attribute is harmless\nIn Vector2d, we provided read-only access to x and y using the @property decorator\nhas an attribute named x; if not, the search goes to the class (my_obj.__class__), and\nmethod defined in the class of my_obj is called with self and the name of the\nattribute as a string (e.g., 'x').\nExample 12-8 lists our __getattr__ method.\nvector component.\nPart of vector_v3.py: __getattr__ method added to the Vector class\nGet the Vector class for later use.\nChapter 12: Special Methods for Sequences\nrather use a method like str.find here, but tuple doesn’t implement it.)\n>>> v = Vector(range(5))\nVector([0.0, 1.0, 2.0, 3.0, 4.0])\nVector([0.0, 1.0, 2.0, 3.0, 4.0])  \nHowever, the vector components did not change.\ntime if that value is not in the vector components array?\nworks: Python only calls that method as a fallback, when the object does not have the\nattribute, so __getattr__ will no longer be called to retrieve v.x: the interpreter will\nVector Take #3: Dynamic Attribute Access \njust return the value 10 that is bound to v.x. On the other hand, our implementation\nof __getattr__ pays no attention to instance attributes other than self._compo\nWe need to customize the logic for setting attributes in our Vector class in order to\nRecall that in the latest Vector2d examples from Chapter 11, trying to assign to the .x\nor .y instance attributes raised AttributeError.\nPart of vector_v3.py: __setattr__ method in the Vector class\nChapter 12: Special Methods for Sequences\ninstance raises AttributeError with the message \"can't set attribute\".\nones, to avoid confusion with the supported read-only attributes x, y, z, and t.\nting new instance attributes, it’s tempting to use that feature\nEven without supporting writing to the Vector components, here is an important\nBut Vector will\nOnce more we get to implement a __hash__ method.\n__eq__, this will make Vector instances hashable.\nThe __hash__ in Vector2d (Example 11-8) computed the hash of a tuple built with\nthe two components, self.x and self.y. Now we may be dealing with thousands of\nreduce is not as popular as before,4 but computing the hash of all vector components\nChapter 12: Special Methods for Sequences\nTo code Vector.__hash__ in my preferred style, we need to import the functools\nPart of vector_v4.py: two imports and __hash__ method added to the\nVector class from vector_v3.py\nclass Vector:\nhashes = (hash(x) for x in self._components)  \nAs implemented, the __hash__ method in Example 12-12 is a perfect example of a\nChapter 12: Special Methods for Sequences\nwe used in the __hash__ method of Example 12-8.\nThis works for Vector2d and for Vector—it even considers Vector([1, 2]) equal to\nFor Vector2d (with only two components), it’s a good shortcut, but not for the\nVector or iterable would be Example 12-13.\nExample 12-14 is the implementation we choose for __eq__ in vector_v4.py.\nChapter 12: Special Methods for Sequences\nWe wrap up this chapter by bringing back the __format__ method from Vector2d to\nVector.\nVector Take #5: Formatting\nThe __format__ method of Vector will resemble that of Vector2d, but instead of\nformat codes supported by built-in types.\nded mini-language also uses the float formatting codes 'eEfFgGn%'\nFor example, given a Vector object in 4D space (len(v) == 4), the 'h' code will pro‐\ndoctests of vector_v5.py (see Example 12-16):\n>>> format(Vector([-1, -1, -1, -1]), 'h')\n>>> format(Vector([2, 2, 2, 2]), '.3eh')\n>>> format(Vector([0, 1, 0, 0]), '0.5fh')\nChapter 12: Special Methods for Sequences\nthe Vector components array.\nExample 12-16 is a full listing of vector_v5.py consolidating all we’ve implemented\nvector_v5.py: doctests and all code for the final Vector class; callouts\nA multidimensional ``Vector`` class, take 5\n>>> Vector([3.1, 4.2])\nVector([3.1, 4.2])\n>>> Vector((3, 4, 5))\nVector([3.0, 4.0, 5.0])\nVector([0.0, 1.0, 2.0, 3.0, 4.0, ...])\nTests with two dimensions (same results as ``vector2d_v1.py``)::\n>>> v1 = Vector([3, 4])\n>>> x, y = v1\nVector([3.0, 4.0])\nTest of ``.frombytes()`` class method:\nVector Take #5: Formatting \nVector([3.0, 4.0])\n>>> v1 = Vector([3, 4, 5])\nVector([3.0, 4.0, 5.0])\n>>> v7 = Vector(range(7))\nVector([0.0, 1.0, 2.0, 3.0, 4.0, ...])\n>>> v1 = Vector([3, 4, 5])\nVector([3.0, 4.0, 5.0])\n>>> v1 = Vector([3, 4, 5])\nChapter 12: Special Methods for Sequences\n>>> v7 = Vector(range(7))\nVector([1.0, 2.0, 3.0])\nVector([6.0])\n>>> v7 = Vector(range(10))\nAttributeError: 'Vector' object has no attribute 'k'\n>>> v3 = Vector(range(3))\nAttributeError: 'Vector' object has no attribute 't'\nAttributeError: 'Vector' object has no attribute 'spam'\n>>> v1 = Vector([3, 4])\n>>> v2 = Vector([3.1, 4.2])\n>>> v3 = Vector([3, 4, 5])\n>>> v6 = Vector(range(6))",
      "keywords": [
        "vector",
        "vector class",
        "Python",
        "special methods",
        "format",
        "attribute",
        "Pythonic Object",
        "method",
        "Vector Class Redux",
        "Python special methods",
        "class attribute",
        "object",
        "instance attributes",
        "vector instances",
        "Vector components"
      ],
      "concepts": [
        "vector",
        "python",
        "pythonic",
        "examples",
        "classes",
        "formatted",
        "format",
        "method",
        "attributes",
        "useful"
      ],
      "similar_chapters": [
        {
          "book": "Fluent Python 2nd",
          "chapter": 16,
          "title": "",
          "score": 0.734,
          "base_score": 0.584,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 17,
          "title": "",
          "score": 0.675,
          "base_score": 0.525,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 364,
          "title": "",
          "score": 0.607,
          "base_score": 0.607,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 1,
          "title": "",
          "score": 0.528,
          "base_score": 0.528,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 13,
          "title": "",
          "score": 0.49,
          "base_score": 0.49,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "vector2d",
          "vector",
          "class",
          "format",
          "attribute"
        ],
        "semantic": [],
        "merged": [
          "vector2d",
          "vector",
          "class",
          "format",
          "attribute"
        ]
      },
      "topic_id": 1,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.40666580648217887,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:09.220152+00:00"
      }
    },
    {
      "chapter_number": 14,
      "title": "is an important follow-up to this one",
      "start_page": 513,
      "end_page": 686,
      "summary": "to static typing in Python, including static duck typing, addressed in their “Protocols\nnumeric types.\nThe MVP Journey of Python Static Typing\nfor adding the typing module, on which no other part of the standard library depen‐\nlike variable annotations, generic built-in types, and protocols.\nbuilt-in and standard library collections to accept generic type hints out of the box in\ntyping support.\nAfter I learned Go, the lack of static duck typing in Python was\nTyping Approaches in Popular Languages\npopular languages that support each of the typing approaches.\nFour approaches to type checking and some languages that support them.\ntyping quadrants would have languages in them.\nvalue in each of the four approaches to typing.\nBut monkey patching can also be useful, for example, to make a class implement a\nmenting a whole new class.\nJavaScript, Python does not let you monkey patch the built-in types.\nThis chapter is about inheritance and subclassing.\n• The pitfalls of subclassing from built-in types\n• Multiple inheritance and method resolution order\n• Mixin classes\nMultiple inheritance is the ability of a class to have more than one base class.\nHowever, we have to maintain existing systems designed with complex class hierar‐\nI will illustrate practical uses of multiple inheritance with the standard library, the\nchanged the examples in “Multiple Inheritance and Method Resolution Order” on\n1. Use super().__setitem__ to call that method on the superclass, to let it insert or\nclasses to do their part in initializing the instance.\nYou may have seen code that doesn’t use super(), but instead calls the method\nFirst, it hardcodes the base class.\nThe second reason is that super implements logic to handle class hierarchies with\nWe’ll come back to that in “Multiple Inheritance and Method\nsuper(LastUpdatedOrderedDict, self).__setitem__(key, value)\ntype\nBy default, it is the class that owns the method where the super() call appears.\nobject_or_type\nThe object (for instance method calls) or class (for class method calls) to be the\ndynamic proxy object that finds a method (such as __setitem__ in the example) in a\nsuperclass of the type parameter, and binds it to the object_or_type, so that we\nNow let’s discuss the caveats when subclassing built-in types.\nSubclassing Built-In Types Is Tricky\nIt was not possible to subclass built-in types such as list or dict in the earliest ver‐\nclasses.\nof built-in types get implicitly called or not.\nnever called by other built-in methods of the same object.\n>>> class DoppelDict(dict):\nThe __init__ method inherited from dict clearly ignored that __setitem__ was\nThe update method from dict does not use our version of __setitem__ either:\nthe search for methods should always start from the class of the receiver (self), even\nSubclassing Built-In Types Is Tricky \nPython is late bound like a virtual method, built-in objects written in C seem to have nonvirtual methods by\nto be called must be determined at runtime, based on the class of the receiver x.4\nself.__getitem__()—but also happens with overridden methods of other classes\n>>> class AnswerDict(dict):\nSubclassing built-in types like dict or list or str directly is error-\nInstead of subclassing the built-ins, derive your classes\n>>> class DoppelDict2(collections.UserDict):\n>>> class AnswerDict2(collections.UserDict):\nthe StrKeyDict class from Example 3-9 to subclass dict instead of UserDict.\nSubclassing Built-In Types Is Tricky \nwithin the C language code of the built-in types, and only affects classes derived\ndirectly from those types.\nIf you subclass a base class coded in Python, such as\nNow let’s focus on an issue that arises with multiple inheritance: if a class has two\nMultiple Inheritance and Method Resolution Order\nAny language implementing multiple inheritance needs to deal with potential nam‐\ndiamond.py: classes Leaf, A, B, Root form the graph in Figure 14-1\nclass Root:  \ncls_name = type(self).__name__\nclass A(Root):  \nclass B(Root):  \nclass Leaf(A, B):  \nThe ping and pong methods in class A both call super().\nOnly the ping method in class B calls super().\nClass Leaf implements only ping, and it calls super().\nNow let’s see the effect of calling the ping and pong methods on an instance of Leaf\nMultiple Inheritance and Method Resolution Order \n7 Classes also have a .mro() method, but that’s an advanced feature of metaclass programming, mentioned in\nof a class.\nCalling leaf1.ping() activates the ping methods in Leaf, A, B, and Root, because\nthe ping methods in the first three classes call super().ping().\n• The method resolution order of the Leaf class.\n• The use of super() in each method.\nEvery class has an attribute called __mro__ holding a tuple of references to the super‐\nclasses in method resolution order, from the current class all the way to the object\nclass.7 For the Leaf class, this is the __mro__:\n<class 'diamond1.Root'>, <class 'object'>)\nclass hierarchy.\nPython 2.3 Method Resolution Order”.\nbe activated in each of the classes depends on whether each implementation calls\nThe Leaf class does not override it,\ntherefore calling leaf1.pong() activates the implementation in the next class of\nLeaf.__mro__: the A class.\nMethod A.pong calls super().pong().\nThe B class is next\nmond.py (Example 14-4) the Leaf class was declared as Leaf(B, A), then class B\nping methods, and would also cause leaf1.pong() to activate B.pong via inheritance,\nWhen a method calls super(), it is a cooperative method.\nmultiple inheritance in Python requires the active cooperation of the methods\nIn the B class, ping cooperates, but pong does not.\nrecommended that every method m of a nonroot class should call\nPython is a dynamic language, so the interaction of super() with the MRO is also\ndiamond2.py: classes to demonstrate the dynamic nature of super()\nclass U():  \nclass LeafUA(U, A):  \nMultiple Inheritance and Method Resolution Order \nClass A comes from diamond.py (Example 14-4).\nThe 'super' object returned by super() has no attribute 'ping' because the MRO\nof U has two classes: U and object, and the latter has no attribute named 'ping'.\nNote the base classes of LeafUA are (U, A) in that order.\nin A.ping would activate Root.ping, and that method does not call super().\nIn a real program, a class like U could be a mixin class: a class intended to be used\ntogether with other classes in multiple inheritance, to provide additional functional‐\nmultiple inheritance graph of the Tkinter GUI toolkit from the Python standard\nLeft: UML diagram of the Tkinter Text widget class and superclasses.\nTo study the picture, start at the Text class at the bottom.\nThe Text class implements\nbut also inherits many methods from other classes.\nMultiple Inheritance and Method Resolution Order \nMixin Classes\nA mixin class is designed to be subclassed together with at least one other class in a\nA mixin is not supposed to be the only base class\nof a concrete class, because it does not provide all the functionality for a concrete\nMixin classes are a convention with no explicit language support in\nincluded to add functionality to a class.\nLet’s see a simple but handy example of a mixin class.\nExample 14-8 shows UpperCaseMixin, a class designed to provide case-insensitive\nclass UpperCaseMixin:  \nreturn super().get(_upper(key), default)\nThis helper function takes a key of any type, and tries to return key.upper(); if\nThe mixin implements four essential methods of mappings, always calling\nSince every method ot UpperCaseMixin calls super(), this mixin depends on a sibling\nclass that implements or inherits methods with the same signature.\ntribution, a mixin usually needs to appear before other classes in the MRO of a sub‐\nclass that uses it.\nuppermixin.py: two classes that use UpperCaseMixin\nclass UpperDict(UpperCaseMixin, collections.UserDict):  \nfirst base class, otherwise the methods from UserDict would be called instead.\nMixin Classes \n9 As previously mentioned, Java 8 allows interfaces to provide method implementations as well.\nFor example, my first version of UpperCaseMixin did not provide the get method.\nturn relies on the get method inherited from dict.\ndict class does not call __getitem__.\nThe next section covers several examples of multiple inheritance, often featuring\nmixin classes.\nIn the Design Patterns book,8 almost all the code is in C++, but the only example of\nIn Python, multiple inheritance is not the\nIn the Python standard library, the most visible use of multiple inheritance is the col\nprovide concrete method implementations.9\nPython’s official documentation of collections.abc uses the term mixin method for\nclasses.\nof the mixin methods provided by collections.abc.MutableMapping.\nThe http.server package provides HTTPServer and ThreadingHTTPServer classes.\nThis class is identical to HTTPServer but uses threads to handle requests by using\nThis is the complete source code for the ThreadingHTTPServer class in Python 3.10:\nclass ThreadingMixIn:\n\"\"\"Mixin class to handle each request in a new thread.\"\"\"\nIts implementation calls three instance methods that HTTPServer\nThis overrides the process_request method that HTTPServer inherits from sock\nThe concept of class-based views was introduced in Django 1.3, along with a set of\ngeneric view classes organized as base classes, mixins, and ready-to-use concrete\nclasses.\nIn Django 3.2, the base classes and mixins are in the base module of\n10 Django programmers know that the as_view class method is the most visible part of the View interface, but\nUML class diagram for the django.views.generic.base module.\nmethods in each class (inherited, overridden, and added methods),\nsource code on GitHub. View is the base class of all views (it could be an ABC), and it provides core function‐\nThe RedirectView class inherits only from View, and you can see that it implements\nConcrete subclasses of View are supposed to implement the handler methods, so why\nIt’s dynamic because the View class does not force subclasses to implement all han‐\nplateView, the inherited View.dispatch method checks that there is no post han‐\nFor Django users, the most important class in Figure 14-4 is ListView, which is an\naggregate class, with no code at all (its body is just a docstring).\nThe Django class-based views API is a better example of multiple inheritance than\nIn particular, it is easy to make sense of its mixin classes: each has a well-\nUML class diagram for the django.views.generic.list module.\nthe three classes of the base module are collapsed (see Figure 14-3).\nThe ListView class\nhas no methods or attributes: it’s an aggregate class.\nClass-based views were not universally embraced by Django users.\nIt does take some time to learn how to leverage class-based views and how to extend\nClass-based views are\nAn extreme example of multiple inheritance in Python’s standard library is the\nFigure 14-5 shows all the widget classes in the tkinter base package\nged «mixin» are designed to provide concrete methods to other classes via multiple\nConsider these classes from Figure 14-5:\nHere are the MROs of those classes, displayed by the print_mro function from\nBy current standards, the class hierarchy of Tkinter is very deep.\nclass library.\nwhere inheritance is most useful.\n• Toplevel is the only graphical class that does not inherit from Widget, because it\nFavor Object Composition over Class Inheritance\ntkinter.Widget class, instead of inheriting the methods from all geometry managers,\nable to different classes, but cannot replace the use of interface inheritance to define a\nhierarchy of types.\nWhen dealing with multiple inheritance, it’s useful to keep straight the reasons why\n• Inheritance of implementation avoids code duplication by reuse.\nInheritance for code reuse is an implementation detail, and it can often be\nInterface inheritance should use only ABCs as base\nclasses, if possible.\nIn modern Python, if a class is intended to define an interface, it should be an explicit\nABC or a typing.Protocol subclass.\nIf a class is designed to provide method implementations for reuse by multiple unre‐\nmixin class.\nConceptually, a mixin does not define a new type; it merely bundles\nA mixin should never be instantiated, and concrete classes should\nany internal state; i.e., a mixin class should not have instance attributes.\nThere is no formal way in Python to state that a class is a mixin, so it is highly recom‐\nProvide Aggregate Classes to Users\nA class that is constructed primarily by inheriting from mixins and does not add its\nown structure or behavior is called an aggregate class.\nFor example, here is the complete source code for the Django ListView class on the\nThe body of ListView is empty, but the class provides a useful service: it brings\ntogether a mixin and a base class that should be used together.\nAnother example is tkinter.Widget, which has four base classes and no methods or\nThanks to the Widget aggregate class, we can\nSubclass Only Classes Designed for Subclassing\nSubclassing any complex class and overriding its methods is error-\ning methods, or at least restrain yourself to subclassing classes\nThat’s great advice, but how do we know whether or how a class was designed to be\nframework for network servers.” Its BaseServer class is designed for subclassing, as\nsource code of the class explicitly note which of its methods are intended to be over‐\nthat can be applied to classes or individual methods, so that IDEs or type checkers\ncan report misguided attempts to subclass those classes or override those methods.14\nAvoid Subclassing from Concrete Classes\nSubclassing concrete classes is more dangerous than subclassing ABCs and mixins,\nEffective C++, which says: “all non-leaf classes should be abstract.” In other words,\nMeyer recommends that only abstract classes should be subclassed.\nbe in mixin methods of ABCs or in explicitly named mixin classes.\nClass Inheritance” on page 510.\nThe docstring of tkinter.Widget starts with the words “Internal class.” This suggests\nThe Tk class, which encapsulates the GUI application logic, inherits from Wm and\nMisc has more than 100 methods, and all widgets inherit from it.\nMisc should be split into several specialized mixin classes,\nand not all widgets should inherit from every one of those mixins.\nTo be fair, as a Tkinter user, you don’t need to know or use multiple inheritance at\nIt’s an implementation detail hidden behind the widget classes that you will\nexcessive multiple inheritance when you type dir(tkinter.Button) and try to find\nWe then discussed the problem with subclassing built-in types: their\nnative methods implemented in C do not call overridden methods in subclasses,\nstr type, it’s easier to subclass UserList, UserDict, or UserString—all defined in the\ncollections module, which actually wrap the corresponding built-in types and dele‐\nFirst we saw how the method resolution order, encoded in the __mro__ class\nattribute, addresses the problem of potential naming conflicts in inherited methods.\nmixin classes, which we then studied through the simple example of the UpperCase\nWe saw how multiple inhertance and mixin methods are used in Python’s ABCs, as\nmultiple inheritance were exemplified by Django’s class-based views and the Tkinter\nexample of overly complex class hierarchies we may find in legacy systems.\nand applied some of that advice in a commentary of the Tkinter class hierarchy.\nlar to what we now have with protocol types since Python 3.8.\nfor building types and interfaces by composition, but it does not support inheritance\nbut especially don’t mix the various types of inheritance, and don’t use subclassing for\nfunctions in depth before classes and inheritance.\nyou can accomplish with functions leveraging existing classes from the standard\nlibrary, before creating your own classes.\nSubclassing built-ins, the super function, and advanced features like descriptors and\nclasses in Python 2.2”.\ndirectly or indirectly—to create a so-called “new style class.” In Python 3, every class\nseveral recipes showing the use of super() and mixin classes.\nings of super and multiple inheritance in Python from a positive perspective.\nionato has a long series of blog posts about multiple inheritance in Python, including\n“The wonders of cooperative inheritance, or using super in Python 3”; “Mixins con‐\navoiding the tight coupling and failure modes of classes and inheritance.\nThink about the Classes You Really Need\nWhen we write applications, we normally don’t need to code class hier‐\nAt most, we write classes that subclass from ABCs or other classes provided\nclass that will act as the superclass of another.\nThe classes we code are almost always\nleaf classes (i.e., leaves of the inheritance tree).\nclass hierarchies, it’s likely that one or more of the following applies:\ndesigned framework, which is forcing you to code class after class to solve trivial\nThe built-in dict, list, and str types are essential building blocks of Python itself,\nof those types: one “internal,” optimized for use by the interpreter, and an external,\nThe first popular language to implement multiple inheritance was C++, and the fea‐\nwithout support for multiple inheritance of implementation (i.e., no mixin classes).\nthe abstract classes used to define interfaces in C++ and in Python.\nA Ruby class can include a module in its body, so\nthe methods defined in the module become part of the class implementation.\nhas no influence on the type of the class where it’s used.\nJulia has a type hierarchy but subtypes cannot inherit\nMore About Type Hints\nThis chapter is a sequel to Chapter 8, covering more of Python’s gradual type system.\n• typing.TypedDict for type hinting dicts used as records\n• Type casting\n• Runtime access to type hints\n• Generic types\nticularly important when the return type of the function depends on the type of two\nThe sum built-in is written in C, but typeshed has overloaded type hints for it, in\nThe type checker tries to match the given arguments with each overloaded signature,\nExample 15-1 shows how sum would appear annotated and implemented in a Python\nChapter 15: More About Type Hints\nfrom typing import overload, Union, TypeVar\nThe result type may be T\nIf we reused T, then the type of start would have to be\nthe same type as the elements of Iterable[T].\nThe signature of the actual function implementation has no type hints.\nAiming for 100% of annotated code may lead to type hints that add\nIt is difficult to add type hints to functions that leverage the powerful dynamic fea‐\n# overloaded type hints omitted, see next listing\nChapter 15: More About Type Hints\nfrom typing import Protocol, Any, TypeVar, overload, Union\nMy Python implementation of max is about the same length as all those typing\nchecks, and provides the same error checking as those type hints—but only at run‐\nA key benefit of @overload is declaring the return type as precisely as possible,\nArguments implementing SupportsLessThan, but key and default not provided\nIn these cases, the inputs are either separate arguments of type LT implementing\nThe return type of max is the same\nThe inputs can be separate items of any type T or a single Iterable[T], and key=\nmust be a callable that takes an argument of the same type T, and returns a value that\nChapter 15: More About Type Hints\nThe return type of max is the same as the actual argu‐\nmax(['Go', 'Python', 'Rust'], key=len)  # returns 'Python'\nThe input is an iterable of items of type LT implementing SupportsLessThan.\nreturn type of max must be a Union of type LT and the type of the default argument.\n• An Iterable of items of any type T\n• Callable that takes an argument of type T and returns a value of type LT that\n• A default value of any type DT\nThe return type of max must be a Union of type T or the type of the default\nType hints allow Mypy to flag a call like max([None, None]) with this error message:\nmymax_demo.py:109: error: Value of type variable \"_LT\" of \"max\"\nOn the other hand, having to write so many lines to support the type checker may\ndone at runtime, and not with static type checking.\nchecking of JSON-like structures using type hints, check out the\nand field values of different types.\nFor example, consider a record describing a book in JSON or Python:\nmapping types we saw in “Generic Mappings” on page 276 limit all values to have the\nsame type.\nThe values may be of any type.\nChapter 15: More About Type Hints\nPEP 589—TypedDict: Type Hints for Dictionaries with a Fixed Set of Keys addressed\nfrom typing import TypedDict\nclass BookDict(TypedDict):\nAt first glance, typing.TypedDict may seem like a data class builder, similar to\ntyping.NamedTuple—covered in Chapter 5.\n• Class-like syntax to annotate a dict with type hints for the value of each “field.”\n• A constructor that tells the type checker to expect a dict with the keys and values\n>>> type(pp)\n<class 'dict'>\n{'isbn': <class 'str'>, 'title': <class 'str'>, 'authors': typing.List[str],\n'pagecount': <class 'int'>}\nThe type hints are in BookDict.__annotations__, and not in pp.\nWithout a type checker, TypedDict is as useful as comments: it may help people read\nIn contrast, the class builders from Chapter 5 are useful even if\nyou don’t use a type checker, because at runtime they generate or enhance a custom\nclass that you can instantiate.\nThey also provide several useful methods or functions\nfrom typing import TYPE_CHECKING\nChapter 15: More About Type Hints\nif TYPE_CHECKING:  \nreveal_type(authors)  \nRemember to add a return type, so that Mypy doesn’t ignore the function.\nThis is a valid BookDict: all the keys are present, with values of the correct types.\nMypy will infer the type of authors from the annotation for the 'authors' key\nThe previous if statement prevents reveal_type(authors) from being called at\nreveal_type is not a runtime Python function, but a debugging facility\nType checking demo_books.py from Example 15-6, we get Example 15-7.\nType checking demo_books.py\ndemo_books.py:13: note: Revealed type is 'built-ins.list[built-ins.str]'  \ndemo_books.py:14: error: Incompatible types in assignment\ndemo_books.py:15: error: TypedDict \"BookDict\" has no key 'weight'  \ndemo_books.py:16: error: Key 'title' of TypedDict \"BookDict\" cannot be deleted  \nThe type of the authors variable was inferred from the type of the book['au\nNow let’s see BookDict used in function signatures, to type check function calls.\nChapter 15: More About Type Hints\n2016 in Mypy issue #182: Define a JSON type.\nbecause it inferred the type of value returned from book.items() as object,\nExample 15-9 shows a function that parses a JSON str and returns a BookDict.\nThe return type of json.loads() is Any.6\nincluding the declared return type, BookDict.\nbooks_any.py:30: error: Expression has type \"Any\"\nbooks_any.py:31: error: Expression has type \"Any\"\nNow whatever is of type BookDict, the declared return type.\nDon’t be lulled into a false sense of type safety by Example 15-10!\nStatic type checking is unable to prevent errors with code that is inherently dynamic,\nsuch as json.loads(), which builds Python objects of different types at runtime, as\nfrom typing import TYPE_CHECKING\nif TYPE_CHECKING:  \nreveal_type(not_book)\nreveal_type(not_book['authors'])\nChapter 15: More About Type Hints\nThis should not be a problem: print can handle object and every other type.\ndemo_not_book.py:12: note: Revealed type is\ndemo_not_book.py:13: note: Revealed type is 'built-ins.list[built-ins.str]'  \ndemo_not_book.py:16: error: TypedDict \"BookDict\" has no key 'flavor'  \nThe revealed type is the nominal type, not the runtime content of not_book.\nAgain, this is the nominal type of not_book['authors'], as defined in BookDict.\nNot the runtime type.\nnominal type.\nUsing a TypedDict while handling JSON data did not provide much type\nIf you look at the code for to_xml in Example 15-8 through the lens of duck typing,\nthe argument book must provide an .items() method that returns an iterable of\n• key must have an .upper() method\nType Casting\nThe typing.cast() special function provides one way to handle type checking mal‐\nfunctions or incorrect type hints in code we can’t fix.\nChapter 15: More About Type Hints\n7 The use of enumerate in the example is intended to confuse the type checker.\n\"\"\"Cast a value to a type.",
      "keywords": [
        "multiple inheritance",
        "Python",
        "Type",
        "inheritance",
        "Type Hints",
        "method",
        "classes",
        "method resolution order",
        "super",
        "key",
        "Mixin classes",
        "built-in types",
        "multiple",
        "subclassing built-in types",
        "Mixin"
      ],
      "concepts": [
        "classes",
        "typing",
        "type",
        "typed",
        "methods",
        "python",
        "pythonic",
        "examples",
        "object",
        "function"
      ],
      "similar_chapters": [
        {
          "book": "Fluent Python 2nd",
          "chapter": 21,
          "title": "",
          "score": 0.914,
          "base_score": 0.764,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 11,
          "title": "",
          "score": 0.755,
          "base_score": 0.605,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 13,
          "title": "",
          "score": 0.687,
          "base_score": 0.537,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 488,
          "title": "",
          "score": 0.679,
          "base_score": 0.529,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 1,
          "title": "",
          "score": 0.656,
          "base_score": 0.506,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "class",
          "type",
          "inheritance",
          "mixin",
          "multiple inheritance"
        ],
        "semantic": [],
        "merged": [
          "class",
          "type",
          "inheritance",
          "mixin",
          "multiple inheritance"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.42660243862837455,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:09.220178+00:00"
      }
    },
    {
      "chapter_number": 18,
      "title": "with, match, and else Blocks",
      "start_page": 687,
      "end_page": 724,
      "summary": "1 PyCon US 2013 keynote: “What Makes Python Awesome”; the part about with starts at 23:00 and ends at\nContext managers may end up being almost as important as the subroutine itself.\n• The with statement and context manager protocol\ncontrol of a context manager object.\n“Pattern Matching in lis.py: A Case Study” on page 669 is a new section.\nlib module added since Python 3.6, and the new parenthesized context managers\nContext Managers and with Blocks\nContext manager objects exist to control a with statement, just like iterators exist to\nblock is terminated by return, an exception, or a sys.exit() call.\nThe Python community is finding new, creative uses for context managers.\nThe context manager interface consists of the __enter__ and __exit__ methods.\nthe top of the with, Python calls the __enter__ method of the context manager\nWhen the with block completes or terminates for any reason, Python calls\n__exit__ on the context manager object.\nThe most common example is making sure a file object is closed.\nDemonstration of a file object as a context manager\nfp is bound to the opened text file because the file’s __enter__ method returns\nThe fp variable is still available—with blocks don’t define a new scope, as func‐\nager object is the result of evaluating the expression after with, but the value bound\nmethod of the context manager object.\nIt just happens that the open() function returns an instance of TextIOWrapper, and\nits __enter__ method returns self.\nmay also return some other object instead of the context manager instance.\non the context manager object, not on whatever was returned by __enter__.\nContext Managers and with Blocks \nExample 18-2 shows the operation of a perfectly frivolous context manager designed\nto highlight the distinction between the context manager and the object returned by\nTest-driving the LookingGlass context manager class\nThe context manager is an instance of LookingGlass; Python calls __enter__ on\nthe context manager and the result is bound to what.\nWe can see that the value returned by __enter__,\nmirror.py: code for the LookingGlass context manager class\nPython invokes __enter__ with no arguments besides self.\nPython calls __exit__ with None, None, None if all went well; if an exception is\nIf __exit__ returns None or any falsy value, any exception raised in the with\ncontext manager does exactly that: just pass it the file-like object\nContext Managers and with Blocks \nFor a detailed look at how a context manager works, see Example 18-4, where\nCall the manager’s __enter__ method and store result in monster.\nCall manager.__exit__ to restore the previous stdout.write.\nParenthesized Context Managers in Python 3.10\nand decorators for building, combining, and using context managers.\nBefore rolling your own context manager classes, take a look at contextlib—“Utilit‐\nBesides the redirect_stdout context manager mentioned right after Example 18-3,\nA function to build context managers out of objects that provide a close()\nA context manager to temporarily ignore exceptions given as arguments.\nobjects that may not implement a suitable context manager.\ntext manager for the with statement—added in Python 3.7.\nContext Managers and with Blocks \nA decorator that lets you build a context manager from a simple generator func‐\nAn ABC that formalizes the context manager interface, and makes it a bit easier\nto create context manager classes by subclassing—added in Python 3.6.\nA base class for defining class-based context managers that can also be used as\nfunction decorators, running the entire function within a managed context.\nA context manager that lets you enter a variable number of context managers.\nWhen the with block ends, ExitStack calls the stacked context managers’\nyou don’t know beforehand how many context managers you need to enter in\nyour with block; for example, when opening all files from an arbitrary list of files\nthree distinctive Python features: a function decorator, a generator, and the with\nUsing @contextmanager reduces the boilerplate of creating a context manager:\ninstead of writing a whole class with __enter__/__exit__ methods, you just imple‐\n__enter__ method to return.\nIn a generator decorated with @contextmanager, yield splits the body of the function\nwith block when the interpreter calls __enter__; the code after yield will run when\nfunction.\nmirror_gen.py: a context manager implemented with a generator\nExample 18-6 shows the looking_glass function in operation.\nTest-driving the looking_glass context manager function\nContext Managers and with Blocks \ncode in Lib/contextlib.py in Python 3.10.\nThe only difference from Example 18-2 is the name of the context manager: look\nThe contextlib.contextmanager decorator wraps the function in a class that imple‐\ngenerator function body.\nExample 18-5 has a flaw: if an exception is raised in the body of the with block, the\nPython interpreter will catch it and raise it again in the yield expression inside look\nExample 18-7 adds special handling of the ZeroDivisionError exception, making it\nfunctionally equivalent to the class-based Example 18-3.\nmirror_gen_exc.py: generator-based context manager implementing\nby returning a truthy value; in that case, the interpreter suppresses the exception.\nContext Managers and with Blocks \nExample 18-8 shows the looking_glass context manager from Example 18-5 used as\nThe looking_glass context manager also works as a decorator\nContrast Example 18-8 with Example 18-6, where looking_glass is used as a context\nA context manager for rewriting files in place\nThe inplace function is a context manager that gives you two handles—infh and\nspecial forms like (define …), (if …), and (quote …) that don’t behave at all like function calls.\nIt’s easier to use than the standard library’s fileinput.input function\n(which also provides a context manager, by the way).\nThis concludes our overview of the with statement and context managers.\nto match/case in the context of a complete example.\nPattern Matching in lis.py: A Case Study\nsequence patterns extracted from the evaluate function of Peter Norvig’s lis.py inter‐\nlis.py works, and also explore all the case clauses of evaluate, explaining not only the\n1. Norvig’s lis.py is a beautiful example of idiomatic Python code.\n3. Learning how an interpreter works gave me a deeper understanding of Python\nBefore looking at the Python code, let’s get a little taste of Scheme so you can make\nIn Scheme there is no distinction between expressions and statements, like we have in\nPython.\nassignment statement x = 13 in Python.\nPattern Matching in lis.py: A Case Study \n7 To make iteration through recursion practical and efficient, Scheme and other functional languages imple‐\nExample 18-10 shows three Scheme expressions: two function definitions—mod and\nExample 18-11 is the same code in Python (shorter than an English explanation of\nSame as Example 18-10, written in Python\nfunction definitions, and make the examples as similar as possible, to help you read\nNow let’s review the code of the Python 3.10 version of lis.py.\nExample 18-12 shows the first lines of lis.py.\nThe building blocks of Scheme programs are expressions made of atoms and\nNorvig’s parser is 36 lines of code showcasing the power of Python applied to han‐\nPattern Matching in lis.py: A Case Study \nlis.py: the main parsing functions\ndef read_from_tokens(tokens: list[str]) -> Expression:\nThe main function of that group is parse, which takes an S-expression as a str and\nreturns an Expression object, as defined in Example 18-12: an Atom or a list that\nScheme of lis.py, so every '(' or ')' is an expression delimiter.\ncode is in read_from_tokens, a 14-line function that you can read in the fluentpy‐\nidentifiers in Scheme but not in Python.\n3. Expressions inside '(' and ')' are recursively parsed as lists containing atoms or\nUsing the terminology of the Python interpreter, the output of parse is an AST\nA Scheme lambda expression represented as source code (concrete syntax),\nlis.py: the Environment class\nPattern Matching in lis.py: A Case Study \nenv.change('b', 333) seeks the 'b' key and assigns a new value to it in-place,\nNext is the standard_env() function, which builds and returns an Environment\nloaded with predefined functions, similar to Python’s __builtins__ module that is\nlis.py: standard_env() builds and returns the global environment\ndef standard_env() -> Environment:\nenv = Environment()\nREPL that accepts partial S-expressions and prompts for the continuation, similar to how Python’s REPL\nreturn env\n• All functions from Python’s math module\n• Selected operators from Python’s op module\n• Simple but powerful functions built with Python’s lambda\n• Python built-ins renamed, like callable as procedure?, or directly mapped, like\nPattern Matching in lis.py: A Case Study \nval = evaluate(ast, global_env)\nCalls standard_env() to provide built-in functions for the global environment,\nthen enters an infinite loop, reading and parsing each input line, evaluating it in\nnew global variable or named function, it is stored in the first mapping of the\nThe inverse function of parse: given a Python object representing an expression,\nparse returns the Scheme source code for it.\nThe evaluate function in Example 18-17 takes an Expres\nThe body of evaluate is a single match statement with an expression exp as the sub‐\nThe case patterns express the syntax and semantics of Scheme with amazing\nevaluate takes an expression and computes its value\ndef evaluate(exp: Expression, env: Environment) -> Any:\n\"Evaluate an expression in an environment.\"\nif evaluate(test, env):\nreturn evaluate(consequence, env)\nreturn evaluate(alternative, env)\nreturn Procedure(parms, body, env)\ncase ['define', Symbol(name), value_exp]:\nenv[name] = evaluate(value_exp, env)\ncase ['define', [Symbol(name), *parms], *body] if body:\ncase ['set!', Symbol(name), value_exp]:\nenv.change(name, evaluate(value_exp, env))\nproc = evaluate(func_exp, env)\nvalues = [evaluate(arg, env) for arg in args]\ning an S-expression that would match the pattern when parsed into a Python list.\nDoctests extracted from examples_test.py demonstrate each case.\nPattern Matching in lis.py: A Case Study \n>>> from lis import parse, evaluate, standard_env\nLook up var in env and return its value.\n>>> evaluate(parse('+'), standard_env())\n>>> evaluate(parse('ni!'), standard_env())\nList starting with the symbol 'quote', followed by one expression x.\nReturn x without evaluating it.\n>>> evaluate(parse('(quote no-such-name)'), standard_env())\n>>> evaluate(parse('(quote (99 bottles of beer))'), standard_env())\n>>> evaluate(parse('(quote (/ 10 0))'), standard_env())\nSymbol naming a special form, operator, or function\nAlthough simple, quote cannot be implemented as a function in Scheme.\npower is to prevent the interpreter from evaluating (f 10) in the expression (quote\n• To manage the environment, as in define and set\nThink about Python’s def, if, yield, import, del, and what they do.\nif evaluate(test, env):\nreturn evaluate(consequence, env)\nreturn evaluate(alternative, env)\n• If true, evaluate consequence and return its value.\n• Otherwise, evaluate alternative and return its value.\nPattern Matching in lis.py: A Case Study \n>>> evaluate(parse('(if (= 3 3) 1 0))'), standard_env())\n>>> evaluate(parse('(if (= 3 4) 1 0))'), standard_env())\nexp2…), provided as a function in lis.py—see Example 18-15.\nScheme’s lambda form defines anonymous functions.\ntations of Python’s lambda: any function that can be written in Scheme can be written\nreturn Procedure(parms, body, env)\nCreate and return a new Procedure instance with the parameter names, the list\n>>> f = evaluate(parse(expr), standard_env())\nparameter names, a function body, and a reference to the environment in which the\nfunction is defined.\ncase ['define', Symbol(name), value_exp]:\nenv[name] = evaluate(value_exp, env)\nList starting with 'define', followed by a Symbol and an expression.\nEvaluate the expression and put its value into env, using name as key.\n>>> evaluate(parse('(define answer (* 7 6))'), global_env)\nThe doctest for this case creates a global_env so that we can verify that evaluate\nmous functions, using (lambda …) as the value_exp.\nStandard Scheme provides a shortcut for defining named functions.\ncase ['define', [Symbol(name), *parms], *body] if body:\nThe doctest in Example 18-18 defines a function named % that computes a percentage\nPattern Matching in lis.py: A Case Study \nDefining a function named % that computes a percentage\n>>> evaluate(parse(percent), global_env)\nform changes the value of a previously defined variable.11\ncase ['set!', Symbol(name), value_exp]:\nenv.change(name, evaluate(value_exp, env))\nList starting with 'set!', followed by a Symbol and an expression.\nUpdate the value of name in env with the result of evaluating the expression.\nimplementing the 'set!' keyword, we could use Python’s ChainMap as the Environ\nPython’s nonlocal and Scheme’s set!\nform is related to the use of the nonlocal keyword in Python:\nenvironment of the function.\nCreates a new closure with the inner function defined by lambda, and the vari‐\nNow we get to a function call.\nPattern Matching in lis.py: A Case Study \nFunction call\nproc = evaluate(func_exp, env)\nvalues = [evaluate(arg, env) for arg in args]\n'lambda', 'set!']—listed right before evaluate in Example 18-17.\nThe pattern matches any list with one or more expressions, binding the first\n• Evaluate func_exp to obtain a function proc.\n• Evaluate each item in args to build a list of argument values.\n>>> evaluate(parse('(% (* 12 14) (- 500 100))'), global_env)\nThis doctest continues from Example 18-18: it assumes global_env has a function\narguments are evaluated before the function is called.\n>>> evaluate(parse('(lambda is not like this)'), standard_env())\nIf the case for function call did not have that guard rejecting keywords, the (lambda\nis not like this) expression would be handled as a function call, which would\nnot a Python built-in function.\nthe function.\nThe environment is used when the function is called to provide the val‐\nWe learned how to use closures in Python, but now we can dive deeper and see how a\nself, parms: list[Symbol], body: list[Expression], env: Environment\nresult = evaluate(exp, env)\nCalled when a function is defined by the lambda or define forms.\nSave the parameter names, body expressions, and environment for later use.\nCalled by proc(*values) in the last line of the case [func_exp, *args] clause.\nenvironment that was saved when the function was defined.\nPattern Matching in lis.py: A Case Study \nIterate over each expression in self.body, evaluating it in the combined env.\nReturn the result of the last expression evaluated.\nThere are a couple of simple functions after evaluate in lis.py: run reads a complete\nI will not describe those functions because\nmatch/case is a great addition to Python.\nIn the context of a case clause, the | operator has a special mean‐\nexpressions like a | b in other contexts, where it is overloaded to\nreturn Procedure(parms, body, env)\nIn all cases, the else clause is also skipped if an exception or a return, break, or\nUsing else with these statements often makes the code easier to read and saves the\nFor clarity and correctness, the body of a try block should only have the statements\nThis common Python coding style\nand “the leaping.” For example, the code, if key in mapping: return mapping[key]\nThis chapter started with context managers and the meaning of the with statement,\nimplemented a custom context manager: the LookingGlass class with the\n@contextmanager decorator, makes it possible to implement a context manager using\nfunction, and discussed how to do exception handling when using @contextmanager.\nThen we studied Peter Norvig’s elegant lis.py, a Scheme interpreter written in\nidiomatic Python, refactored to use match/case in evaluate—the function at the\nChapter 8, “Compound Statements,” in The Python Language Reference says pretty\nThe Python Standard Library, Chapter 4, “Built-in Types,” has a section devoted to\nmented in The Python Language Reference in “With Statement Context Managers”.\nContext managers were introduced in PEP 343—The “with” Statement.\nthe examples using context managers with the pycairo graphics library.\nDefining Context Managers the Easy Way” introduces a context man‐\nager for timing code, and another for making transactional changes to a list object:\nPython))”.\nitory fluentpython/lispy includes the mylis forks of lis.py, updated to Python 3.10, with\nThe bit about context managers is from 23:00 to 26:15.\nStandard Scheme implementations are required to provide proper tail calls (PTC), to\nA tail call is when a function returns the result of a function call, which may be the\nsame function or not.\nPython does not have PTC, so there’s no advantage in writing tail recursive functions.\nuses, don’t forget that Python has math.factorial, written in C without recursion.\nrecursive function, only those that are carefully written to make tail calls.\nthe body of the called function without creating a new stack frame, saving memory.\nThe Case Against Proper Tail Calls in Python and JavaScript\nThere are cases when recursion is the best solution, even in Python without PTC.\n[…] a typical Python implementation allows 1000 recursions, which is plenty for\nin evaluate and the code in the case for function calls: that combination makes the\neven though Python does not implement PTC, it’s possible and not very hard to write\nan interpreter, in Python, that does implement PTC.\nI shared the code for the Python 3.10 version of lis.py with Peter Norvig.\nbefore the case for function calls.\ncase clauses demonstrate more features of pattern matching, and the code is more",
      "keywords": [
        "context manager",
        "Python",
        "Context",
        "context manager object",
        "env",
        "case",
        "manager",
        "function",
        "Scheme",
        "Blocks",
        "Python calls",
        "Pattern matching",
        "call",
        "Environment",
        "Case Study"
      ],
      "concepts": [
        "examples",
        "python",
        "pythonic",
        "functional",
        "function",
        "functions",
        "evaluating",
        "evaluate",
        "evaluator",
        "evaluation"
      ],
      "similar_chapters": [
        {
          "book": "Fluent Python 2nd",
          "chapter": 1,
          "title": "",
          "score": 0.633,
          "base_score": 0.483,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 13,
          "title": "",
          "score": 0.599,
          "base_score": 0.449,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 10,
          "title": "",
          "score": 0.575,
          "base_score": 0.425,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 20,
          "title": "",
          "score": 0.557,
          "base_score": 0.407,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 21,
          "title": "",
          "score": 0.537,
          "base_score": 0.387,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "manager",
          "evaluate",
          "context manager",
          "context",
          "env"
        ],
        "semantic": [],
        "merged": [
          "manager",
          "evaluate",
          "context manager",
          "context",
          "env"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.34459769627193415,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:09.220203+00:00"
      }
    },
    {
      "chapter_number": 19,
      "title": "Concurrency Models in Python",
      "start_page": 725,
      "end_page": 752,
      "summary": "modern laptop with 4 CPU cores is routinely running more than 200 processes at any\ncompare Python’s core packages for concurrent programming: threading, multi\nprocessing, and asyncio.\nbecause Python’s fitness for concurrent and parallel computing is not limited to what\nThe spinner examples in\napproaches to concurrency: threads, processes, and native coroutines.\non the most basic factor: starting threads or processes is easy enough, but how do you\nChapter 19: Concurrency Models in Python\nThose familiar options are not available when you start a thread or process: you don’t\nAdditionally, starting a thread or a process is not cheap, so you don’t want to start\ntize the startup cost by making each thread or process into a “worker” that enters a\nand that can make them as hard to monitor as threads or processes.\nFinally, Python coroutines and threads are not suitable for CPU-intensive tasks, as\ncesses, threads, and coroutines.\nThread\nWhen a process starts, it uses a single\nthread: the main thread.\nA process can create more threads to operate concur‐\nrently by calling operating system APIs. Threads within a process share the same\nLike processes, threads also enable pre‐\nA thread con‐\nIn Python, classic coroutines\nPython coroutines usually run within a single\nthread under the supervision of an event loop, also in the same thread.\ntive multitasking supported by processes and threads.\ncoroutine consumes less resources than a thread or process doing the same job.\nChapter 19: Concurrency Models in Python\npackage in Python’s standard library provides queue classes to support threads,\nCPU contention, when compute-intensive processes or threads must wait for the\nNow let’s use some of that jargon to understand concurrency support in Python.\nProcesses, Threads, and Python’s Infamous GIL\n1. Each instance of the Python interpreter is a process.\nPython processes using the multiprocessing or concurrent.futures libraries.\nPython’s subprocess library is designed to launch processes to run external pro‐\n2. The Python interpreter uses a single thread to run the user’s program and the\nYou can start additional Python threads using the\nthreading or concurrent.futures libraries.\nOnly one Python thread can\nThis means that only one thread can execute Python\ncode at any time, regardless of the number of CPU cores.\n4. To prevent a Python thread from holding the GIL indefinitely, Python’s bytecode\ninterpreter pauses the current Python thread every 5ms by default,4 releasing the\nThe thread can then try to reacquire the GIL, but if there are other threads\n5. When we write Python code, we have no control over the GIL.\nPython/C API level—can release the GIL while running time-consuming tasks.\n6. Every Python standard library function that makes a syscall5 releases the GIL.\nPython threads that are not affected by the GIL.\nSuch GIL-free threads generally\n8. The effect of the GIL on network programming with Python threads is relatively\nConsequently, each individual thread spends a lot of time waiting anyway,\n9. Contention over the GIL slows down compute-intensive Python threads.\nSequential, single-threaded code is simpler and faster for such tasks.\nTo run CPU-intensive Python code on multiple cores, you must use multiple\nPython processes.\nonly one thread can execute Python code at once (even though certain performance-\nChapter 19: Concurrency Models in Python\nthreading is still an appropriate model if you want to run multiple I/O-bound tasks\nshare the same Python thread among themselves and with the\nthreads in an asynchronous program, but the best practice is that\none thread runs the event loop and all coroutines, while additional\nthreads carry out specific tasks.\nDuring a discussion about threads and how to avoid the GIL, Python contributor\nSimionato’s program uses multiprocessing, but I adapted it to introduce threading\nLet’s start with the threading version, which may look familiar\nSpinner with Threads\nthreads, then with coroutines.\nThe scripts spinner_thread.py and spinner_async.py produce similar out‐\nLet’s review the spinner_thread.py script first.\nspinner_thread.py: the spin and slow functions\nfrom threading import Thread, Event\nThis function will run in a separate thread.\nthreading.Event, a simple object to synchronize threads.\nChapter 19: Concurrency Models in Python\nanother thread; if the timeout elapses, it returns False.\nslow() will be called by the main thread.\nCalling sleep blocks the main thread, but the GIL is released so the\nspinner thread can proceed.\nThe first important insight of this example is that time.sleep()\nblocks the calling thread but releases the GIL, allowing other\nPython threads to run.\nThe spin and slow functions will execute concurrently.\nthread when the program starts—will start a new thread to run spin and then call\nBy design, there is no API for terminating a thread in Python.\nThe threading.Event class is Python’s simplest signalling mechanism to coordinate\nthreads.\nEvent.wait(), it is blocked until another thread calls Event.set(), at which time\nis called by another thread.\nThe supervisor function, listed in Example 19-2, uses an Event to signal the spin\nspinner_thread.py: the supervisor and main functions\nspinner = Thread(target=spin, args=('thinking!', done))  \nsupervisor will return the result of slow.\nThe threading.Event instance is the key to coordinate the activities of the main\nthread and the spinner thread, as explained further down.\nTo create a new Thread, provide a function as the target keyword argument,\nStart the spinner thread.\nCall slow, which blocks the main thread.\nWait until the spinner thread finishes.\nWhen the main thread sets the done event, the spinner thread will eventually notice\nSpinner with Processes\nThe multiprocessing package supports running concurrent tasks in separate Python\nprocesses instead of threads.\na whole new Python interpreter is started as a child process in the background.\neach Python process has its own GIL, this allows your program to use all available\nChapter 19: Concurrency Models in Python\nemulates the threading API, making it easy to convert simple programs from\nthreads to processes, as shown in spinner_proc.py (Example 19-3).\nsame as spinner_thread.py\nfrom multiprocessing import Process, Event  \n# [snip] the rest of spin and slow functions are unchanged from spinner_thread.py\nspinner = Process(target=spin,               \nThe basic multiprocessing API imitates the threading API, but type hints and\nlike threading.Event) which returns a synchronize.Event instance…\nBasic usage of the Process class is similar to Thread.\nThe spinner object is displayed as <Process name='Process-1' parent=14868\ninitial>, where 14868 is the process ID of the Python instance running\nPython provides different semaphore classes for use with threads, processes, and coroutines.\nThe basic API of threading and multiprocessing are similar, but their implementa‐\nconverting from threads to processes is how to communicate between processes that\nthreads or processes.\nSpinner with Coroutines\napproach with the threads and processes concurrency models.\nIt is the job of OS schedulers to allocate CPU time to drive threads and processes.\nThe event loop and the library coroutines and\nthe user coroutines all execute in a single thread.\nChapter 19: Concurrency Models in Python\nThe coroutine version of the spinner program is easier to understand if we start from\nspinner_async.py: the main function and supervisor coroutine\nresult = asyncio.run(supervisor())  \nspinner = asyncio.create_task(spin('thinking!'))  \nThe asyncio.run function starts the event loop to drive the coroutine that will\ncoro=<spin() running at /path/to/spinner_async.py:11>>.\ncoroutine, as we’ll see in Example 19-5.\nExample 19-4 demonstrates the three main ways of running a coroutine:\nCalled from a regular function to drive a coroutine object that usually is the entry\nCalled from a coroutine to transfer control to the coroutine object returned by\ncoroutine object, but does not run the body of the coro function.\nDriving the body of coroutines is the job of the event loop.\nNow let’s study the spin and slow coroutines in Example 19-5.\nspinner_async.py: the spin and slow coroutines\nChapter 19: Concurrency Models in Python\nted its job in spinner_thread.py (Example 19-1).\nUse await asyncio.sleep(.1) instead of time.sleep(.1), to pause without\nThe slow coroutine also uses await asyncio.sleep instead of time.sleep.\nImport the time module, then go to the slow coroutine and replace the line await\nasyncio.sleep(3) with a call to time.sleep(3), like in Example 19-6.\nspinner_async.py: replacing await asyncio.sleep(3) with\ncoro=<spin() running at /path/to/spinner_async.py:12>>.\none flow of execution, unless you’ve explicitly started additional threads or processes.\nThat means only one coroutine executes at any point in time.\nspinner_async_experiment.py: the supervisor and slow coroutines\nspinner = asyncio.create_task(spin('thinking!'))  \nRight after slow returns, the spinner task is cancelled.\nNever use time.sleep(…) in asyncio coroutines unless you want\nAs we discuss concurrency with coroutines, it’s important to mention the greenlet\nChapter 19: Concurrency Models in Python\nThe line count of spinner_thread.py and spinner_async.py is nearly the same.\nspinner_thread.py: the threaded supervisor function\nspinner = Thread(target=spin,\nspinner_async.py: the asynchronous supervisor coroutine\nspinner = asyncio.create_task(spin('thinking!'))\n• An asyncio.Task is roughly the equivalent of a threading.Thread.\n• A Task drives a coroutine object, and a Thread invokes a callable.\n• When asyncio.create_task(…) returns a Task object, it is already scheduled to\nrun, but a Thread instance must be explicitly told to run by calling its start\n• In the threaded supervisor, slow is a plain function and is directly invoked by\nthe main thread.\n• The supervisor coroutine must be started with asyncio.run in the main\nwith asyncio, in contrast to how it’s done with the Threading module, which may be\nOne final point related to threads versus coroutines: if you’ve done any nontrivial\ngram because the scheduler can interrupt a thread at any time.\nchronize the operations of multiple threads, coroutines are “synchronized” by defini‐\nChapter 19: Concurrency Models in Python\nIn the threading code (Example 19-1), you can replace the time.sleep(3) call in the\nYou can also replace the asyncio.sleep(3) expression in the slow coroutine to\nsuch libraries provide coroutines that yield control back to the event loop while wait‐\nExample 19-10, which returns True if the argument is a prime number, False if it’s\nprimes.py: an easy to read primality check, from Python’s ProcessPool\n1. In spinner_proc.py, replace time.sleep(3) with a call to is_prime(n)?\n2. In spinner_thread.py, replace time.sleep(3) with a call to is_prime(n)?\n3. In spinner_async.py, replace await asyncio.sleep(3) with a call to\nThe spinner is controlled by a child process, so it continues spinning while the pri‐\n2. Answer for threading\nThe spinner is controlled by a secondary thread, so it continues spinning while the\nprimality test is computed by the main thread.\nIn this particular example, the spinner keeps spinning because Python suspends the\nrunning thread every 5ms (by default), making the GIL available to other pending\nthreads.\nTherefore, the main thread running is_prime is interrupted every 5ms,\nit calls the wait method of the done event, at which time it will release the GIL.\nmain thread will then grab the GIL, and the is_prime computation will proceed for\nThe main thread running\nis_prime will have the GIL most of the time.\nWe got away with a compute-intensive task using threading in this simple experi‐\nChapter 19: Concurrency Models in Python\nBut if you have two or more threads vying for a lot of CPU time, your program will\nIf you call is_prime(5_000_111_000_222_021) in the slow coroutine of the spin‐\nner_async.py example, the spinner will never appear.\nwe had in Example 19-6, when we replaced await asyncio.sleep(3) with\nOne way to keep the spinner alive is to rewrite is_prime as a coroutine, and periodi‐\nspinner_async_nap.py: is_prime is now a coroutine\nI wrote this section to show the use of multiple processes for CPU-\nChapter 19: Concurrency Models in Python\nand threading code for CPU-intensive work.\nThe check function (in the next callout) returns a Result tuple with the boolean\ncheck(n) calls is_prime(n) and computes the elapsed time to return a Result.\nThe next example, procs.py, shows the use of multiple processes to distribute the pri‐\n$ python3 procs.py\nChecking 20 numbers with 12 processes:\nwhile, other processes were checking other numbers in parallel.\nChapter 19: Concurrency Models in Python\nthe code launches 12 processes to use all cores on this laptop.\nThe multiprocessing.cpu_count() function returns 12 on the\nWhen we delegate computing to threads or processes, our code does not call the\ndriven by the thread or process library, and it eventually produces a result that needs\nprocs.py: multiprocess primality check; imports, types, and functions\nfrom multiprocessing import Process, SimpleQueue, cpu_count  \nproc = Process(target=worker, args=(jobs, results))  \nuse to send numbers to the processes that will do the work.\nprocs is the number of processes that will compute the prime checks in parallel.\nThe worker function in Example 19-13 follows a common pattern in concurrent pro‐\nHowever, that does not work across processes because Python objects must be\nNow let’s study the main function of procs.py in Example 19-14.\nprocs.py: multiprocess primality check; main function\nprint(f'Checking {len(NUMBERS)} numbers with {procs} processes:')\nStart proc processes to consume jobs and post results.",
      "keywords": [
        "Python",
        "Python threads",
        "thread",
        "spinner",
        "Concurrency Models",
        "main thread",
        "GIL",
        "coroutine",
        "Python objects",
        "Models in Python",
        "process",
        "Python code",
        "spinner thread",
        "function",
        "Concurrency"
      ],
      "concepts": [
        "python",
        "threading",
        "processing",
        "process",
        "examples",
        "concurrency",
        "concurrent",
        "results",
        "function",
        "functions"
      ],
      "similar_chapters": [
        {
          "book": "Fluent Python 2nd",
          "chapter": 20,
          "title": "",
          "score": 0.879,
          "base_score": 0.729,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 18,
          "title": "",
          "score": 0.497,
          "base_score": 0.347,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 13,
          "title": "",
          "score": 0.453,
          "base_score": 0.303,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 3,
          "title": "",
          "score": 0.444,
          "base_score": 0.294,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 1,
          "title": "",
          "score": 0.439,
          "base_score": 0.289,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "thread",
          "processes",
          "threads",
          "spinner",
          "python"
        ],
        "semantic": [],
        "merged": [
          "thread",
          "processes",
          "threads",
          "spinner",
          "python"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.2519109701006844,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:09.220225+00:00"
      }
    },
    {
      "chapter_number": 20,
      "title": "is easier to use and",
      "start_page": 753,
      "end_page": 864,
      "summary": "You may want try running procs.py, passing arguments to set the number of worker\n$ python3 procs.py 2\n16 See 19-concurrency/primes/threads.py in the Fluent Python code repository.\nI ran procs.py 12 times with 1 to 20 processes, totaling 240 runs.\nmedian time for all runs with the same number of processes, and plotted Figure 19-2.\nMedian run times for each number of processes from 1 to 20.\nnature of is_prime, the threaded version is slower than the sequential code in\nExample 19-12, and it gets slower as the number of threads increase, because of CPU\nChapter 19: Concurrency Models in Python\nThe next two chapters will cover more about concurrent programming in Python,\nusing the high-level concurrent.futures library to manage threads and processes\nDespite the GIL, Python is thriving in applications that require concurrent or parallel\nrent.futures package we’ll see in Chapter 20 can be used to perform the same oper‐\nBeyond the standard library, there are popular Python-based projects to manage\nChapter 19: Concurrency Models in Python\nApplications in these fields are compute-intensive, but Python\nsupport other languages as well, but Python is their main focus and is used by the\nPython is widely used in web applications and for the backend APIs supporting\nand Reddit—among others—managed to build Python server-side applications serv‐\nChapter 19: Concurrency Models in Python\nPython server-side applications, two specific components are often deployed:\nPython application.\nFigure 19-3, handling client requests before they reached the application code.\nces in Python server-side deployments.\nWSGI—the Web Server Gateway Interface—is a standard API for a Python frame‐\nwork or application to receive requests from an HTTP server and send responses to\nit.23 WSGI application servers manage one or more processes running your applica‐\nThe best-known application servers in Python web projects are:\nChapter 19: Concurrency Models in Python\nother requests to the application server, which forks child processes to run the applica‐\ncation server and the Python application code.\nThe main point: all of these application servers can potentially use all CPU cores on\nthe server by forking multiple Python processes to run traditional web apps written\nthreading, multiprocessing, or asyncio modules: the application server handles\nwith server-side Python applications.\nWhen the application server delivers a request to one of the Python processes run‐\nCelery and RQ are the best known open source task queues with Python APIs. Cloud\nChapter 19: Concurrency Models in Python\nRecall that our simple procs.py (Example 19-13) used two queues: one for job\nThis wraps up our introduction to concurrency in Python.\ncontinue this theme, focusing on the concurrent.futures and asyncio packages of\nof Python’s three native concurrency programming models:\nworked—despite the GIL—because Python periodically interrupts threads, and the\nexample used only two threads: one doing compute-intensive work, and the other\ntiprocessing and threading, proving that only processes allow Python to benefit\nfrom multicore CPUs. Python’s GIL makes threads worse than sequential code for\nThe GIL dominates discussions about concurrent and parallel computing in Python,\nelements to support Python server-side applications at scale: WSGI application\nConcurrency with Threads and Processes\nThe concurrent.futures library covered in Chapter 20 uses threads, processes, locks,\nProcesses, Threads, and Coroutines” on his website and book, The Python 3 Standard\n—making it one of the longest chapters in the Python standard library.\nfor primes with a different strategy than our procs.py example.\nChapter 19: Concurrency Models in Python\ncomputing in Python.\nPython Development cover concurrent programming with threading and asyncio.\ncepts behind concurrency and parallelism, covering Python’s standard library as well\nthe fundamental challenges of threads have nothing to do with Python or the GIL.\n• Threading makes code hard to reason about.\n• Threading is an inefficient model for large-scale concurrency (thousands of con‐\ncode, so the canonical reference is in the C-API documentation: Thread State and the\n“Parallelism and Concurrency”: a deep dive into Python’s native support for threads\nand processes, including managing the GIL from extensions using the C/Python API.\nPython 3.2.\nI’ve already mentioned two books that cover concurrency using the Python standard\nand Parallel Programming with Python.\nPierfederici’s Distributed Computing with Python (Packt) covers the standard library\nChapter 19: Concurrency Models in Python\n(O’Reilly) presents architectural patterns for Python server-side applications.\neventually allow Python to use multiple cores without the overheads of multiprocess‐\nThe actor model of concurrent programming is at the core of the highly scalable\n28 Python’s threading and concurrent.futures APIs are heavily influenced by the Java standard library.\nConcurrency and Scalability Beyond Python\n(AMQP) standard, with examples in Python, PHP, and Ruby.\nChapter 19: Concurrency Models in Python\nChapter 19: Concurrency Models in Python\n1 From Michele Simionato’s post, “Threads, processes and concurrency in Python: some thoughts”, summar‐\nabout threads and other forms of concurrency.”\nConcurrent Executors\nThis chapter focuses on the concurrent.futures.Executor classes that encapsulate\nfoundation not only of concurrent.futures but also of the asyncio package, the\nFutures\nAll the HTTP client examples now use the new HTTPX library, which provides syn‐\nhttp.server package in Python 3.7.\nConcurrent Web Downloads\nTo demonstrate with code, I wrote three simple programs to download images of 20\nThe first one, flags.py, runs sequentially: it only requests\ntwo scripts make concurrent downloads: they request several images practically at the\nThe flags_threadpool.py script uses the con\ncurrent.futures package, while flags_asyncio.py uses asyncio.\nExample 20-1 shows the result of running the three scripts, three times each.\nThe results in Example 20-1 were obtained after several runs, so the\nThree typical runs of the scripts flags.py, flags_threadpool.py, and\nflags_asyncio.py\n$ python3 flags.py\n20 flags downloaded in 7.26s  \n$ python3 flags.py\nChapter 20: Concurrent Executors\n20 flags downloaded in 7.20s\n$ python3 flags.py\n20 flags downloaded in 7.09s\n$ python3 flags_threadpool.py\n20 flags downloaded in 1.37s  \n$ python3 flags_threadpool.py\n20 flags downloaded in 1.60s\n$ python3 flags_threadpool.py\n20 flags downloaded in 1.22s\n$ python3 flags_asyncio.py  \n20 flags downloaded in 1.36s\n$ python3 flags_asyncio.py\n20 flags downloaded in 1.27s\n$ python3 flags_asyncio.py\n20 flags downloaded in 1.42s\nThe output for each run starts with the country codes of the flags as they are\nIt took flags.py an average 7.18s to download 20 images.\nFor flags_asyncio.py, 1.35s was the average time.\nNote the order of the country codes: the downloads happened in a different\norder every time with the concurrent scripts.\nto hundreds of downloads, the concurrent scripts can outpace the sequential code by\nWhile testing concurrent HTTP clients against public web servers,\nWe’ll use Python’s http.server package to run tests later in this\nConcurrent Web Downloads \nI will leave the third script, flags_asyncio.py, for\nExample 20-2 contains the implementation of flags.py, the first script we ran in\nflags.py: sequential download script; some functions will be reused by\nChapter 20: Concurrent Executors\nGiven a country code, build the URL and download the image, returning the\nConcurrent Web Downloads \ndownload_many is the key function to compare with the concurrent\nthat the ordering is preserved in the output; return the number of country codes\nDisplay one country code at a time in the same line so we can see progress as\nmain must be called with the function that will make the downloads; that way, we\ncan use main as a library function with other implementations of download_many\nRecord and report the elapsed time after running the downloader function.\nThe HTTPX library is inspired by the Pythonic requests package,\nHTTP client examples in this chapter and the next.\nChapter 20: Concurrent Executors\nscripts, and I used it as a library to avoid redundant code when implementing them.\nNow let’s see a reimplementation using concurrent.futures.\nDownloading with concurrent.futures\nThe main features of the concurrent.futures package are the ThreadPoolExecutor\nmanage a pool of worker threads or processes, and queues to distribute jobs and col‐\nof those details for a simple use case like our flag downloads.\nExample 20-3 shows the easiest way to implement the downloads concurrently, using\nflags_threadpool.py: threaded download script using futures.Thread\nfrom concurrent import futures\nwith futures.ThreadPoolExecutor() as executor:         \nres = executor.map(download_one, sorted(cc_list))  \nReuse some functions from the flags module (Example 20-2).\nFunction to download a single image; this is what each worker will execute.\nConcurrent Web Downloads \ntion will be called concurrently from multiple threads; it returns a generator that\neach call to download_one will return a country code.\nCall the main function from the flags module, passing the concurrent version of\nNote that the download_one function from Example 20-3 is essentially the body of the\nfor loop in the download_many function from Example 20-2.\ntoring when writing concurrent code: turning the body of a sequential for loop into a\ntions from the sequential flags.py script.\nconcurrent.futures is to make it simple to add concurrent execu‐\nThe library is called concurrency.futures, yet there are no futures to be seen in\nChapter 20: Concurrent Executors\nWhere Are the Futures?\nFutures are core components of concurrent.futures and of asyncio, but as users of\nExample 20-3 depends on futures\nan overview of futures, with an example that shows them in action.\nSince Python 3.4, there are two classes named Future in the standard library: concur\nAn important thing to know about futures is that you and I should not create them:\nconcurrent.futures or asyncio.\nIn particular, concurrent.futures.Future instances are created only as\nthe result of submitting a callable for execution with a concurrent.futures.Execu\nit to run, and returns a Future.\nApplication code is not supposed to change the state of a future: the concurrency\nBoth types of Future have a .done() method that is nonblocking and returns a\nHowever, instead of repeatedly asking whether a future is done, client code usu‐\nwill run in the same worker thread or process that ran the function wrapped in the\nfuture.\nfuture is done: it returns the result of the callable, or re-raises whatever exception\nHowever, when the future is\nof Future.\nIn a concurrency.futures.Future instance, invoking f.result() will\nConcurrent Web Downloads \nbe passed, and if the future is not done in the specified time, the result method\nThe asyncio.Future.result method does not support time‐\ndoesn’t work with concurrency.futures.Future instances.\nSeveral functions in both libraries return futures; others use them in their implemen‐\ntor.map we saw in Example 20-3: it returns an iterator in which __next__ calls the\nresult method of each future, so we get the results of the futures, and not the futures\nTo get a practical look at futures, we can rewrite Example 20-3 to use the concur\nrent.futures.as_completed function, which takes an iterable of futures and returns\nUsing futures.as_completed requires changes to the download_many function only.\nschedule the futures, the other to retrieve their results.\nfew print calls to display each future before and after it’s done.\nthe code for a new download_many function.\nflags_threadpool_futures.py: replacing executor.map with execu\ntor.submit and futures.as_completed in the download_many function\nwith futures.ThreadPoolExecutor(max_workers=3) as executor:  \nfuture = executor.submit(download_one, cc)  \nprint(f'Scheduled for {cc}: {future}')  \nres: str = future.result()  \nprint(f'{future} result: {res!r}')  \nChapter 20: Concurrent Executors\nSet max_workers to 3 so we can see pending futures in the output.\nIterate over country codes alphabetically, to make it clear that results will arrive\nexecutor.submit schedules the callable to be executed, and returns a future\nDisplay a message with the country code and the respective future.\nGet the result of this future.\nDisplay the future and its result.\nNote that the future.result() call will never block in this example because the\nOutput of flags_threadpool_futures.py\n$ python3 flags_threadpool_futures.py\nScheduled for BR: <Future at 0x100791518 state=running>  \nScheduled for CN: <Future at 0x100791710 state=running>\nScheduled for ID: <Future at 0x100791a90 state=running>\nCN <Future at 0x100791710 state=finished returned str> result: 'CN'  \nBR ID <Future at 0x100791518 state=finished returned str> result: 'BR'  \n<Future at 0x100791a90 state=finished returned str> result: 'ID'\nIN <Future at 0x101807080 state=finished returned str> result: 'IN'\nUS <Future at 0x101807128 state=finished returned str> result: 'US'\nstate: the first three are running, because there are three worker threads.\nThe last two futures are pending, waiting for worker threads.\nConcurrent Web Downloads \nThe first CN here is the output of download_one in a worker thread; the rest of the\nHere, two threads output codes before download_many in the main thread can\ndisplay the result of the first thread.\nI recommend experimenting with flags_threadpool_futures.py.\nyou run it several times, you’ll see the order of the results varying.\nWe saw two variants of the download script using concurrent.futures: one in\nfutures.as_completed.\nIf you are curious about the code for flags_asyncio.py, you\njobs using concurrent.futures.\nLaunching Processes with concurrent.futures\nThe concurrent.futures documentation page is subtitled “Launching parallel\nsupports distributing work among multiple Python processes using the ProcessPool\nconcurrent.futures.\nwith futures.ThreadPoolExecutor() as executor:\nwith futures.ProcessPoolExecutor() as executor:\nChapter 20: Concurrent Executors\nProcesses use more memory and take longer to start than threads, so the real value\nconcurrent.futures.\nExample 20-6 we solve the same problem in the proc_pool.py program using a Proc\nfrom concurrent import futures  \nexecutor = futures.ProcessPoolExecutor(workers)  \nLaunching Processes with concurrent.futures \nNo need to import multiprocessing, SimpleQueue etc.; concurrent.futures\nprocs.py, but we don’t need the queues and the worker function anymore.\nIf you run Example 20-6, you’ll see the results appearing in strict descending order, as\nFor example, procs.py shows the result for\nChapter 20: Concurrent Executors\nRunning proc_pool.py, you’ll observe not only the descending order of the results, but\nLaunching Processes with concurrent.futures \n• As mentioned before, executor.map(check, numbers) returns the result in the\n• By default, proc_pool.py uses as many workers as there are CPUs—it’s what\nprime, all the other processes have completed their last jobs, so the results appear\nfrom concurrent import futures\nChapter 20: Concurrent Executors\nexecutor = futures.ThreadPoolExecutor(max_workers=3)  \nImmediately display the results of invoking executor.map: it’s a generator, as\nin turn will invoke _f.result() on the (internal) _f future representing the first\nThe result method will block until the future is done, therefore\nfinishes, particularly because sleep always releases the GIL, so Python may switch to another thread even if\nSample run of demo_executor_map.py from Example 20-8\n$ python3 demo_executor_map.py\nworkers, it can run three functions concurrently).\nThis shows that the results returned by executor.map is a generator; nothing so\nChapter 20: Concurrent Executors\nfirst future is complete.\nThe Executor.map function is easy to use, but often it’s preferable to get the results as\ncombination of the Executor.submit method and the futures.as_completed func‐\nThe combination of executor.submit and futures.as_completed\nIn the next section, we will resume the flag download examples with new require‐\nments that will force us to iterate over the results of futures.as_completed instead\nflags2_common.py\nread it in the fluentpython/example-code-2e repository: 20-executors/getflags/\nflags2_common.py.\nflags2_sequential.py\nIts download_one function is also used by flags2_threadpool.py.\nflags2_threadpool.py\nConcurrent HTTP client based on futures.ThreadPoolExecutor to demon‐\nflags2_asyncio.py\nWhen testing concurrent HTTP clients on public web servers, you\nrun the threaded and asyncio scripts three times each, and every time they complete\nChapter 20: Concurrent Executors\nshots: during and after running flags2_threadpool.py.\nTop-left: flags2_threadpool.py running with live progress bar generated by\nIf you type the following code in the Python console after installing the tqdm pack‐\nflags2 examples provides an opportunity to look deeper into how the concurrent\nscripts actually work, by forcing us to use the futures.as_completed and the asyn\ncio.as_completed functions so that tqdm can display progress as each future is\nThe other feature of the flags2 example is a command-line interface.\n$ python3 flags2_threadpool.py -h\nusage: flags2_threadpool.py [-h] [-a] [-e] [-l N] [-m CONCURRENT] [-s LABEL]\nDownload flags for country codes.\nUse http://localhost:8000/flags; this is the default.\nUse http://fluentpython.com/data/flags; that is a public website owned by\nUse http://localhost:8001/flags; a server delaying HTTP responses should\nYou’ll find it in the 20-futures/getflags/ directory of the Fluent Python code repos‐\nUse http://localhost:8002/flags; a server returning some HTTP errors\nChapter 20: Concurrent Executors\npython3 -m http.server\npython3 slow_server.py\npython3 slow_server.py 8002 --error-rate .25\nBy default, each flags2*.py script will fetch the flags of the 20 most populous countries\nfrom the LOCAL server (http://localhost:8000/flags) using a default number of\na sample run of the flags2_sequential.py script using all defaults.\nneed a local server, as explained in “Be Careful when Testing Concurrent Clients” on\nRunning flags2_sequential.py with all defaults: LOCAL site, top 20\nflags, 1 concurrent connection\n$ python3 flags2_sequential.py\n20 flags downloaded.\nhow to download all flags with country codes starting with the letters A, B, or C.\nRun flags2_threadpool.py to fetch all flags with country codes prefixes\n$ python3 flags2_threadpool.py -s DELAY a b c\n43 flags downloaded.\nRegardless of how the country codes are selected, the number of flags to fetch can be\nRun flags2_asyncio.py to get 100 flags (-al 100) from the ERROR\nserver, using 100 concurrent requests (-m 100)\n$ python3 flags2_asyncio.py -s ERROR -al 100 -m 100\n73 flags downloaded.\nThat’s the user interface of the flags2 examples.\nError Handling in the flags2 Examples\nform the actual downloads in the flags2_sequential.py and flags2_threadpool.py\nflags2_sequential.py: basic functions in charge of downloading; both\nare reused in flags2_threadpool.py\nChapter 20: Concurrent Executors\ndownload_one catches HTTPStatusError to handle HTTP code 404 specifically…\nan Enum imported from flags2_common.py.\nIf the -v/--verbose command-line option is set, the country code and status\nExample 20-15 lists the sequential version of the download_many function.\nflags2_sequential.py: the sequential implementation of download_many\ncc_iter holds the list of the country codes received as arguments, ordered\nChapter 20: Concurrent Executors\nHTTP status code exceptions raised by get_flag and not handled by down\nabort the script, because the flags2_common.main function that calls down\nIn verbose mode, display the error message for the current country code, if any.\nWe’ll now study the refactored thread pool example, flags2_threadpool.py.\nUsing futures.as_completed\nthe flags2_threadpool.py script uses futures.ThreadPoolExecutor with the\nfutures.as_completed function we’ve already seen.\nof flags2_threadpool.py.\nfunctions are reused from flags2_common.py and flags2_sequential.py.\nflags2_threadpool.py: full listing\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\nfrom flags2_sequential import download_one  \nfuture = executor.submit(download_one, cc,\nto_do_map[future] = cc  \nfor future in done_iter:  \nstatus = future.result()  \ncc = to_do_map[future]  \nReuse download_one from flags2_sequential (Example 20-14).\nmum number of concurrent requests, implemented as the size of the thread pool;\nMAX_CONCUR_REQ caps the maximum number of concurrent requests regardless of\nthe number of flags to download or the -m/--max_req command-line option.\nChapter 20: Concurrent Executors\nCreate the executor with max_workers set to concur_req, computed by the main\nStore the future and the country code in the dict.\nfutures.as_completed returns an iterator that yields futures as each task is\nIterate over the futures as they are completed.\nCalling the result method on a future either returns the value returned by the\nas_completed only returns futures that are done.\nsequential download_many in Example 20-15), except for the next callout.\nknew the current cc; here we are iterating over the futures.\nother data that may be useful when the future is completed.\nthe to_do_map maps each future to the country code assigned to it.\nPython threads are well suited for I/O-intensive applications, and the concur\nrent.futures package makes it relatively simple to use for certain use cases.\nduction to concurrent.futures.\nWe started the chapter by comparing two concurrent HTTP clients with a sequential\nAfter studying the first example based on concurrent.futures, we took a closer look\nat future objects, either instances of concurrent.futures.Future or asyncio\nWe saw how to create futures by calling Executor.sub\nmit, and iterate over completed futures with concurrent.futures.as_completed.\nWe then discussed the use of multiple processes with the concurrent.futures.Proc\nIn the following section, we saw how the concurrent.futures.ThreadPoolExecutor\nNext we went back to the flag downloading examples.\nfuture.as_completed generator function, showing a common pattern: storing\nuse that information when the future comes out of the as_completed iterator.\nThe concurrent.futures package was contributed by Brian Quinlan, who presented\nhas no slides; he shows what the library does by typing code directly in the Python\nChapter 20: Concurrent Executors",
      "keywords": [
        "Python",
        "Concurrent Web Downloads",
        "Concurrent Executors",
        "future",
        "concurrent",
        "code",
        "download",
        "Python server-side applications",
        "concurrent import futures",
        "flags",
        "Python application code",
        "Fluent Python code",
        "Python web",
        "Python code",
        "threads"
      ],
      "concepts": [
        "python",
        "pythonic",
        "examples",
        "future",
        "concurrency",
        "concurrently",
        "thread",
        "coding",
        "codes",
        "downloads"
      ],
      "similar_chapters": [
        {
          "book": "Fluent Python 2nd",
          "chapter": 19,
          "title": "",
          "score": 0.879,
          "base_score": 0.729,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 18,
          "title": "",
          "score": 0.557,
          "base_score": 0.407,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 1,
          "title": "",
          "score": 0.549,
          "base_score": 0.399,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 13,
          "title": "",
          "score": 0.544,
          "base_score": 0.394,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 3,
          "title": "",
          "score": 0.509,
          "base_score": 0.359,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "concurrent",
          "futures",
          "future",
          "20",
          "flags"
        ],
        "semantic": [],
        "merged": [
          "concurrent",
          "futures",
          "future",
          "20",
          "flags"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.30489812119910903,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:09.220250+00:00"
      }
    },
    {
      "chapter_number": 22,
      "title": "Dynamic Attributes and Properties",
      "start_page": 865,
      "end_page": 882,
      "summary": "indeed advisable for you to expose public data attributes as part of your class’s public\nData attributes and methods are collectively known as attributes in Python.\nRecord and Event classes that appear in “Computed Properties” on page 845.\nIn the next few examples, we’ll leverage dynamic attributes to work with a JSON\nfour records from that dataset.3\nExample 22-1 shows 4 of the 895 records in the JSON file.\ngle JSON object with the key \"Schedule\", and its value is another mapping with four\nkeys: \"conferences\", \"events\", \"speakers\", and \"venues\".\nmaps to a list of records.\nrecord shown in Example 22-1.\nList the four record collections inside \"Schedule\".\nExploring JSON-Like Data with Dynamic Attributes\nExample 22-2 is simple enough, but the syntax feed['Schedule']['events'][40]\nFrozenJSON from Example 22-4 allows reading attributes like name, and\n<class 'explore0.FrozenJSON'>\nBuild a FrozenJSON instance from the raw_feed made of nested dicts and lists.\nItem 40 in the events list was a JSON object; now it’s a FrozenJSON instance.\nEvent records have a speakers list with speaker serial numbers.\nThe keystone of the FrozenJSON class is the __getattr__ method, which we already\nclass FrozenJSON:\nself.__data = dict(mapping)  \nreturn getattr(self.__data, name)  \nreturn FrozenJSON.build(self.__data[name])  \nreturn self.__data.keys()\nIf name matches an attribute of the instance __data dict, return that.\nhow calls like feed.keys() are handled: the keys method is an attribute of the\n6 The source of the data is JSON, and the only collection types in JSON data are dict and list.\nOtherwise, fetch the item with the key name from self.__data, and return the\nself.__data, because __getattr__ builds FrozenJSON instances on the fly—use‐\nA FrozenJSON instance has the __data private instance attribute stored under the\nname _FrozenJSON__data, as explained in “Private and ‘Protected’ Attributes in\nThis method will first look if the self.__data dict has an attribute\n(not a key!) by that name; this allows FrozenJSON instances to handle dict methods\nan attribute with the given name, __getattr__ uses name as a key to retrieve an item\nfrom self.__data, and passes that item to FrozenJSON.build.\nanother FrozenJSON instance by the build class method.\nverse the data, __getattr__ creates FrozenJSON instances again and again.\nThe FrozenJSON code doesn’t handle attribute names that are Python keywords.\nself.__data[key] = value\nA similar problem may arise if a key in a JSON record is not a valid Python identifier:\nessential feature of FrozenJSON: the logic of the build class method.\nInstead of a class method, the same logic could be implemented as the __new__ spe‐\nWhen a class is called to create an instance, the special method that Python calls on\nthat class to construct an instance is __new__.\ninstance returned by __new__ and then passes it as the first argument self of\nIf necessary, the __new__ method can also return an instance of a different class.\nif isinstance(new_object, the_class):\nthe_class.__init__(new_object, some_arg)\nclass FrozenJSON:\nself.__data[key] = value\nreturn getattr(self.__data, name)\nreturn FrozenJSON(self.__data[name])  \nreturn self.__data.keys()\nare calling __new__ from the object base class, passing FrozenJSON as the only\nFrozenJSON class, which Python handles by calling FrozenJSON.__new__.\nobject will be an instance of that class.\nthe instance built by the object class is actually an instance of FrozenJSON.\n__class__ attribute of the new instance will hold a reference to FrozenJSON, even\nget each speaker, we must iterate over that list until we find a record with a matching\nThe records in the 'events' list of the OSCON JSON data contain integer serial\nnumbers pointing to records in the 'speakers' and 'venues' lists.\nWe will implement an Event class with venue and speakers properties to return the\nReading venue and speakers returns Record objects\n<Record serial=1449>\n…reading event.venue returns a Record object instead of a serial number.\nThe event.speakers property returns a list of Record instances.\nAs usual, we will build the code step-by-step, starting with the Record class and a\nfunction to read the JSON data and return a dict with Record instances.\n>>> speaker = records['speaker.3471']  \n<Record serial=3471>\nThe keys in records are strings built from the record type and serial number.\nspeaker is an instance of the Record class defined in Example 22-9.\nFields from the original JSON can be retrieved as Record instance attributes.\nclass Record:\nreturn f'<{self.__class__.__name__} serial={self.serial!r}>'  \nrecords = {}  \nfor collection, raw_records in raw_data['Schedule'].items():  \nkey = f'{record_type}.{raw_record[\"serial\"]}' \nreturn records\nUse the serial field to build the custom Record representation shown in\nload will ultimately return a dict of Record instances.\nParse the JSON, returning native Python objects: lists, dicts, strings, numbers,\nrecord_type is the list name without the last character, so speakers becomes\nCreate a Record instance and save it in records with the key.\nThe Record.__init__ method illustrates an old Python hack.\nDepending on the application, the Record class may need to deal\nembedded __data dict attributes—which we used to invoke methods like .keys()—\nThe Python standard library provides classes similar to Record,\nI wrote the simpler Record class to highlight the essential\nAfter reorganizing the schedule dataset, we can enhance the Record class to automat‐\nically retrieve venue and speaker records referenced in an event record.\nThe goal of this next version is: given an event record, reading its venue property will\nreturn a Record.\n>>> event = Record.fetch('event.33950')  \n<Record serial=1449>\nThe Record.fetch static method gets a Record or an Event from the dataset.\nNote that event is an instance of the Event class.\nAccessing event.venue returns a Record instance.\nThe Event instance also has a venue_serial attribute, from the JSON data.\nEvent is a subclass of Record adding a venue to retrieve linked records, and a special‐\nenhanced Record class.\nschedule_v2.py: Record class with a new fetch method\nclass Record:\nreturn f'<{self.__class__.__name__} serial={self.serial!r}>'\nreturn Record.__index[key]  \nThe __index private class attribute will eventually hold a reference to the dict\nUse it to retrieve the record with the given key.\nThe fetch method always acts on the Record.__index class\nNow we get to the use of a property in the Event class, listed in Example 22-12.\nschedule_v2.py: the Event class\nclass Event(Record):  \nreturn self.__class__.fetch(key)  \nEvent extends Record.\nThe venue property builds a key from the venue_serial attribute, and passes it\nto the fetch class method, inherited from Record (the reason for using\nThe second line of the venue method of Example 22-12 returns self\n.__class__.fetch(key).\nworks with the specific OSCON dataset because there is no event record with a\nBut, if an event record had a key named 'fetch', then within that spe‐\ncific Event instance, the reference self.fetch would retrieve the value of that field,\ninstead of the fetch class method that Event inherits from Record.\nWhen creating instance attribute names from data, there is always\nIf the Record class behaved more like a mapping, implementing a dynamic __geti\nRecord.\nrecords = {}\nfor collection, raw_records in raw_data['Schedule'].items():\nkey = f'{record_type}.{raw_record[\"serial\"]}'\nrecords[key] = factory(**raw_record)  \nreturn records\nCapitalize the record_type to get a possible class name; e.g., 'event' becomes\nGet an object by that name from the module global scope; get the Record class if\nor a subclass like Event, selected according to the record_type.\nNote that the only record_type that has a custom class is Event, but if classes named\nSpeaker or Venue are coded, load will automatically use those classes when building\nand saving records, instead of the default Record class.\nWe’ll now apply the same idea to a new speakers property in the Events class.\nrecords of the \"events\" collection.\nIn contrast, each record in the events collection has a speakers field with a list of\ninstances, which returns a list of Record instances.",
      "keywords": [
        "Record",
        "Dynamic Attributes",
        "Record class",
        "Attributes",
        "data",
        "Event",
        "event record",
        "Python",
        "JSON",
        "Record instance attributes",
        "Dynamic",
        "key",
        "FrozenJSON",
        "JSON data",
        "instance"
      ],
      "concepts": [
        "record",
        "attributes",
        "data",
        "examples",
        "methods",
        "key",
        "keys",
        "events",
        "python",
        "pythonic"
      ],
      "similar_chapters": [
        {
          "book": "Fluent Python 2nd",
          "chapter": 23,
          "title": "",
          "score": 0.65,
          "base_score": 0.5,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 1,
          "title": "",
          "score": 0.571,
          "base_score": 0.421,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 11,
          "title": "",
          "score": 0.569,
          "base_score": 0.419,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 13,
          "title": "",
          "score": 0.546,
          "base_score": 0.396,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 9,
          "title": "",
          "score": 0.522,
          "base_score": 0.372,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "record",
          "event",
          "frozenjson",
          "__data",
          "class"
        ],
        "semantic": [],
        "merged": [
          "record",
          "event",
          "frozenjson",
          "__data",
          "class"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.29323777179558735,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:09.220274+00:00"
      }
    },
    {
      "chapter_number": 23,
      "title": "will reveal that a property is",
      "start_page": 883,
      "end_page": 1011,
      "summary": "the instance __dict__ to avoid a recursive call to the speakers property.\nInside the speakers method, trying to read self.speakers will invoke the property\nself.__dict__['speakers'], Python’s usual algorithm for retrieving attributes is\nIf the class has a property with the my_attr name, that\nproperty shadows an instance attribute by the same name.\nIf the instance doesn’t have an attribute named __speaker_objs, fetch the\nThe handmade caching in Example 22-15 is straightforward, but creating an attribute\nChapter 22: Dynamic Attributes and Properties\nneed to compute the data for the cache attribute (__speaker_objs in the examples)\ninstance attribute with the same name.\ncomputed by the venue method is stored in a venue attribute in self.\nwhen client code tries to read venue, the newly created venue instance attribute is\nreturn self.__class__.fetch(key)\nproperty shadows an instance attribute by the same name.\nIf the property overrides the instance attribute, the venue\ndecorator does not create a full-fledged property, it creates a nonoverriding descriptor.\nA descriptor is an object that manages the access to an attribute in another class.\nregular property blocks attribute writes unless a setter is defined.\nThe cached_property decorator only runs on lookups and only when an attribute of\nattribute with the same name.\nover the cached_property method and it works like a normal attribute.\nBack to our Event class: the specific behavior of @cached_property makes it unsuita‐\ndecorated method already depends on an instance attribute\n__dict__, because it creates an instance attribute after\nChapter 22: Dynamic Attributes and Properties\nUsing a Property for Attribute Validation\nBesides computing attribute values, properties are also used to enforce business rules\nclass, as in Example 22-19.\nUsing a Property for Attribute Validation \nattribute with a property.\nExample 22-21 lists the code for a read/write weight property.\nChapter 22: Dynamic Attributes and Properties\nHere the property setter is already in use, making sure that no instances with\n@property decorates the getter method.\nattribute: weight.\nThe descriptor class approach is more flexible, and we’ll devote Chapter 23\nProperties are in fact implemented as descriptor classes\nUsing a Property for Attribute Validation \nAlthough often used as a decorator, the property built-in is actually a class.\nChapter 22: Dynamic Attributes and Properties\nBuild the property and assign it to a public class attribute.\nThe presence of a property in a class affects how attributes in instances of that class\nProperties Override Instance Attributes\nProperties are always class attributes, but they actually manage attribute access in the\ninstances of the class.\nIn “Overriding Class Attributes” on page 389 we saw that when an instance and its\nclass both have a data attribute by the same name, the instance attribute overrides, or\nshadows, the class attribute—at least when read through that instance.\nInstance attribute shadows the class data attribute\n>>> obj = Class()\nDefine Class with two class attributes: the data attribute and the prop property.\nvars returns the __dict__ of obj, showing it has no instance attributes.\nReading from obj.data retrieves the value of Class.data.\nWriting to obj.data creates an instance attribute.\nInspect the instance to see the instance attribute.\nNow reading from obj.data retrieves the value of the instance attribute.\nread from the obj instance, the instance data shadows the class data.\nThe Class.data attribute is intact.\nNow, let’s try to override the prop attribute on the obj instance.\nInstance attribute does not shadow the class property (continued from\nReading prop directly from Class retrieves the property object itself, without\nTrying to set an instance prop attribute fails.\nChapter 22: Dynamic Attributes and Properties\nWe can see that obj now has two instance attributes: data and prop.\nshadowed by an instance attribute.\nOverwriting Class.prop destroys the property object.\nNow obj.prop retrieves the instance attribute.\nClass.prop is not a property any‐\nAs a final demonstration, we’ll add a new property to Class, and see it overriding an\ninstance attribute.\nNew class property shadows the existing instance attribute (continued\n>>> Class.data = property(lambda self: 'the \"data\" prop value')  \nobj.data retrieves the instance data attribute.\nClass.data retrieves the class data attribute.\nOverwrite Class.data with a new property.\nobj.data is now shadowed by the Class.data property.\nobj.data now reads the instance data attribute again.\nis no property named data in the class, Python looks in the obj instance itself.\napplies to overriding descriptors in general, of which properties are just one example.\nEvery Python code unit—modules, functions, classes, meth‐\nChapter 22: Dynamic Attributes and Properties\ntecting both the weight and price attributes of LineItem so they only accept values\nExample 22-27 shows the clean look of the LineItem class using two instances of\nquantity properties: one for managing the weight attribute, the other for price.\nUse the factory to define the first custom property, weight, as a class attribute.\nThe properties are also in use here, retrieving the values stored in the instance.\nRecall that properties are class attributes.\ning which class attribute name will be bound to it.\nExample 22-28 lists the implementation of the quantity property factory.11\nstrange because this is not a class body; instance refers to the LineItem instance\nChapter 22: Dynamic Attributes and Properties\ndepend on the storage_name variable to know where to get/set the managed attribute\nwhere to retrieve/store the managed attribute values.\nattributes.\nbulkfood_v2prop.py: exploring properties and storage attributes\ninstance attributes.\n“Properties Override Instance Attributes” on page 861: the weight property overrides\nthe weight instance attribute so that every reference to self.weight or nut\nproperty logic is to access the instance __dict__ directly.\nextensible descriptor class, with specialized subclasses performing different valida‐\nNow let us wrap up the discussion of properties with the issue of attribute deletion.\ncharge of deleting the attribute managed by the property.\nChapter 22: Dynamic Attributes and Properties\nFor example, the member property would be coded like this in the\nIf you are not using a property, attribute deletion can also be handled by implement‐\nattributes.\n__class__\nPython looks for special methods such as __getattr__ only in an object’s class,\nA mapping that stores the writable attributes of an object or class.\nIf a class has a\n__slots__ attribute, then its instances may not have a __dict__.\nAn attribute that may be defined in a class to save memory.\n__slots__, then the instances of that class will not have a __dict__ of their own,\nand only the attributes listed in __slots__ will be allowed in those instances.\nThese five built-in functions perform object attribute reading, writing, and\nSeveral special attributes of classes, such as __mro__, __bases__,\nChapter 22: Dynamic Attributes and Properties\ncase is to retrieve attributes (or methods) whose names we don’t know before‐\nThis may fetch an attribute from the object’s class or from a superclass.\nReturns True if the named attribute exists in the object, or can be somehow\nAssigns the value to the named attribute of object, if the object allows it.\nReturns the __dict__ of object; vars can’t deal with instances of classes that\nSpecial Methods for Attribute Handling\nWhen implemented in a user-defined class, the special methods listed here handle\ning attributes directly in the instance __dict__ does not trigger these special methods\nIn other words, assume that the special methods will be retrieved on the class itself,\nnot shadowed by instance attributes with the same name.\nIn the following examples, assume there is a class named Class, obj is an instance of\nClass, and attr is an attribute of obj.\nFor every one of these special methods, it doesn’t matter if the attribute access is done\nproperty, its deleter method is never called if the class implements __delattr__.\nClass.__getattr__(obj, 'no_such_attr'), but only if an attribute by that\nUsing properties or descriptors is less error prone than defining\nChapter 22: Dynamic Attributes and Properties\nspecial method to convert data structures on the fly, whenever their attributes were\nmethod to transform a class into a flexible factory of objects, not limited to instances\nWe then converted the JSON dataset to a dict storing instances of a Record class.\nCoverage of properties continued with the LineItem class, where a property was\nclosures, and instance attribute overriding by properties—to provide an elegant\nFinally, we had a brief look at handling attribute deletion with properties, followed by\nan overview of the key special attributes, built-in functions, and special methods that\nSpecial Attributes” covers __class__ and __dict__ attributes.\nDelegating Attribute Access” implements a proxy class showcasing most special\nChapter 22: Dynamic Attributes and Properties\nEvery instance attribute in these languages is private, so\nChapter 22: Dynamic Attributes and Properties\nPython Code did not recommend CamelCase for class names.\ndozens of classes in the standard library have lowercase names (e.g., property, str,\nAttribute Descriptors\nDescriptors are a way of reusing the same access logic in multiple attributes.\nA descriptor is a class that implements a dynamic protocol consisting of the __get__,\nThe property class implements the full descrip‐\nfor Attribute Validation” on page 857, replacing properties with descriptors.\nmake it easier to reuse the attribute validation logic across different classes.\nPython functions are descriptors.\nspecial method added to the descriptor protocol in Python 3.6.\nThe AutoStorage class that used to appear in “LineItem Take #5: A New Descriptor\nDescriptor Example: Attribute Validation\nset of accessor functions and builds a custom property instance from them, with clo‐\nsame problem is a descriptor class.\ntity descriptor class.\n__delete__ method is a descriptor.\nYou use a descriptor by declaring instances of it\nas class attributes of another class.\nWe’ll create a Quantity descriptor, and the LineItem class will use two instances of\nQuantity: one for managing the weight attribute, the other for price.\nChapter 23: Attribute Descriptors\nUML class diagram for LineItem using a descriptor class named Quan\nUnderlined attributes in UML are class attributes.\ninstances of Quantity attached to the LineItem class, but LineItem instances also have\ntheir own weight and price attributes where those values are stored.\ndistinct attributes named weight: one is a class attribute of LineItem, the other is an\ninstance attribute that will exist in each LineItem object.\nDescriptor class\nA class implementing the descriptor protocol.\nManaged class\nThe class where the descriptor instances are declared as class attributes.\nDescriptor instance\nEach instance of a descriptor class, declared as a class attribute of the managed\nclass.\narrow with an underlined name (the underline means class attribute in UML).\nThe black diamonds touch the LineItem class, which contains the descriptor\nDescriptor Example: Attribute Validation \nOne instance of the managed class.\nIn this example, LineItem instances are the\nmanaged instances (they are not shown in the class diagram).\nAn attribute of the managed instance that holds the value of a managed attribute\nIn Figure 23-1, the LineItem instance attributes\nweight and price are the storage attributes.\ninstances, which are always class attributes.\nManaged attribute\nA public attribute in the managed class that is handled by a descriptor instance,\nIn other words, a descriptor instance and\nIt’s important to realize that Quantity instances are class attributes of LineItem.\nChapter 23: Attribute Descriptors\nrelationships involving classes and instances, like the relationship between a managed\nclass and the descriptor instances.2 So I invented my own “language,” the Mills & Giz‐\nMGN is designed to make very clear the distinction between classes and instances.\nMGN sketch showing the LineItem class making three instances, and Quan\nOne instance of Quantity is retrieving a value stored in a LineItem\nQuantity instances are descriptors, they have a magnifying glass to __get__ values,\ndescriptor class, and Example 23-2 lists a new LineItem class using two instances of\nDescriptor Example: Attribute Validation \nclass Quantity:  \ndef __set__(self, instance, value):  \ninstance.__dict__[self.storage_name] = value  \nreturn instance.__dict__[self.storage_name]\nEach Quantity instance will have a storage_name attribute: that’s the name of\nthe storage attribute to hold the value in the managed instances.\n__set__ is called when there is an attempt to assign to the managed attribute.\nHere, self is the descriptor instance (i.e., LineItem.weight or LineItem.price),\nWe must store the attribute value directly into __dict__; calling set attr\n(instance, self.storage_name) would trigger the __set__ method again,\nIn the House class, the managed attribute is rooms, but the storage attribute is\nChapter 23: Attribute Descriptors\nargument is a reference to the managed class (e.g., LineItem), and it’s useful if you\nwant the descriptor to support retrieving a class attribute—perhaps to emulate\nPython’s default behavior of retrieving a class attribute when the name is not found\nIf a managed attribute, such as weight, is retrieved via the class like Line\nItem.weight, the descriptor __get__ method receives None as the value for the\npractice to make __get__ return the descriptor instance when the managed attribute\nreturn instance.__dict__[self.storage_name]\nbulkfood_v3.py: Quantity descriptors manage attributes in LineItem\nThe first descriptor instance will manage the weight attribute.\nThe second descriptor instance will manage the price attribute.\nDescriptor Example: Attribute Validation \nWhen coding descriptor __get__ and __set__ methods, keep in\ndescriptor instance, and instance is the managed instance.\nDescriptors managing instance attributes should store values in the\nargument to the descriptor methods.\ndescriptor instance itself.\ninstance.__dict__[self.storage_name] = value\narguments to __set__: self and instance.\nHere, self is the descriptor instance,\nwhich is actually a class attribute of the managed class.\ndescriptors: the class attributes LineItem.weight and LineItem.price.\nyou store in the descriptor instances themselves is actually part of a LineItem class\nattribute, and therefore is shared among all LineItem instances.\nthe descriptors are instantiated in the managed class body.\nChapter 23: Attribute Descriptors\na descriptor instance, and there is no way the code in the Quantity class can guess the\nAutomatic naming of a descriptor storage attribute used to be a\nTo avoid retyping the attribute name in the descriptor instances, we’ll implement\nspecial method was added to the descriptor protocol in Python 3.6.\ncalls __set_name__ on each descriptor it finds in a class body—if the descriptor\nIn Example 23-3, the LineItem descriptor class doesn’t need an __init__.\ndescriptor instance\nclass Quantity:\ndef __set__(self, instance, value):   \ninstance.__dict__[self.storage_name] = value\nDescriptor Example: Attribute Validation \nself is the descriptor instance (not the managed instance), owner is the managed\nclass, and name is the name of the attribute of owner to which this descriptor\ninstance was assigned in the class body of owner.\nthe price attribute directly from the LineItem instance.\nple of attributes, but it’s important to realize that the descriptor logic is now abstrac‐\ndescriptor class now resides in the imported model_v4c module\nChapter 23: Attribute Descriptors\nBecause descriptors are implemented as classes, we can leverage inheritance to reuse\nclasses.\nDescriptor Example: Attribute Validation \nIn Example 23-5, Validated.__set__ is the template method and self.validate is\ndef __set__(self, instance, value):\ninstance.__dict__[self.storage_name] = value  \nChapter 23: Attribute Descriptors\nget to use Quantity and NonBlank to automate the validation of instance attributes.\nSee the latest LineItem class in Example 23-7.\ndescriptors to manage data attributes.\ndescriptors because its __set__ method overrides (i.e., intercepts and overrules) the\nsetting of an instance attribute by the same name in the managed instance.\nDescriptor Example: Attribute Validation \nReading an attribute through an instance normally returns the attribute defined in\nthe instance, but if there is no such attribute in the instance, a class attribute will be\nOn the other hand, assigning to an attribute in an instance normally creates\nthe attribute in the instance, without affecting the class at all.\ndescriptors, depending on whether the __set__ method is implemented.\nis present, the class is an overriding descriptor; otherwise, it is a nonoverriding\nObserving the different descriptor categories requires a few classes, so we’ll use the\nEvery __get__ and __set__ method in Example 23-8 calls\ndescriptorkinds.py: simple classes for studying descriptor overriding\nChapter 23: Attribute Descriptors\ndef __set__(self, instance, value):\nprint_args('set', self, instance, value)\ndef __set__(self, instance, value):\nprint_args('set', self, instance, value)\nclass Managed:  \nAn overriding descriptor class with __get__ and __set__.\nThe print_args function is called by every descriptor method in this example.\nAn overriding descriptor without a __get__ method.\nNo __set__ method here, so this is a nonoverriding descriptor.\nThe managed class, using one instance of each of the descriptor classes.\non the Managed class, and one instance of it, going through each of the different\nA descriptor that implements the __set__ method is an overriding descriptor, because\nalthough it is a class attribute, a descriptor implementing __set__ will override\nattempts to assign to instance attributes.\nProperties are also overriding descriptors: if you don’t provide a setter function, the\ndefault __set__ from the property class will raise AttributeError to signal that the\n-> Overriding.__get__(<Overriding object>, None, <class Managed>)\nobj.over triggers the descriptor __get__ method, passing the managed instance\nManaged.over triggers the descriptor __get__ method, passing None as the sec‐\nAssigning to obj.over triggers the descriptor __set__ method, passing the value\nChapter 23: Attribute Descriptors\nReading obj.over still invokes the descriptor __get__ method.\nBypassing the descriptor, setting a value directly to the obj.__dict__.\nHowever, even with an instance attribute named over, the Managed.over\nProperties and other overriding descriptors, such as Django model fields, implement\nthe descriptor through an instance will return the descriptor object itself because\nIf a namesake instance attribute is created\nwith a new value via direct access to the instance __dict__, the __set__ method will\nply return the new value from the instance, instead of returning the descriptor object.\nIn other words, the instance attribute will shadow the descriptor, but only when read‐\nThis overriding descriptor doesn’t have a __get__ method, so reading\nobj.over_no_get retrieves the descriptor instance from the class.\nmanaged class.\nTrying to set a value to obj.over_no_get invokes the __set__ descriptor\nretrieves the descriptor instance from the managed class.\nGoing through the instance __dict__ to set an instance attribute named\nNow that over_no_get instance attribute shadows the descriptor, but only for\nTrying to assign a value to obj.over_no_get still goes through the descriptor set.\ninstance attribute.\nan instance attribute with the same name will shadow the descriptor, rendering\nit ineffective for handling that attribute in that specific instance.\nobj.non_over triggers the descriptor __get__ method, passing obj as the second\nChapter 23: Attribute Descriptors\nThe obj now has an instance attribute named non_over, which shadows the\nnamesake descriptor attribute in the Managed class.\nclass.\nIf the non_over instance attribute is deleted…\n…then reading obj.non_over hits the __get__ method of the descriptor in the\nclass, but note that the second argument is the managed instance.\nIn the previous examples, we saw several assignments to an instance attribute with\n__set__ method in the descriptor.\nThe setting of attributes in the class cannot be controlled by descriptors attached to\nthe same class.\nIn particular, this means that the descriptor attributes themselves can\nOverwriting a Descriptor in the Class\nthe descriptors are replaced by integers, which would effectively break any class that\nAny descriptor can be overwritten on the class itself\nOverwrite the descriptor attributes in the class.\nalthough the reading of a class attribute can be controlled by a descriptor with\n__get__ attached to the managed class, the writing of a class attribute cannot be han‐\ndled by a descriptor with __set__ attached to the same class.\nIn order to control the setting of attributes in a class, you have to\nattach descriptors to the class of the class—in other words, the met‐\nLet’s now focus on how descriptors are used to implement methods in Python.\nMethods Are Descriptors\nA function within a class becomes a bound method when invoked on an instance\ndescriptors when attached to a class.\nmethod from the Managed class introduced in Example 23-8.\nA method is a nonoverriding descriptor\nAssigning a value to obj.spam shadows the class attribute, rendering the spam\nmethod inaccessible from the obj instance.\nFunctions do not implement __set__, therefore they are nonoverriding descriptors,\nmethod object: a callable that wraps the function and binds the managed instance\nChapter 23: Attribute Descriptors\nmethod_is_descriptor.py: a Text class, derived from UserString\n(<class 'function'>, <class 'method'>)\nA method called on the class works as a function.\nMethods Are Descriptors \nThe bound method object has a __self__ attribute holding a reference to the\ninstance on which the method was called.\nthe __self__ attribute of the method as the first argument.\nThe property built-in creates overriding descriptors implementing __set__ and\nproperty raises AttributeError: can't set attribute, so a property is the\nChapter 23: Attribute Descriptors\n9 However, recall that creating instance attributes after the __init__ method runs defeats the key-sharing\nIf you use a descriptor class to implement a read-only attribute, you must\nattribute on an instance will shadow the descriptor.\nIn a descriptor designed only for validation, the __set__ method should check\nthe value argument it gets, and if valid, set it directly in the instance __dict__\nusing the descriptor instance name as key.\nIf you code just the __get__ method, you have a nonoverriding descriptor.\nattribute will shadow the descriptor, so subsequent access to that attribute will\nfetch it directly from the instance __dict__ and not trigger the descriptor\nNonspecial methods can be shadowed by instance attributes\nwithout affecting the class or other instances.\nthe existence of an attribute named __getattr__ in an instance will not subvert\n10 Customizing the help text for each descriptor instance is surprisingly hard.\nbuilding a wrapper class for each descriptor instance.\nThe FrozenJSON class in Example 22-5 is safe from instance\nattribute shadowing methods because its only methods are special\nmethods and the build class method.\nClass methods are safe as\noverriding descriptors, so they are not shadowed by instance\nattributes.\nThe docstring of a descriptor class is used to document every instance of the descrip‐\nwith the Quantity and NonBlank descriptors from Examples 23-6 and 23-7.\nwith properties, because each property handles a specific managed attribute.\ndescriptors, the same Quantity descriptor class is used for weight and price.10\n__set__ in the descriptor class.\ndescriptor class with __delete__ is left as an exercise to the leisurely reader.\nChapter 23: Attribute Descriptors\nIn Example 23-2, we replaced properties with descriptors.\ndescriptor is a class that provides instances that are deployed as attributes in the man‐\nterms such as managed instance and storage attribute.\nabstract descriptor class to share code while building specialized descriptors with\nmethod when accessed through an instance, by leveraging the descriptor protocol.\n__set_name__ special method of the descriptor protocol, added in\nissues with the interaction of function decorators, descriptors, and methods,\nChapter 23: Attribute Descriptors\ncial method, and includes an example of a validating descriptor.",
      "keywords": [
        "attribute",
        "instance attribute",
        "descriptor",
        "Attribute Descriptors",
        "class attribute",
        "Quantity descriptor class",
        "Descriptor instance",
        "instance",
        "property",
        "managed attribute",
        "descriptor class",
        "Quantity descriptor instance",
        "Managed class",
        "Attribute Descriptors class",
        "Python"
      ],
      "concepts": [
        "classes",
        "attribute",
        "property",
        "properties",
        "descriptor",
        "method",
        "examples",
        "python",
        "instances",
        "object"
      ],
      "similar_chapters": [
        {
          "book": "Fluent Python 2nd",
          "chapter": 22,
          "title": "",
          "score": 0.65,
          "base_score": 0.5,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 1,
          "title": "",
          "score": 0.577,
          "base_score": 0.427,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 10,
          "title": "",
          "score": 0.565,
          "base_score": 0.415,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 6,
          "title": "",
          "score": 0.557,
          "base_score": 0.407,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 9,
          "title": "",
          "score": 0.534,
          "base_score": 0.384,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "descriptor",
          "attribute",
          "class",
          "instance",
          "property"
        ],
        "semantic": [],
        "merged": [
          "descriptor",
          "attribute",
          "class",
          "instance",
          "property"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.314980854795313,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:09.220300+00:00"
      }
    }
  ],
  "total_chapters": 23,
  "enrichment_provenance": {
    "taxonomy_id": "none",
    "taxonomy_version": "none",
    "taxonomy_path": "none",
    "taxonomy_checksum": "sha256:none",
    "source_metadata_file": "Fluent Python 2nd_metadata.json",
    "enrichment_date": "2025-12-17T23:07:09.229950+00:00",
    "enrichment_method": "msep",
    "model_version": "ai-agents-msep-v1",
    "processing_time_ms": 3342.8030849991046,
    "total_similar_chapters": 115
  }
}