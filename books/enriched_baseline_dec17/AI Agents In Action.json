{
  "metadata": {
    "title": "AI Agents In Action",
    "source_file": "AI Agents In Action_metadata.json"
  },
  "chapters": [
    {
      "chapter_number": 1,
      "title": "Segment 1 (pages 1-8)",
      "start_page": 1,
      "end_page": 8,
      "summary": "deﬁnition of agent.\nof agent is...\nof an agent.\nImage generation model\nNo agent or assistant\nAgent/assistant proxy for\nAgent/assistant acting on\nbehalf of user\nimportant emails.\nimportant emails.\ndecisions on behalf of user\nweather information and\nAI Agents in Action\nAI Agents in Action\nFor online information and ordering of this and other Manning books, please visit\nThe publisher offers discounts on this book when ordered in quantity.\nManning Publications Co. 20 Baldwin Road\nEmail: orders@manning.com\nWhere those designations appear in the book, and Manning Publications \nRecognizing the importance of preserving what has been written, it is Manning’s policy to have \nthe books we publish printed on acid-free paper, and we exert our best efforts to that end.\nRecognizing also our responsibility to conserve the resources of our planet, Manning books\nThe authors and publisher have made every effort to ensure that the information in this book \nManning Publications Co. Development editor: Becky Whitney\nTechnical editor: Ross Turner\nBooks are a powerful way for an author to connect with readers on a deeply personal ",
      "keywords": [
        "Large language model",
        "agent",
        "Manning Publications",
        "LLM",
        "language model",
        "Large language",
        "model",
        "language",
        "user",
        "Publications",
        "information",
        "book",
        "Large",
        "SHELTER ISLAND",
        "Manning books"
      ],
      "concepts": [
        "agents",
        "editor",
        "llm",
        "assistant",
        "emails",
        "model",
        "actions",
        "weather",
        "designations",
        "designer"
      ],
      "similar_chapters": [
        {
          "book": "AI Agents In Action",
          "chapter": 39,
          "title": "",
          "score": 0.782,
          "base_score": 0.632,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 3,
          "title": "",
          "score": 0.67,
          "base_score": 0.52,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 4,
          "title": "",
          "score": 0.644,
          "base_score": 0.494,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 5,
          "title": "",
          "score": 0.635,
          "base_score": 0.485,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 2,
          "title": "",
          "score": 0.618,
          "base_score": 0.468,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "manning",
          "publications",
          "manning publications",
          "books",
          "information"
        ],
        "semantic": [],
        "merged": [
          "manning",
          "publications",
          "manning publications",
          "books",
          "information"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.3207254660001658,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:00:43.645247+00:00"
      }
    },
    {
      "chapter_number": 2,
      "title": "Segment 2 (pages 9-16)",
      "start_page": 9,
      "end_page": 16,
      "summary": "1 Introduction to agents and their world\nDefining agents\nUnderstanding the component systems of an agent\nNavigating the agent landscape\nExploring GPT assistants through ChatGPT\nCreating an assistant to build an assistant\n4 Exploring multi-agent systems\nIntroducing multi-agent systems with AutoGen Studio\nwith agent critics\nGroup chat with agents and AutoGen\nBuilding an agent crew with CrewAI\nCreating a jokester crew of CrewAI agents\n■Observing agents \nRevisiting coding agents with CrewAI\n5 Empowering agents with actions\nDefining agent actions\nGetting started with SK semantic functions\nSynergizing semantic and native functions\nsemantic functions\nSemantic Kernel as an interactive service agent\nBuilding a semantic GPT interface\n6 Building autonomous assistants\nExploring the GPT Assistants Playground\nIntroducing agentic behavior trees\nRequired X setup\nBuilding conversational autonomous multi-agents\n7 Assembling and using an agent platform\nIntroducing Nexus, not just another agent platform\nDeveloping profiles and personas for agents\nPowering the agent and understanding the agent \nGiving an agent actions and tools\n8 Understanding agent memory and knowledge\nUnderstanding retrieval in AI applications\nDelving into semantic search and document \nApplying RAG to building agent knowledge\nImplementing memory in agentic systems\n9 Mastering agent prompts with prompt flow\nUnderstanding agent profiles and personas\n10 Agent reasoning and evaluation\nprompting\nprompting\nprompting\n11 Agent planning and feedback\nPlanning: The essential tool for all agents/assistants\nassistant and agentic systems\nApplication of assistant/agentic planning\nassistant/agentic reasoning\nagentic systems\n■Application of feedback to agentic/assistant \nreinforcement learning to create intelligent agents.\ncode, developing agents in Unity ML-Agents and deep reinforcement learning.\nworld’s perception of AI, and it changed the way we build intelligent systems.\nagentic systems that could undertake specific tasks, but now, those once-theoretical\nThis book is the culmination of my decades of experience in building intelligent\nAI agents are here, poised to transform how we interact with technology, how\nof understanding and expertise in building these systems.\nI want to introduce AI agents as tools that can be accessible",
      "keywords": [
        "agent",
        "GPT",
        "Building",
        "GPT assistants",
        "Understanding",
        "Semantic",
        "systems",
        "cover illustration xxii",
        "Exercises",
        "assistant",
        "Studio",
        "Creating",
        "AutoGen Studio",
        "application",
        "LLM"
      ],
      "concepts": [
        "agents",
        "prompting",
        "exercises",
        "semantic",
        "building",
        "understanding",
        "assistant",
        "systems",
        "creating",
        "create"
      ],
      "similar_chapters": [
        {
          "book": "AI Agents In Action",
          "chapter": 38,
          "title": "",
          "score": 0.918,
          "base_score": 0.768,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 3,
          "title": "",
          "score": 0.872,
          "base_score": 0.722,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 15,
          "title": "",
          "score": 0.864,
          "base_score": 0.714,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 14,
          "title": "",
          "score": 0.855,
          "base_score": 0.705,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 5,
          "title": "",
          "score": 0.852,
          "base_score": 0.702,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "agent",
          "agents",
          "systems",
          "agentic",
          "understanding"
        ],
        "semantic": [],
        "merged": [
          "agent",
          "agents",
          "systems",
          "agentic",
          "understanding"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.5022914653880577,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:00:43.645303+00:00"
      }
    },
    {
      "chapter_number": 3,
      "title": "Segment 3 (pages 17-24)",
      "start_page": 17,
      "end_page": 24,
      "summary": "Writing a book, even with the help of AI, is no small feat.\nmy time there that I first began developing the concepts and designs for agentic sys-\nbook.\nabout this book\nAI Agents in Action is about building and working with intelligent agent systems—not\njust creating autonomous entities but also developing agents that can effectively tackle\nThe book starts with the basics of working with large\nlanguage models (LLMs) to build assistants, multi-agent systems, and agentic behav-\nioral agents.\nFrom there, it explores the key components of agentic systems: retrieval\nI hope this book inspires you to see intelligent agents as partners in\nThis book is for anyone curious about intelligent agents and how to develop agentic\ncomplex multi-agent systems.\nNo prior experience with agents, agentic systems,\nworld of AI agents to do so with confidence.\nABOUT THIS BOOK\npossibilities of AI, this book is for you.\nligent agents.\nof AI agents in action.\nThis book has 11 chapters.\nChapter 1, “Introduction to agents and their world,”\nchat systems, assistants, and autonomous agents.\nAssistants are foundational agent\nHere, we explore two sophisticated multi-agent systems: CrewAI\nagentic system.\nThis chapter discusses how agents can use tools and functions to\ncoordinated agents.\nChapter 7, “Assembling and using an agent platform”—This chapter introduces Nexus,\na sophisticated platform for orchestrating multiple agents and LLMs. We discuss\nABOUT THIS BOOK\nof LLM agents.\nWe discuss how agents can incorporate planning to\nexamples of agentic systems that solve real-world problems.\nThe code for this book is spread across several open source projects, many of which\nbook, I strive to make the content as accessible as possible, taking a low-code approach\ncan generate meaningful code, showcasing the power of AI-assisted development.\nAdditionally, you’ll find a variety of assistant profiles and multi-agent systems that\nagents.\nThis book contains many examples of source code both in numbered listings and in\nABOUT THIS BOOK\nbook at https://livebook.manning.com/book/ai-agents-in-action.\nwww.manning.com/books/ai-agents-in-action.\nbook has been placed in three GitHub repositories that are all publicly accessible:\nGPT-Agents (the original book title), at https://github.com/cxbxmxcx/GPT-\nAgents, holds the code for several examples demonstrated in the chapters.\nomous agent systems.\nagentic tool that can help you create agentic systems and demonstrate various\nPurchase of AI Agents in Action includes free access to liveBook, Manning’s online\nbook/ai-agents-in-action/discussion.\nauthored multiple influential books exploring deep learning, game development,\nThe figure on the cover of AI Agents in Action is “Clémentinien,” taken from Balthasar",
      "keywords": [
        "book",
        "Agents",
        "code",
        "systems",
        "agentic systems",
        "agentic",
        "assistants",
        "GPT assistants",
        "agent systems",
        "multi-agent systems",
        "explore",
        "source code",
        "actions",
        "chapters",
        "book learning assistant"
      ],
      "concepts": [
        "agents",
        "book",
        "chapters",
        "code",
        "assistants",
        "developing",
        "including",
        "include",
        "help",
        "discusses"
      ],
      "similar_chapters": [
        {
          "book": "AI Agents In Action",
          "chapter": 2,
          "title": "",
          "score": 0.872,
          "base_score": 0.722,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 5,
          "title": "",
          "score": 0.798,
          "base_score": 0.648,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 36,
          "title": "",
          "score": 0.776,
          "base_score": 0.626,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 14,
          "title": "",
          "score": 0.775,
          "base_score": 0.625,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 4,
          "title": "",
          "score": 0.767,
          "base_score": 0.617,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "book",
          "agents",
          "systems",
          "agentic",
          "ai"
        ],
        "semantic": [],
        "merged": [
          "book",
          "agents",
          "systems",
          "agentic",
          "ai"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.41178767190027254,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:00:43.645346+00:00"
      }
    },
    {
      "chapter_number": 4,
      "title": "Segment 4 (pages 25-32)",
      "start_page": 25,
      "end_page": 32,
      "summary": "Introduction to agents\nDefining agents\nagent):\nagent\nWhy agents?\nIntroduction to agents and their world\nTools like OpenAI’s GPT Assistants will also fall under the AI agent blanket.\n(LLM) directly or through an agent/assistant proxy, an agent/assistant, or an autono-\nmous agent.\nThere is no proxy agent or other assistant\nrienced a proxy agent interaction.\nagent is an everyday use case to assist users with unfamiliar tasks or models.\nAutonomous agent—In this use case, the agent interprets the user’s request, con-\nThe agent may\nsingle agent.\nFor more complex problems, we often break agents into profiles or per-\nEach agent profile is given a specific task and executes that task with specialized\nMulti-agent systems are agent profiles that work together in various configurations to\nDefining agents\nThese agents work and communicate\nMulti-agent systems can work autonomously but may also function guided entirely\ndeﬁnition of agent.\nof agent is...\nof an agent.\nNo agent or assistant\nAgent/assistant proxy for\nAgent/assistant acting on\nAutonomous agent making\nThe differences between the LLM interactions from direct action compared to using proxy agents, \nagents, and autonomous agents\nIntroduction to agents and their world\nagent but often magnified.\nWhere a single agent typically specializes in a single task,\nmulti-agent systems can tackle multiple tasks in parallel.\nMultiple agents can also pro-\nHowever, an agent itself can also be assembled using multiple components.\nnext section, we’ll cover topics ranging from an agent’s profile to the actions it may\nUnderstanding the component systems of an agent\nAgents can be complex units composed of multiple component systems.\nponents are the tools the agent employs to help it complete its goal or assigned tasks\nFigure 1.3 describes the major categories of components a single-agent system may\nThe controller agent\nWorker agents\nUnderstanding the component systems of an agent\nAt the core of all agents is the profile and persona; extending from\nthat are the systems and functions that enhance the agent.\nThe agent profile and persona shown in figure 1.4 represent the base description of\nthe agent.\nWe’ll explore how to create effective and specific agent profiles/personas through\nA persona represents the agent’s\ntool an agent can use.\nground the agent and empower\nallow the agent to learn and\nThe five main components of a single-agent system (image generated through DALL-E 3)\nIntroduction to agents and their world\nThe agent or assistant profile is composed of elements, including the\nFigure 1.5 demonstrates the component actions and tool use in the context of agents\nplans, influencing the agent’s behavior and enhancing learning.\npredefined plans, enhancing our ability to effectively shape agent behavior and learn-\nAgents\nAgent persona: We’ll understand how\nthe agent effectively.\nAgent role and demographics: We’ll\nor other agents.\nagent capabilities.\nAn in-depth look at how we’ll explore creating agent profiles\nUnderstanding the component systems of an agent\neven simple lists serving as agent memories.\nFigure 1.7 shows the reasoning and evaluation component of an agent system.\nto clarify the agent’s objectives.\nof agent behaviors.\nTools, self-knowledge, other agents\nstates, other agents\nThe aspects of agent actions we’ll explore in this book\nrelevant data and enhancing the agent’s\nExploring the role and use of agent memory and knowledge\nIntroduction to agents and their world\nFigure 1.8 shows the component agent planning/feedback and its role in organizing\nPlanning without feedback—Autonomous agents make decisions independently.\nWithin planning, agents may employ single-path reasoning, sequential reasoning through\nReasoning enables the agent\nfor an agent’s self-reﬂection\n• LLM feedback\nExploring the role of agent planning and reasoning",
      "keywords": [
        "agent",
        "LLM",
        "feedback",
        "’ll",
        "user",
        "task",
        "assistant",
        "language model",
        "planning",
        "memory",
        "persona",
        "actions",
        "large language model",
        "language",
        "systems"
      ],
      "concepts": [
        "agents",
        "actions",
        "plan",
        "planning",
        "task",
        "feedback",
        "persona",
        "user",
        "reasoning",
        "generation"
      ],
      "similar_chapters": [
        {
          "book": "AI Agents In Action",
          "chapter": 5,
          "title": "",
          "score": 0.862,
          "base_score": 0.712,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 2,
          "title": "",
          "score": 0.842,
          "base_score": 0.692,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 15,
          "title": "",
          "score": 0.839,
          "base_score": 0.689,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 36,
          "title": "",
          "score": 0.796,
          "base_score": 0.646,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 12,
          "title": "",
          "score": 0.791,
          "base_score": 0.641,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "agent",
          "agents",
          "systems",
          "component",
          "agent assistant"
        ],
        "semantic": [],
        "merged": [
          "agent",
          "agents",
          "systems",
          "component",
          "agent assistant"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.428191045639271,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:00:43.645387+00:00"
      }
    },
    {
      "chapter_number": 5,
      "title": "Segment 5 (pages 33-40)",
      "start_page": 33,
      "end_page": 40,
      "summary": "component has a role outside of the autonomous agent and can effectively empower\neven the regular agent.\nAI agents and assistants have quickly moved from the main commodity in AI research\nin the construction and empowerment of agents.\nThe first agent systems, such as AutoGPT, emerged from\nagent systems.\nThe agent is designed to iterate a planned sequence of tasks that it\nThrough each task iteration of steps, the agent\nagent may replan the steps and update the plan based on new knowledge or human\nning and iteration with LLM models.\nFrom this and in tandem, other agent systems\nHowever, autonomous agent systems require trust in the agent decision-making\ning of an autonomous agent’s capabilities.\nnew world of AI believe an AGI using autonomous agent systems is an\nTherefore, as our goal in this book is to understand all agent\nforms, many more practical applications will be driven by non-autonomous agents.\nAgents and agent tools are only the top layer of a new software application devel-\nThe agent evaluates if\nModels (GPT-4)\nThe agent can be\nAgent executes\nThe agent could write code to\nThe agent\nThe AI agent paradigm is not only a shift in how we work with LLMs but is also per-\nand what role AI agents play.\nThese AI interfaces allow agents to collect data and\ninteract with software applications, even other agents or agent applications.\nAgent interface layer (natural language)\nPlanning: Agent takes the goal and breaks into tasks.\n4. Agent presents the report.\nExternal agents\n3. External agent formats data and\nA vision of how agents will interact with software systems\nThe construction of AI interfaces will empower agents that need to consume\nGPT agents represent an entire shift in how consumers and developers approach\ndaily, a new agent framework, component, or interface pops up on GitHub or in a\ngrasp what agent systems are and how to use them.\nguage model (LLM) in AI.\nThe four main types of LLM interactions include direct user interaction, agent/\nActions and tools for agents can be manually generated, recalled from memory,\nThe rise of AI agents has introduced a new software development paradigm,\nagent systems, whether single, multiple, or autonomous.\nof large language models\nThe term large language models (LLMs) has now become a ubiquitous descriptor of a\nLLMs and GPTs are generative models, which means they are trained to generate\nGenerative models create something from the input, whereas predictive and\nthis diagram, data represents the content used to train the model, and architecture is\nmodel.\nModels are further trained specifically to the desired use case, including\nthat refines the input data and model training to better match a particular use case\ncontent the model will train on.\ntrain the model.\ndeﬁne the model use case, such as\nHarnessing the power of large language models\nHarnessing the power of large language models\nthese models will be successively trained using various methods for the desired use\nproduces a model use case called chat completions.\ning agents and assistants.\nCompletion models are trained/designed only to provide\nLLMs called chat completions models.\ning other model forms for your agents.\nNumerous AI agents and assistant projects use the OpenAI API SDK to connect to an\nThis chapter will look at connecting to an LLM model using the OpenAI Python\nConnecting to the chat completions model\nthrough setting up an OpenAI account and accessing GPT-4 or other models.",
      "keywords": [
        "agent",
        "autonomous agent",
        "LLMs",
        "LLM",
        "models",
        "agent systems",
        "data",
        "autonomous agent systems",
        "Language",
        "tasks",
        "large language models",
        "autonomous",
        "natural language",
        "language models",
        "systems"
      ],
      "concepts": [
        "agent",
        "models",
        "data",
        "tasks",
        "plans",
        "planning",
        "uses",
        "generate",
        "generated",
        "language"
      ],
      "similar_chapters": [
        {
          "book": "AI Agents In Action",
          "chapter": 4,
          "title": "",
          "score": 0.862,
          "base_score": 0.712,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 2,
          "title": "",
          "score": 0.852,
          "base_score": 0.702,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 36,
          "title": "",
          "score": 0.827,
          "base_score": 0.677,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 3,
          "title": "",
          "score": 0.798,
          "base_score": 0.648,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 15,
          "title": "",
          "score": 0.758,
          "base_score": 0.608,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "agent",
          "models",
          "language",
          "agents",
          "systems"
        ],
        "semantic": [],
        "merged": [
          "agent",
          "models",
          "language",
          "agents",
          "systems"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.42078090147871433,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:00:43.645442+00:00"
      }
    },
    {
      "chapter_number": 6,
      "title": "Segment 6 (pages 41-49)",
      "start_page": 41,
      "end_page": 49,
      "summary": "Next, open the connecting.py file in VS Code, and inspect the code shown in listing 2.2.\nBe sure to set the model’s name to an appropriate name—for example, gpt-4.\nmodel=\"gpt-4-1106-preview\",\nmessages=[{\"role\": \"system\",\n{\"role\": \"user\", \"content\": user_message}],\nreturn response.choices[0].message.content    \nYou must set your OpenAI API key in the .env file, as shown in the next listing.\nAgain, refer to appendix A to find out how to get a key and find a model name.\nAfter setting the key, you can debug the file by pressing the F5 key or selecting Run >\nRemember that the response from a generative model depends on the probability.\nIf you want a model to be more consistent, turn the temperature down to 0, but if you\nwant the model to produce more variation, turn the temperature up.\nDigging into the chat completions request and response features can be helpful.\nmodel, the messages, and the temperature.\nmodel=\"gpt-4-1106-preview\",                \nmessages=[{\"role\": \"system\", \n{\"role\": \"user\", \"content\": user_message}],     \nWithin the request, the messages block describes a set of messages and roles used in a\nMessages for a chat completions model can be defined in three roles:\nThe model or deployment used \nrole message\nGo ahead and reduce the temperature to .0, and run the message_history.py\nSetting a request’s temperature will often depend on your particular use case.\nrunning the message_history.py file in VS Code.\n\"model\": \"gpt-4-1106-preview\",    \nA model may \nmodel used\nexplore in the next section how to load and use open source LLMs. 2.2\nInstalling and running LM Studio\ndownload and set up LM Studio:\nFigure 2.3 shows the LM Studio window running.\nrent list of hot models, search for others, and even download.\nit with the requirements of a given model.\ncan run a given model.\nFrom this page, you can see all the model\nCompatibility Guess button, the software will even tell you if the model will run on\nClick to download any model that will run on your system.\nwith models designed for chat completions, but if your system is limited, work with\nmodels.\nRun a local model\ndownloaded models.\nAfter the model is downloaded, you can then load and run the model on the chat\nFigure 2.5 shows loading and running a\nmodel on the chat page.\nTo load and run a model, open the drop-down menu at the top middle of the\npage, and select a downloaded model.\nmodel inference.\nA GPU will generally speed up the model response times in some\nChatting with a model and using or playing with various prompts can help you\ndetermine how well a model will work for your given use case.\nLM Studio also allows a model to be run on a server and made accessible using the\nWe’ll see how to use the server feature and serve a model in the\nLook at the model\ninforms you if a model will run.\ndownloaded models\nRunning an LLM locally as a server is easy with LM Studio.\nload a model, and then click the Start Server button, as shown in figure 2.6.\nthere, you can copy and paste any of the examples to connect with your model.\nLoaded model\nModel system\nModel performance\nThe LM Studio chat page with a loaded, locally running LLM\nmodel=\"local-model\",                          \nLoaded model\nThe LM Studio server page and a server running an LLM\nlems, be sure your configuration for the Server Model Settings matches the model\nFor example, in figure 2.6, shown earlier, the loaded model differs from the\nNow, you can use a locally hosted LLM or a commercial model to build, test, and\nA prompt defined for LLMs is the message content used in the request for better\nLoaded model\nmatch the loaded model.\nChoosing the correct Server Model Settings for the loaded model",
      "keywords": [
        "model",
        "Studio",
        "LLMs",
        "message",
        "OpenAI",
        "role",
        "API",
        "request",
        "key",
        "server",
        "LLM",
        "response",
        "Code",
        "Run",
        "OpenAI API"
      ],
      "concepts": [
        "model",
        "response",
        "prompt",
        "listing",
        "messages",
        "server",
        "setting",
        "studio",
        "run",
        "runs"
      ],
      "similar_chapters": [
        {
          "book": "AI Agents In Action",
          "chapter": 22,
          "title": "",
          "score": 0.755,
          "base_score": 0.605,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 37,
          "title": "",
          "score": 0.59,
          "base_score": 0.44,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 19,
          "title": "",
          "score": 0.588,
          "base_score": 0.438,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 23,
          "title": "",
          "score": 0.559,
          "base_score": 0.409,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 14,
          "title": "",
          "score": 0.537,
          "base_score": 0.387,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "model",
          "server",
          "loaded",
          "loaded model",
          "lm"
        ],
        "semantic": [],
        "merged": [
          "model",
          "server",
          "loaded",
          "loaded model",
          "lm"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.3026719327639669,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:00:43.645484+00:00"
      }
    },
    {
      "chapter_number": 7,
      "title": "Segment 7 (pages 50-57)",
      "start_page": 50,
      "end_page": 57,
      "summary": "Figure 2.9 shows the tactics for this strategy in more detail,\nalong with examples for each tactic.\nWe’ll look at running these examples using a\nto a task you can specify in a request, the better the response.\nThis strategy has been broken down into specific tactics you can apply to prompts.\nTo understand how to use those, a code demo (prompt_engineering.py) with various\nprompt examples is in the chapter 2 source code folder.\nOpen the prompt_engineering.py file in VS Code, as shown in listing 2.8.\ncode starts by loading all the JSON Lines files in the prompts folder.\nthe list of files as choices and allows the user to select a prompt option.\nthe option, the prompts are submitted to an LLM, and the response is printed.\nTactics include detailing queries, adopting personas, using delimiters,\nspecifying steps, providing examples, and specifying output length.\nTactics involve instructing the model to use or cite reference texts.\nTactics involve evaluating model outputs with reference to standard\nPrompt Engineering Strategies\nOpenAI prompt engineering strategies reviewed in this book, by chapter location\nif not text_files:\nprint(\"No text files found in the directory.\")\nprint(\"Available prompt tactics:\")\nExamples\nSpecify Output\nTactics for Strategy: Writing Clear Instructions\nminister of Canada,\nYou are a prompt\nEXAMPLES\nStep 1 - Summarize\nexample.\nlength of output\nExamples are a\nThe tactics for the Write Clear Instructions strategy\nselected_file = text_files[choice - 1]\nprompts = \nprint(f\"Running prompts for {selected_file}\")\nprint(f\"PROMPT {i+1} --------------------\")\nprint(prompt)\nprint(prompt_llm(prompt))                      \nThis will allow you to explore the same prompt engineering tactics applied to\nBy default, this example uses the OpenAI model\nFigure 2.10 shows the output of running the prompt engineering tactics tester, the\nprompt_engineering.py file in VS Code.\nIn the following sections, we’ll explore each prompt tactic in more detail.\nexamples for exploring this tactic.\nprompt and \nprompt to an \nThe output of the prompt engineering tactics tester\n\"content\": \"What is an agent?\"     \nPlease give me 3 examples of a GPT agent\nThis example demonstrates the difference between using detailed queries and not.\nalso goes a step further by asking for examples.\ncontext you can provide in your prompt, the better the overall response.\nexamples is another way of enforcing the relationship between the question and the\nThe LLM can then use that context and/or rules to frame all later output\nThis is a compelling tactic and one that we’ll make heavy use of throughout\nListing 2.10 shows an example of employing two personas to answer the same ques-\nand ask for examples.\nAnswer all your replies as \nthe way the LLM outputs the response.\nDelimiters are a useful way of isolating and getting the LLM to focus on some part of a\nThe following listing demonstrates two examples, but there are several\nuse an LLM.\nSummarize the text delimited by triple quotes \nWhen you run this tactic, pay attention to the parts of the text the LLM focuses on\nwhen it outputs the response.\nSpecifying steps\nSpecifying steps is another powerful tactic that can have many uses, including in\ncomplex prompts into a step-by-step process that the LLM can follow.\nUse the following step-by-step instructions to respond to user inputs.\nStep 1 - The user will provide you with text in triple single quotes.\nSummarize this text in one sentence with a prefix that says 'Summary: '.\nUse the following step-by-step instructions to respond to user inputs.\nStep 1 - The user will provide you with text.\nthe text in one sentence with a prefix that says 'Answer: '.\nProviding examples\nProviding examples is an excellent way to guide the desired output of an LLM.\nare numerous ways to demonstrate examples to an LLM.\nThe system message/prompt\ncan be a helpful way to emphasize general output.\nIn the following listing, the example\nis added as the last LLM assistant reply, given the prompt “Teach me about Python.”\nAnswer all replies in a consistent style that follows the format, \nExample:\nproviding_examples.jsonl\nAdds a limit output tactic to \nProviding examples can also be used to request a particular output format from a\nFor example, asking an LLM to pro-\nduce code that matches a sample output is an excellent use of examples.\nthis tactic throughout the book, but other methods exist for guiding output.\nSpecifying output length\nThe tactic of specifying output length can be helpful in not just limiting tokens but\nListing 2.14 shows an example of using\nstrates limiting output to a concise set of bullet points.\ndown the output and keep answers short.\nspecifying_output_length.jsonl",
      "keywords": [
        "LLM",
        "prompt",
        "user",
        "output",
        "role",
        "Text",
        "content",
        "Prompt Engineering",
        "tactic",
        "Clear Instructions strategy",
        "Write Clear Instructions",
        "prompt engineering tactics",
        "Clear Instructions",
        "SYSTEM",
        "listing"
      ],
      "concepts": [
        "prompts",
        "role",
        "tactics",
        "listing",
        "output",
        "examples",
        "answers",
        "user",
        "printed",
        "uses"
      ],
      "similar_chapters": [
        {
          "book": "AI Agents In Action",
          "chapter": 28,
          "title": "",
          "score": 0.763,
          "base_score": 0.613,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 30,
          "title": "",
          "score": 0.726,
          "base_score": 0.576,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 31,
          "title": "",
          "score": 0.712,
          "base_score": 0.562,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 33,
          "title": "",
          "score": 0.602,
          "base_score": 0.452,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 32,
          "title": "",
          "score": 0.567,
          "base_score": 0.417,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "tactics",
          "examples",
          "tactic",
          "output",
          "prompt"
        ],
        "semantic": [],
        "merged": [
          "tactics",
          "examples",
          "tactic",
          "output",
          "prompt"
        ]
      },
      "topic_id": 1,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.4037000319215909,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:00:43.645525+00:00"
      }
    },
    {
      "chapter_number": 8,
      "title": "Segment 8 (pages 58-66)",
      "start_page": 58,
      "end_page": 66,
      "summary": "in processor models.\nModel Performance:\nmodel may perform on a\nModel Parameters (Size):\nmodel in billions of\nmodels typically perform\nUse Case (Model Type):\nmodel and expected use\ncompletions for a model\nthe model.\nhow the model is trained\nModels\nmodel’s context size is in\nModel Speed (Model\nspeed of the model.\nmodels marked Turbo are\nModel Cost (Project\nmodel on your infrastructure.\nating a GPT agent or any LLM task.\nModel context size and speed could be considered the sixth\nand seventh criteria, but they are usually considered variations of a model deployment\nModel parameters (size)—The size of a model is often an excellent indication of\nown locally hosted model, the model size will also primarily dictate the com-\nUse case (model type)—The type of model has several variations.\nmodels such as ChatGPT are effective for iterating and reasoning through a\nproblem, whereas models such as completion, question/answer, and instruct\nA chat completions model is essential for\ntate the domain of a model.\nWhile general models can be effective across tasks,\nmore specific or fine-tuned models can be more relevant to a domain.\nmodel may perform as well as or better than a larger model such as GPT-4.\nstand what method was used to train a model.\nHow a model is trained can\nContext token size—The context size of a model is more specific to the model\nIt dictates the size of context or memory the model may\nThe models will typically be\nModel speed (model deployment)—The speed of a model is dictated by its inference\nFor commercial models,\nThere is a lot to consider when choosing which model you want to build a production\n– Serve the model using LM Studio.\n– Write Python code to connect to the served model.\n– Integrate the prompt engineering tactics example with the served model.\nObjective—Compare the performance of a commercial LLM such as GPT-4\nTurbo with an open source model using prompt engineering examples.\n– Implement the prompt engineering examples using GPT-4 Turbo.\n– Evaluate the models based on criteria such as response accuracy, coherence,\ncommercial model.\n– Compare these options to using a commercial model in terms of cost, perfor-\nGenerative models (e.g., LLMs and GPTs) differ from predictive/classification\nThe OpenAI API SDK can be used to connect to an LLM from models, such as\nGPT-4, and also used to consume open source LLMs.\nOpen source LLMs are an alternative to commercial models and can be hosted\nGPT assistants\nmately, an agent platform called GPT Assistants, we’ll introduce GPT assistants\nIntroducing the OpenAI GPT Assistants platform \nEngaging GPT assistants\nExploring GPT assistants through ChatGPT\nChatGPT (ChatGPT Plus, at the time of writing) allows you to build GPT assistants,\nWhen OpenAI announced the release of the GPT Assistants platform, it helped\ning GPT assistants through ChatGPT Plus, which requires a premium subscription.\ning along with the GPT Builder chat interface.\nyour own GPT.\nExploring GPT assistants through ChatGPT\nthe GPT Builder to create an \nEngaging GPT assistants\nThe Configure panel of the GPT Assistants platform interface",
      "keywords": [
        "Model",
        "GPT assistants",
        "GPT",
        "LLM",
        "LLMs",
        "GPT Store",
        "GPT Assistants platform",
        "assistants",
        "Exploring GPT assistants",
        "GPT Builder",
        "agent",
        "GPTs",
        "Engaging GPT assistants",
        "Size",
        "Open source LLMs"
      ],
      "concepts": [
        "models",
        "agents",
        "llm",
        "llms",
        "tasks",
        "exercises",
        "assistant",
        "assists",
        "differences",
        "different"
      ],
      "similar_chapters": [
        {
          "book": "AI Agents In Action",
          "chapter": 2,
          "title": "",
          "score": 0.585,
          "base_score": 0.435,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 4,
          "title": "",
          "score": 0.567,
          "base_score": 0.417,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 27,
          "title": "",
          "score": 0.566,
          "base_score": 0.416,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 9,
          "title": "",
          "score": 0.551,
          "base_score": 0.401,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 36,
          "title": "",
          "score": 0.548,
          "base_score": 0.398,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "model",
          "gpt",
          "size",
          "gpt assistants",
          "models"
        ],
        "semantic": [],
        "merged": [
          "model",
          "gpt",
          "size",
          "gpt assistants",
          "models"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.3055409589282077,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:00:43.645565+00:00"
      }
    },
    {
      "chapter_number": 9,
      "title": "Segment 9 (pages 67-76)",
      "start_page": 67,
      "end_page": 76,
      "summary": "Exploring GPT assistants through ChatGPT\nWhen generating a recipe, provide a shopping list of ingredients with \nWhen generating a recipe, estimate the total cost per serving based on \nDefining rules for an assistant/agent essentially creates a template for what the agent\nGiving an agent/assistant a particular personality can make a differ-\nTry the assistant by requesting a recipe and providing a list of ingredients you have\nFigure 3.4 shows the formatted output results from the GPT provided by the prompt.\ninstructions we provided the agent.\nEngaging GPT assistants\nOut of the box, though, GPT Assistants is quite impressive for quickly building a proof-\nof-concept assistant or agent.\nat more impressive features GPTs provide, such as file uploads and code interpretation.\nBuilding a GPT that can do data science\nThe GPT Assistants platform has and will likely be extended to include various agent\nIn our next exercise, we’ll build an assistant to perform a first-pass data science\nThis agent will use the ability or action that\nassistant will allow file uploads by default.\nthat than to ask an LLM to build us an assistant?\ning ChatGPT (GPT-4) to design a data science assistant.\ncsv file that contains interesting data?\nPrompting for a data science assistant\nThe GPT assistant creates\nCompanion GPT Assistant\nBuilding a GPT that can do data science\nThe result of that conversation provided for the assistant instructions shown in listing\nIn this case, the assistant was named Data Scout, but feel free to name your assis-\nThis GPT, named Data Scout, is designed to assist users by analyzing CSV \nstatistical testing, predictive modeling, data visualization, and more, \nData Scout requires the user to upload a csv file of data they want to \ntasks:\nAsk the user to upload a csv file of data.\nInstructions: Use the pandas library to read the data from the CSV \nTask: Identify and handle missing values, correct data types.\nnumerical data, use the median or mean.\nConvert data types if necessary \nTask: Create visualizations to explore the data.\nData Scout instructions\nEngaging GPT assistants\nTask: Test a hypothesis formulated based on the dataset.\nInstructions: Depending on the data type, perform statistical tests \nInstructions: Based on the task (classification or regression), select \nTask: Split the data into training and testing sets, then train the \ndata.\nTask: Assess the model performance.\nBe sure to give the assistant the Code Interpretation tool (skill) by\nNow, we can test the assistant by uploading a CSV file and asking questions about\nOf course, you can use any CSV file you\nBuilding a GPT that can do data science\nWe could upload the file and ask the assistant to do its thing, but for this exercise,\nListing 3.6 shows the prompt and uploading the file to engage\nthe assistant (including Netflix_titles.csv in the request).\nDepending on your data and filter, the assistant will now use the\nCode Interpreter as a data scientist would to analyze and extract trends in the data.\nnetflix_titles.csv (top row of data)\nPrompting the Data Scout\nof data from the \nEngaging GPT assistants\nFigure 3.6 shows the output generated for the prompt in listing 3.5 using the net-\nflix_titles.csv file for data.\nThe data science plots the assistant is building are created by writing and executing\nmovies\nThe output generated by the assistant as it analyzed the CSV data\nGPT in the next section to assist us.\nCreating an assistant to build an assistant\nGiven GPTs’ capabilities, it only makes sense that we use one to assist in building oth-\nIn this section, we’ll build a GPT that can help us create a service we can connect\nThe following listing shows the prompt for creating the instructions for our helper\nThis prompt is intended to generate the instructions for the assistant.\nI want to create a GPT assistant that can generate a FastAPI service that \ngeneration, I want the assistant to generate the OpenAPI specification for \nListing 3.8 shows the bulk of the instructions generated for the prompt.\nCopy and paste those instructions from the file (assistant_builder.txt) into your\nThis GPT is designed to assist users in generating FastAPI services \nThe assistant will provide code snippets \n3. Generate FastAPI Code:\nCustom action assistant instructions\nEngaging GPT assistants\nstructure of the input and output data.\nFastAPI automatically generates the OpenAPI specification based on \nAfter preparing the assistant, ensure everything is set in the Configure panel (includ-\nListing 3.9 shows the request to the Custom Action Assistant to create a daily task\nOf course, you can also ask the assistant to guide you and create your service.\nI want to define a GET endpoint that replies with my list of daily tasks  \nAfter you enter the prompt, the assistant will generate the code and instructions for\ntasks = [    \nPrompt requesting task endpoint service\ndaily_tasks_api.py (generated from assistant)\na type for the task.\nTask(id=3, description=\"Complete FastAPI project\", completed=False),\n@app.get(\"/tasks\", response_model=List[Task])   \nRetrieve a list of daily tasks.\nfollowing listing, which runs the API in the chapter source file.\nThe tasks endpoint\nEngaging GPT assistants\nsave this document for later use when setting up the custom action on the agent.\nendpoint produces JSON, but you can also use specifications written in YAML.\n/tasks:\ndescription: Retrieve a list of daily tasks.\nTask:\ntitle: Task\nBefore connecting an assistant to the service, you must set up and use ngrok to open a\nPrompt the GPT to provide the\nOpenAPI specification for the task API ",
      "keywords": [
        "GPT assistants",
        "GPT",
        "Engaging GPT assistants",
        "data",
        "assistant",
        "task",
        "code",
        "GPT assistant creates",
        "Data Scout",
        "instructions",
        "data science assistant",
        "Listing",
        "agent",
        "Code Interpreter",
        "data science"
      ],
      "concepts": [
        "task",
        "list",
        "assistant",
        "assist",
        "uses",
        "instructions",
        "instruct",
        "type",
        "typing",
        "descriptive"
      ],
      "similar_chapters": [
        {
          "book": "AI Agents In Action",
          "chapter": 10,
          "title": "",
          "score": 0.807,
          "base_score": 0.657,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 19,
          "title": "",
          "score": 0.798,
          "base_score": 0.648,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 11,
          "title": "",
          "score": 0.765,
          "base_score": 0.615,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 2,
          "title": "",
          "score": 0.729,
          "base_score": 0.579,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 36,
          "title": "",
          "score": 0.682,
          "base_score": 0.532,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "data",
          "assistant",
          "gpt",
          "csv",
          "data science"
        ],
        "semantic": [],
        "merged": [
          "data",
          "assistant",
          "gpt",
          "csv",
          "data science"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.41264969724416817,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:00:43.645607+00:00"
      }
    },
    {
      "chapter_number": 10,
      "title": "Segment 10 (pages 77-84)",
      "start_page": 77,
      "end_page": 84,
      "summary": "Copy this URL for later use when setting up the assistant.\nnext section, we’ll create the assistant that consumes this service as a custom action.\nConnecting the custom action to an assistant\nngrok tunnel, we can build the new assistant.\nThis time, we’ll create a simple assistant\ntions shown in listing 3.14 into the new assistant.\nBe sure to name the assistant and\nallow the assistant to create the final plot, showing the tasks.\nEngaging GPT assistants\nin the assistant custom actions will need to be updated.\nCustom actions are a great way to add dynamic functionality to an assistant, whether\nan assistant’s knowledge.\nEngaging GPT assistants\nExtending an assistant’s knowledge using file uploads\nThe GPT Assistants platform provides a knowledge capability called file uploads,\nAs of writing, the GPT Assistants platform allows you to upload up to\ndesigned to assist users with consuming books.\nTo demonstrate this concept, we’ll build a GPT based on a classic math text called\nIf you’re serious about learning calculus but this assistant is still too\nYou could also try making your Calculus and Pizza assistant if you\nupload the file, as shown in figure 3.10.\nUpload the book from the chapter’s source\nGPT’s knowledge.\nExtending an assistant’s knowledge using file uploads\nA copy of the book is uploaded at \nThe GPT can \nInstructions for Calculus Made Easy GPT\nassistant additional knowledge.\nknowledge for the assistant.\nso the assistant can demonstrate\nAdding files to the assistant’s knowledge\nEngaging GPT assistants\nAfter updating the assistant, you can try it in the preview window or the book version\nby searching for Calculus Made Easy in the GPT Store.\nThis GPT demonstrates the ability of an assistant to use a book as a companion\nbooks or other documents could be uploaded.\nusing a GPT.\nIn the next section, we’ll look at how knowledge of file uploads can be\nKnowledge search and more with file uploads\nThe GPT Assistants platform’s file upload capability supports up to 512 MB of\nuploads for a single assistant.\nFor this next exercise, we’ll employ an assistant with knowledge of multiple books\nassistant will consume classic texts about robots.\nWe’ll name this assistant the Classic\nStart by creating a new GPT assistant in the ChatGPT interface.\ninstructions in listing 3.17, and name and describe the assistant.\nyour assistants and \nExtending an assistant’s knowledge using file uploads\nThis GPT, Classic Robot Reads and uses the persona of \nThis GPT will only references and discusses the books \nin its knowledge base of uploaded files.\nthe GPT to teach the basics of calculus.\nOutput from asking the GPT to teach calculus\nto give your GPT a \nassistant only \nEngaging GPT assistants\nFigure 3.12 demonstrates uploading multiple files at a time.\nMake the assistant more helpful by\nUploading documents to the assistant’s knowledge",
      "keywords": [
        "GPT",
        "GPT assistants",
        "assistant",
        "Engaging GPT assistants",
        "GPT Assistants platform",
        "Made Easy GPT",
        "Calculus Made Easy",
        "knowledge",
        "Calculus",
        "File uploads",
        "Calculus Made",
        "Easy GPT",
        "Engaging GPT",
        "Made Easy",
        "GPT Builder"
      ],
      "concepts": [
        "assistant",
        "assist",
        "calculus",
        "knowledge",
        "service",
        "books",
        "tasks",
        "making",
        "make",
        "uploads"
      ],
      "similar_chapters": [
        {
          "book": "AI Agents In Action",
          "chapter": 19,
          "title": "",
          "score": 0.879,
          "base_score": 0.729,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 9,
          "title": "",
          "score": 0.807,
          "base_score": 0.657,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 11,
          "title": "",
          "score": 0.803,
          "base_score": 0.653,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 21,
          "title": "",
          "score": 0.66,
          "base_score": 0.51,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 2,
          "title": "",
          "score": 0.66,
          "base_score": 0.51,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "gpt",
          "assistant",
          "calculus",
          "knowledge",
          "uploads"
        ],
        "semantic": [],
        "merged": [
          "gpt",
          "assistant",
          "calculus",
          "knowledge",
          "uploads"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.37863318502667603,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:00:43.645648+00:00"
      }
    },
    {
      "chapter_number": 11,
      "title": "Segment 11 (pages 85-94)",
      "start_page": 85,
      "end_page": 94,
      "summary": "assistant.\ncreation of assistants as a form of knowledge that can be exposed publicly.\nsection, we’ll look at how to make assistants consumable by all.\nOnce you’re happy with your GPT, you can use it or share it with others by providing a\nConsuming GPT assistants through ChatGPT currently requires a Plus subscrip-\nUse cases for a knowledge assistant\npublic, usage of that assistant is taken\nGPT \nEngaging GPT assistants\nStore, the assistant’s usage is taken from the account using it, not the publisher.\nExpensive GPT assistants\nTherefore, we want to ensure that users using your GPT don’t exceed their resource\nwhile using the GPT:\nVision, describing images—If you’re building an assistant that uses vision to describe\nMaking your assistant aware of resource usage can be as simple as adding the rule\nshown in listing 3.18 to the assistant’s instructions.\nment relaying the warning to the user and making the assistant aware.\nyour assistant.\nUpon the release of GPT Assistants and the GPT Store, OpenAI announced the\nassistants, provided you have a Plus subscription, but that may change in the future.\nfew GPTs in the GPT Store can help demonstrate your knowledge and ability to\nThese types of assistants\nStore and provides companies the ability to lead customers using an assistant.\ntrend with OpenAI continues, we’ll likely see a fully public GPT Store.\nEngaging GPT assistants\nyour GPT:\ngood search engine optimization can help increase exposure to your assistant.\nuse your assistant.\nto iterate over a few images can help draw users to your assistant.\nfits your assistant.\nstanding of how to build agents and assistants.\nbook, GPT assistants are a useful foundation for your knowledge.\nExercise 1—Build Your First GPT Assistant\nObjective—Create a simple GPT assistant using the ChatGPT interface.\n– Navigate to the GPT Assistants platform, and click the Create button.\n– Follow the Builder chat interface to create a Culinary Companion assistant\n– Manually configure the assistant to add custom rules for recipe generation,\nObjective—Develop a GPT assistant that can analyze CSV files and provide\n– Design a data science assistant that can load and analyze CSV files, similar to\n– Use the assistant to perform tasks such as data cleaning, visualization, and\nObjective—Extend a GPT assistant with a custom action using a FastAPI service.\n– Configure a new assistant to use this custom action, ensuring it connects cor-\n– Test the assistant by asking it to perform the action and verify the output.\nEngaging GPT assistants\nExercise 4—File Upload Knowledge Assistant\nObjective—Build an assistant with specialized knowledge from uploaded\n– Upload these files to a new GPT assistant, and configure the assistant to act\n– Create a series of prompts to test the assistant’s ability to reference and sum-\n– Evaluate the assistant’s performance, and make any necessary adjustments to\nExercise 5—Publish and Share Your Assistant\nObjective—Publish your GPT assistant to the GPT Store and share it with others.\n– Finalize the configuration and testing of your assistant to ensure it works as\nassistant.\n– Publish the assistant to the GPT Store, and share the link with friends or\n– Gather feedback from users, and refine the assistant based on their input to\nThe OpenAI GPT Assistants platform enables building and deploying AI agents\nuser-uploaded CSV files, enabling assistants to function as data scientists.\ning these services to your assistant.\nKnowledge assistants can handle various tasks, from searching and comparing\nPublishing assistants require careful consideration of resource usage, user expe-\non coding of AutoGen agents to solve tasks using conversations and group chat\nBuilding multi-agent systems using AutoGen \nIntroducing multi-agent systems with AutoGen Studio\nIntroducing multi-agent systems with AutoGen Studio\nAutoGen Studio is a powerful tool that employs multiple agents behind the scenes to\nAutoGen is a conversational multi-agent platform because\nagent acts as a proxy and directs communication to relevant agents to complete tasks.\nAutoGen uses conversable agents, which\nHow AutoGen agents communicate through conversations (Source: AutoGen)\nThe basic pattern in AutoGen uses a UserProxy and one or more assistant\ndirecting an assistant agent enabled to write code to perform the tasks.\nthe assistant completes a task, the proxy agent reviews, evaluates, and provides feed-\nback to the assistant.\nIf you need assistance with\nto the user proxy agent,\nAssistant agent\nthe proxy and the assistant.\nThe user proxy agent and assistant agent communication (Source: AutoGen)",
      "keywords": [
        "GPT",
        "GPT Store",
        "GPT assistants",
        "assistant",
        "Engaging GPT assistants",
        "GPT Assistants platform",
        "GPTs",
        "store",
        "OpenAI GPT Assistants",
        "AutoGen Studio",
        "Consuming GPT assistants",
        "simple GPT assistant",
        "public GPT Store",
        "AutoGen",
        "Expensive GPT assistants"
      ],
      "concepts": [
        "assistant",
        "assistance",
        "agents",
        "tasks",
        "uses",
        "exercises",
        "users",
        "helps",
        "creating",
        "building"
      ],
      "similar_chapters": [
        {
          "book": "AI Agents In Action",
          "chapter": 19,
          "title": "",
          "score": 0.853,
          "base_score": 0.703,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 10,
          "title": "",
          "score": 0.803,
          "base_score": 0.653,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 9,
          "title": "",
          "score": 0.765,
          "base_score": 0.615,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 2,
          "title": "",
          "score": 0.624,
          "base_score": 0.474,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 4,
          "title": "",
          "score": 0.618,
          "base_score": 0.468,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "assistant",
          "gpt",
          "assistants",
          "gpt assistants",
          "autogen"
        ],
        "semantic": [],
        "merged": [
          "assistant",
          "gpt",
          "assistants",
          "gpt assistants",
          "autogen"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.32850124929619534,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:00:43.645688+00:00"
      }
    },
    {
      "chapter_number": 12,
      "title": "Segment 12 (pages 95-102)",
      "start_page": 95,
      "end_page": 102,
      "summary": "Introducing multi-agent systems with AutoGen Studio\nagents to work on.\nwith agents.\nagents and skills, and the Gallery tab is for\nThe proxy agent and assistant\nagent will not work together\nEntering a task for the agents to work on in the AutoGen interface\nThe agent assistant generates code snippets to perform or complete various subtasks\nas the agents work together through the task in the example.\nThe user proxy agent then\nagent to approve the task’s completion.\nIf you encounter any problems with the assistant agent requests, ask the proxy\nFigure 4.4 shows the agent’s completion of the task.\nThe proxy agent will collect any\ngenerated code snippet, images, or other documents and append them to the message.\nﬁnished with this agent session.\nThe output after the agents complete the task\nIntroducing multi-agent systems with AutoGen Studio\nYou can also review the agent conversation by opening the Agent Messages expander.\nIn many cases, if you ask the agent to generate plots or applications, secondary win-\nAmazingly, the agents will perform most tasks nicely and complete them well.\nSometimes, an agent may only go so far to complete a task because it lacks the\nIn the next section, we’ll look at how to add skills to agents.\nwhich agents can extend themselves.\nActions give agents the ability to execute code,\nMany agentic systems employ the practice of allowing agents to code to\nters, it’s better to provide agents with skills/actions/tools to solve problems.\nthe assistant to generate an image with particular content.\nWith AutoGen Studio running, go to the Build tab and click Skills, as shown in\nThen, click the New Skill button to open a code panel where you can\nFrom this tab, you can also configure models, agents, and agent\nUses GPT-4 Vision to inspect and describe the contents of the image.\nother models, agents, and\nIntroducing multi-agent systems with AutoGen Studio\nThe describe_image function uses the OpenAI GPT-4 vision model to describe what\nis in the image.\nThe agents can confirm that the generated image matches the\nAfter the skill is added, it must be added to the specific agent workflow and agent\nFigure 4.6 demonstrates adding the new skill to the primary assistant agent in\nNow that the skill is added to the primary assistant, we can task the agent with cre-\nimage generators notoriously struggle with correct text, we’ll create an exercise task to\nEnter the text shown in listing 4.3 to prompt the agents to create a book image\nthe agent uses the new describe_image function to verify the image.\nPlease create a cover for the book GPT Agents In Action, use the \neverything works correctly, the agents will return with the results shown in figure 4.7.\nRemarkably, the agent coordination completed the task in just a couple of itera-\nintegrate skills that the agents can further adapt to complete some goal.\nsection will show how these powerful agents are implemented in code.\nAgent Workﬂow.\ndescribe_image skill.\nConfiguring the primary_assistant agent with the new skill\nWhile AutoGen Studio is a fantastic tool for understanding multi-agent systems, we\nFortunately, coding multiple agent examples with AutoGen is\nThis next exercise will look at coding a basic multi-agent system that uses a user proxy\nand conversable agent.\nThe agents generate additional\ncode to use the skills as needed.\nThe generated file outputs from the agent work on the image generation task\nNow, we can look at the code for a basic multi-agent chat using the out-of-the-box\n\"agent\", \nThis agent talks \nThis agent proxies ",
      "keywords": [
        "agent",
        "AutoGen Studio",
        "image",
        "code",
        "AutoGen",
        "API",
        "Studio",
        "proxy agent",
        "task",
        "API key",
        "skill",
        "CONFIG",
        "image skill",
        "key",
        "assistant agent"
      ],
      "concepts": [
        "agents",
        "images",
        "coding",
        "skills",
        "uses",
        "listing",
        "message",
        "generated",
        "generate",
        "generators"
      ],
      "similar_chapters": [
        {
          "book": "AI Agents In Action",
          "chapter": 13,
          "title": "",
          "score": 0.811,
          "base_score": 0.661,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 4,
          "title": "",
          "score": 0.791,
          "base_score": 0.641,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 2,
          "title": "",
          "score": 0.721,
          "base_score": 0.571,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 5,
          "title": "",
          "score": 0.707,
          "base_score": 0.557,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 36,
          "title": "",
          "score": 0.7,
          "base_score": 0.55,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "agent",
          "image",
          "agents",
          "skill",
          "autogen"
        ],
        "semantic": [],
        "merged": [
          "agent",
          "image",
          "agents",
          "skill",
          "autogen"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.3777874684716132,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:00:43.645729+00:00"
      }
    },
    {
      "chapter_number": 13,
      "title": "Segment 13 (pages 103-110)",
      "start_page": 103,
      "end_page": 110,
      "summary": "The code in list-\ning 4.6 uses a simple task to demonstrate code writing.\nThese coding tasks are also some of the author’s regular baselines to\nThen it will run the code, and you’ll see the output in the terminal or as a\nfor code execution agents, and if you’re comfortable with containers, this is a good\nEither way, after the proxy generates and runs the code, the working_dir folder\nyou to run the code at your leisure, make changes, or even ask for improvements, as\ning agents.\nEnhancing code output with agent critics\nIn the next exercise, we’ll add another agent critic to our agent system to help\nwith coding tasks.\nOpen autogen_coding_critic.py, as shown in the following listing.\nSimple coding task examples\nautogen_coding_critic.py\nYour task is to scrutinize code content for any harmful or \ndef review_code(recipient, messages, sender, config):     \n\"message\": review_code,\nA second assistant critic agent is \ncode for review by\nmessage=task, \nRun the autogen_coding_critic.py file in VS Code in debug mode, and watch the\ndialog between the agents.\ncode.\nNested chats work well for supporting and controlling agent interactions, but we’ll\nAutoGen can consume many tokens over chat iterations as a conversable multi-agent\nallows your agents to continue conversations if they get interrupted.\nIn code, you can control the cache folder for your agent’s run, as shown in listing 4.9.\nThe proxy agent initiates a \nThe folder code\nAutoGen tasks in the future by just setting the cache_seed for the previous cache.\nmessage=task,\nhow an agent conversation generated the results.\nanother conversational pattern in which AutoGen supports group chat.\nGroup chat with agents and AutoGen\nagents, this is certainly no different, and chatting through nested or sequential con-\nused the nested chat feature in the previous section to build a nested agent chat.\nOpen autogen_coding_group.py with relevant parts, as shown in listing 4.10.\nThe agents and messages are held with the group chat, similar to a messaging\nTo counter this, AutoGen provides a group chat, a mechanism by which agents par-\nThis allows agents to review all past conversations\nGroup chat with agents and AutoGen\ngroupchat = GroupChat(agents=[user_proxy, \nAgents now collaborate\nConversable Agents Nested Chat\nConversable Agents Group Chat\nThe difference between nested and group chat for conversable agents\nagents and stores the \nmessage=task,\nRun this exercise, and you’ll see how the agents collaborate.\nGroup conversations are an excellent way to strengthen your agents’ abilities as\nAutoGen is a powerful multi-agent platform that can be experienced using a web\nWhatever your preference, this agent collaboration tool is an excel-\nlent platform for building code or other complex tasks.\nBuilding an agent crew with CrewAI\nWith CrewAI, you build a crew of agents to focus on specific areas of a task goal.\nUnlike AutoGen, CrewAI doesn’t require the use of the user proxy agent but instead\nassumes the agents only work among themselves.\nIt shows a sequential-processing agent system\nwith generic researcher and writer agents.\nAgents are assigned tasks that may also include\nure 4.10 shows the sequential process by iterating across the given agents and their\nCreating a jokester crew of CrewAI agents\nOpen crewai_introduction.py in VS Code and look at the top section, as shown\nBuilding an agent crew with CrewAI\nexample, we’re using two agents: a senior joke researcher and a joke writer.\nfrom crewai import Agent, Crew, Process, Task\njoke_researcher = Agent(     \ncrewai_introduction.py (agent section)\nTasks\nAgents\nto agents and tasks.\nAgents have a goal\nagents and \nagent to emit output\nmemory for the agents\nThe backstory is the agent’s background—its persona.\njoke_writer = Agent(    \nMoving down the code, we next see the tasks, as shown in listing 4.12.\nagent’s process to complete the primary system goal.\nThey also link an agent to work\nagent=joke_researcher,     \nagent=joke_writer,        \nThe agents can either be delegated to or \nagents and \nagent to emit output\nmemory for the agents\nagent’s background—\nthe agent will complete the task.\nagent \ntask\nthe agent will complete the task.\nIf the agent should execute \nAny output the agent will generate",
      "keywords": [
        "code",
        "agent",
        "task",
        "chat",
        "AutoGen",
        "group chat",
        "config",
        "cache",
        "critic",
        "proxy",
        "message",
        "CrewAI",
        "joke",
        "proxy agent",
        "group"
      ],
      "concepts": [
        "agent",
        "task",
        "code",
        "list",
        "conversations",
        "conversation",
        "cache",
        "caching",
        "messages",
        "messaging"
      ],
      "similar_chapters": [
        {
          "book": "AI Agents In Action",
          "chapter": 12,
          "title": "",
          "score": 0.811,
          "base_score": 0.661,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 14,
          "title": "",
          "score": 0.738,
          "base_score": 0.588,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 21,
          "title": "",
          "score": 0.69,
          "base_score": 0.54,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 15,
          "title": "",
          "score": 0.65,
          "base_score": 0.5,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 2,
          "title": "",
          "score": 0.644,
          "base_score": 0.494,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "agents",
          "agent",
          "group",
          "group chat",
          "nested"
        ],
        "semantic": [],
        "merged": [
          "agents",
          "agent",
          "group",
          "group chat",
          "nested"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.40202219209121065,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:00:43.645771+00:00"
      }
    },
    {
      "chapter_number": 14,
      "title": "Segment 14 (pages 111-118)",
      "start_page": 111,
      "end_page": 118,
      "summary": "Building an agent crew with CrewAI\nincluding the agents, tasks, process type, memory, cache, maximum requests per min-\nagents=[joke_researcher, joke_writer],   \nresult = crew.kickoff(inputs={\"topic\": \"AI engineer jokes\"})\nthis agent system is to craft jokes related to AI engineering.\nnier jokes generated over a few runs of the agent system:\nThis section shows how to add observability to the multi-agent system.\nObserving agents working with AgentOps\nCrewAI supports connecting to a specialized agent operations platform appropri-\ncrewai_introduction.py (crew section)\nThe agents assembled\ninto the crew\nThe tasks the agents\nDefining how the agents \nif agents/tasks have it on\nobservability with any agent platform specific to LLM usage.\nand adding a line of code to your crew setup.\nAgentOps can also be connected to other agent platforms for observability.\npip install crewai[agentops]\nadditions as they are added to the crewai_agentops.py file.\nfrom crewai import Agent, Crew, Process, Task\ncrewai_agentops.py (AgentOps additions)\nBuilding an agent crew with CrewAI\nRun the crewai_agentops.py file in VS Code (F5), and watch the agents work as before.\nHowever, you can now go to the AgentOps dashboard and view the agent interactions\nFigure 4.11 shows the dashboard for running the joke crew to create the best joke.\nand indicative of how verbose agent conversations can become.\nThe AgentOps platform is an excellent addition to any agent platform.\nIn the future, we’ll likely see the spawn of more agent observability patterns.\nAgents can be very powerful, but they can also become very costly,\nThe AgentOps dashboard for running the joke crew\nagents that can code games.\nRevisiting coding agents with CrewAI\nOpen crewai_coding_crew.py in VS Code, and we’ll first review the agent section\nprint(\"## Welcome to the Game Crew\")     \nsenior_engineer_agent = Agent(\nqa_engineer_agent = Agent(\nYou are a software engineer that specializes in checking code\ncrewai_coding_crew.py (agent section)\nRevisiting coding agents with CrewAI\nchief_qa_engineer_agent = Agent(\nScrolling down in the file will display the agent tasks, as shown in listing 4.18.\nAgain, each agent has a\ncode_task = Task(\nYou will write the code for the game using python.\"\"\",\nagent=senior_engineer_agent,\nagent=qa_engineer_agent,\ncrewai_coding_crew.py (task section)\nagent=chief_qa_engineer_agent,\nEach agent and task are added, as well as the verbose and process attributes.\nagents=[senior_engineer_agent, \nqa_engineer_agent, \nchief_qa_engineer_agent],\nWhen you run the VS Code (F5) file, you’ll be prompted to enter the instructions for\nThen, let the agents work, and observe what they produce.\ntional code changes to a new file that uses the coding crew in a hierarchical method.\naddition is adding this class as the crew manger, manager_llm.\ncrewai_coding_crew.py (crew section)\nRevisiting coding agents with CrewAI\nagents=[senior_engineer_agent, \nqa_engineer_agent, \nchief_qa_engineer_agent],\ncrewai_hierarchy.py (crew manager sections)\nCrew\nAgents\nto agents and tasks.\nAgents have a goal\ncrew\na managing agent.\nHierarchical processing of agents coordinated through a crew manager\nObserve the agents work through the code and review it repeatedly for\nAn example of this spiral that often happens when agents continually iterate over\ntion your agent system encounters.\nnumber of agents.\nGenerally, the job role is allocated to an agent role/persona,\nThe repetition of thoughts as they occurred within an agent run\nagent interaction.",
      "keywords": [
        "agent",
        "crew",
        "Code",
        "engineer",
        "CrewAI",
        "task",
        "AgentOps",
        "game",
        "listing",
        "crew manager",
        "API key",
        "agent crew",
        "Quality Control Engineer",
        "system",
        "agent system"
      ],
      "concepts": [
        "agents",
        "task",
        "listing",
        "code",
        "coding",
        "processing",
        "crewai",
        "jokes",
        "observing",
        "observe"
      ],
      "similar_chapters": [
        {
          "book": "AI Agents In Action",
          "chapter": 2,
          "title": "",
          "score": 0.855,
          "base_score": 0.705,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 3,
          "title": "",
          "score": 0.775,
          "base_score": 0.625,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 15,
          "title": "",
          "score": 0.764,
          "base_score": 0.614,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 13,
          "title": "",
          "score": 0.738,
          "base_score": 0.588,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 21,
          "title": "",
          "score": 0.731,
          "base_score": 0.581,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "crew",
          "agent",
          "agents",
          "agentops",
          "crewai"
        ],
        "semantic": [],
        "merged": [
          "crew",
          "agent",
          "agents",
          "agentops",
          "crewai"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.442991563017134,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:00:43.645813+00:00"
      }
    },
    {
      "chapter_number": 15,
      "title": "Segment 15 (pages 119-130)",
      "start_page": 119,
      "end_page": 130,
      "summary": "– Create a simple multi-agent system with a user proxy and two assistant agents.\n– Develop and integrate a new skill into an AutoGen agent that allows it to\n– Ensure the agent can ask for user preferences (e.g., city for weather, type of\n– Use the group chat feature to allow agents to share information, ask ques-\nagents.\nCrewAI supports integrating memory and tools for agents to consume through\nIn this chapter, we explore actions through the use of functions and how agents\nWe’ll start by looking at OpenAI function calling and then\nwhich we’ll use to build and manage skills and functions for agents or as agents.\nsemantic functions\nparameters, which it passes to the new movie recommender.\ninformation to a new prompt request to an LLM.\nCalls the plugin/function\nthe recommender plugin\nPlugin calls LLM to get a recommendation\nrecommended new movie.\nNew Movie Recommender\nplugin (agent)\nThe plugin/agent\nAI agents can be considered plugins and consumers of plugins, tools, skills, and\nother agents.\nAdding skills, functions, and tools to an agent/plugin allows it to exe-\nAn agent action is an ability that allows it to use a function, skill, or tool.\nChatGPT plugins and functions represent an actionable ability that ChatGPT or an\nagent system can use to perform additional actions.\nOpenAI plugins and the function definition.\nrequest for a plugin/agent\nCalls the agent/plugin\nAgent System\nrecommended new movie.\nNew Movie Recommender\nplugin (agent)\nThe plugin/agent scrapes\n3. The agent uses an action\nAn agent may use the\nagent action.\nAn agent action can be a\nfunction or skill/tool prompt.\na recommender plugin\nPlugin calls LLM to get a\nrecommendation for the list of new movies.\nAgent uses a function or\nHow an agent uses actions to perform external tasks\nExecuting OpenAI functions\nExecuting OpenAI functions\ning the interface between functions/plugins an LLM could action.\nThese same function definitions are now also being used to define plugins for\nNext, we’ll explore how to use functions directly with\nAdding functions to LLM API calls\nFigure 5.3 demonstrates how an LLM recognizes and uses the function definition to\ncast its response as the function call.\nListing 5.1 shows the details of an LLM API call using tools and a function definition.\nAdding a function definition allows the LLM to reply regarding the function’s input\nfirst_function.py (API call)\nLLM using tools.\nthe function de nition from the\nUser: please recommend a movie.\n\"type\": \"function\",\n(function) and input parameters\nfor the function\nfunctions added to a request.\nexecute the function.\n\"type\": \"function\",    \n\"function\": {\nfolder: chapter_4/first_function.py.\nFunction calling is an extra capability provided by the LLM com-\nNext, we’ll look at the bottom of the code in first_function.py, as shown in list-\nfirst_function.py (exercising the API)\nNew parameter called tools\nSets the type of tool to function\nthe function does\ndefined function\nExecuting OpenAI functions\nFunction(arguments='{\"topic\":\"time travel movie\"}', \nuser = \"Can you please recommend me a good time travel movie?\"\nFunction(arguments='{\"topic\":\"time travel movie\",\nIn this case, the tool is the single function definition, that is, the rec-\nommended function.\nThe LLM extracts the input parameters from this function and\ngested function and the relevant input parameters.\nact on the function.\nActioning function calls\nNow that we understand that an LLM doesn’t execute the function or plugin directly,\nthat includes a tool function definition, asking for three recommendations.\nin turn, will reply with the three function calls with input parameters (time travel, rec-\nThe results from executing the functions are then passed back to the\nListing 5.3 shows the Python function that you want to call to give recommendations.\nfunction to call \ndefined function\nReturned in the name of the function to \nNext, we’ll look at the function called run_conversation, where all the work starts\nparallel_functions.py (recommend function)\nparallel_functions.py (run_conversation, request)\nLLM using tools.\nTools: recommend function de nition\nReturns 3 tool calls to the function recommend\nCreates 3 function replies, one\nAdd results of function execution to\nExecute functions.\nReturns the function\nA sample request returns three tool function calls and then submits the results back to the LLM \n\"type\": \"function\",\n\"function\": {\nrequired function calls.\nAdds the function \navailable_functions = {\nfunction_name = tool_call.function.name\nfunction_args = json.loads(tool_call.function.arguments)\nfunction_response = function_to_call(\ntopic=function_args.get(\"topic\"),    \n\"name\": function_name,\n\"content\": function_response,\n)  # extend conversation with function response\nThe tool call outputs and the calls to the recommender function results are appended\nparallel_functions.py (run_conversation, tool_calls)\nOnly one function but \nfunction from extracted \neach function call to the ",
      "keywords": [
        "LLM",
        "function",
        "agent",
        "Plugin calls LLM",
        "plugin",
        "functions",
        "tools",
        "request",
        "Calls",
        "LLM API calls",
        "user",
        "LLM API",
        "parameters",
        "movie",
        "calls LLM"
      ],
      "concepts": [
        "functions",
        "agents",
        "tool",
        "tasks",
        "recommendation",
        "recommendations",
        "request",
        "actions",
        "uses",
        "llm"
      ],
      "similar_chapters": [
        {
          "book": "AI Agents In Action",
          "chapter": 2,
          "title": "",
          "score": 0.864,
          "base_score": 0.714,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 4,
          "title": "",
          "score": 0.839,
          "base_score": 0.689,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 36,
          "title": "",
          "score": 0.768,
          "base_score": 0.618,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 3,
          "title": "",
          "score": 0.766,
          "base_score": 0.616,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 14,
          "title": "",
          "score": 0.764,
          "base_score": 0.614,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "function",
          "plugin",
          "calls",
          "functions",
          "llm"
        ],
        "semantic": [],
        "merged": [
          "function",
          "plugin",
          "calls",
          "functions",
          "llm"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.4664127437065005,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:00:43.645855+00:00"
      }
    },
    {
      "chapter_number": 16,
      "title": "Segment 16 (pages 131-138)",
      "start_page": 131,
      "end_page": 138,
      "summary": "Semantic Kernel (SK) is another open source project from Microsoft intended to help\ndefine actions, or what the platform calls semantic plugins, which are wrappers for skills\nand functions.\nFigure 5.5 shows how the SK can be used as a plugin and a consumer of OpenAI\nplugins.\nThe SK relies on the OpenAI plugin definition to define a plugin.\nAn OpenAI plugin definition maps precisely to the function definitions in listing 5.4.\nThis means that SK is the orchestrator of API tool calls, aka plugins.\nthat SK can help organize multiple plugins with a chat interface or an agent.\nThe team at SK originally labeled the functional modules as skills.\nPlugins (Semantic Skills and Native Functions)\nRecommend Plugin\n(semantic function)\nGet Movies Plugin\nHow the Semantic Kernel integrates as a plugin and can also consume plugins\nplugins.\nfore, throughout this chapter, we’ll use skills and plugins to mean the same thing.\nSK is a useful tool for managing multiple plugins (actions for agents) and, as we’ll see\nGetting started with SK semantic functions\nListing 5.8 shows how to install SK from a terminal within VS Code.\nimport semantic_kernel as sk\nInstalling Semantic Kernel \n➥ prompt=\"recommend a movie about \nOne highly recommended time travel movie is \"Back to the Future\" (1985) \nThis example demonstrates how a semantic function can be created with SK\nA semantic function is the equivalent of a prompt template in prompt\nIn this example, we define a simple prompt as a function.\nIt’s important to note that this semantic function isn’t defined as a plugin.\never, the kernel can create the function as a self-contained semantic element that\nSemantic functions can be used alone or regis-\nSemantic functions and context variables\nsemantic function.\ntemplate_format=\"semantic-kernel\",\nrecommend_function = kernel.create_function_from_prompt(    \nfunction_name=\"Recommend_Movies\",\nplugin_name=\"Recommendation\",\nfunction from \nSynergizing semantic and native functions\nrecommend_function,\nthe basis for setting up SK and creating and exercising semantic functions.\nsection, we move on to see how a semantic function can be registered as a skill/plugin.\nSynergizing semantic and native functions\nSemantic functions encapsulate a prompt/profile and execute through interaction with\nBoth semantic and native functions can\nregister as plugins/skills in the SK kernel.\nA function, semantic or native, can be registered as a plugin and used the same\nWhen a function is\nThe next section looks at how a semantic function is created and regis-\nCreating and registering a semantic skill/plugin\nThe VS Code extension for SK provides helpful tools for creating plugins/skills.\nthis section, we’ll use the SK extension to create a plugin/skill and then edit the com-\nAfter that, we’ll register and execute the plugin in the SK.\nFigure 5.6 shows the process for creating a new skill within VS Code using the SK\nYou’ll then be given the option for the skill/plugin folder to place the function.\nfunction call\nfunction \nYou can see the completed skills and functions by opening the skills/plugin folder\nskills/Recommender/Recommend_Movies folder, as shown in figure 5.7.\nis a config.json file, the function description, and the semantic function/prompt in\nListing 5.11 shows the contents of the semantic function definition, also known as\nfunction because this is a semantic function.\nnew semantic skill/plugin.\n3. Name the function.\nThe process of creating a new skill/plugin\nSynergizing semantic and native functions\n\"description\": \"A function to recommend movies based on users list of \nNext, we can look at the definition of the semantic function prompt, as shown in list-\nThis prompt recommends movies based on a list of mov-\n/plugin\nDeﬁnes the function/plugin\nsemantic function\nfunction skill/plugin\nSemantic functions are \nfunction\nNow, we’ll dive into the code that loads the skill/plugin and executes it in a simple\nOpen the SK_first_skill.py file in VS Code.\nrecommender = kernel.import_plugin_from_prompt_directory(\ngenre, I would recommend the following movie that you have not watched \nthe plugins folder\nFunction is executed ",
      "keywords": [
        "semantic function",
        "function",
        "Semantic",
        "plugin",
        "Semantic Kernel",
        "prompt",
        "Functions",
        "Recommend",
        "Kernel",
        "Native Functions",
        "code",
        "Movies",
        "Introducing Semantic Kernel",
        "skill",
        "service"
      ],
      "concepts": [
        "functions",
        "functional",
        "kernel",
        "listing",
        "semantic",
        "recommend",
        "skills",
        "folder",
        "movies",
        "prompt"
      ],
      "similar_chapters": [
        {
          "book": "AI Agents In Action",
          "chapter": 15,
          "title": "",
          "score": 0.764,
          "base_score": 0.614,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 17,
          "title": "",
          "score": 0.72,
          "base_score": 0.57,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 2,
          "title": "",
          "score": 0.669,
          "base_score": 0.519,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 38,
          "title": "",
          "score": 0.658,
          "base_score": 0.508,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 14,
          "title": "",
          "score": 0.594,
          "base_score": 0.444,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "semantic",
          "plugin",
          "function",
          "sk",
          "semantic function"
        ],
        "semantic": [],
        "merged": [
          "semantic",
          "plugin",
          "function",
          "sk",
          "semantic function"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.3539603575988769,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:00:43.645896+00:00"
      }
    },
    {
      "chapter_number": 17,
      "title": "Segment 17 (pages 139-146)",
      "start_page": 139,
      "end_page": 146,
      "summary": "Synergizing semantic and native functions\nsimple semantic function that can be hosted as a plugin.\nHowever, this function\nAs stated, native functions are code that can do anything.\nwe’ll introduce a native function to assist the semantic function we built earlier.\nThis native function will load a list of movies the user has previously seen, from a file.\nNative functions can be created and registered using the SK extension.\nple, we’ll create a native function directly in code to make the example easier to follow.\nOpen SK_native_functions.py in VS Code.\nnative function is defined.\n@kernel_function(    \ndescription=\"Loads a list of movies … user has already seen\",\nSK_native_functions.py (MySeenMovieDatabase)\nreturns a list of movies in a \nmovies from\nseen_movies_plugin = kernel.import_plugin_from_object(\nreturn seen_movie_list\nprint(seen_movie_list)\nOne important aspect to note is how the native function was imported into the kernel.\nThe act of importing to the kernel registers that function as a plugin/skill.\nWe’ll see how to embed a native function within a semantic function in\nSK_native_functions (remaining code)\nLoads the semantic function \nregisters the function \nfunction\nfunction and returns \nfunction and \nSynergizing semantic and native functions\nEmbedding native functions within semantic functions\nity to embed native or semantic functions within other semantic functions.\ning listing shows how a native function can be embedded within a semantic function.\nThe next example, SK_semantic_native_functions.py, uses inline native and seman-\ncreate, register, and execute the functions.\nrecommend_function = kernel.create_function_from_prompt(\nfunction_name=\"Recommend_Movies\",\nrecommend_function,\nSK_semantic_native_functions.py (skprompt)\nSK_semantic_native_functions.py (abridged)\nby class name and function name.\nfunction from the prompt\nfunction asynchronously\nnote is that the native function is registered with the kernel, but the semantic function\nkernel, which uses the import_plugin function call—the first line in listing 5.17.\never, the semantic function itself isn’t registered.\nadding a plugin representing a service or GPT interface to a chat function.\nnative functions.\nchapter, implement it as plugins into a chat function.\nA semantic service layer is a GPT interface that exposes functions through natural\nFigure 5.9 shows the structure of the new plugin called Movies and the semantic\nFor native functions, the parent folder’s name (Movies) is\nThis file contains a class called TMDbService, which exposes several functions\nThis will expose the functions as plugins for a chat\nfrom semantic_kernel.functions import kernel_funct\ndef print_function_call():    \nand set of native functions\nthe functions for \n@kernel_function(    \nname=\"get_movie_genre_id\",\nprint_function_call()\nendpoint = f\"{base_url}/genre/movie/list\nThen, each function was wrapped\nwith the sk_function decorator to expose it semantically.\nanother example of a function exposed to the semantic service layer.\nThis function\n@kernel_function(    \nname=\"get_top_movies_by_genre\",\nprint_function_call()\ntmdb.py (get_top_movies_by_genre)\nFunction wrapped in \nDecorates the function \nthe full service, we’ll test each of the functions in the next section.\ntion tests for each semantic service function.\nfrom plugins.Movies.tmdb import TMDbService\ntmdb_service = kernel.import_plugin_from_object \nawait tmdb_service[\"get_movie_genre_id\"](\nawait tmdb_service[\"get_top_movies_by_genre\"](\nto functions, \nfunctions\nto functions, \nfunctions\nprint(await tmdb_service[\"get_movie_genres\"](\n# Run the main function\nFunction name: get_top_tv_shows_by_genre    \nFunction name: get_tv_show_genre_id    \nWith the TMDB functions exposed semantically, we can move on to integrating them\nof code that creates the functions, as shown in listing 5.21.\nThe functions created here\nare now exposed as plugins, except we filter out the chat function, which we don’t\nto functions, \nExecutes and tests the various functions\nthe various functions\nthe function is",
      "keywords": [
        "function",
        "functions",
        "native function",
        "genre",
        "movies",
        "semantic",
        "native",
        "API",
        "GPT interface",
        "semantic function",
        "TMDB",
        "kernel",
        "plugin",
        "service",
        "TMDB API"
      ],
      "concepts": [
        "function",
        "movies",
        "kernel",
        "listing",
        "genre",
        "semantic",
        "api",
        "file",
        "tmdb",
        "important"
      ],
      "similar_chapters": [
        {
          "book": "AI Agents In Action",
          "chapter": 16,
          "title": "",
          "score": 0.72,
          "base_score": 0.57,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 18,
          "title": "",
          "score": 0.698,
          "base_score": 0.548,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 15,
          "title": "",
          "score": 0.569,
          "base_score": 0.419,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 23,
          "title": "",
          "score": 0.522,
          "base_score": 0.372,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 13,
          "title": "",
          "score": 0.51,
          "base_score": 0.36,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "function",
          "functions",
          "native",
          "semantic",
          "native function"
        ],
        "semantic": [],
        "merged": [
          "function",
          "functions",
          "native",
          "semantic",
          "native function"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.2380660236427951,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:00:43.645932+00:00"
      }
    },
    {
      "chapter_number": 18,
      "title": "Segment 18 (pages 147-158)",
      "start_page": 147,
      "end_page": 158,
      "summary": "Semantic Kernel as an interactive service agent\nchat_function = kernel.create_function_from_prompt(\nfunction_name=\"Chat\",\nNext, we can continue by scrolling in the same file to review the chat function, as\nSK_service_chat.py (function setup)\nSK_service_chat.py (chat function)\nCreates the chat function\nchat_function_name=\"Chat\",\nthe code that calls the chat function in a loop.\n\\n  Ask to get a list of currently playing movies by genre.\"\nwhile chatting:    \nThis output shows how a request to list movies from two genres made the chat inter-\nface make multiple calls to the get_top_movie_by_genre function.\nSK_service_chat.py (main function)\nSK_service_chat.py (example conversation) \nthe chat.\nfunction to call \nthe function and \nchat function \nAsk to get a list of currently playing movies by genre.\nUser:> Input: can you give me list of the current top playing movies for \nFunction name: get_top_movies_by_genre    \nFunction name: get_movie_genre_id    \nFunction name: get_top_movies_by_genre    \nFunction name: get_movie_genre_id    \nAgent:> Here are the current top-playing movies \nFor example, try asking for a list of genres for movies or television\nAs it is, the functions return the titles of the top movies and television\nget_top_movies_by_genre function.\nNow open SK_service_chat.py in VS Code, and comment and uncomment the line\nRerun the SK_service_chat.py file in VS Code, and alter your query slightly, as\nUser:> get a list of currently playing movies for the \naction genre and only return movies about space    \nAgent:> To find currently playing action movies that are specifically \nSK_service_chat.py (modifying imports)\nSK_service_chat.py (TMDb_v2 service output)\nBecause the semantic service functions now return the complete movie listing in\nbuilding autonomous agents using behavior trees.\nObjective—Familiarize yourself with creating a simple plugin for the OpenAI chat\n– Create a plugin for the OpenAI chat completions API that fetches weather\n– Create a semantic function that uses a native function to enhance its capabilities.\n– For example, develop a semantic function that generates a meal plan and\n– Use SK to wrap a news API and expose it as a semantic service plugin in a\nchat agent.\nstanding how these functions allow the LLM to perform additional actions.\nused to build AI applications and agent systems.\ntic plugins in defining native and semantic functions.\nNative functions encapsulate code that performs or executes an action using an\nservice layer and expose them as chat or agent interface plugins.\nthe practical implementation of these concepts in creating efficient AI agents.\ncan look at how behavior trees can guide agentic systems.\ning the basics of behavior trees and how they control robotics and AI in games.\nWe’ll return to agentic actions and examine how actions can be implemented\nFrom there, we’ll look at how to build an autonomous agentic behavior tree (ABT)\ntrols and guardrails on autonomous agents and using control barrier functions.\nAutonomous control of agentic behavior trees\nvia agentic behavior trees\nUsing back chaining to create behavior trees \nto monitor our autonomous behavior-driven agentic systems.\nintroduces behavior trees.\nIntroducing behavior trees\nBehavior trees are a long-established pattern used to control robotics and AI in games.\nexpanded on using the tree and node structure we have today.\nacted with advanced robotic systems, you’ve witnessed behavior trees at work.\nshows a simple behavior tree.\nThe tree represents all the primary nodes: selector or\nfallback nodes, sequence nodes, action nodes, and condition nodes.\nTable 6.1 describes the functions and purpose of the primary nodes we’ll explore in\nThe primary nodes used in behavior trees\nNode\nFunction\nlast successful node that executed.\nreturn success; if no nodes suc-\nA simple behavior tree of eating an apple or a pear\nIntroducing behavior trees\nThe primary nodes in table 6.1 can provide enough functionality to handle numerous\nHowever, understanding behavior trees initially can be daunting.\nsome simple trees, we want to look at execution in more detail in the next section.\nUnderstanding behavior tree execution\nUnderstanding how behavior trees execute is crucial to designing and implementing\nbehavior trees.\nUnlike most concepts in computer science, behavior trees operate in\nWhen a node in a behavior tree executes, it will return\neither success or failure; this even applies to conditions and selector nodes.\nBehavior trees execute from top to bottom and left to right.\nthe tree controls has an apple but no pear.\nIn the first sequence node, a condition\nnode, another sequence, that checks if the AI has a pear, and because it does, the\nThis node executes all of its children \nin sequence until one node fails or \nBehavior trees don’t use Boolean \nThe node returns success or failure \nThe node executes and returns suc-\nThe node controls execution of \nthe child nodes.\nbehaviors.\nThe node executes all of its child \nThe primary nodes used in behavior trees (continued)\nNode\nFunction\nBehavior trees provide control over how an AI system will execute at a macro or micro\nRegarding robotics, behavior trees will typically be designed to operate at the\nConversely, behavior trees can also control more macro systems, such as NPCs\nFor agentic systems, behavior trees support controlling an agent or assistant at\nWe’ll explore controlling agents at the task and, in later chapters,\nbehavior tree.\nbehavior trees.\nDeciding on behavior trees\ntrolling agentic systems.\nThey can demonstrate the benefits of behavior trees and pro-\nThe behavior tree is an excellent pattern, but\npossible application to agentic AI control.\nSequence nodes execute\na node fails, the sequence\nNode success/failure\nSelector nodes execute\nThe execution process of a simple behavior tree\nIntroducing behavior trees\nControl agentic AI?\nwith behavior trees.\ntree.\nBehavioral \ninto behavior trees or into \nagentic systems.\nAgentic systems can \noptimize behavior trees.\nb Exists in behavior trees or can easily be incorporated\ntrees as the base.\nments, they lack the scalability of behavior trees.\nBehavior trees can provide several benefits as an AI control system, including scal-\nThe following list highlights other notable benefits of using behavior trees:\nNodes in a\nbehavior tree can be easily reused across different parts of the tree or even in\nScalability—As systems grow in complexity, behavior trees handle the addition\ntrees allow for the hierarchical organization of tasks, making it easier to manage\nnodes (actions, conditions, decorators) can be added without drastically alter-\nTools that support behavior trees often\nHaving made a strong case for behavior trees, we should now consider how to imple-\nRunning behavior trees with Python and py_trees\nBecause behavior trees have been around for so long and have been incorporated into\ntree.",
      "keywords": [
        "behavior trees",
        "behavior",
        "trees",
        "function",
        "chat",
        "node",
        "simple behavior tree",
        "Semantic",
        "functions",
        "chat function",
        "semantic functions",
        "systems",
        "genre",
        "movies",
        "service"
      ],
      "concepts": [
        "behavior",
        "behavioral",
        "trees",
        "function",
        "functions",
        "functionality",
        "node",
        "agents",
        "chat",
        "chatting"
      ],
      "similar_chapters": [
        {
          "book": "AI Agents In Action",
          "chapter": 17,
          "title": "",
          "score": 0.698,
          "base_score": 0.548,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 15,
          "title": "",
          "score": 0.611,
          "base_score": 0.461,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 22,
          "title": "",
          "score": 0.589,
          "base_score": 0.439,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 16,
          "title": "",
          "score": 0.588,
          "base_score": 0.438,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 23,
          "title": "",
          "score": 0.575,
          "base_score": 0.425,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "trees",
          "behavior",
          "behavior trees",
          "nodes",
          "node"
        ],
        "semantic": [],
        "merged": [
          "trees",
          "behavior",
          "behavior trees",
          "nodes",
          "node"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.30510318316594204,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:00:43.645971+00:00"
      }
    },
    {
      "chapter_number": 19,
      "title": "Segment 19 (pages 159-166)",
      "start_page": 159,
      "end_page": 166,
      "summary": "code as is or alter what the conditions return and then run the tree again.\nworking with agents/assistants.\nwith OpenAI Assistants.\nAssistants.\nExploring the GPT Assistants Playground\nOne such project, the GPT Assistants\nPlayground, is built using Gradio for the interface that mimics the OpenAI Assistants\nInside the project, the Python code uses the OpenAI Assistants API to create a chat inter-\ncollection of actions assistants you can use, and you can easily add your own actions.\nInstalling the GPT Assistants Playground\nRunning the GPT Assistants Playground\nExploring the GPT Assistants Playground\nan assistant\nOpenAI defines a GPT as the assistant you can run and use within the ChatGPT inter-\nAn assistant can only be consumed through the API and requires custom code\nWhen you run an assistant, you’re charged according to the model\nSelect an existing Assistant\nor create a new assistant.\nThe assistant\nThe GPT Assistants Playground interface being used to learn math\nActions and tools are the building blocks that empower agents and assistants.\nThe Playground provides several custom actions that can be attached to assistants\nassistant.\nactions, scroll to the bottom, and click Add Assistant to add the assistant.\nAssistants\nAfter you create the assistant, you can ask it to list all available assistants.\nAdding your custom actions is as simple as adding code to a file and dropping it in\nOpen the playground/assistant_actions folder from the main\nfile_actions.py file in VS Code, as shown in listing 6.4.\nfunctionality you want to an assistant.\nExploring the GPT Assistants Playground\nOUTPUT_FOLDER = \"assistant_outputs\"\nplayground/assistant_actions/file_actions.py\nName your assistant\nAsk to list the assistants, and you’ll\nsee all the assistants you've created.\nSelect call_assistant\nand list_assistants.\nThe call_assistant action allows\nto other assistants.\nthe assistant uses to \nYou can add any custom action you want by placing the file in the assistant_actions\nwe’ll look at a special custom action that allows the assistant to run code locally.\nInstalling the assistants database\nTo run several of the examples in this chapter, you’ll need to install the assistants data-\nThe upcoming instructions detail the process for installing the assistants and\nGive the assistant the create_manager_assistant action (found under the\nSelect the new Manager Assistant.\nThis assistant has the instructions and actions\nTalk to the Manager Assistant to give you a list of assistants to install, or just ask\nGetting an assistant to run code locally\nGetting agents and assistants to generate and run executable code has a lot of power.\nIn the Playground, it’s a simple matter to select the custom action run_code, as\nExploring the GPT Assistants Playground\nYou can now ask an assistant to generate and run the code to be sure it works on your\nTry this out by adding the custom actions and asking the assistant to generate\nand run code, as shown in figure 6.6.\nAgain, the Python code running in the Playground creates a new virtual environ-\nAdding actions to run code or other tasks can make assistants feel like a black box.\nassistant is doing behind the scenes.\nSelect both the run_code and\nSelecting custom actions for the assistant to run Python code\nPlayground, capturing action and tool use when an assistant calls another assistant.\nWe can try this by asking an assistant to use a tool and then open the log.\nexample of how you can do this is by giving an assistant the Code Interpreter tool and\nUsually, when the Assistant Code Interpreter tool is enabled, you don’t see any\nAny assistant can generate code.\nGetting the assistant to generate and run Python code",
      "keywords": [
        "GPT Assistants Playground",
        "Assistant",
        "Assistants Playground",
        "GPT Assistants",
        "code",
        "Playground",
        "actions",
        "OpenAI Assistants API",
        "Code Interpreter",
        "DEBUG",
        "manager assistant",
        "Assistant Code Interpreter",
        "Assistants API",
        "Eat apple",
        "custom actions"
      ],
      "concepts": [
        "assistants",
        "code",
        "action",
        "playground",
        "running",
        "run",
        "runs",
        "listing",
        "installing",
        "tick"
      ],
      "similar_chapters": [
        {
          "book": "AI Agents In Action",
          "chapter": 10,
          "title": "",
          "score": 0.879,
          "base_score": 0.729,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 11,
          "title": "",
          "score": 0.853,
          "base_score": 0.703,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 21,
          "title": "",
          "score": 0.81,
          "base_score": 0.66,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 20,
          "title": "",
          "score": 0.807,
          "base_score": 0.657,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 9,
          "title": "",
          "score": 0.798,
          "base_score": 0.648,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "assistants",
          "assistant",
          "playground",
          "assistants playground",
          "code"
        ],
        "semantic": [],
        "merged": [
          "assistants",
          "assistant",
          "playground",
          "assistants playground",
          "code"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.44377238930819457,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:00:43.646011+00:00"
      }
    },
    {
      "chapter_number": 20,
      "title": "Segment 20 (pages 167-176)",
      "start_page": 167,
      "end_page": 176,
      "summary": "Agentic behavior trees (ABTs) implement behavior trees on assistant and agent sys-\nten in Python but will require the setup and configuration of various assistants.\nManaging assistants with assistants\nFortunately, the Playground can help us quickly manage and create the assistants.\nWe’ll first install the Manager Assistant, followed by installing the predefined assis-\nlet’s get started with installing the Manager Assistant using the following steps:\nBuilding autonomous assistants\nOpen Playground in your browser, and create a new simple assistant or use an\nexisting assistant.\nIf you need a new assistant, create it and then select it.\nWith the assistant selected, open the Actions accordion, and select the create_\nmanager_assistant action.\nthe assistant automatically.\nconfirm that the Manager Assistant is now available.\nSelect the Manager Assistant.\nIf you’ve modified the Manager Assistant, you can\nAsk the Manager Assistant what assistants can be installed by typing the follow-\nPlease list all the installable assistants.\nIdentify which assistant you want installed when you ask the Manager Assistant\nPlease install the Python Coding Assistant.\nYou can manage and install any available assistants using the Playground.\nask the Manager Assistant to save the definitions of all your assistants as JSON:\nPlease save all the assistants as JSON to a file called assistants.json.\nThe Manager Assistant can access all actions, which should be considered unique and\ninstall the required assistants.\nAlternatively, you can ask the Manager Assistant to\ninstall all available assistants.\nEither way, we look at creating an ABT with assistants in\nBuilding a coding challenge ABT\nCoding challenges provide a good baseline for testing and evaluating agent and assis-\nBuilding autonomous assistants\nassistant for the actions and conditions.\nFor the first step, the Python coding assistant\n(called the Hacker) generates a solution that is then reviewed by the coding challenge\nent Python coding assistant (called the Verifier).\nAssistants use mes-\nsage threads, similar to a Slack or Discord channel, where all assistants conversing on\nof the action/condition nodes with the assistants and gives them the instructions.\nAssistants use threads to\nThe ABT for the coding challenge\nBuilding autonomous assistants\nhacker = create_assistant_action_on_thread(   \nassistant_name=\"Python Coding Assistant\",\nassistant_instructions=textwrap.dedent(f\"\"\"\njudge = create_assistant_action_on_thread(    \naction_name=\"Judge solution\",\nassistant_name=\"Coding Challenge Judge\",\nassistant_instructions=textwrap.dedent(\nThen confirm is a solution to the challenge \nRun the code for the solution and confirm it passes all the test cases.\nIf the solution passes all tests save the solution to a file called \nverifier = create_assistant_condition(    \nassistant_name=\"Python Coding Assistant\",\nassistant_instructions=textwrap.dedent(\nLoad the file called judged_solution.py and \nagentic_btree_coding_challenge.py\n### Required assistants – \n### Python Coding Assistant and Coding Challenge Judge \n### install these assistants through the Playground\nput in the terminal, and watch how the assistants work through each step in the tree.\nfunctions create_assistant_condition and create_assistant_action_on_thread.\nthe OpenAI Assistants code wrapped in the Playground.\nHaving your assistants/agents pass files around\ncoding challenges and perhaps even to work as a coding ABT.\nBuilding autonomous assistants\nPosting YouTube videos to X\nReview the summarized transcripts and select a video to write an X (formerly\nReview the post and then post it on X.\nFigure 6.9 shows the ABT assembled with each of the different assistants.\ncise, we use a sequence node for the root, and each assistant performs a different\nThis isolates each assistant’s interaction into a concise conversation that’s\nThis assistant searches\nThe assistant loads the\nThe assistant loads the\nAssistants always use\nPost to X\nIf you plan to run the code in this exercise, you must add your X credentials to the\nstep, posting, will fail, but you can still look at the file (youtube_twitter_post.txt)\nListing 6.9 shows just the code for creating the assistant actions.\ndifferent assistants, each with its own task instructions.\nNote that each assistant has a\nassistant by using the Playground.\nsearch_youtube_action = create_assistant_action(\nassistant_name=\"YouTube Researcher v2\",\nassistant_instructions=f\"\"\"\nwrite_post_action = create_assistant_action(\nassistant_name=\"Twitter Post Writer\",\nassistant_instructions=\"\"\"\nThe assistants have been configured to try to\nBuilding autonomous assistants\nand save it to a file called youtube_twitter_post.txt.\npost_action = create_assistant_action(\nassistant_instructions=\"\"\"\nLoad the file called youtube_twitter_post.txt and post the content \n### Required assistants – YouTube Researcher v2, Twitter Post Writer, \nin the assistants_output folder.",
      "keywords": [
        "assistant",
        "Manager Assistant",
        "Python Coding Assistant",
        "Coding Assistant",
        "ABT",
        "challenge",
        "post",
        "Manager",
        "thread",
        "Coding",
        "Python Coding",
        "coding challenge",
        "solution",
        "Judge",
        "action"
      ],
      "concepts": [
        "assistant",
        "challenge",
        "thread",
        "code",
        "coding",
        "agent",
        "solution",
        "solutions",
        "list",
        "tree"
      ],
      "similar_chapters": [
        {
          "book": "AI Agents In Action",
          "chapter": 21,
          "title": "",
          "score": 0.845,
          "base_score": 0.695,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 19,
          "title": "",
          "score": 0.807,
          "base_score": 0.657,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 2,
          "title": "",
          "score": 0.738,
          "base_score": 0.588,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 38,
          "title": "",
          "score": 0.697,
          "base_score": 0.547,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 14,
          "title": "",
          "score": 0.682,
          "base_score": 0.532,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "assistants",
          "assistant",
          "coding",
          "manager assistant",
          "manager"
        ],
        "semantic": [],
        "merged": [
          "assistants",
          "assistant",
          "coding",
          "manager assistant",
          "manager"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.39128409582440266,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:00:43.646052+00:00"
      }
    },
    {
      "chapter_number": 21,
      "title": "Segment 21 (pages 177-187)",
      "start_page": 177,
      "end_page": 187,
      "summary": "Driving agents with ABTs that silo assis-\nconversation across agents/assistants.\nFortunately, the Playground provides methods to silo or join assistants to conversation\nFor the next exercise, we’ll employ two assistants in an ABT\ncode with the respective assistants.\nSiloed assistants\nAgent/Assistant\nAgent/Assistant\nConversational assistants\nAgent/Assistant\nThe various layouts of siloed and conversational assistants\nBuilding autonomous assistants\ndebug_code = create_assistant_action_on_thread(    \nverify = create_assistant_condition_on_thread(    \nassistant_name=\"Python Coding Assistant\",\nThree nodes comprise the tree: the root sequence, the debug code action, and the\nBecause the tree’s root is a sequence, the two assistants will con-\nBoth assistants\nopen the assistants_output/fixed_bug.py file and verify the results are all good.\ning your own ABTs. Creates a message thread for the \nassistants to share and converse over\ncode action with a \nWill the assistants be siloed or converse over threads, or is a combi-\nStart by building the behavior tree from the goal behavior, add-\ninteresting and perhaps meta goal is to build an ABT that helps build assistants.\n– Create an assistant.\n– Verify the assistant.\n– Test the assistant.\n– Name the assistant.\n– Give the assistant the relevant instructions.\n– Verify the assistant.\nBuilding autonomous assistants\n– (action) Give the assistant relevant instructions to help a user with a given task.\n– (action) Name the assistant.\n– (action) Test the assistant.\n– (condition) Verify the assistant.\n– (action) Create the assistant.\n│    ├── Action: Give the assistant relevant instructions to help a user \n│    ├── Action: Name the assistant\n│    ├── Action: Test the assistant\n│    ├── Condition: Verify the assistant\n│    └── Action: Create the assistant\nFrom this point, we can start building the tree by iterating over each action and condi-\ntion node and determining what instructions the assistant needs.\nIdeally, we want to create as few assistants\nAfter determining the assistant, tools, and actions for each assistant and for which\ncombine actions and reduce the number of assistants.\nwith different assistants.\nObjective—Build an agentic behavior tree (ABT) to plan a travel itinerary using\nassistants.\n– Set up the GPT Assistants Playground on your local machine.\nABT for building an assistant\n– Create an ABT to plan a travel itinerary.\n– Action: Use the Travel assistant to gather information about potential des-\n– Action: Use the Itinerary Planner to create a day-by-day travel plan.\nanother Travel Assistant.\n– Implement and run the ABT to create a complete travel itinerary.\nassistants.\n– Set up the GPT Assistants Playground on your local machine.\n– Create an ABT with the following structure:\n– Action: Use the Customer Query Analyzer assistant to categorize customer\n– Action: Use the Response Generator assistant to draft responses based on\n– Action: Use the Customer Support assistant to send the responses to\n– Set up the GPT Assistants Playground on your local machine.\n– Action: Use the Inventory Checker assistant to review current stock levels.\n– Action: Use the Order assistant to place orders for low-stock items.\nassistants.\n– Set up the GPT Assistants Playground on your local machine.\n– Create an ABT to develop a personalized fitness plan:\n– Action: Use the Fitness Assessment assistant to evaluate the user’s current\nBuilding autonomous assistants\n– Action: Use the Training Plan Generator to create a custom fitness plan\nassistant.\n– Set up the GPT Assistants Playground on your local machine.\n– Define the following goal: “Create an assistant that can provide financial\n– Using back chaining, determine the actions and conditions needed to\ncutes nodes in sequence, condition tests the state, action does the work, decora-\nThe GPT Assistants Playground allows for creating and managing custom actions,\nwhich is essential for building versatile assistants.\nABTs control agents and assistants by using prompts to direct actions and condi-\ntions for assistants.\ntional assistants to use structured processes and emergent behaviors.\nAfter we explored some basic concepts about agents and looked at using actions\nDeveloping the base Nexus agent\nDeveloping, testing, and engaging agent actions \nIntroducing Nexus, not just another agent platform\nIntroducing Nexus, not just another agent platform\nbuilt and introduce two primary agent components: profiles/personas and actions/tools.\nto configure an agent to use a specific API/model, the persona, and possible actions.\nThe tools/actions the agent\nAs we progress through this book, Nexus will be added to support new agent features.\nassistance creating one, refer to appendix B.\nthe command line or create a new .env file and add the setting.\nIntroducing Nexus, not just another agent platform\nLogging in or creating a new Nexus user",
      "keywords": [
        "GPT Assistants Playground",
        "Assistant",
        "ABT",
        "Nexus",
        "Assistants Playground",
        "action",
        "GPT Assistants",
        "create",
        "API Key",
        "Agent",
        "API",
        "thread",
        "ABTs",
        "OpenAI API Key",
        "key"
      ],
      "concepts": [
        "assistants",
        "assistance",
        "action",
        "agents",
        "nexus",
        "threads",
        "condition",
        "conditions",
        "tree",
        "behaviors"
      ],
      "similar_chapters": [
        {
          "book": "AI Agents In Action",
          "chapter": 20,
          "title": "",
          "score": 0.845,
          "base_score": 0.695,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 19,
          "title": "",
          "score": 0.81,
          "base_score": 0.66,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 38,
          "title": "",
          "score": 0.74,
          "base_score": 0.59,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 2,
          "title": "",
          "score": 0.732,
          "base_score": 0.582,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 14,
          "title": "",
          "score": 0.731,
          "base_score": 0.581,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "assistants",
          "assistant",
          "action",
          "action use",
          "abt"
        ],
        "semantic": [],
        "merged": [
          "assistants",
          "assistant",
          "action",
          "action use",
          "abt"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.42600098968942707,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:00:43.646093+00:00"
      }
    },
    {
      "chapter_number": 22,
      "title": "Segment 22 (pages 188-196)",
      "start_page": 188,
      "end_page": 196,
      "summary": "Figure 7.3 shows the Login or Create New User screen.\nThis application uses cookies to remember the user, so you\nmanages the database, agent manager, action manager, and profile managers.\nThis agent platform is written entirely in Python, and the web interface uses Stream-\nIn the next section, we look at how to build an OpenAI LLM chat application.\nIntroducing Streamlit for chat application development\nIntroducing Streamlit for chat application \nBuilding a Streamlit chat application\nAgents, action functions, and proﬁles are all dynamically\nAgent Manager\nAgent classes\nWe’ll start by opening the chatgpt_clone_response.py file in VS Code.\nThis code uses the Streamlit state to load\nif \"openai_model\" not in st.session_state:\nst.session_state[\"openai_model\"] \nif \"messages\" not in st.session_state:\nst.session_state[\"messages\"] = []  \nfor message in st.session_state[\"messages\"]:     \nwith st.chat_message(message[\"role\"]):\nst.markdown(message[\"content\"])\nall interface components when the web page refreshes or a user selects an action.\nif prompt := st.chat_input(\"What do you need?\"):    \nst.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\nwith st.chat_message(\"user\"):    \nthe message state; if none, \nSets the chat message \nIntroducing Streamlit for chat application development\nwith st.chat_message(\"assistant\"):\nresponse = client.chat.completions.create(\nmodel=st.session_state[\"openai_model\"],\nfor m in st.session_state.messages\nst.session_state.messages.append(\nthe st.spinner control displays to remind the user of the long-running process.\nStreamlit apps are run using the module, and to debug applications, you need to\nAfter you have the launch.json file configuration set, save it, and open the chatgpt_\nclone_response.py file in VS Code.\nmessage response \nto the message state\nFigure 7.5 shows the app running and waiting to return a response.\nCreating a streaming chat application\nAdding support for streaming to any application UI is generally not a trivial task,\nOpen chapter_7/chatgpt_clone_streaming.py in VS Code.\nUsing the st.write_stream control allows the UI\nIntroducing Streamlit for chat application development\nwith st.chat_message(\"assistant\"):\nstream = client.chat.completions.create(\nmodel=st.session_state[\"openai_model\"],\nfor m in st.session_state.messages\nresponse = st.write_stream(stream)    \nst.session_state.messages.append(\nyou’ll see that the response is streamed to the window in real time, as shown in figure 7.6.\nAdds the response to the message state\nThe updated interface with streaming of the text response\nNexus uses a Streamlit interface because it’s easy to use and\nDeveloping profiles and personas for agents\nNexus uses agent profiles to describe an agent’s functions and capabilities.\nFor now, as of this writing, Nexus only supports the persona and actions section of the\nAdd any agent profiles to Nexus by copying an agent YAML profile file into the Nexus/\nThe nexus_profiles folder\nThe Agent Proﬁle\nAgent Tools\nSet of tools an agent can\nAgent Evaluation and Reasoning\nAgent Memory and Knowledge\nAgent Planning and Feedback\nThe agent profile as it’s mapped to the YAML file definition\nDeveloping profiles and personas for agents\nWe can easily define a new agent profile by creating a new YAML file in the nexus_\ncode folder and install Nexus in developer mode (see listing 7.7).\nfiona.yaml file in the Nexus/nexus/nexus_base/nexus_profiles folder.\nAfter saving the file, you can start Nexus from the command line or run it in debug\n\"args\": [\"run\", \" Nexus/nexus/streamlit_ui.py\"]     \nAt this point, the profile is responsible for defining the agent’s system prompt.\nThe profile and persona are the base definitions for how the agent interacts with\nPowering the profile requires an agent engine.\nagent can use\nAgent engines power agents within Nexus.\nBy providing a base agent abstraction, Nexus should be able to support\nCurrently, Nexus only implements an OpenAI API–powered agent.\nhow the base agent is defined by opening the agent_manager.py file from the Nexus/\nWhen creating a new agent\nagent proﬁle.",
      "keywords": [
        "agent",
        "Nexus",
        "Streamlit",
        "chat",
        "message",
        "User",
        "application",
        "state",
        "chat application",
        "Code",
        "file",
        "response",
        "interface",
        "agent platform",
        "listing"
      ],
      "concepts": [
        "agent",
        "nexus",
        "stream",
        "listing",
        "chat",
        "chatting",
        "messages",
        "application",
        "applications",
        "figuration"
      ],
      "similar_chapters": [
        {
          "book": "AI Agents In Action",
          "chapter": 6,
          "title": "",
          "score": 0.755,
          "base_score": 0.605,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 23,
          "title": "",
          "score": 0.724,
          "base_score": 0.574,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 14,
          "title": "",
          "score": 0.66,
          "base_score": 0.51,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 15,
          "title": "",
          "score": 0.639,
          "base_score": 0.489,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 27,
          "title": "",
          "score": 0.623,
          "base_score": 0.473,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "st",
          "session_state",
          "st session_state",
          "nexus",
          "agent"
        ],
        "semantic": [],
        "merged": [
          "st",
          "session_state",
          "st session_state",
          "nexus",
          "agent"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.3702903172875461,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:00:43.646135+00:00"
      }
    },
    {
      "chapter_number": 23,
      "title": "Segment 23 (pages 197-207)",
      "start_page": 197,
      "end_page": 207,
      "summary": "async def get_semantic_response(self, \ndef get_response_stream(self, \ndef load_chat_history(self):      \ndef load_actions(self):    \nOpen the nexus_agents/oai_agent.py file in VS Code.\nListing 7.10 shows an agent\nengine implementation of the get_response function that directly consumes the\nasync def get_response(self, user_input, thread_id=None):\nresponse = self.client.chat.completions.create(    \noai_agent.py (get_response)\nfunction\nthe agent’s internal \nagent has available to use\nLike the agent profiles, Nexus uses a plugin system that allows you to place new agent\nengine definitions in the nexus_agents folder.\nIf you create your agent, it just needs\nAgent performs.\nIn the next section, we’ll look at agent functions that agents can\nGiving an agent actions and tools\nLike the SK, Nexus supports having native (code) and semantic (prompt) functions.\nand the second is a prompt/semantic function.\nfrom nexus.nexus_base.action_manager import agent_action\n@agent_action                                             \n@agent_action     \ntest_actions.py (native/semantic function definitions)\nApplies the agent_action \nfunction an action\nfunction\nApplies the agent_action \nfunction an action\nThe function \nGiving an agent actions and tools\nPlace both functions in the nexus_actions folder, and they will be automatically dis-\nAdding the agent_action decorator allows the functions to be inspected and\nuse this tool specification for tool use and function calling.\nListing 7.12 shows the generated OpenAI tool specification for both functions, as\nThe semantic function, which uses a prompt, also\nwhich function to call.\n\"type\": \"function\",\n\"function\": {\n\"type\": \"function\",\n\"function\": {\ntest_actions: OpenAI-generated tool specifications\nThe function \nthe function tool \nThe function \nthe function tool \nThe agent engine also needs to implement that capability to implement functions and\nThe OpenAI agent has been implemented to support parallel\nfunction calling.\nOther agent engine implementations will be required to support\nBefore we dive into a demo on tool use, let’s observe how the OpenAI agent\nimplements actions by opening the oai_agent.py file in VS Code.\ning shows the top of the agent’s get_response_stream function and its implementa-\ndef get_response_stream(self, user_input, thread_id=None):\nself.messages += [{\"role\": \"user\", \"content\": user_input}]\nresponse = self.client.chat.completions.create(\nresponse = self.client.chat.completions.create(\ntool_calls = response_message.tool_calls    \nthe agent supports parallel function/tool calls.\nagent executes each one together and in no order.\nthe agent has \nIf no tools, calls the \nwere any tools used by \nGiving an agent actions and tools\nif tool_calls:    \nfunction_name = tool_call.function.name\nfunction_args = json.loads(tool_call.function.arguments)\nfunction_response = function_to_call(\n**function_args, _caller_agent=self\n\"name\": function_name,\n\"content\": str(function_response),\nsecond_response = self.client.chat.completions.create(\nFigure 7.9 shows the result of entering a query and the agent responding by using\nboth tools in its response.\nIf you need to review how these agent actions work in more detail, refer to chap-\nNow, you can continue exercising the various agent options within Nexus.\nchapter, we unveil how agents can consume external memory and knowledge using\noai_agent.py (get_response_stream: execute tool calls)\nin the LLM response\n– Create a new agent profile with a unique persona.\nThe agent answered in a\nSelect the terse agent\nHow the agent can use tools in parallel and respond with a single response\n– Implement this action as both a native (code) function and a semantic\n(prompt-based) function.\nObjective—Enhance the capabilities of a Nexus agent by integrating a real\nNexus supports creating and customizing agent profiles and personas, allowing\nusers to define their agents’ personalities and behaviors.\nhow agents interact with and respond to user inputs.\nbased) and native (code-based) actions and tools within agents.\nthe creation of highly functional and responsive agents.\ncontributions and the addition of new features, tools, and agent capabilities by\nUnderstanding agent\nmemory and knowledge\nNow that we’ve explored agent actions using external tools, such as plugins in the\nform of native or semantic functions, we can look at the role of memory and knowl-\nedge using retrieval in agents and chat interfaces.\nstand memory knowledge, we’ll investigate document indexing, construct retrieval\nRetrieval in knowledge/memory in AI functions\nRetrieval augmented generation for agentic \nRetrieval patterns for memory in agents\nRetrieval in agent and chat applications is a mechanism for obtaining knowledge to\nBoth knowledge and memory use retrieval as the\nKnowledge and Memory\nActions, Knowledge, Memory\nagent\nMemory, retrieval, and augmentation of the prompt using the following prompt engineering \nstrategies: Use External Tools and Provide Reference Text.\nUnderstanding agent memory and knowledge\nThe retrieval mechanism, called retrieval augmented generation (RAG), has\nFigure 8.2 shows how RAG can allow a document to be queried using an LLM.\nLLM generates a response\nMemory Retrieval Augmented Generation\nRetrieved memory\nMemory retrieval for augmented generation uses the same embedding patterns to index items to a ",
      "keywords": [
        "agent",
        "nexus",
        "function",
        "LLM",
        "response",
        "memory",
        "tool",
        "Retrieval",
        "Retrieval Augmented Generation",
        "functions",
        "action",
        "knowledge",
        "prompt",
        "agent actions",
        "user"
      ],
      "concepts": [
        "agent",
        "function",
        "functions",
        "functionality",
        "retrieval",
        "retrieve",
        "tools",
        "response",
        "responsive",
        "actions"
      ],
      "similar_chapters": [
        {
          "book": "AI Agents In Action",
          "chapter": 22,
          "title": "",
          "score": 0.724,
          "base_score": 0.574,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 26,
          "title": "",
          "score": 0.715,
          "base_score": 0.565,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 2,
          "title": "",
          "score": 0.696,
          "base_score": 0.546,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 27,
          "title": "",
          "score": 0.692,
          "base_score": 0.542,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 34,
          "title": "",
          "score": 0.689,
          "base_score": 0.539,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "function",
          "agent",
          "retrieval",
          "self",
          "memory"
        ],
        "semantic": [],
        "merged": [
          "function",
          "agent",
          "retrieval",
          "self",
          "memory"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.4149628020467931,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:00:43.646176+00:00"
      }
    },
    {
      "chapter_number": 24,
      "title": "Segment 24 (pages 208-215)",
      "start_page": 208,
      "end_page": 215,
      "summary": "Delving into semantic search and document indexing\nApplying vector similarity search\nLet’s look now at how a document can be transformed into a semantic vector, or a repre-\nNow open the document_vector_similarity.py file in VS Code, and review the\nthe document set.\nimportance within a set of documents.\ndocuments = [     \nX = vectorizer.fit_transform(documents)     \ndocument_vector_similarity (transform to vector)\nSamples of documents\ndocuments.\nDelving into semantic search and document indexing\nTF for blue can be calculated as the number of times blue appears in the document\nin four of these documents.\nhave the elements represented as vectors, we can measure document similarity using\npieces or documents of text.\nSimilarities are calculated for each document against all\nother documents in the set.\nThe computed matrix of similarities for documents is\nselect the document to view its similarities to the other documents.\nDelving into semantic search and document indexing\nselected_document_similarities = \ncosine_similarities[selected_document_index]    \n# code to plot document similarities omitted\nAfter you select a document, you’ll see the similarities between the various\ndocuments in the set.\nA document will have a cosine similarity of 1 with itself.\ndocument_vector_similarity (cosine similarity)\nComputes the document \ndocument index \nagainst all documents\nThe select document is compared against all\nother documents to show similarity\nmeasure between document vectors.\nThe cosine similarity between selected documents and the document set\ndocuments.\nBefore we move on to better methods of vectorizing documents, we’ll\nVector databases and similarity search\nAfter vectorizing documents, they can be stored in a vector database for later similar-\nOpen document_vector_database.py in VS Code, as shown in listing 8.3.\ndocument text and the similarity score.\nX = vectorizer.fit_transform(documents)\ndef cosine_similarity_search(query,\nsearch_results = cosine_similarity_search(query,\nprint(\"Top Matched Documents:\")\nTop Matched Documents:\ndocument_vector_database.py\ndocument vectors \nDelving into semantic search and document indexing\nthe results of documents being returned.\nword context and meaning from the document.\nof transforming documents into vectors that better preserves their semantic meaning.\nDemystifying document embeddings\nTF–IDF is a simple form that tries to capture semantic meaning in documents.\nembedding, a form of document vectorizing that better preserves the semantic mean-\ning of the document.\nsets to map words, sentences, or documents to high-dimensional vectors, capturing\ntypically perfect for capturing the semantic context of embedded documents.\n8.4 shows the relevant code that uses OpenAI to embed the documents into vectors\ndocument_visualizing_embeddings.py (relevant sections)\nfor each document of \nWhen a document is embedded using an OpenAI model, it transforms the text into a\ndocuments are now grouped.\nQuerying document embeddings from Chroma\nSimilar documents are now similar in\nEmbeddings in 3D, showing how similar semantic documents are grouped\nDelving into semantic search and document indexing\nListing 8.5 shows the new and relevant code sections from the document_query_\nname=\"documents\")       \nresults['documents'][0])]\nprint(\"Top Matched Documents:\")\nTop Matched Documents:\ndocument_query_chromadb.py (relevant code sections)\nfor each document and \nAdds document \nrelevant documents\nrelevant documents/scores",
      "keywords": [
        "document",
        "documents",
        "IDF",
        "similarity",
        "cosine",
        "Top Matched Documents",
        "cosine similarity",
        "blue",
        "vector",
        "search",
        "top",
        "embeddings",
        "INVERSE DOCUMENT FREQUENCY",
        "score",
        "query"
      ],
      "concepts": [
        "document",
        "documents",
        "vectorization",
        "similar",
        "similarities",
        "embeddings",
        "score",
        "scored",
        "queried",
        "query"
      ],
      "similar_chapters": [
        {
          "book": "AI Agents In Action",
          "chapter": 25,
          "title": "",
          "score": 0.608,
          "base_score": 0.458,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 16,
          "title": "",
          "score": 0.364,
          "base_score": 0.214,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 17,
          "title": "",
          "score": 0.363,
          "base_score": 0.213,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 18,
          "title": "",
          "score": 0.358,
          "base_score": 0.208,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 2,
          "title": "",
          "score": 0.357,
          "base_score": 0.207,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "documents",
          "document",
          "similarity",
          "vectors",
          "semantic"
        ],
        "semantic": [],
        "merged": [
          "documents",
          "document",
          "similarity",
          "vectors",
          "semantic"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.14996556183029058,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:00:43.646207+00:00"
      }
    },
    {
      "chapter_number": 25,
      "title": "Segment 25 (pages 216-223)",
      "start_page": 216,
      "end_page": 223,
      "summary": "As the earlier scenario demonstrated, you can now query the documents using seman-\ndocuments for retrieval.\nThe critical difference between document and memory\nwe’ll start by splitting and loading documents with LangChain.\nSplitting and loading documents with LangChain\nsupports document import\nthe document\nLoad, transform, embed, and store steps in storing documents for later retrieval\na local document.\noption is to split the document and use the relevant parts to request context—pre-\nSplitting a document is essential in breaking down content into semantically and\nOften, splitting a document into\nIdeally, when we split documents into chunks, they are broken down by relevance and\nrent toolkit options within LangChain for splitting documents.\nFor the next exercise, open langchain_load_splitting.py in VS Code, as shown\nSplit the documents into chunks.\nLoad the document(s).\nHow the document would ideally be split into chunks for better semantic and contextual meaning\nFrom langchain_community.document_loaders \n\"sample_documents/mother_goose.html\")  \ndocuments = text_splitter.split_documents(data)\ndocuments = [doc.page_content \n➥ for doc in documents] [100:350]  \nTop Matched Documents:\nNote in listing 8.6 that the HTML document gets split into 100-character chunks with\nThe overlap allows the document’s parts not to cut off specific\nGo ahead and run the langchain_load_splitting.py file in VS Code (F5).\nRemember that we only embedded 250 document chunks to\ndocument splitting.\nYou can use numerous methods to split a document, including\nment for numerous embedding views of the same document.\nwe’ll examine a more general technique for splitting documents, using tokens and\nlangchain_load_splitting.py (sections and output)\ndocument \ndocument\nSplits the document into blocks of \neach document\nSplitting documents by token with LangChain\nSplitting documents using tokenization provides a better base for how the text will\nmatching of documents more relevant and generally providing better results.\nFor the next code exercise, open the langchain_token_splitting.py file in VS\nNow we split the document using tokenization, which\nbreaks the document into sections of unequal size.\nlarge sections of whitespace of the original document.\nloader = UnstructuredHTMLLoader(\"sample_documents/mother_goose.html\")\ndocuments = text_splitter.split_documents(data)\ndef query_documents(query, top_n=2):\nTop Matched Documents:\nDocument 1: GEORGY PORGY\nRun the langchain_token_splitting.py code in VS Code (F5).\nlangchain_token_splitting.py (relevant new code)\ndocuments that \nTop Matched Documents:\nDocument 1: WILLY, WILLY\nKnowledge in agents encompasses employing RAG to search semantically across\nunstructured documents.\nsoft Word documents and all text, including code.\nthe previous chapter, employs complete knowledge and memory systems for agents.\nStore, and then upload the sample_documents/back_to_the_future.txt movie script.\nThe script is a large document, and it may take a while to load, chunk, and embed the\nselect an agent and the time_travel knowledge store, as shown in figure 8.11.\nAdding a new knowledge store and populating it with a document\ndocument embeddings\nThe embeddings and document query views\nEnabling the knowledge store for agent use\ntype of splitter (Chunking Option field) to chunk the document, along with the\nThe loading, splitting, chunking, and embedding options provided are the only basic\ndocument splitter used to extract\nchunks from the document\nManaging the knowledge store splitting and chunking options",
      "keywords": [
        "documents",
        "document",
        "knowledge",
        "Knowledge Store",
        "LangChain",
        "RAG",
        "Code",
        "store",
        "agent",
        "query",
        "Nexus",
        "TEXT",
        "chunks",
        "Top Matched Documents",
        "splitting documents"
      ],
      "concepts": [
        "documents",
        "document",
        "chunks",
        "code",
        "stores",
        "storing",
        "agent",
        "knowledge",
        "nexus",
        "semantically"
      ],
      "similar_chapters": [
        {
          "book": "AI Agents In Action",
          "chapter": 24,
          "title": "",
          "score": 0.608,
          "base_score": 0.458,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 17,
          "title": "",
          "score": 0.476,
          "base_score": 0.326,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 23,
          "title": "",
          "score": 0.403,
          "base_score": 0.253,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 26,
          "title": "",
          "score": 0.397,
          "base_score": 0.247,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 22,
          "title": "",
          "score": 0.395,
          "base_score": 0.245,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "documents",
          "document",
          "splitting",
          "chunks",
          "split"
        ],
        "semantic": [],
        "merged": [
          "documents",
          "document",
          "splitting",
          "chunks",
          "split"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.2059118649199563,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:00:43.646243+00:00"
      }
    },
    {
      "chapter_number": 26,
      "title": "Segment 26 (pages 224-232)",
      "start_page": 224,
      "end_page": 232,
      "summary": "Understanding agent memory and knowledge\nsection, we’ll explore what makes memory in agents unique.\ntive memory functions.\nterm memory.\neach form of memory maps to agent functions:\nSemantic memory provides a robust capacity to store and retrieve rel-\nVisual memory\nSensory memory\nMemory\nEpisodic memory\nSemantic memory\nmemory and RAG\nmemory of most\nsection will examine how basic memory stores work in Nexus.\nAdding memories\nBasic memory augmentation\nNew memories\nConversations are then fed back into the memory function\nMemory function,\nmemories\nUnderstanding agent memory and knowledge\nConsuming memory stores in Nexus\nMemory stores operate and are constructed like knowledge stores in Nexus.\ntion is fed into a memory store, it’s generally processed through an LLM using a memory\nstore called my_memory.\nSelect the memory\nengine to process the memory.\nMemory page.\nrelevant information related to the type of memory.\nListing 8.10 shows the conversational memory function used to extract information\nfrom a conversation into memories.\nAfter you generate a few relevant memories about yourself, return to the Chat area in\nNexus, enable the my_memory memory store, and see how well the agent knows you.\nconversations and stores them in a vector database as memories.\nConversational memory function\nSelect the memory store.\nengine that supports memory.\nthe facts you just added to memory.\nConversing with a different agent on the same memory store\nUnderstanding agent memory and knowledge\nand procedural memory\nFigure 8.17 shows the semantic memory categorization process, also sometimes\ncalled semantic memory.\nSemantic memory augmentation\nfed back into the memory\nnew memories.\nmemory.\nHow semantic memory augmentation works\nrelevant memories.\nating a new semantic memory store.\nFigure 8.18 shows how to configure a new memory store using semantic memory.\nrelevance before querying a memory store.\nSelect SEMANTIC as the type of memory.\nmemory store ﬁrst.\nSummarization function is used in memory\nConfiguration for changing the memory store type to semantic\nUnderstanding agent memory and knowledge\nof the relevant memory type.\nMemory and knowledge can significantly assist an agent with various application types.\nIndeed, a single memory/knowledge store could feed one or multiple agents, allowing\nUnderstanding memory and knowledge compression\nchapter by discussing memory/knowledge compression next.\nUnderstanding memory and knowledge compression\nMuch like our own memory, memory stores can become cluttered with redundant\nwith memory clutter by compressing or summarizing memories.\nWe can apply similar principles of memory compression to agent memory and\nFigure 8.20 shows the process of memory/knowledge compression.\nMemories or\nmemories are passed through a compression function, which summarizes and collects\nNexus provides for both knowledge and memory store compression using k-means\nFigure 8.21 shows the compression interface for memory.\nCompressing memories and even knowledge is generally recommended if the\nMemory/Knowledge Comparison\nMemories and\nlist of memories and\nThe process of memory and knowledge compression\nUnderstanding agent memory and knowledge\nMemory will often benefit from the periodic compression application, whereas knowl-\nThe interface for compressing memories",
      "keywords": [
        "memory",
        "memory store",
        "Semantic memory",
        "compression",
        "memories",
        "knowledge",
        "Semantic",
        "agent memory",
        "agent",
        "store",
        "user",
        "time travel movies",
        "memory function",
        "time travel",
        "time"
      ],
      "concepts": [
        "memories",
        "compression",
        "compressing",
        "stores",
        "semantic",
        "agents",
        "functions",
        "function",
        "facts",
        "knowledge"
      ],
      "similar_chapters": [
        {
          "book": "AI Agents In Action",
          "chapter": 27,
          "title": "",
          "score": 0.781,
          "base_score": 0.631,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 2,
          "title": "",
          "score": 0.74,
          "base_score": 0.59,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 23,
          "title": "",
          "score": 0.715,
          "base_score": 0.565,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 15,
          "title": "",
          "score": 0.653,
          "base_score": 0.503,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 34,
          "title": "",
          "score": 0.636,
          "base_score": 0.486,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "memory",
          "memories",
          "compression",
          "memory store",
          "store"
        ],
        "semantic": [],
        "merged": [
          "memory",
          "memories",
          "compression",
          "memory store",
          "store"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.36329661963461424,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:00:43.646291+00:00"
      }
    },
    {
      "chapter_number": 27,
      "title": "Segment 27 (pages 233-241)",
      "start_page": 233,
      "end_page": 241,
      "summary": "Understanding agent memory and knowledge\n– Interact with an agent using each type of memory store, and observe the dif-\nmemory, highlighting their use in contextualizing prompts for more relevant\nNexus is a platform that implements agentic knowledge and memory systems,\nincluding setting up knowledge stores for document retrieval and memory\ntion stored in memory and knowledge systems, improving retrieval efficiency\nMastering agent prompts\nwith prompt flow\nIn this chapter, we delve into the Test Changes Systematically prompt engineering\nbuild better prompts and, consequently, better agent profiles and personas.\nsystemic prompt engineering.\nUnderstanding systematic prompt engineering \nand setting up your first prompt flow\nCrafting an effective profile/persona prompt\nWhy we need systematic prompt engineering\nWhy we need systematic prompt engineering\nPrompt engineering, by its nature, is an iterative process.\nWhen building a prompt,\napplication of prompt engineering to a ChatGPT question.\nand open a new conversation with ChatGPT, and enter the following prompt, as\nChatGPT itself guides the user into better prompting.\nfigure 9.2 shows the OpenAI prompt engineering strategies.\nNo prompt engineering\nApplying prompt engineering\nthe prompt/request.\nThe differences in applying prompt engineering and iterating\nMastering agent prompts with prompt flow\nPrompt Engineering Strategies\nOpenAI prompt engineering strategies, broken down by agent component\nWhy we need systematic prompt engineering\nThis time, enter the following prompt and include\nThe effect of adding a system prompt to our previous conversation\nMastering agent prompts with prompt flow\nHowever, we haven’t defined the iterative flow for evaluating the prompt and\ndetermining when a prompt is effective.\nThe system of iterating and evaluating prompts covers the broad Test Changes System-\nEvaluating the performance and effectiveness of prompts is still new,\nAn agent profile is an encapsulation of component prompts or messages that describe\nprompt engineering strategies described in this book.\nAt a basic level, an agent profile is a set of prompts describing the agent.\nSystemic Prompt Engineering\nBuild prompt\nprompt\nprompt\nof prompt\nPrompt is\nPrompt or proﬁle\nof the prompt/proﬁle.\nEvaluate the prompt\nUse prompt\nwrite the prompt.\nThe systemic method of prompt engineering\nSetting up your first prompt flow\ncomprises an entire agent prompt profile.\nPrompts are the heart of an agent’s function.\nFor actions/tools, these prompts are well\ndefined, but as we’ve seen, prompts for memory and knowledge can vary significantly\nThe definition of an AI agent profile is more than just a system prompt.\nPrompt\nflow can allow us to construct the prompts and code comprising the agent profile but\nSetting up your first prompt flow\ntion platform, it has since shown its strength in developing and evaluating prompts/\nThe Agent Proﬁle (prompts)\nthe prompt under the covers.\nKnowledge and memory are prompts\nSimilar to prompt personas, the agent\nAgent Memory and Knowledge",
      "keywords": [
        "prompt",
        "prompt engineering",
        "agent",
        "MEMORY",
        "prompt flow",
        "engineering",
        "KNOWLEDGE",
        "prompt engineering strategies",
        "agent profile",
        "systematic prompt engineering",
        "agent prompts",
        "Semantic",
        "system prompt",
        "memory stores",
        "Mastering agent prompts"
      ],
      "concepts": [
        "prompts",
        "agents",
        "memory",
        "memories",
        "stores",
        "storing",
        "retrieval",
        "retrieve",
        "exercises",
        "knowledge"
      ],
      "similar_chapters": [
        {
          "book": "AI Agents In Action",
          "chapter": 2,
          "title": "",
          "score": 0.826,
          "base_score": 0.676,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 26,
          "title": "",
          "score": 0.781,
          "base_score": 0.631,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 38,
          "title": "",
          "score": 0.705,
          "base_score": 0.555,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 34,
          "title": "",
          "score": 0.703,
          "base_score": 0.553,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 36,
          "title": "",
          "score": 0.698,
          "base_score": 0.548,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "prompt",
          "prompt engineering",
          "engineering",
          "prompts",
          "agent"
        ],
        "semantic": [],
        "merged": [
          "prompt",
          "prompt engineering",
          "engineering",
          "prompts",
          "agent"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.4222508717825883,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:00:43.646333+00:00"
      }
    },
    {
      "chapter_number": 28,
      "title": "Segment 28 (pages 242-251)",
      "start_page": 242,
      "end_page": 251,
      "summary": "Mastering agent prompts with prompt flow\nine the basics of starting with prompt flow.\nInstall prompt flow packages—Within your virtual environment, do a quick pip\nvirtual environment connected and have installed the prompt flow packages and\nFirst, you’ll want to create a connection to your LLM resource within the prompt\nOpen the prompt flow extension within VS Code, and then click to\nThis will open a terminal prompt below the document,\nWe’ll now test the connection by first opening the simple flow in the chap-\nThen, open the flow.dag.yaml file in VS\nThis is a YAML file, but the prompt flow extension provides a visual editor\nSetting up your first prompt flow\nClick to open the prompt ﬂow extension.\nCreating a new prompt flow LLM connection\nMastering agent prompts with prompt flow\nAfter the visual editor window is opened, you’ll see a graph representing the flow and\nDouble-click the recommender block, and set the connection name,\nAPI type, and model or deployment name, as shown in figure 9.10.\nOpening the prompt flow visual editor\nSetting up your first prompt flow\nA prompt flow is composed of a set of blocks starting with an Inputs block and termi-\nWithin this simple flow, the recommender block represents\nthe LLM connection and the prompt used to converse with the model.\nWhen creating a connection to an LLM, either in prompt flow or through an\nAPI, here are the crucial parameters we always need to consider (prompt flow docu-\nPrompt flow supports multiple services, including locally\nMastering agent prompts with prompt flow\nThe flow responds with time travel movie recommendations because of the prompt or\nBy default, prompt flow uses Jinja2 templates to define the content of\nthe prompt or what we’ll call a profile.\ntion of AI agents, we’ll refer to these templates as the profile of a flow or agent.\nWhile prompt flow doesn’t explicitly refer to itself as an assistant or agent engine, it\nsee, prompt flow even supports deployments of flows into containers and as services.\nOpen VS Code to chapter_09/promptflow/simpleflow/flow.dag.yaml, and open\nThen, locate the Prompt field, and click the recommended\nSetting the inputs and starting the flow\nuser portion of the prompt/proﬁle\nOpening the prompt Jinja2 template and examining the parts of the profile/prompt\nSetting up your first prompt flow\nWhile there is no standard way to construct prompts or agent profiles, our\nAt this point, change the role within the system prompt of the recommended.jin-\nThen, run all blocks of the flow by opening the flow in the visual editor\nprompt flow for testing or actual deployment.\nDeploying a prompt flow API\nBecause prompt flow was also designed to be deployed as a service, it supports a cou-\nPrompt flow can be deployed as a local\nReturn to the flow.dag.yaml file in the visual editor from VS Code.\nClick the Build button as shown in figure 9.13, and then select to deploy as a local\nMastering agent prompts with prompt flow\nhow to evaluate prompts and profiles.\nA key element of any prompt or agent profile is how well it performs its given task.\nwe see in our recommendation example, prompting an agent profile to give a list of\nFortunately, prompt flow has been designed to evaluate prompts/profiles at scale.\nIn the next section, we look at how prompt flow can be configured to run prompt/\nPrompt flow provides a mechanism to allow for multiple variations within an LLM\nprompt/profile.\nOpen the recommender_with_variations/flow.dag.yaml file in VS Code and the\nflow visual editor, as shown in figure 9.15.\nThe new inputs Subject, Genre, Format, and Custom allow us to define a profile that\nThe recommender, with variations in flow and expanded inputs\nMastering agent prompts with prompt flow\nThe option you choose will dictate how you need to evaluate your profiles.\nTo get back to VS Code and the visual view of the recommender with variants flow,\nclick the icon shown earlier in figure 9.15 to open the variants and allow editing.\ninjects the inputs into the user prompt, and the other injects them into the system\nprompt.\nThe user interaction options for interfacing with the agent profile to prime inputs to the agent profile\nFor this simple example, we’re just going to use prompt variations by varying the input\nto reflect in either the system or user prompt.\nLLM variation options in prompt flow\nJinja2 prompt \nCompare system prompt variations, \nuser prompt variations, or mixed prompt \nprompt.\nThe system prompt describes a generic recommender\nthe user prompt.\nthe system prompt.",
      "keywords": [
        "prompt flow",
        "prompt",
        "flow",
        "LLM",
        "prompt flow LLM",
        "prompt flow extension",
        "prompt flow API",
        "Code",
        "flow LLM connection",
        "connection",
        "agent prompts",
        "Inputs",
        "Mastering agent prompts",
        "profile",
        "agent"
      ],
      "concepts": [
        "prompted",
        "flows",
        "inputs",
        "tokens",
        "llm",
        "click",
        "comparing",
        "compare",
        "blocks",
        "model"
      ],
      "similar_chapters": [
        {
          "book": "AI Agents In Action",
          "chapter": 7,
          "title": "",
          "score": 0.763,
          "base_score": 0.613,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 31,
          "title": "",
          "score": 0.758,
          "base_score": 0.608,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 33,
          "title": "",
          "score": 0.724,
          "base_score": 0.574,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 30,
          "title": "",
          "score": 0.7,
          "base_score": 0.55,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 27,
          "title": "",
          "score": 0.524,
          "base_score": 0.524,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "flow",
          "prompt",
          "prompt flow",
          "connection",
          "profile"
        ],
        "semantic": [],
        "merged": [
          "flow",
          "prompt",
          "prompt flow",
          "connection",
          "profile"
        ]
      },
      "topic_id": 1,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.3540357060030567,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:00:43.646370+00:00"
      }
    },
    {
      "chapter_number": 29,
      "title": "Segment 29 (pages 252-260)",
      "start_page": 252,
      "end_page": 260,
      "summary": "Evaluation of prompt/profile performance isn’t something we can typically do using a\nIn education, the rubric concept defines a structured set of criteria and standards a\nA rubric can also be used to\ndefine a guide for the performance of a profile or prompt.\nto define a rubric we can use to evaluate the performance of a profile or prompt:\nFor example, do you want to evaluate the quality of recom-\nDevelop a set of criteria or dimensions that you’ll use to evaluate\nThese criteria should align with your objectives and provide clear\nRunning both prompt variations at the same time\nFor example, you may want to measure a recommendation by how well it fits\nwith the genre and then by subject and format.\nWhen assessing a prompt or profile, use the rubric to evaluate\nthe prompt’s performance based on the established criteria.\nIf multiple evaluators are assessing the profile, it’s\nGrounding is a concept that can be applied to profile and prompt evaluation—it\ndefines how well a response is aligned with a given rubric’s specific criteria and stan-\nwith profile evaluation:\nGrounding refers to aligning responses with the criteria, objectives, and context\ndefined by the rubric and prompt.\nrubric criteria, stays on topic, and adheres to any provided instructions.\nA well-grounded response aligns with all the rubric criteria within the given context\nprocess for defining a rubric as applied to our recommender example:\nmend three top items given a subject, format, genre, and custom input.\nFor simplicity, we’ll evaluate how a particular recommendation\naligns with the given input criteria, subject, format, and genre.\nprofile recommends a book when asked for a movie format, we expect a low\nscore in the format criteria.\nto evaluate the rubric against recommendations manually.\nFor our rubric, we’ll average the score for all criteria to\nThe technique we’ll use for evaluation will provide\nWe’ll review, compare, and iterate on our profiles, rubrics,\nand the evaluations themselves.\nThis basic rubric can now be applied to evaluate the responses for our profile.\nGrounding evaluation with an LLM profile\nThis section will employ another LLM prompt/profile for evaluation and grounding.\nThis second LLM prompt will add another block after the recommendations are gen-\nIt will process the generated recommendations and evaluate each one, given\nsidered using another LLM prompt to evaluate or ground a profile.\nRubric ratings \nExcellent alignment: this is a good recommendation for the given criteria.\nGrounding evaluation with an LLM profile\ncomparing profiles against each other, using the same LLM for evaluation and ground-\nOpen the recommender_with_LLM_evaluation\\flow.dag.yaml file in the prompt\nflow visual editor, scroll down to the evaluate_recommendation block, and click the\nevaluate_recommendation.jinja2 link to open the file, as shown in figure 9.19.\nWe have a rubric that is not only well defined but also in the form of a prompt that can\nbe used to evaluate recommendations.\nrubric to score and evaluate the recommendations manually for a better baseline.\nUsing LLMs to evaluate prompts and profiles provides a strong base-\nlent mechanism to establish baseline groundings for any profile or prompt.\nReturning to the recommender_with_LLM_evaluation flow visual editor, we can run\nDeﬁne the basic criteria for the rubric.\nDeﬁne the rubric scale and\nThe evaluation prompt, with each of the parts of the rubric outlined\nrecommendation or run both variations when prompted.\nWe now have a rubric for grounding our recommender, and the evaluation is run\nWith our understanding of rubrics and grounding, we can now move on to evaluating\noutput from the LLM evaluation block.\nParsing the LLM evaluation output\nAs the raw output from the evaluation block is text, we now want to parse that into\nOpen chapter_09\\prompt_flow\\recommender_with_parsing\\flow.dag.yaml in\nThe code for the parsing_results.py file is shown in listing 9.2.\nLLM rubric evaluation output\n# Function to parse individual recommendation block into dictionary\nWe’re converting the recommendations output from listing 9.1, which is just a string,\nafter LLM evaluation.\nAt this point, we have a full working recommendation and LLM evaluation flow\nevaluations of a particular profile, we want to generate multiple recommendations\nwith various criteria.\nRunning batch processing in prompt flow\nIn our generic recommendation profile, we want to evaluate how various input crite-\nlist document of our input criteria.\nCan you please generate a random list of these criteria and output it in the format of\ngenerated file can be found in the flow folder, called \\bulk_recommend.jsonl.\nWith this bulk file, we can run both variants using the various input criteria in the bulk",
      "keywords": [
        "prompt",
        "rubric",
        "profile",
        "criteria",
        "format",
        "LLM",
        "subject",
        "Evaluation",
        "genre",
        "LLM prompt",
        "prompt flow",
        "LLM evaluation",
        "grounding",
        "evaluate",
        "LLM profile"
      ],
      "concepts": [
        "criteria",
        "recommendation",
        "recommendations",
        "evaluate",
        "evaluation",
        "evaluators",
        "evaluations",
        "evaluating",
        "profile",
        "rubrics"
      ],
      "similar_chapters": [
        {
          "book": "AI Agents In Action",
          "chapter": 30,
          "title": "",
          "score": 0.663,
          "base_score": 0.513,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 7,
          "title": "",
          "score": 0.499,
          "base_score": 0.349,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 31,
          "title": "",
          "score": 0.459,
          "base_score": 0.309,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 32,
          "title": "",
          "score": 0.453,
          "base_score": 0.303,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 28,
          "title": "",
          "score": 0.372,
          "base_score": 0.222,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "rubric",
          "criteria",
          "profile",
          "evaluation",
          "prompt"
        ],
        "semantic": [],
        "merged": [
          "rubric",
          "criteria",
          "profile",
          "evaluation",
          "prompt"
        ]
      },
      "topic_id": 1,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.20054528910633743,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:00:43.646410+00:00"
      }
    },
    {
      "chapter_number": 30,
      "title": "Segment 30 (pages 261-269)",
      "start_page": 261,
      "end_page": 269,
      "summary": "After the bulk file is selected, a new YAML document will open with a Run link added\nClick the link to do the batch run\nrun to complete, and you’ll see a summary of results in the terminal.\nYou can also view the run results by opening the prompt flow extension and select-\nLoading the bulk JSONL file to run the flow on multiple input variations\nClick to run the batch.\nRunning the batch run of inputs\nMastering agent prompts with prompt flow\nand evaluate the results of both prompts.\nform the profile/prompt evaluation.\nCreating an evaluation flow for grounding\nOpen chapter_3\\prompt_flow\\evaluate_groundings\\flow.dag.yaml in the visual edi-\nPython code blocks that will run the scoring and then aggregate the scores.\n#1 Open the prompt\nAn opening run visualization and an examination of a batch run\nLooking at the evaluate_groundings flow used to ground recommendation runs\nMastering agent prompts with prompt flow\nFrom the grounded recommendations, we can move on to aggregating the scores\nThe result of the aggregations will be a summary score for each criterion and the aver-\nSince the evaluation/grounding flow is separate, it can be run over any rec-\nThis will allow us to use the batch run results for any\nWe can run the grounding flow by opening flow.dag.yaml in the visual editor and\nThen, when prompted, we select an existing run and\nthen select the run we want to evaluate, as shown in figure 9.25.\nOpen the prompt flow extension, focus on the Batch Run History window, and\nSelect the runs\nThe Batch Run Visual-\nhopefully you can see what an excellent tool prompt flow will be for building agent\nprofiles and prompts.\nSelect the run you want to evaluate, noting the name.\nLoading a previous run to be grounded and evaluated\n#2 Select the runs you want to evaluate,\nright-click and select Visualize Runs.\nresults against each of the runs.\nMastering agent prompts with prompt flow\nExercise 1—Create a New Prompt Variant for Recommender Flow (Intermediate)\nprompt variant in prompt flow.\n– Create a new prompt variant for the recommender flow in prompt flow.\n– Run the flow in batch mode.\n– Update the evaluation flow to score the new criterion.\n– Evaluate the results, and analyze the effect of the new criterion on the\n– Build the prompt for the new use case.\n– Create a rubric for evaluating the new prompt.\n– Update or alter the evaluation flow to aggregate and compare the results of\n– Evaluate other open source LLMs.\nExercise 5—Build and Evaluate Prompts Using Prompt Flow (Intermediate)\nObjective—Apply prompt engineering strategies to build and evaluate new prompts\nor profiles using prompt flow.\n– Build new prompts or profiles for evaluation using prompt flow.\n– Evaluate the prompts and profiles using prompt flow.\nAn agent profile consists of several other component prompts that can drive\nPrompt flow can be used to evaluate an agent’s component prompts.\nSystemic prompt engineering is an iterative process evaluating a prompt and\nAgent profiles and prompt engineering have many similarities.\nagent profile as the combination of prompt engineering elements that guide\ntures for developing and evaluating profiles and prompts.\nAn LLM connection in prompt flow supports additional parameters, including\nLLM blocks support prompt and profile variants, which allow for evaluating\nGrounding is the scoring and evaluation of a rubric.\nPrompt flow supports running multiple variations as single runs or batch runs.\nIn prompt flow, an evaluation flow is run after a generative flow to score and\nThe Visualize Runs option can compare the aggregated\ncriteria from scoring the rubric across multiple runs.\nTo explore how LLMs can be prompted to reason, understand, and plan, we’ll\ndemonstrate how to engage reasoning through prompt engineering and then\nFigure 10.1 demonstrates the high-level prompt engineering strategies we’ll\nEmploying an evaluation prompt to narrow \nPrompt\nanswer prompting\nprompting\nprompting\nprompting\nprompting\nprompting\nPrompt Engineering Strategies\nHow the two planning prompt engineering strategies align with the various techniques",
      "keywords": [
        "prompt flow",
        "prompt",
        "Run",
        "prompt engineering",
        "batch run",
        "flow",
        "runs",
        "evaluation",
        "evaluate",
        "score",
        "evaluation flow",
        "results",
        "batch",
        "prompt engineering strategies",
        "Visualize Runs"
      ],
      "concepts": [
        "prompt",
        "evaluate",
        "evaluation",
        "evaluated",
        "evaluations",
        "flows",
        "run",
        "running",
        "runs",
        "recommendations"
      ],
      "similar_chapters": [
        {
          "book": "AI Agents In Action",
          "chapter": 7,
          "title": "",
          "score": 0.726,
          "base_score": 0.576,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 28,
          "title": "",
          "score": 0.7,
          "base_score": 0.55,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 33,
          "title": "",
          "score": 0.699,
          "base_score": 0.549,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 29,
          "title": "",
          "score": 0.663,
          "base_score": 0.513,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 31,
          "title": "",
          "score": 0.636,
          "base_score": 0.486,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "flow",
          "prompt",
          "prompt flow",
          "run",
          "batch"
        ],
        "semantic": [],
        "merged": [
          "flow",
          "prompt",
          "prompt flow",
          "run",
          "batch"
        ]
      },
      "topic_id": 1,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.3491144069201824,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:00:43.646446+00:00"
      }
    },
    {
      "chapter_number": 31,
      "title": "Segment 31 (pages 270-277)",
      "start_page": 270,
      "end_page": 277,
      "summary": "10.1.1 Question-and-answer prompting\nFor the exercises in this chapter, we’ll employ prompt flow to build and evaluate the var-\nchapter if you need a review.) Prompt flow is an excellent tool for understanding how\nWe’ll look at the first flow in the prompt_flow/question-answering-prompting\nOpen the flow.dag.yaml file in the visual editor, as shown in figure 10.2.\nAt the top is the question_answer\nLLM prompt, followed by two Embedding components and a final LLM prompt to do\nquestion-answer-prompting flow\nPrompt ﬂow folder to open\nLLM: Question-Answer (the prompt used to ask the question)\nthe prediction/answer to the question\nEmbeddings: uses an LLM embedding model to create the embedding \nEmbedding_predicted: embeds the output of the Question-Answer LLM\nEmbedding_expected: embeds the output of the expected answer\npredicted: -> output.question_answer\nBefore running this flow, make sure your LLM block is configured correctly.\nAfter configuring your LLM connection, run the flow by clicking the Play but-\nOpen the question_answer.jinja2 file in VS Code, as shown in listing 10.2.\nlisting shows the basic question-and-answer-style prompt.\nAnswer the users question based on the context below.\nThis exercise shows the simple method of using an LLM to ask questions about a\nWe can see from the output in listing 10.1 that the LLM does a good job of\nanswering a question about the context.\ntechnique that uses direct prompting.\n10.1.2 Implementing few-shot prompting\nFew-shot prompting is like question-and-answer prompting, but the makeup of the\nprompt is more about providing a few examples than about facts or context.\nOpen prompt_flow/few-shot-prompting/flow.dag.yaml in VS Code and the visual\nLLM prompt.\nshould answer the question about.\nstatement  : introduces the context and then asks for output\nexpected : the expected answer to the statement\nLLM: few_shot (the prompt used to ask the question)\noutputs: the prediction/answer to the statement\nEmbeddings: uses an LLM embedding model to create the embedding \nEmbedding_predicted: embeds the output of the few_shot LLM\nEmbedding_expected: embeds the output of the expected answer\nOutputs: the similarity score between predicted and expected\npredicted: -> output.few_shot\nYou should see output like listing 10.3 where the LLM has used the word sunner (a\nThis exercise demonstrates the ability to use a prompt to alter the behavior of the\nOpen the few_shot.jinja2 prompt in VS Code, shown in listing 10.4.\nfew-shot-prompting flow\nintent is to get the LLM to use \nprompt allows for the LLM to extend the examples and produce similar results using\nAn example of a sentence that uses the word whatpu is:    \nIt allows prompts to be constructed to guide an LLM to do\ntion and background of an LLM, we’ll move on to demonstrate a final example of a\n10.1.3 Extracting generalities with zero-shot prompting\nZero-shot prompting or learning is the ability to generate a prompt in such a manner that\ndemonstrated through zero-shot prompting, where no examples are given, but instead a\nOpen prompt_flow/zero-shot-prompting/flow.dag.yaml in the VS Code prompt\nLLM from outputting \nLLM: zero_shot (the prompt used to classify)\noutputs: the predicted class given the statement\nEmbeddings: uses an LLM embedding model to create the embedding \nEmbedding_predicted: embeds the output of the zero_shot LLM\nEmbedding_expected: embeds the output of the expected answer\nOutputs: the similarity score between predicted and expected\npredicted: -> output.few_shot\nRun the flow by pressing Shift-F5 within the VS Code prompt flow visual editor.\nNow open the zero_shot.jinja2 prompt as shown in listing 10.6.\nThe prompt is\nzero-shot-prompting flow\nLLM to classify\nZero-shot prompt engineering is about using the ability of the LLM to generalize\nReasoning in prompt engineering\nWhile an LLM isn’t designed to reason, the training material fed into\nfore, by extension, an LLM understands what reasoning is and can employ the con-\napplication of reasoning, we look to having the LLM solve challenging problems it\nOur goal is to acquire the ability to prompt the LLM\nThe example in figure 10.3 is complicated to solve for an LLM, but the part it\nReasoning in prompt engineering\nThe next section will use reasoning in prompts to solve\nThrough the demonstration of reasoning, the LLM can\nLLM isn’t trained with the goal of reasoning, we can elicit the model to reason, using\nOpen prompt_flow/chain-of-thought-prompting/flow.dag.yaml in the VS Code\nprompt flow visual editor.\nWith only two LLM blocks, the flow first uses a CoT prompt to solve a complex ques-\ntion; then, the second LLM prompt evaluates the answer.\ninputs/outputs of the flow in more detail.\nJumps back in time 100 years (3 days before the battle)\nThe complexity of the time travel problems we intend to solve using LLMs with reasoning and ",
      "keywords": [
        "LLM",
        "LLM embedding model",
        "LLM prompt",
        "prompt",
        "Code prompt flow",
        "flow",
        "LLM embedding",
        "output",
        "expected",
        "Embedding",
        "question",
        "LLMs",
        "statement",
        "prompt flow visual",
        "prompt flow"
      ],
      "concepts": [
        "prompts",
        "llm",
        "questions",
        "outputs",
        "outputting",
        "statement",
        "similarity",
        "listing",
        "evaluation",
        "evaluate"
      ],
      "similar_chapters": [
        {
          "book": "AI Agents In Action",
          "chapter": 28,
          "title": "",
          "score": 0.758,
          "base_score": 0.608,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 7,
          "title": "",
          "score": 0.712,
          "base_score": 0.562,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 32,
          "title": "",
          "score": 0.663,
          "base_score": 0.513,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 30,
          "title": "",
          "score": 0.636,
          "base_score": 0.486,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 33,
          "title": "",
          "score": 0.548,
          "base_score": 0.398,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "llm",
          "flow",
          "prompt",
          "question",
          "answer"
        ],
        "semantic": [],
        "merged": [
          "llm",
          "flow",
          "prompt",
          "question",
          "answer"
        ]
      },
      "topic_id": 1,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.33604794186421594,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:00:43.646482+00:00"
      }
    },
    {
      "chapter_number": 32,
      "title": "Segment 32 (pages 278-287)",
      "start_page": 278,
      "end_page": 287,
      "summary": "LLM: cot (the prompt used to solve the problem)\noutputs: the predicted answer given the problem statement\nLLM: evaluate_answer (the prompt used to evaluate the solution)\noutputs: a score of how well the problem was answered\nchain-of-thought-prompting flow\nLLM prompt that uses chain of\nLLM prompt that evaluates\nReasoning in prompt engineering\nevaluation_score: output.evaluate_answer\nOpen the cot.jinja2 prompt file as shown in listing 10.8.\nexamples of time travel problems and then the thought-out and reasoned solution.\nThe process of showing the LLM the steps to complete the problem provides the rea-\nproblem\nsteps and output.\nproblem \nto the problem \nreasoning steps\ntime by 50 years and stays there for 20 days.\nInitial Travel: Alex arrives three days before the battle starts.\nTime Spent Before Time Jump: Alex spends six days in the past.\nFirst Time Jump: Alex jumps 50 years forward and stays for 20 days.\nThink step by step but only show the final answer to the statement.\nabout the problem.\nFrom this, you can see the reasoning steps the LLM applied to get\nNow, we can look at the prompt that evaluates how well the solution solved the\nproblem.\nOpen evaluate_answer.jinja2, shown in listing 10.9, to review the prompt\nproblem \nto the problem \nreasoning steps\nThe problem statement the \nReasoning in prompt engineering\nLooking at the LLM output shown earlier in listing 10.7, you can see why the evalua-\nanother example of prompt reasoning.\nAs our time travel demonstrates, CoT prompting can be expensive in terms of prompt\nOpen prompt_flow/zero-shot-cot-prompting/flow.dag.yaml in the VS Code\nLLM: cot (the prompt used to solve the problem)\noutputs: the predicted answer given the problem statement\nLLM: evaluate_answer (the prompt used to evaluate the solution)\noutputs: a score of how well the problem was answered\nzero-shot-CoT-prompting flow\nproblem \nevaluation_score: output.evaluate_answer\nOpen the cot.jinja2 prompt in VS Code, as shown in listing 10.11.\nprompt Let’s think step by step triggers the LLM to consider internal context show-\nThis, in turn, directs the LLM to reason out the problem in steps.\nYou are an expert in solving time travel problems.\nYou are given a time travel problem and you have to solve it.\n10.2.3 Step by step with prompt chaining\nprompts that force the LLM to solve the problem in steps.\ntechnique called prompt chaining that forces an LLM to process problems in steps.\nsolve a problem into chains of prompts.\nproblem in terms of steps.\nsteps have been \nThe problem \nReasoning in prompt engineering\nThis flow chains the output of the first LLM block into the second and then\nLLM: decompose_steps (the prompt used to decompose the problem)\noutputs: the breakdown of steps to solve the problem\nLLM: calculate_steps (the prompt used to calculate the steps)\noutputs: the calculation for each step\nprompt-chaining flow\noutput for each step.\nsolution using the steps.\nthe problem into steps.\nThe prompt chaining flow\nof prompts\ninto this step\nLLM: calculate_solution (attempts to solve the problem)\noutputs: the final solution statement\n\"solution\": \"Alex spends 13 days in the \nsee all the work the LLM is doing to reason out the problem.\nOpen up all three prompts: decompose_steps.jinja2, calculate_steps.jinja2,\nAll three prompts shown in the listings can be compared to show how outputs chain\nYour job is to break the users problem down into smaller steps and list \nDo not attempt to solve the problem, just list the steps.\nYou will be given a list of steps that solve a problem.\ninto this step\nlist only the steps \njust list output for each of the steps.\n{{steps}}    \nYou will be given a list of steps and the calculated output for each step.\nUse the calculated output from each step to determine the final \nsolution to the problem.\nProvide only the final solution to the problem in a \n{{steps}}    \nthe evaluation, we can see that this sequence of prompts still has problems solving our\nmore challenging time travel problem shown earlier in figure 10.3.\nsolve such complex problems consistently.\nproblem, just the steps\nand not any steps\n10.3.1 Evaluating self-consistency prompting\nSelf-consistent prompting is the technique of generating multiple plans/solutions for\nOpen prompt_flow/self-consistency-prompting/flow.dag.yaml in the VS Code\nprompt flow provides a batch processing mechanism, we can use that to simulate\nOpen the self-consistency-prompting/cot.jinja2 prompt template in VS\nprompting\nprompt uses two (few-shot prompt) examples of a CoT to demonstrate the thought\nself-consistency-prompting/cot.jinja2\nprompt that is\nThe self-consistency prompt generation beside the evaluation flow",
      "keywords": [
        "LLM",
        "problem",
        "steps",
        "prompt",
        "Max",
        "statement",
        "problem statement",
        "days",
        "Output",
        "problem statement LLM",
        "LLM prompt",
        "years",
        "time travel problem",
        "flow",
        "solution"
      ],
      "concepts": [
        "prompt",
        "reasoning",
        "steps",
        "listing",
        "outputs",
        "year",
        "problem",
        "statements",
        "solution",
        "days"
      ],
      "similar_chapters": [
        {
          "book": "AI Agents In Action",
          "chapter": 31,
          "title": "",
          "score": 0.663,
          "base_score": 0.513,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 7,
          "title": "",
          "score": 0.567,
          "base_score": 0.417,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 30,
          "title": "",
          "score": 0.515,
          "base_score": 0.365,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 28,
          "title": "",
          "score": 0.495,
          "base_score": 0.345,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 29,
          "title": "",
          "score": 0.453,
          "base_score": 0.303,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "problem",
          "steps",
          "prompt",
          "cot",
          "solution"
        ],
        "semantic": [],
        "merged": [
          "problem",
          "steps",
          "prompt",
          "cot",
          "solution"
        ]
      },
      "topic_id": 1,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.2554232965895098,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:00:43.646513+00:00"
      }
    },
    {
      "chapter_number": 33,
      "title": "Segment 33 (pages 288-295)",
      "start_page": 288,
      "end_page": 295,
      "summary": "Open the self-consistency-prompting/flow.dag.yaml file in VS Code.\nListing 10.17 shows the JSON output from executing the flow in batch mode.\n\"name\": \"self-consistency-prompting_default_20240203_100322_912000\",\n\"display_name\": \"self-consistency-prompting_variant_0_202402031022\",\n\"flow_path\": \"…prompt_flow/self-consistency-prompting\",    \n\"output_path\": \"…/.promptflow/.runs/self-\n➥ consistency-prompting_default_20240203_100322_912000\",    \n\"prompt_tokens\": 3635,\n\"flow_name\": \"self-consistency-prompting\",\n\"data\": \"…/prompt_flow/self-consistency-prompting/\n\"output\": \"…/.promptflow/.runs/self-consistency-\n➥ prompting_default_20240203_100322_912000/flow_outputs\"\nfolder with all the output from the run.\nFortunately, the evaluation feature in prompt flow can help us identify consis-\nOpen self-consistency-evaluation/flow.dag.yaml in VS Code (see figure\nmine the most consistent answer.\nFrom the flow, open consistency.py in VS Code, as shown in listing 10.18.\ncode for this tool function calculates the cosine similarity for all pairs of answers.\nThen, it finds the most similar answer, logs it, and outputs that as the answer.\nself-consistency-prompting batch execution output\noutputs of the flow \ndef consistency(texts: List[str],\nWe need to run the evaluation flow in batch mode as well.\nevaluation/flow.dag.yaml in VS Code and run the flow in batch mode (beaker\nThen, select Existing Run as the flow input, and when prompted, choose the\ntop or the last run you just executed as input.\nAgain, after the flow completes processing, you’ll see an output like that shown in\nCtrl-click on the output folder link to open a new instance of VS Code\nfew more batch runs of the prompt and/or increase the number of runs in a batch\nand then evaluate flows to see if you get better answers.\nSelf-consistency uses a reflective approach to evaluate the most likely thought.\n10.3.2 Evaluating tree of thought prompting\nevaluations.\nUnfortunately, due to the DAG execution pattern of prompt flow, we can’t\nThe VS Code is open to the batch run output folder.\nthe output showing the most similar answer.\nOpen tree-of-thought-evaluation/flow.dag.yaml in VS Code.\nThis flow functions like a breadth-first ToT pattern—the\nflow chains together a series of prompts asking the LLM to return multiple plans at\nBecause the flow executes in a breadth-first style, each level output of the nodes is also\nevaluated.\nEach node in the flow uses a pair of semantic functions—one to generate\nthe answer and the other to evaluate the answer.\nPython flow block that processes multiple inputs and generates multiple outputs.\nthe SK for direct use within prompt flow.\nthe output of the answer.\nToT pattern expressed and prompt flow\nevaluation_function: str,\nevaluation = kernel.create_semantic_function(\nevaluation_function,        \nfunction_name=\"Evaluation\",\nThe semantic function tool is used in the tree’s experts, nodes, and answer blocks.\neach step, the function determines if any text is being input.\nevaluation function\nRuns the evaluate function and\nThis may be a complex pattern to grasp at first, so go ahead and run the flow in VS\nListing 10.20 shows just the answer node output of a run; these results may vary\nNodes that return no text either failed evalu-\nThe output in listing 10.20 shows how only a select set of nodes was evaluated.\ncases, the evaluated nodes returned an answer that could be valid.\nnodes all return empty, the parent node fails to evaluate.\nThe execution of this flow can take up to 27 calls to an LLM to generate an output.\nPrompting\nOutput from tree-of-thought-evaluation flow\nanswer 2 failed evaluation\nto evaluate and wasn’t run.\nObjective—Develop an evaluation prompt that asks the LLM to predict the out-\n– Create a follow-up prompt that evaluates the LLM’s prediction for accuracy\nChain of thought prompting guides the LLMs through a reasoning process step\nSelf-consistency is a prompt technique that generates multiple solutions to a\nproblem and selects the most consistent answer through evaluation, emphasiz-\nTree of thought prompting combines self-evaluation and prompt chaining to",
      "keywords": [
        "flow",
        "answer",
        "output",
        "Run",
        "evaluation",
        "prompt",
        "LLM",
        "Code",
        "function",
        "batch",
        "Batch Run",
        "prompt flow",
        "batch run output",
        "step",
        "input"
      ],
      "concepts": [
        "prompted",
        "evaluation",
        "evaluating",
        "evaluations",
        "evaluates",
        "flow",
        "answer",
        "output",
        "functions",
        "functionality"
      ],
      "similar_chapters": [
        {
          "book": "AI Agents In Action",
          "chapter": 28,
          "title": "",
          "score": 0.724,
          "base_score": 0.574,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 30,
          "title": "",
          "score": 0.699,
          "base_score": 0.549,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 7,
          "title": "",
          "score": 0.602,
          "base_score": 0.452,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 31,
          "title": "",
          "score": 0.548,
          "base_score": 0.398,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 32,
          "title": "",
          "score": 0.445,
          "base_score": 0.295,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "flow",
          "consistency",
          "self consistency",
          "self",
          "answer"
        ],
        "semantic": [],
        "merged": [
          "flow",
          "consistency",
          "self consistency",
          "self",
          "answer"
        ]
      },
      "topic_id": 1,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.23436025090339052,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:00:43.646542+00:00"
      }
    },
    {
      "chapter_number": 34,
      "title": "Segment 34 (pages 296-303)",
      "start_page": 296,
      "end_page": 303,
      "summary": "Agent planning\nNow that we’ve examined how large language models (LLMs) can reason and plan,\nPlanning should be at the core of any agent/assistant platform\nOpenAI Assistants platform, which automatically incorporates planning.\nagents and assistants\nactions\nPlanning: The essential tool for all agents/assistants\nPlanning: The essential tool for all agents/assistants\nAgents and assistants who can’t plan and only follow simple interactions are nothing\nFigure 11.1 explains the overall planning process that the agent/assistant will\ntakes the goal, constructs the plan, executes it, and then returns the results.\nand others, you may have already encountered a planning assistant and not even noticed.\nAgent interface layer (natural language)\nPlanning: Agent takes the goal and breaks it into tasks.\nThe agent planning process\nAgent planning and feedback\nplan and an agent that can.\nFor the next exercise, we’ll use Nexus to demonstrate how raw LLMs can’t plan\nYou can’t use LM Studio unless the model/server supports tool/action use.\nCreating a new agent in Nexus\n1. Select to create a new agent.\n2. Name your agent.\nwith your agent,  you will need\nPlanning: The essential tool for all agents/assistants\nAfter creating the agent, we want to give it specific actions (tools) to undertake or\nGenerally, providing only the actions an agent needs to complete its\nMore actions can confuse an agent into deciding which to use or even how to\nAgents may use your actions in ways you didn’t intend unless that’s your goal.\nagents will operate independently and may perform any action.\nWatching an agent emerge new behaviors using actions can\nSearch Wikipedia for pages on {topic} and download each page and save it \nThis goal will demonstrate the following actions:\nSet the actions on the agent, as shown in figure 11.3.\nAfter you choose the actions and planner, enter the goal in listing 11.2.\nDemonstrating planning: The goal \nAgent planning and feedback\nFigure 11.4 shows the results of submitting the goal to the plain agent.\nagent executed the tool/action to search for the topic but couldn’t execute any\nsequential or planned actions.\nSelecting the actions for the agent and disabling the planner\nAnthropic’s Claude and OpenAI Assistants support sequential action planning.\nmeans both models can be called with sequential plans, and the model will execute them\nIn the next section, we’ll explore sequential planning and then\nIn the next exercise, we’ll ask an OpenAI assistant to solve the same goal.\nFigure 11.5 shows the difference between executing tasks sequentially (planning)\nThese advanced tools already incorporate plan-\nform of planning and tool use.\nLet’s open the GPT Assistants Playground to demonstrate sequential planning in\naction.\nbut, this time, run it against an assistant (which has built-in planning).\nThe results from trying to get the agent/LLM to complete the goal\nAgent planning and feedback\nwikipedia, get_wikipedia_page, and save_file actions.\nof entering the goal to the assistant.\nanother task, summarizing each page, to the goal.\nNow that we understand how LLMs function without planners and plan-\nSequential execution of a goal\nTasks/plan\nthe agent.\nagent asks to continue to the\nThe agent\n(planned)\nThe difference between iterative and planned execution\nengineering strategies that incorporate planning and reasoning.\nThe assistant processing the goal and outputting the results",
      "keywords": [
        "Agent",
        "planning",
        "goal",
        "Wikipedia",
        "Agent planning",
        "actions",
        "assistant",
        "Nexus",
        "search",
        "save",
        "n’t",
        "LLM",
        "sequential",
        "tool"
      ],
      "concepts": [
        "plan",
        "planned",
        "agents",
        "actions",
        "goal",
        "assistants",
        "assistance",
        "uses",
        "model",
        "tool"
      ],
      "similar_chapters": [
        {
          "book": "AI Agents In Action",
          "chapter": 36,
          "title": "",
          "score": 0.878,
          "base_score": 0.728,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 2,
          "title": "",
          "score": 0.816,
          "base_score": 0.666,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 4,
          "title": "",
          "score": 0.791,
          "base_score": 0.641,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 15,
          "title": "",
          "score": 0.758,
          "base_score": 0.608,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 35,
          "title": "",
          "score": 0.758,
          "base_score": 0.608,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "planning",
          "agent",
          "goal",
          "actions",
          "agent planning"
        ],
        "semantic": [],
        "merged": [
          "planning",
          "agent",
          "goal",
          "actions",
          "agent planning"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.4328382158582544,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:00:43.646582+00:00"
      }
    },
    {
      "chapter_number": 35,
      "title": "Segment 35 (pages 304-312)",
      "start_page": 304,
      "end_page": 312,
      "summary": "Agent planning and feedback\nEach subtask must be from within the [AVAILABLE FUNCTIONS] list.\nuse any functions that are not in the list.\nname of the function.\nfeedback from previous plans to help you make your decision.\ndescription: execute a function for each item in a list\n{\"function\": \"for-each\",\n\"function\": \ndescription: execute a function for each item in a list\nBe sure to only use functions from the list of available functions.\nbuilding a planning prompt, submitting it to an LLM to construct the plan, parsing\nand executing the plan locally, returning the results to an LLM to evaluate and sum-\nplan is built in isolation by not adding context history.\ngoal because most planning prompts consume many tokens.\nExecuting the functions\nListing 11.4 shows the code for the create_plan function from the BasicNexus-\nThe goal and available functions list are then inserted into\nfunction\nagent’s list of available \nfunctions.\nAgent planning and feedback\ndef create_plan(self, nexus, agent, goal: str, prompt: str = PROMPT) -> Plan:\nbasic_nexus_planner.py (create_plan)\nThe planning prompt\nfunctions and the goal to\nThe plan\nResults of executed goal\nplanning prompt.\nEach step of the plan is executed,\nto execute the actions/functions.\nPlanning prompt\nThe planning process for creating and executing a plan\nplan_text = nexus.execute_prompt(agent, prompt)    \nreturn Plan(prompt=prompt, \nThe code to execute the plan, shown in listing 11.5, parses the JSON string and exe-\nWhen executing the plan, the code detects the particular for-each\nfunction, which iterates through a list and executes each element in a function.\nresults of each function execution are added to the context.\neach function call and returned as the final output.\ndef execute_plan(self, nexus, agent, plan: Plan) -> str:\nfor task in plan[\"subtasks\"]:    \nresult = nexus.execute_task(agent, inner_task, context)\ncontext[f\"for-each_{list_name}_{item}\"] = result\ncontext[f\"for-each_{list_name}\"] = for_each_output\nresult = nexus.execute_task(agent,\ncontext[f\"output_{task['function']}\"] = result\nbasic_nexus_planner.py (execute_plan)\nThe results (the plan) are wrapped in a \nPlan class and returned for execution.\nsubtask in the plan\nthe results of each function call\nAgent planning and feedback\nThe returned context from the entire execution is sent in a final call to the LLM,\nagent you used last time, but select the planner under the Advanced options this time,\nber, though, that plan execution is done at the local level, and only context, plan, and\nThe agent will execute the tasks and\nThe results from requesting to complete the goal in Nexus using the basic planner\nThis means that plan execution can be completed by any process, not necessarily\nExecuting a plan outside the LLM reduces the tokens and tool use the\nInstead, the planner completes the action execution, and the agent is only\nmodels that support tool use but can’t plan.\nity for models that support both tool use and planning, such as Claude.\ncomplete a multistep goal with and without planning enabled, and then see the results.\nPlanning allows agents to complete multiple sequential tasks to achieve more com-\nThe problem with external or prompt planning is that it bypasses the feed-\nand others are now directly integrating reasoning and planning at the LLM level, as\ntion tasks but also able to engage in reasoning, planning, evaluation, and feedback\nConsider our time travel problem from chapter 10 and shown again in figure 11.9.\nHowever, after spending six days in the past, he jumps forward in time \nTime travel reasoning/planning problem\nAgent planning and feedback\nAlex arrives 3 days before the battle begins.\nAfter these 6 days, Alex jumps 50 years forward in time.\nHe spends 20 days in this future time.\nAlex then returns to the past to witness the end of the battle.\nremaining 7 days of the battle, he must return to a point in time before \nTo see the end of the battle, he returns to the past on the last day of \no1-preview response to time travel problem\nHowever, after spending six days in the past, he jumps forward in time by\nJumps back in time 100 years (3 days before the battle)\nto what time Alex returns\nThe time travel problem, revisited\nUpon returning, he spends 1 more day in the past to witness the battle's \n6 days before jumping forward in time.\nlike this can happen when we remove feedback in LLM interactions and agentic sys-\ndoesn’t spend the day to witness the battle) and assumed the LLM or agent was cor-\nengage the LLM in reasoning and planning feedback.\nreasoning and planning within the model.\nate constructive feedback from the LLM concerning our time travel problem.\nListing 11.9 shows an example of the feedback provided by o1-preview.\ncomplex time travel problems.\nAgent planning and feedback\nhow the application of reasoning, planning, evaluation, and feedback can be\nIn recent chapters, we’ve examined how the agentic components of planning, reason-\nlook at how planning can be integrated into assistant/agentic systems.\n11.5.1 Application of assistant/agentic planning\nPlanning is the component where an assistant or agent can plan to undertake a set of",
      "keywords": [
        "LLM",
        "plan",
        "time",
        "list",
        "function",
        "battle",
        "days",
        "FUNCTIONS",
        "Agent",
        "planning",
        "feedback",
        "goal",
        "context",
        "Alex",
        "prompt"
      ],
      "concepts": [
        "plan",
        "planned",
        "list",
        "time",
        "feedback",
        "functions",
        "function",
        "functional",
        "agents",
        "context"
      ],
      "similar_chapters": [
        {
          "book": "AI Agents In Action",
          "chapter": 34,
          "title": "",
          "score": 0.758,
          "base_score": 0.608,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 23,
          "title": "",
          "score": 0.65,
          "base_score": 0.5,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 36,
          "title": "",
          "score": 0.648,
          "base_score": 0.498,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 21,
          "title": "",
          "score": 0.641,
          "base_score": 0.491,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 38,
          "title": "",
          "score": 0.621,
          "base_score": 0.471,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "planning",
          "plan",
          "time",
          "feedback",
          "days"
        ],
        "semantic": [],
        "merged": [
          "planning",
          "plan",
          "time",
          "feedback",
          "days"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.37109413006294456,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:00:43.646623+00:00"
      }
    },
    {
      "chapter_number": 36,
      "title": "Segment 36 (pages 313-321)",
      "start_page": 313,
      "end_page": 321,
      "summary": "Applying planning, reasoning, evaluation, and feedback to assistant and agentic sys-\ntant or agent deployed to assist in some capacity.\nessential to these new assistants/agents to coordinate numerous complex tasks\nAutonomous agent—As we’ve seen in previous chapters, agents with the ability to\nan essential element of any autonomous agentic system.\nCollaborative workflows—Think of these as agents or assistants that sit alongside\na workflow where agents are automatically tasked with writing and executing\nagent\nagent prompt \nagent and/or \nagent or LLM\nAgent planning and feedback\nimagine in-game agents or assistants that can assist or challenge the player.\ning these agents the ability to plan and execute complex workflows could dis-\nResearch—Similar to collaborative workflows, these agents will be responsible\nAs you can see, planning is an essential part of many LLM applications, whether\n11.5.2 Application of assistant/agentic reasoning\nReasoning, while often strongly associated with planning and task completion, is a\nagent\nagent prompt \nagent or LLM\nApplying planning, reasoning, evaluation, and feedback to assistant and agentic sys-\ntant or agent deployed to assist in some capacity.\nagent employs may be limited.\nWhile this may limit the complexity at which an agent\nagents, we still don’t know how much reasoning is too much.\nStrawberry become available for agentic workflows, we can gauge at what\nwell-defined autonomous agent workflows.\neral tactical agents.\nagents that may provide more strategic control.\nsider the agent pillar of evaluation of various applications.\n11.5.3 Application of evaluation to agentic systems\nEvaluation is the component of agentic/assistant systems that can guide how well the\nWhile we demonstrated incorporating evaluation in some agentic\nworkflows, evaluation is often an external component in agentic systems.\nAgent planning and feedback\ntant or agent deployed to assist in some capacity.\nand guide the performance of agent responses.\nWhen and where evaluation is employed and used in various applications\nagent system\nagent\nagent or evalu-\nagent or another \nagent\nApplying planning, reasoning, evaluation, and feedback to assistant and agentic sys-\nAutonomous agent—In most cases, a manual review of agent output will be a pri-\nmary guide to the success of an autonomous agent.\ninternal evaluation can help guide the agent when it’s undertaking complex\nMultiple agent systems, such\nas CrewAI and AutoGen, are examples of autonomous agents that use internal\nfeedback to improve the generated output.\nreal time correct the assistant/agent by evaluating the output.\nagents could be added similarly to autonomous agents for more extensive\nevaluating how the agent interacts with the game—and in-game evaluation, evalu-\nating how well an agent succeeded at a task.\nform is similar to autonomous agents but aims to improve some strategies or\nAn agent could employ some form of evaluation simi-\nlar to autonomous agents to improve the generated output, perhaps even\nBecause this is currently a new area for agentic develop-\nEvaluation is an essential element to any agentic or assistant system, especially if that\ntems for agents and assistants is likely something that could or should have its own\n11.5.4 Application of feedback to agentic/assistant applications\nFeedback as a component of agentic systems is often, if not always, implemented as\nTable 11.4 showcases how feedback can be implemented into various LLM\nAgent planning and feedback\nTable 11.4 shows several application scenarios in which we may find an assistant or agent\nprovides more details about how feedback may be employed in each application:\nPersonal assistant—If the assistant or agent interacts with the user in a chat-style\ndevelops within agentic memory.\nCustomer service bot—User or system feedback is typically provided through a survey\nto an external system that aggregates the feedback for later improvements.\nAutonomous agent—Much like bots, feedback within autonomous agents is typi-\ncally regulated to after the agent has completed a task that a user then reviews.\nWhen and where feedback is employed and used in various applications\nagent system\nagent\nthe agent or \nanother agent\nApplying planning, reasoning, evaluation, and feedback to assistant and agentic sys-\nagentic memory.\ntional and multiple agents.\nAI that can evaluate its actions, improve those with feedback, and remember\nResearch—Similar to evaluation in the context of research, feedback is typically\nbeen done using multiple agent systems incorporating agents for evaluation\nFeedback is another powerful component of agentic and assistant systems, but it’s not\nevaluation mechanisms can greatly benefit agentic systems in the long term concern-\nHow you implement each of these components in your agentic systems may, in\npart, be guided by the architecture of your chosen agentic platform.\nyou in selecting the right agent system that fits your application and business use case.\nRegardless of your application, you’ll want to employ several agentic components in\nAs agentic systems mature and LLMs themselves get smarter, some of the compo-\nhow we undertake it through agents.\nAgent planning and feedback\nExercise 1—Implement a Simple Planning Agent (Beginner)\nObjective—Learn how to implement a basic planning agent using a prompt to\n– Create an agent that receives a goal, breaks it into steps, and executes those\n– Implement the agent using a basic planner prompt (refer to the planner\n– Run the agent, and evaluate how well it plans and executes each step.\nExercise 2—Test Feedback Integration in a Planning Agent (Intermediate)\nof an agentic system.\n– Modify the agent from exercise 1 to include a feedback loop after each task.\n– Use the feedback to adjust or correct the next task in the sequence.\n– Test the agent by giving it a more complex task, such as gathering data from\n– Document and compare the agent’s behavior before and after adding feedback.\nhow they affect agent behavior.\n– Set up two agents using Nexus: one that executes tasks in parallel and another\n– Compare the performance and output of both agents, noting any errors or\nObjective—Learn how to build a custom planner and integrate it into an agent\n– Integrate this planner into Nexus, and create an agent that uses it.\nExercise 5—Implement Error Handling and Feedback in Sequential Planning\ntial planning in an agentic system.\n– Using a sequential planner, set up an agent to perform a goal that may encoun-\n– Add feedback loops to adjust the plan or retry actions based on the error\nhow the agent recovers or adjusts its plan.\nPlanning is central to agents and assistants, allowing them to take a goal, break\nWithout planning, agents are reduced to simple\nFeedback is crucial in guiding agents to correct their course and improve per-\nbe integrated with agents to refine their decision-making processes.\nplanning and can execute complex, multistep tasks.\nAgents using these plat-\nforms can use sequential action planning for sophisticated workflows.\nProperly selecting and limiting agent actions is vital to avoid confusion and\nToo many actions may overwhelm an agent, while unnec-\nbetween a raw LLM and a planner-enhanced agent.",
      "keywords": [
        "agent",
        "LLM",
        "feedback",
        "planning",
        "application",
        "LLM applications",
        "evaluation",
        "Autonomous agent",
        "reasoning",
        "assistant",
        "external",
        "agentic",
        "system",
        "Personal assistant",
        "Agent planning"
      ],
      "concepts": [
        "agent",
        "evaluation",
        "evaluate",
        "evaluating",
        "evaluations",
        "feedback",
        "tasked",
        "planning",
        "plan",
        "external"
      ],
      "similar_chapters": [
        {
          "book": "AI Agents In Action",
          "chapter": 34,
          "title": "",
          "score": 0.878,
          "base_score": 0.728,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 2,
          "title": "",
          "score": 0.84,
          "base_score": 0.69,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 5,
          "title": "",
          "score": 0.827,
          "base_score": 0.677,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 4,
          "title": "",
          "score": 0.796,
          "base_score": 0.646,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 3,
          "title": "",
          "score": 0.776,
          "base_score": 0.626,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "agent",
          "feedback",
          "agentic",
          "planning",
          "evaluation"
        ],
        "semantic": [],
        "merged": [
          "agent",
          "feedback",
          "agentic",
          "planning",
          "evaluation"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.42949124907821823,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:00:43.646663+00:00"
      }
    },
    {
      "chapter_number": 37,
      "title": "Segment 37 (pages 322-331)",
      "start_page": 322,
      "end_page": 331,
      "summary": "this book recommends using OpenAI services directly or through Azure OpenAI\nAccessing OpenAI accounts and keys\nThe following general steps can help you quickly set up using OpenAI LLMs for agent\nAccessing OpenAI large language models\nOpen the left menu, and select the API Keys option, as shown in figure A.2.\nAccessing OpenAI accounts and keys\nClick the Create button to create a new key, enter a name for the key, and click\nthe Create Secret Key button, as shown in figure A.3.\nthrough other means of registering an OpenAI key.\nthis book, configuring OpenAI will generally only require the key.\nsuch as Azure OpenAI, will require the configuration of a model deployment and a\nAccessing OpenAI large language models\nAzure OpenAI Studio, keys, and deployments\nsion behind, but Microsoft generally keeps current with the latest OpenAI models.\nAzure and methods of creating accounts and accessing the studio (for specific instruc-\nCreate a new Azure OpenAI Studio resource in a region that makes sense to\nWithin Azure OpenAI, models are exposed through a resource allocation\nDeployments wrap a model, such as GPT-4, and provide\nselect the model you want to deploy.\nClick to create the key.\nAzure OpenAI Studio, keys, and deployments\nAfter the model is wrapped in a deployment, you must access the parent Azure\nThe api key to access the model\nmodels.\nOpenAI model\nDeploying a model through an Azure OpenAI Studio deployment\nAccessing OpenAI large language models\nTo download and run the source code, install Git, and then pull the repository\ninstall VS Code or understand how to load a chapter folder as a workspace, con-\nInstalling Python\nthe standard Python installation, version 3.10.\nWe’ll also confirm the installation when setting up VS Code.\nInstalling VS Code\nInstalling VS Code is relatively straightforward and can be done in just a few steps:\nWith VS Code running, we can install the necessary extensions.\nInstalling VS Code Python extensions\nThousands of extensions for VS Code can provide an excellent Python coding envi-\nWhen installing\nTo install the extensions, follow these steps:\nInstalling VS Code Python extensions\nLaunch VS Code, and open the Extensions panel, as shown in figure B.1.\nInstall the following list of extensions:\n– Python Extension Pack, for covering other extensions\n– Python Indent, for code formatting\nYou’ll only need to install the extensions for each VS Code environment you’re run-\nHowever, if you run VS Code in containers, you must install extensions for\nInstalling VS Code extensions",
      "keywords": [
        "Azure OpenAI Studio",
        "code",
        "Azure OpenAI",
        "OpenAI",
        "Python",
        "Code Python extensions",
        "key",
        "OpenAI Studio",
        "Azure",
        "extensions",
        "model",
        "Code Python",
        "API",
        "Studio",
        "appendix"
      ],
      "concepts": [
        "openai",
        "python",
        "extensions",
        "extension",
        "install",
        "code",
        "coding",
        "keys",
        "key",
        "models"
      ],
      "similar_chapters": [
        {
          "book": "AI Agents In Action",
          "chapter": 6,
          "title": "",
          "score": 0.59,
          "base_score": 0.44,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 15,
          "title": "",
          "score": 0.565,
          "base_score": 0.415,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 34,
          "title": "",
          "score": 0.559,
          "base_score": 0.409,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 11,
          "title": "",
          "score": 0.537,
          "base_score": 0.387,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 19,
          "title": "",
          "score": 0.53,
          "base_score": 0.38,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "extensions",
          "azure",
          "openai",
          "azure openai",
          "openai studio"
        ],
        "semantic": [],
        "merged": [
          "extensions",
          "azure",
          "openai",
          "azure openai",
          "openai studio"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.2496621847531606,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:00:43.646699+00:00"
      }
    },
    {
      "chapter_number": 38,
      "title": "Segment 38 (pages 332-340)",
      "start_page": 332,
      "end_page": 340,
      "summary": "ABTs (agentic behavior trees) 143–152\ncoding challenge ABT 145–149\nand tools, agent platforms 174–179\nexecuting OpenAI functions 101–107\nactioning function calls 103–107\nnative functions 111–118\nsemantic functions 111–118\nsemantic functions 108–111\nassistant/agentic planning 288–290\nassistant/agentic reasoning 290–291\nevaluation to agentic systems 292–293\napplications 293–295\nimplementing memory in 200–207\nactions and tools 174–179\noverview of 161–164\nStreamlit 165–170\nbuilding chat applications 165–168\nevaluating 224–228\ndirect solution prompting 245–252\nfew-shot prompting 248–250\n246–248\ndefining 1–4\nexecuting OpenAI functions 101–107\nindexing 184–192\nplanning 273–277\nABTs (agentic behavior trees) 143–152\nPlayground 136–142\nassistant/agentic planning 288–290\nassistant/agentic reasoning 290–291\nevaluation to agentic systems 292–293\n293–295\n69–76\ndeciding on 132–134\ndeciding on 132–134\nChatGPT, engaging assistants through 40–44\ntree) 145–149\nbuilding agent crew with 84–90\n84–87\n87–90\nrevisiting coding agents with 90–95\ncustom actions 49–55\ncreating assistant to build assistant 49–53\ndirect solution prompting 245–252\nfew-shot prompting 248–250\nquestion and answer prompting 246–248\ndocument indexing 184–192\nsolutions 261–270\nToT prompting 266–270\napplications 293–295\n285–287\nusing 56–61\nuploads 58–61\nactioning function calls 103–107\nGPT Assistants Playground 136–142\nbuilding 44–48\nOpenAI Assistants 136–149\npublishing 61–65\nbuilding semantic interface 119–121\ncustomizing 49–55\n49–53\ngrounding 228–230\nas 118–125\n122–125\nbuilding agent knowledge 196–200\nuploads 56–61\nknowledge search with file uploads 58–61\nOpenAI API 16–20\nprompt engineering 25–34\nimplementing in agentic systems 200–207\nAutoGen 77–82\ninstalling and consuming 77–79\nbuilding agent crew with CrewAI 84–90\n84–87\n87–90\nrevisiting coding agents with CrewAI 90–95\nnative functions 111–118, 127\noverview of 161–164\nOpenAI API 16–20\n285–287\nplanning agents 273–277\nplugins, creating and registering 111–115\ncomparing 232–243\n238–241\nflow 235–238\nprompt chaining 258–261\nprompt engineering 9, 25–34\nreasoning in 252–261\nchain of thought prompting 253–257\n258–261\nagent profiles, evaluating 224–228\n238–241\nflow 235–238\nsetting up 217–224\nprerequisites 218–221\napplying to building agent knowledge 196–200\nin prompt engineering 252–261\nchain of thought prompting 253–257\nstep-by-step with prompt chaining 258–261\nplugins 111–115\nsemantic functions 111–115\nsemantic plugins 111–115\nsemantic skills 111–115\nskills 111–115\nrubrics 228–230\nsemantic functions 111–118, 127\ncreating and registering 111–115\nsemantic plugins, creating 111–115\nsemantic search 184–192\nsemantic skills, creating 111–115\ncreating 111–115\nregistering 111–115\nas interactive service agent 118–125\nlayer 122–125\nsemantic functions 108–111\nstep-by-step with prompt chaining 258–261\n285–287\nbuilding chat applications 165–168\noverview 165–170\nFrequency) 184–188\nTMDbService class 119–120, 122\n266–270",
      "keywords": [
        "Code Dev Containers",
        "Code",
        "agent",
        "semantic",
        "assistant",
        "Python",
        "Docker",
        "prompting",
        "Document Frequency",
        "function",
        "document",
        "Inverse Document Frequency",
        "functions",
        "Creating",
        "semantic functions"
      ],
      "concepts": [
        "agent",
        "assistants",
        "prompts",
        "creating",
        "create",
        "memory",
        "code",
        "coding",
        "file",
        "semantic"
      ],
      "similar_chapters": [
        {
          "book": "AI Agents In Action",
          "chapter": 2,
          "title": "",
          "score": 0.918,
          "base_score": 0.768,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 19,
          "title": "",
          "score": 0.756,
          "base_score": 0.606,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 34,
          "title": "",
          "score": 0.756,
          "base_score": 0.606,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 36,
          "title": "",
          "score": 0.753,
          "base_score": 0.603,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 15,
          "title": "",
          "score": 0.751,
          "base_score": 0.601,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "111",
          "115",
          "111 115",
          "semantic",
          "261"
        ],
        "semantic": [],
        "merged": [
          "111",
          "115",
          "111 115",
          "semantic",
          "261"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.4464746178908385,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:00:43.646760+00:00"
      }
    },
    {
      "chapter_number": 39,
      "title": "Segment 39 (pages 341-346)",
      "start_page": 341,
      "end_page": 346,
      "summary": "Multi-Agent Systems with AutoGen\n325 pages (estimated), $59.99\n350 pages (estimated), $49.99\n240 pages, $39.99\n464 pages, $59.99\nIn MEAP, the Manning Early Access Program, you can read \nMEAP customers are the first to get final versions of all books!\nExplore dozens of titles in MEAP at www.manning.com.\nliveBook, our online reading platform, adds a new dimension to your Manning books, \nwith features that make reading, learning, and sharing easier than ever.\nversion of your book is included FREE with every Manning book.\nThis next generation book platform is more than an online reader.\n• Learn from other readers in the discussion forum\n• Read all your purchased Manning content in any browser, anytime, anywhere\nAs an added bonus, you can search every Manning book and video in liveBook—even \nFind out more at www.manning.com/livebook-program.\nSequential execution of a goal\nIterative execution of a goal\nReturns the page content\nthe agent.\nagent asks to continue to the\nThe agent\nReturns the page content\nost production AI systems require many orchestrated \nAI agents capture and organize \nTh is book will show you how to create AI \nIn AI Agents in Action, you’ll learn how to build production\n-ready assistants, multi-agent systems, and behavioral agents.\nmulti-agent applications that can use software tools, plan tasks \n● Feedback loops for continuous agent learning\n● Collaborative multi-agent systems\nHe has authored books \non deep learning, including Manning’s Evolutionary Deep \nLearning.\nAI Agents IN ACTION\nthis book!”\nCouldn’t put this book \nI was learning from a \nTh is book transformed my \nand multi-agent systems.\nSee first page",
      "keywords": [
        "Code Dev Containers",
        "Visual Studio Code",
        "book",
        "Manning Early Access",
        "Code Dev",
        "Dev Containers",
        "Subsystem for Linux",
        "Code",
        "MEAP",
        "pages",
        "Early Access Program",
        "Studio Code",
        "learning",
        "INDEX",
        "Windows Subsystem"
      ],
      "concepts": [
        "agent",
        "learning",
        "book",
        "pages",
        "code",
        "systems",
        "prompting",
        "product",
        "production",
        "python"
      ],
      "similar_chapters": [
        {
          "book": "AI Agents In Action",
          "chapter": 1,
          "title": "",
          "score": 0.782,
          "base_score": 0.632,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 3,
          "title": "",
          "score": 0.568,
          "base_score": 0.418,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 2,
          "title": "",
          "score": 0.529,
          "base_score": 0.379,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 5,
          "title": "",
          "score": 0.528,
          "base_score": 0.378,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 15,
          "title": "",
          "score": 0.523,
          "base_score": 0.373,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "manning",
          "book",
          "learning",
          "99",
          "meap"
        ],
        "semantic": [],
        "merged": [
          "manning",
          "book",
          "learning",
          "99",
          "meap"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.2753872578212304,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:00:43.646798+00:00"
      }
    }
  ],
  "total_chapters": 39,
  "enrichment_provenance": {
    "taxonomy_id": "none",
    "taxonomy_version": "none",
    "taxonomy_path": "none",
    "taxonomy_checksum": "sha256:none",
    "source_metadata_file": "AI Agents In Action_metadata.json",
    "enrichment_date": "2025-12-17T23:00:43.651550+00:00",
    "enrichment_method": "msep",
    "model_version": "ai-agents-msep-v1",
    "processing_time_ms": 5140.315169001042,
    "total_similar_chapters": 195
  }
}