{
  "metadata": {
    "title": "Microservice APIs Using Python Flask FastAPI",
    "source_file": "Microservice APIs Using Python Flask FastAPI_metadata.json"
  },
  "chapters": [
    {
      "chapter_number": 1,
      "title": "introduces the main concepts of the book: microservices and APIs. It",
      "start_page": 23,
      "end_page": 23,
      "summary": "simple API, and explains how to design a microservices platform:\nChapter 1 introduces the main concepts of the book: microservices and APIs. It\nIt also explains what APIs\nChapter 3 explains how to design a microservices platform.\nPart 2 explains how to design, document, and build REST APIs, and how to build a\nChapter 4 explains the design principles of REST APIs. It introduces the six\nChapter 5 explains how to document a REST API using the OpenAPI specifica-\nChapter 6 explains how to build REST APIs using two popular Python frame-\nPart 3 explains how to design, consume, and build GraphQL APIs:\nChapter 8 explains how to design GraphQL APIs and how the Schema Defini-",
      "keywords": [
        "explains",
        "REST APIs",
        "APIs",
        "build REST APIs",
        "REST",
        "design",
        "microservices",
        "BOOK",
        "build REST",
        "introduces",
        "BOOK xxi",
        "build",
        "’ll",
        "learn",
        "REST API"
      ],
      "concepts": [
        "apis",
        "api",
        "chapters",
        "microservices",
        "schema",
        "design",
        "models",
        "rest",
        "fastapi",
        "build"
      ],
      "similar_chapters": [
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 9,
          "title": "",
          "score": 0.93,
          "base_score": 0.78,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 2,
          "title": "",
          "score": 0.916,
          "base_score": 0.766,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 382,
          "title": "",
          "score": 0.695,
          "base_score": 0.545,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 8,
          "title": "",
          "score": 0.68,
          "base_score": 0.53,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 4,
          "title": "",
          "score": 0.619,
          "base_score": 0.469,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "explains design",
          "explains",
          "chapter explains",
          "rest",
          "design"
        ],
        "semantic": [],
        "merged": [
          "explains design",
          "explains",
          "chapter explains",
          "rest",
          "design"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.3921902458669923,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:35.192774+00:00"
      }
    },
    {
      "chapter_number": 9,
      "title": "explains how to consume GraphQL APIs. You’ll learn to run a mock",
      "start_page": 24,
      "end_page": 28,
      "summary": "Chapter 9 explains how to consume GraphQL APIs. You’ll learn to run a mock\nChapter 10 explains how to build GraphQL APIs using Python’s Ariadne frame-\nYou’ll learn to leverage the API documentation to automatically load data\nPart 4 explains how to test, secure, and deploy your microservice APIs:\nChapter 11 explains how to add authentication and authorization to your APIs\nChapter 12 explains how to test and validate your APIs. You’ll learn what property-\nbased testing is and how to use it to test your APIs, and you’ll also learn to use\nChapter 13 explains how to Dockerize your microservice APIs, how to run them\nChapter 14 explains how to deploy your microservice APIs to AWS using Kuber-\nand in chapter 3, we break the platform down into microservices.\ncation and authorization to your APIs, you can jump straight into chapter 11, or if you\nwant to learn how to test APIs, you can go directly to chapter 12.\nAPIs, you should be able to skip directly to chapter 12.\nchapters in part 4.\nAbout the code\nThis book contains many examples of source code both in numbered listings and in\nlight code that has changed from previous steps in the chapter, such as when a new\nExcept for chapters 1, 3, and 4, every chapter of the book is full of coding exam-\nthe coding examples are in Python, except in chapters 5, 8, and 9, which focus on API\nbook at https://livebook.manning.com/book/microservice-apis.\nfor the examples in the book is available for download from the Manning website at\ngithub.com/abunuwas/microservice-apis.\nThe GitHub repository for this book shows the final state of the code in every\nchapter.\nthose cases, the version of the code you’ll find on GitHub matches the final version of\nthe code in the chapter.\nThe Python code examples in the book have been tested with Python 3.10, although\nThe code and the com-\nIn each chapter’s\nthat I used to run the code examples.\nPurchase of Microservice APIs includes free access to liveBook, Manning’s online reading\nTo access the forum, go to https://livebook.manning.com/book/microservice\nIf you want to learn more about microservice APIs, you can check out my blog, https://",
      "keywords": [
        "’ll learn",
        "APIs",
        "BOOK",
        "code",
        "microservice APIs",
        "learn",
        "chapters",
        "’ll",
        "GraphQL APIs",
        "API",
        "explains",
        "Python",
        "microservice",
        "source code",
        "build GraphQL APIs"
      ],
      "concepts": [
        "apis",
        "api",
        "chapters",
        "book",
        "code",
        "coding",
        "build",
        "discussion",
        "discussions",
        "graphql"
      ],
      "similar_chapters": [
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 1,
          "title": "",
          "score": 0.93,
          "base_score": 0.78,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 2,
          "title": "",
          "score": 0.828,
          "base_score": 0.678,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 8,
          "title": "",
          "score": 0.718,
          "base_score": 0.568,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 10,
          "title": "",
          "score": 0.658,
          "base_score": 0.508,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 382,
          "title": "",
          "score": 0.649,
          "base_score": 0.499,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "microservice",
          "chapter",
          "apis",
          "microservice apis",
          "book"
        ],
        "semantic": [],
        "merged": [
          "microservice",
          "chapter",
          "apis",
          "microservice apis",
          "book"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.40470573572878493,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:35.192846+00:00"
      }
    },
    {
      "chapter_number": 2,
      "title": "gives you a taste of building a REST API, and in the second part of this book,",
      "start_page": 29,
      "end_page": 73,
      "summary": "Microservice APIs\nMicroservices collaborate through APIs, and in this book, you’ll learn to\ndesign and build REST and GraphQL APIs for your microservices.\nyou’ll learn additional patterns and principles to build robust REST APIs. The\nent and the API server follow the API specification, and in chapter 1 you’ll learn\nAPI journey with a good and well-documented design.\nIntroducing Microservice APIs\nbuilding microservices and driving their integrations with APIs. In the rest of this\nmicroservice APIs?\nThis chapter defines the most important concepts in this book: microservices and\nAPIs. Microservices are an architectural style in which components of a system are\ndesigned as independently deployable services, and APIs are the interfaces that allow\nwhen designing, implementing, and operating microservices.\nWhat are microservice APIs?\nWhat are microservices?\nmicroservices compare with monolithic applications.\nSo, what are microservices?\nThis definition emphasizes the fact that microservices are applications that run\ndeveloping a single application as a suite of small services, each running in its own\nMicroservices are\nthis book, you will learn to design and build microservices that expose their capabilities\nWhat are microservices?\nthrough web APIs, though other types of interfaces are also possible, such as messag-\nOrders service\nIn microservices architecture, every service implements a specific business \nWhat are microservice APIs?\nOrders service\nOrders service\nOrders service\nWhat are microservices?\napplication using microservices, each microservice runs in a different process, often\nThey just did not call it microservices.\nout into independently deployable components, with an API in front of them.\nAPI.\nWhat are microservice APIs?\nHowever, microservices are not for everyone, and\nWhat are web APIs?\nIn this section, we will explain web APIs. You will learn that a web API is a specific\ninstance of the more general concept of an application programming interface (API).\nIt is important to understand that an API is just a layer on top of an application, and\nWhat is an API?\nAn API is an interface that allows us to programmatically interact with an application.\nWhat are web APIs?\nWe can also use cURL with the -O option in order to download the contents of a URL\nWhat is a web API?\nNow that we understand what an API is, we will explain the defining features of a web\nAPI.\nA web API is an API that uses the Hypertext Transfer Protocol (HTTP) protocol\naged by API technologies to enhance the interaction with the server, such as request\nWeb APIs are implemented\nHow do APIs help us drive microservices integrations?\nMicroservices communicate with each other using APIs, and therefore APIs represent\nAPIs are documented using standard protocols.\nyou can see in figure 1.4, API documentation represents a contract between services:\nAPI specifications \nthe API server and the API \nthe specification, the API \nWhat are microservice APIs?\nas long as both the client and the server follow the API documentation, communica-\nAs you can see in figure 1.5, web APIs exchange data through HTTP.\nport layer knows nothing about the specific API protocol we are using, and therefore\nGET /orders\nGET /orders\nOrders API\nAPI\nMicroservices \ncommunicate over APIs using \nAPIs must be stable, and behind them you can change the internal implementations\nof any service provided they comply with the API documentation.\nAPIs are and how they help us drive integrations between services, let’s look at the\nOne of the most important challenges when designing microservices is service decom-\nIn chapter 3, you’ll learn useful design patterns and service\nWhat are microservice APIs?\nYou can use different strategies to test microservices integrations.\nAPI.\nYou can test the API implementation against the API specification using tools\ndeliver the order, and any of those requests can fail at any point.\nservice, and to process the payment, the orders service works together with the\nIf payment is successful, the orders service makes a request to the kitchen ser-\nOnce the order has been produced, the kitchen service makes a request to the\n7 To learn more about API development workflows and how to use API mock servers to build the client, check\nInterface with the kitchen service to schedule the order for production.\nOrders service\n2. Upon successful payment, the orders service schedules the order.\nOrders service\nWhat are microservice APIs?\nwant to update the availability of the ingredients at the time of making the order, and\nWhen you have a dozen microservices, every service\nOrders\norder for\nAs we explained in section 1.2.3, the success of an API integration depends on good\nAPI documentation, and in this section, we introduce an API development workflow\nure 1.8, documentation-driven development is an approach to building APIs that works\nYou design and document the API.\nYou build the API client and the API server following the documentation.\nYou test both the API client and the API server against the documentation.\ntion helps to deliver successful API integrations.\nWhat is API documentation?\nAPI doc-\nworks that make it easier to build, test, and visualize our APIs, and therefore it’s worth\nIn this book, you’ll learn to document your APIs with\nOnce we have produced a documented API design, we move on to the second\nstage, which consists of building the API server and the API client against the API\nOpenAPI specification and to build an API application against them, and in chap-\nWhat are microservice APIs?\nalso leverage the API documentation to run API mock servers and test their code\nThe final stage involves testing our implementation against the API documenta-\nIn chapter 12, you’ll learn to use automated API testing tools such as Dredd and\nconfidence that your API implementation works as it should.\nthat breaks the contract with the API documentation.\n8 To learn how API server and client developers can leverage API documentation in their software development\nprocess, check out my talk “Leveraging API Documentation to Deliver Reliable API Integrations,” API Specifi-\n1. API design and\nagainst the API\nBy putting API documentation at the forefront of the development process,\nAPI developers face: disagreements between the client and the server development\ndevelopers often need to guess on implementation details of the API.\nthe API rarely succeeds its first integration test.\ntaste of the kinds of things you’ll learn in this book, we’ll begin implementing the API\nof CoffeeMesh’s orders service in chapter 2.\nneed to have knowledge of web APIs or microservices, as we will explain these technol-\nThis book shows you how to develop API-driven microservices with Python\nHow to design REST APIs and how to document them using the OpenAPI spec-\nHow to build REST APIs in Python using popular frameworks like FastAPI and\nHow to design and consume GraphQL APIs and how to build them using\nHow to test your APIs using property-based testing and API testing frameworks\nWhat are microservice APIs?\nYou will know how to integrate microservices using APIs, you will know\nhow to build and document those APIs using standards and best practices, and you\nwill be prepared to define the domain of an API with clear application boundaries.\nFinally, you’ll also know how to test, deploy, and secure your microservice APIs. Summary\nApplications can have multiple types of interfaces, such as UIs, CLIs, and APIs. An API is an interface that allows us to interact with an application program-\nA web API is an API that runs on a web server and uses HTTP for data trans-\nWe use web APIs to expose service capabilities through the internet.\ndata between the API client and the API server without knowing anything about\nthe API protocol being used.\nAPIs are correctly implemented.\nlogs, enable API visibility, and trace requests across services.\n– Design and document the API.\n– Build the API against the documentation.\n– Test the API against the documentation.\nBy putting API documentation at the forefront of the development process,\nA basic API\nIn this chapter, we implement the API for the orders service, which is one of the\nThe orders service allows customers to place orders with\nAs we implement the orders API, you will get an early look into the\nof an API specification\nImplementing API endpoints using FastAPI\nIntroducing the orders API specification\nIntroducing the orders API specification\nLet’s begin by analyzing the requirements of the orders API.\nUsing the orders API, we\nThe orders API\nmenting REST APIs. In chapter 5, you’ll learn to document your APIs using OpenAPI.\nIn addition to documenting the API endpoints, the specification also includes data\nnents section of the orders API specification.\nOur API implementation\npayload before we try to create the order.\nReturns an order\nUpdates an order\nDeletes an order\nCancels an order\nPays for an order\n/orders\nReturns a list of orders\nThe orders API exposes seven endpoints structured around four URL paths.\nendpoint implements different capabilities, such as placing and cancelling an order.\nA basic API implementation\nNow that we understand the requirements for building the orders API, let’s look at\nHigh-level architecture of the orders application\nThis section offers a high-level overview of the orders API’s architectural layout.\nAs you can see in figure 2.2, we organize into three layers: the API layer, the busi-\nAPI\nservice’s API.\nImplementing the API endpoints\ntions between the API layer and the data layer.\nFor the orders service, it’s the part that\nThe API layer of a service is different from the business layer.\nimplements the capabilities of a service, while the API layer is an adapter on top of the\nThe API layer is an adapter on top of the business layer.\nThe API layer\nThe API layer is equivalent to\nImplementing the API endpoints\nIn this section, you will learn to implement the API layer of the orders service.\nshow you how to break down the implementation of the API into progressive steps.\nlibrary and how you can use it to build a web API.\n/orders\nAPI\nWhen a user request reaches the orders service, it’s first validated by the \nA basic API implementation\nFastAPI (https://github.com/tiangolo/fastapi) is a web API framework built on top of\n/orders\nAPI endpoints\nStarlette’s routes with data validation and API documentation functionality.\nImplementing the API endpoints\nBefore we start implementing the API, we need to set up our environment for this\nNow that our dependencies are installed, let’s build the API.\nThen create a subfolder named orders, which will contain our API\nWithin the orders folder, create a file called app.py.\nsubfolder called orders/api, and within that folder create a file called orders/api/\napi.py.\n├── api\nA basic API implementation\nListing 2.3 shows how to create an instance of the FastAPI application in file orders/\nAPI we are implementing.\nfrom orders.api import api     \nListing 2.4 shows a minimal implementation of our API endpoints.\nwithin the orders/api/api.py file.\nsame data in all the endpoints except the DELETE /orders/{order_id} endpoint,\ndynamic list of orders.\nlike we do in the POST /orders and in the DELETE /orders/{order_id} endpoints.\n# file: orders/api/api.py\norder = {       \n'order': [\nMinimal implementation of the orders API\nrepresents our API application.\nWe import the api module so \nWe define an order object to \nImplementing the API endpoints\n@app.get('/orders')  \n@app.post('/orders', status_code=status.HTTP_201_CREATED)    \ndef create_order():\nreturn order\nreturn order\nreturn order\n@app.delete('/orders/{order_id}', status_code=status.HTTP_204_NO_CONTENT)\nreturn order\nreturn order\nWe use these decorators to register our API endpoints.\n258aaaef9533, our view functions will be called with the order_id parameter set to\norder_id’s type is a universally unique identifier (UUID).\nsuch as order_id, within \nA basic API implementation\ning 2.4, we set status_code to 201 (Created) in the POST /orders endpoint, and to\n204 (No Content) in the DELETE /orders/{order_id} endpoint.\nYou can now run the app to get a feeling of what the API looks like by executing\nURL in a browser and you will see an interactive display of the API documentation\nNow that we have the basic skeleton of our API, we’ll move on to implementing\nIn this illustration, a GET request on the /orders/{order_id} \nendpoint with order_id set to ff0f1355-e821-4178-9567-\nImplementing the API endpoints\nAPI endpoints\nA basic API implementation\nNow that we have implemented the main layout for the URL paths of our API, we\nData validation and marshalling are crucial operations in an API, and to\ndeliver a successful API integration, we need to get them right.\nAPIs. FastAPI uses pydantic for data validation, so we’ll start by learning to create\nthe context of web APIs, marshalling refers to the process of transforming an\nThe orders API specification contains three schemas: CreateOrderSchema, GetOrder-\n- order\nSpecification for the orders API schemas\norder = {\n'order': [\nOrder object\norder = [\n\"order\": [{\nA basic API implementation\norder:\n- order\norder:\nWe use GetOrderSchema when we return the details of an order from the server and\nCreateOrderSchema to validate an order placed by a customer.\nOrderSchema only requires the presence of one property in the payload: the order\nNow that we understand our API schemas, it’s time to implement them.\nnew file called orders/api/schemas.py.\ning 2.6 shows how we implement CreateOrderSchema, GetOrderSchema, and Order-\nThe code in listing 2.6 goes in the orders/api/schemas.py\npydantic’s conlist type to define CreateOrderSchema’s order property as a list with at\nrequired: [ order ]\n'order': [\nOrder\n+ order: List[OrderItem]\nA basic API implementation\n# file: orders/api/schemas.py\norders: List[GetOrderSchema]\nthem with the API to validate and marshal payloads.\nIn this section, we use the models we implemented in section 2.4 to validate request\n# file: orders/api/api.py\nfrom orders.api.schemas import CreateOrderSchema     \n@app.post('/orders', status_code=status.HTTP_201_CREATED)\nreturn order\nreturn order\nreturn order\nendpoint of the /orders URL path, you’ll see that the UI now gives you an example of\n\"order\",\nHooking validation models up with the API endpoints \nA basic API implementation\nFor example, the error message \"loc: /body/order/0/product\" is roughly equivalent\nto the following notation in Python: loc['body']['order'][0]['product'].\nproperty /body/order/0/product is missing from the payload.\n\"order\",\n{ \"order\": [\n\"order\": [\n\"order\": [\nus make the API integration more reliable.\nFor example, if we send the following payload to the POST /orders end-\n\"order\": [\nIn terms of API integrations, optional isn’t quite the same as nullable: a property can\nA basic API implementation\n# file: orders/api/schemas.py\nNow that we know how to test our API implementation using a Swagger UI, let’s see\nhow we use pydantic to validate and serialize our API responses.\nvalidate the response payloads of our API.\nFor example, the schema for the response payload of the POST /orders endpoint is\nGetOrderSchema, which requires the presence of the id, created, status, and order\nAPI clients will expect the presence of all these fields in the response payload and\nMalformed response payloads are a common source of API integration\nListing 2.9 shows how we use pydantic models to validate the responses from the GET\n/orders/{order_id} endpoint, which returns an empty response.\n# file: orders/api/api.py\nfrom orders.api.schemas import (\n@app.get('/orders', response_model=GetOrdersSchema)\norder\n'/orders',\nreturn order\nour API.\nThen head over to the GET /orders endpoint and send a request.\nthe order that we hardcoded at the top of the orders/api/api.py file.\n# orders/api/api.py\norder = {\nHooking validation models for responses in the API endpoints\nA basic API implementation\n'order': [\nIf we call the GET /orders endpoint again, we’ll get the same response we obtained\n\"order\": [\nLet’s now remove the created property from the order payload and call the GET\n/orders endpoint again:\n# orders/api/api.py\norder = {\n'order': [\nAdding an in-memory list of orders to the API\nrequest against the GET /orders endpoint:\n# orders/api/api.py\norder = {\n'order': [\nstate management mechanism for the application so that we can place orders and\nchange their state through the API.\nAdding an in-memory list of orders to the API\nSo far, our API implementation has returned the same response object.\norders as a Python list.\nWe’ll manage the list within the view functions of the API layer.\nListing 2.10 shows the changes required for the view functions under api.py to man-\nthe orders/api/api.py file.\nWe represent the collection of orders as a Python list, and we\n# file: orders/api/api.py\nA basic API implementation\nfrom orders.api.schemas import GetOrderSchema, CreateOrderSchema\nORDERS = []     \n@app.get('/orders', response_model=GetOrdersSchema)\nreturn ORDERS     \n'/orders',\norder['status'] = 'created'\nreturn order        \n@app.get('/orders/{order_id}', response_model=GetOrderSchema)\nreturn order\nstatus_code=404, detail=f'Order with ID {order_id} not found'\n@app.put('/orders/{order_id}', response_model=GetOrderSchema)\nreturn order\nstatus_code=404, detail=f'Order with ID {order_id} not found'\nTo return the list of orders, we \nevery order\nTo create the order, \nTo find an order by ID, we \nAdding an in-memory list of orders to the API\nstatus_code=404, detail=f'Order with ID {order_id} not found'\n@app.post('/orders/{order_id}/cancel', response_model=GetOrderSchema)\norder['status'] = 'cancelled'\nreturn order\nstatus_code=404, detail=f'Order with ID {order_id} not found'\n@app.post('/orders/{order_id}/pay', response_model=GetOrderSchema)\norder['status'] = 'progress'\nreturn order\nstatus_code=404, detail=f'Order with ID {order_id} not found'\nIf you play around with the POST /orders endpoint, you’ll be able to create new\norders, and using their IDs you’ll be able to update them by hitting the PUT\n/orders/{order_id} endpoint.\nIn every endpoint under the /orders/{order_id}\nURL path, we check whether the order requested by the API client exists, and if it\nWe are now able to use the orders API to create orders, update them, pay for\nAPI for a microservice application!\nlibraries to build web APIs, and you’ve seen how to add robust data validation to\nyour APIs. You’ve also learned to put it all together and run it with success.\nbuilding microservices exposing web APIs. In the coming chapters, we’ll delve\nmicroservice API integrations.\nWe order from the list using \nA basic API implementation\nthrough an API\nFastAPI is a popular framework for building web APIs. It’s highly performant,\nbetween microservices?\nThe process of breaking down a system into microservices is called service decom-\nA well-designed microservices architecture is",
      "keywords": [
        "API",
        "Orders API",
        "order",
        "Microservice APIs",
        "APIs",
        "orders API specification",
        "API implementation",
        "Microservices",
        "API documentation",
        "API endpoints",
        "web APIs",
        "orders service",
        "basic API implementation",
        "API layer",
        "basic API"
      ],
      "concepts": [
        "apis",
        "api",
        "microservice",
        "orders",
        "services",
        "applications",
        "application",
        "fastapi",
        "responsibility",
        "responses"
      ],
      "similar_chapters": [
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 1,
          "title": "",
          "score": 0.916,
          "base_score": 0.766,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 382,
          "title": "",
          "score": 0.84,
          "base_score": 0.69,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 9,
          "title": "",
          "score": 0.828,
          "base_score": 0.678,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 8,
          "title": "",
          "score": 0.782,
          "base_score": 0.632,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 384,
          "title": "",
          "score": 0.736,
          "base_score": 0.586,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "orders",
          "order",
          "orders api",
          "microservices",
          "apis"
        ],
        "semantic": [],
        "merged": [
          "orders",
          "order",
          "orders api",
          "microservices",
          "apis"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.4367946368603127,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:35.192883+00:00"
      }
    },
    {
      "chapter_number": 3,
      "title": "Designing microservices",
      "start_page": 74,
      "end_page": 89,
      "summary": "CoffeeMesh is a fictitious company that allows customers to order all sorts of products\nWhen a customer places an order through the CoffeeMesh website, the ordered\nBefore we learn to apply service\nvices are designed around well-defined business subdomains, they have clearly defined\nDatabase-per-service principle\nDatabase-per-service principle\nThe database-per-service principle states that each microservice owns a specific set\nto ensure that the data owned by a specific service is not accessed directly by another\nservice.\nservice calculates the price of a customer order.\nvice needs the price of each item in the order, which is available in the Products data-\nthe orders service requests this data from the products and users services.\nProducts service\nUsers service\nOrders\nOrder 1\nOrder 2\nOrder 3\n1. The orders service\nfrom the products service.\n2. The orders service requests\nfrom the users service.\n3. The orders service calculates\nOrders service\nEach microservice has its own database, and access to another service’s data \nto design our data models for optimal access for the service.\nIf the orders service\ndatabase would require updates to both the products and orders services.\ncoupling the orders service’s code to the Products database, and therefore we’d be break-\nLoose coupling states that we must design services with clear separation of concerns.\nTo calculate a forecast, the sales forecast service makes an API call to the historical\nservice\nhistorical data service.\nservice\nService decomposition by business capability\nthis means we should strive for the design of services around a single business capabil-\nbusiness capability and by subdomain.\nService decomposition by business capability\nthe business has a customer management team, we build a customer management ser-\nservice; for a kitchen team, we build the corresponding kitchen service; and so on.\nbusinesses that are structured around products, we may have a microservice per prod-\nin an architecture that maps every business team to a microservice.\nMesh website, customers can order different types of coffee-related products out of a\nUsing service decomposition by business capability, we reflect the \nA sales team is dedicated to improving the experience of ordering products through\nTo decompose services by business capability, we map each business team to a micros-\nProducts team maps to the products service—This service owns CoffeeMesh product\nThe products team uses this service to maintain CoffeeMesh’s\nservice’s interface.\nIngredients team maps to the ingredients service—This service owns data about Cof-\nThe ingredients team uses this service to keep the\nSales team maps to the sales service—This service guides customers through their\nfrom this service to analyze and improve the customer journey.\nFinance team maps to the finance service—This service implements payment proces-\nfinance team uses this service to keep the company accounts up to date and to\nKitchen team maps to the kitchen service—This service sends orders to the auto-\nDelivery team maps to the delivery service—This service arranges the delivery of the\norder to the customer once it has been produced by the kitchen.\nThis service\nService decomposition by business capability\nThe delivery team collects data from this service to monitor the\nIn this microservices architecture, we named every service after the business structure\nsince all user interactions with this service will be related to their payments.\nFrom the previous analysis, it’s clear that every service owns its own data: the\nproducts service owns product data, the ingredients service owns ingredients data,\nThe SRP also applies, as every service is restricted to one business area:\nthe finance service only processes payments, the delivery service only manages deliv-\nTo serve the CoffeeMesh catalogue, the products service needs to\nSince the stock of ingredients data is owned by the ingredients service,\nthe products service needs to make an API call per product to the ingredients service.\nThere’s a high degree of coupling between the products and ingredients services,\nand therefore both business capabilities should be implemented within the same service.\nProducts service\nIngredients service\nNow that we know how to decompose services by business capability, let’s see how\nService decomposition by subdomains\nProducts service\nDelivery service\nKitchen service\nFinance service\nSales service\nservices by business capability, we \nmap every team to a service.\nService decomposition by subdomains\nWe can call it the products subdomain.\ntheir order.\nTo place an order, the customer lands on the CoffeeMesh website, selects \nitems from the product catalogue, and pays for the order.\norder’s details to the kitchen, which produces it while the customer monitors its progress.\nService decomposition by subdomains\nThe second step represents a subdomain that allows users to select products.\nThis subdomain owns data about users’ orders, and it exposes an interface that allows\nProducts subdomain\nOrders subdomain\nOrders subdomain\nthe order to\nthe order and\nOrders subdomain\nOnce the order\nOrders subdomain\nWe map to a subdomain every step in the process of placing and delivering an order.\nproduction of customer orders.\nkitchen system to schedule the production of customer orders and track their prog-\nOnce an order is produced, the kitchen subdomain notifies the orders subdo-\nthe production of customer orders, and it exposes an interface that allows us to send\nThe orders subdomain inter-\nThe orders subdomain interfaces with the deliv-\nery subdomain to update the itinerary of the customer’s order to meet the require-\nvices, and therefore we say they’re loosely coupled; each service owns its own data,\nProducts subdomain maps to the products service—Manages CoffeeMesh’s product\nOrders subdomain maps to the orders service—Manages customer orders\nKitchen subdomain maps to the kitchen service—Manages the production of orders\ncome of service decomposition by business capability, and we evaluate the benefits\nWhich service decomposition strategy should we use to design our microservices: decom-\nposition by business capability or decomposition by subdomains?\napply both approaches to service decomposition.\nmendation system, and the orders service would use the reviews service’s interface to\nProducts subdomain\nOrders subdomain\nProducts service\nDelivery service\nOrders service\nPayments service\nKitchen service\nan undesirable division between the products and ingredients services.\nWe call the process of breaking down a system into microservices service decom-\ndesigns microservices for each team in the organization.\nof the business through subdomains.\nservice for each subdomain, which results in a more robust technical design.\n– Database-per-service principle—Each microservice owns its own data, and access\nto that data happens through the service’s API.\n– Single Responsibility Principle—We must design each service around a specific\nbusiness capability or subdomain.\nWe make services talk to each other using APIs, and in part 2 you learn to\ntion, and in chapter 6, you learn to build CoffeeMesh’s orders and kitchen APIs\nfor building web APIs.1 In this chapter, we study the design principles of REST and",
      "keywords": [
        "service",
        "orders service",
        "Products service",
        "business",
        "order",
        "subdomain",
        "products",
        "orders subdomain",
        "REST APIs",
        "service decomposition",
        "customer",
        "business capability",
        "kitchen",
        "team",
        "microservices"
      ],
      "concepts": [
        "services",
        "products",
        "production",
        "customers",
        "microservice",
        "steps",
        "design",
        "team",
        "user",
        "api"
      ],
      "similar_chapters": [
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 7,
          "title": "",
          "score": 0.851,
          "base_score": 0.701,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 4,
          "title": "",
          "score": 0.66,
          "base_score": 0.51,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 13,
          "title": "",
          "score": 0.538,
          "base_score": 0.388,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 14,
          "title": "",
          "score": 0.533,
          "base_score": 0.383,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 384,
          "title": "",
          "score": 0.526,
          "base_score": 0.376,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "service",
          "subdomain",
          "team",
          "products",
          "business"
        ],
        "semantic": [],
        "merged": [
          "service",
          "subdomain",
          "team",
          "products",
          "business"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.31839358512421123,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:35.192915+00:00"
      }
    },
    {
      "chapter_number": 4,
      "title": "Principles of REST API design",
      "start_page": 90,
      "end_page": 119,
      "summary": "Principles of REST API design\nlearn to apply them by designing the orders API of the CoffeeMesh platform, the on-\nand status codes, to create highly expressive APIs. The final part of this chapter covers\nbest practices for designing API payloads and URL query parameters.\nhighly scalable APIs. REST APIs are structured around resources, entities that\nexample, CoffeeMesh’s orders service manages orders, and through its API we can\n\"order\": [\nsion of resources and resource modeling in REST APIs (https://www.thoughtworks.com/en-gb/insights/blog/\nrest-api-design-resource-modeling).\n/orders/{order_id}/status endpoint that allows us to get an order’s status without\nThe resource-oriented nature of REST APIs may sometimes appear limiting.\nDesigning clean endpoints is the first step toward building REST APIs that are easy\nthe six architectural constraints of REST API applications.\nPrinciples of REST API design\nIn REST, every request to the server must contain all the information necessary to pro-\nAPI server\nGET /orders\n{\"orders\": [...]]}\nGET /orders/8\nAPI client\nThis allows us to deploy multiple instances of the API server and respond \nto the API client with any of them.\nof the server, and because none of those instances manages the API client’s state, the\nGET /orders/8\nGET /orders/8\nWhen we check the order’s status for the first time, the orders service requests the status from\n\"order\": [...]\n\"order\": [...]\nthe API server performance.\nPrinciples of REST API design\nIn a REST architecture, clients must have a unique point of entry to your API and must\n/orders\n/orders\nAPI client\nwith ID 8, and a GET request on this URI always returns the state of the order with\nlearn to make your APIs discoverable by enriching a resource’s description with\nNow that we understand the most important design constraints of REST APIs, let’s look\nHATEOAS is a paradigm in the design of REST APIs that emphasizes the\nHATEOAS makes APIs easier to use by enriching responses\nmust include related links in their responses to allow clients to navigate the API by fol-\nent requests a resource from the server, the response must contain a list of\norder, the response must include the links to cancel and pay for the order.\nFor example, as you can see in figure 4.5, when a client requests the details of an\norder, the API includes a collection of links related to the order.\nPrinciples of REST API design\n\"order\": [\n\"order\": [\nOrders API\nRequest: GET /orders/8\nof the order\nIn the HATEOAS paradigm, the API sends a representation of the requested resource with other \nProviding relational links makes APIs navigational and easier to use, since every\nPOST /orders endpoint in the CoffeeMesh API to place an order, and they are\nalso able to use the GET /orders/{order_id} endpoint to retrieve the details\nof an order.\n/orders/{order_id} endpoint to external users since they are not able to use\nFor example, you can call the POST /orders/1234/cancel endpoint\nresponse payload too big, hence compromising the performance of the API and\nPrinciples of REST API design\nAPI.\nextent your APIs comply with the design principles of REST.\nments of good REST API design (figure 4.6).\nAll the requests to the server are made on the same endpoint and\nMesh website, the client might send a POST request on a generic /api endpoint with\n\"order\": [\nThe server invariably responds with 200 status codes and an accompanying payload\nan order, a client might make the following POST request on the generic /api end-\n\"order\": [\nLevel 1 introduces the concept of resource URLs. Instead of a generic /api endpoint,\norder.\nTo place an order, the client sends a POST request on the /orders endpoint\n\"order\": [\nPrinciples of REST API design\nThis time when requesting the details of the last order, the client will make a POST\nrequest on the URI representing that order: /orders/8.\nLevel 2: Using HTTP methods and status codes\nLevel 2 introduces the concept of HTTP verbs and status codes.\nFor example, to place an order, a client\nsends a POST request on the /orders endpoint with the following payload:\n\"order\": [\nand the payload only includes the details of the order we want to place.\nget the details of an order, we send a GET request on the order’s URI: /orders/\n{order_id}.\nlevel 2 introduces the semantic use of HTTP status codes to report the outcome of\nrequest, we get a 201 response status code, and a request for a nonexistent resource\nFor example, a GET request on the /orders/{order_id} end-\nStructured resource URLs with HTTP methods\n\"order\": [\nNow that we understand the main design principles of REST APIs, it’s time to start\ndesigning the orders API!\nStructured resource URLs with HTTP methods\nAs we learned in section 4.4, using HTTP methods and status codes is associated with\ntion’s orders API.\nProper use of HTTP methods makes our APIs\nPrinciples of REST API design\nThe most important HTTP methods for REST APIs are GET, POST,\nevant HTTP methods in REST APIs are GET, POST, PUT, PATCH, and DELETE:\nHTTP methods allow us to model the basic operations we can perform on a resource:\nwhich are APIs designed to perform these operations on resources.\nStructured resource URLs with HTTP methods\nHow do we use HTTP methods to define the endpoints of CoffeeMesh’s orders API?\nWe use HTTP methods in combination with URLs, so let’s first define the resource\n\"order\": [\nIn the orders API, we’ll implement updates as PUT requests.\nPrinciples of REST API design\nIn the orders API, we have these two resource URLs:\nby the ID of an order.\nAs you can see in figure 4.7, we use the singleton URL /orders/{order_id} to per-\nPOST /orders to place orders since we use POST to create new resources.\nNow that we know how to design API endpoints by combining URL paths with HTTP\nmethods, let’s see how to leverage the semantics of HTTP status codes to return\n/orders\nWe combine HTTP methods with URL paths to design our API endpoints.\nexample, we use the POST method to create new resources, so we use it in the POST \nUsing HTTP status codes to create expressive HTTP responses\nThis section explains how we use HTTP status codes in the responses of a REST API.\ngroups, and then we explain how to use them to model our API responses.\nWhat are HTTP status codes?\nWe use status codes to signal the result of processing a request in the server.\nproperly used, HTTP status codes help us deliver expressive responses to our APIs’\nHTTP response status codes are used to indicate the outcome of process-\nFor example, the 200 status code indicates that the request\nserver error was raised while processing the request.\nmonly used codes and see how we apply them in our API designs.\nWhen thinking about HTTP status codes, it’s useful to distinguish between success-\nwe use the following successful HTTP status codes:\nGET /orders: 200 (OK)—Signals that the request was successfully processed.\nGET /orders/{order_id}: 200 (OK)—Signals that the request was successfully\nPUT /orders/{order_id}: 200 (OK)—Signals that the resource was successfully\nDELETE /orders/{order_id}: 204 (No Content)—Signals that the request was\nall other methods, a DELETE request doesn’t require a response with payload,\n204 (No Content) code is a good choice for this type of HTTP request.\nPrinciples of REST API design\npoint, we use the 200 (OK) status code since we’re not really creating a resource,\nwe use the 200 (OK) status code since we’re not really creating a resource, and all\nof errors can we encounter in the server while processing requests, and what kinds of\naddress this type of error with an HTTP status code in the 4xx group.\nUsing HTTP status codes to report client errors in the request\nAn API client can make different types of errors when sending a request to an API.\nsee in figure 4.8, we address this type of error with a 400 (Bad Request) status code.\n/orders\nStatus code: 400 (Bad Request)\n\"order\": [\n\"order\": [\nUsing HTTP status codes to create expressive HTTP responses\nexample, let’s say that, to place an order, our API expects a POST request on the\n\"order\": [\nAs you can see in figure 4.9, an API client can send a payload missing one of the\n/orders\n\"order\": [\n\"order\": [\nWhen an API client sends a malformed payload, the server responds \nback with a 400 (Bad Request) status code.\nPrinciples of REST API design\nAnother common error happens when an API client requests a resource that doesn’t\nIf a client uses that endpoint with a nonexistent order ID, we\nshould respond with an HTTP status code signaling that the order doesn’t exist.\nAnother common error happens when API clients send a request using an HTTP\nThere are two HTTP status codes we can use to address this situation.\nTwo common errors in API requests have to do with authentication and authoriza-\nWhen an API client requests a resource that doesn’t exist, the server responds with \nThe POST method on the /orders/{order_id}/pay URL path is not supported.\nWhen an API client sends a request to a URL path with an HTTP method \nUsing HTTP status codes to create expressive HTTP responses\nNow that we know how to use HTTP status codes to report user errors, let’s turn our\nattention to status codes for server errors.\nWhen an API client makes a request on a URL path with an HTTP method \nGET /orders\nThe API client is making an unauthenticated request.\nWhen an API \nWhen an authenticated user makes a request using an HTTP method \nthey’re not allowed to use, the server responds with a 403 (Forbidden) status code.\nPrinciples of REST API design\nUsing HTTP status codes to report errors in the server\nrespond with a 500 (Internal Server Error) status code, as you can see in figure 4.15.\nOur API can become unresponsive when the server is\nGET /orders\nStatus code: 500 (Internal Server Error)\nGET /orders\nThe API backend is overloaded and can’t serve additional requests.\nWhen the API \nGET /orders\nThe API server is slow responding the request.\nWhen the API \nDesigning API payloads\ndesign of web APIs. The correct use of status codes goes a long way toward deliver-\nwe need to design well: API payloads.\nDesigning API payloads\nThis section explains best practices for designing user-friendly HTTP request and\nserver through an HTTP request.\nate or update a resource, and the server sends us payloads when we request data.\npayloads make APIs difficult to use and result in bad user experiences.\nAn HTTP request is a message an application client sends to a web server, and an\nHTTP response is the server’s reply to the request.\nAn HTTP request includes a URL,\nan HTTP response includes a status code, a set of headers, and, optionally, a payload.\nIn REST APIs, data is typically represented as a JSON document.\nBoth HTTP requests and responses can\nIn REST APIs,\nHTTP requests include a payload when we need to send data to the server.\nple, a POST request typically sends data to create a resource.\nallows us to include payloads in all HTTP methods, but it discourages their use in GET\nPrinciples of REST API design\nAccording to the HTTP specification, responses with a 1xx status code, as\nresource cannot be found in the server, can include the following error message:\nFastAPI uses \"detail\", so we’ll use that keyword in the orders API specification.\nRESPONSE PAYLOADS FOR POST REQUESTS\nWe use POST requests to create resources.\nIn CoffeeMesh’s orders API, we place\nto the order, and therefore the order’s ID must be returned in the response payload.\nThe server also sets the time when the order was taken and its initial status.\nfull representation of the resource in the response to a POST request.\nDesigning API payloads\nRESPONSE PAYLOADS FOR PUT AND PATCH REQUESTS\nTo update a resource, we use a PUT or a PATCH request.\nmake PUT/PATCH requests on a singleton resource URI, such as the PUT /orders/\n{order_id} endpoint of CoffeeMesh’s orders API.\n\"order\": [...]\n{\"order\": [...]}\nproperties, like the order ID and the status.\nthe order to the client.\nAPI client\nWhen an API client sends a POST request to create a new resource, the server \n\"order\": [...]\nWhen an API client sends a PUT request to update a resource, the server responds \nPrinciples of REST API design\nRESPONSE PAYLOADS FOR GET REQUESTS\nWe retrieve resources from the server using GET requests.\n4.5, CoffeeMesh’s orders API exposes two GET endpoints: the GET /orders and the\nAPI client all the information they need in one request.\nThe second strategy for the GET /orders endpoint’s payload is to include a partial\nNow that we know how to design API payloads, let’s turn our attention to URL\n\"orders\": [\n\"order\": [...]\nGET /orders\nWhen an API \nGET /orders endpoint, the \nabout the order.\nSome endpoints, such as the GET /orders endpoint of the orders API, return a\n\"orders\": [\nGET /orders\n\"orders\": [\n\"order\": [...]\nWhen the API client makes a GET request on the /orders URL path, the server \nresponds with a list of order IDs. The client uses those IDs to request the details of each order on the \nPrinciples of REST API design\nof the orders API.\ncelled orders and restrict the number of results to 5, we make the following API request:\nIt’s also common practice to allow API clients to paginate results.\nparameters in an API request as in the following example:\nAPIs. You’re now equipped with the resources you need to design highly expressive\nstates that REST APIs must include referential links in their responses.\nGood REST API design leverages features of the HTTP protocol, such as HTTP\nmethods and status codes, to create well-structured and highly expressive APIs\nThe most important HTTP methods for REST APIs are\nWe exchange data with an API server using payloads.\nbody of an HTTP request or response.\nClients send request payloads using the\nDocumenting REST APIs\nOpenAPI uses JSON Schema to describe an API’s structure and models, so we\nModeling the payloads for API requests and \npoints and schemas for the payloads of the API’s requests and responses, step by step.\nFor the examples in this chapter, we work with the API of CoffeeMesh’s orders ser-\nThe full specification for the orders API is available under\nuses JSON Schema to describe the properties of an API.",
      "keywords": [
        "REST API design",
        "REST APIs",
        "REST API",
        "HTTP status codes",
        "API",
        "orders API",
        "HTTP status",
        "orders",
        "API client",
        "HTTP methods",
        "APIs",
        "API design",
        "REST",
        "status code",
        "HTTP request"
      ],
      "concepts": [
        "apis",
        "orders",
        "ordering",
        "resource",
        "designing",
        "status",
        "server",
        "request",
        "requests",
        "codes"
      ],
      "similar_chapters": [
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 382,
          "title": "",
          "score": 0.867,
          "base_score": 0.717,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 6,
          "title": "",
          "score": 0.83,
          "base_score": 0.68,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 384,
          "title": "",
          "score": 0.735,
          "base_score": 0.585,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 5,
          "title": "",
          "score": 0.735,
          "base_score": 0.585,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 2,
          "title": "",
          "score": 0.698,
          "base_score": 0.548,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "orders",
          "status",
          "http",
          "order",
          "request"
        ],
        "semantic": [],
        "merged": [
          "orders",
          "status",
          "http",
          "order",
          "request"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.478881065409148,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:35.192949+00:00"
      }
    },
    {
      "chapter_number": 5,
      "title": "Documenting REST APIs with OpenAPI",
      "start_page": 120,
      "end_page": 139,
      "summary": "Documenting REST APIs with OpenAPI\nJSON Schema supports the following basic data types:\nTo define an object using JSON Schema, we declare its type as object, and we list its\nThe following shows how we define an object named order,\nwhich is one of the core models of the orders API.\n\"order\": {\nSince order is an object, the order attribute also has properties, defined under the\n\"order\": {\nDefining the schema of an object with JSON Schema\nschema as an object.\nUsing JSON Schema to model data\n\"order\": {\nIn this case, the order property is an array.\nin their schema, which is the items property that defines the type of each of the ele-\nobject that represents an item in the order.\navoid this problem, JSON Schema allows us to define each object separately and to use\nwithin the order array as a model called OrderItemSchema and use a JSON pointer to\nDefining an array of objects with JSON Schema\nUsing JSON pointers to reference other schemas\nDocumenting REST APIs with OpenAPI\n\"Order\": {\n\"order\": {\ndefinition within the schema.\nA JSON pointer is a special syntax in JSON Schema that allows us\nWe can refactor our specification using JSON pointers by extracting common schema\nIn addition to being able to specify the type of a property, JSON Schema also\nmats or use JSON Schema’s built-in formats.\na date, we can use the date format—a built-in format supported by JSON Schema that\nHowever, JSON Schema\nter, we’ll use YAML to develop the specification of the orders API.\nIn this section, we introduce the OpenAPI standard, and we learn to structure an API\nport in the current ecosystem, so we’ll document the API using OpenAPI 3.0.\nOpenAPI is a standard specification format for documenting RESTful APIs (fig-\nOpenAPI allows us to describe in detail every element of an API, including\nits endpoints, the format of its request and response payloads, its security schemes,\nsource specification format for describing RESTful web APIs. Over time, this frame-\nby far the most popular specification format used to document RESTful APIs,3 and it\nschemas\nAPI endpoints, while the components section contains \nDocumenting REST APIs with OpenAPI\nAn OpenAPI specification contains everything that the consumer of the API needs to\nservers—Contains a list of URLs where the API is available.\ncation, such as schemas, parameters, security schemes, request bodies, and\nresponses.4 A schema is a definition of the expected attributes and types in your\nOpenAPI schemas are defined using JSON Schema\nmenting the endpoints of the orders API.\nDocumenting the API endpoints\nIn this section, we declare the endpoints of the orders API.\ntion 5.2, the paths section of an OpenAPI specification describes the interface of your\nAPI.\nIt lists the URL paths exposed by the API, with the HTTP methods they imple-\nIn this section, we’ll focus specifically on documenting the URL paths and the\nIn chapter 4, we established that the orders API contains the follow-\norder.\nendpoint, it requires a full representation of the order.\ndefined in the components section of the API specification.\nThe following shows the high-level definitions of the orders API endpoints.\nID to each endpoint so that we can reference them in other sections of the document.\n/orders:    \nFor the GET /orders\nlearn to build specifications for different elements of the API, starting with the\nIn this section, we learn to define URL query parameters\nThe GET /orders endpoint allows us to filter orders using the follow-\nHigh-level definition of the orders API endpoints\nby the /orders URL path\nDocumenting REST APIs with OpenAPI\n5.5 shows the specification for the GET /orders endpoint’s query parameters.\ndefinition of a parameter requires a name, which is the value we use to refer to it in the\n{order_id}, order_id is a path parameter that identifies a specific order.\nWe define the parameter’s type using the schema keyword (Boolean in the\n/orders:\nschema:    \nschema:\nrequest payloads of the orders API endpoints.\nIn section 5.1, we established that the payload for the POST /orders end-\nSpecification for the GET /orders endpoint’s query parameters\ntype under schema.\n\"order\": [\nThis payload contains an attribute order, which represents an array of items.\nproduct—The type of product the user is ordering.\nListing 5.6 shows how we define the schema for this payload.\nThe schema for our payload\nis an object with one property: order, whose type is array.\nobjects with three properties: the product property, with type string; the size prop-\ndefine an enumeration for the size property, which constrains the accepted values to\n/orders:\nschema:    \norder:\nSpecification for the POST /orders endpoint\nschema.\nDocumenting REST APIs with OpenAPI\nEmbedding payload schemas within the endpoints’ definitions, as in listing 5.6, can\nIn this section, we learn strategies for refactoring schemas to keep the API specification\nThe definition of the POST /orders endpoint in listing 5.6 is long\nthe payload’s schema to a different section of the API specification: the components sec-\nthe name of the schema, and the values are the properties that describe it.\n/orders:\nschema:\nschemas:\norder:\nSpecification for the POST /orders endpoint using a JSON pointer\nreference a schema defined\nSchema \nEvery schema is an \nMoving the schema for the POST /orders request payload under the components sec-\nWe simply need to refer to the CreateOrderSchema schema using a JSON pointer:\nmore readable by refactoring the definition of the order item in the array in the fol-\nThis strategy allows us to reuse the schema for the order’s item in other\nschemas:\nSchema definitions for OrderItemSchema and Order\nDocumenting REST APIs with OpenAPI\norder:\nan order or to update it, so we can reuse it in the PUT /orders/{order_id} endpoint,\nAs we learned in chapter 4, the /orders/{order_id} URL\nWe specify that the order_id parameter is a string with a UUID format (a\nlong, random string often used as an ID).6 We define the URL path parameter directly\n/orders:\nname: order_id    \nschema:\nschema:\nNow that we understand how to define the schemas for our request payloads, let’s\nDocumenting API responses\nIn this section, we learn to document API responses.\nfor the GET /orders/{order_id} endpoint.\nThe response of the GET /orders/\n{order_id} endpoint looks like this:\nSpecification for the PUT /orders/{order_id} endpoint\nthe order’s\nThe order_id parameter \nThe order_id \nDocumenting API responses\n\"order\": [\nThis payload shows the products ordered by the user, when the order was placed, and\ntion 5.6 for the POST and PUT endpoints, so we can reuse our previous schemas.\nschemas:\norder:\nthe properties of different schemas in a single object definition.\nschema.\nschema using a \nDocumenting REST APIs with OpenAPI\ncombine the properties of different schemas into a single object.\nwhen a schema contains properties that have already been defined elsewhere,\nschemas:\nNow that we have the schema for the GET /orders/{order_id} endpoint’s response\ndescribe the response’s content type and its schema, GetOrderSchema.\n/orders:\nSpecification for the GET /orders/{order_id} endpoint\nother schemas.\nanother schema.\nname: order_id\nschema:\nsummary: Returns the details of a specific order    \nschema:\nAs you can see, we define response schemas within the responses section of the end-\nIn this section, we learn to add error responses to our API endpoints.\nsection of the API specification to provide generic definitions of those responses, and\nWe define generic responses within the responses header of the API’s components\ncase is defined by the Error schema.\nDocumenting REST APIs with OpenAPI\nschema:\nschemas:\nendpoints under the /orders/{order_id} URL path, since all of those endpoints are\npoints of a URL path, why can’t we define the responses directly under the\nWe can use the generic 404 response from listing 5.13 under the GET /orders/\n{order_id} endpoint.\nname: order_id\nschema:\nsummary: Returns the details of a specific order\nUsing the 404 response schema under GET /orders/{order_id} \nschema for the \nDefining the authentication scheme of the API\nschema:\nThe orders API specification in the GitHub repository for this book also contains a\nThe endpoint’s payload reuses GetOrderSchema to define the items in\nthe orders array.\n/orders:\ndescription: A JSON array of orders\nschema:\norders:\n- order\nOur API’s endpoints are now fully documented!\nDefining the authentication scheme of the API\nThis section explains how we document our API’s\nSpecification for the GET /orders endpoint\n/orders URL path.\norders is \nDocumenting REST APIs with OpenAPI\nThe security definitions of the API go within the components section\nschemas:\nDocumenting an API’s security scheme\nThis concludes our journey through documenting REST APIs with OpenAPI.\nYou’ve learned how to use JSON Schema; how OpenAPI works; how to\nstructure an API specification; how to break down the process of documenting your\nAPI into small, progressive steps; and how to produce a full API specification.\nJSON Schema is a specification for defining the types and formats of the prop-\nJSON Schema is useful for defining data validation\nOpenAPI is a standard documentation format for describing REST APIs and\nuses JSON Schema to describe the properties of the API.\nA JSON pointer allows you to reference a schema using the $ref keyword.\nJSON pointers, we can create reusable schema definitions that can be used in dif-\n– openapi—Specifies the version of OpenAPI used to document the API\n– paths—Describes the endpoints exposed by the API, including the schemas\nfor the API requests and responses and any relevant URL path or query\nschemas, generic responses, and authentication schemes\nIn previous chapters, you learned to design and document REST APIs. In this chap-\nWe’ll build the APIs for the orders service and for the kitchen\nIn chapter 2, we implemented part of the orders API.\nchapter, we pick up the orders API where we left it in chapter 2 and implement its\nOverview of the orders API\na popular choice for building REST APIs. We’ll learn how to add URL query parame-\nAfter completing the implementation of the orders API, we’ll implement the API\nto implement our APIs following Flask application patterns, and we’ll define valida-\nFolder ch06 contains two subfolders: one for the orders API (ch06/orders)\nOverview of the orders API\nIn this section, we recap the minimal implementation of the orders API that we under-\nYou can find the full specification of the orders API under ch06/\nIn chapter 2, we implemented the API endpoints of the orders API, and we created\npydantic schemas to validate request and response payloads.\nAs a reminder, the endpoints exposed by the orders API are the following:\nPOST /orders and PUT /orders/{order_id} require request payloads that define\nthe properties of an order, and in chapter 2 we implemented schemas for those pay-\nGET /orders endpoint.",
      "keywords": [
        "orders API",
        "API",
        "REST APIs",
        "JSON Schema",
        "Documenting REST APIs",
        "orders",
        "JSON",
        "orders API endpoints",
        "Schema",
        "API specification",
        "URL",
        "URL path",
        "APIs",
        "URL query parameters",
        "type"
      ],
      "concepts": [
        "schema",
        "order",
        "ordering",
        "apis",
        "api",
        "openapi",
        "type",
        "specification",
        "specifications",
        "properties"
      ],
      "similar_chapters": [
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 4,
          "title": "",
          "score": 0.735,
          "base_score": 0.585,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 382,
          "title": "",
          "score": 0.706,
          "base_score": 0.556,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 400,
          "title": "",
          "score": 0.637,
          "base_score": 0.487,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 6,
          "title": "",
          "score": 0.611,
          "base_score": 0.461,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 378,
          "title": "",
          "score": 0.563,
          "base_score": 0.413,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "schema",
          "orders",
          "order",
          "documenting",
          "schemas"
        ],
        "semantic": [],
        "merged": [
          "schema",
          "orders",
          "order",
          "documenting",
          "schemas"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.368385821205876,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:35.192982+00:00"
      }
    },
    {
      "chapter_number": 6,
      "title": "Building REST APIs with Python",
      "start_page": 140,
      "end_page": 173,
      "summary": "We implement the orders API using the FastAPI\ncomplete the implementation of the orders API!\nURL query parameters for the orders API\nIn this section, we enhance the GET /orders endpoint of the orders API by adding\nWe also implement validation schemas for the parameters.\nchapter 4, we learned that URL query parameters allow us to filter the results of a\nURL query parameters to filter orders by cancellation and also to limit the list of\nSpecification for the GET /orders URL query parameters\nURL query parameters for the orders API\nWe need to implement two URL query parameters: cancelled (Boolean) and limit\nImplementing URL query parameters for an endpoint is easy with FastAPI.\n# file: orders/orders/api/api.py\nNow that we have query parameters available in the GET /orders endpoint, how should\nstand the decision flow for filtering the list of orders based on the query parameters.\n# file: orders/orders/api/api.py\nfor order in query_set\nImplementation of URL query parameters for GET /orders\nImplementation of URL query parameters for GET /orders\nfor order in query_set\nreturn {'orders': query_set[:limit]}\nreturn {'orders': query_set}\ncancelled parameter is set to True or False, we use it to filter the list of \nis set, we only return the corresponding number of orders from the list.\nValidating payloads with unknown fields\nNow that we know how to add URL query parameters to our endpoints, let’s see how\nValidating payloads with unknown fields\nAPI client sends a payload with fields that haven’t been declared in our schemas, the\nvalidation models for our APIs. Pydantic is a popular data validation library\nIn chapter 2, we implemented the schema definitions of the orders API following the\nIn the field of web APIs, this means that we must strictly validate the payloads we\nAPI clients.\nCheck out the orders API specification under ch06/orders/oas.yaml in the GitHub\n# file: orders/orders/api/schemas.py\nValidating payloads with unknown fields\nunderstand the API implementation.\nize, and document the orders API.\nunderstand how we’ve implemented the API.\nadd to our API specification in chapter 12.\nTesting the API with the Swagger UI: to test an endpoint, click the endpoint itself, then click \nFastAPI’s dynamically generated API specification with our API design document.\nTo load the API specification document, we need PyYAML, which you can install\nIn the orders/app.py file, we load the API specification, and we overwrite our applica-\nfrom orders.api import api\nTo be able to test the API using the Swagger UI, we need to add the localhost URL to\nthe API specification.\nWe’ll serve the orders API’s Swagger UI under /docs/orders, and\nOverriding FastAPI’s dynamically generated API specification\nAPI specification.\nThis concludes our journey through building the orders API with FastAPI.\ntime to move on to building the API for the kitchen service, for which we’ll use a new\nOverview of the kitchen API\nIn this section, we analyze the implementation requirements for the kitchen API.\nvice to check how many orders are scheduled and to manage them.\nThe specification for the kitchen API is provided under ch06/kitchen/oas.yaml in the\nThe kitchen API contains four URL paths (see fig-\n/kitchen/schedules—Allows us to schedule an order for production in the\nkitchen (POST) and to retrieve a list of orders scheduled for production (GET)\nscheduled order (GET), to update its details (PUT), and to delete it from our\nSchedule order\nGet list of scheduled orders\nManage scheduled orders\nThe kitchen service schedules orders for production, and it tracks their progress.\nCoffeeMesh staff members use the kitchen service to manage scheduled orders.\nOverview of the kitchen API\n/kitchen/schedules/{schedule_id}/status—Allows us to read the status of\nan order scheduled for production\n/kitchen/schedules/{schedule_id}/cancel—Allows us to cancel a scheduled\nThe kitchen API contains three schemas: OrderItemSchema, ScheduleOrderSchema,\nrequired to schedule an order for production, while the GetScheduledOrderSchema\nrepresents the details of an order that has been scheduled.\nJust like in the orders API,\n/kitchen/schedule\n/kitchen/schedule/{schedule_id}\n/kitchen/schedule\nscheduled orders\nSchedules an order\nscheduled order\n/kitchen/schedule/{schedule_id}/status\nThe kitchen API has four URL paths: /kitchen/schedules exposes a GET and a POST \nendpoint; /kitchen/schedules/{schedule_id} exposes PUT, GET, and DELETE endpoints; \n/kitchen/schedules/{schedule_id}/cancel exposes a POST endpoint; and \n/kitchen/schedules/{schedule_id}/status exposes a GET endpoint.\nThis section introduces the framework we’ll use to build the kitchen API: flask-smorest\n(https://github.com/marshmallow-code/flask-smorest).\nFlask-smorest is a REST API\nbuilding web applications, while marshmallow is a popular data validation library that\nFlask-smorest builds on top of both frameworks, which means we implement our API\nschemas using marshmallow, and we implement our API endpoints following the\n/kitchen/schedules/{schedule_id}\nAPI endpoints\nimplements a typical Flask blueprint, which allows us to build and configure our \nAPI endpoints just as we would in a standard Flask application.\nprinciples and patterns we used when we built the orders API with FastAPI can be\nkitchen API with flask-smorest.\nBuilding APIs with flask-smorest offers an experience similar to building them with\nFastAPI uses pydantic for data validation, while flask-smorest uses marshmallow.\nFlask allows us to implement API endpoints with class-based views.\ncan use a class to represent a URL path and implement its HTTP methods as\nWith this covered, let’s kick off the implementation of the kitchen API!\nIn this section, we set up the environment to start working on the kitchen API.\nch06/kitchen for the kitchen API implementation.\nkitchen API specification, which is available under ch06/kitchen/oas.yaml in this\noas.yaml contains the API specification for the kitchen\nAPI.\nWe’ll also create an instance of flask-smorest’s Api object, which will represent\nour API.\nfrom flask_smorest import Api\nkitchen_api = Api(app)    \nour API.\nAPI_TITLE = 'Kitchen API'    \nfrom flask_smorest import Api\nInitialization of the Flask application object and the Api object\nConfiguration for the orders API\nflask-smorest’s Api object.\nAPI\nof our API\nof our API\nUI of our API\nImplementing the API endpoints\nkitchen_api = Api(app)\nmenting the endpoints for the kitchen API!\nImplementing the API endpoints\nThis section explains how we implement the endpoints of the kitchen API using flask-\nAPI exactly as we’d do any other Flask application.\npatterns, we use Flask blueprints.\nuration for a group of URLs. To implement the kitchen API endpoints, we’ll use the\nflask-smorest’s Blueprint class.\nWe can use Blueprint’s route decorators to create an endpoint or URL path.\nnient to use class-based routes, which we implement using Flask’s MethodView class.\nListing 6.9 illustrates how we implement the endpoints for the kitchen API using\nkitchen/api/api.py file.\nBlueprint object allows us to register our endpoints and add data validation to them.\n/kitchen/schedule\nscheduled orders\nSchedules an order\n@blueprint.route('/kitchen/schedule')\nreturn schedules, 201\n/kitchen/schedule/{schedule_id}/cancel\nCancels a scheduled order\n@blueprint.route('/kitchen/schedule/<schedule_id>/cancel')\nreturn schedules[0], 200\nImplementing the API endpoints\nWe use class-based routes for the /kitchen/schedules and the\n/kitchen/schedules/{schedule_id} paths since they expose more than one HTTP\nmethod, and we use function-based routes for the /kitchen/schedules/{schedule_\nid}/cancel and /kitchen/schedules/{schedule_id}/status paths because they\nWe return a mock schedule object in each endpoint\n# file: kitchen/api/api.py\nblueprint = Blueprint('kitchen', __name__, description='Kitchen API')   \nschedules = [{     \n@blueprint.route('/kitchen/schedules')     \nreturn schedules[0], 201\n@blueprint.route('/kitchen/schedules/<schedule_id>')     \nImplementation of the endpoints of the orders API\nof schedules.\n/kitchen/schedules URL \nreturn schedules[0], 200\ndef put(self, payload, schedule_id):\nreturn schedules[0], 200\n'/kitchen/schedules/<schedule_id>/cancel', methods=['POST']\nreturn schedules[0], 200\n@blueprint.route('/kitchen/schedules/<schedule_id>/status, methods=[GET])\nreturn schedules[0], 200\nNow that we have created the blueprint, we can register it with our API object in the\nfrom flask_smorest import Api\nfrom api.api import blueprint    \nkitchen_api = Api(app)\nkitchen_api.register_blueprint(blueprint)    \nRegistering the blueprint with the API object\n/kitchen/schedules/<schedule_id>/cancel \nkitchen API object.\nImplementing payload validation models with marshmallow\nIf you run curl http:/ /127.0.0.1:5000/kitchen/schedules, you’ll get\nthe mock object we defined in the kitchen/api/api.py module.\nImplementing payload validation models \nFlask-smorest uses marshmallow models to validate request and response payloads.\nthis section, we learn to work marshmallow models by implementing the schemas of\nthe kitchen API.\nThe marshmallow models will help flask-smorest validate our pay-\nAs you can see in the kitchen API specification under ch06/kitchen/oas.yaml in\nthis book’s GitHub repository, the kitchen API contains three schemas: Schedule-\nOrderSchema schema, which contains the details needed to schedule an order; Get-\nScheduledOrderSchema, which represents the details of a scheduled order; and\nshows how to implement these schemas as marshmallow models under kitchen/api/\nWe define the models’ properties with the help of marshmallow’s field classes,\nMarshmallow uses these property definitions to validate\n# file: kitchen/api/schemas.py\nfrom marshmallow import Schema, fields, validate, EXCLUDE\nSchema definitions for the orders API\nschedules = fields.List(\n6.12 shows how we use the models to add validation for request and response payloads\nTo add request payload validation to a view, we use the blueprint’s\npayload, the blueprint’s response() decorator doesn’t perform validation and only\nImplementing payload validation models with marshmallow\n# file: kitchen/api/api.py\nfrom api.schemas import (\nblueprint = Blueprint('kitchen', __name__, description='Kitchen API')\nreturn schedules[0]\n@blueprint.route('/kitchen/schedules/<schedule_id>')\nreturn schedules[0]\ndef put(self, payload, schedule_id):\nreturn schedules[0]\nAdding validation to the API endpoints\n'/kitchen/schedules/<schedule_id>/cancel', methods=['POST']\nreturn schedules[0]\n'/kitchen/schedules/<schedule_id>/status', methods=['GET']\nreturn schedules[0]\nsee in figure 6.8, flask-smorest now recognizes the validation schemas that need to be\naround with the UI now, for example by hitting the GET /kitchen/schedules end-\nnext step is adding URL query parameters to the GET /kitchen/schedules endpoint.\nThe Swagger UI shows the schema for the request for the POST /kitchen/schedules \nValidating URL query parameters\nValidating URL query parameters\nIn this section, we learn how to add URL query parameters to the GET /kitchen/\nschedules endpoint.\nAs shown in listing 6.13, the GET /kitchen/schedules end-\n/kitchen/schedules:\nsummary: Returns a list of orders scheduled for production\nHow do we implement URL query parameters in flask-smorest?\neters for the kitchen API using marshmallow.\nquery parameters to kitchen/api/schemas.py with the other marshmallow models.\nSpecification for the GET /kitchen/schedules URL query parameters\n# file: kitchen/api/schemas.py\nfrom marshmallow import Schema, fields, validate, EXCLUDE\nWe register the schema for URL query parameters using the blueprint’s arguments()\nURL, so we set the location parameter to query.\n# file: kitchen/api/api.py\nfrom api.schemas import (\nblueprint = Blueprint('kitchen', __name__, description='Kitchen API')\n@blueprint.route('/kitchen/schedules')\nreturn schedules\nIf you reload the Swagger UI, you’ll see that the GET /kitchen/schedules endpoint\nURL query parameters in marshmallow\nAdding URL query parameters to GET /kitchen/schedules\nValidating URL query parameters\n# file: kitchen/api/api.py\n@blueprint.route('/kitchen/schedules')\nUse filters in GET /kitchen/schedules\nThe Swagger UI shows the URL query parameters of the GET /kitchen/schedules \nreturn the full list of schedules.\nlist of schedules.\nreturn {'schedules': query_set}    \nNow that we know how to handle URL query parameters with flask-smorest, there’s\nNow that we have schemas to validate our request payloads and we have hooked them\nup with our routes, we have to ensure that our response payloads are also validated.\nthis section, we learn how to use marshmallow models to validate data.\nfunctionality to validate our response payloads, but you could use the same approach\nWhen we send a payload in a response, flask-smorest serializes the payload using\nlist of schedules.\npayload with the flask-smorest \nPayload is valid\nThe data that we send from the kitchen API comes from a database.\ninstance of the schema we want to validate against and use its validate() method to\n>>> from api.schemas import GetScheduledOrderSchema\n{'order': ['Missing data for required field.'], 'scheduled': ['Missing\na schedule containing only the id field, and in line 3 marshmallow helpfully reports\nthat the order, scheduled, and status fields are missing, and that the id field is not a\nWe validate schedules in the GET /kitchen/schedules\nschedules to validate one at a time.\n# file: kitchen/api/api.py\n@blueprint.route('/kitchen/schedules')\nerrors = GetScheduledOrderSchema().validate(schedule)   \nreturn {'schedules': query_set}\nThis concludes the implementation of the functionality of the kitchen API.\never, the API is still returning the same mock schedule across all endpoints.\nschedules so that we can make our API dynamic.\nImplementing an in-memory list of schedules\nschedule orders, update them, and cancel them through the API.\nchanges that we need to make to kitchen/api/api.py to make this possible.\ndata validation code into an independent function named validate_schedule() so\nWhen a schedule payload\nsuch as the ID, the scheduled time, and the status.\n# file: kitchen/api/api.py\nschedules = []    \ndef validate_schedule(schedule):     \nerrors = GetScheduledOrderSchema().validate(schedule)\n@blueprint.route('/kitchen/schedules')\nIn-memory implementation of schedules\nschedules as \nImplementing an in-memory list of schedules\nschedules.append(payload)\nvalidate_schedule(payload)\n@blueprint.route('/kitchen/schedules/<schedule_id>')\nvalidate_schedule(schedule)\nreturn schedule\ndef put(self, payload, schedule_id):\nschedule.update(payload)     \nvalidate_schedule(schedule)\nreturn schedule\n'/kitchen/schedules/<schedule_id>/cancel', methods=['POST']\nschedule['status'] = 'cancelled'     \nvalidate_schedule(schedule)\nreturn schedule\n'/kitchen/schedules/<schedule_id>/status', methods=['GET']\nof the schedule to \nvalidate_schedule(schedule)\nAPI specification to make sure we serve our API design instead of our implementation.\nOverriding flask-smorest’s dynamically generated API \nAs we learned in section 6.4, API specifications dynamically generated from code are\nwe’ll use to load the API design document:\noverride APISpec’s to_dict() method so that it returns our API design document.\nfrom flask_smorest import Api\nfrom api.api import blueprint\nkitchen_api = Api(app)\nkitchen_api.register_blueprint(blueprint)\nOverriding flask-smorest’s dynamically generated API specification\nkitchen_api.spec = spec\nYou can build REST APIs in Python using frameworks like FastAPI and flask-\na data validation library that uses type hints to create validation rules.\nFastAPI uses pydantic for data validation.\nBy default, FastAPI validates both request and response payloads.\nFlask-smorest uses marshmallow for data validation.\ntested framework that uses class fields to define validation rules.\nflask-smorest doesn’t validate response payloads, but you can validate responses\nby using marshmallow models’ validate() method.\nWith flask-smorest, you can use Flask’s MethodView to create class-based views\nant with errors in HTTP requests and validating response payloads.\nIn previous chapters, we learned how to design and implement REST APIs. In those\nIn this chapter, we’ll complete our implementation of the orders service by adding\nThe orders service owns and manages data about orders, so we’ll implement a per-",
      "keywords": [
        "API",
        "URL query parameters",
        "kitchen API",
        "Building REST APIs",
        "REST APIs",
        "URL query",
        "orders API",
        "schedule",
        "URL",
        "kitchen",
        "APIs",
        "API specification",
        "orders",
        "Kitchen API schedules",
        "Flask"
      ],
      "concepts": [
        "apis",
        "api",
        "scheduled",
        "schedule",
        "validation",
        "validating",
        "validate",
        "orders",
        "list",
        "payloads"
      ],
      "similar_chapters": [
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 4,
          "title": "",
          "score": 0.83,
          "base_score": 0.68,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 400,
          "title": "",
          "score": 0.714,
          "base_score": 0.564,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 382,
          "title": "",
          "score": 0.701,
          "base_score": 0.551,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 12,
          "title": "",
          "score": 0.638,
          "base_score": 0.488,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 5,
          "title": "",
          "score": 0.611,
          "base_score": 0.461,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "kitchen",
          "schedules",
          "kitchen schedules",
          "kitchen api",
          "blueprint"
        ],
        "semantic": [],
        "merged": [
          "kitchen",
          "schedules",
          "kitchen schedules",
          "kitchen api",
          "blueprint"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.39542201536548055,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:35.193017+00:00"
      }
    },
    {
      "chapter_number": 7,
      "title": "Service implementation patterns for microservices",
      "start_page": 174,
      "end_page": 213,
      "summary": "application, the business layer, which implements the service’s capabilities.\nThe same goes for the database: our data layer should know how the application\nnology, but the core business layer should know nothing specific about the database.\nAs you can see in figure 7.3, when it comes to the orders service, we’ll have a core\nprocess an order and its payment, to schedule its production, or to keep track of its\nwill use functions and classes from the business layer interface to serve the requests of\nwith the database and return business objects for the core business layer.\nIn this section, we set up the environment to work on the orders service and lay out\nOur service implementation will live under a folder named orders, so go ahead\nand the API and database adapters, we’ll implement each of them in different directo-\nThe business layer will live under orders/orders_service.\nThe orders service consist of three packages: the core business logic, \nwhich implements the capabilities of the service; an API layer, which allows clients \nwhich the API layer and the data layer are implemented.\napplication in different directories: orders_service for the core business layer; repository \nImplementing the database models\nSince the API layer is a web component, it will live under orders/web, which contains\nweb adapters for the orders service.\nThe data layer will live under orders/repository.\nahead and copy over the files from the GitHub repository under ch07/order/web\n└── orders     \n├── orders_service     \nImplementing the database models\nHigh-level structure of the orders service\nof the orders service\nwe’ll define the database models for the orders service; that is, we’ll design the data-\nImplementing the database models\nTable order_item\norder_id: FOREIGN KEY\n+ order_id: ForeignKey(order)\nUsing an ORM, we can implement our data models as classes that map to database tables.\nfrom orders.repository.models import Base\nNext, we’ll implement our database models.\nThe core object of the orders service is the\norder.\nUsers place, pay, update, or cancel orders.\nOrders have a life cycle, and we’ll\ndefine our order model:\nID—Unique ID for the order.\ninformation about the number of orders that exist in the database from our\nItems—The list of items included in the order and the amount of each product.\nSince an order can have any number of items linked to it, we’ll use a different\nmodel for items, and we’ll create a one-to-many relationship between the order\nStatus—The status of the order throughout the system.\nAn order can have the\nSchedule ID—The ID of the order in the kitchen service.\nthe kitchen service after scheduling the order for production, and we’ll use it to\nImplementing the database models\nDelivery ID—The ID of the order in the delivery service.\nWhen users place an order, they add any number of items to the order.\nbetween orders and items, and therefore we’ll implement a model for items and link\nOrder ID—A foreign key representing the ID of the order the item belongs to.\nThis is what allows us to connect items and orders that belong together.\nOur SQLAlchemy models will live under the orders/repository folder, which we cre-\nated to encapsulate our data layer, in a file called orders/repository/models.py.\nuse these classes to interface with the database and rely on SQLAlchemy to translate\nshows the definition of the database models for the orders service.\nthat we can access the list of items in an order through OrderModel’s items attribute.\nEach item also maps to the order it belongs to through the order_id property, which\nment allows us to access the full order object from an item directly through a property\ncalled order.\nIDs. Each database model is enhanced with a dict() method, which allows us to out-\ntranslate database models to business objects, the dict() method only returns the\n# file: orders/repository/models.py\n__tablename__ = 'order'    \nitems = relationship('OrderItemModel', backref='order')   \n__tablename__ = 'order_item'\norder_id = Column(Integer, ForeignKey('order.id'))\nSQLAlchemy models for the orders service\nIn the previous section, we learned to design the database models for the orders ser-\ndatabase models ready, we can interact with the database to create orders and manage\ndata layer, and we’ll learn what the repository pattern is and how we can use it to cre-\nate an interface between the business layer and the database.\ndecouple the business layer from the implementation details of the database.\nness layer and the database is to use the database models directly within the business\nOur database models already contain data about the orders, so we could enhance\nis useful when we have one-to-one mapping between service capabilities and database\nRemember, the database is an adapter that the orders service uses to persist\ndata, and the implementation details of the database should not leak into the busi-\nTo decouple the business layer from the data layer, we’ll use the repository pattern.\nget, add, or delete orders from the list, and the repository will take care of translating\nlayer and the business layer is by using the database models directly in \nNow that we know how we can use the repository pattern to allow the business layer to\nof the database, we’ll learn to implement the repository pattern.\nwhen we add an order object to the repository, the repository will add the order to a\nWhy can’t we commit database changes within the repository?\n+ add(payload): Order\n+ get(id): Order\n+ list(): List[Order]\nOrder\nThe repository pattern encapsulates the implementation details of the data layer by \nexposing an in-memory list interface to the business layer, and it translates database models to \npay_order() method to process the request.\nIf the payment is successful, OrdersService schedules the order with the kitchen\nOrdersService updates the state of the order in the database using the orders\nexactly the API layer controls the database session and commits the transactions.\n+ place_order()\nto place an order.\nuses the orders\nthe order to the\n3. The API layer commits the changes to the database.\n+ add(payload): Order\nUsing the repository pattern, the API layer uses the place_order() capability of \nOrdersService to place an order.\nTo place the order, OrdersService interfaces with the orders \nrepository to add the order to the database.\nmany implementations, you’ll see repositories returning instances of the database\nmodels (i.e., the classes defined in orders/repository/models.py).\nInstead, we’ll return objects that represent orders from the business layer\ntionship between the business layer and the orders repository.\nOur orders repository implementation will live under orders/repository/orders_\nListing 7.3 shows the implementation of the orders repository.\n+ pay_order()\nfor an order.\n5. The API layer commits the changes to the database.\norder with the\nof the order in the\norders repository.\npayment, then with the kitchen service to schedule the order for production, and finally updates the status of \nthe order through the orders repository.\nOrder objects from the business layer (see section 7.5 for Order’s implementation\nTo create instances of Order, we pass dictionary representations of the SQL-\nmethod, we also include a pointer to the actual SQLAlchemy model through Order’s\norder_ parameter.\norder’s ID after committing the database transaction.\n+ add(payload): Order\n+ get(id): Order\n+ list(): List[Order]\nOrder\nthe database records into Order objects for consumption by the business layer by\nSession object, but it also encapsulates these details, and to the business layer the\nOrder objects in return.\nthe implementation details of the data layer from the business layer.\n# file: orders/repository/orders_repository.py\nfrom orders.orders_service.orders import Order\nfrom orders.repository.models import OrderModel, OrderItemModel\nreturn Order(**record.dict(), order_=record)   \norder = self._get(id_)   \nif order is not None:       \nreturn Order(**order.dict())\nreturn [Order(**record.dict()) for record in records]  \nOrders repository\norder, we also\nin the order.\nOrder class.\nIf the order exists, we \nreturn an Order object.\norder is cancelled using the \nlist of Order\nreturn Order(**record.dict())\nWe’ve done a lot of work designing the database models for the orders service and\nIn this section, we’ll implement the business layer of the\norders service.\nThe business layer implements the service’s capabilities.\ncapabilities of the orders service?\nknow that the orders service allows users of the platform to place their orders and\nAs illustrated in figure 7.12, the orders service manages the life cycle of an order through\nTo update an order, we first delete the \nitems linked to the order and then create \napplication, the business layer, which implements the service’s \nOther components, such as a web API interface or a database, \norders service and highlights integrations with other services (refer to figure 7.9 for\nThe order won’t be\nIf the payments service confirms the payment is successful, the orders\nservice schedules the order for production with the kitchen service.\nof the order, the orders service will communicate with the kitchen or the deliv-\nery service to cancel the order.\nSchedule order for production in the kitchen—After payment, the orders service\nschedules the order for production in the kitchen with the help of the kitchen\nthe orders service.\nDepending on the status of the order, the orders service\nabout the state of the order.\nWe’ll define this class under orders/orders_service/orders_service.py.\nduties, OrdersService uses the orders repository to interface with the database.\nOrders service\nIn order to perform some of its functions, the orders service needs \nto interact with orders services.\ninteract with the payments service, and to schedule an order for production, it \ncould let OrdersService import and initialize the orders repository as in the follow-\nfrom repository.orders_repository import OrdersRepository\nHowever, doing this would place too much responsibility on the orders service since it\nwould need to know how to configure the orders repository.\nthe implementation of the orders repository and the orders service, and we wouldn’t be\nIn the orders service, a suitable inversion of con-\nmeans that, instead of letting the orders service import and instantiate the orders\nTo make the orders repository injectable into the orders service, we parameterize it:\ndef __init__(self, orders_repository):\nself.orders_repository = orders_repository\nThis makes the orders service easier to use in\ntakes an instance of the orders repository as a parameter to make it injectable.\nlayer, it will be the responsibility of the API to get a valid instance of the orders reposi-\n# file: orders/orders_service/orders_service.py\ndef __init__(self, orders_repository):\nself.orders_repository = orders_repository \ndef place_order(self, items):\ndef get_order(self, order_id):\ndef update_order(self, order_id, items):\ndef list_orders(self, **filters):\ndef pay_order(self, order_id):\ndef cancel_order(self, order_id):\nSince orders contain data, it will be useful to\nhave a class that represents orders and has methods to perform tasks related to an\norder.\nWithin the context of the orders service, an order is a core object of the orders\nare the objects returned by the orders repository.\nWe’ll implement our Order class\nunder orders/orders_service/orders.py.\ntion of the Order class.\nIn addition to the Order class, listing 7.5 also provides an OrderItem class that rep-\nresents each of the items in an order.\nWe’ll use the Order class to represent orders\nSome of the properties of an order, such\norder to the repository, the returned object won’t have those properties.\nThe order’s\nID and its creation time become available through the order’s database record after\nFor this reason, Order’s initializer binds the order’s ID,\nself._id), and we use the order_ parameter in the Order class to hold a pointer to\nthe order’s database record.\nIf we retrieve the details of an order already saved to the\nwe define Order’s id, created, and status properties using the property() decorator,\norder_ to None by default.\n# file: orders/orders_service/orders.py\nclass Order:\ndelivery_id=None, order_=None):     \nreturn self._id or self._order.id\nreturn self._created or self._order.created\nreturn self._status or self._order.status\nIn addition to holding data about an order, the Order class also needs to handle\ntasks such as cancelling, paying, and scheduling an order.\nsimple in this chapter, we’ll implement the external API calls within the Order class.\nImplementation of the Order business object class\nrepresents an order item\nThe order_ \norder item.\nTo build the integration between the orders service and the kitchen and payments\nGitHub repository for this book contains three OpenAPI files: one for the orders API\nKitchen service (kitchen.yaml)—To schedule an order with the kitchen service, we\nthe list of items in the order.\nule_id, which we can use to keep track of the state of the order.\nPayments service (payments.yaml)—To process the payment for an order, we must\norder.\nBefore we can cancel an order, we need to check its status.\nIf the order is scheduled\nIf the order is out for delivery, we won’t allow users\nto cancel the order, and therefore we raise an exception.\nListing 7.6 extends the implementation of the Order class by adding methods that\nimplement API calls to the kitchen and payment services.\n# file: orders/orders_service/orders.py\nEncapsulating per-order capabilities within the Order class\nfrom orders.orders_service.exceptions import (\nclass Order:\njson={\"order\": [item.dict() for item in self.items]},\nf'Could not cancel order with id {self.id}'\nf'Cannot cancel order with id {self.id}'\n'http:/ /localhost:3001/payments', json={'order_id': self.id}\nf'Could not process payment for order with id {self.id}'\njson={'order': [item.dict() for item in self.items]}\nf'Could not schedule order with id {self.id}'\nListing 7.7 contains the implementation of the custom exceptions we use in the order\nthe OrdersService class when a user tries to fetch the details of an order that doesn’t\nIf an order is in progress, \nWe don’t allow orders that are \nWe schedule an order for \n# file: orders/orders_service/exceptions.py\nAs we mentioned earlier, the API module won’t use the Order class directly.\norders domain, and it takes care of using the orders repository to get orders objects\nListing 7.8 shows the implementation of the Orders-\nTo instantiate the OrdersService class, we require an orders repository object that\nwe can use to add or delete orders from our records.\nTo place an order, we create a\ndatabase record using the orders repository, and to retrieve the details of an order, we\nIf the requested order isn’t found,\nThe list_orders() method accepts fil-\nTo get a list of orders, the orders repository forces us\nIn the pay_order() method, we\nschedule the order by calling the kitchen API.\nAfter scheduling the order, we update\nthe order record by setting its schedule_id attribute to the schedule ID returned by\n# file: orders/orders_service/orders_service.py\nfrom orders.orders_service.exceptions import OrderNotFoundError\ndef __init__(self, orders_repository):    \nself.orders_repository = orders_repository\ndef place_order(self, items):\nreturn self.orders_repository.add(items)   \nOrders service custom exceptions\nan order doesn’t exist\nthe orders repository.\nWe place an order by \ndef get_order(self, order_id):\norder = self.orders_repository.get(order_id)    \nif order is not None:     \nreturn order\nraise OrderNotFoundError(f'Order with id {order_id} not found')\ndef update_order(self, order_id, items):\norder = self.orders_repository.get(order_id)\nif order is None:\nraise OrderNotFoundError(f'Order with id {order_id} not found')\nreturn self.orders_repository.update(order_id, {'items': items})\ndef list_orders(self, **filters):\nreturn self.orders_repository.list(limit, **filters)\ndef pay_order(self, order_id):\norder = self.orders_repository.get(order_id)\nif order is None:\nraise OrderNotFoundError(f'Order with id {order_id} not found')\norder.pay()\nschedule_id = order.schedule()    \nreturn self.orders_repository.update(\norder_id, {'status': 'scheduled', 'schedule_id': schedule_id}\ndef cancel_order(self, order_id):\norder = self.orders_repository.get(order_id)\nif order is None:\nraise OrderNotFoundError(f'Order with id {order_id} not found')\norder.cancel()\nreturn self.orders_repository.update(order_id, status=\"cancelled\")\nThe orders service is ready to be used in our API module.\nAs we mentioned in section 7.4, the orders repository doesn’t commit any actions to\nclass to access any of its capabilities, we must inject an instance of the Orders-\nWe get the details of an order using the orders \nIf the order doesn’t \nAfter scheduling the order, we \ncode would have to be repeated in every API function that interacts with the Orders-\n+ add(payload): Order\n+ place_order()\norders repository.\n3. The API layer instantiates the orders\nplace_order() method.\nTo persist our changes to the database, we could simply make the API layer use the \nSession object already implements the unit of work pattern for database transactions\nsection, we’ll implement our unit of work context manager as a class.\nager for the orders service.\n# file: orders/repository/unit_of_work.py\nnation with the orders repository and the OrdersService?\nThen we get an instance of the orders repository passing in\nthe UnitOfWork’s database session object, and an instance of the OrdersService class\npassing in the orders repository object.\nThen we use the orders service object to place\nan order, and we commit the transaction using UnitOfWork’s commit() method.\norders_service = OrdersService(repo)       \norders_service.place_order(order_details)     \nWhen a user tries to perform an action on an order, we make sure we\nListing 7.11 shows the new version of the orders/web/api/api.py module.\nif the requested order doesn’t exist.\nIn the create_order() function, we retrieve the dictionary representation of the\norder using order.dict() before we exit the UnitOfWork context so that we can\norder’s ID.\nRemember that the order ID doesn’t exist until the changes are commit-\nWe get an instance of the orders repository \nthe orders repository object.\nan order.\n# file: orders/web/api/api.py\nfrom orders.orders_service.exceptions import OrderNotFoundError\nfrom orders.orders_service.orders_service import OrdersService\nfrom orders.repository.orders_repository import OrdersRepository\nfrom orders.repository.unit_of_work import UnitOfWork\nfrom orders.web.app import app\nfrom orders.web.api.schemas import (\n+ add(payload): Order\n+ get(id): Order\n+ list(): List[Order]\nOrder\n+ order_: OrderModel\ninterfaces with the orders\norder to the database\n3. The orders repository returns\norder’s ID isn’t available.\nthe order_ property to an\nan order.\ntransaction, the order’s\ninjected into the Order-\npoint, the Order object\norder_id.\nWhen we place an order, the object returned by the orders repository doesn’t contain an ID.\nTherefore, we bind an instance of the model to the Order object so that it can pull the ID from the model \n@app.get('/orders', response_model=GetOrdersSchema)\ndef get_orders(\norders_service = OrdersService(repo)\nresults = orders_service.list_orders(\n'/orders',\ndef create_order(payload: CreateOrderSchema):\norders_service = OrdersService(repo)\norder = orders_service.place_order(payload.dict()['order'])\nfor item in order:\norder = orders_service.place_order(order)     \nreturn_payload = order.dict()    \n@app.get('/orders/{order_id}', response_model=GetOrderSchema)\ndef get_order(order_id: UUID):\norders_service = OrdersService(repo)\norder = orders_service.get_order(order_id=order_id)\nreturn order.dict()\nstatus_code=404, detail=f'Order with ID {order_id} not found'\n@app.put('/orders/{order_id}', response_model=GetOrderSchema)\ndef update_order(order_id: UUID, order_details: CreateOrderSchema):\nan order.\nWe access the order’s dictionary \norders_service = OrdersService(repo)\nfor item in order:\norder = orders_service.update_order(\norder_id=order_id, items=order\nreturn order.dict()\nstatus_code=404, detail=f'Order with ID {order_id} not found'\n\"/orders/{order_id}\",\ndef delete_order(order_id: UUID):\norders_service = OrdersService(repo)\norders_service.delete_order(order_id=order_id)\nstatus_code=404, detail=f'Order with ID {order_id} not found'\n@app.post('/orders/{order_id}/cancel', response_model=GetOrderSchema)\ndef cancel_order(order_id: UUID):\norders_service = OrdersService(repo)\norder = orders_service.cancel_order(order_id=order_id)\nreturn order.dict()\nstatus_code=404, detail=f'Order with ID {order_id} not found'\n@app.post('/orders/{order_id}/pay', response_model=GetOrderSchema)\ndef pay_order(order_id: UUID):\norders_service = OrdersService(repo)\norder = orders_service.pay_order(order_id=order_id)\nreturn order.dict()\nstatus_code=404, detail=f'Order with ID {order_id} not found'\norders service.\nthe implementation details of the database and the application interface.\nthe business layer will always receive the same objects from the repository.\nresource, such as the price of a product or the status of an order.",
      "keywords": [
        "order",
        "API layer",
        "orders service",
        "orders repository",
        "API",
        "business layer",
        "layer",
        "database",
        "Service",
        "data layer",
        "repository",
        "Service implementation patterns",
        "Web API interface",
        "business",
        "API layer commits"
      ],
      "concepts": [
        "orders",
        "database",
        "list",
        "layers",
        "classes",
        "services",
        "objects",
        "apis",
        "ids",
        "methods"
      ],
      "similar_chapters": [
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 3,
          "title": "",
          "score": 0.851,
          "base_score": 0.701,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 14,
          "title": "",
          "score": 0.684,
          "base_score": 0.534,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 2,
          "title": "",
          "score": 0.66,
          "base_score": 0.51,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 4,
          "title": "",
          "score": 0.656,
          "base_score": 0.506,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 382,
          "title": "",
          "score": 0.629,
          "base_score": 0.479,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "order",
          "orders",
          "layer",
          "orders repository",
          "repository"
        ],
        "semantic": [],
        "merged": [
          "order",
          "orders",
          "layer",
          "orders repository",
          "repository"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.39420051209556806,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:35.193080+00:00"
      }
    },
    {
      "chapter_number": 8,
      "title": "Designing GraphQL APIs",
      "start_page": 214,
      "end_page": 261,
      "summary": "Designing GraphQL APIs\nthese reasons, GraphQL is an excellent choice for building the products API.\nAs we build the specification for the products API, you’ll learn about GraphQL’s\nscalar types, designing custom object types, as well as queries and mutations.\nend of this chapter, you’ll understand how GraphQL compares with other types of\nallows us to run queries in an API server.\nguage for databases, GraphQL provides a query language for APIs.2 GraphQL also\nprovides a specification for how those queries are resolved in a server so that anyone\nGraphQL to write specifications that describe the type of data that can be queried\nto use the SDL to produce a specification for the products API.\ntice, this is the most common type of protocol used in GraphQL APIs.\nwishes to get a list of just product names and prices, with GraphQL they can do that.\nIn contrast, with other types of APIs, such as REST, you get a full list of details for each\nferent types of resources, and to expose those connections to our clients for use in\ntheir queries.\nFor example, in the products API, products and ingredients are differ-\nlist of products, including their names, prices, and their ingredients, with GraphQL\nclients to explore and query those connections, GraphQL makes an excellent choice.\nUsing a GraphQL API, a client can request a list of items with specific details.\nthis example, a client is requesting the name and price of each product in the products API.\nAPI has two types of \nproduct’s ingredients \nWe’ll learn how to define the types of our data, how to create meaning-\nful connections between resources, and how to define operations for querying the data\nrequirements for the products API, and that’s what we do in the next section!\nThis section discusses the requirements of the products API.\nIn particular, they must be able to query the stock of a product\nproducts API.\nknow which type of resources we should expose through the API and the products’ prop-\nmanages two types of resources: products and ingredients.\nThe CoffeeMesh platform offers two types of products: cakes and beverages.\nincluding the product’s name, price, size, list of ingredients, and its availability.\nCoffeeMesh exposes two types of products: Cake and Beverage, both of which share a \nList of properties that describe an ingredient.\nIn the following sections, we’ll learn to create a GraphQL\nspecification for the products API, and along the way we’ll learn how GraphQL works.\nOur first stop is GraphQL’s type system, which we’ll use to model the resources man-\nIntroducing GraphQL’s type system\nIn this section, we introduce GraphQL’s type system.\nIn GraphQL, types are defini-\nof a GraphQL API, and we use them to model the resources owned by the API.\nsection, you’ll learn to use GraphQL’s type system to describe the resources we\nThis section explains how we define the type of a property using GraphQL’s type sys-\nobject types are collection of properties that represent entities.\nThe syntax for defining a property’s type is very similar\nto how we use type hints in Python: we include the name of the property followed by a\nUsing GraphQL’s type system, we describe these\nGraphQL supports the following types of scalars:\nIntroducing GraphQL’s type system\nIn addition to defining the type of a property, we can also indicate whether the prop-\nThis line defines a property name of type String, and it marks it as non-nullable by\nThis section explains how we use GraphQL’s type system to model resources.\nare the entities managed by the API, such as the ingredients, cakes, and beverages that\nobject type.\nObject types are collections of properties, and as the name indicates, we use\nTo define an object type, we use the type keyword followed\nIn GraphQL, ID is a type with a unique value.\nThe following illustrates how we describe the cake resource as an object type.\nlisting contains the basic properties of the cake type, such as the ID, the name, and\ntype Cake {    \nthat every cake object returned by our API will contain an ID, a name, its availability,\nDefinition of the Cake object type\nWe define an object type.\ncode shows the definitions for the Beverage and Ingredient types.\nIngredient type.\ntype Beverage {\ntype Ingredient {\ntype Supplier {\nGraphQL’s type system by learning how to create our own custom types!\ncases, this list of scalar types is sufficient to model our API resources.\nhowever, GraphQL’s built-in scalar types might prove limited.\nSince the products API is used to manage products and ingredients and make\nDefinitions of the Beverage and Ingredient object types\ntype Cake {\nThis concludes our exploration of GraphQL scalars and object types.\nposition to define basic object types in GraphQL and create your own custom scalars.\ntypes, and we’ll learn how to use lists, interfaces, enumerations, and more!\nLists are arrays of types, and they’re defined by\ntype Ingredient {\nThe use of exclamation points for list types is one\nNow that we’ve learned about GraphQL’s type system and list properties, we’re ready\nbetween types.\nbetween object types\nThis section explains how we create connections between objects in GraphQL.\nmakes our GraphQL API more easily consumed.\nConnecting types through edge properties\nThis section explains how we connect types by using edge properties: properties that\npoint to another type.\nTypes can be connected by creating a property that points to\nanother type.\ntype with the Supplier type by adding a property called supplier to Ingredient that\ntype Ingredient {\ncan see in figure 8.7, we can reach the Supplier type from the Ingredient type, but\nneed to add a property to the Supplier type that points to the Ingredient type.\nlist of Ingredient types.\nwhat the new relationship between the Ingredient and the Supplier types looks like.\ntype Supplier {\nthe Ingredient and the Supplier types.\nTo connect the Ingredient type with the Supplier type, \nSupplier type.\ncreating a connection between two types, we call it an edge.\nCreating connections with through types\nthrough types to connect our products, cakes, and beverages, with their ingredients.\nSupplier types.\nIngredient’s supplier property points to the Supplier type, while the \na list of Ingredient types, but \nTo connect cakes and beverages with their ingredients, we’ll use a through type\ntype Cake {\ntype Beverage {\nthrough type, which allows us to detail how much of each ingredient goes into a cake recipe.\nthrough type.\nthrough types.\nBy creating connections between different object types, we give our API consumers\nMore often than not, we need to create properties that represent multiple types.\nexample from the products API!\nIn the products API, Cake and Beverage are two types of products.\nsaw how we connect Cake and Beverage with the Ingredient type.\nto the Ingredient type, which points to a list of Cakes and Beverages, like this:\ntype for that.\nIf we add new types of products to the system in the future, we don’t want to\nGraphQL offers two ways to bring various types together under a single type: unions\nInterfaces are useful when we have types that share properties in common.\nthe case for the Cake and the Beverage types, which share most of their properties.\ntypes.\nThe Cake and Beverage types implement ProductInterface,\ntype.\nBy looking at the ProductInterface type, any user of our API can quickly get an\nidea of which properties are accessible on both the Beverage and Cake types.\ncommon properties shared by our product types.\nWhile interfaces help us define the common properties of various types, unions\nthe Cake and Beverage types as a single Product type, and unions allow us to do that.\ninterface type.\nThe Cake type \never add a new type of product to the API, we can make sure it offers a similar inter-\nface to Cake and Beverage by making it implement the ProductInterface type.\noperations that use the Product union type.\nconstrain the values of object type properties through enumerations.\nThis section covers GraphQL’s enumeration type.\nFor example, in section 8.5.2, we defined a through type called Ingre-\nthe Cake types.\nDefining queries to serve data from the API\nproperty of the Ingredient type.\ntype Stock {    \ntype Ingredient {\nThis concludes our journey through GraphQL’s type system.\nblocks of an API specification, but without a mechanism to query or interact with them,\nGraphQL queries and mutations.\nDefining queries to serve data from the API\nThis section introduces GraphQL queries: operations that allow us to fetch or read data\nand GraphQL offers great flexibility to create a powerful query interface.\nreminder, these are the query operations that the products API needs to support:\nWe connect the Ingredient type \nwith the Stock type through \nthe products() query.\ntor our query parameters into their own type to improve readability and maintenance.\nThe specification of a GraphQL query looks similar to the signature definition of\na Python function: we define the query name, optionally define a list of parameters\nfor the query between parentheses, and specify the return type after a colon.\nfollowing code shows the simplest query in the products API: the allProducts()\nquery, which returns a list of all products.\ntype Query {    \nSuch a query is useful if we want to run an exhaustive analysis of all products, but in\nusing the products() query, which, according to the requirements we gathered in sec-\nquery.\nIt includes arguments that allows our API consumers to filter products by availabil-\nare free to use any or all of the query arguments, or none.\narguments when using the products() query, they’ll get a list of all the products.\ntype Query {\nIn addition to filtering the list of products, API consumers will likely want to be able to\na query in different sets of a specified size, and it’s commonly used in APIs to ensure\nSimple GraphQL query to return a list of products\nSimple GraphQL query to return a list of products\nAll queries are defined under \nthe Query object type.\nWe define the allProducts() query.\nthe return type of the query is.\nQuery parameters are \nDefining queries to serve data from the API\npet shows in bold the changes to the products() query after we add these arguments:\ntype Query {\nOffering numerous query arguments gives a lot of flexibility to our API consumers, but\nments in the products() query and includes a SortingOrder enumeration that con-\ntype Query {\nSetting default values for query arguments \nby setting its type to the \nThe signature of the products() query is becoming a bit cluttered.\nwe can refactor the arguments out of the query specification into their own type.\nGraphQL, we can define lists of parameters by using input types, which have the same\nlook and feel as any other GraphQL object type, but they’re meant for use as input for\nqueries and mutations.\ntype Query {\nThe remaining API queries, namely, allIngredients(), product(), and ingredient(),\nuct() and ingredient() return a single product or ingredient by ID, and therefore have\nID, the queries will return the details of the requested item; otherwise, they’ll return null.\ntype Query {\nNow that we know how to define queries, it’s time to learn about mutations, which are\nRefactoring query arguments into input types\nSpecification for all the queries in the products API\nresult of type Product.\nIn section 8.2, we discussed that the products API needs to support the following\na Product type.\nWe use type to\nusers to specify properties of each type, namely hasFilling and hasNutsTopping-\ntype Mutation {    \nthe Mutation object type.\nparameters into their own type.\nmutation by moving the list of parameters into an input type.\ntype Mutation {\ntype Mutation {\nlaunch a mock server using the products API specification and how to consume and\ninteract with the GraphQL API.\nWe use GraphQL’s scalar types to define the properties of an object type: Bool-\nGraphQL’s object types are collections of properties, and they typically repre-\nto another object, and by using through types.\nTo constrain the values of a property, we use enumeration types.\nGraphQL queries are operations that allow API clients to fetch data from the\nWhen queries and mutations have long lists of parameters, we can refactor\nInput types\ncan also be reused in more than one query or mutation.\nGraphQL APIs\nGraphQL offers a query language for web APIs, and in this chapter you’ll learn how\nto use this language to run queries on the server.\nmake queries against a GraphQL API.\ncover its available types, queries, and mutations.\nUnderstanding how GraphQL APIs\nthat makes it easier to run queries on the server.\nconsume a GraphQL API\nRunning queries and mutations against a \nGraphQL API\nTo illustrate the concepts and ideas behind GraphQL’s query language, we’ll run\nimplemented the API specification for the products API, we’ll learn to run a mock\nFinally, you’ll also learn to run queries against a\nIn this section, we’ll run a mock server on the products API.\nIn this chapter, we’ll use GraphQL Faker (https://github.com/APIs-guru/graphql\nwe’ll use to explore the API and run our queries.\nConsuming GraphQL APIs\nproducts API.\nour products API.\nTo discover the queries and mutations exposed by the API, click the Docs button on the\nup offering two choices: queries or mutations (see figure 9.3 for an illustration).\nparameterized queries\nAPI documentation explorer and query panel interface in GraphiQL\nmutations available in the API, as well as the types they return and their properties.\nConsuming GraphQL APIs\nselect queries, you’ll see the list of queries exposed by the server with their return\ntypes.\nYou can click the return types to explore their properties, as you can see in fig-\nIn the next section, we’ll start testing the GraphQL API!\nIntroducing GraphQL queries\nIn this section, we learn to consume a GraphQL API by running queries using\nWe’ll start with simple queries that don’t require any parameters, and then\nwe’ll move on to queries with parameters.\nRunning simple queries\nIn this section, we introduce simple queries that don’t take any parameters.\nucts API offers two queries of this type: allProducts(), which returns a list of all\nWe’ll use GraphiQL to run queries against the API.\nTo run the query, go to the\nshows how we run the allIngredients() query.\nAs you can see, to run a query we\nmust use the name of the query operation followed by curly braces.\nGraphQL queries must always include\ncalled a query document.\nA response to a successful query from a GraphQL API contains a JSON document with\nquery.\nWe query \nThe result of the query is \nafter the query itself.\nIntroducing GraphQL queries\nNow that we know the basics of GraphQL queries, let’s spice up our queries by adding\nRunning queries with parameters\nThis section explains how we use parameters in GraphQL queries.\nquery that requires a parameter.\nOne example of such a query is the ingredient()\nquery, which requires an id parameter.\ningredient() query with a random ID.\nAs you can see, we include the query parame-\nNow that we know how to run queries with parameters, let’s look at the kinds of prob-\nUnderstanding query errors\nGraphQL queries, and it teaches you how to read and interpret them.\nIf you omit the required parameter when running the ingredient() query, you’ll\nlocations—Specifies where in the query the error was found, including the\nListing 9.4 shows what happens when you run the query with empty parentheses.\nRunning a query with a required parameter\nConsuming GraphQL APIs\n# Query:\nOn the other hand, if you run the ingredient() query without any parentheses at all,\nUSE OF PARENTHESES IN GRAPHQL QUERIES AND MUTATIONS\nparameters of a query are defined within parentheses.\nIf you run a query with\nIf you run a query without parameters, you must omit the\nFor example, when we run the allIngredients() query, we\n# Query:\n\"message\": \"Field \\\"ingredient\\\" argument \\\"id\\\" of type \\\"ID!\\\" is \nMissing query parameter errors\nMissing query parameter errors\nquery without the required \nthe error in our query\nline of our query document.\nquery without the \nUsing fragments in queries\nin our queries, let’s explore queries that return multiple types.\nUsing fragments in queries\nThis section explains how we run queries that return multiple types.\nThe queries\nHowever, our product-related queries, such as allProducts()\nand product(), return the Product union type, which is the combination of the Cake\nand Beverage types.\nHow do we run our queries in this case?\nWhen a GraphQL query returns multiple types, we must create selection sets for\neach type.\n# Query\n\"message\": \"Cannot query field \\\"name\\\" on type \\\"Product\\\".\nline of our query document.\nquery without parameters.\nthird line of the query \nConsuming GraphQL APIs\nword and the type on which the selection set applies, as well as a selection of properties\nListing 9.7 fixes the allProducts() query by adding inline fragments that select prop-\nerties on the ProductInterface, Cake, and Beverage types.\ntype is Product, which is the union of Cake and Beverage, so we can select properties\nfrom both types.\nment the ProductInterface interface type, so we can conveniently select properties\nqueries more readable.\nselection set on the Cake type\nBeverage type\nNow that we know how to deal with queries that return multiple object types, let’s take\nIn the next section, we’ll learn to run queries with\na specific type of parameter called an input parameter.\nRunning queries with input parameters\nThis section explains how we run queries with input type parameters.\nwe learned that input types are similar to object types, but they’re meant for use as\nparameters for a GraphQL query or mutation.\nter of the products() query.\nHow do we call the products() query?\nWhen a query takes parameters in the form of an input type, the query’s input type\nWe call the products() query using Products-\nTo use any of the parameters in the input type, we\nNow that we know how to call queries with input parameters, let’s take a deeper look\nThis section explains how we select properties from multiple types by leveraging their\nIn section 8.5, we learned to create connections between object types\nby using edge properties and through types.\nCalling a query with a required parameter\nConsuming GraphQL APIs\nexample, in the products API, the Cake and Beverage types are connected with the\nIngredient type by means of a through type called IngredientRecipe.\nthis connection, we can run queries that fetch information about the ingredients\nIn this section, we’ll learn to build such queries.\nIn our queries, whenever we add a selector for a property that points to another\nwe add a selector for the ingredient property on the ProductInterface type, we have\nThe query selects the name of\ntypes to fetch information from both types in a single query, but we can take this fur-\nThe Ingredient type contains a supplier property, which points to the Supplier\ntype.\nSay we want to get a list of products, including their names and ingredients,\nQuerying nested object types\nTraversing the products API graph through connections between types\ntages in comparison with other types of APIs, such as REST.\nNow that we know how to traverse the graph of types in a GraphQL API, let’s take\nThis section explains how to run multiple queries per request and how to create\nmake multiple queries per request.\nRunning multiple queries in the same request\nLet’s say we wanted to obtain a list of all the products and ingredients available in the\nwith the allProducts() queries.\nwithin the same query document.\nBy including multiple queries within the same\nquery document, we make sure all of them are sent to the server in the same request,\nment that selects properties on the ProductInterface type.\nMultiple queries per request\nquery without parameters.\nConsuming GraphQL APIs\nAliasing our queries\nan anonymous query, the data returned by the server appears under a key named after\n# Query:\nallIngredients() query.\nQuery document\nQuery results\nIn GraphQL, we can run multiple queries within the same request, and \nquery.\nthe query\nQuery \nthe query for all products and ingredients shown in listing 9.12 becomes more read-\nresults of each query: the result of allProducts() appears under the product alias,\nand the result of the allIngredients() query appears under the ingredients alias.\nple, in listing 9.15, we run the products() query twice to select two datasets: one for\nby the same query: products.\nAs you can see, without query aliasing, this request\nallProducts() query\nallIngredients() query\nWe run the products() query\nConsuming GraphQL APIs\nTo resolve the conflict created by the queries in listing 9.15, we must use aliases.\nthe query that filters for available products and unavailableProducts for the query\nThe query returns an unsuccessful \nthat the query document \nquery document.\nproducts() query\nunavailable products() query\nproducts() query\nproducts() query\nThis concludes our overview of GraphQL queries.\nYou’ve learned to run queries with\nparameters, with input types, with inline and named fragments, and with aliases, and\nyou’ve learned to include multiple queries within the same request.\nBut no overview of the GraphQL query language would be complete with-\nThis section explains how we run GraphQL mutations.\nmutation is similar to running a query.\nintent: queries are meant to read data from the server, while mutations are meant to\nWhen we use mutations, we must start our query\nhas one required argument, a product ID, and its return value is a simple Boolean, so\ntype—The product type.\ninput—Additional product properties, such as its price, size, list of ingredients,\nThe full list of properties is given by the AddProductInput type.\naddProduct() returns a value of type Product, which means, in this case, we must\ntypes, so our selection set must use fragments to indicate which type’s properties we\nproperty on the ProductInterface type.\naddProduct(name: \"Mocha\", type: beverage, input: {price: 10, size: BIG, \nCalling a mutation with input parameters and complex return type\nConsuming GraphQL APIs\nRunning parameterized queries and mutations\nThis section introduces parameterized queries and explains how we can use them to\nqueries and mutations that require parameters, we defined the values for each param-\nGraphQL offers a solution for this, which is to use parameterized queries.\nusing GraphiQL (the code for the query is also shown in listing 9.19 so that you can\nQuery document\nGraphiQL offers a Query Variables panel where we can include the input values for our \nparameterized queries.\nRunning parameterized queries and mutations\nassign values for the query/mutation parameters in a query variables object.\n# Query document\n# Query variables\n\"type\": \"beverage\",    \nCreating a query/mutation wrapper.\ntion wrapper around the query or mutation.\nwe use to define a query.\nProduct()), we specify the expected type of the parameterized arguments.\nParameterizing through a query variables object.\nwrap multiple queries or mutations, all the parameterized arguments must be defined\nthe type parameter.\nConsuming GraphQL APIs\nquery from listing 9.19 to include a call to the deleteProduct() mutation.\n# Query document\nQuery wrapper for\nmutation CreateProduct( $name: String!, $type: ProductType!, $input: AddProductInput!\nQuery parameters\n\"type\": \"beverage\",\nwith their types.\nTo parameterize queries and mutations, we create a function wrapper around the query or \nDemystifying GraphQL queries\n# Query variables\n\"type\": \"beverage\",\ncan now inspect any GraphQL API, explore its types, and play around with its queries\nDemystifying GraphQL queries\nThis section explains how GraphQL queries work under the hood in the context of\nGraphQL API and to interact with it.\nGraphiQL are interfaces that make it easier to interact with a GraphQL API.\nTo send a request to a GraphQL API, you can use either of the GET or POST\nters, and if you use POST, you include the query in the request payload.\nLet’s run the allIngredients() query, selecting only the name property of each\nSince this is a GET request, our query document must be included in the\nURL as a query parameter.\nConsuming GraphQL APIs\nURL: http:/ /localhost:9002/graphql?query=%7BallIngredients%7Bname%7D%7D.\n'query={allIngredients{name}}'\nNow that you understand how GraphQL API requests work under the hood, let’s see\nGraphQL API.\nCalling a GraphQL API with Python code\nThis section illustrates how we can interact with a GraphQL API using Python.\nListing 9.21 shows how we call the allIngredients() query, adding a selector\nrequests, we send the query document in the form of URL-encoded data.\nthe GraphiQL query panel, and the result from the API also looks the same.\nquery_document = '''     \nscalar types supported by GraphQL in chapter 8 to making complex queries using tools\nspecification for the products API, and we interacted with it using a GraphQL mock\nWhen we call a query or mutation that returns an object type, our query must\nfrom the object returned by the query.\nWhen a query or mutation returns a list of multiple types, our selection set must\nFragments are selections of properties on a specific type,\nWhen calling a query or mutation that includes arguments, we can parameter-\nCalling a GraphQL query using Python\nThe query \nserver with the query document\nas a URL query parameter.\nConsuming GraphQL APIs\nBehind the scenes, a GraphQL query is a simple HTTP request that uses either\nIn chapter 8, we designed a GraphQL API for the products service, and we pro-",
      "keywords": [
        "products API",
        "GraphQL APIs",
        "API",
        "query",
        "type",
        "GraphQL",
        "products",
        "Ingredient",
        "Consuming GraphQL APIs",
        "Designing GraphQL APIs",
        "APIs",
        "String",
        "Ingredient type",
        "APIs type Cake",
        "GraphQL APIs ingredients"
      ],
      "concepts": [
        "queries",
        "query",
        "queried",
        "types",
        "list",
        "graphql",
        "product",
        "apis",
        "api",
        "ingredients"
      ],
      "similar_chapters": [
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 10,
          "title": "",
          "score": 0.941,
          "base_score": 0.791,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 384,
          "title": "",
          "score": 0.893,
          "base_score": 0.743,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 382,
          "title": "",
          "score": 0.817,
          "base_score": 0.667,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 2,
          "title": "",
          "score": 0.782,
          "base_score": 0.632,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 9,
          "title": "",
          "score": 0.718,
          "base_score": 0.568,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "query",
          "type",
          "queries",
          "graphql",
          "types"
        ],
        "semantic": [],
        "merged": [
          "query",
          "type",
          "queries",
          "graphql",
          "types"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.3849790804981395,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:35.193112+00:00"
      }
    },
    {
      "chapter_number": 10,
      "title": "Building GraphQL APIs with Python",
      "start_page": 262,
      "end_page": 294,
      "summary": "The products API specification is available under ch10/web/products.graphql in\ntypes that represent the data we can retrieve from the API and a set of queries and\nqueries and mutations defined in the schema return either an array or a single\ninstance of the Ingredient and Product types.\nobject type, so we’ll look at queries and mutations that use this type first.\nProduct is\nthe union of the Beverage and Cake types, both of which implement the Product-\nAs we’ll see, implementing queries and mutations that return union\nA query that returns a list of Product objects contains\ninstances of both the Beverage and Cake types, so we need to implement additional\nIn this section, we discuss the tech stack that we’ll use to implement the products API.\nWe discuss which libraries are available for implementing GraphQL APIs in Python,\nto the Python ecosystem that allows you to implement a GraphQL server using a\nWe’ll learn how to run a GraphQL server with Ariadne, how\nto load a GraphQL specification, and how to implement a simple GraphQL resolver.\nAs we saw in chapter 9, users interact with GraphQL APIs by running queries and\nA GraphQL resolver is a function that knows how to execute one of those\nIn our implementation, we’ll have as many resolvers as queries\nresolvers are the pillars of a GraphQL server since it’s through resolvers that we can\ntype Query {\nschema defines only one query, named hello(), which returns a string.\nTo expose this query through our GraphQL server, we need to implement a resolver\nquery {\nResolvers\nproducts\nTo serve data to a user, a GraphQL server uses resolvers, which are functions that \nAriadne can run a GraphQL server from this simple schema definition.\nple, when we return the payload for a query, Ariadne validates the payload against\nOnce we’ve loaded the schema, we can initialize our server using Ariadne’s GraphQL\nproducts.graphql\nAriadne resolvers\n(resolvers and data validation)\nTo run the GraphQL server with Ariadne, we produce an executable \nschema by loading the GraphQL schema for the API and a collection of resolvers \ntype Query {     \nserver = GraphQL(make_executable_schema(schema), debug=True)  \nHow can we make the hello() query return a\nResolvers are functions that let the server know how to produce\nTo make the hello() query return an actual string,\nwe need to implement a resolver.\nLet’s create a resolver that returns a string of 10 ran-\nResolver parameters in Ariadne\nAriadne’s resolvers always have two positional-only parameters, which are commonly\na parent resolver, in which case obj will be set to the value returned by the parent\nresolver.\nWe encounter the latter case when a resolver doesn’t return an explicit type.\nFor example, the resolver for the allProducts() query, which we’ll implement in\nIt returns an object of type Product,\nobject, Ariadne needs to call a resolver for the Product type.\ntype_resolver(obj={...}, info={...})\nresolve_all_products(obj, info)\nresolver is None,\nresolver, obj will be\nresolver.\nWhen a resolver \nresolver, the obj \nA resolver needs to be bound to its corresponding object type.\nable classes for each GraphQL type:\nQueryType for query types.\nIn GraphQL, the query type represents the collec-\nquery is a function that reads data from a GraphQL server.\nSince hello() is a query, we need to bind its resolver to an instance of Ariadne’s Query-\nType.\ntor method to bind our resolver, which is available on most of Ariadne’s bindable\nclasses and allows us to bind a resolver to a specific field.\nAriadne’s resolvers always get two positional-only\nresolvers, we need to pass our bindable objects as an array to the make_executable_\nImplementing a GraphQL resolver with Ariadne\nImplementing the products API\ntype Query {     \nserver = GraphQL(make_executable_schema(schema, [query]), debug=True)    \nschema with Ariadne, how to run the GraphQL server, and how to implement a resolver\nthe GraphQL API for the products service.\nImplementing the products API\nGraphQL API for the products service.\nthe queries and mutations of the products API, to handle query parameters, and to\nframework and various strategies for testing and implementing GraphQL resolvers.\nIn this section, we structure our project for the products API implementation.\nWe bind a resolver for the hello() query \nmutations.py will contain resolvers for the mutations in the products API.\nqueries.py will contain resolvers for queries.\ntypes.py will contain resolvers for object types, custom scalar types, and object\nThe products.graphql specification file also goes under the web folder, since it’s han-\nfrom the ch10/web/products.graphql file in the GitHub repository for this book.\n├── products.graphql\ninstance of Ariadne’s GraphQL class and load an executable schema from the products\nImplementing the products API\nThe API specification for the products API is available under the web/products.graphql\nWe then pass the resulting schema object to Ariadne’s GraphQL\nning any of the queries defined in the products API specification; however, most of\nQuery.allProducts.” The server doesn’t know how to produce a value for the Ingredient\ntype since we don’t have a resolver for it, so let’s build it!\n10.4.3 Implementing query resolvers\nIn this section, we learn to implement query resolvers.\nquery resolver is a Python function that knows how to return a valid payload for a\nWe’ll build a resolver for the allIngredients() query, which is one of\nthe simplest queries in the products API specification (listing 10.3).\nTo implement a resolver for the allIngredients() query, we simply need to cre-\nate a function that returns a data structure with the shape of the Ingredient type,\n# file: web/products.graphql\ntype Ingredient {\nSpecification for the Ingredient type\nResolver\nQuery\ntype Ingredient {\ndef resolve_all_ingredients(obj, info):\n‘products’: [],\nresolve_all_ingredients\nis a resolver for the\nGraphQL uses resolvers to serve the query requests sent by the user to the \nA resolver is a Python function that knows how to return a valid payload for a given \nquery.\nproducts.\nImplementing the products API\n'products': [],\nNow that we have some data, we can use it in the allIngredients()’ resolver.\nSince this is a resolver for a query type, the implementation goes under the\ndef resolve_all_ingredients(*_):\nTo enable the query resolver, we have to pass the query object to the make_executable_\n(Path(__file__).parent / 'products.graphql').read_text(), [query]\nA resolver for the allIngredients() query\nresolver using the \nLet’s write a more complex query to test our resolver more\nThe following query selects the id, name, and description of an ingredi-\nproducts {\n\"products\": [],\nto implement resolvers for simple queries, in the next section, we’ll learn to imple-\n10.4.4 Implementing type resolvers\nIn this section, we’ll learn to implement resolvers for queries that return multiple\ntypes.\nThe allIngredients() query is fairly simple since it only returns one type of\nobject: the Ingredient type.\nImplementing the products API\nCake implement the ProductInterface type, we know they both require an id, a\nname, a list of ingredients, and a field called available, which signals if the product\ntype Ingredient {\ntype Beverage implements ProductInterface {\nThe allIngredients() query returns an array of Ingredient \nobjects, while the allProducts() query returns an array of Product objects, \nwhere Product is the union of two types: Beverage and Cake.\nproducts = [\nResolver for the allProducts() query\ntype\nProduct\ntype\nProduct is the union of the Beverage and the Cake types, both of which implement the \nSince Beverage and Cake implement the same interface, both types \nImplementing the products API\nNow that we have a list of products, let’s use it in the allProducts()’ resolver.\nfrom web.data import ingredients, products\ndef resolve_all_products(*_):\nreturn products      \nLet’s run a simple query to test the resolver:\nresolver using the field() \nIn these situations, we need a type resolver.\nAs you can see in figure 10.7, a type resolver is a Python function that determines what\ntype an object is, and it returns the name of the type.\nWe need type resolvers in queries and mutations that return more than one object\ntype.\nIn the products API, this affects all queries and mutations that return the Prod-\nuct type, such as allProducts(), addProduct(), and product().\ntypes, you’ll need to implement a type resolver.\nmutations that return union types and object types that implement interfaces.\nListing 10.7 shows how we implement a type resolver for the Product type in Ariadne.\nThe type resolver function takes two positional parameters, the first of which is an\nQuery resolver\ndef resolve_all_products(obj, info):\nType resolver\ndef resolve_product_type(obj, info):\nA type resolver is a function that determines the type of an object.\nexample shows how the resolve_product_type() resolver determines the type of \nan object returned by the resolve_all_products() resolver.\nImplementing the products API\nThe type resolver must be bound to the Product type.\nSince Product is a union type,\nits type.\nTo resolve the type\nSince this is a type resolver, this code goes\n# file: web/types.py\nproduct_type = UnionType('Product')    \n@product_type.type_resolver      \ndef resolve_product_type(obj, *_):   \nImplementing a type resolver for the Product union type\nType resolver\ndef resolve_product_type(obj, info):\nA type resolver inspects the properties of a payload to determine its type.\nexample, resolve_product_type() looks for distinguishing properties that differentiate a Cake \nfor the Product type using \nresolver using the \nTo enable the type resolver, we need to add the product object to the make_executable_\nfrom web.types import product_type\n[query, product_type]\nYou have just learned to implement type resolv-\ners and to handle queries that return multiple types!\nIn this section, we learn to handle query parameters in the resolvers.\nries in the products API accept filtering parameters, and all the mutations require at\nfrom the products API: the products() query, which accepts an input filter object\nHow do we access this filter object in a resolver?\nAs you can see in figure 10.9, when a query or mutation takes parameters, Ariadne\nhow we access the input parameter for the products() query resolver.\nsortBy—An enumeration type that allows us to sort products by price or name\nImplementing the products API\n@query.field('products')     \ndef resolve_products(*_, input=None):     \nAccessing input parameters in a resolver\nresolve_products(\nQuery parameters are passed to our resolvers \nresolve_products() resolver is called, with the input \nresolver using the \nof products.\nproducts by\nLet’s run a query to test this resolver:\nproducts(input: {available: true}) {\nexamples here are to illustrate how you use the query parameters in the resolver.\nImplementing the products API\nfrom web.data import ingredients, products\n@query.field('products')\ndef resolve_products(*_, input=None):\nMutation resolvers are similar to query resolvers,\nWe resolve the \n10.4.6 Implementing mutation resolvers\nIn this section, we learn to implement mutation resolvers.\nresolver follows the same guidelines we saw for queries.\nwe use to bind the mutation resolvers.\nLet’s have a look at implementing the resolver for the addProduct() mutation.\nparameters: name, type, and input.\nFinally, the addProduct() mutation must return a product type.\nListing 10.10 shows how we implement the resolver for the addProduct() muta-\naddProduct() must return a valid Product object, so we\nresolve_add_product(\ntype\nMutation parameters are passed to our resolvers as keyword \nThis example illustrates how the resolve_add_product() \nresolver is called, with the name, type, and input parameters passed as \nImplementing the products API\nSince Product\nfrom web.data import products\ndef resolve_add_product(*_, name, type, input):       \nproduct = {    \nreturn product\nTo enable the resolver implemented in listing 10.10, we need to add the mutation\nfrom web.types import product_type\nResolver for the addProduct() mutation\nresolver using the \nproduct as a \n[query, mutation, product_type]\naddProduct(name: \"Mocha\", type: beverage, input:{ingredients: []}) {\nwe’ll take this further by learning how to implement resolvers for custom scalar types.\n10.4.7 Building resolvers for custom scalar types\nIn this section, we learn how to implement resolvers for custom scalar types.\nin chapter 8, GraphQL provides a decent amount of scalar types, such as Boolean,\nproducts API contains a custom scalar called Datetime.\nthe Ingredient and Product types have a Datetime scalar type.\nresolver for it.\nImplementing the products API\nthe Datetime scalar in the products API, we have to implement a method to\nWhen the GraphQL server sends data to the user, it transforms native Python objects into \nments a type resolver.\n# file: web/types.py\nImplementing the products API\nfrom web.types import product_type, datetime_scalar\n[query, mutation, product_type, datetime_scalar]\ntopic we need to explore: implementing resolvers for the fields of an object type.\n10.4.8 Implementing field resolvers\nIn this section, we learn to implement resolvers for the fields of an object type.\nimplemented nearly all the resolvers that we need to serve all sorts of queries on the\nproducts API, but there’s still one type of query that our server can’t resolve: queries\nFor example, the Products type has a\n# file: web/products.graphql\nobject type.\nThis means that, when we query the ingredients field of a product, we\nquery against the server:\nImplementing the products API\ncould make sure that each ingredient payload is correctly built in the resolvers for\neach query that returns a Product type.\nproduct’s ingredients property to make sure it contains a full ingredient payload.\nof products.\ndef resolve_all_products(*_):\nreturn products_with_ingredients    \nUpdating products to contain full ingredient payloads, not just IDs\nproducts with\nresolver, we can create a specific resolver for the product’s ingredients property and\nfor the product’s ingredients property looks like and goes under web/types.py since\nit implements a resolver for object properties.\n# file: web/types.py\n@product_interface.field('ingredients')\ndef resolve_product_ingredients(product, _):\nImplementing a field resolver\nQuery resolver\ndef resolve_all_products(obj, info):\nField resolver\nProduct\ndef resolve_product_ingredients(obj, info):\nGraphQL allows us to create resolvers for specific fields of an object.\nresolve_product_ingredients() resolver takes care of returning a valid payload for the \ningredients property of a product.\nhaving to perform this operation in every resolver that returns a product type.\nresolver.\nYou have to know that there’s a resolver for products’ ingredients and look\ninto that resolver.\nYou can use the Ariadne framework to implement GraphQL APIs following a\nFor each query and mutation in the API specification, we need to implement a\nresolver.\nTo register a resolver, we use one of Ariadne’s bindable classes, such as Query-\nresolver function.\ntype, we must implement a resolver that knows how to determine the type of an\nobject; otherwise, the GraphQL server doesn’t know how to resolve it.\ntom scalar, we must implement resolvers that know how to serialize, parse, and\nvalidate the custom scalar type; otherwise, the GraphQL server doesn’t know",
      "keywords": [
        "products API",
        "Product",
        "Building GraphQL APIs",
        "GraphQL APIs",
        "Ariadne",
        "API",
        "resolver",
        "type",
        "query",
        "GraphQL",
        "products API specification",
        "Ingredient",
        "products API datetime",
        "Python",
        "type resolver"
      ],
      "concepts": [
        "resolve",
        "resolving",
        "products",
        "type",
        "queries",
        "query",
        "implementing",
        "implement",
        "implementations",
        "list"
      ],
      "similar_chapters": [
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 8,
          "title": "",
          "score": 0.941,
          "base_score": 0.791,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 384,
          "title": "",
          "score": 0.822,
          "base_score": 0.672,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 382,
          "title": "",
          "score": 0.708,
          "base_score": 0.558,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 9,
          "title": "",
          "score": 0.658,
          "base_score": 0.508,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 2,
          "title": "",
          "score": 0.628,
          "base_score": 0.478,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "resolver",
          "type",
          "products",
          "resolvers",
          "query"
        ],
        "semantic": [],
        "merged": [
          "resolver",
          "type",
          "products",
          "resolvers",
          "query"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.3748207983394735,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:35.193143+00:00"
      }
    },
    {
      "chapter_number": 11,
      "title": "kicks off",
      "start_page": 295,
      "end_page": 331,
      "summary": "API authorization it’s Open Authorization (OAuth) 2.1.\nment a robust API authentication and authorization strategy for your APIs.\nAPI authorization\nour APIs\nour API users\nUnderstanding JSON Web Tokens (JWT) and \nmiddleware to our APIs\nAPI authorization and authentication\nlearn to prevent unauthorized access to your APIs by using standard authentication\nIn my experience, API authentication and authorization are two of the most con-\nable to add a robust authorization flow to your own APIs.\nAuthentication is the process of verifying the identity of a user, while authorization\nhow to validate authorization tokens.\nproduce signed tokens and to validate them.\nof adding authentication and authorization to the orders API.\nPyJWT is a Python library that allows us to work with JSON Web Tokens, while cryptog-\nworld of user authentication and authorization.\nauthorization flows for our APIs. 11.2.1 Understanding Open Authorization\nOAuth allows a user to grant a third-party application access to protected resources\nOAuth is an open standard that allows users to grant access to\naccess is granted by issuing a token, which the third-party application uses to\naccess the user’s information.\nand grants access to LinkedIn. Facebook issues a token that LinkedIn\nWith OAuth, a user can grant a third-party application access to their information on another \nAPI authorization and authentication\ntemporary token LinkedIn can use to import Susan’s contacts.\nClient—The application or server requesting access to the user’s resources.\nOAuth offers four different flows to grant authorization to a user depending on the\nOAuth flows are the strategies that a client application uses to authorize their access\nto an API.\nTVs to obtain access tokens.\nAUTHORIZATION CODE FLOW\nIn the authorization code flow, the client server exchanges a secret with the authoriza-\nan access token.\nauthorization code flow designed to protect applications whose source code is publicly\nAPI server\nThe server request the user's data.\ntoken.\nfor an access token.\naccess token.\nIn the authorization code flow, the authorization server produces a signing URL, which \nthe user can use to prove their identity and grant access to the third-party application.\nAPI authorization and authentication\nsending an authorization request to the server, the client includes both the code veri-\ntion code, which the client can exchange for an access token.\nTo get the access token,\nAPI server\nAuthorization request with code challenge\nAccess token\nRequest user’s data\nIn the PKCE flow, an SPA served by the client requests access to the user’s data directly \ntion attacks, in which a malicious user intercepts the authorization code and uses it to\nget hold of an access token.\ncan see in figure 11.4, it involves the exchange of a secret to obtain an access token.\nThe refresh token flow allows clients to exchange a refresh token for a new access\ntoken.\nFor security reasons, access tokens are valid for a limited period of time.\naccess token has expired, and to obtain the new token they use the refresh token flow.\nAs you can see in figure 11.5, API clients typically receive both an access token and\na refresh token when they successfully gain access to the API.\nyou refresh your access token, you’ll get a new refresh token.\nan access token.\nissues the access token.\nAPI server\nAccess the API\nthe authorization server to obtain an access token.\nAPI authorization and authentication\nit allows users to use the same identity across different websites without having to cre-\nAPI server\nAuthorization request\nAccess token + efresh token\nRequest user’s data\nRefresh access token\nTo allow API clients to use refresh tokens to continue communicating with the API server after \nthe access token has expired, the authorization server issues a new refresh token every time the client \nrequests a new access token.\nID token\nAccess token\nAccess token\nserver issues an ID token\nand an Access token.\ntoken to access the\nissues an ID token and an access \ntoken, which the user can use to \nSince OIDC is built on top of OAuth, we can use any of the authorization flows\ndescribed in the previous section to authenticate and authorize users.\ntypes of tokens: ID tokens and access tokens.\nWeb Tokens, but they serve different purposes: ID tokens identify the user, and they\nYou use ID tokens only to verify the user identity, and never to determine\nwhether a user has access to an API.\nAPI access is validated with access tokens.\ntokens typically don’t contain user information but a set of claims about the access rights\nID TOKENS VS.\nACCESS TOKENS\nID tokens and access tokens.\nID tokens are tokens that carry the identity of\nnot for validating access to an API.\nAPI access is validated through access\ntokens.\nAccess tokens rarely contain a user’s identity details, and instead con-\ntain claims about the user’s right to access the API.\nbetween ID tokens and access tokens is the audience: the ID token’s audience is\nthe authorization server, while the access token’s audience is our API server.\ntokens.\n\"token\",\n\"id_token\",\n\"code token\",\n\"code id_token\",\n\"token id_token\",\nAPI authorization and authentication\n\"code token id_token\",\nauthorization access token, which URL returns user information, or which URL we\nuse to revoke an access token.\nWorking with JSON Web Tokens\nIn OAuth and OpenID Connect, user access is verified by means of a token known as\nJSON Web Token, or JWT.\nA JWT is a token that represents a JSON document.\nmally signed with a private secret or a cryptographic key.6 A typical JSON Web Token\n6 The full specification for how JSON Web Tokens should be produced and validated is available under J.\nSakimura, “JSON Web Token (JWT),” RFC-7519, May 2015, https://datatracker.ietf.org/\nWorking with JSON Web Tokens\nHeader—Identifies the type of token as well as the algorithm and the key that\nwere used sign the token.\nlist of reserved claims that identify the issuer of the token (the authorization\nserver), the token’s audience or intended recipient (our API server), and its\nwhether the user has access to the API.\nJWTs contain a header that describes the type of token, as well as the algorithm and\nthe key used to sign the token.\nvate/public key pair to sign the token.\nabout the token itself, a payload with claims \nabout the user’s access to the website, and \nthe token.\nAPI authorization and authentication\ntyp—Tells us that this is a JWT token\nkid—Tells us that the key used to sign the token has the ID \nA token’s signature can only be verified using the same secret or key that was used to\nFor security, we often use a collection of secrets or keys to sign the tokens.\nkid field tells us which secret or key to use to sign the token so that we can use the\ntokens, chances are the token isn’t for your API server unless you’re the creator of the\ntokens issued by the Azure Active Directory to access its Graph API contain a nonce\ntoken, which means you shouldn’t use those tokens to authorize access to your custom\nAPIs. Now that we understand the properties of a token’s header, the next section\ntoken’s signature is correct by using a public key.\nWorking with JSON Web Tokens\nour API server.\ncheck this field to validate that the token is intended for our APIs. If we don’t\nRequests with expired tokens must be rejected.\nAPIs can use this value to control access to the resources owned by this user in\nAPI authorization and authentication\naud tells us that this token has been issued to grant access to the orders API.\nthe value of this field is a different URL, the orders API will reject the request.\nazp tells us that the token has been requested by an application with identifier\nNow that we know how to work with token claims, let’s see how we produce and vali-\nTo produce a signed token with this payload, we use PyJWT’s encode() function, pass-\ning in the token, the key to sign the token, and the algorithm we want to use to sign\nthe token:\nWorking with JSON Web Tokens\nFor a more secure encryption, we use a private/public key pair to sign the token with\nNow that we have a private/public key pair, we can use them to sign our tokens\ntents of listing 11.2, which shows how to generate JWT tokens signed with a private\nto sign the token (RS256).\nAPI authorization and authentication\ntoken validation is failing, it’s useful to inspect the payload and verify whether its\nnew token.\nYou can also verify the token’s signature by providing your public key.\nthe contents of that file into the public key input panel in jwt.io to verify the token’s\nWorking with JSON Web Tokens\nFor example, to decode the token’s header\nYou can also verify the token’s signature by pasting the public key in \nAPI authorization and authentication\na valid signature shouldn’t be accepted by the API server, while an active token with an\nEvery user request to the server must carry a\ntoken, and the token must be validated on each request.\nWhen a user interacts with our API server,\nthey must send a JWT in each request, and we must validate the token on\ntion code flow we discussed in section 11.2.1, store tokens in a session cache\nand check the request’s token against the cache.\nAs we saw in section 11.3.3, tokens can be signed with a secret key or with a pri-\nFor security, most websites use tokens that are signed with pri-\nvate/public keys, and to validate the signature of such tokens, we use the public key.\nLet’s see how we validate a token in code.\nsection 11.3.3 to produce and validate the token.\nrunning pipenv shell, and execute the jwt_generator.py script to issue a new token.\nTo validate the token, we must first load the public key using the following code:\nNow that we have the public key available, we can use it to validate a token with the\n>>> access_token = \"eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiJ...\"\n>>> jwt.decode(access_token, key=public_key, algorithms=['RS256'], \n➥ audience=[\"http:/ /127.0.0.1:8000/orders\"])\n➥ b41e4831a962', 'aud': 'http:/ /127.0.0.1:8000/orders', 'iat': \nAs you can see, if the token is valid, we’ll get back the JWT payload.\nIf the token is\ndate JWTs, let’s see how we authorize requests in an API server.\nAdding authorization to the API server\nAdding authorization to the API server\nNow that we know how to validate access tokens, let’s put all this code together in our\nAPI server.\nIn this section, we add authorization to the orders API.\nthe orders API are protected, while others must be accessible to everyone.\nto ensure that our server checks for valid access tokens under the protected endpoints.\nWe’ll allow public access to the /docs/orders and the /openapi/orders.json end-\nAll other endpoints require valid tokens.\nHow do we add authorization to our APIs?\nitate service discovery, but it can also be used to authorize user access, validate access\ntokens, and enrich the request with custom headers that add information about the\nThe second method is to handle authorization within each API.\nhandle authorization within the service since we don’t have an API gateway.\nSince authorization is needed to validate user access to the service through\nSince authorization controls access to our server, the authorization middleware\nnamed orders/web/api/auth.py and copy the code in listing 11.3 into it.\nTo validate the token, we first\nvalidate the token, passing in as parameters the token itself, the public key required\nto validate the token, the expected list of audiences, and the algorithms used to sign\nAPI authorization and authentication\n# file: orders/web/api/auth.py\ndef decode_and_validate_token(access_token):\nValidates an access token.\nIf the token is valid, it returns the token payload.\naccess_token,\nAdding an authorization module to the API\nauthorization token.\nAdding authorization to the API server\na JWT, let’s incorporate it into the API by adding a middleware that uses it to validate\naccess to the API.\nTo add authorization to our API, we create an authorization middleware.\ninto the orders/web/app.py file, with the newly added code in bold.\ntest for the request user.\nNext, we check whether the user is requesting the API documentation.\nto authorize the request.\nto check which origins, methods, and request headers are accepted by the API server,\nCORS requests aren’t authenticated, so when we add authorization to\nIf it’s not a CORS request, we attempt to capture the token from the request headers.\nWe expect the token under the Authorization header.\nAPI authorization and authentication\nThe format of the Authorization header’s value is Bearer <ACCESS_TOKEN>, so if the\nAuthorization header is found, we capture the token by splitting the header value\ntoken is valid, and therefore we can process the request, so we return a call to the next\nWe also store the user ID from the token payload in the request’s state\nfrom orders.api.auth import decode_and_validate_token\nAdding an authorization middleware to the orders API\nAdding authorization to the API server\nrequest.state.user_id = \"test\"    \nbearer_token = request.headers.get(\"Authorization\")   \n\"detail\": \"Missing access token\",\n\"body\": \"Missing access token\",\ntoken_payload = decode_and_validate_token(auth_token)     \nrequest.state.user_id = token_payload[\"sub\"]    \nfrom orders.api import api\nauthorization code at work.\nthe token\nIf the token is \nuser ID from the \nAPI authorization and authentication\nAs you can see, a request with a missing token is rejected with a 401 error and a mes-\nsage telling us that the access token is missing.\nNow generate a token using the jwt_\ngenerator.py script we implemented in section 11.3.3, and use the token to make a\nIf the token is valid, this time you’ll get a successful response with a list of orders.\nauthorization code is working!\nAuthorizing resource access\nfrom orders.api.auth import decode_and_validate_token\nfrom orders.api import api\nOur server can now authorize users and handle CORS requests.\nAuthorizing resource access\nWe’ve protected our API by making sure only authenticated users can access it.\nwe must ensure that the details of each order are only accessible to the user who\nplaced it; we don’t want to allow users to access each other’s data.\nvalidation authorization, and in this section, you’ll learn to add it to your APIs. Listing 11.5\nAPI authorization and authentication\n11.5.1 Updating the database to link users and orders\nbetween each order and a user.\norder with a user?\nA typical strategy is to create a user table and link our orders to user\nEach user has already an ID, and\nAll we need to do is add a new column to the orders table to store the ID of the user\nAuthorizing resource access\nuser table that is directly accessed by multiple services to create foreign keys\nListing 11.6 shows how we add a user_id field to the OrderModel class.\nAdding a user ID foreign key to the order table\nuser_id.\nAPI authorization and authentication\nAuthorizing resource access\n$ PYTHONPATH=`pwd` alembic revision --autogenerate -m \"Add user id to order table\"\nOur database is now ready to start linking orders and users.\nhow we fetch the user ID from the request object and feed it to our data repositories.\n11.5.2 Restricting user access to their own resources\nNow that our database is ready, we need to update our API views to capture the user\nuser ID when placing the order.\nsaw in section 11.4.2, we store the user ID under the request’s state property, so the\nThe second change is passing the user ID to the Order-\n# file: orders/web/api/api.py\ndef create_order(request: Request, payload: CreateOrderSchema):     \norder = orders_service.place_order(order, request.state.user_id)   \nCapturing the user ID when placing an order\nAPI authorization and authentication\ndef place_order(self, items, user_id):\nreturn self.orders_repository.add(items, user_id)\nuser ID:\nNow that we know how to save an order with the user ID, let’s see how we make sure a\nuser gets only a list of their own orders when they call the GET /orders endpoint.\n# file: orders/web/api/api.py\nEnsuring a user only gets a list of their own orders\nAuthorizing resource access\ncating that the user doesn’t have access to the requested resource.\nThe user ID will become an\nThe following code shows the changes required to the get_order() function to\ninclude the user ID in our queries, with the newly added code in bold.\ninclude the request object in the function signature, and we pass on the user ID to the\n# file: orders/web/api/api.py\ndef get_order(request: Request, order_id: UUID):\norder_id=order_id, user_id=request.state.user_id\nTo be able to query orders by user ID as well, we also need to update the Orders-\nFiltering orders with order ID and user ID\nAPI authorization and authentication\nThe rest of the view functions in the orders/web/api/api.py file require changes simi-\nThis concludes our journey through API authentication and authorization, and\nFinally, you’ve learned how to authorize API requests and how to authorize user access\nauthorization to your own APIs!\nWe authorize access to our APIs using the standard protocols OAuth and OpenID\n– Authorization code—The API server exchanges a code with the authorization\nserver to request the user’s access token.\ncode challenge to obtain an access token from the authorization server.\nvate secret in return for an access token.\n– Refresh token—A client obtains a new access token in exchange for a refresh\ntoken.\nJWTs are JSON documents that contain claims about the user’s access permis-\nTo authenticate a request, users send their access tokens in the request’s Autho-\n<ACCESS_TOKEN>.\nWe use PyJWT to validate access tokens.\nIf the token is invalid, we reject the request\nTo link users to their resources, we use the user ID as represented in the sub\nThis chapter teaches you how to test and validate API implementations.\nIn this chapter, we learn how to run an exhaustive test suite against our API\nAPI server.\nyour API development cycle, while Schemathesis runs a robust test suite that is useful\nTo illustrate how we test REST APIs, we’ll use the orders API, which we imple-\nThe orders API is the interface to the orders service, which manages cus-\ntomers’ orders, while the products API is the interface to the products service, which\nWithin this folder, we’ll copy the orders API and the products API.\nkeep things simple in this chapter, we use the implementation of the orders API as we\nChapter 6 contains a full implementation of the orders API, but it\nWithin the ch12 folder, copy the implementation of the orders API from",
      "keywords": [
        "API",
        "API authorization",
        "JSON Web Tokens",
        "token",
        "access token",
        "API server",
        "authorization",
        "orders API",
        "access",
        "JWT",
        "user",
        "APIs",
        "orders",
        "Authorization server",
        "Authorization code"
      ],
      "concepts": [
        "apis",
        "api",
        "orders",
        "tokens",
        "users",
        "requesting",
        "request",
        "authorization",
        "authorize",
        "accessible"
      ],
      "similar_chapters": [
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 400,
          "title": "",
          "score": 0.736,
          "base_score": 0.586,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 396,
          "title": "",
          "score": 0.692,
          "base_score": 0.542,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 402,
          "title": "",
          "score": 0.684,
          "base_score": 0.534,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 398,
          "title": "",
          "score": 0.653,
          "base_score": 0.503,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 394,
          "title": "",
          "score": 0.614,
          "base_score": 0.464,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "token",
          "authorization",
          "access",
          "tokens",
          "user"
        ],
        "semantic": [],
        "merged": [
          "token",
          "authorization",
          "access",
          "tokens",
          "user"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.39211197546494203,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:35.193177+00:00"
      }
    },
    {
      "chapter_number": 12,
      "title": "Testing and validating APIs",
      "start_page": 332,
      "end_page": 359,
      "summary": "Testing and validating APIs\ndevelopment packages to test the orders API.\nTo run the tests, we’ll use a slightly modified version of the orders API specification\nAPI security testing is a\nWe’ll use pytest and schemathesis to test the products API, which you can install by\nthe Dredd API testing framework.\nTesting REST APIs with Dredd\nThis section explains what Dredd is and how we use it to test REST APIs. Dredd is an\nAPI testing framework that automatically generates tests to validate the behavior of\nIt generates tests by parsing the API specification and learning from it\ntion of the orders API.\nWe’ll start by first running a basic test suite against the API, and\nDredd is an API testing framework.\nTesting REST APIs with Dredd\nTo test the API, Dredd sends requests to each of the endpoints defined in the API\n12.2.2 Installing and running Dredd’s default test suite\nIn this section, we install Dredd and run its default test suite against the orders API.\ncomplete, we can start using Dredd to test the API.\n/orders:\nGET /orders endpoint\nPOST /orders endpoint\nPOST /orders endpoint\nGET /orders\nPOST /orders\nOpenAPI speciﬁcation for the orders API\nTesting and validating APIs\ntests.\nexecute the simplest Dredd command to run a test:\noption, we tell Dredd which command needs to be used to start the orders API\norder_id, which is required in some of the URL paths.\nTo address Dredd’s complaint, we add an example of the order_id parameter in\nFor example, for the /orders/{order_id} URL path, we\nwill use the exact value provided in the examples to test the API.\nname: order_id\nOnce we’ve added examples for the order_id parameter, we can run the Dredd CLI\nAdding examples for the order_id URL path parameter\nfor the order_id URL \nTesting REST APIs with Dredd\nDredd runs three tests for each of those endpoints, and it expects to obtain one suc-\ntesting those endpoints.\nusing one for the tests).\nThere’s also a failing test for the POST /orders endpoint in which Dredd expects\nThe failed tests for 422 responses happen because Dredd doesn’t\nknow how to create tests that generate those responses, and Dredd hooks will also\n12.2.3 Customizing Dredd’s test suite with hooks\ndoesn’t know how to handle endpoints with URL path parameters, such as order_id\ntest.\nUsing Dredd hooks, we can create resources for use during the test, save their IDs,\nDredd hooks allow us to trigger actions before and after the whole test suite, and\nbefore and after each endpoint-specific test.\nTesting and validating APIs\nuse hooks to place an order using the POST /orders endpoint, save the ID of the\n/orders endpoint fulfills its job of creating a resource, and we can test other end-\nAfter the POST /orders test, we use a hook to save the ID returned by the\nBefore the GET, PUT, and DELETE /orders/{order_id} tests, we use hooks\nto tell Dredd to use the ID from the order created at point (1).\nfore, after running the DELETE /orders/{order_id} test, the order will no\nid}/cancel endpoints, we use hooks to create new orders for use in these tests.\n{order_id} test from point (2) deletes the order from the server.\nWe’ll use two approaches: for the POST /orders endpoint, we’ll\nAfter the POST /orders endpoint test, the save_created_order()hook saves the ID from \nand before_delete_order() hooks use the ID from response_stash to form their resource URLs. POST /orders\n1. The POST /orders endpoint test creates a new resource.\n2. The save_created_order() hook\n3. The before_get_order(),\nbefore_put_order(), and\nfor their tests.\nbefore_get_order()\nbefore_put_order()\nTesting REST APIs with Dredd\nBefore executing the test, the before_pay_order() and the before_cancel_ \norder() hooks use the POST /orders endpoint to place a new order and use the ID from the \nresponse payload form their resource URLs. POST /orders/23de3420-2e49-4a10-857c-328e1023fbdb/pay\nPOST /orders\n1. Before executing the test, the before_pay_order() and the\nbefore_cancel_order() hooks use the POST /orders endpoint\nto create a new resource for use during their tests.\nBefore executing the test, the fail_create_order() hook injects an invalid payload\nfor the POST /orders endpoint’s test, while the faill_target_speciﬁc_order() hook\ninjects an invalid order identiﬁer for the singleton endpoints’ tests.\nPOST /orders\nGET /orders/8\nPUT /orders/8\nTesting and validating APIs\nshows the implementation of an after hook for the POST /orders endpoint.\ning 12.2, we bind the save_created_order() hook to the 201 response of the POST\n/orders endpoint.\n/orders:\nDredd hook path for the POST /orders endpoint test\nTesting REST APIs with Dredd\nduring the test.\norder() hook is to fetch the ID of the created order, we inspect the payload returned\n@dredd_hooks.after('/orders > Creates an order > 201 > application/json')\norder_id = json.loads(response_payload)['id']    \nresponse_stash['created_order_id'] = order_id    \nNow that we know how to save the ID of the order created in a POST request, let’s see\nhow we use the ID to form the order’s resource URL.\nhooks for the order resource endpoints.\nTo specify which URL Dredd should use when testing the /orders/{order_id} path,\nTo form the URL, we access the order’s ID from the response_stash dictionary.\nImplementation of an after hook for the POST /orders endpoint\n/orders endpoint test.\n/orders endpoint.\nTesting and validating APIs\n\"/orders/\" + response_stash[\"created_order_id\"]\n'/orders/' + response_stash['created_order_id']\n'/orders/' + response_stash['created_order_id']\n'/orders/' + response_stash['created_order_id']\n@dredd_hooks.before('/orders/{order_id} > Deletes an existing order > 204')\n'/orders/' + response_stash['created_order_id']\n'/orders/' + response_stash['created_order_id']\nUSING DREDD HOOKS TO CREATE RESOURCES BEFORE A TEST\nso we can’t use the same order ID to test the /orders/{order_id}/pay and\n/orders/{order_id}/cancel endpoints.\nInstead, we’ll use hooks to create new orders\nbefore testing those endpoints.\nTo create new orders, we’ll call the POST /orders endpoint using the requests\nJSON payload required to create an order.\norder, we fetch its ID from the response payload and use the ID to modify the trans-\nthe GET /orders/{order_id} endpoint test.\nendpoint test’s URL \nthe order we created \nTesting REST APIs with Dredd\nSome of the endpoints in the orders API accept request payloads or URL path param-\nUsing before hooks to create resources before a test\ncreated order’s ID.\nWe change the POST /orders/{order_id}/pay endpoint test’s \nURL by to include the ID of the order we created earlier.\nTesting and validating APIs\nfail_create_order() intercepts the request for the POST /orders endpoint\nSince we know that Dredd fires this test using the example ID we provided\ntypes of payloads and parameters, and if you need to, you can create specific tests for\n@dredd_hooks.before('/orders > Creates an order > 422 > application/json')\ncan run the Dredd test suite again.\n12.2.4 Using Dredd in your API testing strategy\nDredd is a fantastic tool for testing API implementations, but its test suite is limited.\nDredd only tests the happy path of each endpoint.\nFor example, to test the POST\n/orders endpoint, Dredd sends only a valid payload to the endpoint and expects it\nsituations, and to run tests that go beyond the happy path, we need to use a differ-\nmathesis uses: property-based testing.\nexcellent property-based testing library, hypothesis.\ning helps us create robust test suites for APIs, allowing us to easily generate hundreds\nsis, an API testing framework that uses property-based testing.\nthe result of running our code.1 Typically, a property-based framework generates test\nTesting and validating APIs\n12.3.2 The traditional approach to API testing\nLet’s say we want to test our POST /orders endpoint to ensure it only accepts valid\nAs you can see from the OpenAPI specification for the orders API under the\nch012/orders/oas.yaml file, a valid payload for the POST /orders endpoint contains\nSchema for the POST /orders endpoint’s request payload\n2. We run our code on the test data.\nIn property-based testing, we use a framework to generate test cases for \n- order\norder:\nthe POST /orders endpoint and write the expected result for each payload.\nillustrates how we test the POST /orders endpoint with two different payloads.\nwant to try out the code in listing 12.7, create a file called orders/test.py and run the\nrequired size property of an order item and another with a valid payload.\ncases, we use FastAPI’s test client to send the payloads to our API server, and we test\n# file: orders/test.py\ndef test_create_order_fails():    \nTesting the POST /orders endpoint with different payloads\nWe create a test.\nthe POST /orders endpoint.\nTesting and validating APIs\nresponse = test_client.post('/orders', json=bad_payload)    \ndef test_create_order_succeeds():\nresponse = test_client.post('/orders', json=good_payload)\n12.3.3 Property-based testing with Hypothesis\nmon approach to API testing.\nFor a more comprehensive approach to API testing, we want to be able to use a\ncan run property-based tests with the help of the excellent hypothesis library.\nHypothesis uses the concept of strategy to generate test data.\nTo test the POST /orders endpoint with Hypothesis, we want to define a strategy that\nWe test the \n/orders endpoint.\n12.3.4 Using Hypothesis to test a REST API endpoint\nLet’s put all of this together to create an actual test for the POST /orders endpoint.\nTesting and validating APIs\nwe can define a strategy that generates payloads to test the CreateOrderSchema\ncomprehensive test for the POST /orders endpoint.\nHypothesis strategies into a test function.\norders/test.py file.\nThe testing strategy in listing 12.8 uses the jsonschema library to validate the pay-\nwhich takes a Hypothesis strategy as an argument and uses it to feed test cases to our\n# file: orders/test.py\ncreate_order_schema = ( \norders_api_spec['components']['schemas']['CreateOrderSchema']    \nUsing hypothesis to run property-based tests against an API \nTesting and validating APIs\nresponse = test_client.post('/orders', json=payload)    \nif is_valid_payload(payload, create_order_schema):    \nlibrary before trying to generate your own Hypothesis strategies for testing web APIs. Now that we understand what property-based testing is and how Hypothesis works,\nTesting REST APIs with Schemathesis\ntest REST APIs. Schemathesis is an API testing framework that uses property-based\ntesting to validate our APIs. It uses the hypothesis library under the hood, and thanks\nto its approach, it’s capable of running a more exhaustive test suite than Dredd.\n12.4.1 Running Schemathesis’s default test suite\nIn this section, we’ll get familiar with Schemathesis by running its default test suite.\ntrast with Dredd, Schemathesis requires you to have your API server running before\nyou run your test suite.\n/orders endpoint.\nTesting REST APIs with Schemathesis\nHypothesis, the library that Schemathesis uses to generate test cases, creates a folder\ntests against the API, testing all possible combinations of parameters, types, and for-\nwhether the POST /orders endpoint is creating orders correctly nor if we can per-\nthe orders API.\nFor example, using links, we can specify that the POST /orders endpoint returns a\npayload with an ID, and that we can use that ID to form the resource URL of the order\njust created under the GET /orders/{order_id} endpoint.\nbetween the POST /orders endpoint and the GET /orders/{order_id} endpoint.\nTesting and validating APIs\nIn listing 12.9, we name the link between the POST /orders and the GET\n/order/{order_id} endpoints GetOrder.\nThe GET /order/{order_id} endpoint\nthat the response body from the POST /orders endpoint contains an id property,\nwhich we can use to replace order_id in the GET /order/{order_id} endpoint.\n/orders:\n/orders endpoint’s response.\n/orders endpoint contains an id property\nexample, the POST /orders response contains an id property that we can use to replace the \nTesting REST APIs with Schemathesis\n/orders:\norder_id: '$response.body#/id'   \ntation and use them to run tests on the resources created through the POST /orders\n/orders\n/orders/{order_id} endpoint.\nThe order_id URL\nTesting and validating APIs\nNotice that some of the tests appear nested within the POST /orders endpoint (the\nIf the tests on the POST /orders endpoint’s links pass, we can\nGET /orders .\nPOST /orders .\nTest for the GET /orders endpoint\nTest for the GET /orders/{order_id} \n/orders endpoint test\nThe test suite runs 1,200\nTesting GraphQL APIs\nAs you can see, this time Schemathesis runs over a thousand test cases per check:\nto the world of GraphQL API testing, which is the topic of the next section!\nTesting GraphQL APIs\nThis section explains how we test and validate GraphQL APIs so that we can ensure\nmatically generate tests for REST APIs based on the API specification.\n12.5.1 Testing GraphQL APIs with Schemathesis\nThis section explains how we use Schemathesis to test and validate a GraphQL API.\nwe explained in section 12.4, Schemathesis is an API testing framework that uses an\napproach known as property-based testing to validate our APIs. Schemathesis can be\nused to test both REST and GraphQL APIs. In both cases, as you can see in figure 12.10,\nTesting and validating APIs\nTo generate tests for a GraphQL API, Schemathesis uses hypothesis-graphql\nBefore we run our test, we need to start the GraphQL API server.\nTo test a GraphQL API\npens with GraphQL APIs. The following shows the output of the test suite, omitting\nDesigning your API testing strategy\nsis tests all of the  queries and mutations exposed by the products API, generating a\nAfter running the Schemathesis test suite against the products API, we can be certain\nDesigning your API testing strategy\nand Schemathesis, which run automated test suites against your APIs based on the API\nYou’ve also learned about property-based testing and how to use\nHypothesis to automatically generate test cases to test your REST and GraphQL APIs.\nAs we saw in section 12.2, Dredd runs a simple test suite against your APIs. Dredd\nonly tests the happy path: it makes sure your API accepts the expected payloads and\nDredd’s testing strategy is useful in the early development stage of your API, when\nOutput of a Schemathesis test suite for a GraphQL API\nTesting and validating APIs\ntested with Schemathesis.\nSchemathesis runs a more comprehensive test suite, which\nDredd and Schemathesis are API testing tools that automatically generate vali-\ndation tests for APIs from the documentation.\nSchemathesis is a more generic API test framework that runs an exhaustive test\ntest both REST and GraphQL APIs.\nTo test that your POST endpoints are creating resources correctly, you can\nIn Python, you can run property-based tests",
      "keywords": [
        "API",
        "Testing REST APIs",
        "order",
        "dredd",
        "orders API",
        "orders endpoint",
        "post",
        "APIs",
        "REST APIs",
        "API testing",
        "Dredd hooks",
        "schemathesis",
        "API specification",
        "Dredd API testing",
        "orders endpoint test"
      ],
      "concepts": [
        "tested",
        "apis",
        "api",
        "orders",
        "ordered",
        "responses",
        "listing",
        "endpoints",
        "hypothesis",
        "server"
      ],
      "similar_chapters": [
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 400,
          "title": "",
          "score": 0.646,
          "base_score": 0.496,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 6,
          "title": "",
          "score": 0.638,
          "base_score": 0.488,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 402,
          "title": "",
          "score": 0.621,
          "base_score": 0.471,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 4,
          "title": "",
          "score": 0.605,
          "base_score": 0.455,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 382,
          "title": "",
          "score": 0.596,
          "base_score": 0.446,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "test",
          "orders",
          "dredd",
          "testing",
          "endpoint"
        ],
        "semantic": [],
        "merged": [
          "test",
          "orders",
          "dredd",
          "testing",
          "endpoint"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.35433645067205427,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:35.193210+00:00"
      }
    },
    {
      "chapter_number": 13,
      "title": "Dockerizing microservice APIs",
      "start_page": 360,
      "end_page": 371,
      "summary": "Dockerizing microservice APIs\nto Dockerize an application using the orders service of the CoffeeMesh platform.\nYou’ll also learn to publish your Docker builds to a container registry by uploading\nimages to AWS’s Elastic Container Registry (ECR).\nTo build and run Docker containers, you’ll need a Docker runtime on your machine.\nto learn how to install Docker on your system (https://docs.docker.com/get-docker/).\nSince we’re going to publish our Docker images to AWS’s ECR, we need to\nDockerizing a microservice\nNow that our environment is ready, it’s time to Dockerize our applications!\nDockerizing a microservice\nWhat does Dockerizing an application mean?\nan application as a Docker image.\nYou can think of a Docker image as a build or arti-\ndencies are already installed in the Docker image, and to run the image, we only need\na Docker runtime.\nTo execute the image, the Docker runtime creates a container,\nDocker is very convenient since it allows us to run our applications in isolated pro-\nThere are different options for installing a Docker runtime depending on your\nIn this section, we create an optimized Docker image of the orders service.\ninstructions required to build a Docker image.\nYou’ll also learn how to run Docker\nyou can interact with the application running inside the container.\nlearn how to manage containers with the Docker CLI.\nDocker runtime\nDocker containers run in isolated processes on top of the host operating \nDockerizing microservice APIs\ncoded database URL, but to operate the service in different environments, we need to\norders/repository/unit_of_work.py file to pull the database URL from the environ-\nWe also need to update our Alembic files to pull the database URL from the environ-\nDockerizing a microservice\nTo build a Docker image, we need\nWe use the slim version of the official Python 3.9 Docker image as our base\nSlim images contain just the dependencies that we need to run our applica-\nTo use a base image, we use Docker’s FROM direc-\nbash commands, such as mkdir in this case, we use Docker’s RUN directive.\n/orders/orders as the working directory using Docker’s WORKDIR directive.\nDocker’s COPY directive to copy files from our filesystem into the Docker image.\nwe’re running in Docker, we don’t need a virtual environment, so we install the depen-\nthe command that needs to be executed to get the orders service up and running.\nThe command that Docker must use to execute our application is specified using\nWe also use Docker’s EXPOSE directive to make sure the running\ncontainer listens on port 8000, the port on which our API runs.\nThe order of our statements in the Dockerfile matters because Docker caches each\nThat way, Docker will only install the dependencies\nDockerizing microservice APIs\nRUN pipenv install --system --deploy    \nTo build the Docker image from listing 13.3, you need to run the following command\n$ docker build -t orders:1.0 .\nA Docker tag has two parts: the image name on the left of\n$ docker run --env DB_URL=sqlite:///orders.db \\\nthe container, and we use it to set the URL of the database.\nwhich the application is running inside the container to a port in the host machine.\nDockerizing a microservice\nTo run the container in detached mode, you use the -d flag:\n$ docker run -d –-env DB_URL=sqlite:///orders.db \\\nIn this case, you’ll need to stop the container with the docker stop command.\nyou need to figure out the ID of the running container with the following command: \nThis command will list all currently running containers in your machine.\nCONTAINER ID   IMAGE       COMMAND       CREATED         STATUS...\ndocker run -env DB_URL=sqlite:///orders.db -v $(pwd)/orders.db:/orders/orders.db\nWhen we run a container, we can include various configurations to set environment variables \nDockerizing microservice APIs\nThat’s all it takes to build and run Docker containers!\nRunning applications with Docker Compose\nIn the previous section, we ran the orders service’s container by mounting it on our\nto connect our containerized applications to a database is using Docker Compose,\nIn this section, you’ll learn how to run the orders service with a Post-\ngreSQL database using docker-compose.\nTo use Docker Compose, first we need to install it.\n$ pip install docker-compose\nrun our application.\nListing 13.4 shows the docker-compose file for the orders service.\nWe use Docker Compose’s latest specification format, version 3.9, and we declare two\nservices: database and api.\ndatabase runs PostgreSQL’s official Docker image, while\napi runs the orders service.\nWe use the build keyword to point to the Docker build con-\nwe use a volume called database-data, which docker-compose will use to persist our\n# file: docker-compose.yaml\ndocker-compose file for the orders service\ndocker-compose’s \nRunning applications with Docker Compose\nExecute the following command to run our Docker Compose file:\n$ docker-compose up --build\nThe --build flag instructs Docker Compose to rebuild your images if your files\npipenv environment, and run the following command:\nTo stop docker-compose, run the following command from\n$ docker-compose down\nThis is all it takes to run Docker Compose!\nDocker Compose is often used to run integration tests\nThe database service’s Docker image\nDockerizing microservice APIs\nWith our Docker stack ready and our images tested, it’s time to learn how to push\nPublishing Docker builds to a container registry\nTo deploy our Docker builds, we need to publish them first to a Docker container reg-\nA container registry is a repository of Docker images.\ndeploy our applications to AWS’s Elastic Kubernetes Service, so we publish our builds\nKeeping our Docker images within AWS will make it easier to deploy\nFirst, let’s create an ECR repository for our images with the following command:\n$ aws ecr create-repository --repository-name coffeemesh-orders\n➥ \"arn:aws:ecr:<aws_region>:<aws_account_id>:repository/coffeemesh-orders\",\nIn this command, we create a ECR repository named coffeemesh-orders.\nrun the command, the placeholder for <aws_account_id> in the output payload will\nTo publish our Docker build to ECR, we need to tag our build with the name\nprevious command’s output (in bold), and use it to tag the Docker build we created in\n$ docker tag orders:1.0 \\\n<aws_account_id>.dkr.ecr.<aws_region>.amazonaws.com/coffeemesh-orders:1.0\n$ aws ecr get-login-password --region <aws_region> | docker login \\\ncreated the Docker repository, such as eu-west-1 for Europe (Ireland) or us-east-2 for\nThe aws ecr get-login-password command produces an instruction that Docker\nOur Docker build is now in ECR.\nA Docker build is called\nan image, which is executed in processes called Docker containers.\nmultiple containers simultaneously, such as databases and APIs. Using Docker\nTo deploy Docker images, we publish them to a container registry, such as\nour containers to AWS services.\nYou can also deploy a Kubernetes cluster in your machine and run\nwe’ll use EKS, which is currently the most popular managed Kubernetes service.2",
      "keywords": [
        "Docker",
        "Docker Compose",
        "run Docker containers",
        "Docker image",
        "AWS",
        "URL",
        "Docker containers",
        "run",
        "orders",
        "run Docker",
        "docker build",
        "Docker Compose file",
        "database URL",
        "run Docker Compose",
        "Kubernetes"
      ],
      "concepts": [
        "docker",
        "order",
        "running",
        "run",
        "runs",
        "container",
        "database",
        "commands",
        "file",
        "services"
      ],
      "similar_chapters": [
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 14,
          "title": "",
          "score": 0.703,
          "base_score": 0.553,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 9,
          "title": "",
          "score": 0.561,
          "base_score": 0.411,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 2,
          "title": "",
          "score": 0.554,
          "base_score": 0.404,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 7,
          "title": "",
          "score": 0.547,
          "base_score": 0.397,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 3,
          "title": "",
          "score": 0.538,
          "base_score": 0.388,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "docker",
          "compose",
          "docker compose",
          "run",
          "image"
        ],
        "semantic": [],
        "merged": [
          "docker",
          "compose",
          "docker compose",
          "run",
          "image"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.2798175538481633,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:35.193248+00:00"
      }
    },
    {
      "chapter_number": 14,
      "title": "Deploying microservice APIs with Kubernetes",
      "start_page": 372,
      "end_page": 405,
      "summary": "Deploying microservice APIs with Kubernetes\nSince we’ll deploy to AWS, we need to be able to access AWS services programmati-\nYou’re going to learn how to deploy services to Kubernetes, so you also need to\ncluster, the next section explains some of the main concepts related to Kubernetes to\nThe core of a Kubernetes cluster is the control plane, a process that runs the\nKubernetes API for our cluster, controls its state, and manages the available resources,\nThe Kubernetes control plane is a process that runs the Kubernetes\nAPI and controls the state of the cluster and manages the available resources,\ncontainer per pod, and in this chapter, we deploy the orders service as a single con-\nTo deploy pods into the cluster, we use workloads.\nthe most common type of Kubernetes workload and is useful for running stateless dis-\nService\nservice.\nDeploying microservice APIs with Kubernetes\nservices are all stateless, in this chapter we deploy the orders service as a Deployment.\nFor example, we can create a namespace for each service in our platform.\nTo run our applications as web services, Kubernetes offers the concept of services—\nTo expose our services through the internet, we use a load balancer, which sits\nin front of the Kubernetes cluster, and forwards traffic to the services based on\ncomputing resources in which our services run.\nexample, when running a Kubernetes cluster in AWS, our nodes will be represented\nNow that we understand what the main parts of Kubernetes are, let’s create a cluster!\nCreating a Kubernetes cluster with EKS\nIn this section, you’ll learn how to create a Kubernetes cluster using the AWS EKS.\nlaunch the Kubernetes cluster using eksctl, which is the recommended tool for man-\naging Kubernetes in AWS.\nCloudFormation is AWS’s infrastructure-as-code service.\nCreating a Kubernetes cluster with EKS\nTo run the containers in the Kubernetes cluster, we use AWS Fargate.\nin figure 14.2, Fargate is AWS’s serverless container service that allows us to run contain-\nTo create a Kubernetes cluster using eksctl, run the following command:\n$ eksctl create cluster --name coffeemesh --region <aws_region> --fargate \\\n--region—The AWS region where you want to deploy the cluster.\nKubernetes cluster\nof servers required to operate our Kubernetes cluster.\nKubernetes cluster.\nDeploying microservice APIs with Kubernetes\nthe Kubernetes cluster.\nTo make advanced use of Kubernetes, you need to\nKubernetes cluster.\nrequirements of a Kubernetes cluster (https://eksctl.io/usage/vpc-networking/) and\nKubernetes cluster\nIt also deploys the Kubernetes cluster within the VPC.\nCreating a Kubernetes cluster with EKS\nwe can get a list of running nodes with the following command:\nTo get the list of pods running in the cluster, run the following command:\nThere are many more useful commands you can run to learn more about your cluster.\nNow that our cluster is up and running, in the next section, we’ll create\nan IAM role for our Kubernetes service accounts.\nDeploying microservice APIs with Kubernetes\nUsing IAM roles for Kubernetes service accounts\nEvery process that runs in your Kubernetes cluster has an identity, and that identity\nSometimes, our services need to interact with AWS resources\nTo give access to the AWS API, we need to create IAM roles—\nentities that give applications access to the AWS API—for our services.\nsee in figure 14.4, to link a Kubernetes service account to an IAM role, we use OpenID\nTo check if your cluster has an OIDC provider, run the following command, replacing\n$ aws eks describe-cluster --name coffeemesh \\\nThis command lists all the OIDC providers in your AWS account, and it uses grep to\nService\npod access to the AWS API.\naccess to the AWS API, and therefore gives them access to AWS services.\nDeploying a Kubernetes load balancer\nyour cluster, run the following command, replacing <cluster_name> with the name of\ntion, we deploy a Kubernetes load balancer to enable external traffic to the cluster.\nDeploying a Kubernetes load balancer\nTo enable external access to the cluster, we need an ingress controller.\nKubernetes cluster and load balances it among our pods.\npods, we create ingress resources for each service.\nIn this section, we’ll deploy a Kubernetes ingress controller as an AWS Load Balancer\nController.3 As you can see in figure 14.5, the AWS Load Balancer Controller deploys\nan AWS Application Load Balancer (ALB), which sits in front of our cluster, captures\n3 The AWS Load Balancer Controller is an open source project hosted on GitHub (https://github.com/kubernetes\nService\nKubernetes cluster\npods using an ingress resource per service.\nAn ingress controller accepts traffic from outside of the Kubernetes cluster and forwards it to \nDeploying microservice APIs with Kubernetes\nTo install the AWS Load Balancer Controller, we need to have an OIDC provider in\nfirst step to deploying an AWS Load Balancer Controller is to create an IAM policy\nhttps:/ /raw.githubusercontent.com/kubernetes-sigs/aws-load-balancer-\nAfter running this command, you’ll see a file called alb_controller_policy.json in your\nThe next step is to create an IAM role associated to a Kubernetes service account for\nwith the policy we created earlier, as well as a service account named alb-controller\nDeploying microservices to the Kubernetes cluster\nNow that helm is up to date, we can install the AWS Load Balancer Controller.\ninstall the controller, we need to get hold of the ID of the VPC eksctl created when we\nTo find the VPC ID, run the following command:\nWe also instruct Helm not to create a new service account for the controller,\nand instead use the alb-controller service account we created earlier.\n$ kubectl get deployment -n kube-system aws-load-balancer-controller\ntime to deploy the orders service!\nDeploying microservices to the Kubernetes cluster\nNow that our Kubernetes cluster is ready, it’s time to start deploying our services!\nthis section, we walk through the steps required to deploy the orders service.\nfollow the same steps to deploy other services of the CoffeeMesh platform.\nAs you can see in figure 14.6, we deploy the orders service to a new namespace\ncalled orders-service.\nrequired to operate the orders service.\nTo create a new namespace, we run the follow-\n$ kubectl create namespace orders-service\nDeploying microservice APIs with Kubernetes\nSince we’ll run the orders service in the new namespace, we also need to create a new\nFargate profile configured to schedule jobs within the orders-service namespace.\nTo create the new Fargate profile, run the following command:\n$ eksctl create fargateprofile --namespace orders-service --cluster \\\nWith the orders-service namespace and the Fargate profile ready, we can deploy the\norders service.\nCreate a deployment object for the orders service.\nCreate a service object.\nCreate an ingress resource to expose the service.\n14.6.1 Creating a deployment object\nLet’s begin by creating a deployment for the orders service using a service manifest\nAs you can see in figure 14.7, deployments are Kubernetes objects that operate\nCreate a file named orders-service-deployment.yaml\nWe use Kubernetes’ API version apps/v1 and declare this object a Deployment.\nmetadata, we name the deployment orders-service, we specify its namespace, and\nService\norders-service namespace\npods can run on AWS servers.\nA service\nall the components needed to operate the microservice, such as a Deployment object and a Service \nDeploying microservices to the Kubernetes cluster\nwe add the label app: orders-service.\norders-service, which means this deployment will only operate pods with this label.\nWe label the pod with the app: orders-service key-value pair in agreement\nwhich is the orders service application.\nWithin the definition of the orders service con-\n# file: orders-service-deployment.yaml\nDeploying microservice APIs with Kubernetes\nname: orders-service     \nnamespace: orders-service   \napp: orders-service\napp: orders-service     \napp: orders-service    \n- name: orders-service\nTo create the deployment, we run the following command:\n$ kubectl apply -f orders-service-deployment.yaml\nThis command creates the deployment and launches the pods we defined in the man-\n$ kubectl get pods -n orders-service\nIn Kubernetes, we can create objects using manifest files.\nsuch as namespaces, deployments, services, and so on.\napiVersion—The version of the Kubernetes API that we want to use.\nversion of each object for your Kubernetes cluster by running the following\nDeploying microservices to the Kubernetes cluster\n14.6.2 Creating a service object\nNow that our deployment is ready, we will create a service object for the orders service.\nAs we learned in section 14.2, services are Kubernetes objects that allow us to expose\nour applications as web services and redirects traffic from the cluster to our pods on\nCreate a file named orders-service.yaml, and copy into it the con-\nWe use version v1 of the Kubernetes API to declare our service.\norders-service namespace.\nWe also add a label: app: orders-service.\nThere are other types of services in Kubernetes,\nvice, we use this section to specify the type of service we’re creating (e.g.,\nTo create an object from a manifest file, we use the kubectl apply command.\nService\nKubernetes cluster\nA service object redirects traffic from the cluster to the pods on the specified \nDeploying microservice APIs with Kubernetes\nwhen to use each type, see the sidebar, “Which type of Kubernetes service should I use?”)\norders-service label, which means this service will only operate pods with that label.\n# file: orders-service.yaml\nname: orders-service\nnamespace: orders-service\napp: orders-service\napp: orders-service\nTo deploy this service, run the following command:\n$ kubectl apply -f orders-service.yaml\nWhich type of Kubernetes service should I use?\nKubernetes has four types of services.\nClusterIP—Exposes services on the cluster’s internal IP and therefore\ncan only run one service per node.\ncluster, but you can expose them by creating ingress rules that forward traffic to them.\nThe service \nThe service must \nThe service\nDeploying microservices to the Kubernetes cluster\n14.6.3 Exposing services with ingress objects\nneed to create an ingress resource that routes traffic to the service.\nfigure 14.9, an ingress resource is a service that redirects HTTP traffic to the pods run-\nning in our Kubernetes cluster on the specified ports and URL paths.\nnamed orders-service-ingress.yaml and copy the content of listing 14.3 to it.\nIn the ingress manifest, we use version networking.k8s.io/v1 of the Kubernetes API,\norders-service-ingress, and we specify that it should be deployed within the orders-\nWe use annotations to bind the ingress object to the AWS Load\nunder the /orders path to the orders service and additional rules to access the ser-\n# file: orders-service-ingress.yaml\nLoadBalancer is useful if you’d like to use one cloud load balancer per service.\naccess your services from within the cluster using custom domains.\nService\nKubernetes cluster\nDeploying microservice APIs with Kubernetes\nname: orders-service-ingress\nnamespace: orders-service\nservice:\nname: orders-service     \nservice:\nname: orders-service\nservice:\nname: orders-service\nTo create this ingress resource, we run the following command:\n$ kubectl apply -f orders-service-ingress.yaml\n$ kubectl get ingress/orders-service-ingress -n orders-service\norders-service-ingress   <none>   *       k8s-ordersse-ordersse-3c391193...\n$ kubectl get ingress/orders-service-ingress -n orders-service -o json | \\\nservice that\nThe orders-service \nWe can use this URL to call the orders service API.\nThe orders service is almost ready: the application is up and running, and we can\nthe many managed database services that cloud providers offer.\nWe’ll launch our Aurora database within the Kubernetes cluster’s VPC.\nlaunch a database within an existing VPC, we need to create a database subnet group: a\nKubernetes cluster’s VPC into six subnets: three public and three private.\nWhen creating a database subnet group, the subnets must all be either private\nFor security, it’s best practice to use private subnets in database subnet groups as it\nDeploying microservice APIs with Kubernetes\nthe list of private subnets in the VPC, we first need to obtain the ID of the Kubernetes\ncluster’s VPC with the following command:\nThen use the following command to get the IDs of the private subnets in the VPC:\nThe previous command lists all the subnets in the Kubernetes cluster’s VPC, and it\nthe database subnet group using the following command:\n$ aws rds create-db-subnet-group --db-subnet-group-name \\\nAs you can see in figure 14.10, this command creates a database subnet group named\nThe following command creates a security\nWe deploy an Aurora database within a database subnet group named coffeemesh-\nThe database subnet group is created on top of the three private subnets of our \n$ aws ec2 create-security-group --group-name db-access --vpc-id <vpc-id> \\\nIn the previous command, replace <vpc-id> with the ID of your Kubernetes cluster’s\nWe use the following command to create an inbound traffic\nto connect to it, we can use the subnet group to launch an Aurora Serverless cluster\nRun the following command to launch an Aurora Serverless cluster:\n$ aws rds create-db-cluster --db-cluster-identifier coffeemesh-orders-db \\\nthe cluster coffeemesh-orders-db.\nDeploying microservice APIs with Kubernetes\n--db-subnet-group—The name of the database security group we created earlier.\nTo connect our services to the database, we need a secure way to pass the connection\nAWS EKS offers two secure ways to manage Kubernetes secrets: we can use the AWS\nSecrets & Configuration Provider for Kubernetes,7 or we can use AWS Key Manage-\nProvider with Your Kubernetes Secrets Store CSI driver,” https://aws.amazon.com/blogs/security/how-to-use\n-aws-secrets-configuration-provider-with-kubernetes-secrets-store-csi-driver/.\nthe following command to create the key:\ntion in our Kubernetes cluster using eksctl:\nwith the region where you deployed the Kubernetes cluster.\nLet’s create a secret that represents the database connection\nrds create-db-cluster command.\nDeploying microservice APIs with Kubernetes\nTo store the database connection string as a Kubernetes secret, we run the following\n$ kubectl create secret generic -n orders-service db-credentials \\\nThe previous command creates a secret object named db-credentials within the\norders-service namespace.\n$ kubectl get secret db-credentials -n orders-service -o json\n\"namespace\": \"orders-service\",\nTo make the secret available to the orders service, we need to update the order ser-\n# file: orders-service-deployment.yaml\nname: orders-service\nnamespace: orders-service\napp: orders-service\napp: orders-service\napp: orders-service\n- name: orders-service\n➥ <aws_account_id>.dkr.ecr.<aws_region>.amazonaws.com/coffeemesh-orders:1.0\n$ kubectl apply -f orders-service-deployment.yaml\nOur service can now connect to the database!\n14.7.3 Running the database migrations and connecting our service \nOur database is up and running, and now we can connect the orders service with it.\nHowever, before we can create records and run queries, we must ensure the database\nIn the previous section, we deployed the Aurora database to our private subnets,\nour cluster is already up and running, using a Kubernetes Job is a suitable option for us.\nTo create the Kubernetes job, we first need to create a Docker image for running the\nDeploying microservice APIs with Kubernetes\n$ aws ecr create-repository --repository-name coffeemesh-orders-migrations\n➥ <aws_account_id>.dkr.ecr.<aws_region>.amazonaws.com/coffeemesh-orders-\nNow that our image is ready, we need to create a Kubernetes Job object.\nservice, we expose the database connection string in the environment by loading the\nlong the pod will last in the orders-service namespace once it’s finished the job.\nname: orders-service-migrations\nnamespace: orders-service\napp: orders-service\n- name: orders-service-migrations\n➥ <aws_account_id>.dkr.ecr.<aws_region>.amazonaws.com/coffeemesh-orders-\nLet’s create the Job by running the following command:\nby running the following command:\n$ kubectl get pods -n orders-service\n$ kubectl logs -f jobs/orders-service-migrations -n orders-service\nCreating a database migrations job\nDeploying microservice APIs with Kubernetes\nOur service is now ready for use.\nNow that our service is ready and the database is deployed and configured, it’s time to\nthe API specification with the hostname of our Kubernetes cluster’s ALB.\nwe update the order’s API specification, make a new deployment, and test it.\n$ kubectl get ingress/orders-service-ingress -n orders-service -o json | \\\nNext, we need to update the orders service deployment manifest.\n# file: orders-service-deployment.yaml\nname: orders-service\nnamespace: orders-service\napp: orders-service\napp: orders-service\napp: orders-service\n- name: orders-service\n➥ <aws_account_id>.dkr.ecr.<aws_region>.amazonaws.com/coffeemesh-orders:1.1\nFinally, we apply the new deployment configuration by running the following command:\n$ kubectl apply -f orders-service-deployment.yaml\nkubectl get pods -n orders-service\nOnce the old pod is terminated and the new one is up and running, load the order’s\nand managed to get your Kubernetes cluster up and running, please accept my most\nDeploying microservice APIs with Kubernetes\nunderstanding of how Kubernetes works, and it’s sufficient to get a cluster up and run-\nDeleting the Kubernetes cluster\nstep is crucial to make sure you don’t get billed for the Kubernetes cluster once\nKubernetes cluster\nService\nDeleting the Kubernetes cluster\ndatabase cluster, and in the last step we’ll delete the VPC.\nLet’s delete the database cluster with the following command:\n$ aws rds delete-db-cluster --db-cluster-identifier coffeemesh-db \\\nOnce it’s deleted, we can delete the database subnet group with the following command:\nNext, let’s delete the AWS Load Balancer Controller.\nKubernetes cluster\nDeploying microservice APIs with Kubernetes\nwe delete the ALB that was created when we installed the controller.\n$ kubectl get ingress/orders-service-ingress -n orders-service -o json | \\\nAfter running this command, we need to delete the ALB.\nWe’ll use the AWS CLI to list the load balancers in our account and fil-\nNow we can delete the Kubernetes cluster with following command:\nFinally, let’s delete the KMS key we created earlier to encrypt our Kubernetes secrets.\nTo delete the key, we run the following command:\nThe three major managed Kubernetes services are Google’s Kubernetes Engine\n(GKE), Azure’s Kubernetes Service (AKS), and AWS’s Elastic Kubernetes Ser-\nIn this chapter, we learned to deploy a Kubernetes cluster with EKS,\nwhich is the most widely adopted Kubernetes managed service.\nWe can deploy a Kubernetes cluster in AWS using the console, CloudFormation,\nit’s the AWS recommended way to manage a Kubernetes cluster.\nTo make our Kubernetes cluster reachable from the internet, we use an ingress\nTo deploy a microservice to a Kubernetes cluster, we create the following\n– An Ingress object bound to the ingress controller (the AWS Load Balancer\n– Using the AWS Secrets & Configuration Provider for Kubernetes\n– Using Kubernetes secrets in combination with the AWS Key Managed Service",
      "keywords": [
        "Kubernetes cluster",
        "Kubernetes",
        "AWS Load Balancer",
        "AWS",
        "Kubernetes API",
        "Kubernetes load balancer",
        "cluster",
        "Kubernetes service",
        "Load balancer",
        "AWS Load",
        "service",
        "AWS API",
        "Load Balancer Controller",
        "Kubernetes secrets",
        "Kubernetes API etcd"
      ],
      "concepts": [
        "services",
        "kubernetes",
        "create",
        "creating",
        "order",
        "deploying",
        "deployments",
        "cluster",
        "running",
        "run"
      ],
      "similar_chapters": [
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 13,
          "title": "",
          "score": 0.703,
          "base_score": 0.553,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 7,
          "title": "",
          "score": 0.684,
          "base_score": 0.534,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 9,
          "title": "",
          "score": 0.61,
          "base_score": 0.46,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 2,
          "title": "",
          "score": 0.575,
          "base_score": 0.425,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 3,
          "title": "",
          "score": 0.533,
          "base_score": 0.383,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "kubernetes",
          "cluster",
          "service",
          "orders service",
          "kubernetes cluster"
        ],
        "semantic": [],
        "merged": [
          "kubernetes",
          "cluster",
          "service",
          "orders service",
          "kubernetes cluster"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.28480562053819997,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:35.193283+00:00"
      }
    },
    {
      "chapter_number": 378,
      "title": "APPENDIX A\nT",
      "start_page": 406,
      "end_page": 407,
      "summary": "Types of web APIs and protocols\nSOAP and the emergence of API standards\nSOAP was conceived as a messaging protocol, and it runs on top\nAPI server\nUsing JSON-RPC, an API client sends a request to an API server invoking the \ncalculate_price() function to get the price of a medium cup of cappuccino.\nSOAP and the emergence of API standards\nThe payloads exchanged with a SOAP endpoint are represented in XML, and as illus-\nEnvelope (required)—Identifies the XML document as a SOAP payload\nBody (required)—Contains the payload (actual message being exchanged) of the\nSOAP was a major contribution to the field of APIs. The availability of a standard pro-\nThe payloads exchanged through SOAP contain large XML documents, which\nIdentiﬁes the message as a SOAP payload\n</SOAP-ENV:Body>\nAt the top of a SOAP message, we find a section called Envelope that tells us that this is a \nSOAP payload.\nAn optional Header section includes metadata about the message, such as the type of \nThe Body section includes the actual payload of the message: the data being exchanged between ",
      "keywords": [
        "SOAP",
        "API",
        "SOAP payload",
        "API server",
        "server",
        "payload",
        "API client",
        "API standards",
        "APIs",
        "Body",
        "Request",
        "XML",
        "message",
        "SOAP include",
        "Includes"
      ],
      "concepts": [
        "soap",
        "apis",
        "api",
        "including",
        "include",
        "payloads",
        "server",
        "protocols",
        "body",
        "contained"
      ],
      "similar_chapters": [
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 382,
          "title": "",
          "score": 0.733,
          "base_score": 0.583,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 4,
          "title": "",
          "score": 0.599,
          "base_score": 0.449,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 380,
          "title": "",
          "score": 0.595,
          "base_score": 0.445,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 2,
          "title": "",
          "score": 0.568,
          "base_score": 0.418,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 5,
          "title": "",
          "score": 0.563,
          "base_score": 0.413,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "soap",
          "message",
          "soap payload",
          "exchanged soap",
          "xml"
        ],
        "semantic": [],
        "merged": [
          "soap",
          "message",
          "soap payload",
          "exchanged soap",
          "xml"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.35647208793909124,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:35.193318+00:00"
      }
    },
    {
      "chapter_number": 380,
      "title": "APPENDIX A\nT",
      "start_page": 408,
      "end_page": 409,
      "summary": "for serializing structured data.\ntic and can be translated into the native data structures of other languages.\nPython’s pickle format allows you to serialize any type of data structure running in\nthe serialized data is highly specific to the version of Python that you were running at\nAs you can see in figure A.4, in gRPC you must first define the schema for the data\nstructures that you want to exchange over the API using the Protobuf specification\nclient and the API server.\nThe data structures generated from the Protobuf specifications are called stubs.\nstubs are implemented in code native to the language we use to build the API client\ning the data exchanged between client and server.\nsure that communication over the API is highly optimized, since the data is exchanged\n3 According to Postman’s 2022 State of the API Report, 11% of the surveyed developers use gRPC (https://\nPython stubs for server API\nPython stubs for client-side\ngRPC uses Protobuf to encode the data exchanged through the API.\nprotoc CLI, we can generate code (stubs) for both the client and the server from a Protobuf \nAPI client\nAPI server\nand the API server and ",
      "keywords": [
        "API",
        "data",
        "API client",
        "API server",
        "Python",
        "Protobuf",
        "gRPC",
        "client",
        "data structures",
        "API client gRPC",
        "stubs",
        "server",
        "API server gRPC",
        "data exchanged",
        "format"
      ],
      "concepts": [
        "grpc",
        "data",
        "apis",
        "api",
        "format",
        "protobuf",
        "exchanges",
        "exchanged",
        "specific",
        "specifications"
      ],
      "similar_chapters": [
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 378,
          "title": "",
          "score": 0.595,
          "base_score": 0.445,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 382,
          "title": "",
          "score": 0.567,
          "base_score": 0.417,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 10,
          "title": "",
          "score": 0.562,
          "base_score": 0.412,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 8,
          "title": "",
          "score": 0.544,
          "base_score": 0.394,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 384,
          "title": "",
          "score": 0.469,
          "base_score": 0.319,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "stubs",
          "grpc",
          "protobuf",
          "data",
          "server"
        ],
        "semantic": [],
        "merged": [
          "stubs",
          "grpc",
          "protobuf",
          "data",
          "server"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.2836323229623076,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:35.193348+00:00"
      }
    },
    {
      "chapter_number": 382,
      "title": "APPENDIX A\nT",
      "start_page": 410,
      "end_page": 411,
      "summary": "HTTP-native APIs with REST\nsaw in chapter 4, REST APIs are structured around resources.\nFor example, in figure A.6, /orders represents a collection of orders,\nWe use /orders to\nGood REST API design leverages features from the HTTP protocol to deliver\nhighly expressive APIs. For example, as you can see in figure A.7, we use HTTP meth-\nods to define API endpoints and express their intent (POST to create resources and\nGET to retrieve resources); we use HTTP status codes to signal the result of process-\nWe document REST APIs using the OpenAPI standard, which was originally cre-\nThe data exchanged through a REST API goes in the body of an HTTP request/\nin a standard specification format, REST is an ideal candidate for enterprise API inte-\nGraphQL is designed to address some of the limitations of REST APIs, such as the\nGET /orders/8\nPUT /orders/8\nDELETE /orders/8\nGET /orders\nREST APIs are structured around endpoints.\nmethods, REST API responses include HTTP status codes that signal the result of processing the request.",
      "keywords": [
        "REST APIs",
        "REST",
        "REST API",
        "API",
        "orders",
        "APIs",
        "status",
        "status code",
        "HTTP status codes",
        "REST API design",
        "REST API responses",
        "payload",
        "HTTP status",
        "Good REST API",
        "document REST APIs"
      ],
      "concepts": [
        "apis",
        "api",
        "order",
        "ordered",
        "rest",
        "resources",
        "graphql",
        "payloads",
        "openapi",
        "exchange"
      ],
      "similar_chapters": [
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 4,
          "title": "",
          "score": 0.867,
          "base_score": 0.717,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 2,
          "title": "",
          "score": 0.84,
          "base_score": 0.69,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 384,
          "title": "",
          "score": 0.834,
          "base_score": 0.684,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 8,
          "title": "",
          "score": 0.817,
          "base_score": 0.667,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 378,
          "title": "",
          "score": 0.733,
          "base_score": 0.583,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "rest",
          "rest api",
          "http",
          "status",
          "orders"
        ],
        "semantic": [],
        "merged": [
          "rest",
          "rest api",
          "http",
          "status",
          "orders"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.48669577535196346,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:35.193380+00:00"
      }
    },
    {
      "chapter_number": 384,
      "title": "APPENDIX A\nT",
      "start_page": 412,
      "end_page": 413,
      "summary": "Another limitation of REST is the inability for clients to make granular requests\nent to the /ingredients API.\nrequests to the API to obtain a simple representation of a product.\nThe API client also\nProducts API\nsupplier: Arlington Milk\nsupplier: Fourier Chocolates\nsupplier: Nested Coﬀee\nsupplier: Sudoku Sugar\nA limitation of REST APIs is the inability of API clients to make granular requests of data, \nTo obtain the ingredients’ names, the client must request the details of each \nAs a result, the API client ends up making too many requests \nAPI, the client receives a full description of each ingredient, when it only needs the\nGraphQL avoids these problems by allowing clients to make granular queries on\nallowing API clients to fetch data from related entities.\nan API client can request a list of products and the names of their ingredients in a sin-\ngle request, GraphQL is an ideal candidate for APIs, which are consumed by clients\nGraphQL\nmost developers also find it more difficult to interact with a GraphQL API.\nUsing a GraphQL API, we can query data from related entities, such as \nproducts and ingredients.\nIn this figure, an API client requests a list of products with ",
      "keywords": [
        "API",
        "API client",
        "GraphQL",
        "products",
        "ingredients",
        "request",
        "APIs",
        "client",
        "data",
        "GraphQL API",
        "requests",
        "API client requests",
        "Products API",
        "REST APIs",
        "ingredients API"
      ],
      "concepts": [
        "graphql",
        "apis",
        "api",
        "ingredients",
        "clients",
        "products",
        "request",
        "protocols",
        "limitations",
        "limitation"
      ],
      "similar_chapters": [
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 8,
          "title": "",
          "score": 0.893,
          "base_score": 0.743,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 382,
          "title": "",
          "score": 0.834,
          "base_score": 0.684,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 10,
          "title": "",
          "score": 0.822,
          "base_score": 0.672,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 2,
          "title": "",
          "score": 0.736,
          "base_score": 0.586,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 4,
          "title": "",
          "score": 0.735,
          "base_score": 0.585,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "client",
          "ingredients",
          "api client",
          "graphql",
          "supplier"
        ],
        "semantic": [],
        "merged": [
          "client",
          "ingredients",
          "api client",
          "graphql",
          "supplier"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.4077260513101191,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:35.193413+00:00"
      }
    },
    {
      "chapter_number": 386,
      "title": "APPENDIX A\nT",
      "start_page": 414,
      "end_page": 415,
      "summary": "appendix B\nOften, API\nPart of managing an API is\ndix, we study API versioning strategies to manage API changes.\nIn addition to evolving and changing, APIs also sometimes come to an end.\nVersioning strategies for evolving APIs\nLet’s see how we use versioning to manage API changes.\nversioning systems for APIs:",
      "keywords": [
        "API",
        "APIs",
        "REST API",
        "API changes",
        "versioning",
        "changes",
        "manage API changes",
        "API versioning",
        "manage API",
        "APPENDIX",
        "version",
        "GraphQL",
        "REST",
        "manage",
        "make"
      ],
      "concepts": [
        "apis",
        "api",
        "change",
        "changing",
        "introduce",
        "create",
        "entities",
        "fields",
        "endpoint",
        "alto"
      ],
      "similar_chapters": [
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 388,
          "title": "",
          "score": 0.894,
          "base_score": 0.744,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 390,
          "title": "",
          "score": 0.772,
          "base_score": 0.622,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 382,
          "title": "",
          "score": 0.626,
          "base_score": 0.626,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 384,
          "title": "",
          "score": 0.514,
          "base_score": 0.514,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 4,
          "title": "",
          "score": 0.473,
          "base_score": 0.473,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "versioning",
          "manage api",
          "api changes",
          "manage",
          "changes"
        ],
        "semantic": [],
        "merged": [
          "versioning",
          "manage api",
          "api changes",
          "manage",
          "changes"
        ]
      },
      "topic_id": 1,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.3996157712703861,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:35.193442+00:00"
      }
    },
    {
      "chapter_number": 388,
      "title": "APPENDIX B\nM",
      "start_page": 416,
      "end_page": 417,
      "summary": "APPENDIX B\nManaging an API’s life cycle\nPatch versions indicate bug fixes.\nvery often, or when your releases are time sensitive.\nadditional counter to keep track of each release, for example, 2022.12.01.3,\n(For more details on calendar versioning, see http://mng.bz/O6MO.)\nIf you release a new version of your API, that ver-\nAn example\nB.2\nManaging the life cycle of your APIs\nSince we’re using the Accept header, we respond with a 415 (Unsupported\nVersioning using custom Request Header fields—In this approach, you use a cus-\nHowever, indicating the\nAPI version in the URL also means that our resource URIs change depending on the\nUsing the Accept header is another popular option, but it couples the logic for\nour API clients.\nB.2\nManaging the life cycle of your APIs\never; as the products and services that you offer through APIs evolve and change,\nA deprecated API is still in\nAPIs, your users won’t expect further changes to them.\nDeprecation serves as a grace",
      "keywords": [
        "API",
        "API version",
        "APIs",
        "Accept Header",
        "Header",
        "versioning",
        "Calendar versioning",
        "version",
        "Header field",
        "API consumers",
        "Accept",
        "URL",
        "request Header",
        "API clients",
        "request Header field"
      ],
      "concepts": [
        "versions",
        "version",
        "api",
        "apis",
        "strategy",
        "strategies",
        "uses",
        "useful",
        "accept",
        "deprecate"
      ],
      "similar_chapters": [
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 390,
          "title": "",
          "score": 0.972,
          "base_score": 0.822,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 386,
          "title": "",
          "score": 0.894,
          "base_score": 0.744,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 382,
          "title": "",
          "score": 0.475,
          "base_score": 0.475,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 4,
          "title": "",
          "score": 0.451,
          "base_score": 0.451,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 402,
          "title": "",
          "score": 0.429,
          "base_score": 0.429,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "header",
          "versioning",
          "request header",
          "accept header",
          "accept"
        ],
        "semantic": [],
        "merged": [
          "header",
          "versioning",
          "request header",
          "accept header",
          "accept"
        ]
      },
      "topic_id": 1,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.3599915727374729,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:35.193470+00:00"
      }
    },
    {
      "chapter_number": 390,
      "title": "APPENDIX B\nM",
      "start_page": 418,
      "end_page": 419,
      "summary": "If the API is going to be deprecated in the future, we set the Deprecation header to\nthe date when the API will be deprecated:\nOnce the API is deprecated, we set the Deprecation header to true:\nYou can also use the Link header to provide additional information about your API\nFor example, you can provide a link to your deprecation policy:\n.com/deprecation to find additional information about the deprecation of the API.\nIf you’re deprecating an old version of your API, you can use the Link header to\nIn addition to broadcasting the deprecation of your APIs, you should also announce\nwhen the API will be retired.\nWe use the Sunset header to signal when the API will\nand 4xx status codes when a user calls the old API.\nassigned a new URI, and therefore it may be useful when you migrate your API to a\nProper management of API changes and deprecations is a crucial yet often over-\napplying the recommendations from this appendix, you’ll be able to evolve your APIs\nIn this appendix, you’ll learn to add authentication to your APIs with",
      "keywords": [
        "API",
        "Deprecation",
        "Deprecation header",
        "header",
        "Deprecation HTTP Header",
        "HTTP Header Field",
        "API deprecation",
        "API deprecation process",
        "APIs",
        "Sunset HTTP Header",
        "Link header",
        "Sunset header",
        "APPENDIX",
        "Link",
        "HTTP Header"
      ],
      "concepts": [
        "api",
        "apis",
        "deprecated",
        "deprecations",
        "authentication",
        "authenticating",
        "managing",
        "status",
        "provide",
        "providers"
      ],
      "similar_chapters": [
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 388,
          "title": "",
          "score": 0.972,
          "base_score": 0.822,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 386,
          "title": "",
          "score": 0.772,
          "base_score": 0.622,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 4,
          "title": "",
          "score": 0.465,
          "base_score": 0.465,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 382,
          "title": "",
          "score": 0.458,
          "base_score": 0.458,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 402,
          "title": "",
          "score": 0.424,
          "base_score": 0.424,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "deprecation",
          "header",
          "http header",
          "link",
          "api deprecation"
        ],
        "semantic": [],
        "merged": [
          "deprecation",
          "header",
          "http header",
          "link",
          "api deprecation"
        ]
      },
      "topic_id": 1,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.3580401567909035,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:35.193498+00:00"
      }
    },
    {
      "chapter_number": 392,
      "title": "APPENDIX C\nAPI",
      "start_page": 420,
      "end_page": 421,
      "summary": "API authorization using an identity provider\nwe can focus our time and efforts on building our APIs. Good IDaaS providers are built\nOnce you’ve created the API, go to Permissions and add a permission scope to the\nAPI, as shown in figure C.2.\nYour APIs page\nThis API’s permissions tab\nTo add permission scopes to the API, click on the Permissions tab, and fill in the Add a \nTo find out your tenant’s default domain, go to the tenant’s settings page and click the ",
      "keywords": [
        "API",
        "provider",
        "IDaaS",
        "tenant",
        "create",
        "permission",
        "Add permission scopes",
        "Custom Domains tab",
        "click",
        "permission scopes",
        "Custom Domains",
        "add",
        "tab",
        "IDaaS provider",
        "Add permission"
      ],
      "concepts": [
        "api",
        "apis",
        "provider",
        "security",
        "domains",
        "user",
        "permissions",
        "form",
        "tab",
        "identifier"
      ],
      "similar_chapters": [
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 402,
          "title": "",
          "score": 0.755,
          "base_score": 0.605,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 394,
          "title": "",
          "score": 0.527,
          "base_score": 0.377,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 400,
          "title": "",
          "score": 0.527,
          "base_score": 0.377,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 398,
          "title": "",
          "score": 0.511,
          "base_score": 0.361,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 11,
          "title": "",
          "score": 0.489,
          "base_score": 0.339,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "permission",
          "tab",
          "add permission",
          "permission scopes",
          "scopes"
        ],
        "semantic": [],
        "merged": [
          "permission",
          "tab",
          "add permission",
          "permission scopes",
          "scopes"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.2792850315699179,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:35.193540+00:00"
      }
    },
    {
      "chapter_number": 394,
      "title": "APPENDIX C\nAPI",
      "start_page": 422,
      "end_page": 423,
      "summary": "https:/ /<tenant>.<region>.auth0.com/.well-known/openid-configuration\nthe URL that returns the public keys we can use to verify Auth0’s tokens.\n$ curl https:/ /coffeemesh.eu.auth0.com/.well-known/openid-configuration \\\n\"https:/ /coffeemesh-dev.eu.auth0.com/.well-known/jwks.json\"\nabout each of your tenant’s public keys.\nkid is the ID of the key,\nlic keys in the form of X.509 certificates, the first of which we use to verify the JWT’s\ntificate, and load the public keys from the well-known endpoint.\nSince Auth0 uses several keys to sign the tokens, we load the public keys by calling\nthe JWKS endpoint, and we dynamically load the right key for the given token.\ncan see in figure C.4, the kid property in the token’s headers tells us which key we\nneed to use, and our custom function _get_certificate_for_kid() finds the X.509\ncertificate for the token’s kid.\nTo load the key, we use cryptography’s load_pem_x-\n509_certificate() function, passing in the public key formatted into our X.509 byte-\nfrom cryptography.x509 import load_pem_x509_certificate\n\"-----BEGIN CERTIFICATE-----\\n{key}\\n-----END CERTIFICATE-----\"  \npublic_keys = requests.get(\n\"https:/ /coffeemesh-dev.eu.auth0.com/.well-known/jwks.json\"\nReturn the public key whose ID matches the provided kid.\nkeys from the tenant’s ",
      "keywords": [
        "CERTIFICATE",
        "key",
        "keys",
        "public keys",
        "kid",
        "API",
        "well-known",
        "public",
        "URL",
        "BEGIN CERTIFICATE",
        "END CERTIFICATE",
        "tenant",
        "token",
        "load",
        "template"
      ],
      "concepts": [
        "keys",
        "key",
        "kid",
        "certificates",
        "function",
        "looks",
        "algorithms",
        "dependencies",
        "uses",
        "header"
      ],
      "similar_chapters": [
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 396,
          "title": "",
          "score": 0.843,
          "base_score": 0.693,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 402,
          "title": "",
          "score": 0.669,
          "base_score": 0.519,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 11,
          "title": "",
          "score": 0.614,
          "base_score": 0.464,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 4,
          "title": "",
          "score": 0.575,
          "base_score": 0.425,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 392,
          "title": "",
          "score": 0.527,
          "base_score": 0.377,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "keys",
          "public",
          "key",
          "known",
          "certificate"
        ],
        "semantic": [],
        "merged": [
          "keys",
          "public",
          "key",
          "known",
          "certificate"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.2937951024024081,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:35.193572+00:00"
      }
    },
    {
      "chapter_number": 396,
      "title": "APPENDIX C\nAPI",
      "start_page": 424,
      "end_page": 425,
      "summary": "Public Key\nsigning keys from the\nkey for the JWT by\nTo validate a JWT, we verify its signature using its corresponding signing key.\nraise Exception(f\"Not matching key found for kid {kid}\")    \ndef load_public_key_from_x509_cert(certificate):    \nLoads the public signing key into a RSAPublicKey object.\nWe can then load the key using cryptography's\nconvenient `load_pem_x509_certificate` function.\nreturn load_pem_x509_certificate(certificate).public_key()    \ndef decode_and_validate_token(access_token):     \nValidates an access token.\nunverified_headers = jwt.get_unverified_header(access_token)   \npublic_key = load_public_key_from_x509_cert(   \nX509_CERT_TEMPLATE.format(key=x509_certificate).encode(\"utf-8\")\naccess_token,\nThe orders service is now able to validate tokens issued by Auth0.\nIn the PKCE flow, the API client requests an ID token and an access token directly\ntoken to interact with the API server.\nthe public key object \nkey.\nthe token’s\ntoken’s key ID.\npublic key\ndecode the token.\nthe token’s header.\nthe token.",
      "keywords": [
        "Key",
        "Token",
        "CERTIFICATE",
        "Public",
        "Public Key",
        "signing key",
        "kid",
        "load",
        "API",
        "public key object",
        "JWT",
        "signing",
        "access",
        "API server",
        "access token"
      ],
      "concepts": [
        "key",
        "keys",
        "certificate",
        "token",
        "kid",
        "application",
        "orders",
        "function",
        "returns",
        "sections"
      ],
      "similar_chapters": [
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 394,
          "title": "",
          "score": 0.843,
          "base_score": 0.693,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 11,
          "title": "",
          "score": 0.692,
          "base_score": 0.542,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 402,
          "title": "",
          "score": 0.616,
          "base_score": 0.466,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 400,
          "title": "",
          "score": 0.553,
          "base_score": 0.403,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 398,
          "title": "",
          "score": 0.55,
          "base_score": 0.4,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "key",
          "token",
          "public",
          "signing",
          "public key"
        ],
        "semantic": [],
        "merged": [
          "key",
          "token",
          "public",
          "signing",
          "public key"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.27858224738539905,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:35.193602+00:00"
      }
    },
    {
      "chapter_number": 398,
      "title": "APPENDIX C\nAPI",
      "start_page": 426,
      "end_page": 427,
      "summary": "with Vue.js that talks to the orders API, and it’s configured to authenticate with an\nOnce the application is configured, you can run it by executing the following command:\nsure the orders API is also running, since the Vue.js application talks to it.\norders API, run the following command from the orders folder:\nexample, you can get a list of orders for your user by calling the API with the follow-\nThrough the Vue.js application, you can create new orders and display the orders\nThe PKCE flow works for users accessing your APIs through the browser.\ngrammatic access to your APIs, you need to support the client credentials flow.\nThis section explains how to implement the client credentials flow for server-to-server\nservices to access other APIs, or when we want to allow programmatic access to our\nAPIs. In the client credentials flow, our services request an access token from the\nWe can then use this access token to access the API of the target audience.\nTo use this authorization flow, you need to register a server-to-server client with\nIn your Auth0 dashboard’s applications page, click Create Appli-\nsecret, which you can use to obtain access tokens.\naccess token and make a call to the orders API.\nfunction to obtain the access token from the authorization server by calling the POST\nwe get back an access token, which we then use to call the orders API.\nAuthorizing a client for machine-to-machine access to the orders API",
      "keywords": [
        "orders API",
        "client",
        "API",
        "client credentials flow",
        "application",
        "ACCESS",
        "orders",
        "access token",
        "token",
        "client credentials",
        "flow",
        "Allowed Web Origins",
        "APIs",
        "Vue.js application",
        "credentials flow"
      ],
      "concepts": [
        "orders",
        "application",
        "applications",
        "flow",
        "accessing",
        "access",
        "authorize",
        "authorizing",
        "server",
        "apis"
      ],
      "similar_chapters": [
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 400,
          "title": "",
          "score": 0.691,
          "base_score": 0.541,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 11,
          "title": "",
          "score": 0.653,
          "base_score": 0.503,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 402,
          "title": "",
          "score": 0.578,
          "base_score": 0.428,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 396,
          "title": "",
          "score": 0.55,
          "base_score": 0.4,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 4,
          "title": "",
          "score": 0.537,
          "base_score": 0.387,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "access",
          "flow",
          "credentials flow",
          "orders",
          "token"
        ],
        "semantic": [],
        "merged": [
          "access",
          "flow",
          "credentials flow",
          "orders",
          "token"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.3182423917201063,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:35.193635+00:00"
      }
    },
    {
      "chapter_number": 400,
      "title": "APPENDIX C\nAPI",
      "start_page": 428,
      "end_page": 429,
      "summary": "def create_order(token):\n'order': [{\norder = requests.post(\norder = create_order(access_token)\nto authenticate your requests using a Swagger UI so that you can test your API more\nAuthorizing requests in the Swagger UI\nYou can use the Swagger UI to test your API authorization as well, and in this section\nFirst, cd into appendix_c/orders and up the API server with autho-\nYou can now access the Swagger UI on http:/ /localhost:8000/docs/orders.\nAuthorizing requests in the Swagger UI\ntest.py script, you’ll get a token and the result of creating an order:\n➥ {'order': [{'product': 'latte', 'size': 'small', 'quantity': 1}], 'id': ",
      "keywords": [
        "Swagger",
        "API",
        "token",
        "order",
        "’ll",
        "API authorization",
        "machine",
        "authorization",
        "access",
        "requests",
        "authorize",
        "test your API",
        "APPENDIX",
        "request",
        "’ll learn"
      ],
      "concepts": [
        "order",
        "authorizing",
        "authorized",
        "authorize",
        "requests",
        "request",
        "token",
        "flow",
        "apis",
        "learn"
      ],
      "similar_chapters": [
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 11,
          "title": "",
          "score": 0.736,
          "base_score": 0.586,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 6,
          "title": "",
          "score": 0.714,
          "base_score": 0.564,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 402,
          "title": "",
          "score": 0.706,
          "base_score": 0.556,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 398,
          "title": "",
          "score": 0.691,
          "base_score": 0.541,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 4,
          "title": "",
          "score": 0.677,
          "base_score": 0.527,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "swagger",
          "swagger ui",
          "ui",
          "order",
          "ui test"
        ],
        "semantic": [],
        "merged": [
          "swagger",
          "swagger ui",
          "ui",
          "order",
          "ui test"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.39884778468957766,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:35.193668+00:00"
      }
    },
    {
      "chapter_number": 402,
      "title": "APPENDIX C\nAPI",
      "start_page": 430,
      "end_page": 442,
      "summary": "APPENDIX C\nAPI authorization using an identity provider\nThis is all it takes to test your API authorization with a Swagger UI.\nexternal identity provider, how to test the PKCE and the client credentials flows, and\nand build secure APIs!\nFigure C.6\nbatch operations 295–297\nAPI authorization 293–300\nupdating database to link users and orders 294–297\nAPI Gateway 287\nAPI life cycle 390\nproperty-based testing 315–322\ntraditional approach to testing 316–317\ncustomizing test suite with hooks 307–315\noverview 304–305\nrunning default test suite 305–307\nrunning default test suite 322–323\nusing - -stateful=links 323–327\nAPI versioning 387–389\nbuilding resolvers for custom scalars 258–262\ncreating entry point for GraphQL server 242–243\nimplementing mutation resolvers 256–258\naud reserved claim, JWT 281–282\nclient credentials flow 399–400\nidentity providers 391–402\nusing identity as service provider 392–397\nauthorization code flow 273\nPKCE flow 273–275\nPKCE flow 397–398\nauthorization code, OAuth 274\nAuthorization HTTP header 108\nAuthorization server, OAuth 272\nAuthorizeRequestMiddleware class, orders API 289\nAWS Aurora 361–370\ncreating serverless databases 361–364\nbase64 encoding 284–285\nbearerAuth security scheme, OpenAPI 304, 400–401\ncacheability principle (REST) 65–66\nclass-based views 122–123, 125–127\nclient credentials flow, OAuth 275, 399–400\nCoffeeMesh 17\nanalyzing business structure of 49–50\napplying strategic analysis to 53–56\nkitchen API (REST)\ninitializing web application 123–125\noverview 120–122\norders API (REST)\nhigh-level architecture 22–23\nimplementing in-memory list of orders 41–43\noverview 111–112\nvalidating payloads with unknown fields 115–118\nvalidating request payloads with pydantic 34–38\nimplementing mutation resolvers 256–258\nlaying out project structure 241–242\noverview 189–192\ncontext managers 174–175\nCore Kubernetes (Vyas and Love) 345\nadding CORS middleware 292–293\ncryptography library 271, 283, 286, 288, 395–397\nDatetime custom scalar (GraphQL) 194, 258–260\nDDD (domain-driven design) 52–53, 166\nDeprecation HTTP header 389–390\nDias, Nuwan 333\ndiscoverability (HATEOAS, REST) 72–73\ndistributed transaction tracing 13–14\nbuilding image 333–336\nDocker in Action (Kuenzli) 338\ndocumentation-driven development 15–17\ndomain-driven design (DDD) 52–53, 166\noverview 304–305\ngenerating error responses 313–314\nsaving ID of created resource 309–311\nECR (Elastic Container Registry) 340–341\neksctl CLI 346–349\nElastic Container Registry (ECR), AWS 340–341\nencode() function, PyJWT 282–283\n__enter__() method, context manager class 174–176\nenvironment keyword, Docker Compose 338\n__exit__() method, context manager class 174–175\nexp reserved claim, JWT 281–283\nFargate, AWS 347\nvalidating payloads with unknown fields 115–118\nvalidating request payloads with pydantic 34–38\nfixed_dictionaries(), hypothesis 319–320\ninitializing web application 123–125\noverview 122–123\noverview 186–189\nbuilding resolvers for custom scalars 258–262\nimplementing mutation resolvers 256–258\nlaying out project structure 241–242\nrunning parametrized 226–229\nrunning parametrized 226–229\nunderstanding errors 215–217\nrunning mock server 211–214\ngraphql-faker (GraphQL mocking tool) 211–213\ngRPC 380–381\nHTTP-native APIs with REST 382\nHTTP status codes 72, 77–83\nreporting client errors with 78–81\nreporting errors in server with 82–83\n- -hypothesis-database flag 323\nproperty-based testing with 318–319\ntesting endpoints 319–322\nidentity, OIDC 391–402\nID (Unique Identifiers) scalar, GraphQL 192–194\ninfo parameter (Ariadne resolvers) 239–240, 256\ninfrastructure overhead 14–15\njq (JSON query CLI) 344\nJWTs (JSON Web Tokens) 108, 278–286, 391\nkitchen API\nimplementing in-memory list of schedules 140–142\noverview 120–122\ncreating clusters with EKS 346–349\ndeleting clusters 372–374\nexposing services with ingress objects 359–361\nIAM roles for service accounts 350–351\noverview 344–346\nKubernetes in Action (Lukša) 372\nkube-system namespace 347, 352–353\nLewis, James 4, 8, 10\nmachine_to_machine_test.py script 400–401\nMethodView class, Flask 125–127\ncreating clusters with EKS 346–349\ndistributed transaction tracing 13–14\ndocumentation-driven development 15–17\nGraphQL API\nby business capability 49–52, 57–58\nMicroservices Patterns (Richardson) 11\nMicroservices Security in Action (Siriwardena and \nDias) 333\nmicroservices vs.\nimplementing mutation resolvers 256–258\nrunning parametrized 226–229\nMutationType class (Ariadne framework) 256–257\nOAuth2 (Open Authorization) 108\nauthorization code flow 273\nPKCE flow 273–275\nobject relational mapper (ORM) 150–151\nobj parameter, Ariadne resolvers 239–240, 256\nrefactoring schema definitions 100–102\ncreating generic 105–107\nOpen Authorization (OAuth) 108\nOpenID Connect in Action (Siriwardena) 278\noperational complexity 14–15\norders API\nhigh-level architecture 22–23\nimplementing in-memory list of orders 41–43\noverview 111–112\nvalidating payloads with unknown fields 115–118\nvalidating request payloads with pydantic 34–38\nORM (object relational mapper) 150–151\nOAuth 273–275, 397–398\nports, hexagonal architecture 145–146\nbuilding resolvers for custom scalars 258–262\ncreating entry point for GraphQL server 242–243\nimplementing mutation resolvers 256–258\nlaying out project structure 241–242\noverview 189–192\nproperty-based testing 315–322\nusing hypothesis to test endpoints 319–322\ntraditional approach to testing 316–317\npublic certificate 283–284\npublic key 283–286\nvalidating payloads with unknown fields 115–118\nrunning parametrized 226–229\nunderstanding errors 215–217\nReal-World Cryptography (Wong) 280\nbuilding resolvers for custom scalars 258–262\nimplementing mutation resolvers 256–258\nmarshalling and validating with pydantic 38–41\nHTTP-native APIs with REST 382\nHTTP status codes 77–83\nreporting client errors in request 78–81\nreporting errors in server 82–83\nRichardson maturity model 70–73\nkitchen API\ninitializing web application 123–125\noverview 120–122\norders API\nhigh-level architecture 22–23\noverview 111–112\nvalidating request payloads with pydantic 34–38\nREST API testing\ncustomizing test suite with hooks 307–315\noverview 304–305\nrunning default test suite 322–323\nusing - -stateful=links 323–327\nRichardson maturity model 70–73\nRiedesel, Jamie 14\nRPC (remote procedure call) 71, 377–386\nXML-RPC 377–386\nbuilding resolvers for custom scalars 258–262\nScheduleOrderSchema schema, kitchen API 121, \nrunning default test suite 322–323\nusing - -stateful=links 323–327\nservers section, OpenAPI 96, 119, 370–372\nby business capability 49–52\nanalyzing business structure 49–50\napplying strategic analysis 53–56\ndomain-driven design 52–53\nby business capability 57–58\nsingleton resource, REST APIs 62\nSOAP (Simple Object Access Protocol) 378–379\nSoftware Telemetry (Riedesel) 14\nSPAs (single-page applications) 64, 274, 397\nSQLite 150–151, 295–296\nstatelessness principle (REST) 64–65\nString scalar (GraphQL) 192–194\nStrong, James 348\ntolerant reader pattern 115–116\nbuilding resolvers for custom scalars 258–262\nscalars, creating custom 194–195\nHTTP-native APIs with REST 382\ngRPC 380–381\nXML-RPC 377–386\nXML-RPC 377–386\nHexagonal architecture helps us build services with loosely coupled components.\nUsing this connection, a client can request the name and price \nstock: 55.4 KG\nstock: 119.2 L\nstock: 67.3 KG\nWell-designed APIs enable reliable integra-\nprotocols, and strategies you need to design, build, and deploy \nGraphQL APIs\n● Service implementation patterns for loosely coupled \n● API authorization with OAuth and OIDC\nJosé Haro Peralta is a consultant, author, and instructor.\nAPIs, with neat examples \nTh e service implementation \nA well-designed API makes ",
      "keywords": [
        "REST API",
        "REST API testing",
        "API",
        "REST APIs",
        "REST API design",
        "implementing API endpoints",
        "GraphQL API",
        "REST",
        "JSON Schema",
        "APIs",
        "REST API implementation",
        "implementing",
        "GraphQL API testing",
        "API testing",
        "implementing API"
      ],
      "concepts": [
        "apis",
        "graphql",
        "property",
        "properties",
        "openapi",
        "implementation",
        "rest",
        "pattern",
        "designing",
        "service"
      ],
      "similar_chapters": [
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 392,
          "title": "",
          "score": 0.755,
          "base_score": 0.605,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 400,
          "title": "",
          "score": 0.706,
          "base_score": 0.556,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 11,
          "title": "",
          "score": 0.684,
          "base_score": 0.534,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 394,
          "title": "",
          "score": 0.669,
          "base_score": 0.519,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 382,
          "title": "",
          "score": 0.641,
          "base_score": 0.491,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "258",
          "resolvers",
          "overview",
          "256",
          "implementing"
        ],
        "semantic": [],
        "merged": [
          "258",
          "resolvers",
          "overview",
          "256",
          "implementing"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.4238405825142343,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:35.193723+00:00"
      }
    }
  ],
  "total_chapters": 27,
  "enrichment_provenance": {
    "taxonomy_id": "none",
    "taxonomy_version": "none",
    "taxonomy_path": "none",
    "taxonomy_checksum": "sha256:none",
    "source_metadata_file": "Microservice APIs Using Python Flask FastAPI_metadata.json",
    "enrichment_date": "2025-12-17T23:07:35.202008+00:00",
    "enrichment_method": "msep",
    "model_version": "ai-agents-msep-v1",
    "processing_time_ms": 3907.6189610004803,
    "total_similar_chapters": 135
  }
}