{
  "metadata": {
    "title": "Python Microservices Development",
    "source_file": "Python Microservices Development_metadata.json"
  },
  "chapters": [
    {
      "chapter_number": 1,
      "title": "Understanding Microservices",
      "start_page": 22,
      "end_page": 46,
      "summary": "Understanding Microservices\nindependent microservices.\nUnderstanding Microservices\nMonolithic approach of building an application\nMicroservices approach of building applications\nBenefits of microservices\nPitfalls in microservices\nImplementing microservices with Python\nbuilding microservices with a good understanding of what they are and what they aren't--\nand how you can use Python.\nwhat microservices are.\nUnderstanding Microservices\ncan be everything and anything as long as you are not running all your application code\nNow if we want to give a complete definition of what are microservices, the best way to do\nLet's take a very simple example of a traditional monolithic application: a hotel booking\nWhen a user performs a search on the hotel website, the application goes through the\nUnderstanding Microservices\nThe application interacts with a database that contains the hotel's information, the\nThe biggest one is that the whole application is in a single code base, and when the project\ndata into a single database also simplifies the development of the application.\nUnderstanding Microservices\nThe deployment is also a no brainer: we can tag the code base, build a package, and run it\nIf your application stays small, this model works well and is easy to maintain for a single\nhaving the whole application in a single code base brings some nasty issues along the way.\nyour banking service or your database layer, the whole application gets into a very unstable\nThe application is bound to get new features, and\nIt's not fun, and developers who work on such a project dream of building the application\nDeploying one application is simple.\nUnderstanding Microservices\nthe whole application may break.\nBuilding a web app in Python if you use a framework like Flask, lets you focus on the\nPython package that uses Reportlab and some templates to do the work.\nBut you're still building a single application and some problems remain, like the inability to\nIf one part of your application uses a library, but the PDF\nLet's now look at how the same application would look like if we were to use microservices\nUnderstanding Microservices\nThe microservice approach\nIf we were to build the same application using microservices, we would organize the code\napplication in charge of everything, we would split it into many different microservices, as\nBooking UI: A frontend service, which generates the web user interface, and\ninteracts with all the other microservices.\nUnderstanding Microservices\nwhich each microservice can use to authenticate when calling others.\nThose microservices, along with the few external services like the email service, would\nprovide a feature set similar to the monolithic application.\nThere's no centralized database, as each microservice deals internally with its own data\nBut besides this particular UI case, a web application designed with microservices is a\ncomposition of several microservices, which may interact with each other through HTTP to\nA microservice is a lightweight application, which provides a narrowed\nbased service that exchanges binary data as a microservice for example.\nBut in our case, and throughout the book, all our microservices are just simple web\napplications that use the HTTP protocol, and consume and produce JSON when it's not a\nUnderstanding Microservices\nMicroservice benefits\nWhile the microservices architecture looks more complicated than its monolithic\nFirst of all, each microservice can be developed independently by a separate team.\ninstance, building a reservation service can be a full project on its own.\nimpact is localized inside that service, and the rest of the application stays stable and is\nApplied to microservices, it means that we want to make sure that\napplication such as PDF reporting, even if you do it cleanly, you make the base code bigger,\nBuilding that feature in a separate application\nUnderstanding Microservices\nDealing with a smaller project also reduces risks when improving the application: if a team\na prototype that implements the same microservice API, try it out, and decide whether or\nFinally, having your application split into components makes it easier to scale depending on\nthe PDF generation starts to heat up the CPUs. You can deploy that specific microservice in\nsome servers that have bigger CPUs. Another typical example are RAM-consuming microservices like the ones that interact with\nWe can, thus, summarize the benefits of microservices as follows:\nA team can develop each microservice independently, and use whatever\nDevelopers break the application complexity into logical components.\nSince microservices are standalone applications, there's a finer control on\nThe microservices architecture is good at solving a lot of the problems that may arise once\nUnderstanding Microservices\nMicroservices pitfalls\nAs said earlier, building an application with microservices has a lot of benefits, but it's not a\nmicroservices:\nThe first issue of a microservice architecture is how it gets designed.\nSome microservices\nmicroservices can be more painful than refactoring a monolithic application.\nYou can mitigate this problem by avoiding splitting your app in microservices if the split is\nIt's always easier to split apart some of the code into a new microservice later than to\nmerge back to two microservices in the same code base because the decision turned out to\nFor instance, if you always have to deploy two microservices together, or if one change in a\nmicroservice impacts the data model of another one, the odds are that you did not split the\napplication correctly, and that those two services should be reunited.\nUnderstanding Microservices\napplication.\nAn effective microservice needs to be\nindependent of other microservices, and ideally, should not share a database.\nmicroservices-based applications.\nUnderstanding Microservices\nAnother problem happens when a feature change impacts several microservices.\ndiscover in the second part of the book when we'll build our application.\nYou need to be able to play with your whole application when you develop it.\nMicroservices-style architecture boosts deployment tools innovation, and\nThe pitfalls of using microservices can be summarized as follows:\nPremature splitting of an application into microservices can lead to architectural\nTesting and deploying microservices can be complex\nAnd the biggest challenge--data sharing between microservices is hard\nUnderstanding Microservices\nThey may seem overwhelming, and the traditional monolithic application may look like a\nsafer bet, but in the long term, splitting your project into microservices will make many of\nImplementing microservices with Python\nAs you probably already know, it's used to build many different kinds of applications--from\nbuild web applications.\nbuilding microservices, and many major companies are happily using it.\nmicroservices using Python, some insights on asynchronous versus synchronous\nUnderstanding Microservices\napplication up and running.\ncan write a Python application in order to serve HTTP requests.\nWhen your code uses that standard, your project can be executed by standard web servers\nYour application just has to deal with incoming requests and send back JSON responses,\nYou can create a fully functional microservice that returns the server's local time with a\ndef application(environ, start_response):\nhook before or after the WSGI application function itself, to do something within the\nSome web frameworks, like Bottle (h t t p ://b o t t l e p y .\nThe application function\nAnd writing microservices means your code will have to wait for responses from various\nUnderstanding Microservices\nbidirectional applications like web socket-based ones.\nseveral incoming requests that call your application at the same time?\nWhen you're coding a Twisted application, you can use callbacks to pause and resume the\nIn the meantime, building microservices with synchronous frameworks is still possible and\nThere's, however, one trick to boost synchronous web applications--Greenlet, which is\nAsynchronous applications use an event loop that pauses and resumes execution contexts\nUnderstanding Microservices\ncan be used to call Python functions.\nwrite an asynchronous application using a thread-like interface paradigm.\nFor building microservices based on the WSGI standard, if the underlying code uses\nUnderstanding Microservices\ndef application(environ, start_response):\nIf you are building microservices where increasing the number of concurrent requests you\nTo implement the same microservices, you need to write\nUnderstanding Microservices\nproblems when building HTTP microservices, which are as follows:\nYou need to implement each endpoint in your microservice with a class derived\nProperly testing your Twisted application is hard, and you have to use a Twisted-\nrouting system, and does everything possible to make the code closer to plain Python.\nWhen Guido van Rossum started to work on adding async features in Python 3, part of the\nUnderstanding Microservices\nThe way the Python core developers coded asyncio,\nimplement coroutines, made asynchronous applications built with vanilla Python 3.5+ code\nPython and how to use them.\nin Node.js or Twisted (Python 2) applications.\nasyncio package to build asynchronous applications, refer to h t t p s ://d o c s .\nPython is now as expressive as languages like Lua to create coroutine-based applications,\nsame microservice, fully asynchronous, with it would simply need these few elegant lines:\napp = web.Application()\nUnderstanding Microservices\nBut asynchronous frameworks and libraries based on Python 3 are still emerging, and if you\nIf you need to use a library that is not asynchronous in your code, to use it from your\nAnd there are many great synchronous frameworks to build microservices with Python,\nUnderstanding Microservices\nmicroservices is very close to plain Python, and the framework is mostly\nIn the previous sections, we've been through the two different ways to write microservices:\nasynchronous versus synchronous, and whatever technique you use, the speed of Python\ndirectly impacts the performance of your microservice.\nA microservice is often a thin layer of code that sits most of its life\napplications cannot use several processes.\nUnderstanding Microservices\nstatic extension of the language like Cython (h t t p ://c y t h o n .\nUnderstanding Microservices\nBut if you build your microservice with a standard set of libraries, chances are that it will\nperformance issues described in this section, because the overhead in a microservice is\nAnd if performance is a problem, the microservice approach allows you to\nIn this chapter, we've compared the monolithic versus microservice approach to building\nYou should see microservices as an improvement of an application that started its life as a\nmicroservices.\nUnderstanding Microservices\nwrite web applications, and therefore, microservices--for the same reasons, it's a language of",
      "keywords": [
        "Microservices",
        "Understanding Microservices",
        "Python",
        "application",
        "code",
        "building microservices",
        "service",
        "Understanding",
        "WSGI",
        "Python web",
        "project",
        "building HTTP microservices",
        "web",
        "web applications",
        "data"
      ],
      "concepts": [
        "microservices",
        "python",
        "applicative",
        "application",
        "applications",
        "code",
        "coded",
        "service",
        "web",
        "understanding"
      ],
      "similar_chapters": [
        {
          "book": "Python Microservices Development",
          "chapter": 5,
          "title": "",
          "score": 0.543,
          "base_score": 0.543,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Python Microservices Development",
          "chapter": 2,
          "title": "",
          "score": 0.504,
          "base_score": 0.504,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Python Microservices Development",
          "chapter": 10,
          "title": "",
          "score": 0.485,
          "base_score": 0.485,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Python Microservices Development",
          "chapter": 9,
          "title": "",
          "score": 0.485,
          "base_score": 0.485,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Python Microservices Development",
          "chapter": 8,
          "title": "",
          "score": 0.468,
          "base_score": 0.468,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "understanding microservices",
          "understanding",
          "building",
          "microservice",
          "python"
        ],
        "semantic": [],
        "merged": [
          "understanding microservices",
          "understanding",
          "building",
          "microservice",
          "python"
        ]
      },
      "topic_id": null,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.48003164383133723,
        "topic_boost": 0.0,
        "timestamp": "2025-12-17T23:08:32.291527+00:00"
      }
    },
    {
      "chapter_number": 2,
      "title": "Discovering Flask",
      "start_page": 47,
      "end_page": 78,
      "summary": "Discovering Flask\nFlask was started around 2010, leveraging the Werkzeug WSGI toolkit (h t t p ://w e r k z e u g .\no r g /), which provides the foundations for interacting with HTTP requests via the\nIt lets you freely organize your application code as you want, and use whatever\nDiscovering Flask\nFlask, on the other hand, does not care what library you use to interact with your data.\nconsist of adding a package like Flask-SQLAlchemy in your project.\nThis chapter will make sure you know what Flask has to offer, and how to\nHow Flask handles requests\nFlask built-in features\nmicroservices with Flask.\nDiscovering Flask\nAnd building microservices means each app will run in isolation, so it would be entirely\no r g /d o c s /l a t e s t /p y t h o n 3/#p y t h o n 3- s u p p o\nSince Flask is not using any new bleeding-edge Python 3 language features, your code will\no r g /s i x /) to make your code compatible with both versions if\n2. Python 2 will not be supported anymore after 2020; see h t t p s ://p y t h o n c l o c k .\nThis book uses the latest Python 3.5 stable release for all its code examples,\nHow Flask handles requests\nThe framework entry point is the Flask class in the flask.app module.\nRunning a Flask\nincoming Web Server Gateway Interface (WSGI) requests, dispatch them to the right code,\nDiscovering Flask\nmapping, and frameworks such as Flask take care of routing the call to the\nsystem uses a small rule engine to match views with incoming requests, and will be\nHere's a very basic example of a fully functional Flask application:\nfrom flask import Flask, jsonify\napp = Flask(__name__)\n@app.route('/api')\nThat app returns a JSON mapping when called on /api.\nFlask will use the\nIf you run that module in a shell, the Flask app will run its web server, and start listen to\n$ python flask_basic.py\nheaders, thanks to the jsonify() function, which takes care of converting the Python dict\nDiscovering Flask\nThe jsonify() function creates a Response object, and dumps the mapping in its body.\nWhile many web frameworks explicitly pass a request object to your code, Flask provides\nas your view returns what the client should get and Flask can serialize it, everything is\nFlask uses a mechanism called context locals, which we will\nfrom flask import Flask, jsonify, request\napp = Flask(__name__)\n@app.route('/api')\nDiscovering Flask\n$ python flask_details.py\n<Request 'http://127.0.0.1:5000/api' [GET]>\nDiscovering Flask\nRouting: Flask creates the Map class\nRequest: Flask passes a Request object to the view\nThe routing happens in app.url_map, which is an instance of Werkzeug's Map class.\nclass uses regular expressions to determine if a function decorated by @app.route matches\nDiscovering Flask\n@app.route('/api', methods=['POST', 'DELETE', 'GET'])\nFor example, if you want to create a function that handles all requests to /person/N, with N\nWhen Flask calls your function, it converts the value it finds in the URL section as the\n@app.route('/api/person/<person_id>')\nDiscovering Flask\nIf a request matches a route, but a converter fails to change a value, Flask will return a 404\nDiscovering Flask\nfrom flask import Flask, jsonify, request\napp = Flask(__name__)\n@app.route('/api/person/<registered:name>')\nDiscovering Flask\n<p> The requested URL was not found on the server.\nThe last interesting feature of Flask's routing system is the url_for() function.\n>>> from flask_converter import app\n>>> from flask import url_for\n>>> with app.test_request_context():\nThis feature is quite useful in templates when you want to display the URLs of some views\nDiscovering Flask\nWhen a request comes in, Flask calls the view inside a thread-safe block, and uses\nAs we've seen earlier, Flask uses the incoming WSGI environment data to create the request\nThe work done by Flask is quite\nfrom flask import Flask, request\napp = Flask(__name__)\n@app.route(\"/\")\nprint(\"Flask's Authorization header\")\nDiscovering Flask\n$ bin/python flask_auth.py\nFlask's Authorization header\nIn the previous examples, we've used the jsonify() function, which creates a Response\nThe Response object is, technically, a standard WSGI application you could use directly.\nIt's wrapped by Flask, and called with the WSGI's environ, and the start_response\nWhen Flask picks a view via its URL mapper, it expects it to return a callable object that can\nparsed into a Request object by the time the Response object is called\nWhen your code needs to interact with the request,\nit can use the global Request object, and ignore what's happening inside\nDiscovering Flask\nIn case the returned value is not a callable, Flask will try to convert it into a Response object\nIn most cases, when building microservices, we'll use the built-in jsonify() function, but\nheaders) tuple, which will be converted by Flask into a proper Response object.\nfrom flask import Flask\napp = Flask(__name__)\n@app.route('/api')\nThe way Flask handles requests can be summarized as follows:\nWhen the application starts, any function decorated with @app.route() is\nregistered as a view, and stored into the app.url_map.\nDiscovering Flask\nThese four steps are roughly all you need to know to start building apps using Flask.\nnext section will summarize the most important built-in features that Flask offers alongside\nFlask built-in features\nThe previous section gave us a good understanding of how Flask processes a request, and\nBut Flask comes with more helpers, which are quite useful.\nLike the request object, Flask creates a session object, which is unique to the request\nIt's a dict-like object, which Flask serializes into a cookie on the user side.\nDiscovering Flask\nFlask will let you customize the signing algorithm to use, but HMAC + SHA1 is good\nAs discussed earlier in this chapter, Flask provides a mechanism to store global variables\nThe flask.g variable contains all globals, and you can set whatever attributes you want on\nIn Flask, the @app.before_request decorator can be used to point a function that the app\nIt's a typical pattern in Flask to use before_request to set values in the globals.\nall the functions that are called within the request context can interact with g and get the\nfrom flask import Flask, jsonify, g, request\napp = Flask(__name__)\n@app.before_request\nDiscovering Flask\n@app.route('/api')\nWhen a client requests the /api view, the authenticate function will set g.user depending\nthroughout your code, can be shared via flask.g. Signals\nFlask integrates with Blinker (h t t p s ://p y t h o n h o s t e d .\nEvents are instances of the blinker.signal class created with a unique label, and Flask\no r g /d o c s /l a t e s t /a p i /#c o r e - s i g n\nIn the following example, we register the finished function to the request_finished\nfrom flask import Flask, jsonify, g, request_finished\nfrom flask.signals import signals_available\nDiscovering Flask\napp = Flask(__name__)\n@app.route('/api')\nSome signals implemented in Flask are not useful in microservices, such as the ones\nthat Flask triggers throughout the request life, which can be used to log what's going on\nPython client (Raven) hooks itself onto Flask to log exceptions.\nDiscovering Flask\nFlask extensions are simply Python projects that, once installed, provide a package or a\nFlask has a curated list of extensions maintained at h t t p ://f l a s k .\nThe other mechanism to extend Flask is to use WSGI middlewares.\nIn the example that follows, the middleware fakes a X-Forwarded-For header, so the Flask\nfrom flask import Flask, jsonify, request\nreturn self.app(environ, start_response)\napp = Flask(__name__)\n@app.route('/api')\nDiscovering Flask\nIn Flask,\nthe app object is not the WSGI application itself as we've seen earlier.\nresponse status code, and headers before the app sends back the actual body content.\nextension that will interact from within the Flask application.\nFor anything that's text-based, Flask integrates a template engine called Jinja (h t t p ://j i n j\nDiscovering Flask\nDiscovering Flask\nin Flask.\nFlask uses a mechanism similar to Django in its configuration approach.\nThe Flask object\nbe updated when you start your Flask app via your configuration objects.\n>>> from flask import Flask\n>>> app = Flask(__name__)\nDiscovering Flask\napplication, they will need to edit the Python code to do so.\nSince Flask exposes its configuration via app.config, it's pretty simple to load additional\nDiscovering Flask\nUsing it with Flask is straightforward:\n[flask]\n>>> from flask import Flask\n>>> app = Flask(__name__)\n>>> app.config.update(c.get_map('flask'))\norganize your code is to have one module per endpoint, and when you create your app\ninstance, to make sure they get imported so that Flask registers the views.\napp.py: To contain the Flask app object, and to run the app\nYou can create a Blueprint object which looks like a Flask app object, and\nDiscovering Flask\nfrom flask import Blueprint, jsonify\nThe main module (app.py) can then import this file, and register its blueprint with\nThe Flask-Restless (h t t p s ://f l a s k - r e s t l e s s .\nThe following is from the Flask-Restless documentation (Person is SQLAlchemy model):\npages when you encounter a 404 or a 50x error, and that's how Flask works out of the box.\nDiscovering Flask\nWhen your code does not handle an exception, Flask returns an HTTP 500 response without\nFlask lets you customize the app error handling via a couple of functions.\nproviding an endpoint, the decorator links a function to a specific error code.\nIn the following example, we use it to connect a function that will return a JSON-formatted\nerror when Flask returns a 500 server response (any code exception):\nfrom flask import Flask, jsonify\napp = Flask(__name__)\n@app.route('/api')\nDiscovering Flask\nFlask will call this error view no matter what exception the code raises.\nyou will be back to the default HTML responses that Flask sends.\nTo make sure your app sends JSON for every 4xx and 50x, we need to register that function\nfrom flask import Flask, jsonify, abort\napp.register_error_handler(code, error_handling)\nreturn app\napp = JsonApp(Flask(__name__))\n@app.route('/api')\nThe JsonApp function wraps a Flask app instance, and sets up the custom JSON error\nDiscovering Flask\nThe Flask application run method has a debug option, which, when used, runs it in the\nDiscovering Flask\nc o m /p y c h a r m ), for example, is a commercial IDE for Python, which offers a\no r g /w i k i /S e c u r i t y /P r o j e c t s\n/B a n d i t ) tracks Flask applications that are executed with a plain debug\nSo far in this chapter, we've looked at how Flask works, and at most of the built-in features\ninstantiate your Flask app.\nLastly, the run() call can be removed from the code, since Flask provides a generic runner\nthat looks for an app variable given a module pointed by the FLASK_APP environment\nDiscovering Flask\ncreated for this book, and is a generic Flask project that you can use to start a microservice.\nThis project uses Flakon (h t t p s ://g i t h u b .\nFlask application with an INI file and a default JSON behavior.\nremove it from your project, and build your function that creates an app;\nDiscovering Flask\nIn the following code, the app.py file instantiates a Flask app using Flakon's create_app\nThe home.py view uses Flakon's JsonBlueprint class, which implements the error\nThis example application can run via Flask's built-in command line, using the package\n$ FLASK_APP=myservice flask run\n* Serving Flask app \"myservice\"\nDiscovering Flask\nFlask wraps a simple request-response mechanism around the WSGI protocol,\nFlask is easy to extend, and it works with Python 3.\nFlask comes with nice built-in features: blueprints, globals, signals, a template\nThe microservice project is a Flask skeleton, which will be used to write\nIt's a simple app that uses an INI file for its",
      "keywords": [
        "Flask",
        "Discovering Flask",
        "flask import",
        "Flask app",
        "Python",
        "python flask",
        "request",
        "Flask app object",
        "Flask application",
        "response",
        "app",
        "Flask handles requests",
        "WSGI",
        "code",
        "Flask Authorization header"
      ],
      "concepts": [
        "flask",
        "python",
        "request",
        "requested",
        "likely",
        "code",
        "uses",
        "useful",
        "responses",
        "error"
      ],
      "similar_chapters": [
        {
          "book": "Python Microservices Development",
          "chapter": 8,
          "title": "",
          "score": 0.729,
          "base_score": 0.579,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Python Microservices Development",
          "chapter": 12,
          "title": "",
          "score": 0.556,
          "base_score": 0.556,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Python Microservices Development",
          "chapter": 1,
          "title": "",
          "score": 0.504,
          "base_score": 0.504,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Python Microservices Development",
          "chapter": 10,
          "title": "",
          "score": 0.466,
          "base_score": 0.466,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Python Microservices Development",
          "chapter": 5,
          "title": "",
          "score": 0.458,
          "base_score": 0.458,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "flask",
          "discovering",
          "discovering flask",
          "app",
          "flask flask"
        ],
        "semantic": [],
        "merged": [
          "flask",
          "discovering",
          "discovering flask",
          "app",
          "flask flask"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.4294964279924521,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:08:32.291612+00:00"
      }
    },
    {
      "chapter_number": 3,
      "title": "Coding, Testing, and Documenting - the Virtuous Cycle",
      "start_page": 79,
      "end_page": 108,
      "summary": "Coding, Testing, and\ntests.\nCoding, Testing, and Documenting - the Virtuous Cycle\nWriting tests is time-consuming at first, but in the long run, it's often the best approach to\nresults, or create a test suite that's horrible to maintain and takes too long to run.\nWriting tests is also a good way to get some perspective on your code.\nHow to run tests or add\nCoding, Testing, and Documenting - the Virtuous Cycle\nextracts in the documentation could be part of the test suite to make sure they work.\nIn any case, no matter how much energy you spend on tests and documentation, there's one\ngolden rule: testing, documenting, and coding your projects should be done continuously.\nwords, changes in the code should ideally be reflected in the tests and documentation as\ntesting and documentation tools can be used in the context of building microservices with\ndifferent kinds of tests depending on the project's nature.\nUnit tests: Make sure a class or a function works as expected in isolation\nFunctional tests: Verify that the microservice does what it says from the\nIntegration tests: Verify how a microservice integrates with all its network\nLoad tests: Measure the microservice performances\nCoding, Testing, and Documenting - the Virtuous Cycle\nUnit tests\nUnit tests are the simplest tests to add to a project, and the standard library comes with\nthe views, some functions and classes, which can be unit-tested in isolation.\nTesting in isolation in Python usually means that you instantiate a class or call a function\nresource (socket, files, and so on), and you can't run them from within your tests\nSpecific behaviors to reproduce: When you want to write a test to try out your\nAPI, using the requests (h t t p ://d o c s .\np y t h o n - r e q u e s t s .\nCoding, Testing, and Documenting - the Virtuous Cycle\nThis class has a bug_link() method, which we can test in isolation, and one\ncomplicated to run our Bugzilla server when the test is executed, so we can mock the calls\nThis technique is used in the following example with request_mock (h t t p ://r e q u e s t s - m o\nr e a d t h e d o c s .\ndef test_bug_id(self):\ndef test_get_new_bugs(self, mocker):\nCoding, Testing, and Documenting - the Virtuous Cycle\ndef test_network_error(self, mocked):\nAPI, and the server your project uses is updated, your tests will happily\nThis test ensures\nThis kind of unit test is usually enough to cover most of your classes' and functions'\nThis test class will probably cover more cases as the project grows and new situations occur.\nCoding, Testing, and Documenting - the Virtuous Cycle\nmicroservice project, unit tests are not a priority, and aiming at 100% test coverage (where\nevery line of your code is called somewhere in your tests) in your unit tests will add a lot of \nFunctional tests\nFunctional tests for a microservice project are all the tests that interact with the published\n(you send gibberish to your app and see what happens) to penetration tests (you try to break\nAs developers, the two most important kinds of functional tests we should focus on are\nTests that verify that the application does what it was built for\nThe way those scenarios are organized in the tests class is up to the developers, but the\ngeneral pattern is to create an instance of the application in the test class and then interact\ntests, but the same request-response cycle happens, so it's realistic enough.\nfrom the app object via its test_client() method.\nThe following is an example of a test against the first app we showed in this chapter, which\nfrom flask_basic import app as tested_app\ndef test_help(self):\nCoding, Testing, and Documenting - the Virtuous Cycle\napp = tested_app.test_client()\nThere's a testing flag in the Flask class, which you can use to propagate exceptions to the\ntest, but some prefer not to use it by default to get back from the app what a real client\nfrom flask_error import app as tested_app\nself.app = tested_app.test_client()\ndef test_raise(self):\ndef test_proper_404(self):\nCoding, Testing, and Documenting - the Virtuous Cycle\nIntegration tests\nUnit tests and functional tests focus on testing your service code without calling other\nIntegration tests are functional tests without any mocking, and should be able to run on a\nRabbitMQ, they will be called by your service as normal when the integration tests are run.\nThe caveat is that running tests against an actual deployment makes it harder to set up tests\nservice, but if it's easy to do, you can also have a dedicated testing deployment, which will\nCoding, Testing, and Documenting - the Virtuous Cycle\nYou can use whatever tool you want to write your integration test.\nBut it's nicer if integration tests can be written in Python, and can be part of your project's\ntests collection.\nway to test it.\ntests that can either be run on a local Flask application or against an actual\nLoad tests\nWriting load tests can help you answer the following questions:\nCoding, Testing, and Documenting - the Virtuous Cycle\nFor performing a simple load test that does not require any particular scenario, Boom (h t t p\nIn the following example, Boom performs a 10-second load test against a Flask web server\nBut this small test alone can often catch problems early on, in particular when your code is\nCoding, Testing, and Documenting - the Virtuous Cycle\nc o m /t a r e k z i a d e /m o l o t o v ), which gives you the ability to write Python \nFor instance, the test itself will\nWhen performing a load test, it's better to add some metrics on the server side.\nlevel, you can use a small tool like flask-profiler (h t t p s ://g i t h u b .\nr e a d t h e d o c s .\nCoding, Testing, and Documenting - the Virtuous Cycle\nThe test needs to behave like a real client, and call the system through the\nCoding, Testing, and Documenting - the Virtuous Cycle\nside, you will need to use a tool like Selenium (h t t p ://d o c s .\nFunctional tests are the most important tests to write, and it's easy to do it in\nFlask by instantiating the app in the tests and interacting with it\nIntegration tests are like functional tests, but against a real deployment\nLoad tests are useful to learn about your microservice bottlenecks and plan for\nEnd-to-end tests require using the same UI that the client would normally use\nKnowing when you will need to write integration, load, or end-to-end tests depends on\nhow your project is managed--but both unit and functional tests should be written every\nUnit tests can be written using vanilla Python, thanks to the excellent unittest package\nincluded in the standard library--and we will see later how the pytest (h t t p ://d o c s .\nFor functional tests, we'll look in the next section at WebTest.\nCoding, Testing, and Documenting - the Virtuous Cycle\nr e a d t h e d o c s .\no r g ) project, which provides a Request and Response class similar (but\nTo use it with Flask, you can install the flask-webtest package (h t t p s ://f l a s k - w e b t e s t\n. r e a d t h e d o c s .\nfrom flask_basic import app as tested_app\ndef test_help(self):\napp = TestApp(tested_app)\nCoding, Testing, and Documenting - the Virtuous Cycle\ndef test_help(self):\nWhen this last test is executed with HTTP_SERVER=http://myservice/, it performs all its\nhaving to write two distinct tests.\ndeployed service works as expected directly from your test suite, just by flipping an option.\nAs your project grows, you will have more and more tests\nTo automatically discover and run all the tests in a project, the unittest package has\nintroduced a Test Discovery feature in Python 3.2, which finds and runs tests given a few\nThis feature has been around for a while in projects like Nose (h t t p s ://n o s e .\nCoding, Testing, and Documenting - the Virtuous Cycle\nWhich runner to use is a matter of taste, and as long as you stick to writing your tests in\n$ pytest test_*\ntest_app.py .\ntest_app_webtest.py .\ntest_bugzilla.py ...\ntest_error.py ..\nThe pytest package comes with a lot of extensions, which are listed at h t t p ://p l u g i n c o m p\nh e r o k u a p p .\n(h t t p s ://c o v e r a g e .\nr e a d t h e d o c s .\ni o ) to display the test coverage of your project, and the\nc o m /p y c q a /f l a k e 8) linter to make sure that\n$ pytest --cov=flask_basic --flake8 test_*\ntest_app.py F.\ntest_app_webtest.py F.\ntest_bugzilla.py F...\nCoding, Testing, and Documenting - the Virtuous Cycle\ntest_app.py:18:1: E305 expected 2 blank lines after class or function\ntest_app.py:21:1: W391 blank line at end of file\ntest_app_webtest.py:29:1: W391 blank line at end of file\ntest_bugzilla.py:26:80: E501 line too long (80 > 79 characters)\ntest_bugzilla.py:28:80: E501 line too long (82 > 79 characters)\ntest_bugzilla.py:40:1: W391 blank line at end of file\nAnother useful tool that can be used in conjunction with pytest is Tox (h t t p ://t o x .\nIf your projects need to run on several version of Python, or if you only want to make sure\ncreation of separate environments to run your tests.\nThe tox.ini file contains the command lines to run the tests along with the Python\ncommands =  pytest --cov=flask_basic --flake8 test_*\nCoding, Testing, and Documenting - the Virtuous Cycle\neach Python version, deploy your package and its dependencies in it, and run the tests in it\nthe tests quickly.\nFor instance, tox -e py35 will just run pytest under Python 3.5.\nHow to run the tests\ns p h i n x - d o c .\nCoding, Testing, and Documenting - the Virtuous Cycle\nThe content of the documentation must be written in reStructuredText (reST) (h t t p ://d o c u\ns p h i n x - d o c .\nMarkdown (h t t p s ://d a r i n g f i r e b a l l .\nn e t /p r o j e c t s /m a r k d o w n /) is\nCoding, Testing, and Documenting - the Virtuous Cycle\ns p h i n x - d o c .\nThis is how Python documents its standard library at h t t p s ://d o c s .\nCoding, Testing, and Documenting - the Virtuous Cycle\ncan be included in the test suite to make sure it works.\nThe following is a full example of a project documentation using Sphinx:\nCoding, Testing, and Documenting - the Virtuous Cycle\nCoding, Testing, and Documenting - the Virtuous Cycle\nrunning tests on various Python interpreters, verifying coverage and PEP 8 conformance,\nc o m ), GitLab (h t t p ://g i t l a b .\nCoding, Testing, and Documenting - the Virtuous Cycle\nMozilla uses GitHub for its Rust project (h t t p s ://g i t h u b .\no r g /), which runs for free for open source projects.\nCoding, Testing, and Documenting - the Virtuous Cycle\nTravis also has support for setting up specific services like databases (refer to h t t p s ://d o c s\nc o m /u s e r /d a t a b a s e - s e t u p /), which can get deployed for your projects via the\nThe Travis documentation (h t t p s ://d o c s .\nrepository is ReadTheDocs (RTD) (h t t p s ://d o c s .\nr e a d t h e d o c s .\nCoding, Testing, and Documenting - the Virtuous Cycle\nor Bitbucket is Coveralls (h t t p s ://c o v e r a l l s .\nThis service displays your test code \ni o directly from Travis-CI by instructing Tox to ping to h t t p ://c o v e r a l l s .\ni o after the tests are run.\nCoding, Testing, and Documenting - the Virtuous Cycle\nCoding, Testing, and Documenting - the Virtuous Cycle\nCoding, Testing, and Documenting - the Virtuous Cycle\nFunctional tests are the tests you will write more often, and WebTest\nTo run the tests, pytest combined with Tox will make your\nNow that we've covered how a Flask project can be continuously developed, tested, and",
      "keywords": [
        "Virtuous Cycle",
        "Python",
        "functional tests",
        "Documenting",
        "Virtuous",
        "project",
        "Cycle",
        "Integration tests",
        "Flask",
        "Tox",
        "code",
        "def test",
        "run",
        "app",
        "Unit tests"
      ],
      "concepts": [
        "tested",
        "coding",
        "code",
        "project",
        "python",
        "important",
        "imports",
        "documenting",
        "document",
        "useful"
      ],
      "similar_chapters": [
        {
          "book": "Python Microservices Development",
          "chapter": 1,
          "title": "",
          "score": 0.404,
          "base_score": 0.404,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Python Microservices Development",
          "chapter": 9,
          "title": "",
          "score": 0.304,
          "base_score": 0.304,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "tests",
          "cycle",
          "documenting",
          "virtuous",
          "documenting virtuous"
        ],
        "semantic": [],
        "merged": [
          "tests",
          "cycle",
          "documenting",
          "virtuous",
          "documenting virtuous"
        ]
      },
      "topic_id": null,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.2990327589203444,
        "topic_boost": 0.0,
        "timestamp": "2025-12-17T23:08:32.291638+00:00"
      }
    },
    {
      "chapter_number": 4,
      "title": "Designing Runnerly",
      "start_page": 109,
      "end_page": 134,
      "summary": "microservices-based app is to start with a monolithic version that implements all the\nPresentation of our Runnerly application and its user stories\nRunnerly offers a web view where users can see their runs, races, and training plans, all in\nThe view is responsive so the users can display the app on their phones or\nRunnerly also sends monthly reports about the user activity.\nA user who is registered into Runnerly needs to hook his/her account to Strava\napplication to call a service with an access token that is unique to the user.\nAfter it has been authorized by the user, Runnerly pulls runs out of Strava to feed its\nlast 10 runs and will let the users use Runnerly's extra features: races, training plans, and\nLet's dive into Runnerly's features through its user stories.\nUser stories\nThe best way to describe an application is through its user stories.\nUser stories are very\nsimple descriptions of all the interactions a user can have with an application and is the first\nAs a user, I can create an account on Runnerly with my email and activate it\nAs a user, I can connect to Runnerly and link my profile to my Strava account.\nAs a connected user, I can see my last 10 runs appear in the dashboard.\nAs a connected user, I can add a race I want to participate in.\nOther users can see\nAs a registered user, I receive a monthly report by email that describes how I am\nAs a connected user, I can select a training plan for a race I am planning to do,\nThe app needs a registration mechanism that will add the user to our database and\nThe app will authenticate users with a password.\nTo pull data out of Strava, a strava user token needs to be stored in the user profile\nBesides runs, the database needs to store races and training plans.\nIn a Flask application based on SQLAlchemy, the model is described through classes, which\nthe User table with the SQLAlchemy class:\nclass User(db.Model):\n__tablename__ = 'user'\nWhen used in a Flask app, Flask-SQLAlchemy will take care of wrapping all the calls to\nSQLAlchemy and exposing a session object to your Flask app views to manipulate your\nFlask app that uses the schema described earlier in a View that can be queried from /users:\napp = Flask(__name__)\n@app.route('/users')\ndef users():\nusers = db.session.query(User)\nreturn render_template(\"users.html\", users=users)\napp.run()\nuser info with a template that could look like this:\n<h1>User List</h1>\n{% for user in users: %}\nThe following module implements a form for the User table, using FlaskForm as its basis:\ncreate a form for the user table.\nuser submits the form:\n@app.route('/create_user', methods=['GET', 'POST'])\ndef create_user():\nnew_user = User()\nform.populate_obj(new_user)\ndb.session.add(new_user)\nreturn redirect('/users')\nreturn render_template('create_user.html', form=form)\nuser.\nThe create_user.html template iterates through the form field list and WTForm takes\nFor Runnerly, we'll need to reproduce this pattern to create forms for adding training plans\nmodel = User\nWe've created views and forms that are interacting with the database via the\nStrava runs and generates monthly reports\nAuthentication and authorization: This lets our users log in and restrict editing\nThe code that fetches new runs from Strava to add them in the Runnerly database can poll\ngenerate a report and send it to the user by email.\nBut unlike user requests, they are background tasks, and they need to run on their own\nweb apps is to use Celery (http://docs.celeryproject.org), a distributed task queue that\nFor instance, if the app wants Celery to run\nprovides an abstraction for a Python app to work on both sides of it: to send and run jobs.\nThe part that runs the job is called a worker, and Celery provides a Celery class to start\nTo use celery from a Flask application, you can create a background.py module that\nlibrary to grab runs from Strava for each user in Runnerly that has a Strava token:\nfrom monolith.database import db, User, Run\ndef activity2run(user, activity):\nrun.runner = user\nrun.strava_id = activity.id\nq = db.session.query(User)\nfor user in q:\nif user.strava_token is None:\nruns_fetched[user.id] = fetch_runs(user)\ndef fetch_runs(user):\nclient = Client(access_token=user.strava_token)\nq = db.session.query(Run).filter(Run.strava_id == activity.id)\nIn this example, the task looks for each user that has a Strava token, then imports their most\nFrom there, in your Flask app, you can import the same background.py module and call\napp = Flask(__name__)\nfrom monolith.background import fetch_all_runs\nIn a sense, since the Celery service is invoked by the Flask application by passing messages\ndeployment since both the Redis server and the Celery app can be deployed on another\nInstead of having the Flask app trigger the job every hour, we can use Celery's\nThe Flask app, in that case, would schedule the periodic task the same way it triggered the\napp.config['STRAVA_CLIENT_ID'] = 'runnerly-strava-id'\napp.config['STRAVA_CLIENT_SECRET'] = 'runnerly-strava-secret'\nIn this example, it's the app running locally.\nmethod can be used to present a link to a connected Runnerly user.\nOnce the user authorizes Runnerly on the Strava site, the /strava_auth view will get a\nbehalf of that user.\nThe view then simply copies the token into the user database entry:\naccess_token = xc(client_id=app.config['STRAVA_CLIENT_ID'],\ncurrent_user.strava_token = access_token\ndb.session.add(current_user)\nIn that view, @login_required and current_user are part of the authentication and\nOne last thing that we need to add is a way for users to authenticate.\nknow who's connected since the dashboard will display user-specific data.\n(https://en.wikipedia.org/wiki/Basic_access_authentication) scheme where the user\nwhen the user logs in, you need to hash the incoming password to compare it to the stored\ninto our User class.\nLet's extend our User class with methods to set and verify a password:\nclass User(db.Model):\n__tablename__ = 'user'\nWhen creating new users in the database, the set_password() method can be used to\nhash and store a password in the User model.\nand log out users, and to keep track of who's connected so you can change how your app\nFlask-Login provides two functions to set a user in the current Flask session: login_user()\nand logout_user().\nWhen the login_user() method is called, the user ID is stored in\nThe user will be remembered for the\nfrom flask_login import LoginManager, login_user, logout_user\nq = db.session.query(User).filter(User.email == email)\nuser = q.first()\nif user is not None and user.authenticate(password):\nlogin_user(user)\nlogout_user()\n@login_manager.user_loader\ndef load_user(user_id):\nif user is not None:\nuser._authenticated = True\nreturn user\nThe @login_manager.user_loader decorated function is used every time Flask-Login\nneeds to convert a stored user ID to an actual user instance.\nThe authentication part is done in the login view by calling user.authenticate(), and\nthen set in the session with login_user(user).\nthe user edition form should not be accessible if you are not logged in.\n@app.route('/create_user', methods=['GET', 'POST'])\ndef create_user():\nIn the code, @login_required will ensure that you are a valid user and that you've\nusers have is admin.\nAdmins have super powers across the app, while simple users can only\nIf we add an is_admin Boolean flag in the User model, we can create a similar decorator\ncurrent_user variable Flask-Login sets in the application context.\nuse this to allow a user to change their data, but prevent the user from changing other users'\nA typical deployment will group the Flask app with one Redis and one Celery instance on\nrequests and users it can handle.\nSince we're having thousands of users, these tasks take most of the server resources,\nFlask application code to operate.\nneeds to include the whole Flask app.\nin the app, we'll need to update the Celery workers as well to avoid regression.\nStrava, all the dependencies the Flask application has.\nFlask application in the first place?\" That design was excellent when we started to code\nInstead of using the Flask app code, the Celery worker code could be entirely independent\nmonolithic app--let's call it the Strava Service.\nreports can be split the same way to run, on its own, the Reports Service.\nSince the original Flask app, the Strava service and the Reports Service will all share the\nStrava service get some work from Redis and interact with the Data Service, as shown in\nThe Data Service is an HTTP API that wraps the database containing all the users and runs\nThe dashboard is the frontend that implements the HTML user interface.\nThe Data service view needs to implement the following APIs:\nFor the Strava service--a POST endpoint to add runs\nA GET endpoint to retrieve a list of user IDs\nA GET endpoint to get a list of runs given a user ID and a month\n/apis/users_ids endpoint and supports the GET method to retrieve the list of user IDs:\n/user_ids:\nFor implementing a Flask app that uses the first approach, a framework such as Connexion\nfunctions, and Connexion, will generate a Flask app.\n/api/users_ids will need to be located at api.users_ids.get().\ndef get_user_ids():\nThe rest of the Data Service API is implemented as described, and can be found in the\nadded a few HTTP API views for the new microservices to interact with the main\nSince the new API allows us to add runs, there's another part we can split out of the\nWhen a user wants\nto start a new training plan, the main app can interact with the Training microservice and\nmicroservice publishes an API that returns a list of runs with their specific structure, exactly\nRunnerly runs.\nRunnerly users: it gets asked to generate a plan given a few params.\nother applications?\", \"Will the Training feature need other data in the future to work?\"\nthe main Flask app.\nthat main application, turn the Data Service as a full microservice, and build a JavaScript\nThe Runnerly app is a typical web app that interacts with a database and a few backend",
      "keywords": [
        "user",
        "Runnerly",
        "Designing Runnerly",
        "Flask app",
        "Strava",
        "app",
        "Flask",
        "Celery",
        "Strava Service",
        "runs",
        "Data Service",
        "service",
        "Runnerly users",
        "Flask application",
        "Runnerly Data Service"
      ],
      "concepts": [
        "user",
        "runs",
        "running",
        "run",
        "designing",
        "forms",
        "apis",
        "api",
        "important",
        "imports"
      ],
      "similar_chapters": [
        {
          "book": "Python Microservices Development",
          "chapter": 7,
          "title": "",
          "score": 0.56,
          "base_score": 0.56,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Python Microservices Development",
          "chapter": 5,
          "title": "",
          "score": 0.349,
          "base_score": 0.349,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Python Microservices Development",
          "chapter": 1,
          "title": "",
          "score": 0.318,
          "base_score": 0.318,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Python Microservices Development",
          "chapter": 8,
          "title": "",
          "score": 0.308,
          "base_score": 0.308,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "user",
          "users",
          "runnerly",
          "app",
          "strava"
        ],
        "semantic": [],
        "merged": [
          "user",
          "users",
          "runnerly",
          "app",
          "strava"
        ]
      },
      "topic_id": null,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.323230993587273,
        "topic_boost": 0.0,
        "timestamp": "2025-12-17T23:08:32.291668+00:00"
      }
    },
    {
      "chapter_number": 5,
      "title": "Interacting with Other Services",
      "start_page": 135,
      "end_page": 164,
      "summary": "When a user looks at the main web view, the application needs to fetch the list of runs and\nThe network calls that are triggered by that request\nThere are also cases where a mix of synchronous and asynchronous calls are useful.\nIn any case, the bottom line is that we need to interact with other services through the\nHow a service can make asynchronous calls and communicate with other services\ncan be done via RESTful HTTP APIs using JSON payloads.\nIf your web service implements an HTTP API that accepts JSON, any developer using any\nSending and receiving JSON payloads is the simplest way for a microservice to interact\npass using HTTP requests.\nTo do this, you just need to use an HTTP client.\nhttp.client module, but the Requests library (h t t p s ://d o c s .\nHTTP requests in the requests library are built around the concept of session, and the best\nway to use it is to create a Session object that is reused every time you interact with any\ndefault headers you want to set for all requests your application will make.\nfrom requests import Session\ns.headers['Content-Type'] = 'application/json'\ns.get('http://localhost:5000/api').json()\ns.get('http://localhost:5000/api2').json()\nLet's see how we can generalize this pattern in a Flask app that needs to interact with other\nUsing Session in a Flask app\nfrom requests import Session\ndef setup_connector(app, name='default', **options):\nheaders['Content-Type'] = 'application/json'\napp.extensions['connectors'][name] = session\nIn this example, the setup_connector() function will create a Session object and store it\nThe created Session will set the Content-Type header to\napplication/json by default, so it's suitable for sending data to JSON-based\nIn the following example, a Flask app running on port 5001\nsub_result = conn.get('http://localhost:5000/api').json()\nwhen making a request, it will raise a ReadTimeout in case the remote server fails to\nconn.get('http://localhost:5000/api',timeout=2.0).json()\nSince it's good practice to always use the timeout option, a better way would be to set a\nTo do this, the requests library has a way to set up custom transport adapters, where you\nfrom requests.adapters import HTTPAdapter\ndef send(self, request, **kw):\nreturn super().send(request, **kw)\ndef setup_connector(app, name='default', **options):\nheaders['Content-Type'] = 'application/json'\nsession.mount('http://', adapter)\napp.extensions['connectors'][name] = session\nThe session.mount(host, adapter) call will tell requests to use the\nHTTPTimeoutAdapter every time a request for any HTTP service is made.\nsession.mount('http://myspecial.service', adapter2)\nThanks to this pattern, a single request Session object can be instantiated into your\napplication to interact with many other HTTP services.\nRequests use urllib3 under the hood, which will create one pool of connectors per host\nIn other words, if your service calls several other services, you don't need to worry about\nrecycling connections made to those services; requests should handle it for you.\ndefault behavior, then the requests library's connection pooling doesn't help you much.\nconnections are made to other services.\neach thread gets its version of flask.g (the global), flask.request or flask.response,\nIf you don't share any states outside flask.g and just calling the Request session, it\neach process will execute a Request session that has a single connection to the external\nservice, and that will serialize the calls.\nOne way to speed up your application for calls to other services, is to make sure it uses\nand HEADs. The simplest way to implement it is to return along with a result an ETag header in the\nWhen making a new request, the client can look up the dictionary and pass along a stored\nThere's a project called CacheControl (h t t p ://c a c h e c o n t r o l .\nbe used with the Request session, which implements this behavior for you fairly\nOf course, this means the services that you are calling should implement this caching\nIn the following example, the Flask app uses the current server time to create ETag\nheader to compare it to the user's modified field, and returns a 304 response if it matches:\nfrom flask import Flask, jsonify, request, Response, abort\n@app.route('/api/user/<user_id>', methods=['POST'])\nuser = request.json\n@app.route('/api/user/<user_id>')\nif user['modified'] in request.if_none_match:\nThe change_user() view sets a new modified value when the client POST a user.\nfollowing client session, we're changing the user and making sure we get a 304 response\n$ curl -H \"Content-Type: application/json\" -X POST -d\n'{\"name\":\"Tarek\",\"age\":40}' http://127.0.0.1:5000/api/user/1\nhttp://127.0.0.1:5000/api/user/1\nThere's also the problem of race conditions if two requests change the same entry within the\nBut sending HTTP requests and responses with JSON payloads can add some bandwidth\nSerializing and deserializing data from Python objects to JSON\nproduced by the Flask app on port 5000, with an application/json content type:\ngzip_types application/json;\nFrom the client-side, making an HTTP request to the nginx server at localhost:8080\n$ curl http://localhost:8080/api -H \"Accept-Encoding: gzip\"\nIn Python, request responses will automatically decompress responses that are gzip\n>>> import requests\n>>> requests.get('http://localhost:8080/api', headers={'Accept-Encoding':\nTo compress the data you're sending to the server, you can use the gzip module and\n>>> import gzip, json, requests\n>>> requests.post('http://localhost:8080/api',\nTo summarize, setting up GZIP compression for all your service responses is a no-brainer\nHandling GZIP compression in HTTP requests is a little trickier because if you don't\nuse Apache, you need to implement decompression of incoming data in Python code or\nIf you want to further reduce the size on HTTP request/response payloads, another option\nif your JSON contains a lot of strings--which is often the case in microservices--GZIP will do\n>>> len(json.dumps(python_data))\n>>> len(gzip.compress(bytes(json.dumps(data), 'utf8')))\nserializable in JSON and MessagePack, so you need to make sure you convert them.\nIn any case, in a world of microservices where JSON is the most accepted standard, sticking\nRequests can be used as the HTTP client to call other services.\ncalling other services, since Flask is a synchronous framework, but it's dangerous.\nImplementing HTTP cache headers is a great way to speed up repeated requests\nGZIP compression is an efficient way to lessen the size of requests and responses\ngoes beyond the request-response pattern.\nAsynchronous calls can be as simple as a separate thread or process within a microservice\napp, that's getting some work to be done and perform it without interfering with the HTTP\ngets some work from a message broker like Redis or RabbitMQ.\nworker blocks until a new message is added to the Redis queue.\nBut there are other ways to exchange messages between services that are not necessarily a\nThe pattern used by Celery workers is a push-pull tasks queue.\nmessages into a specific queue, and some workers pick them up from the other end and \nworkers go offline, we don't loose the messages that are in the queue.\nworkers blindly picking every message that is added to one or several queues, they subscribe\nmessages they pick from the queue so that they match the topic.\nCelery is an excellent tool for building tasks queues, however, for more complex messaging,\nTo implement complex messaging pattern, the good news is that we can use a Rabbit MQ\nmessage broker who still works with Celery and interacts with another library.\nA binding defines how messages are routed from exchanges to queues\nFor our topic queue, we need to set one exchange, so RabbitMQ accepts new messages, and\nall the queues we want for workers to pick messages.\nmessages to the different queues depending on the topics, using a binding.\nLet's say we have two workers, one that wants to receive messages about races and another\nIn this setup, every message is sent to RabbitMQ, wherein, if the topic starts with race., it\nTo interact with RabbitMQ in the code, we can use Pika (h t t p s ://p i k a .\nPython RPC client that implements all the RPC endpoints a Rabbit service publishes.\nsend and receive messages, and check what's in a queue.\n# sending a message about race 34\nmessage('race.34', 'We have some results!')\nmessage('training.12', \"It's time to do your long run\")\nThese RPC calls will end up adding one message respectively in the race and training\ndef on_message(channel, method_frame, header_frame, body):\nchannel.basic_consume(on_message, queue='race')\nNotice that Pika is sends back an ACK to RabbitMQ about the message, so it can be safely\nYour Flask application can create a synchronous connection to RabbitMQ using\npika.BlockingConnection and send messages through it.\nc o m /b n i n j a /p i k a - p o o l ) implement simple connection pools so you can\napplication, and trigger a function when a message is received.\nasynchronous framework, but for a Flask application, you will need to execute the code that\nwould be blocked every time a request is received in Flask.\nstandalone Python application that consumes messages on behalf of your Flask\nmicroservice and performs synchronous HTTP calls.\nimport requests\ndef on_message(channel, method_frame, header_frame, body):\nres = requests.post(FLASK_ENDPOINT, json=message,\nchannel.basic_consume(on_message, queue='race')\nThis script will perform HTTP calls on Flask with the messages delivered in the queue.\nmessages to HTTP endpoints, but isolating this bridge into our little script\nfrom flask import Flask, jsonify, request\nmessage = request.json['message']\nThe previous pattern has workers that handle specific topics of messages, and the messages\nmessage.\nWith a pubsub in place, you can broadcast messages to all your microservices if you need\nAMQP also implements a synchronous request/response pattern, which means that we\ncould use RabbitMQ instead of the usual HTTP JSON calls to have our microservice directly\nAsynchronous calls should be used every time a microservice can execute some\nmicroservices interact with each other via messages.\nchallenge when writing functional tests for a service that calls other services is to isolate all\nIn this section, we'll see how we can mock synchronous calls made with Requests, and\nasynchronous calls for Celery workers and other asynchronous processes.\nIf you are using Requests to perform all the calls--or you are using a library that is based on\nThe requests-mock project (h t t p s ://r e q u e s t s - m o c k .\nadapter that will let you mock network calls in your tests.\nEarlier in this chapter, we saw an example of a Flask app that was an HTTP endpoint to\nThat application used a Request session that was created by a setup_connector()\nIn the following test, we're mounting the requests_mock adapter into that session by\ncalling session.mount() with a fresh requests_mock.Adapter() instance:\nfrom flask_application import app, get_connector\nimport requests_mock\n# mocking the request calls\nsession = get_connector(app)\nself.adapter = requests_mock.Adapter()\nsession.mount('http://', self.adapter)\nmocked_value = json.dumps({'some': 'data'})\nself.assertEqual(res.json['result']['some'], 'data')\nIn the test_api() test, it will let us try out the application view and make sure it uses the\nprovided JSON data when it calls the external service.\nThat said, mocking responses from other services is still a fair amount of work and quite\ndoing integration tests as well, where the service is tested in a deployment where it calls\nIf your application sends or receives calls asynchronously, setting up some testing is a little\nAsynchronous calls mean that the application is sending something somewhere and don't\nIf you are building tests for Celery workers, the simplest way to run your tests is to use a\nUsing a real broker means that you can run your Celery worker in your test, just to validate\nconfigure pytest to use it, you need to implement the celery_config and\nFrom there, your tests can use the echo task, and have the worker get called for real:\nfrom celery.execute import send_task\nThe reason is that when a microservice wants to run a task from a worker that is its\nmicroservice, we don't want to have to import that worker code just to get the task function.\nIn the following example, the echo task is running in a standalone microservice and we can\ntrigger it via a send_task() call just by knowing the task name--no need to import the\n>>> f = app.send_task('echo', ['meh'])\nBack to your testing, if your tests are mocking some Celery workers, make sure the remote\nthe application you are testing uses send_task() throughout its code.\nThat way, your Celery fixtures will magically mock the workers for your app.\nLastly, the application will probably not wait for the Celery worker to return the result\nsynchronously--so you will need to inspect what the test worker has done after the API call.\nIf you do some messaging with Pika and RabbitMQ, the Pika library directly uses the socket\nLike for Celery, you could just run a local RabbitMQ server for your tests--Travis-CI also\nSending messages, in that case, is done as usual, and you can create a script that picks them\nWhen you need to test a process where an event is received from RabbitMQ, if that happens\nWhat's important is to make sure you can run your tests without depending on other\nBut dependencies on messaging servers such as Redis or RabbitMQ are not a\nsynchronously, by using a Requests session, and asynchronously, by using Celery workers\nWe've also looked at ways to test a service in isolation by mocking other services, but\nwithout mocking the message brokers themselves.",
      "keywords": [
        "Services",
        "JSON",
        "Flask",
        "Celery",
        "session",
        "message",
        "requests",
        "request Session",
        "calls",
        "data",
        "HTTP requests",
        "HTTP JSON calls",
        "request",
        "requests import Session",
        "user"
      ],
      "concepts": [
        "messaging",
        "message",
        "services",
        "request",
        "requests",
        "important",
        "interacting",
        "interactions",
        "interaction",
        "data"
      ],
      "similar_chapters": [
        {
          "book": "Python Microservices Development",
          "chapter": 8,
          "title": "",
          "score": 0.546,
          "base_score": 0.546,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Python Microservices Development",
          "chapter": 1,
          "title": "",
          "score": 0.543,
          "base_score": 0.543,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Python Microservices Development",
          "chapter": 7,
          "title": "",
          "score": 0.496,
          "base_score": 0.496,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Python Microservices Development",
          "chapter": 11,
          "title": "",
          "score": 0.465,
          "base_score": 0.315,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Python Microservices Development",
          "chapter": 2,
          "title": "",
          "score": 0.458,
          "base_score": 0.458,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "message",
          "json",
          "requests",
          "http",
          "session"
        ],
        "semantic": [],
        "merged": [
          "message",
          "json",
          "requests",
          "http",
          "session"
        ]
      },
      "topic_id": 1,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.44286531647906097,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:08:32.291691+00:00"
      }
    },
    {
      "chapter_number": 6,
      "title": "Monitoring Your Services",
      "start_page": 165,
      "end_page": 182,
      "summary": "Python applications can emit logs to help you debug issues, but jumping from one server to\nThankfully, we can centralize all the logs to monitor a distributed deployment.\nCentralizing logs\nCentralizing logs\nwill send an email every time an exception is happening in the decorated function.\nthat the handler is doing a telnet session with the SMTP server to send the email, so if\nimport logging\nfrom logging.handlers import SMTPHandler\nlogger = logging.getLogger('theapp')\nlogger.setLevel(logging.INFO)\ndef email_errors(func):\ndef _email_errors(*args, **kw):\nPython has a lot of handlers built-in the logging package; refer to h t t p s\nSending emails on errors is an improvement, but with high-traffic microservices, it's\nThere are several existing systems to centralize logs generated by Python applications.\nof them can receive logs in HTTP or UDP payloads, with a preference for the latter because\ncentralizing error logs and provides a nice UI to deal with tracebacks.\nBut Sentry is focused on errors and is not well suited for general logging.\nlogs other than errors, you need to use something else.\nAnother open-source solution is Graylog (h t t p ://g r a y l o g .\no r g ), which is a general logging\nc o /) where the logs are stored.\nGraylog can receive any logs via its custom logging format or alternative formats, such as\nSetting up Graylog\nA Graylog server is a Java application that uses MongoDB as its database, and stores all the\nlogs it receives into Elasticsearch.\nA typical production setup will use a dedicated Elastic Search cluster and several Graylog\ndocumentation (h t t p ://d o c s .\no r g /e n /l a t e s t /p a g e s /a r c h i t e c t u r e .\nAn excellent way to try out Graylog is to use its Docker (h t t p s ://d o c s .\nas described here in h t t p ://d o c s .\no r g /e n /l a t e s t /p a g e s /i n s t a l l a t i o n /d o c k e r\nbit is not the end of the world, then running your Graylog stack can be a good solution.\nour microservices can interact with Graylog.\nTo run a Graylog service locally, you need to have Docker installed (see Chapter 10,\ngraylog:\nimage: graylog2/server:2.1.1-1\nThe next step is to go to System | Inputs to add a new UDP input so Graylog can receive\nour microservices logs.\nSending logs to Graylog\nTo send logs to Graylog from Python, you can use Graypy (h t t p s ://g i t h u b .\nc o m /s e v e r b /g\nr a y p y ), which converts Python logs to the Graylog Extended Log Format (GELF) (h t t p ://d\no r g /e n /l a t e s t /p a g e s /g e l f .\nGraypy will send the logs via UDP by default, but can also send them via AMQP if you\nneed to be 100% sure that every log makes it to Graylog.\nIn most cases, UDP is good enough for centralizing logs.\nIf your logging\nlogger = logging.getLogger('theapp')\nlogger.setLevel(logging.INFO)\nThe graypy.GELFHandler class will convert the log into a UDP payload and send it to a\nIt's unlikely that the code that sends the UDP payload will raise an error, and the overhead\nYou can also automatically log exceptions in an error handler registered every\nimport logging\napp.logger.exception(str(error), extra=result)\napp.logger.info(\"Logged into Graylog\")\n# this will also be logged\nWhen calling /api, this application will send a simple log to Graylog, then the exception\nGraypy adds some metadata fields to each log such as the following:\nGraylog itself will add the hostname from which each log is received, as the source field,\nefficiently in our logs.\nuse a logging.Filter class to add it in each logging record sent to Graylog:\nimport logging\nIf the logs have too many details, it might become hard to search\nTo conclude this part about log centralization, we've looked at how microservices can send\nall its logs to a centralized service with minimal overhead via UDP.\nOnce the logs are\nKeeping all the logs is extremely useful to investigate microservices issues, but this should\narchiving older logs  h t t p s ://w w w .\no r g /e n t e r p r i s e /f e a t u r e\nIt's important to be able to track memory usage over time to find out about these issues\nIn Python, the psutil (h t t p s ://p y t h o n h o s t e d .\no r g /p s u t i l ) project is a cross-platform \nIn the following example, an asyncio loop sends the CPU usage in percent every second to\nGraylog:\nimport logging\nlogger = logging.getLogger('sysmetrics')\nlogger.setLevel(logging.INFO)\nThe system-metrics (h t t p s ://g i t h u b .\napp, as described in h t t p ://d o c s .\no r g /e n /l a t e s t /p a g e s /d a s h b o a r d s .\nLike we did for sending logs, we can also add custom performance metrics inside our\nFor some microservices, it can also be useful to get performance metrics inside the code.\nimport logging\ndef set_view_metrics(view_func):\ndef _set_view_metrics(*args, **kw):\ndef set_app_metrics(app):\napp.view_functions[endpoint] = set_view_metrics(func)\napp.logger.setLevel(logging.INFO)\nGraylog has a\nmarketplace (h t t p s ://m a r k e t p l a c e .\nc o m /G r a y l o g 2/g r a y l o g - c o n t e n\nt p a c k - n g i n x ) that will parse nginx's access and error logs to push them in Graylog.\nlogs through UDP using syslog (h t t p ://n g i n x .\no r g /e n /d o c s /s y s l o g .\nCombined with app-specific metrics and system metrics, all these logs will let you build live\nWe've also learned how to set up Graylog to centralize and use all the\ngenerated logs and performance metrics.\nGraylog uses Elasticsearch to store all the data, and that choice offers fantastic search\nBut deploying Graylog should be\nnot meant to store raw logs and exceptions.\nSo if you just care about performance metrics and exceptions, maybe a good solution would\nIn any case, as long as your applications and web servers generate logs and",
      "keywords": [
        "Graylog",
        "logs",
        "Services",
        "Monitoring Your Services",
        "UDP",
        "metrics",
        "Monitoring",
        "Flask",
        "log",
        "handler",
        "Graylog service",
        "server",
        "system",
        "Python",
        "CPU"
      ],
      "concepts": [
        "logs",
        "logging",
        "log",
        "services",
        "important",
        "time",
        "timed",
        "memory",
        "handler",
        "microservices"
      ],
      "similar_chapters": [
        {
          "book": "Python Microservices Development",
          "chapter": 2,
          "title": "",
          "score": 0.433,
          "base_score": 0.433,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Python Microservices Development",
          "chapter": 1,
          "title": "",
          "score": 0.396,
          "base_score": 0.396,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Python Microservices Development",
          "chapter": 9,
          "title": "",
          "score": 0.378,
          "base_score": 0.378,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Python Microservices Development",
          "chapter": 5,
          "title": "",
          "score": 0.376,
          "base_score": 0.376,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Python Microservices Development",
          "chapter": 12,
          "title": "",
          "score": 0.368,
          "base_score": 0.368,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "graylog",
          "logs",
          "logging",
          "udp",
          "logger"
        ],
        "semantic": [],
        "merged": [
          "graylog",
          "logs",
          "logging",
          "udp",
          "logger"
        ]
      },
      "topic_id": null,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.3599084922897342,
        "topic_boost": 0.0,
        "timestamp": "2025-12-17T23:08:32.291704+00:00"
      }
    },
    {
      "chapter_number": 7,
      "title": "Securing Your Services",
      "start_page": 183,
      "end_page": 217,
      "summary": "Securing Your Services\nservice (authentication) and we need to make sure that the caller is allowed to perform the\nIn a microservice-based architecture, we can't use that scheme everywhere because services\nare not users and won't use web forms to authenticate.\nusers and services.\nimplement an authentication microservice.\nSecuring Your Services\nHow token-based authentication works in practice\nSome best practices to secure your microservice code\nwith users and other web applications, and yet it's hard to understand because it's based on\nand can grant some access in the form of codes or tokens; let's call them keys.\ncan be used by users or services to access a resource, as long as the service providing that\nThe service interacts with the Strava API on behalf of the users after it was granted access\nvia Strava's authentication service.\nuser, the authentication service, and a third-party application.\nSecuring Your Services\nWhen the user calls app (1), they get redirected to\nthe Strava service to grant access to the Strava API by app (2).\ngets an authorization code through an HTTP callback and can use the Strava API on behalf\nFor a service-to-service authentication that doesn't necessarily involve a particular user,\nthere's another grant type called Client Credentials Grant (CCG), where service A can\nauthenticate to the authentication microservice and ask for a token that it can use to call\nIt works like the authorization code, but the service is not redirected to a web page like a\nInstead, it's implicitly authorized with a secret key that can be traded for a token.\nimplements part of the OAuth2 protocol to authenticate services and keep track of how they\nus to secure our microservices interactions independently from the users.\nSecuring Your Services\nneeded for a microservice-based application (h t t p s ://a u t h 0.\nBefore we go ahead and implement our authentication microservice, let's look at how\ntoken-based authentication works from the ground.\nToken-based authentication\nAs we said earlier, when a service wants to get access to another service without any user\nlike a user would do, and ask for a token that it can then use to authenticate against other\nservices.\nWhether you are a user or a microservice, if you own a token that the resource recognizes,\nTokens can hold any information that is useful for the authentication and authorization\nA timestamp indicating when the token was issued\nA token is usually built as a self-contained proof that you can use a service.\nmeans that the service will be able to validate the token without having to call an external\nDepending on the implementation, a token can also be used to access different\nSecuring Your Services\nOAuth2 uses the JWT standard for its tokens.\nThe JSON Web Token (JWT) described in RFC 7519 (h t t p s ://t o o l s .\no r g /h t m l /r f c\nHeader: This provides info on the token, such as which hashing algorithm is used\nSignature: This is a signed hash of the token to check that it's legitimate\nJWT tokens are base64 encoded so they can be used in query strings.\nHere's a JWT token in its encoded form:\nSecuring Your Services\nEvery part of the JWT token is a JSON mapping except the signature.\nThe typ key says it's a JWT token, and the alg key\ntoken is invalid\naud: This is the Audience, which is the recipient for whom the token was issued\niat: This stands for Issued At, which is a timestamp for when the token was\ntimestamps that make the token valid 24h after it was issued.\nOnce valid, that token can be\nSecuring Your Services\nDepending on the nature of the microservice, the token Time-To-Live (TTL) can be very\nregenerate tokens all the time.\nThe last part of a JWT token is the signature.\nLet's see how we can deal with JWT tokens in Python.\nneed to generate and read back JWT tokens.\nand the decode() functions to create tokens.\nIn the following example, we're creating a JWT token using HMAC-SHA256 and reading it\nThe signature is verified when the token is read, by providing the secret:\n>>> def create_token(alg='HS256', secret='secret', **data):\nreturn jwt.encode(data, secret, algorithm=alg)\n>>> def read_token(token, secret='secret', algs=['HS256']):\nreturn jwt.decode(token, secret)\n>>> token = create_token(some='data', inthe='token')\n>>> print(token)\n{'inthe': 'token', 'some': 'data'}\nSecuring Your Services\nThe create_token() function calls jwt.decode() with the algorithms\nargument to make sure the token is verified with the right algorithm.\nis good practice to prevent attacks where a malicious token can trick the\nc o m /b l o g /c r i t i c a l - v u l n e r a b i l i t i e s - i n - j s o n - w e b - t o\nWhen executing this code, the token is displayed in its compressed and uncompressed\nsingle service is compromised and the secret is stolen, your whole authentication system is\nThe private key is used by the token issuer to sign the tokens, and the public key can be\ntheir web server and use it to encrypt and decrypt data on-the-fly.\nSecuring Your Services\none of the CAs trusted by the browser, like Let's Encrypt (h t t p s ://l e t s e n c r y p t .\nusing extend you can also use it to secure your microservices as long as\ntokens.\nSecuring Your Services\ndef create_token(**data):\nSecuring Your Services\ndef read_token(token):\nreturn jwt.decode(token, PUBKEY)\ntoken = create_token(some='data', inthe='token')\nprint(token)\n{'some': 'data', 'inthe': 'token'}\nNotice that adding over 700 bytes of data to each request can add up over time, so the\nsecret-based JWT token technique is an option to keep in mind if you need to reduce the \nNow that we've learned how to deal with JWT tokens, let start to implement our\nFor that flow, the app receives requests from services that\nwant a token and generates them on-demand.\nThe generated tokens will have a lifespan of\nThis service will be the only service to possess the private key that is used to sign the tokens\nand will expose the public key for other services that want to verify tokens.\nThis service will\nSecuring Your Services\nWe will greatly simplify the implementation by stating that once a service gets a token, it\nWhen a service is accessed with a token, it\ncan verify that token locally or call the TokenDealer to perform the verification.\nthat it will add some CPU overhead when working with JWT tokens, which can be\nintensive work, adding the work required for checking the token might require to use a\nWeb Key (JWK) format as described in RFC 7517 (h t t p s ://t o o l s .\nl /r f c 7517), when other microservices want to verify tokens on their own.\nPOST /oauth/token: This returns a token, given some credentials.\nPOST /verify_token: This returns the token payload, given a token.\ntoken is not valid, it returns a 400.\nUsing the microservice skeleton at h t t p s ://g i t h u b .\nLet's look at the most important one, POST /oauth/token.\nThe POST/oauth/token implementation\nFor the CCG flow, the service that wants a token sends a POST request with an URL-\nclient_secret: This is a secret key that authenticates the requester.\nSecuring Your Services\nThe authentication part will just ensure that the secret is valid, then the service will create a\ntoken and return it:\ndef is_authorized_app(client_id, client_secret):\n@home.route('/oauth/token', methods=['POST'])\ndef create_token():\nif not is_authorized_app(client_id, client_secret):\ntoken = {'iss': 'https://tokendealer.example.com',\nSecuring Your Services\ntoken = jwt.encode(token, key, algorithm='RS512')\nreturn {'access_token': token.decode('utf8')}\nThe create_token() view uses the private key found in the application configuration\nThis blueprint is all we need with a pair of keys to run a microservice that will take care of\ngenerating self-contained JWT tokens for all our microservices that require authentication.\nThe whole source code of the TokenDealer microservice can be found at h t\nThe microservice could offer more features around token generation.\nability to manage scopes and make sure microservice A is not allowed to generate a token\nthat can be used in microservice B or managing a whitelist of services that are authorized to\nask for some tokens.\nSecuring Your Services\nBut the pattern we've implemented is the basis for an efficient token-based authentication\nIn the following diagram, training plans, data service, and races can use JWT tokens to\nJWT access in this diagram means that the service requires a JWT token.\nThose services may\nvalidate the token by calling the TokenDealer.\ntokens from the TokenDealer on behalf of its users (link not shown in the diagram).\nSecuring Your Services\nIn Runnerly, the Data Service | Strava worker link (3) is a good example of a place where\nAdding runs via the Data Service needs to be restricted to\nThe Strava worker uses client_id and client_secret to ask a token to the\nThe Strava worker adds the token in each request against to the Data Service (3).\nThe Data Service verifies the token by calling the TokenDealer, or by performing\nSecuring Your Services\nFrom there, the service can get a new token every time it needs it (because it's the first time\nor because the token is outdated) and add that token in the Authorization header when\ncalling Data Service.\nexample a TokenDealer running on localhost:5000 and a Data Service running on\ndef get_token():\nurl = server + '/oauth/token'\nreturn resp.json()['access_token']\nNotice that the /oauth/token is accepting form encoded data rather than\nAuthorization header, when the code calls the Data Service:\n_TOKEN = None\nglobal _TOKEN\nif _TOKEN is None or new:\n_TOKEN = get_token()\nreturn 'Bearer ' + _TOKEN\nSecuring Your Services\ndef _call_service(endpoint, token):\nheaders={'Authorization': token})\ndef call_data_service(endpoint):\ntoken = get_auth_header()\nresp = _call_service(endpoint, token)\ntoken = get_auth_header(new=True)\nresp = _call_service(endpoint, token)\nThe call_data_service() function will try to get a new token if the call to the Data\nThis refresh-token-on-401 pattern can be used in all your microservices to automate token\nservices, that is, adding a web application firewall.\nThe Open Web Application Security Project (OWASP) (h t t p s ://w w w .\neven provide a set of rules for the ModSecurity (h t t p s ://m o d s e c u r i t y .\nSecuring Your Services\nIn microservices-based applications, anything that's published to the web can be attacked,\nserver uses some of the request content (typically the arguments) to build SQL\nand easy to find a PHP app that uses invalidated user input when the server is called.\nIt can send legitimate requests and just hammer your service with it, leading\nSecuring Your Services\nmaking too many requests on our service.\nOpenResty (h t t p ://o p e n r e s t y .\no r g /e n /) is an nginx distribution that embeds a Lua (h t t p\no r g /) interpreter that can be used to script the web server.\nSecuring Your Services\nWhen you invoke some Lua code from your nginx configuration, the LuaJIT (h t t p ://l u a j i\no r g /p e r f o r m a n c e .\nIn the following example, the nginx configuration will proxy calls to a Flask application\nSecuring Your Services\nforeground (daemon off) on port 8888 to proxy pass all requests to the Flask app running\nc o m /R u n n e r l y /w a f .\naccess_by_lua_block: This is called on every incoming request before a\nLet's see in the next section how we can rate-limit incoming requests.\nSecuring Your Services\nby the web server to the same remote user and starting to reject new ones when it reaches a\nc o m /o p e n r e s t y /l u a - r e s t y - l i m i t - t r a f f i c ); you can use it in\nSecuring Your Services\nThe access_by_lua_block section can be considered as a Lua function and can use some\nfunction and every time a request reaches the server, it calls the incoming() function with\nnginx that rejects requests instead of letting your Flask microservice pile up error logs and\nSecuring Your Services\nIf you want a WAF with more features, the lua-resty-waf (h t t p s ://g i t h u b .\nk 5/l u a - r e s t y - w a f ) project works like lua-resty-limit-traffic, but offers a lot of \nIf you look at the components page at h t t p ://o p e n r e s t y .\no r g /e n /c o m p o n e n t s .\nother use cases where you can transfer some code that's in the Flask app to a few lines of\nc o m /o p e n r e s t y /s r c a c h e - n g i n x - m\nTo conclude this section about web application firewalls, OpenResty is a powerful nginx\nmicroservices, it opens a whole new world of possibilities, thanks to Lua. The next section that ends this chapter will focus on what can be done at the code level to\nSecuring Your Services\nJSON data from the incoming request and uses it to push data to a database, you should\nMicroservices usually use JSON, but if you happen to use templates, that's yet another place\nUber's website (h t t p s ://h a c k e r o n e .\nSecuring Your Services\nIn the following example, the user_id variable security hole is exploited to read the value\nSecuring Your Services\nSecuring Your Services\nSecuring Your Services\nThat scope limitation can be done with the JWT tokens by defining roles (such as\nread/write) and adding that information in the token under a permissions or scope key, for\nwith a token that is supposed only to read data.\nSecuring Your Services\nA web service process should be run by a non-root user\nBe very cautious when executing processes from your web service and avoid it if\nlinter called Bandit to try to catch insecure code (h t t p s ://w i k i .\nr i t y /P r o j e c t s /B a n d i t ).\nSecuring Your Services\nSecuring Your Services\nSecuring Your Services\nmicroservices-based application environment using OAuth2 and JWT tokens.\nTokens give\nWhen used with public/private keys, it also prevents an attacker that breaks into one service\nto break the whole app, as long as it's not the token issuer that's compromised.\nSecuring Your Services",
      "keywords": [
        "token",
        "service",
        "JWT tokens",
        "Securing Your Services",
        "data service",
        "data",
        "JWT",
        "user",
        "Lua",
        "microservice",
        "key",
        "web",
        "application",
        "Securing",
        "client"
      ],
      "concepts": [
        "token",
        "securing",
        "secure",
        "services",
        "requests",
        "returns",
        "data",
        "keys",
        "key",
        "code"
      ],
      "similar_chapters": [
        {
          "book": "Python Microservices Development",
          "chapter": 4,
          "title": "",
          "score": 0.56,
          "base_score": 0.56,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Python Microservices Development",
          "chapter": 5,
          "title": "",
          "score": 0.496,
          "base_score": 0.496,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Python Microservices Development",
          "chapter": 1,
          "title": "",
          "score": 0.428,
          "base_score": 0.428,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Python Microservices Development",
          "chapter": 8,
          "title": "",
          "score": 0.365,
          "base_score": 0.365,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "token",
          "securing",
          "securing services",
          "services",
          "tokens"
        ],
        "semantic": [],
        "merged": [
          "token",
          "securing",
          "securing services",
          "services",
          "tokens"
        ]
      },
      "topic_id": null,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.3527883699010776,
        "topic_boost": 0.0,
        "timestamp": "2025-12-17T23:08:32.291734+00:00"
      }
    },
    {
      "chapter_number": 8,
      "title": "Bringing It All Together",
      "start_page": 218,
      "end_page": 238,
      "summary": "Modern web applications rely a lot on client-side JavaScript (JS).\nTools like Facebook's ReactJS (h t t p s ://f a c e b o o k .\nFeatures like Service Workers (h t t p s ://d e v e l o p e r .\nweb development, because they allow developers to run JS code in the background,\nchange how your microservices publish data to make them specific to a JS framework.\nFor Runnerly, we shall use ReactJS to build our little dashboard, and we will wrap it in a\nHow to embed ReactJS in a Flask app\nin Flask, and how to make it interact with microservices whether you choose to use ReactJS\nBuilding a ReactJS dashboard\nImplementing classes for React can be done in JavaScript or JSX.\nThe JSX syntax extension (h t t p s ://f a c e b o o k .\nthe ReactJS community as the best way to write React apps.\n<script src=\"/static/react/react.min.js\"></script>\n<script src=\"/static/react-dom.min.js\"></script>\n<script src=\"/static/babel/browser.min.js\"></script>\ncreating JS classes--with or without JSX--which is used to render web pages.\nFor example, if you want to display a list of runs, you can create a Run class that is in charge\nof rendering a single run given its values, and a Runs class that iterates through a list of\nruns, and call the Run class to render each item.\nIn the following example, in a new JavaScript file we define a Run class with a render()\nfunction, which returns a <div> tag, and a Runs class:\nvar Run = React.createClass( {\nvar Runs = React.createClass( {\nvar runNodes = this.props.data.map(function (run)  {\n<Run\nThe Run class returns in a div this value: {this.props.title} ({this.props.type}),\nwhich is rendered by visiting the props attribute in the Run instance.\nthe render() method of the Runs class.\nWe want to instantiate a Runs class, and put a list of\nruns to be rendered by React in its props.data list.\nIn our Runnerly app, this list can be provided by the microservice that publishes runs, and\nThe code calls the server to get the data by making a GET request on the URL set in the\nWhen the state changes, it triggers the React class to update the DOM with the new data.\nThe framework calls the render() method, which displays the <div> containing Runs.\n<script src=\"/static/react/react.js\"></script>\n<script src=\"/static/react/react-dom.js\"></script>\n<script src=\"/static/babel/browser.min.js\"></script>\n<script src=\"/static/runs.jsx\" type=\"text/babel\"></script>\n<window.RunsBox url=\"/api/runs.json\" />,\nThe RunsBox class is instantiated with the /api/runs.json URL for this demo, and once\nthe page is displayed, React calls that URL, and expects to get back a list of runs, which it\ndoes not expose the global variables from the runs.jsx file.\nPeople building React apps usually code their server-side parts in Node.js (h t t p s ://n o d e j s\nHowever, serving React apps with Flask is not a problem at all.\nrendered using Jinja2, and the transpiled JSX files serve as static files like you would do for\ndistribution as JS files, and just add them into our Flask static directory alongside other files.\nOur Flask app, let's name it dashboard, will start off with a simple structure like this:\nruns.jsx\nAlso, the app.py file, a basic Flask application that serves the unique HTML file, will be\napp = Flask(__name__)\napp.run()\nThat is all we need to serve a ReactJS-based app from Flask.\nSo far, we have used static JavaScript files to build our React UI in a Flask app.\nlike the JS community does, it is much better to handle React and any other Javascript\nTo manage JavaScript dependencies in our Flask project, we will use Bower (h t t p s ://b o w e\ni o /), a package manager for web applications, which leverages npm to package all JS\nOnce Bower is installed, you can go to the root of your Flask Dashboard app, and run the\nSince we want to serve the JavaScript files from our Flask app (and in production from\nreact#15.4.2 dashboard/static/react\nWe also need to install the Babel transpiler with npm to transpile the JSX files into JS files\nFrom there, running this command converts all our JSX files into a single, plain JS file called\ndashboard.js.\n$ node_modules/.bin/babel dashboard/static/*.jsx >\ndashboard/static/dashboard.js\nOnce this Babel command is called, our Flask template can use the JS version of the React\nclasses by pointing to the JS file instead of the JSX file.\n<RunsBox url=\"/api/runs.json\" />,\ndashboard.js file when it generates it - since scripts are treated in alphabetical order.\n<script src=\"/static/react/react.js\"></script>\n<script src=\"/static/react/react-dom.js\"></script>\n<script src=\"/static/dashboard.js\"></script>\nReact picked was served by the same Flask app at the /api/runs.json endpoint.\nIf the JS code that's executed in the client page for your domain tries to call\nanother domain that you don't own, it could potentially run malicious JS code and harm\nIn the following Flask app, the /api/runs.json endpoint can be used by any\napp = Flask(__name__)\n@app.route('/api/runs.json')\napp.run(port=5002)\nWhen running this app and using cURL to do a GET request, we can see that the Access-\n$ curl -v http://localhost:5002/api/runs.json\n> GET /api/runs.json HTTP/1.1\nIf your JS app is served by a Flask app\nthe runs on localhost:5000 for instance, you can restrict calls to that domain with the\n@app.route('/api/runs.json')\nand can be found at the following link: h t t p s ://d e v e l o p e r .\n/e n - U S /d o c s /W e b /H T T P /A c c e s s _ c o n t r o l _ C O R S\ncross-domain calls, which are useful in JS apps.\nWhat's still missing to make our JS app fully functional is authentication and authorization.\nThe React dashboard needs to be able to authenticate its users, and perform authorized calls\nIt also needs to let the user grant access to Strava.\nAs a first-time user, when I visit the dashboard, there's a \"login\" link.\nthe dashboard redirects me to Strava to grant access to my resources.\nAs described, our Flask app performs an OAuth2 dance with Strava to authenticate users.\nConnecting to Strava also means we need to store the access token into the Runnerly user\nBefore going further, we need to make a design decision: do we want the dashboard\nThe database that holds user data is served by the DataService microservice, which is used\nand JS content and other microservices with its JSON APIs. The benefit of this approach is that we do not need to worry about implementing yet\nReactJS app, there's not a lot we need to add on top of DataService to make it usable for\nIf the dashboard is on its own, it needs to drive DataService\nmuch as possible, the opposite of CRUD-like APIs. For example, the API to create a user in DataService could be a POST that just asks for the\nuser's Strava token and e-mail, and returns some user ID.\nchange, and the dashboard can simply act as a proxy between the users and DataService.\nA significant benefit of having the Dashboard app isolated from the DataService is stability.\nFor all those reasons, having two separate apps for the dashboard and DataService sounds\nc o m /h o z n /s t r a v a l i b ), all the tools to use it.\nImplementing the dance is done by redirecting the user to Strava and exposing an endpoint\nthe user is redirected to once granted access to Strava.\nWhat we get in return is the user info from its Strava account along with the token access.\nmail and token values to DataService so that the Celery strava worker can also use the\ncid = app.config['STRAVA_CLIENT_ID']\nThat function takes client_id from the Runnerly application (generated in the Strava API\nsettings panel) and the redirect URL defined for the dashboard, and returns a URL we can\nreturn render_template('index.html', strava_url=strava_url,\nWhen the user clicks on the login link, she is redirected to Strava and back to our \ncid = app.config['STRAVA_CLIENT_ID']\nsend_user_to_dataservice(email, access_token)\nLastly, the send_user_to_dataservice(email, access_token) can interact with the\nDataService microservice to make sure the e-mail and access tokens are stored there, using a\nThe process is similar--the Dashboard app\nWhen the Dashboard app performs the OAuth2 dance with Strava, it stores user \ninformation into the session, which is perfect to have the user authenticate the dashboard.\nHowever, when the ReactJS UI calls the DataService microservice to display the user runs,\nProxy all the calls to the microservices via the Dashboard web app using the\nGenerate a JWT token for the end user, which they can store and use against\none token per user for accessing DataService.\nDashboard service even when it is not needed.\nClient app needs to authenticate back even if the Strava token is still valid.\non behalf of the user means that the Dashboard application uses its JWT token to call\nDataService to grab the user data.\nto return runs: GET /runs/<user_id>/<year>/<month>.\nIf we make the assumption that the Dashboard keeps track of the (e-mail, user ID) tuples,\nDashboard code can find back the user ID given the user e-mail currently logged into the\n@app.route('/api/runs/<int:year>/<int:month>')\nThe call_data_service() function calls the DataService endpoint with a JWT token, and\nIn this chapter, we looked at how to build a ReactJS UI wrapped into a Flask application\nWe also looked at how to use a toolchain based on npm, Bower, and Babel to manage JS\nThe Dashboard application uses Strava's three-legged OAuth API to connect users and get\nDashboard application from DataService, so the token is sent to the DataService\nruns on behalf of the user.\nThe following is a diagram of the new architecture, which includes the Dashboard app:\nYou can find the full code of the Dashboard in the Runnerly org at h t t p s\nWith now six different Flask apps that compose it, developing an application like Runnerly\nThere's an obvious need to be able to run all microservices in a single dev box without too",
      "keywords": [
        "dashboard",
        "Flask",
        "runs",
        "React",
        "User",
        "Strava",
        "Flask app",
        "Flask Dashboard app",
        "JSX",
        "run",
        "Runnerly Dashboard",
        "JSX files",
        "app",
        "Dashboard app",
        "script"
      ],
      "concepts": [
        "user",
        "runs",
        "run",
        "running",
        "dashboard",
        "react",
        "calling",
        "bringing",
        "data",
        "file"
      ],
      "similar_chapters": [
        {
          "book": "Python Microservices Development",
          "chapter": 2,
          "title": "",
          "score": 0.729,
          "base_score": 0.579,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Python Microservices Development",
          "chapter": 5,
          "title": "",
          "score": 0.546,
          "base_score": 0.546,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Python Microservices Development",
          "chapter": 10,
          "title": "",
          "score": 0.494,
          "base_score": 0.494,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Python Microservices Development",
          "chapter": 1,
          "title": "",
          "score": 0.468,
          "base_score": 0.468,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Python Microservices Development",
          "chapter": 12,
          "title": "",
          "score": 0.394,
          "base_score": 0.394,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "dashboard",
          "react",
          "js",
          "runs",
          "app"
        ],
        "semantic": [],
        "merged": [
          "dashboard",
          "react",
          "js",
          "runs",
          "app"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.4433782233804428,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:08:32.291751+00:00"
      }
    },
    {
      "chapter_number": 9,
      "title": "Packaging and Running Runnerly",
      "start_page": 239,
      "end_page": 264,
      "summary": "Packaging and Running\napplication was run by pointing the Python scripts to the interpreter.\npackaging, releasing, and distributing Python projects was done manually.\nreal standard back then, and each project had a long README on how to install it with all\nBigger projects used the system packaging tools to release their work--whether it was\nEventually, the Python modules from those projects all ended up\nin the site-packages directory of the Python installation, sometimes after a compilation phase,\nPython projects.\ncommunity to improve how a Python project can be packaged, released, and distributed.\nThis chapter is going to explain how to use the latest Python packaging tools for your\nPackaging and Running Runnerly\ncase of Runnerly, having to open six different shells to run all the microservices is not\nsomething a developer would want to do every time they need to run the app.\nIn this chapter, we are going to look at how we can leverage the packaging tools to run all\nHowever, first, let's look at how to package your projects, and which tools should be\ndistribute Python projects.\nprojects.\nPeople who needed advanced toolchains used other tools, like SCons (h t t p ://s c o\nProjects\nPackaging and Running Runnerly\nstandard library takes months to be released, whereas a change in a third-party project can\nWhen we talk about packaging Python projects, a few terms can be confusing, because their\nWe need to define, what's a Python package, a Python project, a Python library, and a\nA Python package is a directory tree containing Python modules.\nA Python project can contain several packages and other resources, and is what\nEach microservice you build with Flask is a Python project.\nA Python application is a Python project that can be directly used through a user\nLastly, a Python library is a specific kind of Python project which provides\nfeatures to be used in other Python projects, and has no direct user interface.\nPackaging and Running Runnerly\nfirst use case is to provide Python packages for other projects.\nproject that was a library becomes an application.\nNow that we have defined Python package, project, application, and library, let's look at\nhow to package your projects.\nWhen you package your Python project, there are three necessary files you need to have\nalongside your Python packages:\nrequirements.txt: A file listing dependencies\nThe setup.py file\nThe setup.py file is what governs everything when you want to interact with a Python\nproject.\nThe metadata file holds all the metadata for the project, but you\nThe reason why you cannot use a static version is that the author of a project might have\nplatform-specific code in setup.py, which generates a different metadata file depending on\nTo rely on running a Python module to extract static information about a project has always\nPackaging and Running Runnerly\nA very common mistake when creating the setup.py file is to import your package in it\nThe only dependency you can afford to import directly in your setup.py file is Setuptools,\nbecause you can make the assumption that anyone trying to install your project is likely to\nproject.\nYour project can work with just a name, a version, a URL, and an author, but this is \nprojects:\nto the Python Package Index (PyPI)\npackages: A list of packages that your project includes--Setuptools can populate\nPackaging and Running Runnerly\ninstall_requires: A list of dependencies (this is a Setuptools option)\ninclude_package_data: A flag that simplifies the inclusion of non-Python files\nThe following is an example of a setup.py file that includes those options:\nc t u r e d t e x t - l i n t ) is a linter that you can use to verify a reST file syntax.\nPackaging and Running Runnerly\nproject.\nPython versions, the license (which duplicates and should match the license option), and\nKeywords are a good way to make your project visible if you publish it to the Python\nFor instance, if you are creating a Flask microservice, you should use flask\nare callables that can be used as plugins once the project is installed in Python.\ncommand-line script will be installed alongside the Python interpreter, and the function\nthe project is installed.\nThis list of Python projects the\nproject uses, and can be used by projects like PIP when the installation occurs.\nOnce this setup.py file is created, a good way to try it is by creating a local virtual\nPackaging and Running Runnerly\nAssuming you have virtualenv installed, if you run these commands in the directory\ncontaining the setup.py file, it will create a few directories including a bin directory\nFrom there, running the pip install -e command will install the project in editable mode.\nThis command installs the project by reading its setup file, but unlike install, the installation\nPython modules in the project, and they will be linked to the local Python installation via its\nUsing a vanilla install call would have created copies of the files into the local site-\npackages directory, and changing the source code would have had no impact on the installed\nThis metadata file is what describes your project and is what is used to register it to the\nPackaging and Running Runnerly\nThe PIP call also pulls all the project dependencies by looking from them in the PyPI on h t t\no r g /p y p i and installs them in the local site-packages.\nwith another way of listing the project dependencies, the requirements.txt file, which is \nfile,which lists all the project dependencies, but also proposes an extended syntax to install \nYou can create as many requirements files as you want in a\nproject, and have your users call the pip install -r thefile.txt command to install\ncontained in thesetup.py file's install_requires section.\nPackaging and Running Runnerly\nThey use install_requires in their library's setup.py file, and the PIP requirement file\nsetup.py file's install_requires option filled with its dependencies.\nthe dependencies are first installed via the requirements file.\nhaving two different ways to describe Python projects dependencies, since the distinction\nwhich offer some syncing automation between setup.py and requirements files.\ngenerates a requirements.txt file (or any other filename) via a pip-compile CLI, as\n#    pip-compile --output-file requirements.txt setup.py\nNotice that the generated file contains versions for each package.\nrelease your project.\nPackaging and Running Runnerly\ngenerate a list of all the current versions that are installed in your Python.\nThat way, PIP can install the latest version\nthe versions by running the pip install -r requirements.txt command.\nTo summarize, defining dependencies should be done in each project's setup.py file, and\nreproducible process to generate them from the setup.py file to avoid duplication.\nThe last mandatory file your projects should have is the MANIFEST.in file.\nWhen creating a source or binary release, Setuptools will include all the packages modules\nPackaging and Running Runnerly\nThe file follows a simple glob-like syntax, described at h t t p s ://d o c s .\ndistribution when you'll release your project.\nA typical microservice project, as described in this book, will have the following list of files:\nrequirements.txt: PIP requirement files generated from install_requires\nFrom there, releasing your project consists of creating a source distribution, which is\nPython packaging tools do not enforce a specific versioning pattern.\nversioning schemes and, sometimes, they were not compatible with installers and tools.\nPackaging and Running Runnerly\nFor instance, when Python is about to ship a new version, it will ship release candidates using\nincompatible version of a project.\nif all projects were using the same versioning scheme.\nSemVer, you will be compatible with PEP 440 and the PIP installer as long as you don't use\nFor instance, 3.6.0rc2 translates to 3.6.0-rc2 in SemVer. Packaging and Running Runnerly\nHere's an example of a sorted list of versions for a project that will work in Python, and\nFor your microservice project, or any Python project for that matter, you should start with\nPackaging and Running Runnerly\nsetup.py (the code) and one may be published in your Swagger specification file, or \nTo release your project, a simple command called sdist is provided in Python's Distutils.\nDistutils has a series of commands that can be invoked with the python setup.py\nRunning the python setup.py sdist command in the root of\nIn the following example, sdist is called in Runnerly's tokendealer project:\ncopying files to runnerly-tokendealer-0.1.0...\nPackaging and Running Runnerly\nThis archive can be used directly with PIP to install the project as follows:\n$ pip install dist/runnerly-tokendealer-0.1.0.tar.gz\nthe installation process will be faster than with sdist; PIP is just going to move files around\nTo build a Wheel archive, you need to install the wheel project, then to call the\nPackaging and Running Runnerly\nThis flag tells the command to generate a source release that can be installed on both Python\nWithout the flag, a runnerly_tokendealer-0.1.0-py3-none-any.whl file would have\nbeen created, indicating that the release works only for Python 3.\nthe wheel, and the project will get installed faster than with sdist.\nWhen you call the pip install <project> command, PIP will browse the PyPI index to\nThe public name is the name you use in your setup.py file and you need to register it at\nWhen creating microservices for an application or an organization, you can use a common\nPackaging and Running Runnerly\nPython has a namespace package feature, which allows you to create a top-level package\nname (like runnerly), and then have packages in separate Python projects, which will end\nup being installed under the top-level runnerly package.\nTo do this, you just need to create the same top-level directory in every project, with the\neach project can have the same top-level package name.\nBoth will ship a runnerly top-level package, and when PIP installs them, the\npackages/runnerly.\nto create a lot of libraries that are used across projects.\nPackaging and Running Runnerly\nTo publish the releases at PyPI, you first need to register a new user using the form at h t t p s\nPython Distutils has a register and upload command to register a new project at PyPI, but it\nThe preceding command will create a new entry in the index using your package metadata.\nhttps://pypi.python.org/pypi/<project>.\nAnd the pip install <project>\nPackaging and Running Runnerly\nNow that we know how to package each microservice, let's see how to run them all in the\nIn the following example, the application for Runnerly, the dataservice microservice is\n$ FLASK_APP=runnerly/dataservice/app.py bin/flask run\nRunning apps using Flask's command line is fine, but it restricts us to use its interface\nAnother option is to create our own launcher using the argparse module (h t t p s ://d o c s .\nconfiguration file that contains everything needed by the microservice to run.\nPackaging and Running Runnerly\nPackaging and Running Runnerly\nWe have used the -e option earlier in PIP to run a project in develop mode.\nsame option for all our microservices from within the same Python, we will be able to run\na requirements.txt file that lists all your microservices.\nFor example, the following requirements.txt file points to two GitHub repositories:\nFrom there, running the pip install -r requirements.txt command will clone the\ntwo projects in a src directory and install them in develop mode, meaning that you can \nSockets to run Flask apps is common when the application is proxied via a front server like\nPackaging and Running Runnerly\nTo use this model for your Flask app, you can use uWSGI (h t t p ://u w s g i - d o c s .\ndevelopment environment, a few other processes, like a Redis instance, which need to run\nalongside your microservices on the same box, you will need to use another process\nCircus is a Python application, so, to use it, you can simply run the pip install circus\nCircus uses an INI-like configuration file, where you can list the commands to run in\nCircus can also bind sockets, and let the forked process use them via their file descriptors.\nWhen a socket is created on your system, it uses a file descriptor (FD), which is a system\nhandle a program can use to reach a file or an I/O resource like sockets.\nPackaging and Running Runnerly\nIn the following example, two commands are being run.\nTo run this script, you can use the circusd command line.\nThere are a few WSGI web servers out there that provide an option to run against a file\ni o /) project was created to let you run \nOnce you've run the pip install\nchaussette command, you can run the Flask app with a variety of backend listed at h t t p\nneeds to be adapted in order to be able to run with file descriptors.\nPackaging and Running Runnerly\nPackaging and Running Runnerly\nIn this chapter, we've looked at how to package, release, and distribute each microservice.\nHaving numerous projects to run a single application adds a lot of complexity when you\nTools like PIP's development mode and Circus are useful for this, as it allows you to\nsimplify how you run the whole stack--but they still require that you install things on your",
      "keywords": [
        "Running Runnerly",
        "Python",
        "Python project",
        "project",
        "file",
        "Runnerly",
        "Running",
        "PIP",
        "pip install",
        "Packaging and Running",
        "setup.py file",
        "packaging Python projects",
        "Python package",
        "Python packaging",
        "Python packaging tools"
      ],
      "concepts": [
        "packaging",
        "packages",
        "files",
        "versions",
        "version",
        "python",
        "projects",
        "install",
        "installations",
        "runner"
      ],
      "similar_chapters": [
        {
          "book": "Python Microservices Development",
          "chapter": 12,
          "title": "",
          "score": 0.561,
          "base_score": 0.561,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Python Microservices Development",
          "chapter": 10,
          "title": "",
          "score": 0.521,
          "base_score": 0.521,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Python Microservices Development",
          "chapter": 1,
          "title": "",
          "score": 0.485,
          "base_score": 0.485,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Python Microservices Development",
          "chapter": 2,
          "title": "",
          "score": 0.43,
          "base_score": 0.43,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Python Microservices Development",
          "chapter": 8,
          "title": "",
          "score": 0.386,
          "base_score": 0.386,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "packaging",
          "packaging running",
          "running runnerly",
          "file",
          "python"
        ],
        "semantic": [],
        "merged": [
          "packaging",
          "packaging running",
          "running runnerly",
          "file",
          "python"
        ]
      },
      "topic_id": null,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.42645377462877665,
        "topic_boost": 0.0,
        "timestamp": "2025-12-17T23:08:32.291779+00:00"
      }
    },
    {
      "chapter_number": 10,
      "title": "Containerized Services",
      "start_page": 265,
      "end_page": 284,
      "summary": "Most of the time, it is fine to do so, because running a Python application in a virtual\nthe application requires a database system, you need that database to run on your system,\nIn no time, your system is going to have various software running, which were installed\nDocker can run your applications in production at native speed.\nIn this chapter, we present Docker, and explain how to run Flask-based microservices with\nWhat is Docker?\nc o m /) project is a container platform, which lets you run\nAs a Docker user, you just need to point which image you want to run, and Docker does all\nall the instructions required to create a set of running processes on the top of a Linux kernel\nto run one container.\nAn image includes all the resources necessary to run a Linux\nFor instance, you can run whatever version of Ubuntu you want in a Docker\nIf you have already installed Docker in Chapter 6, Monitoring Your Services, to set up a\ncontainers.\nInstalling Docker on Linux is a no-brainer-- you can probably find a package for\nFor macOS, Docker uses a VM to run a Linux Kernel.\nRunning Docker via a VM adds a bit of overhead, but it is quite lightweight,\nUnder Windows, Docker uses the Windows built-in Hyper-V, which might need to be\nIf the installation was successful, you should be able to run the docker command in your\n$ docker version\nA Docker installation is composed of a Docker server (the engine that's being executed by a\ndaemon) and a Docker client (the shell commands like docker).\n(usually, /var/run/docker.sock) or through the network.\nIn other words, the Docker client can interact with Docker daemons running on other boxes.\nPython library like docker-py (h t t p s ://g i t h u b .\nNow that Docker is installed on your system, let's discover how it works.\nDocker 101\nRunning a container in Docker is done by executing a series of commands which starts a\nDocker can be used to run a single process, but in practice we want to run a full Linux\nNot to worry, everything needed to run a full Linux inside Docker is already\nEvery existing Linux distribution out there provides a base image, which lets you run the\ndistribution in Docker.\nThe typical way you use images is by creating a Dockerfile (h t t p s\nc o m /e n g i n e /r e f e r e n c e /b u i l d e r /), where you point the base image you\nwant to use, and add some extra commands to be run to create the container.\nThe following is a basic example of a Docker file:\nRUN apt-get update && apt-get install -y python\nRUN: Runs the commands in the container once the base image is installed\nCMD: The command to run when the container is executed by Docker\nTo create that image and then run it, you can use the docker build and run commands\n$ docker build -t runnerly/python .\nStep 2/3 : RUN apt-get update && apt-get install -y python\n$ docker run -it --rm runnerly/python\nWhen Docker creates images, it creates a cache which has every instruction from the\nIf you run the build command a second time, without changing the file, it\nThe Docker Hub (h t t p s ://h u b .\nc o m ) is to Docker containers\nIn the previous example, the ubuntu base image was pulled from the Hub by Docker, and\nlook at the Python page on the official Docker Hub and pick one (h t t p s ://h u b .\nThe Python images based on Alpine Linux (refer to h t t p ://g l i d e r l a b s .\nk e r - a l p i n e /) are also quite popular, because they produce the smallest images to run\nfaster to download and set up for people wanting to run your project in Docker.\nBuilding and running this Dockerfile drops you in a Python 3.6 shell.\ngreat if you run a Python application that does not require a lot of system-level\nRunning Flask in Docker\nTo run a Flask application in Docker, we can use the base Python image.\ninstalled in the Python image.\ninstructing Docker how to use the pip command.\ncopies a directory structure inside the Docker image, and the RUN command runs PIP via\nRUN pip install -r /app/requirements.txt\nRUN pip install /app/\nThe COPY command automatically creates the top-level app directory in the container, and\n$ docker build -t runnerly/tokendealer .\nStep 3/6 : RUN pip install -r /app/requirements.txt\nare already in a container.\nThat is why the CMD instruction that points which command should be run when the\n$ docker run -p 5555:5000 -t runnerly/tokendealer\nThe last thing we need to do for a fully functional image is to run a web server in front of\nWhen you release microservices as Docker images, there are two strategies for including a\nserver like OpenResty could then run in its docker container, proxying calls to your Flask\ncontainer.\nIn the diagram that follows, the docker container implements the second strategy, and runs\nAdd a Circus configuration file to run nginx and the Flask app.\nThe base Python image uses Debian's apt package manager, and OpenResty (the nginx\nThat directory needs to be created via a RUN instruction, and a mount point can be added\nA Docker container filesystem should always be considered as a volatile\nOnce nginx runs, it makes the assumption that Circus listens to incoming TCP connections\nCircus can also watch the single nginx process we want to run in our container.\nThe first step to using Circus as a process manager in our container is to install it, together\nRUN pip install circus chaussette\nCOPY docker/circus.ini /app/circus.ini\nRUN pip install circus chaussette\nRUN pip install -r /app/requirements.txt\nRUN pip install /app/\n# command that runs when the container is executed\nAssuming this Docker file is located in a /docker subdirectory in the microservice project,\nit can be built and then run with the following calls:\n$ docker build -t runnerly/tokendealer -f docker/Dockerfile .\n$ docker run --rm --v /tmp/logs:/logs -p 8080:8080 --name tokendealer -it\nThe -i option makes sure that stopping the run with a Ctrl + C forwards the termination\nrun a Docker container in a console.\nIf you do not use -i, and kill the run with Ctrl + C, the\nDocker image will still run, and you will need to terminate it manually via a docker\nname to the container in the Docker environment.\nYou can also expose some of the running options, like the number of Flask processes you\nwant to start--like environment variables--and pass them at run time via Docker with -e.\nDocker-based deployments\nOnce you have microservices running inside containers, you need them to interact with\ndeployed inside a container on host A can talk to a service deployed inside a container on\nHowever, when two containers need to run on the same host, using the public DNS to make\nFor example, if you run a container in Docker for internal needs, like a\nTo make this use case easier to implement, Docker provides a user-defined network feature,\nrun with a --name option, Docker acts as a DNS resolver, and makes them available in\nOnce this network is created, we can run containers in it, using the --net option.\n$ docker run --rm --net=runnerly --name=tokendealer -v /tmp/logs:/logs -p\nIf we run a second container with the same image and a different name on the same\n$ docker run --rm --net=runnerly --name=tokendealer2 -v /tmp/logs:/logs -p\nUsing dedicated Docker networks for your microservices container when you deploy them\nis good practice even if you have a single container running.\nDocker has other network strategies you can look at in h t t p s ://d o c s .\nHaving to deploy several containers to run one microservice requires you to make sure that\nTo make that configuration easier, Docker has a high-level tool called Docker Compose,\nThe command-lines required to run several containers on the same host can be quite long\nDocker Compose (h t t p s ://d o c s .\nyou can download or even install with PIP (refer to h t t p s ://d o c s .\nOnce the script is installed on your system, you need to create a YAML file named docker-\ncompose.yml, which contains a services section to enumerate your Docker containers.\ncontainers.\nthe Redis's image from the Docker Hub:\ncreate it manually on your host before you deploy your containers.\nTo build and run those two containers, you can use the up command as follows:\nmicroservices, which includes every piece of software needed to run it.\nc o m /_ /p o s t g r e s /), and link it to your service in a Docker Compose file.\nHowever, as we stated earlier, a Docker container should be seen as\nSo if you use a container for your database, make sure that the\nSo far in this chapter, we have looked at how to run apps in Docker containers, and how to\ndeploy several containers per host and have them interact with each other.\nWhen you deploy a microservice that needs scaling, it is often required to run several\nThe next section discusses various options to run several instances of the same container in\nDeploying a microservice at scale can be done by running several containers spread across\nOnce your Docker image is created, every host that runs a Docker daemon can be used to\nrun as many containers as you want within the limits of the physical resources.\nyou run several instances of the same container on the same host, you need to use a\nThe collection of containers running the same image is called a cluster, and there are a\nDocker has a built-in cluster functionality called swarm mode (h t t p s ://d o c s .\nWhile Docker tries to provide all the tools to deal with clusters of containers, managing\nc o m /e t c d /) and Docker's swarm mode can be\nRead a configuration file that describes the instances needed via a few Docker\nMake sure everything needed to run services on the VM is set.\nInteract with the Docker daemon on each VM to start some containers.\nclusters containers on hosts.\nuse than running your own PostgreSQL or MySQL deployment, while others make their\nyour Docker images as its basis for deploying your application.\nIn this chapter, we looked at how microservices can be containerized with Docker, and how\nyou can create a deployment entirely based on Docker images.",
      "keywords": [
        "Docker",
        "run",
        "docker run",
        "Docker container",
        "RUN pip install",
        "Containerized Services",
        "COPY docker",
        "container",
        "Services",
        "Python",
        "Docker Compose",
        "Docker Hub",
        "Circus",
        "Linux",
        "RUN pip"
      ],
      "concepts": [
        "docker",
        "running",
        "run",
        "runs",
        "container",
        "python",
        "services",
        "images",
        "file",
        "circus"
      ],
      "similar_chapters": [
        {
          "book": "Python Microservices Development",
          "chapter": 12,
          "title": "",
          "score": 0.652,
          "base_score": 0.652,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Python Microservices Development",
          "chapter": 9,
          "title": "",
          "score": 0.521,
          "base_score": 0.521,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Python Microservices Development",
          "chapter": 8,
          "title": "",
          "score": 0.494,
          "base_score": 0.494,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Python Microservices Development",
          "chapter": 1,
          "title": "",
          "score": 0.485,
          "base_score": 0.485,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Python Microservices Development",
          "chapter": 2,
          "title": "",
          "score": 0.466,
          "base_score": 0.466,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "docker",
          "container",
          "containers",
          "image",
          "pip"
        ],
        "semantic": [],
        "merged": [
          "docker",
          "container",
          "containers",
          "image",
          "pip"
        ]
      },
      "topic_id": null,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.43967436963571926,
        "topic_boost": 0.0,
        "timestamp": "2025-12-17T23:08:32.291797+00:00"
      }
    },
    {
      "chapter_number": 11,
      "title": "Deploying on AWS",
      "start_page": 285,
      "end_page": 310,
      "summary": "Deploying on AWS\nAmazon Web Services (AWS) and others have numerous\nservices that let you manage virtual machines from a web console, and they add new\ninstance, you do not have to spend too much money to set up a service that might see a\nDeploying on AWS\nAmazon Web Service began in 2006 with Amazon Elastic Compute Cloud (Amazon EC2),\nDeploying on AWS\nThe AWS services we are interested in can be organized into four five main groups as seen\nExecution: Services that execute your code, such as EC2 or Lambda\nhttps://aws.amazon.com/<service name>.\nDeploying on AWS\nRoute53 (https://aws.amazon.com/route53/) refers to the TCP port 53 that's used for DNS\nservers, and is Amazon's DNS service.\nup the service to automatically route the requests to specific AWS services that host\nIf you are deploying your services on AWS, it is highly\n(https://aws.amazon.com/elasticloadbalancing/), which is a load balancer that can be \ndeploying several VMs for the same microservice to create a cluster, ELB can be used to\n(https://aws.amazon.com/autoscaling/).\nThis service can add instances automatically\nWith these three services, you can set up a robust routing system for your microservices.\nThe core of AWS is EC2 (https://aws.amazon.com/ec2/), which lets you create Virtual\nDeploying on AWS\nAn EC2 instance comes in different series (https://aws.amazon.com/ec2/instance-\nHowever, since we are deploying our microservices as Docker images, we do not need to\nIn AWS, the built-in way to perform Docker deployments is to use the EC2 Container\nService (ECS) (https://aws.amazon.com/ecs).\nECS uses its own Linux AMI to run\nDocker containers, but you can configure the service to run another AMI.\nCoreOS (https://coreos.com/) is a Linux distribution whose sole purpose is to run Docker\nLastly, Lambda (https://aws.amazon.com/lambda/) is a service you can use to trigger the\ndeploy a Celery microservice that needs to run 24/7 to pick messages from a queue.\nusing Lambda means you are locked in AWS services.\nDeploying on AWS\nWhen you create an EC2 instance, it works with one or several Elastic Block Stores (EBS)\n(https://aws.amazon.com/ebs/).\nSimple Storage Service (S3) (https://aws.amazon.com/s3/) is a storage service that \n(https://aws.amazon.com/glacier/) can be used as a backend when you want to store big\nElasticCache (https://aws.amazon.com/elasticache/) is a cache service that has two\nRelational Database Service (RDS) (https://aws.amazon.com/rds/) is a database service\nDeploying on AWS\nLastly, CloudFront (https://aws.amazon.com/cloudfront/) is Amazon's Content Delivery\nFor all messaging needs, AWS provides these three major services:\nIf you use the local SMTP service from the application's server that sends the\nDeploying on AWS\nThere are many of them on the market, and AWS has Simple Email Service (SES)\n(https://aws.amazon.com/ses/ ).\nSQS (https://aws.amazon.com/sqs/) is a subset of what you get with RabbitMQ, but it is\nThe last service in the messaging tools is SNS (https://aws.amazon.com/sns/), which \noffers two messaging APIs. Deploying on AWS\nIn the next section, we are going to look at the AWS services you can use to provision and\ndeploy services.\nused on AWS to manage all your running instances.\nAWS also offers its service to deploy clusters of containerized applications; it is called EC2\nContainer Service-ECS (https://aws.amazon.com/ecs) and leverages another service\ncalled CloudFormation (https://aws.amazon.com/cloudformation/).\nCloudFormation lets you describe the different instances you want to run on Amazon via\nJSON files, and drives everything automatically on AWS, from deploying instances to\nECS is, basically, a set of dashboards to visualize and operate clusters deployed via\nDeploying on AWS\nWhat's convenient with ECS is that you can create and run a cluster for a given Docker\nDeploying on AWS - the basics\nNow that we have looked at the major AWS services, let's see how to deploy a microservice\nTo understand how AWS works, it is good to know how to manually deploy an EC2\ninstance, and run a Docker container in it.\ndeployments using ECS.\nThe first step in deploying on Amazon is to create an account at https://aws.amazon.com.\nThe services that are offered for free are good enough to evaluate AWS.\nDeploying on AWS\nhttps://console.aws.amazon.com/billing/home#/ (or navigating to it from the menu),\nDeploying on AWS\nDeploying on AWS\nhttps://console.aws.amazon.com/ec2/v2/home, where you can create new instances:\nDeploying on AWS\nDeploying on EC2 with CoreOS\nLet's click on the Launch Instance blue button, and pick an AMI to run a new VM:\nDeploying on AWS\nDeploying on AWS\nAWS to deploy the VM.\nDeploying on AWS\nInstances list in the EC2 console and click on the Security Group that was created for the\nDeploying on AWS\nThis is what it takes to run a Docker image on AWS, and it is the basis for any deployment.\nFrom there, you can deploy clusters by creating groups of instances managed by the\nAWS when you are using Docker-let's see how to use it in the next section.\nDeploying with ECS\nAs described earlier in this chapter, ECS takes care of deploying Docker images\nautomatically, and sets up all the services needed around the instances.\nYou do not need, in this case, to create EC2 instances yourself.\nis tweaked to run Docker containers on EC2.\nA Service, which uses the Task Definition to drive the creation of EC2 instances,\nA Cluster, which groups Services, Task Definitions, and an ELB\nDeploying on AWS\nThis wizard is displayed when you go to the ECS service on the console for the first time,\nYou can check the Deploy a sample application onto Amazon ECS Cluster option, and get\nDeploying on AWS\nDeploying on AWS\nDeploying on AWS\nWe add three tasks into that service, as we want to run three instances in our cluster with\nDeploying on AWS\nThe Service page summarizes all the parts of the deployment, and has\nThe deployment done by the ECS wizard can be\nA task definition was created to run the Docker container\nA Service was added to the cluster, and Task Definition was used to deploy\nDocker containers in the EC2 instance\nDeploying on AWS\nconsole at https://console.aws.amazon.com/route53, and click on the hosted zones\nDeploying on AWS\nDeploying on AWS\nThis step is all it takes to link a domain name to your deployed ECS cluster; and you can\ncheck that you can use to ping your ELB and underlying services regularly.\nSo, if your application is dockerized, you should be able to deploy it\nIn this chapter, we have looked at how to do it in AWS, which has its service (ECS) to\nmanage Docker images that is tightly integrated with all the other main AWS services.\nOnce you are familiar with all the AWS services, it is a pretty powerful platform that can be",
      "keywords": [
        "AWS",
        "AWS services",
        "Deploying on AWS",
        "service",
        "Docker",
        "Docker containers",
        "Deploying",
        "ECS",
        "Amazon DNS service",
        "run Docker containers",
        "Amazon",
        "run",
        "ELB",
        "instance",
        "specific AWS services"
      ],
      "concepts": [
        "services",
        "deploying",
        "deployments",
        "instance",
        "ecs",
        "docker",
        "amazon",
        "messaging",
        "messages",
        "routing"
      ],
      "similar_chapters": [
        {
          "book": "Python Microservices Development",
          "chapter": 5,
          "title": "",
          "score": 0.465,
          "base_score": 0.315,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Python Microservices Development",
          "chapter": 1,
          "title": "",
          "score": 0.327,
          "base_score": 0.327,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Python Microservices Development",
          "chapter": 10,
          "title": "",
          "score": 0.322,
          "base_score": 0.322,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "aws",
          "amazon",
          "deploying aws",
          "deploying",
          "aws amazon"
        ],
        "semantic": [],
        "merged": [
          "aws",
          "amazon",
          "deploying aws",
          "deploying",
          "aws amazon"
        ]
      },
      "topic_id": 1,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.31414454396429825,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:08:32.291825+00:00"
      }
    },
    {
      "chapter_number": 12,
      "title": "What Next?",
      "start_page": 311,
      "end_page": 334,
      "summary": "Five years ago, choosing a Python version was driven by these two factors:\nThe availability of the libraries your application used\nHowever, using CentOS means you cannot use the latest Python version for your projects\nunless you install a custom Python instance on the system.\ntime, and that prevented them from using the newest Python syntax and features.\nThe other reason people stayed on Python 2 was that a few essential libraries were still not\nported to Python 3.\nproject in 2017, everything is available for Python 3.\nThose two reasons to stick with older Python versions are gone nowadays; you can pick the\nlatest Python 3, and ship your app on whatever Linux distribution is inside a Docker\nAs we've seen in Chapter 10, Containerized services, Docker seems to be the new standard\nlike CoreOs's rkt (h t t p s ://c o r e o s .\nFor all these reasons, using the latest Python 3 and Docker for your microservices is a safe\nSo, if Python 3.6 or the next versions have great features, nothing will prevent you from\nthe book, it's fine to use different stacks or Python versions for each microservice.\nIn this book, Flask was picked, because that framework is excellent to build microservices,\nBut since Python 3.5, web frameworks based on the\nasyncio library (h t t p s ://d o c s .\npopular framework, because the benefits regarding the performances of I/O bound\nmicroservices are huge, and developers are starting to adopt asynchronous programming.\nIn this last chapter, we are going to look at how asynchronous programming works in\nPython 3.5+, and discover two web frameworks that can be used to build microservices\nasynchronously.\nTo understand how asynchronous programming works in Python, it is important to first\nunderstand how iterators and generators work because they are the basis of asynchronous\nfeatures in Python.\nAn iterator in Python is a class that implements the Iterator protocol.\ndef __iter__(self):\nTo make iterators more Pythonic, generators were added to Python.\nWhen yield is used by a function instead of return, this function is\nEach time the yield keyword is encountered, the function\nreturns the yielded value and pauses its execution.\nThis behavior makes generators a bit similar to coroutines found in other languages, except\nThey return a value as yield does, but they can also receive\nBeing able to pause the execution of a function and communicate with it both ways is the\nbasis for asynchronous programming--once you have this ability, you can use an event\nloop, and pause and resume functions.\nIn the next example, a terminal() function simulates a console, which\nWhen instantiated, this generator can receive data via its send() method:\nThanks to this addition, Python generators became similar to coroutines.\nConsider the following example, where a generator is uses two other generators to yield\nThe two for loops in the gen() function can be replaced by a single yield from call as\nHere's an example of calling the gen() method until each sub generator gets exhausted:\nCalling several other coroutines and waiting for their completion is a prevalent pattern in\nasynchronous programming.\nEach yield call is an opportunity for the function to pause\nits execution and let another function take over.\nWith these features, Python got one step closer to supporting asynchronous programming\nIterators and generators were used as building blocks to create native coroutines.\nCoroutines\nTo make asynchronous programming more straightforward, the await and async\nkeywords were introduced in Python 3.5, along with the coroutine type.\nalmost equivalent to yield from, as its goal is to let you call a coroutine from another\ncoroutine.\nThe difference is that you can't use the await call to call a generator (yet).\nThe async keyword marks a function, a for or a with loop, as being a native coroutine, and\nif you try to use that function, you will not retrieve a generator but a coroutine object.\nThe native coroutine type that was added in Python is like a fully symmetric generator, but\nIn the example that follows, the asyncio library is used to run main(), which, in turn, calls\nloop = asyncio.get_event_loop()\nloop.run_until_complete(main())\nWhat's compelling about such an application is that, besides the async and await\nkeywords, it looks like plain sequential Python--making it very readable.\noccur in the same way every time it runs unlike programming with threads.\nNotice that the asyncio.sleep() function is a coroutine, so it is called with the await\n$ python async.py\nIn the next section, we will take a closer look at the asyncio library.\nThe asyncio library\nThe asyncio (h t t p s ://d o c s .\noriginally an experiment called Tulip run by Guido, provides all the infrastructure to build\nasynchronous programs based on an event loop.\nThe library predates the introduction of async, await, and native coroutines in the\nThe asyncio library is inspired by Twisted, and offers classes that mimic Twisted transports\nYou can use coroutine with asyncio protocol and transport classes, but the original design\nHowever, the central feature is the event loop API and all the functions used to schedule\nhow the coroutines will get executed.\nAn event loop uses the operating system I/O poller\n(devpoll, epoll, and kqueue) to register the execution of a function given an I/O event.\nFor instance, the loop can wait for some data to be available in a socket to trigger a function\ncoroutine A awaits for coroutine B to be finished, the call to asyncio sets an I/O event, which\nis triggered when coroutine B is over and makes coroutine A wait for that event to resume.\nThe result is that if your program is split into a lot of interdependent coroutines, their\ncan run thousands of coroutines concurrently without having to be thread-safe and without\nTo build an asynchronous microservice, the typical pattern is like this:\nasync def my_view(request):\nquery = await process_request(request)\nresponse = await build_response(data)\nreturn response\nAn event loop running this coroutine for each incoming request will be able to accept\nIf the same service were built with Flask, and typically run with a single thread, each new\nFlask app.\nHammering the service with several hundred concurrent requests will issue\nThe execution time for a single request is the same in both cases, but the ability to run many\nrequests concurrently and interleave their execution is what makes asynchronous\napplications better for I/O-bound microservices.\nAnd if some of your services have CPU-bound tasks, asyncio provides a function to run\nthe code in a separate thread or process from within the loop.\nIn the next two sections, we will present two frameworks based on asyncio, which can be\nused to build microservices.\ni o /) framework is a popular asynchronous \nframework based on the asyncio library, which has been around since the first days of the\nlibrary.\nLike Flask, it provides a request object and a router to redirect queries to functions that\nThe asyncio library's event loop is wrapped into an Application object, which handles\nAs a microservice developer, you can just focus on building\nyour views as you would do with Flask.\nIn the following example, the api() coroutine returns some JSON response when the\nasync def api(request):\nreturn web.json_response({'some': 'data'})\napp = web.Application()\nweb.run_app(app)\nThe aiohttp framework has a built-in web server, which is used to run this script via the\nrun_app() method, and, overall, if you are used to Flask, the biggest difference is that you\ndo not use decorators to route requests to your views.\nThis framework provides helpers like those you find in Flask, plus some original features\nsuch as its Middleware, which will let you register coroutines to perform specific tasks such\ni o /) is another interesting project, which specifically\ntries to provide a Flask-like experience with coroutines.\nSanic uses uvloop (h t t p s ://g i t h u b .\nc o m /M a g i c S t a c k /u v l o o p ) for its event loop, which is a\nCython implementation of the asyncio loop protocol using libuv, allegedly making it\nany speed gain when it is just a transparent switch to a specific event loop implementation.\nIf we write the previous example in Sanic, it's very close to Flask:\nasync def api(request):\nreturn response.json({'some': 'data'})\nSanic also has its original features, like the ability to write your views in a class\nThe framework also provides middleware to change the request or response.\nfrom sanic.response import json\nasync def convert(request, response):\nreturn json(response)\nreturn response\nasync def api(request):\nreturn {'some': 'data'}\nThis little middleware function simplifies your views if your microservice produces only\nSwitching to an asynchronous model means you will need to use asynchronous code all the\nFor example, if your microservice uses a Requests library that is not asynchronous, every\ncall made to query an HTTP endpoint will block the event loop, and you will not benefit\nfrom asynchronicity.\nAnd making an existing project asynchronous is not an easy task because it changes the\nMost projects that want to support asynchronous calls are redesigning\nThe good news is that there are more and more asynchronous libraries\navailable, which can be used to build a microservice.\nc o m /p y t h o n /a s y n c i o /w i k i /T h i r d P a r t y\naiohttp.Client: Can replace the requests package\nIn case you cannot find a replacement for one of your libraries, asyncio provides a way to\nrun blocking code in a separate thread or process via an executor.\nThis function is a\ncoroutine, and uses a ThreadPoolExecutor or a ProcessPoolExecutor class from the\nIn the example that follows, the requests library is used via a pool of threads:\nreturn requests.get(url).text\n# coroutine\nasync def example(loop):\ntasks.append(loop.run_in_executor(executor, fetch, url))\ncompleted, pending = await asyncio.wait(tasks)\nloop = asyncio.get_event_loop()\nloop.run_until_complete(example(loop))\nEach call to run_in_executor() returns a Future object, which can be used to set some\nsynchronization points in your asynchronous program.\nPython 3 has two Future classes that are slightly different, and that can be\nThe asyncio.Future is a class you can use directly with the\nevent loop, while concurrent.futures.Future is a class that is used in\nThe asyncio.wait() function can wait for all the Futures to complete, so the example()\nfunction here will block until all the Futures return.\nThe Wait() function can take a timeout\nvalue, so the function returns a tuple composed of the list of completed Futures and the\nYou can use processes instead of threads, but, in that case, all the data that goes in and out\nThat said, if you have a function that is CPU bound, it can be worthwhile to run it in a\nseparate process to use all the CPU cores available, and speed up your microservice.\nIn this final chapter, we have looked at how we can write microservices using asynchronous\nprogramming in Python.\nWhile Flask is a great framework, asynchronous programming\nmight be the next big revolution in Python for writing microservices that are usually I/O\nThere are more and more asynchronous frameworks and libraries based on Python 3.5 and\nSwitching from Flask to one of these frameworks for one of your microservices can be a\nAmazon Elastic Compute Cloud (Amazon EC2) \nAmazon Web Services (AWS)\nasynchronous calls\nasynchronous libraries\nasynchronous\nasyncio library\nreturning user  218\nData Service, interacting with  218, 219\nAWS services\nbuilt-in features, Flask\ncoroutines  301\ncreate_token() function  176\ncurl command\nData Service\ndebug mode  60\nwith EC2 Container Service (ECS)  279, 288,\nFlask, executing  256, 257, 258\nEC2 Container Service (ECS)\nService  288\nFlask app\nFlask-SQLAlchemy\nflask-webtest package\nFlask\nCircus, configuring  258, 259, 261\nexecuting, in Docker  256, 257, 258\nOpenResty, configuring  258, 259, 260, 261\nrequests, handling  35, 37, 39, 44\nfunctional tests\nasynchronous calls, mocking  147\nHMAC-SHA256 (HS256)  174\nJSON Web Token (JWT)\nLAMP (Linux-Apache-MySQL-Perl/PHP/Python) \nwith Simple Queue Service (SQS)  277\nmicroservice project\nmicroservices\nimplementing, with Python  21\nfunction, adding  189\nOpen Web Application Security Project (OWASP)\nPython project, packaging  228\nPython application  227\nPython library  227\nPython package  227\nPython Package Index (PyPI)  13, 229\nPython project  227\nPython project, packaging\nPython, for microservice implementation\nPython\nmicroservices, implementing  21\nFlask  210, 211\nrequest_mock library\nrequests library\nrequests-mock project\nurl_for function  43\nSimple Queue Service (SQS)\nSimple Storage Service (S3)\nSimple Storage Service (S3)  276\nStrava Service  113\nSession, using in Flask app  123\nfunctional tests  67\nJSON Web Token (JWT)  173, 175\nTokenDealer microservice  179, 180\nTokenDealer microservice\nurl_for function  43\nWeb Application Framework (WAF)  186",
      "keywords": [
        "url",
        "Python",
        "service",
        "Flask",
        "asynchronous",
        "function",
        "loop",
        "event loop",
        "yield",
        "project",
        "asyncio",
        "coroutines",
        "request",
        "call",
        "library"
      ],
      "concepts": [
        "urls",
        "url",
        "pythonic",
        "services",
        "projects",
        "request",
        "requests",
        "asynchronous",
        "function",
        "functions"
      ],
      "similar_chapters": [
        {
          "book": "Python Microservices Development",
          "chapter": 10,
          "title": "",
          "score": 0.652,
          "base_score": 0.652,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Python Microservices Development",
          "chapter": 9,
          "title": "",
          "score": 0.561,
          "base_score": 0.561,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Python Microservices Development",
          "chapter": 2,
          "title": "",
          "score": 0.556,
          "base_score": 0.556,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Python Microservices Development",
          "chapter": 1,
          "title": "",
          "score": 0.402,
          "base_score": 0.402,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Python Microservices Development",
          "chapter": 8,
          "title": "",
          "score": 0.394,
          "base_score": 0.394,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "asynchronous",
          "loop",
          "asyncio",
          "python",
          "coroutine"
        ],
        "semantic": [],
        "merged": [
          "asynchronous",
          "loop",
          "asyncio",
          "python",
          "coroutine"
        ]
      },
      "topic_id": null,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.395202539346561,
        "topic_boost": 0.0,
        "timestamp": "2025-12-17T23:08:32.291854+00:00"
      }
    }
  ],
  "total_chapters": 12,
  "enrichment_provenance": {
    "taxonomy_id": "none",
    "taxonomy_version": "none",
    "taxonomy_path": "none",
    "taxonomy_checksum": "sha256:none",
    "source_metadata_file": "Python Microservices Development_metadata.json",
    "enrichment_date": "2025-12-17T23:08:32.302157+00:00",
    "enrichment_method": "msep",
    "model_version": "ai-agents-msep-v1",
    "processing_time_ms": 3149.584335000327,
    "total_similar_chapters": 53
  }
}