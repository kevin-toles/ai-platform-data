{
  "metadata": {
    "title": "Game_Engine_Architecture",
    "source_file": "Game_Engine_Architecture_metadata.json"
  },
  "chapters": [
    {
      "chapter_number": 1,
      "title": "Segment 1 (pages 1-18)",
      "start_page": 1,
      "end_page": 18,
      "summary": "Game Engine Architecture\nGame Engine Architecture\nGame Engine Architecture\nA K Peters/CRC Press is an imprint of Taylor & Francis Group, an Informa business\nFor permission to photocopy or use material electronically from this work, please access www.copyright.com (http://www.copyright.com/) or contact the Copyright Clearance \nStructure of a Typical Game Team \nWhat Is a Game?\nWhat Is a Game Engine?\nGame Engine Survey \nEngineering for Games \n3D Math for Games \nThe Game Loop and Real-Time Simulation \nThe Game Loop \nGame Loop Architectural Styles \nMultiprocessor Game Loops \nNetworked Multiplayer Game Loops \nGame Engine HID Systems \nIn-Game Menus \nIn-Game Console \nDebug Cameras and Pausing the Game \nIn-Game Proﬁ ling \nDo You Want Physics in Your Game?\nIntegrating a Physics Engine into Your Game \nAnatomy of a Game World \nImplementing Dynamic Elements: Game Objects \nData-Driven Game Engines \nThe Game World Editor \nLoading and Streaming Game Worlds \nUpdating Game Objects in Real Time \nHigh-Level Game Flow \nhe very ﬁ rst video game was built entirely out of hardware, but rapid ad-\ngames are played on versatile PCs and specialized video game consoles that \nuse soft ware to make it possible to oﬀ er a tremendous variety of gaming ex-\nIt’s been 50 years since those ﬁ rst primitive games, but the industry \nVideo games are now a multibillion-dollar industry covering a wide range of \nVideo games come in all shapes and sizes, falling into categories or \nrole-playing games, and these games are played on virtually anything with a \nThese days, you can get games for your PC, your cell phone, \nas well as a number of diﬀ erent specialized gaming consoles—both handheld \ntend to represent the cutt ing edge of gaming technology, and the patt ern of \nThe recent explosion of downloadable and casual games has added even \nmore complexity to the diverse world of commercial video games.\nbig games are still big business.\nWith so many diﬀ erent styles of game on such a wide array of platforms, \npackage that perfectly suits every aspect of a new game design.\nprograms and degrees in video games.\nneed a good place to turn to for solid game-development information.\noft en not directly applicable to production game environments or suﬀ er from \nFor the rest of game \nNaughty Dog—one of the most highly regarded video game studios in the \nWhile teaching a course in game programming at USC, Jason found \ngame architecture.\nally used in shipped game projects and bring together the entire game-devel-\nexamples to show you how the pieces come together to actually make a game.\nactual ones we use to create games, and while the examples are oft en ground-",
      "keywords": [
        "Game Engine Architecture",
        "Game",
        "Game Engine",
        "Engine",
        "Engine Architecture",
        "Game Engine HID",
        "video games",
        "Whiting Game Engine",
        "Game Loop",
        "Engine HID Systems",
        "Game Engine Survey",
        "Engine Systems",
        "Animation System Architecture",
        "Francis Group",
        "Engine Architecture Jason"
      ],
      "concepts": [
        "game",
        "gaming",
        "engine",
        "engineering",
        "systems",
        "animation",
        "contents",
        "video",
        "world",
        "data"
      ],
      "similar_chapters": [
        {
          "book": "Game_Engine_Architecture",
          "chapter": 2,
          "title": "",
          "score": 0.815,
          "base_score": 0.665,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 42,
          "title": "",
          "score": 0.714,
          "base_score": 0.564,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 21,
          "title": "",
          "score": 0.629,
          "base_score": 0.479,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 17,
          "title": "",
          "score": 0.568,
          "base_score": 0.568,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 3,
          "title": "",
          "score": 0.552,
          "base_score": 0.552,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "video",
          "architecture",
          "games",
          "engine architecture",
          "engine"
        ],
        "semantic": [],
        "merged": [
          "video",
          "architecture",
          "games",
          "engine architecture",
          "engine"
        ]
      },
      "topic_id": 1,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.3421532274742987,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:57.759026+00:00"
      }
    },
    {
      "chapter_number": 2,
      "title": "Segment 2 (pages 19-41)",
      "start_page": 19,
      "end_page": 41,
      "summary": "elcome to Game Engine Architecture.\nmercial game engine.\nGame programming is an immense topic, so we have a \non all aspects of game technology, and this text serves both as a foundation-\nOur focus in this book will be on game engine technologies and architec-\ntems that comprise a commercial game engine and also the data structures, \nThe line between the game engine and the game is rather blurry.\nThis layer includes the game’s object model, world editor, \nWe’ll also touch on some aspects of game-\ncollege-level series in intermediate game programming.\nbe used by amateur soft ware engineers, hobbyists, self-taught game program-\nuse this text to solidify their understanding of game mathematics, engine ar-\nchitecture, and game technology.\nengines are still writt en primarily in C or C++, and any serious game pro-\nThen move on to another area of game technology.\nyou’re practicing the art of game programming, not just reading about it.\nand colleagues in the game industry, and I’d like to extend warm thanks to \ncredible game engine systems that I highlight in this book.\nProgramming Game Engines, which I have been teaching under the auspices \nhen I got my ﬁ rst game console in 1979—a way-cool Intellivision sys-\nand arcade games were considered by most adults to be nothing more than \nToday, games are \nGames’ Unreal Engine 3 and Valve’s Source engine—have become fully fea-\nbuild almost any game imaginable.\nWhile game engines vary widely in the details of their architecture and \nboth publicly licensed game engines and their proprietary in-house counter-\nVirtually all game engines contain a familiar set of core components, in-\nsystem, the audio system, the game world object model, the artiﬁ cial intelli-\nThere are a great many books that cover individual game engine subsys-\nmake up a modern game engine.\nz how real industrial-strength production game engines are architected;\nz how game development teams are organized and work in the real \nvirtually every game engine;\nz which subsystems are genre- or game-agnostic, and which ones are typ-\nically designed explicitly for a speciﬁ c genre or game;\nz where the engine normally ends and the game begins.\nlar game engines, such as Quake and Unreal , and some well-known mid-\nengine, and Rad Game Tools’ Granny 3D animation and geometry man-\nscale soft ware engineering in a game engine context, including\nlanguage of choice among most modern game developers) and that you un-\nStructure of a Typical Game Team\nStructure of a Typical Game Team\nBefore we delve into the structure of a typical game engine, let’s ﬁ rst take a \nbrief look at the structure of a typical game development team.\nGame  stu-\ndios are usually composed of ﬁ ve basic disciplines: engineers, artists, game \nThe  engineers design and implement the soft ware that makes the game, and \nprogrammers (who work on the engine and the game itself) and tools program-\nto work at the systems level and not get too involved in how the game actu-\nthe visual and audio content in the game, and the quality of their work can \nliterally make or break a game.\nwith a vision of what the ﬁ nal game will look like.\nin the virtual game world.\nother objects that populate the game world, while the latt er build \nz Lighting artists lay out all of the light sources in the game world, both \nz Animators imbue the characters and objects in the game with motion.\nHowever, a game animator \nbeing integrated into the game.\nz  Voice actors provide the voices of the characters in many games.\nz Many games have one or more  composers, who compose an original \nscore for the game.\nSome game teams have one or more art directors—very senior artists who \nmanage the look of the entire game and ensure consistency across the work of \nGame Designers\nThe  game designers’ job is to design the interactive portion of the player’s \nSome (usually senior) game designers work at the \non individual levels or geographical areas within the virtual game world, lay-\nSome game designers are ex-engineers, who \nSome game teams employ one or more  writers.\nA game writer’s job can \nof a game’s design, help manage schedules, and ensure that the work of indi-\nIn some game \nIn other companies, producers serve in a senior game \ntwo co-presidents, play a direct role in constructing the game; team man-\nThe team of people who directly construct the game is typically supported by \nStructure of a Typical Game Team\nhandled by a publisher, not by the game studio itself.\nMany game studios are not aﬃ  liated with a particular publisher.\nFor example, THQ’s game studios are independently managed, but \nvelopers are game studios owned directly by the console manufacturers (Sony, \nThese studios produce games exclusively for the gaming hardware \nWhat Is a Game?\nWhat Is a Game?\nFor the purposes of this book, we’ll focus on the subset of games that \nbe on game engines capable of producing ﬁ rst-person shooters, third-person \naction/platform games, racing games, ﬁ ghting games, and the like.\nVideo Games as Soft Real-Time Simulations\nMost two- and three-dimensional video games are examples of what comput-\nis a simulation of the real or imagined  game world.\npliﬁ cation are two of the game developer’s most powerful tools.\ntsional computer games very well, where the agents are vehicles, characters, \nit should come as no surprise that most games nowadays are implemented in \ntime as the game’s events and story unfold.\nA video game must also respond \nchess or non-real-time strategy games.\nBut even these types of games usually \nthe purposes of this book, we’ll assume that all video games have at least some \nkinds of deadlines in video games as well.\nHence all video games are  soft  real-time systems—if the frame rate \nhope to model the entire game analytically.\nGames work in the same way.\nWhat Is a Game Engine?\nThe term “ game engine” arose in the mid-1990s in reference to ﬁ rst-person \nshooter (FPS) games like the insanely popular Doom by id Soft ware.\nworlds, and rules of play that comprised the player’s gaming experience.\nTowards the end of the 1990s, some games like  Quake III Arena \nToday, game developers can license a game engine and \ngames.\nThe  line between a game and its engine is oft en blurry.\nIn one game, the rendering code might “know” speciﬁ -\nIn another game, the rendering engine might pro-\nbetween the game and the engine, which is understandable considering that \nthe deﬁ nitions of these two components oft en shift  as the game’s design so-\ngine from a piece of software that is a game but not an engine.\ncan be used as the foundation for many different games without major \nWhat Is a Game Engine?\ntions of some well-known games/engines along this  gamut.\nOne would think that a game engine could be something akin to Apple \nsoft ware capable of playing virtually any game content imaginable.\nMost game engines \nare carefully craft ed and ﬁ ne-tuned to run a particular game on a particular \ngines are really only suitable for building games in one particular genre, such \nas ﬁ rst-person shooters or racing games.\npurpose a game engine or middleware component is, the less optimal it is for \nrunning a particular game on a particular platform.\na real-time strategy game, for example.\nbuild any game in a \ngame imaginable\nmore than one game\nmake very similar games\nGame engine reusability gamut.\nA game can always be made more impressive \nparticular game and/or hardware platform.\nGame engines are typically somewhat  genre speciﬁ c.\nfor a two-person ﬁ ghting game in a boxing ring will be very diﬀ erent from a \nmassively multiplayer online game (MMOG) engine or a ﬁ rst-person shooter \nLet’s take a look at some of the most common game genres and explore \nThe  ﬁ rst-person shooter (FPS) genre is typiﬁ ed by games like Quake , Unreal \nFirst-person games are typically some of the most technologically chal-\nFor example, indoor “dungeon crawl” games oft en \nOutdoor FPS games use other kinds of rendering optimizations such as \nOf course, immersing a player in a hyperrealistic game world requires \nPlatformers and Other Third-Person Games\n“ Platformer” is the term applied to third-person character-based action games \nture games, like Ghost Recon, Gears of War (Figure 1.4), and Uncharted: Drake’s \nThird-person character-based games have a lot in common with ﬁ rst-per-\ngame.\nin these same games; nor can it be compared to the ﬁ delity of the player avatar \nin a third-person game.\nSome of the technologies speciﬁ cally focused on by games in this genre \nFighting Games\nFighting games are typically two-player games involving humanoid char-\nby games like Soul Calibur and Tekken (see Figure 1.5).\nhtt p://en.wikipedia.org/wiki/Fighting_game provides an overview of this \nTraditionally games in the ﬁ ghting genre have focused their technology \nSince the 3D world in these games is small and the camera is centered \non the action at all times, historically these games have had litt le or no need \nState-of-the-art ﬁ ghting games like EA’s Fight Night Round 3 (Figure 1.6) \nIt’s important to note that some ﬁ ghting games like Heavenly Sword take \nﬁ ghting game can have technical requirements more akin to those of a ﬁ rst-\nperson shooter or real-time strategy game.\nRacing Games\nThe racing  genre encompasses all games whose primary task is driving a car \nSimulation-focused racing games (“sims”) aim to provide a driving experi-\na subcategory in which popular characters from platformer games or cartoon \n“Racing” games need not always involve time-based \nSome kart racing games, for example, oﬀ er modes in which play-\nwiki/Racing_game.",
      "keywords": [
        "Game",
        "Game Engine",
        "Engine",
        "game world",
        "Video Games",
        "Typical Game Team",
        "Game Engine Architecture",
        "game engine systems",
        "Typical Game",
        "book",
        "soft ware",
        "typical game engine",
        "Programming Game Engines",
        "racing games",
        "game designers"
      ],
      "concepts": [
        "game",
        "gaming",
        "engine",
        "engineering",
        "time",
        "timed",
        "based",
        "design",
        "ers",
        "worlds"
      ],
      "similar_chapters": [
        {
          "book": "Game_Engine_Architecture",
          "chapter": 1,
          "title": "",
          "score": 0.815,
          "base_score": 0.665,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 42,
          "title": "",
          "score": 0.806,
          "base_score": 0.656,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 21,
          "title": "",
          "score": 0.586,
          "base_score": 0.436,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 36,
          "title": "",
          "score": 0.502,
          "base_score": 0.502,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 3,
          "title": "",
          "score": 0.491,
          "base_score": 0.491,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "games",
          "person",
          "engine",
          "game engine",
          "racing"
        ],
        "semantic": [],
        "merged": [
          "games",
          "person",
          "engine",
          "game engine",
          "racing"
        ]
      },
      "topic_id": 1,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.3113631856352243,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:57.759111+00:00"
      }
    },
    {
      "chapter_number": 3,
      "title": "Segment 3 (pages 42-63)",
      "start_page": 42,
      "end_page": 63,
      "summary": "A racing game is oft en very linear, much like older FPS games.\nRacing games usually focus all \nlatest installment in the well-known Gran Turismo racing game series, Gran \nSome of the technological properties of a typical racing game include the \nz Various “tricks” are used when rendering distant background elements, \nz The camera typically follows behind the vehicle for a third-person per-\nOther games in this genre include Warcraft , \nThe game world is \nEngine Differnces Across Genres\ndevelopers to employ various optimizations in the rendering engine of an RTS \ngame.\nOlder games in the genre employed a grid-based (cell-based) world con-\nModern RTS games sometimes use perspective projection and a true 3D \nSome other common practices in RTS games include the following tech-\nz Each unit is relatively low-res, so that the game can support large num-\nz Height-ﬁ eld terrain is usually the canvas upon which the game is de-\nz The player is oft en allowed to build new structures on the terrain in ad-\nMassively Multiplayer Online Games (MMOG)\nThe  massively multiplayer online game (MMOG) genre is typiﬁ ed by games \nAn MMOG is deﬁ ned as any game that supports huge numbers of \nEngine Differnces Across Genres\nthis genre include MMO role-playing games (MMORPG), MMO real-time \nstrategy games (MMORTS), and MMO ﬁ rst-person shooters (MMOFPS).\nservers maintain the authoritative state of the game world, manage users sign-\ning in and out of the game, provide inter-user chat or voice-over-IP (VoIP) \nthe game world or out-of-game as well.\nserve as the game developer’s primary source of revenue.\ntremely large numbers of users supported by these kinds of games.\nThere are of course many  other game genres which we won’t cover in depth \nz role-playing games (RPG);\nz God games, like Populus and Black & White;\nz environmental/social simulation games, like SimCity or The Sims;\nz puzzle games like Tetris;\nz conversions of non-electronic games, like chess, card games, go, etc.;\nz web-based games, such as those oﬀ ered at Electronic Arts’ Pogo site;\nWe have seen that each game genre has its own particular technologi-\nThis explains why game engines have traditionally diﬀ ered \nGame Engine Survey\nThe ﬁ rst 3D ﬁ rst-person shooter (FPS) game is generally accepted to be  Castle \ngame led the game industry in a new and exciting direction.\nAll of these engines are very \nQuake technology has been used to create many other games and even other \nengines.\nMany other games based on Quake technology follow equally circuitous paths \nthrough many diﬀ erent games and studios.\nto create the Half-Life games) also has distant roots in Quake technology.\nas great examples of how industrial-strength game engines are built.\nIf you own the Quake and/or Quake II games, you can actually build the \ncode using Microsoft  Visual Studio and run the game under the debugger \nusing the real game assets from the disk.\nYou can set break points, run the game, and then analyze how the engine \nloading one or both of these engines and analyzing the source code in this \nGame Engine Survey\nThe Unreal Family of Engines\nEpic Games Inc. burst onto the FPS scene in 1998 with its legendary game  Un-\nprojects, and commercial games.\ncreating shaders and a graphical user interface for game logic programming \nMany games are being developed with UE3 lately, including of \nopers modify it in various ways to run their game optimally on a particular \ntool and commercial game development platform, and it can be used to build \nvirtually any 3D ﬁ rst-person or third-person game (not to mention games in \nSome of the documentation on Unreal Engine \nextremely expensive, and hence out of reach for all independent game devel-\nSource is the game engine that drives the smash hit  Half-Life 2 and its sequels \nUnreal Engine 3 in terms of graphics capabilities and tool set.\nMicrosoft’s XNA Game Studio\nMicrosoft ’s  XNA Game Studio is an easy-to-use and highly accessible game \ngames and share them with the online gaming community, much as YouTube \nto game art assets are managed within Visual Studio.\ners can create games for the PC platform and Microsoft ’s Xbox 360 console.\nAft er paying a modest fee, XNA games can be uploaded to the  Xbox Live \nperson to create new games.\nOther Commercial Engines\nThere are lots of other commercial game engines out there.\ngreat source of information about game engines and game programming in \nFor example, check out the  C4 Engine by Terathon Soft ware (htt p://\nMany companies build and maintain proprietary in-house game engines.\nElectronic Arts built many of its RTS games on a proprietary engine called \ncially licensed game engines like Quake , Source, or the Unreal Engine started \nOpen Source Engines\nOpen source 3D game engines are engines built by amateur and professional \ngame developers and provided online for free.\nGame Engine Survey\nThere are a staggering number of open source engines available on the \nThe list of game engines provided online at htt p://cg.cs.tu-berlin.de/~ki/\ning engine.\nIt boasts a fully featured 3D renderer including advanced lighting \nthors’ own admission, not a full game engine, but it does provide many of the \nfoundational components required by prett y much any game engine.\nSome other well-known open source engines are listed here.\nz  Panda3D is a script-based engine.\nThe engine’s primary interface is the \n3D games and virtual worlds convenient and fast.\nz  Yake is a relatively new fully featured game engine built on top of \nz  Crystal Space is a game engine with an extensible modular architecture.\nz  Torque and  Irrlicht are also well-known and widely used engines.\nRuntime Engine Architecture\nA game engine generally consists of a tool suite and a  runtime component.\ntypical 3D game engine.\nGame engines are deﬁ nitely large soft ware systems.\nLike all soft ware systems, game engines are built in layers.\nThis is especially true for a large-scale system like a game \nengine.\nRuntime Engine Architecture\nDynamic Game \nHigh-Level Game Flow System/FSM\nGame-Specific \nIn-Game Menus \nEngine Config\nResources (Game Assets)\nGame \nGame-Specific \nGame Mgmt.\nGame State \nIn-Game Menus\nIn-Game GUI\nIn-Game Cinematics \nGAME-SPECIFIC SUBSYSTEMS\nGame-Specific Rendering\nGame Cameras\n(Engine Interface)\nRuntime game engine architecture.\ncomputer system or console on which the game will run.\nPlayStation Portable (PSP), and PLAYSTATION 3, and Nintendo’s DS, Game-\nware resources and shield the operating system and upper engine layers from \ngame.\na PC game can never assume it has full control of the hardware—it must “play \nRuntime Engine Architecture\ncompiled directly into your game executable.\nOn a console, the game typically \ntem on these consoles can interrupt the execution of your game, or take over \nplayer to pause the game and bring up the PS3’s Xross Media Bar or the Xbox \nMost game engines leverage a number of third-party  soft ware development \nLike any soft ware system, games depend heavily on collection data structures \nGame developers are divided on the question of whether to use template \nlibraries like STL in their game engines.\nSTL unusable in a game.\ngo far wrong doing the same on a PC game project either.)\nMost game rendering engines are built on top of a hardware interface library, \nz  OpenGL is a widely used portable 3D graphics SDK.\nz  DirectX is Microsoft ’s 3D graphics SDK and primary rival to OpenGL .\nz  libgcm is a low-level direct interface to the PLAYSTATION 3’s RSX graph-\nz  Edge is a powerful and highly-eﬃ  cient rendering and animation engine \nby a number of ﬁ rst- and third-party game studios.\nin the game development community) are provided by the following well-\nknown SDKs. z  Havok is a popular industrial-strength physics and collision engine.\nz  PhysX is another popular industrial-strength physics and collision en-\nz  Open Dynamics Engine (ODE) is a well-known open source physics/col-\nRad Game Tools’ popular Granny toolkit includes robust 3D \nz  Havok Animation .\na powerful and eﬃ  cient animation engine and an eﬃ  cient geometry-\nprocessing engine for rendering.\ntom manner for each game.\nRuntime Engine Architecture\ngames and other forms of digital media.\nMost game engines are required to be capable of running on more than one \nfor example, always target their games at a wide variety of platforms, because \nit exposes their games to the largest possible market.\nTypically, the only game \nstudios that do not target at least two diﬀ erent platforms per game are ﬁ rst-\nmost game engines are architected with a  platform independence layer, like \nating system, and other third-party soft ware and shields the rest of the engine \nEvery game engine, and really every large, complex C++ soft ware application, \nof the game.\nz  Memory management.\nVirtually every game engine implements its own \nGames are by their nature highly mathematics-intensive.\nsuch, every game engine has at least one, if not many, math libraries.\ntions, and whatever other facilities the game programmers require.\nUnless an engine’s designers de-\nA detailed discussion of the most common core engine systems can be \nPresent in every game engine in some form, the  resource manager provides \ngame assets and other engine input data.\nSome engines do this in a highly \nit up to the game programmer to directly access raw ﬁ les on disk or within \nRuntime Engine Architecture\nEngine Config\nCore engine systems.\nLow-level rendering engine.\nResources (Game Assets)\nGame \nRendering Engine\nThe  rendering engine is one of the largest and most complex components of \nany game engine.\nOne common and eﬀ ective approach to rendering engine design is to em-\nFor a PC game engine, you also need code to integrate your renderer with \nThis ties the game’s keyboard poll-\nThe low-level renderer usually provides a viewport abstraction with an \nalso manages the state of the graphics hardware and the game’s shaders via \nFor very small game worlds, a simple frustum  cull (i.e., removing objects \nFor larger game \nRuntime Engine Architecture\nmight also be applied in this layer of the rendering engine.\nThis permits diﬀ erent game \nsystem that is speciﬁ c to the needs of each team’s game.\nOGRE 3D open source rendering engine (htt p://www.ogre3d.org) is a great \nGame developers can either select from a number of pre-\nModern game engines support a wide range of  visual eﬀ ects , as shown in \nz full-screen  post eﬀ ects , applied aft er the 3D scene has been rendered to \nIt is common for a game engine to have an eﬀ ects system component that \nof the rendering engine and act as inputs to the low-level renderer .\nhandled internally within the rendering engine proper.\nMost games employ some kind of 2D graphics  overlaid on the 3D scene for \nz the game’s heads-up display (HUD);\nz in-game menus, a console, and/or other development tools, which may or \nz possibly an in-game  graphical user interface (GUI), allowing the player to \nperform other complex in-game tasks.\nRuntime Engine Architecture\nIn-Game Menus\nIn-Game GUI\nIn-Game Cinematics \nearlier (either rendered with the game’s rendering engine or using another \nA related system is the  in-game cinematics (IGC) system.\ntypically allows cinematic sequences to be choreographed within the game it-\nbetween two key characters might be implemented as an in-game cinematic.\nsubtly integrated into the game without the human player even realizing that \nGames are real-time systems and, as such, game engineers oft en need to proﬁ le \nthe performance of their games in order to optimize performance.\n1.23, encompasses these tools and also includes in-game debugging facilities, \nsuch as  debug drawing, an  in-game menu system or console, and the ability to \nHowever, most game engines also incorporate a suite of custom proﬁ ling \nz a facility for displaying the proﬁ ling statistics on-screen while the game \nz a facility for determining how much memory is being used by the en-\nwhen the game terminates and/or during gameplay;\nIn-Game Menus \nRuntime Engine Architecture\nz the ability to record game events and then play them back.\nCollision detection is important for every game.\nSome games also include a realistic or semi-realistic \nWe call this the “physics system” in the game industry, \ngame companies write their own collision /physics engine.\nparty SDK is typically integrated into the engine.\nz  PhysX by NVIDIA is another excellent collision and dynamics engine.\nIt was integrated into Unreal Engine 3 and is also available for free as \na standalone product for PC game development.",
      "keywords": [
        "Game Engine",
        "game",
        "Engine",
        "Unreal Engine",
        "Game Engine Survey",
        "Runtime Engine Architecture",
        "rendering engine",
        "Engine Architecture",
        "system",
        "game rendering engines",
        "game engine architecture",
        "Runtime Engine",
        "game world",
        "Runtime game engine",
        "Open Source Engines"
      ],
      "concepts": [
        "game",
        "gaming",
        "engine",
        "rendering",
        "render",
        "animation",
        "animator",
        "animations",
        "layers",
        "layered"
      ],
      "similar_chapters": [
        {
          "book": "Game_Engine_Architecture",
          "chapter": 1,
          "title": "",
          "score": 0.552,
          "base_score": 0.552,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 4,
          "title": "",
          "score": 0.532,
          "base_score": 0.532,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 17,
          "title": "",
          "score": 0.503,
          "base_score": 0.503,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 37,
          "title": "",
          "score": 0.5,
          "base_score": 0.5,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 2,
          "title": "",
          "score": 0.491,
          "base_score": 0.491,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "engine",
          "games",
          "engine architecture",
          "runtime engine",
          "engines"
        ],
        "semantic": [],
        "merged": [
          "engine",
          "games",
          "engine architecture",
          "runtime engine",
          "engines"
        ]
      },
      "topic_id": null,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.3473584666680245,
        "topic_boost": 0.0,
        "timestamp": "2025-12-17T23:05:57.759166+00:00"
      }
    },
    {
      "chapter_number": 4,
      "title": "Segment 4 (pages 64-82)",
      "start_page": 64,
      "end_page": 82,
      "summary": "Any game that has organic or semi-organic characters (humans, animals, car-\nbasic types of animation used in games:\nz rigid body hierarchy animation,\nz skeletal animation,\nz vertex animation, and\nSkeletal animation permits a detailed 3D character mesh to be posed by \nanimation are used in some engines, skeletal animation is the most prevalent \nanimation method in games today; as such, it will be our primary focus in this \nGame-Specific \nEvery game needs to process input from the player, obtained from various \nz other specialized game controllers, like steering wheels, ﬁ shing rods, \nlow-level details of the game controller(s) on a particular hardware platform \nfrom the high-level game controls.\nand logical game functions.\nGame-Specific \nAudio is just as important as graphics in any game engine.\naudio oft en gets less att ention than rendering, physics, animation, AI, and \n(In fact, I’ve known quite a few game programmers \ndio engines are prett y basic, and game teams usually augment them with \nvides a powerful 3D audio engine called  Scream, which has been used on \nHowever, even if a game team uses a pre-existing audio engine, every game \nMany games permit multiple human players to play within a single virtual \nMultiplayer games come in at least four basic ﬂ avors.\namples of this style of multiplayer gaming include Smash Brothers, Lego \ntual world, with multiple HIDs att ached to a single game machine, but \nz Massively multiplayer online games (MMOG).\nMultiplayer games are quite similar in many ways to their single-player \nimpact on the design of certain game engine components.\nThe game world \nobject model, renderer, human input device system, player control system, \nStill, many game teams have done it successfully.\nplayer game into a single-player game—is typically trivial.\nIn fact, many game \nengines treat single-player mode as a special case of a multiplayer game, in \nThe term  gameplay refers to the action that takes place in the game, the rules \nthat govern the virtual world in which the game takes place, the abilities of \nGame-\nsystems that we’ve discussed thus far, most game engines introduce a layer \nDynamic Game \nHigh-Level Game Flow System/FSM\nGame Mgmt.\nGame State \ngame-speciﬁ c logic can be implemented conveniently.\nGame Worlds and Object Models\nThe gameplay foundations layer introduces the notion of a  game world, con-\ntypes that make up a game is called the  game object model.\nThe game object \nin the virtual game world.\nTypical types of game objects include\nz player characters (PC);\nThe game world model is intimately tied to a  soft ware object model, and \nIn the context of game engines, \nz Is your game engine designed in an object-oriented manner?\nz How are objects referenced?\nz How are the lifetimes of game objects managed?\nz How are the states of the game objects simulated over time?\nWe’ll explore soft ware object models and game object models in consider-\nGame objects invariably need to communicate with one another.\nMany game engines employ a  scripting language in order to make develop-\nment of game-speciﬁ c gameplay rules and content easier and more rapid.\nWithout a scripting language, you must recompile and relink your game ex-\nengine.\nto game logic and data can be made by modifying and reloading the script \nSome engines allow script to be reloaded while the game continues to \nOther engines require the game to be shut down prior to script recompi-\nbe if you had to recompile and relink the game’s executable.\ngame-speciﬁ c soft ware—it was usually not considered part of the game en-\nKynapse , which acts as an “AI foundation layer” upon which game-speciﬁ c \nz a path-ﬁ nding engine based on the well-known A* algorithm;\nz hooks into the collision system and world model, for line-of-sight (LOS) \nz a custom world model which tells the AI system where all the entities of \nGame-Speciﬁ c Subsystems\nOn top of the gameplay foundation layer and the other low-level engine com-\nfeatures of the game itself.\nvaried, and speciﬁ c to the game being developed.\nplayer character, various in-game camera systems, artiﬁ cial intelligence for \nGAME-SPECIFIC SUBSYSTEMS\nGame-Specific Rendering\nGame Cameras\n(Engine Interface)\nGame-speciﬁ c subsystems.\ngame, it would lie between the game-speciﬁ c subsystems and the gameplay \nAt least some game-speciﬁ c knowledge invariably seeps down through the \nengine itself.\nAny game engine must be fed a great deal of data, in the form of  game assets, \ngame assets typically found in modern game engines.\nassets all the way through to the game engine itself.\nGames are multimedia applications by nature.\nA game engine’s input data \nanimation data to audio ﬁ les.\n3D meshes and animation data.\nSome types of game data cannot be created using an oﬀ -\nFor example, most game engines provide a custom editor \nfor laying out game worlds.\ntools for  game world layout.\nI’ve seen game teams use 3ds Max or Maya as a \ngame developers, and they’ll tell you they can remember a time when they \ngame team is going to be able to develop a highly polished product in a timely \nGame World\nGame \nGame Object \nGame Obj.\nGame \nGame \nGAME\nGame \nly suitable for direct use in-game.\ncomplex than what the game engine requires.\ngame engine typically only needs a tiny fraction of this information in \norder to render the model in-game.\n2. The DCC application’s ﬁ le format is oft en too slow to read at run time, \ncessible standardized format, or a custom ﬁ le format, for use in-game.\nther processed before being sent to the game engine.\nAnd if a game studio \nis shipping its game on more than one platform, the intermediate ﬁ les might \nThe pipeline from DCC app to game engine is sometimes called the asset \nEvery game engine has this in some form.\nThe visible geometry you see in a game is typically made up of two kinds of \nthe game world editor.\nz accessible to game designers—oft en used to “block out” a game level for \nz cannot support articulated objects or animated characters.\nposite object that may contain multiple meshes, plus animation data and other \nmetadata for use by the game.\nsemi-standard export formats, although none are perfectly suited for game \nTherefore, game \nteams oft en create custom ﬁ le formats and custom exporters to go with \nSkeletal Animation Data\nIn order to render a skeletal mesh , the game engine requires three distinct \nHowever, some game engines allow \na bank of animations to be exported as a single ﬁ le, and some even lump the \nmesh, skeleton, and animations into one monolithic ﬁ le.\nThus animation data \nmat for game-ready animation data.\nModern games make use of complex particle eﬀ ects.\nas  Houdini, permit ﬁ lm-quality eﬀ ects to be authored; however, most game \nFor this reason, many game companies create a custom \nwill appear in-game.\nGame World Data and the World Editor\nThe  game world is where everything in a game engine comes together.\nknowledge, there are no commercially available  game world editors (i.e., the \ngame world equivalent of Maya or Max).\navailable game engines provide good world editors.\nz Some variant of the  Radiant game editor is used by most game engines \nz The Half-Life 2 Source engine provides a world editor called  Hammer;\nz  UnrealEd is the Unreal Engine’s world editor.\nserves as the asset manager for all data types that the engine can con-\npart of any good game engine.\nA game engine’s tool suite may be architected in any number of ways.\nSome tools might be built into the game itself.\nFor example, Quake - and Unreal -based games both boast an in-game console \ncommands while running the game.\nmanager, UnrealEd , is built right into the runtime game engine.\neditor, you run your game with a command-line argument of “editor.” This \nRun-Time Engine\ndata structure – one for the runtime engine and one for the tools.\nthat running the game from within the editor is very fast (because the game \nLive in-game editing, a feature that is normally \na part of the game.\nFor example, when the engine is crashing, the tools become \nRun-Time Engine\nTools built on a framework shared with the game.\nRun-Time Engine\nChapter 2, we’ll explore the tools used by the majority of professional game \nengineers.\nGame development is one of the most demanding and broad areas of soft -\nA version control system is a tool that permits multiple users to work on a \ner, version control can be used for other kinds of ﬁ les as well.\nHowever, many game studios use a single version control system to \nmanage both source code ﬁ les (which are text) and game assets like textures, \n3D meshes, animations, and audio ﬁ les (which are usually binary).\nz provides a central repository from which engineers can share source \nz keeps a history of the changes made to each source ﬁ le;\nz provides mechanisms allowing speciﬁ c versions of the code base to be \nz permits versions of the code to be branched oﬀ  from the main develop-\nA source control system can be useful even on a single-engineer project.\nduring your career as a game engineer.\nSubversion is an open source version control system aimed \nz  Git. This is an open source revision control system that has been \ngit development model, the programmer makes changes to ﬁ les and \nPerforce is used by many game companies, including Naughty \nsystem designed explicitly for the game industry.\ncode ﬁ les and binary game art assets, with a customizable user interface \npackage that has been used successfully on some game projects.\nSubversion, like most other version control systems, employs a client-",
      "keywords": [
        "game",
        "game engine",
        "Engine",
        "game world",
        "control system",
        "Game Object",
        "Version control systems",
        "source control system",
        "Game Object Model",
        "system",
        "Tools",
        "Animation",
        "world",
        "Version Control",
        "data"
      ],
      "concepts": [
        "game",
        "engines",
        "engineering",
        "animation",
        "animals",
        "animator",
        "animated",
        "animations",
        "tool",
        "object"
      ],
      "similar_chapters": [
        {
          "book": "Game_Engine_Architecture",
          "chapter": 20,
          "title": "",
          "score": 0.582,
          "base_score": 0.432,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 1,
          "title": "",
          "score": 0.533,
          "base_score": 0.533,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 3,
          "title": "",
          "score": 0.532,
          "base_score": 0.532,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 31,
          "title": "",
          "score": 0.49,
          "base_score": 0.49,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 30,
          "title": "",
          "score": 0.489,
          "base_score": 0.489,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "engine",
          "world",
          "animation",
          "game speciﬁ",
          "version control"
        ],
        "semantic": [],
        "merged": [
          "engine",
          "world",
          "animation",
          "game speciﬁ",
          "version control"
        ]
      },
      "topic_id": 6,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.32914630961571634,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:57.759204+00:00"
      }
    },
    {
      "chapter_number": 5,
      "title": "Segment 5 (pages 83-102)",
      "start_page": 83,
      "end_page": 102,
      "summary": "lay icons to show you the status of your version-controlled ﬁ les and folders.\nInstall it by double-clicking the .msi ﬁ le \nGoogle Code), create a folder on your local hard disk and then right-click \nwhere myprojectname is whatever you named your project when you ﬁ rst cre-\nGoogle Code home page, Project Hosting link.\nThe server maintains a version history for each ﬁ le, as shown \nsion-controlled ﬁ le.\ncal version of each ﬁ le and the latest version of that same ﬁ le in the repository.\na line-by-line comparison of the two versions of the ﬁ le.\non any ﬁ le in the TortoiseSVN Commit dialog (Figure 2.6) to see the diﬀ s be-\nFiles that have changed (i.e., any ﬁ les that “have diﬀ s”) are committ ed.\ning a new entry to the ﬁ le’s version history.\nAny ﬁ les that have not changed \nIf you created any new ﬁ les prior to the commit, they will be listed as \nAny ﬁ les that you deleted \nyou and others on your team will know why these ﬁ les were checked in.\nmust ﬁ rst indicate your intentions to modify a ﬁ le by checking it out and lock-\nThe ﬁ le(s) that are checked out to you are writable on your local disk \nAll other ﬁ les in the repository are \nOnce you’re done editing the ﬁ le, you can check \nThe process of exclusively locking ﬁ les for editing ensures \nthat no two people can edit the same ﬁ le simultaneously.\nsystems also permit  multiple check-out.; i.e., you can be editing a ﬁ le while \nsomeone else is editing that same ﬁ le.\nted ﬁ rst become the latest version of the ﬁ le in the repository.\nﬁ le, the version control system must  merge the changes in order to produce a \nﬁ nal version of the ﬁ le.\nthen your edits would have been to a diﬀ erent range of lines in the ﬁ le than \nenough to keep track of which version of each ﬁ le you currently have on your \nThat way, when you merge the ﬁ les, the system will know which ver-\nto check out ﬁ les explicitly at all.\nYou simply start editing the ﬁ les locally—all \nﬁ les are writable on your local disk at all times.\nmine which ﬁ les you have changed, Subversion must search the entire tree of \nsource ﬁ les, which can be slow.\nexplicitly keep track of which ﬁ les you have modiﬁ ed, are usually easier to \nhas changed the ﬁ le since you last updated your local copy, then your changes \nyour commits carefully to be sure you aren’t committ ing any ﬁ les that you \nyou can double-click on an individual ﬁ le in order to see the diﬀ s you made \nWhen a ﬁ le is deleted from the repository, it’s not really gone.\nThe ﬁ le still ex-\nusers will no longer see the ﬁ le in their local directory trees.\nand access previous versions of a deleted ﬁ le by right-clicking on the folder in \nwhich the ﬁ le was contained and selecting “Show log” from the TortoiseSVN \nYou can undelete a deleted ﬁ le by updating your local directory to the \nversion immediately before the version in which the ﬁ le was marked deleted.\nThen simply commit the ﬁ le again.\nthe ﬁ le with the version just prior to the deletion, eﬀ ectively undeleting the \nﬁ le.\ntransform source code into an executable program.\nA program writt en in C++ is comprised of  source ﬁ les.\nSource ﬁ les are technically known as  translation units, because the com-\npiler translates one source ﬁ le at a time from C++ into machine code.\nA special kind of source ﬁ le, known as a  header ﬁ le, is oft en used in order to \nHeader ﬁ les are not seen by the compiler.\nsponding header ﬁ le prior to sending the translation unit to the compiler.\nHeader ﬁ les exist as distinct \nﬁ les from the point of view of the programmer—but thanks to the preproces-\nsor’s header ﬁ le expansion, all the compiler ever sees are translation units.\nWhen a translation unit is compiled, the resulting machine code is placed in \nan  object ﬁ le (ﬁ les with a .obj extension under Windows, or .o under UNIX-\nThe machine code in an object ﬁ le is\nObject ﬁ les can be collected into groups called libraries.\nan archive, much like a Zip or tar ﬁ le, containing zero or more object ﬁ les.\nbraries exist merely as a convenience, permitt ing a large number of object ﬁ les \nto be collected into a single easy-to-use ﬁ le.\nObject ﬁ les and libraries are linked into an  executable by the linker.\nexecutable ﬁ le contains fully resolved machine code that can be loaded and \nz to calculate the ﬁ nal relative addresses of all the machine code, as it will \nby each translation unit (object ﬁ le) are properly resolved.\nIt’s important to remember that the machine code in an executable ﬁ le is still \nrelocatable, meaning that the addresses of all instructions and data in the ﬁ le \nThe executables that use a DLL contain partially linked machine code.\nof the function and data references are fully resolved within the ﬁ nal execut-\na project is a collection of source ﬁ les which, when compiled, produce a library, \nProjects are stored in project ﬁ les with a .vcproj ex-\nand Visual Studio 2008 (version 9), .vcproj ﬁ les are in XML format, so they are \nsolution ﬁ les (ﬁ les with a .sln extension) as a means of containing and manag-\ndependent projects intended to build one or more libraries, executables and/\nSource ﬁ les and headers are shown as \nhave nothing to do with the folder structure in which the ﬁ les may reside \nBuild Conﬁ gurations\nnamed foo.cpp, output the result to an object ﬁ le named foo.obj (/Fo foo.obj), \nA build conﬁ guration is really just \nﬁ gurations, name them whatever you want, and conﬁ gure the preprocessor, \ncompiler, and linker options diﬀ erently in each conﬁ guration.\ntell which .cpp ﬁ les have custom sett ings and which do not.)\nMost projects have at least two build conﬁ gurations, typically called \n“Debug” and “Release.” The release build is for the ﬁ nal shipping soft ware, \nwhile the debug build is for development purposes.\nA debug build runs more \nbuild conﬁ gurations for a game engine project.\nThe C++ preprocessor handles the expansion of #included ﬁ les and the deﬁ -\nvia command-line options (and hence via build conﬁ gurations).\nﬁ ned in this way act as though they had been writt en into your source code \nple, the symbol _DEBUG is always deﬁ ned for a debug build, while in release \ncompilers when compiling a C++ ﬁ le.\npiler should include  debugging information with the object ﬁ les it produces.\nSo, it is always stripped from the ﬁ nal shipping version of your \nall optimizations are usually turned oﬀ  in a debug build.\noutput ﬁ le to produce—an executable or a DLL.\nbug libraries when building a debug executable and with optimized libraries \nTypical Build Conﬁ gurations\nGame projects oft en have more than just two build conﬁ gurations.\nA debug build is a very slow version of your program, with all \nA  release build is a faster version of your program, but with \nA production conﬁ guration is intended for building the ﬁ nal \nSome game studios utilize code libraries that are shared between \nprocessor macro (e.g., TOOLS_BUILD) that informs the code that it is be-\nA  hybrid build is a build conﬁ guration in which the majority of the translation \nbuild which permits users to specify the use of debug mode on a per-transla-\n$HYBRID_SOURCES, which lists the names of all translation units (.cpp ﬁ les) \nthat should be compiled in debug mode for our hybrid build.\nrules for compiling both debug and release versions of every translation unit, \nand arrange for the resulting object ﬁ les (.obj/.o) to be placed into two diﬀ er-\nThe ﬁ nal link rule is set up to \nlink with the debug versions of the object ﬁ les listed in $HYBRID_SOURCES\nand with the release versions of all other object ﬁ les.\nthe translation units that we want to build in debug mode.\nbuild conﬁ guration at the solution level, which picks and chooses between \ndebug and release builds on a per-project (and hence per-library) basis.\nBuild Conﬁ gurations and Testability\nThe more build conﬁ gurations your project supports, the more diﬃ  cult test-\nTherefore, each build conﬁ guration must be \nbuilds, because the debug conﬁ guration is primarily intended for internal use \nz Conﬁ guration Properties/Debugging,\nsett ings should of course be diﬀ erent between debug and release builds.\nOn the General tab, shown in Figure 2.10, the most useful ﬁ elds are the fol-\nThis deﬁ nes where the ﬁ nal product(s) of the build will \nThis deﬁ nes where intermediate ﬁ les, primarily \nobject ﬁ les (.obj extension), are placed during a build.\nIntermediate ﬁ les \nduring the process of building your executable, library, or DLL.\nit is a good idea to place intermediate ﬁ les in a diﬀ erent directory than \nthe ﬁ nal products (.exe, .lib or .dll ﬁ les).\nthat can be referred to in your project conﬁ guration sett ings.\nThe name of the ﬁ nal executable, library, or DLL \nﬁ le being built by this project.\nThe full path of the folder containing the ﬁ nal execut-\non the build conﬁ guration, so using them can permit you to use identical set-\nclick the litt le arrow to the right of the text ﬁ eld, select “Edit…” and then click \nhow your source ﬁ les will be compiled into object ﬁ les (.obj extension).\nsett ings on this page do not aﬀ ect how your object ﬁ les are linked into a ﬁ nal \nThis ﬁ eld lists the on-disk directories that \nwill be searched when looking for #included header ﬁ les.\nThis ﬁ eld controls whether or not debug \nThe ﬁ nal production build will \ncode when it is compiled.\nThe “Linker” tab lists properties that aﬀ ect how your object code ﬁ les will be \nﬁ nal product of the build, usually an executable or DLL.\nsearched when looking for libraries and object ﬁ les to link into the ﬁ nal \nThis ﬁ eld lists external libraries that you \nlibraries you’re actually linking to in the “Additional Dependencies” ﬁ eld.\nready works, I’ll oft en just copy that .vcproj ﬁ le and then modify it as neces-\nYou simply copy the .vcproj ﬁ le \nOne caveat when copying project ﬁ les is that the name of the project is \nstored inside the .vcproj ﬁ le itself.\nﬁ rst time in Visual Studio 2005, it will still have the original name.\nthat the project creates is speciﬁ ed explicitly in the .vcproj ﬁ le.\n“$(OutDir)\\MyGame.exe.” In this case, you’ll need to open the .vcproj ﬁ le \nProject ﬁ les are XML, so you \ncan rename your copied .vcproj ﬁ le to have an “.xml” extension and then open \nput ﬁ les in your project.\ncally be reﬂ ected in the name of the output executable ﬁ le.\nI should mention that using a text editor to manipulate .vcproj ﬁ les is not \nof your graphics header ﬁ les to a new path on disk.\nC/C++ tab, and ﬁ nally update the include path manually, it’s much easier and \nless error-prone to edit the ﬁ les as XML text and do a search-and-replace.\ncan even do a “Replace in ﬁ les” operation in Visual Studio for mass edits.\nDebugging Your Code\nHowever, you can usually ﬁ nd an equivalent to Visual Studio’s \neven if you don’t use Visual Studio to debug your code.\nA Visual Studio solution can contain more than one project.\nprojects build executables, while others build libraries or DLLs. It’s possible \nto have more than one project that builds an executable in a single solution.\nVisual Studio provides a sett ing known as the “Start-Up Project.”  This is the \nstart-up project (if the start-up project builds an executable).\nHitt ing F11 steps into a function call (i.e., the next line of code \nyou’ll see is the ﬁ rst line of the called function), while F10 steps over that func-",
      "keywords": [
        "Visual Studio",
        "Microsoft Visual Studio",
        "Build Conﬁ gurations",
        "Visual Studio project",
        "Build Conﬁ",
        "code",
        "conﬁ guration",
        "Studio",
        "Visual",
        "build",
        "version",
        "les",
        "conﬁ",
        "project",
        "Microsoft Visual"
      ],
      "concepts": [
        "versions",
        "project",
        "code",
        "coded",
        "build",
        "debugging",
        "debug",
        "compiled",
        "compile",
        "libraries"
      ],
      "similar_chapters": [],
      "enriched_keywords": {
        "tfidf": [
          "les",
          "le",
          "build",
          "build conﬁ",
          "conﬁ"
        ],
        "semantic": [],
        "merged": [
          "les",
          "le",
          "build",
          "build conﬁ",
          "conﬁ"
        ]
      },
      "topic_id": null,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.04066504036783759,
        "topic_boost": 0.0,
        "timestamp": "2025-12-17T23:05:57.759233+00:00"
      }
    },
    {
      "chapter_number": 6,
      "title": "Segment 6 (pages 103-120)",
      "start_page": 103,
      "end_page": 120,
      "summary": "The base class of a class is always \nshown as the ﬁ rst child of an instance of a derived class.\ninspect not only the class’ data members, but also the data members of its base \nclass(es).\nYou can type virtually any valid C/C++ expression into the watch window, \ndisplay “8.” You can cast variables from one type to another by using C or C++ \nYou can even call functions in your program from within the watch window.\nVisual Studio re-evaluates the expressions typed into the watch window(s) \ncalled every time you hit a break point or single-step your code.\nFor example, let’s say that your game engine provides a function called \nYou can call this function in the watch window in order to easily in-\nz The “,d” suﬃ  x forces values to be displayed in decimal notation.\nz The “,x” suﬃ  x forces values to be displayed in hexadecimal notation.\nData Break Points\nRegular break points trip when the CPU’s program counter hits a particular \nture of modern debuggers is the ability to set a break point that trips when-\never a speciﬁ c memory address is writt en to (i.e., changed).\ndata break points, because they are triggered by changes to data, or sometimes \nmemory address is writt en to.\nHere’s how data break points are typically used.\ning inside a member variable of a particular object called m_angle that should \n(You can just type “&object.m_angle” into the watch window to \nﬁ nd its address.) To track down the culprit, you can set a data break point on \nthe address of object.m_angle, and then simply let the program run.\nTo set a data break point in Visual Studio, take the following steps.\nz Type in the raw address or an address-valued expression, such as \nand hit counts on any type break point—data break points or regular line-of-\ncode break points.\nA  conditional break point causes the debugger to evaluate the C/C++ expres-\nsion you provide every time the break point is hit.\nIf the expression is false, the break point is ignored and the program contin-\nThis is very useful for sett ing break points that only trip when a function \nis called on a particular instance of a class.\nDeﬁ ning a data break point.\nThe Visual Studio break points window.\nthe class instance whose memory address (this pointer) is 0x12345678.\nSpecifying a  hit count for a break point causes the debugger to decrement \na counter every time the break point is hit, and only actually stop the program \nOne note of caution: Conditional break points cause the debugger to eval-\nuate the conditional expression every time the break point is hit, so they can \nbuild, due primarily to the way the compiler optimizes the code.\nables and dynamically allocated memory blocks are oft en set to zero in debug \nrelease build (e.g., when important code is erroneously placed inside an asser-\noptimizer itself, causing it to emit incorrect code in a fully optimized build.\npain of debugging optimized code is to practice doing it and to expand your \ncode is currently being executed.\nfunction when viewed in source code mode.\nz Use registers to deduce variables’ values or addresses.\na register, you can oft en discover its value or its address by inspecting \nz Inspect variables and object contents by address.\naddress to the appropriate type in a watch window.\nknow that an instance of the Foo class resides at address 0x1378A0C0, we \ncan type “(Foo*)0x1378A0C0” in a watch window, and the debugger \nwill interpret that memory address as if it were a pointer to a Foo object.\nexample, if we want to ﬁ nd the address of an internal object within the \nz Modify the code.\nily, consider modifying the source code to help you debug the problem.\nAdd code to detect a problem condition or to isolate a \nparticular instance of a class.\nProﬁ ling Tools\nGames are typically high-performance real-time programs.\ngine programmers are always looking for ways to speed up their code.\nProﬁ ling Tools\nSo, how do you know which 10% of your code to optimize?\nA proﬁ ler is a tool that measures the execution time of your \ncode.\nSome proﬁ lers also tell you how many times each function is called.\nFor example, a function that runs an A* algorithm to compute the \nproﬁ lers report the call graph, meaning that for any given function, you can \nsee which functions called it (these are known as parent functions) and which \neven see what percentage of the function’s time was spent calling each of its \nand epilogue code into every function.\ncalls into a proﬁ ling library, which in turn inspects the program’s call \ncalled the function in question and how many times that parent has \nline of code in your source program, allowing it to report how long each \nPlus tool suite, is an excellent instrumenting proﬁ ler.\nThere are a great many proﬁ ling tools available.\nTwo other problems that plague C and C++ programmers are  memory leaks \na nonzero integer or ﬂ oating-point value, it becomes a dangerous tool for cor-\nrupting memory, because data writt en through it can quite literally end up \nClearly good coding practices are one approach to avoiding pointer-re-\ntions made by your code.\nWhen you run your code under Purify, you get a \nproblem is linked directly to the source code that caused the problem, making \nmore information on Purify at htt p://www-306.ibm.com/soft ware/awdtools\nThere are a number of other commonly used tools in a game programmer’s \nz Diﬀ erence tools.\nA diﬀ erence tool, or diﬀ  tool, is a program that com-\n(See htt p://en.wikipedia.org/wiki/Diﬀ  for a discussion of \ntheir version control soft ware to use the tool of their choice.\npendent websites as well), and the GNU diﬀ  tools package (htt p://www.\nz  Three-way merge tools.\nis called a three-way merge tool.\nSome popular merge tools include AraxisMerge (htt p://www.arax-\nan excellent three-way merge tool (htt p://www.perforce.com/perforce/\non  object-oriented programming (e.g., [5]) and C++ in particular (e.g., [39] and \nClasses and Objects\nA  class is a collection of att ributes (data) and behaviors (code) which together \ndividual instances of the class, known as objects, should be constructed.\nexample, your pet Rover is an instance of the class “dog.” Thus there is a one-\nto-many relationship between a class  and its instances.\nneed only understand the class’ limited interface, not the potentially intricate \nInheritance allows new classes to be deﬁ ned as extensions to pre-existing class-\nThe new class modiﬁ es or extends the data, interface, and/or behavior of \nthe existing class.\nIn this relationship, the class Parent is \nknown as the base class or superclass, and the class Child is the derived class \nships between classes.\nInheritance creates an “is-a” relationship between classes.\nit would probably make sense to derive our Circle class from a base class \ncalled Shape.\nWe can draw diagrams of class hierarchies using the conventions deﬁ ned \nThe inheritance arrow points from child class to parent.\nSome languages support multiple inheritance (MI), meaning that a class can \nhave more than one parent class.\nbecause multiple inheritance transforms a simple tree of classes into a poten-\nA class graph can have all sorts of problems that never \norg/wiki/Diamond_problem), in which a derived class ends up containing two \ncopies of a grandparent base class (see Figure 3.2).\nSuch classes are sometimes called mix-in classes \nclass that adds animation\nfunctionality to whatever class it\nExample of a mix-in class.\nbecause they can be used to introduce new functionality at arbitrary points in a \nclass tree.\nSee Figure 3.3 for a somewhat contrived example of a  mix-in class.\nPolymorphism is a language feature that allows a collection of objects of diﬀ er-\nneous, from the point of view of the code using the interface.\nshapes is to use a switch statement to perform diﬀ erent drawing commands \nsimple example, but as our code grows in size and complexity, it can become \ntype is added, one must ﬁ nd every place in the code base where knowledge \ndeﬁ ne classes for each of the types of shapes we wish to support.\nclasses would inherit from the common base class Shape.\ncalled Draw(), and each distinct shape class would implement this function \nWithout “knowing” what speciﬁ c types of shapes it has \nbeen given, the drawing function can now simply call each shape’s Draw()\ntween classes.\nWe have a class Window that represents any rectan-\nWe also have a class called Rectangle that encapsulates \nthe Window class from the Rectangle class (using an “is-a” relationship).\nin a more ﬂ exible and well-encapsulated design, the Window class would refer \nIn object-oriented programming, a number of common de-\nThis patt ern ensures that a particular class has only one in-\ncrete classes.\nCoding Standards: Why and How Much?\nDiscussions of coding conventions among engineers can oft en lead to heated \n1. Some standards make the code more readable, understandable, and \nFor example, a coding standard might encourage the \nnames that map directly to the purpose of the class, function, or vari-\nUse C++ namespaces or a common \nz Follow C++ best practices.\ncode that is writt en in a way that makes common programming errors \nData, Code, and Memory in C/C++\nvalued numbers need to be stored in the computer’s memory.",
      "keywords": [
        "Visual Studio",
        "break point",
        "Data Break Points",
        "code",
        "watch window",
        "shape",
        "data",
        "Data Break",
        "draw shape",
        "Visual Studio break",
        "function",
        "memory",
        "Studio break points",
        "Proﬁ",
        "Tools"
      ],
      "concepts": [
        "classes",
        "code",
        "coding",
        "data",
        "memory",
        "tools",
        "program",
        "programming",
        "inheritance",
        "inherited"
      ],
      "similar_chapters": [
        {
          "book": "Game_Engine_Architecture",
          "chapter": 8,
          "title": "",
          "score": 0.591,
          "base_score": 0.441,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 13,
          "title": "",
          "score": 0.57,
          "base_score": 0.42,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 12,
          "title": "",
          "score": 0.489,
          "base_score": 0.339,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 36,
          "title": "",
          "score": 0.437,
          "base_score": 0.437,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 37,
          "title": "",
          "score": 0.416,
          "base_score": 0.416,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "class",
          "break",
          "break point",
          "code",
          "break points"
        ],
        "semantic": [],
        "merged": [
          "class",
          "break",
          "break point",
          "code",
          "break points"
        ]
      },
      "topic_id": 2,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.2891536886000646,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:57.759268+00:00"
      }
    },
    {
      "chapter_number": 7,
      "title": "Segment 7 (pages 121-141)",
      "start_page": 121,
      "end_page": 141,
      "summary": "Data, Code, and Memory in C/C++\nbit unsigned integer, we simply encode the value using binary notation (see \nThe range of possible values for a 32-bit unsigned integer is 0x00000000 \nTo represent a signed integer in 32 bits, we need a way to diﬀ erentiate be-\nthe most signiﬁ cant bit as a sign bit—when this bit is zero the value is positive, \npossible with simple sign bit (positive zero and negative zero).\nto represent the whole part of the number, and the rest of the bits are used \nmost signiﬁ cant bit to the least signiﬁ cant bit), the magnitude bits represent \ndecreasing powers of two (…, 16, 8, 4, 2, 1), while the fractional bits represent \nnumber –173.25 in 32-bit ﬁ xed-point notation, with one sign bit, 16 bits for the \nmagnitude and 15 bits for the fraction, we ﬁ rst convert the sign, the whole part \nthose values together into a 32-bit integer.\nConsider a 32-bit ﬁ xed-point value with 16 bits \nfor the magnitude, 15 bits for the fraction, and a sign bit.\nA ﬂ oating-point number is broken into \nstring of digits the decimal point lies, and a sign bit, which of course indicates \nIt states that a 32-bit ﬂ oating-point number will be represented \nwith the sign in the most signiﬁ cant bit, followed by 8 bits of exponent, and \nﬁ nally 23 bits of mantissa.\nThe value v represented by a sign bit s, an exponent e and a mantissa m is \nThe sign bit s has the value +1 or –1.\nan implicit 1 that is not actually stored in memory, and the rest of the bits are \nHence the value represented is really 1 \n+ m, where m is the fractional value stored in the mantissa.\nmagnitude (16 bits)\nFixed-point notation with 16-bit magnitude and 16-bit fraction.\nFor example, the bit patt ern shown in Figure 3.5 represents the value \nThe  precision of a ﬂ oating-point number increases as the magnitude decreases, \nThis is because there are a ﬁ xed number of bits in the mantissa, \nat the largest possible ﬂ oating-point value, FLT_MAX ≈ 3.403×1038, whose rep-\nresentation in 32-bit IEEE ﬂ oating-point format is 0x7F7FFFFF.\nz The largest absolute value that we can represent with a 23-bit mantissa \nData, Code, and Memory in C/C++\nexponent (8 bits)\nmantissa (23 bits)\nIEEE-754 32-bit ﬂ oating-point format.\nto any actual bits in our 32-bit ﬂ oating-point value—they just appear out of \nThe opposite eﬀ ect occurs for ﬂ oating-point values whose magnitudes \nthe same number of signiﬁ cant digits (or really signiﬁ cant bits) in our ﬂ oating-\npoint numbers, and the exponent can be used to shift  those signiﬁ cant bits into \nsmallest nonzero value we can represent with any ﬂ oating-point notation.\nanother way, the real number line is quantized when using a ﬂ oating-point \nﬁ ned to be the smallest ﬂ oating-point value ε  that satisﬁ es the equation, 1 + \nFor an IEEE-754 ﬂ oating-point number, with its 23 bits of precision, the \nﬁ t the sum into a mantissa with only 23 bits.\nFor example, let’s say we use a ﬂ oating-point vari-\naway with using a 32-bit ﬂ oating-point clock measured in seconds in a game.\nIEEE Floating-Point Bit Tricks\nSee [7], Section 2.1, for a few really useful IEEE ﬂ oating-point “bit tricks” that \nAs you know, C and C++ provide a number of  atomic data types.\ndata types, but each compiler is free to deﬁ ne the types slightly diﬀ erently in \nﬁ ned to be 32 bits wide on Pentium class PCs. A short is intended to \nOn most modern compilers, a float is a 32-bit IEEE-754 ﬂ oat-\ning-point value.\nA double is a double-precision (i.e., 64-bit) IEEE-754 ﬂ oating-\npoint value.\nas a single bit, but some compilers deﬁ ne it to be 8 bits while others use \na full 32 bits.\nData, Code, and Memory in C/C++\nthe most commonly used SIMD register format packs four 32-bit IEEE-754 \nﬂ oating-point quantities into a 128-bit SIMD register.\nVisual Studio compiler provides the built-in data type  __m128 to represent a \ncompiler uses the syntax vector float to declare a packed four-ﬂ oat SIMD \nz  F32 is a 32-bit IEEE-754 ﬂ oating-point value.\nz  U32F and  I32F are “fast” unsigned and signed 32-bit values, respec-\nEach of these data types acts as though it contains a 32-bit value, \nbut it actually occupies 64 bits in memory.\nvariables directly into its 64-bit registers, providing a signiﬁ cant speed \nboost over reading and writing 32-bit variables.\nz  VF32 represents a packed four-ﬂ oat SIMD value.\nOGRE deﬁ nes a number of atomic types of its own.\nOgre ::Real deﬁ nes a real ﬂ oating-point value.\n64 bits wide (like a double) by deﬁ ning the preprocessor macro OGRE_DOU-\nmath with 32-bit or 16-bit ﬂ oats, the CPU/FPU is also usually faster when \nworking in single-precision, and SIMD vector instructions operate on 128-bit \nregisters that contain four 32-bit ﬂ oats each.\nto single-precision ﬂ oating-point math.\nﬁ nes no signed 8-, 16-, or 64-bit integral types.\ngine on top of OGRE, you will probably ﬁ nd yourself deﬁ ning these types \nMulti-Byte Values and Endianness\nValues that are larger than eight bits (one byte) wide are called  multi-byte quan-\nand ﬂ oating-point values that are 16 bits or wider.\nvalue 4660 = 0x1234 is represented by the two bytes 0x12 and 0x34.\nIn a 32-bit value, such as 0xABCD1234, the MSB is 0xAB and the LSB is 0x34.\nThe same concepts apply to 64-bit integers and to 32- and 64-bit ﬂ oating-point \nvalues as well.\nData, Code, and Memory in C/C++\na multi-byte value at a lower memory address than the most signiﬁ cant \na multi-byte value at a lower memory address than the least signiﬁ cant \never, when you’re a game programmer, endianness can become a bit of a thorn \nwhen you generate a data ﬁ le for consumption by your game engine on an \nIntel processor and then try to load that data ﬁ le into your engine running on \nAny multi-byte value that you wrote out into that data \nﬁ le will be stored in litt le-endian format.\nﬁ le, it expects all of its data to be in big-endian format.\n1. You could write all your data ﬁ les as text and store all multi-byte num-\nU32 value = 0xABCD1234;\nbinary data ﬁ le.\nIn eﬀ ect, you make sure that the data ﬁ le uses the endi-\nthe most signiﬁ cant byte of the value and swap it with the least signiﬁ cant \nbyte; you continue this process until you reach the half-way point in the value.\ning the contents of a C struct or C++ class from memory out to a ﬁ le.\nU32   m_c;\nmight be writt en out to a data ﬁ le as follows:\nand the swap functions might be deﬁ ned like this:\ninline U16 swapU16(U16 value)\ninline U32 swapU32(U32 value)\nData, Code, and Memory in C/C++\nLet’s take a brief look at how ﬂ oating-point endian-swapping diﬀ ers from in-\nAs we’ve seen, an IEEE-754 ﬂ oating-point value has \nfor the exponent, and a sign bit.\nu.m_asF32 = value;\nDeclarations, Deﬁ nitions, and Linkage\nThe compiler translates one .cpp ﬁ le at a time, and for each one it generates \nA .cpp ﬁ le is the smallest unit of \nAn object ﬁ le contains not only the compiled machine code for all of the func-\ntions deﬁ ned in the .cpp ﬁ le, but also all of its global and static variables.\ndition, an object ﬁ le may contain  unresolved references to functions and global \nvariables deﬁ ned in other .cpp ﬁ les.\nData, Code, and Memory in C/C++\nit encounters a reference to an external global variable or function, it must \nglobal variables, and static variables, with all cross-translation-unit references \n2. The linker might ﬁ nd more than one variable or function with the same \nIn the C and C++ languages, variables and functions must be declared and de-\ntween a declaration and a deﬁ nition in C and C++.\nz A  declaration is a description of a data object or function.\ncompiler with the name of the entity and its  data type or function signature \nIn other words, a declaration is a reference to an entity, while a deﬁ nition is the \nFunctions are deﬁ ned by writing the body of the function immediately af-\nA pure declaration can be provided for a function so that it can be used in \nextern int max(int a, int b); // a function declaration\nVariables and instances of classes and structs are deﬁ ned by writing the \ndata type followed by the name of the variable or instance, and an optional \nA global variable deﬁ ned in one translation unit can optionally be declared for \nMultiplicity of Declarations and Deﬁ nitions\nNot surprisingly, any particular data object or function in a C/C++ program \nIf two or more identical deﬁ nitions exist in a single translation unit, \nData, Code, and Memory in C/C++\nIt is usually dangerous to place deﬁ nitions in header ﬁ les.\nshould be prett y obvious: If a header ﬁ le containing a deﬁ nition is  #included \nInline function deﬁ nitions are an exception to this rule, because each in-\ntion deﬁ nitions must be placed in header ﬁ les if they are to be used in more \ngets the ﬁ nal say as to whether the function will really be inlined or not.\nEvery deﬁ nition in C and C++ has a property known as linkage.\ncal static deﬁ nitions in two or more diﬀ erent .cpp ﬁ les are considered to be \n// This function can be called from other .cpp files \n// This function can only be called from within foo.cpp\nData, Code, and Memory in C/C++\nA declaration is merely a reference to an entity deﬁ ned \nway to cross-reference a single declaration in multiple .cpp ﬁ les.\ndeclaration in a header ﬁ le, then multiple .cpp ﬁ les can “see” that declaration, \nThis leads us to the real reason why inline function deﬁ nitions are permit-\nted in header ﬁ les: It is because inline functions have internal linkage by de-\na header containing an inline function deﬁ nition, each translation unit gets a \nprivate copy of that function’s body, and no “multiply deﬁ ned symbol” errors \nA program writt en in C or C++ stores its data in a number of diﬀ erent places in \ntypes of C/C++ variables work, we need to understand the memory layout of \nWhen a C/C++ program is built, the linker creates an executable ﬁ le.\nexecutable ﬁ le format called the  executable and linking format (ELF).\nWhatever its format, the executable ﬁ le always contains a \necutable machine code for all functions deﬁ ned by the program.\nSo when the executable ﬁ le is loaded into memory, the \nic variables deﬁ ned by the program.\ndeﬁ ne the initial value of any uninitialized global or static variable to be \nﬁ lls it with zeros prior to calling the program’s entry point (e.g. main()\nment contains any read-only (constant) global data deﬁ ned by the pro-\nFor example, all ﬂ oating-point constants (e.g., const float kPi \nData, Code, and Memory in C/C++\nGlobal variables, i.e., variables deﬁ ned at ﬁ le  scope outside any function or \nclass declaration, are stored in either the data or BSS segments, depending on \nable or function deﬁ nition internal linkage, meaning that it will be “hidden” \na global variable within a function.\nA function-static variable is lexically scoped \nto the function in which it is declared (i.e., the variable’s name can only be \nIt is initialized the ﬁ rst time the function is called \n(rather than before main() is called as with ﬁ le-scope statics).\nmemory layout in the executable image, a function-static variable acts identi-\ncally to a ﬁ le-static global variable—it is stored in either the data or BSS seg-\nWhenever a function \nIf function a() calls another function b(), \n1. It stores the  return address of the calling function, so that execution may \nThis allows the new function to use the registers in any way it sees ﬁ t, \nwithout fear of overwriting data needed by the calling function.\nexecution of the calling function may resume.\nThe return value of the \ncalled function, if any, is usually left  in a speciﬁ c register so that the call-\n3. The stack frame also contains all  local variables declared by the func-\nvariable, even when a function calls itself recursively.\nif they were allocated within the function’s stack frame.) For example:\nData, Code, and Memory in C/C++\nfunction a() is called\nfunction b() is called\nfunction c() is called\n// call function c()\n// call function b()\nWhen a function containing automatic variables returns, its stack frame \nexecutable image, as deﬁ ned by the data and BSS segments of the executable \nage are statically deﬁ ned, meaning that the size and layout of the memory \nC structs and C++  classes allow  variables to be grouped into logical units.\nData, Code, and Memory in C/C++",
      "keywords": [
        "function",
        "Memory",
        "deﬁ",
        "Data",
        "bits",
        "deﬁ ned",
        "Data Types",
        "Deﬁ nition",
        "bit",
        "Software Engineering",
        "Atomic Data Types",
        "variables",
        "oating-point",
        "variables deﬁ ned",
        "Types"
      ],
      "concepts": [
        "value",
        "bit",
        "bits",
        "functions",
        "function",
        "data",
        "variable",
        "point",
        "numbers",
        "memory"
      ],
      "similar_chapters": [
        {
          "book": "Game_Engine_Architecture",
          "chapter": 29,
          "title": "",
          "score": 0.599,
          "base_score": 0.449,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 11,
          "title": "",
          "score": 0.538,
          "base_score": 0.388,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 23,
          "title": "",
          "score": 0.489,
          "base_score": 0.339,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 9,
          "title": "",
          "score": 0.483,
          "base_score": 0.333,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 24,
          "title": "",
          "score": 0.467,
          "base_score": 0.317,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "bit",
          "bits",
          "value",
          "oating point",
          "function"
        ],
        "semantic": [],
        "merged": [
          "bit",
          "bits",
          "value",
          "oating point",
          "function"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.21063294302143964,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:57.759306+00:00"
      }
    },
    {
      "chapter_number": 8,
      "title": "Segment 8 (pages 142-159)",
      "start_page": 142,
      "end_page": 159,
      "summary": "Once a struct or class has been declared, it can be allocated (deﬁ ned) in \nz as a global, ﬁ le-static or function-static;\nClass-Static Members\nvariable or function so it can only be seen inside this .cpp ﬁ le.”\nz When used at function scope, static means “this variable is a global, \nz When used inside a struct or  class declaration, static means “this \nNotice that when static is used inside a class declaration, it does not \nand per-class variables that act like globals.\nClass-static variables are automatically \nincluded within the namespace of the class or struct in which they are \nSo the name of the class or struct must be used to disambigu-\nate the variable whenever it is used outside that class or struct (e.g., \nof a class-static variable within a class allocates no memory.\nthe class-static variable must be deﬁ ned in a .cpp ﬁ le.\nclass Foo\nIt’s useful to be able to visualize the memory layout of your classes and \nfor the struct or class, with horizontal lines separating data members.\nData, Code, and Memory in C/C++\nAs we start to think more carefully about the layout of our structs and classes \nThe alignment of a data \nz An object with one-byte alignment resides at any memory address.\nz An object with two-byte alignment resides only at even addresses (i.e., \nz An object with four-byte alignment resides only at addresses that are a \nz A 16-byte aligned object resides only at addresses that are a multiple of \nonly read and write properly aligned blocks of data.\nrequests that a 32-bit (four-byte) integer be read from address 0x6A341174, the \nmemory controller will load the data happily because the address is four-byte \nfour-byte alignment requirement, 16-bit values should be two-byte aligned, \nand 8-bit values can be stored at any address (one-byte aligned).\nWhen smaller data types like 8-bit bools \nData, Code, and Memory in C/C++\n// 32 bits (4-byte aligned)\n// 32 bits (4-byte aligned)\n// 32 bits (4-byte aligned)\n// 32 bits (4-byte aligned)\n// 8 bits (1-byte aligned)\n// 8 bits (1-byte aligned)\nthese structs is deﬁ ned and the ﬁ rst element of the array is aligned, then the \nAligned and unaligned reads of a 32-bit integer.\n// 32 bits (4-byte aligned)\n// 32 bits (4-byte aligned)\n// 32 bits (4-byte aligned)\n// 32 bits (4-byte aligned)\n// 8 bits (1-byte aligned)\n// 8 bits (1-byte aligned)\nMemory Layout of C++ Classes\nmemory layout:  inheritance and virtual functions.\nWhen class B inherits from class A, B’s data members simply appear im-\nclass simply tacks its data members on at the end, although alignment re-\nin the memory layout of a derived class.\ncause game programmers usually prefer to avoid  multiple inheritance alto-\nIf a class contains or inherits one or more virtual functions, then four ad-\nclass’ layout.\nThe vtable for a particular class contains pointers \nto all the virtual functions that it declares or inherits.\nits own virtual table, and every instance of that class has a pointer to it, stored \nReturning to the ubiquitous example of a Shape base class with de-\nrived classes for Circle, Rectangle, and Triangle, let’s imagine that Shape\ndeﬁ nes a virtual function called Draw().\nthis function, providing distinct implementations named Circle::Draw(), \nclass derived from Shape will contain an entry for the Draw() function, but \nData, Code, and Memory in C/C++\npointer, look up the Draw() function’s entry in the vtable, and call it.\nbase class Shape deﬁ nes two virtual functions, SetId() and Draw(), the lat-\nno default implementation of the Draw() function, and derived classes must \noverride it if they want to be instantiable.) Class Circle derives from Shape, \nadds some data members and functions to manage its center and radius, and \noverrides the Draw()function; this is depicted in Figure 3.17.\nClass Triangle\nClass \nThe memory image generated by the Triangle class \nclass Shape\n// code to draw a Circle\npShape1 points to an instance of class Circle.\nclass Circle : public Shape\n// code to draw a circle\nclass Triangle : public Shape\n// code to draw a triangle\npShape2 points to an instance of class Triangle.\n// code to draw a Triangle\nData, Code, and Memory in C/C++\nCatching and Handling Errors\nThere are a number of ways to catch and handle error conditions in a game \nAs a game programmer, it’s important to understand these diﬀ erent \nTypes of Errors\nIn any soft ware project there are two basic kinds of  error conditions: user er-\nrors and programmer errors.\nA user error occurs when the user of the program \nA programmer error is the result of a bug in the \nessence of a programmer error is that the problem could have been avoided if \ncontext of a game project, user errors can be roughly divided into two catego-\nries: errors caused by the person playing the game and errors caused by the \ntrack of which type of user is aﬀ ected by a particular error and handle the er-\nrors and programmer errors gets blurry.\na function f(), and programmer B tries to call it.\ncould be seen as a user error by programmer A, but it would be a program-\nhave handled them gracefully, so the problem really is a programmer error, \nHandling Errors\nWhen handling errors, the requirements diﬀ er signiﬁ cantly between the two \nIt is best to handle user errors as gracefully as possible, displaying some \nProgrammer errors, \nIn an ideal world, all programmer errors would be caught \nHandling Player Errors\nWhen the “user” is the person playing your game, errors should obviously be \nHandling Developer Errors\nmator or game designer, errors may be caused by an invalid asset of some sort.\nFor these kinds of developer errors, there are two \nCatching and Handling Errors\nthe bad asset surviving all the way into the ﬁ nal shipping game.\nthis point of view to an extreme, then the best way to handle bad game assets \nline of thought, a game engine should be robust to almost any kind of problem \nbloated with error-catching and error-handling code that won’t be needed \nWhen a developer error occurs, I like to make the error \ngame.\nOf course, we should only handle errors in \nof problems, and your judgment about what type of error handling approach \nHandling Programmer Errors\nThe best way to detect and handle programmer errors (a.k.a. bugs) is oft en \nto embed error-checking code into your source code and arrange for failed \nerror checks to halt the program.\nsaid above, one programmer’s user error is another programmer’s bug; hence, \nassertions are not always the right way to handle every programmer error.\nMaking a judicious choice between an assertion and a more graceful error \nImplementation of Error Detection and Handling\nWe’ve looked at some philosophical approaches to handling errors.\nimplementing error detection and handling code.\nError Return Codes\nA common approach to handling errors is to return some kind of failure code \nfrom the function in which the problem is ﬁ rst detected.\ncode from the output(s) of the function, and the exact nature of the problem \nThe calling function should intercept error return codes and act appro-\nIt might handle the error immediately.\nproblem, complete its own execution, and then pass the error code on to what-\nError return codes are a simple and reliable way to communicate and respond \nHowever, error return codes have their drawbacks.\nhaps the biggest problem with error return codes is that the function that \ndetects an error may be totally unrelated to the function that is capable of \nappropriate error code all the way back up to the top-level error-handling \nfunction.\nCatching and Handling Errors\nthat detects a problem to communicate the error to the rest of the code with-\nout knowing anything about which function might handle the error.\nexception is thrown, relevant information about the error is placed into a data \nThe ability to separate error detection from error handling in such a clean \nception handling in your game engine altogether.\nAssertions\nAn assertion is a line of code that checks an expression.\nAssertions check a programmer’s assumptions.\nFor example, if a programmer changes code that \nthe code changes that caused the problem are fresh in the programmer’s \nAssertions are implemented as a #define macro, which means that the \nassertion checks can be stripped out of the code if desired, by simply changing \ndevelopment, but stripping out the assertions prior to shipping the game can \nAssertions are usually implemented via a combination of a #defined macro \ntion fails (the expression evaluates to false), and a bit of assembly code that \nCatching and Handling Errors\nmacro is deﬁ ned in its fully glory, and all assertion checks in the code \nASSERT(expr) evaluates to nothing, and all instances of it in the code \nz The ASSERT() macro itself is deﬁ ned using a full if/else statement (as \nHere’s an example of what would happen if ASSERT() were deﬁ ned \nASSERT(a \nI highly recommend the use of assertions in your code.\nﬁ ning two kinds of assertion macros.\nleast these assertions become active when programmers are debugging their \nIt’s also extremely important to use assertions properly.\nused to catch bugs in the program itself—never to catch user errors.\nfective.) In other words, assertions should only be used to catch fatal errors.\nof the error in some other way, such as with an on-screen message, or some \nCatching and Handling Errors\nGame programmers make use of virtually all branches \ngame programmer.",
      "keywords": [
        "error",
        "draw",
        "Error Return Codes",
        "game",
        "Code",
        "Handling Errors",
        "Foo",
        "programmer errors",
        "function",
        "memory",
        "data",
        "Triangle",
        "virtual void Draw",
        "Games struct Foo",
        "programmer"
      ],
      "concepts": [
        "errors",
        "game",
        "assertion",
        "assertions",
        "assert",
        "classes",
        "handling",
        "code",
        "data",
        "alignment"
      ],
      "similar_chapters": [
        {
          "book": "Game_Engine_Architecture",
          "chapter": 6,
          "title": "",
          "score": 0.591,
          "base_score": 0.441,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 12,
          "title": "",
          "score": 0.58,
          "base_score": 0.43,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 13,
          "title": "",
          "score": 0.572,
          "base_score": 0.422,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 36,
          "title": "",
          "score": 0.372,
          "base_score": 0.372,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 37,
          "title": "",
          "score": 0.324,
          "base_score": 0.324,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "error",
          "errors",
          "byte",
          "class",
          "byte aligned"
        ],
        "semantic": [],
        "merged": [
          "error",
          "errors",
          "byte",
          "class",
          "byte aligned"
        ]
      },
      "topic_id": 2,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.22761912281303665,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:57.759338+00:00"
      }
    },
    {
      "chapter_number": 9,
      "title": "Segment 9 (pages 160-181)",
      "start_page": 160,
      "end_page": 181,
      "summary": "Points and Vectors\nthe vector.\nPoints and Cartesian Coordinates\nSo a point P is represented by a pair or triple of real numbers, (Px , Py) \nIn cylindrical coordinates, a point P is represented by the triple of num-\nPoints and Vectors\nof your right hand around the z-axis with the thumb pointing toward positive \nz coordinates, your ﬁ ngers point from the x-axis toward the y-axis.\nFor example, if the y-axis points upward and x points to the right, \nchoose to have the y-axis pointing up, with z forward and x to the left  (RH) \nOr we could choose to have the z-axis point up.\nwith a left -handed coordinate system, with the y-axis pointing up, x to the \nright and positive z pointing away from the viewer (i.e., in the direction the \nVectors\nA vector is a quantity that has both a magnitude and a direction in n-dimensional \nA vector can be visualized as a directed line segment extending from a \nUsually scalars are writt en in italics (e.g., v) while vectors are writt en \nA 3D vector can be represented by a triple of scalars (x, y, z), just as a point \nThe distinction between points and vectors is actually quite subtle.\nTechnically, a vector is just an oﬀ set relative to some known point.\nA vector \ndon’t change, it is the same vector.\nA vector can be used to represent a point, provided that we ﬁ x the tail of \nthe vector to the origin of our coordinate system.\nSuch a vector is sometimes \nPoints and Vectors\ntriple of scalars as either a point or a vector, provided that we remember that \na position vector is constrained such that its tail remains at the origin of the \nThis implies that points and vectors are treated in \nwhile vectors are relative.\nboth to points (position vectors) and to vectors in the strict linear algebra sense \n(purely directional vectors).\nIn this book, we’ll use the term “direction vector ” or just “direc-\nfor manipulation with 4 × 4 matrices, so gett ing the two types of vector mixed \nCartesian Basis Vectors\nIt is oft en useful to deﬁ ne three orthogonal unit vectors (i.e., vectors that are mu-\nThe unit vector along the x-axis is typically \ncalled i, the y-axis unit vector is called j, and the z-axis unit vector is called k.\nAny point or vector can be expressed as a sum of scalars (real numbers) \nmultiplied by these unit basis vectors.\nVector Operations\napplied to vectors as well.\nto vectors.\nMultiplication of a vector a by a scalar s is accomplished by multiplying the \nvector, while leaving its direction unchanged, as shown in Figure 4.5.\nplication by –1 ﬂ ips the direction of the vector (the head becomes the tail and \nVector addition and subtraction.\nscale , and it can be represented as the component-wise product of a scaling vector \ns and the vector in question, which we’ll denote with the ⊗ operator.\ncally speaking, this special kind of product between two vectors is known as \nAs we’ll see in Section 4.3.7.3, a scaling vector s is really just a compact way to \nrepresent a 3 × 3 diagonal scaling matrix S.\nThe addition of two vectors a and b is deﬁ ned as the vector whose components \nVector subtraction a – b is nothing more than addition of a and –b (i.e., the \nThis corresponds to the vector \nMultiplication of a vector by the scalar 2.\nPoints and Vectors\nMagnitude of a vector (shown in 2D for ease of illustration).\nVector addition and subtraction are depicted in Figure 4.6.\nYou can add and subtract direction vectors freely.\nvector to a point, the result of which is another point.\nthe diﬀ erence between two points, resulting in a direction vector.\nz point + direction = point\nz point – point = direction\nThe magnitude of a vector is a scalar representing the length of the vector as \ncalculate a vector’s magnitude, as shown in Figure 4.7:\nVector Operations in Action\nif we have the current position vector of an A.I. character P1, and a vector v \nP2 by scaling the velocity vector by the frame time interval Δt, and then adding \nAs shown in Figure 4.8, the resulting vector equation \nspheres, C1 and C2, we can ﬁ nd a direction vector between them by simply \nThe magnitude of this vector d = |d| de-\nNormalization and Unit Vectors\nA unit vector is a vector with a magnitude (length) of one.\nUnit vectors are very \nPoints and Vectors\nGiven an arbitrary vector v of length v =     , we can convert it to a unit \nvector u that points in the same direction as v, but has unit length.\nNormal Vectors\nNormal vectors are highly useful in games and computer graphics.\nample, a plane can be deﬁ ned by a point and a normal vector.\ngraphics, lighting calculations make heavy use of normal vectors to deﬁ ne \nNormal vectors are usually of unit length, but they do not need to be.\nA normal vector is any \nvector that is perpendicular to a surface, whether or not it is of unit length.\nVectors can be multiplied, but unlike scalars there are a number of diﬀ erent \nkinds of vector multiplication.\nz the cross product (a.k.a. vector product or outer product).\nThe dot product of two vectors yields a scalar; it is deﬁ ned by adding the \nproducts of the individual components of the two vectors:\ntwo vectors and the cosine of the angle between them:\nThe dot product is commutative (i.e., the order of the two vectors can be \nVector Projection\nIf u is a unit vector (     = 1), then the dot product (a ⋅ u) represents the length \nof the projection of vector a onto the inﬁ nite line deﬁ ned by the direction of \nVector projection using the dot product.\nThe squared magnitude of a vector can be found by taking the dot product of \nthat vector with itself.\nDot products are great for testing if two vectors are collinear or perpendicular, \nany two arbitrary vectors a and b, game programmers oft en use the following \ndegrees—this dot product equals +1 when a and b are unit vectors).\ndegrees—this dot product equals –1 when a and b are unit vectors).\nPoints and Vectors\nWe can ﬁ nd a vector from the player’s position P to \nthe enemy’s position E by simple vector subtraction (v = E – P).\nwe have a vector f pointing in the direction that the player is facing .\nsee in Section 4.3.10.3, the vector f can be extracted directly from the player’s \nmodel-to-world matrix .) The dot product d = v ⋅ f can be used to test whether \nThe dot product can be used to ﬁ nd the height of a point above or below a \nThe dot product can also be used to ﬁ nd the height of a point above or \nWe can deﬁ ne a plane with two vector quantities: a point Q lying \nanywhere on the plane, and a unit vector n that is perpendicular (i.e., normal) \na vector from any point on the plane (Q will do nicely) to the point in ques-\nThe dot product of vector v with the unit-length \nnormal vector n is just the projection of v onto the line deﬁ ned by n.\nThe cross product (also known as the outer product or vector product) of two vec-\nThe magnitude of the cross product vector is the product of the magnitudes of \nthe two vectors and the sine of the angle between them.\nﬁ ed by the position vectors V1 , V2 , and V3 can be calculated as one-half of the \nproduct of vectors a \nthat they point in the direction you’d rotate vector a to move it on top of vector \nb, and the cross product (a × b) will be in the direction of your thumb.\nof all the points and vectors stay the same, but one axis ﬂ ips.\nproduct itself would have to be changed so that the z-coordinate of the cross \nThe Cartesian basis vectors are related by cross products as follows:\nPoints and Vectors\nThese three cross products deﬁ ne the direction of positive rotations about the \ncommon uses is for ﬁ nding a vector that is perpendicular to two other vectors.\nAs we’ll see in Section 4.3.10.2, if we know an object’s local unit basis vectors, \n(which we already know) and the world-space up vector jworld (which equals \nA very similar technique can be used to ﬁ nd a unit vector normal to the \nP2 , and P3 , the normal vector is just n = normalize[(P2 – P1) × (P3 – P1)].\nGiven a force F, and a vector r from the center of mass to the point \nLinear Interpolation of Points and Vectors\nIn games, we oft en need to ﬁ nd a vector that is midway between two known \nvectors.\nGeometrically, L = LERP(A, B, β) is the position vector of a point that lies \nthe two input vectors, with weights (1 – β) and β, respectively.\nWe can think of the rows and/or columns of a 3 × 3 matrix as 3D vectors.\nWhen all of the row and column vectors of a 3 × 3 matrix are of unit magni-\nUnder certain constraints, a 4 × 4 matrix can represent arbitrary 3D trans-\nmatrix are applied to a point or vector via matrix multiplication.\nThe product P of two matrices A and B is writt en P = AB.\ntransformation matrices, then the product P is another transformation matrix \nmatrix and B is a rotation, the matrix P would both scale and rotate the points \nor vectors to which it is applied.\nrows of the nA × mA matrix A and the columns of the nB × mB matrix B.\nproduct becomes one component of the resulting matrix P.\nMatrix multiplication is oft en called concatenation, because the product \nRepresenting Points and Vectors as Matrices\nPoints and vectors can be represented as row matrices (1 × n) or column matrices \nFor example, the vector v = (3, 4, –1) can be writt en either as\nz to multiply a 1 × n row vector by an n × n matrix, the vector must appear \nz to multiply an n × n matrix by an n × 1 column vector, the vector must \nvector v, the transformations “read” from left  to right when using row vectors, \nbut from right to left  when using column vectors.\nthis is to realize that the matrix closest to the vector is applied ﬁ rst.\nv’ = ( ( ( vA ) B ) C )    Row vectors: read left -to-right; \nv’ = ( C ( B ( Av ) ) )    Column vectors: read right-to-left .\nIn this book we’ll adopt the row vector convention, because the left -to-right \nusually tell by seeing whether vector-matrix multiplications are writt en with \nthe vector on the left  (for row vectors) or the right (for column vectors) of the \nWhen using column vectors, you’ll need to transpose all the matrices \nSo, for example, if A rotates objects by 37 degrees about the z-axis, \nThe matrices used by a row-vector-\nthe column vector convention.\nces to points and vectors.\nTo rotate a vector r through an angle of φ degrees \nby a 3 × 3 matrix.\n3 matrix such that the result of multiplying it with the column vector r yields \nthe dot product of the vector r with column 1 of the matrix will yield (1 × rx) + \ncontains zeros, then the resulting vector will also have a 1 in its w component.\nHere’s what the ﬁ nal 4 × 4 translation matrix looks like:\nWhen a point or vector is extended from three dimensions to four in this \nby game engines is performed using 4 × 4 matrices with four-element points \nand vectors writt en in homogeneous coordinates.\nTransforming Direction Vectors\nMathematically, points (position vectors) and direction vectors are treated in \nWhen transforming a point by a matrix, the translation, \nrotation, and scale of the matrix are all applied to the point.\nThis is because direction vectors have no translation per se—applying \ntheir w components equal to one, while direction vectors have their w com-\nof the vector v multiplies with the t vector in the matrix, thereby eliminating \nof a point, but dividing a pure direction vector’s components by w = 0 would \nA point at inﬁ nity in 4D can be rotated but not translated, be-\nSo in eﬀ ect, a pure direction vector in three-dimensional space acts like \nz the upper 3 × 3 matrix U, which represents the rotation and/or scale,\nz a 1 × 3 translation vector t,\nz a 3 × 1 vector of zeros 0 = [ 0 0 0 ]T, and\nz a scalar 1 in the bott om-right corner of the matrix.\nWhen a point is multiplied by a matrix that has been partitioned like this, the \nThe following matrix translates a point by the vector t:\nTo invert a pure translation matrix, simply negate the vector t (i.e., negate tx ,\nThe t vector is zero and the upper 3 × 3 matrix R contains cosines and sines of \nThe following matrix represents rotation about the x-axis by an angle φ:\nThe matrix below represents rotation about the y-axis by an angle θ.\nThis matrix represents rotation about the z-axis by an angle γ:\nrotation matrix about the y-axis is transposed relative to the other two.\nThe following matrix scales the point r by a factor of sx along the x-axis, sy\nz When a uniform scale matrix Su and a rotation matrix R are concat-\nThe rightmost column of an aﬃ  ne 4 × 4 matrix always contains the vector \nWe’ve seen how to apply transformations to points and direction vectors us-\nWe said above that a point is a vector whose tail is ﬁ xed to the origin of \nvector) is always expressed relative to a set of coordinate axes.\nIn Figure 4.16, we see a point P represented by two \ndiﬀ erent position vectors—the vector PA gives the position of P relative to the ",
      "keywords": [
        "vector",
        "matrix",
        "cross product",
        "point",
        "product",
        "Dot Product",
        "coordinate system",
        "direction vector",
        "direction",
        "unit vector",
        "matrices",
        "coordinate",
        "cross product vector",
        "game",
        "column vectors"
      ],
      "concepts": [
        "vectors",
        "matrix",
        "point",
        "matrices",
        "coordinates",
        "product",
        "rotate",
        "rotations",
        "rotation",
        "rotated"
      ],
      "similar_chapters": [
        {
          "book": "Game_Engine_Architecture",
          "chapter": 10,
          "title": "",
          "score": 0.742,
          "base_score": 0.592,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 11,
          "title": "",
          "score": 0.665,
          "base_score": 0.515,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 23,
          "title": "",
          "score": 0.486,
          "base_score": 0.336,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 26,
          "title": "",
          "score": 0.484,
          "base_score": 0.334,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 7,
          "title": "",
          "score": 0.483,
          "base_score": 0.333,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "vector",
          "vectors",
          "product",
          "matrix",
          "direction"
        ],
        "semantic": [],
        "merged": [
          "vector",
          "vectors",
          "product",
          "matrix",
          "direction"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.24336580578187336,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:57.759375+00:00"
      }
    },
    {
      "chapter_number": 10,
      "title": "Segment 10 (pages 182-202)",
      "start_page": 182,
      "end_page": 202,
      "summary": "“A” axes, while the vector PB gives the position of that same point relative to a \nPeople in the game industry also use the term coordinate space (or simply \nspace) to refer to a set of coordinate axes.\nat a few of the most common coordinate spaces used in games and computer \nrefer to a unit basis vector along the front axis.\nThe unit basis vector along this axis will be denoted U.\nPosition vectors for the point P relative to different coordinate axes.\nThe unit basis vector along this axis will be denoted L or R, \nand the label up to the positive y-axis (or in terms of unit basis vectors, F = k, \nthe (i, j, k) basis vectors because their orientation is arbitrary.\ndeﬁ ne pitch, yaw, and roll in terms of the (L, U, F) basis vectors, because their \nz pitch is rotation about L or R,\nz yaw is rotation about U, and\nz roll is rotation about F.\nWorld space is a ﬁ xed coordinate space, in which the positions, orientations, \nOne possible choice of the model-space front, left and up axis basis vectors for \n(In our game, front vectors correspond to the positive z-axis in model \ndown the positive x-axis in world space, with its model-space origin at some \nBecause the F vector of the airplane, \nwhich corresponds to +z in model space, is facing down the +x-axis in world \nspace, we know that the jet has been rotated by 90 degrees about the world \nView space (also known as camera space) is a coordinate frame ﬁ xed to the cam-\nIf the jet is rotated by 90 \ndegrees about the world-space y-axis, and its model-space origin translated to (–25, 50, 8) in \norientation, and scale of a set of axes in three-dimensional space, you must \nThe matrix that transforms points and directions from any child coordinate \nAny child-space position vector PC can \nbe transformed into a parent-space position vector PP as follows:\nLeft- and right-handed examples of view space, also known as camera space.\nz iC is the unit basis vector along the child space x-axis, expressed in par-\nz jC is the unit basis vector along the child space y-axis, in parent space;\nz kC is the unit basis vector along the child space z-axis, in parent space;\nThe iC , jC , and kC unit vectors form the upper 3 × 3 \nof the matrix, which is a pure rotation matrix because these vectors are of unit \na situation in which child space is rotated by an angle γ about the z-axis, with \nThe matrix for such a rotation is given by \nBut in Figure 4.20, we can see that the coordinates of the iC and jC vectors, \nunit basis vectors appropriately.\nrotate ( , )\nExtracting Unit Basis Vectors from a Matrix\nchild-space basis vectors iC , jC , and kC from it by simply isolating the appropri-\nate rows of the matrix (or columns if your math library uses column vectors).\nThis is really just a change of basis matrix, transforming points in model space \nthe positive z-axis always points in the direction that an object is facing.\nﬁ nd a unit vector representing the vehicle’s facing direction, we can simply ex-\nTransforming Coordinate Systems versus Vectors\ntranslation of the child coordinate axes relative to the world space axes.\nreverse of what happens to points and direction vectors.\nmatrix transforms vectors from child space to parent space, then it also trans-\nforms coordinate axes from parent space to child space.\naxes ﬁ xed is the same as moving the coordinate axes 20 units to the left  with \nChange of basis when child axes are rotated by an angle γ relative to parent.\nif you’re thinking in terms of points and vectors, they go in the other direction!\nz Transformations apply to vectors (not coordinate axes).\nz Vectors are writt en as rows (not columns).\nnate axes moving around rather than the points and vectors, you either have \nat thinking about 3D vector and matrix math, you’ll ﬁ nd it prett y easy to ﬂ ip \nTransforming Normal Vectors\nIn general, if a point or (non-normal) vector can be rotated from space A to \n, then a normal vector n will be transformed \nfrom space A to space B via the inverse transpose of that matrix, \nuniform scale and no shear, then the angles between all surfaces and vectors in \nwill actually work just ﬁ ne for any vector, normal or non-normal.\nangles between surfaces and vectors are not preserved when moving from \nA vector that was normal to a surface in space A will not \nvalues we ﬁ nd there as a 4-element vector.\nmatching up exactly with row vector matrix equations (which is another reason \ntimes necessary when doing fast matrix-vector multiplies using a vector-en-\nQuaternions\nQuaternions\nWe’ve seen that a 3  ×  3 matrix can be used to represent an arbitrary rotation in \na rotation, for a number of reasons:\nWe need nine ﬂ oating-point values to represent a rotation, which seems \nRotating a vector requires a vector-matrix multiplication, which involves \nWe would like to ﬁ nd a rotational representation that is less expensive \nfew seconds, we need to be able to ﬁ nd lots of intermediate rotations be-\nA quaternion \nqw2 = 1) represent three-dimensional rotations.\nUnit Quaternions as 3D Rotations\nA unit quaternion can be visualized as a three-dimensional vector plus a \nThe vector part qV is the unit axis of rotation, scaled \nby the sine of the half-angle of the rotation.\nSo the unit quaternion q can be writt en as follows:\nwhere a is a unit vector along the axis of rotation, and θ is the angle of rota-\nThe direction of the rotation follows the right-hand rule , so if your thumb \npoints in the direction of a, positive rotations will be in the direction of your \nOf course, we can also write q as a simple four-element vector:\nA unit quaternion is very much like an axis+angle representation of a ro-\nHowever, quaternions \nQuaternions support some of the familiar operations from vector algebra, \nsum of two unit quaternions does not represent a 3D rotation, because such a \nquaternion would not be of unit length.\nGiven two quaternions p and q representing two rotations P \nand Q, respectively, the product pq represents the composite rotation (i.e., ro-\ntation Q followed by rotation P).\nQuaternions\nends up in the x, y, and z components of the resultant quaternion, and a scalar \nThe inverse of a quaternion q is denoted q–1 and is deﬁ ned as a quaternion \nThe quaternion [ 0  0  0  1 ] represents a zero rotation (which makes \nIn order to calculate the inverse of a quaternion, we must ﬁ rst deﬁ ne a \nOur quaternions are always of unit length (i.e., |q| = 1), because they represent \n3D rotations.\nRotating Vectors with Quaternions\nHow can we apply a quaternion rotation to a vector ?\nthe vector in quaternion form .\nA vector is a sum involving the unit basis vectors \nSo it makes sense that a vector can be writt en as a quaternion \nIn order to rotate a vector v by a quaternion q, we pre-multiply the vec-\nTherefore, the rotated vector v’ can be found as fol-\nThe rotated vector v’ is obtained by simply extracting it from its quaternion \nFor example, let’s say that we want to ﬁ nd a unit vector describing the \nthe positive z-axis always points toward the front of an object by convention.\nSo the forward unit vector of any object in model space is always FM  ≡ [ 0  0  1 ] \nTo transform this vector into world space, we can simply take \nour aircraft ’s orientation quaternion q and use it with Equation (4.4) to rotate \nour model-space vector FM into its world space equivalent FW (aft er converting \nthese vectors into quaternion form, of course):\nRotations can be concatenated in exactly the same way that matrix-based trans-\ner three distinct rotations, represented by the quaternions q1 , q2 , and q3 , with \nWe want to apply rotation 1 ﬁ rst, followed \nby rotation 2 and ﬁ nally rotation 3.\nThe composite rotation matrix Rnet can be \nrotate(q, )\nrotate(q, )\nQuaternions\nLikewise, the composite rotation quaternion qnet can be found and applied to \nvector v (in its quaternion form, v) as follows:\nThis is because quaternion \nrotations always multiply on both sides of the vector, with the uninverted \nthe individual inverses, so the uninverted quaternions read right-to-left  while \nthe inverted quaternions read left -to-right.\nQuaternion-Matrix Equivalence\nWe can convert any 3D rotation freely between a 3  ×  3 matrix representation \nR and a quaternion representation q.\n[ x  y  z  w ], then we can ﬁ nd R as follows:\ngamasutra.com/view/feature/3278/rotating_objects_using_quaternions.php.\nRotational Linear Interpolation\nWith the help of quaternions, rotations \ncan be easily interpolated just as vectors and points can.\na four-dimensional vector LERP on the quaternions you wish to interpolate.\nGiven two quaternions qA and qB representing rotations A and B, we can \nﬁ nd an intermediate rotation qLERP that is β percent of the way from A to B as \nis necessary because the LERP operation does not preserve a vector’s length \nGeometrically, qLERP = LERP(qA , qB , β) is the quaternion whose orientation \nfact that quaternions are really points on a four-dimensional hypersphere.\nLinear interpolation (LERP) between quaternions qA and qB.\nQuaternions\nbetween the two quaternions.\nThe cosine of the angle between any two unit-length quaternions can \nComparison of Rotational Representations\nWe’ve seen that rotations can be represented in quite a few diﬀ erent ways.\nA rotation represented via \nYou can also easily interpolate simple rotations about a single axis.\nFor example, it’s trivial to ﬁ nd intermediate rotations between two distinct yaw \ninterpolated easily when the rotation is about an arbitrarily-oriented axis.\nFor example, if you rotate by 90 \nComparison of Rotational Representations\nany further rotations about the original y-axis, because rotations about y and z \nAnother problem with Euler angles is that the order in which the rotations \nNo one standard rotation order exists for Euler angles across all disciplines \nSo the rotation \nfrom the x-, y -, and z-axes onto the natural front, left /right, and up directions for \nthe object being rotated.\nFor example, yaw is always deﬁ ned as rotation about \ncorresponds to a rotation about x, y, or z.\nA 3 × 3 matrix is a convenient and eﬀ ective rotational representation for a \nRotations can be applied to points and vectors in \nRotations can also be reversed \nby ﬁ nding an inverse matrix, which for a pure rotation matrix is the same \nAlso, rotation matrices are not easily interpolated.\nFinally, a rotation matrix takes up a lot of storage (nine ﬂ oating-point num-\nWe can represent rotations as a unit vector deﬁ ning the axis of rotation plus a \nscalar for the angle of rotation.\nis the axis of rotation and θ the angle in radians.\nsystem, the direction of a positive rotation is deﬁ ned by the right-hand rule, \nthe axis+angle representation into a matrix or quaternion ﬁ rst.\nQuaternions\nAs we’ve seen, a unit-length quaternion can represent 3D rotations in a man-\ntween the two representations is that a quaternion’s axis of rotation is scaled \nfourth component of the vector, we store the cosine of the half angle.\napplied directly to points and vectors via quaternion multiplication.\nit permits rotations to be easily interpolated via simple LERP or SLERP op-\nBy itself, a quaternion can only represent a rotation, whereas a 4  ×  4 matrix \ncan represent an arbitrary aﬃ  ne transformation (rotation, translation, and \nWhen a quaternion is combined with a translation vector and a scale \na scale factor, a quaternion for rotation, and a translation vector.\nas opposed to the 12 ﬂ oating-point numbers needed for a 4  ×  3 matrix) and \nThe translation vector and scale factor \nare interpolated via LERP, and the quaternion can be interpolated with either \nComparison of Rotational Representations\nComplete transformations involving rotation, translation, and scale can be \nrepresented using a mathematical object known as a dual quaternion.\nquaternions, where the second one is multiplied by the dual unit, as follows: \nand z-axes) and three degrees of freedom in its rotation (about the x-, y-, and \nangles require three ﬂ oats, but axis+angle and quaternion representations use \nAll 3D rotational representations employ ",
      "keywords": [
        "space",
        "vector",
        "quaternion",
        "rotation",
        "unit basis vector",
        "Matrix",
        "World Space",
        "basis vectors",
        "rotations",
        "child space",
        "coordinate space",
        "coordinate",
        "Model Space",
        "LERP",
        "parent space"
      ],
      "concepts": [
        "rotation",
        "rotated",
        "rotate",
        "rotations",
        "vector",
        "quaternions",
        "space",
        "matrix",
        "coordinate",
        "point"
      ],
      "similar_chapters": [
        {
          "book": "Game_Engine_Architecture",
          "chapter": 9,
          "title": "",
          "score": 0.742,
          "base_score": 0.592,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 11,
          "title": "",
          "score": 0.605,
          "base_score": 0.455,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 27,
          "title": "",
          "score": 0.535,
          "base_score": 0.385,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 31,
          "title": "",
          "score": 0.511,
          "base_score": 0.361,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 23,
          "title": "",
          "score": 0.463,
          "base_score": 0.313,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "quaternion",
          "rotation",
          "vector",
          "quaternions",
          "space"
        ],
        "semantic": [],
        "merged": [
          "quaternion",
          "rotation",
          "vector",
          "quaternions",
          "space"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.25820841171074055,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:57.759424+00:00"
      }
    },
    {
      "chapter_number": 11,
      "title": "Segment 11 (pages 203-224)",
      "start_page": 203,
      "end_page": 224,
      "summary": "If we subtract the number of constraints from the number of ﬂ oating-point \nin addition to points, vectors, matrices and quaternions.\nAn inﬁ nite line can be represented by a point P0 plus a unit vector u in the \npoint P along the line by starting at the initial point P0 and moving an arbi-\nof points P becomes a vector function of the scalar parameter t:\ndo not have to store the constraint L in a separate ﬂ oating-point parameter; it \ndeﬁ ned as a center point C plus a radius r, as shown in Figure 4.27.\ndata into a vector containing four 32-bit ﬂ oats (i.e., a 128-bit package).\nThis equation is satisﬁ ed only for the locus of points P = [ x  y  z ] that lie on \nPlanes can be represented by a point P0 and a unit vector n that is normal \nditional plane equation are interpreted as a 3D vector, that vector lies in the di-\nIf the vector [ A  B  C ] is normalized to unit length, \nthen the normalized sub-vector [ a  b  c ] = n, and the normalized parameter \nof d is positive if the plane’s normal vector (n) is pointing toward the origin \n(n x P) = –  d, which means that when any point P on the plane is projected onto \nthe plane normal n, the length of that projection will be –  d.\nA plane can actually be packed into a four-element vector, much like a \nonly the normal vector n = [ a  b  c ] and the distance from the origin d.\nfour-element vector L = [ n  d ] = [ a  b  c  d ] is a compact and convenient way \nmogeneous coordinates with w = 1, the equation (L x P) = 0 is yet another way \nof writing (n x P) = –  d.\n(These equations are satisﬁ ed for all points P that lie \nPlanes deﬁ ned in four-element vector form can be easily transformed \npoints and (non-normal) vectors from space A to space B, we already know \nthat to transform a normal vector such as the plane’s n vector, we need to use \nvector L will, in fact, correctly transform that plane from space A to space B.\nexpensive method of testing whether a point P is inside or outside any given \nsent the the near and far clipping planes (i.e., they deﬁ ne the minimum and \nnormal vector per plane).\nTesting whether a point lies inside a frustum is a bit involved, but the basic \nple, the CPU might multiply four pairs of ﬂ oating-point numbers in parallel \nThe SSE instruction set utilizes 128-bit registers that can \nThe SSE mode most commonly used by game engines is called packed 32-\nbit ﬂ oating-point mode.\nis just what the doctor ordered when multiplying a four-element vector by a \nSSE Registers\nIn packed 32-bit ﬂ oating-point mode, each 128-bit SSE register contains four \nThe individual ﬂ oats within an SSE register are conveniently re-\nferred to as [ x  y  z  w ], just as they would be when doing vector/matrix math \nregisters work, here’s an example of a SIMD instruction:\nThe addps instruction adds the four ﬂ oats in the 128-bit XMM0 register with \nthe four ﬂ oats in the XMM1 register, and stores the four results back into \nxmm0.w = xmm0.w + xmm1.w. The four ﬂ oating-point values stored in an SSE register can be extracted \nSSE registers is particularly bad, because the CPU has to wait for either the x87 \ndata in the SSE registers for as long as possible.\nvalues are left  in SSE registers, rather than transferring them out to float\nresult, but if we leave that result in an SSE register it can be used later in other \nThe four components of an SSE register in 32-bit ﬂ oating-point mode.\nby duplicating the single ﬂ oating-point value across all four “slots” in an SSE \nSo to store the scalar s in an SSE register, we’d set x = y = z = w = s.\nUsing one of these magic SSE 128-bit values in C or C++ is quite easy.\n__m128.\nmanipulated directly in the CPU’s SSE registers.\nvariables and function arguments to be of type __m128 oft en results in the \ncompiler storing those values directly in SSE registers, rather than keeping \nAlignment of __m128 Variables\nIn order to use the __m128 data type and SSE intrinsics, your .cpp ﬁ le \nThis instruction can be invoked in C/C++ using the intrinsic _mm\n__m128 a,\n__m128 b)\n__m128 a,\n__m128 b)\n_mm_add_ps(a, b);\nthe input parameters a and b and the SSE registers xmm0 and xmm1 manually, \nsembly, and the SSE instruction looks just like a regular function call.\nfloats into an __m128 variable (i.e., into an SSE register).\n// load a and b from floating-point data arrays above\n__m128 a = _mm_load_ps(&A[0]);\n__m128 b = _mm_load_ps(&B[0]);\n__m128 c = addWithAssembly(a, b);\n__m128 d = addWithIntrinsics(a, b);\n_mm_store_ps(&B[0], b);\n_mm_store_ps(&C[0], c);\n_mm_store_ps(&D[0], d);\nVector-Matrix Multiplication with SSE\nLet’s take a look at how vector-matrix multiplication might be implemented \nusing SSE instructions.\nmatrix M to generate a result vector r.\nSo to do this calculation using SSE instructions, \nwe might ﬁ rst try storing v in an SSE register (__m128), and storing each of \nthe columns of M in SSE registers as well.\nv M\nv M\nv M\nv M\nv M\nv M\nv M\nv M\nv M\nv M\nv M\nv M\nv M\nv M\nv M\nv M\n__m128 vMcol1 = _mm_mul_ps(v, Mcol1);\n__m128 vMcol2 = _mm_mul_ps(v, Mcol2);\n__m128 vMcol3 = _mm_mul_ps(v, Mcol3);\n__m128 vMcol4 = _mm_mul_ps(v, Mcol4);\nthe registers” in order to generate the results we need.\nregisters, which would need to be combined into the single result vector r.\nwill end up in the four components of a single SSE register representing \na single component of v, such as vx, across a register to yield a vector like \nThankfully there’s a powerful SSE instruction which can replicate values \npurpose instruction that can shuﬄ  e the components of an SSE register around \nfollowing macros replicate the x, y, z or w components of a vector across an \n_mm_replicate_x_ps(v) \\\n_mm_replicate_y_ps(v) \\\n_mm_replicate_z_ps(v) \\\n_mm_replicate_w_ps(v) \\\nGiven these convenient macros, we can write our vector-matrix multipli-\n__m128 xMrow1 = _mm_mul_ps(_mm_replicate_x_ps(v),  \n__m128 yMrow2 = _mm_mul_ps(_mm_replicate_y_ps(v),  \n__m128 zMrow3 = _mm_mul_ps(_mm_replicate_z_ps(v),  \n__m128 wMrow4 = _mm_mul_ps(_mm_replicate_w_ps(v),  \n__m128 result = _mm_add_ps(xMrow1, yMrow2);\nresult        = _mm_add_ps(result, zMrow3);\nresult        = _mm_add_ps(result, wMrow4);\nThis code produces the following intermediate vectors:\nAdding these four vectors in parallel produces our result r:\nv M\nv M\nv M\nv M\nv M\nv M\nv M\nv M\nv M\nv M\nv M\nv M\nv M\nv M\nv M\nv M\ninstruction multiplies its ﬁ rst two arguments and then adds the result to its \n#define _mm_madd_ps(a, b, c) \\\n_mm_add_ps(_mm_mul_ps((a), (b)), (c))\n__m128 result;\nresult = _mm_mul_ps (_mm_replicate_x_ps(v), Mrow1);\nresult = _mm_madd_ps(_mm_replicate_y_ps(v), Mrow2,  \nresult = _mm_madd_ps(_mm_replicate_z_ps(v), Mrow3,  \nresult = _mm_madd_ps(_mm_replicate_w_ps(v), Mrow4,  \nRandom numbers are ubiquitous in game engines, so it behooves us to have \na brief look at the two most common random number generators, the linear \nThe Mersenne Twister pseudo-random number generator algorithm was de-\ning a particularly cool one that uses SIMD vector instructions for an extra \nrandom number generator one would ever need.\nvery game engine requires some low-level support systems that manage \nWhen the engine ﬁ rst starts up, each subsystem must be conﬁ g-\nSince the programming language used in most modern game engines is C++, \nmantics can be leveraged in order to start up and shut down our engine’s sub-\nIn C++, global and static objects are constructed before the program’s \nof global and static class instances are called aft er main() (or WinMain()) \nis to deﬁ ne a singleton class (oft en called a manager ) for each subsystem.\ngave us more control over the order in which global and static class instances \nstatic, we can control the order of construction for our global singletons.\nexplicit start-up and shut-down functions for each singleton manager class.\nThat way, the start-up and shut-down functions can be explicitly called in the \nTextureManager          gTextureManager;\nVideoManager            gVideoManager;\n// Start up engine systems in the correct order.\nAs long as you can start up and shut down your engine’s subsystems \nLet’s take a brief look at some examples of engine start-up and shut-down \nfull-ﬂ edged game engines, including a simple and elegant start-up and shut-",
      "keywords": [
        "SSE",
        "SSE Registers",
        "vector",
        "SIMD Math",
        "Hardware-Accelerated SIMD Math",
        "plane",
        "game engine",
        "engine",
        "SSE instruction",
        "game",
        "result",
        "Math",
        "register",
        "Engine Support Systems",
        "order"
      ],
      "concepts": [
        "vectors",
        "points",
        "instruction",
        "instructions",
        "engineers",
        "engineering",
        "ordered",
        "order",
        "bit",
        "bits"
      ],
      "similar_chapters": [
        {
          "book": "Game_Engine_Architecture",
          "chapter": 9,
          "title": "",
          "score": 0.665,
          "base_score": 0.515,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 10,
          "title": "",
          "score": 0.605,
          "base_score": 0.455,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 7,
          "title": "",
          "score": 0.538,
          "base_score": 0.388,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 25,
          "title": "",
          "score": 0.498,
          "base_score": 0.348,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 24,
          "title": "",
          "score": 0.47,
          "base_score": 0.32,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "sse",
          "__m128",
          "vector",
          "register",
          "_mm_mul_ps"
        ],
        "semantic": [],
        "merged": [
          "sse",
          "__m128",
          "vector",
          "register",
          "_mm_mul_ps"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.20752873806811525,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:57.759463+00:00"
      }
    },
    {
      "chapter_number": 12,
      "title": "Segment 12 (pages 225-246)",
      "start_page": 225,
      "end_page": 246,
      "summary": "of allocating singleton instances.\nAlso, dynamic memory allocation is avoided wherever possible, so \nmany of the singletons are statically-allocated objects (e.g., g_fileSystem, \nU8[ALLOCATION_GLOBAL_PHYS_HEAP]; \nALLOCATION_GLOBAL_PHYS_HEAP);\nMemory Management\nMemory Management\n1. Dynamic memory allocation via malloc() or C++’s global operator new\nby either avoiding dynamic allocation altogether or by making use of \ncustom memory allocators that greatly reduce allocation costs.\nin small, contiguous blocks of memory can be operated on much more \na wide range of memory addresses.\nOptimizing Dynamic Memory Allocation\nDynamic memory allocation via malloc() and free() or C++’s global new\nFirst, a heap allocator is \nOf course, no game engine can entirely avoid dynamic memory alloca-\ntion, so most game engines implement one or more custom allocators.\nFirst, a custom allocator can \nsatisfy requests from a preallocated memory block (itself allocated using \nheap allocator.\ntom allocators.\nout-of-memory.\nStack-Based Allocators\nMany games allocate memory in a stack-like fashion.\nlevel is loaded, memory is allocated for it.\nlitt le or no dynamic memory allocation takes place.\nthe level, its data is unloaded and all of its memory can be freed.\na lot of sense to use a stack-like data structure for these kinds of memory \nallocations.\nA stack allocator is very easy to implement.\nWe simply allocate a large con-\ntiguous block of memory using malloc() or global new, or by declaring a \nglobal array of bytes (in which case the memory is eﬀ ectively allocated out of \nAll memory addresses below this pointer are considered to be in use, and all \nthe lowest memory address in the stack.\nEach allocation request simply moves \nThe most-recently allocated \nblock can be freed by simply moving the top pointer back down by the size \nIt is important to realize that with a stack allocator, memory cannot be \nsite to that in which they were allocated.\nat the boundary between two allocated blocks, because otherwise new al-\nthat this is done properly, a stack allocator oft en provides a function that \nThe interface of a stack allocator oft en looks something like \nMemory Management\n// Constructs a stack allocator with the given total   \n// Allocates a new block of the given size from stack  \nalloc(U32 size_bytes);\nObtain marker after allocating blocks A and B.\nAllocate additional blocks C , D and E.\nStack allocation, and freeing back to a marker.\nDouble-Ended Stack Allocators\nA single memory block can actually contain two stack allocators—one which \nallocates up from the bott om of the block and one which allocates down from \nA double-ended stack allocator is useful because it uses \nations, both stacks may use roughly the same amount of memory and meet in \na lot more memory than the other stack, but all allocation requests can still be \nIn Midway’s Hydro Thunder arcade game, all memory allocations are \nmade from a single large block of memory managed by a double-ended stack \nallocator.\ntracks), while the top stack is used for temporary memory blocks that are al-\nA double-ended stack allocator.\nMemory Management\nPool Allocators\ngeneral) to allocate lots of small blocks of memory, each of which are the same \nFor example, we might want to allocate and free matrices, or iterators, or \nFor this type of memory \nA pool allocator works by preallocating a large block of memory whose \nsize is an exact multiple of the size of the elements that will be allocated.\nWhenever an allocation request is made, \nBoth allocations and \ntime of both allocations and frees are roughly constant and do not depend on \nwe need a single pointer (four bytes on most machines) for each free ele-\nWhere should we obtain the memory for these pointers?\nthey could be stored in a separate preallocated memory block, occupying \nfree memory blocks.\nSo why not use the free blocks themselves to store the \nAligned Allocations\nOn the PS3, memory blocks that \nAll memory allocators must be capable of returning aligned memory \nWe simply allocate \na litt le bit more memory than was actually requested, adjust the address of \nthe memory block upward slightly so that it is aligned properly, and then re-\nBecause we allocated a bit more memory than was \nIn most implementations, the number of additional bytes allocated is \nmemory block, we would allocate 16 additional bytes.\nby masking oﬀ  the least-signiﬁ cant bits of the original block’s memory ad-\nallocated block’s address is 0x50341233, ANDing this address with the mask \nHere’s one possible implementation of an aligned memory allocator:\n// Aligned allocation function.\n// Determine total amount of memory to allocate.\n// Allocate an unaligned block & convert address to a  \nMemory Management\nWhen this block is later freed, the code will pass us the adjusted address, \nnot the original address we allocated.\nextra bytes we allocated in order to align the data in the ﬁ rst place.\n// Aligned allocation function.\n// Determine total amount of memory to allocate.\n// Allocate an unaligned block & convert address to a  \nSingle-Frame and Double-Buffered Memory Allocators\nVirtually all game engines allocate at least some temporary data during the \ncommon that many engines support single- and double-buﬀ ered allocators.\nSingle-Frame Allocators\nA single-frame allocator is implemented by reserving a block of memory and \nmanaging it with a simple stack allocator as described above.\nof each frame, the stack’s “top” pointer is cleared to the bott om of the memory \nAllocations made during the frame grow toward the top of the block.\n// Clear the single-frame allocator’s buffer every  \nMemory Management\n// Allocate from the single-frame buffer.\nvoid* p = g_singleFrameAllocator.alloc(nBytes);\nOne of the primary beneﬁ ts of a single-frame allocator is that allocated \nmemory needn’t ever be freed—we can rely on the fact that the allocator will \nSingle-frame allocators are also blind-\nThe one big negative is that using a single-frame allocator requires \nrealize that a memory block allocated out of the single-frame buﬀ er will only \na single-frame memory block across the frame boundary!\nDouble-Buffered Allocators\nA double-buﬀ ered allocator allows a block of memory allocated on frame i to \nallocators of equal size and then ping-pong between them every frame.\nalloc(U32 nBytes)\nm_stack[m_curStack].alloc(nBytes);\nClear the single-frame allocator every frame as   \n// buffered allocator.\n// Allocate out of the current buffer, without  \nAgain, this memory never\nvoid* p = g_doubleBufAllocator.alloc(nBytes);\nThis kind of allocator is extremely useful for caching the results of asyn-\nbuﬀ ered allocations that might be made during this frame.\nMemory Fragmentation\nAnother problem with dynamic heap allocations is that memory can become \nWhen a program ﬁ rst runs, its heap memory is entirely \nWhen a block is allocated, a contiguous region of heap memory of the \nMemory Management\ntions of various sizes occur in random order, the heap memory begins to look \nThe problem with memory fragmentation is that allocations may fail \nproblem is that allocated memory blocks must always be contiguous.\nenough bytes are available but the allocation fails because they are not contigu-\nAfter one allocation...\nAfter eight allocations...\nAfter eight allocations and three frees...\nAfter n allocations and m frees...\nMemory fragmentation.\nous blocks of physical memory known as pages into a virtual address space, in \nmemory system.\nconsole game engines still do not make use of virtual memory due to the in-\nAvoiding Fragmentation with Stack and Pool Allocators\nstack and/or pool allocators.\nA stack allocator is impervious to fragmentation because allocations are \nthat in which they were allocated.\nA pool allocator is also free from fragmentation problems.\nMemory Management\nA stack allocator is free from fragmentation problems.\nSingle free block, always contiguous\nAllocated blocks, always contiguous\nallocation\nAllocated and free blocks all the same size\nA pool allocator is not degraded by fragmentation.\nder, neither a stack-based allocator nor a pool-based allocator can be used.\nby shift ing allocated blocks from higher memory addresses down to lower \ngorithm is to search for the ﬁ rst “hole” and then take the allocated block im-\nrepeated, eventually all the allocated blocks will occupy a contiguous region \nof memory at the low end of the heap’s address space, and all the holes will \nThe shift ing of memory blocks described above is not particularly tricky \nlocated blocks of memory around.\nmemory block so that they point to the correct new address aft er the shift .\nDefragmentation by shifting allocated blocks to lower addresses.\nof memory.\nit can be coded to handle memory relocation properly.\never a block of memory is shift ed within the heap, the linked list of all smart \nmemory can be adjusted appropriately.\nWhen an allocated block is shift ed in \nmemory, the handle table can be scanned and all relevant pointers found and \ntable, their values never change no matt er how the memory blocks are shift ed, \nso the objects that use the handles are never aﬀ ected by memory relocation.\nAnother problem with relocation arises when certain memory blocks can-\nally to arrange for the library in question to allocate its memory from a special \npointers are carefully tracked and relocated manually whenever a memory \nWe can allow up to N allocated \nMemory Management\nblocks to be shift ed each frame, for some small value of N like 8 or 16.\nﬁ rst to understand how modern processors read and write memory.\nern processors utilize a high-speed memory cache.\nA cache is a special type of memory that can be read from and writt en to \ncaching is to load a small chunk of memory into the high-speed cache when-\nrequired data is not already in the cache does main RAM have to be accessed.\nWhen caching techniques were ﬁ rst developed, the cache memory was locat-\nof memory module than main RAM in order to give it the required boost in \nHowever, cache memory was expensive, so the cache size was usually \nfaster type of cache memory was developed that was located on the CPU die \nThis gave rise to two distinct types of cache memory: an on-die level 1 \nanyway.) But suﬃ  ce it to say that RAM is slower than L2 cache memory, and \nMemory Management\nthe CPU writes data to a memory address and then reads the data back before \nThe best way to avoid D-cache misses is to organize your data in contiguous \n(i.e., you don’t “jump around” in memory a lot), a single cache miss will load \n“jump around” within the contiguous memory block), you achieve the mini-\nmemory.\nFunctions are laid out in memory in the order they appear in the \nin memory.\nkeeping our functions contiguous in memory.)\nin memory but rather linked to one another via pointers (e.g., STL’s ",
      "keywords": [
        "memory",
        "memory block",
        "cache",
        "Engine Support Systems",
        "block",
        "Memory Management",
        "dynamic memory allocation",
        "stack allocator",
        "main RAM",
        "stack",
        "allocator",
        "Support Systems",
        "cache memory",
        "memory allocation",
        "RAM"
      ],
      "concepts": [
        "allocating",
        "allocators",
        "allocations",
        "allocate",
        "block",
        "cache",
        "caching",
        "aligned",
        "alignments",
        "free"
      ],
      "similar_chapters": [
        {
          "book": "Game_Engine_Architecture",
          "chapter": 13,
          "title": "",
          "score": 0.596,
          "base_score": 0.446,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 8,
          "title": "",
          "score": 0.58,
          "base_score": 0.43,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 38,
          "title": "",
          "score": 0.542,
          "base_score": 0.542,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 6,
          "title": "",
          "score": 0.489,
          "base_score": 0.339,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 15,
          "title": "",
          "score": 0.431,
          "base_score": 0.431,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "memory",
          "allocator",
          "block",
          "stack",
          "allocated"
        ],
        "semantic": [],
        "merged": [
          "memory",
          "allocator",
          "block",
          "stack",
          "allocated"
        ]
      },
      "topic_id": 2,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.2593430116911726,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:57.759498+00:00"
      }
    },
    {
      "chapter_number": 13,
      "title": "Segment 13 (pages 247-268)",
      "start_page": 247,
      "end_page": 268,
      "summary": "Game engines that make use of container classes inevitably make use of vari-\nAdd a new element to the container.\nRemove an element from the container; may require a ﬁ nd op-\nAccessing each element of the container in \nAccessing elements in the container in an arbitrary or-\nAn iterator is a litt le class that “knows” how to eﬃ  ciently visit the elements \nrefers to one element in the container at a time, it can be advanced to the \nor not all elements in the container have been visited.\nﬁ rst of the following two code snippets iterates over a C-style array using a \npointer, while the second iterates over an STL linked list using almost identi-\nGame engines that make use of container classes inevitably make use of vari-\nAdd a new element to the container.\nRemove an element from the container; may require a ﬁ nd op-\nAccessing each element of the container in \nAccessing elements in the container in an arbitrary or-\nAn iterator is a litt le class that “knows” how to eﬃ  ciently visit the elements \nrefers to one element in the container at a time, it can be advanced to the \nor not all elements in the container have been visited.\nﬁ rst of the following two code snippets iterates over a C-style array using a \npointer, while the second iterates over an STL linked list using almost identi-\nstd::vector) stores its elements contiguously in memory and requires no \nlinked list (e.g., std::list) wraps each element in a “link” data structure \nthat contains a pointer to the next element and possibly also a pointer to the \nthe elements in a linked list need not be contiguous in memory and oft en \nrays are usually bett er than linked lists in terms of cache performance (unless \nthe nodes of the linked list are themselves allocated from a small, contiguous \nlinked list is bett er for situations in which speed of inserting and removing \nMany game engines provide their own custom implementations of the com-\nthird-party libraries like STL (for example, searching for the n most-\ncommon ways in which game engine programmers tend to tackle contain-\nful set of container classes covering prett y much every type of data structure \nsuch as ﬁ nding an element in a container, which can be applied to virtually \nSTL does a lot of dynamic memory allocation, and it’s sometimes chal-\nOn the other hand, STL is not generally well-suited for use on memory-\nprobably also not OK—the std::list class dynamically allocates a \n(htt p://www.stlport.org), an implementation of STL that was speciﬁ cally \nUsing STL on a game engine \nBoost provides a lot of useful facilities not available in STL.\nFixed-size C-style arrays are used quite a lot in game programming, because \ntend to turn either to linked lists or dynamic arrays.\nThe easiest way to implement a dynamic array is to allocate an n-element \nthan n elements to it.\nSo, as with all data structures that allocate memory, \nLinked Lists\nremove elements at random is paramount, then a linked list is usually the data \nLinked lists are quite easy to implement, but they’re also \nand tricks for creating robust linked lists.\nThe Basics of Linked Lists\nA linked list is a very simple data structure.\nEach element in the list has a \npointer to the next element, and, in a doubly-linked list , it also has a pointer to \nThese two pointers are referred to as links.\nThe list as a \nThe head pointer points to the ﬁ rst element, while the tail pointer points \nto the last element.\nInserting a new element into a doubly-linked list involves adjusting the \nwhen adding a node to a linked list:\nAdding the ﬁ rst element to a previously-empty list;\nRemoving an element involves the same kinds of operations in and \nremoving the last element (emptying the list).\nThe Link Data Structure\nLinked list code isn’t particularly tough to write, but it can be error-prone.\nAs such, it’s usually a good idea to write a general-purpose linked list facility \nthat can be used to manage lists of any element type.\nseparate the data structure that contains the links (i.e., the next and previ-\nous pointers) from the element data structure.\nThe link data structure is typi-\ncally a simple struct or class, oft en called something like Link, Node, or \nThe four cases that must be handled when adding an element to a linked list: add \nLink<ELEMENT>* m_pPrev;\nLink<ELEMENT>* m_pNext;\nAn extrusive list is a linked list in which the Link data structures are entirely \nseparate from the element data structures.\nEach Link contains a pointer to the \na linked list, a link is allocated for it, and the pointers to the element and the \nWhen an element is removed \nfrom a linked list, its link can be freed.\ntiple linked lists simultaneously—all we need is one link per list.\nside is that the Link objects must be dynamically allocated.\nAn intrusive list is a linked list in which the Link data structure is embedded \nwe allocate an element.\nm_link;\nWe can also derive our element class from class Link.\ntance like this is virtually identical to embedding a Link as the ﬁ rst member \nof the class, but it has the additional beneﬁ t of allowing a pointer to a link \n(Link<SomeElement>*) to be down-cast into a pointer to the element itself \nLink<ELEMENT>* m_pPrev;\nLink<ELEMENT>*  m_pNext;\n// No ELEMENT* pointer required, thanks to\nThe big pitfall of the intrusive linked list design is that it prevents an ele-\nment from residing in more than one linked list at a time (because each ele-\nN concurrent lists by providing it with N embedded link instances (in which \nThe choice between intrusive and extrusive linked lists depends on the \nmemory allocation must be avoided at all costs, then an intrusive list is prob-\nthird-party library in a linked list and are unable or unwilling to modify that \nHead and Tail Pointers: Circular Lists\nTo fully implement a linked list, we need to provide a head and a tail pointer.\nLink<ELEMENT>* \nLink<ELEMENT>* \nLinkedList and a Link—they both contain a pair of pointers to Link.\nLink<ELEMENT> \nus to make the linked list circular as shown in Figure 5.9.\nthe m_pPrev pointer of the ﬁ rst “real” node in the list.\nto remove an element from a linked list when “loose” head and tail pointers \nvoid LinkedList::remove(Link<ELEMENT>& link)\n// Removing last element in the list.\n// Removing first element in the list.\nWhen the head and tail pointers are stored in a link, the linked list can be made \nvoid LinkedList::remove(Link<ELEMENT>& link)\n// The link must currently be a member of the list.\n// list.\ncircularly linked list approach: A link’s m_pPrev and m_pNext pointers are \nnever null, unless the link is not a member of any list (i.e., the link is unused/\nm_pPrev pointer of the ﬁ rst element in the list is always null, as is the m_pN-\next pointer of the last element.\nAnd if there is only one element in the list, that \nlink’s next and previous pointers will both be null.\nknow whether or not a given Link is a member of a list or not.\nSingly-Linked Lists\nA singly-linked list is one in which the elements have a next pointer, but no pre-\n(The list as a whole might have both a head and a tail pointer, or \nelement from the list.\nlist from the head in order to ﬁ nd the previous element, so that its m_pNext\nfor a doubly-linked list, but it’s an O(n) operation for a singly-linked list.\nlinked lists are doubly linked.\nonly ever add and remove elements from the head of the list (as when imple-\nwith a queue—and your list has both a head and a tail pointer), then you can \nget away with a singly-linked list and save yourself some memory.\nDictionaries and Hash Tables\ntree or as a hash table.\nIn a hash table implementation, the values are stored in a ﬁ xed-size table, \npair into a hash table, the key is ﬁ rst converted into integer form via a pro-\nhash table is calculated by taking the hashed key modulo the size of the table.\nthe integer key by the table size.\nSo if the hash table has ﬁ ve slots, then a key of \nCollisions: Open and Closed Hash Tables\nSometimes two or more keys end up occupying the same slot in the hash table.\ning rise to two diﬀ erent kinds of hash tables:\n. In an open hash table (see Figure 5.10), collisions are resolved \nin the form of a linked list.\nwhenever a new key-value pair is added to the table.\n. In a closed hash table (see Figure 5.11), collisions are resolved via \nnumber of key-value pairs that can reside in the table (because each slot \nhash table is that it uses up a ﬁ xed amount of memory and requires no dy-\nHashing\nHashing is the process of turning a key of some arbitrary data type into an \nMathematically, given a key k, we want to generate an integer hash value h us-\ning the hash function H, and then ﬁ nd the index i into the table as follows:\nIf the keys are unique integers, the hash function can be the identity func-\nAn open hash table.\nA closed hash table.\nIf the key is a string, we can employ a string hashing function, which combines \nhash table.\nStrings are probably the most prevalent type of key you’ll encounter, so \nit’s particularly helpful to know a “good” string hashing function.\nImplementing a Closed Hash Table\nIn a closed hash table, the key-value pairs are stored directly in the table, rath-\ner than in a linked list at each table entry.\nhash table.\nWhen using closed hashing, it is a good idea to make your table size a \nslides.pdf for a good discussion of why prime hash table sizes are preferable.\nStrings\nStrings are ubiquitous in almost every soft ware project, and game engines are \nThe Problem with Strings\neither have to hard-code limitations on the sizes of our strings, or we need to \ndynamically allocate our string buﬀ ers.\na string class, rather than deal directly with character arrays.\nstring class should we use?\nSTL provides a reasonably good string class, but if \ngame engine for things like resource ﬁ le names and object ids.\nHow our engine deals with these internal strings oft en has pervasive ram-\nhand, comparing strings requires an O(n) scan of the character arrays using a \nfunction like strcmp() (where n is the length of the string).\nCopying a string \nString Classes\nString classes can make working with strings much more convenient for the \nHowever, a string class can have hidden costs that are diﬃ  cult \nFor example, passing a string to a function \nCopying strings might involve dynamic \nFor this reason, in game programming I generally like to avoid string \nHowever, if you feel a strong urge to use a string class, make sure you \nyour string class: Does it treat all string buﬀ ers as read-only?\nStrings\nwrite.) As a rule of thumb, always pass string objects by reference, never by \nvalue (as the latt er oft en incurs string-copying costs).\nand oft en to ensure that your string class isn’t becoming a major source of lost \nPath class could add signiﬁ cant value over a raw C-style character array.\nStrings seem like a natural choice for such identiﬁ ers.\ntheir ﬁ le paths, which of course are strings.\nstring, but with the speed of an integer.\nHashed String Ids\nOne good solution is to hash our strings.\nString hash codes can be compared just \nin a hash table, then the original string can always be recovered from the hash \nThis is useful for debugging purposes and to permit hashed strings to \nterm string id to refer to such a hashed string.\nstrings might end up with the same hash code).\nsonable input strings we might use in our game.\nAft er all, a 32-bit hash code \ngorithm to hash our strings, and we didn’t encounter a single collision in over \nConceptually, it’s easy enough to run a hash function on your strings in order \nto generate string ids.\nMost game engines that use string \ning of strings, but we also preprocess our source code using a simple utility \nThis permits string ids to \nthat generates a string id at runtime is not a constant, so it cannot be used as \ninterning the string, because in addition to hashing it, the string is typi-\ncally also added to a global string table.\ncapable of hashing strings into string ids.\ndata for consumption by your engine, the strings will already have been \nhashed.\nThe hashing function must be run on the string, which can be an expensive \nIn addition, memory must be allocated for the string, and it must be copied \nAs a result (if you are not generating string ids at \nStrings\nthis because the latt er implementation causes the strings to be unnecessarily ",
      "keywords": [
        "element",
        "linked list",
        "list",
        "Engine Support Systems",
        "link",
        "STL",
        "string",
        "STL linked list",
        "hash table",
        "Container",
        "Strings",
        "Hash",
        "elements",
        "Support Systems",
        "Link Data Structure"
      ],
      "concepts": [
        "string",
        "strings",
        "link",
        "element",
        "elements",
        "list",
        "memory",
        "classes",
        "hash",
        "engine"
      ],
      "similar_chapters": [
        {
          "book": "Game_Engine_Architecture",
          "chapter": 12,
          "title": "",
          "score": 0.596,
          "base_score": 0.446,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 8,
          "title": "",
          "score": 0.572,
          "base_score": 0.422,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 6,
          "title": "",
          "score": 0.57,
          "base_score": 0.42,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 37,
          "title": "",
          "score": 0.406,
          "base_score": 0.406,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 15,
          "title": "",
          "score": 0.378,
          "base_score": 0.378,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "link",
          "hash",
          "element",
          "string",
          "linked"
        ],
        "semantic": [],
        "merged": [
          "link",
          "hash",
          "element",
          "string",
          "linked"
        ]
      },
      "topic_id": 2,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.25035642259732055,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:57.759532+00:00"
      }
    },
    {
      "chapter_number": 14,
      "title": "Segment 14 (pages 269-288)",
      "start_page": 269,
      "end_page": 288,
      "summary": "the strings—the game itself should only ever use the ids.\nimpact on the memory footprint of the ﬁ nal shipping game.\nLocalization of a game (or any soft ware project) is a big undertaking.\nHere are some tips that should help you plan your game engine \nStrings\nANSI strings \ngame engines are UTF-8 and UTF-16.\nThis works because the ﬁ rst character of a \nstring as well.\n“wide ” UTF-16 character (WCS), while the char type is used both for ANSI \nPrett y much every standard C library function that deals with strings has \nWindows also provides functions for translating between ANSI character \nVariants of some common standard C library string functions for use with ANSI, \nStrings\nThe Xbox 360 soft ware development kit (XDK) uses WCS strings prett y much \nexclusively, for all strings—even for internal strings like ﬁ le paths.\ning is a bit wasteful on memory, so diﬀ erent game engines may employ diﬀ er-\nto manage a database of all human-readable strings in your game, so that \ntral database of human-readable strings and an in-game system for looking \nThese four strings would be stored in the localization \nthe game.\nOnce our game’s strings have been translated into \nAdditional columns can be added for each new language your game \n(CSV ) ﬁ le and parsed by the game engine or as complex as a full-ﬂ edged Or-\nthe game engine, as long as it can read in the string ids and the correspond-\ning Unicode strings for whatever language(s) your game supports.\nExample of a string database used for localization.\nStrings\nmight be done via a conﬁ guration sett ing which is ﬁ xed during the installa-\nthe ﬂ y via an in-game menu.\nGame engines are complex beasts, and they invariably end up having a large \nplayer via one or more options menus in-game.\nFor example, a game might \nwalk speed might be exposed as an option so that it can be ﬁ ne-tuned during \nThere are a number of simple ways to load and save conﬁ guration options:\nText conﬁ guration ﬁ les.\nﬁ les.\nThe format of these ﬁ les varies widely from engine to engine, but it \nFor example, Windows INI ﬁ les (which are used \nThe XML format is another common choice for conﬁ gurable game op-\ntions ﬁ les.\nGame options are sometimes \nstored on these cards, along with saved games.\ntree, where the interior nodes (known as registry keys) act like ﬁ le fold-\nregistry key) for its exclusive use, and then store any set of options with-\nINI ﬁ les, and in fact it was introduced into Windows as a replacement \nfor the ever-growing network of INI ﬁ les used by both the operating \nThe engine might provide a mechanism for controlling any option \nset of the game’s options here.\npurchased and unlockable game features, game options, and other in-\nMost game engines diﬀ erentiate between global options and per-user options .\nIt is also a useful concept during development of the game, \nIn a console game, the user is typically \nusually implemented as ﬁ les on the media in question.\nder Application Data and can use it to store whatever per-user information it \nWindows games sometimes store per-user conﬁ guration data in the reg-\ntions can manage per-user conﬁ guration options by simply reading and writ-\nIn this section, we’ll take a brief look at how some real game engines manage \ntheir conﬁ guration options.\nThe Quake family of engines uses a conﬁ guration management system known \nname, its value as a string or ﬂ oat, a set of ﬂ ag bits, and a pointer to the next \nnot the CVAR will be saved into a conﬁ guration ﬁ le called conﬁ g.cfg.\nis set, the value of the CVAR will persist across multiple runs of the game.\nThe Ogre3D rendering engine uses a collection of text ﬁ les in Windows INI \nformat for its conﬁ guration options.\ncontains a search path specifying where game assets (a.k.a.\nbe quite easy to change it to search for its conﬁ guration ﬁ les in the user’s C:\\\nwrites brand new conﬁ guration ﬁ les, as well.\nNaughty Dog’s Uncharted engine makes use of a number of conﬁ guration \nIn-Game Menu Settings\nThe Uncharted engine supports a powerful in-game menu system, allowing \ndevelopers to control global conﬁ guration options and invoke commands.\nThe data types of the conﬁ gurable options must be relatively simple (primar-\nEach conﬁ guration option is implemented as a global variable.\nmenu sett ings are saved in an INI-style text ﬁ le, allowing the saved global vari-\nany option which is not saved will take on its programmer-speciﬁ ed default \nunless of course a user has saved a custom value for that particular option.\nThe vast majority of engine and game conﬁ guration information in Uncharted \ninto binary ﬁ les that can be loaded by the engine.\nout header ﬁ les containing C struct declarations for every data type deﬁ ned \nThese header ﬁ les allow the engine to properly interpret the data \ncontained in the loaded binary ﬁ les.\nthe game.\n;; Define a new data type called simple-animation.\n(name             string)\nThis Scheme code would generate the following C/C++ header ﬁ le:\nIn-game, the data can be read by calling the LookupSymbol() function, which \nstring options all the way to complex, nested, interconnected data structures.\nA game engine therefore \nbecause memory is usually scarce, a game engine needs to ensure that only \none copy of each media ﬁ le is loaded into memory at any given time.\nMost game engines employ some \nEvery resource manager makes heavy use of the ﬁ le system.\nsonal computer, the ﬁ le system is exposed to the programmer via a library \nHowever, game engines oft en “wrap” the native \nﬁ le system API in an engine-speciﬁ c API, for two primary reasons.\nengine might be cross-platform, in which case the game engine’s ﬁ le system \nSecond, the operating system’s ﬁ le system API \nmight not provide all the tools needed by a game engine.\nengines support ﬁ le streaming (i.e., the ability to load data “on the ﬂ y” while \nthe game is running), yet most operating systems don’t provide a streaming \nﬁ le system API out of the box.\nConsole game engines also need to provide ac-\nto optional hard drives to a DVD-ROM or Blu-ray ﬁ xed disk to network ﬁ le \nengine’s ﬁ le system API.\nIn this chapter, we’ll ﬁ rst explore the kinds of ﬁ le system APIs found in \nmodern 3D game engines.\nA game engine’s ﬁ le system API typically addresses the following areas of \nz manipulating ﬁ le names and paths,\nz opening, closing, reading and writing individual ﬁ les,\nz handling asynchronous ﬁ le I/O requests (for streaming).\nA path is a string describing the location of a ﬁ le or directory within a ﬁ le sys-\nEach operating system uses a slightly diﬀ erent path format, but \nvolume/directory1/ directory2/…/directoryN/ﬁ le-name\nIn other words, a path generally consists of an optional volume speciﬁ er fol-\nnames a directory along the route from the root directory to the ﬁ le or direc-\nIf the path speciﬁ es the location of a ﬁ le, the last compo-\nnent in the path is the ﬁ le name; otherwise it names the target directory.\nroot directory is usually indicated by a path consisting of the optional volume \nspeciﬁ er followed by a single path separator character (e.g., / on UNIX, or C:\\\nz UNIX uses a forward slash (/) as its path component separator, while \nz Mac OS 8 and 9 use the colon (:) as the path separator character.\nThe entire ﬁ le system is contained within a single monolithic \na result, UNIX paths never have a volume speciﬁ er.\nz On Microsoft  Windows, volumes can be speciﬁ ed in two ways.\ndisk drive is speciﬁ ed using a single lett er followed by a colon (e.g., the \nz Under DOS and early versions of Windows, a ﬁ le name could be up to \nseparated from the main ﬁ le name by a dot.\nthe ﬁ le’s type, for example .txt for a text ﬁ le or .exe for an executable \nﬁ le.\nIn recent Windows implementations, ﬁ le names can contain any \nﬁ nal dot are still interpreted as the ﬁ le’s extension by many applications \nz Each operating system disallows certain characters in the names of ﬁ les \nFor example, ﬁ le and directory names may \nz Both UNIX and Windows have the concept of a current working directory \nz Operating systems that support multiple volumes, like Windows, also \nz Consoles oft en also employ a set of predeﬁ ned path preﬁ xes to repre-\nAll paths are speciﬁ ed relative to some location within the ﬁ le system.\npath is speciﬁ ed relative to the root directory, we call it an absolute path .\nit is relative to some other directory in the ﬁ le system hierarchy, we call it a \nrator character (/ or \\), while relative paths have no leading path separator.\nOn Windows, both absolute and relative paths may have an optional volume \nz \\game\\assets\\animation\\walk.anim (current working volume)\nz System32 (relative to CWD \\Windows on the current volume)\nz X:animation\\walk.anim (relative to CWD \\game\\assets on the X:\nz src/audio/effects.cpp (relative to CWD /game)\nstring representing the location of a single ﬁ le or directory within the ﬁ le \nA search path is a string containing a list of paths, each sepa-\nwhen looking for a ﬁ le.\nmand prompt, the operating system ﬁ nds the executable ﬁ le by searching \nSome game engines also use search paths to locate resource ﬁ les.\nample, the Ogre3D rendering engine uses a resource search path contained in \na text ﬁ le named resources.cfg.\nThe ﬁ le provides a simple list of directories \nPath APIs\nClearly paths are much more complex than simple strings.\ning the directory, ﬁ lename and extension, canonicalizing a path, converting \nﬁ le shlwapi.h. Complete documentation for this API is provided on the \ncross-platform game engine, we cannot use platform-speciﬁ c APIs directly.\ngame engine may not need all of the functions provided by an API like sh-\nFor these reasons, game engines oft en implement a stripped-\ndown path-handling API that meets the engine’s particular needs and works \nEvery ﬁ le I/O \nof the bytes passing between the program and the ﬁ le on disk.\nWe say a ﬁ le \nC library’s buﬀ ered ﬁ le I/O routines are sometimes referred to as the stream \nI/O API, because they provide an abstraction which makes disk ﬁ les look like \nThe standard C library functions for buﬀ ered and un-buﬀ ered ﬁ le I/O are \ntion CreateFile() creates or opens a ﬁ le for writing or reading, ReadFile()",
      "keywords": [
        "Engine Support Systems",
        "game",
        "Windows",
        "game engine",
        "conﬁ guration",
        "system",
        "Engine Conﬁ guration",
        "conﬁ guration options",
        "Engine",
        "system API",
        "API",
        "path",
        "options",
        "string",
        "Strings"
      ],
      "concepts": [
        "string",
        "strings",
        "game",
        "gaming",
        "paths",
        "windows",
        "options",
        "optional",
        "engine",
        "data"
      ],
      "similar_chapters": [
        {
          "book": "Game_Engine_Architecture",
          "chapter": 16,
          "title": "",
          "score": 0.591,
          "base_score": 0.441,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 15,
          "title": "",
          "score": 0.494,
          "base_score": 0.344,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 41,
          "title": "",
          "score": 0.336,
          "base_score": 0.336,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 42,
          "title": "",
          "score": 0.301,
          "base_score": 0.301,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "le",
          "conﬁ guration",
          "guration",
          "options",
          "conﬁ"
        ],
        "semantic": [],
        "merged": [
          "le",
          "conﬁ guration",
          "guration",
          "options",
          "conﬁ"
        ]
      },
      "topic_id": 5,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.21292711175735968,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:57.759562+00:00"
      }
    },
    {
      "chapter_number": 15,
      "title": "Segment 15 (pages 289-307)",
      "start_page": 289,
      "end_page": 307,
      "summary": "an open ﬁ le handle.\nSome game teams ﬁ nd it useful to manage their own buﬀ ers.\nthe Red Alert 3 team at Electronic Arts observed that writing data into log ﬁ les \nA game engine can be writt en to use the standard C library’s ﬁ le I/O functions or \nHowever, many game engines wrap the ﬁ le \nOpen a ﬁ le\nRead from a ﬁ le\nWrite to a ﬁ le\nBuffered and unbuffered ﬁ le operations in the standard C library.\n6. Resources and the File System\nBoth of the standard C library’s ﬁ le I/O libraries are synchronous, meaning that \nIn order to support streaming, we must utilize an asynchronous ﬁ le I/O \nﬁ le I/O library out of the box.\nIf an asynchronous ﬁ le \n6. Resources and the File System\n6. Resources and the File System\nIt’s important to remember that ﬁ le I/O is a real-time system, subject to dead-\nAsynchronous ﬁ le I/O works by handling I/O requests in a separate thread .\nThe Resource Manager\nEvery game is constructed from a wide variety of resources (sometimes called \nA game’s resources must be managed, both in \nresource manager of some kind.\nEvery resource manager is comprised of two distinct but integrated com-\nmanages the resources at runtime, ensuring that they are loaded into memory \nIn some engines, the resource manager is a cleanly-designed, uniﬁ ed, \ncentralized subsystem that manages all types of resources used by the game.\nIn other engines, the resource manager doesn’t exist as a single subsystem \nand some of the implementation details of a typical game engine resource \nOff-Line Resource Management and the Tool Chain\nOn a small game project, the game’s assets can be managed by keeping loose \nSome game teams use a source code revision control system to manage \ntheir resources.\nmany source control systems work by copying ﬁ les from the central reposito-\nry down to the user’s local machine, the sheer size of the asset ﬁ les can render \nThe Resource Manager\n6. Resources and the File System\nﬁ les he or she actually needs.\nThe Resource Database\nFor every resource that passes through the asset \nthat resource should be processed.\nProcessing individual resource \nsome kind of semi-automated resource pipeline, and the data that drives the \npipeline is stored in some kind of resource database.\nThe resource database takes on vastly diﬀ erent forms in diﬀ erent game \nIn one engine, the metadata describing how a resource should be \nstored as so-called blind data within a Maya ﬁ le).\nsource resource ﬁ le might be accompanied by a small text ﬁ le that describes \nStill other engines encode their resource build-\ning metadata in a set of XML ﬁ les, perhaps wrapped in some kind of custom \nWhatever its form, a resource database must provide the following basic \nz The ability to deal with multiple types of resources, ideally (but certainly \nz The ability to create new resources.\nz The ability to delete resources.\nz The ability to move a resource’s source ﬁ le(s) from one location to an-\nz The ability of a resource to cross-reference other resources (e.g., the ma-\nThese cross-references typically drive both the resource building \nz It is also very helpful if the resource database supports searching or \nThe Resource Manager\n6. Resources and the File System\nﬁ nd a resource whose name momentarily escapes them.\nand implemented properly, the resource database can quite literally make \nSome Successful Resource Database Designs\nsions when designing their resource database.\nUnreal’s resource database is managed by their über-tool, UnrealEd .\nis responsible for literally everything, from resource metadata management to \naccess literally every resource that is consumed by the engine.\nresource data in most other game engines is fragmented across countless in-\nJust being able to ﬁ nd any resource easily in \nmust be explicitly imported into Unreal’s resource database.\nmost game engines, any old data can be thrown into the resource database, \nall resource data is stored in a small number of large package ﬁ les .\nThe Resource Manager\n6. Resources and the File System\ntegrated, and streamlined asset creation toolkit, resource database, and asset- \naway from MySQL in favor of an XML ﬁ le-based asset database, managed \nBuilder, Naughty Dog’s resource database GUI, is depicted in Figure 6.2.\ngame designers can organize their resources in any way they see ﬁ t.\ntypes of resources can be created and managed within any folder, including \nThe asset conditioning pipeline on UDF consists of a set of resource ex-\nthese are packaged into one of two types of resource ﬁ les: actors and levels.\nto package it into binary .pak ﬁ les that can be loaded by the game engine.\nis much simpler than in many engines, where resources have to be exported \nThe beneﬁ ts of the resource pipeline design used by Naughty Dog in-\nz Granular resources.\nThe Resource Manager\nThe front-end GUI for Naughty Dog’s off-line resource database, Builder.\n6. Resources and the File System\nresource types are granular enough that the team almost never has \nwaste any resources creating features they didn’t need.\nsource assets (native DCC ﬁ les, like Maya .ma ﬁ les or photoshop .psd \nﬁ les) make up a particular resource.\nresource database GUI.\nlevels, another to manage the majority of resources in the resource data-\nresource database front-end).\nOgre’s Resource Manager System\nresource.\nprogrammer can quite easily implement a resource manager for a brand new \nkind of asset and integrate it easily into Ogre’s resource framework.\nOne of the drawbacks of Ogre’s resource manager is that it is a runtime- \nOgre lacks any kind of oﬀ -line resource database.\nprovide some exporters which are capable of converting a Maya ﬁ le into a \nMaya ﬁ le should be exported and processed must be entered by the user do-\nIn summary, Ogre’s runtime resource manager is powerful and well-de-\nmodern resource database and asset conditioning pipeline on the tools side.\nXNA’s resource management system is unique, in that it lever-\nmanage and build the assets in the game as well.\nIn Section 1.7, we learned that resource data is typically created using ad-\nSo the majority of resource data \nis passed through an asset conditioning pipeline (ACP) on its way to the game \nEvery resource pipeline starts with a collection of source assets in native \nis the plug-in’s job to export the data into some kind of intermediate ﬁ le \nThe Resource Manager\n6. Resources and the File System\n2. Resource compilers .\nNot all types of resources need to be compiled—\n3. Resource linkers .\nMultiple resource ﬁ les sometimes need to be combined \ninto a single useful package prior to being loaded by the game engine.\nC++ program into an executable ﬁ le, and so this process is sometimes \ncalled resource linking.\nite resource like a 3D model, we might need to combine the data from \nmultiple exported mesh ﬁ les, multiple material ﬁ les, a skeleton ﬁ le, and \nmultiple animation ﬁ les into a single resource.\nNot all types of resources \nneed to be linked—some assets are game-ready aft er the export or com-\nMuch like compiling the source ﬁ les in a C or C++ project and then linking \nsets (in the form of Maya geometry and animation ﬁ les, Photoshop PSD ﬁ les, \nraw audio clips, text ﬁ les, etc.), converts them into game-ready form, and then \nthe source ﬁ les in a computer program, game assets oft en have interdepen-\nIf the format of the ﬁ les used \nSome game engines employ data \nasset ﬁ les and engine code tend to become bulky.\nRuntime Resource Management\nLet us turn our att ention now to how the assets in our resource database are \nResponsibilities of the Runtime Resource Manager\nA game engine’s runtime resource manager takes on a wide range of responsi-\nz Manages the lifetime of each resource loads needed resources and un-\nloads resources that are no longer needed.\nz Handles loading of composite resources.\ncomprised of other resources.\nresource that consists of a mesh, one or more materials, one or more \nto texture resources; animations refer to a skeleton, which ultimately \nWhen loading a composite resource, \nthe resource manager must ensure that all necessary subresources are \nz Manages the memory usage of loaded resources and ensures that re-\nThe Resource Manager\n6. Resources and the File System\nz Permits custom processing to be performed on a resource aft er it has been \nloaded, on a per-resource-type basis.\nas logging in or load-initializing the resource.\nwhich a wide variety of resource types can be managed.\nof resources as they are needed by the game development team.\nz Handles streaming (i.e., asynchronous resource loading), if the engine \nIn some game engines (typically PC engines), each individual resource is \nmanaged in a separate “loose” ﬁ le on-disk.\ntypically doesn’t care where resource ﬁ les are located within the resource \nHere’s a typical resource directory tree for a hypothetical game called \nResources\nRoot of all resources.\nFirst level’s resources.\nSecond level’s resources.\nOther engines package multiple resources together in a single ﬁ le, such as \ndata from ﬁ les, the three biggest costs are seek times (i.e., moving the read head \nindividual ﬁ le, and the time to read the data from the ﬁ le into memory.\nthese, the seek times and ﬁ le-open times can be non-trivial on many operating \nsingle ﬁ le can be organized sequentially on the disk, reducing seek times to \nresource ﬁ les is eliminated.\nThe Ogre3D rendering engine’s resource manager permits resources to \nThe Ogre resource manager identiﬁ es all resources \nloose ﬁ les on disk, and a game programmer needn’t be aware of the dif-\noccupied by resources.\ntimes, as less data need be loaded into memory from the ﬁ xed disk.\nResources can be grouped together into a ZIP \nﬁ le and managed as a unit.\nThe Resource Manager",
      "keywords": [
        "Resource",
        "Resource Manager",
        "Resource Database",
        "game",
        "File System",
        "runtime resource manager",
        "game engine",
        "les",
        "data",
        "assets",
        "system",
        "File System resource",
        "resource data",
        "Resource Manager System",
        "engine"
      ],
      "concepts": [
        "resources",
        "assets",
        "tools",
        "data",
        "engine",
        "manage",
        "managed",
        "loading"
      ],
      "similar_chapters": [
        {
          "book": "Game_Engine_Architecture",
          "chapter": 16,
          "title": "",
          "score": 0.785,
          "base_score": 0.635,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 14,
          "title": "",
          "score": 0.494,
          "base_score": 0.344,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 40,
          "title": "",
          "score": 0.458,
          "base_score": 0.458,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 12,
          "title": "",
          "score": 0.431,
          "base_score": 0.431,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 17,
          "title": "",
          "score": 0.423,
          "base_score": 0.423,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "resource",
          "resources",
          "resource manager",
          "resource database",
          "les"
        ],
        "semantic": [],
        "merged": [
          "resource",
          "resources",
          "resource manager",
          "resource database",
          "les"
        ]
      },
      "topic_id": 5,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.28969207731248076,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:57.759599+00:00"
      }
    },
    {
      "chapter_number": 16,
      "title": "Segment 16 (pages 308-325)",
      "start_page": 308,
      "end_page": 325,
      "summary": "6. Resources and the File System\nResource File Formats\nEach type of resource ﬁ le potentially has a diﬀ erent format.\nmesh ﬁ le is always stored in a diﬀ erent format than that of a texture bitmap.\nMany game engine programmers roll their own ﬁ le formats for various \nof time needed to load and process resource data at runtime.\nResource GUIDs\nEvery resource in a game must have some kind of globally unique identiﬁ er \nThe most common choice of GUID is the resource’s ﬁ le system path \ncause it clearly maps each resource to a physical ﬁ le on-disk.\nHowever, a ﬁ le system path is by no means the only choice for a resource \nusing a ﬁ le system path as a resource identiﬁ er is infeasible.\nUnreal Engine 3 stores many resources in a single large ﬁ le known as a pack-\nvidual resource within a package a unique name which looks much like a ﬁ le \n(unique) name of the package ﬁ le with the in-package path of the resource \nThe Resource Registry\nIn order to ensure that only one copy of each unique resource is loaded into \nmemory at any given time, most resource managers maintain some kind of \nregistry of loaded resources.\nwhile the values are typically pointers to the resources in memory.\nWhenever a resource is loaded into memory, an entry for it is added to the \nWhenever a resource is \nWhen a resource is requested by the \ngame, the resource manager looks up the resource by its GUID within the re-\nIf the resource can be found, a pointer to it is simply returned.\nIf the resource cannot be found, it can either be loaded automatically or a \nLoading a resource is a slow operation, because it involves lo-\nalso possibly performing post-load initialization of the resource data once it \nto load the resource might cause a very noticeable hitch in the game’s frame \nThe Resource Manager\n6. Resources and the File System\nResource loading might be disallowed completely during active game-\nIn this model, all of the resources for a game level are loaded en \nResource loading might be done \nResource Lifetime\nThe lifetime of a resource is deﬁ ned as the time period between when it is ﬁ rst \nEach resource has its own lifetime requirements:\nz Some resources must be loaded when the game ﬁ rst starts up and must \nAny resource \nresource.\nz Other resources have a lifetime that matches that of a particular game \nThese resources must be in memory by the time the level is ﬁ rst \nbeing loaded into memory.\nThe question of when to load a resource is usually answered quite easily, \nquestion of when to unload a resource and reclaim its memory is not so eas-\nWe don’t want to unload a resource when level A is done, only to im-\nmediately reload it because level B needs the same resource.\nOne solution to this problem is to reference-count the resources.\never a new game level needs to be loaded, the list of all resources used by that \nlevel is traversed, and the reference count for each resource is incremented \nNext, we traverse the resources of any \nunneeded levels and decrement their reference counts by one; any resource \nlist of all resources whose reference count just went from zero to one and load \nFor example, imagine that level 1 uses resources A, B, and C, and that \nlevel 2 uses resources B, C, D, and E.\nTable 6.2 shows the reference counts of these ﬁ ve resources as the player plays \ntype to indicate that the corresponding resource actually exists in memory, \nwhile a grey background indicates that the resource is not in memory.\nence count in parentheses indicates that the corresponding resource data is \nMemory Management for Resources\nResource management is closely related to memory management , because we \nmust inevitably decide where the resources should end up in memory once \nThe destination of every resource is not always the \nThe Resource Manager\n6. Resources and the File System\nresource that is loaded and stays resident for the entire game (LSR resources) \nmight be loaded into one region of memory, while resources that are loaded \nneeds of the resource manager.\nHeap-Based Resource Allocation\nLevel 1 loads\nResource usage as two levels load and unload.\nStack-Based Resource Allocation\nA stack allocator can be used to load resources if the following \nz The game is linear and level-centric (i.e., the player watches a loading \nz Each level ﬁ ts into memory in its entirety.\ntor to load resources as follows: When the game ﬁ rst starts up, the load-and-\nstay-resident (LSR) resources are allocated ﬁ rst.\nply allocate its resources on the top of the stack.\nfreeing all of the level’s resources in one fell swoop without disturbing the LSR \nresources.\nThe Resource Manager\nLoading resources using a stack allocator.\n6. Resources and the File System\nstack allocator can be used is to ping-pong level loads.\nlevel A to level B, we simply free level A’s resources (by clearing the lower \nPool-Based Resource Allocation\nAnother resource allocation technique that is common in game engines that \nsupport streaming is to load resource data in equally-sized chunks.\nWhen resources are later unloaded, the chunks can be freed \nOf course, a chunk-based allocation approach requires that all resource \nWe cannot simply load an arbitrary resource ﬁ le in chunks, because the ﬁ le \nresource data must be designed with “chunkiness” in mind.\nFor example, when level A is loaded, it might allocate and make use of \nUnless a resource ﬁ le’s size is an exact multiple of the chunk \nsize, the last chunk in a ﬁ le will not be fully utilized (see Figure 6.5).\nchunks, the more onerous the restrictions on the layout of the resource data.\nat Naughty Dog, we use a chunky resource allocator as part of our resource \nThe Resource Manager\nChunky allocation of resources for levels A and B.\nThe last chunk of a resource ﬁ le is often not fully utilized.\n6. Resources and the File System\nResource Chunk Allocators\nit a resource chunk allocator for lack of a bett er name.\nA resource chunk allocator is not particularly diﬃ  cult to implement.\nIf we allocate memory in the unused regions of our resource chunks, what hap-\nof a resource chunk will magically disappear when that resource is unloaded.\nlocate memory out of level A’s chunks for data that is associated exclusively \nwith level A and only allocate from B’s chunks memory that is used exclu-\nThis requires our resource chunk allocator to manage each \nwhen loading resources, over and above the memory required for the resource \nSo a resource chunk allocator can be a fruitful way to reclaim \nSectioned Resource Files\nAnother useful idea that is related to “chunky” resource ﬁ les is the concept \nA typical resource ﬁ le might contain between one and four sec-\nAnother section could contain temporary data that is needed during the load-\ning process but is discarded once the resource has been completely loaded.\nUsually a game’s resource database consists of multiple resource ﬁ les, each ﬁ le \nUsually cross-references imply dependency (i.e., if resource A refers \nto resource B, then both A and B must be in memory in order for the resources \nto be functional in the game.) In general, a game’s resource database can be \ntwo objects within a single ﬁ le) or external (a reference to an object in a dif-\nThe Resource Manager\n6. Resources and the File System\nTo fully load a composite resource \nlike a 3D model into memory, all of its dependent resources must be loaded \nHandling Cross-References between Resources\nmanaging the cross-references between resource objects and guaranteeing \nﬁ le, we cannot use pointers to describe inter-object dependencies.\nTo make this kind of cross-reference work, the runtime resource manager \nWhenever a resource object is load-\ned into memory, a pointer to that object is stored in the table with its GUID as \nAft er all resource objects have been loaded into memory and \nof each cross-referenced object in the global resource look-up table via that \nof objects into a binary ﬁ le, we need to visit each object once (and only once) \nin an arbitrary order and write each object’s memory image into the ﬁ le se-\nwithin the ﬁ le, even when their memory images are not contiguous in RAM.\nBecause the objects’ memory images are now contiguous within the ﬁ le, \nthose oﬀ sets into the ﬁ le in place of the pointers.\nﬁ le is loaded into memory some time later.\nWhen the ﬁ le’s binary image is loaded, the objects contained \nThe Resource Manager\nIn-memory object images become contiguous when saved into a binary ﬁ le.\n6. Resources and the File System\nContiguous resource ﬁ le image, after it has been loaded into RAM.\nLater, when the ﬁ le is loaded into \nbinary ﬁ le is to ensure that the objects’ constructors are called.\nobjects within a single resource ﬁ le.\nnary image into memory and then apply the pointer ﬁ x-ups to resolve all the \nBut when cross-references reach out into other resource ﬁ les, \nresource ﬁ le in which the referenced object resides.\nThe Resource Manager\n6. Resources and the File System\nThe key to loading a multi-ﬁ le composite resource is to load all of the \nThis can be done by loading one resource ﬁ le and \nreferenced ﬁ les that have not already been loaded.\nAs we load each data object \nall of the interdependent ﬁ les have been loaded and all of the objects are pres-\nmaster look-up table to convert GUIDs or ﬁ le oﬀ sets into real addresses.\nMany types of resources re-\ntion to refer to any processing of resource data aft er it has been loaded.\ntear-down step prior to a resource’s memory being freed.\nwe call this logging out a resource.)\nresource to a pair of function pointers, one for post-load initialization and one \nPost-load initialization is closely related to a resource’s memory allocation \ndata loaded from the ﬁ le.\nIt would permit resources to be loaded in one of two ways: (a) directly \nresource would be discarded aft er post-load initialization was complete.\nwas very useful for loading resource ﬁ les that contained both relevant and \ndata in an out-of-date format could be loaded into temporary memory and \nThe Resource Manager",
      "keywords": [
        "Resource",
        "resource manager",
        "memory",
        "resource chunk allocator",
        "resource data",
        "chunk",
        "data",
        "Resource Chunk",
        "object",
        "level",
        "File",
        "loaded",
        "game",
        "File System",
        "resource GUID"
      ],
      "concepts": [
        "resources",
        "memory",
        "data",
        "level",
        "chunks",
        "load",
        "game",
        "objects",
        "ers",
        "allocation"
      ],
      "similar_chapters": [
        {
          "book": "Game_Engine_Architecture",
          "chapter": 15,
          "title": "",
          "score": 0.785,
          "base_score": 0.635,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 14,
          "title": "",
          "score": 0.591,
          "base_score": 0.441,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 38,
          "title": "",
          "score": 0.404,
          "base_score": 0.404,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 12,
          "title": "",
          "score": 0.387,
          "base_score": 0.387,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 37,
          "title": "",
          "score": 0.339,
          "base_score": 0.339,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "resource",
          "resources",
          "loaded",
          "le",
          "memory"
        ],
        "semantic": [],
        "merged": [
          "resource",
          "resources",
          "loaded",
          "le",
          "memory"
        ]
      },
      "topic_id": 5,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.2699899629875767,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:57.759635+00:00"
      }
    },
    {
      "chapter_number": 17,
      "title": "Segment 17 (pages 326-347)",
      "start_page": 326,
      "end_page": 347,
      "summary": "7. The Game Loop and Real-Time Simulation\nReal-time 3D computer graphics are implemented in an entirely diﬀ erent \nIn a real-time rendering application, this is sometimes known as the \nThe Game Loop\nMost game engine subsystems require periodic servicing while the game is \nThe Game Loop\ngame engine subsystems.\nis oft en called the game loop, because it is the master loop that services every \nThe following pseudocode demonstrates what the game loop of a pong \ngame might look like at its core :\nwhile (true) // game loop\nbreak; // exit the game loop\n7. The Game Loop and Real-Time Simulation\nThe original pong games were \nframes per second.\ntime.\nAs you can see, when the game ﬁ rst runs, it calls initGame() to do \nThen the main game loop is entered.\nGame Loop Architectural Styles\nGame Loop Architectural Styles\nGame loops can be implemented in a number of diﬀ erent ways—but at their \nOn a Windows platform, games need to service messages from the Windows \noperating system in addition to servicing the various subsystems in the game \narrive and to service the game engine only when no Windows messages are \n// iteration of our \"real\" game loop.\nOne of the side-eﬀ ects of implementing the game loop like this is that Win-\ngame’s window around on the desktop.\n7. The Game Loop and Real-Time Simulation\nIn a framework-based rendering engine or game engine, the main game \nThe game programmer can \nrendering engine is an example of a library that has been wrapped in a frame-\nby a game engine programmer.\nThe Ogre framework’s implementation of its internal game loop looks some-\nA particular game’s frame listener implementation might look something like \n// is rendered (i.e., service all game engine   \nIn games, an event is any interesting change in the state of the game or its \nMost game engines have an event system, which permits \nA game’s event system is usually very similar to the event/messaging system \nSome game engines leverage their event system in order to implement \nA game engine can then implement periodic updat-\nGame Loop Architectural Styles\n7. The Game Loop and Real-Time Simulation\ntime values in either integer or ﬂ oating-point format.\nReal Time\nWe can think of times measured directly via the CPU’s high-resolution timer \nIt measures times in units of CPU cycles (or some mul-\nGame Time\nFor example, we can deﬁ ne a game timeline that is technically \nUnder normal circumstances, game time coincides \nwith real time.\nIf we wish to pause the game, we can simply stop updating \nthe game timeline temporarily.\nwe can update the game clock more slowly than the real-time clock.\nPausing or slowing down the game clock is also a highly useful debug-\nTo track down a visual anomaly, a developer can pause game time \nferent clock (either the real-time clock, or a separate camera clock).\nWe can even support single-stepping the game clock, by \nadvancing the game clock by one target frame interval (e.g., 1/30 of a second) \nthe game loop is still running when the game is paused—only the game clock \nSingle-stepping the game by adding 1/30 of a second to a paused \ngame clock is not the same thing as sett ing a break point in your main loop, \ntime.\nThe local timeline measures how time progressed \nback in-game, we needn’t play it at the original rate.\ncal timeline and a global timeline, such as real time or game time.\nof the animation’s local timeline (t = 0) onto the desired start time \nplayback rate R, in addition to the clip’s global start time \ntime scale (R < 0) as shown in Figure 7.3.\nglobal game timeline.\n7. The Game Loop and Real-Time Simulation\nMeasuring and Dealing with Time\nimplemented in real game engines.\nFrame Rate and Time Deltas\nThe frame rate of a real-time game describes how rapidly the sequence of still \nIn games and ﬁ lm, frame rate is typically measured in frames per sec-\nAnimation play-back speed can be controlled by simply scaling the local time line \nPlaying an animation in reverse is like mapping the clip to the global time line with \na time scale of R = –1.\nof the world, games update at 50 FPS, because this is the natural refresh rate \nThe amount of time that elapses between frames is known as the frame \n30 FPS, then its delta time is 1/30 of a second, or 33.3 ms (milliseconds).\n60 FPS, the delta time is half as big, 1/60 of a second or 16.6 ms.\nhow much time has elapsed during one iteration of the game loop, we need to \nsurement in games.\nFrom Frame Rate to Speed\na constant speed of 40 meters per second (or in a 2D game, we might specify \nframe Δt (measured in seconds), yielding a change in position Δx = v Δt (which \ntechniques make use of the elapsed frame time Δt in one way or another.\nIn many early video games, no att empt was made to measure how much real \ntime had elapsed during the game loop.\nMeasuring and Dealing with Time\n7. The Game Loop and Real-Time Simulation\nthe objects in these games were entirely dependent upon the frame rate that \nof game were to be run on a computer with a faster CPU than the machine for \nFor this reason, I’ll call these games CPU-dependent games .\ngames.\nspeed, but CPU-dependent games would run in fast forward.\nUpdating Based on Elapsed Time\nTo make our games CPU-independent, we must measure Δt in some way, rath-\nwe call from within the game loop or by storing it in a global variable or en-\nThe approach outlined above is used by many game engines.\ntempted to go out on a limb and say that most game engines use it.\nframe that causes it to take much more time (or much less) than the current \nframe.\nWe call such an event a frame-rate spike.\nthe game into a “viscious cycle” of poor frame times.\nIt is true that game loops tend to have at least some frame-to-frame coher-\nframe-time measurements over a small number of frames and use that as the \nThis allows the game to adapt to varying frame \nthe averaging interval, the less responsive the game will be to varying frame \nframe as before.\nIf the measured duration is less than the ideal frame time, we \nsimply put the main thread to sleep until the target frame time has elapsed.\nIf the measured duration is more than the ideal frame time, we must “take \nour lumps” and wait for one more whole frame time to elapse.\nClearly this approach only works when your game’s frame rate is reason-\nbetween 30 FPS and 15 FPS due to frequent “slow” frames, then the game’s \nLater on, when the game is get-\nMeasuring and Dealing with Time\n7. The Game Loop and Real-Time Simulation\nframe rate also looks bett er, and as we’ll see in the next section, it can be used \nIn addition, when elapsed frame times are consistent, features like record \nbugs can be reproduced by simply playing back a recorded game that dem-\neﬀ ectively clamps the frame rate of the main game loop to a multiple of the \nof 60 Hz, the game’s real update rate is eﬀ ectively quantized to a multiple \nIf more than 1/60 of a second elapses between frames, \nthe frame rate of your game, even when it is synchronized to the v-blank in-\nMeasuring Real Time with a High-Resolution Timer\nnot suitable for measuring elapsed times in a real-time game, because they \nFor example, time() returns an integer \ntime in a game, because its resolution is usually on the order of the duration \nresolution timer increments once per CPU cycle, or 3 billion times per second.\nall of our time-measurement needs in a game.\nbe used to read the two 32-bit time base registers, while on other PowerPC \nMeasuring and Dealing with Time\n7. The Game Loop and Real-Time Simulation\nBe aware that even timing measurements taken via a high-resolution timer can \nTime Units and Clock Variables\nWhenever we measure or specify time durations in a game, we have two \ntime units should be used?\ndata type should be used to store time measurements?\nNotice that we still store the raw time measurements in 64-bit integer \nOnly the time delta dt is stored in a 32-bit variable.\nthen we would measure a negative time delta if we were to truncate the indi-\nvidual time measurements to 32 bits each prior to subtracting them.\nAnother common approach is to store relatively small time deltas in ﬂ oating- \n// Start off assuming an ideal frame time (30 FPS).\nwhile (true) // main game loop\nMeasuring and Dealing with Time\n7. The Game Loop and Real-Time Simulation\ntrack of the amount of time that has elapsed since the game was started, a \nFloating-point clocks are usually only used to store relatively short time \ndeltas, measuring at most a few minutes, and more oft en just a single frame \nIf an absolute-valued ﬂ oating-point clock is used in a game, you will \nOther Time Units\nSome game engines allow timing values to be speciﬁ ed in a game-deﬁ ned \ncommon choice is a 1/300 second time unit.\nObviously a 1/300 second time unit is not precise enough to handle subtle \neﬀ ects, like time-scaling an animation.\nfor many purposes, it’s still best to use ﬂ oating-point time units, or machine \nBut a 1/300 second time unit can be used eﬀ ectively for things like \nWhen your game hits a break point, its loop stops running and the debug-\nHowever, the CPU continues to run, and the real-time clock \nA large amount of wall clock time can pass while \nto continue, this can lead to a measured frame time many seconds, or even \nIf we are lucky, the game might con-\nframe.\ngame loop, if we ever measure a frame time in excess of some predeﬁ ned up-\nof a second (or whatever the target frame rate is).\nIn eﬀ ect, the game becomes \nwhile (true) // main game loop\n// estimate of next frame’s delta time.\n// frame.\nMeasuring and Dealing with Time\n7. The Game Loop and Real-Time Simulation\nSome game engines encapsulate their clock variables in a class.\nA clock class typically contains a variable that tracks the absolute time \nfollowing example, we’ll store absolute times in the same way the CPU \nA clock class can support some nift y features, like time-scaling.\nbe implemented by simply multiplying the measured time delta by an arbi-\npause time by simply skipping its update while the clock is paused.\nstepping a clock can be implemented by adding a ﬁ xed time interval to a \n// Call this when the game first starts up.\n// Return the current time in cycles.\n// not return absolute time measurements in floating   \n// absolute time and that of another clock, in \n// with the real measured frame time delta in seconds.\nMeasuring and Dealing with Time\n7. The Game Loop and Real-Time Simulation\nMultiprocessor Game Loops\nNow that we’ve investigated basic single-threaded game loops and learned \nsome of the ways in which time is commonly measured and manipulated \nin a game engine, let’s turn our att ention to some more complex kinds of \ngame loops.\nIn this section, we’ll explore how game loops have evolved to \ngame loops.\nern game engines running on multicore systems like the Xbox 360 and the \nPLAYSTATION 3 can no longer rely on a single main game loop to service \nBy 2008, most game studios had \nways in which game engines leverage multicore hardware.\nMultiprocessor Game Console Architectures\nMultiprocessor Game Loops",
      "keywords": [
        "Game Loop",
        "Game",
        "time",
        "main game loop",
        "frame",
        "Game Loop Architectural",
        "frame time",
        "Loop",
        "Game Time",
        "Frame Rate",
        "game engine",
        "game clock",
        "clock",
        "game engine subsystems",
        "Multiprocessor Game Loops"
      ],
      "concepts": [
        "time",
        "timing",
        "game",
        "frame",
        "clock",
        "measures",
        "measuring",
        "measurements",
        "bit",
        "bits"
      ],
      "similar_chapters": [
        {
          "book": "Game_Engine_Architecture",
          "chapter": 18,
          "title": "",
          "score": 0.642,
          "base_score": 0.642,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 1,
          "title": "",
          "score": 0.568,
          "base_score": 0.568,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 3,
          "title": "",
          "score": 0.503,
          "base_score": 0.503,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 39,
          "title": "",
          "score": 0.499,
          "base_score": 0.499,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 40,
          "title": "",
          "score": 0.491,
          "base_score": 0.491,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "time",
          "game loop",
          "loop",
          "frame",
          "clock"
        ],
        "semantic": [],
        "merged": [
          "time",
          "game loop",
          "loop",
          "frame",
          "clock"
        ]
      },
      "topic_id": null,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.3492756792776059,
        "topic_boost": 0.0,
        "timestamp": "2025-12-17T23:05:57.759675+00:00"
      }
    },
    {
      "chapter_number": 18,
      "title": "Segment 18 (pages 348-366)",
      "start_page": 348,
      "end_page": 366,
      "summary": "7. The Game Loop and Real-Time Simulation\nﬁ ed memory architecture, the PS3 divides its RAM into a number of blocks, \nThe PS3’s main CPU is called the Power Processing Unit (PPU).\ncommonly-used in games are instructions that operate on four 32-bit ﬂ oating-\nMultiprocessor Game Loops\n7. The Game Loop and Real-Time Simulation\ntribute these workloads onto multiple processing cores or hardware threads \nWhen applied to the game loop, the fork/join architecture results in a \nmain loop that looks very similar to its single-threaded counterpart, but with \nUpdate Game \nGame Object Update\nFork and join used to parallelize selected CPU-intensive phases of the game loop.\nbecause the console has three cores with two hardware threads each.\navailable.) We then “fork” (i.e., create) N threads, requesting each one to work \nThe main thread can either continue doing \ncalculate the global pose, this time with each thread working on one or more \nhandle the lion’s share of the game’s high-level logic (the main game loop ).\nthis design allows these threaded engine subsystems to execute in parallel.\nMultiprocessor Game Loops\n7. The Game Loop and Real-Time Simulation\nincluding that of the main game loop, may be blocked.\ndivide up the work that is done by the game engine into multiple small, rela-\nof data and a bit of code that operates on that data.\nThe main game loop runs on the PPU, and the six SPUs \nEach job’s code and data are sent to an SPU’s local \nthe one-thread-per-subsystem architecture does not do particularly well).\nWhen writing or retroﬁ tt ing a game engine to take advantage of multitasking \nFor example, a game might request that a ray be cast into the world, in \nIn a job architecture, work is broken down into ﬁ ne-grained chunks that can \nproviding the main game loop with improved ﬂ exibility.\nMultiprocessor Game Loops\n7. The Game Loop and Real-Time Simulation\nwhile (true) // main game loop\nThe main thread can continue doing other unrelated work while \ncompleted, the main thread can pick up the results of the ray cast query and \nwhile (true) // main game loop\nRayCastResult r;\nwhile (true) // main game loop\n// Wait for the results of last frame’s ray cast job.\nNetworked Multiplayer Game Loops\nThe game loop of a networked multiplayer game is particularly interesting, \nroom here to go into the all of the details of how multiplayer games work.\nhere, and then look at how these architectures aﬀ ect the structure of the game \nNetworked Multiplayer Game Loops\n7. The Game Loop and Real-Time Simulation\nClient-Server\nIn the client-server model, the vast majority of the game’s logic runs on a single \nworked single-player game.\nMultiple client machines can connect to the server \ndering engine that also reads human interface devices and controls the local \nthan this so-called player prediction code, the client is usually not much more \nThe server may be running on a dedicated machine, in which case we say \ngames, the single-player game mode is really just a degenerate multiplayer \ngame, in which there is only one client, and both the client and server are run-\nThe game loop of a client-server multiplayer game can be implemented \nthreads of execution, within a single process.\ncommunicate locally, when being run in client-on-top-of-server mode.\nresult, a lot of multiplayer games run both client and server in a single thread, \nserviced by a single game loop.\nIt’s important to realize that the client and server code can be updated \nFor example, in Quake, the server runs at 20 FPS (50 ms per \nimplemented by running the main game loop at the faster of the two rates \n(60 FPS) and then servicing the server code once roughly every three frames.\ntracked, and when it reaches or exceeds 50 ms, a server frame is run and the \nSuch a game loop might look something like this:\nF32 dtServer = 0.0f;     // the server’s delta time\nwhile (true) // main game loop\n// Run the client at maximum frame rate.\nIn the peer-to-peer multiplayer architecture, every machine in the online game \nmachine has authority over each dynamic object in the game.\njects in the game world, the machine acts like a client, rendering the objects in \nThe structure of a peer-to-peer multiplayer game loop is much simpler \nthan a client-server game loop, in that at the top-most level, it looks very much \nlike a single-player game loop.\ncode is running on the server and which code is client-side.\nNetworked Multiplayer Game Loops\n7. The Game Loop and Real-Time Simulation\nexample, if one computer drops out of the game, all of the objects over which \nit had authority must be picked up by the other machines in the game.\nwise, when a new machine joins the game, it should ideally take over author-\nity of some game objects from other machines, in order to balance the load.\nplayer architectures can have profound eﬀ ects on the structure of a game’s \nThe following is an excerpt from the Quake II game loop .\ngame), calculation of the real frame delta time , ﬁ xed-time and time-scaled \nmodes of operation, and servicing of both server-side and client-side engine \n// Run a frame of the game.\n// Service the in-game console.\nNetworked Multiplayer Game Loops\n7. The Game Loop and Real-Time Simulation\n// Run a server frame.\n// Run a client frame.\nsome way of providing inputs to the game.\ndevices (HID) exist for gaming, including joysticks, joypads, keyboards and \nmice, track balls, the  Wii remote, and specialized input devices like steering \nwe’ll investigate how game engines typically read, process, and utilize the \ninputs from human interface devices.\nfrom these devices provide feedback to the human player.\nA wide range of human interface devices are available for gaming purposes.\nAn arcade machine’s input device is usually \n8. Human Interface Devices (HID)\nVarious custom input devices for the arcade game Mortal Kombat II by Midway.\nMany specialized input devices are available for use with consoles.\nsomewhat customized to the game in question, although input hardware is \nOn console platforms, specialized input devices and adapters are usually \navailable, in addition to the “standard” input device such as the joypad.\ngames, steering wheels can be purchased for driving games, and games like \nAll human interface devices provide input to the game soft ware, and some \nGame soft ware reads and writes HID inputs and \nSome simple devices, like game pads and old-school joysticks, are read by \npolling the hardware periodically (usually once per iteration of the main game \n8. Human Interface Devices (HID)\nMicrosoft ’s XInput API, for use with Xbox 360 game pads on both the \nEvery frame, the game calls the function XInputGetState().\nSome HIDs only send data to the game engine when the state of the controller \nwill probably read the state of the device, store it oﬀ  for later processing, and \nThe game engine can pick \nThe inputs and outputs of a Bluetooth device, like the WiiMote, the \ncan request the HID to send input data (such as the states of its butt ons) back \naudio data) to the device.\nseparate from the game engine’s main loop, or at least encapsulated behind a \nrelatively simple interface that can be called from the main loop.\npoint of view of the game programmer, the state of a Bluetooth device can be \nAlthough human interface devices for games vary widely in terms of form \nGame programmers oft en \nIn soft ware, the state of a digital butt on (pressed or not pressed) is usually \nIt is quite common for the states of all of the butt ons on a device to be \nXInput API, the state of the Xbox 360 joypad is returned in a struct called \n8. Human Interface Devices (HID)\n#define XINPUT_GAMEPAD_DPAD_UP          0x0001 // bit 0\n#define XINPUT_GAMEPAD_DPAD_DOWN        0x0002 // bit 1\n#define XINPUT_GAMEPAD_DPAD_LEFT        0x0004 // bit 2\n#define XINPUT_GAMEPAD_DPAD_RIGHT       0x0008 // bit 3\n#define XINPUT_GAMEPAD_START            0x0010 // bit 4\n#define XINPUT_GAMEPAD_BACK             0x0020 // bit 5\n#define XINPUT_GAMEPAD_LEFT_THUMB       0x0040 // bit 6\n#define XINPUT_GAMEPAD_RIGHT_THUMB      0x0080 // bit 7\n#define XINPUT_GAMEPAD_LEFT_SHOULDER    0x0100 // bit 8\n#define XINPUT_GAMEPAD_RIGHT_SHOULDER   0x0200 // bit 9\n#define XINPUT_GAMEPAD_A                0x1000 // bit 12\n#define XINPUT_GAMEPAD_B                0x2000 // bit 13\n#define XINPUT_GAMEPAD_X                0x4000 // bit 14\n#define XINPUT_GAMEPAD_Y                0x8000 // bit 15",
      "keywords": [
        "Game Loop",
        "main game loop",
        "Game",
        "Multiplayer Game Loops",
        "main game",
        "human interface devices",
        "Loop",
        "Multiplayer Game",
        "define XINPUT",
        "Multiprocessor Game Loops",
        "XInput",
        "interface devices",
        "game loop runs",
        "GAMEPAD",
        "Networked Multiplayer Game"
      ],
      "concepts": [
        "game",
        "gaming",
        "threads",
        "engine",
        "code",
        "times",
        "processing",
        "process",
        "processes",
        "devices"
      ],
      "similar_chapters": [
        {
          "book": "Game_Engine_Architecture",
          "chapter": 39,
          "title": "",
          "score": 0.664,
          "base_score": 0.514,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 17,
          "title": "",
          "score": 0.642,
          "base_score": 0.642,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 40,
          "title": "",
          "score": 0.594,
          "base_score": 0.444,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 38,
          "title": "",
          "score": 0.567,
          "base_score": 0.417,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 1,
          "title": "",
          "score": 0.545,
          "base_score": 0.545,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "loop",
          "game loop",
          "devices",
          "server",
          "client"
        ],
        "semantic": [],
        "merged": [
          "loop",
          "game loop",
          "devices",
          "server",
          "client"
        ]
      },
      "topic_id": 3,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.32048357269285216,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:57.759712+00:00"
      }
    },
    {
      "chapter_number": 19,
      "title": "Segment 19 (pages 367-384)",
      "start_page": 367,
      "end_page": 384,
      "summary": "On some devices, certain butt ons are analog as well, meaning that the \ngame can actually detect how hard the player is pressing on them.\nthe signals produced by analog butt ons are usually too noisy to be particu-\nI have yet to see a game that uses analog butt on inputs eﬀ ectively \nAn analog input signal is usually digitized, mean-\nan analog input might range from –32,768 to 32,767 if represented by a 16-bit \nThese input values range from 0 (not pressed) to 255 \nTypes of Inputs\nThe position of an analog butt on, trigger, joystick, or thumb stick is absolute, \ninputs of some devices are relative .\nat which the input value should be zero.\na delta from the last time the input value was read.\ndetect acceleration along the three principle axes (x, y, and z), as shown in Fig-\nWhen the controller is not accelerating these inputs are zero, but when \nSome Wii and PS3 games make use of the three accelerometers in the WiiMote \nWiiMote or Sixaxis joypad, because of the fact that we are playing these games \ncos(45°) = 0.707 g on both the y and z inputs.\nerometer inputs to ﬁ nd the zero points along each axis, we can calculate pitch, \nsuch as with the butt ons facing the player’s chest, or with the IR sensor point-\nTypes of Inputs\nGame pads like the PlayStation’s DualShock line of controllers and the Xbox \nplayer games, in which human players can communicate with one another via \nOther Inputs and Outputs\nHuman interface devices may of course support many other kinds of inputs \nThe Xbox 360 game pad, the Sixaxis and \nGame Engine HID Systems\nMost game engines don’t use “raw” HID inputs directly.\nmassaged in various ways to ensure that the inputs coming from the HID \nand the game in order to abstract HID inputs in various ways.\nbutt on-mapping table might be used to translate raw butt on inputs into logi-\ncal game actions, so that human players can re-assign the butt ons’ functions \nA game engine’s HID system usually provides some or all of the following \nz event detection (e.g., butt on up, butt on down),\nz detection of butt on sequences and multibutt on combinations (known as \nz gesture detection,\nz controller input re-mapping,\nAny input values that are within the dead \nfor the noisiest inputs generated by an undisturbed control, but small enough \nThis noise can sometimes cause the in-game behaviors controlled by \nFor this reason, many games ﬁ lter the \nraw inputs coming from the HID.\nis to pass the raw input data through a simple low-pass ﬁ lter , prior to it being \nused by the game.\nthe current unﬁ ltered input value with last frame’s ﬁ ltered input.\nthe sequence of unﬁ ltered inputs by the time-varying function u(t) and the \nﬁ ltered inputs by f(t), where t denotes time, then we can write\nthe calling code will keep track of last frame’s ﬁ ltered input for use on the \nAnother way to ﬁ lter HID input data is to calculate a simple moving av-\nFor example, if we wish to average the input data over a 3/30 second \nGame Engine HID Systems\nThe ﬁ ltered input value is then the sum of the values in this array at \ntwo frames of input, during which the 3-element array has not yet been ﬁ lled \nDetecting Input Events\nThe low-level HID interface typically provides the game with the current \nstates of the device’s various inputs.\nThe most common HID events are probably butt on \ndown (pressed) and butt on up (released), but of course we can detect other \nLet’s assume for the moment that our butt ons’ input bits are 0 when not pressed \nThe easiest way to detect a change in butt on state is to \nkeep track of the butt ons’ state bits as observed last frame and compare them \nThe current state of each butt on tells us whether the event is a butt on-up or a \nbutt on-down.\nWe can use simple bit-wise operators to detect butt on-down and but-\nstate bits of up to 32 butt ons, we want to generate two new 32-bit words: \none for butt on-down events which we’ll call buttonDowns and one for \nbutt on-up events which we’ll call buttonUps. In both cases, the bit corre-\nsponding to each butt on will be 0 if the event has not occurred this frame \nTo implement this, we also need last frame’s butt on states, \nand current butt on state words, we’ll get 1’s only for butt ons whose states \nevent is a butt on-up or a butt on-down, we need to look at the current state \nof each butt on.\nAny butt on whose state has changed that is currently down \nlowing code applies these ideas in order to generate our two butt on event \nGame Engine HID Systems\nU32 m_buttonStates;  \nU32 m_prevButtonStates; // previous frame’s states\n^ m_prevButtonStates;\nA chord is a group of butt ons that, when pressed at the same time, produce a \nbutt ons on the WiiMote together in order to start a new game.\nz Pressing the 1 and 2 butt ons on the WiiMote at the same time put it into \nz The “grapple” move in many ﬁ ghting games is triggered by a two-but-\nof two or more butt ons and only perform the requested operation when all of \nchord includes a butt on or butt ons that have other purposes in the game, we \nmust take care not to perform both the actions of the individual butt ons and \ncheck that the other butt ons in the chord are not down when detecting the \nindividual butt on-presses.\npress one or more of the butt ons in the chord slightly earlier than the rest.\nmore individual butt ons on frame i and the rest of the chord on frame i + 1 (or \nz You can design your butt on inputs such that a chord always does \nthe actions of the individual butt ons plus some additional action.\nThat way, whether or not the individual butt ons are detected \nz You can introduce a delay between when an individual butt on-down \nprecedence over the individual butt on-down events.\nz You can detect the chord when the butt ons are pressed, but wait to \ntrigger the eﬀ ect until the butt ons are released again.\nz You can begin the single-butt on move immediately and allow it to be \nGame Engine HID Systems\nSequences and Gesture Detection\ngesture is a sequence of actions performed via a HID by the human player \nFor example, in a ﬁ ghting game or brawler, we might \nwant to detect a sequence of butt on presses, such as A-B-A.\nidea to non-butt on inputs as well.\nan event is generated telling the rest of the game engine that the gesture \nHowever, if any non-valid intervening inputs are detected, or \nMany games require the user to tap a butt on rapidly in order to perform an ac-\nThe frequency of the butt on presses may or may not translate into some \nWe can detect the frequency of a butt on press by simply keeping track of \nthe last time we saw a butt on-down event for the butt on in question.\nEvery time we detect a new butt on-down \nm_buttonMask; // which button to observe (bit   \nm_dtMax;      // max allowed time between   \nm_tLast;      // last button-down event, in  \nm_tLast(CurrentTime() – dtMax) // start out  \nF32 dt = t – m_tLast;\n(ButtonsJustWentDown(m_buttonMask))\nm_tLast \nthe number of butt ons on the HID in question).\nGame Engine HID Systems\nbutt on’s index (1U << buttonId ).\nreturns a non-zero value if any one of the butt ons speciﬁ ed by the given bit \nmultiple simultaneous butt on-down events.\nWe can detect this butt on sequence as follows: We maintain a variable \nthat tracks which butt on in the sequence we’re currently looking for.\nﬁ ne the sequence with an array of butt on ids (e.g., aButtons[3] = {A, B, \nto the ﬁ rst butt on in the sequence, i = 0.\nentire sequence, Tstart  , much as we did in the rapid butt on-pressing example.\nThe logic goes like this: Whenever we see a butt on-down event that match-\nes the butt on we’re currently looking for, we check its time stamp against the \nwindow, we advance the current butt on to the next butt on in the sequence; \nfor the ﬁ rst butt on in the sequence only (i = 0), we also update Tstart  .\na butt on-down event that doesn’t match the next butt on in the sequence, or \nif the time delta has grown too large, we reset the butt on index i back to the \nm_aButtonIds;  // sequence of buttons to watch for \nm_dtMax;       // max time for entire sequence\nm_tStart;      // start time of sequence, in   \nm_eventId(eventIdToSend), // event to send when   \nm_iButton(0),             // start of sequence\n++m_iButton; // advance to next button\nF32 dt = CurrentTime() – m_tStart;\nGame Engine HID Systems\n++m_iButton; // advance to next button\nbutt on press and detect a full rotation with a slightly modiﬁ ed version of the \nsequence detection code shown above.\nDetecting circular rotations of the stick by dividing the 2D range of stick inputs \ngames.\nand route each one’s inputs to the appropriate player in the game.\nplayers at the time the user hits the Start butt on.\nEven in a single-player game with only one HID, the engine needs to be \nOn systems with batt ery-operated HIDs, the game or the operating sys-\nOne way to handle HID inputs and \nGame Engine HID Systems\nFor example, if our game is to ship on Xbox 360 and PS3, the layout \nof the controls (butt ons, axes and triggers) on these two joypads are almost \nAINDEX_RPAD_RIGHT,    // Xbox 360 B, PS3 Circle\n// Left and right thumb stick buttons\nAINDEX_LSTICK_BUTTON,  // Xbox 360 LThumb, PS3 L3,\nAINDEX_RSTICK_BUTTON,  // Xbox 360 RThumb, PS3 R3,",
      "keywords": [
        "Game Engine HID",
        "Engine HID Systems",
        "butt",
        "HID",
        "Human Interface Devices",
        "butt ons",
        "Engine HID",
        "game",
        "HID Systems",
        "inputs",
        "game engine",
        "Interface Devices",
        "butt on-down event",
        "butt on-down",
        "HID inputs"
      ],
      "concepts": [
        "game",
        "gaming",
        "input",
        "hid",
        "bit",
        "bits",
        "butt",
        "detect",
        "button",
        "controller"
      ],
      "similar_chapters": [
        {
          "book": "Game_Engine_Architecture",
          "chapter": 20,
          "title": "",
          "score": 0.512,
          "base_score": 0.512,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 1,
          "title": "",
          "score": 0.322,
          "base_score": 0.322,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 4,
          "title": "",
          "score": 0.32,
          "base_score": 0.32,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 17,
          "title": "",
          "score": 0.312,
          "base_score": 0.312,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "butt",
          "butt ons",
          "ons",
          "hid",
          "inputs"
        ],
        "semantic": [],
        "merged": [
          "butt",
          "butt ons",
          "ons",
          "hid",
          "inputs"
        ]
      },
      "topic_id": null,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.19632759591728577,
        "topic_boost": 0.0,
        "timestamp": "2025-12-17T23:05:57.759742+00:00"
      }
    },
    {
      "chapter_number": 20,
      "title": "Segment 20 (pages 385-402)",
      "start_page": 385,
      "end_page": 402,
      "summary": "controller, we might want to separate this axis into two distinct axes on the \nnaming our abstract controls according to their function in the game, rather \nof all of the game code that requires HID I/O.\nbut virtually all cross-platform game engines insulate the game from hard-\nMany games allow the player some degree of choice with regard to the func-\nthe sense of the vertical axis of the right thumb stick for camera control in a \nconsole game.\nstick angles the camera up (much like an airplane control stick).\nOther games \nSome PC games allow the user full control over the functions of individual \nfunction in the game a unique id and then provide a simple table which maps \neach physical or abstract control index to a logical function in the game.\nGame Engine HID Systems\never the game wishes to determine whether a particular logical game function \nid in the table and then reads the state of that control.\nWe cannot use a butt on as the control for a logical game func-\nour controls into a few classes, we can normalize the inputs within those \nz Unidirectional absolute axes (e.g., triggers, analog butt ons).\ning-point input values in the range [0, 1].\nProduce ﬂ oating-point input \nrelative oﬀ set possible within a single game frame (i.e., during a period \nIn many games, a single physical control can have diﬀ erent functions, depend-\nWhen the player is walking around, the controls are \nused to navigate and control the camera.\nlar HID control may have a diﬀ erent purpose.\nSome games implement a priority system to \nthe HID might be “owned” by diﬀ erent parts of the game.\ninputs are for player control, some for camera control, and still others are for \nuse by the game’s wrapper and menu system (pausing the game, etc.) Some \ngame engines introduce the concept of a logical device, which is composed of \nbe used for player control, while another is used by the camera system, and \nIn most games, it is sometimes necessary to disallow the player from control-\nan in-game cinematic, we might want to disable all player controls temporar-\nvidual controls on the input device itself.\nthe disable mask, the game can get itself into a state where the player looses \nall control forever, and must restart the game.\nGame Engine HID Systems\nthe deflection of the right thumb stick, for example, other game engine \nof any good game.\nof low-pass ﬁ ltering, bug-free handling of control scheme mappings, achiev-\nTools for Debugging \nthe game development process easier and less error-prone.\nwe’ll take a look at the development and debugging tools most oft en found in \nprofessional-grade game engines.\nprintf debugging (aft er the standard C library function, printf()).\n9. Tools for Debugging and Development\nEvery game platform has some kind of console or teletype (TTY) output \nWin32, you can produce output in the console by printing to stdout or \nz Unfortunately, printf() and iostream don’t work if your game is built \nVisual Studio debugger, it provides a debug console to which you can \nprint via the Win32 function OutputDebugString().\nmessages can be printed by the game engine.\nSo printing out information for debugging purposes is almost always as easy \nHowever, most game en-\nkinds of printing facilities most game engines provide.\nThe Win32 function OutputDebugString() is great for printing debug-\nging information to Visual Studio’s Debug Output window.\ngame engines wrap OutputDebugString() in a custom function, like this:\nint VDebugPrintF(const char* format, va_list argList)\nkind of mechanism for controlling the level of verbosity via the command-line, \nVerboseDebugPrintF() function whose ﬁ rst argument is the verbosity level \n9. Tools for Debugging and Development\nIt’s also extremely useful to be able to categorize your debug output into chan-\nOn some platforms, like the PLAYSTATION 3, debug output can be di-\nOther platforms like Windows provide only a single debug output con-\nIn this model, if a developer is debugging an animation-related problem, for \nA channel-based debug output system can be implemented quite easily \nby adding an additional channel argument to our debug printing function.\nThe printing function can simply consult the list of active channels and \nonly print the message if the speciﬁ ed channel is among them.\nIt’s a good idea to mirror all debug output to one or more log ﬁ les (e.g., one \nthe log ﬁ le(s) should contain all of the debug output, independent of the cur-\ndebug output function to ensure that if the game crashes the log ﬁ le(s) won’t \ndebug output call if either (a) you are not doing a lot of logging, or (b) you \nSome game engines produce special text output and/or log ﬁ les when the \ngame crashes.\nz Current level(s) being played at the time of the crash.\nz World-space location of the player character when the crash occurred.\nz Animation/action state of the player when the game crashed.\n9. Tools for Debugging and Development\nDebug Drawing Facilities\nto position and orient objects in the game world, move them around, test for \nAlmost all modern games are three-\nreason, most good game engines provide an API for drawing colored lines, \nWe call this a debug drawing facility, because the \ngame.\nA debug drawing API can save you huge amounts of time.\nwithin your game?\nWith a debug drawing API, logical and mathematical er-\nminutes of debugging.\nHere are some examples of debug drawing in action within Naughty \nout new features and debugging problems in the game.\nz Figure 9.1 shows how a single line can help developers understand \nDebug Drawing Facilities\nalso notice some debug text rendered just above the head of the enemy, \n9. Tools for Debugging and Development\noﬀ , and the developer is given full control over the character’s move-\ntarget points in the game world by simply aiming the camera and can \nDebug Drawing API\nA debug drawing API generally needs to satisfy the following requirements:\nz It should support a useful set of primitives , including (but not limited \nManually controlling an NPC’s actions for debugging purposes.\nDebug Drawing Facilities\n9. Tools for Debugging and Development\nz It should provide a good deal of ﬂ exibility in controlling how primitives \nz It should be possible to draw primitives in world space (full 3D, using \nthe game camera’s perspective projection matrix) or in screen space (ei-\nScreen-space primitives are helpful for displaying debugging \nz It should be possible to draw primitives with or without depth testing \nz It should be possible to make calls to the drawing API from anywhere \nted for rendering during a speciﬁ c phase of the game loop, usually at \nqueue up all incoming debug drawing requests, so that they may be \nz Ideally, every debug primitive should have a lifetime associated with it.\nThe lifetime controls how long the primitive will remain on-screen aft er \nIf the code that is drawing the primitive is called \nher debug primitives a longer lifetime, on the order of a few seconds.\nz It’s also important that the debug drawing system be capable of han-\ndling a large number of debug primitives eﬃ  ciently.\ning debug information for 1,000 game objects, the number of primitives \ncan really add up, and you don’t want your game to be unusable when \ndebug drawing is turned on.\nThe debug drawing API in Naughty Dog’s Uncharted: Drake’s Fortune en-\n// Adds a line segment to the debug drawing queue.\n// a point) to the debug drawing queue.\n// Adds a wireframe sphere to the debug drawing queue.\n// Adds a circle to the debug drawing queue.\nDebug Drawing Facilities\n9. Tools for Debugging and Development\n// transformation to the debug drawing queue.\n// Adds a wireframe triangle to the debug drawing  \n// Adds an axis-aligned bounding box to the debug  \n// Adds an oriented bounding box to the debug queue.\n// Adds a text string to the debug drawing queue.\n// This global debug drawing manager is configured for \nIn-Game Menus\n// This global debug drawing manager draws its \nHere’s an example of this API being used within game code:\n// Debug-draw my velocity vector.\n// Debug-draw my name and number of passengers.\nYou’ll notice that the names of the drawing functions use the verb “add” \nrather than “draw.” This is because the debug primitives are typically not \ndrawn immediately when the drawing function is called.\nof the game loop.\nIn-Game Menus\nEvery game engine has a large number of conﬁ guration options and features.\n9. Tools for Debugging and Development\namount of time the game development team spends on debugging problems \nand sett ing up new levels or game mechanics.",
      "keywords": [
        "Debug Drawing",
        "game",
        "debug drawing API",
        "debug",
        "debug drawing queue",
        "Game Engine HID",
        "Debug Drawing Facilities",
        "Drawing",
        "Debug Output",
        "const Point",
        "game engines",
        "control",
        "output",
        "drawing API",
        "Debugging"
      ],
      "concepts": [
        "game",
        "control",
        "controller",
        "debugging",
        "debug",
        "point",
        "functional",
        "function",
        "functions",
        "engine"
      ],
      "similar_chapters": [
        {
          "book": "Game_Engine_Architecture",
          "chapter": 4,
          "title": "",
          "score": 0.582,
          "base_score": 0.432,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 19,
          "title": "",
          "score": 0.512,
          "base_score": 0.512,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 1,
          "title": "",
          "score": 0.458,
          "base_score": 0.458,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 41,
          "title": "",
          "score": 0.42,
          "base_score": 0.42,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 21,
          "title": "",
          "score": 0.405,
          "base_score": 0.405,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "debug",
          "drawing",
          "debug drawing",
          "debugging",
          "output"
        ],
        "semantic": [],
        "merged": [
          "debug",
          "drawing",
          "debug drawing",
          "debugging",
          "output"
        ]
      },
      "topic_id": 6,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.30983714406703156,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:57.759780+00:00"
      }
    },
    {
      "chapter_number": 21,
      "title": "Segment 21 (pages 403-420)",
      "start_page": 403,
      "end_page": 420,
      "summary": "In-Game Console\na system of in-game menus.\nItems on an in-game menu can do any number of \nAn in-game menu should be easy and convenient to bring up, perhaps via \nmenus usually pauses the game.\nThis allows the developer to play the game \nuntil the moment just before a problem occurs, then pause the game by bring-\nmore clearly, and then un-pause the game to inspect the problem in depth.\nIn-Game Console\nSome engines provide an in-game console, either in lieu of or in addition to an \nin-game menu system.\nAn in-game console provides a command-line inter-\nface to the game engine’s features, much as a DOS command prompt provides \nMuch like a menu system, the game engine \nSome in-game consoles provide only a rudimentary set \nscreen shot of the in-game console in Quake 4 is shown in Figure 9.9.\nSome game engines provide a powerful scripting language that can be \nused by programmers and game designers to extend the functionality of the \nengine, or even build entirely new games.\nIf the in-game console “speaks” \nDebug Cameras and Pausing the Game\nAn in-game menu or console system is best accompanied by two other crucial \n(b) the ability to pause , un-pause and single-step the game (see Section 7.5.6).\nWhen the game is paused, it is important to still be able to control the camera.\nrunning, even when the game’s logical clock is paused.\nthe real-time clock, we can put the game into slo-mo by simply updating the \nThe in-game console in Quake 4, overlaid on top of the main game menu.\nWhen developing or debugging a game, it’s important to allow the user to \ncharacter and ﬂ y him or her around in the game world, with collisions dis-\ngame in an att empt to get the player character into some desirable location, \nweapon in the game for testing purposes.\nwhatever cheats you need in order to develop or debug the game.\nshipping game.\ntives in the game.\ntem captures a sequence of screen shots at the target frame rate of the game, \npart to the time required to transfer the frame buﬀ er data from video RAM \nthe game will typically be frozen).\nIn-Game Proﬁ ling\nGames are real-time systems, so achieving and maintaining a high frame rate \nTherefore, part of any game program-\nIn-Game Proﬁ ling \nto know which bits require optimization is to measure your game’s performance.\nThe Uncharted 2 engine also provides a proﬁ le hierarchy display that allows the \ncoarse timing ﬁ gures for various top-level engine systems.\nthis reason, and/or for convenience, many game engines provide an in-game \nTypically an in-game proﬁ ler permits the programmer to annotate blocks \nproﬁ ler measures the execution time of each annotated block via the CPU’s \nwhich shows up-to-date execution times for each code block (examples are \nFor example, let’s imagine that function a() calls functions b() and c(), and \nfunction b() in turn calls functions d(), e() and f().\nIn-Game Proﬁ ling \ntion is called by a start-up function that is part of the standard C runtime library \nIf we measure the execution time of a single function, the time we measure \nincludes the execution time of any the child functions called and all of their \nany proﬁ ling data we might collect, we must be sure to take the function call \nand exclusive execution times of every function that is called during a proﬁ l-\nof the function including all of its children, while exclusive times measure \nonly the time spent in the function itself.\n(The exclusive time of a function \ndren from the inclusive time of the function in question.) In addition, some \nproﬁ lers record how many times each function is called.\nand functions that eat up time because they are called a very large number of \nIn contrast, in-game proﬁ ling tools are not so sophisticated and usually \nIf our game engine’s main loop \nWe could proﬁ le this game at a very coarse level by measuring the execution \ntimes of each major phase of the game loop:\nIn-Game Proﬁ ling \nPROFILE(\"Game Object Update\");\n__int64 elapsedTime = endTime – m_startTime;\nadditional PROFILE() annotations within the RenderScene() function, we \nFor example, we might set up the in-game proﬁ ler during engine initialization \nIn-Game Proﬁ ling \nwe try to proﬁ le a function that is called by more than one parent function.\nerarchy, but actually the same function can reappear many times in the tree, \nfunction’s time will be included in one of the parent bins, but really should be \nMost game engines don’t make an at-\ncoarse-grained functions that are only called from one speciﬁ c location in the \nproﬁ ling your code with a simple in-engine proﬁ le of the sort found in most \ngame engines.\nWe would also like to account for how many times a given function is \nKeeping track of the number of times a function is \nSome game engines permit the data captured by the in-game proﬁ ler to be \nthe game’s execution.\nond actual game time measured in seconds.\nIn-Game Memory Stats and Leak Detection\nIn addition to runtime performance (i.e., frame rate), most game engines are \nBut even PC games are constrained \nFor this reason, most game engines implement custom memory-tracking \nmemory usage of your game so that it will ﬁ t onto the console or type of PC \nKeeping track of how much memory a game actually uses can be a sur-\nyou write the operating system, drivers, and the game engine entire-\nyour game with at least some third-party libraries.\nIn-Game Memory Stats and Leak Detection \nMany games make use of specialized \ncial heap for managing the memory created by game objects as they \nframe), an allocator for video RAM, and a debug memory heap used only \nfor allocations that will not be needed in the ﬁ nal shipping game.\nof these allocators grabs a large hunk of memory when the game starts \ncreating in-engine memory-tracking tools that provide accurate and detailed \nallocations made by the game during a speciﬁ c period of time.\ninclude high water marks for each memory allocator or each game system, \nengines also provide heads-up displays of memory usage while the game is \nengine will provide this information in as helpful a way as possible.\ngames are developed, the game team usually works on high-powered PCs \ngames are developed on special development kits which have more memory \nSo in both cases, the game can continue to run even when \ngame engine can display a message saying something like, “Out of memory—\nThere are lots of other ways in which a game engine’s memory tracking \nhovering in the game world where that object would have been.\ntexture that is very obviously not part of the ﬁ nal game.\nIn-Game Memory Stats and Leak Detection ",
      "keywords": [
        "game",
        "function",
        "In-Game Proﬁ ling",
        "In-Game Proﬁ",
        "game engine",
        "memory",
        "Proﬁ ling",
        "Proﬁ",
        "time",
        "engine",
        "function call",
        "In-Game",
        "game engines provide",
        "PROFILE",
        "In-Game Console"
      ],
      "concepts": [
        "game",
        "memory",
        "engine",
        "profile",
        "functions",
        "functionality",
        "time",
        "timing",
        "timed",
        "frame"
      ],
      "similar_chapters": [
        {
          "book": "Game_Engine_Architecture",
          "chapter": 1,
          "title": "",
          "score": 0.629,
          "base_score": 0.479,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 2,
          "title": "",
          "score": 0.586,
          "base_score": 0.436,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 42,
          "title": "",
          "score": 0.567,
          "base_score": 0.417,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 17,
          "title": "",
          "score": 0.465,
          "base_score": 0.465,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 4,
          "title": "",
          "score": 0.456,
          "base_score": 0.456,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "proﬁ",
          "game proﬁ",
          "function",
          "ling",
          "proﬁ ling"
        ],
        "semantic": [],
        "merged": [
          "proﬁ",
          "game proﬁ",
          "function",
          "ling",
          "proﬁ ling"
        ]
      },
      "topic_id": 1,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.2895766532780997,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:57.759817+00:00"
      }
    },
    {
      "chapter_number": 22,
      "title": "Segment 22 (pages 421-440)",
      "start_page": 421,
      "end_page": 440,
      "summary": "ematics that underlie any real-time 3D rendering engine.\nadvanced rendering techniques and lighting models in use by game engines \nTriangle Rasterization\nz A virtual scene is described, usually in terms of 3D surfaces represented \neventually ﬁ nd their way onto the image-sensing surface of the virtual \nz The visual properties of the surfaces in the scene are described.\nﬁ nes how light should interact with each surface.\nz For each pixel within the imaging rectangle, the rendering engine calcu-\nlates the color and intensity of the light ray(s) converging on the virtual \nuse light transport models that match physical reality as closely as possible.\nReal-time rendering engines perform the steps listed above repeatedly, \nThis means a real-time rendering engine has at \nAn object might be opaque (in which case light cannot \never is behind the object), or translucent (meaning that light can pass through \nof colors that hint at the objects behind it).\nOpaque objects can be rendered by considering only their surfaces .\ndon’t need to know what’s inside an opaque object in order to render it, be-\ncause light cannot penetrate its surface.\ntranslucent object, we really should model how light is reﬂ ected, refracted, \nThey just render the surfaces \nrendering surfaces.\nIn the ﬁ lm industry, surfaces are oft en represented by a collection of rect-\ner surfaces (e.g., bicubic patches , which are third-order Béziers —see htt p://\ner triangles, and N-patches (also known as normal patches—see htt p://www.\nHigh-end ﬁ lm rendering engines like Pixar’s RenderMan use subdivision \nEach surface is represented by a mesh of \nTriangle Meshes\nGame developers have traditionally modeled their surfaces using triangle \nTriangles serve as a piece-wise linear approximation to a surface, \nTriangles are the polygon of choice for real-time rendering because they \nz The triangle is the simplest type of polygon.\nz A triangle is always planar.\nz Triangles remain triangles under most kinds of transformations, including \ntriangle rasterization.\naround triangle rasterization.\nTriangulation is tessellation of a surface into triangles.\nOne problem with the kind of triangle mesh used in games is that its level \ncan cause an object’s silhouett e edges to look blocky, as shown in Figure 10.3; \nform triangle-to-pixel density, no matt er how close or far away the object is.\non distance from the camera, so that every triangle is less than one pixel in \nrendering engine to spend the majority of its time transforming and lighting \nConstructing a Triangle Mesh\nNow that we understand what triangle meshes are and why they’re used, let’s \nA triangle is deﬁ ned by the position vectors of its three vertices, which we can \nside of the triangle should be considered the front (i.e., the outside surface of \nan object) and which should be the back (i.e., its inside surface).\nMost low-level graphics APIs give us a way to cull back-facing triangles \nDeriving the edges and plane of a triangle from its vertices.\nTriangle Lists\nThe easiest way to deﬁ ne a mesh is simply to list the vertices in groups of \nknown as a triangle list ; it is illustrated in Figure 10.6.\nA triangle list.\nIndexed Triangle Lists\nYou probably noticed that many of the vertices in the triangle list shown in \ndata structure known as an indexed triangle list .\nvertices once with no duplication and then to use light-weight vertex indi-\nThe vertices are stored in an array known as a vertex \nSpecialized mesh data structures known as triangle strips and triangle fans are \nAn indexed triangle list.\nas triangles:\nA triangle strip.\nIn a strip, the ﬁ rst three vertices deﬁ ne the ﬁ rst triangle.\nvertex forms an entirely new triangle, along with its previous two neigh-\nA triangle strip is \nIn a fan, the ﬁ rst three vertices deﬁ ne the ﬁ rst triangle and each subse-\nquent vertex deﬁ nes a new triangle with the previous vertex and the ﬁ rst ver-\nAs vertices are processed by the vertex \nbett er, we can use an indexed strip or indexed fan to virtually eliminate vertex \nourselves to strip or fan vertex ordering.\ngeometry processing tool that att empts to list the triangles in an order that \nA triangle fan.\nas triangles:\nFor example, the vertex cache optimizer included in Sony’s \nThe position vectors of a triangle mesh’s vertices are usually speciﬁ ed relative \nto a convenient local coordinate system called model space , local space,  or object \nThe origin of model space is usually either in the center of the object or \nWe call each such object a mesh instance .\nincludes a transformation matrix that converts the mesh’s vertices from model \nGiven a vertex expressed in model-space coordinates, the rendering en-\nWhen rendering a mesh, the model-to-world matrix is also applied to the \nsurface normals of the mesh (see Section 10.1.2.1).\nDescribing the Visual Properties of a Surface\nIn order to properly render and light a surface, we need a description of its \ndirection of the surface normal at various points on the surface.\nencompass a description of how light should interact with the surface.\nincludes diﬀ use color, shininess/reﬂ ectivity, roughness or texture, degree of \nface properties might also include a speciﬁ cation of how the surface should \nlight’s behavior as it interacts with the objects in the scene.\nIntroduction to Light and Color\nThe color of light is determined by its intensity I and its \nmally narrow spike at about 570 THz. Light-Object Interactions\nFor example, when white light falls on a red object, all wavelengths except \ncan also be anisotropic , meaning that the way in which light reﬂ ects from a sur-\ncase for translucent objects), partially absorbed (as with colored glass), or re-\nLight can also enter a semi-solid surface, bounce around, and then exit \nthe surface at a diﬀ erent point from the one at which it entered the surface.\nColor Spaces and Color Models\nA color model is a three-dimensional coordinate system that measures colors.\nColor models are typically three-dimensional because of the \nThe most commonly used color model in computer graphics is the RGB \nIn this model, color space is represented by a unit cube, with the rela-\ncolor model, each channel ranges from zero to one.\nA color format is deﬁ ned in part by the number of bits per pixel \nA number of other color models are also used in 3D rendering.\nhow the log-LUV color model is used for high dynamic range (HDR) lighting \nA fourth channel called alpha  is oft en tacked on to RGB color vectors.\nThe simplest way to describe the visual properties of a surface is to specify \nnient place to store surface properties, in which case they are called vertex \nA typical triangle mesh includes some or all of the following att ributes at \neach vertex.\nThis is the 3D position of the ith vertex in \nIt is usually speciﬁ ed in a coordinate space local to the object, \nknown as model space.\nz Vertex normal (ni = [ nix  niy  niz ]).\nThis vector deﬁ nes the unit surface nor-\nIt is used in per-vertex dynamic lighting \nunit vectors lie perpendicular to one another and to the vertex normal \nThis space is used for various per-pixel lighting \nit is not normal to the surface.)\nthe diﬀ use color of the surface, expressed in the RGB color space.\nsurface at the position of the vertex.\nspecular highlight that should appear when light reﬂ ects directly from a \nshiny surface onto the virtual camera’s imaging plane.\nsurface of a mesh—a process known as texture mapping.\ntwo-dimensional normalized coordinate space of the texture.\nA triangle \nvertex must specify to which joint it is att ached via an index, k.\nA vertex \ncan be inﬂ uenced by multiple joints, in which case the ﬁ nal vertex posi-\nVertex Formats\nVertex att ributes are typically stored within a data structure such as a C \nhence need diﬀ erent vertex formats.\nmon vertex formats:\n// Simplest possible vertex – position only (useful for\n// A typical vertex format with position, vertex normal \n// vertex normal\nClearly the number of possible permutations of vertex att ributes—and \nof all these vertex formats is a common source of headaches for any graphics \nSome steps can be taken to reduce the number of vertex formats that an \nretically possible vertex formats are simply not useful, or they cannot be \nalso limit themselves to a subset of the useful/feasible vertex formats in or-\nno more than two sets of texture coordinates per vertex.\ncapable of extracting a subset of att ributes from a vertex data structure, so \nThe att ributes at a triangle’s vertices are just a coarse, discretized approxima-\ntion to the visual properties of the surface as a whole.\ntriangle as “seen” through each pixel on-screen.\nknow the values of the att ributes on a per-pixel basis, not a per-vertex basis.\nOne simple way to determine the per-pixel values of a mesh’s surface at-\ntributes is to linearly interpolate the per-vertex att ribute data.\nvertex colors, att ribute interpolation is known as Gouraud shading .\nof Gouraud shading applied to a triangle is shown in Figure 10.11, and its ef-\nfects on a simple triangle mesh are illustrated in Figure 10.12.\nroutinely applied to other kinds of vertex att ribute information as well, such \nas vertex normals, texture coordinates, and depth.\nVertex Normals and Smoothing\nAs we’ll see in Section 10.1.3, lighting is the process of calculating the color of \nan object at various points on its surface, based on the visual properties of the \nsurface and the properties of the light impinging upon it.\nlight a mesh is to calculate the color of the surface on a per-vertex basis.\nwords, we use the properties of the surface and the incoming light to calculate \nthe diﬀ use color of each vertex (di).\nThese vertex colors are then interpolated \nacross the triangles of the mesh via Gouraud shading.\nIn order to determine how a ray of light will reﬂ ect from a point on a sur-\nface, most lighting models make use of a vector that is normal to the surface at \non a per-vertex basis, we can use the vertex normal ni for this purpose.\nfore, the directions of a mesh’s vertex normals can have a signiﬁ cant impact on \nto appear to be sharp-edged, we can specify the vertex normals to be perpen-\nAs we light each triangle, we will encounter the \nsame normal vector at all three vertices, so the resulting lighting will appear \nspecifying vertex normals that point radially outward from the box’s center \nIn this case, the vertices of each triangle will have diﬀ erent vertex nor-\nmals, causing us to calculate diﬀ erent colors at each vertex.\nwill smoothly interpolate these vertex colors, resulting in lighting that appears \nThe directions of a mesh’s vertex normals can have a profound effect on the \ncolors calculated during per-vertex lighting calculations.\nWhen triangles are relatively large, specifying surface properties on a per-ver-\nhighly tessellated, per-vertex lighting combined with Gouraud shading can \nTo overcome the limitations of per-vertex surface att ributes, rendering en-\ncolor information and is usually projected onto the triangles of a mesh.\nBut a texture can contain other kinds of visual surface proper-\nThe most common type of texture is known as a diﬀ use map , or albedo map .\ndescribes the diﬀ use surface color at each texel on a surface and acts like a de-\ndescription of the visual properties of a surface, especially when tessellation is low.",
      "keywords": [
        "Triangle",
        "Rendering Engine",
        "vertex",
        "Depth-Buffered Triangle Rasterization",
        "Triangle Rasterization",
        "Rendering",
        "surface",
        "color",
        "light",
        "triangle mesh",
        "mesh",
        "object",
        "Model Space",
        "space",
        "Depth-Buffered Triangle"
      ],
      "concepts": [
        "vertex",
        "light",
        "color",
        "surfaces",
        "rendering",
        "render",
        "triangle",
        "engine",
        "objects",
        "vectors"
      ],
      "similar_chapters": [
        {
          "book": "Game_Engine_Architecture",
          "chapter": 26,
          "title": "",
          "score": 0.68,
          "base_score": 0.53,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 24,
          "title": "",
          "score": 0.668,
          "base_score": 0.518,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 25,
          "title": "",
          "score": 0.647,
          "base_score": 0.497,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 23,
          "title": "",
          "score": 0.573,
          "base_score": 0.423,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 30,
          "title": "",
          "score": 0.5,
          "base_score": 0.35,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "vertex",
          "surface",
          "triangle",
          "color",
          "light"
        ],
        "semantic": [],
        "merged": [
          "vertex",
          "surface",
          "triangle",
          "color",
          "light"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.26390375423642964,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:57.759854+00:00"
      }
    },
    {
      "chapter_number": 23,
      "title": "Segment 23 (pages 441-462)",
      "start_page": 441,
      "end_page": 462,
      "summary": "of how various types of textures can be used for image-based lighting and \nWe can actually use texture maps to store any information that we happen \nto need in our lighting calculations.\nFor example, a one-dimensional texture \nTexture Coordinates\nLet’s consider how to project a two-dimensional texture onto a mesh.\nthis, we deﬁ ne a two-dimensional coordinate system known as texture space .\nA texture coordinate is usually represented by a normalized pair of numbers \nTo map a triangle onto a 2D texture, we simply specify a pair of texture \nimage plane in texture space.\nAn example of texture mapping is depicted in \nAn example of texture mapping.\nsional space and in texture space.\ngraphics hardware can handle out-of-range texture coordinates in any one of \nidea is to break the texture into 2 × 2 blocks of pixels and use a small color pal-\nCompressed textures do \nIn this case, each texel maps exactly to a single pixel on-screen, and \ntion of the texture hasn’t changed, so the quad’s texel density is now greater \nClearly texel density is not a ﬁ xed quantity—it changes as a texture-\nFor each texture, \nFor example, a 64 × 64 texture would have the \nFor example, if a texture takes up an area of 40 × 40 on-screen, the 64 × 64 mip \nMip levels for a 64×64 texture.\nWorld Space Texel Density\nspace area on a textured surface.\na 256 × 256 texture would have a texel density of 2562/22 = 16,384.\nworld space texel density to diﬀ erentiate it from the screen space texel density \nWorld-space texel density need not be close to one, and in fact the speciﬁ c \nmapped with a reasonably consistent world space texel density.\ngame have a reasonably consistent world space texel density.\nWhen rendering a pixel of a textured triangle, the graphics hardware samples \nthe texture map by considering where the pixel center falls in texture space.\nand pixel centers can fall at any place in texture space, including directly on \nMost graphics cards support the following kinds of texture ﬁ ltering:\ncal resolution needed to achieve a screen-space texel density of one.\nangle, thereby increasing the quality of textured surfaces when viewed \nincludes a speciﬁ cation of the textures that are mapped to its surface and also \nLighting Basics\nLighting is at the heart of all CG rendering.\nWithout good lighting, an other-\nFigure 10.20, the scene is rendered without textures.\nsame scene with diﬀ use textures applied.\nA scene from Uncharted: Drake’s Fortune rendered without textures.\nRendering engines use various mathematical models of light-surface and light-\nvolume interactions called light transport models .\ncount for direct lighting in which light is emitt ed, bounces oﬀ  a single object in \nlocal eﬀ ects of light on a single object are considered; objects do not aﬀ ect one \nanother’s appearance in a local lighting model.\nwere the ﬁ rst to be used in games, and they are still in use today—local light-\ning , where light bounces multiple times oﬀ  many surfaces before reaching the \nLighting models that account for indirect lighting are called \nThe UDF scene with full lighting.\nows, modeling reﬂ ective surfaces, accounting for interreﬂ ection between ob-\nany other text on advanced rendering and lighting for more details on the \nThe Phong Lighting Model\nThe most common local lighting model employed by game rendering engines \nis the Phong reﬂ ection model .\nIt models the light reﬂ ected from a surface as a \nz The ambient term models the overall lighting level of the scene.\nz The diﬀ use term accounts for light that is reﬂ ected uniformly in all direc-\ntions from each direct light source.\nway in which real light bounces oﬀ  a matt e surface, such as a block of \ning angle is closely aligned with a path of direct reﬂ ection from a light \nTo calculate Phong reﬂ ection at a speciﬁ c point on a surface, we require \nz the viewing direction vector V = [ Vx  Vy  Vz ], which extends from the \nlight \nz the surface normal N = [ Nx  Ny  Nz ] at the point the light ray impinges \nz and, for each light source i, \nthe light’s color and intensity \nLi from the reﬂ ection point to the light source.\nIn the Phong model, the intensity I of light reﬂ ected from a point can be ex-\nwhere the sum is taken over all lights i aﬀ ecting the point in question.\nIn these equations, the vector Ri = [ Rxi  Ryi  Rzi ] is the reﬂ ection of the light ray’s \nexample, we can break up the light direction vector L as follows:\nThe reﬂ ected vector R has the same normal component as L but the opposite \nThis equation can be used to ﬁ nd all of the Ri values corresponding to the light \nThe Blinn-Phong lighting model is a variation on Phong shading that calcu-\nbe the vector that lies halfway between the view vector V and the light direc-\nThe three terms in the Phong lighting model are special cases of a general local \nthe reﬂ ection point were viewed from that direction.\nray L, not the viewing angle V.\nThe specular term of the Phong model is kS(R · V)α.\non both the illumination direction L and the viewing direction V.\na specular “hot spot” when the viewing angle aligns closely with the reﬂ ection \nR of the illumination direction L about the surface normal.\ntribution falls oﬀ  very quickly as the viewing angle diverges from the reﬂ ected \nModeling Light Sources\nIn addition to modeling the light’s interactions with surfaces, we need to de-\nscribe the sources of light in the scene.\nwe approximate real-world light sources using various simpliﬁ ed models.\nThe diffuse term of the Phong reﬂ ection model is dependent upon N • L, but is \nThe specular term of the Phong reﬂ ection model is at its maximum when the \nviewing angle V coincides with the reﬂ ected light direction R and drops off quickly as V di-\nStatic Lighting\nLighting is there-\nWe can also precalculate lighting on a per pixel basis and store the \nresults in a kind of texture map known as a light map .\nAt runtime, the light \nmap texture is projected onto the objects in the scene in order to determine the \nlight’s eﬀ ects on them.\ninto the diﬀ use textures in the scene.\nthing, diﬀ use texture maps are oft en tiled and/or repeated throughout a scene, \nInstead, a single light map \nis usually generated per light source and applied to any objects that fall within \nlight maps can be of a diﬀ erent (oft en lower) resolution than our diﬀ use tex-\nFinally, a “pure” light map usually compresses bett er than one that \nAmbient Lights\nAn ambient light corresponds to the ambient term in the Phong lighting model.\nThis term is independent of the viewing angle and has no speciﬁ c direction.\nAn ambient light is therefore represented by a single color, corresponding to \nthe A color term in the Phong equation (which is scaled by the surface’s ambi-\nThe intensity and color of ambient light may \nDirectional Lights\nA directional light models a light source that is eﬀ ectively an inﬁ nite distance \nfrom a directional light are parallel, and the light itself does not have any \nA directional light is therefore modeled \nas a light color C and a direction vector L.\nA directional light is depicted in \nPoint (Omni-Directional) Lights\nA point light (omni-directional light) has a distinct position in the game world \nThe intensity of the light is usually \nconsidered to fall oﬀ  with the square of the distance from the light source, \nA point light is modeled as a light position P, a source color/intensity C, \nof a directional light \nel of a point light \npoint light to those surfaces that fall within is sphere of inﬂ uence (a signiﬁ cant \nFigure 10.27 illustrates a point light.\nSpot Lights\nThe light intensity falls oﬀ  as the angle increases from the inner to the \nboth cones, the light intensity also falls oﬀ  with radial distance.\nA spot light is \nmodeled as a position P, a source color C, a central direction vector L, a maxi-\nillustrates a spot light source.\nArea Lights\nAll of the light sources we’ve discussed thus far radiate from an idealized \nRather than trying to model area lights explicitly, CG engineers oft en use \nSome surfaces in a scene are themselves light sources.\nsurfaces can be modeled using an emissive texture map —a texture whose colors \nFor example, a ﬂ ashlight might be rendered using an emissive texture \ncasts light into the scene, a yellow translucent mesh to simulate the light cone, \nif high dynamic range lighting is supported by the engine), and a projected \ntexture to produce the caustic eﬀ ect that a ﬂ ashlight has on the surfaces it il-\nof a spot light source.\nangular virtual light sensors, each corresponding to a single pixel on-screen.\nintensity of light would be recorded by each of these virtual sensors.\nView Space\nknown as view space or camera space.\npositive or negative z-axis in view space, with y up and x to the left  or right.\nTypical left - and right-handed view space axes are illustrated in Figure 10.30.\nthe scene, an emissive texture on the lens, and camera-facing cards for the lens ﬂ are.\nworld matrix , just as a mesh instance is located in the scene with its model-to-\ncamera space, expressed in world-space coordinates, the view-to-world ma-\na model-to-view matrix:\nmodel space to world space, and then from world space to view space.\nperform this latt er transformation, we need the world-to-view matrix , which \nview matrix:\nThe world-to-view matrix is oft en concatenated to the model-to-world \ncalled the model-view matrix in OpenGL.\ning vertices from model space into view space:\nmodel view.\nIn order to render a 3D scene onto a 2D image plane, we use a special kind \nprimarily for rendering plan views (e.g., front, side, and top) of 3D models or \nThe region of space that the camera can “see” is known as the view volume .\nWhen rendering the scene with a perspective projection, the shape of the \nA cube rendered using a perspective projection (on the left) and an ortho-\nBoth perspective and orthographic projections transform points in view space \nis to convert the camera-space view volume into a canonical view volume that \nIn clip space, the canonical view volume is a rectangular prism extending \nAlong the z-axis, the view volume ex-\nThe canonical view volume in homogeneous clip space.\nmaking it convenient to clip triangles to the view volume in this space (even \nThe canonical clip-space view \ntrix transforms vertices from view space into homogeneous clip space.) If we \ntake view space to be right-handed, then the near plane intersects the z-axis \n(Typically the virtual screen is centered on the camera-space z-axis, in \nDirectX deﬁ nes the z-axis extents of the clip-space view volume to lie in \nTo understand why this happens, consider multiplying a view-space point \nreally just the negative view-space z-coordinate \nThus the homogeneous clip space coordinates have been divided by the view-\nspace z-coordinate, which is what causes perspective foreshortening.\nScreen space is a two-dimensional coordinate system whose axes are mea-\nWe can render triangles expressed in homogeneous clip space by simply \nThe ﬁ nal rendered image is stored in a bitmapped color buﬀ er known as the ",
      "keywords": [
        "light",
        "texture",
        "Rendering Engine",
        "space",
        "Texel Density",
        "Depth-Buffered Triangle Rasterization",
        "Space Texel Density",
        "rendering",
        "light source",
        "Phong reﬂ ection",
        "Phong Lighting Model",
        "Triangle Rasterization",
        "View Space",
        "texture space",
        "view"
      ],
      "concepts": [
        "lighting",
        "textures",
        "textured",
        "model",
        "render",
        "rendered",
        "color",
        "screen",
        "vectors",
        "space"
      ],
      "similar_chapters": [
        {
          "book": "Game_Engine_Architecture",
          "chapter": 22,
          "title": "",
          "score": 0.573,
          "base_score": 0.423,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 24,
          "title": "",
          "score": 0.545,
          "base_score": 0.395,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 26,
          "title": "",
          "score": 0.534,
          "base_score": 0.384,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 29,
          "title": "",
          "score": 0.503,
          "base_score": 0.353,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 25,
          "title": "",
          "score": 0.498,
          "base_score": 0.348,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "light",
          "space",
          "texture",
          "view",
          "lighting"
        ],
        "semantic": [],
        "merged": [
          "light",
          "space",
          "texture",
          "view",
          "lighting"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.2186740581484672,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:57.759889+00:00"
      }
    },
    {
      "chapter_number": 24,
      "title": "Segment 24 (pages 463-481)",
      "start_page": 463,
      "end_page": 481,
      "summary": "ceed to render a new frame into buﬀ er C, rather than idling while it waits for \nAny buﬀ er into which the rendering engine draws graphics is known as a ren-\nsorts of other oﬀ -screen render targets, in addition to the frame buﬀ ers.\nTriangle Rasterization and Fragments\nTo produce an image of a triangle on-screen, we need to ﬁ ll in the pixels it \nbuﬀ er, it must pass a number of tests (described in more depth below).\nten into the frame buﬀ er or blended with the pixel color that’s already there.\nA fragment is a small region of a triangle corresponding to a pixel on the \nIt passes through the rendering pipeline and is either discarded or its color is written \nThe Rendering Engine\nthe surrounding colors in the frame buﬀ er.\nantialiasing (FSAA), the image is rendered into a frame buﬀ er that is twice \nrendering a double-sized frame means ﬁ lling four times the number of pixels.\none fragment per pixel.\nWhen rendering two triangles that overlap each other in screen space, we \nWe could accomplish this by always rendering our triangles in \nThe painter’s algorithm renders triangles in a back-to-front order to produce \nwhich the triangles are rendered, rendering engines use a technique known \nthe depths of the triangle’s vertices.) When a fragment’s color is writt en into \nthe frame buﬀ er, it depth is stored into the corresponding pixel of the depth \npixel, the engine compares the new fragment’s depth to the depth already \nhas a smaller depth), it overwrites the pixel in the frame buﬀ er.\neﬀ ect known as z-ﬁ ghting .\nsion of clip-space z-depths (\n) in the depth buﬀ er instead of clip-space z-coordinates (\nThe Rendering Engine\nThe z- and w-buﬀ ers store \nnates, the z-buﬀ er stores 1/z (i.e., 1/\n) while the w-buﬀ er stores z (i.e., \nThe Rendering Pipeline\nEach stage of a pipeline can typically operate independently of the other \nstages.\non one data element, the second stage can be processing the results previously \nthat stage.\nThe throughput of a pipeline measures how many data items are processed \nThe slowest stage of a pipeline dictates the throughput of the entire pipe-\nTherefore, when designing a rendering pipeline, we att empt to minimize and \ndesigned pipeline, all the stages operate simultaneously, and no stage is ever \nOverview of the Rendering Pipeline\nSome graphics texts divide the rendering pipeline into three coarse-grained \nstages.\nThe high level stages in our pipeline are:\nz Tools stage (oﬄ  ine).\nz Asset conditioning stage (oﬄ  ine).\nStage 3\nStage 1\nStage 2\nThe Rendering Pipeline\nThe Rendering Engine\nz Application stage (CPU).\nrendering.\nz Geometry processing stage (GPU).\noptional geometry shader and then clipped to the frustum.\nz Rasterization stage (GPU).\nand ﬁ nally blended into the frame buﬀ er.\nHow the Rendering Pipeline Transforms Data\nthrough the rendering pipeline.\nIn the rasterization stage, each triangle is broken into fragments, and these \nbuﬀ er as colors.\nous stages of the rendering pipeline.\nThe ﬁ rst two stages of the rendering pipeline are implemented oﬄ  ine, usually \nPS3’s SPUs. The geometry and rasterization stages are usually implemented \nlated into triangles prior to rendering by the runtime portion of the pipeline.\nMaterials are also deﬁ ned by the artists during the tools stage.\nvolves selecting a shader for each material, selecting textures as required by \nshader.\nTextures are mapped onto the surfaces, and other vertex att ributes are \nand debugged by the artist or a shader engineer.\nThe Rendering Pipeline\nThe Rendering Engine\nThe Unreal Engine 3 graphical shader language.\ngraphical shader editor is shown in Figure 10.42.\nThe asset conditioning stage is itself a pipeline, sometimes called the asset \nexample, a 3D model is comprised of geometry (vertex and index buﬀ ers), \nfor the Xbox 360 might be output as index and vertex buﬀ ers that are ready \nThe ACP oft en takes the needs of the material/shader into account \nFor example, a particular shader might require tangent \ntion of light colors at the vertices of a mesh (this is called “baked” vertex \nThe Rendering Pipeline\nThe Rendering Engine\ntors provided support for the geometry processing stage as well.\nimplementation known as the ﬁ xed-function pipeline .\nnow write programs called shaders to control exactly how the pipeline pro-\ncessed vertices (vertex shaders) and fragments (fragment shaders, more common-\nly known as pixel shaders).\nshader known as a geometry shader was added.\ndata through the pipeline .\nCertain pipeline stages are either entirely ﬁ xed in \nern GPU and see how the runtime portion of the rendering pipeline is typi-\nnot support programmable shaders, and most PC games need to support fall-\nprogrammable shader support.\nVertex Shader\nshader handles transformation from model space to view space via the model-\nThe output of this stage is a fully transformed \nOn modern GPUs, the vertex shader has full access to texture data—a ca-\npability that used to be available only to the pixel shader.\nuseful when textures are used as stand-alone data structures like height maps \nGeometry Shader\nThe geometry shader oper-\nShader\nShader\nShader\nThe geometry processing and rasterization stages of the rendering pipeline, as \nThe Rendering Pipeline\nThe Rendering Engine\npoints of the hair splines within the vertex shader.\nThe geometry shader tes-\ntop of the pipeline so they can be rendered.\nThe clipping stage chops oﬀ  those portions of the triangles that straddle the \nThis stage is ﬁ xed in function, but it is somewhat conﬁ gurable.\nThis stage can also be conﬁ gured to cull triangles that lie entirely out-\nThis stage is entirely ﬁ xed and non-conﬁ gurable.\nThe triangle traversal stage also interpolates vertex att ributes \nin order to generate per-fragment att ributes for processing by the pixel shader.\nThis allows the (potentially very expensive) pixel shader \nstage to be skipped entirely for occluded fragments.\nstage of the pipeline.\npha testing, aft er the pixel shader had run.\nthe early z test or early depth test stage.\nPixel Shader\nThe pixel shader can also discard fragments, for ex-\nThe pixel shader \nThe input to this stage is a collection of per-fragment att ributes (which \nstage).\nThe ﬁ nal stage of the pipeline is known as the merging stage or blending stage, \nalso known as the raster operations stage or ROP in NVIDIA parlance.\nIf the fragment passes all of the tests, its color is blended (merged) with \nthe color that is already present in the frame buﬀ er.\nThe Rendering Pipeline\nThe Rendering Engine\ntination” (the pixel in the frame buﬀ er), respectively.\nter the opaque geometry has been rendered to the frame buﬀ er.\ncause aft er alpha blending has been performed, the depth of the new fragment \nProgrammable Shaders\npixel shader diﬀ ered signiﬁ cantly from those of the vertex shader.\n9 brought with it support for high-level C-like shader languages such as Cg \nA shader takes a single element of input data and transforms it into zero \nz In the case of the vertex shader, the input is a vertex whose position and \nvertex shader is a fully transformed and lit vertex, expressed in homo-\nz The input to the geometry shader is a single n-vertex primitive—a point \nshader could convert points into two-triangle quads, or it could trans-\nz The pixel shader’s input is a fragment whose att ributes have been in-\nThe output of the pixel shader is the color that will be writt en into the \nframe buﬀ er (presuming the fragment passes the depth test and other \nThe pixel shader is also capable of discarding fragments \nBecause the GPU implements a data processing pipeline, access to RAM is \nA shader program cannot read from or write to \nShader Registers\nA shader can access RAM indirectly via registers.\nThe Rendering Pipeline\nThe Rendering Engine\nThese registers are the shader’s primary source of input \nIn a vertex shader, the input registers contain att ribute data ob-\nIn a pixel shader, the input registers \nstant only from the point of view of the shader program.\nother parameters required by the shader that are not available as vertex \nThese registers are for use by the shader program inter-\nz Output registers.\nThe contents of these registers are ﬁ lled in by the shader \nIn a vertex shader, the output regis-\nmal vectors in homogeneous clip space, optional vertex colors, texture \nIn a pixel shader, the output register contains \nto calling the shader program, and it also writes the contents of the output \nthe data can be passed to the next stage of the pipeline.\nrecently processed vertices emitt ed by the vertex shader.\npost-transform vertex cache if possible—the vertex shader need only be called \nA shader also has direct read-only access to texture maps.\nThe GPU’s texture samplers automatically ﬁ lter the texture data, blending val-\nThis can be useful when a texture map is used as a data table, for \nShaders can only write to texture maps in an indirect manner—by render-\ning the scene to an oﬀ -screen frame buﬀ er that is interpreted as a texture map \nThis feature is known as render to texture .\nHigh-level shader languages like Cg and GLSL are modeled aft er the C pro-\nable we declare in Cg or GLSL is mapped directly onto registers by the shader \nshader compiler to bind the variable or data member to a particular \nvertex or fragment att ribute.\nFor example, in a vertex shader we might \nThe Rendering Pipeline\nThe Rendering Engine\na vertex shader as follows:\nthe texture maps themselves are declared using a special data type known as \nCg pixel shader applies a diﬀ use texture to a triangle:\nrequired by the GPU pipeline in order to call the shader program with mean-\nthe uniform variables declared in the shader program.\nsual eﬀ ects require two or more rendering passes, but a shader program only \nDiﬀ erent rendering engines implement eﬀ ects in slightly diﬀ erent ways.\nz At global scope, structs, shader programs (implemented as various \na reference to a vertex, geometry and/or pixel shader program’s “main” \nThe Rendering Pipeline",
      "keywords": [
        "rendering pipeline",
        "shader",
        "rendering",
        "stage",
        "pipeline",
        "pixel shader",
        "Vertex Shader",
        "rendering engine",
        "frame buﬀ",
        "data",
        "buﬀ",
        "vertex",
        "GPU",
        "geometry shader",
        "Triangle"
      ],
      "concepts": [
        "stages",
        "render",
        "data",
        "vertex",
        "triangle",
        "graphics",
        "graphical",
        "textures",
        "fragments",
        "fragment"
      ],
      "similar_chapters": [
        {
          "book": "Game_Engine_Architecture",
          "chapter": 25,
          "title": "",
          "score": 0.732,
          "base_score": 0.582,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 26,
          "title": "",
          "score": 0.686,
          "base_score": 0.536,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 22,
          "title": "",
          "score": 0.668,
          "base_score": 0.518,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 23,
          "title": "",
          "score": 0.545,
          "base_score": 0.395,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 28,
          "title": "",
          "score": 0.526,
          "base_score": 0.376,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "shader",
          "stage",
          "pipeline",
          "pixel",
          "vertex"
        ],
        "semantic": [],
        "merged": [
          "shader",
          "stage",
          "pipeline",
          "pixel",
          "vertex"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.24389804681297175,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:57.759923+00:00"
      }
    },
    {
      "chapter_number": 25,
      "title": "Segment 25 (pages 482-502)",
      "start_page": 482,
      "end_page": 502,
      "summary": "The Rendering Engine\n2. Submitt ing geometry to the GPU for rendering.\nsent to the GPU via a rendering call like DrawIndexedPrimitive()\nThe geometry may be sorted for optimal render-\nscene needs to be rendered in multiple passes.\n3. Controlling shader parameters and render state.\nmable pipeline stages to ensure that each primitive is rendered ap-\ntant to cull objects from the scene that do not contribute to the ﬁ nal rendered \nIn frustum culling , all objects that lie entirely outside the frustum are exclud-\ned from our render list.\ntween the object’s bounding volume and the six frustum planes.\nmize frustum culling by allowing us to ignore objects whose bounding spheres \nother objects is called occlusion culling .\na PVS lists those scene objects that might be visible.\nactually would have contributed to the rendered scene.\nusually operates by rendering the scene from various randomly distributed \nlist of visible regions can be found by scanning the resulting frame buﬀ er and \nAnother way to determine what portions of a scene are visible is to use portals .\nIn portal rendering, the game world is divided up into semiclosed regions \nThe Rendering Pipeline\nThe Rendering Engine\nTo render a scene with portals, we start by rendering the region that con-\nregion can be culled to this portal volume in exactly the same way geometry is \nin the adjacent regions will be rendered.\nIn this example, objects A, B, and D will be culled because they \noccluding object and extend planes outward from the camera’s focal point \nclusion volumes and cull them if they lie entirely within the occlusion region.\nvolume of the camera frustum, resulting in a large number of objects outside \nage of the total camera frustum volume, resulting in large numbers of culled \nprimitives must be submitt ed to the GPU pipeline for rendering.\nRender State\nz light direction vectors;\nThe Rendering Pipeline\nThe Rendering Engine\nsubmesh-material pair, sett ing the render state based on the material’s speciﬁ -\nA render state leak might manifest itself as an object with the wrong \ntexture or an incorrect lighting eﬀ ect, for example.\nThese commands interleave render state sett ings with references to the \nFor example, to render objects A and B with \nmaterial 1, followed by objects C, D, and E using material 2, the command list \nz Set render state for material 1 (multiple commands, one per render state \nz Set render state for material 2 (multiple commands).\nRender state sett ings are global—they apply to the entire GPU as a whole.\nSo in order to change render state sett ings, the entire GPU pipeline must be \nClearly we’d like to change render sett ings as infrequently as possible.\nwe can install material A’s sett ings, render all geometry associated with mate-\nof early z, we need to draw the triangles in front-to-back order.\nclosest triangles will ﬁ ll the z-buﬀ er right oﬀ  the bat, and all of the fragments \ning need to render opaque geometry in a front-to-back order?\nThe idea behind z prepass is to render the scene twice: the ﬁ rst time to \nOpaque geometry can be rendered in front-\nand rendered in full color with minimal stage changes for maximum pipeline \nOnce the opaque geometry has been rendered, transparent surfaces can \nWe must render it \nscenes does not lie within the camera frustum, so frustum culling all of these \nThe Rendering Pipeline\nThe Rendering Engine\nto-back order for the z prepass or in material order for full-color rendering.\nlike data structures oft en used by ﬁ lm rendering engines and DCC tools like \nhaving to frustum cull all of the individual objects within them.\nten used to store renderable primitives such as mesh instances, subregions of \nThe renderable primitives are stored at the \nTo determine which primitives are visible within the camera frustum, \nrectangular regions, a bounding sphere tree divides space into spherical regions \nTo generate a list of potentially visible primitives, we walk the tree \nIn the context of rendering, a BSP tree divides space with a single plane at \nThe Rendering Pipeline\nThe Rendering Engine\nA BSP tree can be used for frustum culling in much the same way a \nz-buﬀ er and so were forced to use the painter’s algorithm (i.e., to render the \nscene from back to front) to ensure proper inter-triangle occlusion.\nGiven a camera view point in 3D space, a back-to-front sorting algorithm \ndividing plane, we visit the node’s front children ﬁ rst, then draw the triangles \nAn example of back-to-front traversal of the triangles in a BSP tree.\nto be rendering.\nrendering scenes for your particular game.\nIn order to render photorealistic scenes, we need physically accurate global \nThe Rendering Engine\nimage data, usually in the form of two-dimensional texture maps.\ncalled image-based lighting algorithms.\nA normal map speciﬁ es a surface normal direction vector at each texel.\nlows a 3D modeler to provide the rendering engine with a highly detailed de-\nUsing a normal map, a single ﬂ at triangle can be made to \nAn example of a normal-mapped surface.\nor below the surface of the triangle.\nA height map can also be used as a cheap way to generate surface normals.\ngame engines store surface normal information explicitly in a normal map, \nWhen light reﬂ ects directly oﬀ  a shiny surface, we call this specular reﬂ ection.\nviewer, the light source, and the surface normal.\nthe light’s direction vector about the surface normal, V is the direction to the \nmap texture is used to deﬁ ne the surface details.\nThe Rendering Engine\nlights will have at each texel.\nThis kind of texture is called a specular power map .\ntaken from the point of view of an object in the scene, covering a full 360 \nronment map acts like a description of the general lighting environment sur-\nIt is generally used to inexpensively render reﬂ ections.\nsphere whose radius is inﬁ nite, centered about the object being rendered.\nDuring rendering, a cube map is treated as though it were mapped onto the \nsix inner surfaces of a box at inﬁ nity, centered on the object being rendered.\nTo read the environment map texel corresponding to a point P on the \nsurface of an object, we take the ray from the camera to the point P and reﬂ ect \nFor example, we could render a marble \nThe Rendering Engine\ning algorithms that account for light’s interactions with multiple objects in the \nscene, on its way from the light source to the virtual camera .\ntion accounts for eﬀ ects like the shadows that arise when one surface occludes \nanother, reﬂ ections, caustics, and the way the color of one object can “bleed” \nmethods aim to reproduce a single isolated eﬀ ect, like shadows or reﬂ ections.\nShadow Rendering\nShadows are created when a surface blocks light’s path.\nby an ideal point light source would be sharp, but in the real world shadows \nThe two most prevalent shadow rendering techniques are shadow vol-\numes and shadow maps.\nboth techniques, objects in the scene are generally divided into three catego-\njects that are entirely excluded from consideration when rendering shadows.\nThis important optimization limits the number of light-object \nvantage point of a shadow-generating light source, and the shadow caster’s \ngeometry that describes the volume of space in which the light is occluded by \nRendering can be masked \nto only render fragments whose corresponding stencil values are non-zero.\naddition, the GPU can be conﬁ gured so that rendered geometry updates the \nTo render shadows, the scene is ﬁ rst drawn to generate an unshadowed \nrendered from the point of view of the camera in such a way that front-facing \nwhere the back face of the shadow volume has been occluded by “real” scene \nSo we can render shadows in a third pass, by simply darkening \nthose regions of the screen that contain a non-zero stencil buﬀ er value.\nShadow Maps\nThe shadow mapping technique is eﬀ ectively a per-fragment depth test per-\nformed from the point of view of the light instead of from the point of view \nThe scene is rendered in two steps: First, a shadow map texture \ncasting object as seen from the point of view of the light source.\nThe Rendering Engine\nis generated by rendering the scene from the point of view of the light source \nSecond, the scene is rendered \nas usual, and the shadow map is used to determine whether or not each frag-\nAt each fragment in the scene, the shadow map tells us \nwhether or not the light is being occluded by some geometry that is closer to \nthe light source, in just the same way that the z-buﬀ er tells us whether a frag-\nA shadow map contains only depth information—each texel records how \nShadow maps are therefore typically ren-\nFor a point light source, a perspective projection is \nused when rendering the shadow map; for a directional light source, an ortho-\nTo render a scene using a shadow map, we draw the scene as usual from \ngenerating the shadow map in the ﬁ rst place.\ngiven fragment is in shadow or not, we convert the fragment’s light-space (x, \ny)-coordinates into texture coordinates (u, v) within the shadow map.\ncompare the fragment’s light-space z-coordinate with the depth stored at the \ncorresponding texel in the shadow depth map.\nIf the fragment’s light-space z \nis farther away from the light than the texel in the shadow map, then it must be \nLikewise, if the fragment’s light-space z is closer to the \nlight source than the texel in the shadow map, then it is not occluded and is \nThe shadow mapping process is illustrated in Figure 10.52.\nThe far left image is a shadow map—the contents of the z-buffer as rendered \nfrom the point of view of a particular light source.\nwhere the light-space depth test failed (fragment in shadow) and white where it succeeded \nThe far right image shows the ﬁ nal scene rendered with shadows.\nows that arise when a scene is illuminated by only ambient light.\nbient occlusion describes how “accessible” each point on a surface is to light \ntypically stored in a texture map that records the level of ambient occlusion at \nReﬂ ections occur when light bounces oﬀ  a highly specular (shiny) surface pro-\nrendered with ambient \nMirror reﬂ ections in Luigi’s Mansion implemented by rendering the scene to a \nThe Rendering Engine\nDirect reﬂ ections in ﬂ at surfaces like mirrors can be produced \nby reﬂ ecting the camera’s position about the plane of the reﬂ ective surface and \nthen rendering the scene from that reﬂ ected point of view into a texture .\nWhen light enters a surface at one point, is scatt ered beneath the surface, \nbased subsurface scatt ering renders a shadow map (see Section 10.3.3.1), but \nThe shadowed side of the object is then given \nposite to the light source but only where the object is relatively thin.\nto simulate the eﬀ ects of radiosity-based rendering methods in real time.\ndent light ray would interact with a surface (reﬂ ect, refract, scatt er, etc.) when \nIn general the light’s response at a point on the surface is a complex func-\nThe Rendering Engine\nIn traditional triangle-rasterization–based rendering, all lighting and shad-\ning calculations are performed on the triangle fragments in view space.",
      "keywords": [
        "Rendering Engine",
        "Rendering",
        "shadow map",
        "scene",
        "light",
        "Shadow",
        "map",
        "surface",
        "objects",
        "GPU",
        "point",
        "BSP tree",
        "light source",
        "Global Illumination",
        "geometry"
      ],
      "concepts": [
        "light",
        "rendering",
        "render",
        "objects",
        "maps",
        "mapping",
        "map",
        "surfaces",
        "triangles",
        "regions"
      ],
      "similar_chapters": [
        {
          "book": "Game_Engine_Architecture",
          "chapter": 24,
          "title": "",
          "score": 0.732,
          "base_score": 0.582,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 26,
          "title": "",
          "score": 0.683,
          "base_score": 0.533,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 22,
          "title": "",
          "score": 0.647,
          "base_score": 0.497,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 23,
          "title": "",
          "score": 0.498,
          "base_score": 0.348,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 11,
          "title": "",
          "score": 0.498,
          "base_score": 0.348,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "shadow",
          "light",
          "rendering",
          "render",
          "map"
        ],
        "semantic": [],
        "merged": [
          "shadow",
          "light",
          "rendering",
          "render",
          "map"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.27384739537047914,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:57.759958+00:00"
      }
    },
    {
      "chapter_number": 26,
      "title": "Segment 26 (pages 503-525)",
      "start_page": 503,
      "end_page": 525,
      "summary": "dering visual elements like particle eﬀ ects, decals (small geometry overlays \nscreen post eﬀ ects may be applied, including vignett e (slight blur around the \nThe Rendering Engine\nfollowing sections, we’ll provide a brief overview of these rendering systems, \nThe key features that diﬀ erentiate a particle eﬀ ect from other kinds of render-\nparticle eﬀ ects have some stringent rendering order constraints that do \nz Particles animate in a rich variety of ways.\nParticle eﬀ ects could be rendered using regular triangle mesh geometry \nlisted above, a specialized particle eﬀ ect animation and rendering system is \nThese texture-mapped triangles are then rendered over the top of the regular \nThe Rendering Engine\nrequires some kind of environmental rendering eﬀ ects.\nrendering techniques.\nOne simple approach is to ﬁ ll the frame buﬀ er with the sky texture prior \nin the frame buﬀ er are set to the maximum z-value when the sky is rendered.\nFor more information on sky rendering, see [1] Section 10.3 and \nClouds are oft en implemented with a specialized rendering and anima-\ncloud techniques include camera-facing cards (billboards), particle-eﬀ ect \nThe Rendering Engine\nFor more information on terrain rendering, see \nWater renderers are commonplace in games nowadays.\nWater systems sometimes interact with a game’s rigid body dynamics \nWater eﬀ ects are oft en created by combining disparate render-\nof specialized water shaders, scrolling textures, particle eﬀ ects for mist at the \nmensional graphics rendered directly in view space or screen space .\nOverlays are generally rendered aft er the primary scene, with z testing \nTwo-dimensional overlays are typically implemented by rendering quads (tri-\nA game engine’s text /font system is typically implemented as a special kind of \nrendering system needs to be capable of displaying a sequence of character \nThe Rendering Engine\nprovide various fun features like the ability to animate characters across the \nscreen in various ways, the ability to animate individual characters, and so \ngine with an advanced text animation if your game never needs to display \nanimated text!\nGamma encoding can be performed by the 3D rendering engine to ensure \nrendering and then re-encoding the gamma of the ﬁ nal rendered scene so that \nFull-screen post eﬀ ects are eﬀ ects applied to a rendered three-dimensional \nA few examples of full-screen post eﬀ ects are given below:\nThis is typically implemented by rendering a buﬀ er of \nscreen-space velocity vectors and using this vector ﬁ eld to selectively \nThe Rendering Engine\ntimes implemented by literally rendering a texture overlay on top of the \ncreating three-dimensional computer graphics and animation for games and \nAnimation Systems\nhe majority of modern 3D games revolve around characters —oft en human \nchallenges, over and above what is required to simulate and animate rigid \nnent known as the character animation system.\nAs we’ll see, an animation system gives game designers a powerful suite \nobject that is not 100% rigid can take advantage of the animation system.\nengine’s animation system.\nTypes of Character Animation\nCharacter animation technology has come a long way since Donkey Kong.\nﬁ rst, games employed very simple techniques to provide the illusion of life-\nAnimation Systems\ntechniques used in modern game engines.\nCel Animation\nThe precursor to all game animation techniques is known as traditional anima-\nAn animated \nanimation.\nHence, a sprite is to 2D game animation what a cel \nRigid Hierarchical Animation\nTypes of Character Animation\nbitmaps (known as an animated texture ) to produce the illusion of motion.\nbrought with it the need for improved character animation methods.\nThe earliest approach to 3D character animation is a technique known as \nrigid hierarchical animation.\nat the joints.\nthe character’s body is oft en not very pleasing due to “cracking” at the joints.\nRigid hierarchical animation works well for \nCracking at the joints is a big problem in rigid hierarchical animation.\nAnimation Systems\nPer-Vertex Animation and Morph Targets\nRigid hierarchical animation tends to look unnatural because it is rigid.\nper-vertex animation.\nIn this approach, the vertices of the mesh are animated \nA variation on this technique known as morph target animation is used in \nan animator to create a relatively small set of ﬁ xed, extreme poses.\nAnimations \nThe morph target technique is oft en used for facial animation, because \nSkinned Animation\nAs the capabilities of game hardware improved further, an animation tech-\nanimation.\nSkinned animation was ﬁ rst used by games like Super Mario 64, and it \nin whole or in part, using skinned animation techniques.\nIn skinned animation, a skeleton is constructed from rigid “bones ,” just as \nin rigid hierarchical animation.\nskin is bound to the joints of the skeleton; its vertices track the movements of \nthe joints.\nEach vertex of the skin mesh can be weighted to multiple joints, so \nthe skin can stretch in a natural way as the joints move.\nTypes of Character Animation\nAnimation Systems\ninside him we can see the rigid bones and joints that make his skin move.\nAnimation Methods as Data Compression Techniques\nAnimating the vertices of a triangle mesh is a simpli-\nanimation is just another way to compress vertex animation data by imposing \njoints.\nWhen considering the trade-oﬀ s between various animation techniques, \nthe animation method that provides the best compression without producing \nrequired number of joints approaches the number of vertices in the mesh, thus \nfacial animation.\nA skeleton is comprised of a hierarchy of rigid pieces known as joints .\nare simply the empty spaces between the joints.\npelvis joint in the Crank the Weasel character model.\nIt is a single joint, but be-\nbones—only the joints matt er.\nabout joints.\nAs we’ve mentioned, the joints in a skeleton form a hierarchy or tree structure.\nA typical joint hierarchy for skinned animation looks almost \njoint hierarchy might look something like this:\nThe pelvis joint of this character connects to four other joints (tail, spine, and two \nAnimation Systems\nvarious face joints\nBecause each joint \njoint has no parent, so its parent index usually contains an invalid index such \ncontains an array of data structures for the individual joints.\nThe joints are \nusually listed in an order that ensures a child joint will always appear aft er \nJoint indices  are usually used to refer to joints within animation data struc-\nFor example, a child joint typically refers to its parent joint by specifying \nLikewise, in a skinned triangle mesh, a vertex refers to the joint or \njoints to which it is bound by index.\nEach joint data structure typically contains the following information:\nindex of the joint’s parent within the skeleton.\ninverse bind pose transform of the joint.\nThe bind pose of a joint is the \nposition, orientation, and scale of that joint at the time it was bound to \nstruct Joint\nm_jointCount;  // number of joints\nPoses\nNo matt er what technique is used to produce an animation, be it cel-based, \nrigid hierarchical, or skinned/skeletal, every animation takes place over time.\nthan displaying a single pose verbatim.) In skeletal animation, the pose of the \nskeleton directly controls the vertices of the mesh, and posing is the anima-\ncan animate a skeleton, we must ﬁ rst understand how to pose it.\nA skeleton is posed by rotating, translating, and possibly scaling its joints \nThe pose of a joint is deﬁ ned as the joint’s position, orien-\nA joint pose is usually \nPoses\nAnimation Systems\nThe pose of a skeleton is just the \nset of all of its joints’ poses and is normally represented as a simple array of \nThe pose \nbinding the vertices to the joints easier.\nA joint’s pose is most oft en speciﬁ ed relative to its parent joint.\ntive pose allows a joint to move naturally.\nder joint, but leave the parent-relative poses of the elbow, wrist and ﬁ ngers \nWe sometimes use the term local pose to describe a parent-relative \npose.\nGraphically, many 3D authoring packages like Maya represent joints as \nHowever, a joint has a rotation and a scale, not just a trans-\nto picture a joint as a set of Cartesian coordinate axes.\nthe option of displaying a joint’s local coordinate axes —this is shown in Fig-\nMathematically, a joint pose is nothing more than an aﬃ  ne transformation.\nThe pose of joint j can be writt en as the 4 × 4 aﬃ  ne transformation matrix Pj , \nEvery joint in a skeletal hierarchy deﬁ nes a set of local coordinate space axes, \nknown as joint space.\nPoses\nAnimation Systems\nJoint Scale\nSome game engines assume that joints will never be scaled, in which case Sj\nor animation.\n(Uniform scale requires a single ﬂ oating-point scalar per joint per \nanimation frame, while nonuniform scale requires three ﬂ oats, and a full 3 × 3 \nin engines that perform such tests on a per-joint basis.\nRepresenting a Joint Pose in Memory\nAs we mentioned above, joint poses are usually stored in SQT format.\nIf nonuniform scale is permitt ed, we might deﬁ ne a joint pose like this \nThe local pose of an entire skeleton can be represented as follows, where \nm_pSkeleton;  // skeleton + num joints\n// local joint poses\nThe Joint Pose as a Change of Basis\nIt’s important to remember that a local joint pose is speciﬁ ed relative to the \njoint’s immediate parent.\nthe joint pose transform Pj is applied to a point or vector that is expressed in \nthe coordinate system of the joint j, the result is that same point or vector ex-\npressed in the space of the parent joint.\nSince a joint pose takes \npoints and vectors from the child joint’s space (C) to that of its parent joint (P), \nreturns the parent index of joint j, and write the local pose of joint j as \ndirection—from parent space into the space of the child joint.\nis just the inverse of the local joint pose.\nSometimes it is convenient to express a joint’s pose in model space or world \nMathematically, the model-space pose of a joint (j→M) can be found by \nwalking the skeletal hierarchy from the joint in question all the way to the \nThe parent space of the root joint is deﬁ ned to be model \n. The model-space pose of joint J2 can therefore be writt en \nLikewise, the model-space pose of joint J5 is just \nPoses",
      "keywords": [
        "joint",
        "animation",
        "joint pose",
        "pose",
        "rendering",
        "Animation Systems",
        "character animation",
        "game",
        "Rigid Hierarchical Animation",
        "system",
        "Rendering Engine",
        "character",
        "local joint pose",
        "screen",
        "character animation system"
      ],
      "concepts": [
        "animation",
        "animated",
        "animal",
        "animates",
        "animator",
        "animations",
        "joints",
        "rendering",
        "render",
        "games"
      ],
      "similar_chapters": [
        {
          "book": "Game_Engine_Architecture",
          "chapter": 24,
          "title": "",
          "score": 0.686,
          "base_score": 0.536,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 25,
          "title": "",
          "score": 0.683,
          "base_score": 0.533,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 22,
          "title": "",
          "score": 0.68,
          "base_score": 0.53,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 23,
          "title": "",
          "score": 0.534,
          "base_score": 0.384,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 30,
          "title": "",
          "score": 0.496,
          "base_score": 0.346,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "joint",
          "animation",
          "pose",
          "joints",
          "joint pose"
        ],
        "semantic": [],
        "merged": [
          "joint",
          "animation",
          "pose",
          "joints",
          "joint pose"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.22244285213720993,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:57.759993+00:00"
      }
    },
    {
      "chapter_number": 27,
      "title": "Segment 27 (pages 526-548)",
      "start_page": 526,
      "end_page": 548,
      "summary": "In general, the global pose (joint-to-model transform) of any joint j can be \nbased on the number of joints in the skeleton:\nm_pSkeleton;     // skeleton + num joints\n// local joint poses\nm_aGlobalPose; // global joint poses\nscene can be animated as one long, contiguous sequence of frames.\nA global pose can be calculated by walking the hierarchy from the joint in \ntransforms of each joint as we go.\nGame animation is diﬀ erent.\nAs such, game animations are almost never created as long, \nindividual motions animation clips , or sometimes just animations.\nreal time by the game engine itself.\nThe Local Time Line\nWe can think of every animation clip as having a local time line , usually de-\nPose Interpolation and Continuous Time\nanimator.\nIn both ﬁ lm and game animation, the animator almost never poses \nimportant poses known as key poses or key frames at speciﬁ c times within the \nclip, and the computer calculates the poses in between via linear or curve-\nBecause of the animation engine’s ability to interpolate poses (which we’ll \ncharacter at any time during the clip—not just on integer frame indices.\nother words, an animation clip’s time line is continuous.\nthe animation time-line, because its frame rate is locked at exactly 24, 30, or \nIn ﬁ lm, the viewer sees the characters’ poses at frames \nAnimation A: Local Time\nThe local time line of an animation showing poses at selected time indices.\nposes\nAn animator creates a relatively small number of key poses, and the engine ﬁ lls \n1, 2, 3, and so on—there’s never any need to ﬁ nd a character’s pose on frame \nIn contrast, a real-time game’s frame rate always varies a litt le, depending \nanimations are sometimes time-scaled in order to make the character appear to \nmation clip is almost never sampled on integer frame numbers.\na time scale of 1.0, a clip should be sampled at frames 1, 2, 3, and so on.\nthe time scale is 0.5, then the player might actually see frames 1.1, 1.4, 1.9, 2.6, \nA negative time scale can even be used to play an animation in \nSo in game animation, time is both continuous and scalable.\nBecause an animation’s time line is continuous, time is best measured in units \nof a second for game animation.\nfor doing things like “tweening” between frames or scaling an animation’s \nother contexts, the term frame is applied to a single point in time (e.g., we might \nspeak of the pose of the character “at frame 42”).\nI personally prefer to use the term sample to refer to a single point in time, \nSo for example, a one-second animation created at a rate \nspaced time intervals.\nFrames, Samples and Looping Clips\nlooped animation .\ntime with sample 1 of the second clip, as shown in Figure 11.12.\nloop properly, then, we can see that the pose of the character at the end of the \nclip must exactly match the pose at the beginning.\nMany game engines therefore omit the last sample of a looping clip.\nframes in any animation clip:\nnon-looping, an N-frame animation will have N + 1 unique \nA one-second animation sampled at 30 frames per second is 30 frames in duration \nThe last sample of a looping clip coincides in time with its ﬁ rst sample and is, \nWe sometimes refer to normalized time as the phase of the animation \nclip, because u acts like the phase of a sine wave when the animation is looped.\nNormalized time is useful when synchronizing two or more animation \nto ensure that the two animations remain synchronized at all times, so that the \nthe normalized start time of the walk clip, uwalk to match the normalized time \nThe Global Time Line\nJust as every animation clip has a local time line (whose clock starts at 0 at \nthe beginning of the clip), every character in a game has a global time line \n(whose clock starts when the character is ﬁ rst spawned into the game world, \nthe time variable τ to measure global time, so as not to confuse it with the local \nWe can think of playing an animation as simply mapping that clip’s local \ntime line onto the character’s global time line.\ntrates playing animation clip A starting at a global time of τstart = 102 seconds.\nA: Normalized Local Time\nAn animation clip, showing normalized time units.\nPlaying animation clip A starting at a global time of 102 seconds.\nAs we saw above, playing a looping animation is like laying down an \ninﬁ nite number of back-to-front copies of the clip onto the global time line.\nWe can also imagine looping an animation a ﬁ nite number of times, which \nTime-scaling a clip makes it appear to play back more quickly or more \nage of the clip when it is laid down onto the global time line.\nif an animation is to play back at twice the speed (R = 2), then we would scale \nthe clip’s local time line to one-half (1/R = 0.5) of its normal length when map-\nPlaying a clip in reverse corresponds to using a time scale of –1, as shown \nPlaying a looping animation corresponds to laying down multiple back-to-back \nPlaying an animation at twice the speed corresponds to scaling its local time line \nPlaying a clip in reverse corresponds to a time scale of –1.\nIn order to map an animation clip onto a global time line, we need the fol-\nits global start time\nrange [0, T] before using it to sample a pose from the clip:\nIf the clip loops a ﬁ nite number of times (1 < N < ∞), we must ﬁ rst clamp t \nMost game engines work directly with local animation time lines and don’t \nuse the global time line directly.\nThe animation system must keep track of the time indices of every animation \nframes, or in normalized time units (in which case it is oft en called the \nphase of the animation).\nTo advance the animations for-\nward in time, we advance the local clocks of each clip individually.\nsured in seconds, and each clip simply records the global time at which it \nchronizing animations, either within the context of a single character or across \nSynchronizing Animations with a Local Clock\nWith a local clock approach, we said that the origin of a clip’s local time line \nanimation with a non-player character’s corresponding hit reaction anima-\nSynchronizing Animations with a Global Clock\nproblems, because the origin of the time line (τ = 0) is common across all clips \nIf two or more animations’ global start times are numerically \nTypically, animation data is extracted from a Maya scene ﬁ le by sampling the \npose of the skeleton discretely at a rate of 30 or 60 samples per second.\nple comprises a full pose for each joint in the skeleton.\nWe sometimes say that an animation consists of up to 10 channels per joint, \nA global clock approach can alleviate animation synchronization problems.\nJoint 0\nJoint 1\nAn uncompressed animation clip contains 10 channels of ﬂ oating-point data \nper sample, per joint.\nIn C++, an animation clip can be represented in many diﬀ erent ways.\n// poses\nAn animation clip is authored for a speciﬁ c skeleton and generally won’t \nHowever, if the animation loops, \nIt’s important to realize that in a real game engine, animation data isn’t \nfor joints that cannot be found in the skeleton being animated.\nThe samples of an animation clip are really just deﬁ nitions of continuous func-\nous across the entire clip’s local time line, as shown in Figure 11.21 (with the \nThe animation samples in a clip deﬁ ne continuous functions over time.\nanimation.\nat various time indices, as shown in Figure 11.23.\nWhenever the animation’s \nlocal time index passes one of these triggers, an event is sent to the game en-\nlocators , to be animated along with the joints of the skeleton itself.\nA typical application of animated locators is to specify how the game’s \nthe joints of the character(s) in the scene.\nused in-game to move the game’s camera around during the animation.\nJoint 0\nJoint 1\nA special event trigger channel can be added to an animation clip in order to \nsynchronize sound effects, particle effects, and other game events with an animation.\nOther examples of non-joint animation channels include:\ntexture animation\n) joint pose transformations, \none for each joint j.\nfor each joint, a \nUsually a game engine imposes an upper limit on the number of joints \nbetween a two-, three-, and even a four-joint-per-vertex model, most people \nSo the matrix we seek will transform vertices from model space (bind pose) \nto model space (current pose ).\nSimple Example: One-Jointed Skeleton\nﬁ rst, we’ll work with a skeleton consisting of a single joint.\nthe subscript M, and the joint space of our one and only joint, which will be \nThe joint’s coordinate axes start out in bind pose, \nanimation, the joint’s axes move to a new position and orientation in model \nNow consider a single vertex that is skinned to our joint.\nnew model-space position in the current pose, \nThe “trick” to ﬁ nding the skinning matrix for a given joint is to realize \njoint’s coordinate space.\nSo we take the bind-pose position of the vertex in model \nspace, convert it into joint space, move the joint into its current pose, and ﬁ -\nfrom model space to joint space and back again is to “morph” the vertex from \npose).\nWe convert this vertex into its equivalent joint space coordinates \njoint may move.\nOnce we have the joint in the desired current pose, we con-\nspace, due entirely to the motion of the joint from its bind pose to the current \njoint j in model space by the matrix \nJoint Space \nPose Joint \nBind pose and current pose of a simple, one-joint skeleton and a single vertex \nvector whose coordinates are expressed in joint j’s space into an equivalent set \nare expressed in model space with the skeleton in bind pose.\nvertex coordinates into the space of joint j, we simply multiply it by the inverse \nbind pose matrix, \nLikewise, we can denote the joint’s current pose (i.e., any pose that is not \nbind pose) by the matrix \nv  from joint space back into mod-\nel space, we simply multiply it by the current pose matrix as follows:\nvertex directly from its position in bind pose to its position in the current \npose:\nwe formulated everything in terms of global poses (i.e., joint space to model \njoint space\n2. Move joint into\nBy transforming a vertex’s position into joint space, it can be made to “track” \nrenderer looks up the appropriate joint’s skinning matrix in the palett e \nand uses it to transform the vertex from bind pose into current pose.\nframe as the character assumes diﬀ erent poses over time.\nverse bind-pose matrix is constant throughout the entire game, because the \nbind pose of the skeleton is ﬁ xed when the model is created.\nAnimation engines generally calculate local poses for each \njoint (\n), then use Equation (11.1) to convert these into global poses \n), and ﬁ nally multiply each global pose by the corresponding cached \nSkinning a Vertex to Multiple Joints\nWhen a vertex is skinned to more than one joint, we calculate its ﬁ nal position \nby assuming it is skinned to each joint individually, calculating a model space \nK  is the skinning matrix for the joint \nAnimation Blending\nmation clip to contribute the ﬁ nal pose of the character.\nBlending usually combines two or more poses at a single point in time, \nexample, we can blend between an animation in which the character is aim-\nBlending can also be used to ﬁ nd an intermediate pose between two \nknown poses at diﬀ erent points in time.\npose of a character at a point in time that does not correspond exactly to one of \nAnimation Blending\nthe sampled frames available in the animation data.\ndone by performing a linear interpolation (LERP) between the local poses of \neach individual joint in each of the two source poses.\nThe interpolated pose of the whole skeleton is simply the set of interpolated \nposes for all of the joints:\nβ = 0, the ﬁ nal pose of the skeleton will exactly match \njoint poses , which means interpolating 4×4 transformation matrices.\nlooking intermediate pose is generally one in which each joint pose is inter-\nwe were to blend global poses directly in model space, the results would tend \nBecause pose blending is done on local poses, the linear interpolation of \nany one joint’s pose is totally independent of the interpolations of the other \njoints in the skeleton.\nAs we mentioned in Section 11.4.1.1, game animations are almost never sam-\nthe clip’s local time line.\nanimation clip.\nLERP blending is used to ﬁ nd these intermediate poses.\nlet’s imagine that our animation clip contains evenly-spaced pose samples at \nAnimation Blending\nTo ﬁ nd a pose at time t = (2.18)Δt, we simply \nﬁ nd the linear interpolation between the poses at times 2Δt and 3Δt, using a \nIn general, we can ﬁ nd the pose at time t given pose samples at any two \nGame characters are animated by piecing together a large number of ﬁ ne-\ngrained animation clips.\nIf your animators are any good, the character will ap-\nwe see in game animations occur when the character transitions from one clip \nism of an animated character’s movement improves as we move to higher and ",
      "keywords": [
        "Animation",
        "time",
        "animation clip",
        "pose",
        "joint",
        "Local Time Line",
        "clip",
        "Global Time Line",
        "Time Line",
        "Local Time",
        "Global Time",
        "Animation Systems",
        "bind pose",
        "joint space",
        "current pose"
      ],
      "concepts": [
        "animation",
        "animated",
        "animations",
        "animator",
        "pose",
        "posing",
        "posed",
        "time",
        "joint",
        "clips"
      ],
      "similar_chapters": [
        {
          "book": "Game_Engine_Architecture",
          "chapter": 29,
          "title": "",
          "score": 0.718,
          "base_score": 0.568,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 30,
          "title": "",
          "score": 0.688,
          "base_score": 0.538,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 31,
          "title": "",
          "score": 0.639,
          "base_score": 0.489,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 28,
          "title": "",
          "score": 0.537,
          "base_score": 0.387,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 10,
          "title": "",
          "score": 0.535,
          "base_score": 0.385,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "joint",
          "pose",
          "clip",
          "animation",
          "time"
        ],
        "semantic": [],
        "merged": [
          "joint",
          "pose",
          "clip",
          "animation",
          "time"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.3070035514746675,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:57.760031+00:00"
      }
    },
    {
      "chapter_number": 28,
      "title": "Segment 28 (pages 549-568)",
      "start_page": 549,
      "end_page": 568,
      "summary": "However, LERP-based animation blending can be applied to achieve \nbetween clips in this manner, LERP blending is sometimes called cross-fading .\ntwo clips by some reasonable amount, and then blend the two clips together.\nThe blend percentage β starts at zero at time tstart  , meaning that we see only \nAt this point only clip B will be visible, and we can \n(Δtblend = tend – tstart) is sometimes called the blend time .\ntions in the other clip.\nThus the pose of the skeleton from clip A is frozen \nwhile clip B gradually takes over the movement.\ntional blend works well when the two clips are unrelated and cannot be \nClip A\nClip B\nAnimation Blending\nIn Figure 11.27 and Figure 11.28, the blend factor varied linearly with time.\nplied to a currently-running clip that is being blended out, it is known as an \nease-out curve; when it is applied to a new clip that is being blended in, it is \nthe value of β at any time t within the blend interval.\nat the start of the blend interval, tstart , and βend is the ﬁ nal blend factor at time \nClip A\nClip B\nClip A\nClip B\nbe achieved without blending if the animator ensures that the last pose in any \ngiven clip matches the ﬁ rst pose of the clip that follows it.\nning of every clip and returns to a core pose at the end, C0 continuity can be \nachieved by simply ensuring that the core poses match when animations are \nby ensuring that the character’s movement at the end of one clip smoothly \nclips.\nLERP-based animation blending is oft en applied to character locomotion.\nAnimation Blending\nI’ll call these directional locomotion clips.\nthe semicircle, select the two adjacent movement animations, and blend them \ntogether via LERP-based blending.\nso that the blend into the pure forward run animation looks correct.\nWhen we try to blend such strafe animations directly into a backward \nTargeted movement can be implemented by blending together looping locomo-\nWe can then LERP-blend between \nComplex LERP Blends\nIn a real game engine, characters make use of a wide range of complex blends \nGeneralized One-Dimensional LERP Blending\nLERP blending can be easily extended to more than two animation clips, us-\ning a technique I call one-dimensional LERP blending.\nselect the two clips immediately adjacent to it and blend them together using \nIf the two adjacent clips lie at points b1 and b2 , then the blend \nAnimation Blending\nTargeted movement is just a special case of one-dimensional LERP blend-\nclips were placed and use the movement direction angle θ as the param-\nAny number of animation clips \nSimple Two-Dimensional LERP Blending\nWe can extend one-dimensional LERP blending to two dimensions in order to \nClip A\nClip B\nA generalized linear blend between N animation clips.\nThe directional clips used in targeted movement can be thought of as a special \ncase of one-dimensional LERP blending.\nIf we know that our 2D blend involves only four animation clips, and if \nﬁ nd a blended pose by performing two 1D blends.\nsquare region bounded by our four clips, we can ﬁ nd the resulting pose by \nbetween the top two animation clips and one between the bott om two \nclips.\nmensional LERP blends.\nblending the two intermediate poses together.\nTriangular Two-Dimensional LERP Blending\nthe animation clips we wish to blend lie at the corners of a square region.\ncan we blend between an arbitrary number of clips positioned at arbitrary \nLet’s imagine that we have three animation clips that we wish to blend to-\nEach clip, designated by the index i, corresponds to a particular blend \nclip i deﬁ nes a set of joint poses {\nClip A\nClip B\nClip D\nBlend \nBlend \nBlend\nA simple formulation for 2D animation blending between four clips at the \nAnimation Blending\nBut how can we calculate a LERP blend between three animation clips?\nGiven the two-dimensional blend vector b, we ﬁ nd the blend weights α, \ntriangle formed by the three clips in two-dimensional blend space (htt p://\nplugging these blend weights into Equation (11.13) gives us poses \nClip A\nClip B\nBlend\nTwo-dimensional animation blending between three animation clips.\nGeneralized Two-Dimensional LERP Blending\nof animation clips positioned at arbitrary locations within the two-dimension-\nthe various animation clips bi .\nthree-clip LERP blend as described above.\nClip A\nClip B\nClip D\nClip I\nClip J\nDelaunay triangulation between an arbitrary number of animation clips \nAnimation Blending\nPartial-Skeleton Blending\ngame is via a technique known as partial-skeleton blending .\nblending, the same blend percentage β was used for every joint in the skeleton.\n“mask out” certain joints by sett ing their blend percentages to zero.\nWhen Walk, Run, or Stand is LERP-blended with Wave using this blend mask, \nPartial blending is useful, but it has a tendency to make a character’s \nAn abrupt change in the per-joint blend factors can cause the movements \nIn our example, the blend factors change abruptly at the right shoulder \ndriven by one animation, while the right shoulder and arm joints are \nYet with partial blending, the right arm’s animation will \nas additive blending.\nAdditive Blending \nAdditive blending approaches the problem of combining animations in a to-\nIt introduces a new kind of animation called a diﬀ erence clip, \nA diﬀ erence clip can be added onto a regular animation clip in \nIn essence, a diﬀ erence clip encodes the changes that need to be made to \nDiﬀ erence clips are oft en \ncalled additive animation clips in the game industry.\nConceptually, the diﬀ erence clip is D = S – R.\nIf a diﬀ erence clip D is added to \nage of D to R, in much the same way that LERP blending ﬁ nds intermediate \nblending technique is that once a diﬀ erence clip has been created, it can be \nthese animations target clips and denote them with the symbol T.\nAs an example, if the reference clip has the character running normally \nand the source clip has him running in a tired manner, then the diﬀ erence clip \nIf this diﬀ erence clip is now applied to a clip of the character walk-\ning, the resulting animation can make the character look tired while walking.\nated by adding a single diﬀ erence clip onto various “regular” animation clips, \nor a collection of diﬀ erence clips can be created, each of which produces a \ndiﬀ erent eﬀ ect when added to a single target animation.\nAnimation Blending\nskeleton, we can deﬁ ne the diﬀ erence pose Dj at that joint as follows (for this \nIn other words, adding the diﬀ erence animation D back onto the original ref-\nto our diﬀ erence clips as if they were ordinary animations.\nNote that a diﬀ erence animation can only be found when the input clips \nAdditive Blend Percentage\nIn games, we oft en wish to blend in only a percentage of a diﬀ erence anima-\ndiﬀ erence clip causes the character to turn his head 80 degrees to the right, \nblending in 50% of the diﬀ erence clip should make him turn his head only \nthat would result from a full application of the diﬀ erence  animation.\nwe can take the diﬀ erence between a standing clip and a clip of standing while \nblend to make the right arm wave.\nthe “disconnected” look of animations combined via partial blending.\nis because, with an additive blend, we are not replacing the animation for \nIn eﬀ ect, a diﬀ erence animation “knows” how to change a \nskeleton, especially when multiple diﬀ erence clips are applied simultaneous-\nAs a simple example, imagine a target animation in which the character’s \nIf we add a diﬀ erence animation that also \nAnimation Blending\nreference clip to minimize over-rotation of the arms when the diﬀ erence \nclip is added to other targets.\nAnimators should create a new diﬀ erence animation for each core pose \nreally learn how to create and apply diﬀ erence clips is by trial and error or by \napplying diﬀ erence animations.\nFor each desired stance, the animator creates a one-frame diﬀ erence anima-\nWhen one of these single-frame clips is additively blended with a base \nanimation, it causes the entire stance of the character to change drastically \nTarget Clip\nTwo single-frame difference animations A and B can cause a target animation \nTarget Clip\nAdditive blends can be used to add variation to a repetitive idle animation.\nAdditive blending can be \nAnother common use for additive blending is to permit the character to look \nframe diﬀ erence animation.\nThese four diﬀ erence animations can then be additively \nblended onto the original straight ahead animation clip, causing the character \nThe angle of the aim is governed by the additive blend factor of each clip.\nFor example, blending in 100 percent of the right additive causes the character \nAnimation Blending\nBlending 50 percent of the left  additive causes \nIt’s interesting to note that the time axis of an animation clip needn’t be used \nFor example, a three-frame animation clip could be used to \naim to the right, we can simply ﬁ x the local clock of the aim animation on \nTo perform a 50% blend between aiming forward and aiming right, \nOnce a skeleton as been posed by one or more animation clips and the results \nTarget Clip\nAdditive blending can be used to aim a weapon.\nhand-animated clips are used to pose the skeleton initially, and then the pose \na hand-animated clip.\nFor example, imagine that a regular animation clip is used to make a ve-\nthe pose generated by the animation.\nplace of or in addition to hand-animated clips, to cause the joints to move in a \nLet’s say we have an animation clip in which a character leans over to pick up \nA regular animation clip is an example of forward kinematics (FK).\nclip would occupy 117 kB per joint per second.\nOne simple way to reduce the size of an animation clip is to omit channels \nChannel omission can signiﬁ cantly reduce the size of an animation clip.\nan animation clip.",
      "keywords": [
        "diﬀ erence clip",
        "clip",
        "animation clips",
        "animation",
        "LERP blending",
        "blend",
        "animation blending",
        "diﬀ erence",
        "diﬀ erence animation",
        "erence clip",
        "additive blending",
        "pose",
        "LERP",
        "Animation Systems",
        "Two-Dimensional LERP Blending"
      ],
      "concepts": [
        "animations",
        "animator",
        "animating",
        "blend",
        "clips",
        "pose",
        "posed",
        "joint",
        "targeted",
        "look"
      ],
      "similar_chapters": [
        {
          "book": "Game_Engine_Architecture",
          "chapter": 30,
          "title": "",
          "score": 0.661,
          "base_score": 0.511,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 29,
          "title": "",
          "score": 0.588,
          "base_score": 0.438,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 27,
          "title": "",
          "score": 0.537,
          "base_score": 0.387,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 24,
          "title": "",
          "score": 0.526,
          "base_score": 0.376,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 26,
          "title": "",
          "score": 0.468,
          "base_score": 0.318,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "clip",
          "blending",
          "blend",
          "clips",
          "erence"
        ],
        "semantic": [],
        "merged": [
          "clip",
          "blending",
          "blend",
          "clips",
          "erence"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.19587262626190463,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:57.760065+00:00"
      }
    },
    {
      "chapter_number": 29,
      "title": "Segment 29 (pages 569-589)",
      "start_page": 569,
      "end_page": 589,
      "summary": "is the process of converting the original ﬂ oating-point value to a quantized \nTo encode a ﬂ oating-point value as an integer, we ﬁ rst divide the valid \nmine within which interval a particular ﬂ oating-point value lies and represent \nFor example, if we’re encoding a 32-bit ﬂ oating-point value as a 16-bit integer, \nAnimation Systems\nLet’s return to our original problem of animation channel compression.\nis animated in world space, the translations of the characters’ root joints can \nAnimation Systems\nfrom animation to animation, or from joint to joint, we must store the range \nwith the compressed clip data.\nThis will add data to each animation, so it may \nAnimation data tends to be large for three reasons: ﬁ rst, because the pose of \nSome animations look ﬁ ne when exported \nat 15 samples per second, and doing so cuts the animation data size in \nanimations not as a regularly spaced sequence of pose samples but as a collec-\nGranny exports an animation by sampling the joint poses at regular in-\ntervals, much like traditional animation data.\nThe end result is an animation clip that is usually signiﬁ cantly smaller \nOne form of animation compression ﬁ ts B-splines to the animation channel \nThe cheapest animation clip is the one that isn’t in memory at all.\ndon’t need every animation clip to be in memory simultaneously.\nSome clips \nMost games load a core set of animation clips into memory when the game \nthe player character’s core move set and animations that apply to objects that \nAnimation Systems\nengines load animation clips individually, but many package them together \nAnimation System Architecture\ntween the animation system and the other systems in a typical game engine.\nAnimation pipeline.\nFor each animating character and object in the game, \nthe animation pipeline takes one or more animation clips and corre-\nlocal pose to be modiﬁ ed prior to ﬁ nal global pose and matrix palett e \nother forms of procedural animation are applied to the skeleton.\ndriven animation interface for use by virtually all higher-level game \nIn addition, most animation engines permit diﬀ erent parts of the \nAnimation controllers.\ntem of animation controllers.\nHowever, all animation engines need to perform these tasks in one form or an-\nIn the following sections, we’ll explore animation architecture in terms \nThe Animation Pipeline\nThe operations performed by the low-level animation engine form a pipeline \nthat transforms its inputs (animation clips and blend speciﬁ cations) into the \ndesired outputs (local and global poses, plus a matrix palett e for rendering).\n1. Clip decompression and pose extraction .\nThe output of this phase is a local skeletal pose for each input \nclip.\nThis pose might contain information for every joint in the skeleton \na diﬀ erence pose for use in additive blending.\n2. Pose blending .\nThe output of this stage is a single local pose for all joints in the \none animation clip together—otherwise the output pose from stage 1 \nal pose information as input but generate local poses as output.\nThe Animation Pipeline\nAnimation Systems\nA typical animation pipeline is depicted in Figure 11.44.\nEvery animation pipeline is architected diﬀ erently, but most operate in terms \nBlend\nPose \nBlending\nPose\nClip(s)\nPose\nA typical animation pipeline.\nAnimation clips\n. Many hundreds or even thousands of animation clips \ntial-skeleton clips, or diﬀ erence clips for use in additive blending.\nwill be one skeleton, one or more meshes, and one or more animation clips.\nskeleton but don’t have any relationship with the animation clips.\na whole new set of animation clips.\nThe Animation Pipeline\nAnimation Systems\nset of animations.\nmation clip(s), a speciﬁ cation of how the clips are to be blended together (if \nmation clips are currently playing and how these clips are to be blended \nThe degree to which each clip contributes to the ﬁ nal pose is \nClip 1\nClip 2\nClip 3\nMany animation clips and one or more meshes target a single skeleton.\ncontrolled by one or more blend weights.\nods of describing the set of clips that should be blended together: a ﬂ at \nweighted average approach and a tree of blend nodes.\nshared resource, while the blend weights are stored as part of the per-\npose are speciﬁ ed via a set of joint weights .\nIn some animation engines, \njoint, that holds the ﬁ nal pose of the skeleton in model-space or world-\nThe Flat Weighted Average Blend Representation\nAll but the most rudimentary game engines support animation blending in \nThis means that at any given time, multiple animation clips may \nbe contributing to the ﬁ nal pose of a character’s skeleton.\ndescribe how the currently active clips should be blended together is via a \nIn this approach, every animation clip is associated with a blend weight \nA ﬂ at list of all active animation clips (i.e., clips whose blend weights \nTo calculate the ﬁ nal pose of the skeleton, we \nextract a pose at the appropriate time index for each of the N active clips.\nThen, for each joint of the skeleton, we calculate a simple N-point weighted \nextracted from the N active animations.\nThe Animation Pipeline\nAnimation Systems\nThe Ogre3D animation system works in exactly this way.\nOgre::AnimationState objects, one for each active animation.\n/** Represents the state of an animation clip and the  \n// clip\nReal               mWeight;        // blend weight\nbool               mEnabled;       // is this anim   \nanim loop?\n/// Gets the name of the animation.\n/// anim.\n/// anim.\n/// Gets the weight (influence) of this animation\n/// Sets the weight (influence) of this animation\n/// animation duration.\n/// Sets whether or not this animation is enabled.\n/// Sets whether or not this animation should loop.\nEach AnimationState keeps track of one animation clip’s local clock and \nits blend weight.\nThe Animation Pipeline\nAnimation Systems\nfrom the animation clip corresponding to each state at the time index speciﬁ ed \nFor each joint in the skeleton, an N-point weighted \ntion, but unfortunately, Ogre does not support animation time scaling out of \nThe Granny animation system, by Rad Game Tools (htt p://www.radgame-\ntools.com/granny.html), provides a ﬂ at, weighted average animation blend-\nGranny permits any number of animations to be \nThe state of each active animation \nculates a weighted average to determine the ﬁ nal pose, automatically normal-\nidentical to that of Ogre’s animation system.\nBlend Trees\nFor reasons we’ll explore below, some animation engines represent their blend \nspeciﬁ cations not as a ﬂ at weighted average but as a tree of blend operations.\nAn animation blend tree is an example of what is known in compiler theory \nthe various kinds of animation blends we learned about in Sections 11.6.3 and \nClip A\nClip B\nA binary LERP blend, represented by a binary expression tree.\ntwo input poses and blends them together into a single output pose.\nA blend \nweight β controls the percentage of the second input pose that should appear \nat the output, while (1 – β) speciﬁ es the percentage of the ﬁ rst input pose.\none-dimensional LERP blend by placing an arbitrary number of clips along a \na blend can be pictured as an n-input operator, as shown in Figure 11.48.\nGiven a speciﬁ c value for b, such a linear blend can always be transformed \nto b as the inputs to the binary blend and calculate the blend weight β as speci-\nClip A\nClip B\nClip B\nA multi-input expression tree can be used to represent a generalized 1D blend.\nThe Animation Pipeline\nAnimation Systems\ntwo-dimensional blend point b = [ bx  by ], Figure 11.49 shows how this kind of \nblend can be represented in tree form.\nkind of blend in tree form, we need a ternary (three-input) expression tree \nClip A\nClip B\nA triangular 2D LERP blend, represented as a ternary expression tree.\noutput pose is speciﬁ ed by a point b = [ bx  by ] on the plane.\nblend can be represented as a tree node with an arbitrary number of inputs, \nof a ternary blend node with the three clips at the vertices of the triangle as its \nweight β controls the amount of the additive animation that should appear \npose may only be applied to a regular pose, and the result of an additive blend \nThis implies that the additive input of a blend node \nIf we want to apply more than one additive animation to our character, \nClip A\nClip B\nA generalized 2D blend can be represented by a multi-input expression tree node, \nClip A\nAn additive blend represented as a binary tree.\nThe Animation Pipeline\nAnimation Systems\nwe must use a cascaded binary tree with the additive clips always applied to \nAs we saw in Section 11.6.2.2, cross-fading between animations is generally \naccomplished by LERP blending from the previous animation to the next one.\nyour animation engine uses the ﬂ at weighted average architecture or the ex-\nIn an animation engine that employs the ﬂ at weighted average architecture, \ncross-fades are implemented by adjusting the weights of the clips themselves.\nRecall that any clip whose weight wi = 0 will not contribute to the current pose \nclip B, we simply ramp up clip B’s weight, wB , while simultaneously ramping \ndown clip A’s weight, wA.\nClip A\nIn order to additively blend more than one difference pose onto a regular “base” \nA simple cross-fade from clip A to clip B, as implemented in a weighted average \nanimation architecture.\nthis requirement by simply sett ing the weights of both clip groups to their de-\nλ = 0, the output pose is the correct blend of clips A, B, and C, \nλ = 1, the output pose is the correct blend of clips D and E, with \nditional meta-data to be maintained, on top of the ﬂ at array of clip states.\nImplementing a cross-fade in an expression-tree -based animation engine is a \nThe Animation Pipeline\nAnimation Systems\ntransitioning from one clip to another or from one complex blend to another, \nnode at the root of the blend tree for the duration of the cross-fade.\nIts top input is the source tree (which can be a single clip or a complex \nblend), and its bott om input is the destination tree (again a clip or a complex \nblend).\nAnimation Pipeline Optimization\nAnimation pipeline optimizations are usually highly speciﬁ c to the archi-\nA cross-fade between two arbitrary blend trees A and B.\nsult, some animation pipeline APIs are highly speciﬁ c to a particular platform.\nSome animation pipelines \nThe blend is \ngame queues up requests for animation blends in a big list and then kicks \nThis architecture leads to animation pipeline APIs that look similar in \nThe Animation Pipeline",
      "keywords": [
        "Animation",
        "pose",
        "Animation pipeline",
        "LERP blend",
        "animation clips",
        "clip",
        "blend",
        "output pose",
        "Animation Systems",
        "LERP",
        "global pose",
        "binary LERP blend",
        "tree",
        "Triangular LERP Blend",
        "nal pose"
      ],
      "concepts": [
        "animation",
        "animated",
        "animations",
        "pose",
        "blend",
        "clip",
        "data",
        "game",
        "tree",
        "inputs"
      ],
      "similar_chapters": [
        {
          "book": "Game_Engine_Architecture",
          "chapter": 27,
          "title": "",
          "score": 0.718,
          "base_score": 0.568,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 30,
          "title": "",
          "score": 0.615,
          "base_score": 0.465,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 7,
          "title": "",
          "score": 0.599,
          "base_score": 0.449,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 28,
          "title": "",
          "score": 0.588,
          "base_score": 0.438,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 31,
          "title": "",
          "score": 0.535,
          "base_score": 0.385,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "animation",
          "blend",
          "clip",
          "pose",
          "clips"
        ],
        "semantic": [],
        "merged": [
          "animation",
          "blend",
          "clip",
          "pose",
          "clips"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.2697525221670191,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:57.760100+00:00"
      }
    },
    {
      "chapter_number": 30,
      "title": "Segment 30 (pages 590-610)",
      "start_page": 590,
      "end_page": 610,
      "summary": "pipeline and the game characters and other clients of the animation system.\nThis layer is usually implemented as a state machine, known as the action state \nmachine or the animation state machine ( ASM) .\nthe characters in a game to be controlled in a straightforward, state-driven \nThe ASM is also responsible for ensuring that transitions from state \nto state are smooth and natural-looking.\ntiple independent state machines to control diﬀ erent aspects of a character’s \nanimations.\nIn this section, we’ll explore how a typical animation state machine is \nAnimation States\nEach state in an ASM corresponds to an arbitrarily complex blend of simul-\ntaneous animation clips.\nIn a blend tree architecture, each state corresponds \na state represents a group of clips with a speciﬁ c set of relative weights.\nThe blend tree corresponding to a particular animation state can be as \nan “idle” state might be comprised of a single full-body animation.\nning” state might correspond to a semicircular blend, with straﬁ ng left , run-\nThe blend tree for a “running while shooting” state might \nblend nodes for aiming the character’s weapon up, down, left , and right, and \nadditional blends to permit the character to look around with its eyes, head, \nMore additive animations might be included to control the \nState and Blend Tree Speciﬁ cations\nanimation and control systems for the central characters in a game.\nvelopers need a way to specify the states that make up a character’s ASM, to \nlay out the tree structure of each blend tree, and to select the clips that will \nAlthough the states and blend trees could be hard-coded, \nmost modern game engines provide a data-driven means of deﬁ ning animation \nstates.\nThe means by which the users enter animation state data varies widely.\ntion states to be speciﬁ ed in a text ﬁ le with a simple syntax.\nvide a slick, graphical editor that permits animation states to be constructed \ncharacter will look in the ﬁ nal game.\nCustom Blend Tree Node Types\ntypes of blend nodes: clips, binary LERP blends, binary additive blends, and \nA blend tree built exclusively from atomic nodes can quickly become large \ngame might deﬁ ne a node that allows the character to dribble the ball.\ngame could deﬁ ne a special node that handles aiming and ﬁ ring a weapon.\nA brawler could deﬁ ne custom nodes for each ﬁ ght move the characters can \nspecifying animation states.\ntory with the Lisp language , state speciﬁ cations in the Uncharted engine \nSimple States\nA simple state contains a single animation clip.\n:flags (anim-state-flag no-adjust-to-ground)\nﬁ ne a state named “pirate-b-bump-back” whose animation clip also happens \nComplex States\nA complex state contains an arbitrary tree of LERP or additive blends.\nample, the following state deﬁ nes a tree that contains a single binary LERP \nblend node, with two clips (“walk-l-to-r” and “run-l-to-r”) as its inputs:\n(anim-node-lerp\n(anim-node-clip \"walk-l-to-r\")\n(anim-node-clip \"run-l-to-r\")\nposed of LERP or additive blend nodes and nodes that play individual anima-\nFrom this, we can see how the (define-state simple ...) example \nplex blend tree containing a single “clip” node, like this:\n:tree (anim-node-clip \"pirate-b-unimog-bump-back”)\n:flags (anim-state-flag no-adjust-to-ground)\nThe following complex state shows how blend nodes can be cascaded into \n(anim-node-lerp\n(anim-node-additive\n(anim-node-additive\n(anim-node-clip \"move-f\")\n(anim-node-clip \"move-f-look-lr\")\n(anim-node-clip \"move-f-look-ud\")\n(anim-node-additive\n(anim-node-additive\n(anim-node-clip \"move-b\")\n(anim-node-clip \"move-b-look-lr\")\n(anim-node-clip \"move-b-look-ud\")\nalso be deﬁ ned by the user in terms of the basic clip, LERP, and additive blend \nFor example, the complex blend tree used in the state “move-b-to-\nBlend tree corresponding to the example state “move-b-to-f.”\n(anim-node-additive\n(anim-node-additive\n(anim-node-clip base-clip)\n(anim-node-clip look-lr-clip)\n(anim-node-clip look-ud-clip)\n(anim-node-lerp\nThe (look-tree ...) macro can be used to deﬁ ne any number of states that \nrequire this same basic tree structure but want diﬀ erent animation clips as \nAn in-game animation viewer allows a character to be spawned into the game \nand its animations controlled via an in-game menu.\nTo tweak a character’s animations, the user can make \nchanges to the text ﬁ le containing the animation state speciﬁ cations, quick-\nly reload the animation states, and immediately see the eﬀ ects of his or her \nchanges on an animating character in the game.\nAs shown in Figure 11.57, an animation blend tree in Unreal \nkinds of inputs: animations, morphs, and special nodes known as skel controls.\nmorph-target-based animations to drive the character; this is most oft en used \npose generated by the animation and/or morph trees.\nThe UE3 Animation Tree\nThe Unreal animation tree is essentially a blend tree.\nclips (called sequences in Unreal) are represented by nodes of type Anim\nUnreal provides a wide selection of blend node types \nThe UE3 animation tree is also highly customizable.\nanimation blending out of the box, although it’s certainly possible for a game \nIt is interesting to note that Unreal’s approach to character animation is \ning portions of the UE3 animation tree dynamically, so that a game’s mono-\nthe pose of the skeleton that has been generated by the blend tree.\nAs with animation nodes, it is quite easy for a \nTransitions\ntransitions between states in the action state machine to ensure that the splices \nmodern animation engines provide a data-driven mechanism for specifying \nThere are many diﬀ erent ways to manage the transition between states.\na suitable choice when transitioning from state to state.\nFor this kind of state transition, we need one \nor more custom animations.\nintroducing special transitional states into the state machine.\nThese states are \nused as a steady-state node.\nibility when authoring custom-animated transitions.\nWhen describing a particular transition between two states, we generally need \nTo which state(s) does this transition ap-\nvia a transitional state?\nample, a transition from a punch animation to an impact reaction might \nSpecifying transitions between states can be challenging, because the number \ntransitions from any state along the vertical axis to any other state along the \nall state-to-state transitions are possible.\nat least one intermediate state that causes the character to jump out of his \nless even than the number of valid transitions between states.\naction states.\nbrief look at a few transition matrix implementations from real game engines.\ndestination states could contain asterisks (*) as a wild-card character.\nlowed us to specify a single default transition from any state to any other \ndown to custom transitions between speciﬁ c state pairs when necessary.\n<transitions>\n</transitions>\nIn some animation engines, high-level game code requests transitions from \nedge of the names of the states and of which transitions are valid when in a \nparticular state.\ning state transitions from secondary implementation details into ﬁ rst-class \nEach state provides a list of valid transitions to other states, and each \nif a transition is called “walk,” then it always goes from the current state to a \nhigh-level animation control code wants to transition from state A to state B, \nit asks for a transition by name (rather than requesting the destination state \nThe following example state deﬁ nes four transitions named “reload,” \nsame set of transitions is to be used in multiple states.\nThe (transition-\nend of the state’s local time line if no other transition has been taken before \n:tree (aim-tree (anim-node-clip \n:transitions (\npurpose is to allow transitions and states to be modiﬁ ed in a data-driven man-\ndegree of ﬂ exibility is accomplished by shielding the animation control code \nAll of them can transition into a jumping state, but diﬀ erent kinds \nFor each of the ten walking states, \ntransitions to a single generic “jump” state, just to get things up and running.\njump states.\nWe can even introduce transitional states between some of the \nState Layers\napproach to animation.\nto this problem is to introduce the concept of state layers .\nin only one state at a time, but the layers are temporally independent of one \nThe Uncharted engine uses a layered state architecture.\nIn eﬀ ect, a layered state ma-\nState A\nState B\nState C\nA layered animation state machine, showing how each layer’s state transitions \ncomplex animating character.\non the way the character animates.\nA layered state machine converts the blend trees from multiple states into a \nEach clip state \nThe code that controls the character must look up individual clip states by \nlook up these clip states by name and manually control all four blend weights \nIn a blend tree , a diﬀ erent set of problems arise.\nthe blend tree so that it can ﬁ nd the appropriate nodes in the tree in order to \nDiﬀ erent animation engines solve these problems in diﬀ erent ways.\nblend nodes in the tree.\nThe nodes in the blend tree(s) are \nWe’ve seen how action state machines can be used to specify complex blend \ntrees and how a transition matrix can be used to control how transitions be-\nAnother important aspect of character animation \nlook at how these constraints are handled in a typical animation system.\nthe animation blending pipeline but can still be used for att achment purposes.\nFor example, they might be speciﬁ ed as part of the action state ma-\nallows the animators to focus only on the joints that aﬀ ect the look of the \nother when animating.\nThe animator can ensure that all three actors in the scene line up \nthis animated sequence.\nanimation clips.\nWhen the three animation clips are exported, the tools store the position \nwhen the three clips are played back in-game, the animation engine can look \nreference locator appears in each exported animation clip (expressed in that \nThe reference locator is encoded in each actor’s animation ﬁ le.\n// locator as specified in the door’s animation.\n// Play the two characters’ animations relative to  \n// Play all animations relative to the world-space\nthe joints in question are aligned perfectly in clip A and in clip B, LERP blend-\nSome animation engines allow IK chains to be deﬁ ned a priori.",
      "keywords": [
        "State",
        "Action State Machines",
        "blend tree",
        "Animation",
        "animation state machine",
        "State Machines",
        "blend",
        "tree",
        "animation state",
        "Action State",
        "transition",
        "Animation Systems",
        "character",
        "complex blend tree",
        "blend nodes"
      ],
      "concepts": [
        "state",
        "animation",
        "animations",
        "animators",
        "animating",
        "animates",
        "transitions",
        "transition",
        "transitional",
        "tree"
      ],
      "similar_chapters": [
        {
          "book": "Game_Engine_Architecture",
          "chapter": 27,
          "title": "",
          "score": 0.688,
          "base_score": 0.538,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 31,
          "title": "",
          "score": 0.679,
          "base_score": 0.529,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 28,
          "title": "",
          "score": 0.661,
          "base_score": 0.511,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 29,
          "title": "",
          "score": 0.615,
          "base_score": 0.465,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 22,
          "title": "",
          "score": 0.5,
          "base_score": 0.35,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "state",
          "blend",
          "node",
          "anim node",
          "anim"
        ],
        "semantic": [],
        "merged": [
          "state",
          "blend",
          "node",
          "anim node",
          "anim"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.3403464164503768,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:57.760151+00:00"
      }
    },
    {
      "chapter_number": 31,
      "title": "Segment 31 (pages 611-631)",
      "start_page": 611,
      "end_page": 631,
      "summary": "In games, we usually want the locomotion animations of our characters to \nLet’s imagine how we’d animate a character walking forward in a straight \nIn the animation authoring package, the character moves forward in space, and \nis walking forward in-game.\nThe character \nwork in-game.\nbe used in-game to move the local-space origin of the character forward by the \nIf the character moves forward by 4 feet in the animation and the anima-\nexample, to make the character walk at 2 feet/second, we can simply play the \ngame character must be turned and moved in ways that don’t coincide with \nWalk cycle in-game, with extracted root motion data applied to the local-space \nIt’s generally more important for the player character control system to feel \nresponsive and fun than it is for the character’s animations to look perfect.\nyour game lightly.\ned to a game animation engine.\n. If a character can take cover, animation blend-\nvenient interface provided by the action state machine, some game teams ﬁ nd \nlevel control over how characters animate.\nthe game world, or how to drive a vehicle.\nall aspects of the character’s animation-related behavior.\nto implement animation controllers in the game industry (at least not yet).\nCollision and Rigid\nBut in a virtual game world, objects don’t do anything unless we \ntral components of any game engine—the collision detection system.\nA game engine’s collision system is oft en closely integrated with a physics \nOf course, the ﬁ eld of physics is vast, and what most of today’s game \nobject.\ndynamics simulation allows motion to be imparted to objects in the game \nA dynamics simulation makes heavy use of the collision detection system \nin order to properly simulate various physical behaviors of the objects in the \nalone, without a dynamics simulation—many games do not have a “physics” \nCollision and Rigid Body Dynamics\nBut all games that involve objects moving about in two- or three-\ndimensional space have some form of collision detection.\ndetection system and a typical physics (rigid body dynamics) system.\nDo You Want Physics in Your Game?\nNowadays, most game engines have some kind of physical simulation capa-\nphysical simulations, including approximate real-time ﬂ uid mechanics eﬀ ects \nBut adding physics to a game is not \ntive list of physics-driven features in our game, we should (at the very least) \nHere are just a few of the things you can do or have with a game physics \nz Detect collisions between dynamic objects and static world geometry.\nz Simulate free rigid bodies under the inﬂ uence of gravity and other forces.\ndeﬁ ned regions in the game world).\nz Allow characters to pick up rigid objects.\nDo You Want Physics in Your Game?\nWe should note here that in addition to running a physics simulation at \nruntime in our game, we can also run a simulation as part of an oﬄ  ine pre-\nto runtime rigid body dynamics simulations, but oﬀ -line tools are a power-\nThe presence of a rigid body dynamics system in a game does not necessarily \nmake the game fun.\nwith other engine systems, the selection of physics-driven gameplay elements \ncharacter, and the genre of game being made.\nLet’s take a look at a few broad game genres and how a rigid body dy-\nof games.\nClearly, the realism provided by a rigid body dynamics system ﬁ ts \nextremely well into these kinds of games.\nPhysics Puzzle Games\nCollision and Rigid Body Dynamics\nSandbox Games\nIn a sandbox game , there may be no objectives at all, or there may be a large \n“mess around” and explore what the objects in the game world can be made \nSandbox games can put a realistic dynamics simulation to good use, es-\nrealistic) interactions between objects in the game world.\nA goal-based game has rules and speciﬁ c objectives that the player must ac-\nIntegrating a physics system into these kinds of games \nFor example, in a character-based platformer game, we want the player \nIn these kinds of games, \nphysics is oft en not necessarily fun, and in fact it can oft en get in the way \nof fun when the player’s goals are at odds with the physically simulated \nbehaviors of the objects in the game world.\ncareful to apply physics judiciously and take steps to control the behavior \nImpact of Physics on a Game\nAdding a physics simulation to a game can have all sorts of impacts on the \nHere are a few examples across various game de-\nanimation of a character walking.\n“surfb oards” in PsyOps. In general, the game design should usually drive the physics require-\nA good collision/physics pipeline takes time to build and \nHow does the player control the physics objects in the \nz Collision detection.\nCollision models intended for use within a dynamics \nz Animation and character motion.\nAnimation-driven objects can clip slight-\ndynamics simulation, objects may bounce oﬀ  one another in unexpected \nDo You Want Physics in Your Game?\nCollision and Rigid Body Dynamics\nz Rag doll physics.\ncharacter’s body into penetration with other collision volumes—when \nan object with diﬀ erent collision and dynamics conﬁ gurations for diﬀ er-\nThe unpredictability of physics-driven objects can make \nCollision/Physics Middleware\na rigid body dynamics system into their games.\nand wise choices along the way, adding physics to your game can be reward-\nCollision/Physics Middleware\nWriting a collision system and rigid body dynamics simulation is challeng-\nThe collision/physics system of a game engine \nThankfully, a number of robust, high-quality collision/physics engines are \nics SDKs, check out the on-line game development forums (e.g., htt p://www.\nI-Collide is an open-source collision detection library developed by the Uni-\nlibraries that can handle complex non-convex shapes, called V-Collide and \nNone of these libraries can be used right out of the box in a game, but \ncollision detection engine.\nimplies, ODE is an open-source collision and rigid body dynamics SDK.\nneeds of a particular game).\nCollision and Rigid Body Dynamics\nBullet is an open-source collision detection and physics library used by both \nthe game and ﬁ lm industries.\nnamics simulation, but hooks are provided so that the collision system can \nTrueAxis is another collision/physics SDK.\nsupport.) It is available at htt p://www.nvidia.com/object/nvidia_physx.html.\nHavok is comprised of a core collision/physics engine, plus a number of \nThe Collision Detection System\nunique physics engine that uses ﬁ nite element methods to simulate the dy-\nThe Collision Detection System\nThe primary purpose of a game engine’s collision detection system is to deter-\nmine whether any of the objects in the game world have come into contact .\nThe collision \nCollisions can also be used \nA rigid body dynamics simulation is oft en the most \ndemanding client of the collision system, using it to mimic physically realistic \nCollision and Rigid Body Dynamics\neven games that have no physics system can still make heavy use of a collision \nlent books on real-time collision detection are available, including [12], [41], \nIf we want a particular logical object in our game to be capable of colliding \nwith other objects, we need to provide it with a collision representation , describ-\ning the object’s shape and its position and orientation in the game world.\n(the code and data that deﬁ ne its role and behavior in the game) and separate \nshows a few examples of using simple shapes to approximate object volumes \nfor collision detection purposes.\nHavok uses the term collidable to describe a distinct, rigid object that can \ntake part in collision detection.\nFigure 12.1 Simple geometric shapes are often used to approximate the collision volumes of \nthe objects in a game.\ndescribes the shape’s position and orientation in the game world.\nTechnically speaking, a shape only describes the form of an object (i.e., \nMany of the objects in a game are dynamic.\nexample, in a racing game, the shape information for many of the cars \nIn that case, all of the car collidables in the game can \nAny particular object in the game may have no collidable at all (if it doesn’t \nrequire collision detection services), a single collidable (if the object is a simple \nThe Collision/Physics World\nThe collision world is a \ncomplete representation of the game world designed explicitly for use by the \ncollision detection system.\nHavok’s collision world is an instance of the class \nin the game.\ngame objects themselves.\nFor one thing, the collision world need only contain \ncollidables for those game objects that can potentially collide with one another.\nThe Collision Detection System\nCollision and Rigid Body Dynamics\nThe collision world \nThe Physics World\nIf a game has a rigid body dynamics system, it is usually tightly integrated \nwith the collision system.\nthe collision system, and each rigid body in the simulation is usually associat-\namong physics engines because of the frequent and detailed collision queries \nreason, the collision world is oft en called the collision/physics world or some-\ntimes just the physics world.\nEach dynamic rigid body in the physics simulation is usually associated \nwith a single collidable object in the collision system (although not all collid-\n(although the physical properties of the rigid body are stored separately, in an \natt empt to separate the collision library from the rigid body dynamics simu-\n(which is important for games that don’t need physics but do need to detect \ncollisions).\nThe Collision Detection System\nIt’s important to note that some kinds of game objects, like terrain, rivers, \ncollisions between small, fast-moving objects and inﬁ nitesimally thin surfaces \nboth shapes.\nIn games, we’re not usually interested in ﬁ nding the intersection in the strict-\ninformation allows us to separate the objects in a physically plausible and ef-\nCollision systems usually package contact information into a convenient \nslide the objects in order to eﬃ  ciently move them out of collision.\nCollision and Rigid Body Dynamics\nOne of the most important concepts in the ﬁ eld of collision detection is the \nCollision detection systems can usually work with a relatively limited set of \nSome collision systems refer to these shapes as collision primitives \nThe Collision Detection System\nthat if an AABB is used to approximate the shape of an object in the game, \nan object is roughly box-shaped, its AABB may degenerate into a very poor \napproximation to its shape when the object rotates oﬀ -axis.",
      "keywords": [
        "rigid body dynamics",
        "collision detection system",
        "Collision",
        "collision detection",
        "collision system",
        "rigid body",
        "game",
        "Body Dynamics system",
        "physics",
        "Body Dynamics",
        "system",
        "Physics System",
        "character",
        "dynamics simulation",
        "detection system"
      ],
      "concepts": [
        "physics",
        "physical",
        "games",
        "collision",
        "collisions",
        "animation",
        "animations",
        "animate",
        "animator",
        "animated"
      ],
      "similar_chapters": [
        {
          "book": "Game_Engine_Architecture",
          "chapter": 30,
          "title": "",
          "score": 0.679,
          "base_score": 0.529,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 27,
          "title": "",
          "score": 0.639,
          "base_score": 0.489,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 29,
          "title": "",
          "score": 0.535,
          "base_score": 0.385,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 10,
          "title": "",
          "score": 0.511,
          "base_score": 0.361,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 4,
          "title": "",
          "score": 0.49,
          "base_score": 0.49,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "collision",
          "physics",
          "dynamics",
          "rigid",
          "collision detection"
        ],
        "semantic": [],
        "merged": [
          "collision",
          "physics",
          "dynamics",
          "rigid",
          "collision detection"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.2667673665550714,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:57.760187+00:00"
      }
    },
    {
      "chapter_number": 32,
      "title": "Segment 32 (pages 632-651)",
      "start_page": 632,
      "end_page": 651,
      "summary": "It is a convex polytope that approximates the shape of an object.\nshape is to be approximated.\nAn AABB is only a good approximation to a box-shaped object when the object’s \nMost collision engines permit arbitrary convex volumes to be constructed by \nThe artist builds the shape out of polygons \nIf the shape passes the convexity test, \nGJK are applicable to these shapes because they are convex.\nSome collision systems also support totally arbitrary, non-convex shapes.\nThe Collision Detection System\nthis reason, this type of shape is oft en called a polygon soup , or poly soup for \nAs you might imagine, detecting collisions with a poly soup is the most \nexpensive kind of collision test.\nmost games try to limit the use of poly soup shapes to objects that will not take \nUnlike convex and simple shapes, a poly soup does not necessarily represent \nPoly soup shapes oft en \nin order to bring the two objects out of collision.\nTherefore, it is possible to carefully construct a poly soup shape so that all \nsoup shapes (i.e., surfaces).\nCompound Shapes\nSome objects that cannot be adequately approximated by a single shape can \nA compound shape can oft en be a more-eﬃ  cient alternative to a poly \nsoup for modeling non-convex objects; two or more convex volumes can oft en \nout-perform a single poly soup shape.\ncan take advantage of the convex bounding volume of the compound shape as \na whole when testing for collisions.\nAs the example in Figure 12.9 shows, the collision system ﬁ rst tests \nthe convex bounding volumes of the two compound shapes.\nintersect, the system needn’t test the subshapes for collisions at all.\nCollision Testing and Analytical Geometry\nGJK intersection testing algorithm for arbitrary convex polyhedra.\nA collision system need only test the subshapes of a pair of compound shapes \nThe Collision Detection System\nWe can determine whether a point p lies within a sphere by simply forming \nthe separation vector s between the point and the sphere’s center c and then \nDetermining if two spheres intersect is almost as simple as testing a point \nMost collision detection systems make heavy use of a theorem known as \ntwo convex shapes do not overlap, then we can be certain that the two shapes \nIf such an axis does not exist and the shapes are convex, \n(If the shapes are concave, then \none reason why we tend to favor convex shapes in collision detection.)\nshapes onto the axis that is perpendicular to the separating line.\nThe projection of a two-dimensional convex shape onto an axis acts like \nists between two shapes, their projections do not overlap along the separating \na three-dimensional convex shape onto an axis is a line segment, which we can \nSome types of shapes have properties that make the potential separating \nTo detect intersections between two such shapes A and B, we can \nproject the shapes onto each potential separating axis in turn and then check \nshapes do not intersect.\nIf two spheres do not intersect, then the axis parallel to the line segment join-\ning the spheres’ center points will always be a valid separating axis (although \nThe projections of two shapes onto a separating axis are always two disjoint \nThe projections of these same shapes onto a non-separating axis are not \nIf no separating axis exists, the shapes intersect.\nThe Collision Detection System\nlies parallel to the line segment formed by the two spheres’ center points.\nDetecting Convex Collisions: The GJK Algorithm\nevery point that lies within shape B and subtract it pairwise from every point \ninside shape A.\nto two convex shapes, it will contain the origin if and only if those two shapes \nwhy it is true by remembering that when we say two shapes A and B intersect, \npect to eventually hit one of those shared points that lies within both shapes.\norigin if (and only if) sphere A and sphere B have points in common.\nThe Minkowski diﬀ erence of two convex shapes is itself a convex shape.\na four-sided shape made out of triangles) that lies on the convex hull of the \nthe shapes intersect; if one cannot be found, then they don’t.\nThe Collision Detection System\n(i.e., a point becomes a line segment, a line segment becomes a triangle, and \nnever get there, which implies that the two shapes do not intersect.\nThe Minkowski difference of two intersecting convex shapes contains the origin, \nbut the Minkowski difference of two non-intersecting shapes does not.\nWe won’t cover any of the other shape-shape intersection combinations here, \nIn fact, for N shape types, the number of pairwise tests required \nbetween all convex shape types in one fell swoop.\nfrom shape type to shape type is the support function used in the algorithm.)\nlects the appropriate collision-testing function given two arbitrary shapes that \nIn the GJK algorithm, if adding a point to the current simplex creates a shape that \ncontains the origin, we know the shapes intersect; if there is no supporting vertex that will \nbring the simplex any closer to the origin, then the shapes do not intersect.\nThe Collision Detection System\na pair of collidables that are to be collision-tested and then call it, passing the \ntime step and use static intersection tests on each “snapshot” of the collision \nSwept Shapes\nOne way to avoid tunneling is to make use of swept shapes .\nA swept shape is \na new shape formed by the motion of a shape from one point to another over \nRather than testing static snapshots of the collision world for intersec-\ntions, we can test the swept shapes formed by moving the shapes from their \nsweep the shapes along line segments from snapshot to snapshot.\nnately, a convex shape that has been swept along a curve is not itself convex, \nso this can make our collision tests much more complex and computationally \nIn addition, if the convex shape we are sweeping is rotating, the resulting \nswept shape is not necessarily convex, even when it is swept along a line seg-\nAs Figure 12.18 shows, we can always form a convex shape by linearly \nrent snapshots—but the resulting convex shape is not necessarily an accurate \nrepresentation of what the shape really would have done over the time step.\ntating shapes.\nSo unless our shapes are not permitt ed to rotate, intersection \nconvex shape (left).\nA linear interpolation of the motion does form a convex shape (right), but \nThe Collision Detection System\ntesting of swept shapes becomes much more complex and computationally \nSwept shapes can be a useful technique for ensuring that collisions are \nknown as continuous collision detection (CCD).\nThe calculations required to determine whether two shapes intersect are \nFor example, in Havok, collision agents (hkpCollisionAgent) are usually \nbe tested for collisions during each time step.\nThis is known as broad phase collision detection.\nz Second, the coarse bounding volumes of compound shapes are tested.\nThis is known as midphase collision detection.\npound shape composed of three spheres, the bounding volume might \nThe Collision Detection System\nThis is known as narrow phase collision detection.\nphase collision detection employs an algorithm known as sweep and prune \nthetical questions about the collision volumes in the game world.\nThe most common kind of query is a collision cast, sometimes just called a \nplaced into the collision world and moved along a ray or line segment.\ning cast is not really in the collision world—it cannot aﬀ ect the other objects \nThis is why we say that a collision cast answers hypo-\nThe simplest type of collision cast is a ray cast , although this name is actually a \ntion used—see below.) The cast line segment is tested against the collidable \nobjects in the collision world.\nIf it intersects any of them, the contact point or \nRay casting systems typically describe the line segment via its start point \nMost ray casting APIs return their contact points as \nMost collision detection systems are capable of returning the earliest con-\ntact —i.e., the contact point that lies closest to p0 and corresponds to the small-\ncollidables that were intersected by the ray or line segment.\nof the shape or surface that was struck.\ncollision system whether character A has a direct line of sight to character B.\nThe Collision Detection System\nShape Casting\ninary convex shape would be able to travel along a directed line segment be-\nbeing cast is a sphere, or a shape cast in general.\nAs with ray casts, a shape cast is usually described by specifying the start \nentation of the shape we wish to cast.\nThere are two cases to consider when casting a convex shape.\nThe cast shape is already interpenetrating or contacting at least one other \nThe cast shape is not intersecting with anything else at its starting loca-\nIn the ﬁ rst scenario, the collision system typically reports the contact (s) \nbetween the cast shape and all of the collidables with which it is initially in-\nThese contacts might be inside the cast shape or on its surface, \nIn the second case, the shape can move a non-zero distance along the line \nHowever, it is possible for a cast shape to strike \ncourse, if the impacted collidable is a non-convex poly soup, the cast shape \ncast shape in general.\nIf the starting location of a cast shape is not interpenetrating anything, then \nthe shape will move a non-zero distance along its line segment, and its contacts (if any) will \ncan safely say that no matt er what kind of convex shape is cast, it is possible \n(albeit unlikely) for the cast to generate multiple contact points.\nwill always be on the surface of the cast shape in this case, never inside it (be-\ncause we know that the cast shape was not interpenetrating anything when it \nAs with ray casts, some shape casting APIs report only the earliest contact (s) \nexperienced by the cast shape, while others allow the shape to continue along \nThe contact information returned by a shape cast is necessarily a bit more \nshape along its path.\nthe shape, it came into contact with the impacted collidable.\nshape casting APIs return both a t value and the actual contact point, along \nUnlike ray casting APIs, a shape casting system must always be capable of \nwith the earliest t value, the shape may have touched multiple distinct collid-\nables in the game world, or it may be touching a single non-convex collidable \nA shape casting API might return all contacts instead of only the earliest con-\nThe Collision Detection System\nmay not return their contact points sorted by t.\nthe ﬁ rst contact point in the list, it will be guaranteed to be among the earliest \ncontact points along the shape’s path.\nApplications of Shape Casts\nShape casts are extremely useful in games.\ntermine whether the virtual camera is in collision with objects in the game \nSometimes, games need to determine which collidable objects lie within \nHavok supports a special kind of collidable object known as a phantom for \nA phantom acts much like a shape cast whose distance vector d is zero.\nwould be returned by a zero-distance shape cast.\nHowever, unlike a shape cast, a phantom is persistent in the collision \nSome collision engines support other kinds of queries in addition to casts.\nMost collision \nThis is known as collision ﬁ ltering .\nCollision Callbacks\ncallback function whenever a collision is detected.\nWhen contact points are ﬁ rst added to the world, the contactPointAdded()\nThe Collision Detection System",
      "keywords": [
        "Collision Detection System",
        "Collision",
        "Collision Detection",
        "shape",
        "Rigid Body Dynamics",
        "convex shape",
        "cast shape",
        "Point",
        "collision system",
        "Detection System",
        "collision world",
        "contact",
        "convex",
        "cast",
        "contact point"
      ],
      "concepts": [
        "collision",
        "shape",
        "points",
        "convex",
        "intersection",
        "intersecting",
        "intersections",
        "objects",
        "colliding",
        "collide"
      ],
      "similar_chapters": [
        {
          "book": "Game_Engine_Architecture",
          "chapter": 33,
          "title": "",
          "score": 0.554,
          "base_score": 0.404,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 35,
          "title": "",
          "score": 0.484,
          "base_score": 0.334,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 34,
          "title": "",
          "score": 0.39,
          "base_score": 0.24,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 36,
          "title": "",
          "score": 0.351,
          "base_score": 0.351,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 37,
          "title": "",
          "score": 0.345,
          "base_score": 0.345,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "shape",
          "shapes",
          "collision",
          "convex",
          "cast"
        ],
        "semantic": [],
        "merged": [
          "shape",
          "shapes",
          "collision",
          "convex",
          "cast"
        ]
      },
      "topic_id": 4,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.21517982510991326,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:57.760219+00:00"
      }
    },
    {
      "chapter_number": 33,
      "title": "Segment 33 (pages 652-672)",
      "start_page": 652,
      "end_page": 672,
      "summary": "Collision and Rigid Body Dynamics\nRigid Body Dynamics\nMany game engines include a physics system for the purposes of simulating the \nmotion of the objects in the virtual game world in a somewhat physically real-\nspeciﬁ c subdiscipline of mechanics known as classical rigid body dynamics .\nz Rigid bodies .\nGame physics engines are also capable of ensuring that the motions of \nthe rigid bodies in the game world conform to various constraints .\nprovide realistic collision responses whenever bodies are found to be interpen-\ned rigid bodies.\nbetween the rigid bodies in the dynamics simulation and the collidables man-\npossible to create a collidable that has no rigid body).\nobject and as a rigid body for the purposes of the dynamics simulation.\nrigid bodies and their corresponding collidables are usually maintained in a \nThe rigid bodies in the physics engine are typically distinct from the logi-\npositions and orientations of game objects can be driven by the physics simu-\ntransform of each rigid body, and apply it in some way to the transform of \nIt’s also possible for a game object’s motion, \nthe character control system) to drive the position and rotation of a rigid body \nobject may be represented by one rigid body in the physics world, or by many.\nRigid Body Dynamics\nCollision and Rigid Body Dynamics\nbody.\nbody dynamics simulations.\nwritt en on the topic of classical rigid body dynamics .\nlike [1], [9], and [28], include chapters on rigid body dynamics for games.\nresources at htt p://chrishecker.com/Rigid_Body_Dynamics.\nMost rigid body dynamics simulations operate in the MKS system of units .\nSeparability of Linear and Angular Dynamics\nAn unconstrained rigid body is one that can translate freely along all three \nrigid body can be separated into two independent components:\nThis is a description of the motion of the body when \nz Angular dynamics .\nThis is a description of the rotational motion of the body.\nponents of a rigid body’s motion is extremely helpful when analyzing or sim-\nIt means that we can calculate a body’s linear motion \nthe body’s motion.\nFor the purposes of linear dynamics, an unconstrained rigid body acts as \nwords, the mass of a rigid body is distributed evenly around its center of mass \nFor a body with uniform density, the center of mass lies at the centroid of \nthe body.\nIf the body’s density is not uniform, the position of \nRigid Body Dynamics\nCollision and Rigid Body Dynamics\nThe center of mass always lies inside a convex body, although it may actu-\nFor the purposes of linear dynamics , the position of a rigid body can be fully \nto the center of mass of the body, as shown in Figure 12.22.\ndescribing the motion of the body’s center of mass.\nFor the purposes of linear dynamics, the position of a rigid body can be fully \nLinear Velocity and Acceleration\nThe linear velocity of a rigid body deﬁ nes the speed and direction in which the \nVelocity is the ﬁ rst time derivative of position, so we can write\nLinear acceleration is the ﬁ rst derivative of linear velocity with respect to \ntime, or the second derivative of the position of a body’s CM versus time.\nA force is deﬁ ned as anything that causes an object with mass to accelerate or \nforces are applied to a rigid body, their net eﬀ ect on the body’s linear motion \nWhen we multiply a body’s linear velocity by its mass, the result is a \nwe discuss angular dynamics.\nThe central problem in rigid body dynamics is to solve for the motion of \nthe body, given a set of known forces acting on it.\nRigid Body Dynamics\nCollision and Rigid Body Dynamics\nA force can be constant, or it can be a function of time as shown above.\ncan also be a function of the position of the body, its velocity, or any number \nThis can be rewritt en in terms of the position vector and its ﬁ rst and second \nAs we saw in Equation (12.3), force is a function of time, position, and velocity \nscribes the body’s position for all possible values of time t.\nwhere v0 is the vertical velocity at time t = 0.\ntion, so we cannot predict how the forces in a game will behave over time.\nand velocities of the objects in the game as functions of time.\nFor the reasons cited above, game physics engines turn to a technique known \nthat we know the body’s position and velocity at the current time t1 and that \nthe force is known as a function of time, position, and/or velocity, we wish to \nﬁ nd the position and velocity at the next time step t2 = t1 + Δt.\nRigid Body Dynamics\nCollision and Rigid Body Dynamics\nand that we wish to solve the following ODE to ﬁ nd the body’s position on \nUsing the explicit Euler method, we simply convert the velocity from meters \nWe can take an analogous approach to ﬁ nd the body’s velocity next frame \nbody is constant during the time step.\nto predict the body’s position on the next frame.\nposition of the body versus time, we are taking the slope of the function at time \nIn the explicit Euler method, the slope of r(t) at time t1 is used to linearly \nt1 (which is just v(t1)) and extrapolating it linearly to the next time step t2.\nwith a particularly good estimate of the true position at the next time step r(t2), \nvalid when the velocity is constant over the time step.\nIf a numerical method adds energy into the system, object velocities will \nRigid Body Dynamics\nCollision and Rigid Body Dynamics\nTo make the error of a method explicit, we’ll oft en write its equation with the \nThe numerical ODE method most oft en used in interactive games these \nfrom velocity to position).\nIn terms of net force, the Verlet method becomes\nThe more commonly used velocity Verlet method is a four-step process in which \nNotice in the third step that the force function depends on the position \nand velocity on the next time step, r(t2) and v(t2).\nRigid Body Dynamics\nCollision and Rigid Body Dynamics\nframe’s velocity, perhaps using the explicit Euler method.\nAngular Dynamics in Two Dimensions\nUp until now, we’ve focused on analyzing the linear motion of a body’s center \nstrained rigid body will rotate about its center of mass.\nlayer the angular motion of a body on top of the linear motion of its center of \nmass in order to arrive at a complete description of the body’s overall motion.\nThe study of a body’s rotational motion in response to applied forces is called \nangular dynamics .\nIn two dimensions, angular dynamics works almost identically to linear \nIn two dimensions, every rigid body can be treated as a thin sheet of mate-\n(Some physics texts refer to such a body as a plane lamina .) All linear mo-\nThe orientation of a rigid body in 2D is fully described by an angle θ, \nAngular velocity measures the rate at which a body’s rotation angle chang-\nIn two dimensions, angular velocity is a scalar, more correctly \ncalled angular speed , since the term “velocity” really only applies to vectors.\nAngular speed is the derivative of the orientation angle θ(t) with re-\nAngular: \nThe rotational equivalent of mass is a quantity known as the moment of inertia .\nJust as mass describes how easy or diﬃ  cult it is to change the linear velocity \nchange the angular speed of a rigid body about a particular axis.\nIf a body’s \nbody whose mass is spread out away from that axis.\nthe axis of rotation is always z, and a body’s moment of inertia is a simple \nrigid body.\nbody.\nIf the line of action of a force passes through the body’s center of mass, \nthen the force will produce linear motion only, as we’ve already seen.\ntion at which the force is applied as a vector r extending from the body’s center \nOn the left, a force applied to a body’s CM produces purely linear motion.\nthe right, a force applied off-center will give rise to a torque, producing rotational motion as \nRigid Body Dynamics\nCollision and Rigid Body Dynamics\nIt also explains why a force applied directly through the center of mass \nWhen two or more forces are applied to a rigid body, the torque vectors \nTorque is related to angular acceleration and moment of inertia in much \nthe same way that force is related to linear acceleration and mass:\nAngular: \nSolving the Angular Equations of Motion in Two Dimensions\nFor the two-dimensional case, we can solve the angular equations of motion \nAngular: \napplication in body space (i.e., relative to the center of mass) and the force vector.\nAngular: \nAngular Dynamics in Three Dimensions\nAngular dynamics in three dimensions is a somewhat more complex topic \nA rigid body may have a very diﬀ erent distribution of mass about the three \nIn three dimensions, the rotational mass of a rigid body is represented \nRigid Body Dynamics\nCollision and Rigid Body Dynamics\ndown to the three-element vector [ Ixx  Iyy  Izz ] in game physics engines.\nIn two dimensions, we know that the orientation of a rigid body can be de-\nIn three dimensions, a body’s \nrepresenting the body’s rotation about one of the three Cartesian axes.\na body is more oft en represented using either a 3 × 3 matrix R or a unit quater-\nA body’s orientation is of course a function of time, so we should write it q(t).\nAngular Velocity and Momentum in Three Dimensions\nIn three dimensions, angular velocity is a vector quantity, denoted by ω(t).\nThe angular velocity vector can be visualized as a unit-length vector u that \ndeﬁ nes the axis of rotation, scaled by the two-dimensional angular velocity \n= \u0002  of the body about the u-axis.\nIn linear dynamics, we saw that if there are no forces acting on a body, \nthen the linear acceleration is zero, and linear velocity is constant.\nacting on a body in two dimensions, then the angular acceleration α is zero, \nand the angular speed ω about the z-axis is constant.\neven when a rigid body is rotating in the absence of all forces, its angular \nvelocity vector ω(t) may not be constant because the axis of rotation can con-\nThe fact that the angular velocity vector can change in the absence of \ntorques is another way of saying that angular velocity is not conserved.\never, a related quantity called the angular momentum does remain constant \nLike the linear case, angular momentum L(t) is a three-element vector.\nHowever, unlike the linear case, rotational mass (the inertia tensor) is not a \nconstant angular velocity vector.\ndirection of the angular velocity vector changes wildly.\nRigid Body Dynamics\nCollision and Rigid Body Dynamics\nBecause the angular velocity ω is not conserved, we do not treat it as \nThe angular velocity is a secondary quantity, determined only aft er we have \nthe radial position vector of the point of force application and the force vector \nthe angular momentum because angular velocity is not a conserved quantity:\nSolving the Equations of Angular Motion in Three Dimensions\nWhen solving the equations of angular motion in three dimensions, we might \ntwo-dimensional angular motion.\ntion diﬀ er from their linear and two-dimensional angular counterparts in two \nInstead of solving for the angular velocity \nWe then calculate the angular velocity vector as a \ntum is conserved , while angular velocity is not.\nWhen solving for the orientation given the angular velocity, we have \na problem: The angular velocity is a three-element vector, while the \nBut what we can do is convert the angular velocity \nequation that relates the orientation quaternion to the angular veloc-\nIt turns out that when we express a rigid body’s orientation as a quater-\nnion, the derivative of this quaternion is related to the body’s angular velocity \nFirst, we construct an angular velocity quaternion.\nThis quaternion contains the three components of the angular velocity vector \nIt’s important to remember here that ω(t) is the angular velocity quaternion as \nUsing the explicit Euler method, the ﬁ nal approximate solution to the angular \nRigid Body Dynamics\nCollision and Rigid Body Dynamics\nEverything we’ve discussed so far assumes that our rigid bodies are neither \nWhen bodies collide with one another, the dynamics simulation must take \nWhen a force moves a body over a distance, we say that the force does \nto a system of rigid bodies (e.g., an explosion) or it removes energy from the \nbody is the energy it has simply because of where it is relative to a force ﬁ eld \n(For example, the higher up a body \nE = V + T of an isolated system of bodies is a conserved quantity, meaning that \nor in terms of the linear momentum and velocity vectors:\nAnalogously, the kinetic energy arising from a body’s rotational motion is as ",
      "keywords": [
        "Rigid Body Dynamics",
        "Rigid Body",
        "Body Dynamics",
        "Body",
        "Angular velocity",
        "angular velocity vector",
        "Angular Dynamics",
        "Dynamics",
        "Angular",
        "Rigid",
        "explicit Euler method",
        "Velocity",
        "Linear dynamics",
        "body dynamics simulations",
        "Body Dynamics mass"
      ],
      "concepts": [
        "angular",
        "game",
        "linear",
        "collision",
        "dynamics",
        "objects",
        "forces",
        "physical",
        "physics",
        "vector"
      ],
      "similar_chapters": [
        {
          "book": "Game_Engine_Architecture",
          "chapter": 35,
          "title": "",
          "score": 0.82,
          "base_score": 0.67,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 34,
          "title": "",
          "score": 0.677,
          "base_score": 0.527,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 32,
          "title": "",
          "score": 0.554,
          "base_score": 0.404,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 1,
          "title": "",
          "score": 0.506,
          "base_score": 0.506,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 31,
          "title": "",
          "score": 0.423,
          "base_score": 0.423,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "body",
          "angular",
          "rigid",
          "velocity",
          "rigid body"
        ],
        "semantic": [],
        "merged": [
          "body",
          "angular",
          "rigid",
          "velocity",
          "rigid body"
        ]
      },
      "topic_id": 4,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.2951911985648434,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:57.760255+00:00"
      }
    },
    {
      "chapter_number": 34,
      "title": "Segment 34 (pages 673-695)",
      "start_page": 673,
      "end_page": 695,
      "summary": "Most real-time rigid body \nz The collision force acts over an inﬁ nitesimally short period of time, turn-\nthe bodies to change instantaneously as a result of the collision.\nz There is no friction at the point of contact between the objects’ surfaces.\nbodies during the collision is normal to both surfaces—there is no tan-\nThe bodies will stick together aft er the collision, continuing to \nSo for two bodies 1 and 2, we can write\nRigid Body Dynamics\nCollision and Rigid Body Dynamics\nprimed kinetic energy sum becomes zero, and the bodies stick together aft er \nalized impulse to the two bodies.\nin the velocity of the body to which it is applied.\nHence, the momenta of the two bodies aft er the \ntive velocities of the bodies before and aft er the collision.\nthat the bodies cannot rotate yields\nBody 1\nBody 2\nIn a frictionless collision, the impulse acts along a line normal to both surfaces \nthe other body’s velocity vector about the contact normal, as we’d expect:\ncontact on the two bodies rather than the velocities of their centers of mass, \nAnother approach to collision response is to introduce imaginary forces called \natt ached to the contact points between two bodies that have just interpenetrat-\nThey also work well when three or more bodies \nRigid Body Dynamics\nCollision and Rigid Body Dynamics\nUsing Constraints to Resolve Collisions\nous kinds of constraints to be imposed on the motion of the bodies in the \nIf collisions are treated as constraints that disallow object in-\nFriction is a force that arises between two bodies that are in continuous con-\nthe friction that acts instantaneously at the point of contact when two bodies \nobject is just the force due to gravity , G = mg, which is always directed down-\nThe force of friction f is proportional to the normal component of the object’s \nRigid Body Dynamics\nCollision and Rigid Body Dynamics\nframe (e.g., if we know the object was sliding along a surface and a contact \nTo optimize performance, most physics engines allow dynamic objects \ntemporarily, although sleeping objects are still active from a collision stand-\nIf any force or impulse begins acting on a sleeping object, or if the object \nz The body is supported .\nz The body’s linear and angular momentum are below a predeﬁ ned thresh-\nz The total kinetic energy of the body (T =\nz The motion of a body that is about to go to sleep might be progressively \nal rigid bodies.\nRigid Body Dynamics\nCollision and Rigid Body Dynamics\nAn unconstrained rigid body has six degrees of freedom (DOF): It can trans-\nother most common kinds of constraints typically provided by a physics SDK.\npoint on body A \non body B.\nA stiff spring constraint requires that a point on body A be separated from a \nPrismatic constraints act like a piston: A constrained body’s motion is restrict-\nRigid Body Dynamics\nCollision and Rigid Body Dynamics\nThe bodies move along the line \nLong chains of linked bodies are sometimes diﬃ  cult to simulate in a stable \nconstraint solver how the objects are connected.\nA rag doll is a physical simulation of the way a human body might move \nby linking together a collection of rigid bodies, one for each semi-rigid part \nof the body.\nThe rigid bodies in a rag doll are connected to one another via constraints.\nRag doll constraints are specialized to mimic the kinds of motions the joints in \nand rotations of the rigid bodies, and use this information to drive the posi-\nthe rigid bodies in the rag doll and the joints in the animated skeleton —the \nskeleton usually has more joints than the rag doll has bodies.\nneed a system that can map rigid bodies to joints (i.e., one that “knows” to \nwhich joint each rigid body in the rag doll corresponds).\ntional joints between those that are being driven by the rag doll bodies, so the \ntations of the rigid bodies in the rag doll.\nforces or torques, a rigid body representing the lower arm can be made to exactly track the \nRight: if an obstacle blocks the motion of the body, it \nRigid Body Dynamics\nCollision and Rigid Body Dynamics\nforces or torques, the rigid bodies will exactly track the motion of the elbow \nthe lower arm comes in contact with an immovable object), then these forces \nControlling the Motions of Rigid Bodies\nMost game designs call for a degree of control over the way rigid bodies move \ngravity and in response to collisions with other objects in the scene.\nz An air vent applies an upward force to any object that enters its shaft  of \nz The ﬂ ow of a river creates a force ﬁ eld that causes objects ﬂ oating in the \na number of ways to exert control over the bodies in the simulation.\nAny number of forces can be applied to the bodies in a game physics simula-\nimpulses to bodies.\nThe Collision/Physics Step\nimplementing a collision and physics system, let’s take a brief look at how \nEvery collision/physics engine performs the following basic tasks during \nRigid Body Dynamics\nCollision and Rigid Body Dynamics\nThe forces and torques acting on the bodies in the physics world are \n(The bodies normally keep track of their contacts \nthe simulation, the collision engine need only determine whether any \nCollisions are resolved, oft en by applying impulses or penalty forces \nAt the conclusion of step 4, some of the bodies may have moved away from \nonly 2 through 4, depending on how collisions and constraints are resolved) \nthe actual positions and rotations of the bodies in the physics world and their \nof a single pair of bodies connected by a single constraint.\nforms for the two bodies.\nbodies in such a way as to minimize or eliminate it.\nbodies in the system, the second iteration of the step should discover no new \nally goes on in a physics/collision engine every frame.\nRigid Body Dynamics\nCollision and Rigid Body Dynamics\nface points between the collision/physics engine and the rest of the game code.\nThe Linkage between Game Objects and Rigid Bodies\nThe rigid bodies and collidables in the collision/physics world are nothing \nUsually, we don’t draw the rigid bodies directly \nInstead, the rigid bodies are used to describe \nSo the linkage between a rigid body in the \nIn general, a game object is represented in the collision/physics world by \nzero or more rigid bodies.\nz Zero rigid bodies.\nGame objects without any rigid bodies in the phys-\nRigid Body / \nObject\nRigid bodies are linked to their visual representations by way of game objects.\nAn optional direct rendering path is usually provided so that the locations of the rigid bodies \nThis scenario can also apply to objects whose collision \nz One rigid body.\nMost simple game objects need only be represented by a \nsingle rigid body.\nIn this case, the shape of the rigid body’s collidable is \nresentation, and the rigid body’s position and orientation exactly match \nthe position and orientation of the game object itself.\nz Multiple rigid bodies.\nSome complex game objects are represented by \nmultiple rigid bodies in the collision/physics world.\nSuch game objects usually make use of a skeleton (i.e., a \nbodies are usually linked to the joints of the skeleton in such a way that \nthe position and orientation of each rigid body corresponds to the posi-\nbe driven by an animation, in which case the associated rigid bodies \ndrive the locations of rigid bodies and hence indirectly control the loca-\nThe mapping from joints to rigid bodies may or may \ntion, while others are linked to rigid bodies.\nThe linkage between game objects and rigid bodies must be managed by \nTypically, each game object will manage its own rigid \ntween each rigid body’s location and the location of the game object and/or \nFor complex game objects consisting of multiple rigid bodies, \nthe game objects from the nitt y-gritt y details of managing a collection of rigid \nbodies and allows diﬀ erent kinds of game objects to manage their rigid bodies \nPhysics-Driven Bodies\nIf our game has a rigid body dynamics system, then presumably we want \nthe motions of at least some of the objects in the game to be driven entirely \nIntegrating a Physics Engine into Your Game\nCollision and Rigid Body Dynamics\nSuch game objects are called physics-driven objects.\nand shell casings—these are all examples of physics-driven objects.\nA physics-driven rigid body is linked to its game object by stepping the \nsimulation and then querying the physics system for the body’s position and \nThis transform is then applied either to the game object as a whole \nor to a joint or some other data structure within the game object.\nWhen physics-driven rigid bodies are linked to the joints of a skeleton, the \nto create two totally separate rigid bodies in the collision/physics world.\nrigid body for the safe’s housing is att ached to the root joint in the skeleton, \nand the door’s rigid body is linked to the door joint.\nadded to the physics world to ensure that the door body swings properly \nrelative to the housing when the dynamics of the two rigid bodies are simu-\nThe motions of the two rigid bodies representing the housing and the \nlocations of the rigid bodies within the physics world.\nbroken, and impulses can be applied to the rigid bodies to send them ﬂ y-\nBut in reality, it’s still a single game object and \na single triangle mesh with two joints and two rigid bodies.\nGame-Driven Bodies\nIn most games, certain objects in the game world need to be moved about in \nWe oft en want these objects to participate in collision \ndetection—to be capable of pushing the physics-driven objects out of their \nTo accommodate such objects, most physics SDKs \nprovide a special type of rigid body known as a game-driven body.\nGame-driven bodies do not experience the eﬀ ects of gravity.\na mass of zero, since this is an invalid mass for a physics-driven body).\nassumption of inﬁ nite mass ensures that forces and collision impulses within \nthe simulation can never change the velocity of a game-driven body.\nTo move a game-driven body around in the physics world, we cannot \nthe corresponding game object.\na physics-driven body might ﬁ nd itself suddenly interpenetrating a game-\ndriven body, but it would have no information about the game-driven body’s \nmomentum with which to resolve the collision.) As such, game-driven bodies \na game-driven body, we do have to be careful to zero out its velocity when it \nNo rigid body is required for the dial, however, unless of course \nits rigid bodies can be put into game-driven mode.\nthe joints, which in turn drive the rigid bodies.\nblown oﬀ , we can switch the rigid bodies into physics-driven mode, break the \nhinge constraint, apply the impulse, and watch the door ﬂ y.\nIntegrating a Physics Engine into Your Game\nCollision and Rigid Body Dynamics\nFixed Bodies\nMost game worlds are composed of both static geometry and dynamic objects.\nvide a special kind of rigid body known as a ﬁ xed body.\nFixed bodies act a bit \nlike game-driven bodies, but they do not take part in the dynamics simulation \nThey are, in eﬀ ect, collision-only bodies.\nIn Havok, all types of rigid body are represented by instances of the class hkp\nmotion type tells the system whether the body is ﬁ xed, game-driven (what \nIf a rigid body is created with the ﬁ xed motion type, its type can never be \nOtherwise, the motion type of a body can be changed dynamically at \nor throws the object, it would be changed to physics-driven so the dynamics \nthe inertia tensor of a dynamic body.\nUsing the body’s motion type, Havok can decide \nThe physics simulation must of course be updated periodically, usually once \nintegrating, resolving collisions, and applying constraints).\ntween the game objects and their rigid bodies must be maintained as well.\nthe game needs to apply any forces or impulses to any of the rigid bodies, this \nupdate the physics simulation:\nz Update game-driven rigid bodies .\nbodies in the physics world are updated so that they match the trans-\nforms of their counterparts (game objects or joints) in the game world.\nwith no corresponding rigid body.\nthe physics step, so that they will be in the right places when collision \nz Update forces, apply impulses, and adjust constraints.\nintegrating the equations of motion to ﬁ nd the physical state of all bodies \nremove contacts from all rigid bodies in the physics world, resolving col-\nz Update physics-driven game objects .\nobjects are extracted from the physics world, and the transforms of the \ncorresponding game objects or joints are updated to match.\nies and apply forces and impulses prior to the step, so that the eﬀ ects will \nLikewise, physics-driven game objects should \nIntegrating a Physics Engine into Your Game\nCollision and Rigid Body Dynamics\nrun our collision queries (ray and shape casts) aft er the physics step has run \ncations of any game-driven physics bodies have been determined.\nquery prior to the physics step (returning collision information from the \nz Run the query aft er the physics step.\nIn this example, our game objects are updated in three phases: once before an-\nz The locations of all game-driven rigid bodies are generally updated in \ndriven body’s transform is set to match the location of either the game \nz The location of each physics-driven rigid body is generally read in \ngame object or one of the joints in its skeleton.\nIt’s usually a good idea to step your physics/collision SDK with an \nIntegrating a Physics Engine into Your Game",
      "keywords": [
        "rigid body dynamics",
        "rigid body",
        "rigid bodies",
        "body dynamics",
        "body",
        "bodies",
        "rigid",
        "Collision",
        "Game Objects",
        "game",
        "physics",
        "objects",
        "constraint",
        "game-driven rigid bodies",
        "physics engine"
      ],
      "concepts": [
        "collision",
        "collisions",
        "bodies",
        "objects",
        "constraints",
        "game",
        "forces",
        "physics",
        "physical",
        "updates"
      ],
      "similar_chapters": [
        {
          "book": "Game_Engine_Architecture",
          "chapter": 33,
          "title": "",
          "score": 0.677,
          "base_score": 0.527,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 35,
          "title": "",
          "score": 0.563,
          "base_score": 0.413,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 32,
          "title": "",
          "score": 0.39,
          "base_score": 0.24,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "bodies",
          "rigid",
          "body",
          "rigid bodies",
          "rigid body"
        ],
        "semantic": [],
        "merged": [
          "bodies",
          "rigid",
          "body",
          "rigid bodies",
          "rigid body"
        ]
      },
      "topic_id": 4,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.1381462321457794,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:57.760286+00:00"
      }
    },
    {
      "chapter_number": 35,
      "title": "Segment 35 (pages 696-718)",
      "start_page": 696,
      "end_page": 718,
      "summary": "Collision and Rigid Body Dynamics\nOne option is to run the physics/collision engine in a dedicated thread .\ngame object doesn’t update its game-driven rigid bodies in time, the physics \nif the simulation isn’t quite done by the time we want to update our physics-\ndriven objects, the game objects might end up using out-of-date locations as \nthe physics simulation to begin each frame (aft er all game-driven rigid bodies \nis complete (thereby allowing physics-driven bodies to be queried).\nTo manage access to the collision/physics world by multiple threads, phys-\nany time during the game loop (during which the world is locked for read) \nThis is because while a game engine typically only needs to step the \nphysics simulation once per frame, collision queries may be required at many \ndiﬀ erent points during the game loop.\nGame Loop\nGame Loop\ning the game loop.\nExample Uses of Collision and Physics in a Game\nhigh-level look at a few common examples of how collision and/or physics \nsimulations are commonly used in real games.\nIntegrating a Physics Engine into Your Game\nCollision and Rigid Body Dynamics\nSimple Rigid Body Game Objects\nMany games include simple physically simulated objects like weapons, rocks \nSuch objects might be implemented by \ncreating a custom game object class and giving it a reference to a rigid body \nand physics, allowing this feature to be added to virtually any type of game \nobject in the engine.\nSimple physics objects usually change their motion type at runtime.\nare game-driven when being held in a character’s hand and physics-driven \nit game-driven when at rest and change it to physics-driven when hit?\ndepends largely on the game design.\nthe object is allowed to be knocked down, then we might go the game-driven \nand projectiles of one form or another are a big part of most games.\nweapon is ﬁ red, we shoot oﬀ  a ray cast, determine what object was hit, and \nIf these details are important to the game, \ncollision/physics world over time.\nor just over the edge of some other object and yet the collision geometry \nﬁ er of the game object to which it corresponds.\nGrenades in games are sometimes implemented as free-moving physics objects.\nSome game teams actually go so far as to manage the grenade’s motion en-\nWhen the grenade is thrown, the game moves it along its arc and can then \nIn a game, an explosion typically has a few components: some kind of visual \nIntegrating a Physics Engine into Your Game\nCollision and Rigid Body Dynamics\nDestructible objects are commonplace in many games.\nHowever, we can also implement breakable objects using rigid body dynamics.\nmodel the object as separate pieces at all times.\nFor example, we may want to deﬁ ne the structure of the object.\nobjects.\nthe game-driven motion type.\na ball that rolls around in an imaginary game world.\nFor this kind of game, \nIn character-based games, however, we usually don’t take this kind of ap-\nusually model characters as a set of game-driven capsule-shaped rigid bodies, \nsuch as when a character’s arm bumps an object oﬀ  a table.\nbodies are game-driven , they won’t avoid interpenetrations with immovable \nobjects in the physics world, so it is up to the animator to ensure that the char-\nTo move the character around in the game world, most games use sphere \nIntegrating a Physics Engine into Your Game\nCollision and Rigid Body Dynamics\n(most games have a cut-oﬀ  angle aft er which the character will slide \nthat can be used by the game to make movement decisions.\nIn many games, the camera follows the player’s character or vehicle around \nin the game world, and it can oft en by rotated or controlled in limited ways \nby the person playing the game.\nIt’s important in such games to never permit \nthe collision engine in many games.\nmuch eﬀ ort can be involved, many game teams have a dedicated engineer \nIn a third-person game, you can zoom all the way in to a \nIntegrating a Physics Engine into Your Game\nCollision and Rigid Body Dynamics\nz Some games allow the camera to move along an arc lying in a vertical \ninto collision with objects in the world, it can be automatically moved \nIn some games, the oﬀ ending object becomes translucent ; in \nThis may or may not feel good to the person playing the game!\nquality of your game.\nsues that arise when integrating rag doll physics into your game.\nshape around in the game world.\nGame-driven rigid bodies are some-\nthe character to knock over other objects in the world.\nThe character’s limbs are modeled as capsule-shaped rigid bodies connected \nThe set of rigid bodies used for rag doll physics might not be the same \nis alive, its rigid bodies are game-driven, so we don’t care if they interpen-\nquite common for characters to have entirely diﬀ erent collision/physics repre-\nscious (i.e., when their rigid bodies are game-driven).\nbodies might be inside another solid object when the character transitions to \nrather wild-looking rag doll behavior in-game.\nvia phantoms or collision callbacks during the game-driven mode so that you \nIntegrating a Physics Engine into Your Game\nCollision and Rigid Body Dynamics\nin-game.\nAll in all, gett ing rag doll physics to work in your game isn’t particularly \nin game programming, it’s a good idea to budget plenty of time for trial and \nrange of physics-driven eﬀ ects in a game.\nGames have been doing water \ngame teams and researchers are pushing the limits of these simulations, \nWe’ve learned that a game engine is a complex, layered soft -\ntween shapes; how the physics simulation causes objects to move in physi-\ncally realistic ways; how the animation system allows characters and objects \nhave a game!\nA game is deﬁ ned not by its technology but by its gameplay .\nThe term game mechan-\nexist within the game’s virtual world, and the overall ﬂ ow of the gaming expe-\nIn many games, these elements are intertwined with a com-\nSheﬃ  eld refer to the collection of soft ware systems used to implement game-\nplay as a game’s G-factor .\ntools and engine systems that deﬁ ne and manage the game mechanics (a.k.a.\ngameplay, a.k.a. G-factor) of a game.\nAnatomy of a Game World\nGameplay designs vary widely from genre to genre and from game to game.\ngames out there that do not ﬁ t neatly into this mold.\nThis breakdown of the game world is illus-\ngame.\nthe game plays out.\nThe term game state refers to \nthe current state of all dynamic game world elements, taken as a whole.\nThe ratio of dynamic to static elements also varies from game to game.\nMost 3D games consist of a relatively small number of dynamic elements mov-\nOther games, like \nof a game are usually more expensive than the static elements in terms of CPU \nresources, so most 3D games are constrained to a limited number of dynamic \nmore “alive” the game world can seem to the player.\nAs gaming hardware \nelements in a game world is oft en a bit blurry.\nFor example, in the arcade game \nplaced into the game world and positioned by a game designer independently \nA typical game world is comprised of both static and dynamic elements.\nAnatomy of a Game World\nDiﬀ erent game engines draw \nGames with destructible environments are an example of how the line \nbetween the static and dynamic elements in a game world can blur.\nmethodologies change and adapt to the needs of the game design.\nThe geometry of a static world element is oft en deﬁ ned in a tool like Maya.\nthe game world, at diﬀ erent locations and orientations, in order to provide the \nly useful for rapidly blocking out the contents of a game world.\nWhen a game takes place in a very large virtual world, it is typically divided \nmost a handful, of chunks at any given moment while playing the game, and \nhe or she progresses from chunk to chunk as the game unfolds.\nMany game worlds are divided into chunks for various reasons, including memory \nlimitations, the need to control the ﬂ ow of the game through the world, and as a division-of-\nAnatomy of a Game World\nthen, game designs have branched out in many directions, and linear level-\nbased games are much less common today.\nSome games are essentially still \nOther games use a star topology, in which the \ngame.\nHigh-Level Game Flow\nA game’s high-level ﬂ ow deﬁ nes a sequence, tree, or graph of player objectives .\nto world chunks), or waves (if the game is primarily about defeating hordes of \nIn a story-driven game, this ﬂ ow might also include various \nin-game movies that serve to advance the player’s understanding of the story \nEarly games mapped the objectives of the player one-to-one to particular \none-to-one mapping between world chunks and objectives is less popular in \nmodern game design.\nEach objective is associated with one or more world \nThis kind of design oﬀ ers the ﬂ exibility to alter game objectives and \nMany games group their \nGame Objects\nThe dynamic elements of a game are usually designed in an object-oriented \nThis approach is intuitive and natural and maps well to the game de-\ndynamic objects moving about in the game.\nbe able to create and manipulate these elements in the game world editor .\nterm game object (GO) to refer to virtually any dynamic element within a game \nGame objects are commonly referred to as entities, actors, or agents, and the \nObjective 1 A\nObjective 2 A\nObjective 2 I\neach one maps to one or more game world chunks.\nImplementing Dynamic Elements: Game Objects\nAs is customary in object-oriented design, a game object is essentially a \nGame objects are usually \n(Note that if a game object’s behavior is data-\nexample, the game of Pac-Man involves four game object types: ghosts, pellets, \nmost game engines support it in some form.\nGame Object Models\nIn this book, we will use the term game object model to describe the facili-\nties provided by a game engine in order to permit the dynamic entities in the \nvirtual game world to be modeled and simulated.\nIn this sense, the term game \nz A game’s object model is a speciﬁ c object-oriented programming inter-\nset of entities that make up a particular game.\nz Additionally, a game’s object model oft en extends the programming \nIf the game is implemented ",
      "keywords": [
        "game",
        "game world",
        "game object",
        "Rigid Body Dynamics",
        "Physics",
        "world",
        "object",
        "character",
        "Collision",
        "game object model",
        "term game object",
        "dynamic elements",
        "Rigid Body",
        "dynamic game world",
        "physics engine"
      ],
      "concepts": [
        "games",
        "gaming",
        "objects",
        "objectives",
        "collision",
        "collisions",
        "physics",
        "character",
        "dynamics",
        "thread"
      ],
      "similar_chapters": [
        {
          "book": "Game_Engine_Architecture",
          "chapter": 33,
          "title": "",
          "score": 0.82,
          "base_score": 0.67,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 34,
          "title": "",
          "score": 0.563,
          "base_score": 0.413,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 39,
          "title": "",
          "score": 0.498,
          "base_score": 0.498,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 32,
          "title": "",
          "score": 0.484,
          "base_score": 0.334,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 17,
          "title": "",
          "score": 0.482,
          "base_score": 0.482,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "physics",
          "rigid",
          "world",
          "game driven",
          "collision"
        ],
        "semantic": [],
        "merged": [
          "physics",
          "rigid",
          "world",
          "game driven",
          "collision"
        ]
      },
      "topic_id": 4,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.26020961351741717,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:57.760320+00:00"
      }
    },
    {
      "chapter_number": 36,
      "title": "Segment 36 (pages 719-740)",
      "start_page": 719,
      "end_page": 740,
      "summary": "object-oriented language like C++, advanced features like reﬂ ection, per-\nA game object model \ngame engine might combine a compiled programming language such as \nThe object model presented to the designers via the world editor (discussed \nbelow) needn’t be the same object model used to implement the game at run-\nz The tool-side game object model might be implemented at runtime us-\ning a language with no native object-oriented features at all, like C.\nobjects.\nTherefore, a game really has two distinct but closely interrelated object models:\nz The tool-side object model is deﬁ ned by the set of game object types seen by \nz The runtime object model is deﬁ ned by whatever set of language con-\nthe tool-side object model at runtime.\nThe runtime object model might \nIn some game engines, the line between the tool-side and runtime designs \ncreep up into the tool-side design, and game designers must be cognizant of \nthe performance and memory consumption impacts of the game worlds they \nImplementing Dynamic Elements: Game Objects\nvirtually all game engines have some form of tool-side object model and a cor-\nresponding runtime implementation of that object model.\nData-Driven Game Engines\nWhen the behavior of a game \nTools must be provided to allow game designers and art-\nmust also be provided in-game to allow artists and designers to preview their \nEvery game engine should have some data-driven components, but a \nEinstein, everything in a game engine should be made as simple as possible, \nThe Game World Editor\nis the game world editor —a tool (or a suite of tools) that permits game world \nAll commercial game engines have some kind of world editor tool.\nThe game world editor generally permits the initial states of game objects \nMost game world editors \nobjects in the game world.\nThe Game World Editor\neven allow entirely new types of game objects to be deﬁ ned, with litt le or no \nTypical Features of a Game World Editor\nThe design and layout of game world editors varies widely, but most editors \nThe game world editor typically allows new chunks to \nGame World Visualization\nIt’s important for the user of a game world editor to be able to visualize the \ncontents of the game world .\nAs such, virtually all game world editors provide \nThe Game World Editor\nSome editors provide these world views via a custom rendering engine \ntual game engine and use it to render the 3D perspective view.\nmove around within the game world.\njump around the game world, and so on.\nA game world editor is primarily designed to allow the user to populate a \ngame world with static and dynamic elements.\nallow a single object to be selected at a time, while more-advanced editors \nthat objects can be found and selected by name.\nGame worlds are oft en quite densely populated.\nto select objects in 3D, the editor might allow the user to cycle through all of \nMany editors allow the currently selected object(s) to be tem-\nSome editors also allow objects to be grouped into predeﬁ ned or user-deﬁ ned \ngame world to be organized sensibly.\nWhat’s more, if the game world editor is capable of loading and saving \nThe static and dynamic elements that populate a game world chunk typically \nMost world editors display the att ributes of the currently selected object(s) \nThe Game World Editor\nobjects.\nobject types in the selection.\nThis can still be useful, however, because game \nFor example, most objects \nNormally, the set of properties associated with an object, and the data types of \nthose properties, are deﬁ ned on a per-object-type basis.\nSome object properties are treated in a special way by the world editor.\nFor example, if we change the mesh associated with an object in the world, the \nAs such, the game world editor must have special knowledge of these \nMany world editors provide a host of object placement and alignment \nSpecial Object Types\nJust as some object properties must be handled in a special way by the world ed-\nis not a problem if the editor is in-game or can communicate with the \nThe Game World Editor\nSome game engines restrict regions \nin some form—and every game engine is capable of loading world chunks so \nA good game world editor usually supports some degree of dynamic tweak-\nSome editors run within the game itself, allowing the \nlive connection from the editor to the running game.\ndata to be reloaded dynamically into the running game.\nworld and seeing the eﬀ ects of that change in-game).\nIn some engines, the game world editor is integrated with other aspects of \neditor used to create content for games built on the Unreal Engine.\nis integrated directly into the game engine, so any changes made in the editor \nBut UnrealEd is much more than a game \nThe Game World Editor\nby the game engine.\ngame.\nThe Game World Editor\nost game engines provide a suite of runtime soft ware components that \nbe drawn between the game engine and the game itself, then these systems \nbetween the engine and the game can probably be best visualized as one big \nthe game.\nIn some game engines, one might even go so far as to consider the \ngameplay foundation systems as lying entirely above the engine-game line.\nThe diﬀ erences between game engines are most acute when it comes to the \nEvery game engine approaches the problem of gameplay soft ware design \nz Runtime game object model .\nThis is an implementation of the abstract game \nobject model advertised to the game designers via the world editor .\nz Real-time object model updating .\nIn order to permit the game objects \nin the world to behave autonomously, each object must be updated \nThis is where all of the disparate systems in a game engine \nMost game objects need to communicate \nInter-object messages oft en signal changes in the state of the game world \nProgramming high-level game logic in a language like C or \nteam, a scripting language is oft en integrated into the game engine.\nz Objectives and game ﬂ ow management.\ner’s objectives and the overall ﬂ ow of the game.\njectives, and gates the player from one area of the game world to the \nz Spawning and destroying game objects dynamically.\nin a game world oft en need to come and go during gameplay.\ngame engines provide a system for managing the memory and other re-\nsources associated with dynamically spawned game objects.\ngines simply disallow dynamic creation or destruction of game objects \nEvery game object has some kind of \nMost game objects are \nthat every game object has access to the services of the engine systems \nAt its core, a game engine is a real-\na fancy way of saying that the game engine needs to update the states \nof all the game objects dynamically over time.\nbetween the objects, in part by their dependencies on various engine \nz Ability to deﬁ ne new game object types .\nIt’s important that the game object \nto deﬁ ne a new type of object in an entirely data-driven manner.\nin order to add new game object types.\nTypical game worlds contain hundreds or even \nthousands of individual game objects of various types.\nz Game object queries .\nmeans of ﬁ nding objects within the game world.\nz Game object references .\nMany types of game objects are best modeled \nSome game engines provide the ability for a \ngame object to exist in one of many possible states, each with its own \na particular game object is usually owned and managed by one machine.\nz Saving and loading games / object persistence.\nMany game engines allow \nthe current states of the game objects in the world to be saved to disk \nit might simply be the primary means of loading game world chunks \nRuntime Object Model Architectures\nRuntime Object Model Architectures\nIn the world editor , the game designer is presented with an abstract game \nobject model, which deﬁ nes the various types of dynamic elements that can \nThe runtime object model implementation may or may not bear any re-\nsemblance to the abstract tool-side object model.\ngame object.\nWhatever its design, the runtime object model must provide a \nThe runtime object model is the in-game manifestation of the abstract \ntool-side object model presented to the designers in the world editor.\nz Object-centric.\nIn this style, each tool-side game object is represented at \nThe game world is just a collection of game objects.\nIn this style, each tool-side game object is represented \nThe properties of each game object are distributed across many \ndata tables, one per property type, and keyed by object id (rather than \nThe behavior of a game object is im-\nIn an object-centric game world object architecture, each logical game object \nGame object models needn’t be implemented in an object-oriented language \nsimple game object model consisting of only a few object types:\ntents of a game world (i.e., a single race track).\nto arrays of various kinds of game objects.\nnamic objects in the game were represented by instances of a general-purpose \nstruct called WorldOb_t (i.e., a world object).\na game object as we’ve deﬁ ned it in this chapter.\nand other data common to all of the dynamic objects in the game.\nthe Hydro engine did extend its non-object-oriented language (C) to support \nThe user data pointer permitt ed each type of game object to \ntures common to all world objects.\nworld objects to have polymorphic behaviors (via their “update” functions) \nRuntime Object Model Architectures\nIt’s natural to want to classify game object types taxonomically.\nlead game programmers toward an object-oriented language that supports \nrepresent a collection of interrelated game object types.\nthat the majority of commercial game engines employ a class hierarchy based \nexample, but it illustrates the basic ideas that underlie most game object class ",
      "keywords": [
        "Game World Editor",
        "Game World",
        "game object",
        "game",
        "world editor",
        "game object model",
        "game object types",
        "object",
        "world",
        "object model",
        "game engine",
        "runtime object model",
        "game world object",
        "tool-side game object",
        "editor"
      ],
      "concepts": [
        "game",
        "gaming",
        "object",
        "objectives",
        "engine",
        "engineering",
        "editors",
        "worlds",
        "tool",
        "allows"
      ],
      "similar_chapters": [
        {
          "book": "Game_Engine_Architecture",
          "chapter": 37,
          "title": "",
          "score": 0.585,
          "base_score": 0.585,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 1,
          "title": "",
          "score": 0.526,
          "base_score": 0.526,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 41,
          "title": "",
          "score": 0.514,
          "base_score": 0.514,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 2,
          "title": "",
          "score": 0.502,
          "base_score": 0.502,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 4,
          "title": "",
          "score": 0.477,
          "base_score": 0.477,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "object",
          "world",
          "game world",
          "editor",
          "game object"
        ],
        "semantic": [],
        "merged": [
          "object",
          "world",
          "game world",
          "editor",
          "game object"
        ]
      },
      "topic_id": null,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.3502403538207424,
        "topic_boost": 0.0,
        "timestamp": "2025-12-17T23:05:57.760368+00:00"
      }
    },
    {
      "chapter_number": 37,
      "title": "Segment 37 (pages 741-763)",
      "start_page": 741,
      "end_page": 763,
      "summary": "A game object class hierarchy usually begins small and simple, and in \ngame object types.\nThis kind of hierarchy arises when virtually all classes in the game \nobject model inherit from a single, common base class.\ngame object model is a classic example, as Figure 14.3 illustrates.\nMonolithic class hierarchies tend to cause problems for the game develop-\nclass hierarchies.\nAn excerpt from the game object class hierarchy from Unreal Tournament 2004.\nRuntime Object Model Architectures\nWhen one analyzes a real game’s class hierarchy, one oft en ﬁ nds that \nto accommodate a new type of object whose characteristics were not antici-\ningly logical class hierarchy describing diﬀ erent types of vehicles, depicted in \nFor example, multiple inheritance can lead to an object \ntheir class hierarchies.\nRuntime Object Model Architectures\nWhen a monolithic class hierarchy is ﬁ rst designed, the root class(es) are usu-\nhierarchy, into a base class that is common to all objects that need to ﬂ oat.\nﬂ otation eventually becomes a feature of the root object in the class hierarchy \nFor example, in a game’s \nnique for reducing the width, depth, and complexity of a game’s class hier-\ntionality required by all game objects (e.g., RTTI, reﬂ ection, persistence via \nany game object that has a transform (i.e., a position, orientation, and optional \ngame objects need to be rendered—for example, an invisible TriggerRegion\nObject class provides collision information to its instances.\nObject class grants to its instances the ability to be animated via a skeletal \nRuntime Object Model Architectures\nOne big problem with this class hierarchy is that it limits our design \nchoices when creating new types of game objects.\nobject type that is physically simulated, we are forced to derive its class from \nwant a game object class with collision, it must inherit from Collidable even \nObject.\nSuch classes are sometimes called components or service objects.\neach type of game object we create.\nSome component classes correspond \nthetical game object \nclass hierarchy us-\nclasses.\nOur hypothetical game object class hierarchy, re-factored to favor class composi-\nobject.\nIn this revised design, the GameObject class acts like a \nresents the collision geometry of a game object and provides its GameObject\nIn this kind of design, it is typical for the “hub” class to own its components, \nEach unique type of game object is deﬁ ned as a \nderived class of GameObject.\nIn this design, the hierarchy of classes derived from GameObject serves \nas the primary taxonomy for the kinds of objects we want in our game, and the \ncomponent classes serve as optional add-on features.\nclass GameObject\nRuntime Object Model Architectures\n// derived classes.\nthe root game object class with a generic linked list of components.\nobject class to be largely oblivious to the component types that are available \ning the game object class in many cases.\nIt also allows a particular game object \nA linked list of components can provide ﬂ exibility by allowing the hub game ob-\nRuntime Object Model Architectures\npointers to each component existed within the game object class.)\nthan a hard-coded component model because the game object code must be \nThe component classes can likewise make no \nthe context of a particular game object.\nGameObject class into various component classes.\ngive each component a copy of the game object’s unique id.\nof deﬁ ning the various concrete types of game objects our game needs and \nIn a pure component model, a logical game object is comprised of many compo-\nin which we deﬁ ne factory classes, one per game object type, with a virtual \neach game object type.\ngame object types are deﬁ ned in a text ﬁ le that can be parsed by the engine \nwe need an eﬃ  cient way for the components making up a single game object \nthe other components using the game object’s unique id.\nIn the same sense, sending messages from one game object to another \nthat make up the game object in question.\nPure component models can and have been made to work on real game \nguage tend to think naturally in terms of objects that contain att ributes (data \nz Object1\nz Object2\nRuntime Object Model Architectures\nz Object3\nthan the objects.\nWe deﬁ ne the set of all properties that a game object might \nproperty corresponding to each game object that has it.\nObject1 = (0, 3, 15)\nObject2 = (–12, 0, 8)\nObject1 = (0, 43, 0)\nObject3 = (0, –87, 10)\nObject2 = 15\nProperty-centric object models have been used very successfully on many \nobject model.\nalone table), with the game objects’ unique id as the primary key.\nobject-oriented design, an object is deﬁ ned not only by its att ributes, but also \nImplementing Behavior via Property Classes\nEach type of property can be implemented as a property class.\na particular game object is determined by the aggregation of the behaviors of \nFor example, if a game object contains an instance of the Health property, \nThe Health object can \nrespond to any att acks made on the game object by decrementing the object’s \nA property object can also communicate with other \nproperty objects within the same game object to produce cooperative behav-\nthereby allowing the game object to play a suitable hit reaction animation.\nSimilarly, when the Health property detects that the game object is about to \nbase-like tables and use script code to implement a game object’s behaviors.\nery game object could have a special property called something like ScriptId, \nScript code could also be used to allow a game object to respond \nIn some property-centric engines, a core set of hard-coded property classes \nare provided by the engineers, but a facility is provided allowing game design-\ntric design, which isn’t quite the same as a property object.\nHowever, property objects are very closely related to components in many \nIn both designs, a single logical game object is made up of multiple sub-\nobjects.\ncentric design, each subobject deﬁ nes a particular att ribute of the game object \netc.), whereas in a component-based (object-centric) design, the subobjects of-\nRuntime Object Model Architectures\nof the day, you’ll have essentially the same result—a logical game object that is \ndata that is actually in use (i.e., there are never game objects with unused \ngame, because there are no game object class deﬁ nitions to be changed.\nA property-centric design can also be more cache-friendly than an object-\n(Note that we wouldn’t really implement a game object model \ntyped data, rather than a single array of complex objects.)\nstatic const U32 MAX_GAME_OBJECTS = 1024; \nGameObject g_aAllGameObjects[MAX_GAME_OBJECTS];\n[MAX_GAME_OBJECTS];\n[MAX_GAME_OBJECTS];\n[MAX_GAME_OBJECTS];\n[MAX_GAME_OBJECTS];\nample, when a game object is just a grab bag of properties, it becomes much \nﬁ ne-grained behaviors of a group of property objects.\nto debug such systems, as the programmer cannot slap a game object into \nz Rob Fermier, “Creating a Data Driven Engine,” Game Developer’s Con-\nz Scott  Bilas, “A Data-Driven Game Object System,” Game Developer’s \nhtt p://www.drizzle.com/~scott b/gdc/game-objects.\nRuntime Object Model Architectures\nsentation of the game objects within that chunk.\nA game object is deﬁ ned by \nits att ributes and its behaviors, and an object’s behaviors are determined either \nIn an object-centric design, the object’s type \nIn a property-centric design, a game object’s behavior is deter-\ndetermines which properties the object should have (or one might say that an \nobject’s properties deﬁ ne its type).\nSo, for each game object, a world chunk \nz The initial values of the object’s att ributes.\nstate of each game object as it should exist when ﬁ rst spawned into the \ngame world.\nAn object’s att ribute data can be stored in a number of dif-\nz Some kind of speciﬁ cation of the object’s type.\nIn an object-centric engine, \nwhich the object is comprised.\nOne way to store a collection of game objects into a disk ﬁ le is to write a binary \nimage of each object into the ﬁ le, exactly as it looks in memory at runtime.\nThis makes spawning game objects trivial.\nOnce the game world chunk has \nswap the data within each class instance.\nject image format is not usually a good choice for storing game object data \nSerialized Game Object Descriptions\nSerialization is another means of storing a representation of a game object’s in-\nto implement than the binary object image technique.\nTo serialize an object out \nto disk, the object is asked to produce a stream of data that contains enough \nWhen an object is \nobject instances to and from an XML text format.\nobject serialization system here, but we’ll describe the data format and a few \nSerialization data isn’t a binary image of the object.\ngame objects.\n“know” how to serialize the att ributes of that particular class.\nz We can implement a reﬂ ection system for our C++ classes.\nmation about the name of the class, what data members it contains, the types \nThis can be done by encapsulating a class’s data \norder to return appropriate reﬂ ection data for that class, by hand-coding a \nreﬂ ection data structure for each class, or via some other inventive approach.\nably includes the name or unique id of each object’s class or type.\nis used to instantiate the appropriate class when the object is serialized into \nmaps each class name/id to some kind of function or functor object that has \nare both deﬁ ned by the runtime implementation of the game object types they \ngame objects, it must either link directly with the runtime game engine code, \nmatch the data layout of the game objects at runtime.\ntightly coupled to the game object’s implementation, but again, the world edi-\ntor either needs to link with runtime game object code in order to gain access \ncode can be broken by abstracting the descriptions of our game objects in an \nFor each game object in a world chunk \na lightweight, data-only representation of a game object that can be used to \ninstantiate and initialize that game object at runtime.\nthe game object’s tool-side type.\npairs that describe the initial att ributes of the game object.\noft en include a model-to-world transform, since most game objects have \nWhen the game \nobject is spawned, the appropriate class or classes are instantiated, as de-\nA spawner can be conﬁ gured to spawn its game object immediately upon \nduring the game.\nSpawners can be implemented as ﬁ rst-class objects, so they \naddition to object att ributes.\nthan spawning game objects.\ngame world.\nObject Type Schemas\nA game object’s att ributes and behaviors are deﬁ ned by its type.\nIn a game \nworld editor that employs a spawner-based design, a game object type can be \nAt runtime, the tool-side object type can be mapped in either a hard-\ncoded or data-driven way to a class or collection of classes that must be instan-\ntiated in order to spawn a game object of the given type.\nAnother subtle point is that the object type schema provides \nSome game engines permit object type schemas to be inherited , much like \nclasses.\nFor example, every game object needs to know its type and must have \na unique id so that it can be distinguished from all the other game objects at \nAs you can well imagine, the number of att ributes in a typical game object \nspeciﬁ ed by the game designer for each instance of each game object type he \nThis permits game designers \nto place “vanilla” instances of a game object type with litt le eﬀ ort but still \nFor example, our game designers might \nAny new Orcs placed into a game world will now have 30 \nengine has access to the object type schema ﬁ le, so that it can read in the at-\nSome engines allow default values to be overridden in derived object \ngame object are simplicity, ﬂ exibility, and robustness.\nis to manage a binary object image with pointer ﬁ x-ups or a custom serialized \nobject format.\nIf a game object encounters key-value \ngame object is unable to ﬁ nd a key-value pair that it needs, it has the option \nSpawners also simplify the design and implementation of the game world \nand object type schemas.\nDesigners can deﬁ ne new game object type sche-\nprogrammer can implement the runtime implementation of these new object \nto immediately provide an implementation of each new object type as it is \nNew object data can exist safely in \nobject model, we need a way to load world chunks into memory and un-\ngame world chunks and other needed assets from disk into memory and to \nengine also needs to manage the spawning and destruction of game objects as \nmemory for the objects and ensuring that the proper classes are instantiated \nfor each game object.\nworlds are loaded and also have a look at how object spawning systems typi-\nresource data that is required across all game levels is loaded at the bott om ",
      "keywords": [
        "game object",
        "game object class",
        "object",
        "game",
        "game object type",
        "game object model",
        "Object Model Architectures",
        "object class",
        "Runtime Object Model",
        "object type",
        "object class hierarchy",
        "Gameplay Foundation Systems",
        "game world",
        "object model",
        "class hierarchy"
      ],
      "concepts": [
        "classes",
        "objects",
        "games",
        "gaming",
        "components",
        "data",
        "designed",
        "types",
        "typed",
        "vehicle"
      ],
      "similar_chapters": [
        {
          "book": "Game_Engine_Architecture",
          "chapter": 36,
          "title": "",
          "score": 0.585,
          "base_score": 0.585,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 3,
          "title": "",
          "score": 0.5,
          "base_score": 0.5,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 2,
          "title": "",
          "score": 0.484,
          "base_score": 0.484,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 39,
          "title": "",
          "score": 0.47,
          "base_score": 0.47,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 38,
          "title": "",
          "score": 0.456,
          "base_score": 0.456,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "object",
          "game object",
          "class",
          "object type",
          "property"
        ],
        "semantic": [],
        "merged": [
          "object",
          "game object",
          "class",
          "object type",
          "property"
        ]
      },
      "topic_id": null,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.32032328259125853,
        "topic_boost": 0.0,
        "timestamp": "2025-12-17T23:05:57.760405+00:00"
      }
    },
    {
      "chapter_number": 38,
      "title": "Segment 38 (pages 764-785)",
      "start_page": 764,
      "end_page": 785,
      "summary": "thing, the player only sees the game world in discrete chunks—there is no \nloaded, there is no game world in memory.\nto continue playing the game while the next world chunk and its associated \nmemory that we’ve set aside for game world assets into two equally sized \nWe can achieve a similar eﬀ ect by dividing the game world memory into \nduring the initial load there is no game world in memory in which to play.\nHowever, once the player is in the game world, he or she needn’t see a loading \nThe game world was structured as a hub area (the \nGame World Streaming\nLoading and Streaming Game Worlds\nModern game engines support this kind of seamless world by using a \nas needed as the player progresses through the game world.\ncontiguous game world.\ncan divide every game asset, from game world chunks to foreground meshes \nMemory Management for Object Spawning\nOnce a game world has been loaded into memory, we need to manage the pro-\ncess of spawning the dynamic game objects in the world.\nMost game engines \nhave some kind of game object spawning system that manages the instantia-\ntion of the class or classes that make up each game object and handles destruc-\ntion of game objects when they are no longer needed.\nany object spawning system is to manage the dynamic allocation of memory \nfor newly spawned game objects.\ngame objects come in a wide variety of sizes, dynamically allocating them can \nThere are a number of diﬀ erent approaches to game object memo-\nLoading and Streaming Game Worlds\nA game world divided into chunks.\nOff-Line Memory Allocation for Object Spawning\nSome game engines solve the problems of allocation speed and memory frag-\nSuch engines permit game world \nnamic game objects immediately upon loading a chunk.\na “law of conservation of game objects.” No game objects are created or de-\nquirements of all the game objects in a world chunk are (a) known a priori \nThis means that the memory for the game objects can be \nAll game objects are therefore allocated out of the same memory \nused to load the game world and its resources, and they are no more prone \nThere’s no chance that a large group of game objects is going to spawn into the \nworld unexpectedly, and cause the game to run out of memory.\nDynamic object spawning can be simulated by allocating a game object in the \nof game objects of each type that they’ll need when the game world is ﬁ rst \nsupply of health packs, weapons, enemies, or some other kind of game object, \nthey either need to work out a way to recycle their game objects, or they’re \nDynamic Memory Management for Object Spawning\nment than a static game object spawning approach, it can be implemented in \ntypes of game objects (and sometimes even diﬀ erent instances of the same \ntype of object) occupy diﬀ erent amounts of memory, we cannot use our fa-\nOne Memory Pool per Object Type\nIf the individual instances of each game object type are guaranteed to all occu-\nof object we’ll need.\nat runtime, and game objects will fail to spawn.\ncial game engines do successfully employ this kind of memory management \nWe can transform the idea of one pool per game object type into something \nmore workable by allowing a game object to be allocated out of a pool whose \nWhenever we try to allocate a game object, we search for the smallest pool \nLoading and Streaming Game Worlds\nmemory is easy, but because we are moving “live” allocated objects, we need \nthen load up the game at a later time in exactly the state he or she left  it.\ngame system is similar to the world chunk loading system in that it is capable \nof loading the state of the game world from a disk ﬁ le or memory card.\ntems, let’s brieﬂ y compare world chunks to saved game ﬁ les.\nspecify the initial conditions of all dynamic objects in the world, but they also \nA saved game ﬁ le must also store the current state information of the \ngame objects in the world.\nA saved game need not store every detail of every object’s state either.\nthe other game objects, we may only need to store partial state information.\nAs such, saved game ﬁ les tend to be much smaller than world chunk ﬁ les and \nthe size of a saved game ﬁ le as small as possible.\nedge about the state of the game is saved in the current world chunk(s) in the \nAs a result, saved game ﬁ les based on check points can be extremely small.\nTo implement this feature, the size of the saved game data ﬁ le must \nwhen the game is loaded again later.\nIn a save anywhere design, a saved game data ﬁ le contains basically the \nbe stored in a saved game ﬁ le is to omit certain irrelevant game objects and to \nLoading and Streaming Game Worlds\nObject References and World Queries\nEvery game object generally requires some kind of unique id so that it can be \ndistinguished from the other objects in the game, found at runtime, serve as a \nhelpful on the tool side, as they can be used to identify and ﬁ nd game objects \nAt runtime, we invariably need various ways to ﬁ nd game objects.\nOnce a game object has been found via a query , we need some way to re-\nobject references.\nz Orphaned objects.\nobject—an object that still occupies memory but is no longer needed or \nall pointers to that object.\noccupied by a valid object but is now free memory.\nMany game engines make heavy use of pointers, because they are by far \nand some game teams turn to more sophisticated kinds of object references, \nFor example, if a game engine relocates allocated data blocks at runtime to \nA smart pointer is a small object that acts like a pointer for most intents and pur-\nBecause a smart pointer is an object, it can contain additional meta-data \nSmart pointers can also help with object lifetime management by cooper-\nobject.\nObject References and World Queries\nA pointer to a single object with one owner.\nA pointer to an array of objects with one owner.\nA pointer to an object whose lifetime is shared by multiple \nA pointer to an array of objects whose lifetimes are \nobjects to which the handles refer.\nhandle table for the address of the object in question and store its index in the \nIf an object is \nWhen an object \nAgain, all existing handles to the object are automatically \nHandles are prone to the possibility of referencing a stale object.\nobject id in each handle.\nThat way, when a handle to object A is created, it con-\nThis allows stale object A handles to continue \nObject References and World Queries\nA handle table contains raw object pointers.\nObject1\nObject2\nObject3\nObject4\nObject5\nHandle to Object 5\nto return null when dereferenced rather than returning a pointer to object B \nObject class itself—this allows us to create new handles to a GameObject\n// and also the object’s handle index, for efficient \n// and hence the maximum number of game objects that can \nstatic const U32 MAX_GAME_OBJECTS = ...;\nstatic GameObject* g_apGameObject[MAX_GAME_OBJECTS];\n// This is our simple game object handle class.\npointer to each game object.\nthat it gives us a ready-made list of all active game objects in the system.\nobjects in the world, for example.\nGame Object Queries\nEvery game engine provides at least a few ways to ﬁ nd game objects at run-\nWe’ll call these searches game object queries .\nto ﬁ nd a particular game object by its unique id.\nObject References and World Queries\nmakes many other types of game object queries.\nz Iterate over all game objects of a certain type.\nz Find all destructible game objects with more than 80% health.\nz Transmit damage to all game objects within the blast radius of an \nFor maximum ﬂ exibility in performing game object queries, we could \nimagine a general-purpose game object database, complete with the ability to \ndata structures that can accelerate speciﬁ c types of game object queries:\nz Finding game objects by unique id .\nPointers or handles to the game objects \nThe game objects \nall game objects of a particular type, maintain a list of all objects within \ngame object queries.\ning our game objects in some kind of spatial hash data structure.\nUpdating Game Objects in Real Time\nmeans of updating the internal state of every game object over time.\nof a game object can be deﬁ ned as the values of all its att ributes (sometimes \ntime-based simulations, a game object’s state describes its conﬁ guration at one \nIn other words, a game object’s notion of time is discrete \nof object i at an arbitrary time t.\nmathematically correct, but it reminds us that a game object’s state acts like \nA game object may very well \nthe game object’s overall state vector S(t).\nphysics, audio, and so on) require periodic updating, and the game object \nVirtually all game engines update game \nobject states as part of their main game loop—in other words, they treat the \ngame object model as just another engine subsystem that requires periodic \nGame object updating can therefore be thought of as the process of de-\nOnce all object states have been updated, the current \nUpdating Game Objects in Real Time\nbehaviors of the game objects to be paused, slowed down, sped up, or even \nof the game.\nAs we mentioned in Chapter 1, a game object updating system is an ex-\nGame object updating systems also exhibit some aspects \nGames are one of the \ngame object updating by studying the wider ﬁ eld of agent-based and discrete \nor two from game engine design as well!\nHowever, as before, most game \nThe simplest way to update the states of a collection of game objects is to \nUpdate(), on each object in turn.\nGame object classes can \ngine employs a monolithic object hierarchy, in which each game object is rep-\nthat makes up each game object, or we could call Update() on the “hub” \nobject and let it update its associated components as it sees ﬁ t.\nFirst, how should we maintain the collection of all game objects?\nMaintaining a Collection of Active Game Objects\nThe collection of active game objects is oft en maintained by a singleton \nThe collection of game objects generally needs to be dynamic, be-\ncause game objects are spawned and destroyed as the game is played.\nlinked list of pointers, smart pointers, or handles to game objects is one simple \ndestroying of game objects; such engines can use a statically-sized array of \ngame object pointers, smart pointers, or handles rather than a linked list.) As \nof their game objects rather than just a simple, ﬂ at linked list.\nA game object’s Update() function is primarily responsible for determining \nthe state of that game object at the current discrete time index Si(t) given its \nMost game objects interact with one or more engine subsystems.\nUpdating Game Objects in Real Time\nthese subsystems directly from within the game object’s Update() function.\nobject:\nGiven that our Update() functions are structured like this, the game loop \ncould be driven almost entirely by the updating of the game objects, like this:\nHowever att ractive the simple approach to object updating shown above \nto update each object’s animation interleaved with other unrelated operations, \nIn most commercial game engines, each engine subsystem is updated di-\nper-game object basis from within each object’s Update() function.\nIf a game \nexample, a game object that wishes to be rendered via a triangle mesh might \nThe game object controls how it is \ngame object does not control the rendering of the mesh instance directly.\nstead, aft er all game objects have had a chance to update themselves, the ren-\nWith batched updating, a particular game object’s Update() function, \nUpdating Game Objects in Real Time\nand reused for many game objects rather than being redone for each \nobject.\neach game object that is processed.\ncal set of calculations on each and every object in the game world.\nproach breaks down when game objects depend on one another.\nUpdating Game Objects in Real Time",
      "keywords": [
        "game object",
        "game",
        "Object",
        "game world",
        "Game Object Queries",
        "Updating Game Objects",
        "game object states",
        "world",
        "Streaming Game Worlds",
        "Gameplay Foundation Systems",
        "update game object",
        "world chunk",
        "game world chunks",
        "memory",
        "game object spawning"
      ],
      "concepts": [
        "object",
        "games",
        "memory",
        "memories",
        "updated",
        "update",
        "data",
        "worlds",
        "engines",
        "chunks"
      ],
      "similar_chapters": [
        {
          "book": "Game_Engine_Architecture",
          "chapter": 39,
          "title": "",
          "score": 0.685,
          "base_score": 0.535,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 40,
          "title": "",
          "score": 0.603,
          "base_score": 0.453,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 18,
          "title": "",
          "score": 0.567,
          "base_score": 0.417,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 12,
          "title": "",
          "score": 0.542,
          "base_score": 0.542,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 37,
          "title": "",
          "score": 0.456,
          "base_score": 0.456,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "object",
          "game object",
          "game objects",
          "objects",
          "world"
        ],
        "semantic": [],
        "merged": [
          "object",
          "game object",
          "game objects",
          "objects",
          "world"
        ]
      },
      "topic_id": 3,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.30539334118516764,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:57.760443+00:00"
      }
    },
    {
      "chapter_number": 39,
      "title": "Segment 39 (pages 786-808)",
      "start_page": 786,
      "end_page": 808,
      "summary": "We must be careful to update the states of our game objects at the right \ndate() function per game object per frame.\nGame objects may depend upon \nFor example, a game object might request that animations be played \nHowever, that same object \nMany game engines allow game objects to update at multiple points \nFor example, an engine might update game objects three \nbe accomplished by providing each game object class with three virtual func-\nWe can provide our game objects with as many update phases as we see \nBut we must be careful, because iterating over all game objects and calling \nAlso, not all game objects \nUpdating Game Objects in Real Time\nthe need to batch animation updates of all game objects together in order to \nThe game objects with no parents (no dependencies on any other object) \nupdate of the game objects and the engine systems, complete with all update \nUpdating Game Objects in Real Time\nLet’s revisit game object updating, but this time thinking in terms of each ob-\nWe said in Section 14.6 that the state of game object i \nWhen we update a game object, \nIn theory, the states of all game objects are updated from time t1 to time \ngame object and call some kind of update function on each one in turn.\ngame objects’ states would have been updated to Si(t2), while the remaining \nto ask two of our game objects what the current time is during the update \nThe states of all game objects are consistent before and aft er the \nThe inconsistency of game object states during the update loop is a major \nThe problem rears its head most oft en when game objects query one \nIn theory, the states of all game objects are updated instantaneously and in \nUpdating Game Objects in Real Time\nIn practice, the states of the game objects are updated one by one.\non-screen as a lack of synchronization between game objects.\nwhich game objects are permitt ed to query one another for state information.\nIf a game object A wants the updated state vector SB(t2) of another object B, then \nobject B must reside in a previously updated bucket.\nOne way to improve consistency is to arrange for each game object to \nOne easy and low-cost way to improve the consistency of game object states \nAny code that queries the state of another game object during \nPresumably every game object \ngame object against the currently updating bucket and assert that they are not \nway in which game object states are updated?\nParallelizing the Game Object Model Itself\nGame object models are notoriously diﬃ  cult to parallelize, for a few reasons.\nGame objects tend to be highly interdependent upon one another and upon \nThis makes it diﬃ  cult to process game object updates in mul-\na foreign game object’s state vector makes it impossible to DMA a game object \nThat said, game object updating can theoretically be done in parallel.\nto ensure that game objects never peek directly into the state vectors of oth-\ner game objects.\nUpdating Game Objects in Real Time\ntween game objects even when those objects reside in totally separate memory \nlevel engine systems upon which the game objects depend.\nto be more performance-critical than the game object model.\nthe amount of CPU power used by the game object model is oft en somewhat \nOf course, using a single-threaded game object model does not mean that \nwhen a game object requires a time-consuming operation to be performed, it \nproceed with other unrelated work, including updating other game objects, \nframe, or next frame, that game object can pick up the results of its request and \napplies to the process of updating game object states as well.\na game object needs to cast 100 rays into the collision world for various pur-\nto update the object’s state this frame.\nGames are inherently event-driven.\nAn event is anything of interest that hap-\nneed a way to (a) notify interested game objects when an event occurs and (b) \narrange for those objects to respond to interesting events in various ways—we \nUpdating Game Objects in Real Time\ncall this handling the event.\nDiﬀ erent types of game objects will respond in dif-\nferent ways to an event.\nThe way in which a particular type of game object re-\nOne simple way to notify a game object that an event has occurred is to sim-\nexplosion goes oﬀ , we could query the game world for all objects within the \nobject.\nevent-handling function, are said to be late-bound .\nOnExplosion() function requires all game objects to inherit from a common \nOnExplosion(), even if not all game objects can respond to explosions.\nfact, using statically typed virtual functions as event handlers would require \nour base GameObject class to declare virtual functions for all possible events \nevents but not others.\nEvery object in the game, in eﬀ ect, “knows” about every \nment an empty, do-nothing event handler function).\nWhat we really need for our event handlers, then, is dynamically typed \nEncapsulating an Event in an Object\nAn event is really comprised of two components: its type (explosion, friend \nstruct Event\nSome game engines call these things messages or commands instead of events.\nThese names emphasize the idea that informing objects about an event is es-\nPractically speaking, event objects are usually not quite this simple.\nmight implement diﬀ erent types of events by deriving them from a root event \nEncapsulating an event (or message) in an object has many beneﬁ ts:\nz Single event handler function.\nBecause the event object encodes its type \ninternally, any number of diﬀ erent event types can be represented by an \nevents (e.g., virtual void OnEvent(Event& event);).\naft er the function returns, an event object stores both its type and its \nAn event object therefore has persistence.\nAn object can forward an event that it receives to \nanother object without having to “know” anything about the event.\nexample, if a vehicle receives a Dismount event, it can forward it to all \nThis idea of encapsulating an event/message/command in an object is com-\nEvent Types\nThere are many ways to distinguish between diﬀ erent types of events.\nEVENT_TYPE_LEVEL_STARTED,\nEVENT_TYPE_PLAYER_SPAWNED,\nEVENT_TYPE_ENEMY_SPOTTED,\nEVENT_TYPE_EXPLOSION,\nEVENT_TYPE_BULLET_HIT,\nFirst, knowledge of all event types in the entire game \nSecond, the event types are hard-coded, \nwhich means new event types cannot easily be deﬁ ned in a data-driven man-\none accidentally adds a new event type in the middle of the list, the indices \nAs such, an enumeration-based event typing system \nAnother way to encode event types is via strings.\nfree-form, and it allows a new event type to be added to the system by merely \nevent system is considered worth the risks by some game teams.\nFor example, a central database of all event type \nevent types to be added to the database.\nfrom adding duplicate event types.\nThe event database \ncould also store meta-data about each type of event, including documentation \nEvent Arguments\nThe arguments of an event usually act like the argument list of a function, pro-\nEvent \nWe might derive a new type of Event class for each unique type of event.\nAnother approach is to store the event’s arguments as a collection of vari-\non the number of arguments that can be passed with an event, but it also side-\nEvent Arguments as Key-Value Pairs\nA fundamental problem with an indexed collection of event arguments is order \nThis problem can be avoided by implementing event arguments as key-\n\"event\"\nThe arguments of an event object can be implemented as a collection of key-value \nThe keys help to avoid order-dependency problems because each event argument is \nEvent Handlers\nWhen an event, message, or command is received by a game object, it needs to \nrespond to the event in some way.\nThis is known as handling the event, and it \nis usually implemented by a function or a snippet of script code called an event \nOft en an event handler is a single native virtual function or script function \nthat is capable of handling all types of events (e.g., OnEvent(Event& event)).\ncascaded if/else-if clause to handle the various types of events that might be \nA typical event handler function might look something like this:\nEVENT_ATTACK:\n// Unrecognized event.\neach type of event (e.g., OnThis(), OnThat(), …).\nabove, a proliferation of event handler functions can be problematic.\nUnpacking an Event’s Arguments\ntract data from the event’s argument list in a type-safe manner.\nevent.GetHealthPack() presumably returns a HealthPack game object, \nby extension, every other type of event argument in the game!) This is prob-\nof the event is always known when the arguments are unpacked.\nGame objects are almost always dependent upon one another in various ways.\nFor example, game objects usually reside in a transformation hierarchy, which \nGame objects might also be made up of multiple interacting components, \ngeneral, we can envision the interrelationships between game objects as one \nGame objects are interrelated in various ways, and we can draw graphs depicting \nEvent1\nEvent3\nEvent2\nIt oft en makes sense to be able to pass events from one object to the next \nthe vehicle, and those passengers may wish to forward the event to the objects \nWhen a multicomponent game object receives an event, it \nOr when an event is received by a character in a sports \nThe technique of forwarding events within a graph of objects is a com-\nmon design patt ern in object-oriented, event-driven programming, sometimes \nUsually, the order in which the event \nThe event is \npassed to the ﬁ rst object in the chain, and the event handler returns a Boolean \nthe event.\n// Now try to handle the event myself.\nEVENT_ATTACK:\nwant to multicast an event to all objects within a radius of inﬂ uence (for an \nforward the event to all of the returned objects.\nRegistering Interest in Events\nIt’s reasonably safe to say that most objects in a game do not need to respond \nto every possible event.\nMost types of game objects have a relatively small set \nof objects and call each one’s event handler, even if the object is not interested \nlinked list of interested game objects for each distinct type of event, or each \nsponds to whether or not the object is interested in a particular type of event.\nBy doing this, we can avoid calling the event handlers of any objects that do \nnot care about the event.\nﬁ ltering objects by interest in an event can greatly improve the eﬃ  ciency of \nEven bett er, we might be able to restrict our original game object query to \ninclude only those objects that are interested in the event we wish to multicast.\nsion events.\nMost game engines provide a mechanism for handling events immediately \nEvent queuing has some at-\nControl Over When Events are Handled\nIf all events \nare handled immediately upon being sent, the event handler functions end \nexample, we might want the event to be handled later in the same frame, next \nnew event of the same type one period into the future .\nAn event is only \nEach frame, the ﬁ rst event on the queue can be inspected and \nif we see an event whose delivery time is now or in the past, we extract it from \n// job is to dispatch all events whose delivery time is \nEvent* pEvent = PeekNextEvent();\n// Dispatch it to its receiver’s event handler.\nEvent Prioritization\nEven if our events are sorted by delivery time in the event queue, the order \nFor example, if two senders request that events be dispatched \nHowever, the needs of every game’s event system are dif-\nSome Problems with Event Queuing\nIn order to implement a queued event system, we need more code, additional \nimplement an immediate event system.\nWith an immediate event handling approach, the data in an event’s arguments \nneed only persist for the duration of the event handling function (and any \nThis means that the event and its argument data can \nevent.\n//    receiver.OnEvent(event);\nThis implies that we must copy the entire event object \nthat we copy not only the event object itself but its entire argument payload as ",
      "keywords": [
        "game objects",
        "event",
        "game",
        "object",
        "Gameplay Foundation Systems",
        "game object states",
        "event object",
        "Updating Game Objects",
        "event types",
        "Game Object Model",
        "event system",
        "event handler",
        "Runtime Gameplay Foundation",
        "Foundation Systems",
        "type"
      ],
      "concepts": [
        "events",
        "gaming",
        "games",
        "objects",
        "time",
        "type",
        "typed",
        "typing",
        "updating",
        "updates"
      ],
      "similar_chapters": [
        {
          "book": "Game_Engine_Architecture",
          "chapter": 40,
          "title": "",
          "score": 0.711,
          "base_score": 0.561,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 38,
          "title": "",
          "score": 0.685,
          "base_score": 0.535,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 18,
          "title": "",
          "score": 0.664,
          "base_score": 0.514,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 1,
          "title": "",
          "score": 0.506,
          "base_score": 0.506,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 17,
          "title": "",
          "score": 0.499,
          "base_score": 0.499,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "event",
          "game objects",
          "object",
          "objects",
          "game object"
        ],
        "semantic": [],
        "merged": [
          "event",
          "game objects",
          "object",
          "objects",
          "game object"
        ]
      },
      "topic_id": 3,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.3289747492555802,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:57.760481+00:00"
      }
    },
    {
      "chapter_number": 40,
      "title": "Segment 40 (pages 809-829)",
      "start_page": 809,
      "end_page": 829,
      "summary": "sending function’s scope, and it permits the event to be stored indeﬁ nitely.\nexample event-sending function shown above still looks basically the same \nwhen using a queued event system, but as you can see in the italicized code \nbelow, the implementation of the Event::Queue() function is a bit more \nevent.\nDeep-copying of event objects implies a need for dynamic memory allocation, \na game engine due to its potential cost and its tendency to fragment memory.\nAs with all dynamic allocation in a game engine, it’s best if we can select \nbut this will only work if all of our event objects are the same size and if their \nIf our event objects and/or their arguments can \nthat event.\ngame loop, to ensure that events are delivered without incurring unwanted \none-frame delays yet still ensuring that game objects are updated in the proper \nﬁ rst (so that the end of the animation can be detected and the event sent), then \nIn a game engine that supports \ncrux of the problem here is that every event handler function must be writt en \nData-Driven Event/Message-Passing Systems\nEvent systems give the game programmer a great deal of ﬂ exibility over and \nmechanisms provided by languages like C and C++.\nwe could make our event system data-driven, we could extend its power into \nthe hands of our game designers.\nThere are many ways to make an event system data-driven.\nthe extreme of an entirely hard-coded (non-data-driven) event system, we \nclasses of object, respond to certain events.\nsome real commercial game engines are implemented in essentially this way.\nAt the other end of the gamut, our engine might provide the game design-\ners with a simple scripting language (a topic we’ll explore in detail in Section \nular kind of game object will respond to a particular kind of event.\nIn a scripted \nscripting language a daunting task.\nintroducing bugs into the game than their engineer counterparts, unless they \nlanguage.\nto an event like “PlayerSpott ed,” the designer could wire up a ﬂ ow chart that \nOne of the problems with converting a function-call-like event system into \na data-driven system is that diﬀ erent types of events tend to be incompat-\nEach of these game object types may already have an event \nEMP gun is not compatible with any of these objects’ event handlers.\nsult, we end up having to implement a new event type, perhaps called “EMP,” \nand then write custom event handlers for every type of game object in order \nand to think solely in terms of sending streams of data from one game object to \nIn such a system, every game object has one or more input ports, to \nThe other game objects in \nto the input ports of these game objects, we can cause the gun to trigger the de-\nProgrammers decide what kinds of port(s) each type of game object will \nbased scripting language are probably prett y obvious: ease of use, a gradual \nScripting\nA scripting language can be deﬁ ned as a programming language whose pri-\nIn the context of game engines, a script-\nAs such, a scripting language can be used by program-\nGame scripting \nz Data-deﬁ nition languages.\nz Runtime scripting languages .\nRuntime scripting languages are intended to \nThese languag-\nof the engine’s game object model and/or other engine systems.\nIn this section, we’ll focus primarily on using a runtime scripting language for \nizing the game’s object model.\nIn our discussion of scripting languages , it will be helpful for us all to be on \nz Interpreted versus compiled languages.\nof an imaginary CPU, and byte code acts like a list of machine language \nplatform and embedded within a host application like a game engine.\nthan the native CPU executes its machine language instructions.\nz Declarative languages.\nexample of a declarative language.\nz Functional languages.\nFunctional languages, which are technically a sub-\ntional language, programs are deﬁ ned by a collection of functions.\nA program is constructed by passing input data from one function to the \nThese languages \nml, Haskell, and F# are examples of functional languages.\nz Procedural versus object-oriented languages.\nstrast, an object-oriented language’s primary unit of program construc-\nIn a reﬂ ective language, information about the data \ntypes, data member layouts, functions, and hierarchical class relation-\nScripting\nTypical Characteristics of Game Scripting Languages\nThe characteristics that set a game scripting language apart from its native pro-\nMost game scripting languages are interpreted by a virtual \nby the CPU, the game engine is aﬀ orded a great deal of ﬂ exibility re-\ngarding how and when script code will be run.\nMost game scripting languages have been designed for \nwhen script code is changed, the eﬀ ects of the changes can usually be \nSome game engines permit script code to be reloaded \nfaster than when making changes to the native language source code.\nScripting languages are oft en customized to \ngame scripting language might provide functions for ﬁ nding game ob-\nworld editor for use by the game designers, or even handling network \nSome Common Game Scripting Languages\nWhen implementing a runtime game scripting system, we have one funda-\nlanguage and customize it to suit our needs, or do we design and implement \nand mature scripting language and extend it with features speciﬁ c to your \ngame engine.\nThere are a great many third-party scripting languages from \nIn the following sections, we’ll explore a number of custom game script-\ning languages and a number of game-agnostic languages that are commonly \nadapted for use in game engines.\nId Soft ware’s John Carmack implemented a custom scripting language for \nvariant of the C programming language with direct hooks into the Quake en-\nand it could be used to send and receive/handle game events.\nScripting \nlanguages and other forms of data-driven customization allow gamers to \nProbably the best-known example of an entirely custom scripting language \nThis language is based on a C++-like syntacti-\nScripting\nrealScript provides a number of extremely powerful game-speciﬁ c features, \nobject-oriented language.\nThis makes data-driven game design extremely easy (as long as Un-\nUnreal networked games, each game object exists in its full form on one \nby the game.\nLua is a well-known and popular scripting language that is easy to integrate \ninto an application such as a game engine.\norg/about.html) calls the language the “leading scripting language in games.”\nand eﬃ  ciently than many other scripting languages.\nThe core Lua language is very small and \nis not an object-oriented language, but OOP support can and has been \nLua is a dynamically typed language, meaning that variables don’t have \nScripting\nLua treats blocks of code, called chunks, as ﬁ rst-class objects that can be \ncellent choice for use as a game scripting language.\nPython is a procedural, object-oriented, dynamically typed scripting lan-\nas a game scripting language.\nThis makes integrating Python with a game’s \na game engine.\nthe functional interface of an object determines its type (rather than being de-\nengine, integrates well with a game’s object model, and can be an excellent \nand powerful choice as a game scripting language.\nPawn is a lightweight, dynamically typed, C-like scripting language created \nan evolution of an earlier subset of the C language called Small-C, writt en by \nScripting\nunique feature makes it a good ﬁ t for many game applications.\nand easy to integrate with a game engine writt en in C.\nsupport can be very useful for game programming.\nhas shown itself to be a viable game scripting language.\nScript code can play all sorts of roles within a game engine.\npossible architectures, from tiny snippets of script code that perform simple \nfunctions on behalf of an object or engine system to high-level scripts that \nhard-coded in the native programming language, but certain key bits of \nbe writt en in a scripting language.\nFor example, when updating game \nobjects during the game loop, the engine might call an optional callback \nfunction that can be writt en in script.\ncustomize the way in which the game object updates itself over time.\nz Scripted event handlers .\nhook function whose purpose is to allow a game object to respond to \nMany game engines allow users to write \nevent handler hooks in script as well as in the native language.\nz Extending game object types, or deﬁ ning new ones, with script .\nSome script-\ning languages allow game object types that have been implemented in \nthe native language to be extended via script.\ntended even to the point of allowing entirely new types of game objects \nclass writt en in script from a class writt en in the native language) or via \nnative game object).\ngame object model, it only makes sense to permit new components or \nThe game object model was \nC++ or Gas Powered Games’ custom scripting language, Skrit (htt p://\nthey had approximately 148 scripted property types and 21 native C++ \nz Script-driven engine systems .\nFor example, the game object model could conceiv-\nably be written entirely in script, calling into the native engine code \nz Script-driven game.\nSome game engines actually ﬂ ip the relationship \nbetween the native language and the scripting language on its head.\nIn these engines, the script code runs the whole show, and the native \ncan be writt en entirely in the Python language, and the native engine \n(implemented in C++) acts like a library that is called by script code.\n(Panda3D games can also be writt en entirely in C++.)\nFeatures of a Runtime Game Scripting Language\nThe primary purpose of many game scripting languages is to implement \ntomizing a game’s object model.\nInterface with the Native Programming Language\nIn order for a scripting language to be useful, it must not operate in a vacuum.\nIt’s imperative for the game engine to be able to execute script code, and it’s \nScripting\nusually equally important for script code to be capable of initiating operations \nA runtime scripting language’s virtual machine is generally embedded \nwithin the game engine.\nThe engine initializes the virtual machine, runs script \ncode whenever required, and manages those scripts’ execution.\nexecution varies depending on the speciﬁ cs of the language and the game’s \nz In a functional scripting language, the function is oft en the primary unit of \nIn order for the engine to call a script function, it must look up \nz In an object-oriented scripting language, classes are typically the prima-\nTherefore, most scripting languages allowing native code to \nspeciﬁ c, but the basic approach is usually to allow certain script functions to \nbe implemented in the native language rather than in the scripting language.\nTo call an engine function, script code simply makes an ordinary function call.\nThe virtual machine detects that the function has a native implementation, \nlanguage, a language called DC, was integrated into the engine.\nChunks of executable code in DC are known as script lambdas , which are the \ninto chunks of byte code, which are loaded into memory when the game runs \nOnce the engine has a pointer to a chunk of script lambda byte code , it can \nexecute the code by calling a function in the engine and passing the pointer to \nof data the script may want to deal with.\nThe virtual machine also supports a function call stack.\nDC can call other script lambdas (i.e., functions) that have been deﬁ ned by \nprogramming language, a stack is needed to keep track of the states of the \na byte code instruction that tells it to call another script lambda, the byte code \nfor that script lambda is looked up by name, a new stack frame is pushed, and \nexecution continues at the ﬁ rst instruction of that script lambda.\nbyte code instruction in the calling script lambda aft er the one that called the \n// the top-level script lambda \"function\" returns).\nScripting\nScripting",
      "keywords": [
        "game scripting language",
        "scripting language",
        "game",
        "language",
        "event",
        "Gameplay Foundation Systems",
        "Game scripting",
        "game object",
        "game engine",
        "Runtime Gameplay Foundation",
        "scripting",
        "code",
        "event system",
        "runtime scripting language",
        "engine"
      ],
      "concepts": [
        "event",
        "languages",
        "games",
        "gaming",
        "scripted",
        "function",
        "functionality",
        "functions",
        "data",
        "code"
      ],
      "similar_chapters": [
        {
          "book": "Game_Engine_Architecture",
          "chapter": 39,
          "title": "",
          "score": 0.711,
          "base_score": 0.561,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 38,
          "title": "",
          "score": 0.603,
          "base_score": 0.453,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 18,
          "title": "",
          "score": 0.594,
          "base_score": 0.444,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 17,
          "title": "",
          "score": 0.491,
          "base_score": 0.491,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 35,
          "title": "",
          "score": 0.475,
          "base_score": 0.475,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "scripting",
          "language",
          "script",
          "scripting language",
          "event"
        ],
        "semantic": [],
        "merged": [
          "scripting",
          "language",
          "script",
          "scripting language",
          "event"
        ]
      },
      "topic_id": 3,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.31283483415737023,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:57.760520+00:00"
      }
    },
    {
      "chapter_number": 41,
      "title": "Segment 41 (pages 830-848)",
      "start_page": 830,
      "end_page": 848,
      "summary": "DC script lambdas can also call native functions—i.e., global functions \nscript programmer may have made when calling the function.\npObject = GameObject::LookUpByName\nGame Object Handles\nScript functions oft en need to interact with game objects, which themselves \nnative language’s mechanisms for referencing objects (e.g., pointers or refer-\nences in C++) won’t necessarily be valid in the scripting language.\nsome reliable way for script code to reference game objects.\nobjects in script via opaque numeric handles .\nThe script code can obtain object \nperform some kind of query, such as asking for the handles of all game objects \nThe script can then perform operations on the game \nScripting\nobject by calling native functions and passing the object’s handle as an argu-\nport in any scripting language that supports integer data.\ndence to the names of the objects in the game’s world editor.\nFor example, in Naughty Dog’s scripting language, the reserved \nname “self” always refers to the object to which the currently-running script is \nThis allows game designers to write a script, att ach it to an object in \nthe game, and then use the script to play an animation on the object by simply \nUsing strings as object handles has its pitfalls, of course.\nthe names of game objects, which can lead to bugs.\nIn addition, script code can \nbe broken if someone changes the name of an object in the game world editor \nbut forgets to update the name of the object in script.\nto work, your scripting language needs to support hashed string ids in some \nIdeally, we’d like the script compiler to convert our strings into hashed \never, this isn’t always possible in all scripting languages.\nto allow the user to use strings in script and convert them into hashed ids at \nEvents are a ubiquitous communication mechanism in most game engines.\npermitt ing event handler functions to be writt en in script, we open up a pow-\nEvents are usually sent to individual objects and handled within the con-\nHence scripted event handlers need to be associated with \nSome engines use the game object type system for this \npurpose—scripted event handlers can be registered on a per-object-type basis.\nThis allows diﬀ erent types of game objects to respond in diﬀ erent ways to the \nscript functions, or they can be members of a class if the scripting language is \nto the particular object to which the event was sent, much as C++ member \nIn other engines, scripted event handlers are associated with individual \nDog’s Uncharted engine, scripts are objects in their own right.\nsociated with individual game objects, they can be att ached to regions (convex \nobjects in the game world.\nEach script can have multiple states (that is, scripts \nWhen a game object receives an event, \ntached script object, and if one is found, the event is sent to that script’s current \nscript simply ignores the event.\nAllowing scripts to handle game events that are generated by the engine is \nsend events from script code either back to the engine or to other scripts.\nfrom script but to deﬁ ne entirely new event types in script.\nTo deﬁ ne a new event type, the script pro-\nor her script code.\nScript A can deﬁ ne a new event type and send it to Script B.\nIf Script B deﬁ nes an event handler for this type of event, we’ve implemented \nIn some game engines, event- or \nin script.\nScripting\nObject-Oriented Scripting Languages\nSome scripting languages are inherently object-oriented.\nport objects directly but provide mechanisms that can be used to implement \nIn many engines, gameplay is implemented via an object-\noriented game object model of some kind.\nform of object-oriented programming in script as well.\nDeﬁ ning Classes in Scripts\nscripting language that permits new data structures to be deﬁ ned, and pro-\nInheritance in Script\nIn the context of game scripting languages, there are two kinds of in-\nscripted classes from native classes.\nIf your scripting language is object-orient-\ntough to implement even if the scripting language supports inheritance.\nscripted classes to derive from native classes in a seamless way.\nIn script, then, all we \nwith objects that have been deﬁ ned in the native programming language.\nexample, a game object could have a pointer to an optional component writ-\nten entirely in script.\nWe can delegate certain key functionality to the script \nThe script component might have an Update() function \nthat is called whenever the game object is updated, and the scripted compo-\nWhen an event is sent to the game object, it calls the \nappropriate event handler on the scripted component, thus giving the script \nimplemented game object.\nScripted Finite State Machines\nstate machines right into the core game object model.\ngame object can have one or more states, and it is the states—not the game \nobject itself—that contain the update function, event handler functions, and \nSimple game objects can be created by deﬁ ning a single state, but more-\ncomplex game objects have the freedom to deﬁ ne multiple states, each with a \nIf your engine supports a state-driven game object model, it makes a lot of \nsense to provide ﬁ nite state machine support in the scripting language as well.\nAnd of course, even if the core game object model doesn’t support ﬁ nite state \nmachine on the script side.\nlanguage by using class instances to represent states, but some scripting lan-\nAn object-oriented scripting \nstates, or it might provide tools that help the script programmer easily aggre-\nif your scripting language provides no such features, you can always adopt a \nscript you write.\nMultithreaded Scripts\nIt’s  oft en useful to be able to execute multiple scripts in parallel.\nscripts can run at the same time, we are in eﬀ ect providing parallel threads of \nexecution in script code, much like the threads provided by most multitasking \nMost scripting systems that provide parallelism do so via cooperative \nanother script.\nScripting\nanother script to execute.\nscripts to explicitly go to sleep, waiting for something relevant to happen.\nwhenever a script goes to sleep, it puts itself on a list of sleeping script threads \nthreaded script.\nThis script manages the animations of two characters and \nput the script’s threads to sleep while they wait for the characters to reach the \nmodify our script.\nthat the scripting language magically allows a thread to go to sleep, wait-\ncharacter to send an event back to the script and then waking the thread up \nIn our hypothetical scripting language, a signal is just a Boolean ﬂ ag with \nScripting\nA game object model provides the foundations upon which a rich and en-\ntertaining collection of game object types can be implemented with which to \nHowever, by itself, a game object model only per-\nmits us to deﬁ ne the kinds of objects that exist in our game world and how \nIt says nothing of the player’s objectives, what hap-\nwaiting on another can be used to synchronize a pair of script threads.\nevent of the player’s failure to accomplish the necessary tasks or objectives .\nIn the following brief sections, I’ll identify a few of the engine and game-\nof game development, much to the chagrin of the audio engineers, sound de-\nA game is of course much more than just its engine.\ngenre- and game-speciﬁ c gameplay systems.\ngame engine technologies described in this book together into a cohesive \nof course every game within a genre has its own speciﬁ c designs.\naudio, not to mention integration with other gameplay systems like the game \nClearly player mechanics are as varied as the games themselves, so there’s \nPlay games and try to reverse-engineer \nA game’s camera system is almost as important as the player mechanics.\nto have its own camera control style, although of course every game within a \n[6] Section 4.3 for some basic game camera control techniques.\nAs the player character moves about in the game \ngame.\nClearly there’s a lot more to a game than just player mechanics, cameras, and \nSome games have drivable vehicles, implement specialized types of weap-\ngenre- and game-speciﬁ c features, and all of the specialized soft ware systems ",
      "keywords": [
        "Game Object",
        "Game",
        "script",
        "Object",
        "game object model",
        "event",
        "Gameplay Foundation Systems",
        "scripting language",
        "player",
        "Systems",
        "Gameplay Systems",
        "state",
        "event handler functions",
        "game object type",
        "function"
      ],
      "concepts": [
        "game",
        "script",
        "object",
        "objectives",
        "function",
        "functions",
        "functional",
        "systems",
        "video",
        "player"
      ],
      "similar_chapters": [
        {
          "book": "Game_Engine_Architecture",
          "chapter": 36,
          "title": "",
          "score": 0.514,
          "base_score": 0.514,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 21,
          "title": "",
          "score": 0.447,
          "base_score": 0.447,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 20,
          "title": "",
          "score": 0.42,
          "base_score": 0.42,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 39,
          "title": "",
          "score": 0.403,
          "base_score": 0.403,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 40,
          "title": "",
          "score": 0.393,
          "base_score": 0.393,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "script",
          "scripting",
          "event",
          "object",
          "game object"
        ],
        "semantic": [],
        "merged": [
          "script",
          "scripting",
          "event",
          "object",
          "game object"
        ]
      },
      "topic_id": null,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.26309262328057814,
        "topic_boost": 0.0,
        "timestamp": "2025-12-17T23:05:57.760554+00:00"
      }
    },
    {
      "chapter_number": 42,
      "title": "Segment 42 (pages 849-853)",
      "start_page": 849,
      "end_page": 853,
      "summary": "Games: Understanding and Engineering Multiplayer Internet Games.\nReading, MA: Addison-Wesley, 2007.\nGame Programming Gems.\nGame Programming Gems 2.\n3D Game Engine Design: A Practical Approach to Real-Time \nSan Francisco, CA: Morgan Kaufmann, 2001.\n3D Game Engine Architecture: Engineering Real-Time \nSan Francisco, CA: Morgan Kaufmann, 2005.\nGame Physics.\nSan Francisco, CA: Morgan Kaufmann, \nReading, MA: Addison-Wesley, 2004.\nComputer Graphics: Principles and Practice in C, second edition.\nProgramming in Lua, 2nd Edition.\nEdition).\nNew York, NY: John Wiley and Sons, 2000.\n[24] David Kirk (editor).\nSan Francisco, CA: Morgan Kaufmann, \nA Theory of Fun for Game Design.\nReading, MA: Addison-Wesley, \nMathematics for 3D Game Programming and Computer Graphics, \nHingham, MA: Charles River Media, 2003.\nReading, MA: Addison-Wesley, 2005.\nMore Eﬀ ective C++: 35 New Ways to Improve Your Programs and \nReading, MA: Addison-Wesley, 1996.\nReading, MA: Addison-Wesley, 2001.\nGame Physics Engine Development.\nReading, MA: Addison-Wesley, 2007.\n[36] Alan W.\nReading, MA: Addison-Wesley, \nThe C++ Programming Language, special edition (3rd \nReading, MA: Addison-Wesley, 2000.\nGame Programming Gems 3.\n3D Computer Graphics (3rd Edition).\nYork, NY: John Wiley & Sons, 2008.\nGame Engine Architecture\nThis book covers both the theory and practice of game engine software development, bringing\nIntended as the text for a college level series in game programming, this book can also be used by\namateur software engineers, hobbyists, self-taught game programmers, and existing members\nJunior game engineers can use it to solidify their understanding of game\ne large-scale C++ software architecture in a games context\ne mathematics for game programming\nphysics, character animation, and game world object models\ne multiplatform game engines\n© game programming in multiprocessor environments\nJason Gregory has worked as a software engineer in the games industry since March 1999 and\nHe got his start in game programming at Midway\nworked on engine and game play technology for Medal of Honor: Pacific Assault and served as a",
      "keywords": [
        "Naty Hoﬀ man",
        "Morgan Kaufmann",
        "Naty Hoﬀ",
        "San Francisco",
        "Charles River Media",
        "Game Programming Gems",
        "Game",
        "Game Programming",
        "Graphics Gems",
        "Programming",
        "Edition",
        "Francisco",
        "Morgan",
        "Kaufmann",
        "Tomas Akenine-Moller"
      ],
      "concepts": [
        "games",
        "engineering",
        "engine",
        "editor",
        "wesley",
        "programming",
        "programs",
        "edition",
        "developing",
        "design"
      ],
      "similar_chapters": [
        {
          "book": "Game_Engine_Architecture",
          "chapter": 2,
          "title": "",
          "score": 0.806,
          "base_score": 0.656,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 1,
          "title": "",
          "score": 0.714,
          "base_score": 0.564,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 21,
          "title": "",
          "score": 0.567,
          "base_score": 0.417,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 3,
          "title": "",
          "score": 0.472,
          "base_score": 0.472,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 18,
          "title": "",
          "score": 0.448,
          "base_score": 0.448,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "addison wesley",
          "addison",
          "wesley",
          "reading ma",
          "ma addison"
        ],
        "semantic": [],
        "merged": [
          "addison wesley",
          "addison",
          "wesley",
          "reading ma",
          "ma addison"
        ]
      },
      "topic_id": 1,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.3123456646385301,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:57.760592+00:00"
      }
    }
  ],
  "total_chapters": 42,
  "enrichment_provenance": {
    "taxonomy_id": "none",
    "taxonomy_version": "none",
    "taxonomy_path": "none",
    "taxonomy_checksum": "sha256:none",
    "source_metadata_file": "Game_Engine_Architecture_metadata.json",
    "enrichment_date": "2025-12-17T23:05:57.766919+00:00",
    "enrichment_method": "msep",
    "model_version": "ai-agents-msep-v1",
    "processing_time_ms": 4006.6117930000473,
    "total_similar_chapters": 201
  }
}