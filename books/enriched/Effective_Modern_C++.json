{
  "metadata": {
    "title": "Effective Modern C++",
    "author": "Scott Meyers",
    "publisher": "Unknown Publisher",
    "edition": "1st Edition",
    "isbn": "",
    "total_pages": 334,
    "conversion_date": "2025-11-23T09:58:31.413374",
    "conversion_method": "PyMuPDF + OCR fallback",
    "source_pdf": "Effective_Modern_C++.pdf"
  },
  "chapters": [
    {
      "number": 1,
      "title": "Segment 1 (pages 1-8)",
      "start_page": 1,
      "end_page": 8,
      "detection_method": "topic_boundary",
      "content": "Scott Meyers\nEffective \nModern C++\n42 SPECIFIC WAYS TO IMPROVE YOUR USE OF C++11 AND C++14\nwww.it-ebooks.info\n\n\nPROGRAMMING/C++\nEffective Modern C++\nISBN: 978-1-491-90399-5\nUS $49.99\t\n CAN $52.99\n“ After I learned the C++ \nbasics, I then learned \nhow to use C++ in \nproduction code from \nMeyers' series of \nEffective C++ books. \nEffective Modern C++ \nis the most important \nhow-to book for advice \non key guidelines, \nstyles, and idioms to use \nmodern C++ effectively \nand well. Don't own it \nyet? Buy this one. Now.”\n—Herb Sutter \n Chair of ISO C++ Standards Committee and \nC++ Software Architect at Microsoft\nTwitter: @oreillymedia\nfacebook.com/oreilly\nComing to grips with C++11 and C++14 is more than a matter of familiarizing \nyourself with the features they introduce (e.g., auto type declarations, \nmove semantics, lambda expressions, and concurrency support). The \nchallenge is learning to use those features effectively—so that your \nsoftware is correct, efficient, maintainable, and portable. That’s where \nthis practical book comes in. It describes how to write truly great software \nusing C++11 and C++14—i.e., using modern C++.\nTopics include:\n■\n■The pros and cons of braced initialization, noexcept \nspecifications, perfect forwarding, and smart pointer make \nfunctions\n■\n■The relationships among std::move, std::forward, rvalue \nreferences, and universal references\n■\n■Techniques for writing clear, correct, effective lambda \nexpressions\n■\n■How std::atomic differs from volatile, how each should be \nused, and how they relate to C++'s concurrency API\n■\n■How best practices in \"old\" C++ programming (i.e., C++98) \nrequire revision for software development in modern C++\nEffective Modern C++ follows the proven guideline-based, example-driven \nformat of Scott Meyers' earlier books, but covers entirely new material. It's \nessential reading for every modern C++ software developer.\nFor more than 20 years, Scott Meyers' Effective C++ books (Effective C++, More \nEffective C++, and Effective STL) have set the bar for C++ programming guidance. \nHis clear, engaging explanations of complex technical material have earned him a \nworldwide following, keeping him in demand as a trainer, consultant, and confer­\nence presenter. He has a Ph.D. in Computer Science from Brown University.\nwww.it-ebooks.info\n\n\nSo, still interested in C++? You should be! Modern C++ (i.e., C++11/C++14)\nis far more than just a facelift. Considering the new features, it seems that it’s\nmore a reinvention. Looking for guidelines and assistance? Then this book\nis surely what you are looking for. Concerning C++, Scott Meyers was\nand still is a synonym for accuracy, quality, and delight.\n—Gerhard Kreuzer\nResearch and Development Engineer, Siemens AG\nFinding utmost expertise is hard enough. Finding teaching perfectionism—\nan author’s obsession with strategizing and streamlining explanations—is also difficult.\nYou know you’re in for a treat when you get to find both embodied in the same person.\nEffective Modern C++ is a towering achievement from a consummate technical writer.\nIt layers lucid, meaningful, and well-sequenced clarifications on top of complex and\ninterconnected topics, all in crisp literary style. You’re equally unlikely to find a\ntechnical mistake, a dull moment, or a lazy sentence in Effective Modern C++.\n—Andrei Alexandrescu\nPh.D., Research Scientist, Facebook, and author of Modern C++ Design\nAs someone with over two decades of C++ experience, to get the most out of\nmodern C++ (both best practices and pitfalls to avoid), I highly recommend\ngetting this book, reading it thoroughly, and referring to it often!\nI’ve certainly learned new things going through it!\n—Nevin Liber\nSenior Software Engineer, DRW Trading Group\nBjarne Stroustrup—the creator of C++—said, “C++11 feels like a new language.”\nEffective Modern C++ makes us share this same feeling by clearly explaining\nhow everyday programmers can benefit from new features and idioms\nof C++11 and C++14. Another great Scott Meyers book.\n—Cassio Neri\nFX Quantitative Analyst, Lloyds Banking Group\nPraise for Effective Modern C++\nwww.it-ebooks.info\n\n\nScott has the knack of boiling technical complexity down to an understandable kernel.\nHis Effective C++ books helped to raise the coding style of a previous generation of C++\nprogrammers; the new book seems positioned to do the same for those using modern C++.\n—Roger Orr\nOR/2 Limited, a member of the ISO C++ standards committee\nEffective Modern C++ is a great tool to improve your modern C++ skills. Not only does it\nteach you how, when and where to use modern C++ and be effective, it also explains why.\nWithout doubt, Scott’s clear and insightful writing, spread over 42 well-thought items,\ngives programmers a much better understanding of the language.\n—Bart Vandewoestyne\nResearch and Development Engineer and C++ enthusiast\nI love C++, it has been my work vehicle for many decades now. And with\nthe latest raft of features it is even more powerful and expressive than I\nwould have previously imagined. But with all this choice comes the question\n“when and how do I apply these features?” As has always been the case,\nScott’s Effective C++ books are the definitive answer to this question.\n—Damien Watkins\nComputation Software Engineering Team Lead, CSIRO\nGreat read for transitioning to modern C++—new C++11/14\nlanguage features are described alongside C++98, subject items are\neasy to reference, and advice summarized at the end of each section.\nEntertaining and useful for both casual and advanced C++ developers.\n—Rachel Cheng\nF5 Networks\nIf you’re migrating from C++98/03 to C++11/14, you need the eminently practical and\nclear information Scott provides in Effective Modern C++. If you’re already writing\nC++11 code, you’ll probably discover issues with the new features through Scott’s\nthorough discussion of the important new features of the language. Either way, this book\nis worth your time.\n—Rob Stewart\nBoost Steering Committee member (boost.org)\nwww.it-ebooks.info\n\n\nScott Meyers\nEffective Modern C++\nwww.it-ebooks.info\n\n\n978-1-491-90399-5\n[TI]\nEffective Modern C++\nby Scott Meyers\nCopyright © 2015 Scott Meyers. All rights reserved.\nPrinted in the Canada.\nPublished by O’Reilly Media, Inc., 1005 Gravenstein Highway North, Sebastopol, CA 95472.\nO’Reilly books may be purchased for educational, business, or sales promotional use. Online editions are\nalso available for most titles (http://safaribooksonline.com). For more information, contact our corporate/\ninstitutional sales department: 800-998-9938 or corporate@oreilly.com.\nEditor: Rachel Roumeliotis\nProduction Editor: Melanie Yarbrough\nCopyeditor: Jasmine Kwityn\nProofreader: Charles Roumeliotis\nIndexer: Scott Meyers\nInterior Designer: David Futato\nCover Designer: Ellie Volkhausen\nIllustrator: Rebecca Demarest\nNovember 2014:\n First Edition\nRevision History for the First Edition\n2014-11-07: First Release\nSee http://oreilly.com/catalog/errata.csp?isbn=9781491903995 for release details.\nThe O’Reilly logo is a registered trademark of O’Reilly Media, Inc. Effective Modern C++, the cover image\nof a Rose-crowned Fruit Dove, and related trade dress are trademarks of O’Reilly Media, Inc.\nWhile the publisher and the author have used good faith efforts to ensure that the information and\ninstructions contained in this work are accurate, the publisher and the author disclaim all responsibility\nfor errors or omissions, including without limitation responsibility for damages resulting from the use of\nor reliance on this work. Use of the information and instructions contained in this work is at your own\nrisk. If any code samples or other technology this work contains or describes is subject to open source\nlicenses or the intellectual property rights of others, it is your responsibility to ensure that your use\nthereof complies with such licenses and/or rights.\nwww.it-ebooks.info\n\n\n \nFor Darla,\nblack Labrador Retriever extraordinaire\nwww.it-ebooks.info\n\n\nwww.it-ebooks.info\n",
      "page_number": 1,
      "chapter_number": 1,
      "summary": "This chapter covers segment 1 (pages 1-8). Key topics include effective, scott, and books. For more than 20 years, Scott Meyers' Effective C++ books (Effective C++, More \nEffective C++, and Effective STL) have set the bar for C++ programming guidance.",
      "keywords": [
        "Effective Modern",
        "Modern",
        "Effective",
        "Scott Meyers",
        "Scott",
        "Scott Meyers' Effective",
        "Scott Meyers book",
        "Meyers",
        "Software",
        "features",
        "great Scott Meyers",
        "book",
        "Meyers' Effective",
        "O’Reilly Media",
        "Development Engineer"
      ],
      "concepts": [
        "effective",
        "scott",
        "books",
        "technical",
        "software",
        "useful",
        "great",
        "clear",
        "write",
        "writing"
      ],
      "similar_chapters": [
        {
          "book": "More Effective C++",
          "chapter": 1,
          "title": "Segment 1 (pages 1-8)",
          "relevance_score": 0.58,
          "method": "sentence_transformers"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 42,
          "title": "Segment 42 (pages 849-853)",
          "relevance_score": 0.51,
          "method": "sentence_transformers"
        },
        {
          "book": "Release It! Design and Deploy Production-Ready Software",
          "chapter": 1,
          "title": "Segment 1 (pages 3-10)",
          "relevance_score": 0.51,
          "method": "sentence_transformers"
        },
        {
          "book": "Effective-Python",
          "chapter": 1,
          "title": "Segment 1 (pages 2-9)",
          "relevance_score": 0.49,
          "method": "sentence_transformers"
        },
        {
          "book": "More Effective C++",
          "chapter": 3,
          "title": "Segment 3 (pages 17-24)",
          "relevance_score": 0.49,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 2,
      "title": "Segment 2 (pages 9-16)",
      "start_page": 9,
      "end_page": 16,
      "detection_method": "topic_boundary",
      "content": "Table of Contents\nFrom the Publisher. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  xi\nAcknowledgments. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  xiii\nIntroduction. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  1\n1. Deducing Types. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  9\nItem 1: Understand template type deduction.                                                              9\nItem 2: Understand auto type deduction.                                                                  18\nItem 3: Understand decltype.                                                                                     23\nItem 4: Know how to view deduced types.                                                                  30\n2. auto. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  37\nItem 5: Prefer auto to explicit type declarations.                                                      37\nItem 6: Use the explicitly typed initializer idiom when auto deduces\nundesired types.                                                                                                 43\n3. Moving to Modern C++. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  49\nItem 7: Distinguish between () and {} when creating objects.                               49\nItem 8: Prefer nullptr to 0 and NULL.                                                                         58\nItem 9: Prefer alias declarations to typedefs.                                                            63\nItem 10: Prefer scoped enums to unscoped enums.                                                     67\nItem 11: Prefer deleted functions to private undefined ones.                                  74\nItem 12: Declare overriding functions override.                                                     79\nItem 13: Prefer const_iterators to iterators.                                                     86\nItem 14: Declare functions noexcept if they won’t emit exceptions.                     90\nItem 15: Use constexpr whenever possible.                                                              97\nvii\nwww.it-ebooks.info\n\n\nItem 16: Make const member functions thread safe.                                             103\nItem 17: Understand special member function generation.                                  109\n4. Smart Pointers. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  117\nItem 18: Use std::unique_ptr for exclusive-ownership resource\nmanagement.                                                                                                 118\nItem 19: Use std::shared_ptr for shared-ownership resource\nmanagement.                                                                                                 125\nItem 20: Use std::weak_ptr for std::shared_ptr-like pointers that can\ndangle.                                                                                                             134\nItem 21: Prefer std::make_unique and std::make_shared to direct use of\nnew.                                                                                                                  139\nItem 22: When using the Pimpl Idiom, define special member functions in\nthe implementation file.                                                                               147\n5. Rvalue References, Move Semantics, and Perfect Forwarding. . . . . . . . . . . . . . . . . . . .  157\nItem 23: Understand std::move and std::forward.                                           158\nItem 24: Distinguish universal references from rvalue references.                       164\nItem 25: Use std::move on rvalue references, std::forward on universal\nreferences.                                                                                                       168\nItem 26: Avoid overloading on universal references.                                              177\nItem 27: Familiarize yourself with alternatives to overloading on universal\nreferences.                                                                                                       184\nItem 28: Understand reference collapsing.                                                               197\nItem 29: Assume that move operations are not present, not cheap, and not\nused.                                                                                                                203\nItem 30: Familiarize yourself with perfect forwarding failure cases.                    207\n6. Lambda Expressions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  215\nItem 31: Avoid default capture modes.                                                                     216\nItem 32: Use init capture to move objects into closures.                                        224\nItem 33: Use decltype on auto&& parameters to std::forward them.            229\nItem 34: Prefer lambdas to std::bind.                                                                    232\n7. The Concurrency API. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  241\nItem 35: Prefer task-based programming to thread-based.                                    241\nItem 36: Specify std::launch::async if asynchronicity is essential.                 245\nItem 37: Make std::threads unjoinable on all paths.                                          250\nItem 38: Be aware of varying thread handle destructor behavior.                         258\nItem 39: Consider void futures for one-shot event communication.                  262\nviii \n| \nTable of Contents\nwww.it-ebooks.info\n\n\nItem 40: Use std::atomic for concurrency, volatile for special memory.    271\n8. Tweaks. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  281\nItem 41: Consider pass by value for copyable parameters that are cheap to\nmove and always copied.                                                                              281\nItem 42: Consider emplacement instead of insertion.                                            292\nIndex. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  303\nTable of Contents \n| \nix\nwww.it-ebooks.info\n\n\nwww.it-ebooks.info\n\n\nFrom the Publisher\nUsing Code Examples\nThis book is here to help you get your job done. In general, if example code is offered\nwith this book, you may use it in your programs and documentation. You do not\nneed to contact us for permission unless you’re reproducing a significant portion of\nthe code. For example, writing a program that uses several chunks of code from this\nbook does not require permission. Selling or distributing a CD-ROM of examples\nfrom O’Reilly books does require permission. Answering a question by citing this\nbook and quoting example code does not require permission. Incorporating a signifi‐\ncant amount of example code from this book into your product’s documentation\ndoes require permission.\nWe appreciate, but do not require, attribution. An attribution usually includes the\ntitle, author, publisher, and ISBN. For example: “Effective Modern C++ by Scott Mey‐\ners (O’Reilly). Copyright 2015 Scott Meyers, 978-1-491-90399-5.”\nIf you feel your use of code examples falls outside fair use or the permission given\nabove, feel free to contact us at permissions@oreilly.com.\nSafari® Books Online\nSafari Books Online is an on-demand digital library that\ndelivers expert content in both book and video form\nfrom the world’s leading authors in technology and\nbusiness.\nTechnology professionals, software developers, web designers, and business and crea‐\ntive professionals use Safari Books Online as their primary resource for research,\nproblem solving, learning, and certification training.\nSafari Books Online offers a range of plans and pricing for enterprise, government,\neducation, and individuals.\nxi\nwww.it-ebooks.info\n\n\nMembers have access to thousands of books, training videos, and prepublication\nmanuscripts in one fully searchable database from publishers like O’Reilly Media,\nPrentice Hall Professional, Addison-Wesley Professional, Microsoft Press, Sams,\nQue, Peachpit Press, Focal Press, Cisco Press, John Wiley & Sons, Syngress, Morgan\nKaufmann, IBM Redbooks, Packt, Adobe Press, FT Press, Apress, Manning, New\nRiders, McGraw-Hill, Jones & Bartlett, Course Technology, and hundreds more. For\nmore information about Safari Books Online, please visit us online.\nHow to Contact Us\nComments and questions concerning this book may be addressed to the publisher:\nO’Reilly Media, Inc.\n1005 Gravenstein Highway North\nSebastopol, CA 95472\n800-998-9938 (in the United States or Canada)\n707-829-0515 (international or local)\n707-829-0104 (fax)\nTo comment or ask technical questions about this book, send email to bookques‐\ntions@oreilly.com.\nFor more information about our books, courses, conferences, and news, see our web‐\nsite at http://www.oreilly.com.\nFind us on Facebook: http://facebook.com/oreilly\nFollow us on Twitter: http://twitter.com/oreillymedia\nWatch us on YouTube: http://www.youtube.com/oreillymedia\nxii \n| \nFrom the Publisher\nwww.it-ebooks.info\n\n\nAcknowledgments\nI started investigating what was then known as C++0x (the nascent C++11) in 2009. I\nposted numerous questions to the Usenet newsgroup comp.std.c++, and I’m grate‐\nful to the members of that community (especially Daniel Krügler) for their very help‐\nful postings. In more recent years, I’ve turned to Stack Overflow when I had\nquestions about C++11 and C++14, and I’m equally indebted to that community for\nits help in understanding the finer points of modern C++. \nIn 2010, I prepared materials for a training course on C++0x (ultimately published as\nOverview of the New C++, Artima Publishing, 2010). Both those materials and my\nknowledge greatly benefited from the technical vetting performed by Stephan T. Lav‐\navej, Bernhard Merkle, Stanley Friesen, Leor Zolman, Hendrik Schober, and Anthony\nWilliams. Without their help, I would probably never have been in a position to\nundertake Effective Modern C++. That title, incidentally, was suggested or endorsed\nby several readers responding to my 18 February 2014 blog post, “Help me name my\nbook,” and Andrei Alexandrescu (author of Modern C++ Design, Addison-Wesley,\n2001) was kind enough to bless the title as not poaching on his terminological turf. \nI’m unable to identify the origins of all the information in this book, but some sour‐\nces had a relatively direct impact. Item 4’s use of an undefined template to coax type\ninformation out of compilers was suggested by Stephan T. Lavavej, and Matt P. Dziu‐\nbinski brought Boost.TypeIndex to my attention. In Item 5, the unsigned-\nstd::vector<int>::size_type example is from Andrey Karpov’s 28 February\n2010 article, “In what way can C++0x standard help you eliminate 64-bit errors.” The\nstd::pair<std::string, int>/std::pair<const std::string, int> example in\nthe same Item is from Stephan T. Lavavej’s talk at Going Native 2012, “STL11: Magic\n&& Secrets.” Item 6 was inspired by Herb Sutter’s 12 August 2013 article, “GotW #94\nSolution: AAA Style (Almost Always Auto).” Item 9 was motivated by Martinho Fer‐\nnandes’ blog post of 27 May 2012, “Handling dependent names.” The Item 12 exam‐\nple demonstrating overloading on reference qualifiers is based on Casey’s answer to\nthe question, “What’s a use case for overloading member functions on reference\nxiii\nwww.it-ebooks.info\n\n\nqualifiers?,” posted to Stack Overflow on 14 January 2014. My Item 15 treatment of\nC++14’s expanded support for constexpr functions incorporates information I\nreceived from Rein Halbersma. Item 16 is based on Herb Sutter’s C++ and Beyond\n2012 presentation, “You don’t know const and mutable.” Item 18’s advice to have\nfactory functions return std::unique_ptrs is based on Herb Sutter’s 30 May 2013\narticle, “GotW# 90 Solution: Factories.” In Item 19, fastLoadWidget is derived from\nHerb Sutter’s Going Native 2013 presentation, “My Favorite C++ 10-Liner.” My treat‐\nment of std::unique_ptr and incomplete types in Item 22 draws on Herb Sutter’s\n27 November 2011 article, “GotW #100: Compilation Firewalls” as well as Howard\nHinnant’s 22 May 2011 answer to the Stack Overflow question, “Is\nstd::unique_ptr<T> required to know the full definition of T?” The Matrix addition\nexample in Item 25 is based on writings by David Abrahams. JoeArgonne’s 8 Decem‐\nber 2012 comment on the 30 November 2012 blog post, “Another alternative to\nlambda move capture,” was the source of Item 32’s std::bind-based approach to\nemulating init capture in C++11. Item 37’s explanation of the problem with an\nimplicit detach in std::thread’s destructor is taken from Hans-J. Boehm’s 4\nDecember 2008 paper, “N2802: A plea to reconsider detach-on-destruction for thread\nobjects.” Item 41 was originally motivated by discussions of David Abrahams’ 15\nAugust 2009 blog post, “Want speed? Pass by value.” The idea that move-only types\ndeserve special treatment is due to Matthew Fioravante, while the analysis of\nassignment-based copying stems from comments by Howard Hinnant. In Item 42,\nStephan T. Lavavej and Howard Hinnant helped me understand the relative perfor‐\nmance profiles of emplacement and insertion functions, and Michael Winterberg\nbrought to my attention how emplacement can lead to resource leaks. (Michael cred‐\nits Sean Parent’s Going Native 2013 presentation, “C++ Seasoning,” as his source).\nMichael also pointed out how emplacement functions use direct initialization, while\ninsertion functions use copy initialization.\nReviewing drafts of a technical book is a demanding, time-consuming, and utterly\ncritical task, and I’m fortunate that so many people were willing to do it for me. Full\nor partial drafts of Effective Modern C++ were officially reviewed by Cassio Neri,\nNate Kohl, Gerhard Kreuzer, Leor Zolman, Bart Vandewoestyne, Stephan T. Lavavej,\nNevin “:-)” Liber, Rachel Cheng, Rob Stewart, Bob Steagall, Damien Watkins, Bradley\nE. Needham, Rainer Grimm, Fredrik Winkler, Jonathan Wakely, Herb Sutter, Andrei\nAlexandrescu, Eric Niebler, Thomas Becker, Roger Orr, Anthony Williams, Michael\nWinterberg, Benjamin Huchley, Tom Kirby-Green, Alexey A Nikitin, William Deal‐\ntry, Hubert Matthews, and Tomasz Kamiński. I also received feedback from several\nreaders through O’Reilly’s Early Release EBooks and Safari Books Online’s Rough\nCuts, comments on my blog (The View from Aristeia), and email. I’m grateful to each\nof these people. The book is much better than it would have been without their help.\nI’m particularly indebted to Stephan T. Lavavej and Rob Stewart, whose extraordi‐\nnarily detailed and comprehensive remarks lead me to worry that they spent nearly as\nxiv \n| \nAcknowledgments\nwww.it-ebooks.info\n",
      "page_number": 9,
      "chapter_number": 2,
      "summary": "This chapter covers segment 2 (pages 9-16). Key topics include item, types.",
      "keywords": [
        "Item",
        "std",
        "Safari Books Online",
        "Books Online",
        "book",
        "Herb Sutter",
        "Prefer",
        "Safari Books",
        "Stephan T. Lavavej",
        "functions",
        "Online",
        "Understand",
        "Sutter",
        "Press",
        "Modern"
      ],
      "concepts": [
        "item",
        "std",
        "types",
        "functions",
        "function",
        "press",
        "uses",
        "prefer",
        "examples",
        "professionals"
      ],
      "similar_chapters": [
        {
          "book": "Effective-Python",
          "chapter": 17,
          "title": "Segment 17 (pages 165-174)",
          "relevance_score": 0.7,
          "method": "sentence_transformers"
        },
        {
          "book": "Effective-Python",
          "chapter": 2,
          "title": "Segment 2 (pages 10-18)",
          "relevance_score": 0.69,
          "method": "sentence_transformers"
        },
        {
          "book": "Python Distilled",
          "chapter": 38,
          "title": "Segment 38 (pages 345-352)",
          "relevance_score": 0.69,
          "method": "sentence_transformers"
        },
        {
          "book": "AI Agents and Applications",
          "chapter": 27,
          "title": "Segment 27 (pages 230-240)",
          "relevance_score": 0.68,
          "method": "sentence_transformers"
        },
        {
          "book": "Building LLM Powered Applications",
          "chapter": 59,
          "title": "Segment 59 (pages 499-500)",
          "relevance_score": 0.68,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 3,
      "title": "Segment 3 (pages 17-24)",
      "start_page": 17,
      "end_page": 24,
      "detection_method": "topic_boundary",
      "content": "much time on this book as I did. Special thanks also go to Leor Zolman, who, in addi‐\ntion to reviwing the manuscript, double-checked all the code examples.\nDedicated reviews of digital versions of the book were performed by Gerhard\nKreuzer, Emyr Williams, and Bradley E. Needham.\nMy decision to limit the line length in code displays to 64 characters (the maximum\nlikely to display properly in print as well as across a variety of digital devices, device\norientations, and font configurations) was based on data provided by Michael Maher.\nAshley Morgan Williams made dining at the Lake Oswego Pizzicato uniquely enter‐\ntaining. When it comes to man-sized Caesars, she’s the go-to gal.\nMore than 20 years after first living through my playing author, my wife, Nancy L.\nUrbano, once again tolerated many months of distracted conversations with a cock‐\ntail of resignation, exasperation, and timely splashes of understanding and support.\nDuring the same period, our dog, Darla, was largely content to doze away the hours I\nspent staring at computer screens, but she never let me forget that there’s life beyond\nthe keyboard.\nAcknowledgments \n| \nxv\nwww.it-ebooks.info\n\n\nwww.it-ebooks.info\n\n\nIntroduction\nIf you’re an experienced C++ programmer and are anything like me, you initially\napproached C++11 thinking, “Yes, yes, I get it. It’s C++, only more so.” But as you\nlearned more, you were surprised by the scope of the changes. auto declarations,\nrange-based for loops, lambda expressions, and rvalue references change the face of\nC++, to say nothing of the new concurrency features. And then there are the\nidiomatic changes. 0 and typedefs are out, nullptr and alias declarations are in.\nEnums should now be scoped. Smart pointers are now preferable to built-in ones.\nMoving objects is normally better than copying them.\nThere’s a lot to learn about C++11, not to mention C++14.\nMore importantly, there’s a lot to learn about making effective use of the new capabil‐\nities. If you need basic information about “modern” C++ features, resources abound,\nbut if you’re looking for guidance on how to employ the features to create software\nthat’s correct, efficient, maintainable, and portable, the search is more challenging.\nThat’s where this book comes in. It’s devoted not to describing the features of C++11\nand C++14, but instead to their effective application.\nThe information in the book is broken into guidelines called Items. Want to under‐\nstand the various forms of type deduction? Or know when (and when not) to use\nauto declarations? Are you interested in why const member functions should be\nthread safe, how to implement the Pimpl Idiom using std::unique_ptr, why you\nshould avoid default capture modes in lambda expressions, or the differences\nbetween std::atomic and volatile? The answers are all here. Furthermore, they’re\nplatform-independent, Standards-conformant answers. This is a book about portable\nC++.\nThe Items in this book are guidelines, not rules, because guidelines have exceptions.\nThe most important part of each Item is not the advice it offers, but the rationale\nbehind the advice. Once you’ve read that, you’ll be in a position to determine whether\nthe circumstances of your project justify a violation of the Item’s guidance. The true\n1\nwww.it-ebooks.info\n\n\ngoal of this book isn’t to tell you what to do or what to avoid doing, but to convey a\ndeeper understanding of how things work in C++11 and C++14.\nTerminology and Conventions\nTo make sure we understand one another, it’s important to agree on some terminol‐\nogy, beginning, ironically, with “C++.” There have been four official versions of C++,\neach named after the year in which the corresponding ISO Standard was adopted:\nC++98, C++03, C++11, and C++14. C++98 and C++03 differ only in technical\ndetails, so in this book, I refer to both as C++98. When I refer to C++11, I mean both\nC++11 and C++14, because C++14 is effectively a superset of C++11. When I write\nC++14, I mean specifically C++14. And if I simply mention C++, I’m making a broad\nstatement that pertains to all language versions.   \nTerm I Use\nLanguage Versions I Mean\nC++\nAll\nC++98\nC++98 and C++03\nC++11\nC++11 and C++14\nC++14\nC++14\nAs a result, I might say that C++ places a premium on efficiency (true for all ver‐\nsions), that C++98 lacks support for concurrency (true only for C++98 and C++03),\nthat C++11 supports lambda expressions (true for C++11 and C++14), and that\nC++14 offers generalized function return type deduction (true for C++14 only).\nC++11’s most pervasive feature is probably move semantics, and the foundation of\nmove semantics is distinguishing expressions that are rvalues from those that are lval‐\nues. That’s because rvalues indicate objects eligible for move operations, while lvalues\ngenerally don’t. In concept (though not always in practice), rvalues correspond to\ntemporary objects returned from functions, while lvalues correspond to objects you\ncan refer to, either by name or by following a pointer or lvalue reference.\nA useful heuristic to determine whether an expression is an lvalue is to ask if you can\ntake its address. If you can, it typically is. If you can’t, it’s usually an rvalue. A nice\nfeature of this heuristic is that it helps you remember that the type of an expression is\nindependent of whether the expression is an lvalue or an rvalue. That is, given a type\nT, you can have lvalues of type T as well as rvalues of type T. It’s especially important\nto remember this when dealing with a parameter of rvalue reference type, because the\nparameter itself is an lvalue:\n2 \n|\nwww.it-ebooks.info\n\n\nclass Widget {\npublic:\n  Widget(Widget&& rhs);    // rhs is an lvalue, though it has\n  …                        // an rvalue reference type\n};\nHere, it’d be perfectly valid to take rhs’s address inside Widget’s move constructor,\nso rhs is an lvalue, even though its type is an rvalue reference. (By similar reasoning,\nall parameters are lvalues.)\nThat code snippet demonstrates several conventions I normally follow:\n• The class name is Widget. I use Widget whenever I want to refer to an arbitrary\nuser-defined type. Unless I need to show specific details of the class, I use Widget\nwithout declaring it.\n• I use the parameter name rhs (“right-hand side”). It’s my preferred parameter\nname for the move operations (i.e., move constructor and move assignment oper‐\nator) and the copy operations (i.e., copy constructor and copy assignment opera‐\ntor). I also employ it for the right-hand parameter of binary operators:\nMatrix operator+(const Matrix& lhs, const Matrix& rhs);\nIt’s no surprise, I hope, that lhs stands for “left-hand side.”\n• I apply special formatting to parts of code or parts of comments to draw your\nattention to them. In the Widget move constructor above, I’ve highlighted the\ndeclaration of rhs and the part of the comment noting that rhs is an lvalue.\nHighlighted code is neither inherently good nor inherently bad. It’s simply code\nyou should pay particular attention to.\n• I use “…” to indicate “other code could go here.” This narrow ellipsis is different\nfrom the wide ellipsis (“...”) that’s used in the source code for C++11’s variadic\ntemplates. That sounds confusing, but it’s not. For example:\ntemplate<typename... Ts>                // these are C++\nvoid processVals(const Ts&... params)   // source code\n{                                       // ellipses\n  …                                     // this means \"some\n                                        // code goes here\"\n}\nThe declaration of processVals shows that I use typename when declaring type\nparameters in templates, but that’s merely a personal preference; the keyword\nclass would work just as well. On those occasions where I show code excerpts\n \n| \n3\nwww.it-ebooks.info\n\n\nfrom a C++ Standard, I declare type parameters using class, because that’s what\nthe Standards do.\nWhen an object is initialized with another object of the same type, the new object is\nsaid to be a copy of the initializing object, even if the copy was created via the move\nconstructor. Regrettably, there’s no terminology in C++ that distinguishes between\nan object that’s a copy-constructed copy and one that’s a move-constructed copy:\nvoid someFunc(Widget w);        // someFunc's parameter w\n                                // is passed by value\nWidget wid;                     // wid is some Widget\nsomeFunc(wid);                  // in this call to someFunc,\n                                // w is a copy of wid that's\n                                // created via copy construction\nsomeFunc(std::move(wid));       // in this call to SomeFunc,\n                                // w is a copy of wid that's\n                                // created via move construction\nCopies of rvalues are generally move constructed, while copies of lvalues are usually\ncopy constructed. An implication is that if you know only that an object is a copy of\nanother object, it’s not possible to say how expensive it was to construct the copy. In\nthe code above, for example, there’s no way to say how expensive it is to create the\nparameter w without knowing whether rvalues or lvalues are passed to someFunc.\n(You’d also have to know the cost of moving and copying Widgets.)\nIn a function call, the expressions passed at the call site are the function’s arguments.\nThe arguments are used to initialize the function’s parameters. In the first call to\nsomeFunc above, the argument is wid. In the second call, the argument is\nstd::move(wid). In both calls, the parameter is w. The distinction between argu‐\nments and parameters is important, because parameters are lvalues, but the argu‐\nments with which they are initialized may be rvalues or lvalues. This is especially\nrelevant during the process of perfect forwarding, whereby an argument passed to a\nfunction is passed to a second function such that the original argument’s rvalueness\nor lvalueness is preserved. (Perfect forwarding is discussed in detail in Item 30.)\nWell-designed functions are exception safe, meaning they offer at least the basic\nexception safety guarantee (i.e., the basic guarantee). Such functions assure callers\nthat even if an exception is thrown, program invariants remain intact (i.e., no data\nstructures are corrupted) and no resources are leaked. Functions offering the strong\nexception safety guarantee (i.e., the strong guarantee) assure callers that if an excep‐\ntion arises, the state of the program remains as it was prior to the call.\n4 \n|\nwww.it-ebooks.info\n\n\nWhen I refer to a function object, I usually mean an object of a type supporting an\noperator() member function. In other words, an object that acts like a function.\nOccasionally I use the term in a slightly more general sense to mean anything that\ncan be invoked using the syntax of a non-member function call (i.e., “function\nName(arguments)”). This broader definition covers not just objects supporting oper\nator(), but also functions and C-like function pointers. (The narrower definition\ncomes from C++98, the broader one from C++11.) Generalizing further by adding\nmember function pointers yields what are known as callable objects. You can gener‐\nally ignore the fine distinctions and simply think of function objects and callable\nobjects as things in C++ that can be invoked using some kind of function-calling syn‐\ntax.\nFunction objects created through lambda expressions are known as closures. It’s sel‐\ndom necessary to distinguish between lambda expressions and the closures they cre‐\nate, so I often refer to both as lambdas. Similarly, I rarely distinguish between\nfunction templates (i.e., templates that generate functions) and template functions\n(i.e., the functions generated from function templates). Ditto for class templates and\ntemplate classes.\nMany things in C++ can be both declared and defined. Declarations introduce names\nand types without giving details, such as where storage is located or how things are\nimplemented:\nextern int x;                       // object declaration\nclass Widget;                       // class declaration\nbool func(const Widget& w);         // function declaration\nenum class Color;                   // scoped enum declaration\n                                    // (see Item 10)\nDefinitions provide the storage locations or implementation details:\nint x;                              // object definition\nclass Widget {                      // class definition\n  …\n};\nbool func(const Widget& w)\n{ return w.size() < 10; }           // function definition\nenum class Color\n{ Yellow, Red, Blue };              // scoped enum definition\n \n| \n5\nwww.it-ebooks.info\n\n\nA definition also qualifies as a declaration, so unless it’s really important that some‐\nthing is a definition, I tend to refer to declarations.\nI define a function’s signature to be the part of its declaration that specifies parameter\nand return types. Function and parameter names are not part of the signature. In the\nexample above, func’s signature is bool(const Widget&). Elements of a function’s\ndeclaration other than its parameter and return types (e.g., noexcept or constexpr,\nif present), are excluded. (noexcept and constexpr are described in Items 14 and\n15.) The official definition of “signature” is slightly different from mine, but for this\nbook, my definition is more useful. (The official definition sometimes omits return\ntypes.)\nNew C++ Standards generally preserve the validity of code written under older ones,\nbut occasionally the Standardization Committee deprecates features. Such features\nare on standardization death row and may be removed from future Standards. Com‐\npilers may or may not warn about the use of deprecated features, but you should do\nyour best to avoid them. Not only can they lead to future porting headaches, they’re\ngenerally inferior to the features that replace them. For example, std::auto_ptr is\ndeprecated in C++11, because std::unique_ptr does the same job, only better.\nSometimes a Standard says that the result of an operation is undefined behavior. That\nmeans that runtime behavior is unpredictable, and it should go without saying that\nyou want to steer clear of such uncertainty. Examples of actions with undefined\nbehavior include using square brackets (“[]”) to index beyond the bounds of a\nstd::vector, dereferencing an uninitialized iterator, or engaging in a data race (i.e.,\nhaving two or more threads, at least one of which is a writer, simultaneously access\nthe same memory location).\nI call built-in pointers, such as those returned from new, raw pointers. The opposite of\na raw pointer is a smart pointer. Smart pointers normally overload the pointer-\ndereferencing operators (operator-> and operator*), though Item 20 explains that\nstd::weak_ptr is an exception.\nIn source code comments, I sometimes abbreviate “constructor” as ctor and\n“destructor” as dtor.  \nReporting Bugs and Suggesting Improvements\nI’ve done my best to fill this book with clear, accurate, useful information, but surely\nthere are ways to make it better. If you find errors of any kind (technical, expository,\ngrammatical, typographical, etc.), or if you have suggestions for how the book could\nbe improved, please email me at emc++@aristeia.com. New printings give me the\n6 \n|\nwww.it-ebooks.info\n",
      "page_number": 17,
      "chapter_number": 3,
      "summary": "This chapter covers segment 3 (pages 17-24). Key topics include objects, definition, and definitions. Covers function. Special thanks also go to Leor Zolman, who, in addi‐\ntion to reviwing the manuscript, double-checked all the code examples.",
      "keywords": [
        "Widget",
        "function",
        "type",
        "object",
        "code",
        "move",
        "copy",
        "functions",
        "parameter",
        "class Widget",
        "book",
        "definition",
        "const Widget",
        "declaration",
        "lvalues"
      ],
      "concepts": [
        "objects",
        "definition",
        "definitions",
        "code",
        "standards",
        "declarations",
        "declaring",
        "declare",
        "widget",
        "useful"
      ],
      "similar_chapters": [
        {
          "book": "More Effective C++",
          "chapter": 12,
          "title": "Segment 12 (pages 116-123)",
          "relevance_score": 0.73,
          "method": "sentence_transformers"
        },
        {
          "book": "C++ Templates_ The Complete Guide",
          "chapter": 26,
          "title": "Segment 26 (pages 815-849)",
          "relevance_score": 0.7,
          "method": "sentence_transformers"
        },
        {
          "book": "Effective-Python",
          "chapter": 11,
          "title": "Segment 11 (pages 99-114)",
          "relevance_score": 0.69,
          "method": "sentence_transformers"
        },
        {
          "book": "More Effective C++",
          "chapter": 31,
          "title": "Segment 31 (pages 312-319)",
          "relevance_score": 0.69,
          "method": "sentence_transformers"
        },
        {
          "book": "Python Distilled",
          "chapter": 14,
          "title": "Segment 14 (pages 116-123)",
          "relevance_score": 0.69,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 4,
      "title": "Segment 4 (pages 25-35)",
      "start_page": 25,
      "end_page": 35,
      "detection_method": "topic_boundary",
      "content": "opportunity to revise Effective Modern C++, and I can’t address issues I don’t know\nabout!\nTo view the list of the issues I do know about, consult the book’s errata page, http://\nwww.aristeia.com/BookErrata/emc++-errata.html.\n \n| \n7\nwww.it-ebooks.info\n\n\nwww.it-ebooks.info\n\n\nCHAPTER 1\nDeducing Types\nC++98 had a single set of rules for type deduction: the one for function templates.\nC++11 modifies that ruleset a bit and adds two more, one for auto and one for\ndecltype. C++14 then extends the usage contexts in which auto and decltype may\nbe employed. The increasingly widespread application of type deduction frees you\nfrom the tyranny of spelling out types that are obvious or redundant. It makes C++\nsoftware more adaptable, because changing a type at one point in the source code\nautomatically propagates through type deduction to other locations. However, it can\nrender code more difficult to reason about, because the types deduced by compilers\nmay not be as apparent as you’d like.\nWithout a solid understanding of how type deduction operates, effective program‐\nming in modern C++ is all but impossible. There are just too many contexts where\ntype deduction takes place: in calls to function templates, in most situations where\nauto appears, in decltype expressions, and, as of C++14, where the enigmatic\ndecltype(auto) construct is employed.\nThis chapter provides the information about type deduction that every C++ devel‐\noper requires. It explains how template type deduction works, how auto builds on\nthat, and how decltype goes its own way. It even explains how you can force com‐\npilers to make the results of their type deductions visible, thus enabling you to ensure\nthat compilers are deducing the types you want them to.\nItem 1: Understand template type deduction.\nWhen users of a complex system are ignorant of how it works, yet happy with what it\ndoes, that says a lot about the design of the system. By this measure, template type\ndeduction in C++ is a tremendous success. Millions of programmers have passed\n9\nwww.it-ebooks.info\n\n\narguments to template functions with completely satisfactory results, even though\nmany of those programmers would be hard-pressed to give more than the haziest\ndescription of how the types used by those functions were deduced.\nIf that group includes you, I have good news and bad news. The good news is that\ntype deduction for templates is the basis for one of modern C++’s most compelling\nfeatures: auto. If you were happy with how C++98 deduced types for templates,\nyou’re set up to be happy with how C++11 deduces types for auto. The bad news is\nthat when the template type deduction rules are applied in the context of auto, they\nsometimes seem less intuitive than when they’re applied to templates. For that rea‐\nson, it’s important to truly understand the aspects of template type deduction that\nauto builds on. This Item covers what you need to know.\nIf you’re willing to overlook a pinch of pseudocode, we can think of a function tem‐\nplate as looking like this:\ntemplate<typename T>\nvoid f(ParamType param);\nA call can look like this:\nf(expr);                    // call f with some expression\nDuring compilation, compilers use expr to deduce two types: one for T and one for\nParamType. These types are frequently different, because ParamType often contains\nadornments, e.g., const or reference qualifiers. For example, if the template is\ndeclared like this,\ntemplate<typename T>\nvoid f(const T& param);     // ParamType is const T&\nand we have this call,\nint x = 0;\nf(x);                       // call f with an int\nT is deduced to be int, but ParamType is deduced to be const int&.\nIt’s natural to expect that the type deduced for T is the same as the type of the argu‐\nment passed to the function, i.e., that T is the type of expr. In the above example,\nthat’s the case: x is an int, and T is deduced to be int. But it doesn’t always work that\nway. The type deduced for T is dependent not just on the type of expr, but also on the\nform of ParamType. There are three cases:\n10 \n| \nItem 1\nwww.it-ebooks.info\n\n\n• ParamType is a pointer or reference type, but not a universal reference. (Univer‐\nsal references are described in Item 24. At this point, all you need to know is that\nthey exist and that they’re not the same as lvalue references or rvalue references.)\n• ParamType is a universal reference.\n• ParamType is neither a pointer nor a reference.\nWe therefore have three type deduction scenarios to examine. Each will be based on\nour general form for templates and calls to it:\ntemplate<typename T>\nvoid f(ParamType param);\nf(expr);                // deduce T and ParamType from expr\nCase 1: ParamType is a Reference or Pointer, but not a Universal\nReference\nThe simplest situation is when ParamType is a reference type or a pointer type, but\nnot a universal reference. In that case, type deduction works like this:\n1. If expr’s type is a reference, ignore the reference part.\n2. Then pattern-match expr’s type against ParamType to determine T.\nFor example, if this is our template,\ntemplate<typename T>\nvoid f(T& param);       // param is a reference\nand we have these variable declarations,\nint x = 27;             // x is an int\nconst int cx = x;       // cx is a const int\nconst int& rx = x;      // rx is a reference to x as a const int\nthe deduced types for param and T in various calls are as follows:\nf(x);                   // T is int, param's type is int&\nf(cx);                  // T is const int,\n                        // param's type is const int&\nf(rx);                  // T is const int,\n                        // param's type is const int&\nItem 1 \n| \n11\nwww.it-ebooks.info\n\n\nIn the second and third calls, notice that because cx and rx designate const values, T\nis deduced to be const int, thus yielding a parameter type of const int&. That’s\nimportant to callers. When they pass a const object to a reference parameter, they\nexpect that object to remain unmodifiable, i.e., for the parameter to be a reference-to-\nconst. That’s why passing a const object to a template taking a T& parameter is safe:\nthe constness of the object becomes part of the type deduced for T.\nIn the third example, note that even though rx’s type is a reference, T is deduced to\nbe a non-reference. That’s because rx’s reference-ness is ignored during type deduc‐\ntion.\nThese examples all show lvalue reference parameters, but type deduction works\nexactly the same way for rvalue reference parameters. Of course, only rvalue argu‐\nments may be passed to rvalue reference parameters, but that restriction has nothing\nto do with type deduction.\nIf we change the type of f’s parameter from T& to const T&, things change a little, but\nnot in any really surprising ways. The constness of cx and rx continues to be respec‐\nted, but because we’re now assuming that param is a reference-to-const, there’s no\nlonger a need for const to be deduced as part of T:\ntemplate<typename T>\nvoid f(const T& param);  // param is now a ref-to-const\nint x = 27;              // as before\nconst int cx = x;        // as before\nconst int& rx = x;       // as before\nf(x);                    // T is int, param's type is const int&\nf(cx);                   // T is int, param's type is const int&\nf(rx);                   // T is int, param's type is const int&\nAs before, rx’s reference-ness is ignored during type deduction.\nIf param were a pointer (or a pointer to const) instead of a reference, things would\nwork essentially the same way:\ntemplate<typename T>\nvoid f(T* param);        // param is now a pointer\nint x = 27;              // as before\nconst int *px = &x;      // px is a ptr to x as a const int\n12 \n| \nItem 1\nwww.it-ebooks.info\n\n\nf(&x);                   // T is int, param's type is int*\nf(px);                   // T is const int,\n                         // param's type is const int*\nBy now, you may find yourself yawning and nodding off, because C++’s type deduc‐\ntion rules work so naturally for reference and pointer parameters, seeing them in\nwritten form is really dull. Everything’s just obvious! Which is exactly what you want\nin a type deduction system.\nCase 2: ParamType is a Universal Reference\nThings are less obvious for templates taking universal reference parameters. Such\nparameters are declared like rvalue references (i.e., in a function template taking a\ntype parameter T, a universal reference’s declared type is T&&), but they behave differ‐\nently when lvalue arguments are passed in. The complete story is told in Item 24, but\nhere’s the headline version:\n• If expr is an lvalue, both T and ParamType are deduced to be lvalue references.\nThat’s doubly unusual. First, it’s the only situation in template type deduction\nwhere T is deduced to be a reference. Second, although ParamType is declared\nusing the syntax for an rvalue reference, its deduced type is an lvalue reference.\n• If expr is an rvalue, the “normal” (i.e., Case 1) rules apply.\nFor example:\ntemplate<typename T>\nvoid f(T&& param);       // param is now a universal reference\nint x = 27;              // as before\nconst int cx = x;        // as before\nconst int& rx = x;       // as before\nf(x);                    // x is lvalue, so T is int&,\n                         // param's type is also int&\nf(cx);                   // cx is lvalue, so T is const int&,\n                         // param's type is also const int&\nf(rx);                   // rx is lvalue, so T is const int&,\n                         // param's type is also const int&\nf(27);                   // 27 is rvalue, so T is int,\n                         // param's type is therefore int&&\nItem 1 \n| \n13\nwww.it-ebooks.info\n\n\nItem 24 explains exactly why these examples play out the way they do. The key point\nhere is that the type deduction rules for universal reference parameters are different\nfrom those for parameters that are lvalue references or rvalue references. In particu‐\nlar, when universal references are in use, type deduction distinguishes between lvalue\narguments and rvalue arguments. That never happens for non-universal references.\nCase 3: ParamType is Neither a Pointer nor a Reference\nWhen ParamType is neither a pointer nor a reference, we’re dealing with pass-by-\nvalue:\ntemplate<typename T>\nvoid f(T param);         // param is now passed by value\nThat means that param will be a copy of whatever is passed in—a completely new\nobject. The fact that param will be a new object motivates the rules that govern how T\nis deduced from expr:\n1. As before, if expr’s type is a reference, ignore the reference part.\n2. If, after ignoring expr’s reference-ness, expr is const, ignore that, too. If it’s\nvolatile, also ignore that. (volatile objects are uncommon. They’re generally\nused only for implementing device drivers. For details, see Item 40.)\nHence:\nint x = 27;          // as before\nconst int cx = x;    // as before\nconst int& rx = x;   // as before\nf(x);                // T's and param's types are both int\nf(cx);               // T's and param's types are again both int\nf(rx);               // T's and param's types are still both int\nNote that even though cx and rx represent const values, param isn’t const. That\nmakes sense. param is an object that’s completely independent of cx and rx—a copy\nof cx or rx. The fact that cx and rx can’t be modified says nothing about whether\nparam can be. That’s why expr’s constness (and volatileness, if any) is ignored\nwhen deducing a type for param: just because expr can’t be modified doesn’t mean\nthat a copy of it can’t be.\nIt’s important to recognize that const (and volatile) is ignored only for by-value\nparameters. As we’ve seen, for parameters that are references-to- or pointers-to-\nconst, the constness of expr is preserved during type deduction. But consider the\n14 \n| \nItem 1\nwww.it-ebooks.info\n\n\ncase where expr is a const pointer to a const object, and expr is passed to a by-\nvalue param:\ntemplate<typename T>\nvoid f(T param);         // param is still passed by value\nconst char* const ptr =  // ptr is const pointer to const object\n  \"Fun with pointers\";\nf(ptr);                  // pass arg of type const char * const\nHere, the const to the right of the asterisk declares ptr to be const: ptr can’t be\nmade to point to a different location, nor can it be set to null. (The const to the left\nof the asterisk says that what ptr points to—the character string—is const, hence\ncan’t be modified.) When ptr is passed to f, the bits making up the pointer are\ncopied into param. As such, the pointer itself (ptr) will be passed by value. In accord\nwith the type deduction rule for by-value parameters, the constness of ptr will be\nignored, and the type deduced for param will be const char*, i.e., a modifiable\npointer to a const character string. The constness of what ptr points to is preserved\nduring type deduction, but the constness of ptr itself is ignored when copying it to\ncreate the new pointer, param.\nArray Arguments\nThat pretty much covers it for mainstream template type deduction, but there’s a\nniche case that’s worth knowing about. It’s that array types are different from pointer\ntypes, even though they sometimes seem to be interchangeable. A primary contribu‐\ntor to this illusion is that, in many contexts, an array decays into a pointer to its first\nelement. This decay is what permits code like this to compile:\nconst char name[] = \"J. P. Briggs\";  // name's type is\n                                     // const char[13]\nconst char * ptrToName = name;       // array decays to pointer\nHere, the const char* pointer ptrToName is being initialized with name, which is a\nconst char[13]. These types (const char* and const char[13]) are not the same,\nbut because of the array-to-pointer decay rule, the code compiles.\nBut what if an array is passed to a template taking a by-value parameter? What hap‐\npens then?\ntemplate<typename T>\nvoid f(T param);      // template with by-value parameter\nItem 1 \n| \n15\nwww.it-ebooks.info\n\n\nf(name);              // what types are deduced for T and param?\nWe begin with the observation that there is no such thing as a function parameter\nthat’s an array. Yes, yes, the syntax is legal,\nvoid myFunc(int param[]);\nbut the array declaration is treated as a pointer declaration, meaning that myFunc\ncould equivalently be declared like this:\nvoid myFunc(int* param);         // same function as above\nThis equivalence of array and pointer parameters is a bit of foliage springing from the\nC roots at the base of C++, and it fosters the illusion that array and pointer types are\nthe same.\nBecause array parameter declarations are treated as if they were pointer parameters,\nthe type of an array that’s passed to a template function by value is deduced to be a\npointer type. That means that in the call to the template f, its type parameter T is\ndeduced to be const char*:\nf(name);          // name is array, but T deduced as const char*\nBut now comes a curve ball. Although functions can’t declare parameters that are\ntruly arrays, they can declare parameters that are references to arrays! So if we modify\nthe template f to take its argument by reference,\ntemplate<typename T>\nvoid f(T& param);      // template with by-reference parameter\nand we pass an array to it,\nf(name);               // pass array to f\nthe type deduced for T is the actual type of the array! That type includes the size of\nthe array, so in this example, T is deduced to be const char [13], and the type of f’s\nparameter (a reference to this array) is const char (&)[13]. Yes, the syntax looks\ntoxic, but knowing it will score you mondo points with those few souls who care.\nInterestingly, the ability to declare references to arrays enables creation of a template\nthat deduces the number of elements that an array contains:\n// return size of an array as a compile-time constant. (The\n// array parameter has no name, because we care only about\n// the number of elements it contains.)\ntemplate<typename T, std::size_t N>                 // see info\nconstexpr std::size_t arraySize(T (&)[N]) noexcept  // below on\n{                                                   // constexpr\n16 \n| \nItem 1\nwww.it-ebooks.info\n\n\n  return N;                                         // and\n}                                                   // noexcept\nAs Item 15 explains, declaring this function constexpr makes its result available\nduring compilation. That makes it possible to declare, say, an array with the same\nnumber of elements as a second array whose size is computed from a braced initial‐\nizer:\nint keyVals[] = { 1, 3, 7, 9, 11, 22, 35 };      // keyVals has\n                                                 // 7 elements\nint mappedVals[arraySize(keyVals)];              // so does\n                                                 // mappedVals\nOf course, as a modern C++ developer, you’d naturally prefer a std::array to a\nbuilt-in array:\nstd::array<int, arraySize(keyVals)> mappedVals;  // mappedVals'\n                                                 // size is 7\nAs for arraySize being declared noexcept, that’s to help compilers generate better\ncode. For details, see Item 14.\nFunction Arguments\nArrays aren’t the only things in C++ that can decay into pointers. Function types can\ndecay into function pointers, and everything we’ve discussed regarding type deduc‐\ntion for arrays applies to type deduction for functions and their decay into function\npointers. As a result:\nvoid someFunc(int, double);   // someFunc is a function;\n                              // type is void(int, double)\ntemplate<typename T>\nvoid f1(T param);             // in f1, param passed by value\ntemplate<typename T>\nvoid f2(T& param);            // in f2, param passed by ref\nf1(someFunc);                 // param deduced as ptr-to-func;\n                              // type is void (*)(int, double)\nf2(someFunc);                 // param deduced as ref-to-func;\n                              // type is void (&)(int, double)\nThis rarely makes any difference in practice, but if you’re going to know about array-\nto-pointer decay, you might as well know about function-to-pointer decay, too.\nItem 1 \n| \n17\nwww.it-ebooks.info\n",
      "page_number": 25,
      "chapter_number": 4,
      "summary": "This chapter provides the information about type deduction that every C++ devel‐\noper requires Key topics include reference, templates, and types. | \n7\nwww.it-ebooks.info\n www.it-ebooks.info\n CHAPTER 1\nDeducing Types\nC++98 had a single set of rules for type deduction: the one for function templates.",
      "keywords": [
        "type",
        "const int",
        "const",
        "type deduction",
        "int",
        "param",
        "param type",
        "reference",
        "template type deduction",
        "template",
        "const char",
        "deduction",
        "pointer",
        "template type",
        "Item"
      ],
      "concepts": [
        "reference",
        "templates",
        "types",
        "array",
        "declared",
        "declarations",
        "declares",
        "deduction",
        "deductions",
        "pointer"
      ],
      "similar_chapters": [
        {
          "book": "C++ Templates_ The Complete Guide",
          "chapter": 1,
          "title": "Segment 1 (pages 1-35)",
          "relevance_score": 0.76,
          "method": "sentence_transformers"
        },
        {
          "book": "C++ Templates_ The Complete Guide",
          "chapter": 52,
          "title": "Segment 52 (pages 1664-1696)",
          "relevance_score": 0.72,
          "method": "sentence_transformers"
        },
        {
          "book": "C++ Templates_ The Complete Guide",
          "chapter": 13,
          "title": "Segment 13 (pages 394-424)",
          "relevance_score": 0.69,
          "method": "sentence_transformers"
        },
        {
          "book": "C++ Templates_ The Complete Guide",
          "chapter": 64,
          "title": "Segment 64 (pages 2050-2080)",
          "relevance_score": 0.69,
          "method": "sentence_transformers"
        },
        {
          "book": "C++ Templates_ The Complete Guide",
          "chapter": 9,
          "title": "Segment 9 (pages 265-294)",
          "relevance_score": 0.68,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 5,
      "title": "Segment 5 (pages 36-48)",
      "start_page": 36,
      "end_page": 48,
      "detection_method": "topic_boundary",
      "content": "So there you have it: the auto-related rules for template type deduction. I remarked\nat the outset that they’re pretty straightforward, and for the most part, they are. The\nspecial treatment accorded lvalues when deducing types for universal references\nmuddies the water a bit, however, and the decay-to-pointer rules for arrays and func‐\ntions stirs up even greater turbidity. Sometimes you simply want to grab your com‐\npilers and demand, “Tell me what type you’re deducing!” When that happens, turn to\nItem 4, because it’s devoted to coaxing compilers into doing just that.\nThings to Remember\n• During template type deduction, arguments that are references are treated as\nnon-references, i.e., their reference-ness is ignored.\n• When deducing types for universal reference parameters, lvalue arguments get\nspecial treatment.\n• When deducing types for by-value parameters, const and/or volatile argu‐\nments are treated as non-const and non-volatile.\n• During template type deduction, arguments that are array or function names\ndecay to pointers, unless they’re used to initialize references.\nItem 2: Understand auto type deduction.\nIf you’ve read Item 1 on template type deduction, you already know almost every‐\nthing you need to know about auto type deduction, because, with only one curious\nexception, auto type deduction is template type deduction. But how can that be?\nTemplate type deduction involves templates and functions and parameters, but auto\ndeals with none of those things.\nThat’s true, but it doesn’t matter. There’s a direct mapping between template type\ndeduction and auto type deduction. There is literally an algorithmic transformation\nfrom one to the other.\nIn Item 1, template type deduction is explained using this general function template\ntemplate<typename T>\nvoid f(ParamType param);\nand this general call:\nf(expr);                    // call f with some expression\nIn the call to f, compilers use expr to deduce types for T and ParamType.\n18 \n| \nItem 1\nwww.it-ebooks.info\n\n\nWhen a variable is declared using auto, auto plays the role of T in the template, and\nthe type specifier for the variable acts as ParamType. This is easier to show than to\ndescribe, so consider this example:\nauto x = 27;\nHere, the type specifier for x is simply auto by itself. On the other hand, in this decla‐\nration,\nconst auto cx = x;\nthe type specifier is const auto. And here,\nconst auto& rx = x;\nthe type specifier is const auto&. To deduce types for x, cx, and rx in these exam‐\nples, compilers act as if there were a template for each declaration as well as a call to\nthat template with the corresponding initializing expression:\ntemplate<typename T>               // conceptual template for\nvoid func_for_x(T param);          // deducing x's type\nfunc_for_x(27);                    // conceptual call: param's\n                                   // deduced type is x's type\ntemplate<typename T>               // conceptual template for\nvoid func_for_cx(const T param);   // deducing cx's type\nfunc_for_cx(x);                    // conceptual call: param's\n                                   // deduced type is cx's type\ntemplate<typename T>               // conceptual template for\nvoid func_for_rx(const T& param);  // deducing rx's type\nfunc_for_rx(x);                    // conceptual call: param's\n                                   // deduced type is rx's type\nAs I said, deducing types for auto is, with only one exception (which we’ll discuss\nsoon), the same as deducing types for templates.\nItem 1 divides template type deduction into three cases, based on the characteristics\nof ParamType, the type specifier for param in the general function template. In a vari‐\nable declaration using auto, the type specifier takes the place of ParamType, so there\nare three cases for that, too:\n• Case 1: The type specifier is a pointer or reference, but not a universal reference.\n• Case 2: The type specifier is a universal reference.\nItem 2 \n| \n19\nwww.it-ebooks.info\n\n\n• Case 3: The type specifier is neither a pointer nor a reference.\nWe’ve already seen examples of cases 1 and 3:\nauto x = 27;          // case 3 (x is neither ptr nor reference)\nconst auto cx = x;    // case 3 (cx isn't either)\nconst auto& rx = x;   // case 1 (rx is a non-universal ref.)\nCase 2 works as you’d expect:\nauto&& uref1 = x;     // x is int and lvalue,\n                      // so uref1's type is int&\nauto&& uref2 = cx;    // cx is const int and lvalue,\n                      // so uref2's type is const int&\nauto&& uref3 = 27;    // 27 is int and rvalue,\n                      // so uref3's type is int&&\nItem 1 concludes with a discussion of how array and function names decay into\npointers for non-reference type specifiers. That happens in auto type deduction, too:\nconst char name[] =            // name's type is const char[13]\n  \"R. N. Briggs\";\nauto arr1 = name;              // arr1's type is const char*\nauto& arr2 = name;             // arr2's type is\n                               // const char (&)[13]\nvoid someFunc(int, double);    // someFunc is a function;\n                               // type is void(int, double)\nauto func1 = someFunc;         // func1's type is\n                               // void (*)(int, double)\nauto& func2 = someFunc;        // func2's type is\n                               // void (&)(int, double)\n20 \n| \nItem 2\nwww.it-ebooks.info\n\n\nAs you can see, auto type deduction works like template type deduction. They’re\nessentially two sides of the same coin.\nExcept for the one way they differ. We’ll start with the observation that if you want to\ndeclare an int with an initial value of 27, C++98 gives you two syntactic choices:\nint x1 = 27;\nint x2(27);\nC++11, through its support for uniform initialization, adds these:\nint x3 = { 27 };\nint x4{ 27 };\nAll in all, four syntaxes, but only one result: an int with value 27.\nBut as Item 5 explains, there are advantages to declaring variables using auto instead\nof fixed types, so it’d be nice to replace int with auto in the above variable declara‐\ntions. Straightforward textual substitution yields this code:\nauto x1 = 27;\nauto x2(27);\nauto x3 = { 27 };\nauto x4{ 27 };\nThese declarations all compile, but they don’t have the same meaning as the ones\nthey replace. The first two statements do, indeed, declare a variable of type int with\nvalue 27. The second two, however, declare a variable of type std::initial\nizer_list<int> containing a single element with value 27!\nauto x1 = 27;             // type is int, value is 27\nauto x2(27);              // ditto\nauto x3 = { 27 };         // type is std::initializer_list<int>,\n                          // value is { 27 }\nauto x4{ 27 };            // ditto\nThis is due to a special type deduction rule for auto. When the initializer for an\nauto-declared variable is enclosed in braces, the deduced type is a std::initial\nizer_list. If such a type can’t be deduced (e.g., because the values in the braced ini‐\ntializer are of different types), the code will be rejected:\nauto x5 = { 1, 2, 3.0 };  // error! can't deduce T for\n                          // std::initializer_list<T>\nItem 2 \n| \n21\nwww.it-ebooks.info\n\n\nAs the comment indicates, type deduction will fail in this case, but it’s important to\nrecognize that there are actually two kinds of type deduction taking place. One kind\nstems from the use of auto: x5’s type has to be deduced. Because x5’s initializer is in\nbraces, x5 must be deduced to be a std::initializer_list. But std::initial\nizer_list is a template. Instantiations are std::initializer_list<T> for some\ntype T, and that means that T’s type must also be deduced. Such deduction falls under\nthe purview of the second kind of type deduction occurring here: template type\ndeduction. In this example, that deduction fails, because the values in the braced ini‐\ntializer don’t have a single type.\nThe treatment of braced initializers is the only way in which auto type deduction and\ntemplate type deduction differ. When an auto–declared variable is initialized with a\nbraced initializer, the deduced type is an instantiation of std::initializer_list.\nBut if the corresponding template is passed the same initializer, type deduction fails,\nand the code is rejected:\nauto x = { 11, 23, 9 };   // x's type is\n                          // std::initializer_list<int>\ntemplate<typename T>      // template with parameter\nvoid f(T param);          // declaration equivalent to\n                          // x's declaration\nf({ 11, 23, 9 });         // error! can't deduce type for T\nHowever, if you specify in the template that param is a std::initializer_list<T>\nfor some unknown T, template type deduction will deduce what T is:\ntemplate<typename T>\nvoid f(std::initializer_list<T> initList);\nf({ 11, 23, 9 });         // T deduced as int, and initList's\n                          // type is std::initializer_list<int>\nSo the only real difference between auto and template type deduction is that auto\nassumes that a braced initializer represents a std::initializer_list, but template\ntype deduction doesn’t.\nYou might wonder why auto type deduction has a special rule for braced initializers,\nbut template type deduction does not. I wonder this myself. Alas, I have not been able\nto find a convincing explanation. But the rule is the rule, and this means you must\nremember that if you declare a variable using auto and you initialize it with a braced\ninitializer, the deduced type will always be std::initializer_list. It’s especially\nimportant to bear this in mind if you embrace the philosophy of uniform initializa‐\ntion—of enclosing initializing values in braces as a matter of course. A classic mistake\n22 \n| \nItem 2\nwww.it-ebooks.info\n\n\nin C++11 programming is accidentally declaring a std::initializer_list variable\nwhen you mean to declare something else. This pitfall is one of the reasons some\ndevelopers put braces around their initializers only when they have to. (When you\nhave to is discussed in Item 7.)\nFor C++11, this is the full story, but for C++14, the tale continues. C++14 permits\nauto to indicate that a function’s return type should be deduced (see Item 3), and\nC++14 lambdas may use auto in parameter declarations. However, these uses of\nauto employ template type deduction, not auto type deduction. So a function with an\nauto return type that returns a braced initializer won’t compile:\nauto createInitList()\n{\n  return { 1, 2, 3 };         // error: can't deduce type\n}                             // for { 1, 2, 3 }\nThe same is true when auto is used in a parameter type specification in a C++14\nlambda:\nstd::vector<int> v;\n…\nauto resetV =\n  [&v](const auto& newValue) { v = newValue; };     // C++14\n…\nresetV({ 1, 2, 3 });          // error! can't deduce type\n                              // for { 1, 2, 3 }\nThings to Remember\n• auto type deduction is usually the same as template type deduction, but auto\ntype deduction assumes that a braced initializer represents a std::initial\nizer_list, and template type deduction doesn’t.\n• auto in a function return type or a lambda parameter implies template type\ndeduction, not auto type deduction.\nItem 3: Understand decltype.\ndecltype is an odd creature. Given a name or an expression, decltype tells you the\nname’s or the expression’s type. Typically, what it tells you is exactly what you’d\nItem 2 \n| \n23\nwww.it-ebooks.info\n\n\npredict. Occasionally however, it provides results that leave you scratching your head\nand turning to reference works or online Q&A sites for revelation.\nWe’ll begin with the typical cases—the ones harboring no surprises. In contrast to\nwhat happens during type deduction for templates and auto (see Items 1 and 2),\ndecltype typically parrots back the exact type of the name or expression you give it:\nconst int i = 0;           // decltype(i) is const int\nbool f(const Widget& w);   // decltype(w) is const Widget&\n                           // decltype(f) is bool(const Widget&)\nstruct Point {\n  int x, y;                // decltype(Point::x) is int\n};                         // decltype(Point::y) is int\nWidget w;                  // decltype(w) is Widget\nif (f(w)) …                // decltype(f(w)) is bool\ntemplate<typename T>       // simplified version of std::vector\nclass vector {\npublic:\n  …\n  T& operator[](std::size_t index);\n  …\n};\nvector<int> v;             // decltype(v) is vector<int>\n…\nif (v[0] == 0) …           // decltype(v[0]) is int&\nSee? No surprises.\nIn C++11, perhaps the primary use for decltype is declaring function templates\nwhere the function’s return type depends on its parameter types. For example, sup‐\npose we’d like to write a function that takes a container that supports indexing via\nsquare brackets (i.e., the use of “[]”) plus an index, then authenticates the user before\nreturning the result of the indexing operation. The return type of the function should\nbe the same as the type returned by the indexing operation.\noperator[] on a container of objects of type T typically returns a T&. This is the case\nfor std::deque, for example, and it’s almost always the case for std::vector. For\nstd::vector<bool>, however, operator[] does not return a bool&. Instead, it\nreturns a brand new object. The whys and hows of this situation are explored in\n24 \n| \nItem 3\nwww.it-ebooks.info\n\n\nItem 6, but what’s important here is that the type returned by a container’s opera\ntor[] depends on the container.\ndecltype makes it easy to express that. Here’s a first cut at the template we’d like to\nwrite, showing the use of decltype to compute the return type. The template needs a\nbit of refinement, but we’ll defer that for now:\ntemplate<typename Container, typename Index>    // works, but\nauto authAndAccess(Container& c, Index i)       // requires\n  -> decltype(c[i])                             // refinement\n{\n  authenticateUser();\n  return c[i];\n}\nThe use of auto before the function name has nothing to do with type deduction.\nRather, it indicates that C++11’s trailing return type syntax is being used, i.e., that the\nfunction’s return type will be declared following the parameter list (after the “->”). A\ntrailing return type has the advantage that the function’s parameters can be used in\nthe specification of the return type. In authAndAccess, for example, we specify the\nreturn type using c and i. If we were to have the return type precede the function\nname in the conventional fashion, c and i would be unavailable, because they would\nnot have been declared yet.\nWith this declaration, authAndAccess returns whatever type operator[] returns\nwhen applied to the passed-in container, exactly as we desire.\nC++11 permits return types for single-statement lambdas to be deduced, and C++14\nextends this to both all lambdas and all functions, including those with multiple\nstatements. In the case of authAndAccess, that means that in C++14 we can omit the\ntrailing return type, leaving just the leading auto. With that form of declaration,\nauto does mean that type deduction will take place. In particular, it means that com‐\npilers will deduce the function’s return type from the function’s implementation:\ntemplate<typename Container, typename Index>    // C++14;\nauto authAndAccess(Container& c, Index i)       // not quite\n{                                               // correct\n  authenticateUser();\n  return c[i];                  // return type deduced from c[i]\n}\nItem 2 explains that for functions with an auto return type specification, compilers\nemploy template type deduction. In this case, that’s problematic. As we’ve discussed,\noperator[] for most containers-of-T returns a T&, but Item 1 explains that during\nItem 3 \n| \n25\nwww.it-ebooks.info\n\n\ntemplate type deduction, the reference-ness of an initializing expression is ignored.\nConsider what that means for this client code:\nstd::deque<int> d;\n…\nauthAndAccess(d, 5) = 10;  // authenticate user, return d[5],\n                           // then assign 10 to it;\n                           // this won't compile!\nHere, d[5] returns an int&, but auto return type deduction for authAndAccess will\nstrip off the reference, thus yielding a return type of int. That int, being the return\nvalue of a function, is an rvalue, and the code above thus attempts to assign 10 to an\nrvalue int. That’s forbidden in C++, so the code won’t compile.\nTo get authAndAccess to work as we’d like, we need to use decltype type deduction\nfor its return type, i.e., to specify that authAndAccess should return exactly the same\ntype that the expression c[i] returns. The guardians of C++, anticipating the need to\nuse decltype type deduction rules in some cases where types are inferred, make this\npossible in C++14 through the decltype(auto) specifier. What may initially seem\ncontradictory (decltype and auto?) actually makes perfect sense: auto specifies that\nthe type is to be deduced, and decltype says that decltype rules should be used\nduring the deduction. We can thus write authAndAccess like this:\ntemplate<typename Container, typename Index>   // C++14; works,\ndecltype(auto)                                 // but still\nauthAndAccess(Container& c, Index i)           // requires\n{                                              // refinement\n  authenticateUser();\n  return c[i];\n}\nNow authAndAccess will truly return whatever c[i] returns. In particular, for the\ncommon case where c[i] returns a T&, authAndAccess will also return a T&, and in\nthe uncommon case where c[i] returns an object, authAndAccess will return an\nobject, too.\nThe use of decltype(auto) is not limited to function return types. It can also be\nconvenient for declaring variables when you want to apply the decltype type deduc‐\ntion rules to the initializing expression:\nWidget w;\nconst Widget& cw = w;\nauto myWidget1 = cw;             // auto type deduction:\n26 \n| \nItem 3\nwww.it-ebooks.info\n\n\n                                 // myWidget1's type is Widget\ndecltype(auto) myWidget2 = cw;   // decltype type deduction:\n                                 // myWidget2's type is\n                                 //   const Widget&\nBut two things are bothering you, I know. One is the refinement to authAndAccess I\nmentioned, but have not yet described. Let’s address that now.\nLook again at the declaration for the C++14 version of authAndAccess:\ntemplate<typename Container, typename Index>\ndecltype(auto) authAndAccess(Container& c, Index i);\nThe container is passed by lvalue-reference-to-non-const, because returning a refer‐\nence to an element of the container permits clients to modify that container. But this\nmeans it’s not possible to pass rvalue containers to this function. Rvalues can’t bind\nto lvalue references (unless they’re lvalue-references-to-const, which is not the case\nhere).\nAdmittedly, passing an rvalue container to authAndAccess is an edge case. An rvalue\ncontainer, being a temporary object, would typically be destroyed at the end of the\nstatement containing the call to authAndAccess, and that means that a reference to\nan element in that container (which is typically what authAndAccess would return)\nwould dangle at the end of the statement that created it. Still, it could make sense to\npass a temporary object to authAndAccess. A client might simply want to make a\ncopy of an element in the temporary container, for example:\nstd::deque<std::string> makeStringDeque();   // factory function\n// make copy of 5th element of deque returned\n// from makeStringDeque\nauto s = authAndAccess(makeStringDeque(), 5);\nSupporting such use means we need to revise the declaration for authAndAccess to\naccept both lvalues and rvalues. Overloading would work (one overload would\ndeclare an lvalue reference parameter, the other an rvalue reference parameter), but\nthen we’d have two functions to maintain. A way to avoid that is to have authAndAc\ncess employ a reference parameter that can bind to lvalues and rvalues, and Item 24\nexplains that that’s exactly what universal references do. authAndAccess can there‐\nfore be declared like this:\ntemplate<typename Container, typename Index>    // c is now a\ndecltype(auto) authAndAccess(Container&& c,     // universal\n                             Index i);          // reference\nItem 3 \n| \n27\nwww.it-ebooks.info\n\n\nIn this template, we don’t know what type of container we’re operating on, and that\nmeans we’re equally ignorant of the type of index objects it uses. Employing pass-by-\nvalue for objects of an unknown type generally risks the performance hit of unneces‐\nsary copying, the behavioral problems of object slicing (see Item 41), and the sting of\nour coworkers’ derision, but in the case of container indices, following the example of\nthe Standard Library for index values (e.g., in operator[] for std::string,\nstd::vector, and std::deque) seems reasonable, so we’ll stick with pass-by-value\nfor them.\nHowever, we need to update the template’s implementation to bring it into accord\nwith Item 25’s admonition to apply std::forward to universal references:\ntemplate<typename Container, typename Index>       // final\ndecltype(auto)                                     // C++14\nauthAndAccess(Container&& c, Index i)              // version\n{\n  authenticateUser();\n  return std::forward<Container>(c)[i];\n}\nThis should do everything we want, but it requires a C++14 compiler. If you don’t\nhave one, you’ll need to use the C++11 version of the template. It’s the same as its\nC++14 counterpart, except that you have to specify the return type yourself:\ntemplate<typename Container, typename Index>       // final\nauto                                               // C++11\nauthAndAccess(Container&& c, Index i)              // version\n-> decltype(std::forward<Container>(c)[i])\n{\n  authenticateUser();\n  return std::forward<Container>(c)[i];\n}\nThe other issue that’s likely to be nagging at you is my remark at the beginning of this\nItem that decltype almost always produces the type you expect, that it rarely sur‐\nprises. Truth be told, you’re unlikely to encounter these exceptions to the rule unless\nyou’re a heavy-duty library implementer.\nTo fully understand decltype’s behavior, you’ll have to familiarize yourself with a\nfew special cases. Most of these are too obscure to warrant discussion in a book like\nthis, but looking at one lends insight into decltype as well as its use.\nApplying decltype to a name yields the declared type for that name. Names are\nlvalue expressions, but that doesn’t affect decltype’s behavior. For lvalue expressions\nmore complicated than names, however, decltype ensures that the type reported is\n28 \n| \nItem 3\nwww.it-ebooks.info\n\n\nalways an lvalue reference. That is, if an lvalue expression other than a name has type\nT, decltype reports that type as T&. This seldom has any impact, because the type of\nmost lvalue expressions inherently includes an lvalue reference qualifier. Functions\nreturning lvalues, for example, always return lvalue references.\nThere is an implication of this behavior that is worth being aware of, however. In\nint x = 0;\nx is the name of a variable, so decltype(x) is int. But wrapping the name x in\nparentheses—“(x)”—yields an expression more complicated than a name. Being a\nname, x is an lvalue, and C++ defines the expression (x) to be an lvalue, too.\ndecltype((x)) is therefore int&. Putting parentheses around a name can change\nthe type that decltype reports for it!\nIn C++11, this is little more than a curiosity, but in conjunction with C++14’s sup‐\nport for decltype(auto), it means that a seemingly trivial change in the way you\nwrite a return statement can affect the deduced type for a function:\ndecltype(auto) f1()\n{\n  int x = 0;\n  …\n  return x;        // decltype(x) is int, so f1 returns int\n}\ndecltype(auto) f2()\n{\n  int x = 0;\n  …\n  return (x);      // decltype((x)) is int&, so f2 returns int&\n}\nNote that not only does f2 have a different return type from f1, it’s also returning a\nreference to a local variable! That’s the kind of code that puts you on the express train\nto undefined behavior—a train you certainly don’t want to be on.\nThe primary lesson is to pay very close attention when using decltype(auto).\nSeemingly insignificant details in the expression whose type is being deduced can\naffect the type that decltype(auto) reports. To ensure that the type being deduced\nis the type you expect, use the techniques described in Item 4.\nAt the same time, don’t lose sight of the bigger picture. Sure, decltype (both alone\nand in conjunction with auto) may occasionally yield type-deduction surprises, but\nthat’s not the normal situation. Normally, decltype produces the type you expect.\nItem 3 \n| \n29\nwww.it-ebooks.info\n\n\nThis is especially true when decltype is applied to names, because in that case,\ndecltype does just what it sounds like: it reports that name’s declared type.\n \nThings to Remember\n• decltype almost always yields the type of a variable or expression without\nany modifications.\n• For lvalue expressions of type T other than names, decltype always reports a\ntype of T&.\n• C++14 supports decltype(auto), which, like auto, deduces a type from its\ninitializer, but it performs the type deduction using the decltype rules.\nItem 4: Know how to view deduced types.\nThe choice of tools for viewing the results of type deduction is dependent on the\nphase of the software development process where you want the information. We’ll\nexplore three possibilities: getting type deduction information as you edit your code,\ngetting it during compilation, and getting it at runtime.\nIDE Editors\nCode editors in IDEs often show the types of program entities (e.g., variables, param‐\neters, functions, etc.) when you do something like hover your cursor over the entity.\nFor example, given this code,      \nconst int theAnswer = 42;\nauto x = theAnswer;\nauto y = &theAnswer;\nan IDE editor would likely show that x’s deduced type was int and y’s was const\nint*.\nFor this to work, your code must be in a more or less compilable state, because what\nmakes it possible for the IDE to offer this kind of information is a C++ compiler (or\nat least the front end of one) running inside the IDE. If that compiler can’t make\nenough sense of your code to parse it and perform type deduction, it can’t show you\nwhat types it deduced.\nFor simple types like int, information from IDEs is generally fine. As we’ll see soon,\nhowever, when more complicated types are involved, the information displayed by\nIDEs may not be particularly helpful.\n30 \n| \nItem 3\nwww.it-ebooks.info\n",
      "page_number": 36,
      "chapter_number": 5,
      "summary": "This chapter covers segment 5 (pages 36-48). Key topics include returns, item, and templates. • During template type deduction, arguments that are array or function names\ndecay to pointers, unless they’re used to initialize references.",
      "keywords": [
        "type",
        "template type deduction",
        "type deduction",
        "auto type deduction",
        "template type",
        "auto",
        "return type",
        "auto type",
        "deduction",
        "template",
        "int",
        "Item",
        "decltype",
        "container",
        "auto return type"
      ],
      "concepts": [
        "returns",
        "item",
        "templates",
        "deduction",
        "references",
        "refer",
        "std",
        "cases",
        "initialize",
        "initializing"
      ],
      "similar_chapters": [
        {
          "book": "C++ Templates_ The Complete Guide",
          "chapter": 52,
          "title": "Segment 52 (pages 1664-1696)",
          "relevance_score": 0.78,
          "method": "sentence_transformers"
        },
        {
          "book": "C++ Templates_ The Complete Guide",
          "chapter": 55,
          "title": "Segment 55 (pages 1762-1792)",
          "relevance_score": 0.78,
          "method": "sentence_transformers"
        },
        {
          "book": "C++ Templates_ The Complete Guide",
          "chapter": 1,
          "title": "Segment 1 (pages 1-35)",
          "relevance_score": 0.75,
          "method": "sentence_transformers"
        },
        {
          "book": "C++ Templates_ The Complete Guide",
          "chapter": 15,
          "title": "Segment 15 (pages 456-487)",
          "relevance_score": 0.75,
          "method": "sentence_transformers"
        },
        {
          "book": "C++ Templates_ The Complete Guide",
          "chapter": 43,
          "title": "Segment 43 (pages 1373-1403)",
          "relevance_score": 0.75,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 6,
      "title": "Segment 6 (pages 49-59)",
      "start_page": 49,
      "end_page": 59,
      "detection_method": "topic_boundary",
      "content": "Compiler Diagnostics\nAn effective way to get a compiler to show a type it has deduced is to use that type in\na way that leads to compilation problems. The error message reporting the problem\nis virtually sure to mention the type that’s causing it.\nSuppose, for example, we’d like to see the types that were deduced for x and y in the\nprevious example. We first declare a class template that we don’t define. Something\nlike this does nicely:\ntemplate<typename T>       // declaration only for TD;\nclass TD;                  // TD == \"Type Displayer\"\nAttempts to instantiate this template will elicit an error message, because there’s no\ntemplate definition to instantiate. To see the types for x and y, just try to instantiate\nTD with their types:\nTD<decltype(x)> xType;     // elicit errors containing\nTD<decltype(y)> yType;     // x's and y's types\nI use variable names of the form variableNameType, because they tend to yield error\nmessages that help me find the information I’m looking for. For the code above, one\nof my compilers issues diagnostics reading, in part, as follows (I’ve highlighted the\ntype information we’re after):\nerror: aggregate 'TD<int> xType' has incomplete type and\n    cannot be defined\nerror: aggregate 'TD<const int *> yType' has incomplete type\n    and cannot be defined\nA different compiler provides the same information, but in a different form:\nerror: 'xType' uses undefined class 'TD<int>'\nerror: 'yType' uses undefined class 'TD<const int *>'\nFormatting differences aside, all the compilers I’ve tested produce error messages\nwith useful type information when this technique is employed.\nRuntime Output\nThe printf approach to displaying type information (not that I’m recommending\nyou use printf) can’t be employed until runtime, but it offers full control over the\nformatting of the output. The challenge is to create a textual representation of the\ntype you care about that is suitable for display. “No sweat,” you’re thinking, “it’s\ntypeid and std::type_info::name to the rescue.” In our continuing quest to see\nthe types deduced for x and y, you may figure we can write this:\nItem 4 \n| \n31\nwww.it-ebooks.info\n\n\nstd::cout << typeid(x).name() << '\\n';    // display types for\nstd::cout << typeid(y).name() << '\\n';    // x and y\nThis approach relies on the fact that invoking typeid on an object such as x or y\nyields a std::type_info object, and std::type_info has a member function, name,\nthat produces a C-style string (i.e., a const char*) representation of the name of the\ntype.\nCalls to std::type_info::name are not guaranteed to return anything sensible, but\nimplementations try to be helpful. The level of helpfulness varies. The GNU and\nClang compilers report that the type of x is “i”, and the type of y is “PKi”, for exam‐\nple. These results make sense once you learn that, in output from these compilers, “i”\nmeans “int” and “PK” means “pointer to konst const.” (Both compilers support a\ntool, c++filt, that decodes such “mangled” types.) Microsoft’s compiler produces\nless cryptic output: “int” for x and “int const *” for y.\nBecause these results are correct for the types of x and y, you might be tempted to\nview the type-reporting problem as solved, but let’s not be hasty. Consider a more\ncomplex example:\ntemplate<typename T>                 // template function to\nvoid f(const T& param);              // be called\nstd::vector<Widget> createVec();     // factory function\nconst auto vw = createVec();         // init vw w/factory return\nif (!vw.empty()) {\n  f(&vw[0]);                         // call f\n  …\n}\nThis code, which involves a user-defined type (Widget), an STL container (std::vec\ntor), and an auto variable (vw), is more representative of the situations where you\nmight want some visibility into the types your compilers are deducing. For example,\nit’d be nice to know what types are inferred for the template type parameter T and the\nfunction parameter param in f.\nLoosing typeid on the problem is straightforward. Just add some code to f to display\nthe types you’d like to see: \ntemplate<typename T>\nvoid f(const T& param)\n{\n  using std::cout;\n32 \n| \nItem 4\nwww.it-ebooks.info\n\n\n  cout << \"T =     \" << typeid(T).name() << '\\n';     // show T\n  cout << \"param = \" << typeid(param).name() << '\\n'; // show\n  …                                                   // param's\n}                                                     // type\nExecutables produced by the GNU and Clang compilers produce this output:\nT =     PK6Widget\nparam = PK6Widget\nWe already know that for these compilers, PK means “pointer to const,” so the only\nmystery is the number 6. That’s simply the number of characters in the class name\nthat follows (Widget). So these compilers tell us that both T and param are of type\nconst Widget*.\nMicrosoft’s compiler concurs:\nT =     class Widget const *\nparam = class Widget const *\nThree independent compilers producing the same information suggests that the\ninformation is accurate. But look more closely. In the template f, param’s declared\ntype is const T&. That being the case, doesn’t it seem odd that T and param have the\nsame type? If T were int, for example, param’s type should be const int&—not the\nsame type at all.\nSadly, the results of std::type_info::name are not reliable. In this case, for exam‐\nple, the type that all three compilers report for param are incorrect. Furthermore,\nthey’re essentially required to be incorrect, because the specification for std::\ntype_info::name mandates that the type be treated as if it had been passed to a tem‐\nplate function as a by-value parameter. As Item 1 explains, that means that if the type\nis a reference, its reference-ness is ignored, and if the type after reference removal is\nconst (or volatile), its constness (or volatileness) is also ignored. That’s why\nparam’s type—which is const Widget * const &—is reported as const Widget*.\nFirst the type’s reference-ness is removed, and then the constness of the resulting\npointer is eliminated.\nEqually sadly, the type information displayed by IDE editors is also not reliable—or\nat least not reliably useful. For this same example, one IDE editor I know reports T’s\ntype as (I am not making this up):\nconst\nstd::_Simple_types<std::_Wrap_alloc<std::_Vec_base_types<Widget,\nstd::allocator<Widget> >::_Alloc>::value_type>::value_type *\nThe same IDE editor shows param’s type as:\nItem 4 \n| \n33\nwww.it-ebooks.info\n\n\nconst std::_Simple_types<...>::value_type *const &\nThat’s less intimidating than the type for T, but the “...” in the middle is confusing\nuntil you realize that it’s the IDE editor’s way of saying “I’m omitting all that stuff\nthat’s part of T’s type.” With any luck, your development environment does a better\njob on code like this.\nIf you’re more inclined to rely on libraries than luck, you’ll be pleased to know that\nwhere std::type_info::name and IDEs may fail, the Boost TypeIndex library\n(often written as Boost.TypeIndex) is designed to succeed. The library isn’t part of\nStandard C++, but neither are IDEs or templates like TD. Furthermore, the fact that\nBoost libraries (available at boost.com) are cross-platform, open source, and available\nunder a license designed to be palatable to even the most paranoid corporate legal\nteam means that code using Boost libraries is nearly as portable as code relying on the\nStandard Library.\nHere’s how our function f can produce accurate type information using Boost.Type‐\nIndex:\n#include <boost/type_index.hpp>\ntemplate<typename T>\nvoid f(const T& param)\n{\n  using std::cout;\n  using boost::typeindex::type_id_with_cvr;\n  // show T\n  cout << \"T =     \"\n       << type_id_with_cvr<T>().pretty_name()\n       << '\\n';\n  // show param's type\n  cout << \"param = \"\n       << type_id_with_cvr<decltype(param)>().pretty_name()\n       << '\\n';\n  …\n}\nThe way this works is that the function template boost::typeindex::\ntype_id_with_cvr takes a type argument (the type about which we want informa‐\ntion) and doesn’t remove const, volatile, or reference qualifiers (hence the\n“with_cvr” in the template name). The result is a boost::typeindex::type_index\nobject, whose pretty_name member function produces a std::string containing a\nhuman-friendly representation of the type.\n34 \n| \nItem 4\nwww.it-ebooks.info\n\n\nWith this implementation for f, consider again the call that yields incorrect type\ninformation for param when typeid is used:\nstd::vector<Widget> createVec();     // factory function\nconst auto vw = createVec();         // init vw w/factory return\nif (!vw.empty()) {\n  f(&vw[0]);                         // call f\n  …\n}\nUnder compilers from GNU and Clang, Boost.TypeIndex produces this (accurate)\noutput:\nT =     Widget const*\nparam = Widget const* const&\nResults under Microsoft’s compiler are essentially the same:\nT =     class Widget const *\nparam = class Widget const * const &\nSuch near-uniformity is nice, but it’s important to remember that IDE editors, com‐\npiler error messages, and libraries like Boost.TypeIndex are merely tools you can use\nto help you figure out what types your compilers are deducing. All can be helpful, but\nat the end of the day, there’s no substitute for understanding the type deduction\ninformation in Items 1–3.\nThings to Remember\n• Deduced types can often be seen using IDE editors, compiler error messages,\nand the Boost TypeIndex library.\n• The results of some tools may be neither helpful nor accurate, so an under‐\nstanding of C++’s type deduction rules remains essential.\nItem 4 \n| \n35\nwww.it-ebooks.info\n\n\nwww.it-ebooks.info\n\n\nCHAPTER 2\nauto\nIn concept, auto is as simple as simple can be, but it’s more subtle than it looks.\nUsing it saves typing, sure, but it also prevents correctness and performance issues\nthat can bedevil manual type declarations. Furthermore, some of auto’s type deduc‐\ntion results, while dutifully conforming to the prescribed algorithm, are, from the\nperspective of a programmer, just wrong. When that’s the case, it’s important to\nknow how to guide auto to the right answer, because falling back on manual type\ndeclarations is an alternative that’s often best avoided.\nThis brief chapter covers all of auto’s ins and outs.\nItem 5: Prefer auto to explicit type declarations.\nAh, the simple joy of\nint x;\nWait. Damn. I forgot to initialize x, so its value is indeterminate. Maybe. It might\nactually be initialized to zero. Depends on the context. Sigh.\nNever mind. Let’s move on to the simple joy of declaring a local variable to be initial‐\nized by dereferencing an iterator:\ntemplate<typename It>    // algorithm to dwim (\"do what I mean\")\nvoid dwim(It b, It e)    // for all elements in range from\n{                        // b to e\n  while (b != e) {\n    typename std::iterator_traits<It>::value_type\n      currValue = *b;\n    …\n37\nwww.it-ebooks.info\n\n\n  }\n}\nUgh. “typename std::iterator_traits<It>::value_type” to express the type of\nthe value pointed to by an iterator? Really? I must have blocked out the memory of\nhow much fun that is. Damn. Wait—didn’t I already say that?\nOkay, simple joy (take three): the delight of declaring a local variable whose type is\nthat of a closure. Oh, right. The type of a closure is known only to the compiler,\nhence can’t be written out. Sigh. Damn.\nDamn, damn, damn! Programming in C++ is not the joyous experience it should be!\nWell, it didn’t used to be. But as of C++11, all these issues go away, courtesy of auto.\nauto variables have their type deduced from their initializer, so they must be initial‐\nized. That means you can wave goodbye to a host of uninitialized variable problems\nas you speed by on the modern C++ superhighway:\nint x1;                     // potentially uninitialized\nauto x2;                    // error! initializer required\nauto x3 = 0;                // fine, x's value is well-defined\nSaid highway lacks the potholes associated with declaring a local variable whose value\nis that of a dereferenced iterator:\ntemplate<typename It>       // as before\nvoid dwim(It b, It e)\n{\n  while (b != e) {\n    auto currValue = *b;\n    …\n  }\n}\nAnd because auto uses type deduction (see Item 2), it can represent types known\nonly to compilers:\nauto derefUPLess =                        // comparison func.\n  [](const std::unique_ptr<Widget>& p1,   // for Widgets\n     const std::unique_ptr<Widget>& p2)   // pointed to by\n  { return *p1 < *p2; };                  // std::unique_ptrs\nVery cool. In C++14, the temperature drops further, because parameters to lambda\nexpressions may involve auto:\nauto derefLess =                          // C++14 comparison\n  [](const auto& p1,                      // function for\n38 \n| \nItem 5\nwww.it-ebooks.info\n\n\n     const auto& p2)                      // values pointed\n  { return *p1 < *p2; };                  // to by anything\n                                          // pointer-like\nCoolness notwithstanding, perhaps you’re thinking we don’t really need auto to\ndeclare a variable that holds a closure, because we can use a std::function object.\nIt’s true, we can, but possibly that’s not what you were thinking. And maybe now\nyou’re thinking “What’s a std::function object?” So let’s clear that up.\nstd::function is a template in the C++11 Standard Library that generalizes the idea\nof a function pointer. Whereas function pointers can point only to functions, how‐\never, std::function objects can refer to any callable object, i.e., to anything that can\nbe invoked like a function. Just as you must specify the type of function to point to\nwhen you create a function pointer (i.e., the signature of the functions you want to\npoint to), you must specify the type of function to refer to when you create a\nstd::function object. You do that through std::function’s template parameter.\nFor example, to declare a std::function object named func that could refer to any\ncallable object acting as if it had this signature,\nbool(const std::unique_ptr<Widget>&,  // C++11 signature for\n     const std::unique_ptr<Widget>&)  // std::unique_ptr<Widget>\n                                      // comparison function\nyou’d write this:\nstd::function<bool(const std::unique_ptr<Widget>&,\n                   const std::unique_ptr<Widget>&)> func;\nBecause lambda expressions yield callable objects, closures can be stored in\nstd::function objects. That means we could declare the C++11 version of derefUP\nLess without using auto as follows:\nstd::function<bool(const std::unique_ptr<Widget>&,\n                   const std::unique_ptr<Widget>&)>\n  derefUPLess = [](const std::unique_ptr<Widget>& p1,\n                   const std::unique_ptr<Widget>& p2)\n                  { return *p1 < *p2; };\nIt’s important to recognize that even setting aside the syntactic verbosity and need to\nrepeat the parameter types, using std::function is not the same as using auto. An\nauto-declared variable holding a closure has the same type as the closure, and as such\nit uses only as much memory as the closure requires. The type of a std::function-\ndeclared variable holding a closure is an instantiation of the std::function tem‐\nplate, and that has a fixed size for any given signature. This size may not be adequate\nfor the closure it’s asked to store, and when that’s the case, the std::function con‐\nstructor will allocate heap memory to store the closure. The result is that the\nItem 5 \n| \n39\nwww.it-ebooks.info\n\n\nstd::function object typically uses more memory than the auto-declared object.\nAnd, thanks to implementation details that restrict inlining and yield indirect func‐\ntion calls, invoking a closure via a std::function object is almost certain to be\nslower than calling it via an auto-declared object. In other words, the std::func\ntion approach is generally bigger and slower than the auto approach, and it may\nyield out-of-memory exceptions, too. Plus, as you can see in the examples above,\nwriting “auto” is a whole lot less work than writing the type of the std::function\ninstantiation. In the competition between auto and std::function for holding a\nclosure, it’s pretty much game, set, and match for auto. (A similar argument can be\nmade for auto over std::function for holding the result of calls to std::bind, but\nin Item 34, I do my best to convince you to use lambdas instead of std::bind, any‐\nway.)\nThe advantages of auto extend beyond the avoidance of uninitialized variables, ver‐\nbose variable declarations, and the ability to directly hold closures. One is the ability\nto avoid what I call problems related to “type shortcuts.” Here’s something you’ve\nprobably seen—possibly even written:\nstd::vector<int> v;\n…\nunsigned sz = v.size();\nThe official return type of v.size() is std::vector<int>::size_type, but few\ndevelopers are aware of that. std::vector<int>::size_type is specified to be an\nunsigned integral type, so a lot of programmers figure that unsigned is good enough\nand write code such as the above. This can have some interesting consequences. On\n32-bit Windows, for example, both unsigned and std::vector<int>::size_type\nare the same size, but on 64-bit Windows, unsigned is 32 bits, while std::vec\ntor<int>::size_type is 64 bits. This means that code that works under 32-bit\nWindows may behave incorrectly under 64-bit Windows, and when porting your\napplication from 32 to 64 bits, who wants to spend time on issues like that?\nUsing auto ensures that you don’t have to:\nauto sz = v.size();  // sz's type is std::vector<int>::size_type\nStill unsure about the wisdom of using auto? Then consider this code:\nstd::unordered_map<std::string, int> m;\n…\nfor (const std::pair<std::string, int>& p : m)\n{\n  …                   // do something with p\n}\n40 \n| \nItem 5\nwww.it-ebooks.info\n\n\nThis looks perfectly reasonable, but there’s a problem. Do you see it?\nRecognizing what’s amiss requires remembering that the key part of a std::unor\ndered_map is const, so the type of std::pair in the hash table (which is what a\nstd::unordered_map is) isn’t std::pair<std::string, int>, it’s std::pair\n<const std::string, int>. But that’s not the type declared for the variable p in the\nloop above. As a result, compilers will strive to find a way to convert\nstd::pair<const std::string, int> objects (i.e., what’s in the hash table) to\nstd::pair<std::string, int> objects (the declared type for p). They’ll succeed by\ncreating a temporary object of the type that p wants to bind to by copying each object\nin m, then binding the reference p to that temporary object. At the end of each loop\niteration, the temporary object will be destroyed. If you wrote this loop, you’d likely\nbe surprised by this behavior, because you’d almost certainly intend to simply bind\nthe reference p to each element in m.\nSuch unintentional type mismatches can be autoed away:\nfor (const auto& p : m)\n{\n  …                             // as before\n}\nThis is not only more efficient, it’s also easier to type. Furthermore, this code has the\nvery attractive characteristic that if you take p’s address, you’re sure to get a pointer\nto an element within m. In the code not using auto, you’d get a pointer to a tempo‐\nrary object—an object that would be destroyed at the end of the loop iteration.\nThe last two examples—writing unsigned when you should have written std::vec\ntor<int>::size_type and writing std::pair<std::string, int> when you\nshould have written std::pair<const std::string, int>—demonstrate how\nexplicitly specifying types can lead to implicit conversions that you neither want nor\nexpect. If you use auto as the type of the target variable, you need not worry about\nmismatches between the type of variable you’re declaring and the type of the expres‐\nsion used to initialize it.\nThere are thus several reasons to prefer auto over explicit type declarations. Yet auto\nisn’t perfect. The type for each auto variable is deduced from its initializing expres‐\nsion, and some initializing expressions have types that are neither anticipated nor\ndesired. The conditions under which such cases arise, and what you can do about\nthem, are discussed in Items 2 and 6, so I won’t address them here. Instead, I’ll turn\nmy attention to a different concern you may have about using auto in place of tradi‐\ntional type declarations: the readability of the resulting source code.\nItem 5 \n| \n41\nwww.it-ebooks.info\n",
      "page_number": 49,
      "chapter_number": 6,
      "summary": "This chapter covers segment 6 (pages 49-59). Key topics include type, typing. Covers function. We first declare a class template that we don’t define.",
      "keywords": [
        "type",
        "std",
        "const std",
        "Widget",
        "const",
        "Widget const",
        "class Widget const",
        "auto",
        "Widgets const std",
        "function",
        "type const Widget",
        "int",
        "param",
        "Item",
        "class Widget"
      ],
      "concepts": [
        "type",
        "typing",
        "std",
        "compiler",
        "widget",
        "function",
        "functions",
        "error",
        "variable",
        "variables"
      ],
      "similar_chapters": [
        {
          "book": "C++ Templates_ The Complete Guide",
          "chapter": 48,
          "title": "Segment 48 (pages 1536-1565)",
          "relevance_score": 0.75,
          "method": "sentence_transformers"
        },
        {
          "book": "C++ Templates_ The Complete Guide",
          "chapter": 30,
          "title": "Segment 30 (pages 950-980)",
          "relevance_score": 0.71,
          "method": "sentence_transformers"
        },
        {
          "book": "C++ Templates_ The Complete Guide",
          "chapter": 31,
          "title": "Segment 31 (pages 981-1014)",
          "relevance_score": 0.7,
          "method": "sentence_transformers"
        },
        {
          "book": "C++ Templates_ The Complete Guide",
          "chapter": 54,
          "title": "Segment 54 (pages 1729-1761)",
          "relevance_score": 0.69,
          "method": "sentence_transformers"
        },
        {
          "book": "C++ Templates_ The Complete Guide",
          "chapter": 55,
          "title": "Segment 55 (pages 1762-1792)",
          "relevance_score": 0.69,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 7,
      "title": "Segment 7 (pages 60-80)",
      "start_page": 60,
      "end_page": 80,
      "detection_method": "topic_boundary",
      "content": "First, take a deep breath and relax. auto is an option, not a mandate. If, in your pro‐\nfessional judgment, your code will be clearer or more maintainable or in some other\nway better by using explicit type declarations, you’re free to continue using them. But\nbear in mind that C++ breaks no new ground in adopting what is generally known in\nthe programming languages world as type inference. Other statically typed procedural\nlanguages (e.g., C#, D, Scala, Visual Basic) have a more or less equivalent feature, to\nsay nothing of a variety of statically typed functional languages (e.g., ML, Haskell,\nOCaml, F#, etc.). In part, this is due to the success of dynamically typed languages\nsuch as Perl, Python, and Ruby, where variables are rarely explicitly typed. The soft‐\nware development community has extensive experience with type inference, and it\nhas demonstrated that there is nothing contradictory about such technology and the\ncreation and maintenance of large, industrial-strength code bases.\nSome developers are disturbed by the fact that using auto eliminates the ability to\ndetermine an object’s type by a quick glance at the source code. However, IDEs’ abil‐\nity to show object types often mitigates this problem (even taking into account the\nIDE type-display issues mentioned in Item 4), and, in many cases, a somewhat\nabstract view of an object’s type is just as useful as the exact type. It often suffices, for\nexample, to know that an object is a container or a counter or a smart pointer,\nwithout knowing exactly what kind of container, counter, or smart pointer it is.\nAssuming well-chosen variable names, such abstract type information should almost\nalways be at hand.\nThe fact of the matter is that writing types explicitly often does little more than intro‐\nduce opportunities for subtle errors, either in correctness or efficiency or both. Fur‐\nthermore, auto types automatically change if the type of their initializing expression\nchanges, and that means that some refactorings are facilitated by the use of auto. For\nexample, if a function is declared to return an int, but you later decide that a long\nwould be better, the calling code automatically updates itself the next time you com‐\npile if the results of calling the function are stored in auto variables. If the results are\nstored in variables explicitly declared to be int, you’ll need to find all the call sites so\nthat you can revise them.\nThings to Remember\n• auto variables must be initialized, are generally immune to type mismatches\nthat can lead to portability or efficiency problems, can ease the process of\nrefactoring, and typically require less typing than variables with explicitly\nspecified types.\n• auto-typed variables are subject to the pitfalls described in Items 2 and 6.\n42 \n| \nItem 5\nwww.it-ebooks.info\n\n\nItem 6: Use the explicitly typed initializer idiom when\nauto deduces undesired types.\nItem 5 explains that using auto to declare variables offers a number of technical\nadvantages over explicitly specifying types, but sometimes auto’s type deduction zigs\nwhen you want it to zag. For example, suppose I have a function that takes a Widget\nand returns a std::vector<bool>, where each bool indicates whether the Widget\noffers a particular feature:\nstd::vector<bool> features(const Widget& w);\nFurther suppose that bit 5 indicates whether the Widget has high priority. We can\nthus write code like this:\nWidget w;\n…\nbool highPriority = features(w)[5];  // is w high priority?\n…\nprocessWidget(w, highPriority);      // process w in accord\n                                     // with its priority\nThere’s nothing wrong with this code. It’ll work fine. But if we make the seemingly\ninnocuous change of replacing the explicit type for highPriority with auto,\nauto highPriority = features(w)[5];  // is w high priority?\nthe situation changes. All the code will continue to compile, but its behavior is no\nlonger predictable:\nprocessWidget(w, highPriority);      // undefined behavior!\nAs the comment indicates, the call to processWidget now has undefined behavior.\nBut why? The answer is likely to be surprising. In the code using auto, the type of\nhighPriority is no longer bool. Though std::vector<bool> conceptually holds\nbools, operator[] for std::vector<bool> doesn’t return a reference to an element\nof the container (which is what std::vector::operator[] returns for every type\nexcept bool). Instead, it returns an object of type std::vector<bool>::reference\n(a class nested inside std::vector<bool>).\nstd::vector<bool>::reference exists because std::vector<bool> is specified to\nrepresent its bools in packed form, one bit per bool. That creates a problem for\nstd::vector<bool>’s operator[], because operator[] for std::vector<T> is\nsupposed to return a T&, but C++ forbids references to bits. Not being able to return a\nItem 6 \n| \n43\nwww.it-ebooks.info\n\n\nbool&, operator[] for std::vector<bool> returns an object that acts like a bool&.\nFor this act to succeed, std::vector<bool>::reference objects must be usable in\nessentially all contexts where bool&s can be. Among the features in std::vec\ntor<bool>::reference that make this work is an implicit conversion to bool. (Not\nto bool&, to bool. To explain the full set of techniques used by std::vec\ntor<bool>::reference to emulate the behavior of a bool& would take us too far\nafield, so I’ll simply remark that this implicit conversion is only one stone in a larger\nmosaic.)\nWith this information in mind, look again at this part of the original code:\nbool highPriority = features(w)[5];  // declare highPriority's\n                                     // type explicitly\nHere, features returns a std::vector<bool> object, on which operator[] is\ninvoked. operator[] returns a std::vector<bool>::reference object, which is\nthen implicitly converted to the bool that is needed to initialize highPriority. high\nPriority thus ends up with the value of bit 5 in the std::vector<bool> returned\nby features, just like it’s supposed to.\nContrast that with what happens in the auto-ized declaration for highPriority:\nauto highPriority = features(w)[5];  // deduce highPriority's\n                                     // type\nAgain, features returns a std::vector<bool> object, and, again, operator[] is\ninvoked on it. operator[] continues to return a std::vector<bool>::reference\nobject, but now there’s a change, because auto deduces that as the type of highPrior\nity. highPriority doesn’t have the value of bit 5 of the std::vector<bool>\nreturned by features at all.\nThe value it does have depends on how std::vector<bool>::reference is imple‐\nmented. One implementation is for such objects to contain a pointer to the machine\nword holding the referenced bit, plus the offset into that word for that bit. Consider\nwhat that means for the initialization of highPriority, assuming that such a\nstd::vector<bool>::reference implementation is in place.\nThe call to features returns a temporary std::vector<bool> object. This object\nhas no name, but for purposes of this discussion, I’ll call it temp. operator[] is\ninvoked on temp, and the std::vector<bool>::reference it returns contains a\npointer to a word in the data structure holding the bits that are managed by temp,\nplus the offset into that word corresponding to bit 5. highPriority is a copy of this\nstd::vector<bool>::reference object, so highPriority, too, contains a pointer\nto a word in temp, plus the offset corresponding to bit 5. At the end of the statement,\n44 \n| \nItem 6\nwww.it-ebooks.info\n\n\ntemp is destroyed, because it’s a temporary object. Therefore, highPriority contains\na dangling pointer, and that’s the cause of the undefined behavior in the call to proc\nessWidget:\nprocessWidget(w, highPriority);    // undefined behavior!\n                                   // highPriority contains\n                                   // dangling pointer!\nstd::vector<bool>::reference is an example of a proxy class: a class that exists\nfor the purpose of emulating and augmenting the behavior of some other type. Proxy\nclasses are employed for a variety of purposes. std::vector<bool>::reference\nexists to offer the illusion that operator[] for std::vector<bool> returns a refer‐\nence to a bit, for example, and the Standard Library’s smart pointer types (see Chap‐\nter 4) are proxy classes that graft resource management onto raw pointers. The utility\nof proxy classes is well-established. In fact, the design pattern “Proxy” is one of the\nmost longstanding members of the software design patterns Pantheon.\nSome proxy classes are designed to be apparent to clients. That’s the case for\nstd::shared_ptr and std::unique_ptr, for example. Other proxy classes are\ndesigned to act more or less invisibly. std::vector<bool>::reference is an exam‐\nple of such “invisible” proxies, as is its std::bitset compatriot, std::bitset::ref\nerence.\nAlso in that camp are some classes in C++ libraries employing a technique known as\nexpression templates. Such libraries were originally developed to improve the effi‐\nciency of numeric code. Given a class Matrix and Matrix objects m1, m2, m3, and m4,\nfor example, the expression\nMatrix sum = m1 + m2 + m3 + m4;\ncan be computed much more efficiently if operator+ for Matrix objects returns a\nproxy for the result instead of the result itself. That is, operator+ for two Matrix\nobjects would return an object of a proxy class such as Sum<Matrix, Matrix> instead\nof a Matrix object. As was the case with std::vector<bool>::reference and\nbool, there’d be an implicit conversion from the proxy class to Matrix, which would\npermit the initialization of sum from the proxy object produced by the expression on\nthe right side of the “=”. (The type of that object would traditionally encode the entire\ninitialization expression, i.e., be something like Sum<Sum<Sum<Matrix, Matrix>,\nMatrix>, Matrix>. That’s definitely a type from which clients should be shielded.)\nAs a general rule, “invisible” proxy classes don’t play well with auto. Objects of such\nclasses are often not designed to live longer than a single statement, so creating vari‐\nables of those types tends to violate fundamental library design assumptions. That’s\nItem 6 \n| \n45\nwww.it-ebooks.info\n\n\nthe case with std::vector<bool>::reference, and we’ve seen that violating that\nassumption can lead to undefined behavior.\nYou therefore want to avoid code of this form:\nauto someVar = expression of \"invisible\" proxy class type;\nBut how can you recognize when proxy objects are in use? The software employing\nthem is unlikely to advertise their existence. They’re supposed to be invisible, at least\nconceptually! And once you’ve found them, do you really have to abandon auto and\nthe many advantages Item 5 demonstrates for it?\nLet’s take the how-do-you-find-them question first. Although “invisible” proxy\nclasses are designed to fly beneath programmer radar in day-to-day use, libraries\nusing them often document that they do so. The more you’ve familiarized yourself\nwith the basic design decisions of the libraries you use, the less likely you are to be\nblindsided by proxy usage within those libraries.\nWhere documentation comes up short, header files fill the gap. It’s rarely possible for\nsource code to fully cloak proxy objects. They’re typically returned from functions\nthat clients are expected to call, so function signatures usually reflect their existence. \nHere’s the spec for std::vector<bool>::operator[], for example:\nnamespace std {                            // from C++ Standards\n  template <class Allocator>\n  class vector<bool, Allocator> {\n  public:\n    …\n    class reference { … };\n    reference operator[](size_type n);\n    …\n  };\n}\nAssuming you know that operator[] for std::vector<T> normally returns a T&,\nthe unconventional return type for operator[] in this case is a tip-off that a proxy\nclass is in use. Paying careful attention to the interfaces you’re using can often reveal\nthe existence of proxy classes.\nIn practice, many developers discover the use of proxy classes only when they try to\ntrack down mystifying compilation problems or debug incorrect unit test results.\nRegardless of how you find them, once auto has been determined to be deducing the\ntype of a proxy class instead of the type being proxied, the solution need not involve\nabandoning auto. auto itself isn’t the problem. The problem is that auto isn’t deduc‐\n46 \n| \nItem 6\nwww.it-ebooks.info\n\n\ning the type you want it to deduce. The solution is to force a different type deduction.\nThe way you do that is what I call the explicitly typed initializer idiom.\nThe explicitly typed initializer idiom involves declaring a variable with auto, but\ncasting the initialization expression to the type you want auto to deduce. Here’s how\nit can be used to force highPriority to be a bool, for example:\nauto highPriority = static_cast<bool>(features(w)[5]);\nHere, features(w)[5] continues to return a std::vector<bool>::reference\nobject, just as it always has, but the cast changes the type of the expression to bool,\nwhich auto then deduces as the type for highPriority. At runtime, the std::vec\ntor<bool>::reference object returned from std::vector<bool>::operator[]\nexecutes the conversion to bool that it supports, and as part of that conversion, the\nstill-valid pointer to the std::vector<bool> returned from features is derefer‐\nenced. That avoids the undefined behavior we ran into earlier. The index 5 is then\napplied to the bits pointed to by the pointer, and the bool value that emerges is used\nto initialize highPriority.\nFor the Matrix example, the explicitly typed initializer idiom would look like this:\nauto sum = static_cast<Matrix>(m1 + m2 + m3 + m4);\nApplications of the idiom aren’t limited to initializers yielding proxy class types. It\ncan also be useful to emphasize that you are deliberately creating a variable of a type\nthat is different from that generated by the initializing expression. For example, sup‐\npose you have a function to calculate some tolerance value:\ndouble calcEpsilon();            // return tolerance value\ncalcEpsilon clearly returns a double, but suppose you know that for your applica‐\ntion, the precision of a float is adequate, and you care about the difference in size\nbetween floats and doubles. You could declare a float variable to store the result\nof calcEpsilon,\nfloat ep = calcEpsilon();        // impliclitly convert\n                                 // double → float\nbut this hardly announces “I’m deliberately reducing the precision of the value\nreturned by the function.” A declaration using the explicitly typed initializer idiom,\nhowever, does:\nauto ep = static_cast<float>(calcEpsilon());\nSimilar reasoning applies if you have a floating-point expression that you are deliber‐\nately storing as an integral value. Suppose you need to calculate the index of an ele‐\nment in a container with random access iterators (e.g., a std::vector, std::deque,\nItem 6 \n| \n47\nwww.it-ebooks.info\n\n\nor std::array), and you’re given a double between 0.0 and 1.0 indicating how far\nfrom the beginning of the container the desired element is located. (0.5 would indi‐\ncate the middle of the container.) Further suppose that you’re confident that the\nresulting index will fit in an int. If the container is c and the double is d, you could\ncalculate the index this way,\nint index = d * c.size();\nbut this obscures the fact that you’re intentionally converting the double on the right\nto an int. The explicitly typed initializer idiom makes things transparent:\nauto index = static_cast<int>(d * c.size());\nThings to Remember\n• “Invisible” proxy types can cause auto to deduce the “wrong” type for an ini‐\ntializing expression.\n• The explicitly typed initializer idiom forces auto to deduce the type you want\nit to have.\n48 \n| \nItem 6\nwww.it-ebooks.info\n\n\nCHAPTER 3\nMoving to Modern C++\nWhen it comes to big-name features, C++11 and C++14 have a lot to boast of. auto,\nsmart pointers, move semantics, lambdas, concurrency—each is so important, I\ndevote a chapter to it. It’s essential to master those features, but becoming an effective\nmodern C++ programmer requires a series of smaller steps, too. Each step answers\nspecific questions that arise during the journey from C++98 to modern C++. When\nshould you use braces instead of parentheses for object creation? Why are alias decla‐\nrations better than typedefs? How does constexpr differ from const? What’s the\nrelationship between const member functions and thread safety? The list goes on\nand on. And one by one, this chapter provides the answers.\nItem 7: Distinguish between () and {} when creating\nobjects.\nDepending on your perspective, syntax choices for object initialization in C++11\nembody either an embarrassment of riches or a confusing mess. As a general rule,\ninitialization values may be specified with parentheses, an equals sign, or braces:\nint x(0);             // initializer is in parentheses\nint y = 0;            // initializer follows \"=\"\nint z{ 0 };           // initializer is in braces\nIn many cases, it’s also possible to use an equals sign and braces together:\nint z = { 0 };        // initializer uses \"=\" and braces\nFor the remainder of this Item, I’ll generally ignore the equals-sign-plus-braces syn‐\ntax, because C++ usually treats it the same as the braces-only version.\n49\nwww.it-ebooks.info\n\n\nThe “confusing mess” lobby points out that the use of an equals sign for initialization\noften misleads C++ newbies into thinking that an assignment is taking place, even\nthough it’s not. For built-in types like int, the difference is academic, but for user-\ndefined types, it’s important to distinguish initialization from assignment, because\ndifferent function calls are involved:\nWidget w1;            // call default constructor\nWidget w2 = w1;       // not an assignment; calls copy ctor\nw1 = w2;              // an assignment; calls copy operator=\nEven with several initialization syntaxes, there were some situations where C++98\nhad no way to express a desired initialization. For example, it wasn’t possible to\ndirectly indicate that an STL container should be created holding a particular set of\nvalues (e.g., 1, 3, and 5).\nTo address the confusion of multiple initialization syntaxes, as well as the fact that\nthey don’t cover all initialization scenarios, C++11 introduces uniform initialization:\na single initialization syntax that can, at least in concept, be used anywhere and\nexpress everything. It’s based on braces, and for that reason I prefer the term braced\ninitialization. “Uniform initialization” is an idea. “Braced initialization” is a syntactic\nconstruct.\nBraced initialization lets you express the formerly inexpressible. Using braces, speci‐\nfying the initial contents of a container is easy:\nstd::vector<int> v{ 1, 3, 5 }; // v's initial content is 1, 3, 5\nBraces can also be used to specify default initialization values for non-static data\nmembers. This capability—new to C++11—is shared with the “=” initialization syn‐\ntax, but not with parentheses:\nclass Widget {\n  …\nprivate:\n  int x{ 0 };                  // fine, x's default value is 0\n  int y = 0;                   // also fine\n  int z(0);                    // error!\n};\nOn the other hand, uncopyable objects (e.g., std::atomics—see Item 40) may be\ninitialized using braces or parentheses, but not using “=”: \nstd::atomic<int> ai1{ 0 };     // fine\n50 \n| \nItem 7\nwww.it-ebooks.info\n\n\nstd::atomic<int> ai2(0);       // fine\nstd::atomic<int> ai3 = 0;      // error!\nIt’s thus easy to understand why braced initialization is called “uniform.” Of C++’s\nthree ways to designate an initializing expression, only braces can be used every‐\nwhere.\nA novel feature of braced initialization is that it prohibits implicit narrowing conver‐\nsions among built-in types. If the value of an expression in a braced initializer isn’t\nguaranteed to be expressible by the type of the object being initialized, the code won’t\ncompile:\ndouble x, y, z;\n…\nint sum1{ x + y + z };       // error! sum of doubles may\n                             // not be expressible as int\nInitialization using parentheses and “=” doesn’t check for narrowing conversions,\nbecause that could break too much legacy code:\nint sum2(x + y + z);         // okay (value of expression\n                             // truncated to an int)\nint sum3 = x + y + z;        // ditto\nAnother noteworthy characteristic of braced initialization is its immunity to C++’s\nmost vexing parse. A side effect of C++’s rule that anything that can be parsed as a\ndeclaration must be interpreted as one, the most vexing parse most frequently afflicts\ndevelopers when they want to default-construct an object, but inadvertently end up\ndeclaring a function instead. The root of the problem is that if you want to call a con‐\nstructor with an argument, you can do it like this,\nWidget w1(10);     // call Widget ctor with argument 10\nbut if you try to call a Widget constructor with zero arguments using the analogous\nsyntax, you declare a function instead of an object:\nWidget w2();       // most vexing parse! declares a function\n                   // named w2 that returns a Widget!\nFunctions can’t be declared using braces for the parameter list, so default-\nconstructing an object using braces doesn’t have this problem:\nWidget w3{};       // calls Widget ctor with no args\nItem 7 \n| \n51\nwww.it-ebooks.info\n\n\nThere’s thus a lot to be said for braced initialization. It’s the syntax that can be used\nin the widest variety of contexts, it prevents implicit narrowing conversions, and it’s\nimmune to C++’s most vexing parse. A trifecta of goodness! So why isn’t this Item\nentitled something like “Prefer braced initialization syntax”?\nThe drawback to braced initialization is the sometimes-surprising behavior that\naccompanies it. Such behavior grows out of the unusually tangled relationship among\nbraced initializers, std::initializer_lists, and constructor overload resolution.\nTheir interactions can lead to code that seems like it should do one thing, but actually\ndoes another. For example, Item 2 explains that when an auto-declared variable has a\nbraced initializer, the type deduced is std::initializer_list, even though other\nways of declaring a variable with the same initializer would yield a more intuitive\ntype. As a result, the more you like auto, the less enthusiastic you’re likely to be about\nbraced initialization.\nIn constructor calls, parentheses and braces have the same meaning as long as\nstd::initializer_list parameters are not involved:\nclass Widget {\npublic:\n  Widget(int i, bool b);      // ctors not declaring\n  Widget(int i, double d);    // std::initializer_list params\n  …\n};\nWidget w1(10, true);          // calls first ctor\nWidget w2{10, true};          // also calls first ctor\nWidget w3(10, 5.0);           // calls second ctor\nWidget w4{10, 5.0};           // also calls second ctor\nIf, however, one or more constructors declare a parameter of type std::initial\nizer_list, calls using the braced initialization syntax strongly prefer the overloads\ntaking std::initializer_lists. Strongly. If there’s any way for compilers to con‐\nstrue a call using a braced initializer to be to a constructor taking a std::initial\nizer_list, compilers will employ that interpretation. If the Widget class above is\naugmented with a constructor taking a std::initializer_list<long double>, for\nexample,\nclass Widget {\npublic:\n  Widget(int i, bool b);                           // as before\n  Widget(int i, double d);                         // as before\n52 \n| \nItem 7\nwww.it-ebooks.info\n\n\n  Widget(std::initializer_list<long double> il);   // added\n  …\n};\nWidgets w2 and w4 will be constructed using the new constructor, even though the\ntype of the std::initializer_list elements (long double) is, compared to the\nnon-std::initializer_list constructors, a worse match for both arguments!\nLook:\nWidget w1(10, true);     // uses parens and, as before,\n                         // calls first ctor\nWidget w2{10, true};     // uses braces, but now calls\n                         // std::initializer_list ctor\n                         // (10 and true convert to long double)\nWidget w3(10, 5.0);      // uses parens and, as before,\n                         // calls second ctor\nWidget w4{10, 5.0};      // uses braces, but now calls\n                         // std::initializer_list ctor\n                         // (10 and 5.0 convert to long double)\nEven what would normally be copy and move construction can be hijacked by\nstd::initializer_list constructors:\nclass Widget {\npublic:\n  Widget(int i, bool b);                           // as before\n  Widget(int i, double d);                         // as before\n  Widget(std::initializer_list<long double> il);   // as before\n  operator float() const;                          // convert\n  …                                                // to float\n};\nWidget w5(w4);               // uses parens, calls copy ctor\nWidget w6{w4};               // uses braces, calls\n                             // std::initializer_list ctor\n                             // (w4 converts to float, and float\n                             // converts to long double)\nItem 7 \n| \n53\nwww.it-ebooks.info\n\n\nWidget w7(std::move(w4));    // uses parens, calls move ctor\nWidget w8{std::move(w4)};    // uses braces, calls\n                             // std::initializer_list ctor\n                             // (for same reason as w6)\nCompilers’ determination to match braced initializers with constructors taking\nstd::initializer_lists is so strong, it prevails even if the best-match std::ini\ntializer_list constructor can’t be called. For example:\nclass Widget {\npublic:\n  Widget(int i, bool b);                   // as before\n  Widget(int i, double d);                 // as before\n  Widget(std::initializer_list<bool> il);  // element type is\n                                           // now bool\n  …                                        // no implicit\n};                                         // conversion funcs\nWidget w{10, 5.0};      // error! requires narrowing conversions\nHere, compilers will ignore the first two constructors (the second of which offers an\nexact match on both argument types) and try to call the constructor taking a\nstd::initializer_list<bool>. Calling that constructor would require converting\nan int (10) and a double (5.0) to bools. Both conversions would be narrowing\n(bool can’t exactly represent either value), and narrowing conversions are prohibited\ninside braced initializers, so the call is invalid, and the code is rejected.\nOnly if there’s no way to convert the types of the arguments in a braced initializer to\nthe type in a std::initializer_list do compilers fall back on normal overload\nresolution. For example, if we replace the std::initializer_list<bool> construc‐\ntor with one taking a std::initializer_list<std::string>, the non-\nstd::initializer_list constructors become candidates again, because there is no\nway to convert ints and bools to std::strings:\nclass Widget {\npublic:\n  Widget(int i, bool b);               // as before\n  Widget(int i, double d);             // as before\n  // std::initializer_list element type is now std::string\n  Widget(std::initializer_list<std::string> il);\n  …                                    // no implicit\n54 \n| \nItem 7\nwww.it-ebooks.info\n\n\n};                                     // conversion funcs\nWidget w1(10, true);     // uses parens, still calls first ctor\nWidget w2{10, true};     // uses braces, now calls first ctor\nWidget w3(10, 5.0);      // uses parens, still calls second ctor\nWidget w4{10, 5.0};      // uses braces, now calls second ctor\nThis brings us near the end of our examination of braced initializers and constructor\noverloading, but there’s an interesting edge case that needs to be addressed. Suppose\nyou use an empty set of braces to construct an object that supports default construc‐\ntion and also supports std::initializer_list construction. What do your empty\nbraces mean? If they mean “no arguments,” you get default construction, but if they\nmean “empty std::initializer_list,” you get construction from a std::ini\ntializer_list with no elements.\nThe rule is that you get default construction. Empty braces mean no arguments, not\nan empty std::initializer_list:\nclass Widget {\npublic:\n  Widget();                                // default ctor\n  Widget(std::initializer_list<int> il);   // std::initializer\n                                           // _list ctor\n  …                                        // no implicit\n};                                         // conversion funcs\nWidget w1;            // calls default ctor\nWidget w2{};          // also calls default ctor\nWidget w3();          // most vexing parse! declares a function!\nIf you want to call a std::initializer_list constructor with an empty std::ini\ntializer_list, you do it by making the empty braces a constructor argument—by\nputting the empty braces inside the parentheses or braces demarcating what you’re\npassing:\nWidget w4({});        // calls std::initializer_list ctor\n                      // with empty list\nWidget w5{{}};        // ditto\nItem 7 \n| \n55\nwww.it-ebooks.info\n\n\nAt this point, with seemingly arcane rules about braced initializers, std::initial\nizer_lists, and constructor overloading burbling about in your brain, you may be\nwondering how much of this information matters in day-to-day programming. More\nthan you might think, because one of the classes directly affected is std::vector.\nstd::vector has a non-std::initializer_list constructor that allows you to\nspecify the initial size of the container and a value each of the initial elements should\nhave, but it also has a constructor taking a std::initializer_list that permits\nyou to specify the initial values in the container. If you create a std::vector of a\nnumeric type (e.g., a std::vector<int>) and you pass two arguments to the con‐\nstructor, whether you enclose those arguments in parentheses or braces makes a tre‐\nmendous difference:\nstd::vector<int> v1(10, 20);  // use non-std::initializer_list\n                              // ctor: create 10-element\n                              // std::vector, all elements have\n                              // value of 20\nstd::vector<int> v2{10, 20};  // use std::initializer_list ctor:\n                              // create 2-element std::vector,\n                              // element values are 10 and 20\nBut let’s step back from std::vector and also from the details of parentheses,\nbraces, and constructor overloading resolution rules. There are two primary take‐\naways from this discussion. First, as a class author, you need to be aware that if your\nset of overloaded constructors includes one or more functions taking a std::ini\ntializer_list, client code using braced initialization may see only the std::ini\ntializer_list overloads. As a result, it’s best to design your constructors so that\nthe overload called isn’t affected by whether clients use parentheses or braces. In\nother words, learn from what is now viewed as an error in the design of the std::vec\ntor interface, and design your classes to avoid it.\nAn implication is that if you have a class with no std::initializer_list construc‐\ntor, and you add one, client code using braced initialization may find that calls that\nused to resolve to non-std::initializer_list constructors now resolve to the\nnew function. Of course, this kind of thing can happen any time you add a new func‐\ntion to a set of overloads: calls that used to resolve to one of the old overloads might\nstart calling the new one. The difference with std::initializer_list constructor\noverloads is that a std::initializer_list overload doesn’t just compete with\nother overloads, it overshadows them to the point where the other overloads may\nhardly be considered. So add such overloads only with great deliberation.\nThe second lesson is that as a class client, you must choose carefully between paren‐\ntheses and braces when creating objects. Most developers end up choosing one kind\n56 \n| \nItem 7\nwww.it-ebooks.info\n\n\nof delimiter as a default, using the other only when they have to. Braces-by-default\nfolks are attracted by their unrivaled breadth of applicability, their prohibition of nar‐\nrowing conversions, and their immunity to C++’s most vexing parse. Such folks\nunderstand that in some cases (e.g., creation of a std::vector with a given size and\ninitial element value), parentheses are required. On the other hand, the go-\nparentheses-go crowd embraces parentheses as their default argument delimiter.\nThey’re attracted to its consistency with the C++98 syntactic tradition, its avoidance\nof the auto-deduced-a-std::initializer_list problem, and the knowledge that\ntheir object creation calls won’t be inadvertently waylaid by std::initial\nizer_list constructors. They concede that sometimes only braces will do (e.g.,\nwhen creating a container with particular values). There’s no consensus that either\napproach is better than the other, so my advice is to pick one and apply it consis‐\ntently.\nIf you’re a template author, the tension between parentheses and braces for object\ncreation can be especially frustrating, because, in general, it’s not possible to know\nwhich should be used. For example, suppose you’d like to create an object of an arbi‐\ntrary type from an arbitrary number of arguments. A variadic template makes this\nconceptually straightforward:\ntemplate<typename T,                // type of object to create\n         typename... Ts>            // types of arguments to use\nvoid doSomeWork(Ts&&... params)\n{\n  create local T object from params...\n  …\n}\nThere are two ways to turn the line of pseudocode into real code (see Item 25 for\ninformation about std::forward):\nT localObject(std::forward<Ts>(params)...);    // using parens\nT localObject{std::forward<Ts>(params)...};    // using braces\nSo consider this calling code:\nstd::vector<int> v;\n…\ndoSomeWork<std::vector<int>>(10, 20);\nItem 7 \n| \n57\nwww.it-ebooks.info\n\n\n1 More flexible designs—ones that permit callers to determine whether parentheses or braces should be used in\nfunctions generated from a template—are possible. For details, see the 5 June 2013 entry of Andrzej’s C++\nblog, “Intuitive interface — Part I.”\nIf doSomeWork uses parentheses when creating localObject, the result is a\nstd::vector with 10 elements. If doSomeWork uses braces, the result is a std::vec\ntor with 2 elements. Which is correct? The author of doSomeWork can’t know. Only\nthe caller can.\nThis is precisely the problem faced by the Standard Library functions\nstd::make_unique and std::make_shared (see Item 21). These functions resolve\nthe problem by internally using parentheses and by documenting this decision as part\nof their interfaces.1\nThings to Remember\n• Braced initialization is the most widely usable initialization syntax, it prevents\nnarrowing conversions, and it’s immune to C++’s most vexing parse.\n• During constructor overload resolution, braced initializers are matched to\nstd::initializer_list parameters if at all possible, even if other construc‐\ntors offer seemingly better matches.\n• An example of where the choice between parentheses and braces can make a\nsignificant difference is creating a std::vector<numeric type> with two\narguments.\n• Choosing between parentheses and braces for object creation inside templates\ncan be challenging.\nItem 8: Prefer nullptr to 0 and NULL.\nSo here’s the deal: the literal 0 is an int, not a pointer. If C++ finds itself looking at 0\nin a context where only a pointer can be used, it’ll grudgingly interpret 0 as a null\npointer, but that’s a fallback position. C++’s primary policy is that 0 is an int, not a\npointer.\nPractically speaking, the same is true of NULL. There is some uncertainty in the details\nin NULL’s case, because implementations are allowed to give NULL an integral type\nother than int (e.g., long). That’s not common, but it doesn’t really matter, because\nthe issue here isn’t the exact type of NULL, it’s that neither 0 nor NULL has a pointer\ntype.\n58 \n| \nItem 7\nwww.it-ebooks.info\n\n\nIn C++98, the primary implication of this was that overloading on pointer and inte‐\ngral types could lead to surprises. Passing 0 or NULL to such overloads never called a\npointer overload:\nvoid f(int);        // three overloads of f\nvoid f(bool);\nvoid f(void*);\nf(0);               // calls f(int), not f(void*)\nf(NULL);            // might not compile, but typically calls\n                    // f(int). Never calls f(void*)\nThe uncertainty regarding the behavior of f(NULL) is a reflection of the leeway gran‐\nted to implementations regarding the type of NULL. If NULL is defined to be, say, 0L\n(i.e., 0 as a long), the call is ambiguous, because conversion from long to int, long\nto bool, and 0L to void* are considered equally good. The interesting thing about\nthat call is the contradiction between the apparent meaning of the source code (“I’m\ncalling f with NULL—the null pointer”) and its actual meaning (“I’m calling f with\nsome kind of integer—not the null pointer”). This counterintuitive behavior is what\nled to the guideline for C++98 programmers to avoid overloading on pointer and\nintegral types. That guideline remains valid in C++11, because, the advice of this Item\nnotwithstanding, it’s likely that some developers will continue to use 0 and NULL,\neven though nullptr is a better choice.\nnullptr’s advantage is that it doesn’t have an integral type. To be honest, it doesn’t\nhave a pointer type, either, but you can think of it as a pointer of all types. nullptr’s\nactual type is std::nullptr_t, and, in a wonderfully circular definition,\nstd::nullptr_t is defined to be the type of nullptr. The type std::nullptr_t\nimplicitly converts to all raw pointer types, and that’s what makes nullptr act as if it\nwere a pointer of all types.\nCalling the overloaded function f with nullptr calls the void* overload (i.e., the\npointer overload), because nullptr can’t be viewed as anything integral:\nf(nullptr);         // calls f(void*) overload\nUsing nullptr instead of 0 or NULL thus avoids overload resolution surprises, but\nthat’s not its only advantage. It can also improve code clarity, especially when auto\nvariables are involved. For example, suppose you encounter this in a code base:\nauto result = findRecord( /* arguments */ );\nif (result == 0) {\nItem 8 \n| \n59\nwww.it-ebooks.info\n\n\n  …\n}\nIf you don’t happen to know (or can’t easily find out) what findRecord returns, it\nmay not be clear whether result is a pointer type or an integral type. After all, 0\n(what result is tested against) could go either way. If you see the following, on the\nother hand,\nauto result = findRecord( /* arguments */ );\nif (result == nullptr) {\n  …\n}\nthere’s no ambiguity: result must be a pointer type.\nnullptr shines especially brightly when templates enter the picture. Suppose you\nhave some functions that should be called only when the appropriate mutex has been\nlocked. Each function takes a different kind of pointer:\nint    f1(std::shared_ptr<Widget> spw);  // call these only when\ndouble f2(std::unique_ptr<Widget> upw);  // the appropriate\nbool   f3(Widget* pw);                   // mutex is locked\nCalling code that wants to pass null pointers could look like this:\nstd::mutex f1m, f2m, f3m;         // mutexes for f1, f2, and f3\nusing MuxGuard =                  // C++11 typedef; see Item 9\n  std::lock_guard<std::mutex>;\n…\n{\n  MuxGuard g(f1m);            // lock mutex for f1\n  auto result = f1(0);        // pass 0 as null ptr to f1\n}                             // unlock mutex\n…\n{\n  MuxGuard g(f2m);            // lock mutex for f2\n  auto result = f2(NULL);     // pass NULL as null ptr to f2\n}                             // unlock mutex\n…\n{\n60 \n| \nItem 8\nwww.it-ebooks.info\n\n\n  MuxGuard g(f3m);            // lock mutex for f3\n  auto result = f3(nullptr);  // pass nullptr as null ptr to f3\n}                             // unlock mutex\nThe failure to use nullptr in the first two calls in this code is sad, but the code\nworks, and that counts for something. However, the repeated pattern in the calling\ncode—lock mutex, call function, unlock mutex—is more than sad. It’s disturbing.\nThis kind of source code duplication is one of the things that templates are designed\nto avoid, so let’s templatize the pattern:\ntemplate<typename FuncType,\n         typename MuxType,\n         typename PtrType>\nauto lockAndCall(FuncType func,\n                 MuxType& mutex,\n                 PtrType ptr) -> decltype(func(ptr))\n{\n  MuxGuard g(mutex);\n  return func(ptr);\n}\nIf the return type of this function (auto … -> decltype(func(ptr)) has you scratch‐\ning your head, do your head a favor and navigate to Item 3, which explains what’s\ngoing on. There you’ll see that in C++14, the return type could be reduced to a simple\ndecltype(auto):\ntemplate<typename FuncType,\n         typename MuxType,\n         typename PtrType>\ndecltype(auto) lockAndCall(FuncType func,        // C++14\n                           MuxType& mutex,\n                           PtrType ptr)\n{\n  MuxGuard g(mutex);\n  return func(ptr);\n}\nGiven the lockAndCall template (either version), callers can write code like this:\nauto result1 = lockAndCall(f1, f1m, 0);          // error!\n…\nauto result2 = lockAndCall(f2, f2m, NULL);       // error!\n…\nItem 8 \n| \n61\nwww.it-ebooks.info\n\n\nauto result3 = lockAndCall(f3, f3m, nullptr);    // fine\nWell, they can write it, but, as the comments indicate, in two of the three cases, the\ncode won’t compile. The problem in the first call is that when 0 is passed to lockAnd\nCall, template type deduction kicks in to figure out its type. The type of 0 is, was,\nand always will be int, so that’s the type of the parameter ptr inside the instantiation\nof this call to lockAndCall. Unfortunately, this means that in the call to func inside\nlockAndCall, an int is being passed, and that’s not compatible with the\nstd::shared_ptr<Widget> parameter that f1 expects. The 0 passed in the call to\nlockAndCall was intended to represent a null pointer, but what actually got passed\nwas a run-of-the-mill int. Trying to pass this int to f1 as a std::shared_ptr\n<Widget> is a type error. The call to lockAndCall with 0 fails because inside the\ntemplate, an int is being passed to a function that requires a std::\nshared_ptr<Widget>.\nThe analysis for the call involving NULL is essentially the same. When NULL is passed\nto lockAndCall, an integral type is deduced for the parameter ptr, and a type error\noccurs when ptr—an int or int-like type—is passed to f2, which expects to get a\nstd::unique_ptr<Widget>.\nIn contrast, the call involving nullptr has no trouble. When nullptr is passed to\nlockAndCall, the type for ptr is deduced to be std::nullptr_t. When ptr is\npassed to f3, there’s an implicit conversion from std::nullptr_t to Widget*,\nbecause std::nullptr_t implicitly converts to all pointer types.\nThe fact that template type deduction deduces the “wrong” types for 0 and NULL (i.e.,\ntheir true types, rather than their fallback meaning as a representation for a null\npointer) is the most compelling reason to use nullptr instead of 0 or NULL when you\nwant to refer to a null pointer. With nullptr, templates pose no special challenge.\nCombined with the fact that nullptr doesn’t suffer from the overload resolution sur‐\nprises that 0 and NULL are susceptible to, the case is ironclad. When you want to refer\nto a null pointer, use nullptr, not 0 or NULL.\nThings to Remember\n• Prefer nullptr to 0 and NULL.\n• Avoid overloading on integral and pointer types.\n62 \n| \nItem 8\nwww.it-ebooks.info\n",
      "page_number": 60,
      "chapter_number": 7,
      "summary": "Item 5 explains that using auto to declare variables offers a number of technical\nadvantages over explicitly specifying types, but sometimes auto’s type deduction zigs\nwhen you want it to zag Key topics include type, typed, and typing.",
      "keywords": [
        "std",
        "Widget",
        "type",
        "bool",
        "initializer",
        "NULL",
        "Item",
        "int",
        "vector",
        "list",
        "auto",
        "calls",
        "object",
        "braces",
        "pointer"
      ],
      "concepts": [
        "type",
        "typed",
        "typing",
        "std",
        "auto",
        "initializing",
        "initialized",
        "initialize",
        "item",
        "widget"
      ],
      "similar_chapters": [
        {
          "book": "C++ Templates_ The Complete Guide",
          "chapter": 13,
          "title": "Segment 13 (pages 394-424)",
          "relevance_score": 0.47,
          "method": "sentence_transformers"
        },
        {
          "book": "C++ Templates_ The Complete Guide",
          "chapter": 9,
          "title": "Segment 9 (pages 265-294)",
          "relevance_score": 0.46,
          "method": "sentence_transformers"
        },
        {
          "book": "C++ Templates_ The Complete Guide",
          "chapter": 54,
          "title": "Segment 54 (pages 1729-1761)",
          "relevance_score": 0.45,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 2",
          "chapter": 6,
          "title": "Segment 6 (pages 42-52)",
          "relevance_score": 0.45,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 2",
          "chapter": 14,
          "title": "Segment 14 (pages 117-128)",
          "relevance_score": 0.43,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 8,
      "title": "Segment 8 (pages 81-89)",
      "start_page": 81,
      "end_page": 89,
      "detection_method": "topic_boundary",
      "content": "Item 9: Prefer alias declarations to typedefs.\nI’m confident we can agree that using STL containers is a good idea, and I hope that\nItem 18 convinces you that using std::unique_ptr is a good idea, but my guess is\nthat neither of us is fond of writing types like “std::unique_ptr<std::unor\ndered_map<std::string, std::string>>” more than once. Just thinking about it\nprobably increases the risk of carpal tunnel syndrome.\nAvoiding such medical tragedies is easy. Introduce a typedef:\ntypedef\n  std::unique_ptr<std::unordered_map<std::string, std::string>>\n  UPtrMapSS;\nBut typedefs are soooo C++98. They work in C++11, sure, but C++11 also offers \nalias declarations:\nusing UPtrMapSS =\n  std::unique_ptr<std::unordered_map<std::string, std::string>>;\nGiven that the typedef and the alias declaration do exactly the same thing, it’s rea‐\nsonable to wonder whether there is a solid technical reason for preferring one over\nthe other.\nThere is, but before I get to it, I want to mention that many people find the alias dec‐\nlaration easier to swallow when dealing with types involving function pointers:\n// FP is a synonym for a pointer to a function taking an int and\n// a const std::string& and returning nothing\ntypedef void (*FP)(int, const std::string&);      // typedef\n// same meaning as above\nusing FP = void (*)(int, const std::string&);     // alias\n                                                  // declaration\nOf course, neither form is particularly easy to choke down, and few people spend\nmuch time dealing with synonyms for function pointer types, anyway, so this is\nhardly a compelling reason to choose alias declarations over typedefs.\nBut a compelling reason does exist: templates. In particular, alias declarations may be\ntemplatized (in which case they’re called alias templates), while typedefs cannot.\nThis gives C++11 programmers a straightforward mechanism for expressing things\nthat in C++98 had to be hacked together with typedefs nested inside templatized\nstructs. For example, consider defining a synonym for a linked list that uses a cus‐\ntom allocator, MyAlloc. With an alias template, it’s a piece of cake:\nItem 9 \n| \n63\nwww.it-ebooks.info\n\n\ntemplate<typename T>                           // MyAllocList<T>\nusing MyAllocList = std::list<T, MyAlloc<T>>;  // is synonym for\n                                               // std::list<T,\n                                               //   MyAlloc<T>>\nMyAllocList<Widget> lw;                        // client code\nWith a typedef, you pretty much have to create the cake from scratch:\ntemplate<typename T>                     // MyAllocList<T>::type\nstruct MyAllocList {                     // is synonym for\n  typedef std::list<T, MyAlloc<T>> type; // std::list<T,\n};                                       //   MyAlloc<T>>\nMyAllocList<Widget>::type lw;            // client code\nIt gets worse. If you want to use the typedef inside a template for the purpose of cre‐\nating a linked list holding objects of a type specified by a template parameter, you\nhave to precede the typedef name with typename:\ntemplate<typename T>\nclass Widget {                         // Widget<T> contains\nprivate:                               // a MyAllocList<T>\n  typename MyAllocList<T>::type list;  // as a data member\n  …\n};\nHere, MyAllocList<T>::type refers to a type that’s dependent on a template type\nparameter (T). MyAllocList<T>::type is thus a dependent type, and one of C++’s\nmany endearing rules is that the names of dependent types must be preceded by type\nname.\nIf MyAllocList is defined as an alias template, this need for typename vanishes (as\ndoes the cumbersome “::type” suffix):\ntemplate<typename T>\nusing MyAllocList = std::list<T, MyAlloc<T>>;  // as before\ntemplate<typename T>\nclass Widget {\nprivate:\n  MyAllocList<T> list;                         // no \"typename\",\n  …                                            // no \"::type\"\n};\nTo you, MyAllocList<T> (i.e., use of the alias template) may look just as dependent\non the template parameter T as MyAllocList<T>::type (i.e., use of the nested type\n64 \n| \nItem 9\nwww.it-ebooks.info\n\n\ndef), but you’re not a compiler. When compilers process the Widget template and\nencounter the use of MyAllocList<T> (i.e., use of the alias template), they know that\nMyAllocList<T> is the name of a type, because MyAllocList is an alias template: it\nmust name a type. MyAllocList<T> is thus a non-dependent type, and a typename\nspecifier is neither required nor permitted.\nWhen compilers see MyAllocList<T>::type (i.e., use of the nested typedef) in the\nWidget template, on the other hand, they can’t know for sure that it names a type,\nbecause there might be a specialization of MyAllocList that they haven’t yet seen\nwhere MyAllocList<T>::type refers to something other than a type. That sounds\ncrazy, but don’t blame compilers for this possibility. It’s the humans who have been\nknown to produce such code.\n For example, some misguided soul may have concocted something like this:\nclass Wine { … };\ntemplate<>                       // MyAllocList specialization\nclass MyAllocList<Wine> {        // for when T is Wine\nprivate:\n  enum class WineType            // see Item 10 for info on\n  { White, Red, Rose };          // \"enum class\"\n  WineType type;                 // in this class, type is\n  …                              // a data member!\n};\nAs you can see, MyAllocList<Wine>::type doesn’t refer to a type. If Widget were to\nbe instantiated with Wine, MyAllocList<T>::type inside the Widget template\nwould refer to a data member, not a type. Inside the Widget template, then, whether\nMyAllocList<T>::type refers to a type is honestly dependent on what T is, and\nthat’s why compilers insist on your asserting that it is a type by preceding it with\ntypename.\nIf you’ve done any template metaprogramming (TMP), you’ve almost certainly bum‐\nped up against the need to take template type parameters and create revised types\nfrom them. For example, given some type T, you might want to strip off any const-\nor reference-qualifiers that T contains, e.g., you might want to turn const\nstd::string& into std::string. Or you might want to add const to a type or turn\nit into an lvalue reference, e.g., turn Widget into const Widget or into Widget&. (If\nyou haven’t done any TMP, that’s too bad, because if you want to be a truly effective\nC++ programmer, you need to be familiar with at least the basics of this facet of C++.\nYou can see examples of TMP in action, including the kinds of type transformations I\njust mentioned, in Items 23 and 27.)\nItem 9 \n| \n65\nwww.it-ebooks.info\n\n\nC++11 gives you the tools to perform these kinds of transformations in the form of\ntype traits, an assortment of templates inside the header <type_traits>. There are\ndozens of type traits in that header, and not all of them perform type transforma‐\ntions, but the ones that do offer a predictable interface. Given a type T to which you’d\nlike to apply a transformation, the resulting type is std::transformation\n<T>::type. For example:\nstd::remove_const<T>::type           // yields T from const T\nstd::remove_reference<T>::type       // yields T from T& and T&&\nstd::add_lvalue_reference<T>::type   // yields T& from T\nThe comments merely summarize what these transformations do, so don’t take them\ntoo literally. Before using them on a project, you’d look up the precise specifications,\nI know.\nMy motivation here isn’t to give you a tutorial on type traits, anyway. Rather, note\nthat application of these transformations entails writing “::type” at the end of each\nuse. If you apply them to a type parameter inside a template (which is virtually always\nhow you employ them in real code), you’d also have to precede each use with type\nname. The reason for both of these syntactic speed bumps is that the C++11 type\ntraits are implemented as nested typedefs inside templatized structs. That’s right,\nthey’re implemented using the type synonym technology I’ve been trying to convince\nyou is inferior to alias templates!\nThere’s a historical reason for that, but we’ll skip over it (it’s dull, I promise), because\nthe Standardization Committee belatedly recognized that alias templates are the bet‐\nter way to go, and they included such templates in C++14 for all the C++11 type\ntransformations. The aliases have a common form: for each C++11 transformation\nstd::transformation<T>::type, there’s a corresponding C++14 alias template\nnamed std::transformation_t. Examples will clarify what I mean:\nstd::remove_const<T>::type           // C++11: const T → T\nstd::remove_const_t<T>               // C++14 equivalent\nstd::remove_reference<T>::type       // C++11: T&/T&& → T\nstd::remove_reference_t<T>           // C++14 equivalent\nstd::add_lvalue_reference<T>::type   // C++11: T → T&\nstd::add_lvalue_reference_t<T>       // C++14 equivalent\nThe C++11 constructs remain valid in C++14, but I don’t know why you’d want to\nuse them. Even if you don’t have access to C++14, writing the alias templates yourself\nis child’s play. Only C++11 language features are required, and even children can\n66 \n| \nItem 9\nwww.it-ebooks.info\n\n\nmimic a pattern, right? If you happen to have access to an electronic copy of the\nC++14 Standard, it’s easier still, because all that’s required is some copying and past‐\ning. Here, I’ll get you started:\ntemplate <class T>\nusing remove_const_t = typename remove_const<T>::type;\ntemplate <class T>\nusing remove_reference_t = typename remove_reference<T>::type;\ntemplate <class T>\nusing add_lvalue_reference_t =\n  typename add_lvalue_reference<T>::type;\nSee? Couldn’t be easier.\nThings to Remember\n• typedefs don’t support templatization, but alias declarations do.\n• Alias templates avoid the “::type” suffix and, in templates, the “typename”\nprefix often required to refer to typedefs.\n• C++14 offers alias templates for all the C++11 type traits transformations.\nItem 10: Prefer scoped enums to unscoped enums.\nAs a general rule, declaring a name inside curly braces limits the visibility of that\nname to the scope defined by the braces. Not so for the enumerators declared in\nC++98-style enums. The names of such enumerators belong to the scope containing\nthe enum, and that means that nothing else in that scope may have the same name:\nenum Color { black, white, red };   // black, white, red are\n                                    // in same scope as Color\nauto white = false;                 // error! white already\n                                    // declared in this scope\nThe fact that these enumerator names leak into the scope containing their enum defi‐\nnition gives rise to the official term for this kind of enum: unscoped. Their new C++11\ncounterparts, scoped enums, don’t leak names in this way:\nenum class Color { black, white, red };  // black, white, red\n                                         // are scoped to Color\nauto white = false;              // fine, no other\nItem 9 \n| \n67\nwww.it-ebooks.info\n\n\n                                 // \"white\" in scope\nColor c = white;                 // error! no enumerator named\n                                 // \"white\" is in this scope\nColor c = Color::white;          // fine\nauto c = Color::white;           // also fine (and in accord\n                                 // with Item 5's advice)\nBecause scoped enums are declared via “enum class”, they’re sometimes referred to as\nenum classes.\nThe reduction in namespace pollution offered by scoped enums is reason enough to\nprefer them over their unscoped siblings, but scoped enums have a second compelling\nadvantage: their enumerators are much more strongly typed. Enumerators for unsco‐\nped enums implicitly convert to integral types (and, from there, to floating-point\ntypes). Semantic travesties such as the following are therefore completely valid:\nenum Color { black, white, red };        // unscoped enum\nstd::vector<std::size_t>                 // func. returning\n  primeFactors(std::size_t x);           // prime factors of x\nColor c = red;\n…\nif (c < 14.5) {                // compare Color to double (!)\n  auto factors =               // compute prime factors\n    primeFactors(c);           // of a Color (!)\n  …\n}\nThrow a simple “class” after “enum”, however, thus transforming an unscoped enum\ninto a scoped one, and it’s a very different story. There are no implicit conversions\nfrom enumerators in a scoped enum to any other type:\nenum class Color { black, white, red };  // enum is now scoped\nColor c = Color::red;                    // as before, but\n…                                        // with scope qualifier\nif (c < 14.5) {                // error! can't compare\n                               // Color and double\n68 \n| \nItem 10\nwww.it-ebooks.info\n\n\n  auto factors =               // error! can't pass Color to\n    primeFactors(c);           // function expecting std::size_t\n  …\n}\nIf you honestly want to perform a conversion from Color to a different type, do what\nyou always do to twist the type system to your wanton desires—use a cast:\nif (static_cast<double>(c) < 14.5) {       // odd code, but\n                                           // it's valid\n  auto factors =                                // suspect, but\n    primeFactors(static_cast<std::size_t>(c));  // it compiles\n  …\n}\nIt may seem that scoped enums have a third advantage over unscoped enums, because\nscoped enums may be forward-declared, i.e., their names may be declared without\nspecifying their enumerators:\nenum Color;               // error!\nenum class Color;         // fine\nThis is misleading. In C++11, unscoped enums may also be forward-declared, but\nonly after a bit of additional work. The work grows out of the fact that every enum in\nC++ has an integral underlying type that is determined by compilers. For an unsco‐\nped enum like Color,\nenum Color { black, white, red };\ncompilers might choose char as the underlying type, because there are only three val‐\nues to represent. However, some enums have a range of values that is much larger,\ne.g.:\nenum Status { good = 0,\n              failed = 1,\n              incomplete = 100,\n              corrupt = 200,\n              indeterminate = 0xFFFFFFFF\n            };\nHere the values to be represented range from 0 to 0xFFFFFFFF. Except on unusual\nmachines (where a char consists of at least 32 bits), compilers will have to select an\nintegral type larger than char for the representation of Status values.\nItem 10 \n| \n69\nwww.it-ebooks.info\n\n\nTo make efficient use of memory, compilers often want to choose the smallest under‐\nlying type for an enum that’s sufficient to represent its range of enumerator values. In\nsome cases, compilers will optimize for speed instead of size, and in that case, they\nmay not choose the smallest permissible underlying type, but they certainly want to\nbe able to optimize for size. To make that possible, C++98 supports only enum defini‐\ntions (where all enumerators are listed); enum declarations are not allowed. That\nmakes it possible for compilers to select an underlying type for each enum prior to the\nenum being used.\nBut the inability to forward-declare enums has drawbacks. The most notable is proba‐\nbly the increase in compilation dependencies. Consider again the Status enum:\nenum Status { good = 0,\n              failed = 1,\n              incomplete = 100,\n              corrupt = 200,\n              indeterminate = 0xFFFFFFFF\n            };\nThis is the kind of enum that’s likely to be used throughout a system, hence included\nin a header file that every part of the system is dependent on. If a new status value is\nthen introduced,\nenum Status { good = 0,\n              failed = 1,\n              incomplete = 100,\n              corrupt = 200,\n              audited = 500,\n              indeterminate = 0xFFFFFFFF\n            };\nit’s likely that the entire system will have to be recompiled, even if only a single sub‐\nsystem—possibly only a single function!—uses the new enumerator. This is the kind\nof thing that people hate. And it’s the kind of thing that the ability to forward-declare\nenums in C++11 eliminates. For example, here’s a perfectly valid declaration of a\nscoped enum and a function that takes one as a parameter:\nenum class Status;                   // forward declaration\nvoid continueProcessing(Status s);   // use of fwd-declared enum\nThe header containing these declarations requires no recompilation if Status’s\ndefinition is revised. Furthermore, if Status is modified (e.g., to add the audited\nenumerator), but continueProcessing’s behavior is unaffected (e.g., because\n70 \n| \nItem 10\nwww.it-ebooks.info\n\n\ncontinueProcessing doesn’t use audited), continueProcessing’s implementation\nneed not be recompiled, either.\nBut if compilers need to know the size of an enum before it’s used, how can C++11’s\nenums get away with forward declarations when C++98’s enums can’t? The answer is\nsimple: the underlying type for a scoped enum is always known, and for unscoped\nenums, you can specify it.\nBy default, the underlying type for scoped enums is int:\nenum class Status;                 // underlying type is int\nIf the default doesn’t suit you, you can override it:\nenum class Status: std::uint32_t;  // underlying type for\n                                   // Status is std::uint32_t\n                                   // (from <cstdint>)\nEither way, compilers know the size of the enumerators in a scoped enum.\nTo specify the underlying type for an unscoped enum, you do the same thing as for a\nscoped enum, and the result may be forward-declared:\nenum Color: std::uint8_t;       // fwd decl for unscoped enum;\n                                // underlying type is\n                                // std::uint8_t\nUnderlying type specifications can also go on an enum’s definition:\nenum class Status: std::uint32_t { good = 0,\n                                   failed = 1,\n                                   incomplete = 100,\n                                   corrupt = 200,\n                                   audited = 500,\n                                   indeterminate = 0xFFFFFFFF\n                                 };\nIn view of the fact that scoped enums avoid namespace pollution and aren’t suscepti‐\nble to nonsensical implicit type conversions, it may surprise you to hear that there’s\nat least one situation where unscoped enums may be useful. That’s when referring to\nfields within C++11’s std::tuples. For example, suppose we have a tuple holding\nvalues for the name, email address, and reputation value for a user at a social net‐\nworking website:\nusing UserInfo =                 // type alias; see Item 9\n  std::tuple<std::string,        // name\nItem 10 \n| \n71\nwww.it-ebooks.info\n",
      "page_number": 81,
      "chapter_number": 8,
      "summary": "This chapter covers segment 8 (pages 81-89). Key topics include types, typed. This gives C++11 programmers a straightforward mechanism for expressing things\nthat in C++98 had to be hacked together with typedefs nested inside templatized\nstructs.",
      "keywords": [
        "type",
        "std",
        "enum",
        "Color",
        "template",
        "MyAllocList",
        "enum Color",
        "enum class Status",
        "enum class Color",
        "Widget",
        "alias",
        "Status",
        "Item",
        "enum class",
        "underlying type"
      ],
      "concepts": [
        "types",
        "typed",
        "std",
        "templates",
        "compiler",
        "compiles",
        "color",
        "declaration",
        "classes",
        "item"
      ],
      "similar_chapters": [
        {
          "book": "C++ Templates_ The Complete Guide",
          "chapter": 64,
          "title": "Segment 64 (pages 2050-2080)",
          "relevance_score": 0.73,
          "method": "sentence_transformers"
        },
        {
          "book": "C++ Templates_ The Complete Guide",
          "chapter": 63,
          "title": "Segment 63 (pages 2016-2049)",
          "relevance_score": 0.71,
          "method": "sentence_transformers"
        },
        {
          "book": "More Effective C++",
          "chapter": 32,
          "title": "Segment 32 (pages 320-329)",
          "relevance_score": 0.69,
          "method": "sentence_transformers"
        },
        {
          "book": "C++ Templates_ The Complete Guide",
          "chapter": 1,
          "title": "Segment 1 (pages 1-35)",
          "relevance_score": 0.68,
          "method": "sentence_transformers"
        },
        {
          "book": "C++ Templates_ The Complete Guide",
          "chapter": 22,
          "title": "Segment 22 (pages 685-719)",
          "relevance_score": 0.68,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 9,
      "title": "Segment 9 (pages 90-101)",
      "start_page": 90,
      "end_page": 101,
      "detection_method": "topic_boundary",
      "content": "             std::string,        // email\n             std::size_t> ;      // reputation\nThough the comments indicate what each field of the tuple represents, that’s proba‐\nbly not very helpful when you encounter code like this in a separate source file:\nUserInfo uInfo;                  // object of tuple type\n…\nauto val = std::get<1>(uInfo);   // get value of field 1\nAs a programmer, you have a lot of stuff to keep track of. Should you really be\nexpected to remember that field 1 corresponds to the user’s email address? I think\nnot. Using an unscoped enum to associate names with field numbers avoids the need\nto:\nenum UserInfoFields { uiName, uiEmail, uiReputation };\nUserInfo uInfo;                        // as before\n…\nauto val = std::get<uiEmail>(uInfo);   // ah, get value of\n                                       // email field\nWhat makes this work is the implicit conversion from UserInfoFields to\nstd::size_t, which is the type that std::get requires.\nThe corresponding code with scoped enums is substantially more verbose:\nenum class UserInfoFields { uiName, uiEmail, uiReputation };\nUserInfo uInfo;                        // as before\n…\nauto val =\n  std::get<static_cast<std::size_t>(UserInfoFields::uiEmail)>\n    (uInfo);\nThe verbosity can be reduced by writing a function that takes an enumerator and\nreturns its corresponding std::size_t value, but it’s a bit tricky. std::get is a tem‐\nplate, and the value you provide is a template argument (notice the use of angle\nbrackets, not parentheses), so the function that transforms an enumerator into a\nstd::size_t has to produce its result during compilation. As Item 15 explains, that\nmeans it must be a constexpr function.\nIn fact, it should really be a constexpr function template, because it should work\nwith any kind of enum. And if we’re going to make that generalization, we should\n72 \n| \nItem 10\nwww.it-ebooks.info\n\n\ngeneralize the return type, too. Rather than returning std::size_t, we’ll return the\nenum’s underlying type. It’s available via the std::underlying_type type trait. (See\nItem 9 for information on type traits.) Finally, we’ll declare it noexcept (see Item 14),\nbecause we know it will never yield an exception. The result is a function template\ntoUType that takes an arbitrary enumerator and can return its value as a compile-\ntime constant:\ntemplate<typename E>\nconstexpr typename std::underlying_type<E>::type\n  toUType(E enumerator) noexcept\n{\n  return\n    static_cast<typename\n                std::underlying_type<E>::type>(enumerator);\n}\nIn C++14, toUType can be simplified by replacing typename std::underly\ning_type<E>::type with the sleeker std::underlying_type_t (see Item 9):\ntemplate<typename E>                               // C++14\nconstexpr std::underlying_type_t<E>\n  toUType(E enumerator) noexcept\n{\n  return static_cast<std::underlying_type_t<E>>(enumerator);\n}\nThe even-sleeker auto return type (see Item 3) is also valid in C++14:\ntemplate<typename E>                               // C++14\nconstexpr auto\n  toUType(E enumerator) noexcept\n{\n  return static_cast<std::underlying_type_t<E>>(enumerator);\n}\nRegardless of how it’s written, toUType permits us to access a field of the tuple like\nthis:\nauto val = std::get<toUType(UserInfoFields::uiEmail)>(uInfo);\nIt’s still more to write than use of the unscoped enum, but it also avoids namespace\npollution and inadvertent conversions involving enumerators. In many cases, you\nmay decide that typing a few extra characters is a reasonable price to pay for the abil‐\nity to avoid the pitfalls of an enum technology that dates to a time when the state of\nthe art in digital telecommunications was the 2400-baud modem.\nItem 10 \n| \n73\nwww.it-ebooks.info\n\n\nThings to Remember\n• C++98-style enums are now known as unscoped enums.\n• Enumerators of scoped enums are visible only within the enum. They convert\nto other types only with a cast.\n• Both scoped and unscoped enums support specification of the underlying type.\nThe default underlying type for scoped enums is int. Unscoped enums have no\ndefault underlying type.\n• Scoped enums may always be forward-declared. Unscoped enums may be\nforward-declared only if their declaration specifies an underlying type.\nItem 11: Prefer deleted functions to private undefined\nones.\nIf you’re providing code to other developers, and you want to prevent them from\ncalling a particular function, you generally just don’t declare the function. No func‐\ntion declaration, no function to call. Easy, peasy. But sometimes C++ declares func‐\ntions for you, and if you want to prevent clients from calling those functions, the\npeasy isn’t quite so easy any more.\nThe situation arises only for the “special member functions,” i.e., the member func‐\ntions that C++ automatically generates when they’re needed. Item 17 discusses these\nfunctions in detail, but for now, we’ll worry only about the copy constructor and the\ncopy assignment operator. This chapter is largely devoted to common practices in\nC++98 that have been superseded by better practices in C++11, and in C++98, if you\nwant to suppress use of a member function, it’s almost always the copy constructor,\nthe assignment operator, or both.\nThe C++98 approach to preventing use of these functions is to declare them private\nand not define them. For example, near the base of the iostreams hierarchy in the\nC++ Standard Library is the class template basic_ios. All istream and ostream\nclasses inherit (possibly indirectly) from this class. Copying istreams and ostreams is\nundesirable, because it’s not really clear what such operations should do. An istream\nobject, for example, represents a stream of input values, some of which may have\nalready been read, and some of which will potentially be read later. If an istream were\nto be copied, would that entail copying all the values that had already been read as\nwell as all the values that would be read in the future? The easiest way to deal with\nsuch questions is to define them out of existence. Prohibiting the copying of streams\ndoes just that.\n74 \n| \nItem 10\nwww.it-ebooks.info\n\n\nTo render istream and ostream classes uncopyable, basic_ios is specified in C++98\nas follows (including the comments):\ntemplate <class charT, class traits = char_traits<charT> >\nclass basic_ios : public ios_base {\npublic:\n  …\nprivate:\n  basic_ios(const basic_ios& );            // not defined\n  basic_ios& operator=(const basic_ios&);  // not defined\n};\nDeclaring these functions private prevents clients from calling them. Deliberately\nfailing to define them means that if code that still has access to them (i.e., member\nfunctions or friends of the class) uses them, linking will fail due to missing function\ndefinitions.\nIn C++11, there’s a better way to achieve essentially the same end: use “= delete” to\nmark the copy constructor and the copy assignment operator as deleted functions.\nHere’s the same part of basic_ios as it’s specified in C++11:\ntemplate <class charT, class traits = char_traits<charT> >\nclass basic_ios : public ios_base {\npublic:\n  …\n  basic_ios(const basic_ios& ) = delete;\n  basic_ios& operator=(const basic_ios&) = delete;\n  …\n};\nThe difference between deleting these functions and declaring them private may\nseem more a matter of fashion than anything else, but there’s greater substance here\nthan you might think. Deleted functions may not be used in any way, so even code\nthat’s in member and friend functions will fail to compile if it tries to copy\nbasic_ios objects. That’s an improvement over the C++98 behavior, where such\nimproper usage wouldn’t be diagnosed until link-time.\nBy convention, deleted functions are declared public, not private. There’s a reason\nfor that. When client code tries to use a member function, C++ checks accessibility\nbefore deleted status. When client code tries to use a deleted private function, some\ncompilers complain only about the function being private, even though the func‐\ntion’s accessibility doesn’t really affect whether it can be used. It’s worth bearing this\nin mind when revising legacy code to replace private-and-not-defined member\nItem 11 \n| \n75\nwww.it-ebooks.info\n\n\nfunctions with deleted ones, because making the new functions public will generally\nresult in better error messages.\nAn important advantage of deleted functions is that any function may be deleted,\nwhile only member functions may be private. For example, suppose we have a non-\nmember function that takes an integer and returns whether it’s a lucky number:\nbool isLucky(int number);\nC++’s C heritage means that pretty much any type that can be viewed as vaguely\nnumerical will implicitly convert to int, but some calls that would compile might not\nmake sense:\nif (isLucky('a')) …            // is 'a' a lucky number?\nif (isLucky(true)) …           // is \"true\"?\nif (isLucky(3.5)) …            // should we truncate to 3\n                               // before checking for luckiness?\nIf lucky numbers must really be integers, we’d like to prevent calls such as these from\ncompiling.\nOne way to accomplish that is to create deleted overloads for the types we want to\nfilter out:\nbool isLucky(int number);            // original function\nbool isLucky(char) = delete;         // reject chars\nbool isLucky(bool) = delete;         // reject bools\nbool isLucky(double) = delete;       // reject doubles and\n                                     // floats\n(The comment on the double overload that says that both doubles and floats will\nbe rejected may surprise you, but your surprise will dissipate once you recall that,\ngiven a choice between converting a float to an int or to a double, C++ prefers the\nconversion to double. Calling isLucky with a float will therefore call the double\noverload, not the int one. Well, it’ll try to. The fact that that overload is deleted will\nprevent the call from compiling.)\nAlthough deleted functions can’t be used, they are part of your program. As such,\nthey are taken into account during overload resolution. That’s why, with the deleted\nfunction declarations above, the undesirable calls to isLucky will be rejected:\nif (isLucky('a')) …           // error! call to deleted function\n76 \n| \nItem 11\nwww.it-ebooks.info\n\n\nif (isLucky(true)) …          // error!\nif (isLucky(3.5f)) …          // error!\nAnother trick that deleted functions can perform (and that private member func‐\ntions can’t) is to prevent use of template instantiations that should be disabled. For\nexample, suppose you need a template that works with built-in pointers (Chapter 4’s\nadvice to prefer smart pointers to raw pointers notwithstanding):\ntemplate<typename T>\nvoid processPointer(T* ptr);\nThere are two special cases in the world of pointers. One is void* pointers, because\nthere is no way to dereference them, to increment or decrement them, etc. The other\nis char* pointers, because they typically represent pointers to C-style strings, not\npointers to individual characters. These special cases often call for special handling,\nand, in the case of the processPointer template, let’s assume the proper handling is\nto reject calls using those types. That is, it should not be possible to call\nprocessPointer with void* or char* pointers.\nThat’s easily enforced. Just delete those instantiations:\ntemplate<>\nvoid processPointer<void>(void*) = delete;\ntemplate<>\nvoid processPointer<char>(char*) = delete;\nNow, if calling processPointer with a void* or a char* is invalid, it’s probably also\ninvalid to call it with a const void* or a const char*, so those instantiations will\ntypically need to be deleted, too:\ntemplate<>\nvoid processPointer<const void>(const void*) = delete;\ntemplate<>\nvoid processPointer<const char>(const char*) = delete;\nAnd if you really want to be thorough, you’ll also delete the const volatile void*\nand const volatile char* overloads, and then you’ll get to work on the overloads\nfor pointers to the other standard character types: std::wchar_t, std::char16_t,\nand std::char32_t.\nInterestingly, if you have a function template inside a class, and you’d like to disable\nsome instantiations by declaring them private (à la classic C++98 convention), you\ncan’t, because it’s not possible to give a member function template specialization a\nItem 11 \n| \n77\nwww.it-ebooks.info\n\n\ndifferent access level from that of the main template. If processPointer were a\nmember function template inside Widget, for example, and you wanted to disable\ncalls for void* pointers, this would be the C++98 approach, though it would not \ncompile:\nclass Widget {\npublic:\n  …\n  template<typename T>\n  void processPointer(T* ptr)\n  { … }\nprivate:\n  template<>                                 // error!\n  void processPointer<void>(void*);\n};\nThe problem is that template specializations must be written at namespace scope, not\nclass scope. This issue doesn’t arise for deleted functions, because they don’t need a\ndifferent access level. They can be deleted outside the class (hence at namespace\nscope):\nclass Widget {\npublic:\n  …\n  template<typename T>\n  void processPointer(T* ptr)\n  { … }\n  …\n};\ntemplate<>                                          // still\nvoid Widget::processPointer<void>(void*) = delete;  // public,\n                                                    // but\n                                                    // deleted\nThe truth is that the C++98 practice of declaring functions private and not defining\nthem was really an attempt to achieve what C++11’s deleted functions actually\naccomplish. As an emulation, the C++98 approach is not as good as the real thing. It\ndoesn’t work outside classes, it doesn’t always work inside classes, and when it does\nwork, it may not work until link-time. So stick to deleted functions.\n78 \n| \nItem 11\nwww.it-ebooks.info\n\n\nThings to Remember\n• Prefer deleted functions to private undefined ones.\n• Any function may be deleted, including non-member functions and template\ninstantiations.\nItem 12: Declare overriding functions override.\nThe world of object-oriented programming in C++ revolves around classes, inheri‐\ntance, and virtual functions. Among the most fundamental ideas in this world is that\nvirtual function implementations in derived classes override the implementations of\ntheir base class counterparts. It’s disheartening, then, to realize just how easily virtual\nfunction overriding can go wrong. It’s almost as if this part of the language were\ndesigned with the idea that Murphy’s Law wasn’t just to be obeyed, it was to be hon‐\nored.\nBecause “overriding” sounds a lot like “overloading,” yet is completely unrelated, let\nme make clear that virtual function overriding is what makes it possible to invoke a\nderived class function through a base class interface:\nclass Base {\npublic:\n  virtual void doWork();         // base class virtual function\n  …\n};\nclass Derived: public Base {\npublic:\n  virtual void doWork();         // overrides Base::doWork\n  …                              // (\"virtual\" is optional\n};                               // here)\nstd::unique_ptr<Base> upb =      // create base class pointer\n  std::make_unique<Derived>();   // to derived class object;\n                                 // see Item 21 for info on\n…                                // std::make_unique\nupb->doWork();                   // call doWork through base\n                                 // class ptr; derived class\n                                 // function is invoked\nFor overriding to occur, several requirements must be met:\nItem 11 \n| \n79\nwww.it-ebooks.info\n\n\n• The base class function must be virtual.\n• The base and derived function names must be identical (except in the case of\ndestructors).\n• The parameter types of the base and derived functions must be identical.\n• The constness of the base and derived functions must be identical.\n• The return types and exception specifications of the base and derived functions\nmust be compatible.\nTo these constraints, which were also part of C++98, C++11 adds one more:\n• The functions’ reference qualifiers must be identical. Member function reference\nqualifiers are one of C++11’s less-publicized features, so don’t be surprised if\nyou’ve never heard of them. They make it possible to limit use of a member func‐\ntion to lvalues only or to rvalues only. Member functions need not be virtual to\nuse them:\nclass Widget {\npublic:\n  …\n  void doWork() &;       // this version of doWork applies\n                         // only when *this is an lvalue\n  void doWork() &&;      // this version of doWork applies\n};                       // only when *this is an rvalue\n…\nWidget makeWidget();     // factory function (returns rvalue)\nWidget w;                // normal object (an lvalue)\n…\nw.doWork();              // calls Widget::doWork for lvalues\n                         // (i.e., Widget::doWork &)\nmakeWidget().doWork();   // calls Widget::doWork for rvalues\n                         // (i.e., Widget::doWork &&)\nI’ll say more about member functions with reference qualifiers later, but for now,\nsimply note that if a virtual function in a base class has a reference qualifier,\nderived class overrides of that function must have exactly the same reference\n80 \n| \nItem 12\nwww.it-ebooks.info\n\n\nqualifier. If they don’t, the declared functions will still exist in the derived class,\nbut they won’t override anything in the base class.\nAll these requirements for overriding mean that small mistakes can make a big differ‐\nence. Code containing overriding errors is typically valid, but its meaning isn’t what\nyou intended. You therefore can’t rely on compilers notifying you if you do some‐\nthing wrong. For example, the following code is completely legal and, at first sight,\nlooks reasonable, but it contains no virtual function overrides—not a single derived\nclass function that is tied to a base class function. Can you identify the problem in\neach case, i.e., why each derived class function doesn’t override the base class func‐\ntion with the same name?\nclass Base {\npublic:\n  virtual void mf1() const;\n  virtual void mf2(int x);\n  virtual void mf3() &;\n  void mf4() const;\n};\nclass Derived: public Base {\npublic:\n  virtual void mf1();\n  virtual void mf2(unsigned int x);\n  virtual void mf3() &&;\n  void mf4() const;\n};\nNeed some help?\n• mf1 is declared const in Base, but not in Derived.\n• mf2 takes an int in Base, but an unsigned int in Derived.\n• mf3 is lvalue-qualified in Base, but rvalue-qualified in Derived.\n• mf4 isn’t declared virtual in Base.\nYou may think, “Hey, in practice, these things will elicit compiler warnings, so I don’t\nneed to worry.” Maybe that’s true. But maybe it’s not. With two of the compilers I\nchecked, the code was accepted without complaint, and that was with all warnings\nenabled. (Other compilers provided warnings about some of the issues, but not all of\nthem.)\nBecause declaring derived class overrides is important to get right, but easy to get\nwrong, C++11 gives you a way to make explicit that a derived class function is\nItem 12 \n| \n81\nwww.it-ebooks.info\n\n\nsupposed to override a base class version: declare it override. Applying this to the\nexample above would yield this derived class:\nclass Derived: public Base {\npublic:\n  virtual void mf1() override;\n  virtual void mf2(unsigned int x) override;\n  virtual void mf3() && override;\n  virtual void mf4() const override;\n};\nThis won’t compile, of course, because when written this way, compilers will kvetch\nabout all the overriding-related problems. That’s exactly what you want, and it’s why\nyou should declare all your overriding functions override.\nThe code using override that does compile looks as follows (assuming that the goal\nis for all functions in Derived to override virtuals in Base):\nclass Base {\npublic:\n  virtual void mf1() const;\n  virtual void mf2(int x);\n  virtual void mf3() &;\n  virtual void mf4() const;\n};\nclass Derived: public Base {\npublic:\n  virtual void mf1() const override;\n  virtual void mf2(int x) override;\n  virtual void mf3() & override;\n  void mf4() const override;          // adding \"virtual\" is OK,\n};                                    // but not necessary\nNote that in this example, part of getting things to work involves declaring mf4 vir‐\ntual in Base. Most overriding-related errors occur in derived classes, but it’s possible\nfor things to be incorrect in base classes, too.\nA policy of using override on all your derived class overrides can do more than just\nenable compilers to tell you when would-be overrides aren’t overriding anything. It\ncan also help you gauge the ramifications if you’re contemplating changing the signa‐\nture of a virtual function in a base class. If derived classes use override everywhere,\nyou can just change the signature, recompile your system, see how much damage\nyou’ve caused (i.e., how many derived classes fail to compile), then decide whether\nthe signature change is worth the trouble. Without override, you’d have to hope you\nhave comprehensive unit tests in place, because, as we’ve seen, derived class virtuals\n82 \n| \nItem 12\nwww.it-ebooks.info\n\n\n2 Applying final to a virtual function prevents the function from being overridden in derived classes. final\nmay also be applied to a class, in which case the class is prohibited from being used as a base class.\nthat are supposed to override base class functions, but don’t, need not elicit compiler\ndiagnostics.\nC++ has always had keywords, but C++11 introduces two contextual keywords, over\nride and final.2 These keywords have the characteristic that they are reserved, but\nonly in certain contexts. In the case of override, it has a reserved meaning only\nwhen it occurs at the end of a member function declaration. That means that if you\nhave legacy code that already uses the name override, you don’t need to change it\nfor C++11:\nclass Warning {           // potential legacy class from C++98\npublic:\n  …\n  void override();        // legal in both C++98 and C++11\n  …                       // (with the same meaning)\n};\nThat’s all there is to say about override, but it’s not all there is to say about member\nfunction reference qualifiers. I promised I’d provide more information on them later,\nand now it’s later.\nIf we want to write a function that accepts only lvalue arguments, we declare a non-\nconst lvalue reference parameter:\nvoid doSomething(Widget& w);      // accepts only lvalue Widgets\nIf we want to write a function that accepts only rvalue arguments, we declare an\nrvalue reference parameter:\nvoid doSomething(Widget&& w);     // accepts only rvalue Widgets\nMember function reference qualifiers simply make it possible to draw the same dis‐\ntinction for the object on which a member function is invoked, i.e., *this. It’s pre‐\ncisely analogous to the const at the end of a member function declaration, which\nindicates that the object on which the member function is invoked (i.e., *this) is\nconst.\nThe need for reference-qualified member functions is not common, but it can arise.\nFor example, suppose our Widget class has a std::vector data member, and we\noffer an accessor function that gives clients direct access to it:\nclass Widget {\npublic:\nItem 12 \n| \n83\nwww.it-ebooks.info\n",
      "page_number": 90,
      "chapter_number": 9,
      "summary": "As Item 15 explains, that\nmeans it must be a constexpr function Key topics include classes, function, and template. Covers function. std::get is a tem‐\nplate, and the value you provide is a template argument (notice the use of angle\nbrackets, not parentheses), so the function that transforms an enumerator into a\nstd::size_t has to produce its result during compilation.",
      "keywords": [
        "function",
        "base",
        "void",
        "base class",
        "virtual void",
        "functions",
        "derived class function",
        "derived class",
        "derived",
        "Item",
        "member function",
        "virtual",
        "std",
        "base class function",
        "deleted functions"
      ],
      "concepts": [
        "classes",
        "function",
        "template",
        "std",
        "overriding",
        "override",
        "delete",
        "deleting",
        "declare",
        "declaration"
      ],
      "similar_chapters": [
        {
          "book": "C++ Concurrency in Action",
          "chapter": 39,
          "title": "Segment 39 (pages 382-396)",
          "relevance_score": 0.59,
          "method": "sentence_transformers"
        },
        {
          "book": "C++ Templates_ The Complete Guide",
          "chapter": 46,
          "title": "Segment 46 (pages 1469-1503)",
          "relevance_score": 0.59,
          "method": "sentence_transformers"
        },
        {
          "book": "C++ Templates_ The Complete Guide",
          "chapter": 64,
          "title": "Segment 64 (pages 2050-2080)",
          "relevance_score": 0.59,
          "method": "sentence_transformers"
        },
        {
          "book": "C++ Templates_ The Complete Guide",
          "chapter": 7,
          "title": "Segment 7 (pages 198-230)",
          "relevance_score": 0.58,
          "method": "sentence_transformers"
        },
        {
          "book": "C++ Templates_ The Complete Guide",
          "chapter": 27,
          "title": "Segment 27 (pages 850-883)",
          "relevance_score": 0.56,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 10,
      "title": "Segment 10 (pages 102-112)",
      "start_page": 102,
      "end_page": 112,
      "detection_method": "topic_boundary",
      "content": "  using DataType = std::vector<double>;      // see Item 9 for\n  …                                          // info on \"using\"\n  DataType& data() { return values; }\n  …\nprivate:\n  DataType values;\n};\nThis is hardly the most encapsulated design that’s seen the light of day, but set that\naside and consider what happens in this client code:\nWidget w;\n…\nauto vals1 = w.data();               // copy w.values into vals1\nThe return type of Widget::data is an lvalue reference (a std::vector<double>&,\nto be precise), and because lvalue references are defined to be lvalues, we’re initializ‐\ning vals1 from an lvalue. vals1 is thus copy constructed from w.values, just as the\ncomment says.\nNow suppose we have a factory function that creates Widgets,\nWidget makeWidget();\nand we want to initialize a variable with the std::vector inside the Widget returned\nfrom makeWidget:\nauto vals2 = makeWidget().data();    // copy values inside the\n                                     // Widget into vals2\nAgain, Widgets::data returns an lvalue reference, and, again, the lvalue reference is\nan lvalue, so, again, our new object (vals2) is copy constructed from values inside\nthe Widget. This time, though, the Widget is the temporary object returned from\nmakeWidget (i.e., an rvalue), so copying the std::vector inside it is a waste of time.\nIt’d be preferable to move it, but, because data is returning an lvalue reference, the\nrules of C++ require that compilers generate code for a copy. (There’s some wiggle\nroom for optimization through what is known as the “as if rule,” but you’d be foolish\nto rely on your compilers finding a way to take advantage of it.)\nWhat’s needed is a way to specify that when data is invoked on an rvalue Widget, the\nresult should also be an rvalue. Using reference qualifiers to overload data for lvalue\nand rvalue Widgets makes that possible:\n84 \n| \nItem 12\nwww.it-ebooks.info\n\n\nclass Widget {\npublic:\n  using DataType = std::vector<double>;\n  …\n  DataType& data() &                // for lvalue Widgets, \n  { return values; }                // return lvalue\n  DataType data() &&                // for rvalue Widgets,\n  { return std::move(values); }     // return rvalue\n  …\nprivate:\n  DataType values;\n};\nNotice the differing return types from the data overloads. The lvalue reference over‐\nload returns an lvalue reference (i.e., an lvalue), and the rvalue reference overload\nreturns a temporary object (i.e., an rvalue). This means that client code now behaves\nas we’d like:\nauto vals1 = w.data();             // calls lvalue overload for\n                                   // Widget::data, copy-\n                                   // constructs vals1\nauto vals2 = makeWidget().data();  // calls rvalue overload for\n                                   // Widget::data, move-\n                                   // constructs vals2\nThis is certainly nice, but don’t let the warm glow of this happy ending distract you\nfrom the true point of this Item. That point is that whenever you declare a function in\na derived class that’s meant to override a virtual function in a base class, be sure to\ndeclare that function override.\nThings to Remember\n• Declare overriding functions override.\n• Member function reference qualifiers make it possible to treat lvalue and\nrvalue objects (*this) differently.\nItem 12 \n| \n85\nwww.it-ebooks.info\n\n\nItem 13: Prefer const_iterators to iterators.\nconst_iterators are the STL equivalent of pointers-to-const. They point to values\nthat may not be modified. The standard practice of using const whenever possible\ndictates that you should use const_iterators any time you need an iterator, yet\nhave no need to modify what the iterator points to.\nThat’s as true for C++98 as for C++11, but in C++98, const_iterators had only\nhalfhearted support. It wasn’t that easy to create them, and once you had one, the\nways you could use it were limited. For example, suppose you want to search a\nstd::vector<int> for the first occurrence of 1983 (the year “C++” replaced “C with\nClasses” as the name of the programming language), then insert the value 1998 (the\nyear the first ISO C++ Standard was adopted) at that location. If there’s no 1983 in\nthe vector, the insertion should go at the end of the vector. Using iterators in\nC++98, that was easy:\nstd::vector<int> values;\n…\nstd::vector<int>::iterator it =\n  std::find(values.begin(),values.end(), 1983);\nvalues.insert(it, 1998);\nBut iterators aren’t really the proper choice here, because this code never modifies\nwhat an iterator points to. Revising the code to use const_iterators should be\ntrivial, but in C++98, it was anything but. Here’s one approach that’s conceptually\nsound, though still not correct:\ntypedef std::vector<int>::iterator IterT;             // type-\ntypedef std::vector<int>::const_iterator ConstIterT;  // defs\nstd::vector<int> values;\n…\nConstIterT ci =\n  std::find(static_cast<ConstIterT>(values.begin()),  // cast\n            static_cast<ConstIterT>(values.end()),    // cast\n            1983);\nvalues.insert(static_cast<IterT>(ci), 1998);    // may not\n                                                // compile; see\n                                                // below\n86 \n| \nItem 13\nwww.it-ebooks.info\n\n\nThe typedefs aren’t required, of course, but they make the casts in the code easier to\nwrite. (If you’re wondering why I’m showing typedefs instead of following the\nadvice of Item 9 to use alias declarations, it’s because this example shows C++98\ncode, and alias declarations are a feature new to C++11.)\nThe casts in the call to std::find are present because values is a non-const con‐\ntainer and in C++98, there was no simple way to get a const_iterator from a non-\nconst container. The casts aren’t strictly necessary, because it was possible to get\nconst_iterators in other ways (e.g., you could bind values to a reference-to-const\nvariable, then use that variable in place of values in your code), but one way or\nanother, the process of getting const_iterators to elements of a non-const con‐\ntainer involved some amount of contorting.\nOnce you had the const_iterators, matters often got worse, because in C++98,\nlocations for insertions (and erasures) could be specified only by iterators.\nconst_iterators weren’t acceptable. That’s why, in the code above, I cast the\nconst_iterator (that I was so careful to get from std::find) into an iterator:\npassing a const_iterator to insert wouldn’t compile.\nTo be honest, the code I’ve shown might not compile, either, because there’s no\nportable conversion from a const_iterator to an iterator, not even with a\nstatic_cast. Even the semantic sledgehammer known as reinterpret_cast can’t\ndo the job. (That’s not a C++98 restriction. It’s true in C++11, too. const_iterators\nsimply don’t convert to iterators, no matter how much it might seem like they\nshould.) There are some portable ways to generate iterators that point where\nconst_iterators do, but they’re not obvious, not universally applicable, and not\nworth discussing in this book. Besides, I hope that by now my point is clear:\nconst_iterators were so much trouble in C++98, they were rarely worth the\nbother. At the end of the day, developers don’t use const whenever possible, they use\nit whenever practical, and in C++98, const_iterators just weren’t very practical.\nAll that changed in C++11. Now const_iterators are both easy to get and easy to\nuse. The container member functions cbegin and cend produce const_iterators,\neven for non-const containers, and STL member functions that use iterators to iden‐\ntify positions (e.g., insert and erase) actually use const_iterators. Revising the\noriginal C++98 code that uses iterators to use const_iterators in C++11 is truly\ntrivial:\nstd::vector<int> values;                           // as before\n…\nauto it =                                          // use cbegin\nItem 13 \n| \n87\nwww.it-ebooks.info\n\n\n  std::find(values.cbegin(),values.cend(), 1983);  // and cend\nvalues.insert(it, 1998);\nNow that’s code using const_iterators that’s practical!\nAbout the only situation in which C++11’s support for const_iterators comes up a\nbit short is when you want to write maximally generic library code. Such code takes\ninto account that some containers and container-like data structures offer begin and\nend (plus cbegin, cend, rbegin, etc.) as non-member functions, rather than mem‐\nbers. This is the case for built-in arrays, for example, and it’s also the case for some\nthird-party libraries with interfaces consisting only of free functions. Maximally\ngeneric code thus uses non-member functions rather than assuming the existence of\nmember versions.\nFor example, we could generalize the code we’ve been working with into a findAnd\nInsert template as follows:\ntemplate<typename C, typename V>\nvoid findAndInsert(C& container,          // in container, find\n                   const V& targetVal,    // first occurrence\n                   const V& insertVal)    // of targetVal, then\n{                                         // insert insertVal\n  using std::cbegin;                      // there\n  using std::cend;\n  auto it = std::find(cbegin(container),  // non-member cbegin\n                      cend(container),    // non-member cend\n                      targetVal);\n  container.insert(it, insertVal);\n}\nThis works fine in C++14, but, sadly, not in C++11. Through an oversight during\nstandardization, C++11 added the non-member functions begin and end, but it\nfailed to add cbegin, cend, rbegin, rend, crbegin, and crend. C++14 rectifies that\noversight.\nIf you’re using C++11, you want to write maximally generic code, and none of the\nlibraries you’re using provides the missing templates for non-member cbegin and\nfriends, you can throw your own implementations together with ease. For example,\nhere’s an implementation of non-member cbegin:\ntemplate <class C>\nauto cbegin(const C& container)->decltype(std::begin(container))\n{\n88 \n| \nItem 13\nwww.it-ebooks.info\n\n\n  return std::begin(container);         // see explanation below\n}\nYou’re surprised to see that non-member cbegin doesn’t call member cbegin, aren’t\nyou? So was I. But follow the logic. This cbegin template accepts any type of argu‐\nment representing a container-like data structure, C, and it accesses this argument\nthrough its reference-to-const parameter, container. If C is a conventional con‐\ntainer type (e.g., a std::vector<int>), container will be a reference to a const\nversion of that container (e.g., a const std::vector<int>&). Invoking the non-\nmember begin function (provided by C++11) on a const container yields a\nconst_iterator, and that iterator is what this template returns. The advantage of\nimplementing things this way is that it works even for containers that offer a begin\nmember function (which, for containers, is what C++11’s non-member begin calls),\nbut fail to offer a cbegin member. You can thus use this non-member cbegin on\ncontainers that directly support only begin.\nThis template also works if C is a built-in array type. In that case, container becomes\na reference to a const array. C++11 provides a specialized version of non-member\nbegin for arrays that returns a pointer to the array’s first element. The elements of a\nconst array are const, so the pointer that non-member begin returns for a const\narray is a pointer-to-const, and a pointer-to-const is, in fact, a const_iterator for\nan array. (For insight into how a template can be specialized for built-in arrays, con‐\nsult Item 1’s discussion of type deduction in templates that take reference parameters\nto arrays.)\nBut back to basics. The point of this Item is to encourage you to use const_itera\ntors whenever you can. The fundamental motivation—using const whenever it’s\nmeaningful—predates C++11, but in C++98, it simply wasn’t practical when working\nwith iterators. In C++11, it’s eminently practical, and C++14 tidies up the few bits of\nunfinished business that C++11 left behind.\nThings to Remember\n• Prefer const_iterators to iterators.\n• In maximally generic code, prefer non-member versions of begin, end,\nrbegin, etc., over their member function counterparts.\nItem 13 \n| \n89\nwww.it-ebooks.info\n\n\nItem 14: Declare functions noexcept if they won’t emit\nexceptions.\nIn C++98, exception specifications were rather temperamental beasts. You had to\nsummarize the exception types a function might emit, so if the function’s implemen‐\ntation was modified, the exception specification might require revision, too. Chang‐\ning an exception specification could break client code, because callers might be\ndependent on the original exception specification. Compilers typically offered no\nhelp in maintaining consistency among function implementations, exception specifi‐\ncations, and client code. Most programmers ultimately decided that C++98 exception\nspecifications weren’t worth the trouble.\nDuring work on C++11, a consensus emerged that the truly meaningful information\nabout a function’s exception-emitting behavior was whether it had any. Black or\nwhite, either a function might emit an exception or it guaranteed that it wouldn’t.\nThis maybe-or-never dichotomy forms the basis of C++11’s exception specifications,\nwhich essentially replace C++98’s. (C++98-style exception specifications remain\nvalid, but they’re deprecated.) In C++11, unconditional noexcept is for functions\nthat guarantee they won’t emit exceptions.\nWhether a function should be so declared is a matter of interface design. The\nexception-emitting behavior of a function is of key interest to clients. Callers can\nquery a function’s noexcept status, and the results of such a query can affect the\nexception safety or efficiency of the calling code. As such, whether a function is\nnoexcept is as important a piece of information as whether a member function is\nconst. Failure to declare a function noexcept when you know that it won’t emit an\nexception is simply poor interface specification.\nBut there’s an additional incentive to apply noexcept to functions that won’t pro‐\nduce exceptions: it permits compilers to generate better object code. To understand\nwhy, it helps to examine the difference between the C++98 and C++11 ways of saying\nthat a function won’t emit exceptions. Consider a function f that promises callers\nthey’ll never receive an exception. The two ways of expressing that are:\nint f(int x) throw();     // no exceptions from f: C++98 style\nint f(int x) noexcept;    // no exceptions from f: C++11 style\nIf, at runtime, an exception leaves f, f’s exception specification is violated. With the\nC++98 exception specification, the call stack is unwound to f’s caller, and, after some\nactions not relevant here, program execution is terminated. With the C++11 excep‐\ntion specification, runtime behavior is slightly different: the stack is only possibly\nunwound before program execution is terminated.\n90 \n| \nItem 14\nwww.it-ebooks.info\n\n\nThe difference between unwinding the call stack and possibly unwinding it has a sur‐\nprisingly large impact on code generation. In a noexcept function, optimizers need\nnot keep the runtime stack in an unwindable state if an exception would propagate\nout of the function, nor must they ensure that objects in a noexcept function are\ndestroyed in the inverse order of construction should an exception leave the function.\nFunctions with “throw()” exception specifications lack such optimization flexibility,\nas do functions with no exception specification at all. The situation can be summar‐\nized this way:\nRetType function(params) noexcept;     // most optimizable\nRetType function(params) throw();      // less optimizable\nRetType function(params);              // less optimizable\nThis alone is sufficient reason to declare functions noexcept whenever you know\nthey won’t produce exceptions.\nFor some functions, the case is even stronger. The move operations are the preemi‐\nnent example. Suppose you have a C++98 code base making use of a std::vec\ntor<Widget>. Widgets are added to the std::vector from time to time via\npush_back:\nstd::vector<Widget> vw;\n…\nWidget w;\n…                        // work with w\nvw.push_back(w);         // add w to vw\n…\nAssume this code works fine, and you have no interest in modifying it for C++11.\nHowever, you do want to take advantage of the fact that C++11’s move semantics can\nimprove the performance of legacy code when move-enabled types are involved. You\ntherefore ensure that Widget has move operations, either by writing them yourself or\nby seeing to it that the conditions for their automatic generation are fulfilled (see\nItem 17).\nWhen a new element is added to a std::vector, it’s possible that the std::vector\nlacks space for it, i.e., that the std::vector’s size is equal to its capacity. When that\nhappens, the std::vector allocates a new, larger, chunk of memory to hold its\nItem 14 \n| \n91\nwww.it-ebooks.info\n\n\n3 The \nchecking \nis \ntypically \nrather \nroundabout. \nFunctions \nlike \nstd::vector::push_back \ncall\nstd::move_if_noexcept, a variation of std::move that conditionally casts to an rvalue (see Item 23),\ndepending on whether the type’s move constructor is noexcept. In turn, std::move_if_noexcept consults\nstd::is_nothrow_move_constructible, and the value of this type trait (see Item 9) is set by compilers,\nbased on whether the move constructor has a noexcept (or throw()) designation.\nelements, and it transfers the elements from the existing chunk of memory to the new\none. In C++98, the transfer was accomplished by copying each element from the old\nmemory to the new memory, then destroying the objects in the old memory. This\napproach enabled push_back to offer the strong exception safety guarantee: if an\nexception was thrown during the copying of the elements, the state of the std::vec\ntor remained unchanged, because none of the elements in the old memory were\ndestroyed until all elements had been successfully copied into the new memory.\nIn C++11, a natural optimization would be to replace the copying of std::vector\nelements with moves. Unfortunately, doing this runs the risk of violating\npush_back’s exception safety guarantee. If n elements have been moved from the old\nmemory and an exception is thrown moving element n+1, the push_back operation\ncan’t run to completion. But the original std::vector has been modified: n of its\nelements have been moved from. Restoring their original state may not be possible,\nbecause attempting to move each object back into the original memory may itself\nyield an exception.\nThis is a serious problem, because the behavior of legacy code could depend on\npush_back’s strong exception safety guarantee. Therefore, C++11 implementations\ncan’t silently replace copy operations inside push_back with moves unless it’s known\nthat the move operations won’t emit exceptions. In that case, having moves replace\ncopies would be safe, and the only side effect would be improved performance.\nstd::vector::push_back takes advantage of this “move if you can, but copy if you\nmust” strategy, and it’s not the only function in the Standard Library that does. Other\nfunctions sporting the strong exception safety guarantee in C++98 (e.g., std::vec\ntor::reserve, std::deque::insert, etc.) behave the same way. All these functions\nreplace calls to copy operations in C++98 with calls to move operations in C++11\nonly if the move operations are known to not emit exceptions. But how can a func‐\ntion know if a move operation won’t produce an exception? The answer is obvious: it\nchecks to see if the operation  is declared noexcept.3\nswap functions comprise another case where noexcept is particularly desirable. swap\nis a key component of many STL algorithm implementations, and it’s commonly\nemployed in copy assignment operators, too. Its widespread use renders the opti‐\nmizations that noexcept affords especially worthwhile. Interestingly, whether swaps\nin the Standard Library are noexcept is sometimes dependent on whether user-\n92 \n| \nItem 14\nwww.it-ebooks.info\n\n\ndefined swaps are noexcept. For example, the declarations for the Standard Library’s\nswaps for arrays and std::pair are:\ntemplate <class T, size_t N>\nvoid swap(T (&a)[N],                                    // see\n          T (&b)[N]) noexcept(noexcept(swap(*a, *b)));  // below\ntemplate <class T1, class T2>\nstruct pair {\n  …\n  void swap(pair& p) noexcept(noexcept(swap(first, p.first)) &&\n                              noexcept(swap(second, p.second)));\n  …\n};\nThese functions are conditionally noexcept: whether they are noexcept depends on\nwhether the expressions inside the noexcept clauses are noexcept. Given two arrays\nof Widget, for example, swapping them is noexcept only if swapping individual ele‐\nments in the arrays is noexcept, i.e., if swap for Widget is noexcept. The author of\nWidget’s swap thus determines whether swapping arrays of Widget is noexcept.\nThat, in turn, determines whether other swaps, such as the one for arrays of arrays of\nWidget, are noexcept. Similarly, whether swapping two std::pair objects contain‐\ning Widgets is noexcept depends on whether swap for Widgets is noexcept. The\nfact that swapping higher-level data structures can generally be noexcept only if\nswapping their lower-level constituents is noexcept should motivate you to offer\nnoexcept swap functions whenever you can.\nBy now, I hope you’re excited about the optimization opportunities that noexcept\naffords. Alas, I must temper your enthusiasm. Optimization is important, but cor‐\nrectness is more important. I noted at the beginning of this Item that noexcept is\npart of a function’s interface, so you should declare a function noexcept only if you\nare willing to commit to a noexcept implementation over the long term. If you\ndeclare a function noexcept and later regret that decision, your options are bleak.\nYou can remove noexcept from the function’s declaration (i.e., change its interface),\nthus running the risk of breaking client code. You can change the implementation\nsuch that an exception could escape, yet keep the original (now incorrect) exception\nspecification. If you do that, your program will be terminated if an exception tries to\nleave the function. Or you can resign yourself to your existing implementation, aban‐\ndoning whatever kindled your desire to change the implementation in the first place.\nNone of these options is appealing.\nThe fact of the matter is that most functions are exception-neutral. Such functions\nthrow no exceptions themselves, but functions they call might emit one. When that\nItem 14 \n| \n93\nwww.it-ebooks.info\n\n\n4 The interface specifications for move operations on containers in the Standard Library lack noexcept. How‐\never, implementers are permitted to strengthen exception specifications for Standard Library functions, and,\nin practice, it is common for at least some container move operations to be declared noexcept. That practice\nexemplifies this Item’s advice. Having found that it’s possible to write container move operations such that\nexceptions aren’t thrown, implementers often declare the operations noexcept, even though the Standard\ndoes not require them to do so.\nhappens, the exception-neutral function allows the emitted exception to pass through\non its way to a handler further up the call chain. Exception-neutral functions are\nnever noexcept, because they may emit such “just passing through” exceptions. Most\nfunctions, therefore, quite properly lack the noexcept designation.\nSome functions, however, have natural implementations that emit no exceptions, and\nfor a few more—notably the move operations and swap—being noexcept can have\nsuch a significant payoff, it’s worth implementing them in a noexcept manner if at\nall possible.4 When you can honestly say that a function should never emit excep‐\ntions, you should definitely declare it noexcept.\nPlease note that I said some functions have natural noexcept implementations.\nTwisting a function’s implementation to permit a noexcept declaration is the tail\nwagging the dog. Is putting the cart before the horse. Is not seeing the forest for the\ntrees. Is…choose your favorite metaphor. If a straightforward function implementa‐\ntion might yield exceptions (e.g., by invoking a function that might throw), the hoops\nyou’ll jump through to hide that from callers (e.g., catching all exceptions and replac‐\ning them with status codes or special return values) will not only complicate your\nfunction’s implementation, it will typically complicate code at call sites, too. For\nexample, callers may have to check for status codes or special return values. The run‐\ntime cost of those complications (e.g., extra branches, larger functions that put more\npressure on instruction caches, etc.) could exceed any speedup you’d hope to achieve\nvia noexcept, plus you’d be saddled with source code that’s more difficult to com‐\nprehend and maintain. That’d be poor software engineering.\nFor some functions, being noexcept is so important, they’re that way by default. In\nC++98, it was considered bad style to permit the memory deallocation functions (i.e.,\noperator delete and operator delete[]) and destructors to emit exceptions, and\nin C++11, this style rule has been all but upgraded to a language rule. By default, all\nmemory deallocation functions and all destructors—both user-defined and compiler-\ngenerated—are implicitly noexcept. There’s thus no need to declare them noexcept.\n(Doing so doesn’t hurt anything, it’s just unconventional.) The only time a destructor\nis not implicitly noexcept is when a data member of the class (including inherited\nmembers and those contained inside other data members) is of a type that expressly\nstates that its destructor may emit exceptions (e.g., declares it “noexcept(false)”).\nSuch destructors are uncommon. There are none in the Standard Library, and if the\n94 \n| \nItem 14\nwww.it-ebooks.info\n",
      "page_number": 102,
      "chapter_number": 10,
      "summary": "This chapter covers segment 10 (pages 102-112). Key topics include function, functions. Covers function, exception. This time, though, the Widget is the temporary object returned from\nmakeWidget (i.e., an rvalue), so copying the std::vector inside it is a waste of time.",
      "keywords": [
        "noexcept",
        "std",
        "function",
        "const",
        "Widget",
        "functions",
        "exception",
        "Item",
        "iterators",
        "code",
        "n’t",
        "vector",
        "exceptions",
        "move",
        "data"
      ],
      "concepts": [
        "function",
        "functions",
        "std",
        "exceptions",
        "container",
        "code",
        "values",
        "item",
        "implementations",
        "implementation"
      ],
      "similar_chapters": [
        {
          "book": "More Effective C++",
          "chapter": 12,
          "title": "Segment 12 (pages 116-123)",
          "relevance_score": 0.57,
          "method": "sentence_transformers"
        },
        {
          "book": "More Effective C++",
          "chapter": 9,
          "title": "Segment 9 (pages 76-97)",
          "relevance_score": 0.56,
          "method": "sentence_transformers"
        },
        {
          "book": "More Effective C++",
          "chapter": 4,
          "title": "Segment 4 (pages 25-32)",
          "relevance_score": 0.55,
          "method": "sentence_transformers"
        },
        {
          "book": "More Effective C++",
          "chapter": 23,
          "title": "Segment 23 (pages 224-233)",
          "relevance_score": 0.55,
          "method": "sentence_transformers"
        },
        {
          "book": "More Effective C++",
          "chapter": 29,
          "title": "Segment 29 (pages 293-301)",
          "relevance_score": 0.55,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 11,
      "title": "Segment 11 (pages 113-123)",
      "start_page": 113,
      "end_page": 123,
      "detection_method": "topic_boundary",
      "content": "5 “Regardless of the state of the program” and “no constraints” doesn’t legitimize programs whose behavior is\nalready undefined. For example, std::vector::size has a wide contract, but that doesn’t require that it\nbehave reasonably if you invoke it on a random chunk of memory that you’ve cast to a std::vector. The\nresult of the cast is undefined, so there are no behavioral guarantees for the program containing the cast.\ndestructor for an object being used by the Standard Library (e.g., because it’s in a\ncontainer or was passed to an algorithm) emits an exception, the behavior of the pro‐\ngram is undefined.\nIt’s worth noting that some library interface designers distinguish functions with\nwide contracts from those with narrow contracts. A function with a wide contract has\nno preconditions. Such a function may be called regardless of the state of the pro‐\ngram, and it imposes no constraints on the arguments that callers pass it.5 Functions\nwith wide contracts never exhibit undefined behavior.\nFunctions without wide contracts have narrow contracts. For such functions, if a pre‐\ncondition is violated, results are undefined.\nIf you’re writing a function with a wide contract and you know it won’t emit excep‐\ntions, following the advice of this Item and declaring it noexcept is easy. For func‐\ntions with narrow contracts, the situation is trickier. For example, suppose you’re\nwriting a function f taking a std::string parameter, and suppose f’s natural imple‐\nmentation never yields an exception. That suggests that f should be declared noex\ncept.\nNow suppose that f has a precondition: the length of its std::string parameter\ndoesn’t exceed 32 characters. If f were to be called with a std::string whose length\nis greater than 32, behavior would be undefined, because a precondition violation by\ndefinition results in undefined behavior. f is under no obligation to check this pre‐\ncondition, because functions may assume that their preconditions are satisfied. (Call‐\ners are responsible for ensuring that such assumptions are valid.) Even with a\nprecondition, then, declaring f noexcept seems  appropriate:\nvoid f(const std::string& s) noexcept;    // precondition:\n                                          // s.length() <= 32\nBut suppose that f’s implementer chooses to check for precondition violations.\nChecking isn’t required, but it’s also not forbidden, and checking the precondition\ncould be useful, e.g., during system testing. Debugging an exception that’s been\nthrown is generally easier than trying to track down the cause of undefined behavior.\nBut how should a precondition violation be reported such that a test harness or a cli‐\nent error handler could detect it? A straightforward approach would be to throw a\n“precondition was violated” exception, but if f is declared noexcept, that would be\nimpossible; throwing an exception would lead to program termination. For this rea‐\nItem 14 \n| \n95\nwww.it-ebooks.info\n\n\nson, library designers who distinguish wide from narrow contracts generally reserve\nnoexcept for functions with wide contracts.\nAs a final point, let me elaborate on my earlier observation that compilers typically\noffer no help in identifying inconsistencies between function implementations and\ntheir exception specifications. Consider this code, which is perfectly legal:\nvoid setup();           // functions defined elsewhere\nvoid cleanup();\nvoid doWork() noexcept\n{\n  setup();              // set up work to be done\n  …                     // do the actual work\n  cleanup();            // perform cleanup actions\n}\nHere, doWork is declared noexcept, even though it calls the non-noexcept functions\nsetup and cleanup. This seems contradictory, but it could be that setup and\ncleanup document that they never emit exceptions, even though they’re not declared\nthat way. There could be good reasons for their non-noexcept declarations. For\nexample, they might be part of a library written in C. (Even functions from the\nC Standard Library that have been moved into the std namespace lack exception\nspecifications, e.g., std::strlen isn’t declared noexcept.) Or they could be part of a\nC++98 library that decided not to use C++98 exception specifications and hasn’t yet\nbeen revised for C++11.\nBecause there are legitimate reasons for noexcept functions to rely on code lacking\nthe noexcept guarantee, C++ permits such code, and compilers generally don’t issue\nwarnings about it.\nThings to Remember\n• noexcept is part of a function’s interface, and that means that callers may\ndepend on it.\n• noexcept functions are more optimizable than non-noexcept functions.\n• noexcept is particularly valuable for the move operations, swap, memory\ndeallocation functions, and destructors.\n• Most functions are exception-neutral rather than noexcept.\n96 \n| \nItem 14\nwww.it-ebooks.info\n\n\nItem 15: Use constexpr whenever possible.\nIf there were an award for the most confusing new word in C++11, constexpr would\nprobably win it. When applied to objects, it’s essentially a beefed-up form of const,\nbut when applied to functions, it has a quite different meaning. Cutting through the\nconfusion is worth the trouble, because when constexpr corresponds to what you\nwant to express, you definitely want to use it.\nConceptually, constexpr indicates a value that’s not only constant, it’s known dur‐\ning compilation. The concept is only part of the story, though, because when con\nstexpr is applied to functions, things are more nuanced than this suggests. Lest I\nruin the surprise ending, for now I’ll just say that you can’t assume that the results of\nconstexpr functions are const, nor can you take for granted that their values are\nknown during compilation. Perhaps most intriguingly, these things are features. It’s\ngood that constexpr functions need not produce results that are const or known\nduring compilation!\nBut let’s begin with constexpr objects. Such objects are, in fact, const, and they do,\nin fact, have values that are known at compile time. (Technically, their values are\ndetermined during translation, and translation consists not just of compilation but\nalso of linking. Unless you write compilers or linkers for C++, however, this has no\neffect on you, so you can blithely program as if the values of constexpr objects were\ndetermined during compilation.)\nValues known during compilation are privileged. They may be placed in read-only\nmemory, for example, and, especially for developers of embedded systems, this can\nbe a feature of considerable importance. Of broader applicability is that integral val‐\nues that are constant and known during compilation can be used in contexts where\nC++ requires an integral constant expression. Such contexts include specification of\narray sizes, integral template arguments (including lengths of std::array objects),\nenumerator values, alignment specifiers, and more. If you want to use a variable for\nthese kinds of things, you certainly want to declare it constexpr, because then com‐\npilers will ensure that it has a compile-time value:\nint sz;                             // non-constexpr variable\n…\nconstexpr auto arraySize1 = sz;     // error! sz's value not\n                                    // known at compilation\nstd::array<int, sz> data1;          // error! same problem\nconstexpr auto arraySize2 = 10;     // fine, 10 is a\nItem 15 \n| \n97\nwww.it-ebooks.info\n\n\n                                    // compile-time constant\nstd::array<int, arraySize2> data2;  // fine, arraySize2\n                                    // is constexpr\nNote that const doesn’t offer the same guarantee as constexpr, because const\nobjects need not be initialized with values known during compilation:\nint sz;                             // as before\n…\nconst auto arraySize = sz;          // fine, arraySize is\n                                    // const copy of sz\nstd::array<int, arraySize> data;    // error! arraySize's value\n                                    // not known at compilation\nSimply put, all constexpr objects are const, but not all const objects are con\nstexpr. If you want compilers to guarantee that a variable has a value that can be\nused in contexts requiring compile-time constants, the tool to reach for is con\nstexpr, not const.\nUsage scenarios for constexpr objects become more interesting when constexpr\nfunctions are involved. Such functions produce compile-time constants when they\nare called with compile-time constants. If they’re called with values not known until\nruntime, they produce runtime values. This may sound as if you don’t know what\nthey’ll do, but that’s the wrong way to think about it. The right way to view it is this:\n• constexpr functions can be used in contexts that demand compile-time con‐\nstants. If the values of the arguments you pass to a constexpr function in such a\ncontext are known during compilation, the result will be computed during\ncompilation. If any of the arguments’ values is not known during compilation,\nyour code will be rejected.\n• When a constexpr function is called with one or more values that are not\nknown during compilation, it acts like a normal function, computing its result at\nruntime. This means you don’t need two functions to perform the same opera‐\ntion, one for compile-time constants and one for all other values. The constexpr\nfunction does it all.\nSuppose we need a data structure to hold the results of an experiment that can be run\nin a variety of ways. For example, the lighting level can be high, low, or off during the\ncourse of the experiment, as can the fan speed and the temperature, etc. If there are n\nenvironmental conditions relevant to the experiment, each of which has three possi‐\n98 \n| \nItem 15\nwww.it-ebooks.info\n\n\nble states, the number of combinations is 3n. Storing experimental results for all com‐\nbinations of conditions thus requires a data structure with enough room for 3n values.\nAssuming each result is an int and that n is known (or can be computed) during\ncompilation, a std::array could be a reasonable data structure choice. But we’d\nneed a way to compute 3n during compilation. The C++ Standard Library provides\nstd::pow, which is the mathematical functionality we need, but, for our purposes,\nthere are two problems with it. First, std::pow works on floating-point types, and we\nneed an integral result. Second, std::pow isn’t constexpr (i.e., isn’t guaranteed to\nreturn a compile-time result when called with compile-time values), so we can’t use it\nto specify a std::array’s size.\nFortunately, we can write the pow we need. I’ll show how to do that in a moment, but\nfirst let’s look at how it could be declared and used:\nconstexpr                              // pow's a constexpr func\nint pow(int base, int exp) noexcept    // that never throws\n{\n  …                                    // impl is below\n}\nconstexpr auto numConds = 5;                 // # of conditions\nstd::array<int, pow(3, numConds)> results;   // results has\n                                             // 3^numConds\n                                             // elements\nRecall that the constexpr in front of pow doesn’t say that pow returns a const value,\nit says that if base and exp are compile-time constants, pow’s result may be used as a\ncompile-time constant. If base and/or exp are not compile-time constants, pow’s\nresult will be computed at runtime. That means that pow can not only be called to do\nthings like compile-time-compute the size of a std::array, it can also be called in\nruntime contexts such as this:\nauto base = readFromDB(\"base\");       // get these values\nauto exp = readFromDB(\"exponent\");    // at runtime\nauto baseToExp = pow(base, exp);      // call pow function\n                                      // at runtime\nBecause constexpr functions must be able to return compile-time results when\ncalled with compile-time values, restrictions are imposed on their implementations.\nThe restrictions differ between C++11 and C++14.\nIn C++11, constexpr functions may contain no more than a single executable state‐\nment: a return. That sounds more limiting than it is, because two tricks can be used\nItem 15 \n| \n99\nwww.it-ebooks.info\n\n\nto extend the expressiveness of constexpr functions beyond what you might think.\nFirst, the conditional “?:” operator can be used in place of if-else statements, and\nsecond, recursion can be used instead of loops. pow can therefore be implemented\nlike this:\nconstexpr int pow(int base, int exp) noexcept\n{\n  return (exp == 0 ? 1 : base * pow(base, exp - 1));\n}\nThis works, but it’s hard to imagine that anybody except a hard-core functional pro‐\ngrammer would consider it pretty. In C++14, the restrictions on constexpr func‐\ntions are substantially looser, so the following implementation becomes possible:\nconstexpr int pow(int base, int exp) noexcept       // C++14\n{\n  auto result = 1;\n  for (int i = 0; i < exp; ++i) result *= base;\n  return result;\n}\nconstexpr functions are limited to taking and returning literal types, which essen‐\ntially means types that can have values determined during compilation. In C++11, all\nbuilt-in types except void qualify, but user-defined types may be literal, too, because\nconstructors and other member functions may be constexpr:\nclass Point {\npublic:\n  constexpr Point(double xVal = 0, double yVal = 0) noexcept\n  : x(xVal), y(yVal)\n  {}\n  constexpr double xValue() const noexcept { return x; }\n  constexpr double yValue() const noexcept { return y; }\n  void setX(double newX) noexcept { x = newX; }\n  void setY(double newY) noexcept { y = newY; }\nprivate:\n  double x, y;\n};\nHere, the Point constructor can be declared constexpr, because if the arguments\npassed to it are known during compilation, the value of the data members of the con‐\n100 \n| \nItem 15\nwww.it-ebooks.info\n\n\n6 Because Point::xValue returns double, the type of mid.xValue() * 10 is also double. Floating-point types\ncan’t be used to instantiate templates or to specify enumerator values, but they can be used as part of larger\nexpressions that yield integral types. For example, static_cast<int>(mid.xValue() * 10) could be used to\ninstantiate a template or to specify an enumerator value.\nstructed Point can also be known during compilation. Points so initialized could\nthus be constexpr:\nconstexpr Point p1(9.4, 27.7);      // fine, \"runs\" constexpr\n                                    // ctor during compilation\nconstexpr Point p2(28.8, 5.3);      // also fine\nSimilarly, the getters xValue and yValue can be constexpr, because if they’re\ninvoked on a Point object with a value known during compilation (e.g., a constexpr\nPoint object), the values of the data members x and y can be known during compila‐\ntion. That makes it possible to write constexpr functions that call Point’s getters\nand to initialize constexpr objects with the results of such functions:\nconstexpr\nPoint midpoint(const Point& p1, const Point& p2) noexcept\n{\n  return { (p1.xValue() + p2.xValue()) / 2,    // call constexpr\n           (p1.yValue() + p2.yValue()) / 2 };  // member funcs\n}\nconstexpr auto mid = midpoint(p1, p2);     // init constexpr\n                                           // object w/result of\n                                           // constexpr function\nThis is very exciting. It means that the object mid, though its initialization involves\ncalls to constructors, getters, and a non-member function, can be created in read-\nonly memory! It means you could use an expression like mid.xValue() * 10 in an\nargument to a template or in an expression specifying the value of an enumerator!6 It\nmeans that the traditionally fairly strict line between work done during compilation\nand work done at runtime begins to blur, and some computations traditionally done\nat runtime can migrate to compile time. The more code taking part in the migration,\nthe faster your software will run. (Compilation may take longer, however.)\nIn C++11, two restrictions prevent Point’s member functions setX and setY from\nbeing declared constexpr. First, they modify the object they operate on, and in\nC++11, constexpr member functions are implicitly const. Second, they have void\nreturn types, and void isn’t a literal type in C++11. Both these restrictions are lifted\nin C++14, so in C++14, even Point’s setters can be constexpr:\nItem 15 \n| \n101\nwww.it-ebooks.info\n\n\nclass Point {\npublic:\n  …\n  constexpr void setX(double newX) noexcept     // C++14\n  { x = newX; }\n  constexpr void setY(double newY) noexcept     // C++14\n  { y = newY; }\n  …\n};\nThat makes it possible to write functions like this:\n// return reflection of p with respect to the origin (C++14)\nconstexpr Point reflection(const Point& p) noexcept\n{\n  Point result;                       // create non-const Point\n  result.setX(-p.xValue());           // set its x and y values\n  result.setY(-p.yValue());\n  return result;                      // return copy of it\n}\nClient code could look like this:\nconstexpr Point p1(9.4, 27.7);        // as above\nconstexpr Point p2(28.8, 5.3);\nconstexpr auto mid = midpoint(p1, p2);\nconstexpr auto reflectedMid =         // reflectedMid's value is\n  reflection(mid);                    // (-19.1 -16.5) and known\n                                      // during compilation\nThe advice of this Item is to use constexpr whenever possible, and by now I hope it’s\nclear why: both constexpr objects and constexpr functions can be employed in a\nwider range of contexts than non-constexpr objects and functions. By using con\nstexpr whenever possible, you maximize the range of situations in which your\nobjects and functions may be used.\nIt’s important to note that constexpr is part of an object’s or function’s interface.\nconstexpr proclaims “I can be used in a context where C++ requires a constant\nexpression.” If you declare an object or function constexpr, clients may use it in\n102 \n| \nItem 15\nwww.it-ebooks.info\n\n\nsuch contexts. If you later decide that your use of constexpr was a mistake and you\nremove it, you may cause arbitrarily large amounts of client code to stop compiling.\n(The simple act of adding I/O to a function for debugging or performance tuning\ncould lead to such a problem, because I/O statements are generally not permitted in\nconstexpr functions.) Part of “whenever possible” in “Use constexpr whenever\npossible” is your willingness to make a long-term commitment to the constraints it\nimposes on the objects and functions you apply it to.\nThings to Remember\n• constexpr objects are const and are initialized with values known during\ncompilation.\n• constexpr functions can produce compile-time results when called with\narguments whose values are known during compilation.\n• constexpr objects and functions may be used in a wider range of contexts\nthan non-constexpr objects and functions.\n• constexpr is part of an object’s or function’s interface.\nItem 16: Make const member functions thread safe.\nIf we’re working in a mathematical domain, we might find it convenient to have a\nclass representing polynomials. Within this class, it would probably be useful to have\na function to compute the root(s) of a polynomial, i.e., values where the polynomial\nevaluates to zero. Such a function would not modify the polynomial, so it’d be natural\nto  declare it const:\nclass Polynomial {\npublic:\n  using RootsType =          // data structure holding values\n    std::vector<double>;     // where polynomial evals to zero\n  …                          // (see Item 9 for info on \"using\")\n  RootsType roots() const;\n  …\n};\nComputing the roots of a polynomial can be expensive, so we don’t want to do it if\nwe don’t have to. And if we do have to do it, we certainly don’t want to do it more\nthan once. We’ll thus cache the root(s) of the polynomial if we have to compute\nItem 15 \n| \n103\nwww.it-ebooks.info\n\n\nthem, and we’ll implement roots to return the cached value. Here’s the basic\napproach:\nclass Polynomial {\npublic:\n  using RootsType = std::vector<double>;\n  RootsType roots() const\n  {\n    if (!rootsAreValid) {            // if cache not valid\n      …                              // compute roots,\n                                     // store them in rootVals\n      rootsAreValid = true;\n    }\n    return rootVals;\n  }\nprivate:\n  mutable bool rootsAreValid{ false };    // see Item 7 for info\n  mutable RootsType rootVals{};           // on initializers\n};\nConceptually, roots doesn’t change the Polynomial object on which it operates, but,\nas part of its caching activity, it may need to modify rootVals and rootsAreValid.\nThat’s a classic use case for mutable, and that’s why it’s part of the declarations for\nthese data members.\nImagine now that two threads simultaneously call roots on a Polynomial object:\nPolynomial p;\n…\n/*-----  Thread 1  ----- */     /*-------  Thread 2  ------- */\nauto rootsOfP = p.roots();      auto valsGivingZero = p.roots();\nThis client code is perfectly reasonable. roots is a const member function, and that\nmeans it represents a read operation. Having multiple threads perform a read opera‐\ntion without synchronization is safe. At least it’s supposed to be. In this case, it’s not,\nbecause inside roots, one or both of these threads might try to modify the data\nmembers rootsAreValid and rootVals. That means that this code could have dif‐\n104 \n| \nItem 16\nwww.it-ebooks.info\n\n\nferent threads reading and writing the same memory without synchronization, and\nthat’s the definition of a data race. This code has undefined behavior.\nThe problem is that roots is declared const, but it’s not thread safe. The const dec‐\nlaration is as correct in C++11 as it would be in C++98 (retrieving the roots of a poly‐\nnomial doesn’t change the value of the polynomial), so what requires rectification is\nthe lack of thread safety.\nThe easiest way to address the issue is the usual one: employ a mutex:\nclass Polynomial {\npublic:\n  using RootsType = std::vector<double>;\n  RootsType roots() const\n  {\n    std::lock_guard<std::mutex> g(m);     // lock mutex\n    if (!rootsAreValid) {                 // if cache not valid\n      …                                   // compute/store roots\n      rootsAreValid = true;\n    }\n    return rootVals;\n  }                                       // unlock mutex\nprivate:\n  mutable std::mutex m;\n  mutable bool rootsAreValid{ false };\n  mutable RootsType rootVals{};\n};\nThe std::mutex m is declared mutable, because locking and unlocking it are non-\nconst member functions, and within roots (a const member function), m would\notherwise be considered a const object.\nIt’s worth noting that because std::mutex is a move-only type (i.e., a type that can be\nmoved, but not copied), a side effect of adding m to Polynomial is that Polynomial\nloses the ability to be copied. It can still be moved, however.\nIn some situations, a mutex is overkill. For example, if all you’re doing is counting\nhow many times a member function is called, a std::atomic counter (i.e, one where\nother threads are guaranteed to see its operations occur indivisibly—see Item 40) will\noften be a less expensive way to go. (Whether it actually is less expensive depends on\nItem 16 \n| \n105\nwww.it-ebooks.info\n",
      "page_number": 113,
      "chapter_number": 11,
      "summary": "This chapter covers segment 11 (pages 113-123). Key topics include functions, function, and functionality. Covers function. The\nresult of the cast is undefined, so there are no behavioral guarantees for the program containing the cast.",
      "keywords": [
        "constexpr",
        "functions",
        "constexpr functions",
        "point",
        "constexpr Point",
        "function",
        "const",
        "compilation",
        "noexcept",
        "Item",
        "std",
        "constexpr objects",
        "n’t",
        "polynomial",
        "objects"
      ],
      "concepts": [
        "functions",
        "function",
        "functionality",
        "compilers",
        "compile",
        "value",
        "std",
        "point",
        "result",
        "returns"
      ],
      "similar_chapters": [
        {
          "book": "C++ Concurrency in Action",
          "chapter": 39,
          "title": "Segment 39 (pages 382-396)",
          "relevance_score": 0.7,
          "method": "sentence_transformers"
        },
        {
          "book": "C++ Templates_ The Complete Guide",
          "chapter": 64,
          "title": "Segment 64 (pages 2050-2080)",
          "relevance_score": 0.68,
          "method": "sentence_transformers"
        },
        {
          "book": "More Effective C++",
          "chapter": 12,
          "title": "Segment 12 (pages 116-123)",
          "relevance_score": 0.67,
          "method": "sentence_transformers"
        },
        {
          "book": "C++ Templates_ The Complete Guide",
          "chapter": 79,
          "title": "Segment 79 (pages 2535-2565)",
          "relevance_score": 0.64,
          "method": "sentence_transformers"
        },
        {
          "book": "C++ Templates_ The Complete Guide",
          "chapter": 27,
          "title": "Segment 27 (pages 850-883)",
          "relevance_score": 0.63,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 12,
      "title": "Segment 12 (pages 124-133)",
      "start_page": 124,
      "end_page": 133,
      "detection_method": "topic_boundary",
      "content": "the hardware you’re running on and the implementation of mutexes in your Stan‐\ndard Library.) Here’s how you can employ a std::atomic to count calls:\nclass Point {                                // 2D point\npublic:\n  …\n  double distanceFromOrigin() const noexcept     // see Item 14\n  {                                              // for noexcept\n    ++callCount;                             // atomic increment\n    return std::sqrt((x * x) + (y * y));\n  }\nprivate:\n  mutable std::atomic<unsigned> callCount{ 0 };\n  double x, y;\n};\nLike std::mutexes, std::atomics are move-only types, so the existence of call\nCount in Point means that Point is also move-only.\nBecause operations on std::atomic variables are often less expensive than mutex\nacquisition and release, you may be tempted to lean on std::atomics more heavily\nthan you should. For example, in a class caching an expensive-to-compute int, you\nmight try to use a pair of std::atomic variables instead of a mutex:\nclass Widget {\npublic:\n  …\n  int magicValue() const\n  {\n    if (cacheValid) return cachedValue;\n    else {\n      auto val1 = expensiveComputation1();\n      auto val2 = expensiveComputation2();\n      cachedValue = val1 + val2;               // uh oh, part 1\n      cacheValid = true;                       // uh oh, part 2\n      return cachedValue;\n    }\n  }\nprivate:\n106 \n| \nItem 16\nwww.it-ebooks.info\n\n\n  mutable std::atomic<bool> cacheValid{ false };\n  mutable std::atomic<int> cachedValue;\n};\nThis will work, but sometimes it will work a lot harder than it should. Consider:\n• A thread calls Widget::magicValue, sees cacheValid as false, performs the\ntwo expensive computations, and assigns their sum to cachedValue.\n• At that point, a second thread calls Widget::magicValue, also sees cacheValid\nas false, and thus carries out the same expensive computations that the first\nthread has just finished. (This “second thread” may in fact be several other\nthreads.)\nSuch behavior is contrary to the goal of caching. Reversing the order of the assign‐\nments to cachedValue and CacheValid eliminates that problem, but the result is\neven worse:\nclass Widget {\npublic:\n  …\n  int magicValue() const\n  {\n    if (cacheValid) return cachedValue;\n    else {\n      auto val1 = expensiveComputation1();\n      auto val2 = expensiveComputation2();\n      cacheValid = true;                        // uh oh, part 1\n      return cachedValue = val1 + val2;         // uh oh, part 2\n    }\n  }\n  …\n};\nImagine that cacheValid is false, and then:\n• One thread calls Widget::magicValue and executes through the point where\ncacheValid is set to true.\n• At that moment, a second thread calls Widget::magicValue and checks cache\nValid. Seeing it true, the thread returns cachedValue, even though the first\nItem 16 \n| \n107\nwww.it-ebooks.info\n\n\nthread has not yet made an assignment to it. The returned value is therefore\nincorrect.\nThere’s a lesson here. For a single variable or memory location requiring synchroni‐\nzation, use of a std::atomic is adequate, but once you get to two or more variables\nor memory locations that require manipulation as a unit, you should reach for a\nmutex. For Widget::magicValue, that would look like this:\nclass Widget {\npublic:\n  …\n  int magicValue() const\n  {\n    std::lock_guard<std::mutex> guard(m);   // lock m\n    if (cacheValid) return cachedValue;\n    else {\n      auto val1 = expensiveComputation1();\n      auto val2 = expensiveComputation2();\n      cachedValue = val1 + val2;\n      cacheValid = true;\n      return cachedValue;\n    }\n  }                                         // unlock m\n  …\nprivate:\n  mutable std::mutex m;\n  mutable int cachedValue;                  // no longer atomic\n  mutable bool cacheValid{ false };         // no longer atomic\n};\nNow, this Item is predicated on the assumption that multiple threads may simultane‐\nously execute a const member function on an object. If you’re writing a const mem‐\nber function where that’s not the case—where you can guarantee that there will never\nbe more than one thread executing that member function on an object—the thread\nsafety of the function is immaterial. For example, it’s unimportant whether member\nfunctions of classes designed for exclusively single-threaded use are thread safe. In\nsuch cases, you can avoid the costs associated with mutexes and std::atomics, as\nwell as the side effect of their rendering the classes containing them move-only. How‐\never, such threading-free scenarios are increasingly uncommon, and they’re likely to\nbecome rarer still. The safe bet is that const member functions will be subject to con‐\n108 \n| \nItem 16\nwww.it-ebooks.info\n\n\ncurrent execution, and that’s why you should ensure that your const member func‐\ntions are thread safe.\n \nThings to Remember\n• Make const member functions thread safe unless you’re certain they’ll never\nbe used in a concurrent context.\n• Use of std::atomic variables may offer better performance than a mutex, but\nthey’re suited for manipulation of only a single variable or memory location.\nItem 17: Understand special member function\ngeneration.\nIn official C++ parlance, the special member functions are the ones that C++ is willing\nto generate on its own. C++98 has four such functions: the default constructor, the\ndestructor, the copy constructor, and the copy assignment operator. There’s fine\nprint, of course. These functions are generated only if they’re needed, i.e., if some\ncode uses them without their being expressly declared in the class. A default con‐\nstructor is generated only if the class declares no constructors at all. (This prevents\ncompilers from creating a default constructor for a class where you’ve specified that\nconstructor arguments are required.) Generated special member functions are\nimplicitly public and inline, and they’re nonvirtual unless the function in question\nis a destructor in a derived class inheriting from a base class with a virtual destructor.\nIn that case, the compiler-generated destructor for the derived class is also virtual.\nBut you already know these things. Yes, yes, ancient history: Mesopotamia, the Shang\ndynasty, FORTRAN, C++98. But times have changed, and the rules for special mem‐\nber function generation in C++ have changed with them. It’s important to be aware\nof the new rules, because few things are as central to effective C++ programming as\nknowing when compilers silently insert member functions into your classes.\nAs of C++11, the special member functions club has two more inductees: the move\nconstructor and the move assignment operator. Their signatures are:\nclass Widget {\npublic:\n  …\n  Widget(Widget&& rhs);              // move constructor\n  Widget& operator=(Widget&& rhs);   // move assignment operator\n  …\n};\nItem 16 \n| \n109\nwww.it-ebooks.info\n\n\nThe rules governing their generation and behavior are analogous to those for their\ncopying siblings. The move operations are generated only if they’re needed, and if\nthey are generated, they perform “memberwise moves” on the non-static data mem‐\nbers of the class. That means that the move constructor move-constructs each non-\nstatic data member of the class from the corresponding member of its parameter rhs,\nand the move assignment operator move-assigns each non-static data member from\nits parameter. The move constructor also move-constructs its base class parts (if there\nare any), and the move assignment operator move-assigns its base class parts.\nNow, when I refer to a move operation move-constructing or move-assigning a data\nmember or base class, there is no guarantee that a move will actually take place.\n“Memberwise moves” are, in reality, more like memberwise move requests, because\ntypes that aren’t move-enabled (i.e., that offer no special support for move operations,\ne.g., most C++98 legacy classes) will be “moved” via their copy operations. The heart\nof each memberwise “move” is application of std::move to the object to be moved\nfrom, and the result is used during function overload resolution to determine\nwhether a move or a copy should be performed. Item 23 covers this process in detail.\nFor this Item, simply remember that a memberwise move consists of move opera‐\ntions on data members and base classes that support move operations, but a copy\noperation for those that don’t.\nAs is the case with the copy operations, the move operations aren’t generated if you\ndeclare them yourself. However, the precise conditions under which they are gener‐\nated differ a bit from those for the copy operations.\nThe two copy operations are independent: declaring one doesn’t prevent compilers\nfrom generating the other. So if you declare a copy constructor, but no copy assign‐\nment operator, then write code that requires copy assignment, compilers will gener‐\nate the copy assignment operator for you. Similarly, if you declare a copy assignment\noperator, but no copy constructor, yet your code requires copy construction, compil‐\ners will generate the copy constructor for you. That was true in C++98, and it’s still\ntrue in C++11.\nThe two move operations are not independent. If you declare either, that prevents\ncompilers from generating the other. The rationale is that if you declare, say, a move\nconstructor for your class, you’re indicating that there’s something about how move\nconstruction should be implemented that’s different from the default memberwise\nmove that compilers would generate. And if there’s something wrong with member‐\nwise move construction, there’d probably be something wrong with memberwise\nmove assignment, too. So declaring a move constructor prevents a move assignment\noperator from being generated, and declaring a move assignment operator prevents\ncompilers from generating a move constructor.\nFurthermore, move operations won’t be generated for any class that explicitly\ndeclares a copy operation. The justification is that declaring a copy operation (con‐\n110 \n| \nItem 17\nwww.it-ebooks.info\n\n\nstruction or assignment) indicates that the normal approach to copying an object\n(memberwise copy) isn’t appropriate for the class, and compilers figure that if mem‐\nberwise copy isn’t appropriate for the copy operations, memberwise move probably\nisn’t appropriate for the move operations.\nThis goes in the other direction, too. Declaring a move operation (construction or\nassignment) in a class causes compilers to disable the copy operations. (The copy\noperations are disabled by deleting them—see Item 11). After all, if memberwise\nmove isn’t the proper way to move an object, there’s no reason to expect that mem‐\nberwise copy is the proper way to copy it. This may sound like it could break C++98\ncode, because the conditions under which the copy operations are enabled are more\nconstrained in C++11 than in C++98, but this is not the case. C++98 code can’t have\nmove operations, because there was no such thing as “moving” objects in C++98. The\nonly way a legacy class can have user-declared move operations is if they were added\nfor C++11, and classes that are modified to take advantage of move semantics have to\nplay by the C++11 rules for special member function generation.\nPerhaps you’ve heard of a guideline known as the Rule of Three. The Rule of Three\nstates that if you declare any of a copy constructor, copy assignment operator, or\ndestructor, you should declare all three. It grew out of the observation that the need\nto take over the meaning of a copy operation almost always stemmed from the class\nperforming some kind of resource management, and that almost always implied that\n(1) whatever resource management was being done in one copy operation probably\nneeded to be done in the other copy operation and (2) the class destructor would also\nbe participating in management of the resource (usually releasing it). The classic\nresource to be managed was memory, and this is why all Standard Library classes that\nmanage memory (e.g., the STL containers that perform dynamic memory manage‐\nment) all declare “the big three”: both copy operations and a destructor. \nA consequence of the Rule of Three is that the presence of a user-declared destructor\nindicates that simple memberwise copy is unlikely to be appropriate for the copying\noperations in the class. That, in turn, suggests that if a class declares a destructor, the\ncopy operations probably shouldn’t be automatically generated, because they\nwouldn’t do the right thing. At the time C++98 was adopted, the significance of this\nline of reasoning was not fully appreciated, so in C++98, the existence of a user-\ndeclared destructor had no impact on compilers’ willingness to generate copy opera‐\ntions. That continues to be the case in C++11, but only because restricting the\nconditions under which the copy operations are generated would break too much\nlegacy code.\nThe reasoning behind the Rule of Three remains valid, however, and that, combined\nwith the observation that declaration of a copy operation precludes the implicit gen‐\neration of the move operations, motivates the fact that C++11 does not generate\nmove operations for a class with a user-declared destructor.\nItem 17 \n| \n111\nwww.it-ebooks.info\n\n\nSo move operations are generated for classes (when needed) only if these three things\nare true:\n• No copy operations are declared in the class.\n• No move operations are declared in the class.\n• No destructor is declared in the class.\nAt some point, analogous rules may be extended to the copy operations, because\nC++11 deprecates the automatic generation of copy operations for classes declaring\ncopy operations or a destructor. This means that if you have code that depends on\nthe generation of copy operations in classes declaring a destructor or one of the copy\noperations, you should consider upgrading these classes to eliminate the dependence.\nProvided the behavior of the compiler-generated functions is correct (i.e, if member‐\nwise copying of the class’s non-static data members is what you want), your job is\neasy, because C++11’s “= default” lets you say that explicitly:\nclass Widget {\npublic:\n  …\n  ~Widget();                             // user-declared dtor\n  …                                      // default copy ctor\n  Widget(const Widget&) = default;       // behavior is OK\n  Widget&                                // default copy assign\n    operator=(const Widget&) = default;  // behavior is OK\n  …\n};\nThis approach is often useful in polymorphic base classes, i.e., classes defining inter‐\nfaces through which derived class objects are manipulated. Polymorphic base classes\nnormally have virtual destructors, because if they don’t, some operations (e.g., the use\nof delete or typeid on a derived class object through a base class pointer or refer‐\nence) yield undefined or misleading results. Unless a class inherits a destructor that’s\nalready virtual, the only way to make a destructor virtual is to explicitly declare it that\nway. Often, the default implementation would be correct, and “= default” is a good\nway to express that. However, a user-declared destructor suppresses generation of the\nmove operations, so if movability is to be supported, “= default” often finds a sec‐\nond application. Declaring the move operations disables the copy operations, so if\ncopyability is also desired, one more round of “= default” does the job:\nclass Base {\npublic:\n  virtual ~Base() = default;                // make dtor virtual\n112 \n| \nItem 17\nwww.it-ebooks.info\n\n\n  Base(Base&&) = default;                   // support moving\n  Base& operator=(Base&&) = default;\n  Base(const Base&) = default;              // support copying\n  Base& operator=(const Base&) = default;\n  …\n};\nIn fact, even if you have a class where compilers are willing to generate the copy and\nmove operations and where the generated functions would behave as you want, you\nmay choose to adopt a policy of declaring them yourself and using “= default” for\ntheir definitions. It’s more work, but it makes your intentions clearer, and it can help\nyou sidestep some fairly subtle bugs. For example, suppose you have a class repre‐\nsenting a string table, i.e., a data structure that permits fast lookups of string values\nvia an integer ID:\nclass StringTable {\npublic:\n  StringTable() {}\n  …                 // functions for insertion, erasure, lookup,\n                    // etc., but no copy/move/dtor functionality\nprivate:\n  std::map<int, std::string> values;\n};\nAssuming that the class declares no copy operations, no move operations, and no\ndestructor, compilers will automatically generate these functions if they are used.\nThat’s very convenient.\nBut suppose that sometime later, it’s decided that logging the default construction\nand the destruction of such objects would be useful. Adding that functionality is easy:\nclass StringTable {\npublic:\n  StringTable()\n  { makeLogEntry(\"Creating StringTable object\"); }     // added\n  \n  ~StringTable()                                       // also\n  { makeLogEntry(\"Destroying StringTable object\"); }   // added\n  …                                     // other funcs as before\nItem 17 \n| \n113\nwww.it-ebooks.info\n\n\nprivate:\n  std::map<int, std::string> values;    // as before\n};\nThis looks reasonable, but declaring a destructor has a potentially significant side\neffect: it prevents the move operations from being generated. However, creation of\nthe class’s copy operations is unaffected. The code is therefore likely to compile, run,\nand pass its functional testing. That includes testing its move functionality, because\neven though this class is no longer move-enabled, requests to move it will compile\nand run. Such requests will, as noted earlier in this Item, cause copies to be made.\nWhich means that code “moving” StringTable objects actually copies them,\ni.e., copies the underlying std::map<int, std::string> objects. And copying a std\n::map<int, std::string> is likely to be orders of magnitude slower than moving it.\nThe simple act of adding a destructor to the class could thereby have introduced a\nsignificant performance problem! Had the copy and move operations been explicitly\ndefined using “= default”, the problem would not have arisen.\nNow, having endured my endless blathering about the rules governing the copy and\nmove operations in C++11, you may wonder when I’ll turn my attention to the two\nother special member functions, the default constructor and the destructor. That\ntime is now, but only for this sentence, because almost nothing has changed for these\nmember functions: the rules in C++11 are nearly the same as in C++98.\nThe C++11 rules governing the special member functions are thus:\n• Default constructor: Same rules as C++98. Generated only if the class contains\nno user-declared constructors.\n• Destructor: Essentially same rules as C++98; sole difference is that destructors\nare noexcept by default (see Item 14). As in C++98, virtual only if a base class\ndestructor is virtual.\n• Copy constructor: Same runtime behavior as C++98: memberwise copy con‐\nstruction of non-static data members. Generated only if the class lacks a user-\ndeclared copy constructor. Deleted if the class declares a move operation.\nGeneration of this function in a class with a user-declared copy assignment oper‐\nator or destructor is deprecated.\n• Copy assignment operator: Same runtime behavior as C++98: memberwise\ncopy assignment of non-static data members. Generated only if the class lacks a\nuser-declared copy assignment operator. Deleted if the class declares a move\noperation. Generation of this function in a class with a user-declared copy con‐\nstructor or destructor is deprecated.\n114 \n| \nItem 17\nwww.it-ebooks.info\n\n\n• Move constructor and move assignment operator: Each performs memberwise\nmoving of non-static data members. Generated only if the class contains no user-\ndeclared copy operations, move operations, or destructor.\nNote that there’s nothing in the rules about the existence of a member function tem‐\nplate preventing compilers from generating the special member functions. That\nmeans that if Widget looks like this,\nclass Widget {\n  …\n  template<typename T>                // construct Widget\n  Widget(const T& rhs);               // from anything\n  template<typename T>                // assign Widget\n  Widget& operator=(const T& rhs);    // from anything\n  …\n};\ncompilers will still generate copy and move operations for Widget (assuming the\nusual conditions governing their generation are fulfilled), even though these tem‐\nplates could be instantiated to produce the signatures for the copy constructor and\ncopy assignment operator. (That would be the case when T is Widget.) In all likeli‐\nhood, this will strike you as an edge case barely worth acknowledging, but there’s a\nreason I’m mentioning it. Item 26 demonstrates that it can have important conse‐\nquences.\nThings to Remember\n• The special member functions are those compilers may generate on their own:\ndefault constructor, destructor, copy operations, and move operations.\n• Move operations are generated only for classes lacking explicitly declared\nmove operations, copy operations, and a destructor.\n• The copy constructor is generated only for classes lacking an explicitly\ndeclared copy constructor, and it’s deleted if a move operation is declared.\nThe copy assignment operator is generated only for classes lacking an explic‐\nitly declared copy assignment operator, and it’s deleted if a move operation is\ndeclared. Generation of the copy operations in classes with an explicitly\ndeclared destructor is deprecated.\n• Member function templates never suppress generation of special member\nfunctions.\nItem 17 \n| \n115\nwww.it-ebooks.info\n",
      "page_number": 124,
      "chapter_number": 12,
      "summary": "This chapter covers segment 12 (pages 124-133). Key topics include classes, copy, and copies. Because operations on std::atomic variables are often less expensive than mutex\nacquisition and release, you may be tempted to lean on std::atomics more heavily\nthan you should.",
      "keywords": [
        "copy operations",
        "move operations",
        "copy",
        "move",
        "operations",
        "copy assignment operator",
        "Widget",
        "copy assignment",
        "move assignment operator",
        "class Widget",
        "copy constructor",
        "member functions",
        "member",
        "destructor",
        "move assignment"
      ],
      "concepts": [
        "classes",
        "copy",
        "copies",
        "operations",
        "operator",
        "operation",
        "widget",
        "thread",
        "declared",
        "declares"
      ],
      "similar_chapters": [
        {
          "book": "C++ Concurrency in Action",
          "chapter": 6,
          "title": "Segment 6 (pages 50-58)",
          "relevance_score": 0.65,
          "method": "sentence_transformers"
        },
        {
          "book": "C++ Concurrency in Action",
          "chapter": 19,
          "title": "Segment 19 (pages 176-183)",
          "relevance_score": 0.62,
          "method": "sentence_transformers"
        },
        {
          "book": "C++ Concurrency in Action",
          "chapter": 47,
          "title": "Segment 47 (pages 513-528)",
          "relevance_score": 0.62,
          "method": "sentence_transformers"
        },
        {
          "book": "operating_systems_three_easy_pieces",
          "chapter": 32,
          "title": "Segment 32 (pages 310-319)",
          "relevance_score": 0.62,
          "method": "sentence_transformers"
        },
        {
          "book": "C++ Concurrency in Action",
          "chapter": 8,
          "title": "Segment 8 (pages 67-78)",
          "relevance_score": 0.61,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 13,
      "title": "Segment 13 (pages 134-141)",
      "start_page": 134,
      "end_page": 141,
      "detection_method": "topic_boundary",
      "content": "www.it-ebooks.info\n\n\nCHAPTER 4\nSmart Pointers\nPoets and songwriters have a thing about love. And sometimes about counting. Occa‐\nsionally both. Inspired by the rather different takes on love and counting by Elizabeth\nBarrett Browning (“How do I love thee? Let me count the ways.”) and Paul Simon\n(“There must be 50 ways to leave your lover.”), we might try to enumerate the rea‐\nsons why a raw pointer is hard to love:\n1. Its declaration doesn’t indicate whether it points to a single object or to an array.\n2. Its declaration reveals nothing about whether you should destroy what it points\nto when you’re done using it, i.e., if the pointer owns the thing it points to.\n3. If you determine that you should destroy what the pointer points to, there’s no\nway to tell how. Should you use delete, or is there a different destruction mech‐\nanism (e.g., a dedicated destruction function the pointer should be passed to)?\n4. If you manage to find out that delete is the way to go, Reason 1 means it may\nnot be possible to know whether to use the single-object form (“delete”) or the\narray form (“delete []”). If you use the wrong form, results are undefined.\n5. Assuming you ascertain that the pointer owns what it points to and you discover\nhow to destroy it, it’s difficult to ensure that you perform the destruction exactly\nonce along every path in your code (including those due to exceptions). Missing a\npath leads to resource leaks, and doing the destruction more than once leads to\nundefined behavior.\n6. There’s typically no way to tell if the pointer dangles, i.e., points to memory that\nno longer holds the object the pointer is supposed to point to. Dangling pointers\narise when objects are destroyed while pointers still point to them.\n117\nwww.it-ebooks.info\n\n\nRaw pointers are powerful tools, to be sure, but decades of experience have demon‐\nstrated that with only the slightest lapse in concentration or discipline, these tools can\nturn on their ostensible masters.\nSmart pointers are one way to address these issues. Smart pointers are wrappers\naround raw pointers that act much like the raw pointers they wrap, but that avoid\nmany of their pitfalls. You should therefore prefer smart pointers to raw pointers.\nSmart pointers can do virtually everything raw pointers can, but with far fewer\nopportunities for error.\nThere are four smart pointers in C++11: std::auto_ptr, std::unique_ptr,\nstd::shared_ptr, and std::weak_ptr. All are designed to help manage the life‐\ntimes of dynamically allocated objects, i.e., to avoid resource leaks by ensuring that\nsuch objects are destroyed in the appropriate manner at the appropriate time (includ‐\ning in the event of exceptions).\nstd::auto_ptr is a deprecated leftover from C++98. It was an attempt to standard‐\nize what later became C++11’s std::unique_ptr. Doing the job right required move\nsemantics, but C++98 didn’t have them. As a workaround, std::auto_ptr co-opted\nits copy operations for moves. This led to surprising code (copying a std::auto_ptr\nsets it to null!) and frustrating usage restrictions (e.g., it’s not possible to store\nstd::auto_ptrs in containers).\nstd::unique_ptr does everything std::auto_ptr does, plus more. It does it as effi‐\nciently, and it does it without warping what it means to copy an object. It’s better\nthan std::auto_ptr in every way. The only legitimate use case for std::auto_ptr\nis a need to compile code with C++98 compilers. Unless you have that constraint,\nyou should replace std::auto_ptr with std::unique_ptr and never look back.\nThe smart pointer APIs are remarkably varied. About the only functionality common\nto all is default construction. Because comprehensive references for these APIs are\nwidely available, I’ll focus my discussions on information that’s often missing from\nAPI overviews, e.g., noteworthy use cases, runtime cost analyses, etc. Mastering such\ninformation can be the difference between merely using these smart pointers and\nusing them effectively.\nItem 18: Use std::unique_ptr for exclusive-ownership\nresource management.\nWhen you reach for a smart pointer, std::unique_ptr should generally be the one\nclosest at hand. It’s reasonable to assume that, by default, std::unique_ptrs are the\nsame size as raw pointers, and for most operations (including dereferencing), they\nexecute exactly the same instructions. This means you can use them even in situa‐\n118 \n| \nItem 17\nwww.it-ebooks.info\n\n\nclass Investment { … };\nclass Stock:\n  public Investment { … };\nclass Bond:\n  public Investment { … };\nclass RealEstate:\n  public Investment { … };\nInvestment\nBond\nStock\nRealEstate\ntions where memory and cycles are tight. If a raw pointer is small enough and fast\nenough for you, a std::unique_ptr almost certainly is, too.\nstd::unique_ptr embodies exclusive ownership semantics. A non-null std::\nunique_ptr always owns what it points to. Moving a std::unique_ptr transfers\nownership from the source pointer to the destination pointer. (The source pointer is\nset to null.) Copying a std::unique_ptr isn’t allowed, because if you could copy a\nstd::unique_ptr, you’d end up with two std::unique_ptrs to the same resource,\neach thinking it owned (and should therefore destroy) that resource.\nstd::unique_ptr is thus a move-only type. Upon destruction, a non-null\nstd::unique_ptr destroys its resource. By default, resource destruction is accom‐\nplished by applying delete to the raw pointer inside the std::unique_ptr.\nA common use for std::unique_ptr is as a factory function return type for objects\nin a hierarchy. Suppose we have a hierarchy for types of investments (e.g., stocks,\nbonds, real estate, etc.) with a base class Investment.\nA factory function for such a hierarchy typically allocates an object on the heap and\nreturns a pointer to it, with the caller being responsible for deleting the object when\nit’s no longer needed. That’s a perfect match for std::unique_ptr, because the\ncaller acquires responsibility for the resource returned by the factory (i.e., exclusive\nownership of it), and the std::unique_ptr automatically deletes what it points to\nwhen the std::unique_ptr is destroyed. A factory function for the Investment\nhierarchy could be declared like this:\ntemplate<typename... Ts>              // return std::unique_ptr\nstd::unique_ptr<Investment>           // to an object created\nmakeInvestment(Ts&&... params);       // from the given args\nCallers could use the returned std::unique_ptr in a single scope as follows,\n{\n  …\nItem 18 \n| \n119\nwww.it-ebooks.info\n\n\n1 There are a few exceptions to this rule. Most stem from abnormal program termination. If an exception prop‐\nagates out of a thread’s primary function (e.g., main, for the program’s initial thread) or if a noexcept specifi‐\ncation is violated (see Item 14), local objects may not be destroyed, and if std::abort or an exit function\n(i.e., std::_Exit, std::exit, or std::quick_exit) is called, they definitely won’t be.\n  auto pInvestment =              // pInvestment is of type\n    makeInvestment( arguments );  // std::unique_ptr<Investment>\n  …\n}                                 // destroy *pInvestment\nbut they could also use it in ownership-migration scenarios, such as when the\nstd::unique_ptr returned from the factory is moved into a container, the container\nelement is subsequently moved into a data member of an object, and that object is\nlater destroyed. When that happens, the object’s std::unique_ptr data member\nwould also be destroyed, and its destruction would cause the resource returned from\nthe factory to be destroyed. If the ownership chain got interrupted due to an excep‐\ntion or other atypical control flow (e.g., early function return or break from a loop),\nthe std::unique_ptr owning the managed resource would eventually have its\ndestructor called,1 and the resource it was managing would thereby be destroyed.\nBy default, that destruction would take place via delete, but, during construction,\nstd::unique_ptr objects can be configured to use custom deleters: arbitrary func‐\ntions (or function objects, including those arising from lambda expressions) to be\ninvoked when it’s time for their resources to be destroyed. If the object created by\nmakeInvestment shouldn’t be directly deleted, but instead should first have a log\nentry written, makeInvestment could be implemented as follows. (An explanation\nfollows the code, so don’t worry if you see something whose motivation is less than\nobvious.)\nauto delInvmt = [](Investment* pInvestment)       // custom\n                {                                 // deleter\n                  makeLogEntry(pInvestment);      // (a lambda\n                  delete pInvestment;             // expression)\n                };\ntemplate<typename... Ts>                          // revised\nstd::unique_ptr<Investment, decltype(delInvmt)>   // return type\nmakeInvestment(Ts&&... params)\n{\n  std::unique_ptr<Investment, decltype(delInvmt)> // ptr to be\n    pInv(nullptr, delInvmt);                      // returned\n120 \n| \nItem 18\nwww.it-ebooks.info\n\n\n  if ( /* a Stock object should be created */ )\n  {\n    pInv.reset(new Stock(std::forward<Ts>(params)...));\n  }\n  else if ( /* a Bond object should be created */ )\n  {\n    pInv.reset(new Bond(std::forward<Ts>(params)...));\n  }\n  else if ( /* a RealEstate object should be created */ )\n  {\n    pInv.reset(new RealEstate(std::forward<Ts>(params)...));\n  }\n  return pInv;\n}\nIn a moment, I’ll explain how this works, but first consider how things look if you’re\na caller. Assuming you store the result of the makeInvestment call in an auto vari‐\nable, you frolic in blissful ignorance of the fact that the resource you’re using requires\nspecial treatment during deletion. In fact, you veritably bathe in bliss, because the use\nof std::unique_ptr means you need not concern yourself with when the resource\nshould be destroyed, much less ensure that the destruction happens exactly once\nalong every path through the program. std::unique_ptr takes care of all those\nthings automatically. From a client’s perspective, makeInvestment’s interface is\nsweet.\nThe implementation is pretty nice, too, once you understand the following:\n• delInvmt is the custom deleter for the object returned from makeInvestment.\nAll custom deletion functions accept a raw pointer to the object to be destroyed,\nthen do what is necessary to destroy that object. In this case, the action is to call\nmakeLogEntry and then apply delete. Using a lambda expression to create\ndelInvmt is convenient, but, as we’ll see shortly, it’s also more efficient than\nwriting a conventional function.\n• When a custom deleter is to be used, its type must be specified as the second type\nargument to std::unique_ptr. In this case, that’s the type of delInvmt, and\nthat’s why the return type of makeInvestment is std::unique_ptr<Invest\nment, decltype(delInvmt)>. (For information about decltype, see Item 3.)\n• The basic strategy of makeInvestment is to create a null std::unique_ptr,\nmake it point to an object of the appropriate type, and then return it. To asso‐\nciate the custom deleter delInvmt with pInv, we pass that as its second construc‐\ntor argument.\nItem 18 \n| \n121\nwww.it-ebooks.info\n\n\n• Attempting to assign a raw pointer (e.g., from new) to a std::unique_ptr won’t\ncompile, because it would constitute an implicit conversion from a raw to a\nsmart pointer. Such implicit conversions can be problematic, so C++11’s smart\npointers prohibit them. That’s why reset is used to have pInv assume owner‐\nship of the object created via new.\n• With each use of new, we use std::forward to perfect-forward the arguments\npassed to makeInvestment (see Item 25). This makes all the information pro‐\nvided by callers available to the constructors of the objects being created.\n• The custom deleter takes a parameter of type Investment*. Regardless of the\nactual type of object created inside makeInvestment (i.e., Stock, Bond, or Real\nEstate), it will ultimately be deleted inside the lambda expression as an Invest\nment* object. This means we’ll be deleting a derived class object via a base class\npointer. For that to work, the base class—Investment—must have a virtual \ndestructor:\nclass Investment {\npublic:\n  …                                             // essential\n  virtual ~Investment();                        // design\n  …                                             // component!\n};\nIn C++14, the existence of function return type deduction (see Item 3) means that\nmakeInvestment could be implemented in this simpler and more encapsulated fash‐\nion:\ntemplate<typename... Ts>\nauto makeInvestment(Ts&&... params)              // C++14\n{\n  auto delInvmt = [](Investment* pInvestment)    // this is now\n                  {                              // inside\n                    makeLogEntry(pInvestment);   // make-\n                    delete pInvestment;          // Investment\n                  };\n  std::unique_ptr<Investment, decltype(delInvmt)>   // as\n    pInv(nullptr, delInvmt);                        // before\n  if ( … )                                          // as before\n  {\n    pInv.reset(new Stock(std::forward<Ts>(params)...));\n  }\n  else if ( … )                                     // as before\n122 \n| \nItem 18\nwww.it-ebooks.info\n\n\n  {\n    pInv.reset(new Bond(std::forward<Ts>(params)...));\n  }\n  else if ( … )                                     // as before\n  {\n    pInv.reset(new RealEstate(std::forward<Ts>(params)...));\n  }\n  return pInv;                                      // as before\n}\nI remarked earlier that, when using the default deleter (i.e., delete), you can reason‐\nably assume that std::unique_ptr objects are the same size as raw pointers. When\ncustom deleters enter the picture, this may no longer be the case. Deleters that are\nfunction pointers generally cause the size of a std::unique_ptr to grow from one\nword to two. For deleters that are function objects, the change in size depends on\nhow much state is stored in the function object. Stateless function objects (e.g., from\nlambda expressions with no captures) incur no size penalty, and this means that\nwhen a custom deleter can be implemented as either a function or a captureless\nlambda expression, the lambda is preferable:\nauto delInvmt1 = [](Investment* pInvestment)      // custom\n                 {                                // deleter\n                   makeLogEntry(pInvestment);     // as\n                   delete pInvestment;            // stateless\n                 };                               // lambda\ntemplate<typename... Ts>                          // return type\nstd::unique_ptr<Investment, decltype(delInvmt1)>  // has size of\nmakeInvestment(Ts&&... args);                     // Investment*\nvoid delInvmt2(Investment* pInvestment)           // custom\n{                                                 // deleter\n  makeLogEntry(pInvestment);                      // as function\n  delete pInvestment;\n}\ntemplate<typename... Ts>                 // return type has\nstd::unique_ptr<Investment,              // size of Investment*\n                void (*)(Investment*)>   // plus at least size\nmakeInvestment(Ts&&... params);          // of function pointer!\nFunction object deleters with extensive state can yield std::unique_ptr objects of\nsignificant size. If you find that a custom deleter makes your std::unique_ptrs\nunacceptably large, you probably need to change your design.\nItem 18 \n| \n123\nwww.it-ebooks.info\n",
      "page_number": 134,
      "chapter_number": 13,
      "summary": "This chapter covers segment 13 (pages 134-141). Key topics include pointers, delete. Covers function. Its declaration doesn’t indicate whether it points to a single object or to an array.",
      "keywords": [
        "std",
        "unique",
        "ptr",
        "Investment",
        "pointer",
        "object",
        "Raw pointers",
        "Smart Pointers",
        "function",
        "Item",
        "makeInvestment",
        "raw",
        "auto",
        "type",
        "resource"
      ],
      "concepts": [
        "std",
        "pointers",
        "delete",
        "deleting",
        "deletion",
        "investment",
        "investments",
        "invest",
        "object",
        "function"
      ],
      "similar_chapters": [
        {
          "book": "More Effective C++",
          "chapter": 20,
          "title": "Segment 20 (pages 190-199)",
          "relevance_score": 0.68,
          "method": "sentence_transformers"
        },
        {
          "book": "More Effective C++",
          "chapter": 14,
          "title": "Segment 14 (pages 133-140)",
          "relevance_score": 0.65,
          "method": "sentence_transformers"
        },
        {
          "book": "More Effective C++",
          "chapter": 12,
          "title": "Segment 12 (pages 116-123)",
          "relevance_score": 0.64,
          "method": "sentence_transformers"
        },
        {
          "book": "Python Distilled",
          "chapter": 25,
          "title": "Segment 25 (pages 219-229)",
          "relevance_score": 0.64,
          "method": "sentence_transformers"
        },
        {
          "book": "C++ Concurrency in Action",
          "chapter": 6,
          "title": "Segment 6 (pages 50-58)",
          "relevance_score": 0.62,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 14,
      "title": "Segment 14 (pages 142-153)",
      "start_page": 142,
      "end_page": 153,
      "detection_method": "topic_boundary",
      "content": "Factory functions are not the only common use case for std::unique_ptrs. They’re\neven more popular as a mechanism for implementing the Pimpl Idiom. The code for\nthat isn’t complicated, but in some cases it’s less than straightforward, so I’ll refer you\nto Item 22, which is dedicated to the topic.\nstd::unique_ptr comes in two forms, one for individual objects (std::\nunique_ptr<T>) and one for arrays (std::unique_ptr<T[]>). As a result, there’s\nnever any ambiguity about what kind of entity a std::unique_ptr points to. The\nstd::unique_ptr API is designed to match the form you’re using. For example,\nthere’s no indexing operator (operator[]) for the single-object form, while the array\nform lacks dereferencing operators (operator* and operator->).\nThe existence of std::unique_ptr for arrays should be of only intellectual interest\nto you, because std::array, std::vector, and std::string are virtually always\nbetter data structure choices than raw arrays. About the only situation I can conceive\nof when a std::unique_ptr<T[]> would make sense would be when you’re using a\nC-like API that returns a raw pointer to a heap array that you assume ownership of.\nstd::unique_ptr is the C++11 way to express exclusive ownership, but one of its\nmost attractive features is that it easily and efficiently converts to a std::\nshared_ptr:\nstd::shared_ptr<Investment> sp =    // converts std::unique_ptr\n  makeInvestment( arguments );      // to std::shared_ptr\nThis is a key part of why std::unique_ptr is so well suited as a factory function\nreturn type. Factory functions can’t know whether callers will want to use exclusive-\nownership semantics for the object they return or whether shared ownership (i.e.,\nstd::shared_ptr) would be more appropriate. By returning a std::unique_ptr,\nfactories provide callers with the most efficient smart pointer, but they don’t hinder\ncallers from replacing it with its more flexible sibling. (For information about\nstd::shared_ptr, proceed to Item 19.)\nThings to Remember\n• std::unique_ptr is a small, fast, move-only smart pointer for managing\nresources with exclusive-ownership semantics.\n• By default, resource destruction takes place via delete, but custom deleters\ncan be specified. Stateful deleters and function pointers as deleters increase the\nsize of std::unique_ptr objects.\n• Converting a std::unique_ptr to a std::shared_ptr is easy.\n124 \n| \nItem 18\nwww.it-ebooks.info\n\n\nItem 19: Use std::shared_ptr for shared-ownership\nresource management.\nProgrammers using languages with garbage collection point and laugh at what C++\nprogrammers go through to prevent resource leaks. “How primitive!” they jeer.\n“Didn’t you get the memo from Lisp in the 1960s? Machines should manage resource\nlifetimes, not humans.” C++ developers roll their eyes. “You mean the memo where\nthe only resource is memory and the timing of resource reclamation is nondetermin‐\nistic? We prefer the generality and predictability of destructors, thank you.” But our\nbravado is part bluster. Garbage collection really is convenient, and manual lifetime\nmanagement really can seem akin to constructing a mnemonic memory circuit using\nstone knives and bear skins.  Why can’t we have the best of both worlds: a system that\nworks automatically (like garbage collection), yet applies to all resources and has pre‐\ndictable timing (like destructors)?\nstd::shared_ptr is the C++11 way of binding these worlds together. An object\naccessed via std::shared_ptrs has its lifetime managed by those pointers through\nshared ownership. No specific std::shared_ptr owns the object. Instead, all\nstd::shared_ptrs pointing to it collaborate to ensure its destruction at the point\nwhere it’s no longer needed. When the last std::shared_ptr pointing to an object\nstops pointing there (e.g., because the std::shared_ptr is destroyed or made to\npoint to a different object), that std::shared_ptr destroys the object it points to. As\nwith garbage collection, clients need not concern themselves with managing the life‐\ntime of pointed-to objects, but as with destructors, the timing of the objects’ destruc‐\ntion is deterministic.\nA std::shared_ptr can tell whether it’s the last one pointing to a resource by con‐\nsulting the resource’s reference count, a value associated with the resource that keeps\ntrack of how many std::shared_ptrs point to it. std::shared_ptr constructors\nincrement this count (usually—see below), std::shared_ptr destructors decrement\nit, and copy assignment operators do both. (If sp1 and sp2 are std::shared_ptrs to\ndifferent objects, the assignment “sp1 = sp2;” modifies sp1 such that it points to the\nobject pointed to by sp2. The net effect of the assignment is that the reference count\nfor the object originally pointed to by sp1 is decremented, while that for the object\npointed to by sp2 is incremented.) If a std::shared_ptr sees a reference count of\nzero after performing a decrement, no more std::shared_ptrs point to the\nresource, so the std::shared_ptr destroys it.\nThe existence of the reference count has performance implications:\nItem 19 \n| \n125\nwww.it-ebooks.info\n\n\n2 This implementation is not required by the Standard, but every Standard Library implementation I’m familiar\nwith employs it.\n• std::shared_ptrs are twice the size of a raw pointer, because they internally\ncontain a raw pointer to the resource as well as a raw pointer to the resource’s\nreference count.2\n• Memory for the reference count must be dynamically allocated. Conceptually,\nthe reference count is associated with the object being pointed to, but pointed-to\nobjects know nothing about this. They thus have no place to store a reference\ncount. (A pleasant implication is that any object—even those of built-in types—\nmay be managed by std::shared_ptrs.) Item 21 explains that the cost of the\ndynamic allocation is avoided when the std::shared_ptr is created by\nstd::make_shared, but there are situations where std::make_shared can’t be\nused. Either way, the reference count is stored as dynamically allocated data.\n• Increments and decrements of the reference count must be atomic, because\nthere can be simultaneous readers and writers in different threads. For example,\na std::shared_ptr pointing to a resource in one thread could be executing its\ndestructor (hence decrementing the reference count for the resource it points to),\nwhile, in a different thread, a std::shared_ptr to the same object could be\ncopied (and therefore incrementing the same reference count). Atomic opera‐\ntions are typically slower than non-atomic operations, so even though reference\ncounts are usually only a word in size, you should assume that reading and writ‐\ning them is comparatively costly.\nDid I pique your curiosity when I wrote that std::shared_ptr constructors only\n“usually” increment the reference count for the object they point to? Creating a\nstd::shared_ptr pointing to an object always yields one more std::shared_ptr\npointing to that object, so why mustn’t we always increment the reference count?\nMove construction, that’s why. Move-constructing a std::shared_ptr from\nanother std::shared_ptr sets the source std::shared_ptr to null, and that means\nthat the old std::shared_ptr stops pointing to the resource at the moment the new\nstd::shared_ptr starts. As a result, no reference count manipulation is required.\nMoving std::shared_ptrs is therefore faster than copying them: copying requires\nincrementing the reference count, but moving doesn’t. This is as true for assignment\nas for construction, so move construction is faster than copy construction, and move\nassignment is faster than copy assignment.\nLike std::unique_ptr (see Item 18), std::shared_ptr uses delete as its default\nresource-destruction \nmechanism, \nbut \nit \nalso \nsupports \ncustom \ndeleters.\nThe design of this support differs from that for std::unique_ptr, however. For\n126 \n| \nItem 19\nwww.it-ebooks.info\n\n\nstd::unique_ptr, the type of the deleter is part of the type of the smart pointer. For\nstd::shared_ptr, it’s not:\nauto loggingDel = [](Widget *pw)        // custom deleter\n                  {                     // (as in Item 18)\n                    makeLogEntry(pw);\n                    delete pw;\n                  };\nstd::unique_ptr<                        // deleter type is\n  Widget, decltype(loggingDel)          // part of ptr type\n  > upw(new Widget, loggingDel);\nstd::shared_ptr<Widget>                 // deleter type is not\n  spw(new Widget, loggingDel);          // part of ptr type\nThe std::shared_ptr design is more flexible. Consider two std::shared_ptr\n<Widget>s, each with a custom deleter of a different type (e.g., because the custom\ndeleters are specified via lambda expressions):\nauto customDeleter1 = [](Widget *pw) { … };    // custom deleters,\nauto customDeleter2 = [](Widget *pw) { … };    // each with a\n                                               // different type\nstd::shared_ptr<Widget> pw1(new Widget, customDeleter1);\nstd::shared_ptr<Widget> pw2(new Widget, customDeleter2);\nBecause pw1 and pw2 have the same type, they can be placed in a container of objects\nof that type:\nstd::vector<std::shared_ptr<Widget>> vpw{ pw1, pw2 };\nThey could also be assigned to one another, and they could each be passed to a func‐\ntion taking a parameter of type std::shared_ptr<Widget>. None of these things\ncan be done with std::unique_ptrs that differ in the types of their custom deleters,\nbecause the type of the custom deleter would affect the type of the std::unique_ptr.\nIn another difference from std::unique_ptr, specifying a custom deleter doesn’t\nchange the size of a std::shared_ptr object. Regardless of deleter, a\nstd::shared_ptr object is two pointers in size. That’s great news, but it should\nmake you vaguely uneasy. Custom deleters can be function objects, and function\nobjects can contain arbitrary amounts of data. That means they can be arbitrarily\nlarge. How can a std::shared_ptr refer to a deleter of arbitrary size without using\nany more memory?\nItem 19 \n| \n127\nwww.it-ebooks.info\n\n\nIt can’t. It may have to use more memory. However, that memory isn’t part of the\nstd::shared_ptr object. It’s on the heap or, if the creator of the std::shared_ptr\ntook advantage of std::shared_ptr support for custom allocators, it’s wherever the\nmemory managed by the allocator is located. I remarked earlier that a\nstd::shared_ptr object contains a pointer to the reference count for the object it\npoints to. That’s true, but it’s a bit misleading, because the reference count is part of a\nlarger data structure known as the control block. There’s a control block for each\nobject managed by std::shared_ptrs. The control block contains, in addition to the\nreference count, a copy of the custom deleter, if one has been specified. If a custom\nallocator was specified, the control block contains a copy of that, too. The control\nblock may also contain additional data, including, as Item 21 explains, a secondary\nreference count known as the weak count, but we’ll ignore such data in this Item. We\ncan envision the memory associated with a std::shared_ptr<T> object as looking\nlike this:\nPtr to T\nT Object\nReference Count\nWeak Count\nOther Data\n(e.g., custom deleter,\nallocator, etc.)\nControl Block\nPtr to Control Block\nstd::shared_ptr<T>\nAn object’s control block is set up by the function creating the first\nstd::shared_ptr to the object. At least that’s what’s supposed to happen. In gen‐\neral, it’s impossible for a function creating a std::shared_ptr to an object to know\nwhether some other std::shared_ptr already points to that object, so the following\nrules for control block creation are used:\n• std::make_shared (see Item 21) always creates a control block. It manufac‐\ntures a new object to point to, so there is certainly no control block for that\nobject at the time std::make_shared is called.\n• A control block is created when a std::shared_ptr is constructed from a\nunique-ownership pointer (i.e., a std::unique_ptr or std::auto_ptr).\nUnique-ownership pointers don’t use control blocks, so there should be no con‐\ntrol block for the pointed-to object. (As part of its construction, the\nstd::shared_ptr assumes ownership of the pointed-to object, so the unique-\nownership pointer is set to null.)\n128 \n| \nItem 19\nwww.it-ebooks.info\n\n\n• When a std::shared_ptr constructor is called with a raw pointer, it creates a\ncontrol block. If you wanted to create a std::shared_ptr from an object that\nalready had a control block, you’d presumably pass a std::shared_ptr or a\nstd::weak_ptr (see Item 20) as a constructor argument, not a raw pointer.\nstd::shared_ptr constructors taking std::shared_ptrs or std::weak_ptrs\nas constructor arguments don’t create new control blocks, because they can rely\non the smart pointers passed to them to point to any necessary control blocks.\nA consequence of these rules is that constructing more than one std::shared_ptr\nfrom a single raw pointer gives you a complimentary ride on the particle accelerator\nof undefined behavior, because the pointed-to object will have multiple control\nblocks. Multiple control blocks means multiple reference counts, and multiple refer‐\nence counts means the object will be destroyed multiple times (once for each refer‐\nence count). That means that code like this is bad, bad, bad:\nauto pw = new Widget;                          // pw is raw ptr\n…\nstd::shared_ptr<Widget> spw1(pw, loggingDel);  // create control\n                                               // block for *pw\n…\nstd::shared_ptr<Widget> spw2(pw, loggingDel);  // create 2nd\n                                               // control block\n                                               // for *pw!\nThe creation of the raw pointer pw to a dynamically allocated object is bad, because it\nruns contrary to the advice behind this entire chapter: to prefer smart pointers to raw\npointers. (If you’ve forgotten the motivation for that advice, refresh your memory on\npage 115.) But set that aside. The line creating pw is a stylistic abomination, but at\nleast it doesn’t cause undefined program behavior.\nNow, the constructor for spw1 is called with a raw pointer, so it creates a control\nblock (and thereby a reference count) for what’s pointed to. In this case, that’s *pw\n(i.e., the object pointed to by pw). In and of itself, that’s okay, but the constructor for\nspw2 is called with the same raw pointer, so it also creates a control block (hence a\nreference count) for *pw. *pw thus has two reference counts, each of which will even‐\ntually become zero, and that will ultimately lead to an attempt to destroy *pw twice.\nThe second destruction is responsible for the undefined behavior.\nThere are at least two lessons regarding std::shared_ptr use here. First, try to\navoid passing raw pointers to a std::shared_ptr constructor. The usual alternative\nis to use std::make_shared (see Item 21), but in the example above, we’re using cus‐\nItem 19 \n| \n129\nwww.it-ebooks.info\n\n\ntom deleters, and that’s not possible with std::make_shared. Second, if you must\npass a raw pointer to a std::shared_ptr constructor, pass the result of new directly\ninstead of going through a raw pointer variable. If the first part of the code above\nwere rewritten like this,\nstd::shared_ptr<Widget> spw1(new Widget,    // direct use of new\n                             loggingDel);\nit’d be a lot less tempting to create a second std::shared_ptr from the same raw\npointer. Instead, the author of the code creating spw2 would naturally use spw1 as an\ninitialization argument (i.e., would call the std::shared_ptr copy constructor), and\nthat would pose no problem whatsoever:\nstd::shared_ptr<Widget> spw2(spw1);     // spw2 uses same\n                                        // control block as spw1\nAn especially surprising way that using raw pointer variables as std::shared_ptr\nconstructor arguments can lead to multiple control blocks involves the this pointer.\nSuppose our program uses std::shared_ptrs to manage Widget objects, and we\nhave a data structure that keeps track of Widgets that have been processed:\nstd::vector<std::shared_ptr<Widget>> processedWidgets;\nFurther suppose that Widget has a member function that does the processing:\nclass Widget {\npublic:\n  …\n  void process();\n  …\n};\nHere’s a reasonable-looking approach for Widget::process:\nvoid Widget::process()\n{\n  …                                       // process the Widget\n  processedWidgets.emplace_back(this);    // add it to list of\n}                                         // processed Widgets;\n                                          // this is wrong!\nThe comment about this being wrong says it all—or at least most of it. (The part\nthat’s wrong is the passing of this, not the use of emplace_back. If you’re not famil‐\niar with emplace_back, see Item 42.) This code will compile, but it’s passing a raw\npointer (this) to a container of std::shared_ptrs. The std::shared_ptr thus\nconstructed will create a new control block for the pointed-to Widget (*this). That\n130 \n| \nItem 19\nwww.it-ebooks.info\n\n\ndoesn’t sound harmful until you realize that if there are std::shared_ptrs outside\nthe member function that already point to that Widget, it’s game, set, and match for\nundefined behavior.\nThe std::shared_ptr API includes a facility for just this kind of situation. It has\nprobably the oddest of all names in the Standard C++ Library: std::\nenable_shared_from_this. That’s a template for a base class you inherit from if\nyou want a class managed by std::shared_ptrs to be able to safely create a\nstd::shared_ptr from a this pointer. In our example, Widget would inherit from\nstd::enable_shared_from_this as follows:\nclass Widget: public std::enable_shared_from_this<Widget> {\npublic:\n  …\n  void process();\n  …\n};\nAs I said, std::enable_shared_from_this is a base class template. Its type parame‐\nter is always the name of the class being derived, so Widget inherits from\nstd::enable_shared_from_this<Widget>. If the idea of a derived class inheriting\nfrom a base class templatized on the derived class makes your head hurt, try not to\nthink about it. The code is completely legal, and the design pattern behind it is so well\nestablished, it has a standard name, albeit one that’s almost as odd as\nstd::enable_shared_from_this. The name is The Curiously Recurring Template\nPattern (CRTP). If you’d like to learn more about it, unleash your search engine,\nbecause here we need to get back to std::enable_shared_from_this.\nstd::enable_shared_from_this defines a member function that creates a\nstd::shared_ptr to the current object, but it does it without duplicating control\nblocks. The member function is shared_from_this, and you use it in member func‐\ntions whenever you want a std::shared_ptr that points to the same object as the\nthis pointer. Here’s a safe implementation of Widget::process:\nvoid Widget::process()\n{\n  // as before, process the Widget\n  …\n  // add std::shared_ptr to current object to processedWidgets\n  processedWidgets.emplace_back(shared_from_this());\n}\nItem 19 \n| \n131\nwww.it-ebooks.info\n\n\nInternally, shared_from_this looks up the control block for the current object, and\nit creates a new std::shared_ptr that refers to that control block. The design relies\non the current object having an associated control block. For that to be the case, there\nmust be an existing std::shared_ptr (e.g., one outside the member function calling\nshared_from_this) that points to the current object. If no such std::shared_ptr\nexists (i.e., if the current object has no associated control block), behavior is unde‐\nfined, although shared_from_this typically throws an exception.\nTo prevent clients from calling member functions that invoke shared_from_this\nbefore a std::shared_ptr points to the object, classes inheriting from\nstd::enable_shared_from_this often declare their constructors private and\nhave clients create objects by calling factory functions that return std::\nshared_ptrs. Widget, for example, could look like this: \nclass Widget: public std::enable_shared_from_this<Widget> {\npublic:\n  // factory function that perfect-forwards args\n  // to a private ctor\n  template<typename... Ts>\n  static std::shared_ptr<Widget> create(Ts&&... params);\n  …\n  void process();             // as before\n  …\nprivate:\n  …                           // ctors\n};\nBy now, you may only dimly recall that our discussion of control blocks was motiva‐\nted by a desire to understand the costs associated with std::shared_ptrs. Now that\nwe understand how to avoid creating too many control blocks, let’s return to the\noriginal topic.\nA control block is typically only a few words in size, although custom deleters and\nallocators may make it larger. The usual control block implementation is more\nsophisticated than you might expect. It makes use of inheritance, and there’s even a\nvirtual function. (It’s used to ensure that the pointed-to object is properly destroyed.)\nThat means that using std::shared_ptrs also incurs the cost of the machinery for\nthe virtual function used by the control block.\nHaving read about dynamically allocated control blocks, arbitrarily large deleters and\nallocators, virtual function machinery, and atomic reference count manipulations,\nyour enthusiasm for std::shared_ptrs may have waned somewhat. That’s fine.\n132 \n| \nItem 19\nwww.it-ebooks.info\n\n\nThey’re not the best solution to every resource management problem. But for the\nfunctionality they provide, std::shared_ptrs exact a very reasonable cost. Under\ntypical conditions, where the default deleter and default allocator are used and where\nthe std::shared_ptr is created by std::make_shared, the control block is only\nabout three words in size, and its allocation is essentially free. (It’s incorporated into\nthe memory allocation for the object being pointed to. For details, see Item 21.)\nDereferencing a std::shared_ptr is no more expensive than dereferencing a raw\npointer. Performing an operation requiring a reference count manipulation (e.g.,\ncopy construction or copy assignment, destruction) entails one or two atomic opera‐\ntions, but these operations typically map to individual machine instructions, so\nalthough they may be expensive compared to non-atomic instructions, they’re still\njust single instructions. The virtual function machinery in the control block is gener‐\nally used only once per object managed by std::shared_ptrs: when the object is\ndestroyed.\nIn exchange for these rather modest costs, you get automatic lifetime management of\ndynamically allocated resources. Most of the time, using std::shared_ptr is vastly\npreferable to trying to manage the lifetime of an object with shared ownership by\nhand. If you find yourself doubting whether you can afford use of std::shared_ptr,\nreconsider whether you really need shared ownership. If exclusive ownership will do\nor even may do, std::unique_ptr is a better choice. Its performance profile is close\nto that for raw pointers, and “upgrading” from std::unique_ptr to std::\nshared_ptr is easy, because a std::shared_ptr can be created from a std::\nunique_ptr.\nThe reverse is not true. Once you’ve turned lifetime management of a resource over\nto a std::shared_ptr, there’s no changing your mind. Even if the reference count is\none, you can’t reclaim ownership of the resource in order to, say, have a\nstd::unique_ptr manage it. The ownership contract between a resource and the\nstd::shared_ptrs that point to it is of the ’til-death-do-us-part variety. No divorce,\nno annulment, no dispensations.\nSomething else std::shared_ptrs can’t do is work with arrays. In yet another dif‐\nference from std::unique_ptr, std::shared_ptr has an API that’s designed only\nfor pointers to single objects. There’s no std::shared_ptr<T[]>. From time to\ntime, “clever” programmers stumble on the idea of using a std::shared_ptr<T> to\npoint to an array, specifying a custom deleter to perform an array delete (i.e., delete\n[]). This can be made to compile, but it’s a horrible idea. For one thing,\nstd::shared_ptr offers no operator[], so indexing into the array requires awk‐\nward expressions based on pointer arithmetic. For another, std::shared_ptr sup‐\nports derived-to-base pointer conversions that make sense for single objects, but that\nopen holes in the type system when applied to arrays. (For this reason, the\nItem 19 \n| \n133\nwww.it-ebooks.info\n\n\nstd::unique_ptr<T[]> API prohibits such conversions.) Most importantly, given\nthe variety of C++11 alternatives to built-in arrays (e.g., std::array, std::vector,\nstd::string), declaring a smart pointer to a dumb array is almost always a sign of\nbad design.\nThings to Remember\n• std::shared_ptrs offer convenience approaching that of garbage collection\nfor the shared lifetime management of arbitrary resources.\n• Compared to std::unique_ptr, std::shared_ptr objects are typically\ntwice as big, incur overhead for control blocks, and require atomic reference\ncount manipulations.\n• Default resource destruction is via delete, but custom deleters are supported.\nThe type of the deleter has no effect on the type of the std::shared_ptr.\n• Avoid creating std::shared_ptrs from variables of raw pointer type.\nItem 20: Use std::weak_ptr for std::shared_ptr-\nlike pointers that can dangle.\nParadoxically, it can be convenient to have a smart pointer that acts like a\nstd::shared_ptr (see Item 19), but that doesn’t participate in the shared ownership\nof the pointed-to resource. In other words, a pointer like std::shared_ptr that\ndoesn’t affect an object’s reference count. This kind of smart pointer has to contend\nwith a problem unknown to std::shared_ptrs: the possibility that what it points to\nhas been destroyed. A truly smart pointer would deal with this problem by tracking\nwhen it dangles, i.e., when the object it is supposed to point to no longer exists. That’s\nprecisely the kind of smart pointer std::weak_ptr is. \nYou may be wondering how a std::weak_ptr could be useful. You’ll probably won‐\nder even more when you examine the std::weak_ptr API. It looks anything but\nsmart. std::weak_ptrs can’t be dereferenced, nor can they be tested for nullness.\nThat’s because std::weak_ptr isn’t a standalone smart pointer. It’s an augmentation\nof std::shared_ptr.\nThe relationship begins at birth. std::weak_ptrs are typically created from\nstd::shared_ptrs. They point to the same place as the std::shared_ptrs initializ‐\ning them, but they don’t affect the reference count of the object they point to:\nauto spw =                       // after spw is constructed,\n  std::make_shared<Widget>();    // the pointed-to Widget's\n134 \n| \nItem 19\nwww.it-ebooks.info\n\n\n                                 // ref count (RC) is 1. (See\n                                 // Item 21 for info on\n                                 // std::make_shared.)\n…\nstd::weak_ptr<Widget> wpw(spw);  // wpw points to same Widget\n                                 // as spw. RC remains 1\n…\nspw = nullptr;                   // RC goes to 0, and the\n                                 // Widget is destroyed.\n                                 // wpw now dangles\nstd::weak_ptrs that dangle are said to have expired. You can test for this directly,\nif (wpw.expired()) …             // if wpw doesn't point\n                                 // to an object…\nbut often what you desire is a check to see if a std::weak_ptr has expired and, if it\nhasn’t (i.e., if it’s not dangling), to access the object it points to. This is easier desired\nthan done. Because std::weak_ptrs lack dereferencing operations, there’s no way to\nwrite the code. Even if there were, separating the check and the dereference would\nintroduce a race condition: between the call to expired and the dereferencing action,\nanother thread might reassign or destroy the last std::shared_ptr pointing to the\nobject, thus causing that object to be destroyed. In that case, your dereference would\nyield undefined behavior.\nWhat you need is an atomic operation that checks to see if the std::weak_ptr has\nexpired and, if not, gives you access to the object it points to. This is done by creating\na std::shared_ptr from the std::weak_ptr. The operation comes in two forms,\ndepending on what you’d like to have happen if the std::weak_ptr has expired\nwhen you try to create a std::shared_ptr from it. One form is std::\nweak_ptr::lock, which returns a std::shared_ptr. The std::shared_ptr is null\nif the std::weak_ptr has expired:\nstd::shared_ptr<Widget> spw1 = wpw.lock();  // if wpw's expired,\n                                            // spw1 is null\nauto spw2 = wpw.lock();                     // same as above,\n                                            // but uses auto\nThe other form is the std::shared_ptr constructor taking a std::weak_ptr as an\nargument. In this case, if the std::weak_ptr has expired, an exception is thrown:\nstd::shared_ptr<Widget> spw3(wpw);    // if wpw's expired,\n                                      // throw std::bad_weak_ptr\nItem 20 \n| \n135\nwww.it-ebooks.info\n",
      "page_number": 142,
      "chapter_number": 14,
      "summary": "This chapter covers segment 14 (pages 142-153). Key topics include objects, widget. The code for\nthat isn’t complicated, but in some cases it’s less than straightforward, so I’ll refer you\nto Item 22, which is dedicated to the topic.",
      "keywords": [
        "std",
        "ptr",
        "shared",
        "Widget",
        "object",
        "control block",
        "Item",
        "reference count",
        "ptrs",
        "control",
        "count",
        "pointer",
        "block",
        "reference",
        "unique"
      ],
      "concepts": [
        "std",
        "objects",
        "widget",
        "item",
        "pointer",
        "created",
        "creates",
        "uses",
        "useful",
        "block"
      ],
      "similar_chapters": [
        {
          "book": "More Effective C++",
          "chapter": 22,
          "title": "Segment 22 (pages 216-223)",
          "relevance_score": 0.7,
          "method": "sentence_transformers"
        },
        {
          "book": "More Effective C++",
          "chapter": 23,
          "title": "Segment 23 (pages 224-233)",
          "relevance_score": 0.68,
          "method": "sentence_transformers"
        },
        {
          "book": "More Effective C++",
          "chapter": 4,
          "title": "Segment 4 (pages 25-32)",
          "relevance_score": 0.67,
          "method": "sentence_transformers"
        },
        {
          "book": "More Effective C++",
          "chapter": 21,
          "title": "Segment 21 (pages 200-215)",
          "relevance_score": 0.63,
          "method": "sentence_transformers"
        },
        {
          "book": "More Effective C++",
          "chapter": 33,
          "title": "Segment 33 (pages 330-335)",
          "relevance_score": 0.61,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 15,
      "title": "Segment 15 (pages 154-161)",
      "start_page": 154,
      "end_page": 161,
      "detection_method": "topic_boundary",
      "content": "But you’re probably still wondering about how std::weak_ptrs can be useful. Con‐\nsider a factory function that produces smart pointers to read-only objects based on a\nunique ID. In accord with Item 18’s advice regarding factory function return types, it\nreturns a std::unique_ptr:\nstd::unique_ptr<const Widget> loadWidget(WidgetID id);\nIf loadWidget is an expensive call (e.g., because it performs file or database I/O) and\nit’s common for IDs to be used repeatedly, a reasonable optimization would be to\nwrite a function that does what loadWidget does, but also caches its results. Clogging\nthe cache with every Widget that has ever been requested can lead to performance\nproblems of its own, however, so another reasonable optimization would be to\ndestroy cached Widgets when they’re no longer in use.\nFor this caching factory function, a std::unique_ptr return type is not a good fit.\nCallers should certainly receive smart pointers to cached objects, and callers should\ncertainly determine the lifetime of those objects, but the cache needs a pointer to the\nobjects, too. The cache’s pointers need to be able to detect when they dangle, because\nwhen factory clients are finished using an object returned by the factory, that object\nwill be destroyed, and the corresponding cache entry will dangle. The cached pointers\nshould therefore be std::weak_ptrs—pointers that can detect when they dangle.\nThat means that the factory’s return type should be a std::shared_ptr, because\nstd::weak_ptrs can detect when they dangle only when an object’s lifetime is man‐\naged by std::shared_ptrs.\nHere’s a quick-and-dirty implementation of a caching version of loadWidget:\nstd::shared_ptr<const Widget> fastLoadWidget(WidgetID id)\n{\n  static std::unordered_map<WidgetID,\n                            std::weak_ptr<const Widget>> cache;\n  auto objPtr = cache[id].lock();   // objPtr is std::shared_ptr\n                                    // to cached object (or null\n                                    // if object's not in cache)\n  if (!objPtr) {                    // if not in cache,\n    objPtr = loadWidget(id);        // load it\n    cache[id] = objPtr;             // cache it\n  }\n  return objPtr;\n}\n136 \n| \nItem 20\nwww.it-ebooks.info\n\n\nThis implementation employs one of C++11’s hash table containers (std::unor\ndered_map), though it doesn’t show the WidgetID hashing and equality-comparison\nfunctions that would also have to be present.\nThe implementation of fastLoadWidget ignores the fact that the cache may accu‐\nmulate expired std::weak_ptrs corresponding to Widgets that are no longer in use\n(and have therefore been destroyed). The implementation can be refined, but rather\nthan spend time on an issue that lends no additional insight into std::weak_ptrs,\nlet’s consider a second use case: the Observer design pattern. The primary compo‐\nnents of this pattern are subjects (objects whose state may change) and observers\n(objects to be notified when state changes occur). In most implementations, each\nsubject contains a data member holding pointers to its observers. That makes it easy\nfor subjects to issue state change notifications. Subjects have no interest in control‐\nling the lifetime of their observers (i.e., when they’re destroyed), but they have a great\ninterest in making sure that if an observer gets destroyed, subjects don’t try to subse‐\nquently access it. A reasonable design is for each subject to hold a container of\nstd::weak_ptrs to its observers, thus making it possible for the subject to determine\nwhether a pointer dangles before using it.\nAs a final example of std::weak_ptr’s utility, consider a data structure with objects\nA, B, and C in it, where A and C share ownership of B and therefore hold\nstd::shared_ptrs to it:\nA\nB\nC\nstd::shared_ptr\nstd::shared_ptr\nSuppose it’d be useful to also have a pointer from B back to A. What kind of pointer\nshould this be?\nA\nB\nC\nstd::shared_ptr\n???\nstd::shared_ptr\nThere are three choices:\n• A raw pointer. With this approach, if A is destroyed, but C continues to point to\nB, B will contain a pointer to A that will dangle. B won’t be able to detect that, so B\nmay inadvertently dereference the dangling pointer. That would yield undefined\nbehavior.\n• A std::shared_ptr. In this design, A and B contain std::shared_ptrs to each\nother. The resulting std::shared_ptr cycle (A points to B and B points to A) will\nItem 20 \n| \n137\nwww.it-ebooks.info\n\n\nprevent both A and B from being destroyed. Even if A and B are unreachable from\nother program data structures (e.g., because C no longer points to B), each will\nhave a reference count of one. If that happens, A and B will have been leaked, for\nall practical purposes: it will be impossible for the program to access them, yet\ntheir resources will never be reclaimed.\n• A std::weak_ptr. This avoids both problems above. If A is destroyed, B’s\npointer back to it will dangle, but B will be able to detect that. Furthermore,\nthough A and B will point to one another, B’s pointer won’t affect A’s reference\ncount, hence can’t keep A from being destroyed when std::shared_ptrs no\nlonger point to it.\nUsing std::weak_ptr is clearly the best of these choices. However, it’s worth noting\nthat the need to employ std::weak_ptrs to break prospective cycles of std::\nshared_ptrs is not terribly common. In strictly hierarchal data structures such as\ntrees, child nodes are typically owned only by their parents. When a parent node is\ndestroyed, its child nodes should be destroyed, too. Links from parents to children\nare thus generally best represented by std::unique_ptrs. Back-links from children\nto parents can be safely implemented as raw pointers, because a child node should\nnever have a lifetime longer than its parent. There’s thus no risk of a child node\ndereferencing a dangling parent pointer.\nOf course, not all pointer-based data structures are strictly hierarchical, and when\nthat’s the case, as well as in situations such as caching and the implementation of lists\nof observers, it’s nice to know that std::weak_ptr stands at the ready.\nFrom an efficiency perspective, the std::weak_ptr story is essentially the same as\nthat for std::shared_ptr. std::weak_ptr objects are the same size as std::\nshared_ptr objects, they make use of the same control blocks as std::\nshared_ptrs (see Item 19), and operations such as construction, destruction, and\nassignment involve atomic reference count manipulations. That probably surprises\nyou, because I wrote at the beginning of this Item that std::weak_ptrs don’t partici‐\npate in reference counting. Except that’s not quite what I wrote. What I wrote was\nthat std::weak_ptrs don’t participate in the shared ownership of objects and hence\ndon’t affect the pointed-to object’s reference count. There’s actually a second reference\ncount in the control block, and it’s this second reference count that std::weak_ptrs\nmanipulate. For details, continue on to Item 21.\n138 \n| \nItem 20\nwww.it-ebooks.info\n\n\n3 To create a full-featured make_unique with the smallest effort possible, search for the standardization docu‐\nment that gave rise to it, then copy the implementation you’ll find there. The document you want is N3656 by\nStephan T. Lavavej, dated 2013-04-18.\nThings to Remember\n• Use std::weak_ptr for std::shared_ptr-like pointers that can dangle.\n• Potential use cases for std::weak_ptr include caching, observer lists, and the\nprevention of std::shared_ptr cycles.\nItem 21: Prefer std::make_unique and\nstd::make_shared to direct use of new.\nLet’s begin by leveling the playing field for std::make_unique and std::\nmake_shared. std::make_shared is part of C++11, but, sadly, std::make_\nunique isn’t. It joined the Standard Library as of C++14. If you’re using C++11,\nnever fear, because a basic version of std::make_unique is easy to write yourself.\nHere, look:\ntemplate<typename T, typename... Ts>\nstd::unique_ptr<T> make_unique(Ts&&... params)\n{\n  return std::unique_ptr<T>(new T(std::forward<Ts>(params)...));\n}\nAs you can see, make_unique just perfect-forwards its parameters to the constructor\nof the object being created, constructs a std::unique_ptr from the raw pointer new\nproduces, and returns the std::unique_ptr so created. This form of the function\ndoesn’t support arrays or custom deleters (see Item 18), but it demonstrates that with\nonly a little effort, you can create make_unique if you need to.3 Just remember not to\nput your version in namespace std, because you won’t want it to clash with a vendor-\nprovided version when you upgrade to a C++14 Standard Library implementation.\nstd::make_unique and std::make_shared are two of the three make functions:\nfunctions that take an arbitrary set of arguments, perfect-forward them to the con‐\nstructor for a dynamically allocated object, and return a smart pointer to that object.\nThe \nthird \nmake \nfunction \nis \nstd::allocate_shared. \nIt \nacts \njust \nlike\nstd::make_shared, except its first argument is an allocator object to be used for the\ndynamic memory allocation.\nItem 21 \n| \n139\nwww.it-ebooks.info\n\n\nEven the most trivial comparison of smart pointer creation using and not using a\nmake function reveals the first reason why using such functions is preferable. Con‐\nsider:\nauto upw1(std::make_unique<Widget>());      // with make func\nstd::unique_ptr<Widget> upw2(new Widget);   // without make func\nauto spw1(std::make_shared<Widget>());      // with make func\nstd::shared_ptr<Widget> spw2(new Widget);   // without make func\nI’ve highlighted the essential difference: the versions using new repeat the type being\ncreated, but the make functions don’t. Repeating types runs afoul of a key tenet of\nsoftware engineering: code duplication should be avoided. Duplication in source\ncode increases compilation times, can lead to bloated object code, and generally ren‐\nders a code base more difficult to work with. It often evolves into inconsistent code,\nand inconsistency in a code base often leads to bugs. Besides, typing something twice\ntakes more effort than typing it once, and who’s not a fan of reducing their typing\nburden?\nThe second reason to prefer make functions has to do with exception safety. Suppose\nwe have a function to process a Widget in accord with some priority:\nvoid processWidget(std::shared_ptr<Widget> spw, int priority);\nPassing the std::shared_ptr by value may look suspicious, but Item 41 explains\nthat if processWidget always makes a copy of the std::shared_ptr (e.g., by storing\nit in a data structure tracking Widgets that have been processed), this can be a rea‐\nsonable design choice.\nNow suppose we have a function to compute the relevant priority,\nint computePriority();\nand we use that in a call to processWidget that uses new instead of\nstd::make_shared:\nprocessWidget(std::shared_ptr<Widget>(new Widget),  // potential\n              computePriority());                   // resource\n                                                    // leak!\nAs the comment indicates, this code could leak the Widget conjured up by new. But\nhow? Both the calling code and the called function are using std::shared_ptrs, and\nstd::shared_ptrs are designed to prevent resource leaks. They automatically\n140 \n| \nItem 21\nwww.it-ebooks.info\n\n\ndestroy what they point to when the last std::shared_ptr pointing there goes away.\nIf everybody is using std::shared_ptrs everywhere, how can this code leak?\nThe answer has to do with compilers’ translation of source code into object code. At\nruntime, the arguments for a function must be evaluated before the function can be\ninvoked, so in the call to processWidget, the following things must occur before\nprocessWidget can begin execution:\n• The expression “new Widget” must be evaluated, i.e., a Widget must be created\non the heap.\n• The constructor for the std::shared_ptr<Widget> responsible for managing\nthe pointer produced by new must be executed.\n• computePriority must run.\nCompilers are not required to generate code that executes them in this order. “new\nWidget” must be executed before the std::shared_ptr constructor may be called,\nbecause the result of that new is used as an argument to that constructor, but compute\nPriority may be executed before those calls, after them, or, crucially, between them.\nThat is, compilers may emit code to execute the operations in this order:\n1. Perform “new Widget”.\n2. Execute computePriority.\n3. Run std::shared_ptr constructor.\nIf such code is generated and, at runtime, computePriority produces an exception,\nthe dynamically allocated Widget from Step 1 will be leaked, because it will never be\nstored in the std::shared_ptr that’s supposed to start managing it in Step 3.\nUsing std::make_shared avoids this problem. Calling code would look like this:\nprocessWidget(std::make_shared<Widget>(),   // no potential\n              computePriority());           // resource leak\nAt runtime, either std::make_shared or computePriority will be called first. If it’s\nstd::make_shared, the raw pointer to the dynamically allocated Widget is safely\nstored in the returned std::shared_ptr before computePriority is called. If compu\ntePriority then yields an exception, the std::shared_ptr destructor will see to it\nthat the Widget it owns is destroyed. And if computePriority is called first and\nyields an exception, std::make_shared will not be invoked, and there will hence be\nno dynamically allocated Widget to worry about.\nItem 21 \n| \n141\nwww.it-ebooks.info\n\n\nIf we replace std::shared_ptr and std::make_shared with std::unique_ptr and\nstd::make_unique, exactly the same reasoning applies. Using std::make_unique\ninstead of new is thus just as important in writing exception-safe code as using\nstd::make_shared.\nA special feature of std::make_shared (compared to direct use of new) is improved\nefficiency. Using std::make_shared allows compilers to generate smaller, faster\ncode that employs leaner data structures. Consider the following direct use of new:\nstd::shared_ptr<Widget> spw(new Widget);\nIt’s obvious that this code entails a memory allocation, but it actually performs two.\nItem 19 explains that every std::shared_ptr points to a control block containing,\namong other things, the reference count for the pointed-to object. Memory for this\ncontrol block is allocated in the std::shared_ptr constructor. Direct use of new,\nthen, requires one memory allocation for the Widget and a second allocation for the\ncontrol block.\nIf std::make_shared is used instead,\nauto spw = std::make_shared<Widget>();\none allocation suffices. That’s because std::make_shared allocates a single chunk of\nmemory to hold both the Widget object and the control block. This optimization\nreduces the static size of the program, because the code contains only one memory\nallocation call, and it increases the speed of the executable code, because memory is\nallocated only once. Furthermore, using std::make_shared obviates the need for\nsome of the bookkeeping information in the control block, potentially reducing the\ntotal memory footprint for the program.\nThe efficiency analysis for std::make_shared is equally applicable to std::allo\ncate_shared, so the performance advantages of std::make_shared extend to that\nfunction, as well.\nThe arguments for preferring make functions over direct use of new are strong ones.\nDespite their software engineering, exception safety, and efficiency advantages, how‐\never, this Item’s guidance is to prefer the make functions, not to rely on them exclu‐\nsively. That’s because there are circumstances where they can’t or shouldn’t be used.\nFor example, none of the make functions permit the specification of custom deleters\n(see Items 18 and 19), but both std::unique_ptr and std::shared_ptr have con‐\nstructors that do. Given a custom deleter for a Widget,\nauto widgetDeleter = [](Widget* pw) { … };\ncreating a smart pointer using it is straightforward using new:\n142 \n| \nItem 21\nwww.it-ebooks.info\n\n\nstd::unique_ptr<Widget, decltype(widgetDeleter)>\n  upw(new Widget, widgetDeleter);\nstd::shared_ptr<Widget> spw(new Widget, widgetDeleter);\nThere’s no way to do the same thing with a make function.\nA second limitation of make functions stems from a syntactic detail of their imple‐\nmentations. Item 7 explains that when creating an object whose type overloads con‐\nstructors both with and without std::initializer_list parameters, creating the\nobject using braces prefers the std::initializer_list constructor, while creating\nthe object using parentheses calls the non-std::initializer_list constructor.\nThe make functions perfect-forward their parameters to an object’s constructor, but\ndo they do so using parentheses or using braces? For some types, the answer to this\nquestion makes a big difference. For example, in these calls,\nauto upv = std::make_unique<std::vector<int>>(10, 20);\nauto spv = std::make_shared<std::vector<int>>(10, 20);\ndo the resulting smart pointers point to std::vectors with 10 elements, each of\nvalue 20, or to std::vectors with two elements, one with value 10 and the other\nwith value 20? Or is the result indeterminate?\nThe good news is that it’s not indeterminate: both calls create std::vectors of size\n10 with all values set to 20. That means that within the make functions, the perfect\nforwarding code uses parentheses, not braces. The bad news is that if you want to\nconstruct your pointed-to object using a braced initializer, you must use new directly.\nUsing a make function would require the ability to perfect-forward a braced initial‐\nizer, but, as Item 30 explains, braced initializers can’t be perfect-forwarded. However,\nItem 30 also describes a workaround: use auto type deduction to create a std::ini\ntializer_list object from a braced initializer (see Item 2), then pass the auto-\ncreated object through the make function:\n// create std::initializer_list\nauto initList = { 10, 20 };\n// create std::vector using std::initializer_list ctor\nauto spv = std::make_shared<std::vector<int>>(initList);\nFor std::unique_ptr, these two scenarios (custom deleters and braced initializers)\nare the only ones where its make functions are problematic. For std::shared_ptr\nand its make functions, there are two more. Both are edge cases, but some developers\nlive on the edge, and you may be one of them.\nItem 21 \n| \n143\nwww.it-ebooks.info\n",
      "page_number": 154,
      "chapter_number": 15,
      "summary": "This chapter covers segment 15 (pages 154-161). Key topics include widget, code. Con‐\nsider a factory function that produces smart pointers to read-only objects based on a\nunique ID.",
      "keywords": [
        "std",
        "Widget",
        "ptr",
        "make",
        "shared",
        "Item",
        "ptrs",
        "make functions",
        "unique",
        "object",
        "weak",
        "code",
        "function",
        "pointer",
        "functions"
      ],
      "concepts": [
        "std",
        "widget",
        "code",
        "auto",
        "pointers",
        "caches",
        "cached",
        "objects",
        "useful",
        "uses"
      ],
      "similar_chapters": [
        {
          "book": "More Effective C++",
          "chapter": 23,
          "title": "Segment 23 (pages 224-233)",
          "relevance_score": 0.7,
          "method": "sentence_transformers"
        },
        {
          "book": "More Effective C++",
          "chapter": 4,
          "title": "Segment 4 (pages 25-32)",
          "relevance_score": 0.67,
          "method": "sentence_transformers"
        },
        {
          "book": "More Effective C++",
          "chapter": 32,
          "title": "Segment 32 (pages 320-329)",
          "relevance_score": 0.64,
          "method": "sentence_transformers"
        },
        {
          "book": "More Effective C++",
          "chapter": 33,
          "title": "Segment 33 (pages 330-335)",
          "relevance_score": 0.64,
          "method": "sentence_transformers"
        },
        {
          "book": "C++ Templates_ The Complete Guide",
          "chapter": 15,
          "title": "Segment 15 (pages 456-487)",
          "relevance_score": 0.62,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 16,
      "title": "Segment 16 (pages 162-174)",
      "start_page": 162,
      "end_page": 174,
      "detection_method": "topic_boundary",
      "content": "4 In practice, the value of the weak count isn’t always equal to the number of std::weak_ptrs referring to the\ncontrol block, because library implementers have found ways to slip additional information into the weak\ncount that facilitate better code generation. For purposes of this Item, we’ll ignore this and assume that the\nweak count’s value is the number of std::weak_ptrs referring to the control block.\nSome classes define their own versions of operator new and operator delete. The\npresence of these functions implies that the global memory allocation and dealloca‐\ntion routines for objects of these types are inappropriate. Often, class-specific rou‐\ntines are designed only to allocate and deallocate chunks of memory of precisely the\nsize of objects of the class, e.g., operator new and operator delete for class Widget\nare often designed only to handle allocation and deallocation of chunks of memory of\nexactly size sizeof(Widget). Such routines are a poor fit for std::shared_ptr’s\nsupport for custom allocation (via std::allocate_shared) and deallocation (via\ncustom deleters), because the amount of memory that std::allocate_shared\nrequests isn’t the size of the dynamically allocated object, it’s the size of that object\nplus the size of a control block. Consequently, using make functions to create objects\nof types with class-specific versions of operator new and operator delete is typi‐\ncally a poor idea.\nThe size and speed advantages of std::make_shared vis-à-vis direct use of new stem\nfrom std::shared_ptr’s control block being placed in the same chunk of memory\nas the managed object. When that object’s reference count goes to zero, the object is\ndestroyed (i.e., its destructor is called). However, the memory it occupies can’t be\nreleased until the control block has also been destroyed, because the same chunk of\ndynamically allocated memory contains both.\nAs I noted, the control block contains bookkeeping information beyond just the ref‐\nerence count itself. The reference count tracks how many std::shared_ptrs refer to\nthe control block, but the control block contains a second reference count, one that\ntallies how many std::weak_ptrs refer to the control block. This second reference\ncount is known as the weak count.4 When a std::weak_ptr checks to see if it has\nexpired (see Item 19), it does so by examining the reference count (not the weak\ncount) in the control block that it refers to. If the reference count is zero (i.e., if the\npointed-to object has no std::shared_ptrs referring to it and has thus been\ndestroyed), the std::weak_ptr has expired. Otherwise, it hasn’t.\nAs long as std::weak_ptrs refer to a control block (i.e., the weak count is greater\nthan zero), that control block must continue to exist. And as long as a control block\nexists, the memory containing it must remain allocated. The memory allocated by a\nstd::shared_ptr make function, then, can’t be deallocated until the last\nstd::shared_ptr and the last std::weak_ptr referring to it have been destroyed.\n144 \n| \nItem 21\nwww.it-ebooks.info\n\n\nIf the object type is quite large and the time between destruction of the last\nstd::shared_ptr and the last std::weak_ptr is significant, a lag can occur between\nwhen an object is destroyed and when the memory it occupied is freed:\nclass ReallyBigType { … };\nauto pBigObj =                          // create very large\n  std::make_shared<ReallyBigType>();    // object via\n                                        // std::make_shared\n…            // create std::shared_ptrs and std::weak_ptrs to\n             // large object, use them to work with it\n…            // final std::shared_ptr to object destroyed here,\n             // but std::weak_ptrs to it remain\n…            // during this period, memory formerly occupied\n             // by large object remains allocated\n…            // final std::weak_ptr to object destroyed here;\n             // memory for control block and object is released\nWith a direct use of new, the memory for the ReallyBigType object can be released\nas soon as the last std::shared_ptr to it is destroyed:\nclass ReallyBigType { … };              // as before\nstd::shared_ptr<ReallyBigType> pBigObj(new ReallyBigType);\n                                        // create very large\n                                        // object via new\n…            // as before, create std::shared_ptrs and\n             // std::weak_ptrs to object, use them with it\n…            // final std::shared_ptr to object destroyed here,\n             // but std::weak_ptrs to it remain;\n             // memory for object is deallocated\n…            // during this period, only memory for the\n             // control block remains allocated\n…            // final std::weak_ptr to object destroyed here;\n             // memory for control block is released\nShould you find yourself in a situation where use of std::make_shared is impossible\nor inappropriate, you’ll want to guard yourself against the kind of exception-safety\nItem 21 \n| \n145\nwww.it-ebooks.info\n\n\nproblems we saw earlier. The best way to do that is to make sure that when you use\nnew directly, you immediately pass the result to a smart pointer constructor in a\nstatement that does nothing else. This prevents compilers from generating code that\ncould emit an exception between the use of new and invocation of the constructor for\nthe smart pointer that will manage the newed object.\nAs an example, consider a minor revision to the exception-unsafe call to the process\nWidget function we examined earlier. This time, we’ll specify a custom deleter:\nvoid processWidget(std::shared_ptr<Widget> spw,  // as before\n                   int priority);\nvoid cusDel(Widget *ptr);                        // custom\n                                                 // deleter\nHere’s the exception-unsafe call:\nprocessWidget(                                   // as before,\n  std::shared_ptr<Widget>(new Widget, cusDel),   // potential\n  computePriority()                              // resource\n);                                               // leak!\nRecall: if computePriority is called after “new Widget” but before the\nstd::shared_ptr constructor, and if computePriority yields an exception, the\ndynamically allocated Widget will be leaked.\nHere the use of a custom deleter precludes use of std::make_shared, so the way to\navoid the problem is to put the allocation of the Widget and the construction of the\nstd::shared_ptr into their own statement, then call processWidget with the\nresulting std::shared_ptr. Here’s the essence of the technique, though, as we’ll see\nin a moment, we can tweak it to improve its performance:\nstd::shared_ptr<Widget> spw(new Widget, cusDel);\nprocessWidget(spw, computePriority());     // correct, but not\n                                           // optimal; see below\nThis works, because a std::shared_ptr assumes ownership of the raw pointer\npassed to its constructor, even if that constructor yields an exception. In this example,\nif spw’s constructor throws an exception (e.g., due to an inability to dynamically allo‐\ncate memory for a control block), it’s still guaranteed that cusDel will be invoked on\nthe pointer resulting from “new Widget”.\nThe minor performance hitch is that in the exception-unsafe call, we’re passing an\nrvalue to processWidget,\n146 \n| \nItem 21\nwww.it-ebooks.info\n\n\nprocessWidget(\n  std::shared_ptr<Widget>(new Widget, cusDel),  // arg is rvalue\n  computePriority()\n);\nbut in the exception-safe call, we’re passing an lvalue:\nprocessWidget(spw, computePriority());          // arg is lvalue\nBecause processWidget’s std::shared_ptr parameter is passed by value, construc‐\ntion from an rvalue entails only a move, while construction from an lvalue requires a\ncopy. For std::shared_ptr, the difference can be significant, because copying a\nstd::shared_ptr requires an atomic increment of its reference count, while moving\na std::shared_ptr requires no reference count manipulation at all. For the\nexception-safe code to achieve the level of performance of the exception-unsafe code,\nwe need to apply std::move to spw to turn it into an rvalue (see Item 23):\nprocessWidget(std::move(spw),            // both efficient and\n              computePriority());        // exception safe\nThat’s interesting and worth knowing, but it’s also typically irrelevant, because you’ll\nrarely have a reason not to use a make function. And unless you have a compelling\nreason for doing otherwise, using a make function is what you should do.\nThings to Remember\n• Compared to direct use of new, make functions eliminate source code duplica‐\ntion, improve exception safety, and, for std::make_shared and std::allo\ncate_shared, generate code that’s smaller and faster.\n• Situations where use of make functions is inappropriate include the need to\nspecify custom deleters and a desire to pass braced initializers.\n• For std::shared_ptrs, additional situations where make functions may be\nill-advised include (1) classes with custom memory management and (2) sys‐\ntems with memory concerns, very large objects, and std::weak_ptrs that\noutlive the corresponding std::shared_ptrs.\nItem 22: When using the Pimpl Idiom, define special\nmember functions in the implementation file.\nIf you’ve ever had to combat excessive build times, you’re familiar with the Pimpl\n(“pointer to implementation”) Idiom. That’s the technique whereby you replace the\ndata members of a class with a pointer to an implementation class (or struct), put the\nItem 21 \n| \n147\nwww.it-ebooks.info\n\n\ndata members that used to be in the primary class into the implementation class, and\naccess those data members indirectly through the pointer. For example, suppose\nWidget looks like  this:\nclass Widget {                     // in header \"widget.h\"\npublic:\n  Widget();\n  …\nprivate:\n  std::string name;\n  std::vector<double> data;\n  Gadget g1, g2, g3;               // Gadget is some user-\n};                                 // defined type\nBecause Widget’s data members are of types std::string, std::vector, and\nGadget, headers for those types must be present for Widget to compile, and that\nmeans that Widget clients must #include <string>, <vector>, and gadget.h.\nThose headers increase the compilation time for Widget clients, plus they make those\nclients dependent on the contents of the headers. If a header’s content changes,\nWidget clients must recompile. The standard headers <string> and <vector> don’t\nchange very often, but it could be that gadget.h is subject to frequent revision.\nApplying the Pimpl Idiom in C++98 could have Widget replace its data members\nwith a raw pointer to a struct that has been declared, but not defined:\nclass Widget {                 // still in header \"widget.h\"\npublic:\n  Widget();\n  ~Widget();                   // dtor is needed—see below\n  …\nprivate:\n  struct Impl;                 // declare implementation struct\n  Impl *pImpl;                 // and pointer to it\n};\nBecause Widget no longer mentions the types std::string, std::vector, and\nGadget, Widget clients no longer need to #include the headers for these types. That\nspeeds compilation, and it also means that if something in these headers changes,\nWidget clients are unaffected.\nA type that has been declared, but not defined, is known as an incomplete type.\nWidget::Impl is such a type. There are very few things you can do with an incom‐\nplete type, but declaring a pointer to it is one of them. The Pimpl Idiom takes advan‐\ntage of that.\n148 \n| \nItem 22\nwww.it-ebooks.info\n\n\nPart 1 of the Pimpl Idiom is the declaration of a data member that’s a pointer to an\nincomplete type. Part 2 is the dynamic allocation and deallocation of the object that\nholds the data members that used to be in the original class. The allocation and deal‐\nlocation code goes in the implementation file, e.g., for Widget, in widget.cpp:\n#include \"widget.h\"            // in impl. file \"widget.cpp\"\n#include \"gadget.h\"\n#include <string>\n#include <vector>\nstruct Widget::Impl {          // definition of Widget::Impl\n  std::string name;            // with data members formerly\n  std::vector<double> data;    // in Widget\n  Gadget g1, g2, g3;\n};\nWidget::Widget()               // allocate data members for\n: pImpl(new Impl)              // this Widget object\n{}\nWidget::~Widget()              // destroy data members for\n{ delete pImpl; }              // this object\nHere I’m showing #include directives to make clear that the overall dependencies on\nthe headers for std::string, std::vector, and Gadget continue to exist. However,\nthese dependencies have been moved from widget.h (which is visible to and used by\nWidget clients) to widget.cpp (which is visible to and used only by the Widget\nimplementer). I’ve also highlighted the code that dynamically allocates and deallo‐\ncates the Impl object. The need to deallocate this object when a Widget is destroyed\nis what necessitates the Widget destructor.\nBut I’ve shown you C++98 code, and that reeks of a bygone millennium. It uses raw\npointers and raw new and raw delete and it’s all just so…raw. This chapter is built\non the idea that smart pointers are preferable to raw pointers, and if what we want is\nto dynamically allocate a Widget::Impl object inside the Widget constructor and\nhave it destroyed at the same time the Widget is, std::unique_ptr (see Item 18) is\nprecisely the tool we need. Replacing the raw pImpl pointer with a std::unique_ptr\nyields this code for the header file,\nclass Widget {                      // in \"widget.h\"\npublic:\n  Widget();\n  …\nprivate:\nItem 22 \n| \n149\nwww.it-ebooks.info\n\n\n  struct Impl; \n  std::unique_ptr<Impl> pImpl;      // use smart pointer\n};                                  // instead of raw pointer\nand this for the implementation file:\n#include \"widget.h\"                 // in \"widget.cpp\"\n#include \"gadget.h\"\n#include <string>\n#include <vector>\nstruct Widget::Impl {               // as before\n  std::string name;\n  std::vector<double> data;\n  Gadget g1, g2, g3;\n};\nWidget::Widget()                    // per Item 21, create\n: pImpl(std::make_unique<Impl>())   // std::unique_ptr\n{}                                  // via std::make_unique\nYou’ll note that the Widget destructor is no longer present. That’s because we have\nno code to put into it. std::unique_ptr automatically deletes what it points to when\nit (the std::unique_ptr) is destroyed, so we need not delete anything ourselves.\nThat’s one of the attractions of smart pointers: they eliminate the need for us to sully\nour hands with manual resource release.\nThis code compiles, but, alas, the most trivial client use doesn’t:\n#include \"widget.h\"\nWidget w;                           // error!\nThe error message you receive depends on the compiler you’re using, but the text\ngenerally mentions something about applying sizeof or delete to an incomplete\ntype. Those operations aren’t among the things you can do with such types.\nThis apparent failure of the Pimpl Idiom using std::unique_ptrs is alarming,\nbecause (1) std::unique_ptr is advertised as supporting incomplete types, and (2)\nthe Pimpl Idiom is one of std::unique_ptrs most common use cases. Fortunately,\ngetting the code to work is easy. All that’s required is a basic understanding of the\ncause of the problem.\nThe issue arises due to the code that’s generated when w is destroyed (e.g., goes out of\nscope). At that point, its destructor is called. In the class definition using\nstd::unique_ptr, we didn’t declare a destructor, because we didn’t have any code to\nput into it. In accord with the usual rules for compiler-generated special member\n150 \n| \nItem 22\nwww.it-ebooks.info\n\n\nfunctions (see Item 17), the compiler generates a destructor for us. Within that\ndestructor, the compiler inserts code to call the destructor for Widget’s data member\npImpl. pImpl is a std::unique_ptr<Widget::Impl>, i.e., a std::unique_ptr\nusing the default deleter. The default deleter is a function that uses delete on the raw\npointer inside the std::unique_ptr. Prior to using delete, however, implementa‐\ntions typically have the default deleter employ C++11’s static_assert to ensure \nthat the raw pointer doesn’t point to an incomplete type. When the compiler gener‐\nates code for the destruction of the Widget w, then, it generally encounters a\nstatic_assert that fails, and that’s usually what leads to the error message. This\nmessage is associated with the point where w is destroyed, because Widget’s destruc‐\ntor, like all compiler-generated special member functions, is implicitly inline. The\nmessage itself often refers to the line where w is created, because it’s the source code\nexplicitly creating the object that leads to its later implicit destruction.\nTo fix the problem, you just need to make sure that at the point where the code to\ndestroy the std::unique_ptr<Widget::Impl> is generated, Widget::Impl is a\ncomplete type. The type becomes complete when its definition has been seen, and\nWidget::Impl is defined inside widget.cpp. The key to successful compilation,\nthen, is to have the compiler see the body of Widget’s destructor (i.e., the place where\nthe compiler will generate code to destroy the std::unique_ptr data member) only\ninside widget.cpp after Widget::Impl has been defined.\nArranging for that is simple. Declare Widget’s destructor in widget.h, but don’t\ndefine it there:\nclass Widget {                     // as before, in \"widget.h\"\npublic:\n  Widget();\n  ~Widget();                       // declaration only\n  …\nprivate:                           // as before\n  struct Impl;\n  std::unique_ptr<Impl> pImpl;\n};\nDefine it in widget.cpp after Widget::Impl has been defined:\n#include \"widget.h\"                // as before, in \"widget.cpp\"\n#include \"gadget.h\"\n#include <string>\n#include <vector>\n  struct Widget::Impl {            // as before, definition of\nItem 22 \n| \n151\nwww.it-ebooks.info\n\n\n  std::string name;                // Widget::Impl\n  std::vector<double> data;\n  Gadget g1, g2, g3;\n};\nWidget::Widget()                   // as before\n: pImpl(std::make_unique<Impl>())\n{}\nWidget::~Widget()                  // ~Widget definition\n{}\nThis works well, and it requires the least typing, but if you want to emphasize that the\ncompiler-generated destructor would do the right thing—that the only reason you\ndeclared it was to cause its definition to be generated in Widget’s implementation\nfile, you can define the destructor body with “= default”:\nWidget::~Widget() = default;       // same effect as above\nClasses using the Pimpl Idiom are natural candidates for move support, because\ncompiler-generated move operations do exactly what’s desired: perform a move on\nthe underlying std::unique_ptr. As Item 17 explains, the declaration of a destruc‐\ntor in Widget prevents compilers from generating the move operations, so if you\nwant move support, you must declare the functions yourself. Given that the\ncompiler-generated versions would behave correctly, you’re likely to be tempted to\nimplement them as follows:\nclass Widget {                                 // still in\npublic:                                        // \"widget.h\"\n  Widget();\n  ~Widget();\n  Widget(Widget&& rhs) = default;              // right idea,\n  Widget& operator=(Widget&& rhs) = default;   // wrong code!\n \n  …\nprivate:                                       // as before\n  struct Impl;\n  std::unique_ptr<Impl> pImpl;\n};\nThis approach leads to the same kind of problem as declaring the class without a\ndestructor, and for the same fundamental reason. The compiler-generated move\nassignment operator needs to destroy the object pointed to by pImpl before reassign‐\ning it, but in the Widget header file, pImpl points to an incomplete type. The situa‐\n152 \n| \nItem 22\nwww.it-ebooks.info\n\n\ntion is different for the move constructor. The problem there is that compilers\ntypically generate code to destroy pImpl in the event that an exception arises inside\nthe move constructor, and destroying pImpl requires that Impl be complete.\nBecause the problem is the same as before, so is the fix—move the definition of the\nmove operations into the implementation file:\nclass Widget {                       // still in \"widget.h\"\npublic:\n  Widget();\n  ~Widget();\n  Widget(Widget&& rhs);              // declarations\n  Widget& operator=(Widget&& rhs);   // only\n  …\nprivate:                             // as before\n  struct Impl;\n  std::unique_ptr<Impl> pImpl;\n};\n#include <string>                    // as before,\n…                                    // in \"widget.cpp\"\nstruct Widget::Impl { … };           // as before\nWidget::Widget()                     // as before\n: pImpl(std::make_unique<Impl>())\n{}\nWidget::~Widget() = default;         // as before\nWidget::Widget(Widget&& rhs) = default;              // defini-\nWidget& Widget::operator=(Widget&& rhs) = default;   // tions\nThe Pimpl Idiom is a way to reduce compilation dependencies between a class’s\nimplementation and the class’s clients, but, conceptually, use of the idiom doesn’t\nchange what the class represents. The original Widget class contained std::string,\nstd::vector, and Gadget data members, and, assuming that Gadgets, like\nstd::strings and std::vectors, can be copied, it would make sense for Widget to\nsupport the copy operations. We have to write these functions ourselves, because (1)\ncompilers won’t generate copy operations for classes with move-only types like\nstd::unique_ptr and (2) even if they did, the generated functions would copy only\nItem 22 \n| \n153\nwww.it-ebooks.info\n\n\nthe std::unique_ptr (i.e., perform a shallow copy), and we want to copy what the\npointer points to (i.e., perform a deep copy).\nIn a ritual that is by now familiar, we declare the functions in the header file and\nimplement them in the implementation file:\nclass Widget {                         // still in \"widget.h\"\npublic:\n  …                                    // other funcs, as before\n  Widget(const Widget& rhs);              // declarations\n  Widget& operator=(const Widget& rhs);   // only\nprivate:                                  // as before\n  struct Impl;\n  std::unique_ptr<Impl> pImpl;\n};\n#include \"widget.h\"                  // as before,\n…                                    // in \"widget.cpp\"\nstruct Widget::Impl { … };           // as before\nWidget::~Widget() = default;         // other funcs, as before\nWidget::Widget(const Widget& rhs)              // copy ctor\n: pImpl(std::make_unique<Impl>(*rhs.pImpl))\n{}\nWidget& Widget::operator=(const Widget& rhs)   // copy operator=\n{\n  *pImpl = *rhs.pImpl;\n  return *this;\n}\nBoth function implementations are conventional. In each case, we simply copy the\nfields of the Impl struct from the source object (rhs) to the destination object\n(*this). Rather than copy the fields one by one, we take advantage of the fact that\ncompilers will create the copy operations for Impl, and these operations will copy\neach field automatically. We thus implement Widget’s copy operations by calling\nWidget::Impl’s compiler-generated copy operations. In the copy constructor, note\nthat we still follow the advice of Item 21 to prefer use of std::make_unique over\ndirect use of new.\n154 \n| \nItem 22\nwww.it-ebooks.info\n\n\nFor purposes of implementing the Pimpl Idiom, std::unique_ptr is the smart\npointer to use, because the pImpl pointer inside an object (e.g., inside a Widget) has\nexclusive ownership of the corresponding implementation object (e.g., the\nWidget::Impl object). Still, it’s interesting to note that if we were to use\nstd::shared_ptr instead of std::unique_ptr for pImpl, we’d find that the advice\nof this Item no longer applied. There’d be no need to declare a destructor in Widget,\nand without a user-declared destructor, compilers would happily generate the move\noperations, which would do exactly what we’d want them to. That is, given this code\nin widget.h,\nclass Widget {                     // in \"widget.h\"\npublic:\n  Widget();\n  …                                // no declarations for dtor\n                                   // or move operations\nprivate:\n  struct Impl; \n  std::shared_ptr<Impl> pImpl;     // std::shared_ptr\n};                                 // instead of std::unique_ptr\nand this client code that #includes widget.h,\nWidget w1;\nauto w2(std::move(w1));            // move-construct w2\nw1 = std::move(w2);                // move-assign w1\neverything would compile and run as we’d hope: w1 would be default constructed, its\nvalue would be moved into w2, that value would be moved back into w1, and then\nboth w1 and w2 would be destroyed (thus causing the pointed-to Widget::Impl\nobject to be destroyed).\nThe difference in behavior between std::unique_ptr and std::shared_ptr for\npImpl pointers stems from the differing ways these smart pointers support custom\ndeleters. For std::unique_ptr, the type of the deleter is part of the type of the smart\npointer, and this makes it possible for compilers to generate smaller runtime data\nstructures and faster runtime code. A consequence of this greater efficiency is that\npointed-to types must be complete when compiler-generated special functions (e.g.,\ndestructors or move operations) are used. For std::shared_ptr, the type of the\ndeleter is not part of the type of the smart pointer. This necessitates larger runtime\ndata structures and somewhat slower code, but pointed-to types need not be com‐\nplete when compiler-generated special functions are employed.\nItem 22 \n| \n155\nwww.it-ebooks.info\n\n\nFor the Pimpl Idiom, there’s not really a trade-off between the characteristics of\nstd::unique_ptr and std::shared_ptr, because the relationship between classes\nlike Widget and classes like Widget::Impl is exclusive ownership, and that makes\nstd::unique_ptr the proper tool for the job. Nevertheless, it’s worth knowing that\nin \nother \nsituations—situations \nwhere \nshared \nownership \nexists \n(and\nstd::shared_ptr is hence a fitting design choice), there’s no need to jump through\nthe function-definition hoops that use of std::unique_ptr entails.\nThings to Remember\n• The Pimpl Idiom decreases build times by reducing compilation dependencies\nbetween class clients and class implementations.\n• For std::unique_ptr pImpl pointers, declare special member functions in\nthe class header, but implement them in the implementation file. Do this even\nif the default function implementations are acceptable.\n• The above advice applies to std::unique_ptr, but not to std::shared_ptr.\n156 \n| \nItem 22\nwww.it-ebooks.info\n",
      "page_number": 162,
      "chapter_number": 16,
      "summary": "This chapter covers segment 16 (pages 162-174). Key topics include widget, code. Some classes define their own versions of operator new and operator delete.",
      "keywords": [
        "Widget",
        "std",
        "Impl",
        "ptr",
        "class Widget",
        "Pimpl Idiom",
        "Pimpl",
        "shared",
        "Item",
        "Widget clients",
        "unique",
        "struct Widget",
        "object",
        "struct Impl",
        "Impl std"
      ],
      "concepts": [
        "widget",
        "std",
        "code",
        "objects",
        "compilers",
        "compile",
        "uses",
        "include",
        "item",
        "generation"
      ],
      "similar_chapters": [
        {
          "book": "More Effective C++",
          "chapter": 32,
          "title": "Segment 32 (pages 320-329)",
          "relevance_score": 0.69,
          "method": "sentence_transformers"
        },
        {
          "book": "More Effective C++",
          "chapter": 4,
          "title": "Segment 4 (pages 25-32)",
          "relevance_score": 0.68,
          "method": "sentence_transformers"
        },
        {
          "book": "More Effective C++",
          "chapter": 33,
          "title": "Segment 33 (pages 330-335)",
          "relevance_score": 0.68,
          "method": "sentence_transformers"
        },
        {
          "book": "More Effective C++",
          "chapter": 23,
          "title": "Segment 23 (pages 224-233)",
          "relevance_score": 0.65,
          "method": "sentence_transformers"
        },
        {
          "book": "C++ Templates_ The Complete Guide",
          "chapter": 32,
          "title": "Segment 32 (pages 1015-1044)",
          "relevance_score": 0.64,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 17,
      "title": "Segment 17 (pages 175-189)",
      "start_page": 175,
      "end_page": 189,
      "detection_method": "topic_boundary",
      "content": "CHAPTER 5\nRvalue References, Move Semantics,\nand Perfect Forwarding\nWhen you first learn about them, move semantics and perfect forwarding seem\npretty straightforward:\n• Move semantics makes it possible for compilers to replace expensive copying\noperations with less expensive moves. In the same way that copy constructors\nand copy assignment operators give you control over what it means to copy\nobjects, move constructors and move assignment operators offer control over the\nsemantics of moving. Move semantics also enables the creation of move-only\ntypes, such as std::unique_ptr, std::future, and std::thread.\n• Perfect forwarding makes it possible to write function templates that take arbi‐\ntrary arguments and forward them to other functions such that the target func‐\ntions receive exactly the same arguments as were passed to the forwarding\nfunctions.\nRvalue references are the glue that ties these two rather disparate features together.\nThey’re the underlying language mechanism that makes both move semantics and\nperfect forwarding possible.\nThe more experience you have with these features, the more you realize that your ini‐\ntial impression was based on only the metaphorical tip of the proverbial iceberg. The\nworld of move semantics, perfect forwarding, and rvalue references is more nuanced\nthan it appears. std::move doesn’t move anything, for example, and perfect forward‐\ning is imperfect. Move operations aren’t always cheaper than copying; when they are,\nthey’re not always as cheap as you’d expect; and they’re not always called in a context\nwhere moving is valid. The construct “type&&” doesn’t always represent an rvalue\nreference.\n157\nwww.it-ebooks.info\n\n\nNo matter how far you dig into these features, it can seem that there’s always more to\nuncover. Fortunately, there is a limit to their depths. This chapter will take you to the\nbedrock. Once you arrive, this part of C++11 will make a lot more sense. You’ll know\nthe usage conventions for std::move and std::forward, for example. You’ll be\ncomfortable with the ambiguous nature of “type&&”. You’ll understand the reasons\nfor the surprisingly varied behavioral profiles of move operations. All those pieces\nwill fall into place. At that point, you’ll be back where you started, because move\nsemantics, perfect forwarding, and rvalue references will once again seem pretty\nstraightforward. But this time, they’ll stay that way.\nIn the Items in this chapter, it’s especially important to bear in mind that a parameter\nis always an lvalue, even if its type is an rvalue reference. That is, given\nvoid f(Widget&& w);\nthe parameter w is an lvalue, even though its type is rvalue-reference-to-Widget. (If\nthis surprises you, please review the overview of lvalues and rvalues that begins on\npage 2.)\nItem 23: Understand std::move and std::forward.\nIt’s useful to approach std::move and std::forward in terms of what they don’t do.\nstd::move doesn’t move anything. std::forward doesn’t forward anything. At run‐\ntime, neither does anything at all. They generate no executable code. Not a single\nbyte.\nstd::move and std::forward are merely functions (actually function templates)\nthat perform casts. std::move unconditionally casts its argument to an rvalue, while\nstd::forward performs this cast only if a particular condition is fulfilled. That’s it.\nThe explanation leads to a new set of questions, but, fundamentally, that’s the com‐\nplete story.\nTo make the story more concrete, here’s a sample implementation of std::move in\nC++11. It’s not fully conforming to the details of the Standard, but it’s very close.\ntemplate<typename T>                       // in namespace std\ntypename remove_reference<T>::type&&\nmove(T&& param)\n{\n  using ReturnType =                       // alias declaration;\n    typename remove_reference<T>::type&&;  // see Item 9\n  return static_cast<ReturnType>(param);\n}\n158 \n| \nItem 22\nwww.it-ebooks.info\n\n\nI’ve highlighted two parts of the code for you. One is the name of the function,\nbecause the return type specification is rather noisy, and I don’t want you to lose your\nbearings in the din. The other is the cast that comprises the essence of the function.\nAs you can see, std::move takes a reference to an object (a universal reference, to be\nprecise—see Item 24) and it returns a reference to the same object.\nThe “&&” part of the function’s return type implies that std::move returns an rvalue\nreference, but, as Item 28 explains, if the type T happens to be an lvalue reference, T&&\nwould become an lvalue reference. To prevent this from happening, the type trait (see\nItem 9) std::remove_reference is applied to T, thus ensuring that “&&” is applied\nto a type that isn’t a reference. That guarantees that std::move truly returns an\nrvalue reference, and that’s important, because rvalue references returned from func‐\ntions are rvalues. Thus, std::move casts its argument to an rvalue, and that’s all it\ndoes.\nAs an aside, std::move can be implemented with less fuss in C++14. Thanks to func‐\ntion return type deduction (see Item 3) and to the Standard Library’s alias template\nstd::remove_reference_t (see Item 9), std::move can be written this way:\ntemplate<typename T>                          // C++14; still in\ndecltype(auto) move(T&& param)                // namespace std\n{\n  using ReturnType = remove_reference_t<T>&&;\n  return static_cast<ReturnType>(param);\n}\nEasier on the eyes, no?\nBecause std::move does nothing but cast its argument to an rvalue, there have been\nsuggestions that a better name for it might have been something like rvalue_cast.\nBe that as it may, the name we have is std::move, so it’s important to remember\nwhat std::move does and doesn’t do. It does cast. It doesn’t move.\nOf course, rvalues are candidates for moving, so applying std::move to an object\ntells the compiler that the object is eligible to be moved from. That’s why std::move\nhas the name it does: to make it easy to designate objects that may be moved from.\nIn truth, rvalues are only usually candidates for moving. Suppose you’re writing a\nclass representing annotations. The class’s constructor takes a std::string parame‐\nter comprising the annotation, and it copies the parameter to a data member. Flush\nwith the information in Item 41, you declare a by-value parameter:\nclass Annotation {\npublic:\n  explicit Annotation(std::string text);  // param to be copied,\nItem 23 \n| \n159\nwww.it-ebooks.info\n\n\n  …                                       // so per Item 41,\n};                                        // pass by value\nBut Annotation’s constructor needs only to read text’s value. It doesn’t need to\nmodify it. In accord with the time-honored tradition of using const whenever possi‐\nble, you revise your declaration such that text is const:\nclass Annotation {\npublic:\n  explicit Annotation(const std::string text)\n  …\n};\nTo avoid paying for a copy operation when copying text into a data member, you\nremain true to the advice of Item 41 and apply std::move to text, thus producing\nan rvalue:\nclass Annotation {\npublic:\n  explicit Annotation(const std::string text)\n  : value(std::move(text))  // \"move\" text into value; this code\n  { … }                     // doesn't do what it seems to!\n  \n  …\nprivate:\n  std::string value;\n};\nThis code compiles. This code links. This code runs. This code sets the data member\nvalue to the content of text. The only thing separating this code from a perfect real‐\nization of your vision is that text is not moved into value, it’s copied. Sure, text is\ncast to an rvalue by std::move, but text is declared to be a const std::string, so\nbefore the cast, text is an lvalue const std::string, and the result of the cast is an\nrvalue const std::string, but throughout it all, the constness remains.\nConsider the effect that has when compilers have to determine which std::string\nconstructor to call. There are two possibilities:\nclass string {            // std::string is actually a \npublic:                   // typedef for std::basic_string<char>\n  …\n  string(const string& rhs);    // copy ctor\n  string(string&& rhs);         // move ctor\n  …\n};\n160 \n| \nItem 23\nwww.it-ebooks.info\n\n\nIn the Annotation constructor’s member initialization list, the result of\nstd::move(text) is an rvalue of type const std::string. That rvalue can’t be\npassed to std::string’s move constructor, because the move constructor takes an\nrvalue reference to a non-const std::string. The rvalue can, however, be passed to\nthe copy constructor, because an lvalue-reference-to-const is permitted to bind to a\nconst rvalue. The member initialization therefore invokes the copy constructor in\nstd::string, even though text has been cast to an rvalue! Such behavior is essential\nto maintaining const-correctness. Moving a value out of an object generally modifies\nthe object, so the language should not permit const objects to be passed to functions\n(such as move constructors) that could modify them.\nThere are two lessons to be drawn from this example. First, don’t declare objects\nconst if you want to be able to move from them. Move requests on const objects are\nsilently transformed into copy operations. Second, std::move not only doesn’t\nactually move anything, it doesn’t even guarantee that the object it’s casting will be\neligible to be moved. The only thing you know for sure about the result of applying\nstd::move to an object is that it’s an rvalue.\nThe story for std::forward is similar to that for std::move, but whereas\nstd::move unconditionally casts its argument to an rvalue, std::forward does it\nonly under certain conditions. std::forward is a conditional cast. To understand\nwhen it casts and when it doesn’t, recall how std::forward is typically used. The\nmost common scenario is a function template taking a universal reference parameter\nthat is to be passed to another function:\nvoid process(const Widget& lvalArg);     // process lvalues\nvoid process(Widget&& rvalArg);          // process rvalues\ntemplate<typename T>                     // template that passes\nvoid logAndProcess(T&& param)            // param to process\n{\n  auto now =                             // get current time\n    std::chrono::system_clock::now();\n  makeLogEntry(\"Calling 'process'\", now);\n  process(std::forward<T>(param));\n}\nConsider two calls to logAndProcess, one with an lvalue, the other with an rvalue:\nWidget w;\nlogAndProcess(w);                  // call with lvalue\nlogAndProcess(std::move(w));       // call with rvalue\nItem 23 \n| \n161\nwww.it-ebooks.info\n\n\nInside logAndProcess, the parameter param is passed to the function process. pro\ncess is overloaded for lvalues and rvalues. When we call logAndProcess with an\nlvalue, we naturally expect that lvalue to be forwarded to process as an lvalue, and\nwhen we call logAndProcess with an rvalue, we expect the rvalue overload of pro\ncess to be invoked.\nBut param, like all function parameters, is an lvalue. Every call to process inside\nlogAndProcess will thus want to invoke the lvalue overload for process. To prevent\nthis, we need a mechanism for param to be cast to an rvalue if and only if the argu‐\nment with which param was initialized—the argument passed to logAndProcess—\nwas an rvalue. This is precisely what std::forward does. That’s why std::forward\nis a conditional cast: it casts to an rvalue only if its argument was initialized with an\nrvalue.\nYou may wonder how std::forward can know whether its argument was initialized\nwith an rvalue. In the code above, for example, how can std::forward tell whether\nparam was initialized with an lvalue or an rvalue? The brief answer is that that infor‐\nmation is encoded in logAndProcess’s template parameter T. That parameter is\npassed to std::forward, which recovers the encoded information. For details on\nexactly how that works, consult Item 28.\nGiven that both std::move and std::forward boil down to casts, the only differ‐\nence being that std::move always casts, while std::forward only sometimes does,\nyou might ask whether we can dispense with std::move and just use std::forward\neverywhere. From a purely technical perspective, the answer is yes: std::forward\ncan do it all. std::move isn’t necessary. Of course, neither function is really neces‐\nsary, because we could write casts everywhere, but I hope we agree that that would be,\nwell, yucky.\nstd::move’s attractions are convenience, reduced likelihood of error, and greater\nclarity. Consider a class where we want to track how many times the move construc‐\ntor is called. A static counter that’s incremented during move construction is all we\nneed. Assuming the only non-static data in the class is a std::string, here’s the\nconventional way (i.e., using std::move) to implement the move constructor:\nclass Widget {\npublic:\n  Widget(Widget&& rhs)\n  : s(std::move(rhs.s))\n  { ++moveCtorCalls; }\n  …\n162 \n| \nItem 23\nwww.it-ebooks.info\n\n\nprivate:\n  static std::size_t moveCtorCalls;\n  std::string s;\n};\nTo implement the same behavior with std::forward, the code would look like this:\nclass Widget {\npublic:\n  Widget(Widget&& rhs)                      // unconventional,\n  : s(std::forward<std::string>(rhs.s))     // undesirable\n  { ++moveCtorCalls; }                      // implementation\n  …\n};\nNote first that std::move requires only a function argument (rhs.s), while\nstd::forward requires both a function argument (rhs.s) and a template type argu‐\nment (std::string). Then note that the type we pass to std::forward should be a\nnon-reference, because that’s the convention for encoding that the argument being\npassed is an rvalue (see Item 28). Together, this means that std::move requires less\ntyping than std::forward, and it spares us the trouble of passing a type argument\nthat encodes that the argument we’re passing is an rvalue. It also eliminates the possi‐\nbility of our passing an incorrect type (e.g., std::string&, which would result in the\ndata member s being copy constructed instead of move constructed).\nMore importantly, the use of std::move conveys an unconditional cast to an rvalue,\nwhile the use of std::forward indicates a cast to an rvalue only for references to\nwhich rvalues have been bound. Those are two very different actions. The first one\ntypically sets up a move, while the second one just passes—forwards—an object to\nanother function in a way that retains its original lvalueness or rvalueness. Because\nthese actions are so different, it’s good that we have two different functions (and\nfunction names) to distinguish them.\nThings to Remember\n• std::move performs an unconditional cast to an rvalue. In and of itself, it\ndoesn’t move anything.\n• std::forward casts its argument to an rvalue only if that argument is bound\nto an rvalue.\n• Neither std::move nor std::forward do anything at runtime.\nItem 23 \n| \n163\nwww.it-ebooks.info\n\n\n1 Item 25 explains that universal references should almost always have std::forward applied to them, and as\nthis book goes to press, some members of the C++ community have started referring to universal references\nas forwarding references.\nItem 24: Distinguish universal references from rvalue\nreferences.\nIt’s been said that the truth shall set you free, but under the right circumstances, a\nwell-chosen lie can be equally liberating. This Item is such a lie. Because we’re dealing\nwith software, however, let’s eschew the word “lie” and instead say that this Item\ncomprises an “abstraction.”  \nTo declare an rvalue reference to some type T, you write T&&. It thus seems reason‐\nable to assume that if you see “T&&” in source code, you’re looking at an rvalue refer‐\nence. Alas, it’s not quite that simple:\nvoid f(Widget&& param);             // rvalue reference\nWidget&& var1 = Widget();           // rvalue reference\nauto&& var2 = var1;                 // not rvalue reference\ntemplate<typename T>\nvoid f(std::vector<T>&& param);     // rvalue reference\ntemplate<typename T>\nvoid f(T&& param);                  // not rvalue reference\nIn fact, “T&&” has two different meanings. One is rvalue reference, of course. Such\nreferences behave exactly the way you expect: they bind only to rvalues, and their pri‐\nmary raison d’être is to identify objects that may be moved from.\nThe other meaning for “T&&” is either rvalue reference or lvalue reference. Such refer‐\nences look like rvalue references in the source code (i.e., “T&&”), but they can behave\nas if they were lvalue references (i.e., “T&”). Their dual nature permits them to bind to\nrvalues (like rvalue references) as well as lvalues (like lvalue references). Furthermore,\nthey can bind to const or non-const objects, to volatile or non-volatile objects,\neven to objects that are both const and volatile. They can bind to virtually any‐\nthing. Such unprecedentedly flexible references deserve a name of their own. I call\nthem universal references.1\nUniversal references arise in two contexts. The most common is function template\nparameters, such as this example from the sample code above:\n164 \n| \nItem 24\nwww.it-ebooks.info\n\n\ntemplate<typename T>\nvoid f(T&& param);             // param is a universal reference\nThe second context is auto declarations, including this one from the sample code\nabove:\nauto&& var2 = var1;            // var2 is a universal reference\nWhat these contexts have in common is the presence of type deduction. In the tem‐\nplate f, the type of param is being deduced, and in the declaration for var2, var2’s\ntype is being deduced. Compare that with the following examples (also from the sam‐\nple code above), where type deduction is missing. If you see “T&&” without type\ndeduction, you’re looking at an rvalue reference:\nvoid f(Widget&& param);        // no type deduction;\n                               // param is an rvalue reference\nWidget&& var1 = Widget();      // no type deduction;\n                               // var1 is an rvalue reference\nBecause universal references are references, they must be initialized. The initializer\nfor a universal reference determines whether it represents an rvalue reference or an\nlvalue reference. If the initializer is an rvalue, the universal reference corresponds to\nan rvalue reference. If the initializer is an lvalue, the universal reference corresponds\nto an lvalue reference. For universal references that are function parameters, the ini‐\ntializer is provided at the call site:\ntemplate<typename T>\nvoid f(T&& param);     // param is a universal reference\nWidget w;\nf(w);                  // lvalue passed to f; param's type is\n                       // Widget& (i.e., an lvalue reference)\nf(std::move(w));       // rvalue passed to f; param's type is\n                       // Widget&& (i.e., an rvalue reference)\nFor a reference to be universal, type deduction is necessary, but it’s not sufficient. The\nform of the reference declaration must also be correct, and that form is quite con‐\nstrained. It must be precisely “T&&”. Look again at this example from the sample code\nwe saw earlier:\ntemplate<typename T>\nvoid f(std::vector<T>&& param);  // param is an rvalue reference\nWhen f is invoked, the type T will be deduced (unless the caller explicitly specifies it,\nan edge case we’ll not concern ourselves with). But the form of param’s type declara‐\nItem 24 \n| \n165\nwww.it-ebooks.info\n\n\ntion isn’t “T&&”, it’s “std::vector<T>&&”. That rules out the possibility that param is\na universal reference. param is therefore an rvalue reference, something that your\ncompilers will be happy to confirm for you if you try to pass an lvalue to f:\nstd::vector<int> v;\nf(v);                             // error! can't bind lvalue to\n                                  // rvalue reference\nEven the simple presence of a const qualifier is enough to disqualify a reference from\nbeing universal:\ntemplate<typename T>\nvoid f(const T&& param);         // param is an rvalue reference\nIf you’re in a template and you see a function parameter of type “T&&”, you might\nthink you can assume that it’s a universal reference. You can’t. That’s because being\nin a template doesn’t guarantee the presence of type deduction. Consider this\npush_back member function in std::vector:\ntemplate<class T, class Allocator = allocator<T>>  // from C++\nclass vector {                                     // Standards\npublic:\n  void push_back(T&& x);\n  …\n};\npush_back’s parameter certainly has the right form for a universal reference, but\nthere’s no type deduction in this case. That’s because push_back can’t exist without a\nparticular vector instantiation for it to be part of, and the type of that instantiation\nfully determines the declaration for push_back. That is, saying\nstd::vector<Widget> v;\ncauses the std::vector template to be instantiated as follows:\nclass vector<Widget, allocator<Widget>> {\npublic:\n  void push_back(Widget&& x);               // rvalue reference\n  …\n};\nNow you can see clearly that push_back employs no type deduction. This push_back\nfor vector<T> (there are two—the function is overloaded) always declares a parame‐\nter of type rvalue-reference-to-T.\nIn contrast, the conceptually similar emplace_back member function in std::vec\ntor does employ type deduction:\n166 \n| \nItem 24\nwww.it-ebooks.info\n\n\ntemplate<class T, class Allocator = allocator<T>>  // still from\nclass vector {                                     // C++\npublic:                                            // Standards\n  template <class... Args>\n  void emplace_back(Args&&... args);\n  …\n};\nHere, the type parameter Args is independent of vector’s type parameter T, so Args\nmust be deduced each time emplace_back is called. (Okay, Args is really a parameter\npack, not a type parameter, but for purposes of this discussion, we can treat it as if it\nwere a type parameter.)\nThe fact that emplace_back’s type parameter is named Args, yet it’s still a universal\nreference, reinforces my earlier comment that it’s the form of a universal reference\nthat must be “T&&”. There’s no requirement that you use the name T. For example,\nthe following template takes a universal reference, because the form (“type&&”) is\nright, and param’s type will be deduced (again, excluding the corner case where the\ncaller explicitly specifies the type):\ntemplate<typename MyTemplateType>         // param is a\nvoid someFunc(MyTemplateType&& param);    // universal reference\nI remarked earlier that auto variables can also be universal references. To be more\nprecise, variables declared with the type auto&& are universal references, because type\ndeduction takes place and they have the correct form (“T&&”). auto universal refer‐\nences are not as common as universal references used for function template parame‐\nters, but they do crop up from time to time in C++11. They crop up a lot more in\nC++14, because C++14 lambda expressions may declare auto&& parameters. For\nexample, if you wanted to write a C++14 lambda to record the time taken in an arbi‐\ntrary function invocation, you could do this:\nauto timeFuncInvocation =\n  [](auto&& func, auto&&... params)               // C++14\n  {\n    start timer;\n    std::forward<decltype(func)>(func)(           // invoke func\n      std::forward<decltype(params)>(params)...   // on params\n      );                              \n    stop timer and record elapsed time;\n  };\nIf your reaction to the “std::forward<decltype(blah blah blah)>” code inside\nthe lambda is, “What the…?!”, that probably just means you haven’t yet read Item 33.\nDon’t worry about it. The important thing in this Item is the auto&& parameters that\nItem 24 \n| \n167\nwww.it-ebooks.info\n\n\nthe lambda declares. func is a universal reference that can be bound to any callable\nobject, lvalue or rvalue. args is zero or more universal references (i.e., a universal ref‐\nerence parameter pack) that can be bound to any number of objects of arbitrary\ntypes. The result, thanks to auto universal references, is that timeFuncInvocation\ncan time pretty much any function execution. (For information on the difference\nbetween “any” and “pretty much any,” turn to Item 30.)\nBear in mind that this entire Item—the foundation of universal references—is a lie…\ner, an “abstraction.” The underlying truth is known as reference collapsing, a topic to\nwhich Item 28 is dedicated. But the truth doesn’t make the abstraction any less useful.\nDistinguishing between rvalue references and universal references will help you read\nsource code more accurately (“Does that T&& I’m looking at bind to rvalues only or to\neverything?”), and it will avoid ambiguities when you communicate with your collea‐\ngues (“I’m using a universal reference here, not an rvalue reference…”). It will also\nallow you to make sense of Items 25 and 26, which rely on the distinction. So\nembrace the abstraction. Revel in it. Just as Newton’s laws of motion (which are tech‐\nnically incorrect) are typically just as useful as and easier to apply than Einstein’s\ntheory of general relativity (“the truth”), so is the notion of universal references nor‐\nmally preferable to working through the details of reference collapsing.\nThings to Remember\n• If a function template parameter has type T&& for a deduced type T, or if an\nobject is declared using auto&&, the parameter or object is a universal refer‐\nence.\n• If the form of the type declaration isn’t precisely type&&, or if type deduction\ndoes not occur, type&& denotes an rvalue reference.\n• Universal references correspond to rvalue references if they’re initialized with\nrvalues. They correspond to lvalue references if they’re initialized with lval‐\nues.  \nItem 25: Use std::move on rvalue references,\nstd::forward on universal references.\nRvalue references bind only to objects that are candidates for moving. If you have an\nrvalue reference parameter, you know that the object it’s bound to may be moved:\nclass Widget {\n  Widget(Widget&& rhs);        // rhs definitely refers to an\n168 \n| \nItem 24\nwww.it-ebooks.info\n\n\n  …                            // object eligible for moving\n};\nThat being the case, you’ll want to pass such objects to other functions in a way that\npermits those functions to take advantage of the object’s rvalueness. The way to do\nthat is to cast parameters bound to such objects to rvalues. As Item 23 explains, that’s\nnot only what std::move does, it’s what it was created for:\nclass Widget {\npublic:\n  Widget(Widget&& rhs)               // rhs is rvalue reference\n  : name(std::move(rhs.name)),\n    p(std::move(rhs.p))\n    { … }\n  …\nprivate:\n  std::string name;\n  std::shared_ptr<SomeDataStructure> p;\n};\nA universal reference, on the other hand (see Item 24), might be bound to an object\nthat’s eligible for moving. Universal references should be cast to rvalues only if they\nwere initialized with rvalues. Item 23 explains that this is precisely what std::for\nward does:\nclass Widget {\npublic:\n  template<typename T>\n  void setName(T&& newName)               // newName is\n  { name = std::forward<T>(newName); }    // universal reference\n  …\n};\nIn short, rvalue references should be unconditionally cast to rvalues (via std::move)\nwhen forwarding them to other functions, because they’re always bound to rvalues,\nand universal references should be conditionally cast to rvalues (via std::forward)\nwhen forwarding them, because they’re only sometimes bound to rvalues.\nItem 23 explains that using std::forward on rvalue references can be made to\nexhibit the proper behavior, but the source code is wordy, error-prone, and unidio‐\nmatic, so you should avoid using std::forward with rvalue references. Even worse is\nthe idea of using std::move with universal references, because that can have the\neffect of unexpectedly modifying lvalues (e.g., local variables):\nItem 25 \n| \n169\nwww.it-ebooks.info\n\n\nclass Widget {\npublic:\n  template<typename T>\n  void setName(T&& newName)         // universal reference\n  { name = std::move(newName); }    // compiles, but is\n  …                                 // bad, bad, bad!\nprivate:\n  std::string name;\n  std::shared_ptr<SomeDataStructure> p;\n};\nstd::string getWidgetName();        // factory function\nWidget w;\nauto n = getWidgetName();           // n is local variable\nw.setName(n);                       // moves n into w!\n…                                   // n's value now unknown\nHere, the local variable n is passed to w.setName, which the caller can be forgiven for\nassuming is a read-only operation on n. But because setName internally uses\nstd::move to unconditionally cast its reference parameter to an rvalue, n’s value will\nbe moved into w.name, and n will come back from the call to setName with an unspe‐\ncified value. That’s the kind of behavior that can drive callers to despair—possibly to\nviolence.\nYou might argue that setName shouldn’t have declared its parameter to be a univer‐\nsal reference. Such references can’t be const (see Item 24), yet setName surely\nshouldn’t modify its parameter. You might point out that if setName had simply been\noverloaded for const lvalues and for rvalues, the whole problem could have been\navoided. Like this:\nclass Widget {\npublic:\n  void setName(const std::string& newName)      // set from\n  { name = newName; }                           // const lvalue\n  void setName(std::string&& newName)           // set from\n  { name = std::move(newName); }                // rvalue\n  …\n};\n170 \n| \nItem 25\nwww.it-ebooks.info\n\n\nThat would certainly work in this case, but there are drawbacks. First, it’s more\nsource code to write and maintain (two functions instead of a single template). Sec‐\nond, it can be less efficient. For example, consider this use of setName:\nw.setName(\"Adela Novak\");\nWith the version of setName taking a universal reference, the string literal \"Adela\nNovak\" would be passed to setName, where it would be conveyed to the assignment\noperator for the std::string inside w. w’s name data member would thus be assigned\ndirectly from the string literal; no temporary std::string objects would arise. With\nthe overloaded versions of setName, however, a temporary std::string object\nwould be created for setName’s parameter to bind to, and this temporary\nstd::string would then be moved into w’s data member. A call to setName would\nthus entail execution of one std::string constructor (to create the temporary), one\nstd::string move assignment operator (to move newName into w.name), and one\nstd::string destructor (to destroy the temporary). That’s almost certainly a more\nexpensive execution sequence than invoking only the std::string assignment oper‐\nator taking a const char* pointer. The additional cost is likely to vary from imple‐\nmentation to implementation, and whether that cost is worth worrying about will\nvary from application to application and library to library, but the fact is that replac‐\ning a template taking a universal reference with a pair of functions overloaded on\nlvalue references and rvalue references is likely to incur a runtime cost in some cases.\nIf we generalize the example such that Widget’s data member may be of an arbitrary\ntype (rather than knowing that it’s std::string), the performance gap can widen\nconsiderably, because not all types are as cheap to move as std::string (see\nItem 29).\nThe most serious problem with overloading on lvalues and rvalues, however, isn’t the\nvolume or idiomaticity of the source code, nor is it the code’s runtime performance.\nIt’s the poor scalability of the design. Widget::setName takes only one parameter, so\nonly two overloads are necessary, but for functions taking more parameters, each of\nwhich could be an lvalue or an rvalue, the number of overloads grows geometrically:\nn parameters necessitates 2n overloads. And that’s not the worst of it. Some functions\n—function templates, actually—take an unlimited number of parameters, each of\nwhich could be an lvalue or rvalue. The poster children for such functions are\nstd::make_shared, and, as of C++14, std::make_unique (see Item 21). Check out\nthe declarations of their most commonly used overloads:\ntemplate<class T, class... Args>                 // from C++11\nshared_ptr<T> make_shared(Args&&... args);       // Standard\ntemplate<class T, class... Args>                 // from C++14\nunique_ptr<T> make_unique(Args&&... args);       // Standard\nItem 25 \n| \n171\nwww.it-ebooks.info\n",
      "page_number": 175,
      "chapter_number": 17,
      "summary": "This chapter will take you to the\nbedrock Key topics include references, referring. In the same way that copy constructors\nand copy assignment operators give you control over what it means to copy\nobjects, move constructors and move assignment operators offer control over the\nsemantics of moving.",
      "keywords": [
        "rvalue reference",
        "std",
        "Rvalue",
        "reference",
        "Move",
        "Item",
        "universal reference",
        "Widget",
        "type",
        "universal",
        "string",
        "forward",
        "param",
        "lvalue",
        "template"
      ],
      "concepts": [
        "std",
        "references",
        "referring",
        "refer",
        "items",
        "types",
        "typing",
        "template",
        "functions",
        "forwarding"
      ],
      "similar_chapters": [
        {
          "book": "C++ Templates_ The Complete Guide",
          "chapter": 41,
          "title": "Segment 41 (pages 1309-1342)",
          "relevance_score": 0.68,
          "method": "sentence_transformers"
        },
        {
          "book": "More Effective C++",
          "chapter": 22,
          "title": "Segment 22 (pages 216-223)",
          "relevance_score": 0.61,
          "method": "sentence_transformers"
        },
        {
          "book": "Computer Systems A Programmer’s Perspective",
          "chapter": 35,
          "title": "Segment 35 (pages 703-721)",
          "relevance_score": 0.54,
          "method": "sentence_transformers"
        },
        {
          "book": "More Effective C++",
          "chapter": 4,
          "title": "Segment 4 (pages 25-32)",
          "relevance_score": 0.54,
          "method": "sentence_transformers"
        },
        {
          "book": "More Effective C++",
          "chapter": 31,
          "title": "Segment 31 (pages 312-319)",
          "relevance_score": 0.54,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 18,
      "title": "Segment 18 (pages 190-203)",
      "start_page": 190,
      "end_page": 203,
      "detection_method": "topic_boundary",
      "content": "For functions like these, overloading on lvalues and rvalues is not an option: univer‐\nsal references are the only way to go. And inside such functions, I assure you,\nstd::forward is applied to the universal reference parameters when they’re passed\nto other functions. Which is exactly what you should do.\nWell, usually. Eventually. But not necessarily initially. In some cases, you’ll want to\nuse the object bound to an rvalue reference or a universal reference more than once\nin a single function, and you’ll want to make sure that it’s not moved from until\nyou’re otherwise done with it. In that case, you’ll want to apply std::move (for rvalue\nreferences) or std::forward (for universal references) to only the final use of the\nreference. For example:\ntemplate<typename T>                       // text is\nvoid setSignText(T&& text)                 // univ. reference\n{\n  sign.setText(text);                      // use text, but\n                                           // don't modify it\n  auto now =                               // get current time\n    std::chrono::system_clock::now();\n    \n  signHistory.add(now,\n                  std::forward<T>(text));  // conditionally cast\n}                                          // text to rvalue\nHere, we want to make sure that text’s value doesn’t get changed by sign.setText,\nbecause we want to use that value when we call signHistory.add. Ergo the use of\nstd::forward on only the final use of the universal reference.\nFor std::move, the same thinking applies (i.e., apply std::move to an rvalue refer‐\nence the last time it’s used), but it’s important to note that in rare cases, you’ll want to\ncall std::move_if_noexcept instead of std::move. To learn when and why, consult\nItem 14.\nIf you’re in a function that returns by value, and you’re returning an object bound to\nan rvalue reference or a universal reference, you’ll want to apply std::move or\nstd::forward when you return the reference. To see why, consider an operator+\nfunction to add two matrices together, where the left-hand matrix is known to be an\nrvalue (and can hence have its storage reused to hold the sum of the matrices):\nMatrix                                        // by-value return\noperator+(Matrix&& lhs, const Matrix& rhs)\n{\n  lhs += rhs;\n172 \n| \nItem 25\nwww.it-ebooks.info\n\n\n  return std::move(lhs);                      // move lhs into\n}                                             // return value\nBy casting lhs to an rvalue in the return statement (via std::move), lhs will be\nmoved into the function’s return value location. If the call to std::move were omit‐\nted,\nMatrix                                        // as above\noperator+(Matrix&& lhs, const Matrix& rhs)\n{\n  lhs += rhs;\n  return lhs;                                 // copy lhs into\n}                                             // return value\nthe fact that lhs is an lvalue would force compilers to instead copy it into the return\nvalue location. Assuming that the Matrix type supports move construction, which is\nmore efficient than copy construction, using std::move in the return statement\nyields more efficient code.\nIf Matrix does not support moving, casting it to an rvalue won’t hurt, because the\nrvalue will simply be copied by Matrix’s copy constructor (see Item 23). If Matrix is\nlater revised to support moving, operator+ will automatically benefit the next time it\nis compiled. That being the case, there’s nothing to be lost (and possibly much to be\ngained) by applying std::move to rvalue references being returned from functions\nthat return by value.\nThe situation is similar for universal references and std::forward. Consider a func‐\ntion template reduceAndCopy that takes a possibly unreduced Fraction object,\nreduces it, and then returns a copy of the reduced value. If the original object is an\nrvalue, its value should be moved into the return value (thus avoiding the expense of\nmaking a copy), but if the original is an lvalue, an actual copy must be created.\nHence:\ntemplate<typename T>         \nFraction                           // by-value return\nreduceAndCopy(T&& frac)            // universal reference param\n{\n  frac.reduce();\n  return std::forward<T>(frac);    // move rvalue into return\n}                                  // value, copy lvalue\nIf the call to std::forward were omitted, frac would be unconditionally copied into\nreduceAndCopy’s return value.\nSome programmers take the information above and try to extend it to situations\nwhere it doesn’t apply. “If using std::move on an rvalue reference parameter being\nItem 25 \n| \n173\nwww.it-ebooks.info\n\n\n2 Eligible local objects include most local variables (such as w inside makeWidget) as well as temporary objects\ncreated as part of a return statement. Function parameters don’t qualify. Some people draw a distinction\nbetween application of the RVO to named and unnamed (i.e., temporary) local objects, limiting the term\nRVO to unnamed objects and calling its application to named objects the named return value optimization\n(NRVO).\ncopied into a return value turns a copy construction into a move construction,” they\nreason, “I can perform the same optimization on local variables that I’m returning.”\nIn other words, they figure that given a function returning a local variable by value,\nsuch as this,\nWidget makeWidget()        // \"Copying\" version of makeWidget\n{\n  Widget w;                // local variable\n  …                        // configure w\n  return w;                // \"copy\" w into return value\n}\nthey can “optimize” it by turning the “copy” into a move:\nWidget makeWidget()        // Moving version of makeWidget\n{\n  Widget w;\n  …\n  return std::move(w);     // move w into return value\n}                          // (don't do this!)\nMy liberal use of quotation marks should tip you off that this line of reasoning is\nflawed. But why is it flawed?\nIt’s flawed, because the Standardization Committee is way ahead of such program‐\nmers when it comes to this kind of optimization. It was recognized long ago that the\n“copying” version of makeWidget can avoid the need to copy the local variable w by\nconstructing it in the memory alloted for the function’s return value. This is known\nas the return value optimization (RVO), and it’s been expressly blessed by the C++\nStandard for as long as there’s been one.\nWording such a blessing is finicky business, because you want to permit such copy\nelision only in places where it won’t affect the observable behavior of the software.\nParaphrasing the legalistic (arguably toxic) prose of the Standard, this particular\nblessing says that compilers may elide the copying (or moving) of a local object2 in a\nfunction that returns by value if (1) the type of the local object is the same as that\nreturned by the function and (2) the local object is what’s being returned. With that\nin mind, look again at the “copying” version of makeWidget:\n174 \n| \nItem 25\nwww.it-ebooks.info\n\n\nWidget makeWidget()        // \"Copying\" version of makeWidget\n{\n  Widget w;\n  …\n  return w;                // \"copy\" w into return value\n}\nBoth conditions are fulfilled here, and you can trust me when I tell you that for this\ncode, every decent C++ compiler will employ the RVO to avoid copying w. That\nmeans that the “copying” version of makeWidget doesn’t, in fact, copy anything.\nThe moving version of makeWidget does just what its name says it does (assuming\nWidget offers a move constructor): it moves the contents of w into makeWidget’s\nreturn value location. But why don’t compilers use the RVO to eliminate the move,\nagain constructing w in the memory alloted for the function’s return value? The\nanswer is simple: they can’t. Condition (2) stipulates that the RVO may be performed\nonly if what’s being returned is a local object, but that’s not what the moving version\nof makeWidget is doing. Look again at its return statement:\nreturn std::move(w);\nWhat’s being returned here isn’t the local object w, it’s a reference to w—the result of\nstd::move(w). Returning a reference to a local object doesn’t satisfy the conditions\nrequired for the RVO, so compilers must move w into the function’s return value\nlocation. Developers trying to help their compilers optimize by applying std::move\nto a local variable that’s being returned are actually limiting the optimization options\navailable to their compilers!\nBut the RVO is an optimization. Compilers aren’t required to elide copy and move\noperations, even when they’re permitted to. Maybe you’re paranoid, and you worry\nthat your compilers will punish you with copy operations, just because they can. Or\nperhaps you’re insightful enough to recognize that there are cases where the RVO is\ndifficult for compilers to implement, e.g., when different control paths in a function\nreturn different local variables. (Compilers would have to generate code to construct\nthe appropriate local variable in the memory allotted for the function’s return value,\nbut how could compilers determine which local variable would be appropriate?) If so,\nyou might be willing to pay the price of a move as insurance against the cost of a\ncopy. That is, you might still think it’s reasonable to apply std::move to a local\nobject you’re returning, simply because you’d rest easy knowing you’d never pay for a\ncopy.\nIn that case, applying std::move to a local object would still be a bad idea. The part\nof the Standard blessing the RVO goes on to say that if the conditions for the RVO\nare met, but compilers choose not to perform copy elision, the object being returned\nmust be treated as an rvalue. In effect, the Standard requires that when the RVO is\nItem 25 \n| \n175\nwww.it-ebooks.info\n\n\npermitted, either copy elision takes place or std::move is implicitly applied to local\nobjects being returned. So in the “copying” version of makeWidget,\nWidget makeWidget()        // as before\n{\n  Widget w;\n  …\n  return w;\n}\ncompilers must either elide the copying of w or they must treat the function as if it\nwere written like this:\nWidget makeWidget()\n{\n  Widget w;\n  …\n  return std::move(w);     // treat w as rvalue, because\n}                          // no copy elision was performed\nThe situation is similar for by-value function parameters. They’re not eligible for\ncopy elision with respect to their function’s return value, but compilers must treat\nthem as rvalues if they’re returned. As a result, if your source code looks like this,\nWidget makeWidget(Widget w)       // by-value parameter of same\n{                                 // type as function's return\n  …\n  return w;\n}\ncompilers must treat it as if it had been written this way:\nWidget makeWidget(Widget w)\n{\n  …\n  return std::move(w);            // treat w as rvalue\n}\nThis means that if you use std::move on a local object being returned from a func‐\ntion that’s returning by value, you can’t help your compilers (they have to treat the\nlocal object as an rvalue if they don’t perform copy elision), but you can certainly hin‐\nder them (by precluding the RVO). There are situations where applying std::move\nto a local variable can be a reasonable thing to do (i.e., when you’re passing it to a\nfunction and you know you won’t be using the variable any longer), but as part of a\nreturn statement that would otherwise qualify for the RVO or that returns a by-\nvalue parameter isn’t among them.\n176 \n| \nItem 25\nwww.it-ebooks.info\n\n\nThings to Remember\n• Apply std::move to rvalue references and std::forward to universal refer‐\nences the last time each is used.\n• Do the same thing for rvalue references and universal references being\nreturned from functions that return by value.\n• Never apply std::move or std::forward to local objects if they would other‐\nwise be eligible for the return value optimization.\nItem 26: Avoid overloading on universal references.\nSuppose you need to write a function that takes a name as a parameter, logs the cur‐\nrent date and time, then adds the name to a global data structure. You might come up\nwith a function that looks something like this:\nstd::multiset<std::string> names;     // global data structure\nvoid logAndAdd(const std::string& name)\n{\n  auto now =                          // get current time\n    std::chrono::system_clock::now();\n  log(now, \"logAndAdd\");              // make log entry\n  names.emplace(name);                // add name to global data\n}                                     // structure; see Item 42\n                                      // for info on emplace\nThis isn’t unreasonable code, but it’s not as efficient as it could be. Consider three\npotential calls:\nstd::string petName(\"Darla\");\nlogAndAdd(petName);                   // pass lvalue std::string\nlogAndAdd(std::string(\"Persephone\")); // pass rvalue std::string\nlogAndAdd(\"Patty Dog\");               // pass string literal\nIn the first call, logAndAdd’s parameter name is bound to the variable petName.\nWithin logAndAdd, name is ultimately passed to names.emplace. Because name is an\nlvalue, it is copied into names. There’s no way to avoid that copy, because an lvalue\n(petName) was passed into logAndAdd.\nItem 25 \n| \n177\nwww.it-ebooks.info\n\n\nIn the second call, the parameter name is bound to an rvalue (the temporary\nstd::string explicitly created from \"Persephone\"). name itself is an lvalue, so it’s\ncopied into names, but we recognize that, in principle, its value could be moved into\nnames. In this call, we pay for a copy, but we should be able to get by with only a\nmove.\nIn the third call, the parameter name is again bound to an rvalue, but this time it’s to a\ntemporary std::string that’s implicitly created from \"Patty Dog\". As in the sec‐\nond call, name is copied into names, but in this case, the argument originally passed to\nlogAndAdd was a string literal. Had that string literal been passed directly to\nemplace, there would have been no need to create a temporary std::string at all.\nInstead, emplace would have used the string literal to create the std::string object\ndirectly inside the std::multiset. In this third call, then, we’re paying to copy a\nstd::string, yet there’s really no reason to pay even for a move, much less a copy.\nWe can eliminate the inefficiencies in the second and third calls by rewriting\nlogAndAdd to take a universal reference (see Item 24) and, in accord with Item 25,\nstd::forwarding this reference to emplace. The results speak for themselves:\ntemplate<typename T>\nvoid logAndAdd(T&& name)\n{\n  auto now = std::chrono::system_clock::now();\n  log(now, \"logAndAdd\");\n  names.emplace(std::forward<T>(name));\n}\nstd::string petName(\"Darla\");          // as before\nlogAndAdd(petName);                    // as before, copy\n                                       // lvalue into multiset\nlogAndAdd(std::string(\"Persephone\"));  // move rvalue instead\n                                       // of copying it\nlogAndAdd(\"Patty Dog\");                // create std::string\n                                       // in multiset instead\n                                       // of copying a temporary\n                                       // std::string\nHurray, optimal efficiency!\nWere this the end of the story, we could stop here and proudly retire, but I haven’t\ntold you that clients don’t always have direct access to the names that logAndAdd\n178 \n| \nItem 26\nwww.it-ebooks.info\n\n\nrequires. Some clients have only an index that logAndAdd uses to look up the corre‐\nsponding name in a table. To support such clients, logAndAdd is overloaded:\nstd::string nameFromIdx(int idx);      // return name\n                                       // corresponding to idx\nvoid logAndAdd(int idx)                // new overload\n{\n  auto now = std::chrono::system_clock::now();\n  log(now, \"logAndAdd\");\n  names.emplace(nameFromIdx(idx));\n}\nResolution of calls to the two overloads works as expected:\nstd::string petName(\"Darla\");          // as before\nlogAndAdd(petName);                    // as before, these\nlogAndAdd(std::string(\"Persephone\"));  // calls all invoke\nlogAndAdd(\"Patty Dog\");                // the T&& overload\nlogAndAdd(22);                         // calls int overload\nActually, resolution works as expected only if you don’t expect too much. Suppose a\nclient has a short holding an index and passes that to logAndAdd:\nshort nameIdx;\n…                                      // give nameIdx a value\nlogAndAdd(nameIdx);                    // error!\nThe comment on the last line isn’t terribly illuminating, so let me explain what hap‐\npens here.\nThere are two logAndAdd overloads. The one taking a universal reference can deduce\nT to be short, thus yielding an exact match. The overload with an int parameter can\nmatch the short argument only with a promotion. Per the normal overload resolu‐\ntion rules, an exact match beats a match with a promotion, so the universal reference\noverload is invoked.\nWithin that overload, the parameter name is bound to the short that’s passed in.\nname is then std::forwarded to the emplace member function on names (a\nstd::multiset<std::string>), which, in turn, dutifully forwards it to the\nstd::string constructor. There is no constructor for std::string that takes a\nshort, so the std::string constructor call inside the call to multiset::emplace\nItem 26 \n| \n179\nwww.it-ebooks.info\n\n\ninside the call to logAndAdd fails. All because the universal reference overload was a\nbetter match for a short argument than an int.\nFunctions taking universal references are the greediest functions in C++. They\ninstantiate to create exact matches for almost any type of argument. (The few kinds of\narguments where this isn’t the case are described in Item 30.) This is why combining\noverloading and universal references is almost always a bad idea: the universal refer‐\nence overload vacuums up far more argument types than the developer doing the\noverloading generally expects.\nAn easy way to topple into this pit is to write a perfect forwarding constructor. A\nsmall modification to the logAndAdd example demonstrates the problem. Instead of\nwriting a free function that can take either a std::string or an index that can be\nused to look up a std::string, imagine a class Person with constructors that do the\nsame  thing:\nclass Person {\npublic:\n  template<typename T>         \n  explicit Person(T&& n)           // perfect forwarding ctor;\n  : name(std::forward<T>(n)) {}    // initializes data member\n  explicit Person(int idx)         // int ctor\n  : name(nameFromIdx(idx)) {}\n  …\nprivate:\n  std::string name;\n};\nAs was the case with logAndAdd, passing an integral type other than int (e.g.,\nstd::size_t, short, long, etc.) will call the universal reference constructor over‐\nload instead of the int overload, and that will lead to compilation failures. The prob‐\nlem here is much worse, however, because there’s more overloading present in\nPerson than meets the eye. Item 17 explains that under the appropriate conditions,\nC++ will generate both copy and move constructors, and this is true even if the class\ncontains a templatized constructor that could be instantiated to produce the signa‐\nture of the copy or move constructor. If the copy and move constructors for Person\nare thus generated, Person will effectively look like this:\nclass Person {\npublic:\n  template<typename T>              // perfect forwarding ctor\n  explicit Person(T&& n)\n  : name(std::forward<T>(n)) {}\n180 \n| \nItem 26\nwww.it-ebooks.info\n\n\n  explicit Person(int idx);         // int ctor\n  Person(const Person& rhs);        // copy ctor\n                                    // (compiler-generated)\n  Person(Person&& rhs);             // move ctor\n  …                                 // (compiler-generated)\n};\nThis leads to behavior that’s intuitive only if you’ve spent so much time around com‐\npilers and compiler-writers, you’ve forgotten what it’s like to be human:\nPerson p(\"Nancy\");\nauto cloneOfP(p);                   // create new Person from p;\n                                    // this won't compile!\nHere we’re trying to create a Person from another Person, which seems like about as\nobvious a case for copy construction as one can get. (p’s an lvalue, so we can banish\nany thoughts we might have about the “copying” being accomplished through a move\noperation.) But this code won’t call the copy constructor. It will call the perfect-\nforwarding constructor. That function will then try to initialize Person’s\nstd::string data member with a Person object (p). std::string having no con‐\nstructor taking a Person, your compilers will throw up their hands in exasperation,\npossibly punishing you with long and incomprehensible error messages as an expres‐\nsion of their displeasure.\n“Why,” you might wonder, “does the perfect-forwarding constructor get called\ninstead of the copy constructor? We’re initializing a Person with another Person!”\nIndeed we are, but compilers are sworn to uphold the rules of C++, and the rules of\nrelevance here are the ones governing the resolution of calls to overloaded functions.\nCompilers reason as follows. cloneOfP is being initialized with a non-const lvalue\n(p), and that means that the templatized constructor can be instantiated to take a\nnon-const lvalue of type Person. After such instantiation, the Person class looks like\nthis:\nclass Person {\npublic:\n  explicit Person(Person& n)             // instantiated from\n  : name(std::forward<Person&>(n)) {}    // perfect-forwarding\n                                         // template\n  explicit Person(int idx);              // as before\nItem 26 \n| \n181\nwww.it-ebooks.info\n\n\n  Person(const Person& rhs);             // copy ctor\n  …                                      // (compiler-generated)\n};\nIn the statement,\nauto cloneOfP(p);\np could be passed to either the copy constructor or the instantiated template. Calling\nthe copy constructor would require adding const to p to match the copy construc‐\ntor’s parameter’s type, but calling the instantiated template requires no such addition.\nThe overload generated from the template is thus a better match, so compilers do\nwhat they’re designed to do: generate a call to the better-matching function. “Copy‐\ning” non-const lvalues of type Person is thus handled by the perfect-forwarding\nconstructor, not the copy constructor.\nIf we change the example slightly so that the object to be copied is const, we hear an\nentirely different tune:\nconst Person cp(\"Nancy\");     // object is now const\nauto cloneOfP(cp);            // calls copy constructor!\nBecause the object to be copied is now const, it’s an exact match for the parameter\ntaken by the copy constructor. The templatized constructor can be instantiated to\nhave the same signature,\nclass Person {\npublic:\n  explicit Person(const Person& n);      // instantiated from\n                                         // template\n  Person(const Person& rhs);             // copy ctor\n                                         // (compiler-generated)\n  …\n};\nbut this doesn’t matter, because one of the overload-resolution rules in C++ is that in\nsituations where a template instantiation and a non-template function (i.e., a “nor‐\nmal” function) are equally good matches for a function call, the normal function is\npreferred. The copy constructor (a normal function) thereby trumps an instantiated\ntemplate with the same signature.\n182 \n| \nItem 26\nwww.it-ebooks.info\n\n\n(If you’re wondering why compilers generate a copy constructor when they could\ninstantiate a templatized constructor to get the signature that the copy constructor\nwould have, review Item 17.)\nThe interaction among perfect-forwarding constructors and compiler-generated\ncopy and move operations develops even more wrinkles when inheritance enters the\npicture. In particular, the conventional implementations of derived class copy and\nmove operations behave quite surprisingly. Here, take a look:\nclass SpecialPerson: public Person {\npublic:\n  SpecialPerson(const SpecialPerson& rhs)  // copy ctor; calls\n  : Person(rhs)                            // base class\n  { … }                                    // forwarding ctor!\n  SpecialPerson(SpecialPerson&& rhs)       // move ctor; calls\n  : Person(std::move(rhs))                 // base class\n  { … }                                    // forwarding ctor!\n};\nAs the comments indicate, the derived class copy and move constructors don’t call\ntheir base class’s copy and move constructors, they call the base class’s perfect-\nforwarding constructor! To understand why, note that the derived class functions are\nusing arguments of type SpecialPerson to pass to their base class, then work\nthrough the template instantiation and overload-resolution consequences for the\nconstructors in class Person. Ultimately, the code won’t compile, because there’s no\nstd::string constructor taking a SpecialPerson.\nI hope that by now I’ve convinced you that overloading on universal reference\nparameters is something you should avoid if at all possible. But if overloading on uni‐\nversal references is a bad idea, what do you do if you need a function that forwards\nmost argument types, yet needs to treat some argument types in a special fashion?\nThat egg can be unscrambled in a number of ways. So many, in fact, that I’ve devoted\nan entire Item to them. It’s Item 27. The next Item. Keep reading, you’ll bump right\ninto it.\nThings to Remember\n• Overloading on universal references almost always leads to the universal refer‐\nence overload being called more frequently than expected.\n• Perfect-forwarding constructors are especially problematic, because they’re\ntypically better matches than copy constructors for non-const lvalues, and\nthey can hijack derived class calls to base class copy and move constructors.\nItem 26 \n| \n183\nwww.it-ebooks.info\n\n\nItem 27: Familiarize yourself with alternatives to\noverloading on universal references.\nItem 26 explains that overloading on universal references can lead to a variety of\nproblems, both for freestanding and for member functions (especially constructors).\nYet it also gives examples where such overloading could be useful. If only it would\nbehave the way we’d like! This Item explores ways to achieve the desired behavior,\neither through designs that avoid overloading on universal references or by employ‐\ning them in ways that constrain the types of arguments they can match.\nThe discussion that follows builds on the examples introduced in Item 26. If you\nhaven’t read that Item recently, you’ll want to review it before continuing.\nAbandon overloading\nThe first example in Item 26, logAndAdd, is representative of the many functions that\ncan avoid the drawbacks of overloading on universal references by simply using dif‐\nferent names for the would-be overloads. The two logAndAdd overloads, for example,\ncould be broken into logAndAddName and logAndAddNameIdx. Alas, this approach\nwon’t work for the second example we considered, the Person constructor, because\nconstructor names are fixed by the language. Besides, who wants to give up overload‐\ning?\nPass by const T&\nAn alternative is to revert to C++98 and replace pass-by-universal-reference with\npass-by-lvalue-reference-to-const. In fact, that’s the first approach Item 26 considers\n(shown on page 175). The drawback is that the design isn’t as efficient as we’d prefer.\nKnowing what we now know about the interaction of universal references and over‐\nloading, giving up some efficiency to keep things simple might be a more attractive\ntrade-off than it initially appeared.\nPass by value\nAn approach that often allows you to dial up performance without any increase in\ncomplexity is to replace pass-by-reference parameters with, counterintuitively, pass\nby value. The design adheres to the advice in Item 41 to consider passing objects by\nvalue when you know you’ll copy them, so I’ll defer to that Item for a detailed discus‐\nsion of how things work and how efficient they are. Here, I’ll just show how the tech‐\nnique could be used in the Person example:\nclass Person {\npublic:\n  explicit Person(std::string n) // replaces T&& ctor; see\n184 \n| \nItem 27\nwww.it-ebooks.info\n\n\n  : name(std::move(n)) {}        // Item 41 for use of std::move\n  \n  explicit Person(int idx)       // as before\n  : name(nameFromIdx(idx)) {}\n  …\nprivate:\n  std::string name;\n};\nBecause there’s no std::string constructor taking only an integer, all int and int-\nlike arguments to a Person constructor (e.g., std::size_t, short, long) get fun‐\nneled to the int overload. Similarly, all arguments of type std::string (and things\nfrom which std::strings can be created, e.g., literals such as \"Ruth\") get passed to\nthe constructor taking a std::string. There are thus no surprises for callers. You\ncould argue, I suppose, that some people might be surprised that using 0 or NULL to\nindicate a null pointer would invoke the int overload, but such people should be\nreferred to Item 8 and required to read it repeatedly until the thought of using 0 or\nNULL as a null pointer makes them recoil.\nUse Tag dispatch\nNeither pass by lvalue-reference-to-const nor pass by value offers support for perfect\nforwarding. If the motivation for the use of a universal reference is perfect forward‐\ning, we have to use a universal reference; there’s no other choice. Yet we don’t want\nto abandon overloading. So if we don’t give up overloading and we don’t give up uni‐\nversal references, how can we avoid overloading on universal references?\nIt’s actually not that hard. Calls to overloaded functions are resolved by looking at all\nthe parameters of all the overloads as well as all the arguments at the call site, then\nchoosing the function with the best overall match—taking into account all parame‐\nter/argument combinations. A universal reference parameter generally provides an\nexact match for whatever’s passed in, but if the universal reference is part of a param‐\neter list containing other parameters that are not universal references, sufficiently\npoor matches on the non-universal reference parameters can knock an overload with\na universal reference out of the running. That’s the basis behind the tag dispatch\napproach, and an example will make the foregoing description easier to understand.\nWe’ll apply tag dispatch to the logAndAdd example on page 177. Here’s the code for\nthat example, lest you get sidetracked looking it up:\nstd::multiset<std::string> names;      // global data structure\ntemplate<typename T>                   // make log entry and add\nItem 27 \n| \n185\nwww.it-ebooks.info\n",
      "page_number": 190,
      "chapter_number": 18,
      "summary": "This chapter covers segment 18 (pages 190-203). Key topics include copy, copied, and item. And inside such functions, I assure you,\nstd::forward is applied to the universal reference parameters when they’re passed\nto other functions.",
      "keywords": [
        "std",
        "Person",
        "copy",
        "Item",
        "move",
        "universal reference",
        "return std",
        "class Person",
        "copy constructor",
        "string",
        "universal",
        "function",
        "explicit Person",
        "constructor",
        "reference"
      ],
      "concepts": [
        "copy",
        "copied",
        "item",
        "overloading",
        "std",
        "functions",
        "function",
        "person",
        "compilers",
        "compile"
      ],
      "similar_chapters": [
        {
          "book": "C++ Templates_ The Complete Guide",
          "chapter": 41,
          "title": "Segment 41 (pages 1309-1342)",
          "relevance_score": 0.66,
          "method": "sentence_transformers"
        },
        {
          "book": "C++ Templates_ The Complete Guide",
          "chapter": 46,
          "title": "Segment 46 (pages 1469-1503)",
          "relevance_score": 0.59,
          "method": "sentence_transformers"
        },
        {
          "book": "C++ Concurrency in Action",
          "chapter": 39,
          "title": "Segment 39 (pages 382-396)",
          "relevance_score": 0.57,
          "method": "sentence_transformers"
        },
        {
          "book": "More Effective C++",
          "chapter": 7,
          "title": "Segment 7 (pages 52-60)",
          "relevance_score": 0.54,
          "method": "sentence_transformers"
        },
        {
          "book": "C++ Concurrency in Action",
          "chapter": 6,
          "title": "Segment 6 (pages 50-58)",
          "relevance_score": 0.53,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 19,
      "title": "Segment 19 (pages 204-214)",
      "start_page": 204,
      "end_page": 214,
      "detection_method": "topic_boundary",
      "content": "void logAndAdd(T&& name)               // name to data structure\n{\n  auto now = std::chrono::system_clock::now();\n  log(now, \"logAndAdd\");\n  names.emplace(std::forward<T>(name));\n}\nBy itself, this function works fine, but were we to introduce the overload taking an\nint that’s used to look up objects by index, we’d be back in the troubled land of\nItem 26. The goal of this Item is to avoid that. Rather than adding the overload, we’ll\nreimplement logAndAdd to delegate to two other functions, one for integral values\nand one for everything else. logAndAdd itself will accept all argument types, both\nintegral and non-integral.\nThe two functions doing the real work will be named logAndAddImpl, i.e., we’ll use\noverloading. One of the functions will take a universal reference. So we’ll have both\noverloading and universal references. But each function will also take a second\nparameter, one that indicates whether the argument being passed is integral. This\nsecond parameter is what will prevent us from tumbling into the morass described in\nItem 26, because we’ll arrange it so that the second parameter will be the factor that\ndetermines which overload is selected.\nYes, I know, “Blah, blah, blah. Stop talking and show me the code!” No problem.\nHere’s an almost-correct version of the updated logAndAdd:\ntemplate<typename T>\nvoid logAndAdd(T&& name)\n{\n  logAndAddImpl(std::forward<T>(name),\n                std::is_integral<T>());     // not quite correct\n}\nThis function forwards its parameter to logAndAddImpl, but it also passes an argu‐\nment indicating whether that parameter’s type (T) is integral. At least, that’s what it’s\nsupposed to do. For integral arguments that are rvalues, it’s also what it does. But, as\nItem 28 explains, if an lvalue argument is passed to the universal reference name, the\ntype deduced for T will be an lvalue reference. So if an lvalue of type int is passed to\nlogAndAdd, T will be deduced to be int&. That’s not an integral type, because refer‐\nences aren’t integral types. That means that std::is_integral<T> will be false for\nany lvalue argument, even if the argument really does represent an integral value.\nRecognizing the problem is tantamount to solving it, because the ever-handy Stan‐\ndard C++ Library has a type trait (see Item 9), std::remove_reference, that does\nboth what its name suggests and what we need: remove any reference qualifiers from\na type. The proper way to write logAndAdd is therefore:\n186 \n| \nItem 27\nwww.it-ebooks.info\n\n\ntemplate<typename T>\nvoid logAndAdd(T&& name)\n{\n  logAndAddImpl(\n    std::forward<T>(name),\n    std::is_integral<typename std::remove_reference<T>::type>()\n  );\n}\nThis does the trick. (In C++14, you can save a few keystrokes by using\nstd::remove_reference_t<T> in place of the highlighted text. For details, see\nItem 9.)\nWith that taken care of, we can shift our attention to the function being called,\nlogAndAddImpl. There are two overloads, and the first is applicable only to non-\nintegral types (i.e., to types where std::is_integral<typename std::remove_ref\nerence<T>::type> is false):\ntemplate<typename T>                             // non-integral\nvoid logAndAddImpl(T&& name, std::false_type)    // argument:\n{                                                // add it to\n  auto now = std::chrono::system_clock::now();   // global data\n  log(now, \"logAndAdd\");                         // structure\n  names.emplace(std::forward<T>(name));\n}\nThis is straightforward code, once you understand the mechanics behind the high‐\nlighted parameter. Conceptually, logAndAdd passes a boolean to logAndAddImpl\nindicating whether an integral type was passed to logAndAdd, but true and false\nare runtime values, and we need to use overload resolution—a compile-time phenom‐\nenon—to choose the correct logAndAddImpl overload. That means we need a type\nthat corresponds to true and a different type that corresponds to false. This need is\ncommon enough that the Standard Library provides what is required under the\nnames std::true_type and std::false_type. The argument passed to logAndAd\ndImpl by logAndAdd is an object of a type that inherits from std::true_type if T is\nintegral and from std::false_type if T is not integral. The net result is that this\nlogAndAddImpl overload is a viable candidate for the call in logAndAdd only if T is\nnot an integral type.\nThe second overload covers the opposite case: when T is an integral type. In that\nevent, logAndAddImpl simply finds the name corresponding to the passed-in index\nand passes that name back to logAndAdd:\nstd::string nameFromIdx(int idx);             // as in Item 26\nItem 27 \n| \n187\nwww.it-ebooks.info\n\n\nvoid logAndAddImpl(int idx, std::true_type)   // integral\n{                                             // argument: look\n  logAndAdd(nameFromIdx(idx));                // up name and\n}                                             // call logAndAdd\n                                              // with it\nBy having logAndAddImpl for an index look up the corresponding name and pass it\nto logAndAdd (from where it will be std::forwarded to the other logAndAddImpl\noverload), we avoid the need to put the logging code in both logAndAddImpl over‐\nloads.\nIn this design, the types std::true_type and std::false_type are “tags” whose\nonly purpose is to force overload resolution to go the way we want. Notice that we\ndon’t even name those parameters. They serve no purpose at runtime, and in fact we\nhope that compilers will recognize that the tag parameters are unused and will opti‐\nmize them out of the program’s execution image. (Some compilers do, at least some\nof the time.) The call to the overloaded implementation functions inside logAndAdd\n“dispatches” the work to the correct overload by causing the proper tag object to be\ncreated. Hence the name for this design: tag dispatch. It’s a standard building block of\ntemplate metaprogramming, and the more you look at code inside contemporary\nC++ libraries, the more often you’ll encounter it.\nFor our purposes, what’s important about tag dispatch is less how it works and more\nhow it permits us to combine universal references and overloading without the prob‐\nlems described in Item 26. The dispatching function—logAndAdd—takes an uncon‐\nstrained universal reference parameter, but this function is not overloaded. The\nimplementation functions—logAndAddImpl—are overloaded, and one takes a uni‐\nversal reference parameter, but resolution of calls to these functions depends not just\non the universal reference parameter, but also on the tag parameter, and the tag val‐\nues are designed so that no more than one overload will be a viable match. As a\nresult, it’s the tag that determines which overload gets called. The fact that the univer‐\nsal reference parameter will always generate an exact match for its argument is imma‐\nterial.\nConstraining templates that take universal references\nA keystone of tag dispatch is the existence of a single (unoverloaded) function as the\nclient API. This single function dispatches the work to be done to the implementa‐\ntion functions. Creating an unoverloaded dispatch function is usually easy, but the\nsecond problem case Item 26 considers, that of a perfect-forwarding constructor for\nthe Person class (shown on page 178), is an exception. Compilers may generate copy\nand move constructors themselves, so even if you write only one constructor and use\ntag dispatch within it, some constructor calls may be handled by compiler-generated\nfunctions that bypass the tag dispatch system.\n188 \n| \nItem 27\nwww.it-ebooks.info\n\n\nIn truth, the real problem is not that the compiler-generated functions sometimes\nbypass the tag dispatch design, it’s that they don’t always pass it by. You virtually\nalways want the copy constructor for a class to handle requests to copy lvalues of that\ntype, but, as Item 26 demonstrates, providing a constructor taking a universal refer‐\nence causes the universal reference constructor (rather than the copy constructor) to\nbe called when copying non-const lvalues. That Item also explains that when a base\nclass declares a perfect-forwarding constructor, that constructor will typically be\ncalled when derived classes implement their copy and move constructors in the con‐\nventional fashion, even though the correct behavior is for the base class’s copy and\nmove constructors to be invoked.\nFor situations like these, where an overloaded function taking a universal reference is\ngreedier than you want, yet not greedy enough to act as a single dispatch function, tag\ndispatch is not the droid you’re looking for. You need a different technique, one that\nlets you rachet down the conditions under which the function template that the uni‐\nversal reference is part of is permitted to be employed. What you need, my friend, is\nstd::enable_if.\nstd::enable_if gives you a way to force compilers to behave as if a particular tem‐\nplate didn’t exist. Such templates are said to be disabled. By default, all templates are\nenabled, but a template using std::enable_if is enabled only if the condition speci‐\nfied by std::enable_if is satisfied. In our case, we’d like to enable the Person\nperfect-forwarding constructor only if the type being passed isn’t Person. If the type\nbeing passed is Person, we want to disable the perfect-forwarding constructor (i.e.,\ncause compilers to ignore it), because that will cause the class’s copy or move con‐\nstructor to handle the call, which is what we want when a Person object is initialized\nwith another Person.\nThe way to express that idea isn’t particularly difficult, but the syntax is off-putting,\nespecially if you’ve never seen it before, so I’ll ease you into it. There’s some boiler‐\nplate that goes around the condition part of std::enable_if, so we’ll start with that.\nHere’s the declaration for the perfect-forwarding constructor in Person, showing\nonly as much of the std::enable_if as is required simply to use it. I’m showing\nonly the declaration for this constructor, because the use of std::enable_if has no\neffect on the function’s implementation. The implementation remains the same as in\nItem 26.\nclass Person {\npublic:\n  template<typename T,\n           typename = typename std::enable_if<condition>::type>\n  explicit Person(T&& n);\n  …\nItem 27 \n| \n189\nwww.it-ebooks.info\n\n\n};\nTo understand exactly what’s going on in the highlighted text, I must regretfully sug‐\ngest that you consult other sources, because the details take a while to explain, and\nthere’s just not enough space for it in this book. (During your research, look into\n“SFINAE” as well as std::enable_if, because SFINAE is the technology that makes\nstd::enable_if work.) Here, I want to focus on expression of the condition that\nwill control whether this constructor is enabled.\nThe condition we want to specify is that T isn’t Person, i.e., that the templatized con‐\nstructor should be enabled only if T is a type other than Person. Thanks to a type\ntrait that determines whether two types are the same (std::is_same), it would seem\nthat the condition we want is !std::is_same<Person, T>::value. (Notice the “!”\nat the beginning of the expression. We want for Person and T to not be the same.)\nThis is close to what we need, but it’s not quite correct, because, as Item 28 explains,\nthe type deduced for a universal reference initialized with an lvalue is always an\nlvalue reference. That means that for code like this,\nPerson p(\"Nancy\");\nauto cloneOfP(p);          // initialize from lvalue\nthe type T in the universal constructor will be deduced to be Person&. The types Per\nson and Person& are not the same, and the result of std::is_same will reflect that:\nstd::is_same<Person, Person&>::value is false.\nIf we think more precisely about what we mean when we say that the templatized\nconstructor in Person should be enabled only if T isn’t Person, we’ll realize that\nwhen we’re looking at T, we want to ignore\n• Whether it’s a reference. For the purpose of determining whether the universal\nreference constructor should be enabled, the types Person, Person&, and Per\nson&& are all the same as Person.\n• Whether it’s const or volatile. As far as we’re concerned, a const Person and\na volatile Person and a const volatile Person are all the same as a Person.\nThis means we need a way to strip any references, consts, and volatiles from T\nbefore checking to see if that type is the same as Person. Once again, the Standard\nLibrary gives us what we need in the form of a type trait. That trait is std::decay.\nstd::decay<T>::type is the same as T, except that references and cv-qualifiers (i.e.,\nconst or volatile qualifiers) are removed. (I’m fudging the truth here, because\nstd::decay, as its name suggests, also turns array and function types into pointers\n190 \n| \nItem 27\nwww.it-ebooks.info\n\n\n(see Item 1), but for purposes of this discussion, std::decay behaves as I’ve\ndescribed.) The condition we want to control whether our constructor is enabled,\nthen, is\n!std::is_same<Person, typename std::decay<T>::type>::value\ni.e., Person is not the same type as T, ignoring any references or cv-qualifiers. (As\nItem 9 explains, the “typename” in front of std::decay is required, because the type\nstd::decay<T>::type depends on the template parameter T.)\nInserting this condition into the std::enable_if boilerplate above, plus formatting\nthe result to make it easier to see how the pieces fit together, yields this declaration\nfor Person’s perfect-forwarding constructor:\nclass Person {\npublic:\n  template<\n    typename T,\n    typename = typename std::enable_if<\n                 !std::is_same<Person,\n                               typename std::decay<T>::type\n                              >::value\n               >::type\n  >\n  explicit Person(T&& n);\n  …\n};\nIf you’ve never seen anything like this before, count your blessings. There’s a reason I\nsaved this design for last. When you can use one of the other mechanisms to avoid\nmixing universal references and overloading (and you almost always can), you\nshould. Still, once you get used to the functional syntax and the proliferation of angle\nbrackets, it’s not that bad. Furthermore, this gives you the behavior you’ve been striv‐\ning for. Given the declaration above, constructing a Person from another Person—\nlvalue or rvalue, const or non-const, volatile or non-volatile—will never\ninvoke the constructor taking a universal reference.\nSuccess, right? We’re done!\nUm, no. Belay that celebration. There’s still one loose end from Item 26 that contin‐\nues to flap about. We need to tie it down.\nSuppose a class derived from Person implements the copy and move operations in\nthe conventional manner:\nItem 27 \n| \n191\nwww.it-ebooks.info\n\n\nclass SpecialPerson: public Person {\npublic:\n  SpecialPerson(const SpecialPerson& rhs)  // copy ctor; calls\n  : Person(rhs)                            // base class\n  { … }                                    // forwarding ctor!\n  SpecialPerson(SpecialPerson&& rhs)       // move ctor; calls\n  : Person(std::move(rhs))                 // base class\n  { … }                                    // forwarding ctor!\n  …\n};\nThis is the same code I showed in Item 26 (on page 206), including the comments,\nwhich, alas, remain accurate. When we copy or move a SpecialPerson object, we\nexpect to copy or move its base class parts using the base class’s copy and move con‐\nstructors, but in these functions, we’re passing SpecialPerson objects to the base\nclass’s constructors, and because SpecialPerson isn’t the same as Person (not even\nafter application of std::decay), the universal reference constructor in the base class\nis enabled, and it happily instantiates to perform an exact match for a SpecialPer\nson argument. This exact match is better than the derived-to-base conversions that\nwould be necessary to bind the SpecialPerson objects to the Person parameters in\nPerson’s copy and move constructors, so with the code we have now, copying and\nmoving SpecialPerson objects would use the Person perfect-forwarding construc‐\ntor to copy or move their base class parts! It’s déjà Item 26 all over again.\nThe derived class is just following the normal rules for implementing derived class\ncopy and move constructors, so the fix for this problem is in the base class and, in\nparticular, in the condition that controls whether Person’s universal reference con‐\nstructor is enabled. We now realize that we don’t want to enable the templatized con‐\nstructor for any argument type other than Person, we want to enable it for any\nargument type other than Person or a type derived from Person. Pesky inheritance!\nYou should not be surprised to hear that among the standard type traits is one that\ndetermines whether one type is derived from another. It’s called std::is_base_of.\nstd::is_base_of<T1, T2>::value is true if T2 is derived from T1. Types are con‐\nsidered to be derived from themselves, so std::is_base_of<T, T>::value is true.\nThis is handy, because we want to revise our condition controlling Person’s perfect-\nforwarding constructor such that the constructor is enabled only if the type T, after\nstripping it of references and cv-qualifiers, is neither Person nor a class derived from\nPerson. Using std::is_base_of instead of std::is_same gives us what we need:\n192 \n| \nItem 27\nwww.it-ebooks.info\n\n\nclass Person {\npublic:\n  template<\n    typename T,\n    typename = typename std::enable_if<\n                 !std::is_base_of<Person,\n                                  typename std::decay<T>::type\n                                 >::value\n               >::type\n  >\n  explicit Person(T&& n);\n  …\n};\nNow we’re finally done. Provided we’re writing the code in C++11, that is. If we’re\nusing C++14, this code will still work, but we can employ alias templates for\nstd::enable_if and std::decay to get rid of the “typename” and “::type” cruft,\nthus yielding this somewhat more palatable code:\nclass Person {                                     // C++14\npublic:\n  template<\n    typename T,\n    typename = std::enable_if_t<               // less code here\n                 !std::is_base_of<Person,\n                                  std::decay_t<T>  // and here\n                                 >::value\n               >                                   // and here\n  >\n  explicit Person(T&& n);\n  …\n};\nOkay, I admit it: I lied. We’re still not done. But we’re close. Tantalizingly close.\nHonest.\nWe’ve seen how to use std::enable_if to selectively disable Person’s universal ref‐\nerence constructor for argument types we want to have handled by the class’s copy\nand move constructors, but we haven’t yet seen how to apply it to distinguish integral\nand non-integral arguments. That was, after all, our original goal; the constructor\nambiguity problem was just something we got dragged into along the way.\nItem 27 \n| \n193\nwww.it-ebooks.info\n\n\nAll we need to do—and I really do mean that this is everything—is (1) add a Person\nconstructor overload to handle integral arguments and (2) further constrain the\ntemplatized constructor so that it’s disabled for such arguments. Pour these ingredi‐\nents into the pot with everything else we’ve discussed, simmer over a low flame, and\nsavor the aroma of success:\nclass Person {\npublic:\n  template<\n    typename T,\n    typename = std::enable_if_t<\n      !std::is_base_of<Person, std::decay_t<T>>::value\n      &&\n      !std::is_integral<std::remove_reference_t<T>>::value\n    >\n  > \n  explicit Person(T&& n)        // ctor for std::strings and\n  : name(std::forward<T>(n))    // args convertible to\n  { … }                         // std::strings\n  explicit Person(int idx)      // ctor for integral args\n  : name(nameFromIdx(idx))\n  { … }\n  …                             // copy and move ctors, etc.\nprivate:\n  std::string name;\n};\nVoilà! A thing of beauty! Well, okay, the beauty is perhaps most pronounced for\nthose with something of a template metaprogramming fetish, but the fact remains\nthat this approach not only gets the job done, it does it with unique aplomb. Because\nit uses perfect forwarding, it offers maximal efficiency, and because it controls the\ncombination of universal references and overloading rather than forbidding it, this\ntechnique can be applied in circumstances (such as constructors) where overloading\nis unavoidable.\nTrade-offs\nThe first three techniques considered in this Item—abandoning overloading, passing\nby const T&, and passing by value—specify a type for each parameter in the func‐\ntion(s) to be called. The last two techniques—tag dispatch and constraining template\neligibility—use perfect forwarding, hence don’t specify types for the parameters. This\nfundamental decision—to specify a type or not—has consequences.\n194 \n| \nItem 27\nwww.it-ebooks.info\n\n\nAs a rule, perfect forwarding is more efficient, because it avoids the creation of tem‐\nporary objects solely for the purpose of conforming to the type of a parameter decla‐\nration. In the case of the Person constructor, perfect forwarding permits a string\nliteral such as \"Nancy\" to be forwarded to the constructor for the std::string\ninside Person, whereas techniques not using perfect forwarding must create a tem‐\nporary std::string object from the string literal to satisfy the parameter specifica‐\ntion for the Person constructor.\nBut perfect forwarding has drawbacks. One is that some kinds of arguments can’t be\nperfect-forwarded, even though they can be passed to functions taking specific types.\nItem 30 explores these perfect forwarding failure cases.\nA second issue is the comprehensibility of error messages when clients pass invalid\narguments. Suppose, for example, a client creating a Person object passes a string lit‐\neral made up of char16_ts (a type introduced in C++11 to represent 16-bit charac‐\nters) instead of chars (which is what a std::string consists of):\nPerson p(u\"Konrad Zuse\");   // \"Konrad Zuse\" consists of\n                            // characters of type const char16_t\nWith the first three approaches examined in this Item, compilers will see that the\navailable constructors take either int or std::string, and they’ll produce a more or\nless straightforward error message explaining that there’s no conversion from const\nchar16_t[12] to int or std::string.\nWith an approach based on perfect forwarding, however, the array of const\nchar16_ts gets bound to the constructor’s parameter without complaint. From there\nit’s forwarded to the constructor of Person’s std::string data member, and it’s\nonly at that point that the mismatch between what the caller passed in (a const\nchar16_t array) and what’s required (any type acceptable to the std::string con‐\nstructor) is discovered. The resulting error message is likely to be, er, impressive.\nWith one of the compilers I use, it’s more than 160 lines long.\nIn this example, the universal reference is forwarded only once (from the Person\nconstructor to the std::string constructor), but the more complex the system, the\nmore likely that a universal reference is forwarded through several layers of function\ncalls before finally arriving at a site that determines whether the argument type(s) are\nacceptable. The more times the universal reference is forwarded, the more baffling\nthe error message may be when something goes wrong. Many developers find that\nthis issue alone is grounds to reserve universal reference parameters for interfaces\nwhere performance is a foremost concern.\nIn the case of Person, we know that the forwarding function’s universal reference\nparameter is supposed to be an initializer for a std::string, so we can use a\nItem 27 \n| \n195\nwww.it-ebooks.info\n\n\nstatic_assert to verify that it can play that role. The std::is_constructible\ntype trait performs a compile-time test to determine whether an object of one type\ncan be constructed from an object (or set of objects) of a different type (or set of\ntypes), so the assertion is easy to write:\nclass Person {\npublic:\n  template<                                 // as before\n    typename T,\n    typename = std::enable_if_t<\n      !std::is_base_of<Person, std::decay_t<T>>::value\n      &&\n      !std::is_integral<std::remove_reference_t<T>>::value\n    >\n  >\n  explicit Person(T&& n)\n  : name(std::forward<T>(n))\n  {\n    // assert that a std::string can be created from a T object\n    static_assert(\n      std::is_constructible<std::string, T>::value,\n      \"Parameter n can't be used to construct a std::string\"\n   );\n   …                    // the usual ctor work goes here\n  }\n  …                     // remainder of Person class (as before)\n};\nThis causes the specified error message to be produced if client code tries to create a\nPerson from a type that can’t be used to construct a std::string. Unfortunately, in\nthis example the static_assert is in the body of the constructor, but the forward‐\ning code, being part of the member initialization list, precedes it. With the compilers\nI use, the result is that the nice, readable message arising from the static_assert\nappears only after the usual error messages (up to 160-plus lines of them) have been\nemitted.\n \n196 \n| \nItem 27\nwww.it-ebooks.info\n",
      "page_number": 204,
      "chapter_number": 19,
      "summary": "But, as\nItem 28 explains, if an lvalue argument is passed to the universal reference name, the\ntype deduced for T will be an lvalue reference Key topics include types, item.",
      "keywords": [
        "Person",
        "std",
        "type",
        "Item",
        "class Person",
        "Person constructor",
        "constructor",
        "universal reference",
        "explicit Person",
        "typename std",
        "reference",
        "integral",
        "universal",
        "typename",
        "n’t Person"
      ],
      "concepts": [
        "std",
        "types",
        "item",
        "functions",
        "functional",
        "constructor",
        "overload",
        "template",
        "argument",
        "arguments"
      ],
      "similar_chapters": [
        {
          "book": "C++ Templates_ The Complete Guide",
          "chapter": 9,
          "title": "Segment 9 (pages 265-294)",
          "relevance_score": 0.62,
          "method": "sentence_transformers"
        },
        {
          "book": "C++ Templates_ The Complete Guide",
          "chapter": 1,
          "title": "Segment 1 (pages 1-35)",
          "relevance_score": 0.58,
          "method": "sentence_transformers"
        },
        {
          "book": "C++ Templates_ The Complete Guide",
          "chapter": 31,
          "title": "Segment 31 (pages 981-1014)",
          "relevance_score": 0.56,
          "method": "sentence_transformers"
        },
        {
          "book": "C++ Templates_ The Complete Guide",
          "chapter": 6,
          "title": "Segment 6 (pages 167-197)",
          "relevance_score": 0.54,
          "method": "sentence_transformers"
        },
        {
          "book": "C++ Templates_ The Complete Guide",
          "chapter": 7,
          "title": "Segment 7 (pages 198-230)",
          "relevance_score": 0.54,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 20,
      "title": "Segment 20 (pages 215-222)",
      "start_page": 215,
      "end_page": 222,
      "detection_method": "topic_boundary",
      "content": "Things to Remember\n• Alternatives to the combination of universal references and overloading\ninclude the use of distinct function names, passing parameters by lvalue-\nreference-to-const, passing parameters by value, and using tag dispatch.\n• Constraining templates via std::enable_if permits the use of universal ref‐\nerences and overloading together, but it controls the conditions under which\ncompilers may use the universal reference overloads.\n• Universal reference parameters often have efficiency advantages, but they typ‐\nically have usability disadvantages.\nItem 28: Understand reference collapsing.\nItem 23 remarks that when an argument is passed to a template function, the type\ndeduced for the template parameter encodes whether the argument is an lvalue or an\nrvalue. The Item fails to mention that this happens only when the argument is used\nto initialize a parameter that’s a universal reference, but there’s a good reason for the\nomission: universal references aren’t introduced until Item 24. Together, these obser‐\nvations about universal references and lvalue/rvalue encoding mean that for this tem‐\nplate,\ntemplate<typename T>\nvoid func(T&& param);\nthe deduced template parameter T will encode whether the argument passed to param\nwas an lvalue or an rvalue.\nThe encoding mechanism is simple. When an lvalue is passed as an argument, T is\ndeduced to be an lvalue reference. When an rvalue is passed, T is deduced to be a\nnon-reference. (Note the asymmetry: lvalues are encoded as lvalue references, but\nrvalues are encoded as non-references.) Hence:\nWidget widgetFactory();     // function returning rvalue\nWidget w;                   // a variable (an lvalue)\nfunc(w);                    // call func with lvalue; T deduced\n                            // to be Widget&\nfunc(widgetFactory());      // call func with rvalue; T deduced\n                            // to be Widget\nItem 27 \n| \n197\nwww.it-ebooks.info\n\n\nIn both calls to func, a Widget is passed, yet because one Widget is an lvalue and one\nis an rvalue, different types are deduced for the template parameter T. This, as we\nshall soon see, is what determines whether universal references become rvalue refer‐\nences or lvalue references, and it’s also the underlying mechanism through which\nstd::forward does its work.\nBefore we can look more closely at std::forward and universal references, we must\nnote that references to references are illegal in C++. Should you try to declare one,\nyour compilers will reprimand you:\nint x;\n…\nauto& & rx = x;   // error! can't declare reference to reference\nBut consider what happens when an lvalue is passed to a function template taking a\nuniversal reference:\ntemplate<typename T>\nvoid func(T&& param);    // as before\nfunc(w);                 // invoke func with lvalue;\n                         // T deduced as Widget&\nIf we take the type deduced for T (i.e., Widget&) and use it to instantiate the template,\nwe get this:\nvoid func(Widget& && param);\nA reference to a reference! And yet compilers issue no protest. We know from\nItem 24 that because the universal reference param is being initialized with an lvalue,\nparam’s type is supposed to be an lvalue reference, but how does the compiler get\nfrom the result of taking the deduced type for T and substituting it into the template\nto the following, which is the ultimate function signature?\nvoid func(Widget& param);\nThe answer is reference collapsing. Yes, you are forbidden from declaring references\nto references, but compilers may produce them in particular contexts, template\ninstantiation being among them. When compilers generate references to references,\nreference collapsing dictates what happens next.\nThere are two kinds of references (lvalue and rvalue), so there are four possible\nreference-reference combinations (lvalue to lvalue, lvalue to rvalue, rvalue to lvalue,\nand rvalue to rvalue). If a reference to a reference arises in a context where this is per‐\nmitted (e.g., during template instantiation), the references collapse to a single refer‐\nence according to this rule:\n198 \n| \nItem 28\nwww.it-ebooks.info\n\n\nIf either reference is an lvalue reference, the result is an lvalue reference.\nOtherwise (i.e., if both are rvalue references) the result is an rvalue refer‐\nence.\nIn our example above, substitution of the deduced type Widget& into the template\nfunc yields an rvalue reference to an lvalue reference, and the reference-collapsing\nrule tells us that the result is an lvalue reference.\nReference collapsing is a key part of what makes std::forward work. As explained\nin Item 25, std::forward is applied to universal reference parameters, so a common\nuse case looks like this:\ntemplate<typename T>\nvoid f(T&& fParam)\n{\n  …                                    // do some work\n  someFunc(std::forward<T>(fParam));   // forward fParam to\n}                                      // someFunc\nBecause fParam is a universal reference, we know that the type parameter T will\nencode whether the argument passed to f (i.e., the expression used to initialize\nfParam) was an lvalue or an rvalue. std::forward’s job is to cast fParam (an lvalue)\nto an rvalue if and only if T encodes that the argument passed to f was an rvalue, i.e.,\nif T is a non-reference type.\nHere’s how std::forward can be implemented to do that:\ntemplate<typename T>                                // in\nT&& forward(typename                                // namespace\n              remove_reference<T>::type& param)     // std\n{\n  return static_cast<T&&>(param);\n}\nThis isn’t quite Standards-conformant (I’ve omitted a few interface details), but the\ndifferences are irrelevant for the purpose of understanding how std::forward\nbehaves.\nSuppose that the argument passed to f is an lvalue of type Widget. T will be deduced\nas Widget&, and the call to std::forward will instantiate as std::forward\n<Widget&>. Plugging Widget& into the std::forward implementation yields this:\nItem 28 \n| \n199\nwww.it-ebooks.info\n\n\nWidget& && forward(typename\n                     remove_reference<Widget&>::type& param)\n{ return static_cast<Widget& &&>(param); }\nThe type trait std::remove_reference<Widget&>::type yields Widget (see\nItem 9), so std::forward becomes:\nWidget& && forward(Widget& param)\n{ return static_cast<Widget& &&>(param); }\nReference collapsing is also applied to the return type and the cast, and the result is\nthe final version of std::forward for the call:\nWidget& forward(Widget& param)                  // still in\n{ return static_cast<Widget&>(param);  }        // namespace std\nAs you can see, when an lvalue argument is passed to the function template f,\nstd::forward is instantiated to take and return an lvalue reference. The cast inside\nstd::forward does nothing, because param’s type is already Widget&, so casting it to\nWidget& has no effect. An lvalue argument passed to std::forward will thus return\nan lvalue reference. By definition, lvalue references are lvalues, so passing an lvalue to\nstd::forward causes an lvalue to be returned, just like it’s supposed to.\nNow suppose that the argument passed to f is an rvalue of type Widget. In this case,\nthe deduced type for f’s type parameter T will simply be Widget. The call inside f to\nstd::forward will thus be to std::forward<Widget>. Substituting Widget for T in\nthe std::forward implementation gives this:\nWidget&& forward(typename\n                   remove_reference<Widget>::type& param)\n{ return static_cast<Widget&&>(param); }\nApplying std::remove_reference to the non-reference type Widget yields the\nsame type it started with (Widget), so std::forward becomes this:\nWidget&& forward(Widget& param)\n{ return static_cast<Widget&&>(param); }\nThere are no references to references here, so there’s no reference collapsing, and this\nis the final instantiated version of std::forward for the call.\nRvalue references returned from functions are defined to be rvalues, so in this case,\nstd::forward will turn f’s parameter fParam (an lvalue) into an rvalue. The end\nresult is that an rvalue argument passed to f will be forwarded to someFunc as an\nrvalue, which is precisely what is supposed to happen.\n200 \n| \nItem 28\nwww.it-ebooks.info\n\n\nIn C++14, the existence of std::remove_reference_t makes it possible to imple‐\nment std::forward a bit more concisely:\ntemplate<typename T>                         // C++14; still in\nT&& forward(remove_reference_t<T>& param)    // namespace std\n{\n  return static_cast<T&&>(param);\n}\nReference collapsing occurs in four contexts. The first and most common is template\ninstantiation. The second is type generation for auto variables. The details are essen‐\ntially the same as for templates, because type deduction for auto variables is essen‐\ntially the same as type deduction for templates (see Item 2). Consider again this\nexample from earlier in the Item:\ntemplate<typename T>\nvoid func(T&& param);\nWidget widgetFactory();     // function returning rvalue\nWidget w;                   // a variable (an lvalue)\nfunc(w);                    // call func with lvalue; T deduced\n                            // to be Widget&\nfunc(widgetFactory());      // call func with rvalue; T deduced\n                            // to be Widget\nThis can be mimicked in auto form. The declaration\nauto&& w1 = w;\ninitializes w1 with an lvalue, thus deducing the type Widget& for auto. Plugging\nWidget& in for auto in the declaration for w1 yields this reference-to-reference code,\nWidget& && w1 = w;\nwhich, after reference collapsing, becomes\nWidget& w1 = w;\nAs a result, w1 is an lvalue reference.\nOn the other hand, this declaration,\nauto&& w2 = widgetFactory();\ninitializes w2 with an rvalue, causing the non-reference type Widget to be deduced for\nauto. Substituting Widget for auto gives us this:\nItem 28 \n| \n201\nwww.it-ebooks.info\n\n\nWidget&& w2 = widgetFactory();\nThere are no references to references here, so we’re done; w2 is an rvalue reference.\nWe’re now in a position to truly understand the universal references introduced in\nItem 24. A universal reference isn’t a new kind of reference, it’s actually an rvalue ref‐\nerence in a context where two conditions are satisfied:\n• Type deduction distinguishes lvalues from rvalues. Lvalues of type T are\ndeduced to have type T&, while rvalues of type T yield T as their deduced type.\n• Reference collapsing occurs.\nThe concept of universal references is useful, because it frees you from having to rec‐\nognize the existence of reference collapsing contexts, to mentally deduce different\ntypes for lvalues and rvalues, and to apply the reference collapsing rule after mentally\nsubstituting the deduced types into the contexts in which they occur.\nI said there were four such contexts, but we’ve discussed only two: template instantia‐\ntion and auto type generation. The third is the generation and use of typedefs and\nalias declarations (see Item 9). If, during creation or evaluation of a typedef, refer‐\nences to references arise, reference collapsing intervenes to eliminate them. For\nexample, suppose we have a Widget class template with an embedded typedef for an\nrvalue reference type,\ntemplate<typename T>\nclass Widget {\npublic:\n  typedef T&& RvalueRefToT;\n  …\n};\nand suppose we instantiate Widget with an lvalue reference type:\nWidget<int&> w;\nSubstituting int& for T in the Widget template gives us the following typedef:\ntypedef int& && RvalueRefToT;\nReference collapsing reduces it to this,\ntypedef int& RvalueRefToT;\nwhich makes clear that the name we chose for the typedef is perhaps not as descrip‐\ntive as we’d hoped: RvalueRefToT is a typedef for an lvalue reference when Widget\nis instantiated with an lvalue reference type.\n202 \n| \nItem 28\nwww.it-ebooks.info\n\n\nThe final context in which reference collapsing takes place is uses of decltype. If,\nduring analysis of a type involving decltype, a reference to a reference arises, refer‐\nence collapsing will kick in to eliminate it. (For information about decltype, see\nItem 3.)\nThings to Remember\n• Reference collapsing occurs in four contexts: template instantiation, auto type\ngeneration, creation and use of typedefs and alias declarations, and\ndecltype.\n• When compilers generate a reference to a reference in a reference collapsing\ncontext, the result becomes a single reference. If either of the original refer‐\nences is an lvalue reference, the result is an lvalue reference. Otherwise it’s an\nrvalue reference.\n• Universal references are rvalue references in contexts where type deduction\ndistinguishes lvalues from rvalues and where reference collapsing occurs.\nItem 29: Assume that move operations are not present,\nnot cheap, and not used.\nMove semantics is arguably the premier feature of C++11. “Moving containers is now\nas cheap as copying pointers!” you’re likely to hear, and “Copying temporary objects\nis now so efficient, coding to avoid it is tantamount to premature optimization!” Such\nsentiments are easy to understand. Move semantics is truly an important feature. It\ndoesn’t just allow compilers to replace expensive copy operations with comparatively\ncheap moves, it actually requires that they do so (when the proper conditions are ful‐\nfilled). Take your C++98 code base, recompile with a C++11-conformant compiler\nand Standard Library, and—shazam!—your software runs faster.\nMove semantics can really pull that off, and that grants the feature an aura worthy of\nlegend. Legends, however, are generally the result of exaggeration. The purpose of\nthis Item is to keep your expectations grounded.\nLet’s begin with the observation that many types fail to support move semantics. The\nentire C++98 Standard Library was overhauled for C++11 to add move operations\nfor types where moving could be implemented faster than copying, and the imple‐\nmentation of the library components was revised to take advantage of these opera‐\ntions, but chances are that you’re working with a code base that has not been\ncompletely revised to take advantage of C++11. For types in your applications (or in\nthe libraries you use) where no modifications for C++11 have been made, the exis‐\nItem 28 \n| \n203\nwww.it-ebooks.info\n\n\nstd::vector<Widget> vw1;\n// put data into vw1\n…\n// move vw1 into vw2. Runs in\n// constant time. Only ptrs\n// in vw1 and vw2 are modified\nauto vw2 = std::move(vw1);\nvw1\nvw1\nnull\nvw2\nWidgets\nWidgets\ntence of move support in your compilers is likely to do you little good. True, C++11\nis willing to generate move operations for classes that lack them, but that happens\nonly for classes declaring no copy operations, move operations, or destructors (see\nItem 17). Data members or base classes of types that have disabled moving (e.g., by\ndeleting the move operations—see Item 11) will also suppress compiler-generated\nmove operations. For types without explicit support for moving and that don’t qual‐\nify for compiler-generated move operations, there is no reason to expect C++11 to\ndeliver any kind of performance improvement over C++98.\nEven types with explicit move support may not benefit as much as you’d hope. All\ncontainers in the standard C++11 library support moving, for example, but it would\nbe a mistake to assume that moving all containers is cheap. For some containers, this\nis because there’s no truly cheap way to move their contents. For others, it’s because\nthe truly cheap move operations the containers offer come with caveats the container\nelements can’t satisfy.\nConsider std::array, a new container in C++11. std::array is essentially a built-\nin array with an STL interface. This is fundamentally different from the other stan‐\ndard containers, each of which stores its contents on the heap. Objects of such\ncontainer types hold (as data members), conceptually, only a pointer to the heap\nmemory storing the contents of the container. (The reality is more complex, but for\npurposes of this analysis, the differences are not important.) The existence of this\npointer makes it possible to move the contents of an entire container in constant\ntime: just copy the pointer to the container’s contents from the source container to\nthe target, and set the source’s pointer to null:\nstd::array objects lack such a pointer, because the data for a std::array’s con‐\ntents are stored directly in the std::array object:\n204 \n| \nItem 29\nwww.it-ebooks.info\n",
      "page_number": 215,
      "chapter_number": 20,
      "summary": "This chapter covers segment 20 (pages 215-222). Key topics include reference, refer. Item 23 remarks that when an argument is passed to a template function, the type\ndeduced for the template parameter encodes whether the argument is an lvalue or an\nrvalue.",
      "keywords": [
        "Widget",
        "reference",
        "lvalue reference",
        "lvalue",
        "reference collapsing",
        "std",
        "type",
        "type Widget",
        "Item",
        "forward",
        "rvalue",
        "universal references",
        "lvalue reference type",
        "template",
        "universal"
      ],
      "concepts": [
        "reference",
        "refer",
        "std",
        "item",
        "widget",
        "templates",
        "type",
        "collapsing",
        "collapse",
        "auto"
      ],
      "similar_chapters": [
        {
          "book": "C++ Templates_ The Complete Guide",
          "chapter": 46,
          "title": "Segment 46 (pages 1469-1503)",
          "relevance_score": 0.67,
          "method": "sentence_transformers"
        },
        {
          "book": "C++ Templates_ The Complete Guide",
          "chapter": 1,
          "title": "Segment 1 (pages 1-35)",
          "relevance_score": 0.66,
          "method": "sentence_transformers"
        },
        {
          "book": "C++ Templates_ The Complete Guide",
          "chapter": 30,
          "title": "Segment 30 (pages 950-980)",
          "relevance_score": 0.66,
          "method": "sentence_transformers"
        },
        {
          "book": "C++ Templates_ The Complete Guide",
          "chapter": 9,
          "title": "Segment 9 (pages 265-294)",
          "relevance_score": 0.65,
          "method": "sentence_transformers"
        },
        {
          "book": "C++ Templates_ The Complete Guide",
          "chapter": 15,
          "title": "Segment 15 (pages 456-487)",
          "relevance_score": 0.65,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 21,
      "title": "Segment 21 (pages 223-230)",
      "start_page": 223,
      "end_page": 230,
      "detection_method": "topic_boundary",
      "content": "std::array<Widget, 10000> aw1;\n// put data into aw1\n…\n// move aw1 into aw2. Runs in\n// linear time. All elements in\n// aw1 are moved into aw2\nauto aw2 = std::move(aw1);\naw1\nWidgets\naw1\nWidgets (moved from)\naw2\nWidgets (moved to)\nNote that the elements in aw1 are moved into aw2. Assuming that Widget is a type\nwhere moving is faster than copying, moving a std::array of Widget will be faster\nthan copying the same std::array. So std::array certainly offers move support.\nYet both moving and copying a std::array have linear-time computational com‐\nplexity, because each element in the container must be copied or moved. This is far\nfrom the “moving a container is now as cheap as assigning a couple of pointers”\nclaim that one sometimes hears.\nOn the other hand, std::string offers constant-time moves and linear-time copies.\nThat makes it sound like moving is faster than copying, but that may not be the case.\nMany string implementations employ the small string optimization (SSO). With the\nSSO, “small” strings (e.g., those with a capacity of no more than 15 characters) are\nstored in a buffer within the std::string object; no heap-allocated storage is used.\nMoving small strings using an SSO-based implementation is no faster than copying\nthem, because the copy-only-a-pointer trick that generally underlies the performance\nadvantage of moves over copies isn’t applicable.\nThe motivation for the SSO is extensive evidence that short strings are the norm for\nmany applications. Using an internal buffer to store the contents of such strings elim‐\ninates the need to dynamically allocate memory for them, and that’s typically an effi‐\nciency win. An implication of the win, however, is that moves are no faster than\ncopies, though one could just as well take a glass-half-full approach and say that for\nsuch strings, copying is no slower than moving.\nEven for types supporting speedy move operations, some seemingly sure-fire move\nsituations can end up making copies. Item 14 explains that some container opera‐\ntions in the Standard Library offer the strong exception safety guarantee and that to\nensure that legacy C++98 code dependent on that guarantee isn’t broken when\nupgrading to C++11, the underlying copy operations may be replaced with move\noperations only if the move operations are known to not throw. A consequence is\nthat even if a type offers move operations that are more efficient than the corre‐\nItem 29 \n| \n205\nwww.it-ebooks.info\n\n\nsponding copy operations, and even if, at a particular point in the code, a move oper‐\nation would generally be appropriate (e.g., if the source object is an rvalue), compilers\nmight still be forced to invoke a copy operation because the corresponding move\noperation isn’t declared noexcept.\nThere are thus several scenarios in which C++11’s move semantics do you no good:\n• No move operations: The object to be moved from fails to offer move opera‐\ntions. The move request therefore becomes a copy request.\n• Move not faster: The object to be moved from has move operations that are no\nfaster than its copy operations.\n• Move not usable: The context in which the moving would take place requires a\nmove operation that emits no exceptions, but that operation isn’t declared noex\ncept.\nIt’s worth mentioning, too, another scenario where move semantics offers no effi‐\nciency gain:\n• Source object is lvalue: With very few exceptions (see e.g., Item 25) only rvalues\nmay be used as the source of a move operation.\nBut the title of this Item is to assume that move operations are not present, not cheap,\nand not used. This is typically the case in generic code, e.g., when writing templates,\nbecause you don’t know all the types you’re working with. In such circumstances, you\nmust be as conservative about copying objects as you were in C++98—before move\nsemantics existed. This is also the case for “unstable” code, i.e., code where the char‐\nacteristics of the types being used are subject to relatively frequent modification.\nOften, however, you know the types your code uses, and you can rely on their charac‐\nteristics not changing (e.g., whether they support inexpensive move operations).\nWhen that’s the case, you don’t need to make assumptions. You can simply look up\nthe move support details for the types you’re using. If those types offer cheap move\noperations, and if you’re using objects in contexts where those move operations will\nbe invoked, you can safely rely on move semantics to replace copy operations with\ntheir less expensive move counterparts.\nThings to Remember\n• Assume that move operations are not present, not cheap, and not used.\n• In code with known types or support for move semantics, there is no need for\nassumptions.\n206 \n| \nItem 29\nwww.it-ebooks.info\n\n\nItem 30: Familiarize yourself with perfect forwarding\nfailure cases.\nOne of the features most prominently emblazoned on the C++11 box is perfect for‐\nwarding. Perfect forwarding. It’s perfect! Alas, tear the box open, and you’ll find that\nthere’s “perfect” (the ideal), and then there’s “perfect” (the reality). C++11’s perfect\nforwarding is very good, but it achieves true perfection only if you’re willing to over‐\nlook an epsilon or two. This Item is devoted to familiarizing you with the epsilons.\nBefore embarking on our epsilon exploration, it’s worthwhile to review what’s meant\nby “perfect forwarding.” “Forwarding” just means that one function passes—forwards\n—its parameters to another function. The goal is for the second function (the one\nbeing forwarded to) to receive the same objects that the first function (the one doing\nthe forwarding) received. That rules out by-value parameters, because they’re copies\nof what the original caller passed in. We want the forwarded-to function to be able to\nwork with the originally-passed-in objects. Pointer parameters are also ruled out,\nbecause we don’t want to force callers to pass pointers. When it comes to general-\npurpose forwarding, we’ll be dealing with parameters that are references.\nPerfect forwarding means we don’t just forward objects, we also forward their salient\ncharacteristics: their types, whether they’re lvalues or rvalues, and whether they’re\nconst or volatile. In conjunction with the observation that we’ll be dealing with\nreference parameters, this implies that we’ll be using universal references (see\nItem 24), because only universal reference parameters encode information about the\nlvalueness and rvalueness of the arguments that are passed to them.\nLet’s assume we have some function f, and we’d like to write a function (in truth, a\nfunction template) that forwards to it. The core of what we need looks like this:\ntemplate<typename T>\nvoid fwd(T&& param)                  // accept any argument\n{\n  f(std::forward<T>(param));         // forward it to f\n}\nForwarding functions are, by their nature, generic. The fwd template, for example,\naccepts any type of argument, and it forwards whatever it gets. A logical extension of\nthis genericity is for forwarding functions to be not just templates, but variadic tem‐\nplates, thus accepting any number of arguments. The variadic form for fwd looks like\nthis:\ntemplate<typename... Ts>\nvoid fwd(Ts&&... params)             // accept any arguments\n{\nItem 30 \n| \n207\nwww.it-ebooks.info\n\n\n  f(std::forward<Ts>(params)...);    // forward them to f\n}\nThis is the form you’ll see in, among other places, the standard containers’ emplace‐\nment functions (see Item 42) and the smart pointer factory functions,\nstd::make_shared and std::make_unique (see Item 21).\nGiven our target function f and our forwarding function fwd, perfect forwarding fails\nif calling f with a particular argument does one thing, but calling fwd with the same\nargument does something different:\nf( expression );      // if this does one thing,\nfwd( expression );    // but this does something else, fwd fails\n                      // to perfectly forward expression to f\nSeveral kinds of arguments lead to this kind of failure. Knowing what they are and\nhow to work around them is important, so let’s tour the kinds of arguments that can’t\nbe perfect-forwarded.\nBraced initializers\nSuppose f is declared like this:\nvoid f(const std::vector<int>& v);\nIn that case, calling f with a braced initializer compiles,\nf({ 1, 2, 3 });       // fine, \"{1, 2, 3}\" implicitly\n                      // converted to std::vector<int>\nbut passing the same braced initializer to fwd doesn’t compile:\nfwd({ 1, 2, 3 });     // error! doesn't compile\nThat’s because the use of a braced initializer is a perfect forwarding failure case.\nAll such failure cases have the same cause. In a direct call to f (such as f({ 1, 2,\n3 })), compilers see the arguments passed at the call site, and they see the types of the\nparameters declared by f. They compare the arguments at the call site to the parame‐\nter declarations to see if they’re compatible, and, if necessary, they perform implicit\nconversions to make the call succeed. In the example above, they generate a tempo‐\nrary std::vector<int> object from { 1, 2, 3 } so that f’s parameter v has a\nstd::vector<int> object to bind to.\nWhen calling f indirectly through the forwarding function template fwd, compilers\nno longer compare the arguments passed at fwd’s call site to the parameter declara‐\ntions in f. Instead, they deduce the types of the arguments being passed to fwd, and\n208 \n| \nItem 30\nwww.it-ebooks.info\n\n\nthey compare the deduced types to f’s parameter declarations. Perfect forwarding\nfails when either of the following occurs:\n• Compilers are unable to deduce a type for one or more of fwd’s parameters. In\nthis case, the code fails to compile.\n• Compilers deduce the “wrong” type for one or more of fwd’s parameters. Here,\n“wrong” could mean that fwd’s instantiation won’t compile with the types that\nwere deduced, but it could also mean that the call to f using fwd’s deduced types\nbehaves differently from a direct call to f with the arguments that were passed to\nfwd. One source of such divergent behavior would be if f were an overloaded\nfunction name, and, due to “incorrect” type deduction, the overload of f called\ninside fwd were different from the overload that would be invoked if f were\ncalled directly.\nIn the “fwd({ 1, 2, 3 })” call above, the problem is that passing a braced initializer\nto a function template parameter that’s not declared to be a std::initial\nizer_list is decreed to be, as the Standard puts it, a “non-deduced context.” In\nplain English, that means that compilers are forbidden from deducing a type for the\nexpression { 1, 2, 3 } in the call to fwd, because fwd’s parameter isn’t declared to be\na std::initializer_list. Being prevented from deducing a type for fwd’s parame‐\nter, compilers must understandably reject the call.\nInterestingly, Item 2 explains that type deduction succeeds for auto variables initial‐\nized with a braced initializer. Such variables are deemed to be std::initial\nizer_list objects, and this affords a simple workaround for cases where the type the\nforwarding function should deduce is a std::initializer_list—declare a local\nvariable using auto, then pass the local variable to the forwarding function:\nauto il = { 1, 2, 3 };     // il's type deduced to be\n                           // std::initializer_list<int>\nfwd(il);                   // fine, perfect-forwards il to f\n0 or NULL as null pointers\nItem 8 explains that when you try to pass 0 or NULL as a null pointer to a template,\ntype deduction goes awry, deducing an integral type (typically int) instead of a\npointer type for the argument you pass. The result is that neither 0 nor NULL can be\nperfect-forwarded as a null pointer. The fix is easy, however: pass nullptr instead of\n0 or NULL. For details, consult Item 8.\nItem 30 \n| \n209\nwww.it-ebooks.info\n\n\nDeclaration-only integral static const data members\nAs a general rule, there’s no need to define integral static const data members in\nclasses; declarations alone suffice. That’s because compilers perform const propaga‐\ntion on such members’ values, thus eliminating the need to set aside memory for\nthem. For example, consider this code:\nclass Widget {\npublic:\n  static const std::size_t MinVals = 28; // MinVals' declaration\n  …\n};\n…                                        // no defn. for MinVals\nstd::vector<int> widgetData;\nwidgetData.reserve(Widget::MinVals);     // use of MinVals\nHere, we’re using Widget::MinVals (henceforth simply MinVals) to specify widget\nData’s initial capacity, even though MinVals lacks a definition. Compilers work\naround the missing definition (as they are required to do) by plopping the value 28\ninto all places where MinVals is mentioned. The fact that no storage has been set\naside for MinVals’ value is unproblematic. If MinVals’ address were to be taken (e.g.,\nif somebody created a pointer to MinVals), then MinVals would require storage (so\nthat the pointer had something to point to), and the code above, though it would\ncompile, would fail at link-time until a definition for MinVals was provided.\nWith that in mind, imagine that f (the function fwd forwards its argument to) is\ndeclared like this:\nvoid f(std::size_t val);\nCalling f with MinVals is fine, because compilers will just replace MinVals with its\nvalue:\nf(Widget::MinVals);         // fine, treated as \"f(28)\"\nAlas, things may not go so smoothly if we try to call f through fwd:\nfwd(Widget::MinVals);       // error! shouldn't link\nThis code will compile, but it shouldn’t link. If that reminds you of what happens if\nwe write code that takes MinVals’ address, that’s good, because the underlying prob‐\nlem is the same.\nAlthough nothing in the source code takes MinVals’ address, fwd’s parameter is a\nuniversal reference, and references, in the code generated by compilers, are usually\ntreated like pointers. In the program’s underlying binary code (and on the hardware),\n210 \n| \nItem 30\nwww.it-ebooks.info\n\n\npointers and references are essentially the same thing. At this level, there’s truth to\nthe adage that references are simply pointers that are automatically dereferenced.\nThat being the case, passing MinVals by reference is effectively the same as passing it\nby pointer, and as such, there has to be some memory for the pointer to point to.\nPassing integral static const data members by reference, then, generally requires\nthat they be defined, and that requirement can cause code using perfect forwarding to\nfail where the equivalent code without perfect forwarding succeeds.\nBut perhaps you noticed the weasel words I sprinkled through the preceding discus‐\nsion. The code “shouldn’t” link. References are “usually” treated like pointers. Passing\nintegral static const data members by reference “generally” requires that they be\ndefined. It’s almost like I know something I don’t really want to tell you…\nThat’s because I do. According to the Standard, passing MinVals by reference\nrequires that it be defined. But not all implementations enforce this requirement. So,\ndepending on your compilers and linkers, you may find that you can perfect-forward\nintegral static const data members that haven’t been defined. If you do, congratu‐\nlations, but there is no reason to expect such code to port. To make it portable, sim‐\nply provide a definition for the integral static const data member in question. For\nMinVals, that’d look like this:\nconst std::size_t Widget::MinVals;     // in Widget's .cpp file\nNote that the definition doesn’t repeat the initializer (28, in the case of MinVals).\nDon’t stress over this detail, however. If you forget and provide the initializer in both\nplaces, your compilers will complain, thus reminding you to specify it only once.\nOverloaded function names and template names\nSuppose our function f (the one we keep wanting to forward arguments to via fwd)\ncan have its behavior customized by passing it a function that does some of its work.\nAssuming this function takes and returns ints, f could be declared like this:\nvoid f(int (*pf)(int));         // pf = \"processing function\"\nIt’s worth noting that f could also be declared using a simpler non-pointer syntax.\nSuch a declaration would look like this, though it’d have the same meaning as the\ndeclaration above:\nvoid f(int pf(int));            // declares same f as above\nEither way, now suppose we have an overloaded function, processVal:\nint processVal(int value);\nint processVal(int value, int priority);\nWe can pass processVal to f,\nItem 30 \n| \n211\nwww.it-ebooks.info\n\n\nf(processVal);                  // fine\nbut it’s something of a surprise that we can. f demands a pointer to a function as its\nargument, but processVal isn’t a function pointer or even a function, it’s the name\nof two different functions. However, compilers know which processVal they need:\nthe one matching f’s parameter type. They thus choose the processVal taking one\nint, and they pass that function’s address to f.\nWhat makes this work is that f’s declaration lets compilers figure out which version\nof processVal is required. fwd, however, being a function template, doesn’t have any\ninformation about what type it needs, and that makes it impossible for compilers to\ndetermine which overload should be passed:\nfwd(processVal);            // error! which processVal?\nprocessVal alone has no type. Without a type, there can be no type deduction, and\nwithout type deduction, we’re left with another perfect forwarding failure case.\nThe same problem arises if we try to use a function template instead of (or in addi‐\ntion to) an overloaded function name. A function template doesn’t represent one\nfunction, it represents many functions:\ntemplate<typename T>\nT workOnVal(T param)        // template for processing values\n{ … }\nfwd(workOnVal);             // error! which workOnVal\n                            // instantiation?\nThe way to get a perfect-forwarding function like fwd to accept an overloaded func‐\ntion name or a template name is to manually specify the overload or instantiation\nyou want to have forwarded. For example, you can create a function pointer of the\nsame type as f’s parameter, initialize that pointer with processVal or workOnVal\n(thus causing the proper version of processVal to be selected or the proper instan‐\ntiation of workOnVal to be generated), and pass the pointer to fwd:\nusing ProcessFuncType =                        // make typedef;\n  int (*)(int);                                // see Item 9\nProcessFuncType processValPtr = processVal;    // specify needed\n                                               // signature for\n                                               // processVal\nfwd(processValPtr);                            // fine\nfwd(static_cast<ProcessFuncType>(workOnVal));  // also fine\n212 \n| \nItem 30\nwww.it-ebooks.info\n",
      "page_number": 223,
      "chapter_number": 21,
      "summary": "This chapter covers segment 21 (pages 223-230). Key topics include forwarded, item, and function. Covers function. With the\nSSO, “small” strings (e.g., those with a capacity of no more than 15 characters) are\nstored in a buffer within the std::string object; no heap-allocated storage is used.",
      "keywords": [
        "move",
        "fwd",
        "move operations",
        "function",
        "Item",
        "std",
        "type",
        "perfect forwarding",
        "forwarding",
        "n’t",
        "MinVals",
        "operations",
        "int",
        "code",
        "compilers"
      ],
      "concepts": [
        "forwarded",
        "item",
        "function",
        "functions",
        "pointers",
        "std",
        "type",
        "compilers",
        "compiles",
        "copying"
      ],
      "similar_chapters": [
        {
          "book": "More Effective C++",
          "chapter": 7,
          "title": "Segment 7 (pages 52-60)",
          "relevance_score": 0.66,
          "method": "sentence_transformers"
        },
        {
          "book": "Computer Systems A Programmer’s Perspective",
          "chapter": 18,
          "title": "Segment 18 (pages 352-373)",
          "relevance_score": 0.61,
          "method": "sentence_transformers"
        },
        {
          "book": "More Effective C++",
          "chapter": 32,
          "title": "Segment 32 (pages 320-329)",
          "relevance_score": 0.61,
          "method": "sentence_transformers"
        },
        {
          "book": "C++ Concurrency in Action",
          "chapter": 6,
          "title": "Segment 6 (pages 50-58)",
          "relevance_score": 0.6,
          "method": "sentence_transformers"
        },
        {
          "book": "C++ Templates_ The Complete Guide",
          "chapter": 32,
          "title": "Segment 32 (pages 1015-1044)",
          "relevance_score": 0.6,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 22,
      "title": "Segment 22 (pages 231-241)",
      "start_page": 231,
      "end_page": 241,
      "detection_method": "topic_boundary",
      "content": "3 This assumes that bitfields are laid out lsb (least significant bit) to msb (most significant bit). C++ doesn’t\nguarantee that, but compilers often provide a mechanism that allows programmers to control bitfield layout.\nOf course, this requires that you know the type of function pointer that fwd is for‐\nwarding to. It’s not unreasonable to assume that a perfect-forwarding function will\ndocument that. After all, perfect-forwarding functions are designed to accept any‐\nthing, so if there’s no documentation telling you what to pass, how would you know?\nBitfields\nThe final failure case for perfect forwarding is when a bitfield is used as a function\nargument. To see what this means in practice, observe that an IPv4 header can be\nmodeled as follows:3\nstruct IPv4Header {\n  std::uint32_t version:4,\n                IHL:4,\n                DSCP:6,\n                ECN:2,\n                totalLength:16;\n  …\n};\nIf our long-suffering function f (the perennial target of our forwarding function fwd)\nis declared to take a std::size_t parameter, calling it with, say, the totalLength\nfield of an IPv4Header object compiles without fuss:\nvoid f(std::size_t sz);        // function to call\nIPv4Header h;\n…\nf(h.totalLength);              // fine\nTrying to forward h.totalLength to f via fwd, however, is a different story:\nfwd(h.totalLength);            // error!\nThe problem is that fwd’s parameter is a reference, and h.totalLength is a non-\nconst bitfield. That may not sound so bad, but the C++ Standard condemns the\ncombination in unusually clear prose: “A non-const reference shall not be bound to\na bit-field.” There’s an excellent reason for the prohibition. Bitfields may consist of\narbitrary parts of machine words (e.g., bits 3-5 of a 32-bit int), but there’s no way to\ndirectly address such things. I mentioned earlier that references and pointers are the\nsame thing at the hardware level, and just as there’s no way to create a pointer to\nItem 30 \n| \n213\nwww.it-ebooks.info\n\n\narbitrary bits (C++ dictates that the smallest thing you can point to is a char), there’s\nno way to bind a reference to arbitrary bits, either.\nWorking around the impossibility of perfect-forwarding a bitfield is easy, once you\nrealize that any function that accepts a bitfield as an argument will receive a copy of\nthe bitfield’s value. After all, no function can bind a reference to a bitfield, nor can\nany function accept pointers to bitfields, because pointers to bitfields don’t exist. The\nonly kinds of parameters to which a bitfield can be passed are by-value parameters\nand, interestingly, references-to-const. In the case of by-value parameters, the called\nfunction obviously receives a copy of the value in the bitfield, and it turns out that in\nthe case of a reference-to-const parameter, the Standard requires that the reference\nactually bind to a copy of the bitfield’s value that’s stored in an object of some stan‐\ndard integral type (e.g., int). References-to-const don’t bind to bitfields, they bind\nto “normal” objects into which the values of the bitfields have been copied.\nThe key to passing a bitfield into a perfect-forwarding function, then, is to take\nadvantage of the fact that the forwarded-to function will always receive a copy of the\nbitfield’s value. You can thus make a copy yourself and call the forwarding function\nwith the copy. In the case of our example with IPv4Header, this code would do the\ntrick:\n// copy bitfield value; see Item 6 for info on init. form\nauto length = static_cast<std::uint16_t>(h.totalLength);\nfwd(length);                        // forward the copy\nUpshot\nIn most cases, perfect forwarding works exactly as advertised. You rarely have to\nthink about it. But when it doesn’t work—when reasonable-looking code fails to\ncompile or, worse, compiles, but doesn’t behave the way you anticipate—it’s impor‐\ntant to know about perfect forwarding’s imperfections. Equally important is knowing\nhow to work around them. In most cases, this is straightforward. \nThings to Remember\n• Perfect forwarding fails when template type deduction fails or when it deduces\nthe wrong type.\n• The kinds of arguments that lead to perfect forwarding failure are braced ini‐\ntializers, null pointers expressed as 0 or NULL, declaration-only integral const\nstatic data members, template and overloaded function names, and bitfields.\n214 \n| \nItem 30\nwww.it-ebooks.info\n\n\nCHAPTER 6\nLambda Expressions\nLambda expressions—lambdas—are a game changer in C++ programming. That’s\nsomewhat surprising, because they bring no new expressive power to the language.\nEverything a lambda can do is something you can do by hand with a bit more typing.\nBut lambdas are such a convenient way to create function objects, the impact on day-\nto-day C++ software development is enormous. Without lambdas, the STL “_if”\nalgorithms (e.g., std::find_if, std::remove_if, std::count_if, etc.) tend to be\nemployed with only the most trivial predicates, but when lambdas are available, use\nof these algorithms with nontrivial conditions blossoms. The same is true of algo‐\nrithms that can be customized with comparison functions (e.g., std::sort,\nstd::nth_element, std::lower_bound, etc.). Outside the STL, lambdas make it\npossible \nto \nquickly \ncreate \ncustom \ndeleters \nfor \nstd::unique_ptr \nand\nstd::shared_ptr (see Items 18 and 19), and they make the specification of predi‐\ncates for condition variables in the threading API equally straightforward (see\nItem 39). Beyond the Standard Library, lambdas facilitate the on-the-fly specification\nof callback functions, interface adaption functions, and context-specific functions for\none-off calls. Lambdas really make C++ a more pleasant programming language.\nThe vocabulary associated with lambdas can be confusing. Here’s a brief refresher:\n• A lambda expression is just that: an expression. It’s part of the source code. In\nstd::find_if(container.begin(), container.end(),\n             [](int val) { return 0 < val && val < 10; });\nthe highlighted expression is the lambda.\n• A closure is the runtime object created by a lambda. Depending on the capture\nmode, closures hold copies of or references to the captured data. In the call to\n215\nwww.it-ebooks.info\n\n\nstd::find_if above, the closure is the object that’s passed at runtime as the\nthird argument to std::find_if.\n• A closure class is a class from which a closure is instantiated. Each lambda causes\ncompilers to generate a unique closure class. The statements inside a lambda\nbecome executable instructions in the member functions of its closure class.\nA lambda is often used to create a closure that’s used only as an argument to a func‐\ntion. That’s the case in the call to std::find_if above. However, closures may gen‐\nerally be copied, so it’s usually possible to have multiple closures of a closure type\ncorresponding to a single lambda. For example, in the following code,\n{\n  int x;                                 // x is local variable\n  …\n  auto c1 =                              // c1 is copy of the\n    [x](int y) { return x * y > 55; };   // closure produced\n                                         // by the lambda\n  auto c2 = c1;                          // c2 is copy of c1\n  auto c3 = c2;                          // c3 is copy of c2\n  …\n}\nc1, c2, and c3 are all copies of the closure produced by the lambda.\nInformally, it’s perfectly acceptable to blur the lines between lambdas, closures, and\nclosure classes. But in the Items that follow, it’s often important to distinguish what\nexists during compilation (lambdas and closure classes), what exists at runtime (clo‐\nsures), and how they relate to one another.\nItem 31: Avoid default capture modes.\nThere are two default capture modes in C++11: by-reference and by-value. Default\nby-reference capture can lead to dangling references. Default by-value capture lures\nyou into thinking you’re immune to that problem (you’re not), and it lulls you into\nthinking your closures are self-contained (they may not be).\nThat’s the executive summary for this Item. If you’re more engineer than executive,\nyou’ll want some meat on those bones, so let’s start with the danger of default by-\nreference capture.\n216 \n| \nItem 30\nwww.it-ebooks.info\n\n\nA by-reference capture causes a closure to contain a reference to a local variable or to\na parameter that’s available in the scope where the lambda is defined. If the lifetime\nof a closure created from that lambda exceeds the lifetime of the local variable or\nparameter, the reference in the closure will dangle. For example, suppose we have a\ncontainer of filtering functions, each of which takes an int and returns a bool indi‐\ncating whether a passed-in value satisfies the filter:\nusing FilterContainer =                     // see Item 9 for\n  std::vector<std::function<bool(int)>>;    // \"using\", Item 2\n                                            // for std::function\nFilterContainer filters;                    // filtering funcs\nWe could add a filter for multiples of 5 like this:\nfilters.emplace_back(                       // see Item 42 for\n  [](int value) { return value % 5 == 0; }  // info on\n);                                          // emplace_back\nHowever, it may be that we need to compute the divisor at runtime, i.e., we can’t just\nhard-code 5 into the lambda. So adding the filter might look more like this:\nvoid addDivisorFilter()\n{\n  auto calc1 = computeSomeValue1();\n  auto calc2 = computeSomeValue2();\n  auto divisor = computeDivisor(calc1, calc2);\n  filters.emplace_back(                              // danger!\n    [&](int value) { return value % divisor == 0; }  // ref to\n  );                                                 // divisor\n}                                                    // will\n                                                     // dangle!\nThis code is a problem waiting to happen. The lambda refers to the local variable\ndivisor, but that variable ceases to exist when addDivisorFilter returns. That’s\nimmediately after filters.emplace_back returns, so the function that’s added to\nfilters is essentially dead on arrival. Using that filter yields undefined behavior\nfrom virtually the moment it’s created.\nNow, the same problem would exist if divisor’s by-reference capture were explicit,\nfilters.emplace_back(\n  [&divisor](int value)                // danger! ref to\n  { return value % divisor == 0; }     // divisor will\n);                                     // still dangle!\nItem 31 \n| \n217\nwww.it-ebooks.info\n\n\nbut with an explicit capture, it’s easier to see that the viability of the lambda is depen‐\ndent on divisor’s lifetime. Also, writing out the name, “divisor,” reminds us to\nensure that divisor lives at least as long as the lambda’s closures. That’s a more spe‐\ncific memory jog than the general “make sure nothing dangles” admonition that\n“[&]” conveys.\nIf you know that a closure will be used immediately (e.g., by being passed to an STL\nalgorithm) and won’t be copied, there is no risk that references it holds will outlive\nthe local variables and parameters in the environment where its lambda is created. In\nthat case, you might argue, there’s no risk of dangling references, hence no reason to\navoid a default by-reference capture mode. For example, our filtering lambda might\nbe used only as an argument to C++11’s std::all_of, which returns whether all ele‐\nments in a range satisfy a condition:\ntemplate<typename C>\nvoid workWithContainer(const C& container)\n{\n  auto calc1 = computeSomeValue1();             // as above\n  auto calc2 = computeSomeValue2();             // as above\n  auto divisor = computeDivisor(calc1, calc2);  // as above\n  using ContElemT = typename C::value_type;     // type of\n                                                // elements in\n                                                // container\n  using std::begin;                             // for\n  using std::end;                               // genericity;\n                                                // see Item 13\n  if (std::all_of(                              // if all values\n        begin(container), end(container),       // in container\n        [&](const ContElemT& value)             // are multiples\n        { return value % divisor == 0; })       // of divisor...\n      ) {\n    …                                           // they are...\n  } else {\n    …                                           // at least one\n  }                                             // isn't...\n}\nIt’s true, this is safe, but its safety is somewhat precarious. If the lambda were found\nto be useful in other contexts (e.g., as a function to be added to the filters con‐\ntainer) and was copy-and-pasted into a context where its closure could outlive divi\n218 \n| \nItem 31\nwww.it-ebooks.info\n\n\nsor, you’d be back in dangle-city, and there’d be nothing in the capture clause to\nspecifically remind you to perform lifetime analysis on divisor.\nLong-term, it’s simply better software engineering to explicitly list the local variables\nand parameters that a lambda depends on.\nBy the way, the ability to use auto in C++14 lambda parameter specifications means\nthat the code above can be simplified in C++14. The ContElemT typedef can be elimi‐\nnated, and the if condition can be revised as follows:\nif (std::all_of(begin(container), end(container),\n                [&](const auto& value)                // C++14\n                { return value % divisor == 0; }))\nOne way to solve our problem with divisor would be a default by-value capture\nmode. That is, we could add the lambda to filters as follows:\nfilters.emplace_back(                                 // now\n  [=](int value) { return value % divisor == 0; }     // divisor\n);                                                    // can't\n                                                      // dangle\nThis suffices for this example, but, in general, default by-value capture isn’t the anti-\ndangling elixir you might imagine. The problem is that if you capture a pointer by\nvalue, you copy the pointer into the closures arising from the lambda, but you don’t\nprevent code outside the lambda from deleteing the pointer and causing your\ncopies to dangle.\n“That could never happen!” you protest. “Having read Chapter 4, I worship at the\nhouse of smart pointers. Only loser C++98 programmers use raw pointers and\ndelete.” That may be true, but it’s irrelevant because you do, in fact, use raw point‐\ners, and they can, in fact, be deleted out from under you. It’s just that in your\nmodern C++ programming style, there’s often little sign of it in the source code.\nSuppose one of the things Widgets can do is add entries to the container  of filters:\nclass Widget {\npublic:\n  …                                  // ctors, etc.\n  void addFilter() const;            // add an entry to filters\nprivate:\n  int divisor;                       // used in Widget's filter\n};\nWidget::addFilter could be defined like this:\nItem 31 \n| \n219\nwww.it-ebooks.info\n\n\nvoid Widget::addFilter() const\n{\n  filters.emplace_back(\n    [=](int value) { return value % divisor == 0; }\n  );\n}\nTo the blissfully uninitiated, this looks like safe code. The lambda is dependent on\ndivisor, but the default by-value capture mode ensures that divisor is copied into\nany closures arising from the lambda, right?\nWrong. Completely wrong. Horribly wrong. Fatally wrong.\nCaptures apply only to non-static local variables (including parameters) visible in\nthe scope where the lambda is created. In the body of Widget::addFilter, divisor\nis not a local variable, it’s a data member of the Widget class. It can’t be captured. Yet\nif the default capture mode is eliminated, the code won’t compile:\nvoid Widget::addFilter() const\n{\n  filters.emplace_back(                             // error!\n    [](int value) { return value % divisor == 0; }  // divisor\n  );                                                // not\n}                                                   // available\nFurthermore, if an attempt is made to explicitly capture divisor (either by value or\nby reference—it doesn’t matter), the capture won’t compile, because divisor isn’t a\nlocal variable or a parameter:\nvoid Widget::addFilter() const\n{\n  filters.emplace_back(\n    [divisor](int value)                // error! no local\n    { return value % divisor == 0; }    // divisor to capture\n  );\n}\nSo if the default by-value capture clause isn’t capturing divisor, yet without the\ndefault by-value capture clause, the code won’t compile, what’s going on?\nThe explanation hinges on the implicit use of a raw pointer: this. Every non-static\nmember function has a this pointer, and you use that pointer every time you men‐\ntion a data member of the class. Inside any Widget member function, for example,\ncompilers internally replace uses of divisor with this->divisor. In the version of\nWidget::addFilter with a default by-value capture,\n220 \n| \nItem 31\nwww.it-ebooks.info\n\n\nvoid Widget::addFilter() const\n{\n  filters.emplace_back(\n    [=](int value) { return value % divisor == 0; }\n  );\n}\nwhat’s being captured is the Widget’s this pointer, not divisor. Compilers treat the\ncode as if it had been written as follows:\nvoid Widget::addFilter() const\n{\n  auto currentObjectPtr = this;\n  \n  filters.emplace_back(\n    [currentObjectPtr](int value)\n    { return value % currentObjectPtr->divisor == 0; }\n  );\n}\nUnderstanding this is tantamount to understanding that the viability of the closures\narising from this lambda is tied to the lifetime of the Widget whose this pointer they\ncontain a copy of. In particular, consider this code, which, in accord with Chapter 4,\nuses pointers of only the smart variety:\nusing FilterContainer =                     // as before\n  std::vector<std::function<bool(int)>>;\nFilterContainer filters;                    // as before\nvoid doSomeWork()\n{\n  auto pw =                       // create Widget; see\n    std::make_unique<Widget>();   // Item 21 for\n                                  // std::make_unique\n  pw->addFilter();                // add filter that uses\n                                  // Widget::divisor\n  …\n}                                 // destroy Widget; filters\n                                  // now holds dangling pointer!\nWhen a call is made to doSomeWork, a filter is created that depends on the Widget\nobject produced by std::make_unique, i.e., a filter that contains a copy of a pointer\nto that Widget—the Widget’s this pointer. This filter is added to filters, but when\ndoSomeWork finishes, the Widget is destroyed by the std::unique_ptr managing its\nItem 31 \n| \n221\nwww.it-ebooks.info\n\n\nlifetime (see Item 18). From that point on, filters contains an entry with a dangling\npointer.\nThis particular problem can be solved by making a local copy of the data member\nyou want to capture and then capturing the copy:\nvoid Widget::addFilter() const\n{\n  auto divisorCopy = divisor;                // copy data member\n  filters.emplace_back(\n    [divisorCopy](int value)                 // capture the copy\n    { return value % divisorCopy == 0; }     // use the copy\n  );\n}\nTo be honest, if you take this approach, default by-value capture will work, too,\nvoid Widget::addFilter() const\n{\n  auto divisorCopy = divisor;                // copy data member\n  filters.emplace_back(\n    [=](int value)                           // capture the copy\n    { return value % divisorCopy == 0; }     // use the copy\n  );\n}\nbut why tempt fate? A default capture mode is what made it possible to accidentally\ncapture this when you thought you were capturing divisor in the first place.\nIn C++14, a better way to capture a data member is to use generalized lambda cap‐\nture (see Item 32):\nvoid Widget::addFilter() const\n{\n  filters.emplace_back(               // C++14:\n    [divisor = divisor](int value)    // copy divisor to closure\n    { return value % divisor == 0; }  // use the copy\n  );\n}\nThere’s no such thing as a default capture mode for a generalized lambda capture,\nhowever, so even in C++14, the advice of this Item—to avoid default capture modes\n—stands.\nAn additional drawback to default by-value captures is that they can suggest that the\ncorresponding closures are self-contained and insulated from changes to data outside\n222 \n| \nItem 31\nwww.it-ebooks.info\n\n\nthe closures. In general, that’s not true, because lambdas may be dependent not just\non local variables and parameters (which may be captured), but also on objects with\nstatic storage duration. Such objects are defined at global or namespace scope or are\ndeclared static inside classes, functions, or files. These objects can be used inside\nlambdas, but they can’t be captured. Yet specification of a default by-value capture\nmode can lend the impression that they are. Consider this revised version of the add\nDivisorFilter function we saw earlier:\nvoid addDivisorFilter()\n{\n  static auto calc1 = computeSomeValue1();      // now static\n  static auto calc2 = computeSomeValue2();      // now static\n  static auto divisor =                         // now static\n    computeDivisor(calc1, calc2);\n  filters.emplace_back(\n    [=](int value)                     // captures nothing!\n    { return value % divisor == 0; }   // refers to above static\n  );\n  ++divisor;                           // modify divisor\n}\nA casual reader of this code could be forgiven for seeing “[=]” and thinking, “Okay,\nthe lambda makes a copy of all the objects it uses and is therefore self-contained.” But\nit’s not self-contained. This lambda doesn’t use any non-static local variables, so\nnothing is captured. Rather, the code for the lambda refers to the static variable\ndivisor. When, at the end of each invocation of addDivisorFilter, divisor is\nincremented, any lambdas that have been added to filters via this function will\nexhibit new behavior (corresponding to the new value of divisor). Practically speak‐\ning, this lambda captures divisor by reference, a direct contradiction to what the\ndefault by-value capture clause seems to imply. If you stay away from default by-\nvalue capture clauses, you eliminate the risk of your code being misread in this way.\nThings to Remember\n• Default by-reference capture can lead to dangling references.\n• Default by-value capture is susceptible to dangling pointers (especially this),\nand it misleadingly suggests that lambdas are self-contained.\nItem 31 \n| \n223\nwww.it-ebooks.info\n",
      "page_number": 231,
      "chapter_number": 22,
      "summary": "This chapter covers segment 22 (pages 231-241). Key topics include functions, lambda, and divisor. Covers function. C++ doesn’t\nguarantee that, but compilers often provide a mechanism that allows programmers to control bitfield layout.",
      "keywords": [
        "divisor",
        "Default by-value capture",
        "Widget",
        "Lambda",
        "capture",
        "Item",
        "std",
        "void Widget",
        "copy",
        "function",
        "default",
        "by-value capture",
        "Default by-value",
        "closure",
        "int"
      ],
      "concepts": [
        "functions",
        "lambda",
        "divisor",
        "std",
        "capture",
        "captured",
        "value",
        "auto",
        "void",
        "filtering"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 7",
          "chapter": 59,
          "title": "Segment 59 (pages 567-580)",
          "relevance_score": 0.61,
          "method": "sentence_transformers"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 7,
          "title": "Segment 7 (pages 121-141)",
          "relevance_score": 0.61,
          "method": "sentence_transformers"
        },
        {
          "book": "C++ Templates_ The Complete Guide",
          "chapter": 21,
          "title": "Segment 21 (pages 651-684)",
          "relevance_score": 0.6,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 1",
          "chapter": 11,
          "title": "Segment 11 (pages 99-106)",
          "relevance_score": 0.59,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 2",
          "chapter": 2,
          "title": "Segment 2 (pages 9-16)",
          "relevance_score": 0.59,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 23,
      "title": "Segment 23 (pages 242-249)",
      "start_page": 242,
      "end_page": 249,
      "detection_method": "topic_boundary",
      "content": "Item 32: Use init capture to move objects into closures.\nSometimes neither by-value capture nor by-reference capture is what you want. If\nyou have a move-only object (e.g., a std::unique_ptr or a std::future) that you\nwant to get into a closure, C++11 offers no way to do it. If you have an object that’s\nexpensive to copy but cheap to move (e.g., most containers in the Standard Library),\nand you’d like to get that object into a closure, you’d much rather move it than copy\nit. Again, however, C++11 gives you no way to accomplish that.\nBut that’s C++11. C++14 is a different story. It offers direct support for moving\nobjects into closures. If your compilers are C++14-compliant, rejoice and read on. If\nyou’re still working with C++11 compilers, you should rejoice and read on, too,\nbecause there are ways to approximate move capture in C++11.\nThe absence of move capture was recognized as a shortcoming even as C++11 was\nadopted. The straightforward remedy would have been to add it in C++14, but the\nStandardization Committee chose a different path. They introduced a new capture\nmechanism that’s so flexible, capture-by-move is only one of the tricks it can per‐\nform. The new capability is called init capture. It can do virtually everything the\nC++11 capture forms can do, plus more. The one thing you can’t express with an init\ncapture is a default capture mode, but Item 31 explains that you should stay away\nfrom those, anyway. (For situations covered by C++11 captures, init capture’s syntax\nis a bit wordier, so in cases where a C++11 capture gets the job done, it’s perfectly\nreasonable to use it.)\nUsing an init capture makes it possible for you to specify\n1. the name of a data member in the closure class generated from the lambda and\n2. an expression initializing that data member.\nHere’s how you can use init capture to move a std::unique_ptr into a closure:\nclass Widget {                          // some useful type\npublic:\n  …\n  bool isValidated() const;\n  bool isProcessed() const;\n  bool isArchived() const;\nprivate:\n  …\n};\n224 \n| \nItem 32\nwww.it-ebooks.info\n\n\nauto pw = std::make_unique<Widget>();   // create Widget; see\n                                        // Item 21 for info on\n                                        // std::make_unique\n…                                       // configure *pw\nauto func = [pw = std::move(pw)]               // init data mbr\n            { return pw->isValidated()         // in closure w/\n                     && pw->isArchived(); };   // std::move(pw)\nThe highlighted text comprises the init capture. To the left of the “=” is the name of\nthe data member in the closure class you’re specifying, and to the right is the initializ‐\ning expression. Interestingly, the scope on the left of the “=” is different from the\nscope on the right. The scope on the left is that of the closure class. The scope on the\nright is the same as where the lambda is being defined. In the example above, the\nname pw on the left of the “=” refers to a data member in the closure class, while the\nname pw on the right refers to the object declared above the lambda, i.e., the variable\ninitialized by the call to std::make_unique. So “pw = std::move(pw)” means “create\na data member pw in the closure, and initialize that data member with the result of\napplying std::move to the local variable pw.”\nAs usual, code in the body of the lambda is in the scope of the closure class, so uses of\npw there refer to the closure class data member.\nThe comment “configure *pw” in this example indicates that after the Widget is cre‐\nated by std::make_unique and before the std::unique_ptr to that Widget is cap‐\ntured by the lambda, the Widget is modified in some way. If no such configuration is\nnecessary, i.e., if the Widget created by std::make_unique is in a state suitable to be\ncaptured by the lambda, the local variable pw is unnecessary, because the closure\nclass’s data member can be directly initialized by std::make_unique:\nauto func = [pw = std::make_unique<Widget>()]  // init data mbr\n            { return pw->isValidated()         // in closure w/\n                     && pw->isArchived(); };   // result of call\n                                               // to make_unique\nThis should make clear that the C++14 notion of “capture” is considerably general‐\nized from C++11, because in C++11, it’s not possible to capture the result of an\nexpression. As a result, another name for init capture is generalized lambda capture.\nBut what if one or more of the compilers you use lacks support for C++14’s init cap‐\nture? How can you accomplish move capture in a language lacking support for move\ncapture?\nItem 32 \n| \n225\nwww.it-ebooks.info\n\n\nRemember that a lambda expression is simply a way to cause a class to be generated\nand an object of that type to be created. There is nothing you can do with a lambda\nthat you can’t do by hand. The example C++14 code we just saw, for example, can be\nwritten in C++11 like this:\nclass IsValAndArch {                         // \"is validated\npublic:                                      // and archived\"\n  using DataType = std::unique_ptr<Widget>;\n  explicit IsValAndArch(DataType&& ptr)      // Item 25 explains\n  : pw(std::move(ptr)) {}                    // use of std::move\n  bool operator()() const\n  { return pw->isValidated() && pw->isArchived(); }\nprivate:\n  DataType pw;\n};\nauto func = IsValAndArch(std::make_unique<Widget>());\nThat’s more work than writing the lambda, but it doesn’t change the fact that if you\nwant a class in C++11 that supports move-initialization of its data members, the only\nthing between you and your desire is a bit of time with your keyboard.\nIf you want to stick with lambdas (and given their convenience, you probably do),\nmove capture can be emulated in C++11 by\n1. moving the object to be captured into a function object produced by\nstd::bind and\n2. giving the lambda a reference to the “captured” object.\nIf you’re familiar with std::bind, the code is pretty straightforward. If you’re not\nfamiliar with std::bind, the code takes a little getting used to, but it’s worth the\ntrouble.\nSuppose you’d like to create a local std::vector, put an appropriate set of values\ninto it, then move it into a closure. In C++14, this is easy:\nstd::vector<double> data;                 // object to be moved\n                                          // into closure\n…                                         // populate data\nauto func = [data = std::move(data)]      // C++14 init capture\n            { /* uses of data */ };\n226 \n| \nItem 32\nwww.it-ebooks.info\n\n\nI’ve highlighted key parts of this code: the type of object you want to move\n(std::vector<double>), the name of that object (data), and the initializing expres‐\nsion for the init capture (std::move(data)). The C++11 equivalent is as follows,\nwhere I’ve highlighted the same key things:\nstd::vector<double> data;                 // as above\n…                                         // as above\nauto func =\n  std::bind(                              // C++11 emulation\n    [](const std::vector<double>& data)   // of init capture\n    { /* uses of data */ },\n    std::move(data)\n  );\nLike lambda expressions, std::bind produces function objects. I call function\nobjects returned by std::bind bind objects. The first argument to std::bind is a\ncallable object. Subsequent arguments represent values to be passed to that object.\nA bind object contains copies of all the arguments passed to std::bind. For each\nlvalue argument, the corresponding object in the bind object is copy constructed. For\neach rvalue, it’s move constructed. In this example, the second argument is an rvalue\n(the result of std::move—see Item 23), so data is move constructed into the bind\nobject. This move construction is the crux of move capture emulation, because mov‐\ning an rvalue into a bind object is how we work around the inability to move an\nrvalue into a C++11 closure.\nWhen a bind object is “called” (i.e., its function call operator is invoked) the argu‐\nments it stores are passed to the callable object originally passed to std::bind. In\nthis example, that means that when func (the bind object) is called, the move-\nconstructed copy of data inside func is passed as an argument to the lambda that\nwas passed to std::bind.\nThis lambda is the same as the lambda we’d use in C++14, except a parameter, data,\nhas been added to correspond to our pseudo-move-captured object. This parameter\nis an lvalue reference to the copy of data in the bind object. (It’s not an rvalue refer‐\nence, because although the expression used to initialize the copy of data\n(“std::move(data)”) is an rvalue, the copy of data itself is an lvalue.) Uses of data\ninside the lambda will thus operate on the move-constructed copy of data inside the\nbind object.\nBy default, the operator() member function inside the closure class generated from\na lambda is const. That has the effect of rendering all data members in the closure\nItem 32 \n| \n227\nwww.it-ebooks.info\n\n\nconst within the body of the lambda. The move-constructed copy of data inside the\nbind object is not const, however, so to prevent that copy of data from being modi‐\nfied inside the lambda, the lambda’s parameter is declared reference-to-const. If the\nlambda were declared mutable, operator() in its closure class would not be\ndeclared const, and it would be appropriate to omit const in the lambda’s parame‐\nter declaration:\nauto func =\n  std::bind(                               // C++11 emulation\n    [](std::vector<double>& data) mutable  // of init capture\n    { /* uses of data */ },                // for mutable lambda\n    std::move(data)\n  );\nBecause a bind object stores copies of all the arguments passed to std::bind, the\nbind object in our example contains a copy of the closure produced by the lambda\nthat is its first argument. The lifetime of the closure is therefore the same as the life‐\ntime of the bind object. That’s important, because it means that as long as the closure\nexists, the bind object containing the pseudo-move-captured object exists, too.\nIf this is your first exposure to std::bind, you may need to consult your favorite\nC++11 reference before all the details of the foregoing discussion fall into place. Even\nif that’s the case, these fundamental points should be clear:\n• It’s not possible to move-construct an object into a C++11 closure, but it is possi‐\nble to move-construct an object into a C++11 bind object.\n• Emulating move-capture in C++11 consists of move-constructing an object into\na bind object, then passing the move-constructed object to the lambda by refer‐\nence.\n• Because the lifetime of the bind object is the same as that of the closure, it’s pos‐\nsible to treat objects in the bind object as if they were in the closure.\nAs a second example of using std::bind to emulate move capture, here’s the C++14\ncode we saw earlier to create a std::unique_ptr in a closure:\nauto func = [pw = std::make_unique<Widget>()]    // as before,\n            { return pw->isValidated()           // create pw\n                     && pw->isArchived(); };     // in closure\nAnd here’s the C++11 emulation:\nauto func = std::bind(\n              [](const std::unique_ptr<Widget>& pw)\n              { return pw->isValidated()\n                     && pw->isArchived(); },\n228 \n| \nItem 32\nwww.it-ebooks.info\n\n\n              std::make_unique<Widget>()\n            );\nIt’s ironic that I’m showing how to use std::bind to work around limitations in\nC++11 lambdas, because in Item 34, I advocate the use of lambdas over std::bind.\nHowever, that Item explains that there are some cases in C++11 where std::bind\ncan be useful, and this is one of them. (In C++14, features such as init capture and\nauto parameters eliminate those cases.)\nThings to Remember\n• Use C++14’s init capture to move objects into closures.\n• In C++11, emulate init capture via hand-written classes or std::bind.\nItem 33: Use decltype on auto&& parameters to\nstd::forward them.\nOne of the most exciting features of C++14 is generic lambdas—lambdas that use\nauto in their parameter specifications. The implementation of this feature is straight‐\nforward: operator() in the lambda’s closure class is a template. Given this lambda,\nfor example,\nauto f = [](auto x){ return func(normalize(x)); };\nthe closure class’s function call operator looks like this:\nclass SomeCompilerGeneratedClassName {\npublic:\n  template<typename T>                   // see Item 3 for \n  auto operator()(T x) const             // auto return type\n  { return func(normalize(x)); }\n  …                                      // other closure class\n};                                       // functionality\nIn this example, the only thing the lambda does with its parameter x is forward it to\nnormalize. If normalize treats lvalues differently from rvalues, this lambda isn’t\nwritten properly, because it always passes an lvalue (the parameter x) to normalize,\neven if the argument that was passed to the lambda was an rvalue.\nThe correct way to write the lambda is to have it perfect-forward x to normalize.\nDoing that requires two changes to the code. First, x has to become a universal refer‐\nItem 32 \n| \n229\nwww.it-ebooks.info\n\n\nence (see Item 24), and second, it has to be passed to normalize via std::forward\n(see Item 25). In concept, these are trivial modifications:\nauto f = [](auto&& x)\n         { return func(normalize(std::forward<???>(x))); };\nBetween concept and realization, however, is the question of what type to pass to\nstd::forward, i.e., to determine what should go where I’ve written ??? above.\nNormally, when you employ perfect forwarding, you’re in a template function taking\na type parameter T, so you just write std::forward<T>. In the generic lambda,\nthough, there’s no type parameter T available to you. There is a T in the templatized\noperator() inside the closure class generated by the lambda, but it’s not possible to\nrefer to it from the lambda, so it does you no good.\nItem 28 explains that if an lvalue argument is passed to a universal reference parame‐\nter, the type of that parameter becomes an lvalue reference. If an rvalue is passed, the\nparameter becomes an rvalue reference. This means that in our lambda, we can\ndetermine whether the argument passed was an lvalue or an rvalue by inspecting the\ntype of the parameter x. decltype gives us a way to do that (see Item 3). If an lvalue\nwas passed in, decltype(x) will produce a type that’s an lvalue reference. If an\nrvalue was passed, decltype(x) will produce an rvalue reference type.\nItem 28 also explains that when calling std::forward, convention dictates that the\ntype argument be an lvalue reference to indicate an lvalue and a non-reference to\nindicate an rvalue. In our lambda, if x is bound to an lvalue, decltype(x) will yield\nan lvalue reference. That conforms to convention. However, if x is bound to an\nrvalue, decltype(x) will yield an rvalue reference instead of the customary non-\nreference.\nBut look at the sample C++14 implementation for std::forward from Item 28:\ntemplate<typename T>                         // in namespace\nT&& forward(remove_reference_t<T>& param)    // std\n{\n  return static_cast<T&&>(param);\n}\nIf client code wants to perfect-forward an rvalue of type Widget, it normally instanti‐\nates std::forward with the type Widget (i.e, a non-reference type), and the\nstd::forward template yields this function:\nWidget&& forward(Widget& param)            // instantiation of\n{                                          // std::forward when\n  return static_cast<Widget&&>(param);     // T is Widget\n}\n230 \n| \nItem 33\nwww.it-ebooks.info\n\n\nBut consider what would happen if the client code wanted to perfect-forward the\nsame rvalue of type Widget, but instead of following the convention of specifying T to\nbe a non-reference type, it specified it to be an rvalue reference. That is, consider\nwhat would happen if T were specified to be Widget&&. After initial instantiation of\nstd::forward and application of std::remove_reference_t, but before reference\ncollapsing (once again, see Item 28), std::forward would look like this:\nWidget&& && forward(Widget& param)         // instantiation of\n{                                          // std::forward when\n  return static_cast<Widget&& &&>(param);  // T is Widget&&\n}                                          // (before reference-\n                                           // collapsing)\nApplying the reference-collapsing rule that an rvalue reference to an rvalue reference\nbecomes a single rvalue reference, this instantiation emerges:\nWidget&& forward(Widget& param)            // instantiation of\n{                                          // std::forward when\n  return static_cast<Widget&&>(param);     // T is Widget&&\n}                                          // (after reference-\n                                           // collapsing)\nIf you compare this instantiation with the one that results when std::forward is\ncalled with T set to Widget, you’ll see that they’re identical. That means that instanti‐\nating std::forward with an rvalue reference type yields the same result as instantiat‐\ning it with a non-reference type.\nThat’s wonderful news, because decltype(x) yields an rvalue reference type when\nan rvalue is passed as an argument to our lambda’s parameter x. We established\nabove that when an lvalue is passed to our lambda, decltype(x) yields the custom‐\nary type to pass to std::forward, and now we realize that for rvalues, decltype(x)\nyields a type to pass to std::forward that’s not conventional, but that nevertheless\nyields the same outcome as the conventional type. So for both lvalues and rvalues,\npassing decltype(x) to std::forward gives us the result we want. Our perfect-\nforwarding lambda can therefore be written like this:\nauto f =\n  [](auto&& param)\n  {\n    return\n      func(normalize(std::forward<decltype(param)>(param)));\n  };\nFrom there, it’s just a hop, skip, and six dots to a perfect-forwarding lambda that\naccepts not just a single parameter, but any number of parameters, because C++14\nlambdas can also be variadic:\nItem 33 \n| \n231\nwww.it-ebooks.info\n",
      "page_number": 242,
      "chapter_number": 23,
      "summary": "The one thing you can’t express with an init\ncapture is a default capture mode, but Item 31 explains that you should stay away\nfrom those, anyway Key topics include captures, captured. Covers lambda.",
      "keywords": [
        "std",
        "Widget",
        "bind object",
        "lambda",
        "object",
        "bind",
        "data",
        "Item",
        "closure",
        "capture",
        "move",
        "init capture",
        "closure class",
        "rvalue",
        "forward"
      ],
      "concepts": [
        "std",
        "captures",
        "captured",
        "objects",
        "item",
        "refers",
        "reference",
        "data",
        "widget",
        "uses"
      ],
      "similar_chapters": [
        {
          "book": "C++ Concurrency in Action",
          "chapter": 42,
          "title": "Segment 42 (pages 413-421)",
          "relevance_score": 0.36,
          "method": "sentence_transformers"
        },
        {
          "book": "Effective-Python",
          "chapter": 18,
          "title": "Segment 18 (pages 175-187)",
          "relevance_score": 0.35,
          "method": "sentence_transformers"
        },
        {
          "book": "C++ Concurrency in Action",
          "chapter": 45,
          "title": "Segment 45 (pages 455-489)",
          "relevance_score": 0.33,
          "method": "sentence_transformers"
        },
        {
          "book": "More Effective C++",
          "chapter": 33,
          "title": "Segment 33 (pages 330-335)",
          "relevance_score": 0.32,
          "method": "sentence_transformers"
        },
        {
          "book": "LLM-Engineers-Handbook",
          "chapter": 22,
          "title": "Segment 22 (pages 198-207)",
          "relevance_score": 0.31,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 24,
      "title": "Segment 24 (pages 250-258)",
      "start_page": 250,
      "end_page": 258,
      "detection_method": "topic_boundary",
      "content": "auto f =\n  [](auto&&... params)\n  {\n    return\n    func(normalize(std::forward<decltype(params)>(params)...));\n  };\nThings to Remember\n• Use decltype on auto&& parameters to std::forward them.\nItem 34: Prefer lambdas to std::bind.\nstd::bind is the C++11 successor to C++98’s std::bind1st and std::bind2nd,\nbut, informally, it’s been part of the Standard Library since 2005. That’s when the\nStandardization Committee adopted a document known as TR1, which included\nbind’s specification. (In TR1, bind was in a different namespace, so it was\nstd::tr1::bind, not std::bind, and a few interface details were different.) This\nhistory means that some programmers have a decade or more of experience using\nstd::bind. If you’re one of them, you may be reluctant to abandon a tool that’s\nserved you well. That’s understandable, but in this case, change is good, because in\nC++11, lambdas are almost always a better choice than std::bind. As of C++14, the\ncase for lambdas isn’t just stronger, it’s downright ironclad.\nThis Item assumes that you’re familiar with std::bind. If you’re not, you’ll want to\nacquire a basic understanding before continuing. Such an understanding is worth‐\nwhile in any case, because you never know when you might encounter uses of\nstd::bind in a code base you have to read or maintain.\nAs in Item 32, I refer to the function objects returned from std::bind as bind\nobjects.\nThe most important reason to prefer lambdas over std::bind is that lambdas are\nmore readable. Suppose, for example, we have a function to set up an audible alarm:\n// typedef for a point in time (see Item 9 for syntax)\nusing Time = std::chrono::steady_clock::time_point;\n// see Item 10 for \"enum class\"\nenum class Sound { Beep, Siren, Whistle };\n// typedef for a length of time\n232 \n| \nItem 33\nwww.it-ebooks.info\n\n\nusing Duration = std::chrono::steady_clock::duration;\n// at time t, make sound s for duration d\nvoid setAlarm(Time t, Sound s, Duration d);\nFurther suppose that at some point in the program, we’ve determined we’ll want an\nalarm that will go off an hour after it’s set and that will stay on for 30 seconds. The\nalarm sound, however, remains undecided. We can write a lambda that revises\nsetAlarm’s interface so that only a sound needs to be specified:\n// setSoundL (\"L\" for \"lambda\") is a function object allowing a\n// sound to be specified for a 30-sec alarm to go off an hour\n// after it's set\nauto setSoundL =                             \n  [](Sound s)\n  {\n    // make std::chrono components available w/o qualification\n    using namespace std::chrono;\n    setAlarm(steady_clock::now() + hours(1),  // alarm to go off\n             s,                               // in an hour for\n             seconds(30));                    // 30 seconds\n  };\nI’ve highlighted the call to setAlarm inside the lambda. This is a normal-looking\nfunction call, and even a reader with little lambda experience can see that the param‐\neter s passed to the lambda is passed as an argument to setAlarm.\nWe can streamline this code in C++14 by availing ourselves of the standard suffixes\nfor seconds (s), milliseconds (ms), hours (h), etc., that build on C++11’s support for\nuser-defined literals. These suffixes are implemented in the std::literals name‐\nspace, so the above code can be rewritten as follows:\nauto setSoundL =                             \n  [](Sound s)\n  {\n    using namespace std::chrono;\n    using namespace std::literals;         // for C++14 suffixes\n    setAlarm(steady_clock::now() + 1h,     // C++14, but\n             s,                            // same meaning\n             30s);                         // as above\n  };\nItem 34 \n| \n233\nwww.it-ebooks.info\n\n\nOur first attempt to write the corresponding std::bind call is below. It has an error\nthat we’ll fix in a moment, but the correct code is more complicated, and even this\nsimplified version brings out some important issues:\nusing namespace std::chrono;           // as above\nusing namespace std::literals;\nusing namespace std::placeholders;     // needed for use of \"_1\"\nauto setSoundB =                       // \"B\" for \"bind\"\n  std::bind(setAlarm,\n            steady_clock::now() + 1h,  // incorrect! see below\n            _1,\n            30s);\nI’d like to highlight the call to setAlarm here as I did in the lambda, but there’s no\ncall to highlight. Readers of this code simply have to know that calling setSoundB\ninvokes setAlarm with the time and duration specified in the call to std::bind. To\nthe uninitiated, the placeholder “_1” is essentially magic, but even readers in the\nknow have to mentally map from the number in that placeholder to its position in the\nstd::bind parameter list in order to understand that the first argument in a call to\nsetSoundB is passed as the second argument to setAlarm. The type of this argument\nis not identified in the call to std::bind, so readers have to consult the setAlarm\ndeclaration to determine what kind of argument to pass to setSoundB.\nBut, as I said, the code isn’t quite right. In the lambda, it’s clear that the expression\n“steady_clock::now() + 1h” is an argument to setAlarm. It will be evaluated when\nsetAlarm is called. That makes sense: we want the alarm to go off an hour after\ninvoking setAlarm. In the std::bind call, however, “steady_clock::now() + 1h”\nis passed as an argument to std::bind, not to setAlarm. That means that the\nexpression will be evaluated when std::bind is called, and the time resulting from\nthat expression will be stored inside the resulting bind object. As a consequence, the\nalarm will be set to go off an hour after the call to std::bind, not an hour after the\ncall to setAlarm!\nFixing the problem requires telling std::bind to defer evaluation of the expression\nuntil setAlarm is called, and the way to do that is to nest a second call to std::bind\ninside the first one:\nauto setSoundB =\n  std::bind(setAlarm,\n            std::bind(std::plus<>(), steady_clock::now(), 1h),\n            _1,\n            30s);\n234 \n| \nItem 34\nwww.it-ebooks.info\n\n\nIf you’re familiar with the std::plus template from C++98, you may be surprised to\nsee that in this code, no type is specified between the angle brackets, i.e., the code\ncontains “std::plus<>”, not “std::plus<type>”. In C++14, the template type\nargument for the standard operator templates can generally be omitted, so there’s no\nneed to provide it here. C++11 offers no such feature, so the C++11 std::bind\nequivalent to the lambda is:\nusing namespace std::chrono;                   // as above\nusing namespace std::placeholders;\nauto setSoundB =\n  std::bind(setAlarm,\n            std::bind(std::plus<steady_clock::time_point>(),\n                      steady_clock::now(),\n                      hours(1)),\n            _1,\n            seconds(30));\nIf, at this point, the lambda’s not looking a lot more attractive, you should probably\nhave your eyesight checked.\nWhen setAlarm is overloaded, a new issue arises. Suppose there’s an overload taking\na fourth parameter specifying the alarm volume:\nenum class Volume { Normal, Loud, LoudPlusPlus };\nvoid setAlarm(Time t, Sound s, Duration d, Volume v);\nThe lambda continues to work as before, because overload resolution chooses the\nthree-argument version of setAlarm:\nauto setSoundL =                               // same as before\n  [](Sound s)\n  {\n    using namespace std::chrono;\n    setAlarm(steady_clock::now() + 1h,         // fine, calls\n             s,                                // 3-arg version\n             30s);                             // of setAlarm\n  };\nThe std::bind call, on the other hand, now fails to compile:\nauto setSoundB =                               // error! which\n  std::bind(setAlarm,                          // setAlarm?\n            std::bind(std::plus<>(),\n                      steady_clock::now(),\nItem 34 \n| \n235\nwww.it-ebooks.info\n\n\n                      1h),\n            _1,\n            30s);\nThe problem is that compilers have no way to determine which of the two setAlarm\nfunctions they should pass to std::bind. All they have is a function name, and the\nname alone is ambiguous.\nTo get the std::bind call to compile, setAlarm must be cast to the proper function\npointer type:\nusing SetAlarm3ParamType = void(*)(Time t, Sound s, Duration d);\nauto setSoundB =                                        // now\n  std::bind(static_cast<SetAlarm3ParamType>(setAlarm),  // okay\n            std::bind(std::plus<>(),\n                      steady_clock::now(),\n                      1h),\n            _1,\n            30s);\nBut this brings up another difference between lambdas and std::bind. Inside the\nfunction call operator for setSoundL (i.e., the function call operator of the lambda’s\nclosure class), the call to setAlarm is a normal function invocation that can be\ninlined by compilers in the usual fashion:\nsetSoundL(Sound::Siren);      // body of setAlarm may\n                              // well be inlined here\nThe call to std::bind, however, passes a function pointer to setAlarm, and that\nmeans that inside the function call operator for setSoundB (i.e., the function call\noperator for the bind object), the call to setAlarm takes place through a function\npointer. Compilers are less likely to inline function calls through function pointers,\nand that means that calls to setAlarm through setSoundB are less likely to be fully\ninlined than those through setSoundL:\nsetSoundB(Sound::Siren);      // body of setAlarm is less\n                              // likely to be inlined here\nIt’s thus possible that using lambdas generates faster code than using std::bind.\nThe setAlarm example involves only a simple function call. If you want to do any‐\nthing more complicated, the scales tip even further in favor of lambdas. For example,\nconsider this C++14 lambda, which returns whether its argument is between a mini‐\nmum value (lowVal) and a maximum value (highVal), where lowVal and highVal\nare local variables:\n236 \n| \nItem 34\nwww.it-ebooks.info\n\n\nauto betweenL =\n  [lowVal, highVal]\n  (const auto& val)                          // C++14\n  { return lowVal <= val && val <= highVal; };\nstd::bind can express the same thing, but the construct is an example of job secu‐\nrity through code obscurity:\nusing namespace std::placeholders;           // as above\nauto betweenB =\n  std::bind(std::logical_and<>(),            // C++14\n              std::bind(std::less_equal<>(), lowVal, _1),\n              std::bind(std::less_equal<>(), _1, highVal));\nIn C++11, we’d have to specify the types we wanted to compare, and the std::bind\ncall would then look like this:\nauto betweenB =                              // C++11 version\n  std::bind(std::logical_and<bool>(),\n              std::bind(std::less_equal<int>(), lowVal, _1),\n              std::bind(std::less_equal<int>(), _1, highVal));\nOf course, in C++11, the lambda couldn’t take an auto parameter, so it’d have to\ncommit to a type, too:\nauto betweenL =                              // C++11 version\n  [lowVal, highVal]\n  (int val)\n  { return lowVal <= val && val <= highVal; };\nEither way, I hope we can agree that the lambda version is not just shorter, but also\nmore comprehensible and maintainable.\nEarlier, I remarked that for those with little std::bind experience, its placeholders\n(e.g., _1, _2, etc.) are essentially magic. But it’s not just the behavior of the placehold‐\ners that’s opaque. Suppose we have a function to create compressed copies of\nWidgets,\nenum class CompLevel { Low, Normal, High };  // compression\n                                             // level\nWidget compress(const Widget& w,             // make compressed\n                CompLevel lev);              // copy of w\nand we want to create a function object that allows us to specify how much a particu‐\nlar Widget w should be compressed. This use of std::bind will create such an object:\nItem 34 \n| \n237\nwww.it-ebooks.info\n\n\n1 std::bind always copies its arguments, but callers can achieve the effect of having an argument stored by\nreference by applying std::ref to it. The result of\n    auto compressRateB = std::bind(compress, std::ref(w), _1);\nis that compressRateB acts as if it holds a reference to w, rather than a copy.\nWidget w;\nusing namespace std::placeholders;\nauto compressRateB = std::bind(compress, w, _1);\nNow, when we pass w to std::bind, it has to be stored for the later call to compress.\nIt’s stored inside the object compressRateB, but how is it stored—by value or by ref‐\nerence? It makes a difference, because if w is modified between the call to std::bind\nand a call to compressRateB, storing w by reference will reflect the changes, while\nstoring it by value won’t.\nThe answer is that it’s stored by value,1 but the only way to know that is to memorize\nhow std::bind works; there’s no sign of it in the call to std::bind. Contrast that\nwith a lambda approach, where whether w is captured by value or by reference is\nexplicit:\nauto compressRateL =                         // w is captured by\n  [w](CompLevel lev)                         // value; lev is\n  { return compress(w, lev); };              // passed by value\nEqually explicit is how parameters are passed to the lambda. Here, it’s clear that the\nparameter lev is passed by value. Hence:\ncompressRateL(CompLevel::High);              // arg is passed\n                                             // by value\nBut in the call to the object resulting from std::bind, how is the argument passed?\ncompressRateB(CompLevel::High);              // how is arg\n                                             // passed?\nAgain, the only way to know is to memorize how std::bind works. (The answer is\nthat all arguments passed to bind objects are passed by reference, because the func‐\ntion call operator for such objects uses perfect forwarding.)\nCompared to lambdas, then, code using std::bind is less readable, less expressive,\nand possibly less efficient. In C++14, there are no reasonable use cases for\nstd::bind. In C++11, however, std::bind can be justified in two constrained situa‐\ntions:\n238 \n| \nItem 34\nwww.it-ebooks.info\n\n\n• Move capture. C++11 lambdas don’t offer move capture, but it can be emulated\nthrough a combination of a lambda and std::bind. For details, consult Item 32,\nwhich also explains that in C++14, lambdas’ support for init capture eliminates\nthe need for the emulation.\n• Polymorphic function objects. Because the function call operator on a bind\nobject uses perfect forwarding, it can accept arguments of any type (modulo the\nrestrictions on perfect forwarding described in Item 30). This can be useful when\nyou want to bind an object with a templatized function call operator. For exam‐\nple, given this class,\nclass PolyWidget {\npublic:\n    template<typename T>\n    void operator()(const T& param);\n    …\n};\nstd::bind can bind a PolyWidget as follows:\nPolyWidget pw;\nauto boundPW = std::bind(pw, _1);\nboundPW can then be called with different types of  arguments:\nboundPW(1930);              // pass int to\n                            // PolyWidget::operator()\nboundPW(nullptr);           // pass nullptr to\n                            // PolyWidget::operator()\nboundPW(\"Rosebud\");         // pass string literal to\n                            // PolyWidget::operator()\nThere is no way to do this with a C++11 lambda. In C++14, however, it’s easily\nachieved via a lambda with an auto parameter:\nauto boundPW = [pw](const auto& param)    // C++14\n               { pw(param); };\nThese are edge cases, of course, and they’re transient edge cases at that, because com‐\npilers supporting C++14 lambdas are increasingly common.\nWhen bind was unofficially added to C++ in 2005, it was a big improvement over its\n1998 predecessors. The addition of lambda support to C++11 rendered std::bind\nall but obsolete, however, and as of C++14, there are just no good use cases for it.\nItem 34 \n| \n239\nwww.it-ebooks.info\n\n\nThings to Remember\n• Lambdas are more readable, more expressive, and may be more efficient than\nusing std::bind.\n• In C++11 only, std::bind may be useful for implementing move capture or\nfor binding objects with templatized function call operators.\n240 \n| \nItem 34\nwww.it-ebooks.info\n",
      "page_number": 250,
      "chapter_number": 24,
      "summary": "This chapter covers segment 24 (pages 250-258). Key topics include auto, bind. Covers lambda, function. (In TR1, bind was in a different namespace, so it was\nstd::tr1::bind, not std::bind, and a few interface details were different.) This\nhistory means that some programmers have a decade or more of experience using\nstd::bind.",
      "keywords": [
        "std",
        "bind",
        "call",
        "setAlarm",
        "namespace std",
        "Item",
        "auto",
        "function call",
        "lambda",
        "function",
        "Sound",
        "function call operator",
        "bind call",
        "call operator",
        "time"
      ],
      "concepts": [
        "std",
        "auto",
        "bind",
        "lambdas",
        "functions",
        "item",
        "code",
        "compressed",
        "compression",
        "uses"
      ],
      "similar_chapters": [
        {
          "book": "More Effective C++",
          "chapter": 7,
          "title": "Segment 7 (pages 52-60)",
          "relevance_score": 0.55,
          "method": "sentence_transformers"
        },
        {
          "book": "More Effective C++",
          "chapter": 32,
          "title": "Segment 32 (pages 320-329)",
          "relevance_score": 0.54,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 2",
          "chapter": 2,
          "title": "Segment 2 (pages 9-16)",
          "relevance_score": 0.53,
          "method": "sentence_transformers"
        },
        {
          "book": "C++ Templates_ The Complete Guide",
          "chapter": 26,
          "title": "Segment 26 (pages 815-849)",
          "relevance_score": 0.52,
          "method": "sentence_transformers"
        },
        {
          "book": "C++ Templates_ The Complete Guide",
          "chapter": 46,
          "title": "Segment 46 (pages 1469-1503)",
          "relevance_score": 0.51,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 25,
      "title": "Segment 25 (pages 259-270)",
      "start_page": 259,
      "end_page": 270,
      "detection_method": "topic_boundary",
      "content": "CHAPTER 7\nThe Concurrency API\nOne of C++11’s great triumphs is the incorporation of concurrency into the language\nand library. Programmers familiar with other threading APIs (e.g., pthreads or Win‐\ndows threads) are sometimes surprised at the comparatively Spartan feature set that\nC++ offers, but that’s because a great deal of C++’s support for concurrency is in the\nform of constraints on compiler-writers. The resulting language assurances mean\nthat for the first time in C++’s history, programmers can write multithreaded pro‐\ngrams with standard behavior across all platforms. This establishes a solid foundation\non which expressive libraries can be built, and the concurrency elements of the Stan‐\ndard Library (tasks, futures, threads, mutexes, condition variables, atomic objects,\nand more) are merely the beginning of what is sure to become an increasingly rich set\nof tools for the development of concurrent C++ software.\nIn the Items that follow, bear in mind that the Standard Library has two templates for\nfutures: std::future and std::shared_future. In many cases, the distinction is\nnot important, so I often simply talk about futures, by which I mean both kinds.\nItem 35: Prefer task-based programming to thread-\nbased.\nIf you want to run a function doAsyncWork asynchronously, you have two basic\nchoices. You can create a std::thread and run doAsyncWork on it, thus employing\na thread-based approach:\nint doAsyncWork();\nstd::thread t(doAsyncWork);\nOr you can pass doAsyncWork to std::async, a strategy known as task-based:\n241\nwww.it-ebooks.info\n\n\n1 Assuming you have one. Some embedded systems don’t.\nauto fut = std::async(doAsyncWork);        // \"fut\" for \"future\"\nIn such calls, the function object passed to std::async (e.g., doAsyncWork) is con‐\nsidered a task.\nThe task-based approach is typically superior to its thread-based counterpart, and the\ntiny amount of code we’ve seen already demonstrates some reasons why. Here,\ndoAsyncWork produces a return value, which we can reasonably assume the code\ninvoking doAsyncWork is interested in. With the thread-based invocation, there’s no\nstraightforward way to get access to it. With the task-based approach, it’s easy,\nbecause the future returned from std::async offers the get function. The get func‐\ntion is even more important if doAsyncWork emits an exception, because get pro‐\nvides access to that, too. With the thread-based approach, if doAsyncWork throws, the\nprogram dies (via a call to std::terminate).\nA more fundamental difference between thread-based and task-based programming\nis the higher level of abstraction that task-based embodies. It frees you from the\ndetails of thread management, an observation that reminds me that I need to summa‐\nrize the three meanings of “thread” in concurrent C++ software:\n• Hardware threads are the threads that actually perform computation. Contempo‐\nrary machine architectures offer one or more hardware threads per CPU core.\n• Software threads (also known as OS threads or system threads) are the threads\nthat the operating system1 manages across all processes and schedules for execu‐\ntion on hardware threads. It’s typically possible to create more software threads\nthan hardware threads, because when a software thread is blocked (e.g., on I/O or\nwaiting for a mutex or condition variable), throughput can be improved by exe‐\ncuting other, unblocked, threads.\n• std::threads are objects in a C++ process that act as handles to underlying\nsoftware threads. Some std::thread objects represent “null” handles, i.e., corre‐\nspond to no software thread, because they’re in a default-constructed state\n(hence have no function to execute), have been moved from (the moved-to\nstd::thread then acts as the handle to the underlying software thread), have\nbeen joined (the function they were to run has finished), or have been detached\n(the connection between them and their underlying software thread has been\nsevered).\nSoftware threads are a limited resource. If you try to create more than the system can\nprovide, a std::system_error exception is thrown. This is true even if the function\nyou want to run can’t throw. For example, even if doAsyncWork is noexcept,\n242 \n| \nItem 35\nwww.it-ebooks.info\n\n\nint doAsyncWork() noexcept;          // see Item 14 for noexcept\nthis statement could result in an exception:\nstd::thread t(doAsyncWork);          // throws if no more\n                                     // threads are available\nWell-written software must somehow deal with this possibility, but how? One\napproach is to run doAsyncWork on the current thread, but that could lead to unbal‐\nanced loads and, if the current thread is a GUI thread, responsiveness issues. Another\noption is to wait for some existing software threads to complete and then try to create\na new std::thread again, but it’s possible that the existing threads are waiting for an\naction that doAsyncWork is supposed to perform (e.g., produce a result or notify a\ncondition variable).\nEven if you don’t run out of threads, you can have trouble with oversubscription.\nThat’s when there are more ready-to-run (i.e., unblocked) software threads than\nhardware threads. When that happens, the thread scheduler (typically part of the OS)\ntime-slices the software threads on the hardware. When one thread’s time-slice is fin‐\nished and another’s begins, a context switch is performed. Such context switches\nincrease the overall thread management overhead of the system, and they can be par‐\nticularly costly when the hardware thread on which a software thread is scheduled is\non a different core than was the case for the software thread during its last time-slice.\nIn that case, (1) the CPU caches are typically cold for that software thread (i.e., they\ncontain little data and few instructions useful to it) and (2) the running of the “new”\nsoftware thread on that core “pollutes” the CPU caches for “old” threads that had\nbeen running on that core and are likely to be scheduled to run there again.\nAvoiding oversubscription is difficult, because the optimal ratio of software to hard‐\nware threads depends on how often the software threads are runnable, and that can\nchange dynamically, e.g., when a program goes from an I/O-heavy region to a\ncomputation-heavy region. The best ratio of software to hardware threads is also\ndependent on the cost of context switches and how effectively the software threads\nuse the CPU caches. Furthermore, the number of hardware threads and the details of\nthe CPU caches (e.g., how large they are and their relative speeds) depend on the\nmachine architecture, so even if you tune your application to avoid oversubscription\n(while still keeping the hardware busy) on one platform, there’s no guarantee that\nyour solution will work well on other kinds of machines.\nYour life will be easier if you dump these problems on somebody else, and using\nstd::async does exactly that:\nauto fut = std::async(doAsyncWork);   // onus of thread mgmt is\n                                      // on implementer of\n                                      // the Standard Library\nItem 35 \n| \n243\nwww.it-ebooks.info\n\n\nThis call shifts the thread management responsibility to the implementer of the C++\nStandard Library. For example, the likelihood of receiving an out-of-threads excep‐\ntion is significantly reduced, because this call will probably never yield one. “How can\nthat be?” you might wonder. “If I ask for more software threads than the system can\nprovide, why does it matter whether I do it by creating std::threads or by calling\nstd::async?” It matters, because std::async, when called in this form (i.e., with\nthe default launch policy—see Item 36), doesn’t guarantee that it will create a new\nsoftware thread. Rather, it permits the scheduler to arrange for the specified function\n(in this example, doAsyncWork) to be run on the thread requesting doAsyncWork’s\nresult (i.e., on the thread calling get or wait on fut), and reasonable schedulers take\nadvantage of that freedom if the system is oversubscribed or is out of threads.\nIf you pulled this “run it on the thread needing the result” trick yourself, I remarked\nthat it could lead to load-balancing issues, and those issues don’t go away simply\nbecause it’s std::async and the runtime scheduler that confront them instead of\nyou. When it comes to load balancing, however, the runtime scheduler is likely to\nhave a more comprehensive picture of what’s happening on the machine than you\ndo, because it manages the threads from all processes, not just the one your code is\nrunning in.\nWith std::async, responsiveness on a GUI thread can still be problematic, because\nthe scheduler has no way of knowing which of your threads has tight responsiveness\nrequirements. In that case, you’ll want to pass the std::launch::async launch pol‐\nicy to std::async. That will ensure that the function you want to run really executes\non a different thread (see Item 36).\nState-of-the-art thread schedulers employ system-wide thread pools to avoid over‐\nsubscription, and they improve load balancing across hardware cores through work-\nstealing algorithms. The C++ Standard does not require the use of thread pools or\nwork-stealing, and, to be honest, there are some technical aspects of the C++11 con‐\ncurrency specification that make it more difficult to employ them than we’d like.\nNevertheless, some vendors take advantage of this technology in their Standard\nLibrary implementations, and it’s reasonable to expect that progress will continue in\nthis area. If you take a task-based approach to your concurrent programming, you\nautomatically reap the benefits of such technology as it becomes more widespread. If,\non the other hand, you program directly with std::threads, you assume the burden\nof dealing with thread exhaustion, oversubscription, and load balancing yourself, not\nto mention how your solutions to these problems mesh with the solutions imple‐\nmented in programs running in other processes on the same machine.\nCompared to thread-based programming, a task-based design spares you the travails\nof manual thread management, and it provides a natural way to examine the results\nof asynchronously executed functions (i.e., return values or exceptions). Neverthe‐\n244 \n| \nItem 35\nwww.it-ebooks.info\n\n\nless, there are some situations where using threads directly may be appropriate. They\ninclude:\n• You need access to the API of the underlying threading implementation. The\nC++ concurrency API is typically implemented using a lower-level platform-\nspecific API, usually pthreads or Windows’ Threads. Those APIs are currently\nricher than what C++ offers. (For example, C++ has no notion of thread priori‐\nties or affinities.) To provide access to the API of the underlying threading\nimplementation, std::thread objects typically offer the native_handle mem‐\nber function. There is no counterpart to this functionality for std::futures (i.e.,\nfor what std::async returns).\n• You need to and are able to optimize thread usage for your application. This\ncould be the case, for example, if you’re developing server software with a known\nexecution profile that will be deployed as the only significant process on a\nmachine with fixed hardware characteristics.\n• You need to implement threading technology beyond the C++ concurrency\nAPI, e.g., thread pools on platforms where your C++ implementations don’t\noffer them.\nThese are uncommon cases, however. Most of the time, you should choose task-\nbased designs instead of programming with threads.\nThings to Remember\n• The std::thread API offers no direct way to get return values from asyn‐\nchronously run functions, and if those functions throw, the program is termi‐\nnated.\n• Thread-based programming calls for manual management of thread exhaus‐\ntion, oversubscription, load balancing, and adaptation to new platforms.\n• Task-based programming via std::async with the default launch policy han‐\ndles most of these issues for you.\nItem 36: Specify std::launch::async if\nasynchronicity is essential.\nWhen you call std::async to execute a function (or other callable object), you’re\ngenerally intending to run the function asynchronously. But that’s not necessarily\nwhat you’re asking std::async to do. You’re really requesting that the function be\nrun in accord with a std::async launch policy. There are two standard policies, each\nItem 35 \n| \n245\nwww.it-ebooks.info\n\n\n2 This is a simplification. What matters isn’t the future on which get or wait is invoked, it’s the shared state to\nwhich the future refers. (Item 38 discusses the relationship between futures and shared states.) Because\nstd::futures support moving and can also be used to construct std::shared_futures, and because\nstd::shared_futures can be copied, the future object referring to the shared state arising from the call to\nstd::async to which f was passed is likely to be different from the one returned by std::async. That’s a\nmouthful, however, so it’s common to fudge the truth and simply talk about invoking get or wait on the\nfuture returned from std::async.\nrepresented by an enumerator in the std::launch scoped enum. (See Item 10 for\ninformation on scoped enums.) Assuming a function f is passed to std::async for\nexecution,\n• The std::launch::async launch policy means that f must be run asynchro‐\nnously, i.e., on a different thread.\n• The std::launch::deferred launch policy means that f may run only when\nget or wait is called on the future returned by std::async.2 That is, f’s execu‐\ntion is deferred until such a call is made. When get or wait is invoked, f will\nexecute synchronously, i.e., the caller will block until f finishes running. If nei‐\nther get nor wait is called, f will never run.\nPerhaps surprisingly, std::async’s default launch policy—the one it uses if you\ndon’t expressly specify one—is neither of these. Rather, it’s these or-ed together. The\nfollowing two calls have exactly the same meaning:\nauto fut1 = std::async(f);                     // run f using\n                                               // default launch\n                                               // policy\nauto fut2 = std::async(std::launch::async |    // run f either\n                       std::launch::deferred,  // async or\n                       f);                     // deferred\nThe default policy thus permits f to be run either asynchronously or synchronously.\nAs Item 35 points out, this flexibility permits std::async and the thread-\nmanagement components of the Standard Library to assume responsibility for thread\ncreation and destruction, avoidance of oversubscription, and load balancing. That’s\namong the things that make concurrent programming with std::async so conve‐\nnient.\nBut using std::async with the default launch policy has some interesting implica‐\ntions. Given a thread t executing this statement,\nauto fut = std::async(f);   // run f using default launch policy\n246 \n| \nItem 36\nwww.it-ebooks.info\n\n\n• It’s not possible to predict whether f will run concurrently with t, because f\nmight be scheduled to run deferred.\n• It’s not possible to predict whether f runs on a thread different from the\nthread invoking get or wait on fut. If that thread is t, the implication is that\nit’s not possible to predict whether f runs on a thread different from t.\n• It may not be possible to predict whether f runs at all, because it may not be\npossible to guarantee that get or wait will be called on fut along every path\nthrough the program.\nThe default launch policy’s scheduling flexibility often mixes poorly with the use of\nthread_local variables, because it means that if f reads or writes such thread-local\nstorage (TLS), it’s not possible to predict which thread’s variables will be accessed:\nauto fut = std::async(f);        // TLS for f possibly for\n                                 // independent thread, but\n                                 // possibly for thread\n                                 // invoking get or wait on fut\nIt also affects wait-based loops using timeouts, because calling wait_for or\nwait_until on a task (see Item 35) that’s deferred yields the value\nstd::launch::deferred. This means that the following loop, which looks like it\nshould eventually terminate, may, in reality, run forever:\nusing namespace std::literals;        // for C++14 duration\n                                      // suffixes; see Item 34\nvoid f()                              // f sleeps for 1 second,\n{                                     // then returns\n  std::this_thread::sleep_for(1s);\n}\nauto fut = std::async(f);             // run f asynchronously\n                                      // (conceptually)\nwhile (fut.wait_for(100ms) !=         // loop until f has\n       std::future_status::ready)     // finished running...\n{                                     // which may never happen!\n  …\n}\nItem 36 \n| \n247\nwww.it-ebooks.info\n\n\nIf f runs concurrently with the thread calling std::async (i.e., if the launch policy\nchosen for f is std::launch::async), there’s no problem here (assuming f\neventually finishes), but if f is deferred, fut.wait_for will always return std::\nfuture_status::deferred. That will never be equal to std::future_status::\nready, so the loop will never terminate.\nThis kind of bug is easy to overlook during development and unit testing, because it\nmay manifest itself only under heavy loads. Those are the conditions that push the\nmachine towards oversubscription or thread exhaustion, and that’s when a task may\nbe most likely to be deferred. After all, if the hardware isn’t threatened by oversub‐\nscription or thread exhaustion, there’s no reason for the runtime system not to sched‐\nule the task for concurrent execution.\nThe fix is simple: just check the future corresponding to the std::async call to see\nwhether the task is deferred, and, if so, avoid entering the timeout-based loop.\nUnfortunately, there’s no direct way to ask a future whether its task is deferred.\nInstead, you have to call a timeout-based function—a function such as wait_for. In\nthis case, you don’t really want to wait for anything, you just want to see if the return\nvalue is std::future_status::deferred, so stifle your mild disbelief at the neces‐\nsary circumlocution and call wait_for with a zero timeout:\nauto fut = std::async(f);                  // as above\nif (fut.wait_for(0s) ==                    // if task is\n    std::future_status::deferred)          // deferred...\n{\n                        // ...use wait or get on fut\n  …                     // to call f synchronously\n} else {                // task isn't deferred\n  while (fut.wait_for(100ms) !=            // infinite loop not\n         std::future_status::ready) {      // possible (assuming\n                                           // f finishes)\n    …                  // task is neither deferred nor ready,\n                       // so do concurrent work until it's ready\n  }\n  …                    // fut is ready\n}\n248 \n| \nItem 36\nwww.it-ebooks.info\n\n\nThe upshot of these various considerations is that using std::async with the default\nlaunch policy for a task is fine as long as the following conditions are fulfilled:\n• The task need not run concurrently with the thread calling get or wait.\n• It doesn’t matter which thread’s thread_local variables are read or written.\n• Either there’s a guarantee that get or wait will be called on the future returned\nby std::async or it’s acceptable that the task may never execute.\n• Code using wait_for or wait_until takes the possibility of deferred status into\naccount.\nIf any of these conditions fails to hold, you probably want to guarantee that\nstd::async will schedule the task for truly asynchronous execution. The way to do\nthat is to pass std::launch::async as the first argument when you make the call:\nauto fut = std::async(std::launch::async, f);  // launch f\n                                               // asynchronously\nIn fact, having a function that acts like std::async, but that automatically uses\nstd::launch::async as the launch policy, is a convenient tool to have around, so\nit’s nice that it’s easy to write. Here’s the C++11 version:\ntemplate<typename F, typename... Ts>\ninline\nstd::future<typename std::result_of<F(Ts...)>::type>\nreallyAsync(F&& f, Ts&&... params)       // return future\n{                                        // for asynchronous\n  return std::async(std::launch::async,  // call to f(params...)\n                    std::forward<F>(f),\n                    std::forward<Ts>(params)...);\n}\nThis function receives a callable object f and zero or more parameters params and\nperfect-forwards them (see Item 25) to std::async, passing std::launch::async\nas the launch policy. Like std::async, it returns a std::future for the result of\ninvoking f on params. Determining the type of that result is easy, because the type\ntrait std::result_of gives it to you. (See Item 9 for general information on type\ntraits.)\nreallyAsync is used just like std::async:\nauto fut = reallyAsync(f);         // run f asynchronously;\n                                   // throw if std::async\n                                   // would throw\nItem 36 \n| \n249\nwww.it-ebooks.info\n\n\nIn C++14, the ability to deduce reallyAsync’s return type streamlines the function\ndeclaration:\ntemplate<typename F, typename... Ts>\ninline\nauto                                           // C++14\nreallyAsync(F&& f, Ts&&... params)\n{\n  return std::async(std::launch::async,\n                    std::forward<F>(f),\n                    std::forward<Ts>(params)...);\n}\nThis version makes it crystal clear that reallyAsync does nothing but invoke\nstd::async with the std::launch::async launch policy.\nThings to Remember\n• The default launch policy for std::async permits both asynchronous and\nsynchronous task execution.\n• This flexibility leads to uncertainty when accessing thread_locals, implies\nthat the task may never execute, and affects program logic for timeout-based\nwait calls.\n• Specify std::launch::async if asynchronous task execution is essential.\nItem 37: Make std::threads unjoinable on all paths.\nEvery std::thread object is in one of two states: joinable or unjoinable. A joinable\nstd::thread corresponds to an underlying asynchronous thread of execution that is\nor could be running. A std::thread corresponding to an underlying thread that’s\nblocked or waiting to be scheduled is joinable, for example. std::thread objects cor‐\nresponding to underlying threads that have run to completion are also considered\njoinable.\nAn unjoinable std::thread is what you’d expect: a std::thread that’s not joinable.\nUnjoinable std::thread objects include:\n• Default-constructed std::threads. Such std::threads have no function to\nexecute, hence don’t correspond to an underlying thread of execution.\n250 \n| \nItem 36\nwww.it-ebooks.info\n\n\n• std::thread objects that have been moved from. The result of a move is that\nthe underlying thread of execution a std::thread used to correspond to (if any)\nnow corresponds to a different std::thread.\n• std::threads that have been joined. After a join, the std::thread object no\nlonger corresponds to the underlying thread of execution that has finished run‐\nning.\n• std::threads that have been detached. A detach severs the connection\nbetween a std::thread object and the underlying thread of execution it corre‐\nsponds to.\nOne reason a std::thread’s joinability is important is that if the destructor for a\njoinable thread is invoked, execution of the program is terminated. For example, sup‐\npose we have a function doWork that takes a filtering function, filter, and a maxi‐\nmum value, maxVal, as parameters. doWork checks to make sure that all conditions\nnecessary for its computation are satisfied, then performs the computation with all\nthe values between 0 and maxVal that pass the filter. If it’s time-consuming to do the\nfiltering and it’s also time-consuming to determine whether doWork’s conditions are\nsatisfied, it would be reasonable to do those two things concurrently.\nOur preference would be to employ a task-based design for this (see Item 35), but\nlet’s assume we’d like to set the priority of the thread doing the filtering. Item 35\nexplains that that requires use of the thread’s native handle, and that’s accessible only\nthrough the std::thread API; the task-based API (i.e., futures) doesn’t provide it.\nOur approach will therefore be based on threads, not tasks.\nWe could come up with code like this:\nconstexpr auto tenMillion = 10000000;         // see Item 15\n                                              // for constexpr\nbool doWork(std::function<bool(int)> filter,  // returns whether\n            int maxVal = tenMillion)          // computation was\n{                                             // performed; see\n                                              // Item 2 for\n                                              // std::function\n  std::vector<int> goodVals;                  // values that\n                                              // satisfy filter\n  std::thread t([&filter, maxVal, &goodVals]  // populate\n                {                             // goodVals\n                  for (auto i = 0; i <= maxVal; ++i)\n                   { if (filter(i)) goodVals.push_back(i); }\nItem 37 \n| \n251\nwww.it-ebooks.info\n\n\n                });\n  auto nh = t.native_handle();                // use t's native\n  …                                           // handle to set\n                                              // t's priority\n  if (conditionsAreSatisfied()) {\n    t.join();                                 // let t finish\n    performComputation(goodVals);\n    return true;                              // computation was\n  }                                           // performed\n  return false;                               // computation was\n}                                             // not performed\nBefore I explain why this code is problematic, I’ll remark that tenMillion’s initializ‐\ning value can be made more readable in C++14 by taking advantage of C++14’s abil‐\nity to use an apostrophe as a digit separator:\nconstexpr auto tenMillion = 10'000'000;       // C++14\nI’ll also remark that setting t’s priority after it has started running is a bit like closing\nthe proverbial barn door after the equally proverbial horse has bolted. A better design\nwould be to start t in a suspended state (thus making it possible to adjust its priority\nbefore it does any computation), but I don’t want to distract you with that code. If\nyou’re more distracted by the code’s absence, turn to Item 39, because it shows how\nto start threads suspended.\nBut back to doWork. If conditionsAreSatisfied() returns true, all is well, but if it\nreturns false or throws an exception, the std::thread object t will be joinable\nwhen its destructor is called at the end of doWork. That would cause program execu‐\ntion to be terminated.\nYou might wonder why the std::thread destructor behaves this way. It’s because\nthe two other obvious options are arguably worse. They are:\n• An implicit join. In this case, a std::thread’s destructor would wait for its\nunderlying asynchronous thread of execution to complete. That sounds reason‐\nable, but it could lead to performance anomalies that would be difficult to track\ndown. For example, it would be counterintuitive that doWork would wait for its\nfilter to be applied to all values if conditionsAreSatisfied() had already\nreturned false.\n• An implicit detach. In this case, a std::thread’s destructor would sever the\nconnection between the std::thread object and its underlying thread of execu‐\ntion. The underlying thread would continue to run. This sounds no less reason‐\n252 \n| \nItem 37\nwww.it-ebooks.info\n",
      "page_number": 259,
      "chapter_number": 25,
      "summary": "The task-based approach is typically superior to its thread-based counterpart, and the\ntiny amount of code we’ve seen already demonstrates some reasons why Key topics include threading, items.",
      "keywords": [
        "std",
        "thread",
        "async",
        "Item",
        "Software threads",
        "launch",
        "run",
        "software",
        "launch policy",
        "Hardware threads",
        "underlying thread",
        "function",
        "wait",
        "future",
        "doAsyncWork"
      ],
      "concepts": [
        "threading",
        "std",
        "items",
        "based",
        "function",
        "functionality",
        "run",
        "running",
        "runs",
        "auto"
      ],
      "similar_chapters": [
        {
          "book": "C++ Concurrency in Action",
          "chapter": 32,
          "title": "Segment 32 (pages 322-329)",
          "relevance_score": 0.68,
          "method": "sentence_transformers"
        },
        {
          "book": "C++ Concurrency in Action",
          "chapter": 5,
          "title": "Segment 5 (pages 37-49)",
          "relevance_score": 0.65,
          "method": "sentence_transformers"
        },
        {
          "book": "C++ Concurrency in Action",
          "chapter": 4,
          "title": "Segment 4 (pages 26-36)",
          "relevance_score": 0.64,
          "method": "sentence_transformers"
        },
        {
          "book": "C++ Concurrency in Action",
          "chapter": 16,
          "title": "Segment 16 (pages 141-154)",
          "relevance_score": 0.63,
          "method": "sentence_transformers"
        },
        {
          "book": "C++ Concurrency in Action",
          "chapter": 29,
          "title": "Segment 29 (pages 298-305)",
          "relevance_score": 0.63,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 26,
      "title": "Segment 26 (pages 271-286)",
      "start_page": 271,
      "end_page": 286,
      "detection_method": "topic_boundary",
      "content": "able than the join approach, but the debugging problems it can lead to are\nworse. In doWork, for example, goodVals is a local variable that is captured by\nreference. It’s also modified inside the lambda (via the call to push_back). Sup‐\npose, then, that while the lambda is running asynchronously, conditionsAreSa\ntisfied() returns false. In that case, doWork would return, and its local\nvariables (including goodVals) would be destroyed. Its stack frame would be\npopped, and execution of its thread would continue at doWork’s call site.\nStatements following that call site would, at some point, make additional func‐\ntion calls, and at least one such call would probably end up using some or all of\nthe memory that had once been occupied by the doWork stack frame. Let’s call\nsuch a function f. While f was running, the lambda that doWork initiated would\nstill be running asynchronously. That lambda could call push_back on the stack\nmemory that used to be goodVals but that is now somewhere inside f’s stack\nframe. Such a call would modify the memory that used to be goodVals, and that\nmeans that from f’s perspective, the content of memory in its stack frame could\nspontaneously change! Imagine the fun you’d have debugging that.\nThe Standardization Committee decided that the consequences of destroying a joina‐\nble thread were sufficiently dire that they essentially banned it (by specifying that\ndestruction of a joinable thread causes program termination).\nThis puts the onus on you to ensure that if you use a std::thread object, it’s made\nunjoinable on every path out of the scope in which it’s defined. But covering every\npath can be complicated. It includes flowing off the end of the scope as well as jump‐\ning out via a return, continue, break, goto or exception. That can be a lot of paths.\nAny time you want to perform some action along every path out of a block, the nor‐\nmal approach is to put that action in the destructor of a local object. Such objects are\nknown as RAII objects, and the classes they come from are known as RAII classes.\n(RAII itself stands for “Resource Acquisition Is Initialization,” although the crux of\nthe technique is destruction, not initialization). RAII classes are common in the Stan‐\ndard Library. Examples include the STL containers (each container’s destructor\ndestroys the container’s contents and releases its memory), the standard smart point‐\ners (Items 18–20 explain that std::unique_ptr’s destructor invokes its deleter on\nthe object it points to, and the destructors in std::shared_ptr and std::weak_ptr\ndecrement reference counts), std::fstream objects (their destructors close the files\nthey correspond to), and many more. And yet there is no standard RAII class for\nstd::thread objects, perhaps because the Standardization Committee, having rejec‐\nted both join and detach as default options, simply didn’t know what such a class\nshould do. \nItem 37 \n| \n253\nwww.it-ebooks.info\n\n\nFortunately, it’s not difficult to write one yourself. For example, the following class\nallows callers to specify whether join or detach should be called when a Threa\ndRAII object (an RAII object for a std::thread) is destroyed:\nclass ThreadRAII {\npublic:\n  enum class DtorAction { join, detach };    // see Item 10 for\n                                             // enum class info\n  ThreadRAII(std::thread&& t, DtorAction a)  // in dtor, take\n  : action(a), t(std::move(t)) {}            // action a on t\n  \n  ~ThreadRAII()\n  {                                          // see below for\n    if (t.joinable()) {                      // joinability test\n      if (action == DtorAction::join) {\n        t.join();\n      } else {\n        t.detach();\n      }\n      \n    }\n  }\n  std::thread& get() { return t; }           // see below\nprivate:\n  DtorAction action;\n  std::thread t;\n};\nI hope this code is largely self-explanatory, but the following points may be helpful:\n• The constructor accepts only std::thread rvalues, because we want to move the\npassed-in std::thread into the ThreadRAII object. (Recall that std::thread\nobjects aren’t copyable.)\n• The parameter order in the constructor is designed to be intuitive to callers\n(specifying the std::thread first and the destructor action second makes more\nsense than vice versa), but the member initialization list is designed to match the\norder of the data members’ declarations. That order puts the std::thread object\nlast. In this class, the order makes no difference, but in general, it’s possible for\nthe initialization of one data member to depend on another, and because\nstd::thread objects may start running a function immediately after they are\n254 \n| \nItem 37\nwww.it-ebooks.info\n\n\ninitialized, it’s a good habit to declare them last in a class. That guarantees that at\nthe time they are constructed, all the data members that precede them have\nalready been initialized and can therefore be safely accessed by the asynchro‐\nnously running thread that corresponds to the std::thread data member.\n• ThreadRAII offers a get function to provide access to the underlying\nstd::thread object. This is analogous to the get functions offered by the stan‐\ndard smart pointer classes that give access to their underlying raw pointers. Pro‐\nviding get avoids the need for ThreadRAII to replicate the full std::thread\ninterface, and it also means that ThreadRAII objects can be used in contexts\nwhere std::thread objects are required.\n• Before the ThreadRAII destructor invokes a member function on the\nstd::thread object t, it checks to make sure that t is joinable. This is necessary,\nbecause invoking join or detach on an unjoinable thread yields undefined\nbehavior. It’s possible that a client constructed a std::thread, created a\nThreadRAII object from it, used get to acquire access to t, and then did a move\nfrom t or called join or detach on it. Each of those actions would render t\nunjoinable.\nIf you’re worried that in this code,\nif (t.joinable()) {\n  if (action == DtorAction::join) {\n    t.join();\n  } else {\n    t.detach();\n  }\n}\na race exists, because between execution of t.joinable() and invocation of\njoin or detach, another thread could render t unjoinable, your intuition is\ncommendable, but your fears are unfounded. A std::thread object can change\nstate from joinable to unjoinable only through a member function call, e.g., join,\ndetach, or a move operation. At the time a ThreadRAII object’s destructor is\ninvoked, no other thread should be making member function calls on that object.\nIf there are simultaneous calls, there is certainly a race, but it isn’t inside the\ndestructor, it’s in the client code that is trying to invoke two member functions\n(the destructor and something else) on one object at the same time. In general,\nsimultaneous member function calls on a single object are safe only if all are to\nconst member functions (see Item 16).\nEmploying ThreadRAII in our doWork example would look like this:\nItem 37 \n| \n255\nwww.it-ebooks.info\n\n\nbool doWork(std::function<bool(int)> filter,  // as before\n            int maxVal = tenMillion)\n{\n  std::vector<int> goodVals;                  // as before\n  ThreadRAII t(                               // use RAII object\n    std::thread([&filter, maxVal, &goodVals]\n                {                             \n                  for (auto i = 0; i <= maxVal; ++i)\n                    { if (filter(i)) goodVals.push_back(i); }\n                }),\n                ThreadRAII::DtorAction::join  // RAII action\n  );\n  auto nh = t.get().native_handle();\n  …\n  if (conditionsAreSatisfied()) {\n    t.get().join();\n    performComputation(goodVals);\n    return true;\n  }\n  return false;\n}\nIn this case, we’ve chosen to do a join on the asynchronously running thread in the\nThreadRAII destructor, because, as we saw earlier, doing a detach could lead to\nsome truly nightmarish debugging. We also saw earlier that doing a join could lead\nto performance anomalies (that, to be frank, could also be unpleasant to debug), but\ngiven a choice between undefined behavior (which detach would get us), program\ntermination (which use of a raw std::thread would yield), or performance anoma‐\nlies, performance anomalies seems like the best of a bad lot.\nAlas, Item 39 demonstrates that using ThreadRAII to perform a join on\nstd::thread destruction can sometimes lead not just to a performance anomaly, but\nto a hung program. The “proper” solution to these kinds of problems would be to\ncommunicate to the asynchronously running lambda that we no longer need its work\nand that it should return early, but there’s no support in C++11 for interruptible\n256 \n| \nItem 37\nwww.it-ebooks.info\n\n\n3 You’ll find a nice treatment in Anthony Williams’ C++ Concurrency in Action (Manning Publications, 2012),\nsection 9.2.\nthreads. They can be implemented by hand, but that’s a topic beyond the scope of\nthis  book.3\nItem 17 explains that because ThreadRAII declares a destructor, there will be no\ncompiler-generated move operations, but there is no reason ThreadRAII objects\nshouldn’t be movable. If compilers were to generate these functions, the functions\nwould do the right thing, so explicitly requesting their creation isappropriate:\nclass ThreadRAII {\npublic:\n  enum class DtorAction { join, detach };           // as before\n  ThreadRAII(std::thread&& t, DtorAction a)         // as before\n  : action(a), t(std::move(t)) {}\n  ~ThreadRAII()\n  {\n    …                                               // as before\n  }\n  ThreadRAII(ThreadRAII&&) = default;               // support\n  ThreadRAII& operator=(ThreadRAII&&) = default;    // moving\n  std::thread& get() { return t; }                  // as before\nprivate:                                            // as before\n  DtorAction action;\n  std::thread t;\n};\nThings to Remember\n• Make std::threads unjoinable on all paths.\n• join-on-destruction can lead to difficult-to-debug performance anomalies.\n• detach-on-destruction can lead to difficult-to-debug undefined behavior.\n• Declare std::thread objects last in lists of data members.\nItem 37 \n| \n257\nwww.it-ebooks.info\n\n\n4 Item 39 explains that the kind of communications channel associated with a future can be employed for other\npurposes. For this Item, however, we’ll consider only its use as a mechanism for a callee to convey its result to\na caller.\nItem 38: Be aware of varying thread handle destructor\nbehavior.\nItem 37 explains that a joinable std::thread corresponds to an underlying system\nthread of execution. A future for a non-deferred task (see Item 36) has a similar rela‐\ntionship to a system thread. As such, both std::thread objects and future objects\ncan be thought of as handles to system threads.\nFrom this perspective, it’s interesting that std::threads and futures have such dif‐\nferent behaviors in their destructors. As noted in Item 37, destruction of a joinable\nstd::thread terminates your program, because the two obvious alternatives—an\nimplicit join and an implicit detach—were considered worse choices. Yet the\ndestructor for a future sometimes behaves as if it did an implicit join, sometimes as\nif it did an implicit detach, and sometimes neither. It never causes program termina‐\ntion. This thread handle behavioral bouillabaisse deserves closer examination.\nWe’ll begin with the observation that a future is one end of a communications chan‐\nnel through which a callee transmits a result to a caller.4 The callee (usually running\nasynchronously) writes the result of its computation into the communications chan‐\nnel (typically via a std::promise object), and the caller reads that result using a\nfuture. You can think of it as follows, where the dashed arrow shows the flow of\ninformation from callee to caller:\nCaller\nfuture\nCallee\n(typically)\nstd::promise\nBut where is the callee’s result stored? The callee could finish before the caller invokes\nget on a corresponding future, so the result can’t be stored in the callee’s\nstd::promise. That object, being local to the callee, would be destroyed when the\ncallee finished.\nThe result can’t be stored in the caller’s future, either, because (among other reasons)\na std::future may be used to create a std::shared_future (thus transferring\nownership of the callee’s result from the std::future to the std::shared_future),\nwhich may then be copied many times after the original std::future is destroyed.\nGiven that not all result types can be copied (i.e., move-only types) and that the result\n258 \n| \nItem 38\nwww.it-ebooks.info\n\n\nmust live at least as long as the last future referring to it, which of the potentially\nmany futures corresponding to the callee should be the one to contain its result?\nBecause neither objects associated with the callee nor objects associated with the\ncaller are suitable places to store the callee’s result, it’s stored in a location outside\nboth. This location is known as the shared state. The shared state is typically repre‐\nsented by a heap-based object, but its type, interface, and implementation are not\nspecified by the Standard. Standard Library authors are free to implement shared\nstates in any way they like.\nWe can envision the relationship among the callee, the caller, and the shared state as\nfollows, where dashed arrows once again represent the flow of information:\nCaller\nCallee’s\nResult\nShared State\nfuture\nCallee\n(typically)\nstd::promise\nThe existence of the shared state is important, because the behavior of a future’s\ndestructor—the topic of this Item—is determined by the shared state associated with\nthe future. In particular,\n• The destructor for the last future referring to a shared state for a non-\ndeferred task launched via std::async blocks until the task completes. In\nessence, the destructor for such a future does an implicit join on the thread on\nwhich the asynchronously executing task is running.\n• The destructor for all other futures simply destroys the future object. For\nasynchronously running tasks, this is akin to an implicit detach on the underly‐\ning thread. For deferred tasks for which this is the final future, it means that the\ndeferred task will never run.\nThese rules sound more complicated than they are. What we’re really dealing with is\na simple “normal” behavior and one lone exception to it. The normal behavior is that\na future’s destructor destroys the future object. That’s it. It doesn’t join with any‐\nthing, it doesn’t detach from anything, it doesn’t run anything. It just destroys the\nfuture’s data members. (Well, actually, it does one more thing. It decrements the ref‐\nerence count inside the shared state that’s manipulated by both the futures referring\nto it and the callee’s std::promise. This reference count makes it possible for the\nlibrary to know when the shared state can be destroyed. For general information\nabout reference counting, see Item 19.)\nThe exception to this normal behavior arises only for a future for which all of the fol‐\nlowing apply:\nItem 38 \n| \n259\nwww.it-ebooks.info\n\n\n• It refers to a shared state that was created due to a call to std::async.\n• The task’s launch policy is std::launch::async (see Item 36), either because\nthat was chosen by the runtime system or because it was specified in the call to\nstd::async.\n• The future is the last future referring to the shared state. For std::futures,\nthis will always be the case. For std::shared_futures, if other std::shared_\nfutures refer to the same shared state as the future being destroyed, the future\nbeing destroyed follows the normal behavior (i.e., it simply destroys its data\nmembers).\nOnly when all of these conditions are fulfilled does a future’s destructor exhibit spe‐\ncial behavior, and that behavior is to block until the asynchronously running task\ncompletes. Practically speaking, this amounts to an implicit join with the thread\nrunning the std::async-created task.\nIt’s common to hear this exception to normal future destructor behavior summarized\nas “Futures from std::async block in their destructors.” To a first approximation,\nthat’s correct, but sometimes you need more than a first approximation. Now you\nknow the truth in all its glory and wonder.\nYour wonder may take a different form. It may be of the “I wonder why there’s a spe‐\ncial rule for shared states for non-deferred tasks that are launched by std::async”\nvariety. It’s a reasonable question. From what I can tell, the Standardization Commit‐\ntee wanted to avoid the problems associated with an implicit detach (see Item 37),\nbut they didn’t want to adopt as radical a policy as mandatory program termination\n(as they did for joinable std::threads—again, see Item 37), so they compromised\non an implicit join. The decision was not without controversy, and there was serious\ntalk about abandoning this behavior for C++14. In the end, no change was made, so\nthe behavior of destructors for futures is consistent in C++11 and C++14.\nThe API for futures offers no way to determine whether a future refers to a shared\nstate arising from a call to std::async, so given an arbitrary future object, it’s not\npossible to know whether it will block in its destructor waiting for an asynchronously\nrunning task to finish. This has some interesting implications:\n// this container might block in its dtor, because one or more\n// contained futures could refer to a shared state for a non-\n// deferred task launched via std::async\nstd::vector<std::future<void>> futs;   // see Item 39 for info\n                                       // on std::future<void>\nclass Widget {                         // Widget objects might\npublic:                                // block in their dtors\n260 \n| \nItem 38\nwww.it-ebooks.info\n\n\n  …\nprivate:\n  std::shared_future<double> fut;\n};\nOf course, if you have a way of knowing that a given future does not satisfy the condi‐\ntions that trigger the special destructor behavior (e.g., due to program logic), you’re\nassured that that future won’t block in its destructor. For example, only shared states\narising from calls to std::async qualify for the special behavior, but there are other\nways that shared states get created. One is the use of std::packaged_task. A\nstd::packaged_task object prepares a function (or other callable object) for asyn‐\nchronous execution by wrapping it such that its result is put into a shared state. A\nfuture referring to that shared state can then be obtained via std::packaged_task’s\nget_future function:\nint calcValue();                      // func to run\nstd::packaged_task<int()>             // wrap calcValue so it\n  pt(calcValue);                      // can run asynchronously\nauto fut = pt.get_future();           // get future for pt\nAt this point, we know that the future fut doesn’t refer to a shared state created by a\ncall to std::async, so its destructor will behave normally.\nOnce created, the std::packaged_task pt can be run on a thread. (It could be run\nvia a call to std::async, too, but if you want to run a task using std::async, there’s\nlittle reason to create a std::packaged_task, because std::async does everything\nstd::packaged_task does before it schedules the task for execution.)\nstd::packaged_tasks aren’t copyable, so when pt is passed to the std::thread\nconstructor, it must be cast to an rvalue (via std::move—see Item 23):\nstd::thread t(std::move(pt));         // run pt on t\nThis example lends some insight into the normal behavior for future destructors, but\nit’s easier to see if the statements are put together inside a block:\n{                                     // begin block\n  std::packaged_task<int()>\n    pt(calcValue);\n  auto fut = pt.get_future();\nItem 38 \n| \n261\nwww.it-ebooks.info\n\n\n  std::thread t(std::move(pt));\n  …                                   // see below\n}                                     // end block\nThe most interesting code here is the “…” that follows creation of the std::thread\nobject t and precedes the end of the block. What makes it interesting is what can\nhappen to t inside the “…” region. There are three basic possibilities:\n• Nothing happens to t. In this case, t will be joinable at the end of the scope.\nThat will cause the program to be terminated (see Item 37).\n• A join is done on t. In this case, there would be no need for fut to block in its\ndestructor, because the join is already present in the calling code.\n• A detach is done on t. In this case, there would be no need for fut to detach in\nits destructor, because the calling code already does that.\nIn other words, when you have a future corresponding to a shared state that arose\ndue to a std::packaged_task, there’s usually no need to adopt a special destruction\npolicy, because the decision among termination, joining, or detaching will be made in\nthe code that manipulates the std::thread on which the std::packaged_task is\ntypically run.\nThings to Remember\n• Future destructors normally just destroy the future’s data members.\n• The final future referring to a shared state for a non-deferred task launched\nvia std::async blocks until the task completes.\nItem 39: Consider void futures for one-shot event\ncommunication.\nSometimes it’s useful for a task to tell a second, asynchronously running task that a\nparticular event has occurred, because the second task can’t proceed until the event\nhas taken place. Perhaps a data structure has been initialized, a stage of computation\nhas been completed, or a significant sensor value has been detected. When that’s the\ncase, what’s the best way for this kind of inter-thread communication to take place?\nAn obvious approach is to use a condition variable (condvar). If we call the task that\ndetects the condition the detecting task and the task reacting to the condition the\n262 \n| \nItem 38\nwww.it-ebooks.info\n\n\nreacting task, the strategy is simple: the reacting task waits on a condition variable,\nand the detecting thread notifies that condvar when the event occurs. Given\nstd::condition_variable cv;             // condvar for event\nstd::mutex m;                           // mutex for use with cv\nthe code in the detecting task is as simple as simple can be:\n…                                       // detect event\ncv.notify_one();                        // tell reacting task\nIf there were multiple reacting tasks to be notified, it would be appropriate to replace\nnotify_one with notify_all, but for now, we’ll assume there’s only one reacting\ntask.\nThe code for the reacting task is a bit more complicated, because before calling wait\non the condvar, it must lock a mutex through a std::unique_lock object. (Locking\na mutex before waiting on a condition variable is typical for threading libraries. The\nneed to lock the mutex through a std::unique_lock object is simply part of the\nC++11 API.) Here’s the conceptual approach:\n…                                      // prepare to react\n{                                      // open critical section\n  std::unique_lock<std::mutex> lk(m);  // lock mutex\n  cv.wait(lk);                         // wait for notify;\n                                       // this isn't correct!\n  …                                    // react to event\n                                       // (m is locked)\n}                                      // close crit. section;\n                                       // unlock m via lk's dtor\n…                                      // continue reacting\n                                       // (m now unlocked)\nThe first issue with this approach is what’s sometimes termed a code smell: even if the\ncode works, something doesn’t seem quite right. In this case, the odor emanates from\nthe need to use a mutex. Mutexes are used to control access to shared data, but it’s\nentirely possible that the detecting and reacting tasks have no need for such media‐\ntion. For example, the detecting task might be responsible for initializing a global\ndata structure, then turning it over to the reacting task for use. If the detecting task\nItem 39 \n| \n263\nwww.it-ebooks.info\n\n\nnever accesses the data structure after initializing it, and if the reacting task never\naccesses it before the detecting task indicates that it’s ready, the two tasks will stay out\nof each other’s way through program logic. There will be no need for a mutex. The\nfact that the condvar approach requires one leaves behind the unsettling aroma of\nsuspect design.\nEven if you look past that, there are two other problems you should definitely pay\nattention to:\n• If the detecting task notifies the condvar before the reacting task waits, the\nreacting task will hang. In order for notification of a condvar to wake another\ntask, the other task must be waiting on that condvar. If the detecting task hap‐\npens to execute the notification before the reacting task executes the wait, the\nreacting task will miss the notification, and it will wait forever.\n• The wait statement fails to account for spurious wakeups. A fact of life in\nthreading APIs (in many languages—not just C++) is that code waiting on a con‐\ndition variable may be awakened even if the condvar wasn’t notified. Such awak‐\nenings are known as spurious wakeups. Proper code deals with them by\nconfirming that the condition being waited for has truly occurred, and it does\nthis as its first action after waking. The C++ condvar API makes this exception‐\nally easy, because it permits a lambda (or other function object) that tests for the\nwaited-for condition to be passed to wait. That is, the wait call in the reacting\ntask could be written like this:\ncv.wait(lk,\n        []{ return whether the event has occurred; });\nTaking advantage of this capability requires that the reacting task be able to\ndetermine whether the condition it’s waiting for is true. But in the scenario we’ve\nbeen considering, the condition it’s waiting for is the occurrence of an event that\nthe detecting thread is responsible for recognizing. The reacting thread may have\nno way of determining whether the event it’s waiting for has taken place. That’s\nwhy it’s waiting on a condition variable!\nThere are many situations where having tasks communicate using a condvar is a\ngood fit for the problem at hand, but this doesn’t seem to be one of them.\nFor many developers, the next trick in their bag is a shared boolean flag. The flag is\ninitially false. When the detecting thread recognizes the event it’s looking for, it sets\nthe flag:\nstd::atomic<bool> flag(false);      // shared flag; see\n                                    // Item 40 for std::atomic\n…                                   // detect event\n264 \n| \nItem 39\nwww.it-ebooks.info\n\n\nflag = true;                        // tell reacting task\nFor its part, the reacting thread simply polls the flag. When it sees that the flag is set,\nit knows that the event it’s been waiting for has occurred:\n…                                   // prepare to react\nwhile (!flag);                      // wait for event\n…                                   // react to event\nThis approach suffers from none of the drawbacks of the condvar-based design.\nThere’s no need for a mutex, no problem if the detecting task sets the flag before the\nreacting task starts polling, and nothing akin to a spurious wakeup. Good, good,\ngood.\nLess good is the cost of polling in the reacting task. During the time the task is wait‐\ning for the flag to be set, the task is essentially blocked, yet it’s still running. As such,\nit occupies a hardware thread that another task might be able to make use of, it incurs\nthe cost of a context switch each time it starts or completes its time-slice, and it could\nkeep a core running that might otherwise be shut down to save power. A truly\nblocked task would do none of these things. That’s an advantage of the condvar-\nbased approach, because a task in a wait call is truly blocked.\nIt’s common to combine the condvar and flag-based designs. A flag indicates whether\nthe event of interest has occurred, but access to the flag is synchronized by a mutex.\nBecause the mutex prevents concurrent access to the flag, there is, as Item 40\nexplains, no need for the flag to be std::atomic; a simple bool will do. The detect‐\ning task would then look like this:\nstd::condition_variable cv;           // as before\nstd::mutex m;\nbool flag(false);                     // not std::atomic\n…                                     // detect event\n{\n  std::lock_guard<std::mutex> g(m);   // lock m via g's ctor\n  flag = true;                        // tell reacting task\n                                      // (part 1)\n}                                     // unlock m via g's dtor\nItem 39 \n| \n265\nwww.it-ebooks.info\n\n\ncv.notify_one();                      // tell reacting task\n                                      // (part 2)\nAnd here’s the reacting task:\n…                                      // prepare to react\n{                                      // as before\n  std::unique_lock<std::mutex> lk(m);  // as before\n  cv.wait(lk, [] { return flag; });    // use lambda to avoid\n                                       // spurious wakeups\n  …                                    // react to event\n                                       // (m is locked)\n}\n…                                      // continue reacting\n                                       // (m now unlocked)\nThis approach avoids the problems we’ve discussed. It works regardless of whether\nthe reacting task waits before the detecting task notifies, it works in the presence of\nspurious wakeups, and it doesn’t require polling. Yet an odor remains, because the\ndetecting task communicates with the reacting task in a very curious fashion. Notify‐\ning the condition variable tells the reacting task that the event it’s been waiting for\nhas probably occurred, but the reacting task must check the flag to be sure. Setting\nthe flag tells the reacting task that the event has definitely occurred, but the detecting\ntask still has to notify the condition variable so that the reacting task will awaken and\ncheck the flag. The approach works, but it doesn’t seem terribly clean.\nAn alternative is to avoid condition variables, mutexes, and flags by having the react‐\ning task wait on a future that’s set by the detecting task. This may seem like an odd\nidea. After all, Item 38 explains that a future represents the receiving end of a com‐\nmunications channel from a callee to a (typically asynchronous) caller, and here\nthere’s no callee-caller relationship between the detecting and reacting tasks. How‐\never, Item 38 also notes that a communications channel whose transmitting end is a\nstd::promise and whose receiving end is a future can be used for more than just\ncallee-caller communication. Such a communications channel can be used in any sit‐\nuation where you need to transmit information from one place in your program to\nanother. In this case, we’ll use it to transmit information from the detecting task to\nthe reacting task, and the information we’ll convey will be that the event of interest\nhas taken place.\nThe design is simple. The detecting task has a std::promise object (i.e., the writing\nend of the communications channel), and the reacting task has a corresponding\n266 \n| \nItem 39\nwww.it-ebooks.info\n\n\nfuture. When the detecting task sees that the event it’s looking for has occurred, it sets\nthe std::promise (i.e., writes into the communications channel). Meanwhile, the\nreacting task waits on its future. That wait blocks the reacting task until the\nstd::promise has been set.\nNow, both std::promise and futures (i.e., std::future and std::shared_future)\nare templates that require a type parameter. That parameter indicates the type of data\nto be transmitted through the communications channel. In our case, however, there’s\nno data to be conveyed. The only thing of interest to the reacting task is that its future\nhas been set. What we need for the std::promise and future templates is a type that\nindicates that no data is to be conveyed across the communications channel. That\ntype is void. The detecting task will thus use a std::promise<void>, and the react‐\ning task a std::future<void> or std::shared_future<void>. The detecting task\nwill set its std::promise<void> when the event of interest occurs, and the reacting\ntask will wait on its future. Even though the reacting task won’t receive any data\nfrom the detecting task, the communications channel will permit the reacting task to\nknow when the detecting task has “written” its void data by calling set_value on its\nstd::promise.\nSo given\nstd::promise<void> p;               // promise for\n                                    // communications channel\nthe detecting task’s code is trivial,\n…                                   // detect event\np.set_value();                      // tell reacting task\nand the reacting task’s code is equally simple:\n…                                   // prepare to react\np.get_future().wait();              // wait on future\n                                    // corresponding to p\n…                                   // react to event\nLike the approach using a flag, this design requires no mutex, works regardless of\nwhether the detecting task sets its std::promise before the reacting task waits, and\nis immune to spurious wakeups. (Only condition variables are susceptible to that\nproblem.) Like the condvar-based approach, the reacting task is truly blocked after\nmaking the wait call, so it consumes no system resources while waiting. Perfect,\nright?\nItem 39 \n| \n267\nwww.it-ebooks.info\n\n\nNot exactly. Sure, a future-based approach skirts those shoals, but there are other\nhazards to worry about. For example, Item 38 explains that between a std::promise\nand a future is a shared state, and shared states are typically dynamically allocated.\nYou should therefore assume that this design incurs the cost of heap-based allocation\nand deallocation.\nPerhaps more importantly, a std::promise may be set only once. The communica‐\ntions channel between a std::promise and a future is a one-shot mechanism: it can’t\nbe used repeatedly. This is a notable difference from the condvar- and flag-based\ndesigns, both of which can be used to communicate multiple times. (A condvar can\nbe repeatedly notified, and a flag can always be cleared and set again.)\nThe one-shot restriction isn’t as limiting as you might think. Suppose you’d like to\ncreate a system thread in a suspended state. That is, you’d like to get all the overhead\nassociated with thread creation out of the way so that when you’re ready to execute\nsomething on the thread, the normal thread-creation latency will be avoided. Or you\nmight want to create a suspended thread so that you could configure it before letting\nit run. Such configuration might include things like setting its priority or core affin‐\nity. The C++ concurrency API offers no way to do those things, but std::thread\nobjects offer the native_handle member function, the result of which is intended to\ngive you access to the platform’s underlying threading API (usually POSIX threads or\nWindows threads). The lower-level API often makes it possible to configure thread\ncharacteristics such as priority and affinity.\nAssuming you want to suspend a thread only once (after creation, but before it’s run‐\nning its thread function), a design using a void future is a reasonable choice. Here’s\nthe essence of the technique:\nstd::promise<void> p;\nvoid react();                        // func for reacting task\nvoid detect()                        // func for detecting task\n{\n  std::thread t([]                   // create thread\n                {\n                  p.get_future().wait();     // suspend t until\n                  react();                   // future is set\n                });\n  …                                  // here, t is suspended\n                                     // prior to call to react\n  p.set_value();                     // unsuspend t (and thus\n                                     // call react)\n268 \n| \nItem 39\nwww.it-ebooks.info\n",
      "page_number": 271,
      "chapter_number": 26,
      "summary": "This chapter covers segment 26 (pages 271-286). Key topics include thread, future. In doWork, for example, goodVals is a local variable that is captured by\nreference.",
      "keywords": [
        "std",
        "reacting task",
        "task",
        "future",
        "Item",
        "thread",
        "detecting task",
        "reacting",
        "shared state",
        "reacting task waits",
        "shared",
        "object",
        "thread objects",
        "detecting",
        "destructor"
      ],
      "concepts": [
        "std",
        "thread",
        "future",
        "items",
        "task",
        "object",
        "reacting",
        "approach",
        "running",
        "run"
      ],
      "similar_chapters": [
        {
          "book": "C++ Concurrency in Action",
          "chapter": 12,
          "title": "Segment 12 (pages 104-111)",
          "relevance_score": 0.67,
          "method": "sentence_transformers"
        },
        {
          "book": "C++ Concurrency in Action",
          "chapter": 15,
          "title": "Segment 15 (pages 132-140)",
          "relevance_score": 0.67,
          "method": "sentence_transformers"
        },
        {
          "book": "C++ Concurrency in Action",
          "chapter": 16,
          "title": "Segment 16 (pages 141-154)",
          "relevance_score": 0.62,
          "method": "sentence_transformers"
        },
        {
          "book": "C++ Concurrency in Action",
          "chapter": 29,
          "title": "Segment 29 (pages 298-305)",
          "relevance_score": 0.62,
          "method": "sentence_transformers"
        },
        {
          "book": "C++ Concurrency in Action",
          "chapter": 32,
          "title": "Segment 32 (pages 322-329)",
          "relevance_score": 0.62,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 27,
      "title": "Segment 27 (pages 287-297)",
      "start_page": 287,
      "end_page": 297,
      "detection_method": "topic_boundary",
      "content": "5 A reasonable place to begin researching the matter is my 24 December 2013 blog post at The View From Aris‐\nteia, “ThreadRAII + Thread Suspension = Trouble?”\n  …                                  // do additional work\n  t.join();                          // make t unjoinable\n}                                    // (see Item 37)\nBecause it’s important that t become unjoinable on all paths out of detect, use of an\nRAII class like Item 37’s ThreadRAII seems like it would be advisable. Code like this\ncomes to mind:\nvoid detect()\n{\n  ThreadRAII tr(                          // use RAII object\n    std::thread([]\n                {                       \n                  p.get_future().wait();\n                  react();\n                }),\n    ThreadRAII::DtorAction::join          // risky! (see below)\n  );\n  …                                       // thread inside tr\n                                          // is suspended here\n  p.set_value();                          // unsuspend thread\n                                          // inside tr\n  …\n}\nThis looks safer than it is. The problem is that if in the first “…” region (the one with\nthe “thread inside tr is suspended here” comment), an exception is emitted,\nset_value will never be called on p. That means that the call to wait inside the\nlambda will never return. That, in turn, means that the thread running the lambda\nwill never finish, and that’s a problem, because the RAII object tr has been config‐\nured to perform a join on that thread in tr’s destructor. In other words, if an excep‐\ntion is emitted from the first “…” region of code, this function will hang, because tr’s\ndestructor will never complete.\nThere are ways to address this problem, but I’ll leave them in the form of the hal‐\nlowed exercise for the reader.5 Here, I’d like to show how the original code (i.e., not\nusing ThreadRAII) can be extended to suspend and then unsuspend not just one\nItem 39 \n| \n269\nwww.it-ebooks.info\n\n\nreacting task, but many. It’s a simple generalization, because the key is to use\nstd::shared_futures instead of a std::future in the react code. Once you know\nthat the std::future’s share member function transfers ownership of its shared\nstate to the std::shared_future object produced by share, the code nearly writes\nitself. The only subtlety is that each reacting thread needs its own copy of the\nstd::shared_future that refers to the shared state, so the std::shared_future\nobtained from share is captured by value by the lambdas running on the reacting\nthreads:\nstd::promise<void> p;                // as before\nvoid detect()                        // now for multiple\n{                                    // reacting tasks\n  auto sf = p.get_future().share();  // sf's type is\n                                     // std::shared_future<void>\n  std::vector<std::thread> vt;              // container for\n                                            // reacting threads\n  for (int i = 0; i < threadsToRun; ++i) {\n    vt.emplace_back([sf]{ sf.wait();        // wait on local\n                          react(); });      // copy of sf; see\n  }                                         // Item 42 for info\n                                            // on emplace_back\n  …                                  // detect hangs if\n                                     // this \"…\" code throws!\n  p.set_value();                     // unsuspend all threads\n  …\n  for (auto& t : vt) {               // make all threads\n    t.join();                        // unjoinable; see Item 2\n  }                                  // for info on \"auto&\"\n}\nThe fact that a design using futures can achieve this effect is noteworthy, and that’s\nwhy you should consider it for one-shot event communication.\n270 \n| \nItem 39\nwww.it-ebooks.info\n\n\nThings to Remember\n• For simple event communication, condvar-based designs require a superflu‐\nous mutex, impose constraints on the relative progress of detecting and react‐\ning tasks, and require reacting tasks to verify that the event has taken place.\n• Designs employing a flag avoid those problems, but are based on polling, not\nblocking.\n• A condvar and flag can be used together, but the resulting communications\nmechanism is somewhat stilted.\n• Using std::promises and futures dodges these issues, but the approach uses\nheap memory for shared states, and it’s limited to one-shot communication.\nItem 40: Use std::atomic for concurrency, volatile\nfor special memory.\nPoor volatile. So misunderstood. It shouldn’t even be in this chapter, because it has\nnothing to do with concurrent programming. But in other programming languages\n(e.g., Java and C#), it is useful for such programming, and even in C++, some compil‐\ners have imbued volatile with semantics that render it applicable to concurrent\nsoftware (but only when compiled with those compilers). It’s thus worthwhile to dis‐\ncuss volatile in a chapter on concurrency if for no other reason than to dispel the\nconfusion surrounding it.\nThe C++ feature that programmers sometimes confuse volatile with—the feature\nthat definitely does belong in this chapter—is the std::atomic template. Instantia‐\ntions \nof \nthis \ntemplate \n(e.g., \nstd::atomic<int>, \nstd::atomic<bool>,\nstd::atomic<Widget*>, etc.) offer operations that are guaranteed to be seen as\natomic by other threads. Once a std::atomic object has been constructed, opera‐\ntions on it behave as if they were inside a mutex-protected critical section, but the\noperations are generally implemented using special machine instructions that are\nmore efficient than would be the case if a mutex were employed.\nConsider this code using std::atomic:\nstd::atomic<int> ai(0);    // initialize ai to 0\nai = 10;                   // atomically set ai to 10\nstd::cout << ai;           // atomically read ai's value\n++ai;                      // atomically increment ai to 11\nItem 39 \n| \n271\nwww.it-ebooks.info\n\n\n--ai;                      // atomically decrement ai to 10\nDuring execution of these statements, other threads reading ai may see only values\nof 0, 10, or 11. No other values are possible (assuming, of course, that this is the only\nthread modifying ai).\nTwo aspects of this example are worth noting. First, in the “std::cout << ai;” state‐\nment, the fact that ai is a std::atomic guarantees only that the read of ai is atomic.\nThere is no guarantee that the entire statement proceeds atomically. Between the\ntime ai’s value is read and operator<< is invoked to write it to the standard output,\nanother thread may have modified ai’s value. That has no effect on the behavior of\nthe statement, because operator<< for ints uses a by-value parameter for the int to\noutput (the outputted value will therefore be the one that was read from ai), but it’s\nimportant to understand that what’s atomic in that statement is nothing more than\nthe read of ai.\nThe second noteworthy aspect of the example is the behavior of the last two state‐\nments—the increment and decrement of ai. These are each read-modify-write\n(RMW) operations, yet they execute atomically. This is one of the nicest characteris‐\ntics of the std::atomic types: once a std::atomic object has been constructed, all\nmember functions on it, including those comprising RMW operations, are guaran‐\nteed to be seen by other threads as atomic.\nIn contrast, the corresponding code using volatile guarantees virtually nothing in a\nmultithreaded context:\nvolatile int vi(0);        // initialize vi to 0\nvi = 10;                   // set vi to 10\nstd::cout << vi;           // read vi's value\n++vi;                      // increment vi to 11\n--vi;                      // decrement vi to 10\nDuring execution of this code, if other threads are reading the value of vi, they may\nsee anything, e.g, -12, 68, 4090727—anything! Such code would have undefined\nbehavior, because these statements modify vi, so if other threads are reading vi at\nthe same time, there are simultaneous readers and writers of memory that’s neither\nstd::atomic nor protected by a mutex, and that’s the definition of a data race.\n272 \n| \nItem 40\nwww.it-ebooks.info\n\n\nAs a concrete example of how the behavior of std::atomics and volatiles can dif‐\nfer in a multithreaded program, consider a simple counter of each type that’s incre‐\nmented by multiple threads. We’ll initialize each to 0:\nstd::atomic<int> ac(0);    // \"atomic counter\"\nvolatile int vc(0);        // \"volatile counter\"\nWe’ll then increment each counter one time in two simultaneously running threads:\n/*-----  Thread 1  ----- */     /*-------  Thread 2  ------- */\n         ++ac;                             ++ac;\n         ++vc;                             ++vc;\nWhen both threads have finished, ac’s value (i.e., the value of the std::atomic)\nmust be 2, because each increment occurs as an indivisible operation. vc’s value, on\nthe other hand, need not be 2, because its increments may not occur atomically. Each\nincrement consists of reading vc’s value, incrementing the value that was read, and\nwriting the result back into vc. But these three operations are not guaranteed to pro‐\nceed atomically for volatile objects, so it’s possible that the component parts of the\ntwo increments of vc are interleaved as follows:\n1. Thread 1 reads vc’s value, which is 0.\n2. Thread 2 reads vc’s value, which is still 0.\n3. Thread 1 increments the 0 it read to 1, then writes that value into vc.\n4. Thread 2 increments the 0 it read to 1, then writes that value into vc.\nvc’s final value is therefore 1, even though it was incremented twice.\nThis is not the only possible outcome. vc’s final value is, in general, not predictable,\nbecause vc is involved in a data race, and the Standard’s decree that data races cause\nundefined behavior means that compilers may generate code to do literally anything.\nCompilers don’t use this leeway to be malicious, of course. Rather, they perform opti‐\nmizations that would be valid in programs without data races, and these optimiza‐\ntions yield unexpected and unpredictable behavior in programs where races are\npresent.\nThe use of RMW operations isn’t the only situation where std::atomics comprise a\nconcurrency success story and volatiles suffer failure. Suppose one task computes\nan important value needed by a second task. When the first task has computed the\nvalue, it must communicate this to the second task. Item 39 explains that one way for\nthe first task to communicate the availability of the desired value to the second task is\nItem 40 \n| \n273\nwww.it-ebooks.info\n\n\n6 This is true only for std::atomics using sequential consistency, which is both the default and the only consis‐\ntency model for std::atomic objects that use the syntax shown in this book. C++11 also supports consis‐\ntency models with more flexible code-reordering rules. Such weak (aka relaxed) models make it possible to\ncreate software that runs faster on some hardware architectures, but the use of such models yields software\nthat is much more difficult to get right, to understand, and to maintain. Subtle errors in code using relaxed\natomics is not uncommon, even for experts, so you should stick to sequential consistency if at all possible.\nby using a std::atomic<bool>. Code in the task computing the value would look\nsomething like this:\nstd::atomic<bool> valAvailable(false);\nauto imptValue = computeImportantValue();  // compute value\nvalAvailable = true;                       // tell other task\n                                           // it's available\nAs humans reading this code, we know it’s crucial that the assignment to imptValue\ntake place before the assignment to valAvailable, but all compilers see is a pair of\nassignments to independent variables. As a general rule, compilers are permitted to\nreorder such unrelated assignments. That is, given this sequence of assignments\n(where a, b, x, and y correspond to independent variables),\na = b;\nx = y;\ncompilers may generally reorder them as follows:\nx = y;\na = b;\nEven if compilers don’t reorder them, the underlying hardware might do it (or might\nmake it seem to other cores as if it had), because that can sometimes make the code\nrun faster.\nHowever, the use of std::atomics imposes restrictions on how code can be reor‐\ndered, and one such restriction is that no code that, in the source code, precedes a\nwrite of a std::atomic variable may take place (or appear to other cores to take\nplace) afterwards.6 That means that in our code,\nauto imptValue = computeImportantValue();  // compute value\nvalAvailable = true;                       // tell other task\n                                           // it's available\nnot only must compilers retain the order of the assignments to imptValue and\nvalAvailable, they must generate code that ensures that the underlying hardware\n274 \n| \nItem 40\nwww.it-ebooks.info\n\n\ndoes, too. As a result, declaring valAvailable as std::atomic ensures that our crit‐\nical ordering requirement—imptValue must be seen by all threads to change no later\nthan valAvailable does—is maintained.\nDeclaring valAvailable as volatile doesn’t impose the same code reordering\nrestrictions:\nvolatile bool valAvailable(false);\nauto imptValue = computeImportantValue();\nvalAvailable = true;  // other threads might see this assignment\n                      // before the one to imptValue!\nHere, compilers might flip the order of the assignments to imptValue and valAvail\nable, and even if they don’t, they might fail to generate machine code that would\nprevent the underlying hardware from making it possible for code on other cores to\nsee valAvailable change before imptValue.\nThese two issues—no guarantee of operation atomicity and insufficient restrictions\non code reordering—explain why volatile’s not useful for concurrent program‐\nming, but it doesn’t explain what it is useful for. In a nutshell, it’s for telling compilers\nthat they’re dealing with memory that doesn’t behave normally.\n“Normal” memory has the characteristic that if you write a value to a memory loca‐\ntion, the value remains there until something overwrites it. So if I have a normal int,\nint x;\nand a compiler sees the following sequence of operations on it,\nauto y = x;           // read x\ny = x;                // read x again\nthe compiler can optimize the generated code by eliminating the assignment to y,\nbecause it’s redundant with y’s initialization.\nNormal memory also has the characteristic that if you write a value to a memory\nlocation, never read it, and then write to that memory location again, the first write\ncan be eliminated, because it was never used. So given these two adjacent statements,\nx = 10;               // write x\nx = 20;               // write x again\ncompilers can eliminate the first one. That means that if we have this in the source\ncode,\nauto y = x;           // read x\ny = x;                // read x again\nItem 40 \n| \n275\nwww.it-ebooks.info\n\n\nx = 10;               // write x\nx = 20;               // write x again\ncompilers can treat it as if it had been written like this:\nauto y = x;           // read x\nx = 20;               // write x\nLest you wonder who’d write code that performs these kinds of redundant reads and\nsuperfluous writes (technically known as redundant loads and dead stores), the\nanswer is that humans don’t write it directly—at least we hope they don’t. However,\nafter compilers take reasonable-looking source code and perform template instantia‐\ntion, inlining, and various common kinds of reordering optimizations, it’s not\nuncommon for the result to have redundant loads and dead stores that compilers can\nget rid of.\nSuch optimizations are valid only if memory behaves normally. “Special” memory\ndoesn’t. Probably the most common kind of special memory is memory used for\nmemory-mapped I/O. Locations in such memory actually communicate with periph‐\nerals, e.g., external sensors or displays, printers, network ports, etc. rather than read‐\ning or writing normal memory (i.e., RAM). In such a context, consider again the code\nwith seemingly redundant reads:\nauto y = x;           // read x\ny = x;                // read x again\nIf x corresponds to, say, the value reported by a temperature sensor, the second read\nof x is not redundant, because the temperature may have changed between the first\nand second reads.\nIt’s a similar situation for seemingly superfluous writes. In this code, for example,\nx = 10;               // write x\nx = 20;               // write x again\nif x corresponds to the control port for a radio transmitter, it could be that the code is\nissuing commands to the radio, and the value 10 corresponds to a different command\nfrom the value 20. Optimizing out the first assignment would change the sequence of\ncommands sent to the radio.\nvolatile is the way we tell compilers that we’re dealing with special memory. Its\nmeaning to compilers is “Don’t perform any optimizations on operations on this\nmemory.” So if x corresponds to special memory, it’d be declared volatile:\nvolatile int x;\nConsider the effect that has on our original code sequence:\n276 \n| \nItem 40\nwww.it-ebooks.info\n\n\n7 y’s type is auto-deduced, so it uses the rules described in Item 2. Those rules dictate that for the declaration of\nnon-reference non-pointer types (which is the case for y), const and volatile qualifiers are dropped. y’s\ntype is therefore simply int. This means that redundant reads of and writes to y can be eliminated. In the\nexample, compilers must perform both the initialization of and the assignment to y, because x is volatile,\nso the second read of x might yield a different value from the first one.\nauto y = x;           // read x\ny = x;                // read x again (can't be optimized away)\nx = 10;               // write x (can't be optimized away)\nx = 20;               // write x again\nThis is precisely what we want if x is memory-mapped (or has been mapped to a\nmemory location shared across processes, etc.).\nPop quiz! In that last piece of code, what is y’s type: int or volatile int?7\nThe fact that seemingly redundant loads and dead stores must be preserved when\ndealing with special memory explains, by the way, why std::atomics are unsuitable\nfor this kind of work. Compilers are permitted to eliminate such redundant opera‐\ntions on std::atomics. The code isn’t written quite the same way it is for vola\ntiles, but if we overlook that for a moment and focus on what compilers are\npermitted to do, we can say that, conceptually, compilers may take this,\nstd::atomic<int> x;\nauto y = x;           // conceptually read x (see below)\ny = x;                // conceptually read x again (see below)\nx = 10;               // write x\nx = 20;               // write x again\nand optimize it to this:\nauto y = x;           // conceptually read x (see below)\nx = 20;               // write x\nFor special memory, this is clearly unacceptable behavior.\nNow, as it happens, neither of these two statements will compile when x is\nstd::atomic:\nauto y = x;           // error!\ny = x;                // error!\nThat’s because the copy operations for std::atomic are deleted (see Item 11). And\nwith good reason. Consider what would happen if the initialization of y with x com‐\nItem 40 \n| \n277\nwww.it-ebooks.info\n\n\npiled. Because x is std::atomic, y’s type would be deduced to be std::atomic, too\n(see Item 2). I remarked earlier that one of the best things about std::atomics is\nthat all their operations are atomic, but in order for the copy construction of y from x\nto be atomic, compilers would have to generate code to read x and write y in a single\natomic operation. Hardware generally can’t do that, so copy construction isn’t sup‐\nported for std::atomic types. Copy assignment is deleted for the same reason,\nwhich is why the assignment from x to y won’t compile. (The move operations aren’t\nexplicitly declared in std::atomic, so, per the rules for compiler-generated special\nfunctions described in Item 17, std::atomic offers neither move construction nor\nmove assignment.)\nIt’s possible to get the value of x into y, but it requires use of std::atomic’s member\nfunctions load and store. The load member function reads a std::atomic’s value\natomically, while the store member function writes it atomically. To initialize y with\nx, followed by putting x’s value in y, the code must be written like this:\nstd::atomic<int> y(x.load());     // read x\ny.store(x.load());                // read x again\nThis compiles, but the fact that reading x (via x.load()) is a separate function call\nfrom initializing or storing to y makes clear that there is no reason to expect either\nstatement as a whole to execute as a single atomic operation.\nGiven that code, compilers could “optimize” it by storing x’s value in a register\ninstead of reading it twice:\nregister = x.load();              // read x into register\nstd::atomic<int> y(register);     // init y with register value\ny.store(register);                // store register value into y\nThe result, as you can see, reads from x only once, and that’s the kind of optimization\nthat must be avoided when dealing with special memory. (The optimization isn’t per‐\nmitted for volatile variables.)\nThe situation should thus be clear:\n• std::atomic is useful for concurrent programming, but not for accessing spe‐\ncial memory.\n• volatile is useful for accessing special memory, but not for concurrent pro‐\ngramming.\n278 \n| \nItem 40\nwww.it-ebooks.info\n\n\nBecause std::atomic and volatile serve different purposes, they can even be used\ntogether:\nvolatile std::atomic<int> vai;    // operations on vai are\n                                  // atomic and can't be\n                                  // optimized away\nThis could be useful if vai corresponded to a memory-mapped I/O location that was\nconcurrently accessed by multiple threads.\nAs a final note, some developers prefer to use std::atomic’s load and store mem‐\nber functions even when they’re not required, because it makes explicit in the source\ncode that the variables involved aren’t “normal.” Emphasizing that fact isn’t unrea‐\nsonable. Accessing a std::atomic is typically much slower than accessing a non-\nstd::atomic, and we’ve already seen that the use of std::atomics prevents\ncompilers from performing certain kinds of code reorderings that would otherwise\nbe permitted. Calling out loads and stores of std::atomics can therefore help iden‐\ntify potential scalability chokepoints. From a correctness perspective, not seeing a call\nto store on a variable meant to communicate information to other threads (e.g., a\nflag indicating the availability of data) could mean that the variable wasn’t declared\nstd::atomic when it should have been.\nThis is largely a style issue, however, and as such is quite different from the choice\nbetween std::atomic and volatile.\nThings to Remember\n• std::atomic is for data accessed from multiple threads without using\nmutexes. It’s a tool for writing concurrent software.\n• volatile is for memory where reads and writes should not be optimized\naway. It’s a tool for working with special memory.\nItem 40 \n| \n279\nwww.it-ebooks.info\n",
      "page_number": 287,
      "chapter_number": 27,
      "summary": "It shouldn’t even be in this chapter, because it has\nnothing to do with concurrent programming Key topics include atomic, volatiles, and code. That, in turn, means that the thread running the lambda\nwill never finish, and that’s a problem, because the RAII object tr has been config‐\nured to perform a join on that thread in tr’s destructor.",
      "keywords": [
        "std",
        "View From Aris",
        "atomic",
        "Code",
        "Item",
        "read",
        "memory",
        "volatile",
        "Thread",
        "write",
        "compilers",
        "n’t",
        "Thread Suspension",
        "special memory",
        "int"
      ],
      "concepts": [
        "atomic",
        "volatiles",
        "code",
        "value",
        "std",
        "thread",
        "compiled",
        "compile",
        "memory",
        "item"
      ],
      "similar_chapters": [
        {
          "book": "C++ Concurrency in Action",
          "chapter": 10,
          "title": "Segment 10 (pages 88-95)",
          "relevance_score": 0.58,
          "method": "sentence_transformers"
        },
        {
          "book": "operating_systems_three_easy_pieces",
          "chapter": 32,
          "title": "Segment 32 (pages 310-319)",
          "relevance_score": 0.58,
          "method": "sentence_transformers"
        },
        {
          "book": "operating_systems_three_easy_pieces",
          "chapter": 36,
          "title": "Segment 36 (pages 355-364)",
          "relevance_score": 0.58,
          "method": "sentence_transformers"
        },
        {
          "book": "C++ Concurrency in Action",
          "chapter": 37,
          "title": "Segment 37 (pages 363-372)",
          "relevance_score": 0.57,
          "method": "sentence_transformers"
        },
        {
          "book": "C++ Concurrency in Action",
          "chapter": 19,
          "title": "Segment 19 (pages 176-183)",
          "relevance_score": 0.56,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 28,
      "title": "Segment 28 (pages 298-307)",
      "start_page": 298,
      "end_page": 307,
      "detection_method": "topic_boundary",
      "content": "www.it-ebooks.info\n\n\n1 In this Item, to “copy” a parameter generally means to use it as the source of a copy or move operation. Recall\non page 2 that C++ has no terminology to distinguish a copy made by a copy operation from one made by a\nmove operation.\nCHAPTER 8\nTweaks\nFor every general technique or feature in C++, there are circumstances where it’s rea‐\nsonable to use it, and there are circumstances where it’s not. Describing when it\nmakes sense to use a general technique or feature is usually fairly straightforward, but\nthis chapter covers two exceptions. The general technique is pass by value, and the\ngeneral feature is emplacement. The decision about when to employ them is affected\nby so many factors, the best advice I can offer is to consider their use. Nevertheless,\nboth are important players in effective modern C++ programming, and the Items\nthat follow provide the information you’ll need to determine whether using them is\nappropriate for your software.\nItem 41: Consider pass by value for copyable parameters\nthat are cheap to move and always copied.\nSome function parameters are intended to be copied.1 For example, a member func‐\ntion addName might copy its parameter into a private container. For efficiency, such a\nfunction should copy lvalue arguments, but move rvalue arguments:\nclass Widget {\npublic:\n  void addName(const std::string& newName)    // take lvalue;\n  { names.push_back(newName); }               // copy it\n  void addName(std::string&& newName)         // take rvalue;\n281\nwww.it-ebooks.info\n\n\n  { names.push_back(std::move(newName)); }    // move it; see\n  …                                           // Item 25 for use\n                                              // of std::move\nprivate:\n  std::vector<std::string> names;\n};\nThis works, but it requires writing two functions that do essentially the same thing.\nThat chafes a bit: two functions to declare, two functions to implement, two func‐\ntions to document, two functions to maintain. Ugh.\nFurthermore, there will be two functions in the object code—something you might\ncare about if you’re concerned about your program’s footprint. In this case, both\nfunctions will probably be inlined, and that’s likely to eliminate any bloat issues\nrelated to the existence of two functions, but if these functions aren’t inlined every‐\nwhere, you really will get two functions in your object code.\nAn alternative approach is to make addName a function template taking a universal\nreference (see Item 24):\nclass Widget {\npublic:\n  template<typename T>                          // take lvalues\n  void addName(T&& newName)                     // and rvalues;\n  {                                             // copy lvalues,\n    names.push_back(std::forward<T>(newName));  // move rvalues;\n  }                                             // see Item 25\n                                                // for use of\n  …                                             // std::forward\n};\nThis reduces the source code you have to deal with, but the use of universal refer‐\nences leads to other complications. As a template, addName’s implementation must\ntypically be in a header file. It may yield several functions in object code, because it\nnot only instantiates differently for lvalues and rvalues, it also instantiates differently\nfor std::string and types that are convertible to std::string (see Item 25). At the\nsame time, there are argument types that can’t be passed by universal reference (see\nItem 30), and if clients pass improper argument types, compiler error messages can\nbe intimidating (see Item 27).\nWouldn’t it be nice if there were a way to write functions like addName such that lval‐\nues were copied, rvalues were moved, there was only one function to deal with (in\nboth source and object code), and the idiosyncrasies of universal references were\navoided? As it happens, there is. All you have to do is abandon one of the first rules\nyou probably learned as a C++ programmer. That rule was to avoid passing objects of\n282 \n| \nItem 41\nwww.it-ebooks.info\n\n\nuser-defined types by value. For parameters like newName in functions like addName,\npass by value may be an entirely reasonable strategy.\nBefore we discuss why pass-by-value may be a good fit for newName and addName,\nlet’s see how it would be implemented:\nclass Widget {\npublic:\n  void addName(std::string newName)           // take lvalue or\n  { names.push_back(std::move(newName)); }    // rvalue; move it\n  …\n};\nThe only non-obvious part of this code is the application of std::move to the param‐\neter newName. Typically, std::move is used with rvalue references, but in this case,\nwe know that (1) newName is a completely independent object from whatever the\ncaller passed in, so changing newName won’t affect callers and (2) this is the final use\nof newName, so moving from it won’t have any impact on the rest of the function.\nThe fact that there’s only one addName function explains how we avoid code duplica‐\ntion, both in the source code and the object code. We’re not using a universal refer‐\nence, so this approach doesn’t lead to bloated header files, odd failure cases, or\nconfounding error messages. But what about the efficiency of this design? We’re\npassing by value. Isn’t that expensive?\nIn C++98, it was a reasonable bet that it was. No matter what callers passed in, the\nparameter newName would be created by copy construction. In C++11, however, add\nName will be copy constructed only for lvalues. For rvalues, it will be move construc‐\nted. Here, look:\nWidget w;\n…\nstd::string name(\"Bart\");\nw.addName(name);                 // call addName with lvalue\n…\nw.addName(name + \"Jenne\");       // call addName with rvalue\n                                 // (see below)\nItem 41 \n| \n283\nwww.it-ebooks.info\n\n\nIn the first call to addName (when name is passed), the parameter newName is initial‐\nized with an lvalue. newName is thus copy constructed, just like it would be in C++98.\nIn the second call, newName is initialized with the std::string object resulting from\na call to operator+ for std::string (i.e., the append operation). That object is an\nrvalue, and newName is therefore move constructed.\nLvalues are thus copied, and rvalues are moved, just like we want. Neat, huh?\nIt is neat, but there are some caveats you need to keep in mind. Doing that will be\neasier if we recap the three versions of addName we’ve considered:\nclass Widget {                                  // Approach 1:\npublic:                                         // overload for\n  void addName(const std::string& newName)      // lvalues and\n  { names.push_back(newName); }                 // rvalues\n  void addName(std::string&& newName)\n  { names.push_back(std::move(newName)); }\n  …\nprivate:\n  std::vector<std::string> names;\n};\nclass Widget {                                  // Approach 2:\npublic:                                         // use universal\n  template<typename T>                          // reference\n  void addName(T&& newName)\n  { names.push_back(std::forward<T>(newName)); }\n  …\n};\nclass Widget {                                  // Approach 3:\npublic:                                         // pass by value\n  void addName(std::string newName)\n  { names.push_back(std::move(newName)); }\n  …\n};\nI refer to the first two versions as the “by-reference approaches,” because they’re both\nbased on passing their parameters by reference.\n284 \n| \nItem 41\nwww.it-ebooks.info\n\n\nHere are the two calling scenarios we’ve examined:\nWidget w;\n…\nstd::string name(\"Bart\");\nw.addName(name);                       // pass lvalue\n…\nw.addName(name + \"Jenne\");             // pass rvalue\nNow consider the cost, in terms of copy and move operations, of adding a name to a\nWidget for the two calling scenarios and each of the three addName implementations\nwe’ve discussed. The accounting will largely ignore the possibility of compilers opti‐\nmizing copy and move operations away, because such optimizations are context- and\ncompiler-dependent and, in practice, don’t change the essence of the analysis.\n• Overloading: Regardless of whether an lvalue or an rvalue is passed, the caller’s\nargument is bound to a reference called newName. That costs nothing, in terms of\ncopy and move operations. In the lvalue overload, newName is copied into\nWidget::names. In the rvalue overload, it’s moved. Cost summary: one copy for\nlvalues, one move for rvalues.\n• Using a universal reference: As with overloading, the caller’s argument is bound\nto the reference newName. This is a no-cost operation. Due to the use of\nstd::forward, lvalue std::string arguments are copied into Widget::names,\nwhile rvalue std::string arguments are moved. The cost summary for\nstd::string arguments is the same as with overloading: one copy for lvalues,\none move for rvalues.\nItem 25 explains that if a caller passes an argument of a type other than\nstd::string, it will be forwarded to a std::string constructor, and that could\ncause as few as zero std::string copy or move operations to be performed.\nFunctions taking universal references can thus be uniquely efficient. However,\nthat doesn’t affect the analysis in this Item, so we’ll keep things simple by assum‐\ning that callers always pass std::string arguments.\n• Passing by value: Regardless of whether an lvalue or an rvalue is passed, the\nparameter newName must be constructed. If an lvalue is passed, this costs a copy\nconstruction. If an rvalue is passed, it costs a move construction. In the body of\nthe function, newName is unconditionally moved into Widget::names. The cost\nsummary is thus one copy plus one move for lvalues, and two moves for rvalues.\nCompared to the by-reference approaches, that’s one extra move for both lvalues\nand rvalues.\nItem 41 \n| \n285\nwww.it-ebooks.info\n\n\n2 Sentences like this are why it’d be nice to have terminology that distinguishes copies made via copy opera‐\ntions from copies made via move operations.\nLook again at this Item’s title:\nConsider pass by value for copyable parameters that are cheap to move\nand always copied.\nIt’s worded the way it is for a reason. Four reasons, in fact:\n1. You should only consider using pass by value. Yes, it requires writing only one\nfunction. Yes, it generates only one function in the object code. Yes, it avoids the\nissues associated with universal references. But it has a higher cost than the alter‐\nnatives, and, as we’ll see below, in some cases, there are expenses we haven’t yet\ndiscussed.\n2. Consider pass by value only for copyable parameters. Parameters failing this test\nmust have move-only types, because if they’re not copyable, yet the function\nalways makes a copy, the copy must be created via the move constructor.2 Recall\nthat the advantage of pass by value over overloading is that with pass by value,\nonly one function has to be written. But for move-only types, there is no need to\nprovide an overload for lvalue arguments, because copying an lvalue entails call‐\ning the copy constructor, and the copy constructor for move-only types is dis‐\nabled. That means that only rvalue arguments need to be supported, and in that\ncase, the “overloading” solution requires only one overload: the one taking an\nrvalue reference.\nConsider a class with a std::unique_ptr<std::string> data member and a\nsetter for it. std::unique_ptr is a move-only type, so the “overloading”\napproach to its setter consists of a single function:\nclass Widget {\npublic:\n  …\n  void setPtr(std::unique_ptr<std::string>&& ptr)\n  { p = std::move(ptr); }\nprivate:\n  std::unique_ptr<std::string> p;\n};\nA caller might use it this way:\n286 \n| \nItem 41\nwww.it-ebooks.info\n\n\nWidget w;\n…\nw.setPtr(std::make_unique<std::string>(\"Modern C++\"));\nHere \nthe \nrvalue \nstd::unique_ptr<std::string> \nreturned \nfrom\nstd::make_unique (see Item 21) is passed by rvalue reference to setPtr, where\nit’s moved into the data member p. The total cost is one move.\nIf setPtr were to take its parameter by value,\nclass Widget {\npublic:\n  …\n  void setPtr(std::unique_ptr<std::string> ptr)\n  { p = std::move(ptr); }\n  …\n};\nthe same call would move construct the parameter ptr, and ptr would then be\nmove assigned into the data member p. The total cost would thus be two moves\n—twice that of the “overloading” approach.\n3. Pass by value is worth considering only for parameters that are cheap to move.\nWhen moves are cheap, the cost of an extra one may be acceptable, but when\nthey’re not, performing an unnecessary move is analogous to performing an\nunnecessary copy, and the importance of avoiding unnecessary copy operations\nis what led to the C++98 rule about avoiding pass by value in the first place!\n4. You should consider pass by value only for parameters that are always copied. To\nsee why this is important, suppose that before copying its parameter into the\nnames container, addName checks to see if the new name is too short or too long.\nIf it is, the request to add the name is ignored. A pass-by-value implementation\ncould be written like this:\nclass Widget {\npublic:\n  void addName(std::string newName)\n  {\n    if ((newName.length() >= minLen) &&\n        (newName.length() <= maxLen))\n      {\n        names.push_back(std::move(newName));\n      }\n  }\nItem 41 \n| \n287\nwww.it-ebooks.info\n\n\n  …\nprivate:\n  std::vector<std::string> names;\n};\nThis function incurs the cost of constructing and destroying newName, even if\nnothing is added to names. That’s a price the by-reference approaches wouldn’t\nbe asked to pay.\nEven when you’re dealing with a function performing an unconditional copy on a\ncopyable type that’s cheap to move, there are times when pass by value may not be\nappropriate. That’s because a function can copy a parameter in two ways: via con‐\nstruction (i.e., copy construction or move construction) and via assignment (i.e., copy\nassignment or move assignment). addName uses construction: its parameter newName\nis passed to vector::push_back, and inside that function, newName is copy con‐\nstructed into a new element created at the end of the std::vector. For functions\nthat use construction to copy their parameter, the analysis we saw earlier is complete:\nusing pass by value incurs the cost of an extra move for both lvalue and rvalue argu‐\nments.\nWhen a parameter is copied using assignment, the situation is more complicated.\nSuppose, for example, we have a class representing passwords. Because passwords\ncan be changed, we provide a setter function, changeTo. Using a pass-by-value strat‐\negy, we could implement Password like this:\nclass Password {\npublic:\n  explicit Password(std::string pwd)     // pass by value\n  : text(std::move(pwd)) {}              // construct text\n  void changeTo(std::string newPwd)      // pass by value\n  { text = std::move(newPwd); }          // assign text\n  …\nprivate:\n  std::string text;                      // text of password\n};\nStoring the password as plain text will whip your software security SWAT team into a\nfrenzy, but ignore that and consider this code:\n288 \n| \nItem 41\nwww.it-ebooks.info\n\n\nstd::string initPwd(\"Supercalifragilisticexpialidocious\");\nPassword p(initPwd);\nThere are no suprises here: p.text is constructed with the given password, and using\npass by value in the constructor incurs the cost of a std::string move construction\nthat would not be necessary if overloading or perfect forwarding were employed. All\nis well.\nA user of this program may not be as sanguine about the password, however, because\n“Supercalifragilisticexpialidocious” is found in many dictionaries. He or she may\ntherefore take actions that lead to code equivalent to the following being executed:\nstd::string newPassword = \"Beware the Jabberwock\";\np.changeTo(newPassword);\nWhether the new password is better than the old one is debatable, but that’s the user’s\nproblem. Ours is that changeTo’s use of assignment to copy the parameter newPwd\nprobably causes that function’s pass-by-value strategy to explode in cost.\nThe argument passed to changeTo is an lvalue (newPassword), so when the parame‐\nter newPwd is constructed, it’s the std::string copy constructor that’s called. That\nconstructor allocates memory to hold the new password. newPwd is then move-\nassigned to text, which causes the memory already held by text to be deallocated.\nThere are thus two dynamic memory management actions within changeTo: one to\nallocate memory for the new password, and one to deallocate the memory for the old\npassword.\nBut in this case, the old password (“Supercalifragilisticexpialidocious”) is longer than\nthe new one (“Beware the Jabberwock”), so there’s no need to allocate or deallocate\nanything. If the overloading approach were used, it’s likely that none would take \nplace:\nclass Password {\npublic:\n  …\n  void changeTo(const std::string& newPwd)      // the overload\n  {                                             // for lvalues\n    text = newPwd;           // can reuse text's memory if\n                             // text.capacity() >= newPwd.size()\n  }\n  …\nItem 41 \n| \n289\nwww.it-ebooks.info\n",
      "page_number": 298,
      "chapter_number": 28,
      "summary": "Describing when it\nmakes sense to use a general technique or feature is usually fairly straightforward, but\nthis chapter covers two exceptions Key topics include function, functions. Covers function.",
      "keywords": [
        "std",
        "move",
        "string",
        "newName",
        "Item",
        "copy",
        "Widget",
        "class Widget",
        "addName",
        "function",
        "rvalue",
        "lvalue",
        "functions",
        "Password",
        "parameter"
      ],
      "concepts": [
        "std",
        "function",
        "functions",
        "passed",
        "passes",
        "copy",
        "copied",
        "copies",
        "passwords",
        "item"
      ],
      "similar_chapters": [
        {
          "book": "More Effective C++",
          "chapter": 9,
          "title": "Segment 9 (pages 76-97)",
          "relevance_score": 0.57,
          "method": "sentence_transformers"
        },
        {
          "book": "Python Essential Reference 4th",
          "chapter": 7,
          "title": "Program Structure and Control Flow",
          "relevance_score": 0.51,
          "method": "sentence_transformers"
        },
        {
          "book": "A Philosophy of Software Design",
          "chapter": 11,
          "title": "Segment 11 (pages 88-95)",
          "relevance_score": 0.49,
          "method": "sentence_transformers"
        },
        {
          "book": "C++ Concurrency in Action",
          "chapter": 39,
          "title": "Segment 39 (pages 382-396)",
          "relevance_score": 0.49,
          "method": "sentence_transformers"
        },
        {
          "book": "C++ Templates_ The Complete Guide",
          "chapter": 41,
          "title": "Segment 41 (pages 1309-1342)",
          "relevance_score": 0.49,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 29,
      "title": "Segment 29 (pages 308-316)",
      "start_page": 308,
      "end_page": 316,
      "detection_method": "topic_boundary",
      "content": "private:\n  std::string text;                             // as above\n};\nIn this scenario, the cost of pass by value includes an extra memory allocation and\ndeallocation—costs that are likely to exceed that of a std::string move operation\nby orders of magnitude.\nInterestingly, if the old password were shorter than the new one, it would typically be\nimpossible to avoid an allocation-deallocation pair during the assignment, and in\nthat case, pass by value would run at about the same speed as pass by reference. The\ncost of assignment-based parameter copying can thus depend on the values of the\nobjects participating in the assignment! This kind of analysis applies to any parame‐\nter type that holds values in dynamically allocated memory. Not all types qualify, but\nmany—including std::string and std::vector—do.\nThis potential cost increase generally applies only when lvalue arguments are passed,\nbecause the need to perform memory allocation and deallocation typically occurs\nonly when true copy operations (i.e., not moves) are performed. For rvalue argu‐\nments, moves almost always suffice.\nThe upshot is that the extra cost of pass by value for functions that copy a parameter\nusing assignment depends on the type being passed, the ratio of lvalue to rvalue argu‐\nments, whether the type uses dynamically allocated memory, and, if so, the imple‐\nmentation of that type’s assignment operators and the likelihood that the memory\nassociated with the assignment target is at least as large as the memory associated\nwith the assignment source. For std::string, it also depends on whether the imple‐\nmentation uses the small string optimization (SSO—see Item 29) and, if so, whether\nthe values being assigned fit in the SSO buffer.\nSo, as I said, when parameters are copied via assignment, analyzing the cost of pass\nby value is complicated. Usually, the most practical approach is to adopt a “guilty\nuntil proven innocent” policy, whereby you use overloading or universal references\ninstead of pass by value unless it’s been demonstrated that pass by value yields\nacceptably efficient code for the parameter type you need.\nNow, for software that must be as fast as possible, pass by value may not be a viable\nstrategy, because avoiding even cheap moves can be important. Moreover, it’s not\nalways clear how many moves will take place. In the Widget::addName example, pass\nby value incurs only a single extra move operation, but suppose that Widget::add\nName called Widget::validateName, and this function also passed by value. (Pre‐\nsumably it has a reason for always copying its parameter, e.g., to store it in a data\nstructure of all values it validates.) And suppose that validateName called a third\nfunction that also passed by value…\n290 \n| \nItem 41\nwww.it-ebooks.info\n\n\nYou can see where this is headed. When there are chains of function calls, each of\nwhich employs pass by value because “it costs only one inexpensive move,” the cost\nfor the entire chain of calls may not be something you can tolerate. Using by-\nreference parameter passing, chains of calls don’t incur this kind of accumulated\noverhead.\nAn issue unrelated to performance, but still worth keeping in mind, is that pass by\nvalue, unlike pass by reference, is susceptible to the slicing problem. This is well-trod\nC++98 ground, so I won’t dwell on it, but if you have a function that is designed to\naccept a parameter of a base class type or any type derived from it, you don’t want to\ndeclare a pass-by-value parameter of that type, because you’ll “slice off” the derived-\nclass characteristics of any derived type object that may be passed in:\nclass Widget { … };                          // base class\nclass SpecialWidget: public Widget { … };    // derived class\nvoid processWidget(Widget w);   // func for any kind of Widget,\n                                // including derived types;\n…                               // suffers from slicing problem\nSpecialWidget sw;\n…\nprocessWidget(sw);              // processWidget sees a\n                                // Widget, not a SpecialWidget!\nIf you’re not familiar with the slicing problem, search engines and the Internet are\nyour friends; there’s lots of information available. You’ll find that the existence of the\nslicing problem is another reason (on top of the efficiency hit) why pass by value has\na shady reputation in C++98. There are good reasons why one of the first things you\nprobably learned about C++ programming was to avoid passing objects of user-\ndefined types by value.\nC++11 doesn’t fundamentally change the C++98 wisdom regarding pass by value. In\ngeneral, pass by value still entails a performance hit you’d prefer to avoid, and pass by\nvalue can still lead to the slicing problem. What’s new in C++11 is the distinction\nbetween lvalue and rvalue arguments. Implementing functions that take advantage of\nmove semantics for rvalues of copyable types requires either overloading or using\nuniversal references, both of which have drawbacks. For the special case of copyable,\ncheap-to-move types passed to functions that always copy them and where slicing is\nnot a concern, pass by value can offer an easy-to-implement alternative that’s nearly\nas efficient as its pass-by-reference competitors, but avoids their disadvantages.\nItem 41 \n| \n291\nwww.it-ebooks.info\n\n\nThings to Remember\n• For copyable, cheap-to-move parameters that are always copied, pass by value\nmay be nearly as efficient as pass by reference, it’s easier to implement, and it\ncan generate less object code.\n• Copying parameters via construction may be significantly more expensive\nthan copying them via assignment.\n• Pass by value is subject to the slicing problem, so it’s typically inappropriate\nfor base class parameter types.\nItem 42: Consider emplacement instead of insertion.\nIf you have a container holding, say, std::strings, it seems logical that when you\nadd a new element via an insertion function (i.e., insert, push_front, push_back,\nor, for std::forward_list, insert_after), the type of element you’ll pass to the\nfunction will be std::string. After all, that’s what the container has in it.\nLogical though this may be, it’s not always true. Consider this code:\nstd::vector<std::string> vs;         // container of std::string\nvs.push_back(\"xyzzy\");               // add string literal\nHere, the container holds std::strings, but what you have in hand—what you’re\nactually trying to push_back—is a string literal, i.e., a sequence of characters inside\nquotes. A string literal is not a std::string, and that means that the argument\nyou’re passing to push_back is not of the type held by the container.\npush_back for std::vector is overloaded for lvalues and rvalues as follows:\ntemplate <class T,                           // from the C++11\n          class Allocator = allocator<T>>    // Standard\nclass vector {\npublic:\n  …\n  void push_back(const T& x);                // insert lvalue\n  void push_back(T&& x);                     // insert rvalue\n  …\n};\nIn the call\nvs.push_back(\"xyzzy\");\n292 \n| \nItem 41\nwww.it-ebooks.info\n\n\ncompilers see a mismatch between the type of the argument (const char[6]) and the\ntype of the parameter taken by push_back (a reference to a std::string). They\naddress the mismatch by generating code to create a temporary std::string object\nfrom the string literal, and they pass that temporary object to push_back. In other\nwords, they treat the call as if it had been written like this:\nvs.push_back(std::string(\"xyzzy\"));  // create temp. std::string\n                                     // and pass it to push_back\nThe code compiles and runs, and everybody goes home happy. Everybody except the\nperformance freaks, that is, because the performance freaks recognize that this code\nisn’t as efficient as it should be.\nTo create a new element in a container of std::strings, they understand, a\nstd::string constructor is going to have to be called, but the code above doesn’t\nmake just one constructor call. It makes two. And it calls the std::string destruc‐\ntor, too. Here’s what happens at runtime in the call to push_back:\n1. A temporary std::string object is created from the string literal \"xyzzy\". This\nobject has no name; we’ll call it temp. Construction of temp is the first\nstd::string construction. Because it’s a temporary object, temp is an rvalue.\n2. temp is passed to the rvalue overload for push_back, where it’s bound to the\nrvalue reference parameter x. A copy of x is then constructed in the memory for\nthe std::vector. This construction—the second one—is what actually creates a\nnew object inside the std::vector. (The constructor that’s used to copy x into\nthe std::vector is the move constructor, because x, being an rvalue reference,\ngets cast to an rvalue before it’s copied. For information about the casting of\nrvalue reference parameters to rvalues, see Item 25.)\n3. Immediately after push_back returns, temp is destroyed, thus calling the\nstd::string destructor.\nThe performance freaks can’t help but notice that if there were a way to take the\nstring literal and pass it directly to the code in step 2 that constructs the std::string\nobject inside the std::vector, we could avoid constructing and destroying temp.\nThat would be maximally efficient, and even the performance freaks could content‐\nedly decamp.\nBecause you’re a C++ programmer, there’s an above-average chance you’re a perfor‐\nmance freak. If you’re not, you’re still probably sympathetic to their point of view. (If\nyou’re not at all interested in performance, shouldn’t you be in the Python room\ndown the hall?) So I’m pleased to tell you that there is a way to do exactly what is\nItem 42 \n| \n293\nwww.it-ebooks.info\n\n\nneeded for maximal efficiency in the call to push_back. It’s to not call push_back.\npush_back is the wrong function. The function you want is emplace_back.\nemplace_back does exactly what we desire: it uses whatever arguments are passed to\nit to construct a std::string directly inside the std::vector. No temporaries are\ninvolved:\nvs.emplace_back(\"xyzzy\");   // construct std::string inside\n                            // vs directly from \"xyzzy\"\nemplace_back uses perfect forwarding, so, as long as you don’t bump into one of\nperfect forwarding’s limitations (see Item 30), you can pass any number of arguments\nof any combination of types through emplace_back. For example, if you’d like to\ncreate a std::string in vs via the std::string constructor taking a character and\na repeat count, this would do it:\nvs.emplace_back(50, 'x');   // insert std::string consisting\n                            // of 50 'x' characters\nemplace_back is available for every standard container that supports push_back.\nSimilarly, \nevery \nstandard \ncontainer \nthat \nsupports \npush_front \nsupports\nemplace_front. And every standard container that supports insert (which is all\nbut std::forward_list and std::array) supports emplace. The associative con‐\ntainers offer emplace_hint to complement their insert functions that take a “hint”\niterator, and std::forward_list has emplace_after to match its insert_after.\nWhat makes it possible for emplacement functions to outperform insertion functions\nis their more flexible interface. Insertion functions take objects to be inserted, while\nemplacement functions take constructor arguments for objects to be inserted. This dif‐\nference permits emplacement functions to avoid the creation and destruction of tem‐\nporary objects that insertion functions can necessitate.\nBecause an argument of the type held by the container can be passed to an emplace‐\nment function (the argument thus causes the function to perform copy or move con‐\nstruction), emplacement can be used even when an insertion function would require\nno temporary. In that case, insertion and emplacement do essentially the same thing.\nFor example, given\nstd::string queenOfDisco(\"Donna Summer\");\nboth of the following calls are valid, and both have the same net effect on the con‐\ntainer:\nvs.push_back(queenOfDisco);       // copy-construct queenOfDisco\n                                  // at end of vs\nvs.emplace_back(queenOfDisco);    // ditto\n294 \n| \nItem 42\nwww.it-ebooks.info\n\n\nEmplacement functions can thus do everything insertion functions can. They some‐\ntimes do it more efficiently, and, at least in theory, they should never do it less effi‐\nciently. So why not use them all the time?\nBecause, as the saying goes, in theory, there’s no difference between theory and prac‐\ntice, but in practice, there is. With current implementations of the Standard Library,\nthere are situations where, as expected, emplacement outperforms insertion, but,\nsadly, there are also situations where the insertion functions run faster. Such situa‐\ntions are not easy to characterize, because they depend on the types of arguments\nbeing passed, the containers being used, the locations in the containers where inser‐\ntion or emplacement is requested, the exception safety of the contained types’ con‐\nstructors, and, for containers where duplicate values are prohibited (i.e., std::set,\nstd::map, std::unordered_set, std::unordered_map), whether the value to be\nadded is already in the container. The usual performance-tuning advice thus applies:\nto determine whether emplacement or insertion runs faster, benchmark them both.\nThat’s not very satisfying, of course, so you’ll be pleased to learn that there’s a heuris‐\ntic that can help you identify situations where emplacement functions are most likely\nto be worthwhile. If all the following are true, emplacement will almost certainly out‐\nperform insertion:\n• The value being added is constructed into the container, not assigned.  The\nexample that opened this Item (adding a std::string with the value \"xyzzy\" to\na std::vector vs) showed the value being added to the end of vs—to a place\nwhere no object yet existed. The new value therefore had to be constructed into\nthe std::vector. If we revise the example such that the new std::string goes\ninto a location already occupied by an object, it’s a different story. Consider:\nstd::vector<std::string> vs;         // as before\n…                                    // add elements to vs\nvs.emplace(vs.begin(), \"xyzzy\");     // add \"xyzzy\" to\n                                     // beginning of vs\nFor this code, few implementations will construct the added std::string into\nthe memory occupied by vs[0]. Instead, they’ll move-assign the value into place.\nBut move assignment requires an object to move from, and that means that a\ntemporary object will need to be created to be the source of the move. Because\nthe primary advantage of emplacement over insertion is that temporary objects\nare neither created nor destroyed, when the value being added is put into the\ncontainer via assignment, emplacement’s edge tends to disappear.\nAlas, whether adding a value to a container is accomplished by construction or\nassignment is generally up to the implementer. But, again, heuristics can help.\nItem 42 \n| \n295\nwww.it-ebooks.info\n\n\nNode-based containers virtually always use construction to add new values, and\nmost standard containers are node-based. The only ones that aren’t are\nstd::vector, std::deque, and std::string. (std::array isn’t, either, but it\ndoesn’t support insertion or emplacement, so it’s not relevant here.) Within the\nnon-node-based containers, you can rely on emplace_back to use construction\ninstead of assignment to get a new value into place, and for std::deque, the\nsame is true of emplace_front.\n• The argument type(s) being passed differ from the type held by the container.\nAgain, emplacement’s advantage over insertion generally stems from the fact that\nits interface doesn’t require creation and destruction of a temporary object when\nthe argument(s) passed are of a type other than that held by the container. When\nan object of type T is to be added to a container<T>, there’s no reason to expect\nemplacement to run faster than insertion, because no temporary needs to be cre‐\nated to satisfy the insertion interface.\n• The container is unlikely to reject the new value as a duplicate. This means\nthat the container either permits duplicates or that most of the values you add\nwill be unique. The reason this matters is that in order to detect whether a value\nis already in the container, emplacement implementations typically create a node\nwith the new value so that they can compare the value of this node with existing\ncontainer nodes. If the value to be added isn’t in the container, the node is linked\nin. However, if the value is already present, the emplacement is aborted and the\nnode is destroyed, meaning that the cost of its construction and destruction was\nwasted. Such nodes are created for emplacement functions more often than for\ninsertion functions.\nThe following calls from earlier in this Item satisfy all the criteria above. They also\nrun faster than the corresponding calls to push_back.\nvs.emplace_back(\"xyzzy\");   // construct new value at end of\n                            // container; don't pass the type in\n                            // container; don't use container\n                            // rejecting duplicates\nvs.emplace_back(50, 'x');   // ditto\nWhen deciding whether to use emplacement functions, two other issues are worth\nkeeping in mind. The first regards resource management. Suppose you have a con‐\ntainer of std::shared_ptr<Widget>s,\nstd::list<std::shared_ptr<Widget>> ptrs;\nand you want to add a std::shared_ptr that should be released via a custom deleter\n(see Item 19). Item 21 explains that you should use std::make_shared to create\n296 \n| \nItem 42\nwww.it-ebooks.info\n\n\nstd::shared_ptrs whenever you can, but it also concedes that there are situations\nwhere you can’t. One such situation is when you want to specify a custom deleter. In\nthat case, you must use new directly to get the raw pointer to be managed by the\nstd::shared_ptr.\nIf the custom deleter is this function,\nvoid killWidget(Widget* pWidget);\nthe code using an insertion function could look like this:\nptrs.push_back(std::shared_ptr<Widget>(new Widget, killWidget));\nIt could also look like this, though the meaning would be the same:\nptrs.push_back({ new Widget, killWidget });\nEither way, a temporary std::shared_ptr would be constructed before calling\npush_back. push_back’s parameter is a reference to a std::shared_ptr, so there\nhas to be a std::shared_ptr for this parameter to refer to.\nThe creation of the temporary std::shared_ptr is what emplace_back would\navoid, but in this case, that temporary is worth far more than it costs. Consider the\nfollowing potential sequence of events:\n1. In either call above, a temporary std::shared_ptr<Widget> object is construc‐\nted to hold the raw pointer resulting from “new Widget”. Call this object temp.\n2. push_back takes temp by reference. During allocation of a list node to hold a\ncopy of temp, an out-of-memory exception gets thrown.\n3. As the exception propagates out of push_back, temp is destroyed. Being the sole\nstd::shared_ptr referring to the Widget it’s managing, it automatically relea‐\nses that Widget, in this case by calling killWidget.\nEven though an exception occurred, nothing leaks: the Widget created via “new\nWidget” in the call to push_back is released in the destructor of the\nstd::shared_ptr that was created to manage it (temp). Life is good.\nNow consider what happens if emplace_back is called instead of push_back:\nptrs.emplace_back(new Widget, killWidget);\n1. The raw pointer resulting from “new Widget” is perfect-forwarded to the point\ninside emplace_back where a list node is to be allocated. That allocation fails,\nand an out-of-memory exception is thrown.\nItem 42 \n| \n297\nwww.it-ebooks.info\n\n\n2. As the exception propagates out of emplace_back, the raw pointer that was the\nonly way to get at the Widget on the heap is lost. That Widget (and any resources\nit owns) is leaked.\nIn this scenario, life is not good, and the fault doesn’t lie with std::shared_ptr. The\nsame kind of problem can arise through the use of std::unique_ptr with a custom\ndeleter. Fundamentally, the effectiveness of resource-managing classes like\nstd::shared_ptr and std::unique_ptr is predicated on resources (such as raw\npointers from new) being immediately passed to constructors for resource-managing\nobjects. The fact that functions like std::make_shared and std::make_unique\nautomate this is one of the reasons they’re so important.\nIn calls to the insertion functions of containers holding resource-managing objects\n(e.g., std::list<std::shared_ptr<Widget>>), the functions’ parameter types gen‐\nerally ensure that nothing gets between acquisition of a resource (e.g., use of new) and\nconstruction of the object managing the resource. In the emplacement functions,\nperfect-forwarding defers the creation of the resource-managing objects until they\ncan be constructed in the container’s memory, and that opens a window during\nwhich exceptions can lead to resource leaks. All standard containers are susceptible\nto this problem. When working with containers of resource-managing objects, you\nmust take care to ensure that if you choose an emplacement function over its inser‐\ntion counterpart, you’re not paying for improved code efficiency with diminished\nexception safety.\nFrankly, you shouldn’t be passing expressions like “new Widget” to emplace_back or\npush_back or most any other function, anyway, because, as Item 21 explains, this\nleads to the possibility of exception safety problems of the kind we just examined.\nClosing the door requires taking the pointer from “new Widget” and turning it over\nto a resource-managing object in a standalone statement, then passing that object as\nan rvalue to the function you originally wanted to pass “new Widget” to. (Item 21\ncovers this technique in more detail.) The code using push_back should therefore be\nwritten more like this:\nstd::shared_ptr<Widget> spw(new Widget,    // create Widget and\n                            killWidget);   // have spw manage it\nptrs.push_back(std::move(spw));            // add spw as rvalue\nThe emplace_back version is similar:\nstd::shared_ptr<Widget> spw(new Widget, killWidget);\nptrs.emplace_back(std::move(spw));\nEither way, the approach incurs the cost of creating and destroying spw. Given that\nthe motivation for choosing emplacement over insertion is to avoid the cost of a tem‐\n298 \n| \nItem 42\nwww.it-ebooks.info\n",
      "page_number": 308,
      "chapter_number": 29,
      "summary": "This chapter covers segment 29 (pages 308-316). Key topics include emplacement, emplace. The\ncost of assignment-based parameter copying can thus depend on the values of the\nobjects participating in the assignment.",
      "keywords": [
        "std",
        "Widget",
        "back",
        "string",
        "Item",
        "push",
        "container",
        "emplacement",
        "functions",
        "object",
        "type",
        "emplacement functions",
        "temporary std",
        "insertion",
        "function"
      ],
      "concepts": [
        "std",
        "emplacement",
        "emplace",
        "passed",
        "string",
        "type",
        "item",
        "widget",
        "classes",
        "insertion"
      ],
      "similar_chapters": [
        {
          "book": "C++ Templates_ The Complete Guide",
          "chapter": 41,
          "title": "Segment 41 (pages 1309-1342)",
          "relevance_score": 0.63,
          "method": "sentence_transformers"
        },
        {
          "book": "More Effective C++",
          "chapter": 4,
          "title": "Segment 4 (pages 25-32)",
          "relevance_score": 0.52,
          "method": "sentence_transformers"
        },
        {
          "book": "More Effective C++",
          "chapter": 22,
          "title": "Segment 22 (pages 216-223)",
          "relevance_score": 0.52,
          "method": "sentence_transformers"
        },
        {
          "book": "More Effective C++",
          "chapter": 23,
          "title": "Segment 23 (pages 224-233)",
          "relevance_score": 0.52,
          "method": "sentence_transformers"
        },
        {
          "book": "C++ Templates_ The Complete Guide",
          "chapter": 42,
          "title": "Segment 42 (pages 1343-1372)",
          "relevance_score": 0.51,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 30,
      "title": "Segment 30 (pages 317-324)",
      "start_page": 317,
      "end_page": 324,
      "detection_method": "topic_boundary",
      "content": "porary object of the type held by the container, yet that’s conceptually what spw is,\nemplacement functions are unlikely to outperform insertion functions when you’re\nadding resource-managing objects to a container and you follow the proper practice\nof ensuring that nothing can intervene between acquiring a resource and turning it\nover to a resource-managing object.\n A second noteworthy aspect of emplacement functions is their interaction with\nexplicit constructors. In honor of C++11’s support for regular expressions, sup‐\npose you create a container of regular expression objects:\nstd::vector<std::regex> regexes;\nDistracted by your colleagues’ quarreling over the ideal number of times per day to\ncheck one’s Facebook account, you accidentally write the following seemingly mean‐\ningless code:\nregexes.emplace_back(nullptr);    // add nullptr to container\n                                  // of regexes?\nYou don’t notice the error as you type it, and your compilers accept the code without\ncomplaint, so you end up wasting a bunch of time debugging. At some point, you\ndiscover that you have inserted a null pointer into your container of regular expres‐\nsions. But how is that possible? Pointers aren’t regular expressions, and if you tried to\ndo something like this,\nstd::regex r = nullptr;           // error! won't compile\ncompilers would reject your code. Interestingly, they would also reject it if you called\npush_back instead of emplace_back:\nregexes.push_back(nullptr);       // error! won't compile\nThe curious behavior you’re experiencing stems from the fact that std::regex\nobjects can be constructed from character strings. That’s what makes useful code like\nthis legal:\nstd::regex upperCaseWord(\"[A-Z]+\");\nCreation of a std::regex from a character string can exact a comparatively large\nruntime cost, so, to minimize the likelihood that such an expense will be incurred\nunintentionally, the std::regex constructor taking a const char* pointer is\nexplicit. That’s why these lines don’t compile:\nstd::regex r = nullptr;           // error! won't compile\nregexes.push_back(nullptr);       // error! won't compile\nIn both cases, we’re requesting an implicit conversion from a pointer to a\nstd::regex, and the explicitness of that constructor prevents such conversions.\nItem 42 \n| \n299\nwww.it-ebooks.info\n\n\nIn the call to emplace_back, however, we’re not claiming to pass a std::regex\nobject. Instead, we’re passing a constructor argument for a std::regex object. That’s\nnot considered an implicit conversion request. Rather, it’s viewed as if you’d written\nthis code:\nstd::regex r(nullptr);           // compiles\nIf the laconic comment “compiles” suggests a lack of enthusiasm, that’s good, because\nthis code, though it will compile, has undefined behavior. The std::regex construc‐\ntor taking a const char* pointer requires that the pointed-to string comprise a valid\nregular expression, and the null pointer fails that requirement. If you write and com‐\npile such code, the best you can hope for is that it crashes at runtime. If you’re not so\nlucky, you and your debugger could be in for a special bonding experience.\nSetting aside push_back, emplace_back, and bonding for a moment, notice how\nthese very similar initialization syntaxes yield different results:\nstd::regex r1 = nullptr;         // error! won't compile\nstd::regex r2(nullptr);          // compiles\nIn the official terminology of the Standard, the syntax used to initialize r1 (employ‐\ning the equals sign) corresponds to what is known as copy initialization. In contrast,\nthe syntax used to initialize r2 (with the parentheses, although braces may be used\ninstead) yields what is called direct initialization. Copy initialization is not permitted\nto use explicit constructors. Direct initialization is. That’s why the line initializing\nr1 doesn’t compile, but the line initializing r2 does.\nBut back to push_back and emplace_back and, more generally, the insertion func‐\ntions versus the emplacement functions. Emplacement functions use direct initializa‐\ntion, which means they may use explicit constructors. Insertion functions employ\ncopy initialization, so they can’t. Hence:\nregexes.emplace_back(nullptr);  // compiles. Direct init permits\n                                // use of explicit std::regex\n                                // ctor taking a pointer\nregexes.push_back(nullptr);     // error! copy init forbids\n                                // use of that ctor\nThe lesson to take away is that when you use an emplacement function, be especially\ncareful to make sure you’re passing the correct arguments, because even explicit\nconstructors will be considered by compilers as they try to find a way to interpret\nyour code as valid.\n300 \n| \nItem 42\nwww.it-ebooks.info\n\n\nThings to Remember\n• In principle, emplacement functions should sometimes be more efficient than\ntheir insertion counterparts, and they should never be less efficient.\n• In practice, they’re most likely to be faster when (1) the value being added is\nconstructed into the container, not assigned; (2) the argument type(s) passed\ndiffer from the type held by the container; and (3) the container won’t reject\nthe value being added due to it being a duplicate.\n• Emplacement functions may perform type conversions that would be rejected\nby insertion functions.\nItem 42 \n| \n301\nwww.it-ebooks.info\n\n\nwww.it-ebooks.info\n\n\nIndex\nSymbols\n&&, meanings of, 164\n0 (zero)\noverloading and, 59\ntemplates and, 60\ntype of, 58\n= (equals sign), assignment vs. initialization, 50\n=default, 112, 152, 257\n=delete (see deleted functions)\nA\nAbrahams, David, xiv\n\"Adventure\", allusion to, 295\nAlexandrescu, Andrei, xiii\nalias declarations\nalias templates and, 63-65\ndefinition of, 63\nreference collapsing and, 202\nvs. typedefs, 63-65\nalias templates, 63\nallusions\nto \"Adventure\", 295\nto \"Citizen Kane\", 239\nto \"Jabberwocky\", 289\nto \"Mary Poppins\", 289\nto \"Star Trek\", 125\nto \"Star Wars\", 189\nto \"The Hitchhiker's Guide to the Galaxy\",\n30\nto Dave Barry, 33\nto John 8:32, 164\napostrophe, as digit separator, 252\narguments, bound and unbound, 238\narray\narguments, 15-17\ndecay, definition of, 15\nparameters, 16\nreference to, 16\nsize, deducing, 16\nauto, 37-48\nadvantages of, 38-41\nbraced initializers and, 21-23\ncode readability and, 42\nmaintenance and, 42\nproxy classes and, 43-46\nrefactoring and, 42\nreference collapsing and, 201\nreturn type deduction and braced initializ‐\ners and, 21-23\nstd::initializer_list and, 21\ntrailing return types and, 25\ntype deduction, 18-23\nuniversal references and, 167\nvs. std::function for function objects, 39\nB\nback pointers, 138\nBarry, Dave, allusion to, 33\nbasic guarantee, definition of, 4\nBecker, Thomas, xiv\nbig three, the, 111\nbitfield arguments, 214\nboolean flags and event communication, 264\nBoost.TypeIndex, 34-35\nbraced initialization, 50-55\nauto and, 21-23\ndefinition of, 50\nperfect forwarding and, 208-209\n303\nwww.it-ebooks.info\n\n\nreturn type deduction and, 23\nstd::initializer_lists and, 52-54\nBrowning, Elizabeth Barrett, 117\nby-reference captures, 217-219\nby-value capture\npointers and, 219\nproblems with, 219-223\nstd::move and, 283\nby-value parameters, std::move and, 283\nC\nC with Classes, 86\n\"C++ Concurrency in Action\" (book), 257\nC++03, definition of, 2\nC++11, definition of, 2\nC++14, definition of, 2\nC++98\ndefinition of, 2\nexception specifications, 90\nc++filt, 32\ncaching factory function, 136\ncallable objects, definition of, 5\ncaptures\nby-reference, 217\nby-value, 219\ndefault modes, 216-223\nthis pointer and, 220-222\ncasts\nconditional vs. unconditional, 161\nstd::move vs. std::forward, 158\ncbegin, 87\ncend, 87\nCheng, Rachel, xiv\n\"Citizen Kane\", allusion to, 239\nclass templates, definition of, 5\nclosures\nclosure class, definition of, 216\ncopies of, 216\ndefinition of, 5, 216\ncode examples (see example classes/templates;\nexample functions/templates)\ncode reordering\nstd::atomic and, 273\nvolatile and, 275\ncode smells, 263\ncompiler warnings, 81\nnoexcept and, 96\nvirtual function overriding and, 81\ncondition variables\nevent communication and, 262-266\nspurious wakeups and, 264\ntiming dependencies and, 264\ncondvar (see condition variables)\nconst\nconst member functions and thread safety,\n103-109\nconst propagation, definition of, 210\nconst T&&, 166\npointers and type deduction, 14\nvs. constexpr, 98\nconstexpr, 97-103\nconstexpr functions, 98-102\nrestrictions on, 99-102\nruntime arguments and, 99\nconstexpr objects, 97-98\ninterface design and, 102\nvs. const, 98\nconstructors\nconstructor calls, braces vs. parentheses,\n52-55\nexplicit, 299-300\nuniversal references and, 180-183, 188-194\nconst_iterators\nconverting to iterators, 87\nvs. iterators, 86-89\ncontextual keywords, definition of, 83\ncontracts, wide vs. narrow, 95\ncontrol blocks, 128-132\ndefinition of, 128\nsize of, 132\nstd::shared_ptr and, 129\ncopy elision, definition of, 174\ncopy of an object, definition of, 4\ncopy operations\nautomatic generation of, 112\ndefaulting, 113-114\ndefinition of, 3\nfor classes declaring copy operations or\ndtor, 112\nfor std::atomic, 277\nimplicit\nin classes declaring move operations,\n111\nPimpl Idiom and, 153-154\nrelationship to destructor and resource\nmanagement, 111\nvia construction vs. assignment, 288-290\n304 \n| \nIndex\nwww.it-ebooks.info\n\n\nCRTP (Curiously Recurring Template Pattern),\n131\nctor (see constructor)\nCuriously Recurring Template Pattern (CRTP),\n131\ncustom deleters, definition of, 120\nD\ndangling pointer, definition of, 134\ndangling references, 217\ndead stores, definition of, 276\nDealtry, William, xiv\ndeclarations, definition of, 5\ndecltype, 23-30\nauto&& parameters in lambdas and,\n229-232\ndecltype(auto) and, 26\nreference collapsing and, 203\nreturn expressions and, 29\ntreatment of names vs. treatment of expres‐\nsions, 28\ndeduced types, viewing, 30-35\ndeduction, type (see type deduction)\ndeep copy, definition of, 154\ndefault capture modes, 216-223\ndefault launch policy, 246-249\nthread-local storage and, 247\ndefaulted dtor, 152\ndefaulted member functions, 112\ndefaulted virtual destructors, 112\ndefinition of terms\nalias template, 63\nalias templates, 63\narray decay, 15\nbasic guarantee, 4\nbraced initialization, 50\nC++03, 2\nC++11, 2\nC++14, 2\nC++98, 2\ncallable object, 5\nclass template, 5\nclosure, 5, 216\nclosure class, 216\ncode smell, 263\nconst propagation, 210\ncontextual keyword, 83\ncontrol block, 128\ncopy of an object, 4\ncopy operation, 3\nCRTP (Curiously Recurring Template Pat‐\ntern), 131\nctor, 6\ncustom deleter, 120\ndangling pointer, 134\ndead stores, 276\ndeclaration, 5\ndeep copy, 154\ndefinition, 5\ndeleted function, 75\ndependent type, 64\ndeprecated feature, 6\ndisabled templates, 189\ndtor, 6\nenabled templates, 189\nexception safe, 4\nexception-neutral, 93\nexclusive ownership, 119\nexpired std::weak_ptr, 135\nfunction argument, 4\nfunction objects, 5\nfunction parameter, 4\nfunction signature, 6\ngeneralized lambda capture, 225\ngeneric lambdas, 229\nhardware thread, 242\nincomplete type, 148\ninit capture, 224\nintegral constant expression, 97\ninterruptible thread, 256\njoinable std::thread, 250\nlambda, 5, 215\nlambda expression, 215\nlhs, 3\nliteral types, 100\nlvalue, 2\nmake function, 139\nmemory-mapped I/O, 276\nmost vexing parse, 51\nmove operation, 3\nmove semantic, 157\nmove-only type, 105, 119\nnamed return value optimization (NRVO),\n174\nnarrow contracts, 95-96\nnarrowing conversions, 51\nnon-dependent type, 64\nIndex \n| \n305\nwww.it-ebooks.info\n\n\nNRVO (named return value optimization),\n174\noverride, 79\noversubscription, 243\nparameter forwarding, 207\nperfect forwarding, 4, 157, 207\nPimpl Idiom, 147\nRAII classes, 253\nRAII object, 253\nRAII objects, 253\nraw pointer, 6\nredundant loads, 276\nreference collapsing, 198\nreference count, 125\nreference qualifier, 80\nrelaxed memory consistency, 274\nresource ownership, 117\nreturn value optimization (RVO), 174\nrhs, 3\nRule of Three, 111\nrvalue, 2\nRVO (return value optimization), 174\nscoped enums, 67\nsequential memory consistency, 274\nshallow copy, 154\nshared ownership, 125\nshared state, 259\nsmall string optimization (SSO), 205\nsmart pointers, 6\nsoftware threads, 242\nspecial member functions, 109\nspurious wakeups, 264\nstatic storage duration, 222\nstrong guarantee, 4\ntag dispatch, 188\ntask-based programming, 241\ntemplate class, 5\ntemplate function, 5\nthread local storage (TLS), 247\nthread-based programming, 241\ntrailing return type, 25\ntranslation, 97\nundefined behavior, 6\nuniform initialization, 50\nunjoinable std::thread, 250\nunscoped enum, 67\nunscoped enums, 67\nweak count, 144\nweak memory consistency, 274\nwide contracts, 95-96\nWidget, 3\ndefinitions of terms\nalias declarations, 63\ncopy elision, 174\ndefinitions, definition of, 5\ndeleted functions, 74-79\ndefinition of, 75\nvs. private and undefined ones, 74-79\ndeleters\ncustom, 142\nstd::unique_ptr vs. std::shared_ptr, 126, 155\ndeleting non-member functions, 76-77\ndeleting template instantiations, 77-78\ndependent type, definition of, 64\ndeprecated features\nautomatic copy operation generation, 112\nC++98-style exception specifications, 90\ndefinition of, 6\nstd::auto_ptr, 118\ndestructor\ndefaulted, 112, 152\nrelationship to copy operations and\nresource management, 111\ndigit separators, apostrophes as, 252\ndisabled templates, definition of, 189\ndtor (see destructor)\nDziubinski, Matt P., xiv\nE\nEinstein's theory of general relativity, 168\nellipses, narrow vs. wide, 3\nemplacement\nconstruction vs. assignment and, 295\nemplacement functions, 293-300\nexception safety and, 296-299\nexplicit constructors and, 299-300\nheuristic for use of, 295-296\nperfect forwarding and, 294\nvs. insertion, 292-301\nenabled templates, definition of, 189\nenums\ncompilation dependencies and, 70\nenum classes (see scoped enums)\nforward declaring, 69-71\nimplicit conversions and, 68\nscoped vs. unscoped, 67\nstd::get and, 71-73\nstd::tuples and, 71-73\n306 \n| \nIndex\nwww.it-ebooks.info\n",
      "page_number": 317,
      "chapter_number": 30,
      "summary": "This chapter covers segment 30 (pages 317-324). Key topics include function, definition. Covers function. A second noteworthy aspect of emplacement functions is their interaction with\nexplicit constructors.",
      "keywords": [
        "std",
        "definition",
        "functions",
        "regex",
        "type",
        "copy",
        "emplacement functions",
        "function",
        "templates",
        "back",
        "code",
        "Curiously Recurring Template",
        "container",
        "nullptr",
        "adding resource-managing objects"
      ],
      "concepts": [
        "function",
        "std",
        "definition",
        "definitions",
        "type",
        "pointer",
        "templates",
        "object",
        "thread",
        "xiv"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 2",
          "chapter": 2,
          "title": "Segment 2 (pages 9-16)",
          "relevance_score": 0.78,
          "method": "sentence_transformers"
        },
        {
          "book": "More Effective C++",
          "chapter": 29,
          "title": "Segment 29 (pages 293-301)",
          "relevance_score": 0.76,
          "method": "sentence_transformers"
        },
        {
          "book": "C++ Templates_ The Complete Guide",
          "chapter": 30,
          "title": "Segment 30 (pages 950-980)",
          "relevance_score": 0.74,
          "method": "sentence_transformers"
        },
        {
          "book": "C++ Templates_ The Complete Guide",
          "chapter": 1,
          "title": "Segment 1 (pages 1-35)",
          "relevance_score": 0.73,
          "method": "sentence_transformers"
        },
        {
          "book": "C++ Templates_ The Complete Guide",
          "chapter": 26,
          "title": "Segment 26 (pages 815-849)",
          "relevance_score": 0.73,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 31,
      "title": "Segment 31 (pages 325-333)",
      "start_page": 325,
      "end_page": 333,
      "detection_method": "topic_boundary",
      "content": "underlying type for, 69-71\nequals sign (=), assignment vs. initialization, 50\nerrata list for this book, 7\nerror messages, universal reference and, 195\nevent communication\nboolean flags, 264\ncondition variables and, 262\ncost and efficiency of polling, 265\nfuture as mechanism for, 266-270\nexample classes/templates\n(see also std::)\nBase, 79-82, 112\nBond, 119\nDerived, 79, 81-82\nInvestment, 119, 122\nIPv4Header, 213\nIsValAndArch, 226\nMyAllocList, 64\nMyAllocList<Wine>, 65\nPassword, 288-290\nPerson, 180-182, 184, 189, 191, 193, 196\nPoint, 24, 100, 101, 106\nPolynomial, 103-105\nPolyWidget, 239\nRealEstate, 119\nReallyBigType, 145\nSomeCompilerGeneratedClassName, 229\nSpecialPerson, 183, 192\nSpecialWidget, 291\nstd::add_lvalue_reference, 66\nstd::basic_ios, 75\nstd::get, 257\nstd::pair, 93\nstd::remove_const, 66\nstd::remove_reference, 66\nstd::string, 160\nstd::vector, 24, 166, 292\nstd::vector<bool>, 46\nStock, 119\nStringTable, 113\nstruct Point, 24\nTD, 31\nThreadRAII, 254, 257\nWarning, 83\nWidget, 3, 5, 50, 52, 64, 78, 80, 83, 106-108,\n109, 112, 115, 130-132, 148-155, 162,\n168-170, 202, 210, 219, 224, 260,\n281-288, 291\nWidget::Impl, 150-153\nWidget::processPointer, 78\nWine, 65\nexample functions/templates\n(see also std::)\naddDivisorFilter, 217, 223\narraySize, 16\nauthAndAccess, 25-28, 26-27\nBase::Base, 113\nBase::doWork, 79\nBase::mf1, 81-82\nBase::mf2, 81-82\nBase::mf3, 81-82\nBase::mf4, 81-82\nBase::operator=, 113\nBase::~Base, 112\ncalcEpsilon, 47\ncalcValue, 261\ncbegin, 88\ncleanup, 96\ncompress, 237\ncomputerPriority, 140\ncontinueProcessing, 70\ncreateInitList, 23\ncreateVec, 32, 35\ncusDel, 146\ndelInvmt2, 123\nDerived::doWork, 79\nDerived::mf1, 81-82\nDerived::mf2, 81-82\nDerived::mf3, 81-82\nDerived::mf4, 81-82\ndetect, 268, 270\ndoAsyncWork, 241-242\ndoSomething, 83\ndoSomeWork, 57, 221\ndoWork, 96, 251, 255\ndwim, 37-38\nf, 10-16, 18, 22-23, 32, 34, 59, 90, 95,\n164-166, 199, 208, 247\nf1, 17, 29, 60\nf2, 17, 29, 60\nf3, 60\nfastLoadWidget, 136\nfeatures, 43\nfindAndInsert, 88\nfunc, 5, 39, 197-198, 201\nfunc_for_cx, 19\nfunc_for_rx, 19\nfunc_for_x, 19\nIndex \n| \n307\nwww.it-ebooks.info\n\n\nfwd, 207\nInvestment::~Investment, 122\nisLucky, 76\nIsValAndArch::IsValAndArch, 226\nIsValAndArch::operator(), 226\nkillWidget, 297\nloadWidget, 136\nlockAndCall, 61\nlogAndAdd, 177-179, 186-187\nlogAndAddImpl, 187-188\nlogAndProcess, 161\nmakeInvestment, 119-120, 122-123\nmakeStringDeque, 27\nmakeWidget, 80, 84, 174-176\nmidpoint, 101\nmyFunc, 16\nnameFromIdx, 179\noperator+, 3, 172-173\nPassword::changeTo, 288-289\nPassword::Password, 288\nPerson::Person, 180-182, 184, 189, 191,\n193-194, 196\nPoint::distanceFromOrigin, 106\nPoint::Point, 100\nPoint::setX, 100-101\nPoint::setY, 100\nPoint::xValue, 100\nPoint::yValue, 100-101\nPolynomial::roots, 103-105\nPolyWidget::operator(), 239\npow, 99-100\nprimeFactors, 68\nprocess, 130, 132, 161\nprocessPointer, 77, 78\nprocessPointer<char>, 77\nprocessPointer<const char>, 77\nprocessPointer<const void>, 77\nprocessPointer<void>, 78\nprocessVal, 211\nprocessVals, 3\nprocessWidget, 146\nreact, 268\nreallyAsync, 249\nreduceAndCopy, 173\nreflection, 102\nsetAlarm, 233, 235\nsetSignText, 172\nsetup, 96\nSomeCompilerGeneratedClassName::oper‐\nator(), 229\nsomeFunc, 4, 17, 20, 167\nSpecialPerson::SpecialPerson, 183, 192\nSpecialWidget::processWidget, 291\nstd::add_lvalue_reference, 66\nstd::basic_ios::basic_ios, 75, 160\nstd::basic_ios::operator=, 75, 160\nstd::forward, 199-201, 230\nstd::get, 257\nstd::make_shared, 139-147, 171\nstd::make_unique, 139-147, 171\nstd::move, 158\nstd::pair::swap, 93\nstd::remove_const, 66\nstd::remove_reference, 66\nstd::swap, 93\nstd::vector::emplace_back, 167\nstd::vector::operator[], 24, 24\nstd::vector::push_back, 166, 292\nstd::vector<bool>::operator[], 46\nStringTable::StringTable, 113\nStringTable::~StringTable, 113\nThreadRAII::get, 254, 257\nThreadRAII::operator=, 257\nThreadRAII::ThreadRAII, 254, 257\nThreadRAII::~ThreadRAII, 254, 257\ntoUType, 73\nWarning::override, 83\nWidget::addFilter, 219-222\nWidget::addName, 281-284\nWidget::create, 132\nWidget::data, 83-85\nWidget::doWork, 80\nWidget::isArchived, 224\nWidget::isProcessed, 224\nWidget::isValidated, 224\nWidget::magicValue, 106-108\nWidget::operator float, 53\nWidget::operator=, 109, 112, 115, 152-154\nWidget::process, 130-131\nWidget::processPointer<char>, 77\nWidget::processPointer<void>, 77\nWidget::processWidget, 140\nWidget::setName, 169-170\nWidget::setPtr, 286\nWidget::Widget, 3, 52-55, 109, 112, 115,\n148-155, 162, 168-169\nWidget::~Widget, 112, 148, 151\n308 \n| \nIndex\nwww.it-ebooks.info\n\n\nwidgetFactory, 201\nworkOnVal, 212\nworkWithContainer, 218\nexample structs (see example classes/templates)\nexception safety\nalternatives to std::make_shared, 145-147,\n298\ndefinition of, 4\nemplacement and, 296-299\nmake functions and, 140, 298\nexception specifications, 90\nexception-neutral, definition of, 93\nexclusive ownership, definition of, 119\nexpired std::weak_ptr, 135\nexplicit constructors, insertion functions and,\n299\nexplicitly typed initializer idiom, 43-48\nF\nFacebook, 299\nfeminine manifestation of the divine (see\nUrbano, Nancy L.)\nFernandes, Martinho, xiv\nfinal keyword, 83\nFioravante, Matthew, xiv\nforwarding (see perfect forwarding)\nforwarding references, 164\nFrench, gratuitous use of, 164, 194\nFriesen, Stanley, xiii\nfunction\narguments, definition of, 4\nconditionally noexcept, 93\ndecay, 17\ndefaulted (see defaulted member functions)\ndeleted, 74-79\ngreediest in C++, 180\nmember, 87\nmember reference qualifiers and, 83-85\nmember templates, 115\nmember, defaulted, 112\nnames, overloaded, 211-213\nnon-member, 88\nobjects, definition of, 5\nparameters, definition of, 4\npointer parameter syntaxes, 211\nprivate and undefined, 74\nreturn type deduction, 25-26\nsignature, definition of, 6\nuniversal references and, 180\nG\ngeneralized lambda capture, definition of, 225\ngeneric code, move operations and, 206\ngeneric lambdas\ndefinition of, 229\noperator() in, 229\ngratuitous swipe at Python, 293\ngratuitous use\nof French, 164, 194\nof Yiddish, 82\ngreediest functions in C++, 180\nGrimm, Rainer, xiv\nH\nHalbersma, Rein, xiv\nhardware threads, definition of, 242\nhighlighting in this book, 3\nHinnant, Howard, xiv\n\"Hitchhiker's Guide to the Galaxy, The\", allu‐\nsion to, 30\nHuchley, Benjamin, xiv\nI\nimplicit copy operations, in classes declaring\nmove operations, 111\nimplicit generation of special member func‐\ntions, 109-115\nincomplete type, definition of, 148\nindeterminate destructor behavior for futures,\n260\ninference, type (see type deduction)\ninit capture, 224-229\ndefinition of, 224\ninitialization\nbraced, 50\norder with std::thread data members, 254\nsyntaxes for, 49\nuniform, 50\ninlining, in lambdas vs. std::bind, 236\ninsertion\nexplicit constructors and, 300\nvs. emplacement, 292-301\nintegral constant expression, definition of, 97\ninterface design\nconstexpr and, 102\nexception specifications and, 90\nwide vs. narrow contracts, 95\ninterruptible threads, definition of, 256\nIndex \n| \n309\nwww.it-ebooks.info\n\n\nJ\n\"Jabberwocky\", allusion to, 289\nJohn 8:32, allusion to, 164\njoinability, testing std::threads for, 255\njoinable std::threads\ndefinition of, 250\ndestruction of, 251-253\ntesting for joinability, 255\nK\nKaminski, Tomasz, xiv\nKarpov, Andrey, xiv\nkeywords, contextual, 83\nKirby-Green,Tom, xiv\nKohl, Nate, xiv\nKreuzer, Gerhard, xiv, xv\nKrügler, Daniel, xiii\nL\nlambdas\nauto&& parameters and decltype in,\n229-232\nbound and unbound arguments and, 238\nby-reference captures and, 217-219\nby-value capture, drawbacks of, 219-223\nby-value capture, pointers and, 219\ncreating closures with, 216\ndangling references and, 217-219\ndefault capture modes and, 216-223\ndefinition of, 5, 215\nexpressive power of, 215\ngeneric, 229\nimplicit capture of the this pointer, 220-222\ninit capture, 224-229\ninlining and, 236\nlambda capture and objects of static storage\nduration, 222\nmove capture and, 238\noverloading and, 235\npolymorphic function objects and, 239\nvariadic, 231\nvs. std::bind, 232-240\nbound arguments, treatment of, 238\ninlining and, 236\nmove capture and, 239\npolymorphic functions objects and, 239\nreadability and, 232-236\nunbound arguments, treatment of, 238\nLavavej, Stephan T., xiii, 139\nlegacy types, move operations and, 203\nlhs, definition of, 3\nLiber, Nevin “:-)”, xiv\nliteral types, definition of, 100\nload balancing, 244\nlocal variables\nby-value return and, 173-176\nwhen not destroyed, 120\nlvalues, definition of, 2\nM\nMaher, Michael, xv\nmake functions\navoiding code duplication and, 140\ncustom deleters and, 142\ndefinition of, 139\nexception safety and, 140-142, 298\nparentheses vs. braces, 143\n\"Mary Poppins\", allusion to, 289\nMatthews, Hubert, xiv\nmemory\nconsistency models, 274\nmemory-mapped I/O, definition of, 276\nMerkle, Bernhard, xiii\nMesopotamia, 109\n\"Modern C++ Design\" (book), xiii\nmost vexing parse, definition of, 51\nmove capture, 224\nemulation with std::bind, 226-229, 239\nlambdas and, 239\nmove operations\ndefaulting, 113-114\ndefinition of, 3\ngeneric code and, 206\nimplicitly generated, 109-112\nlegacy types and, 203\nPimpl Idiom and, 152-153\nstd::array and, 204\nstd::shared_ptr and, 126\nstd::string and, 205\nstrong guarantee and, 205\ntemplates and, 206\nmove operations and\nmove semantics, definition of, 157\nmove-enabled types, 110\nmove-only type, definition of, 105, 119\n310 \n| \nIndex\nwww.it-ebooks.info\n\n\nN\nnamed return value optimization (NRVO), 174\nnarrow contracts, definition of, 95-96\nnarrow ellipsis, 3\nnarrowing conversions, definition of, 51\nNeedham, Bradley E., xiv, xv\nNeri, Cassio, xiv\nNewton's laws of motion, 168\nNiebler, Eric, xiv\nNikitin, Alexey A., xiv\nnoexcept, 90-96\ncompiler warnings and, 96\nconditional, 93\ndeallocation functions and, 94\ndestructors and, 94\nfunction interfaces and, 93\nmove operations and, 91-92\noperator delete and, 94\noptimization and, 90-93\nstrong guarantee and, 92\nswap functions and, 92-93\nnon-dependent type, definition of, 64\nnon-member functions, 88\ndeleting, 76\nNovak, Adela, 171\nNRVO (named return value optimization), 174\nNULL\noverloading and, 59\ntemplates and, 60\nnullptr\noverloading and, 59\ntemplates and, 60-62\ntype of, 59\nvs. 0 and NULL, 58-62\nO\nobjects\n() vs. {} for creation of, 49-58\ndestruction of, 120\noperator templates, type arguments and, 235\noperator(), in generic lambdas, 229\noperator[], return type of, 24, 46\nOrr, Roger, xiv\nOS threads, definition of, 242\noverloading\nalternatives to, 184-197\nlambdas and, 235\npointer and integral types, 59\nscalability of, 171\nuniversal references and, 171, 177-197\noverride, 79-85\nas keyword, 83\nrequirements for overriding, 79-81\nvirtual functions and, 79-85\noversubscription, definition of, 243\n\"Overview of the New C++\" (book), xiii\nP\nparameters\nforwarding, definition of, 207\nof rvalue reference type, 2\nParent, Sean, xiv\npass by value, 281-292\nefficiency of, 283-291\nslicing problem and, 291\nperfect forwarding\n(see also universal references)\nconstructors, 180-183, 188-194\ncopying objects and, 180-183\ninheritance and, 183, 191-193\ndefinition of, 4, 157, 207\nemplacement and, 294\nfailure cases, 207-214\nbitfields, 213\nbraced initializers, 208\ndeclaration-only integral static const\ndata members, 210-211\noverloaded function/template names,\n211\nstd::bind and, 238\nPimpl Idiom, 147-156\ncompilation time and, 148\ncopy operations and, 153-154\ndefinition of, 147\nmove operations and, 152-153\nstd::shared_ptr and, 155-156\nstd::unique_ptr and, 149\npolling, cost/efficiency of, 265\npolymorphic function objects, 239\nprivate and undefined functions, vs. deleted\nfunctions, 74\nproxy class, 45-46\nPython, gratuitous swipe at, 293\nR\nraces, testing for std::thread joinability and, 255\nRAII classes\ndefinition of, 253\nIndex \n| \n311\nwww.it-ebooks.info\n\n\nfor std::thread objects, 269\nRAII objects, definition of, 253\nraw pointers\nas back pointers, 138\ndefinition of, 6\ndisadvantages of, 117\nread-modify-write (RMW) operations, 272\nstd::atomic and, 272\nvolatile and, 272\nredundant loads, definition of, 276\nreference collapsing, 197-203\nalias declarations and, 202\nauto and, 201\ncontexts for, 201-203\ndecltype and, 203\nrules for, 199\ntypedefs and, 202\nreference count, definition of, 125\nreference counting control blocks (see control\nblocks)\nreference qualifiers\ndefinition of, 80\non member functions, 83-85\nreferences\ndangling, 217\nforwarding, 164\nin binary code, 210\nto arrays, 16\nto references, illegality of, 198\nrelaxed memory consistency, 274\nreporting bugs and suggesting improvements, 6\nResource Acquisition is Initialization (see\nRAII)\nresource management\ncopy operations and destructor and, 111\ndeletion and, 126\nresource ownership, definition of, 117\nreturn value optimization (RVO), 174-176\nrhs, definition of, 3\nRMW (read-modify-write) operations, 272\nRule of Three, definition of, 111\nrvalue references\ndefinition of, 2\nfinal use of, 172\nparameters, 2\npassing to std::forward, 231-232\nvs. universal references, 164-168\nrvalue_cast, 159\nRVO (see return value optimization)\nS\nSchober, Hendrik, xiii\nscoped enums\ndefinition of, 67\nvs. unscoped enums, 67-74\nsequential consistency, definition of, 274\nSFINAE technology, 190\nshallow copy, definition of, 154\nshared ownership, definition of, 125\nshared state\ndefinition of, 259\nfuture destructor behavior and, 259\nreference count in, 259\nshared_from_this, 131\nSimon, Paul, 117\nslicing problem, 291\nsmall string optimization (SSO), 205, 290\nsmart pointers, 117-156\ndangling pointers and, 134\ndefinition of, 6, 118\nexclusive-ownership resource management\nand, 118\nvs. raw pointers, 117\nsoftware threads, definition of, 242\nspecial member functions\ndefinition of, 109\nimplicit generation of, 109-115\nmember function templates and, 115\n\"special\" memory, 275-277\nspurious wakeups, definition of, 264\nSSO (small string optimization), 205, 290\n\"Star Trek\", allusion to, 125\n\"Star Wars\", allusion to, 189\nstatic storage duration, definition of, 222\nstatic_assert, 151, 196\nstd::add_lvalue_reference, 66\nstd::add_lvalue_reference_t, 66\nstd::allocate_shared\nand classes with custom memory manage‐\nment and, 144\nefficiency of, 142\nstd::all_of, 218\nstd::array, move operations and, 204\nstd::async, 243\ndefault launch policy, 246-249\ndestructors for futures from, 259\nlaunch policy, 245\nlaunch policy and thread-local storage,\n247-248\n312 \n| \nIndex\nwww.it-ebooks.info\n\n\nlaunch policy and timeout-based loops, 247\nstd::packaged_task and, 261\nstd::atomic\ncode reordering and, 273\ncopy operations and, 277\nmultiple variables and transactions and,\n106-108\nRMW operations and, 272\nuse with volatile, 279\nvs. volatile, 271-279\nstd::auto_ptr, 118\nstd::basic_ios, 75\nstd::basic_ios::basic_ios, 75\nstd::basic_ios::operator=, 75\nstd::bind\nbound and unbound arguments and, 238\ninlining and, 236\nmove capture and, 238\nmove capture emulation and, 226-229\noverloading and, 235\nperfect forwarding and, 238\npolymorphic function objects and, 239\nreadability and, 232-236\nvs. lambdas, 232-240\nstd::cbegin, 88\nstd::cend, 88\nstd::crbegin, 88\nstd::crend, 88\nstd::decay, 190\nstd::enable_if, 189-194\nstd::enable_shared_from_this, 131-132\nstd::false_type, 187\nstd::forward, 161-162, 199-201\nby-value return and, 172-176\ncasts and, 158\npassing rvalue references to, 231\nreplacing std::move with, 162\nuniversal references and, 168-173\nstd::function, 39-40\nstd::future<void>, 267\nstd::initializer_lists, braced initializers and, 52\nstd::is_base_of, 192\nstd::is_constructible, 195\nstd::is_nothrow_move_constructible, 92\nstd::is_same, 190-191\nstd::launch::async, 246\nautomating use as launch policy, 249\nstd::launch::deferred, 246\ntimeout-based loops and, 247\nstd::literals, 233\nstd::make_shared, 139-147, 171\n(see also make functions)\nalternatives to, 298\nclasses with custom memory management\nand, 144\nefficiency of, 142\nlarge objects and, 144-145\nstd::make_unique, 139-147, 171\n(see also make functions)\nstd::move, 158-161\nby-value parameters and, 283\nby-value return and, 172-176\ncasts and, 158\nconst objects and, 159-161\nreplacing with std::forward, 162-163\nrvalue references and, 168-173\nuniversal references and, 169\nstd::move_if_noexcept, 92\nstd::nullptr_t, 59\nstd::operator, 160\nstd::operator=, 75\nstd::operator[], 24, 46\nstd::packaged_task, 261-262\nstd::async and, 261\nstd::pair, 93\nstd::pair::swap, 93\nstd::plus, 235\nstd::promise, 258\nsetting, 266\nstd::promise<void>, 267\nstd::rbegin, 88\nstd::ref, 238\nstd::remove_const, 66\nstd::remove_const_t, 66\nstd::remove_reference, 66\nstd::remove_reference_t, 66\nstd::rend, 88\nstd::result_of, 249\nstd::shared_future<void>, 267\nstd::shared_ptr, 125-134\narrays and, 133\nconstruction from raw pointer, 129-132\nconstruction from this, 130-132\nconversion from std::unique_ptr, 124\ncreating from std::weak_ptr, 135\ncycles and, 137\ndeleters and, 126\nvs. std::unique_ptr deleters, 155\nIndex \n| \n313\nwww.it-ebooks.info\n\n\nefficiency of, 125, 133\nmove operations and, 126\nmultiple control blocks and, 129\nsize of, 126\nvs. std::weak_ptr, 134\nstd::string, move operations and, 205\nstd::swap, 93\nstd::system_error, 242\nstd::threads\nas data members, member initialization\norder and, 254\ndestroying joinable, 251-253\nimplicit join or detach, 252\njoinable vs. unjoinable, 250\nRAII class for, 253-257, 269\nstd::true_type, 187\nstd::unique_ptr, 118-124\nconversion to std::shared_ptr, 124\ndeleters and, 120-123, 126\nvs. std::shared_ptr deleters, 155\nefficiency of, 118\nfactory functions and, 119-123\nfor arrays, 124\nsize of, 123\nstd::vector, 24, 166, 292\nstd::vector constructors, 56\nstd::vector::emplace_back, 167\nstd::vector::push_back, 166, 292\nstd::vector<bool>, 43-46\nstd::vector<bool>::operator[], 46\nstd::vector<bool>::reference, 43-45\nstd::weak_ptr, 134-139\ncaching and, 136\nconstruction of std::shared_ptr with, 135\ncycles and, 137\nefficiency of, 138\nexpired, 135\nobserver design pattern and, 137\nvs. std::shared_ptr, 134\nSteagall, Bob, xiv\nStewart, Rob, xiv\nstrong guarantee\ndefinition of, 4\nmove operations and, 205\nnoexcept and, 91\nSummer, Donna, 294\nSupercalifragilisticexpialidocious, 289\nSutter, Herb, xiv\nsystem threads, 242\nT\nT&&, meanings of, 164\ntag dispatch, 185-188\ntask-based programming, definition of, 241\ntasks\nload balancing and, 244\nquerying for deferred status, 248\nvs. threads, 241-245\ntemplate\nalias templates, 63-65\naliases, 63\nclasses, definition of, 5\ndisabled vs. enabled, 189\nfunctions, definition of, 5\ninstantiations, deleting, 77\nmove operations and, 206\nnames, perfect forwarding and, 211\nparentheses vs. braces in, 57\nstandard operators and type arguments for,\n235\ntype deduction, 9-18\narray arguments and, 15-17\nfor pass by value, 14-15\nfor pointer and reference types, 11-14\nfor universal references, 13-14\nfunction arguments and, 17\nvs. auto type deduction, 18-19\nterminology and conventions, 2-6\ntesting std::threads for joinability, 255\n\"The Hitchhiker's Guide to the Galaxy\", allu‐\nsion to, 30\n\"The View from Aristeia\" (blog), xv, 269\nthread handle destructor behavior, 258-262\nthread local storage (TLS), definition of, 247\nthread-based programming, definition of, 241\nthreads\ndestruction, 252\nexhaustion, 243\nfunction return values and, 242\nhardware, 242\nimplicit join or detach, 252\njoinable vs. unjoinable, 250\nOS threads, 242\nsetting priority/affinity, 245, 252, 268\nsoftware, 242\nsuspending, 268-270\nsystem threads, 242\ntesting for joinability, 255\nvs. tasks, 241-245\n314 \n| \nIndex\nwww.it-ebooks.info\n\n\nthread_local variables, 247\ntime suffixes, 233\ntimeout-based loops, 247\nTLS (see thread-local storage)\ntranslation, definition of, 97\ntype arguments, operator templates and, 235\ntype deduction\n(see also template, type deduction)\nfor auto, 18-23\nemplace_back and, 166\nuniversal references and, 165\ntype inference (see type deduction)\ntype traits, 66-67\ntype transformations, 66\ntypedefs, reference collapsing and, 202\ntypeid and viewing deduced types, 31-33\ntypename\ndependent type and, 64\nnon-dependent type and, 64\nvs. class for template parameters, 3\ntypes, testing for equality, 190\nU\nundefined behavior, definition of, 6\nundefined template to elicit compiler error\nmessages, 31\nuniform initialization, 50\nuniversal references\n(see also perfect forwarding)\nadvantages over overloading, 171\nalternatives to overloading on, 183-197\nauto and, 167\nconstructors and, 180-183, 188-194\nefficiency and, 178\nerror messages and, 195-196\nfinal use of, 172\ngreedy functions and, 180\ninitializers and, 165\nlvalue/rvalue encoding, 197\nnames of, 167\noverloading and, 177-197\nreal meaning of, 202\nstd::move and, 169\nsyntactic form of, 165\ntype deduction and, 165\nvs. rvalue references, 164-168\nunjoinable std::threads, definition of, 250\nunscoped enums\ndefinition of, 67\nvs. scoped enums, 67-74\nUrbano, Nancy L. (see feminine manifestation\nof the divine)\nV\nVandewoestyn, Bart, xiv\nvariadic lambdas, 231\n\"View from Aristeia, The\" (blog), xv, 269\nvirtual functions, override and, 79-85\nvoid future, 267\nvolatile\ncode reordering and, 275\ndead stores and, 276\nredundant loads and, 276\nRMW operations and, 272\n\"special\" memory and, 275-277\nuse with std::atomic, 279\nvs. std::atomic, 271-279\nW\nWakely, Jonathan, xiv\nwarnings, compiler (see compiler warnings)\nWatkins, Damien, xiv\nweak count, definition of, 144\nweak memory consistency, 274\nwide contracts, definition of, 95-96\nwide ellipsis, 3\nWidget, definition of, 3\nWilliams, Anthony, xiii, 257\nWilliams, Ashley Morgan, xv\nWilliams, Emyr, xv\nWinkler, Fredrik, xiv\nWinterberg, Michael, xiv\nY\nYiddish, gratuitous use of, 82\nZ\nZolman, Leor, xiii, xiv\nZuse, Konrad, 195\nIndex \n| \n315\nwww.it-ebooks.info\n",
      "page_number": 325,
      "chapter_number": 31,
      "summary": "This chapter covers segment 31 (pages 325-333). Key topics include definition. deleted\nfunctions, 74\nproxy class, 45-46\nPython, gratuitous swipe at, 293\nR\nraces, testing for std::thread joinability and, 255\nRAII classes\ndefinition of, 253\nIndex \n| \n311\nwww.it-ebooks.info.",
      "keywords": [
        "std",
        "definition",
        "Widget",
        "xiv",
        "type",
        "reference",
        "move",
        "move operations",
        "functions",
        "operations",
        "operator",
        "universal references",
        "ptr",
        "shared",
        "Base"
      ],
      "concepts": [
        "std",
        "xiv",
        "definition",
        "functions",
        "operator",
        "operations",
        "type",
        "widget",
        "reference",
        "threads"
      ],
      "similar_chapters": [
        {
          "book": "C++ Concurrency in Action",
          "chapter": 53,
          "title": "Segment 53 (pages 582-589)",
          "relevance_score": 0.71,
          "method": "sentence_transformers"
        },
        {
          "book": "More Effective C++",
          "chapter": 32,
          "title": "Segment 32 (pages 320-329)",
          "relevance_score": 0.71,
          "method": "sentence_transformers"
        },
        {
          "book": "C++ Concurrency in Action",
          "chapter": 6,
          "title": "Segment 6 (pages 50-58)",
          "relevance_score": 0.68,
          "method": "sentence_transformers"
        },
        {
          "book": "Computer Systems A Programmer’s Perspective",
          "chapter": 52,
          "title": "Segment 52 (pages 1041-1063)",
          "relevance_score": 0.67,
          "method": "sentence_transformers"
        },
        {
          "book": "C++ Templates_ The Complete Guide",
          "chapter": 26,
          "title": "Segment 26 (pages 815-849)",
          "relevance_score": 0.66,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 32,
      "title": "Segment 32 (pages 334-334)",
      "start_page": 334,
      "end_page": 334,
      "detection_method": "topic_boundary",
      "content": "About the Author\nScott Meyers is one of the world’s foremost experts on C++. A sought-after trainer,\nconsultant, and conference presenter, his Effective C++ books (Effective C++, More\nEffective C++, and Effective STL) have set the bar for C++ programming guidance for\nmore than 20 years. He has a Ph.D. in computer science from Brown University. His\nwebsite is aristeia.com.\nColophon\nThe animal on the cover of Effective Modern C++ is a Rose-crowned fruit dove (Ptili‐\nnopus regina). This species of dove also goes by the names pink-capped fruit dove or\nSwainson’s fruit dove. It is distinguished by its striking plumage: grey head and\nbreast, orange belly, whitish throat, yellow-orange iris, and grey green bill and feet.\nDistributed in lowland rainforests in eastern Australia, monsoon forests in northern\nAustralia, and the Lesser Sunda Islands and Maluku Islands of Indonesia, the Rose-\ncrowned fruit dove’s diet consists of various fruits like figs (which it swallows whole),\npalms, and vines. Camphor Laurel, a large evergreen tree, is another food source for\nthe fruit dove. They feed—in pairs, small parties, or singly—in rainforest canopies,\nusually in the morning or late afternoon. To hydrate, they get water from leaves or\ndew, not from the ground.\nThe fruit dove is considered vulnerable in New South Wales due to rainforest clear‐\ning and fragmentation, logging, weeds, fire regime–altered habitats, and the removal\nof Laurel Camphor without adequate alternatives.\nMany of the animals on O’Reilly covers are endangered; all of them are important to\nthe world. To learn more about how you can help, go to animals.oreilly.com.\nThe cover image is from Wood’s Illustrated Natural History, bird volume. The cover\nfonts are URW Typewriter and Guardian Sans. The text font is Adobe Minion Pro;\nthe heading font is Adobe Myriad Condensed; and the code font is Dalton Maag’s\nUbuntu Mono.\nwww.it-ebooks.info\n",
      "page_number": 334,
      "chapter_number": 32,
      "summary": "Many of the animals on O’Reilly covers are endangered; all of them are important to\nthe world Key topics include fonts, orange, and rainforests. A sought-after trainer,\nconsultant, and conference presenter, his Effective C++ books (Effective C++, More\nEffective C++, and Effective STL) have set the bar for C++ programming guidance for\nmore than 20 years.",
      "keywords": [
        "fruit dove",
        "Effective",
        "dove",
        "fruit",
        "Effective STL",
        "Author",
        "Rose-crowned fruit dove",
        "Effective Modern",
        "Scott Meyers",
        "Lesser Sunda Islands",
        "Brown University",
        "Adobe Minion Pro",
        "Adobe Myriad Condensed",
        "pink-capped fruit dove",
        "crowned fruit dove"
      ],
      "concepts": [
        "fonts",
        "orange",
        "rainforests",
        "rainforest",
        "effective",
        "cover",
        "scott",
        "evergreen",
        "south",
        "logging"
      ],
      "similar_chapters": [
        {
          "book": "AI Engineering Building Applications",
          "chapter": 49,
          "title": "Segment 49 (pages 991-991)",
          "relevance_score": 0.6,
          "method": "sentence_transformers"
        },
        {
          "book": "Microservices Up and Running",
          "chapter": 32,
          "title": "Segment 32 (pages 314-319)",
          "relevance_score": 0.51,
          "method": "sentence_transformers"
        },
        {
          "book": "More Effective C++",
          "chapter": 3,
          "title": "Segment 3 (pages 17-24)",
          "relevance_score": 0.45,
          "method": "sentence_transformers"
        },
        {
          "book": "Designing Machine Learning Systems An Iterative Process for Production-Ready Applications",
          "chapter": 54,
          "title": "Segment 54 (pages 457-461)",
          "relevance_score": 0.39,
          "method": "sentence_transformers"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 42,
          "title": "Segment 42 (pages 849-853)",
          "relevance_score": 0.38,
          "method": "sentence_transformers"
        }
      ]
    }
  ],
  "pages": [
    {
      "page_number": 1,
      "chapter": null,
      "content": "Scott Meyers\nEffective \nModern C++\n42 SPECIFIC WAYS TO IMPROVE YOUR USE OF C++11 AND C++14\nwww.it-ebooks.info\n",
      "content_length": 110,
      "extraction_method": "Direct"
    },
    {
      "page_number": 2,
      "chapter": null,
      "content": "PROGRAMMING/C++\nEffective Modern C++\nISBN: 978-1-491-90399-5\nUS $49.99\t\n CAN $52.99\n“ After I learned the C++ \nbasics, I then learned \nhow to use C++ in \nproduction code from \nMeyers' series of \nEffective C++ books. \nEffective Modern C++ \nis the most important \nhow-to book for advice \non key guidelines, \nstyles, and idioms to use \nmodern C++ effectively \nand well. Don't own it \nyet? Buy this one. Now.”\n—Herb Sutter \n Chair of ISO C++ Standards Committee and \nC++ Software Architect at Microsoft\nTwitter: @oreillymedia\nfacebook.com/oreilly\nComing to grips with C++11 and C++14 is more than a matter of familiarizing \nyourself with the features they introduce (e.g., auto type declarations, \nmove semantics, lambda expressions, and concurrency support). The \nchallenge is learning to use those features effectively—so that your \nsoftware is correct, efficient, maintainable, and portable. That’s where \nthis practical book comes in. It describes how to write truly great software \nusing C++11 and C++14—i.e., using modern C++.\nTopics include:\n■\n■The pros and cons of braced initialization, noexcept \nspecifications, perfect forwarding, and smart pointer make \nfunctions\n■\n■The relationships among std::move, std::forward, rvalue \nreferences, and universal references\n■\n■Techniques for writing clear, correct, effective lambda \nexpressions\n■\n■How std::atomic differs from volatile, how each should be \nused, and how they relate to C++'s concurrency API\n■\n■How best practices in \"old\" C++ programming (i.e., C++98) \nrequire revision for software development in modern C++\nEffective Modern C++ follows the proven guideline-based, example-driven \nformat of Scott Meyers' earlier books, but covers entirely new material. It's \nessential reading for every modern C++ software developer.\nFor more than 20 years, Scott Meyers' Effective C++ books (Effective C++, More \nEffective C++, and Effective STL) have set the bar for C++ programming guidance. \nHis clear, engaging explanations of complex technical material have earned him a \nworldwide following, keeping him in demand as a trainer, consultant, and confer­\nence presenter. He has a Ph.D. in Computer Science from Brown University.\nwww.it-ebooks.info\n",
      "content_length": 2201,
      "extraction_method": "Direct"
    },
    {
      "page_number": 3,
      "chapter": null,
      "content": "So, still interested in C++? You should be! Modern C++ (i.e., C++11/C++14)\nis far more than just a facelift. Considering the new features, it seems that it’s\nmore a reinvention. Looking for guidelines and assistance? Then this book\nis surely what you are looking for. Concerning C++, Scott Meyers was\nand still is a synonym for accuracy, quality, and delight.\n—Gerhard Kreuzer\nResearch and Development Engineer, Siemens AG\nFinding utmost expertise is hard enough. Finding teaching perfectionism—\nan author’s obsession with strategizing and streamlining explanations—is also difficult.\nYou know you’re in for a treat when you get to find both embodied in the same person.\nEffective Modern C++ is a towering achievement from a consummate technical writer.\nIt layers lucid, meaningful, and well-sequenced clarifications on top of complex and\ninterconnected topics, all in crisp literary style. You’re equally unlikely to find a\ntechnical mistake, a dull moment, or a lazy sentence in Effective Modern C++.\n—Andrei Alexandrescu\nPh.D., Research Scientist, Facebook, and author of Modern C++ Design\nAs someone with over two decades of C++ experience, to get the most out of\nmodern C++ (both best practices and pitfalls to avoid), I highly recommend\ngetting this book, reading it thoroughly, and referring to it often!\nI’ve certainly learned new things going through it!\n—Nevin Liber\nSenior Software Engineer, DRW Trading Group\nBjarne Stroustrup—the creator of C++—said, “C++11 feels like a new language.”\nEffective Modern C++ makes us share this same feeling by clearly explaining\nhow everyday programmers can benefit from new features and idioms\nof C++11 and C++14. Another great Scott Meyers book.\n—Cassio Neri\nFX Quantitative Analyst, Lloyds Banking Group\nPraise for Effective Modern C++\nwww.it-ebooks.info\n",
      "content_length": 1804,
      "extraction_method": "Direct"
    },
    {
      "page_number": 4,
      "chapter": null,
      "content": "Scott has the knack of boiling technical complexity down to an understandable kernel.\nHis Effective C++ books helped to raise the coding style of a previous generation of C++\nprogrammers; the new book seems positioned to do the same for those using modern C++.\n—Roger Orr\nOR/2 Limited, a member of the ISO C++ standards committee\nEffective Modern C++ is a great tool to improve your modern C++ skills. Not only does it\nteach you how, when and where to use modern C++ and be effective, it also explains why.\nWithout doubt, Scott’s clear and insightful writing, spread over 42 well-thought items,\ngives programmers a much better understanding of the language.\n—Bart Vandewoestyne\nResearch and Development Engineer and C++ enthusiast\nI love C++, it has been my work vehicle for many decades now. And with\nthe latest raft of features it is even more powerful and expressive than I\nwould have previously imagined. But with all this choice comes the question\n“when and how do I apply these features?” As has always been the case,\nScott’s Effective C++ books are the definitive answer to this question.\n—Damien Watkins\nComputation Software Engineering Team Lead, CSIRO\nGreat read for transitioning to modern C++—new C++11/14\nlanguage features are described alongside C++98, subject items are\neasy to reference, and advice summarized at the end of each section.\nEntertaining and useful for both casual and advanced C++ developers.\n—Rachel Cheng\nF5 Networks\nIf you’re migrating from C++98/03 to C++11/14, you need the eminently practical and\nclear information Scott provides in Effective Modern C++. If you’re already writing\nC++11 code, you’ll probably discover issues with the new features through Scott’s\nthorough discussion of the important new features of the language. Either way, this book\nis worth your time.\n—Rob Stewart\nBoost Steering Committee member (boost.org)\nwww.it-ebooks.info\n",
      "content_length": 1884,
      "extraction_method": "Direct"
    },
    {
      "page_number": 5,
      "chapter": null,
      "content": "Scott Meyers\nEffective Modern C++\nwww.it-ebooks.info\n",
      "content_length": 53,
      "extraction_method": "Direct"
    },
    {
      "page_number": 6,
      "chapter": null,
      "content": "978-1-491-90399-5\n[TI]\nEffective Modern C++\nby Scott Meyers\nCopyright © 2015 Scott Meyers. All rights reserved.\nPrinted in the Canada.\nPublished by O’Reilly Media, Inc., 1005 Gravenstein Highway North, Sebastopol, CA 95472.\nO’Reilly books may be purchased for educational, business, or sales promotional use. Online editions are\nalso available for most titles (http://safaribooksonline.com). For more information, contact our corporate/\ninstitutional sales department: 800-998-9938 or corporate@oreilly.com.\nEditor: Rachel Roumeliotis\nProduction Editor: Melanie Yarbrough\nCopyeditor: Jasmine Kwityn\nProofreader: Charles Roumeliotis\nIndexer: Scott Meyers\nInterior Designer: David Futato\nCover Designer: Ellie Volkhausen\nIllustrator: Rebecca Demarest\nNovember 2014:\n First Edition\nRevision History for the First Edition\n2014-11-07: First Release\nSee http://oreilly.com/catalog/errata.csp?isbn=9781491903995 for release details.\nThe O’Reilly logo is a registered trademark of O’Reilly Media, Inc. Effective Modern C++, the cover image\nof a Rose-crowned Fruit Dove, and related trade dress are trademarks of O’Reilly Media, Inc.\nWhile the publisher and the author have used good faith efforts to ensure that the information and\ninstructions contained in this work are accurate, the publisher and the author disclaim all responsibility\nfor errors or omissions, including without limitation responsibility for damages resulting from the use of\nor reliance on this work. Use of the information and instructions contained in this work is at your own\nrisk. If any code samples or other technology this work contains or describes is subject to open source\nlicenses or the intellectual property rights of others, it is your responsibility to ensure that your use\nthereof complies with such licenses and/or rights.\nwww.it-ebooks.info\n",
      "content_length": 1822,
      "extraction_method": "Direct"
    },
    {
      "page_number": 7,
      "chapter": null,
      "content": " \nFor Darla,\nblack Labrador Retriever extraordinaire\nwww.it-ebooks.info\n",
      "content_length": 72,
      "extraction_method": "Direct"
    },
    {
      "page_number": 8,
      "chapter": null,
      "content": "www.it-ebooks.info\n",
      "content_length": 19,
      "extraction_method": "Direct"
    },
    {
      "page_number": 9,
      "chapter": null,
      "content": "Table of Contents\nFrom the Publisher. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  xi\nAcknowledgments. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  xiii\nIntroduction. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  1\n1. Deducing Types. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  9\nItem 1: Understand template type deduction.                                                              9\nItem 2: Understand auto type deduction.                                                                  18\nItem 3: Understand decltype.                                                                                     23\nItem 4: Know how to view deduced types.                                                                  30\n2. auto. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  37\nItem 5: Prefer auto to explicit type declarations.                                                      37\nItem 6: Use the explicitly typed initializer idiom when auto deduces\nundesired types.                                                                                                 43\n3. Moving to Modern C++. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  49\nItem 7: Distinguish between () and {} when creating objects.                               49\nItem 8: Prefer nullptr to 0 and NULL.                                                                         58\nItem 9: Prefer alias declarations to typedefs.                                                            63\nItem 10: Prefer scoped enums to unscoped enums.                                                     67\nItem 11: Prefer deleted functions to private undefined ones.                                  74\nItem 12: Declare overriding functions override.                                                     79\nItem 13: Prefer const_iterators to iterators.                                                     86\nItem 14: Declare functions noexcept if they won’t emit exceptions.                     90\nItem 15: Use constexpr whenever possible.                                                              97\nvii\nwww.it-ebooks.info\n",
      "content_length": 2546,
      "extraction_method": "Direct"
    },
    {
      "page_number": 10,
      "chapter": null,
      "content": "Item 16: Make const member functions thread safe.                                             103\nItem 17: Understand special member function generation.                                  109\n4. Smart Pointers. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  117\nItem 18: Use std::unique_ptr for exclusive-ownership resource\nmanagement.                                                                                                 118\nItem 19: Use std::shared_ptr for shared-ownership resource\nmanagement.                                                                                                 125\nItem 20: Use std::weak_ptr for std::shared_ptr-like pointers that can\ndangle.                                                                                                             134\nItem 21: Prefer std::make_unique and std::make_shared to direct use of\nnew.                                                                                                                  139\nItem 22: When using the Pimpl Idiom, define special member functions in\nthe implementation file.                                                                               147\n5. Rvalue References, Move Semantics, and Perfect Forwarding. . . . . . . . . . . . . . . . . . . .  157\nItem 23: Understand std::move and std::forward.                                           158\nItem 24: Distinguish universal references from rvalue references.                       164\nItem 25: Use std::move on rvalue references, std::forward on universal\nreferences.                                                                                                       168\nItem 26: Avoid overloading on universal references.                                              177\nItem 27: Familiarize yourself with alternatives to overloading on universal\nreferences.                                                                                                       184\nItem 28: Understand reference collapsing.                                                               197\nItem 29: Assume that move operations are not present, not cheap, and not\nused.                                                                                                                203\nItem 30: Familiarize yourself with perfect forwarding failure cases.                    207\n6. Lambda Expressions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  215\nItem 31: Avoid default capture modes.                                                                     216\nItem 32: Use init capture to move objects into closures.                                        224\nItem 33: Use decltype on auto&& parameters to std::forward them.            229\nItem 34: Prefer lambdas to std::bind.                                                                    232\n7. The Concurrency API. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  241\nItem 35: Prefer task-based programming to thread-based.                                    241\nItem 36: Specify std::launch::async if asynchronicity is essential.                 245\nItem 37: Make std::threads unjoinable on all paths.                                          250\nItem 38: Be aware of varying thread handle destructor behavior.                         258\nItem 39: Consider void futures for one-shot event communication.                  262\nviii \n| \nTable of Contents\nwww.it-ebooks.info\n",
      "content_length": 3585,
      "extraction_method": "Direct"
    },
    {
      "page_number": 11,
      "chapter": null,
      "content": "Item 40: Use std::atomic for concurrency, volatile for special memory.    271\n8. Tweaks. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  281\nItem 41: Consider pass by value for copyable parameters that are cheap to\nmove and always copied.                                                                              281\nItem 42: Consider emplacement instead of insertion.                                            292\nIndex. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  303\nTable of Contents \n| \nix\nwww.it-ebooks.info\n",
      "content_length": 698,
      "extraction_method": "Direct"
    },
    {
      "page_number": 12,
      "chapter": null,
      "content": "www.it-ebooks.info\n",
      "content_length": 19,
      "extraction_method": "Direct"
    },
    {
      "page_number": 13,
      "chapter": null,
      "content": "From the Publisher\nUsing Code Examples\nThis book is here to help you get your job done. In general, if example code is offered\nwith this book, you may use it in your programs and documentation. You do not\nneed to contact us for permission unless you’re reproducing a significant portion of\nthe code. For example, writing a program that uses several chunks of code from this\nbook does not require permission. Selling or distributing a CD-ROM of examples\nfrom O’Reilly books does require permission. Answering a question by citing this\nbook and quoting example code does not require permission. Incorporating a signifi‐\ncant amount of example code from this book into your product’s documentation\ndoes require permission.\nWe appreciate, but do not require, attribution. An attribution usually includes the\ntitle, author, publisher, and ISBN. For example: “Effective Modern C++ by Scott Mey‐\ners (O’Reilly). Copyright 2015 Scott Meyers, 978-1-491-90399-5.”\nIf you feel your use of code examples falls outside fair use or the permission given\nabove, feel free to contact us at permissions@oreilly.com.\nSafari® Books Online\nSafari Books Online is an on-demand digital library that\ndelivers expert content in both book and video form\nfrom the world’s leading authors in technology and\nbusiness.\nTechnology professionals, software developers, web designers, and business and crea‐\ntive professionals use Safari Books Online as their primary resource for research,\nproblem solving, learning, and certification training.\nSafari Books Online offers a range of plans and pricing for enterprise, government,\neducation, and individuals.\nxi\nwww.it-ebooks.info\n",
      "content_length": 1646,
      "extraction_method": "Direct"
    },
    {
      "page_number": 14,
      "chapter": null,
      "content": "Members have access to thousands of books, training videos, and prepublication\nmanuscripts in one fully searchable database from publishers like O’Reilly Media,\nPrentice Hall Professional, Addison-Wesley Professional, Microsoft Press, Sams,\nQue, Peachpit Press, Focal Press, Cisco Press, John Wiley & Sons, Syngress, Morgan\nKaufmann, IBM Redbooks, Packt, Adobe Press, FT Press, Apress, Manning, New\nRiders, McGraw-Hill, Jones & Bartlett, Course Technology, and hundreds more. For\nmore information about Safari Books Online, please visit us online.\nHow to Contact Us\nComments and questions concerning this book may be addressed to the publisher:\nO’Reilly Media, Inc.\n1005 Gravenstein Highway North\nSebastopol, CA 95472\n800-998-9938 (in the United States or Canada)\n707-829-0515 (international or local)\n707-829-0104 (fax)\nTo comment or ask technical questions about this book, send email to bookques‐\ntions@oreilly.com.\nFor more information about our books, courses, conferences, and news, see our web‐\nsite at http://www.oreilly.com.\nFind us on Facebook: http://facebook.com/oreilly\nFollow us on Twitter: http://twitter.com/oreillymedia\nWatch us on YouTube: http://www.youtube.com/oreillymedia\nxii \n| \nFrom the Publisher\nwww.it-ebooks.info\n",
      "content_length": 1240,
      "extraction_method": "Direct"
    },
    {
      "page_number": 15,
      "chapter": null,
      "content": "Acknowledgments\nI started investigating what was then known as C++0x (the nascent C++11) in 2009. I\nposted numerous questions to the Usenet newsgroup comp.std.c++, and I’m grate‐\nful to the members of that community (especially Daniel Krügler) for their very help‐\nful postings. In more recent years, I’ve turned to Stack Overflow when I had\nquestions about C++11 and C++14, and I’m equally indebted to that community for\nits help in understanding the finer points of modern C++. \nIn 2010, I prepared materials for a training course on C++0x (ultimately published as\nOverview of the New C++, Artima Publishing, 2010). Both those materials and my\nknowledge greatly benefited from the technical vetting performed by Stephan T. Lav‐\navej, Bernhard Merkle, Stanley Friesen, Leor Zolman, Hendrik Schober, and Anthony\nWilliams. Without their help, I would probably never have been in a position to\nundertake Effective Modern C++. That title, incidentally, was suggested or endorsed\nby several readers responding to my 18 February 2014 blog post, “Help me name my\nbook,” and Andrei Alexandrescu (author of Modern C++ Design, Addison-Wesley,\n2001) was kind enough to bless the title as not poaching on his terminological turf. \nI’m unable to identify the origins of all the information in this book, but some sour‐\nces had a relatively direct impact. Item 4’s use of an undefined template to coax type\ninformation out of compilers was suggested by Stephan T. Lavavej, and Matt P. Dziu‐\nbinski brought Boost.TypeIndex to my attention. In Item 5, the unsigned-\nstd::vector<int>::size_type example is from Andrey Karpov’s 28 February\n2010 article, “In what way can C++0x standard help you eliminate 64-bit errors.” The\nstd::pair<std::string, int>/std::pair<const std::string, int> example in\nthe same Item is from Stephan T. Lavavej’s talk at Going Native 2012, “STL11: Magic\n&& Secrets.” Item 6 was inspired by Herb Sutter’s 12 August 2013 article, “GotW #94\nSolution: AAA Style (Almost Always Auto).” Item 9 was motivated by Martinho Fer‐\nnandes’ blog post of 27 May 2012, “Handling dependent names.” The Item 12 exam‐\nple demonstrating overloading on reference qualifiers is based on Casey’s answer to\nthe question, “What’s a use case for overloading member functions on reference\nxiii\nwww.it-ebooks.info\n",
      "content_length": 2297,
      "extraction_method": "Direct"
    },
    {
      "page_number": 16,
      "chapter": null,
      "content": "qualifiers?,” posted to Stack Overflow on 14 January 2014. My Item 15 treatment of\nC++14’s expanded support for constexpr functions incorporates information I\nreceived from Rein Halbersma. Item 16 is based on Herb Sutter’s C++ and Beyond\n2012 presentation, “You don’t know const and mutable.” Item 18’s advice to have\nfactory functions return std::unique_ptrs is based on Herb Sutter’s 30 May 2013\narticle, “GotW# 90 Solution: Factories.” In Item 19, fastLoadWidget is derived from\nHerb Sutter’s Going Native 2013 presentation, “My Favorite C++ 10-Liner.” My treat‐\nment of std::unique_ptr and incomplete types in Item 22 draws on Herb Sutter’s\n27 November 2011 article, “GotW #100: Compilation Firewalls” as well as Howard\nHinnant’s 22 May 2011 answer to the Stack Overflow question, “Is\nstd::unique_ptr<T> required to know the full definition of T?” The Matrix addition\nexample in Item 25 is based on writings by David Abrahams. JoeArgonne’s 8 Decem‐\nber 2012 comment on the 30 November 2012 blog post, “Another alternative to\nlambda move capture,” was the source of Item 32’s std::bind-based approach to\nemulating init capture in C++11. Item 37’s explanation of the problem with an\nimplicit detach in std::thread’s destructor is taken from Hans-J. Boehm’s 4\nDecember 2008 paper, “N2802: A plea to reconsider detach-on-destruction for thread\nobjects.” Item 41 was originally motivated by discussions of David Abrahams’ 15\nAugust 2009 blog post, “Want speed? Pass by value.” The idea that move-only types\ndeserve special treatment is due to Matthew Fioravante, while the analysis of\nassignment-based copying stems from comments by Howard Hinnant. In Item 42,\nStephan T. Lavavej and Howard Hinnant helped me understand the relative perfor‐\nmance profiles of emplacement and insertion functions, and Michael Winterberg\nbrought to my attention how emplacement can lead to resource leaks. (Michael cred‐\nits Sean Parent’s Going Native 2013 presentation, “C++ Seasoning,” as his source).\nMichael also pointed out how emplacement functions use direct initialization, while\ninsertion functions use copy initialization.\nReviewing drafts of a technical book is a demanding, time-consuming, and utterly\ncritical task, and I’m fortunate that so many people were willing to do it for me. Full\nor partial drafts of Effective Modern C++ were officially reviewed by Cassio Neri,\nNate Kohl, Gerhard Kreuzer, Leor Zolman, Bart Vandewoestyne, Stephan T. Lavavej,\nNevin “:-)” Liber, Rachel Cheng, Rob Stewart, Bob Steagall, Damien Watkins, Bradley\nE. Needham, Rainer Grimm, Fredrik Winkler, Jonathan Wakely, Herb Sutter, Andrei\nAlexandrescu, Eric Niebler, Thomas Becker, Roger Orr, Anthony Williams, Michael\nWinterberg, Benjamin Huchley, Tom Kirby-Green, Alexey A Nikitin, William Deal‐\ntry, Hubert Matthews, and Tomasz Kamiński. I also received feedback from several\nreaders through O’Reilly’s Early Release EBooks and Safari Books Online’s Rough\nCuts, comments on my blog (The View from Aristeia), and email. I’m grateful to each\nof these people. The book is much better than it would have been without their help.\nI’m particularly indebted to Stephan T. Lavavej and Rob Stewart, whose extraordi‐\nnarily detailed and comprehensive remarks lead me to worry that they spent nearly as\nxiv \n| \nAcknowledgments\nwww.it-ebooks.info\n",
      "content_length": 3309,
      "extraction_method": "Direct"
    },
    {
      "page_number": 17,
      "chapter": null,
      "content": "much time on this book as I did. Special thanks also go to Leor Zolman, who, in addi‐\ntion to reviwing the manuscript, double-checked all the code examples.\nDedicated reviews of digital versions of the book were performed by Gerhard\nKreuzer, Emyr Williams, and Bradley E. Needham.\nMy decision to limit the line length in code displays to 64 characters (the maximum\nlikely to display properly in print as well as across a variety of digital devices, device\norientations, and font configurations) was based on data provided by Michael Maher.\nAshley Morgan Williams made dining at the Lake Oswego Pizzicato uniquely enter‐\ntaining. When it comes to man-sized Caesars, she’s the go-to gal.\nMore than 20 years after first living through my playing author, my wife, Nancy L.\nUrbano, once again tolerated many months of distracted conversations with a cock‐\ntail of resignation, exasperation, and timely splashes of understanding and support.\nDuring the same period, our dog, Darla, was largely content to doze away the hours I\nspent staring at computer screens, but she never let me forget that there’s life beyond\nthe keyboard.\nAcknowledgments \n| \nxv\nwww.it-ebooks.info\n",
      "content_length": 1165,
      "extraction_method": "Direct"
    },
    {
      "page_number": 18,
      "chapter": null,
      "content": "www.it-ebooks.info\n",
      "content_length": 19,
      "extraction_method": "Direct"
    },
    {
      "page_number": 19,
      "chapter": null,
      "content": "Introduction\nIf you’re an experienced C++ programmer and are anything like me, you initially\napproached C++11 thinking, “Yes, yes, I get it. It’s C++, only more so.” But as you\nlearned more, you were surprised by the scope of the changes. auto declarations,\nrange-based for loops, lambda expressions, and rvalue references change the face of\nC++, to say nothing of the new concurrency features. And then there are the\nidiomatic changes. 0 and typedefs are out, nullptr and alias declarations are in.\nEnums should now be scoped. Smart pointers are now preferable to built-in ones.\nMoving objects is normally better than copying them.\nThere’s a lot to learn about C++11, not to mention C++14.\nMore importantly, there’s a lot to learn about making effective use of the new capabil‐\nities. If you need basic information about “modern” C++ features, resources abound,\nbut if you’re looking for guidance on how to employ the features to create software\nthat’s correct, efficient, maintainable, and portable, the search is more challenging.\nThat’s where this book comes in. It’s devoted not to describing the features of C++11\nand C++14, but instead to their effective application.\nThe information in the book is broken into guidelines called Items. Want to under‐\nstand the various forms of type deduction? Or know when (and when not) to use\nauto declarations? Are you interested in why const member functions should be\nthread safe, how to implement the Pimpl Idiom using std::unique_ptr, why you\nshould avoid default capture modes in lambda expressions, or the differences\nbetween std::atomic and volatile? The answers are all here. Furthermore, they’re\nplatform-independent, Standards-conformant answers. This is a book about portable\nC++.\nThe Items in this book are guidelines, not rules, because guidelines have exceptions.\nThe most important part of each Item is not the advice it offers, but the rationale\nbehind the advice. Once you’ve read that, you’ll be in a position to determine whether\nthe circumstances of your project justify a violation of the Item’s guidance. The true\n1\nwww.it-ebooks.info\n",
      "content_length": 2101,
      "extraction_method": "Direct"
    },
    {
      "page_number": 20,
      "chapter": null,
      "content": "goal of this book isn’t to tell you what to do or what to avoid doing, but to convey a\ndeeper understanding of how things work in C++11 and C++14.\nTerminology and Conventions\nTo make sure we understand one another, it’s important to agree on some terminol‐\nogy, beginning, ironically, with “C++.” There have been four official versions of C++,\neach named after the year in which the corresponding ISO Standard was adopted:\nC++98, C++03, C++11, and C++14. C++98 and C++03 differ only in technical\ndetails, so in this book, I refer to both as C++98. When I refer to C++11, I mean both\nC++11 and C++14, because C++14 is effectively a superset of C++11. When I write\nC++14, I mean specifically C++14. And if I simply mention C++, I’m making a broad\nstatement that pertains to all language versions.   \nTerm I Use\nLanguage Versions I Mean\nC++\nAll\nC++98\nC++98 and C++03\nC++11\nC++11 and C++14\nC++14\nC++14\nAs a result, I might say that C++ places a premium on efficiency (true for all ver‐\nsions), that C++98 lacks support for concurrency (true only for C++98 and C++03),\nthat C++11 supports lambda expressions (true for C++11 and C++14), and that\nC++14 offers generalized function return type deduction (true for C++14 only).\nC++11’s most pervasive feature is probably move semantics, and the foundation of\nmove semantics is distinguishing expressions that are rvalues from those that are lval‐\nues. That’s because rvalues indicate objects eligible for move operations, while lvalues\ngenerally don’t. In concept (though not always in practice), rvalues correspond to\ntemporary objects returned from functions, while lvalues correspond to objects you\ncan refer to, either by name or by following a pointer or lvalue reference.\nA useful heuristic to determine whether an expression is an lvalue is to ask if you can\ntake its address. If you can, it typically is. If you can’t, it’s usually an rvalue. A nice\nfeature of this heuristic is that it helps you remember that the type of an expression is\nindependent of whether the expression is an lvalue or an rvalue. That is, given a type\nT, you can have lvalues of type T as well as rvalues of type T. It’s especially important\nto remember this when dealing with a parameter of rvalue reference type, because the\nparameter itself is an lvalue:\n2 \n|\nwww.it-ebooks.info\n",
      "content_length": 2306,
      "extraction_method": "Direct"
    },
    {
      "page_number": 21,
      "chapter": null,
      "content": "class Widget {\npublic:\n  Widget(Widget&& rhs);    // rhs is an lvalue, though it has\n  …                        // an rvalue reference type\n};\nHere, it’d be perfectly valid to take rhs’s address inside Widget’s move constructor,\nso rhs is an lvalue, even though its type is an rvalue reference. (By similar reasoning,\nall parameters are lvalues.)\nThat code snippet demonstrates several conventions I normally follow:\n• The class name is Widget. I use Widget whenever I want to refer to an arbitrary\nuser-defined type. Unless I need to show specific details of the class, I use Widget\nwithout declaring it.\n• I use the parameter name rhs (“right-hand side”). It’s my preferred parameter\nname for the move operations (i.e., move constructor and move assignment oper‐\nator) and the copy operations (i.e., copy constructor and copy assignment opera‐\ntor). I also employ it for the right-hand parameter of binary operators:\nMatrix operator+(const Matrix& lhs, const Matrix& rhs);\nIt’s no surprise, I hope, that lhs stands for “left-hand side.”\n• I apply special formatting to parts of code or parts of comments to draw your\nattention to them. In the Widget move constructor above, I’ve highlighted the\ndeclaration of rhs and the part of the comment noting that rhs is an lvalue.\nHighlighted code is neither inherently good nor inherently bad. It’s simply code\nyou should pay particular attention to.\n• I use “…” to indicate “other code could go here.” This narrow ellipsis is different\nfrom the wide ellipsis (“...”) that’s used in the source code for C++11’s variadic\ntemplates. That sounds confusing, but it’s not. For example:\ntemplate<typename... Ts>                // these are C++\nvoid processVals(const Ts&... params)   // source code\n{                                       // ellipses\n  …                                     // this means \"some\n                                        // code goes here\"\n}\nThe declaration of processVals shows that I use typename when declaring type\nparameters in templates, but that’s merely a personal preference; the keyword\nclass would work just as well. On those occasions where I show code excerpts\n \n| \n3\nwww.it-ebooks.info\n",
      "content_length": 2168,
      "extraction_method": "Direct"
    },
    {
      "page_number": 22,
      "chapter": null,
      "content": "from a C++ Standard, I declare type parameters using class, because that’s what\nthe Standards do.\nWhen an object is initialized with another object of the same type, the new object is\nsaid to be a copy of the initializing object, even if the copy was created via the move\nconstructor. Regrettably, there’s no terminology in C++ that distinguishes between\nan object that’s a copy-constructed copy and one that’s a move-constructed copy:\nvoid someFunc(Widget w);        // someFunc's parameter w\n                                // is passed by value\nWidget wid;                     // wid is some Widget\nsomeFunc(wid);                  // in this call to someFunc,\n                                // w is a copy of wid that's\n                                // created via copy construction\nsomeFunc(std::move(wid));       // in this call to SomeFunc,\n                                // w is a copy of wid that's\n                                // created via move construction\nCopies of rvalues are generally move constructed, while copies of lvalues are usually\ncopy constructed. An implication is that if you know only that an object is a copy of\nanother object, it’s not possible to say how expensive it was to construct the copy. In\nthe code above, for example, there’s no way to say how expensive it is to create the\nparameter w without knowing whether rvalues or lvalues are passed to someFunc.\n(You’d also have to know the cost of moving and copying Widgets.)\nIn a function call, the expressions passed at the call site are the function’s arguments.\nThe arguments are used to initialize the function’s parameters. In the first call to\nsomeFunc above, the argument is wid. In the second call, the argument is\nstd::move(wid). In both calls, the parameter is w. The distinction between argu‐\nments and parameters is important, because parameters are lvalues, but the argu‐\nments with which they are initialized may be rvalues or lvalues. This is especially\nrelevant during the process of perfect forwarding, whereby an argument passed to a\nfunction is passed to a second function such that the original argument’s rvalueness\nor lvalueness is preserved. (Perfect forwarding is discussed in detail in Item 30.)\nWell-designed functions are exception safe, meaning they offer at least the basic\nexception safety guarantee (i.e., the basic guarantee). Such functions assure callers\nthat even if an exception is thrown, program invariants remain intact (i.e., no data\nstructures are corrupted) and no resources are leaked. Functions offering the strong\nexception safety guarantee (i.e., the strong guarantee) assure callers that if an excep‐\ntion arises, the state of the program remains as it was prior to the call.\n4 \n|\nwww.it-ebooks.info\n",
      "content_length": 2738,
      "extraction_method": "Direct"
    },
    {
      "page_number": 23,
      "chapter": null,
      "content": "When I refer to a function object, I usually mean an object of a type supporting an\noperator() member function. In other words, an object that acts like a function.\nOccasionally I use the term in a slightly more general sense to mean anything that\ncan be invoked using the syntax of a non-member function call (i.e., “function\nName(arguments)”). This broader definition covers not just objects supporting oper\nator(), but also functions and C-like function pointers. (The narrower definition\ncomes from C++98, the broader one from C++11.) Generalizing further by adding\nmember function pointers yields what are known as callable objects. You can gener‐\nally ignore the fine distinctions and simply think of function objects and callable\nobjects as things in C++ that can be invoked using some kind of function-calling syn‐\ntax.\nFunction objects created through lambda expressions are known as closures. It’s sel‐\ndom necessary to distinguish between lambda expressions and the closures they cre‐\nate, so I often refer to both as lambdas. Similarly, I rarely distinguish between\nfunction templates (i.e., templates that generate functions) and template functions\n(i.e., the functions generated from function templates). Ditto for class templates and\ntemplate classes.\nMany things in C++ can be both declared and defined. Declarations introduce names\nand types without giving details, such as where storage is located or how things are\nimplemented:\nextern int x;                       // object declaration\nclass Widget;                       // class declaration\nbool func(const Widget& w);         // function declaration\nenum class Color;                   // scoped enum declaration\n                                    // (see Item 10)\nDefinitions provide the storage locations or implementation details:\nint x;                              // object definition\nclass Widget {                      // class definition\n  …\n};\nbool func(const Widget& w)\n{ return w.size() < 10; }           // function definition\nenum class Color\n{ Yellow, Red, Blue };              // scoped enum definition\n \n| \n5\nwww.it-ebooks.info\n",
      "content_length": 2118,
      "extraction_method": "Direct"
    },
    {
      "page_number": 24,
      "chapter": null,
      "content": "A definition also qualifies as a declaration, so unless it’s really important that some‐\nthing is a definition, I tend to refer to declarations.\nI define a function’s signature to be the part of its declaration that specifies parameter\nand return types. Function and parameter names are not part of the signature. In the\nexample above, func’s signature is bool(const Widget&). Elements of a function’s\ndeclaration other than its parameter and return types (e.g., noexcept or constexpr,\nif present), are excluded. (noexcept and constexpr are described in Items 14 and\n15.) The official definition of “signature” is slightly different from mine, but for this\nbook, my definition is more useful. (The official definition sometimes omits return\ntypes.)\nNew C++ Standards generally preserve the validity of code written under older ones,\nbut occasionally the Standardization Committee deprecates features. Such features\nare on standardization death row and may be removed from future Standards. Com‐\npilers may or may not warn about the use of deprecated features, but you should do\nyour best to avoid them. Not only can they lead to future porting headaches, they’re\ngenerally inferior to the features that replace them. For example, std::auto_ptr is\ndeprecated in C++11, because std::unique_ptr does the same job, only better.\nSometimes a Standard says that the result of an operation is undefined behavior. That\nmeans that runtime behavior is unpredictable, and it should go without saying that\nyou want to steer clear of such uncertainty. Examples of actions with undefined\nbehavior include using square brackets (“[]”) to index beyond the bounds of a\nstd::vector, dereferencing an uninitialized iterator, or engaging in a data race (i.e.,\nhaving two or more threads, at least one of which is a writer, simultaneously access\nthe same memory location).\nI call built-in pointers, such as those returned from new, raw pointers. The opposite of\na raw pointer is a smart pointer. Smart pointers normally overload the pointer-\ndereferencing operators (operator-> and operator*), though Item 20 explains that\nstd::weak_ptr is an exception.\nIn source code comments, I sometimes abbreviate “constructor” as ctor and\n“destructor” as dtor.  \nReporting Bugs and Suggesting Improvements\nI’ve done my best to fill this book with clear, accurate, useful information, but surely\nthere are ways to make it better. If you find errors of any kind (technical, expository,\ngrammatical, typographical, etc.), or if you have suggestions for how the book could\nbe improved, please email me at emc++@aristeia.com. New printings give me the\n6 \n|\nwww.it-ebooks.info\n",
      "content_length": 2638,
      "extraction_method": "Direct"
    },
    {
      "page_number": 25,
      "chapter": null,
      "content": "opportunity to revise Effective Modern C++, and I can’t address issues I don’t know\nabout!\nTo view the list of the issues I do know about, consult the book’s errata page, http://\nwww.aristeia.com/BookErrata/emc++-errata.html.\n \n| \n7\nwww.it-ebooks.info\n",
      "content_length": 252,
      "extraction_method": "Direct"
    },
    {
      "page_number": 26,
      "chapter": null,
      "content": "www.it-ebooks.info\n",
      "content_length": 19,
      "extraction_method": "Direct"
    },
    {
      "page_number": 27,
      "chapter": null,
      "content": "CHAPTER 1\nDeducing Types\nC++98 had a single set of rules for type deduction: the one for function templates.\nC++11 modifies that ruleset a bit and adds two more, one for auto and one for\ndecltype. C++14 then extends the usage contexts in which auto and decltype may\nbe employed. The increasingly widespread application of type deduction frees you\nfrom the tyranny of spelling out types that are obvious or redundant. It makes C++\nsoftware more adaptable, because changing a type at one point in the source code\nautomatically propagates through type deduction to other locations. However, it can\nrender code more difficult to reason about, because the types deduced by compilers\nmay not be as apparent as you’d like.\nWithout a solid understanding of how type deduction operates, effective program‐\nming in modern C++ is all but impossible. There are just too many contexts where\ntype deduction takes place: in calls to function templates, in most situations where\nauto appears, in decltype expressions, and, as of C++14, where the enigmatic\ndecltype(auto) construct is employed.\nThis chapter provides the information about type deduction that every C++ devel‐\noper requires. It explains how template type deduction works, how auto builds on\nthat, and how decltype goes its own way. It even explains how you can force com‐\npilers to make the results of their type deductions visible, thus enabling you to ensure\nthat compilers are deducing the types you want them to.\nItem 1: Understand template type deduction.\nWhen users of a complex system are ignorant of how it works, yet happy with what it\ndoes, that says a lot about the design of the system. By this measure, template type\ndeduction in C++ is a tremendous success. Millions of programmers have passed\n9\nwww.it-ebooks.info\n",
      "content_length": 1778,
      "extraction_method": "Direct"
    },
    {
      "page_number": 28,
      "chapter": null,
      "content": "arguments to template functions with completely satisfactory results, even though\nmany of those programmers would be hard-pressed to give more than the haziest\ndescription of how the types used by those functions were deduced.\nIf that group includes you, I have good news and bad news. The good news is that\ntype deduction for templates is the basis for one of modern C++’s most compelling\nfeatures: auto. If you were happy with how C++98 deduced types for templates,\nyou’re set up to be happy with how C++11 deduces types for auto. The bad news is\nthat when the template type deduction rules are applied in the context of auto, they\nsometimes seem less intuitive than when they’re applied to templates. For that rea‐\nson, it’s important to truly understand the aspects of template type deduction that\nauto builds on. This Item covers what you need to know.\nIf you’re willing to overlook a pinch of pseudocode, we can think of a function tem‐\nplate as looking like this:\ntemplate<typename T>\nvoid f(ParamType param);\nA call can look like this:\nf(expr);                    // call f with some expression\nDuring compilation, compilers use expr to deduce two types: one for T and one for\nParamType. These types are frequently different, because ParamType often contains\nadornments, e.g., const or reference qualifiers. For example, if the template is\ndeclared like this,\ntemplate<typename T>\nvoid f(const T& param);     // ParamType is const T&\nand we have this call,\nint x = 0;\nf(x);                       // call f with an int\nT is deduced to be int, but ParamType is deduced to be const int&.\nIt’s natural to expect that the type deduced for T is the same as the type of the argu‐\nment passed to the function, i.e., that T is the type of expr. In the above example,\nthat’s the case: x is an int, and T is deduced to be int. But it doesn’t always work that\nway. The type deduced for T is dependent not just on the type of expr, but also on the\nform of ParamType. There are three cases:\n10 \n| \nItem 1\nwww.it-ebooks.info\n",
      "content_length": 2018,
      "extraction_method": "Direct"
    },
    {
      "page_number": 29,
      "chapter": null,
      "content": "• ParamType is a pointer or reference type, but not a universal reference. (Univer‐\nsal references are described in Item 24. At this point, all you need to know is that\nthey exist and that they’re not the same as lvalue references or rvalue references.)\n• ParamType is a universal reference.\n• ParamType is neither a pointer nor a reference.\nWe therefore have three type deduction scenarios to examine. Each will be based on\nour general form for templates and calls to it:\ntemplate<typename T>\nvoid f(ParamType param);\nf(expr);                // deduce T and ParamType from expr\nCase 1: ParamType is a Reference or Pointer, but not a Universal\nReference\nThe simplest situation is when ParamType is a reference type or a pointer type, but\nnot a universal reference. In that case, type deduction works like this:\n1. If expr’s type is a reference, ignore the reference part.\n2. Then pattern-match expr’s type against ParamType to determine T.\nFor example, if this is our template,\ntemplate<typename T>\nvoid f(T& param);       // param is a reference\nand we have these variable declarations,\nint x = 27;             // x is an int\nconst int cx = x;       // cx is a const int\nconst int& rx = x;      // rx is a reference to x as a const int\nthe deduced types for param and T in various calls are as follows:\nf(x);                   // T is int, param's type is int&\nf(cx);                  // T is const int,\n                        // param's type is const int&\nf(rx);                  // T is const int,\n                        // param's type is const int&\nItem 1 \n| \n11\nwww.it-ebooks.info\n",
      "content_length": 1589,
      "extraction_method": "Direct"
    },
    {
      "page_number": 30,
      "chapter": null,
      "content": "In the second and third calls, notice that because cx and rx designate const values, T\nis deduced to be const int, thus yielding a parameter type of const int&. That’s\nimportant to callers. When they pass a const object to a reference parameter, they\nexpect that object to remain unmodifiable, i.e., for the parameter to be a reference-to-\nconst. That’s why passing a const object to a template taking a T& parameter is safe:\nthe constness of the object becomes part of the type deduced for T.\nIn the third example, note that even though rx’s type is a reference, T is deduced to\nbe a non-reference. That’s because rx’s reference-ness is ignored during type deduc‐\ntion.\nThese examples all show lvalue reference parameters, but type deduction works\nexactly the same way for rvalue reference parameters. Of course, only rvalue argu‐\nments may be passed to rvalue reference parameters, but that restriction has nothing\nto do with type deduction.\nIf we change the type of f’s parameter from T& to const T&, things change a little, but\nnot in any really surprising ways. The constness of cx and rx continues to be respec‐\nted, but because we’re now assuming that param is a reference-to-const, there’s no\nlonger a need for const to be deduced as part of T:\ntemplate<typename T>\nvoid f(const T& param);  // param is now a ref-to-const\nint x = 27;              // as before\nconst int cx = x;        // as before\nconst int& rx = x;       // as before\nf(x);                    // T is int, param's type is const int&\nf(cx);                   // T is int, param's type is const int&\nf(rx);                   // T is int, param's type is const int&\nAs before, rx’s reference-ness is ignored during type deduction.\nIf param were a pointer (or a pointer to const) instead of a reference, things would\nwork essentially the same way:\ntemplate<typename T>\nvoid f(T* param);        // param is now a pointer\nint x = 27;              // as before\nconst int *px = &x;      // px is a ptr to x as a const int\n12 \n| \nItem 1\nwww.it-ebooks.info\n",
      "content_length": 2023,
      "extraction_method": "Direct"
    },
    {
      "page_number": 31,
      "chapter": null,
      "content": "f(&x);                   // T is int, param's type is int*\nf(px);                   // T is const int,\n                         // param's type is const int*\nBy now, you may find yourself yawning and nodding off, because C++’s type deduc‐\ntion rules work so naturally for reference and pointer parameters, seeing them in\nwritten form is really dull. Everything’s just obvious! Which is exactly what you want\nin a type deduction system.\nCase 2: ParamType is a Universal Reference\nThings are less obvious for templates taking universal reference parameters. Such\nparameters are declared like rvalue references (i.e., in a function template taking a\ntype parameter T, a universal reference’s declared type is T&&), but they behave differ‐\nently when lvalue arguments are passed in. The complete story is told in Item 24, but\nhere’s the headline version:\n• If expr is an lvalue, both T and ParamType are deduced to be lvalue references.\nThat’s doubly unusual. First, it’s the only situation in template type deduction\nwhere T is deduced to be a reference. Second, although ParamType is declared\nusing the syntax for an rvalue reference, its deduced type is an lvalue reference.\n• If expr is an rvalue, the “normal” (i.e., Case 1) rules apply.\nFor example:\ntemplate<typename T>\nvoid f(T&& param);       // param is now a universal reference\nint x = 27;              // as before\nconst int cx = x;        // as before\nconst int& rx = x;       // as before\nf(x);                    // x is lvalue, so T is int&,\n                         // param's type is also int&\nf(cx);                   // cx is lvalue, so T is const int&,\n                         // param's type is also const int&\nf(rx);                   // rx is lvalue, so T is const int&,\n                         // param's type is also const int&\nf(27);                   // 27 is rvalue, so T is int,\n                         // param's type is therefore int&&\nItem 1 \n| \n13\nwww.it-ebooks.info\n",
      "content_length": 1951,
      "extraction_method": "Direct"
    },
    {
      "page_number": 32,
      "chapter": null,
      "content": "Item 24 explains exactly why these examples play out the way they do. The key point\nhere is that the type deduction rules for universal reference parameters are different\nfrom those for parameters that are lvalue references or rvalue references. In particu‐\nlar, when universal references are in use, type deduction distinguishes between lvalue\narguments and rvalue arguments. That never happens for non-universal references.\nCase 3: ParamType is Neither a Pointer nor a Reference\nWhen ParamType is neither a pointer nor a reference, we’re dealing with pass-by-\nvalue:\ntemplate<typename T>\nvoid f(T param);         // param is now passed by value\nThat means that param will be a copy of whatever is passed in—a completely new\nobject. The fact that param will be a new object motivates the rules that govern how T\nis deduced from expr:\n1. As before, if expr’s type is a reference, ignore the reference part.\n2. If, after ignoring expr’s reference-ness, expr is const, ignore that, too. If it’s\nvolatile, also ignore that. (volatile objects are uncommon. They’re generally\nused only for implementing device drivers. For details, see Item 40.)\nHence:\nint x = 27;          // as before\nconst int cx = x;    // as before\nconst int& rx = x;   // as before\nf(x);                // T's and param's types are both int\nf(cx);               // T's and param's types are again both int\nf(rx);               // T's and param's types are still both int\nNote that even though cx and rx represent const values, param isn’t const. That\nmakes sense. param is an object that’s completely independent of cx and rx—a copy\nof cx or rx. The fact that cx and rx can’t be modified says nothing about whether\nparam can be. That’s why expr’s constness (and volatileness, if any) is ignored\nwhen deducing a type for param: just because expr can’t be modified doesn’t mean\nthat a copy of it can’t be.\nIt’s important to recognize that const (and volatile) is ignored only for by-value\nparameters. As we’ve seen, for parameters that are references-to- or pointers-to-\nconst, the constness of expr is preserved during type deduction. But consider the\n14 \n| \nItem 1\nwww.it-ebooks.info\n",
      "content_length": 2152,
      "extraction_method": "Direct"
    },
    {
      "page_number": 33,
      "chapter": null,
      "content": "case where expr is a const pointer to a const object, and expr is passed to a by-\nvalue param:\ntemplate<typename T>\nvoid f(T param);         // param is still passed by value\nconst char* const ptr =  // ptr is const pointer to const object\n  \"Fun with pointers\";\nf(ptr);                  // pass arg of type const char * const\nHere, the const to the right of the asterisk declares ptr to be const: ptr can’t be\nmade to point to a different location, nor can it be set to null. (The const to the left\nof the asterisk says that what ptr points to—the character string—is const, hence\ncan’t be modified.) When ptr is passed to f, the bits making up the pointer are\ncopied into param. As such, the pointer itself (ptr) will be passed by value. In accord\nwith the type deduction rule for by-value parameters, the constness of ptr will be\nignored, and the type deduced for param will be const char*, i.e., a modifiable\npointer to a const character string. The constness of what ptr points to is preserved\nduring type deduction, but the constness of ptr itself is ignored when copying it to\ncreate the new pointer, param.\nArray Arguments\nThat pretty much covers it for mainstream template type deduction, but there’s a\nniche case that’s worth knowing about. It’s that array types are different from pointer\ntypes, even though they sometimes seem to be interchangeable. A primary contribu‐\ntor to this illusion is that, in many contexts, an array decays into a pointer to its first\nelement. This decay is what permits code like this to compile:\nconst char name[] = \"J. P. Briggs\";  // name's type is\n                                     // const char[13]\nconst char * ptrToName = name;       // array decays to pointer\nHere, the const char* pointer ptrToName is being initialized with name, which is a\nconst char[13]. These types (const char* and const char[13]) are not the same,\nbut because of the array-to-pointer decay rule, the code compiles.\nBut what if an array is passed to a template taking a by-value parameter? What hap‐\npens then?\ntemplate<typename T>\nvoid f(T param);      // template with by-value parameter\nItem 1 \n| \n15\nwww.it-ebooks.info\n",
      "content_length": 2147,
      "extraction_method": "Direct"
    },
    {
      "page_number": 34,
      "chapter": null,
      "content": "f(name);              // what types are deduced for T and param?\nWe begin with the observation that there is no such thing as a function parameter\nthat’s an array. Yes, yes, the syntax is legal,\nvoid myFunc(int param[]);\nbut the array declaration is treated as a pointer declaration, meaning that myFunc\ncould equivalently be declared like this:\nvoid myFunc(int* param);         // same function as above\nThis equivalence of array and pointer parameters is a bit of foliage springing from the\nC roots at the base of C++, and it fosters the illusion that array and pointer types are\nthe same.\nBecause array parameter declarations are treated as if they were pointer parameters,\nthe type of an array that’s passed to a template function by value is deduced to be a\npointer type. That means that in the call to the template f, its type parameter T is\ndeduced to be const char*:\nf(name);          // name is array, but T deduced as const char*\nBut now comes a curve ball. Although functions can’t declare parameters that are\ntruly arrays, they can declare parameters that are references to arrays! So if we modify\nthe template f to take its argument by reference,\ntemplate<typename T>\nvoid f(T& param);      // template with by-reference parameter\nand we pass an array to it,\nf(name);               // pass array to f\nthe type deduced for T is the actual type of the array! That type includes the size of\nthe array, so in this example, T is deduced to be const char [13], and the type of f’s\nparameter (a reference to this array) is const char (&)[13]. Yes, the syntax looks\ntoxic, but knowing it will score you mondo points with those few souls who care.\nInterestingly, the ability to declare references to arrays enables creation of a template\nthat deduces the number of elements that an array contains:\n// return size of an array as a compile-time constant. (The\n// array parameter has no name, because we care only about\n// the number of elements it contains.)\ntemplate<typename T, std::size_t N>                 // see info\nconstexpr std::size_t arraySize(T (&)[N]) noexcept  // below on\n{                                                   // constexpr\n16 \n| \nItem 1\nwww.it-ebooks.info\n",
      "content_length": 2187,
      "extraction_method": "Direct"
    },
    {
      "page_number": 35,
      "chapter": null,
      "content": "  return N;                                         // and\n}                                                   // noexcept\nAs Item 15 explains, declaring this function constexpr makes its result available\nduring compilation. That makes it possible to declare, say, an array with the same\nnumber of elements as a second array whose size is computed from a braced initial‐\nizer:\nint keyVals[] = { 1, 3, 7, 9, 11, 22, 35 };      // keyVals has\n                                                 // 7 elements\nint mappedVals[arraySize(keyVals)];              // so does\n                                                 // mappedVals\nOf course, as a modern C++ developer, you’d naturally prefer a std::array to a\nbuilt-in array:\nstd::array<int, arraySize(keyVals)> mappedVals;  // mappedVals'\n                                                 // size is 7\nAs for arraySize being declared noexcept, that’s to help compilers generate better\ncode. For details, see Item 14.\nFunction Arguments\nArrays aren’t the only things in C++ that can decay into pointers. Function types can\ndecay into function pointers, and everything we’ve discussed regarding type deduc‐\ntion for arrays applies to type deduction for functions and their decay into function\npointers. As a result:\nvoid someFunc(int, double);   // someFunc is a function;\n                              // type is void(int, double)\ntemplate<typename T>\nvoid f1(T param);             // in f1, param passed by value\ntemplate<typename T>\nvoid f2(T& param);            // in f2, param passed by ref\nf1(someFunc);                 // param deduced as ptr-to-func;\n                              // type is void (*)(int, double)\nf2(someFunc);                 // param deduced as ref-to-func;\n                              // type is void (&)(int, double)\nThis rarely makes any difference in practice, but if you’re going to know about array-\nto-pointer decay, you might as well know about function-to-pointer decay, too.\nItem 1 \n| \n17\nwww.it-ebooks.info\n",
      "content_length": 1991,
      "extraction_method": "Direct"
    },
    {
      "page_number": 36,
      "chapter": null,
      "content": "So there you have it: the auto-related rules for template type deduction. I remarked\nat the outset that they’re pretty straightforward, and for the most part, they are. The\nspecial treatment accorded lvalues when deducing types for universal references\nmuddies the water a bit, however, and the decay-to-pointer rules for arrays and func‐\ntions stirs up even greater turbidity. Sometimes you simply want to grab your com‐\npilers and demand, “Tell me what type you’re deducing!” When that happens, turn to\nItem 4, because it’s devoted to coaxing compilers into doing just that.\nThings to Remember\n• During template type deduction, arguments that are references are treated as\nnon-references, i.e., their reference-ness is ignored.\n• When deducing types for universal reference parameters, lvalue arguments get\nspecial treatment.\n• When deducing types for by-value parameters, const and/or volatile argu‐\nments are treated as non-const and non-volatile.\n• During template type deduction, arguments that are array or function names\ndecay to pointers, unless they’re used to initialize references.\nItem 2: Understand auto type deduction.\nIf you’ve read Item 1 on template type deduction, you already know almost every‐\nthing you need to know about auto type deduction, because, with only one curious\nexception, auto type deduction is template type deduction. But how can that be?\nTemplate type deduction involves templates and functions and parameters, but auto\ndeals with none of those things.\nThat’s true, but it doesn’t matter. There’s a direct mapping between template type\ndeduction and auto type deduction. There is literally an algorithmic transformation\nfrom one to the other.\nIn Item 1, template type deduction is explained using this general function template\ntemplate<typename T>\nvoid f(ParamType param);\nand this general call:\nf(expr);                    // call f with some expression\nIn the call to f, compilers use expr to deduce types for T and ParamType.\n18 \n| \nItem 1\nwww.it-ebooks.info\n",
      "content_length": 2001,
      "extraction_method": "Direct"
    },
    {
      "page_number": 37,
      "chapter": null,
      "content": "When a variable is declared using auto, auto plays the role of T in the template, and\nthe type specifier for the variable acts as ParamType. This is easier to show than to\ndescribe, so consider this example:\nauto x = 27;\nHere, the type specifier for x is simply auto by itself. On the other hand, in this decla‐\nration,\nconst auto cx = x;\nthe type specifier is const auto. And here,\nconst auto& rx = x;\nthe type specifier is const auto&. To deduce types for x, cx, and rx in these exam‐\nples, compilers act as if there were a template for each declaration as well as a call to\nthat template with the corresponding initializing expression:\ntemplate<typename T>               // conceptual template for\nvoid func_for_x(T param);          // deducing x's type\nfunc_for_x(27);                    // conceptual call: param's\n                                   // deduced type is x's type\ntemplate<typename T>               // conceptual template for\nvoid func_for_cx(const T param);   // deducing cx's type\nfunc_for_cx(x);                    // conceptual call: param's\n                                   // deduced type is cx's type\ntemplate<typename T>               // conceptual template for\nvoid func_for_rx(const T& param);  // deducing rx's type\nfunc_for_rx(x);                    // conceptual call: param's\n                                   // deduced type is rx's type\nAs I said, deducing types for auto is, with only one exception (which we’ll discuss\nsoon), the same as deducing types for templates.\nItem 1 divides template type deduction into three cases, based on the characteristics\nof ParamType, the type specifier for param in the general function template. In a vari‐\nable declaration using auto, the type specifier takes the place of ParamType, so there\nare three cases for that, too:\n• Case 1: The type specifier is a pointer or reference, but not a universal reference.\n• Case 2: The type specifier is a universal reference.\nItem 2 \n| \n19\nwww.it-ebooks.info\n",
      "content_length": 1975,
      "extraction_method": "Direct"
    },
    {
      "page_number": 38,
      "chapter": null,
      "content": "• Case 3: The type specifier is neither a pointer nor a reference.\nWe’ve already seen examples of cases 1 and 3:\nauto x = 27;          // case 3 (x is neither ptr nor reference)\nconst auto cx = x;    // case 3 (cx isn't either)\nconst auto& rx = x;   // case 1 (rx is a non-universal ref.)\nCase 2 works as you’d expect:\nauto&& uref1 = x;     // x is int and lvalue,\n                      // so uref1's type is int&\nauto&& uref2 = cx;    // cx is const int and lvalue,\n                      // so uref2's type is const int&\nauto&& uref3 = 27;    // 27 is int and rvalue,\n                      // so uref3's type is int&&\nItem 1 concludes with a discussion of how array and function names decay into\npointers for non-reference type specifiers. That happens in auto type deduction, too:\nconst char name[] =            // name's type is const char[13]\n  \"R. N. Briggs\";\nauto arr1 = name;              // arr1's type is const char*\nauto& arr2 = name;             // arr2's type is\n                               // const char (&)[13]\nvoid someFunc(int, double);    // someFunc is a function;\n                               // type is void(int, double)\nauto func1 = someFunc;         // func1's type is\n                               // void (*)(int, double)\nauto& func2 = someFunc;        // func2's type is\n                               // void (&)(int, double)\n20 \n| \nItem 2\nwww.it-ebooks.info\n",
      "content_length": 1391,
      "extraction_method": "Direct"
    },
    {
      "page_number": 39,
      "chapter": null,
      "content": "As you can see, auto type deduction works like template type deduction. They’re\nessentially two sides of the same coin.\nExcept for the one way they differ. We’ll start with the observation that if you want to\ndeclare an int with an initial value of 27, C++98 gives you two syntactic choices:\nint x1 = 27;\nint x2(27);\nC++11, through its support for uniform initialization, adds these:\nint x3 = { 27 };\nint x4{ 27 };\nAll in all, four syntaxes, but only one result: an int with value 27.\nBut as Item 5 explains, there are advantages to declaring variables using auto instead\nof fixed types, so it’d be nice to replace int with auto in the above variable declara‐\ntions. Straightforward textual substitution yields this code:\nauto x1 = 27;\nauto x2(27);\nauto x3 = { 27 };\nauto x4{ 27 };\nThese declarations all compile, but they don’t have the same meaning as the ones\nthey replace. The first two statements do, indeed, declare a variable of type int with\nvalue 27. The second two, however, declare a variable of type std::initial\nizer_list<int> containing a single element with value 27!\nauto x1 = 27;             // type is int, value is 27\nauto x2(27);              // ditto\nauto x3 = { 27 };         // type is std::initializer_list<int>,\n                          // value is { 27 }\nauto x4{ 27 };            // ditto\nThis is due to a special type deduction rule for auto. When the initializer for an\nauto-declared variable is enclosed in braces, the deduced type is a std::initial\nizer_list. If such a type can’t be deduced (e.g., because the values in the braced ini‐\ntializer are of different types), the code will be rejected:\nauto x5 = { 1, 2, 3.0 };  // error! can't deduce T for\n                          // std::initializer_list<T>\nItem 2 \n| \n21\nwww.it-ebooks.info\n",
      "content_length": 1772,
      "extraction_method": "Direct"
    },
    {
      "page_number": 40,
      "chapter": null,
      "content": "As the comment indicates, type deduction will fail in this case, but it’s important to\nrecognize that there are actually two kinds of type deduction taking place. One kind\nstems from the use of auto: x5’s type has to be deduced. Because x5’s initializer is in\nbraces, x5 must be deduced to be a std::initializer_list. But std::initial\nizer_list is a template. Instantiations are std::initializer_list<T> for some\ntype T, and that means that T’s type must also be deduced. Such deduction falls under\nthe purview of the second kind of type deduction occurring here: template type\ndeduction. In this example, that deduction fails, because the values in the braced ini‐\ntializer don’t have a single type.\nThe treatment of braced initializers is the only way in which auto type deduction and\ntemplate type deduction differ. When an auto–declared variable is initialized with a\nbraced initializer, the deduced type is an instantiation of std::initializer_list.\nBut if the corresponding template is passed the same initializer, type deduction fails,\nand the code is rejected:\nauto x = { 11, 23, 9 };   // x's type is\n                          // std::initializer_list<int>\ntemplate<typename T>      // template with parameter\nvoid f(T param);          // declaration equivalent to\n                          // x's declaration\nf({ 11, 23, 9 });         // error! can't deduce type for T\nHowever, if you specify in the template that param is a std::initializer_list<T>\nfor some unknown T, template type deduction will deduce what T is:\ntemplate<typename T>\nvoid f(std::initializer_list<T> initList);\nf({ 11, 23, 9 });         // T deduced as int, and initList's\n                          // type is std::initializer_list<int>\nSo the only real difference between auto and template type deduction is that auto\nassumes that a braced initializer represents a std::initializer_list, but template\ntype deduction doesn’t.\nYou might wonder why auto type deduction has a special rule for braced initializers,\nbut template type deduction does not. I wonder this myself. Alas, I have not been able\nto find a convincing explanation. But the rule is the rule, and this means you must\nremember that if you declare a variable using auto and you initialize it with a braced\ninitializer, the deduced type will always be std::initializer_list. It’s especially\nimportant to bear this in mind if you embrace the philosophy of uniform initializa‐\ntion—of enclosing initializing values in braces as a matter of course. A classic mistake\n22 \n| \nItem 2\nwww.it-ebooks.info\n",
      "content_length": 2539,
      "extraction_method": "Direct"
    },
    {
      "page_number": 41,
      "chapter": null,
      "content": "in C++11 programming is accidentally declaring a std::initializer_list variable\nwhen you mean to declare something else. This pitfall is one of the reasons some\ndevelopers put braces around their initializers only when they have to. (When you\nhave to is discussed in Item 7.)\nFor C++11, this is the full story, but for C++14, the tale continues. C++14 permits\nauto to indicate that a function’s return type should be deduced (see Item 3), and\nC++14 lambdas may use auto in parameter declarations. However, these uses of\nauto employ template type deduction, not auto type deduction. So a function with an\nauto return type that returns a braced initializer won’t compile:\nauto createInitList()\n{\n  return { 1, 2, 3 };         // error: can't deduce type\n}                             // for { 1, 2, 3 }\nThe same is true when auto is used in a parameter type specification in a C++14\nlambda:\nstd::vector<int> v;\n…\nauto resetV =\n  [&v](const auto& newValue) { v = newValue; };     // C++14\n…\nresetV({ 1, 2, 3 });          // error! can't deduce type\n                              // for { 1, 2, 3 }\nThings to Remember\n• auto type deduction is usually the same as template type deduction, but auto\ntype deduction assumes that a braced initializer represents a std::initial\nizer_list, and template type deduction doesn’t.\n• auto in a function return type or a lambda parameter implies template type\ndeduction, not auto type deduction.\nItem 3: Understand decltype.\ndecltype is an odd creature. Given a name or an expression, decltype tells you the\nname’s or the expression’s type. Typically, what it tells you is exactly what you’d\nItem 2 \n| \n23\nwww.it-ebooks.info\n",
      "content_length": 1658,
      "extraction_method": "Direct"
    },
    {
      "page_number": 42,
      "chapter": null,
      "content": "predict. Occasionally however, it provides results that leave you scratching your head\nand turning to reference works or online Q&A sites for revelation.\nWe’ll begin with the typical cases—the ones harboring no surprises. In contrast to\nwhat happens during type deduction for templates and auto (see Items 1 and 2),\ndecltype typically parrots back the exact type of the name or expression you give it:\nconst int i = 0;           // decltype(i) is const int\nbool f(const Widget& w);   // decltype(w) is const Widget&\n                           // decltype(f) is bool(const Widget&)\nstruct Point {\n  int x, y;                // decltype(Point::x) is int\n};                         // decltype(Point::y) is int\nWidget w;                  // decltype(w) is Widget\nif (f(w)) …                // decltype(f(w)) is bool\ntemplate<typename T>       // simplified version of std::vector\nclass vector {\npublic:\n  …\n  T& operator[](std::size_t index);\n  …\n};\nvector<int> v;             // decltype(v) is vector<int>\n…\nif (v[0] == 0) …           // decltype(v[0]) is int&\nSee? No surprises.\nIn C++11, perhaps the primary use for decltype is declaring function templates\nwhere the function’s return type depends on its parameter types. For example, sup‐\npose we’d like to write a function that takes a container that supports indexing via\nsquare brackets (i.e., the use of “[]”) plus an index, then authenticates the user before\nreturning the result of the indexing operation. The return type of the function should\nbe the same as the type returned by the indexing operation.\noperator[] on a container of objects of type T typically returns a T&. This is the case\nfor std::deque, for example, and it’s almost always the case for std::vector. For\nstd::vector<bool>, however, operator[] does not return a bool&. Instead, it\nreturns a brand new object. The whys and hows of this situation are explored in\n24 \n| \nItem 3\nwww.it-ebooks.info\n",
      "content_length": 1921,
      "extraction_method": "Direct"
    },
    {
      "page_number": 43,
      "chapter": null,
      "content": "Item 6, but what’s important here is that the type returned by a container’s opera\ntor[] depends on the container.\ndecltype makes it easy to express that. Here’s a first cut at the template we’d like to\nwrite, showing the use of decltype to compute the return type. The template needs a\nbit of refinement, but we’ll defer that for now:\ntemplate<typename Container, typename Index>    // works, but\nauto authAndAccess(Container& c, Index i)       // requires\n  -> decltype(c[i])                             // refinement\n{\n  authenticateUser();\n  return c[i];\n}\nThe use of auto before the function name has nothing to do with type deduction.\nRather, it indicates that C++11’s trailing return type syntax is being used, i.e., that the\nfunction’s return type will be declared following the parameter list (after the “->”). A\ntrailing return type has the advantage that the function’s parameters can be used in\nthe specification of the return type. In authAndAccess, for example, we specify the\nreturn type using c and i. If we were to have the return type precede the function\nname in the conventional fashion, c and i would be unavailable, because they would\nnot have been declared yet.\nWith this declaration, authAndAccess returns whatever type operator[] returns\nwhen applied to the passed-in container, exactly as we desire.\nC++11 permits return types for single-statement lambdas to be deduced, and C++14\nextends this to both all lambdas and all functions, including those with multiple\nstatements. In the case of authAndAccess, that means that in C++14 we can omit the\ntrailing return type, leaving just the leading auto. With that form of declaration,\nauto does mean that type deduction will take place. In particular, it means that com‐\npilers will deduce the function’s return type from the function’s implementation:\ntemplate<typename Container, typename Index>    // C++14;\nauto authAndAccess(Container& c, Index i)       // not quite\n{                                               // correct\n  authenticateUser();\n  return c[i];                  // return type deduced from c[i]\n}\nItem 2 explains that for functions with an auto return type specification, compilers\nemploy template type deduction. In this case, that’s problematic. As we’ve discussed,\noperator[] for most containers-of-T returns a T&, but Item 1 explains that during\nItem 3 \n| \n25\nwww.it-ebooks.info\n",
      "content_length": 2377,
      "extraction_method": "Direct"
    },
    {
      "page_number": 44,
      "chapter": null,
      "content": "template type deduction, the reference-ness of an initializing expression is ignored.\nConsider what that means for this client code:\nstd::deque<int> d;\n…\nauthAndAccess(d, 5) = 10;  // authenticate user, return d[5],\n                           // then assign 10 to it;\n                           // this won't compile!\nHere, d[5] returns an int&, but auto return type deduction for authAndAccess will\nstrip off the reference, thus yielding a return type of int. That int, being the return\nvalue of a function, is an rvalue, and the code above thus attempts to assign 10 to an\nrvalue int. That’s forbidden in C++, so the code won’t compile.\nTo get authAndAccess to work as we’d like, we need to use decltype type deduction\nfor its return type, i.e., to specify that authAndAccess should return exactly the same\ntype that the expression c[i] returns. The guardians of C++, anticipating the need to\nuse decltype type deduction rules in some cases where types are inferred, make this\npossible in C++14 through the decltype(auto) specifier. What may initially seem\ncontradictory (decltype and auto?) actually makes perfect sense: auto specifies that\nthe type is to be deduced, and decltype says that decltype rules should be used\nduring the deduction. We can thus write authAndAccess like this:\ntemplate<typename Container, typename Index>   // C++14; works,\ndecltype(auto)                                 // but still\nauthAndAccess(Container& c, Index i)           // requires\n{                                              // refinement\n  authenticateUser();\n  return c[i];\n}\nNow authAndAccess will truly return whatever c[i] returns. In particular, for the\ncommon case where c[i] returns a T&, authAndAccess will also return a T&, and in\nthe uncommon case where c[i] returns an object, authAndAccess will return an\nobject, too.\nThe use of decltype(auto) is not limited to function return types. It can also be\nconvenient for declaring variables when you want to apply the decltype type deduc‐\ntion rules to the initializing expression:\nWidget w;\nconst Widget& cw = w;\nauto myWidget1 = cw;             // auto type deduction:\n26 \n| \nItem 3\nwww.it-ebooks.info\n",
      "content_length": 2155,
      "extraction_method": "Direct"
    },
    {
      "page_number": 45,
      "chapter": null,
      "content": "                                 // myWidget1's type is Widget\ndecltype(auto) myWidget2 = cw;   // decltype type deduction:\n                                 // myWidget2's type is\n                                 //   const Widget&\nBut two things are bothering you, I know. One is the refinement to authAndAccess I\nmentioned, but have not yet described. Let’s address that now.\nLook again at the declaration for the C++14 version of authAndAccess:\ntemplate<typename Container, typename Index>\ndecltype(auto) authAndAccess(Container& c, Index i);\nThe container is passed by lvalue-reference-to-non-const, because returning a refer‐\nence to an element of the container permits clients to modify that container. But this\nmeans it’s not possible to pass rvalue containers to this function. Rvalues can’t bind\nto lvalue references (unless they’re lvalue-references-to-const, which is not the case\nhere).\nAdmittedly, passing an rvalue container to authAndAccess is an edge case. An rvalue\ncontainer, being a temporary object, would typically be destroyed at the end of the\nstatement containing the call to authAndAccess, and that means that a reference to\nan element in that container (which is typically what authAndAccess would return)\nwould dangle at the end of the statement that created it. Still, it could make sense to\npass a temporary object to authAndAccess. A client might simply want to make a\ncopy of an element in the temporary container, for example:\nstd::deque<std::string> makeStringDeque();   // factory function\n// make copy of 5th element of deque returned\n// from makeStringDeque\nauto s = authAndAccess(makeStringDeque(), 5);\nSupporting such use means we need to revise the declaration for authAndAccess to\naccept both lvalues and rvalues. Overloading would work (one overload would\ndeclare an lvalue reference parameter, the other an rvalue reference parameter), but\nthen we’d have two functions to maintain. A way to avoid that is to have authAndAc\ncess employ a reference parameter that can bind to lvalues and rvalues, and Item 24\nexplains that that’s exactly what universal references do. authAndAccess can there‐\nfore be declared like this:\ntemplate<typename Container, typename Index>    // c is now a\ndecltype(auto) authAndAccess(Container&& c,     // universal\n                             Index i);          // reference\nItem 3 \n| \n27\nwww.it-ebooks.info\n",
      "content_length": 2378,
      "extraction_method": "Direct"
    },
    {
      "page_number": 46,
      "chapter": null,
      "content": "In this template, we don’t know what type of container we’re operating on, and that\nmeans we’re equally ignorant of the type of index objects it uses. Employing pass-by-\nvalue for objects of an unknown type generally risks the performance hit of unneces‐\nsary copying, the behavioral problems of object slicing (see Item 41), and the sting of\nour coworkers’ derision, but in the case of container indices, following the example of\nthe Standard Library for index values (e.g., in operator[] for std::string,\nstd::vector, and std::deque) seems reasonable, so we’ll stick with pass-by-value\nfor them.\nHowever, we need to update the template’s implementation to bring it into accord\nwith Item 25’s admonition to apply std::forward to universal references:\ntemplate<typename Container, typename Index>       // final\ndecltype(auto)                                     // C++14\nauthAndAccess(Container&& c, Index i)              // version\n{\n  authenticateUser();\n  return std::forward<Container>(c)[i];\n}\nThis should do everything we want, but it requires a C++14 compiler. If you don’t\nhave one, you’ll need to use the C++11 version of the template. It’s the same as its\nC++14 counterpart, except that you have to specify the return type yourself:\ntemplate<typename Container, typename Index>       // final\nauto                                               // C++11\nauthAndAccess(Container&& c, Index i)              // version\n-> decltype(std::forward<Container>(c)[i])\n{\n  authenticateUser();\n  return std::forward<Container>(c)[i];\n}\nThe other issue that’s likely to be nagging at you is my remark at the beginning of this\nItem that decltype almost always produces the type you expect, that it rarely sur‐\nprises. Truth be told, you’re unlikely to encounter these exceptions to the rule unless\nyou’re a heavy-duty library implementer.\nTo fully understand decltype’s behavior, you’ll have to familiarize yourself with a\nfew special cases. Most of these are too obscure to warrant discussion in a book like\nthis, but looking at one lends insight into decltype as well as its use.\nApplying decltype to a name yields the declared type for that name. Names are\nlvalue expressions, but that doesn’t affect decltype’s behavior. For lvalue expressions\nmore complicated than names, however, decltype ensures that the type reported is\n28 \n| \nItem 3\nwww.it-ebooks.info\n",
      "content_length": 2359,
      "extraction_method": "Direct"
    },
    {
      "page_number": 47,
      "chapter": null,
      "content": "always an lvalue reference. That is, if an lvalue expression other than a name has type\nT, decltype reports that type as T&. This seldom has any impact, because the type of\nmost lvalue expressions inherently includes an lvalue reference qualifier. Functions\nreturning lvalues, for example, always return lvalue references.\nThere is an implication of this behavior that is worth being aware of, however. In\nint x = 0;\nx is the name of a variable, so decltype(x) is int. But wrapping the name x in\nparentheses—“(x)”—yields an expression more complicated than a name. Being a\nname, x is an lvalue, and C++ defines the expression (x) to be an lvalue, too.\ndecltype((x)) is therefore int&. Putting parentheses around a name can change\nthe type that decltype reports for it!\nIn C++11, this is little more than a curiosity, but in conjunction with C++14’s sup‐\nport for decltype(auto), it means that a seemingly trivial change in the way you\nwrite a return statement can affect the deduced type for a function:\ndecltype(auto) f1()\n{\n  int x = 0;\n  …\n  return x;        // decltype(x) is int, so f1 returns int\n}\ndecltype(auto) f2()\n{\n  int x = 0;\n  …\n  return (x);      // decltype((x)) is int&, so f2 returns int&\n}\nNote that not only does f2 have a different return type from f1, it’s also returning a\nreference to a local variable! That’s the kind of code that puts you on the express train\nto undefined behavior—a train you certainly don’t want to be on.\nThe primary lesson is to pay very close attention when using decltype(auto).\nSeemingly insignificant details in the expression whose type is being deduced can\naffect the type that decltype(auto) reports. To ensure that the type being deduced\nis the type you expect, use the techniques described in Item 4.\nAt the same time, don’t lose sight of the bigger picture. Sure, decltype (both alone\nand in conjunction with auto) may occasionally yield type-deduction surprises, but\nthat’s not the normal situation. Normally, decltype produces the type you expect.\nItem 3 \n| \n29\nwww.it-ebooks.info\n",
      "content_length": 2041,
      "extraction_method": "Direct"
    },
    {
      "page_number": 48,
      "chapter": null,
      "content": "This is especially true when decltype is applied to names, because in that case,\ndecltype does just what it sounds like: it reports that name’s declared type.\n \nThings to Remember\n• decltype almost always yields the type of a variable or expression without\nany modifications.\n• For lvalue expressions of type T other than names, decltype always reports a\ntype of T&.\n• C++14 supports decltype(auto), which, like auto, deduces a type from its\ninitializer, but it performs the type deduction using the decltype rules.\nItem 4: Know how to view deduced types.\nThe choice of tools for viewing the results of type deduction is dependent on the\nphase of the software development process where you want the information. We’ll\nexplore three possibilities: getting type deduction information as you edit your code,\ngetting it during compilation, and getting it at runtime.\nIDE Editors\nCode editors in IDEs often show the types of program entities (e.g., variables, param‐\neters, functions, etc.) when you do something like hover your cursor over the entity.\nFor example, given this code,      \nconst int theAnswer = 42;\nauto x = theAnswer;\nauto y = &theAnswer;\nan IDE editor would likely show that x’s deduced type was int and y’s was const\nint*.\nFor this to work, your code must be in a more or less compilable state, because what\nmakes it possible for the IDE to offer this kind of information is a C++ compiler (or\nat least the front end of one) running inside the IDE. If that compiler can’t make\nenough sense of your code to parse it and perform type deduction, it can’t show you\nwhat types it deduced.\nFor simple types like int, information from IDEs is generally fine. As we’ll see soon,\nhowever, when more complicated types are involved, the information displayed by\nIDEs may not be particularly helpful.\n30 \n| \nItem 3\nwww.it-ebooks.info\n",
      "content_length": 1836,
      "extraction_method": "Direct"
    },
    {
      "page_number": 49,
      "chapter": null,
      "content": "Compiler Diagnostics\nAn effective way to get a compiler to show a type it has deduced is to use that type in\na way that leads to compilation problems. The error message reporting the problem\nis virtually sure to mention the type that’s causing it.\nSuppose, for example, we’d like to see the types that were deduced for x and y in the\nprevious example. We first declare a class template that we don’t define. Something\nlike this does nicely:\ntemplate<typename T>       // declaration only for TD;\nclass TD;                  // TD == \"Type Displayer\"\nAttempts to instantiate this template will elicit an error message, because there’s no\ntemplate definition to instantiate. To see the types for x and y, just try to instantiate\nTD with their types:\nTD<decltype(x)> xType;     // elicit errors containing\nTD<decltype(y)> yType;     // x's and y's types\nI use variable names of the form variableNameType, because they tend to yield error\nmessages that help me find the information I’m looking for. For the code above, one\nof my compilers issues diagnostics reading, in part, as follows (I’ve highlighted the\ntype information we’re after):\nerror: aggregate 'TD<int> xType' has incomplete type and\n    cannot be defined\nerror: aggregate 'TD<const int *> yType' has incomplete type\n    and cannot be defined\nA different compiler provides the same information, but in a different form:\nerror: 'xType' uses undefined class 'TD<int>'\nerror: 'yType' uses undefined class 'TD<const int *>'\nFormatting differences aside, all the compilers I’ve tested produce error messages\nwith useful type information when this technique is employed.\nRuntime Output\nThe printf approach to displaying type information (not that I’m recommending\nyou use printf) can’t be employed until runtime, but it offers full control over the\nformatting of the output. The challenge is to create a textual representation of the\ntype you care about that is suitable for display. “No sweat,” you’re thinking, “it’s\ntypeid and std::type_info::name to the rescue.” In our continuing quest to see\nthe types deduced for x and y, you may figure we can write this:\nItem 4 \n| \n31\nwww.it-ebooks.info\n",
      "content_length": 2148,
      "extraction_method": "Direct"
    },
    {
      "page_number": 50,
      "chapter": null,
      "content": "std::cout << typeid(x).name() << '\\n';    // display types for\nstd::cout << typeid(y).name() << '\\n';    // x and y\nThis approach relies on the fact that invoking typeid on an object such as x or y\nyields a std::type_info object, and std::type_info has a member function, name,\nthat produces a C-style string (i.e., a const char*) representation of the name of the\ntype.\nCalls to std::type_info::name are not guaranteed to return anything sensible, but\nimplementations try to be helpful. The level of helpfulness varies. The GNU and\nClang compilers report that the type of x is “i”, and the type of y is “PKi”, for exam‐\nple. These results make sense once you learn that, in output from these compilers, “i”\nmeans “int” and “PK” means “pointer to konst const.” (Both compilers support a\ntool, c++filt, that decodes such “mangled” types.) Microsoft’s compiler produces\nless cryptic output: “int” for x and “int const *” for y.\nBecause these results are correct for the types of x and y, you might be tempted to\nview the type-reporting problem as solved, but let’s not be hasty. Consider a more\ncomplex example:\ntemplate<typename T>                 // template function to\nvoid f(const T& param);              // be called\nstd::vector<Widget> createVec();     // factory function\nconst auto vw = createVec();         // init vw w/factory return\nif (!vw.empty()) {\n  f(&vw[0]);                         // call f\n  …\n}\nThis code, which involves a user-defined type (Widget), an STL container (std::vec\ntor), and an auto variable (vw), is more representative of the situations where you\nmight want some visibility into the types your compilers are deducing. For example,\nit’d be nice to know what types are inferred for the template type parameter T and the\nfunction parameter param in f.\nLoosing typeid on the problem is straightforward. Just add some code to f to display\nthe types you’d like to see: \ntemplate<typename T>\nvoid f(const T& param)\n{\n  using std::cout;\n32 \n| \nItem 4\nwww.it-ebooks.info\n",
      "content_length": 1997,
      "extraction_method": "Direct"
    },
    {
      "page_number": 51,
      "chapter": null,
      "content": "  cout << \"T =     \" << typeid(T).name() << '\\n';     // show T\n  cout << \"param = \" << typeid(param).name() << '\\n'; // show\n  …                                                   // param's\n}                                                     // type\nExecutables produced by the GNU and Clang compilers produce this output:\nT =     PK6Widget\nparam = PK6Widget\nWe already know that for these compilers, PK means “pointer to const,” so the only\nmystery is the number 6. That’s simply the number of characters in the class name\nthat follows (Widget). So these compilers tell us that both T and param are of type\nconst Widget*.\nMicrosoft’s compiler concurs:\nT =     class Widget const *\nparam = class Widget const *\nThree independent compilers producing the same information suggests that the\ninformation is accurate. But look more closely. In the template f, param’s declared\ntype is const T&. That being the case, doesn’t it seem odd that T and param have the\nsame type? If T were int, for example, param’s type should be const int&—not the\nsame type at all.\nSadly, the results of std::type_info::name are not reliable. In this case, for exam‐\nple, the type that all three compilers report for param are incorrect. Furthermore,\nthey’re essentially required to be incorrect, because the specification for std::\ntype_info::name mandates that the type be treated as if it had been passed to a tem‐\nplate function as a by-value parameter. As Item 1 explains, that means that if the type\nis a reference, its reference-ness is ignored, and if the type after reference removal is\nconst (or volatile), its constness (or volatileness) is also ignored. That’s why\nparam’s type—which is const Widget * const &—is reported as const Widget*.\nFirst the type’s reference-ness is removed, and then the constness of the resulting\npointer is eliminated.\nEqually sadly, the type information displayed by IDE editors is also not reliable—or\nat least not reliably useful. For this same example, one IDE editor I know reports T’s\ntype as (I am not making this up):\nconst\nstd::_Simple_types<std::_Wrap_alloc<std::_Vec_base_types<Widget,\nstd::allocator<Widget> >::_Alloc>::value_type>::value_type *\nThe same IDE editor shows param’s type as:\nItem 4 \n| \n33\nwww.it-ebooks.info\n",
      "content_length": 2251,
      "extraction_method": "Direct"
    },
    {
      "page_number": 52,
      "chapter": null,
      "content": "const std::_Simple_types<...>::value_type *const &\nThat’s less intimidating than the type for T, but the “...” in the middle is confusing\nuntil you realize that it’s the IDE editor’s way of saying “I’m omitting all that stuff\nthat’s part of T’s type.” With any luck, your development environment does a better\njob on code like this.\nIf you’re more inclined to rely on libraries than luck, you’ll be pleased to know that\nwhere std::type_info::name and IDEs may fail, the Boost TypeIndex library\n(often written as Boost.TypeIndex) is designed to succeed. The library isn’t part of\nStandard C++, but neither are IDEs or templates like TD. Furthermore, the fact that\nBoost libraries (available at boost.com) are cross-platform, open source, and available\nunder a license designed to be palatable to even the most paranoid corporate legal\nteam means that code using Boost libraries is nearly as portable as code relying on the\nStandard Library.\nHere’s how our function f can produce accurate type information using Boost.Type‐\nIndex:\n#include <boost/type_index.hpp>\ntemplate<typename T>\nvoid f(const T& param)\n{\n  using std::cout;\n  using boost::typeindex::type_id_with_cvr;\n  // show T\n  cout << \"T =     \"\n       << type_id_with_cvr<T>().pretty_name()\n       << '\\n';\n  // show param's type\n  cout << \"param = \"\n       << type_id_with_cvr<decltype(param)>().pretty_name()\n       << '\\n';\n  …\n}\nThe way this works is that the function template boost::typeindex::\ntype_id_with_cvr takes a type argument (the type about which we want informa‐\ntion) and doesn’t remove const, volatile, or reference qualifiers (hence the\n“with_cvr” in the template name). The result is a boost::typeindex::type_index\nobject, whose pretty_name member function produces a std::string containing a\nhuman-friendly representation of the type.\n34 \n| \nItem 4\nwww.it-ebooks.info\n",
      "content_length": 1847,
      "extraction_method": "Direct"
    },
    {
      "page_number": 53,
      "chapter": null,
      "content": "With this implementation for f, consider again the call that yields incorrect type\ninformation for param when typeid is used:\nstd::vector<Widget> createVec();     // factory function\nconst auto vw = createVec();         // init vw w/factory return\nif (!vw.empty()) {\n  f(&vw[0]);                         // call f\n  …\n}\nUnder compilers from GNU and Clang, Boost.TypeIndex produces this (accurate)\noutput:\nT =     Widget const*\nparam = Widget const* const&\nResults under Microsoft’s compiler are essentially the same:\nT =     class Widget const *\nparam = class Widget const * const &\nSuch near-uniformity is nice, but it’s important to remember that IDE editors, com‐\npiler error messages, and libraries like Boost.TypeIndex are merely tools you can use\nto help you figure out what types your compilers are deducing. All can be helpful, but\nat the end of the day, there’s no substitute for understanding the type deduction\ninformation in Items 1–3.\nThings to Remember\n• Deduced types can often be seen using IDE editors, compiler error messages,\nand the Boost TypeIndex library.\n• The results of some tools may be neither helpful nor accurate, so an under‐\nstanding of C++’s type deduction rules remains essential.\nItem 4 \n| \n35\nwww.it-ebooks.info\n",
      "content_length": 1247,
      "extraction_method": "Direct"
    },
    {
      "page_number": 54,
      "chapter": null,
      "content": "www.it-ebooks.info\n",
      "content_length": 19,
      "extraction_method": "Direct"
    },
    {
      "page_number": 55,
      "chapter": null,
      "content": "CHAPTER 2\nauto\nIn concept, auto is as simple as simple can be, but it’s more subtle than it looks.\nUsing it saves typing, sure, but it also prevents correctness and performance issues\nthat can bedevil manual type declarations. Furthermore, some of auto’s type deduc‐\ntion results, while dutifully conforming to the prescribed algorithm, are, from the\nperspective of a programmer, just wrong. When that’s the case, it’s important to\nknow how to guide auto to the right answer, because falling back on manual type\ndeclarations is an alternative that’s often best avoided.\nThis brief chapter covers all of auto’s ins and outs.\nItem 5: Prefer auto to explicit type declarations.\nAh, the simple joy of\nint x;\nWait. Damn. I forgot to initialize x, so its value is indeterminate. Maybe. It might\nactually be initialized to zero. Depends on the context. Sigh.\nNever mind. Let’s move on to the simple joy of declaring a local variable to be initial‐\nized by dereferencing an iterator:\ntemplate<typename It>    // algorithm to dwim (\"do what I mean\")\nvoid dwim(It b, It e)    // for all elements in range from\n{                        // b to e\n  while (b != e) {\n    typename std::iterator_traits<It>::value_type\n      currValue = *b;\n    …\n37\nwww.it-ebooks.info\n",
      "content_length": 1254,
      "extraction_method": "Direct"
    },
    {
      "page_number": 56,
      "chapter": null,
      "content": "  }\n}\nUgh. “typename std::iterator_traits<It>::value_type” to express the type of\nthe value pointed to by an iterator? Really? I must have blocked out the memory of\nhow much fun that is. Damn. Wait—didn’t I already say that?\nOkay, simple joy (take three): the delight of declaring a local variable whose type is\nthat of a closure. Oh, right. The type of a closure is known only to the compiler,\nhence can’t be written out. Sigh. Damn.\nDamn, damn, damn! Programming in C++ is not the joyous experience it should be!\nWell, it didn’t used to be. But as of C++11, all these issues go away, courtesy of auto.\nauto variables have their type deduced from their initializer, so they must be initial‐\nized. That means you can wave goodbye to a host of uninitialized variable problems\nas you speed by on the modern C++ superhighway:\nint x1;                     // potentially uninitialized\nauto x2;                    // error! initializer required\nauto x3 = 0;                // fine, x's value is well-defined\nSaid highway lacks the potholes associated with declaring a local variable whose value\nis that of a dereferenced iterator:\ntemplate<typename It>       // as before\nvoid dwim(It b, It e)\n{\n  while (b != e) {\n    auto currValue = *b;\n    …\n  }\n}\nAnd because auto uses type deduction (see Item 2), it can represent types known\nonly to compilers:\nauto derefUPLess =                        // comparison func.\n  [](const std::unique_ptr<Widget>& p1,   // for Widgets\n     const std::unique_ptr<Widget>& p2)   // pointed to by\n  { return *p1 < *p2; };                  // std::unique_ptrs\nVery cool. In C++14, the temperature drops further, because parameters to lambda\nexpressions may involve auto:\nauto derefLess =                          // C++14 comparison\n  [](const auto& p1,                      // function for\n38 \n| \nItem 5\nwww.it-ebooks.info\n",
      "content_length": 1849,
      "extraction_method": "Direct"
    },
    {
      "page_number": 57,
      "chapter": null,
      "content": "     const auto& p2)                      // values pointed\n  { return *p1 < *p2; };                  // to by anything\n                                          // pointer-like\nCoolness notwithstanding, perhaps you’re thinking we don’t really need auto to\ndeclare a variable that holds a closure, because we can use a std::function object.\nIt’s true, we can, but possibly that’s not what you were thinking. And maybe now\nyou’re thinking “What’s a std::function object?” So let’s clear that up.\nstd::function is a template in the C++11 Standard Library that generalizes the idea\nof a function pointer. Whereas function pointers can point only to functions, how‐\never, std::function objects can refer to any callable object, i.e., to anything that can\nbe invoked like a function. Just as you must specify the type of function to point to\nwhen you create a function pointer (i.e., the signature of the functions you want to\npoint to), you must specify the type of function to refer to when you create a\nstd::function object. You do that through std::function’s template parameter.\nFor example, to declare a std::function object named func that could refer to any\ncallable object acting as if it had this signature,\nbool(const std::unique_ptr<Widget>&,  // C++11 signature for\n     const std::unique_ptr<Widget>&)  // std::unique_ptr<Widget>\n                                      // comparison function\nyou’d write this:\nstd::function<bool(const std::unique_ptr<Widget>&,\n                   const std::unique_ptr<Widget>&)> func;\nBecause lambda expressions yield callable objects, closures can be stored in\nstd::function objects. That means we could declare the C++11 version of derefUP\nLess without using auto as follows:\nstd::function<bool(const std::unique_ptr<Widget>&,\n                   const std::unique_ptr<Widget>&)>\n  derefUPLess = [](const std::unique_ptr<Widget>& p1,\n                   const std::unique_ptr<Widget>& p2)\n                  { return *p1 < *p2; };\nIt’s important to recognize that even setting aside the syntactic verbosity and need to\nrepeat the parameter types, using std::function is not the same as using auto. An\nauto-declared variable holding a closure has the same type as the closure, and as such\nit uses only as much memory as the closure requires. The type of a std::function-\ndeclared variable holding a closure is an instantiation of the std::function tem‐\nplate, and that has a fixed size for any given signature. This size may not be adequate\nfor the closure it’s asked to store, and when that’s the case, the std::function con‐\nstructor will allocate heap memory to store the closure. The result is that the\nItem 5 \n| \n39\nwww.it-ebooks.info\n",
      "content_length": 2680,
      "extraction_method": "Direct"
    },
    {
      "page_number": 58,
      "chapter": null,
      "content": "std::function object typically uses more memory than the auto-declared object.\nAnd, thanks to implementation details that restrict inlining and yield indirect func‐\ntion calls, invoking a closure via a std::function object is almost certain to be\nslower than calling it via an auto-declared object. In other words, the std::func\ntion approach is generally bigger and slower than the auto approach, and it may\nyield out-of-memory exceptions, too. Plus, as you can see in the examples above,\nwriting “auto” is a whole lot less work than writing the type of the std::function\ninstantiation. In the competition between auto and std::function for holding a\nclosure, it’s pretty much game, set, and match for auto. (A similar argument can be\nmade for auto over std::function for holding the result of calls to std::bind, but\nin Item 34, I do my best to convince you to use lambdas instead of std::bind, any‐\nway.)\nThe advantages of auto extend beyond the avoidance of uninitialized variables, ver‐\nbose variable declarations, and the ability to directly hold closures. One is the ability\nto avoid what I call problems related to “type shortcuts.” Here’s something you’ve\nprobably seen—possibly even written:\nstd::vector<int> v;\n…\nunsigned sz = v.size();\nThe official return type of v.size() is std::vector<int>::size_type, but few\ndevelopers are aware of that. std::vector<int>::size_type is specified to be an\nunsigned integral type, so a lot of programmers figure that unsigned is good enough\nand write code such as the above. This can have some interesting consequences. On\n32-bit Windows, for example, both unsigned and std::vector<int>::size_type\nare the same size, but on 64-bit Windows, unsigned is 32 bits, while std::vec\ntor<int>::size_type is 64 bits. This means that code that works under 32-bit\nWindows may behave incorrectly under 64-bit Windows, and when porting your\napplication from 32 to 64 bits, who wants to spend time on issues like that?\nUsing auto ensures that you don’t have to:\nauto sz = v.size();  // sz's type is std::vector<int>::size_type\nStill unsure about the wisdom of using auto? Then consider this code:\nstd::unordered_map<std::string, int> m;\n…\nfor (const std::pair<std::string, int>& p : m)\n{\n  …                   // do something with p\n}\n40 \n| \nItem 5\nwww.it-ebooks.info\n",
      "content_length": 2302,
      "extraction_method": "Direct"
    },
    {
      "page_number": 59,
      "chapter": null,
      "content": "This looks perfectly reasonable, but there’s a problem. Do you see it?\nRecognizing what’s amiss requires remembering that the key part of a std::unor\ndered_map is const, so the type of std::pair in the hash table (which is what a\nstd::unordered_map is) isn’t std::pair<std::string, int>, it’s std::pair\n<const std::string, int>. But that’s not the type declared for the variable p in the\nloop above. As a result, compilers will strive to find a way to convert\nstd::pair<const std::string, int> objects (i.e., what’s in the hash table) to\nstd::pair<std::string, int> objects (the declared type for p). They’ll succeed by\ncreating a temporary object of the type that p wants to bind to by copying each object\nin m, then binding the reference p to that temporary object. At the end of each loop\niteration, the temporary object will be destroyed. If you wrote this loop, you’d likely\nbe surprised by this behavior, because you’d almost certainly intend to simply bind\nthe reference p to each element in m.\nSuch unintentional type mismatches can be autoed away:\nfor (const auto& p : m)\n{\n  …                             // as before\n}\nThis is not only more efficient, it’s also easier to type. Furthermore, this code has the\nvery attractive characteristic that if you take p’s address, you’re sure to get a pointer\nto an element within m. In the code not using auto, you’d get a pointer to a tempo‐\nrary object—an object that would be destroyed at the end of the loop iteration.\nThe last two examples—writing unsigned when you should have written std::vec\ntor<int>::size_type and writing std::pair<std::string, int> when you\nshould have written std::pair<const std::string, int>—demonstrate how\nexplicitly specifying types can lead to implicit conversions that you neither want nor\nexpect. If you use auto as the type of the target variable, you need not worry about\nmismatches between the type of variable you’re declaring and the type of the expres‐\nsion used to initialize it.\nThere are thus several reasons to prefer auto over explicit type declarations. Yet auto\nisn’t perfect. The type for each auto variable is deduced from its initializing expres‐\nsion, and some initializing expressions have types that are neither anticipated nor\ndesired. The conditions under which such cases arise, and what you can do about\nthem, are discussed in Items 2 and 6, so I won’t address them here. Instead, I’ll turn\nmy attention to a different concern you may have about using auto in place of tradi‐\ntional type declarations: the readability of the resulting source code.\nItem 5 \n| \n41\nwww.it-ebooks.info\n",
      "content_length": 2592,
      "extraction_method": "Direct"
    },
    {
      "page_number": 60,
      "chapter": null,
      "content": "First, take a deep breath and relax. auto is an option, not a mandate. If, in your pro‐\nfessional judgment, your code will be clearer or more maintainable or in some other\nway better by using explicit type declarations, you’re free to continue using them. But\nbear in mind that C++ breaks no new ground in adopting what is generally known in\nthe programming languages world as type inference. Other statically typed procedural\nlanguages (e.g., C#, D, Scala, Visual Basic) have a more or less equivalent feature, to\nsay nothing of a variety of statically typed functional languages (e.g., ML, Haskell,\nOCaml, F#, etc.). In part, this is due to the success of dynamically typed languages\nsuch as Perl, Python, and Ruby, where variables are rarely explicitly typed. The soft‐\nware development community has extensive experience with type inference, and it\nhas demonstrated that there is nothing contradictory about such technology and the\ncreation and maintenance of large, industrial-strength code bases.\nSome developers are disturbed by the fact that using auto eliminates the ability to\ndetermine an object’s type by a quick glance at the source code. However, IDEs’ abil‐\nity to show object types often mitigates this problem (even taking into account the\nIDE type-display issues mentioned in Item 4), and, in many cases, a somewhat\nabstract view of an object’s type is just as useful as the exact type. It often suffices, for\nexample, to know that an object is a container or a counter or a smart pointer,\nwithout knowing exactly what kind of container, counter, or smart pointer it is.\nAssuming well-chosen variable names, such abstract type information should almost\nalways be at hand.\nThe fact of the matter is that writing types explicitly often does little more than intro‐\nduce opportunities for subtle errors, either in correctness or efficiency or both. Fur‐\nthermore, auto types automatically change if the type of their initializing expression\nchanges, and that means that some refactorings are facilitated by the use of auto. For\nexample, if a function is declared to return an int, but you later decide that a long\nwould be better, the calling code automatically updates itself the next time you com‐\npile if the results of calling the function are stored in auto variables. If the results are\nstored in variables explicitly declared to be int, you’ll need to find all the call sites so\nthat you can revise them.\nThings to Remember\n• auto variables must be initialized, are generally immune to type mismatches\nthat can lead to portability or efficiency problems, can ease the process of\nrefactoring, and typically require less typing than variables with explicitly\nspecified types.\n• auto-typed variables are subject to the pitfalls described in Items 2 and 6.\n42 \n| \nItem 5\nwww.it-ebooks.info\n",
      "content_length": 2808,
      "extraction_method": "Direct"
    },
    {
      "page_number": 61,
      "chapter": null,
      "content": "Item 6: Use the explicitly typed initializer idiom when\nauto deduces undesired types.\nItem 5 explains that using auto to declare variables offers a number of technical\nadvantages over explicitly specifying types, but sometimes auto’s type deduction zigs\nwhen you want it to zag. For example, suppose I have a function that takes a Widget\nand returns a std::vector<bool>, where each bool indicates whether the Widget\noffers a particular feature:\nstd::vector<bool> features(const Widget& w);\nFurther suppose that bit 5 indicates whether the Widget has high priority. We can\nthus write code like this:\nWidget w;\n…\nbool highPriority = features(w)[5];  // is w high priority?\n…\nprocessWidget(w, highPriority);      // process w in accord\n                                     // with its priority\nThere’s nothing wrong with this code. It’ll work fine. But if we make the seemingly\ninnocuous change of replacing the explicit type for highPriority with auto,\nauto highPriority = features(w)[5];  // is w high priority?\nthe situation changes. All the code will continue to compile, but its behavior is no\nlonger predictable:\nprocessWidget(w, highPriority);      // undefined behavior!\nAs the comment indicates, the call to processWidget now has undefined behavior.\nBut why? The answer is likely to be surprising. In the code using auto, the type of\nhighPriority is no longer bool. Though std::vector<bool> conceptually holds\nbools, operator[] for std::vector<bool> doesn’t return a reference to an element\nof the container (which is what std::vector::operator[] returns for every type\nexcept bool). Instead, it returns an object of type std::vector<bool>::reference\n(a class nested inside std::vector<bool>).\nstd::vector<bool>::reference exists because std::vector<bool> is specified to\nrepresent its bools in packed form, one bit per bool. That creates a problem for\nstd::vector<bool>’s operator[], because operator[] for std::vector<T> is\nsupposed to return a T&, but C++ forbids references to bits. Not being able to return a\nItem 6 \n| \n43\nwww.it-ebooks.info\n",
      "content_length": 2053,
      "extraction_method": "Direct"
    },
    {
      "page_number": 62,
      "chapter": null,
      "content": "bool&, operator[] for std::vector<bool> returns an object that acts like a bool&.\nFor this act to succeed, std::vector<bool>::reference objects must be usable in\nessentially all contexts where bool&s can be. Among the features in std::vec\ntor<bool>::reference that make this work is an implicit conversion to bool. (Not\nto bool&, to bool. To explain the full set of techniques used by std::vec\ntor<bool>::reference to emulate the behavior of a bool& would take us too far\nafield, so I’ll simply remark that this implicit conversion is only one stone in a larger\nmosaic.)\nWith this information in mind, look again at this part of the original code:\nbool highPriority = features(w)[5];  // declare highPriority's\n                                     // type explicitly\nHere, features returns a std::vector<bool> object, on which operator[] is\ninvoked. operator[] returns a std::vector<bool>::reference object, which is\nthen implicitly converted to the bool that is needed to initialize highPriority. high\nPriority thus ends up with the value of bit 5 in the std::vector<bool> returned\nby features, just like it’s supposed to.\nContrast that with what happens in the auto-ized declaration for highPriority:\nauto highPriority = features(w)[5];  // deduce highPriority's\n                                     // type\nAgain, features returns a std::vector<bool> object, and, again, operator[] is\ninvoked on it. operator[] continues to return a std::vector<bool>::reference\nobject, but now there’s a change, because auto deduces that as the type of highPrior\nity. highPriority doesn’t have the value of bit 5 of the std::vector<bool>\nreturned by features at all.\nThe value it does have depends on how std::vector<bool>::reference is imple‐\nmented. One implementation is for such objects to contain a pointer to the machine\nword holding the referenced bit, plus the offset into that word for that bit. Consider\nwhat that means for the initialization of highPriority, assuming that such a\nstd::vector<bool>::reference implementation is in place.\nThe call to features returns a temporary std::vector<bool> object. This object\nhas no name, but for purposes of this discussion, I’ll call it temp. operator[] is\ninvoked on temp, and the std::vector<bool>::reference it returns contains a\npointer to a word in the data structure holding the bits that are managed by temp,\nplus the offset into that word corresponding to bit 5. highPriority is a copy of this\nstd::vector<bool>::reference object, so highPriority, too, contains a pointer\nto a word in temp, plus the offset corresponding to bit 5. At the end of the statement,\n44 \n| \nItem 6\nwww.it-ebooks.info\n",
      "content_length": 2641,
      "extraction_method": "Direct"
    },
    {
      "page_number": 63,
      "chapter": null,
      "content": "temp is destroyed, because it’s a temporary object. Therefore, highPriority contains\na dangling pointer, and that’s the cause of the undefined behavior in the call to proc\nessWidget:\nprocessWidget(w, highPriority);    // undefined behavior!\n                                   // highPriority contains\n                                   // dangling pointer!\nstd::vector<bool>::reference is an example of a proxy class: a class that exists\nfor the purpose of emulating and augmenting the behavior of some other type. Proxy\nclasses are employed for a variety of purposes. std::vector<bool>::reference\nexists to offer the illusion that operator[] for std::vector<bool> returns a refer‐\nence to a bit, for example, and the Standard Library’s smart pointer types (see Chap‐\nter 4) are proxy classes that graft resource management onto raw pointers. The utility\nof proxy classes is well-established. In fact, the design pattern “Proxy” is one of the\nmost longstanding members of the software design patterns Pantheon.\nSome proxy classes are designed to be apparent to clients. That’s the case for\nstd::shared_ptr and std::unique_ptr, for example. Other proxy classes are\ndesigned to act more or less invisibly. std::vector<bool>::reference is an exam‐\nple of such “invisible” proxies, as is its std::bitset compatriot, std::bitset::ref\nerence.\nAlso in that camp are some classes in C++ libraries employing a technique known as\nexpression templates. Such libraries were originally developed to improve the effi‐\nciency of numeric code. Given a class Matrix and Matrix objects m1, m2, m3, and m4,\nfor example, the expression\nMatrix sum = m1 + m2 + m3 + m4;\ncan be computed much more efficiently if operator+ for Matrix objects returns a\nproxy for the result instead of the result itself. That is, operator+ for two Matrix\nobjects would return an object of a proxy class such as Sum<Matrix, Matrix> instead\nof a Matrix object. As was the case with std::vector<bool>::reference and\nbool, there’d be an implicit conversion from the proxy class to Matrix, which would\npermit the initialization of sum from the proxy object produced by the expression on\nthe right side of the “=”. (The type of that object would traditionally encode the entire\ninitialization expression, i.e., be something like Sum<Sum<Sum<Matrix, Matrix>,\nMatrix>, Matrix>. That’s definitely a type from which clients should be shielded.)\nAs a general rule, “invisible” proxy classes don’t play well with auto. Objects of such\nclasses are often not designed to live longer than a single statement, so creating vari‐\nables of those types tends to violate fundamental library design assumptions. That’s\nItem 6 \n| \n45\nwww.it-ebooks.info\n",
      "content_length": 2688,
      "extraction_method": "Direct"
    },
    {
      "page_number": 64,
      "chapter": null,
      "content": "the case with std::vector<bool>::reference, and we’ve seen that violating that\nassumption can lead to undefined behavior.\nYou therefore want to avoid code of this form:\nauto someVar = expression of \"invisible\" proxy class type;\nBut how can you recognize when proxy objects are in use? The software employing\nthem is unlikely to advertise their existence. They’re supposed to be invisible, at least\nconceptually! And once you’ve found them, do you really have to abandon auto and\nthe many advantages Item 5 demonstrates for it?\nLet’s take the how-do-you-find-them question first. Although “invisible” proxy\nclasses are designed to fly beneath programmer radar in day-to-day use, libraries\nusing them often document that they do so. The more you’ve familiarized yourself\nwith the basic design decisions of the libraries you use, the less likely you are to be\nblindsided by proxy usage within those libraries.\nWhere documentation comes up short, header files fill the gap. It’s rarely possible for\nsource code to fully cloak proxy objects. They’re typically returned from functions\nthat clients are expected to call, so function signatures usually reflect their existence. \nHere’s the spec for std::vector<bool>::operator[], for example:\nnamespace std {                            // from C++ Standards\n  template <class Allocator>\n  class vector<bool, Allocator> {\n  public:\n    …\n    class reference { … };\n    reference operator[](size_type n);\n    …\n  };\n}\nAssuming you know that operator[] for std::vector<T> normally returns a T&,\nthe unconventional return type for operator[] in this case is a tip-off that a proxy\nclass is in use. Paying careful attention to the interfaces you’re using can often reveal\nthe existence of proxy classes.\nIn practice, many developers discover the use of proxy classes only when they try to\ntrack down mystifying compilation problems or debug incorrect unit test results.\nRegardless of how you find them, once auto has been determined to be deducing the\ntype of a proxy class instead of the type being proxied, the solution need not involve\nabandoning auto. auto itself isn’t the problem. The problem is that auto isn’t deduc‐\n46 \n| \nItem 6\nwww.it-ebooks.info\n",
      "content_length": 2195,
      "extraction_method": "Direct"
    },
    {
      "page_number": 65,
      "chapter": null,
      "content": "ing the type you want it to deduce. The solution is to force a different type deduction.\nThe way you do that is what I call the explicitly typed initializer idiom.\nThe explicitly typed initializer idiom involves declaring a variable with auto, but\ncasting the initialization expression to the type you want auto to deduce. Here’s how\nit can be used to force highPriority to be a bool, for example:\nauto highPriority = static_cast<bool>(features(w)[5]);\nHere, features(w)[5] continues to return a std::vector<bool>::reference\nobject, just as it always has, but the cast changes the type of the expression to bool,\nwhich auto then deduces as the type for highPriority. At runtime, the std::vec\ntor<bool>::reference object returned from std::vector<bool>::operator[]\nexecutes the conversion to bool that it supports, and as part of that conversion, the\nstill-valid pointer to the std::vector<bool> returned from features is derefer‐\nenced. That avoids the undefined behavior we ran into earlier. The index 5 is then\napplied to the bits pointed to by the pointer, and the bool value that emerges is used\nto initialize highPriority.\nFor the Matrix example, the explicitly typed initializer idiom would look like this:\nauto sum = static_cast<Matrix>(m1 + m2 + m3 + m4);\nApplications of the idiom aren’t limited to initializers yielding proxy class types. It\ncan also be useful to emphasize that you are deliberately creating a variable of a type\nthat is different from that generated by the initializing expression. For example, sup‐\npose you have a function to calculate some tolerance value:\ndouble calcEpsilon();            // return tolerance value\ncalcEpsilon clearly returns a double, but suppose you know that for your applica‐\ntion, the precision of a float is adequate, and you care about the difference in size\nbetween floats and doubles. You could declare a float variable to store the result\nof calcEpsilon,\nfloat ep = calcEpsilon();        // impliclitly convert\n                                 // double → float\nbut this hardly announces “I’m deliberately reducing the precision of the value\nreturned by the function.” A declaration using the explicitly typed initializer idiom,\nhowever, does:\nauto ep = static_cast<float>(calcEpsilon());\nSimilar reasoning applies if you have a floating-point expression that you are deliber‐\nately storing as an integral value. Suppose you need to calculate the index of an ele‐\nment in a container with random access iterators (e.g., a std::vector, std::deque,\nItem 6 \n| \n47\nwww.it-ebooks.info\n",
      "content_length": 2539,
      "extraction_method": "Direct"
    },
    {
      "page_number": 66,
      "chapter": null,
      "content": "or std::array), and you’re given a double between 0.0 and 1.0 indicating how far\nfrom the beginning of the container the desired element is located. (0.5 would indi‐\ncate the middle of the container.) Further suppose that you’re confident that the\nresulting index will fit in an int. If the container is c and the double is d, you could\ncalculate the index this way,\nint index = d * c.size();\nbut this obscures the fact that you’re intentionally converting the double on the right\nto an int. The explicitly typed initializer idiom makes things transparent:\nauto index = static_cast<int>(d * c.size());\nThings to Remember\n• “Invisible” proxy types can cause auto to deduce the “wrong” type for an ini‐\ntializing expression.\n• The explicitly typed initializer idiom forces auto to deduce the type you want\nit to have.\n48 \n| \nItem 6\nwww.it-ebooks.info\n",
      "content_length": 849,
      "extraction_method": "Direct"
    },
    {
      "page_number": 67,
      "chapter": null,
      "content": "CHAPTER 3\nMoving to Modern C++\nWhen it comes to big-name features, C++11 and C++14 have a lot to boast of. auto,\nsmart pointers, move semantics, lambdas, concurrency—each is so important, I\ndevote a chapter to it. It’s essential to master those features, but becoming an effective\nmodern C++ programmer requires a series of smaller steps, too. Each step answers\nspecific questions that arise during the journey from C++98 to modern C++. When\nshould you use braces instead of parentheses for object creation? Why are alias decla‐\nrations better than typedefs? How does constexpr differ from const? What’s the\nrelationship between const member functions and thread safety? The list goes on\nand on. And one by one, this chapter provides the answers.\nItem 7: Distinguish between () and {} when creating\nobjects.\nDepending on your perspective, syntax choices for object initialization in C++11\nembody either an embarrassment of riches or a confusing mess. As a general rule,\ninitialization values may be specified with parentheses, an equals sign, or braces:\nint x(0);             // initializer is in parentheses\nint y = 0;            // initializer follows \"=\"\nint z{ 0 };           // initializer is in braces\nIn many cases, it’s also possible to use an equals sign and braces together:\nint z = { 0 };        // initializer uses \"=\" and braces\nFor the remainder of this Item, I’ll generally ignore the equals-sign-plus-braces syn‐\ntax, because C++ usually treats it the same as the braces-only version.\n49\nwww.it-ebooks.info\n",
      "content_length": 1523,
      "extraction_method": "Direct"
    },
    {
      "page_number": 68,
      "chapter": null,
      "content": "The “confusing mess” lobby points out that the use of an equals sign for initialization\noften misleads C++ newbies into thinking that an assignment is taking place, even\nthough it’s not. For built-in types like int, the difference is academic, but for user-\ndefined types, it’s important to distinguish initialization from assignment, because\ndifferent function calls are involved:\nWidget w1;            // call default constructor\nWidget w2 = w1;       // not an assignment; calls copy ctor\nw1 = w2;              // an assignment; calls copy operator=\nEven with several initialization syntaxes, there were some situations where C++98\nhad no way to express a desired initialization. For example, it wasn’t possible to\ndirectly indicate that an STL container should be created holding a particular set of\nvalues (e.g., 1, 3, and 5).\nTo address the confusion of multiple initialization syntaxes, as well as the fact that\nthey don’t cover all initialization scenarios, C++11 introduces uniform initialization:\na single initialization syntax that can, at least in concept, be used anywhere and\nexpress everything. It’s based on braces, and for that reason I prefer the term braced\ninitialization. “Uniform initialization” is an idea. “Braced initialization” is a syntactic\nconstruct.\nBraced initialization lets you express the formerly inexpressible. Using braces, speci‐\nfying the initial contents of a container is easy:\nstd::vector<int> v{ 1, 3, 5 }; // v's initial content is 1, 3, 5\nBraces can also be used to specify default initialization values for non-static data\nmembers. This capability—new to C++11—is shared with the “=” initialization syn‐\ntax, but not with parentheses:\nclass Widget {\n  …\nprivate:\n  int x{ 0 };                  // fine, x's default value is 0\n  int y = 0;                   // also fine\n  int z(0);                    // error!\n};\nOn the other hand, uncopyable objects (e.g., std::atomics—see Item 40) may be\ninitialized using braces or parentheses, but not using “=”: \nstd::atomic<int> ai1{ 0 };     // fine\n50 \n| \nItem 7\nwww.it-ebooks.info\n",
      "content_length": 2071,
      "extraction_method": "Direct"
    },
    {
      "page_number": 69,
      "chapter": null,
      "content": "std::atomic<int> ai2(0);       // fine\nstd::atomic<int> ai3 = 0;      // error!\nIt’s thus easy to understand why braced initialization is called “uniform.” Of C++’s\nthree ways to designate an initializing expression, only braces can be used every‐\nwhere.\nA novel feature of braced initialization is that it prohibits implicit narrowing conver‐\nsions among built-in types. If the value of an expression in a braced initializer isn’t\nguaranteed to be expressible by the type of the object being initialized, the code won’t\ncompile:\ndouble x, y, z;\n…\nint sum1{ x + y + z };       // error! sum of doubles may\n                             // not be expressible as int\nInitialization using parentheses and “=” doesn’t check for narrowing conversions,\nbecause that could break too much legacy code:\nint sum2(x + y + z);         // okay (value of expression\n                             // truncated to an int)\nint sum3 = x + y + z;        // ditto\nAnother noteworthy characteristic of braced initialization is its immunity to C++’s\nmost vexing parse. A side effect of C++’s rule that anything that can be parsed as a\ndeclaration must be interpreted as one, the most vexing parse most frequently afflicts\ndevelopers when they want to default-construct an object, but inadvertently end up\ndeclaring a function instead. The root of the problem is that if you want to call a con‐\nstructor with an argument, you can do it like this,\nWidget w1(10);     // call Widget ctor with argument 10\nbut if you try to call a Widget constructor with zero arguments using the analogous\nsyntax, you declare a function instead of an object:\nWidget w2();       // most vexing parse! declares a function\n                   // named w2 that returns a Widget!\nFunctions can’t be declared using braces for the parameter list, so default-\nconstructing an object using braces doesn’t have this problem:\nWidget w3{};       // calls Widget ctor with no args\nItem 7 \n| \n51\nwww.it-ebooks.info\n",
      "content_length": 1956,
      "extraction_method": "Direct"
    },
    {
      "page_number": 70,
      "chapter": null,
      "content": "There’s thus a lot to be said for braced initialization. It’s the syntax that can be used\nin the widest variety of contexts, it prevents implicit narrowing conversions, and it’s\nimmune to C++’s most vexing parse. A trifecta of goodness! So why isn’t this Item\nentitled something like “Prefer braced initialization syntax”?\nThe drawback to braced initialization is the sometimes-surprising behavior that\naccompanies it. Such behavior grows out of the unusually tangled relationship among\nbraced initializers, std::initializer_lists, and constructor overload resolution.\nTheir interactions can lead to code that seems like it should do one thing, but actually\ndoes another. For example, Item 2 explains that when an auto-declared variable has a\nbraced initializer, the type deduced is std::initializer_list, even though other\nways of declaring a variable with the same initializer would yield a more intuitive\ntype. As a result, the more you like auto, the less enthusiastic you’re likely to be about\nbraced initialization.\nIn constructor calls, parentheses and braces have the same meaning as long as\nstd::initializer_list parameters are not involved:\nclass Widget {\npublic:\n  Widget(int i, bool b);      // ctors not declaring\n  Widget(int i, double d);    // std::initializer_list params\n  …\n};\nWidget w1(10, true);          // calls first ctor\nWidget w2{10, true};          // also calls first ctor\nWidget w3(10, 5.0);           // calls second ctor\nWidget w4{10, 5.0};           // also calls second ctor\nIf, however, one or more constructors declare a parameter of type std::initial\nizer_list, calls using the braced initialization syntax strongly prefer the overloads\ntaking std::initializer_lists. Strongly. If there’s any way for compilers to con‐\nstrue a call using a braced initializer to be to a constructor taking a std::initial\nizer_list, compilers will employ that interpretation. If the Widget class above is\naugmented with a constructor taking a std::initializer_list<long double>, for\nexample,\nclass Widget {\npublic:\n  Widget(int i, bool b);                           // as before\n  Widget(int i, double d);                         // as before\n52 \n| \nItem 7\nwww.it-ebooks.info\n",
      "content_length": 2194,
      "extraction_method": "Direct"
    },
    {
      "page_number": 71,
      "chapter": null,
      "content": "  Widget(std::initializer_list<long double> il);   // added\n  …\n};\nWidgets w2 and w4 will be constructed using the new constructor, even though the\ntype of the std::initializer_list elements (long double) is, compared to the\nnon-std::initializer_list constructors, a worse match for both arguments!\nLook:\nWidget w1(10, true);     // uses parens and, as before,\n                         // calls first ctor\nWidget w2{10, true};     // uses braces, but now calls\n                         // std::initializer_list ctor\n                         // (10 and true convert to long double)\nWidget w3(10, 5.0);      // uses parens and, as before,\n                         // calls second ctor\nWidget w4{10, 5.0};      // uses braces, but now calls\n                         // std::initializer_list ctor\n                         // (10 and 5.0 convert to long double)\nEven what would normally be copy and move construction can be hijacked by\nstd::initializer_list constructors:\nclass Widget {\npublic:\n  Widget(int i, bool b);                           // as before\n  Widget(int i, double d);                         // as before\n  Widget(std::initializer_list<long double> il);   // as before\n  operator float() const;                          // convert\n  …                                                // to float\n};\nWidget w5(w4);               // uses parens, calls copy ctor\nWidget w6{w4};               // uses braces, calls\n                             // std::initializer_list ctor\n                             // (w4 converts to float, and float\n                             // converts to long double)\nItem 7 \n| \n53\nwww.it-ebooks.info\n",
      "content_length": 1636,
      "extraction_method": "Direct"
    },
    {
      "page_number": 72,
      "chapter": null,
      "content": "Widget w7(std::move(w4));    // uses parens, calls move ctor\nWidget w8{std::move(w4)};    // uses braces, calls\n                             // std::initializer_list ctor\n                             // (for same reason as w6)\nCompilers’ determination to match braced initializers with constructors taking\nstd::initializer_lists is so strong, it prevails even if the best-match std::ini\ntializer_list constructor can’t be called. For example:\nclass Widget {\npublic:\n  Widget(int i, bool b);                   // as before\n  Widget(int i, double d);                 // as before\n  Widget(std::initializer_list<bool> il);  // element type is\n                                           // now bool\n  …                                        // no implicit\n};                                         // conversion funcs\nWidget w{10, 5.0};      // error! requires narrowing conversions\nHere, compilers will ignore the first two constructors (the second of which offers an\nexact match on both argument types) and try to call the constructor taking a\nstd::initializer_list<bool>. Calling that constructor would require converting\nan int (10) and a double (5.0) to bools. Both conversions would be narrowing\n(bool can’t exactly represent either value), and narrowing conversions are prohibited\ninside braced initializers, so the call is invalid, and the code is rejected.\nOnly if there’s no way to convert the types of the arguments in a braced initializer to\nthe type in a std::initializer_list do compilers fall back on normal overload\nresolution. For example, if we replace the std::initializer_list<bool> construc‐\ntor with one taking a std::initializer_list<std::string>, the non-\nstd::initializer_list constructors become candidates again, because there is no\nway to convert ints and bools to std::strings:\nclass Widget {\npublic:\n  Widget(int i, bool b);               // as before\n  Widget(int i, double d);             // as before\n  // std::initializer_list element type is now std::string\n  Widget(std::initializer_list<std::string> il);\n  …                                    // no implicit\n54 \n| \nItem 7\nwww.it-ebooks.info\n",
      "content_length": 2127,
      "extraction_method": "Direct"
    },
    {
      "page_number": 73,
      "chapter": null,
      "content": "};                                     // conversion funcs\nWidget w1(10, true);     // uses parens, still calls first ctor\nWidget w2{10, true};     // uses braces, now calls first ctor\nWidget w3(10, 5.0);      // uses parens, still calls second ctor\nWidget w4{10, 5.0};      // uses braces, now calls second ctor\nThis brings us near the end of our examination of braced initializers and constructor\noverloading, but there’s an interesting edge case that needs to be addressed. Suppose\nyou use an empty set of braces to construct an object that supports default construc‐\ntion and also supports std::initializer_list construction. What do your empty\nbraces mean? If they mean “no arguments,” you get default construction, but if they\nmean “empty std::initializer_list,” you get construction from a std::ini\ntializer_list with no elements.\nThe rule is that you get default construction. Empty braces mean no arguments, not\nan empty std::initializer_list:\nclass Widget {\npublic:\n  Widget();                                // default ctor\n  Widget(std::initializer_list<int> il);   // std::initializer\n                                           // _list ctor\n  …                                        // no implicit\n};                                         // conversion funcs\nWidget w1;            // calls default ctor\nWidget w2{};          // also calls default ctor\nWidget w3();          // most vexing parse! declares a function!\nIf you want to call a std::initializer_list constructor with an empty std::ini\ntializer_list, you do it by making the empty braces a constructor argument—by\nputting the empty braces inside the parentheses or braces demarcating what you’re\npassing:\nWidget w4({});        // calls std::initializer_list ctor\n                      // with empty list\nWidget w5{{}};        // ditto\nItem 7 \n| \n55\nwww.it-ebooks.info\n",
      "content_length": 1845,
      "extraction_method": "Direct"
    },
    {
      "page_number": 74,
      "chapter": null,
      "content": "At this point, with seemingly arcane rules about braced initializers, std::initial\nizer_lists, and constructor overloading burbling about in your brain, you may be\nwondering how much of this information matters in day-to-day programming. More\nthan you might think, because one of the classes directly affected is std::vector.\nstd::vector has a non-std::initializer_list constructor that allows you to\nspecify the initial size of the container and a value each of the initial elements should\nhave, but it also has a constructor taking a std::initializer_list that permits\nyou to specify the initial values in the container. If you create a std::vector of a\nnumeric type (e.g., a std::vector<int>) and you pass two arguments to the con‐\nstructor, whether you enclose those arguments in parentheses or braces makes a tre‐\nmendous difference:\nstd::vector<int> v1(10, 20);  // use non-std::initializer_list\n                              // ctor: create 10-element\n                              // std::vector, all elements have\n                              // value of 20\nstd::vector<int> v2{10, 20};  // use std::initializer_list ctor:\n                              // create 2-element std::vector,\n                              // element values are 10 and 20\nBut let’s step back from std::vector and also from the details of parentheses,\nbraces, and constructor overloading resolution rules. There are two primary take‐\naways from this discussion. First, as a class author, you need to be aware that if your\nset of overloaded constructors includes one or more functions taking a std::ini\ntializer_list, client code using braced initialization may see only the std::ini\ntializer_list overloads. As a result, it’s best to design your constructors so that\nthe overload called isn’t affected by whether clients use parentheses or braces. In\nother words, learn from what is now viewed as an error in the design of the std::vec\ntor interface, and design your classes to avoid it.\nAn implication is that if you have a class with no std::initializer_list construc‐\ntor, and you add one, client code using braced initialization may find that calls that\nused to resolve to non-std::initializer_list constructors now resolve to the\nnew function. Of course, this kind of thing can happen any time you add a new func‐\ntion to a set of overloads: calls that used to resolve to one of the old overloads might\nstart calling the new one. The difference with std::initializer_list constructor\noverloads is that a std::initializer_list overload doesn’t just compete with\nother overloads, it overshadows them to the point where the other overloads may\nhardly be considered. So add such overloads only with great deliberation.\nThe second lesson is that as a class client, you must choose carefully between paren‐\ntheses and braces when creating objects. Most developers end up choosing one kind\n56 \n| \nItem 7\nwww.it-ebooks.info\n",
      "content_length": 2906,
      "extraction_method": "Direct"
    },
    {
      "page_number": 75,
      "chapter": null,
      "content": "of delimiter as a default, using the other only when they have to. Braces-by-default\nfolks are attracted by their unrivaled breadth of applicability, their prohibition of nar‐\nrowing conversions, and their immunity to C++’s most vexing parse. Such folks\nunderstand that in some cases (e.g., creation of a std::vector with a given size and\ninitial element value), parentheses are required. On the other hand, the go-\nparentheses-go crowd embraces parentheses as their default argument delimiter.\nThey’re attracted to its consistency with the C++98 syntactic tradition, its avoidance\nof the auto-deduced-a-std::initializer_list problem, and the knowledge that\ntheir object creation calls won’t be inadvertently waylaid by std::initial\nizer_list constructors. They concede that sometimes only braces will do (e.g.,\nwhen creating a container with particular values). There’s no consensus that either\napproach is better than the other, so my advice is to pick one and apply it consis‐\ntently.\nIf you’re a template author, the tension between parentheses and braces for object\ncreation can be especially frustrating, because, in general, it’s not possible to know\nwhich should be used. For example, suppose you’d like to create an object of an arbi‐\ntrary type from an arbitrary number of arguments. A variadic template makes this\nconceptually straightforward:\ntemplate<typename T,                // type of object to create\n         typename... Ts>            // types of arguments to use\nvoid doSomeWork(Ts&&... params)\n{\n  create local T object from params...\n  …\n}\nThere are two ways to turn the line of pseudocode into real code (see Item 25 for\ninformation about std::forward):\nT localObject(std::forward<Ts>(params)...);    // using parens\nT localObject{std::forward<Ts>(params)...};    // using braces\nSo consider this calling code:\nstd::vector<int> v;\n…\ndoSomeWork<std::vector<int>>(10, 20);\nItem 7 \n| \n57\nwww.it-ebooks.info\n",
      "content_length": 1928,
      "extraction_method": "Direct"
    },
    {
      "page_number": 76,
      "chapter": null,
      "content": "1 More flexible designs—ones that permit callers to determine whether parentheses or braces should be used in\nfunctions generated from a template—are possible. For details, see the 5 June 2013 entry of Andrzej’s C++\nblog, “Intuitive interface — Part I.”\nIf doSomeWork uses parentheses when creating localObject, the result is a\nstd::vector with 10 elements. If doSomeWork uses braces, the result is a std::vec\ntor with 2 elements. Which is correct? The author of doSomeWork can’t know. Only\nthe caller can.\nThis is precisely the problem faced by the Standard Library functions\nstd::make_unique and std::make_shared (see Item 21). These functions resolve\nthe problem by internally using parentheses and by documenting this decision as part\nof their interfaces.1\nThings to Remember\n• Braced initialization is the most widely usable initialization syntax, it prevents\nnarrowing conversions, and it’s immune to C++’s most vexing parse.\n• During constructor overload resolution, braced initializers are matched to\nstd::initializer_list parameters if at all possible, even if other construc‐\ntors offer seemingly better matches.\n• An example of where the choice between parentheses and braces can make a\nsignificant difference is creating a std::vector<numeric type> with two\narguments.\n• Choosing between parentheses and braces for object creation inside templates\ncan be challenging.\nItem 8: Prefer nullptr to 0 and NULL.\nSo here’s the deal: the literal 0 is an int, not a pointer. If C++ finds itself looking at 0\nin a context where only a pointer can be used, it’ll grudgingly interpret 0 as a null\npointer, but that’s a fallback position. C++’s primary policy is that 0 is an int, not a\npointer.\nPractically speaking, the same is true of NULL. There is some uncertainty in the details\nin NULL’s case, because implementations are allowed to give NULL an integral type\nother than int (e.g., long). That’s not common, but it doesn’t really matter, because\nthe issue here isn’t the exact type of NULL, it’s that neither 0 nor NULL has a pointer\ntype.\n58 \n| \nItem 7\nwww.it-ebooks.info\n",
      "content_length": 2079,
      "extraction_method": "Direct"
    },
    {
      "page_number": 77,
      "chapter": null,
      "content": "In C++98, the primary implication of this was that overloading on pointer and inte‐\ngral types could lead to surprises. Passing 0 or NULL to such overloads never called a\npointer overload:\nvoid f(int);        // three overloads of f\nvoid f(bool);\nvoid f(void*);\nf(0);               // calls f(int), not f(void*)\nf(NULL);            // might not compile, but typically calls\n                    // f(int). Never calls f(void*)\nThe uncertainty regarding the behavior of f(NULL) is a reflection of the leeway gran‐\nted to implementations regarding the type of NULL. If NULL is defined to be, say, 0L\n(i.e., 0 as a long), the call is ambiguous, because conversion from long to int, long\nto bool, and 0L to void* are considered equally good. The interesting thing about\nthat call is the contradiction between the apparent meaning of the source code (“I’m\ncalling f with NULL—the null pointer”) and its actual meaning (“I’m calling f with\nsome kind of integer—not the null pointer”). This counterintuitive behavior is what\nled to the guideline for C++98 programmers to avoid overloading on pointer and\nintegral types. That guideline remains valid in C++11, because, the advice of this Item\nnotwithstanding, it’s likely that some developers will continue to use 0 and NULL,\neven though nullptr is a better choice.\nnullptr’s advantage is that it doesn’t have an integral type. To be honest, it doesn’t\nhave a pointer type, either, but you can think of it as a pointer of all types. nullptr’s\nactual type is std::nullptr_t, and, in a wonderfully circular definition,\nstd::nullptr_t is defined to be the type of nullptr. The type std::nullptr_t\nimplicitly converts to all raw pointer types, and that’s what makes nullptr act as if it\nwere a pointer of all types.\nCalling the overloaded function f with nullptr calls the void* overload (i.e., the\npointer overload), because nullptr can’t be viewed as anything integral:\nf(nullptr);         // calls f(void*) overload\nUsing nullptr instead of 0 or NULL thus avoids overload resolution surprises, but\nthat’s not its only advantage. It can also improve code clarity, especially when auto\nvariables are involved. For example, suppose you encounter this in a code base:\nauto result = findRecord( /* arguments */ );\nif (result == 0) {\nItem 8 \n| \n59\nwww.it-ebooks.info\n",
      "content_length": 2301,
      "extraction_method": "Direct"
    },
    {
      "page_number": 78,
      "chapter": null,
      "content": "  …\n}\nIf you don’t happen to know (or can’t easily find out) what findRecord returns, it\nmay not be clear whether result is a pointer type or an integral type. After all, 0\n(what result is tested against) could go either way. If you see the following, on the\nother hand,\nauto result = findRecord( /* arguments */ );\nif (result == nullptr) {\n  …\n}\nthere’s no ambiguity: result must be a pointer type.\nnullptr shines especially brightly when templates enter the picture. Suppose you\nhave some functions that should be called only when the appropriate mutex has been\nlocked. Each function takes a different kind of pointer:\nint    f1(std::shared_ptr<Widget> spw);  // call these only when\ndouble f2(std::unique_ptr<Widget> upw);  // the appropriate\nbool   f3(Widget* pw);                   // mutex is locked\nCalling code that wants to pass null pointers could look like this:\nstd::mutex f1m, f2m, f3m;         // mutexes for f1, f2, and f3\nusing MuxGuard =                  // C++11 typedef; see Item 9\n  std::lock_guard<std::mutex>;\n…\n{\n  MuxGuard g(f1m);            // lock mutex for f1\n  auto result = f1(0);        // pass 0 as null ptr to f1\n}                             // unlock mutex\n…\n{\n  MuxGuard g(f2m);            // lock mutex for f2\n  auto result = f2(NULL);     // pass NULL as null ptr to f2\n}                             // unlock mutex\n…\n{\n60 \n| \nItem 8\nwww.it-ebooks.info\n",
      "content_length": 1390,
      "extraction_method": "Direct"
    },
    {
      "page_number": 79,
      "chapter": null,
      "content": "  MuxGuard g(f3m);            // lock mutex for f3\n  auto result = f3(nullptr);  // pass nullptr as null ptr to f3\n}                             // unlock mutex\nThe failure to use nullptr in the first two calls in this code is sad, but the code\nworks, and that counts for something. However, the repeated pattern in the calling\ncode—lock mutex, call function, unlock mutex—is more than sad. It’s disturbing.\nThis kind of source code duplication is one of the things that templates are designed\nto avoid, so let’s templatize the pattern:\ntemplate<typename FuncType,\n         typename MuxType,\n         typename PtrType>\nauto lockAndCall(FuncType func,\n                 MuxType& mutex,\n                 PtrType ptr) -> decltype(func(ptr))\n{\n  MuxGuard g(mutex);\n  return func(ptr);\n}\nIf the return type of this function (auto … -> decltype(func(ptr)) has you scratch‐\ning your head, do your head a favor and navigate to Item 3, which explains what’s\ngoing on. There you’ll see that in C++14, the return type could be reduced to a simple\ndecltype(auto):\ntemplate<typename FuncType,\n         typename MuxType,\n         typename PtrType>\ndecltype(auto) lockAndCall(FuncType func,        // C++14\n                           MuxType& mutex,\n                           PtrType ptr)\n{\n  MuxGuard g(mutex);\n  return func(ptr);\n}\nGiven the lockAndCall template (either version), callers can write code like this:\nauto result1 = lockAndCall(f1, f1m, 0);          // error!\n…\nauto result2 = lockAndCall(f2, f2m, NULL);       // error!\n…\nItem 8 \n| \n61\nwww.it-ebooks.info\n",
      "content_length": 1557,
      "extraction_method": "Direct"
    },
    {
      "page_number": 80,
      "chapter": null,
      "content": "auto result3 = lockAndCall(f3, f3m, nullptr);    // fine\nWell, they can write it, but, as the comments indicate, in two of the three cases, the\ncode won’t compile. The problem in the first call is that when 0 is passed to lockAnd\nCall, template type deduction kicks in to figure out its type. The type of 0 is, was,\nand always will be int, so that’s the type of the parameter ptr inside the instantiation\nof this call to lockAndCall. Unfortunately, this means that in the call to func inside\nlockAndCall, an int is being passed, and that’s not compatible with the\nstd::shared_ptr<Widget> parameter that f1 expects. The 0 passed in the call to\nlockAndCall was intended to represent a null pointer, but what actually got passed\nwas a run-of-the-mill int. Trying to pass this int to f1 as a std::shared_ptr\n<Widget> is a type error. The call to lockAndCall with 0 fails because inside the\ntemplate, an int is being passed to a function that requires a std::\nshared_ptr<Widget>.\nThe analysis for the call involving NULL is essentially the same. When NULL is passed\nto lockAndCall, an integral type is deduced for the parameter ptr, and a type error\noccurs when ptr—an int or int-like type—is passed to f2, which expects to get a\nstd::unique_ptr<Widget>.\nIn contrast, the call involving nullptr has no trouble. When nullptr is passed to\nlockAndCall, the type for ptr is deduced to be std::nullptr_t. When ptr is\npassed to f3, there’s an implicit conversion from std::nullptr_t to Widget*,\nbecause std::nullptr_t implicitly converts to all pointer types.\nThe fact that template type deduction deduces the “wrong” types for 0 and NULL (i.e.,\ntheir true types, rather than their fallback meaning as a representation for a null\npointer) is the most compelling reason to use nullptr instead of 0 or NULL when you\nwant to refer to a null pointer. With nullptr, templates pose no special challenge.\nCombined with the fact that nullptr doesn’t suffer from the overload resolution sur‐\nprises that 0 and NULL are susceptible to, the case is ironclad. When you want to refer\nto a null pointer, use nullptr, not 0 or NULL.\nThings to Remember\n• Prefer nullptr to 0 and NULL.\n• Avoid overloading on integral and pointer types.\n62 \n| \nItem 8\nwww.it-ebooks.info\n",
      "content_length": 2242,
      "extraction_method": "Direct"
    },
    {
      "page_number": 81,
      "chapter": null,
      "content": "Item 9: Prefer alias declarations to typedefs.\nI’m confident we can agree that using STL containers is a good idea, and I hope that\nItem 18 convinces you that using std::unique_ptr is a good idea, but my guess is\nthat neither of us is fond of writing types like “std::unique_ptr<std::unor\ndered_map<std::string, std::string>>” more than once. Just thinking about it\nprobably increases the risk of carpal tunnel syndrome.\nAvoiding such medical tragedies is easy. Introduce a typedef:\ntypedef\n  std::unique_ptr<std::unordered_map<std::string, std::string>>\n  UPtrMapSS;\nBut typedefs are soooo C++98. They work in C++11, sure, but C++11 also offers \nalias declarations:\nusing UPtrMapSS =\n  std::unique_ptr<std::unordered_map<std::string, std::string>>;\nGiven that the typedef and the alias declaration do exactly the same thing, it’s rea‐\nsonable to wonder whether there is a solid technical reason for preferring one over\nthe other.\nThere is, but before I get to it, I want to mention that many people find the alias dec‐\nlaration easier to swallow when dealing with types involving function pointers:\n// FP is a synonym for a pointer to a function taking an int and\n// a const std::string& and returning nothing\ntypedef void (*FP)(int, const std::string&);      // typedef\n// same meaning as above\nusing FP = void (*)(int, const std::string&);     // alias\n                                                  // declaration\nOf course, neither form is particularly easy to choke down, and few people spend\nmuch time dealing with synonyms for function pointer types, anyway, so this is\nhardly a compelling reason to choose alias declarations over typedefs.\nBut a compelling reason does exist: templates. In particular, alias declarations may be\ntemplatized (in which case they’re called alias templates), while typedefs cannot.\nThis gives C++11 programmers a straightforward mechanism for expressing things\nthat in C++98 had to be hacked together with typedefs nested inside templatized\nstructs. For example, consider defining a synonym for a linked list that uses a cus‐\ntom allocator, MyAlloc. With an alias template, it’s a piece of cake:\nItem 9 \n| \n63\nwww.it-ebooks.info\n",
      "content_length": 2170,
      "extraction_method": "Direct"
    },
    {
      "page_number": 82,
      "chapter": null,
      "content": "template<typename T>                           // MyAllocList<T>\nusing MyAllocList = std::list<T, MyAlloc<T>>;  // is synonym for\n                                               // std::list<T,\n                                               //   MyAlloc<T>>\nMyAllocList<Widget> lw;                        // client code\nWith a typedef, you pretty much have to create the cake from scratch:\ntemplate<typename T>                     // MyAllocList<T>::type\nstruct MyAllocList {                     // is synonym for\n  typedef std::list<T, MyAlloc<T>> type; // std::list<T,\n};                                       //   MyAlloc<T>>\nMyAllocList<Widget>::type lw;            // client code\nIt gets worse. If you want to use the typedef inside a template for the purpose of cre‐\nating a linked list holding objects of a type specified by a template parameter, you\nhave to precede the typedef name with typename:\ntemplate<typename T>\nclass Widget {                         // Widget<T> contains\nprivate:                               // a MyAllocList<T>\n  typename MyAllocList<T>::type list;  // as a data member\n  …\n};\nHere, MyAllocList<T>::type refers to a type that’s dependent on a template type\nparameter (T). MyAllocList<T>::type is thus a dependent type, and one of C++’s\nmany endearing rules is that the names of dependent types must be preceded by type\nname.\nIf MyAllocList is defined as an alias template, this need for typename vanishes (as\ndoes the cumbersome “::type” suffix):\ntemplate<typename T>\nusing MyAllocList = std::list<T, MyAlloc<T>>;  // as before\ntemplate<typename T>\nclass Widget {\nprivate:\n  MyAllocList<T> list;                         // no \"typename\",\n  …                                            // no \"::type\"\n};\nTo you, MyAllocList<T> (i.e., use of the alias template) may look just as dependent\non the template parameter T as MyAllocList<T>::type (i.e., use of the nested type\n64 \n| \nItem 9\nwww.it-ebooks.info\n",
      "content_length": 1937,
      "extraction_method": "Direct"
    },
    {
      "page_number": 83,
      "chapter": null,
      "content": "def), but you’re not a compiler. When compilers process the Widget template and\nencounter the use of MyAllocList<T> (i.e., use of the alias template), they know that\nMyAllocList<T> is the name of a type, because MyAllocList is an alias template: it\nmust name a type. MyAllocList<T> is thus a non-dependent type, and a typename\nspecifier is neither required nor permitted.\nWhen compilers see MyAllocList<T>::type (i.e., use of the nested typedef) in the\nWidget template, on the other hand, they can’t know for sure that it names a type,\nbecause there might be a specialization of MyAllocList that they haven’t yet seen\nwhere MyAllocList<T>::type refers to something other than a type. That sounds\ncrazy, but don’t blame compilers for this possibility. It’s the humans who have been\nknown to produce such code.\n For example, some misguided soul may have concocted something like this:\nclass Wine { … };\ntemplate<>                       // MyAllocList specialization\nclass MyAllocList<Wine> {        // for when T is Wine\nprivate:\n  enum class WineType            // see Item 10 for info on\n  { White, Red, Rose };          // \"enum class\"\n  WineType type;                 // in this class, type is\n  …                              // a data member!\n};\nAs you can see, MyAllocList<Wine>::type doesn’t refer to a type. If Widget were to\nbe instantiated with Wine, MyAllocList<T>::type inside the Widget template\nwould refer to a data member, not a type. Inside the Widget template, then, whether\nMyAllocList<T>::type refers to a type is honestly dependent on what T is, and\nthat’s why compilers insist on your asserting that it is a type by preceding it with\ntypename.\nIf you’ve done any template metaprogramming (TMP), you’ve almost certainly bum‐\nped up against the need to take template type parameters and create revised types\nfrom them. For example, given some type T, you might want to strip off any const-\nor reference-qualifiers that T contains, e.g., you might want to turn const\nstd::string& into std::string. Or you might want to add const to a type or turn\nit into an lvalue reference, e.g., turn Widget into const Widget or into Widget&. (If\nyou haven’t done any TMP, that’s too bad, because if you want to be a truly effective\nC++ programmer, you need to be familiar with at least the basics of this facet of C++.\nYou can see examples of TMP in action, including the kinds of type transformations I\njust mentioned, in Items 23 and 27.)\nItem 9 \n| \n65\nwww.it-ebooks.info\n",
      "content_length": 2479,
      "extraction_method": "Direct"
    },
    {
      "page_number": 84,
      "chapter": null,
      "content": "C++11 gives you the tools to perform these kinds of transformations in the form of\ntype traits, an assortment of templates inside the header <type_traits>. There are\ndozens of type traits in that header, and not all of them perform type transforma‐\ntions, but the ones that do offer a predictable interface. Given a type T to which you’d\nlike to apply a transformation, the resulting type is std::transformation\n<T>::type. For example:\nstd::remove_const<T>::type           // yields T from const T\nstd::remove_reference<T>::type       // yields T from T& and T&&\nstd::add_lvalue_reference<T>::type   // yields T& from T\nThe comments merely summarize what these transformations do, so don’t take them\ntoo literally. Before using them on a project, you’d look up the precise specifications,\nI know.\nMy motivation here isn’t to give you a tutorial on type traits, anyway. Rather, note\nthat application of these transformations entails writing “::type” at the end of each\nuse. If you apply them to a type parameter inside a template (which is virtually always\nhow you employ them in real code), you’d also have to precede each use with type\nname. The reason for both of these syntactic speed bumps is that the C++11 type\ntraits are implemented as nested typedefs inside templatized structs. That’s right,\nthey’re implemented using the type synonym technology I’ve been trying to convince\nyou is inferior to alias templates!\nThere’s a historical reason for that, but we’ll skip over it (it’s dull, I promise), because\nthe Standardization Committee belatedly recognized that alias templates are the bet‐\nter way to go, and they included such templates in C++14 for all the C++11 type\ntransformations. The aliases have a common form: for each C++11 transformation\nstd::transformation<T>::type, there’s a corresponding C++14 alias template\nnamed std::transformation_t. Examples will clarify what I mean:\nstd::remove_const<T>::type           // C++11: const T → T\nstd::remove_const_t<T>               // C++14 equivalent\nstd::remove_reference<T>::type       // C++11: T&/T&& → T\nstd::remove_reference_t<T>           // C++14 equivalent\nstd::add_lvalue_reference<T>::type   // C++11: T → T&\nstd::add_lvalue_reference_t<T>       // C++14 equivalent\nThe C++11 constructs remain valid in C++14, but I don’t know why you’d want to\nuse them. Even if you don’t have access to C++14, writing the alias templates yourself\nis child’s play. Only C++11 language features are required, and even children can\n66 \n| \nItem 9\nwww.it-ebooks.info\n",
      "content_length": 2519,
      "extraction_method": "Direct"
    },
    {
      "page_number": 85,
      "chapter": null,
      "content": "mimic a pattern, right? If you happen to have access to an electronic copy of the\nC++14 Standard, it’s easier still, because all that’s required is some copying and past‐\ning. Here, I’ll get you started:\ntemplate <class T>\nusing remove_const_t = typename remove_const<T>::type;\ntemplate <class T>\nusing remove_reference_t = typename remove_reference<T>::type;\ntemplate <class T>\nusing add_lvalue_reference_t =\n  typename add_lvalue_reference<T>::type;\nSee? Couldn’t be easier.\nThings to Remember\n• typedefs don’t support templatization, but alias declarations do.\n• Alias templates avoid the “::type” suffix and, in templates, the “typename”\nprefix often required to refer to typedefs.\n• C++14 offers alias templates for all the C++11 type traits transformations.\nItem 10: Prefer scoped enums to unscoped enums.\nAs a general rule, declaring a name inside curly braces limits the visibility of that\nname to the scope defined by the braces. Not so for the enumerators declared in\nC++98-style enums. The names of such enumerators belong to the scope containing\nthe enum, and that means that nothing else in that scope may have the same name:\nenum Color { black, white, red };   // black, white, red are\n                                    // in same scope as Color\nauto white = false;                 // error! white already\n                                    // declared in this scope\nThe fact that these enumerator names leak into the scope containing their enum defi‐\nnition gives rise to the official term for this kind of enum: unscoped. Their new C++11\ncounterparts, scoped enums, don’t leak names in this way:\nenum class Color { black, white, red };  // black, white, red\n                                         // are scoped to Color\nauto white = false;              // fine, no other\nItem 9 \n| \n67\nwww.it-ebooks.info\n",
      "content_length": 1825,
      "extraction_method": "Direct"
    },
    {
      "page_number": 86,
      "chapter": null,
      "content": "                                 // \"white\" in scope\nColor c = white;                 // error! no enumerator named\n                                 // \"white\" is in this scope\nColor c = Color::white;          // fine\nauto c = Color::white;           // also fine (and in accord\n                                 // with Item 5's advice)\nBecause scoped enums are declared via “enum class”, they’re sometimes referred to as\nenum classes.\nThe reduction in namespace pollution offered by scoped enums is reason enough to\nprefer them over their unscoped siblings, but scoped enums have a second compelling\nadvantage: their enumerators are much more strongly typed. Enumerators for unsco‐\nped enums implicitly convert to integral types (and, from there, to floating-point\ntypes). Semantic travesties such as the following are therefore completely valid:\nenum Color { black, white, red };        // unscoped enum\nstd::vector<std::size_t>                 // func. returning\n  primeFactors(std::size_t x);           // prime factors of x\nColor c = red;\n…\nif (c < 14.5) {                // compare Color to double (!)\n  auto factors =               // compute prime factors\n    primeFactors(c);           // of a Color (!)\n  …\n}\nThrow a simple “class” after “enum”, however, thus transforming an unscoped enum\ninto a scoped one, and it’s a very different story. There are no implicit conversions\nfrom enumerators in a scoped enum to any other type:\nenum class Color { black, white, red };  // enum is now scoped\nColor c = Color::red;                    // as before, but\n…                                        // with scope qualifier\nif (c < 14.5) {                // error! can't compare\n                               // Color and double\n68 \n| \nItem 10\nwww.it-ebooks.info\n",
      "content_length": 1766,
      "extraction_method": "Direct"
    },
    {
      "page_number": 87,
      "chapter": null,
      "content": "  auto factors =               // error! can't pass Color to\n    primeFactors(c);           // function expecting std::size_t\n  …\n}\nIf you honestly want to perform a conversion from Color to a different type, do what\nyou always do to twist the type system to your wanton desires—use a cast:\nif (static_cast<double>(c) < 14.5) {       // odd code, but\n                                           // it's valid\n  auto factors =                                // suspect, but\n    primeFactors(static_cast<std::size_t>(c));  // it compiles\n  …\n}\nIt may seem that scoped enums have a third advantage over unscoped enums, because\nscoped enums may be forward-declared, i.e., their names may be declared without\nspecifying their enumerators:\nenum Color;               // error!\nenum class Color;         // fine\nThis is misleading. In C++11, unscoped enums may also be forward-declared, but\nonly after a bit of additional work. The work grows out of the fact that every enum in\nC++ has an integral underlying type that is determined by compilers. For an unsco‐\nped enum like Color,\nenum Color { black, white, red };\ncompilers might choose char as the underlying type, because there are only three val‐\nues to represent. However, some enums have a range of values that is much larger,\ne.g.:\nenum Status { good = 0,\n              failed = 1,\n              incomplete = 100,\n              corrupt = 200,\n              indeterminate = 0xFFFFFFFF\n            };\nHere the values to be represented range from 0 to 0xFFFFFFFF. Except on unusual\nmachines (where a char consists of at least 32 bits), compilers will have to select an\nintegral type larger than char for the representation of Status values.\nItem 10 \n| \n69\nwww.it-ebooks.info\n",
      "content_length": 1721,
      "extraction_method": "Direct"
    },
    {
      "page_number": 88,
      "chapter": null,
      "content": "To make efficient use of memory, compilers often want to choose the smallest under‐\nlying type for an enum that’s sufficient to represent its range of enumerator values. In\nsome cases, compilers will optimize for speed instead of size, and in that case, they\nmay not choose the smallest permissible underlying type, but they certainly want to\nbe able to optimize for size. To make that possible, C++98 supports only enum defini‐\ntions (where all enumerators are listed); enum declarations are not allowed. That\nmakes it possible for compilers to select an underlying type for each enum prior to the\nenum being used.\nBut the inability to forward-declare enums has drawbacks. The most notable is proba‐\nbly the increase in compilation dependencies. Consider again the Status enum:\nenum Status { good = 0,\n              failed = 1,\n              incomplete = 100,\n              corrupt = 200,\n              indeterminate = 0xFFFFFFFF\n            };\nThis is the kind of enum that’s likely to be used throughout a system, hence included\nin a header file that every part of the system is dependent on. If a new status value is\nthen introduced,\nenum Status { good = 0,\n              failed = 1,\n              incomplete = 100,\n              corrupt = 200,\n              audited = 500,\n              indeterminate = 0xFFFFFFFF\n            };\nit’s likely that the entire system will have to be recompiled, even if only a single sub‐\nsystem—possibly only a single function!—uses the new enumerator. This is the kind\nof thing that people hate. And it’s the kind of thing that the ability to forward-declare\nenums in C++11 eliminates. For example, here’s a perfectly valid declaration of a\nscoped enum and a function that takes one as a parameter:\nenum class Status;                   // forward declaration\nvoid continueProcessing(Status s);   // use of fwd-declared enum\nThe header containing these declarations requires no recompilation if Status’s\ndefinition is revised. Furthermore, if Status is modified (e.g., to add the audited\nenumerator), but continueProcessing’s behavior is unaffected (e.g., because\n70 \n| \nItem 10\nwww.it-ebooks.info\n",
      "content_length": 2134,
      "extraction_method": "Direct"
    },
    {
      "page_number": 89,
      "chapter": null,
      "content": "continueProcessing doesn’t use audited), continueProcessing’s implementation\nneed not be recompiled, either.\nBut if compilers need to know the size of an enum before it’s used, how can C++11’s\nenums get away with forward declarations when C++98’s enums can’t? The answer is\nsimple: the underlying type for a scoped enum is always known, and for unscoped\nenums, you can specify it.\nBy default, the underlying type for scoped enums is int:\nenum class Status;                 // underlying type is int\nIf the default doesn’t suit you, you can override it:\nenum class Status: std::uint32_t;  // underlying type for\n                                   // Status is std::uint32_t\n                                   // (from <cstdint>)\nEither way, compilers know the size of the enumerators in a scoped enum.\nTo specify the underlying type for an unscoped enum, you do the same thing as for a\nscoped enum, and the result may be forward-declared:\nenum Color: std::uint8_t;       // fwd decl for unscoped enum;\n                                // underlying type is\n                                // std::uint8_t\nUnderlying type specifications can also go on an enum’s definition:\nenum class Status: std::uint32_t { good = 0,\n                                   failed = 1,\n                                   incomplete = 100,\n                                   corrupt = 200,\n                                   audited = 500,\n                                   indeterminate = 0xFFFFFFFF\n                                 };\nIn view of the fact that scoped enums avoid namespace pollution and aren’t suscepti‐\nble to nonsensical implicit type conversions, it may surprise you to hear that there’s\nat least one situation where unscoped enums may be useful. That’s when referring to\nfields within C++11’s std::tuples. For example, suppose we have a tuple holding\nvalues for the name, email address, and reputation value for a user at a social net‐\nworking website:\nusing UserInfo =                 // type alias; see Item 9\n  std::tuple<std::string,        // name\nItem 10 \n| \n71\nwww.it-ebooks.info\n",
      "content_length": 2086,
      "extraction_method": "Direct"
    },
    {
      "page_number": 90,
      "chapter": null,
      "content": "             std::string,        // email\n             std::size_t> ;      // reputation\nThough the comments indicate what each field of the tuple represents, that’s proba‐\nbly not very helpful when you encounter code like this in a separate source file:\nUserInfo uInfo;                  // object of tuple type\n…\nauto val = std::get<1>(uInfo);   // get value of field 1\nAs a programmer, you have a lot of stuff to keep track of. Should you really be\nexpected to remember that field 1 corresponds to the user’s email address? I think\nnot. Using an unscoped enum to associate names with field numbers avoids the need\nto:\nenum UserInfoFields { uiName, uiEmail, uiReputation };\nUserInfo uInfo;                        // as before\n…\nauto val = std::get<uiEmail>(uInfo);   // ah, get value of\n                                       // email field\nWhat makes this work is the implicit conversion from UserInfoFields to\nstd::size_t, which is the type that std::get requires.\nThe corresponding code with scoped enums is substantially more verbose:\nenum class UserInfoFields { uiName, uiEmail, uiReputation };\nUserInfo uInfo;                        // as before\n…\nauto val =\n  std::get<static_cast<std::size_t>(UserInfoFields::uiEmail)>\n    (uInfo);\nThe verbosity can be reduced by writing a function that takes an enumerator and\nreturns its corresponding std::size_t value, but it’s a bit tricky. std::get is a tem‐\nplate, and the value you provide is a template argument (notice the use of angle\nbrackets, not parentheses), so the function that transforms an enumerator into a\nstd::size_t has to produce its result during compilation. As Item 15 explains, that\nmeans it must be a constexpr function.\nIn fact, it should really be a constexpr function template, because it should work\nwith any kind of enum. And if we’re going to make that generalization, we should\n72 \n| \nItem 10\nwww.it-ebooks.info\n",
      "content_length": 1891,
      "extraction_method": "Direct"
    },
    {
      "page_number": 91,
      "chapter": null,
      "content": "generalize the return type, too. Rather than returning std::size_t, we’ll return the\nenum’s underlying type. It’s available via the std::underlying_type type trait. (See\nItem 9 for information on type traits.) Finally, we’ll declare it noexcept (see Item 14),\nbecause we know it will never yield an exception. The result is a function template\ntoUType that takes an arbitrary enumerator and can return its value as a compile-\ntime constant:\ntemplate<typename E>\nconstexpr typename std::underlying_type<E>::type\n  toUType(E enumerator) noexcept\n{\n  return\n    static_cast<typename\n                std::underlying_type<E>::type>(enumerator);\n}\nIn C++14, toUType can be simplified by replacing typename std::underly\ning_type<E>::type with the sleeker std::underlying_type_t (see Item 9):\ntemplate<typename E>                               // C++14\nconstexpr std::underlying_type_t<E>\n  toUType(E enumerator) noexcept\n{\n  return static_cast<std::underlying_type_t<E>>(enumerator);\n}\nThe even-sleeker auto return type (see Item 3) is also valid in C++14:\ntemplate<typename E>                               // C++14\nconstexpr auto\n  toUType(E enumerator) noexcept\n{\n  return static_cast<std::underlying_type_t<E>>(enumerator);\n}\nRegardless of how it’s written, toUType permits us to access a field of the tuple like\nthis:\nauto val = std::get<toUType(UserInfoFields::uiEmail)>(uInfo);\nIt’s still more to write than use of the unscoped enum, but it also avoids namespace\npollution and inadvertent conversions involving enumerators. In many cases, you\nmay decide that typing a few extra characters is a reasonable price to pay for the abil‐\nity to avoid the pitfalls of an enum technology that dates to a time when the state of\nthe art in digital telecommunications was the 2400-baud modem.\nItem 10 \n| \n73\nwww.it-ebooks.info\n",
      "content_length": 1816,
      "extraction_method": "Direct"
    },
    {
      "page_number": 92,
      "chapter": null,
      "content": "Things to Remember\n• C++98-style enums are now known as unscoped enums.\n• Enumerators of scoped enums are visible only within the enum. They convert\nto other types only with a cast.\n• Both scoped and unscoped enums support specification of the underlying type.\nThe default underlying type for scoped enums is int. Unscoped enums have no\ndefault underlying type.\n• Scoped enums may always be forward-declared. Unscoped enums may be\nforward-declared only if their declaration specifies an underlying type.\nItem 11: Prefer deleted functions to private undefined\nones.\nIf you’re providing code to other developers, and you want to prevent them from\ncalling a particular function, you generally just don’t declare the function. No func‐\ntion declaration, no function to call. Easy, peasy. But sometimes C++ declares func‐\ntions for you, and if you want to prevent clients from calling those functions, the\npeasy isn’t quite so easy any more.\nThe situation arises only for the “special member functions,” i.e., the member func‐\ntions that C++ automatically generates when they’re needed. Item 17 discusses these\nfunctions in detail, but for now, we’ll worry only about the copy constructor and the\ncopy assignment operator. This chapter is largely devoted to common practices in\nC++98 that have been superseded by better practices in C++11, and in C++98, if you\nwant to suppress use of a member function, it’s almost always the copy constructor,\nthe assignment operator, or both.\nThe C++98 approach to preventing use of these functions is to declare them private\nand not define them. For example, near the base of the iostreams hierarchy in the\nC++ Standard Library is the class template basic_ios. All istream and ostream\nclasses inherit (possibly indirectly) from this class. Copying istreams and ostreams is\nundesirable, because it’s not really clear what such operations should do. An istream\nobject, for example, represents a stream of input values, some of which may have\nalready been read, and some of which will potentially be read later. If an istream were\nto be copied, would that entail copying all the values that had already been read as\nwell as all the values that would be read in the future? The easiest way to deal with\nsuch questions is to define them out of existence. Prohibiting the copying of streams\ndoes just that.\n74 \n| \nItem 10\nwww.it-ebooks.info\n",
      "content_length": 2367,
      "extraction_method": "Direct"
    },
    {
      "page_number": 93,
      "chapter": null,
      "content": "To render istream and ostream classes uncopyable, basic_ios is specified in C++98\nas follows (including the comments):\ntemplate <class charT, class traits = char_traits<charT> >\nclass basic_ios : public ios_base {\npublic:\n  …\nprivate:\n  basic_ios(const basic_ios& );            // not defined\n  basic_ios& operator=(const basic_ios&);  // not defined\n};\nDeclaring these functions private prevents clients from calling them. Deliberately\nfailing to define them means that if code that still has access to them (i.e., member\nfunctions or friends of the class) uses them, linking will fail due to missing function\ndefinitions.\nIn C++11, there’s a better way to achieve essentially the same end: use “= delete” to\nmark the copy constructor and the copy assignment operator as deleted functions.\nHere’s the same part of basic_ios as it’s specified in C++11:\ntemplate <class charT, class traits = char_traits<charT> >\nclass basic_ios : public ios_base {\npublic:\n  …\n  basic_ios(const basic_ios& ) = delete;\n  basic_ios& operator=(const basic_ios&) = delete;\n  …\n};\nThe difference between deleting these functions and declaring them private may\nseem more a matter of fashion than anything else, but there’s greater substance here\nthan you might think. Deleted functions may not be used in any way, so even code\nthat’s in member and friend functions will fail to compile if it tries to copy\nbasic_ios objects. That’s an improvement over the C++98 behavior, where such\nimproper usage wouldn’t be diagnosed until link-time.\nBy convention, deleted functions are declared public, not private. There’s a reason\nfor that. When client code tries to use a member function, C++ checks accessibility\nbefore deleted status. When client code tries to use a deleted private function, some\ncompilers complain only about the function being private, even though the func‐\ntion’s accessibility doesn’t really affect whether it can be used. It’s worth bearing this\nin mind when revising legacy code to replace private-and-not-defined member\nItem 11 \n| \n75\nwww.it-ebooks.info\n",
      "content_length": 2049,
      "extraction_method": "Direct"
    },
    {
      "page_number": 94,
      "chapter": null,
      "content": "functions with deleted ones, because making the new functions public will generally\nresult in better error messages.\nAn important advantage of deleted functions is that any function may be deleted,\nwhile only member functions may be private. For example, suppose we have a non-\nmember function that takes an integer and returns whether it’s a lucky number:\nbool isLucky(int number);\nC++’s C heritage means that pretty much any type that can be viewed as vaguely\nnumerical will implicitly convert to int, but some calls that would compile might not\nmake sense:\nif (isLucky('a')) …            // is 'a' a lucky number?\nif (isLucky(true)) …           // is \"true\"?\nif (isLucky(3.5)) …            // should we truncate to 3\n                               // before checking for luckiness?\nIf lucky numbers must really be integers, we’d like to prevent calls such as these from\ncompiling.\nOne way to accomplish that is to create deleted overloads for the types we want to\nfilter out:\nbool isLucky(int number);            // original function\nbool isLucky(char) = delete;         // reject chars\nbool isLucky(bool) = delete;         // reject bools\nbool isLucky(double) = delete;       // reject doubles and\n                                     // floats\n(The comment on the double overload that says that both doubles and floats will\nbe rejected may surprise you, but your surprise will dissipate once you recall that,\ngiven a choice between converting a float to an int or to a double, C++ prefers the\nconversion to double. Calling isLucky with a float will therefore call the double\noverload, not the int one. Well, it’ll try to. The fact that that overload is deleted will\nprevent the call from compiling.)\nAlthough deleted functions can’t be used, they are part of your program. As such,\nthey are taken into account during overload resolution. That’s why, with the deleted\nfunction declarations above, the undesirable calls to isLucky will be rejected:\nif (isLucky('a')) …           // error! call to deleted function\n76 \n| \nItem 11\nwww.it-ebooks.info\n",
      "content_length": 2051,
      "extraction_method": "Direct"
    },
    {
      "page_number": 95,
      "chapter": null,
      "content": "if (isLucky(true)) …          // error!\nif (isLucky(3.5f)) …          // error!\nAnother trick that deleted functions can perform (and that private member func‐\ntions can’t) is to prevent use of template instantiations that should be disabled. For\nexample, suppose you need a template that works with built-in pointers (Chapter 4’s\nadvice to prefer smart pointers to raw pointers notwithstanding):\ntemplate<typename T>\nvoid processPointer(T* ptr);\nThere are two special cases in the world of pointers. One is void* pointers, because\nthere is no way to dereference them, to increment or decrement them, etc. The other\nis char* pointers, because they typically represent pointers to C-style strings, not\npointers to individual characters. These special cases often call for special handling,\nand, in the case of the processPointer template, let’s assume the proper handling is\nto reject calls using those types. That is, it should not be possible to call\nprocessPointer with void* or char* pointers.\nThat’s easily enforced. Just delete those instantiations:\ntemplate<>\nvoid processPointer<void>(void*) = delete;\ntemplate<>\nvoid processPointer<char>(char*) = delete;\nNow, if calling processPointer with a void* or a char* is invalid, it’s probably also\ninvalid to call it with a const void* or a const char*, so those instantiations will\ntypically need to be deleted, too:\ntemplate<>\nvoid processPointer<const void>(const void*) = delete;\ntemplate<>\nvoid processPointer<const char>(const char*) = delete;\nAnd if you really want to be thorough, you’ll also delete the const volatile void*\nand const volatile char* overloads, and then you’ll get to work on the overloads\nfor pointers to the other standard character types: std::wchar_t, std::char16_t,\nand std::char32_t.\nInterestingly, if you have a function template inside a class, and you’d like to disable\nsome instantiations by declaring them private (à la classic C++98 convention), you\ncan’t, because it’s not possible to give a member function template specialization a\nItem 11 \n| \n77\nwww.it-ebooks.info\n",
      "content_length": 2056,
      "extraction_method": "Direct"
    },
    {
      "page_number": 96,
      "chapter": null,
      "content": "different access level from that of the main template. If processPointer were a\nmember function template inside Widget, for example, and you wanted to disable\ncalls for void* pointers, this would be the C++98 approach, though it would not \ncompile:\nclass Widget {\npublic:\n  …\n  template<typename T>\n  void processPointer(T* ptr)\n  { … }\nprivate:\n  template<>                                 // error!\n  void processPointer<void>(void*);\n};\nThe problem is that template specializations must be written at namespace scope, not\nclass scope. This issue doesn’t arise for deleted functions, because they don’t need a\ndifferent access level. They can be deleted outside the class (hence at namespace\nscope):\nclass Widget {\npublic:\n  …\n  template<typename T>\n  void processPointer(T* ptr)\n  { … }\n  …\n};\ntemplate<>                                          // still\nvoid Widget::processPointer<void>(void*) = delete;  // public,\n                                                    // but\n                                                    // deleted\nThe truth is that the C++98 practice of declaring functions private and not defining\nthem was really an attempt to achieve what C++11’s deleted functions actually\naccomplish. As an emulation, the C++98 approach is not as good as the real thing. It\ndoesn’t work outside classes, it doesn’t always work inside classes, and when it does\nwork, it may not work until link-time. So stick to deleted functions.\n78 \n| \nItem 11\nwww.it-ebooks.info\n",
      "content_length": 1481,
      "extraction_method": "Direct"
    },
    {
      "page_number": 97,
      "chapter": null,
      "content": "Things to Remember\n• Prefer deleted functions to private undefined ones.\n• Any function may be deleted, including non-member functions and template\ninstantiations.\nItem 12: Declare overriding functions override.\nThe world of object-oriented programming in C++ revolves around classes, inheri‐\ntance, and virtual functions. Among the most fundamental ideas in this world is that\nvirtual function implementations in derived classes override the implementations of\ntheir base class counterparts. It’s disheartening, then, to realize just how easily virtual\nfunction overriding can go wrong. It’s almost as if this part of the language were\ndesigned with the idea that Murphy’s Law wasn’t just to be obeyed, it was to be hon‐\nored.\nBecause “overriding” sounds a lot like “overloading,” yet is completely unrelated, let\nme make clear that virtual function overriding is what makes it possible to invoke a\nderived class function through a base class interface:\nclass Base {\npublic:\n  virtual void doWork();         // base class virtual function\n  …\n};\nclass Derived: public Base {\npublic:\n  virtual void doWork();         // overrides Base::doWork\n  …                              // (\"virtual\" is optional\n};                               // here)\nstd::unique_ptr<Base> upb =      // create base class pointer\n  std::make_unique<Derived>();   // to derived class object;\n                                 // see Item 21 for info on\n…                                // std::make_unique\nupb->doWork();                   // call doWork through base\n                                 // class ptr; derived class\n                                 // function is invoked\nFor overriding to occur, several requirements must be met:\nItem 11 \n| \n79\nwww.it-ebooks.info\n",
      "content_length": 1751,
      "extraction_method": "Direct"
    },
    {
      "page_number": 98,
      "chapter": null,
      "content": "• The base class function must be virtual.\n• The base and derived function names must be identical (except in the case of\ndestructors).\n• The parameter types of the base and derived functions must be identical.\n• The constness of the base and derived functions must be identical.\n• The return types and exception specifications of the base and derived functions\nmust be compatible.\nTo these constraints, which were also part of C++98, C++11 adds one more:\n• The functions’ reference qualifiers must be identical. Member function reference\nqualifiers are one of C++11’s less-publicized features, so don’t be surprised if\nyou’ve never heard of them. They make it possible to limit use of a member func‐\ntion to lvalues only or to rvalues only. Member functions need not be virtual to\nuse them:\nclass Widget {\npublic:\n  …\n  void doWork() &;       // this version of doWork applies\n                         // only when *this is an lvalue\n  void doWork() &&;      // this version of doWork applies\n};                       // only when *this is an rvalue\n…\nWidget makeWidget();     // factory function (returns rvalue)\nWidget w;                // normal object (an lvalue)\n…\nw.doWork();              // calls Widget::doWork for lvalues\n                         // (i.e., Widget::doWork &)\nmakeWidget().doWork();   // calls Widget::doWork for rvalues\n                         // (i.e., Widget::doWork &&)\nI’ll say more about member functions with reference qualifiers later, but for now,\nsimply note that if a virtual function in a base class has a reference qualifier,\nderived class overrides of that function must have exactly the same reference\n80 \n| \nItem 12\nwww.it-ebooks.info\n",
      "content_length": 1677,
      "extraction_method": "Direct"
    },
    {
      "page_number": 99,
      "chapter": null,
      "content": "qualifier. If they don’t, the declared functions will still exist in the derived class,\nbut they won’t override anything in the base class.\nAll these requirements for overriding mean that small mistakes can make a big differ‐\nence. Code containing overriding errors is typically valid, but its meaning isn’t what\nyou intended. You therefore can’t rely on compilers notifying you if you do some‐\nthing wrong. For example, the following code is completely legal and, at first sight,\nlooks reasonable, but it contains no virtual function overrides—not a single derived\nclass function that is tied to a base class function. Can you identify the problem in\neach case, i.e., why each derived class function doesn’t override the base class func‐\ntion with the same name?\nclass Base {\npublic:\n  virtual void mf1() const;\n  virtual void mf2(int x);\n  virtual void mf3() &;\n  void mf4() const;\n};\nclass Derived: public Base {\npublic:\n  virtual void mf1();\n  virtual void mf2(unsigned int x);\n  virtual void mf3() &&;\n  void mf4() const;\n};\nNeed some help?\n• mf1 is declared const in Base, but not in Derived.\n• mf2 takes an int in Base, but an unsigned int in Derived.\n• mf3 is lvalue-qualified in Base, but rvalue-qualified in Derived.\n• mf4 isn’t declared virtual in Base.\nYou may think, “Hey, in practice, these things will elicit compiler warnings, so I don’t\nneed to worry.” Maybe that’s true. But maybe it’s not. With two of the compilers I\nchecked, the code was accepted without complaint, and that was with all warnings\nenabled. (Other compilers provided warnings about some of the issues, but not all of\nthem.)\nBecause declaring derived class overrides is important to get right, but easy to get\nwrong, C++11 gives you a way to make explicit that a derived class function is\nItem 12 \n| \n81\nwww.it-ebooks.info\n",
      "content_length": 1808,
      "extraction_method": "Direct"
    },
    {
      "page_number": 100,
      "chapter": null,
      "content": "supposed to override a base class version: declare it override. Applying this to the\nexample above would yield this derived class:\nclass Derived: public Base {\npublic:\n  virtual void mf1() override;\n  virtual void mf2(unsigned int x) override;\n  virtual void mf3() && override;\n  virtual void mf4() const override;\n};\nThis won’t compile, of course, because when written this way, compilers will kvetch\nabout all the overriding-related problems. That’s exactly what you want, and it’s why\nyou should declare all your overriding functions override.\nThe code using override that does compile looks as follows (assuming that the goal\nis for all functions in Derived to override virtuals in Base):\nclass Base {\npublic:\n  virtual void mf1() const;\n  virtual void mf2(int x);\n  virtual void mf3() &;\n  virtual void mf4() const;\n};\nclass Derived: public Base {\npublic:\n  virtual void mf1() const override;\n  virtual void mf2(int x) override;\n  virtual void mf3() & override;\n  void mf4() const override;          // adding \"virtual\" is OK,\n};                                    // but not necessary\nNote that in this example, part of getting things to work involves declaring mf4 vir‐\ntual in Base. Most overriding-related errors occur in derived classes, but it’s possible\nfor things to be incorrect in base classes, too.\nA policy of using override on all your derived class overrides can do more than just\nenable compilers to tell you when would-be overrides aren’t overriding anything. It\ncan also help you gauge the ramifications if you’re contemplating changing the signa‐\nture of a virtual function in a base class. If derived classes use override everywhere,\nyou can just change the signature, recompile your system, see how much damage\nyou’ve caused (i.e., how many derived classes fail to compile), then decide whether\nthe signature change is worth the trouble. Without override, you’d have to hope you\nhave comprehensive unit tests in place, because, as we’ve seen, derived class virtuals\n82 \n| \nItem 12\nwww.it-ebooks.info\n",
      "content_length": 2025,
      "extraction_method": "Direct"
    },
    {
      "page_number": 101,
      "chapter": null,
      "content": "2 Applying final to a virtual function prevents the function from being overridden in derived classes. final\nmay also be applied to a class, in which case the class is prohibited from being used as a base class.\nthat are supposed to override base class functions, but don’t, need not elicit compiler\ndiagnostics.\nC++ has always had keywords, but C++11 introduces two contextual keywords, over\nride and final.2 These keywords have the characteristic that they are reserved, but\nonly in certain contexts. In the case of override, it has a reserved meaning only\nwhen it occurs at the end of a member function declaration. That means that if you\nhave legacy code that already uses the name override, you don’t need to change it\nfor C++11:\nclass Warning {           // potential legacy class from C++98\npublic:\n  …\n  void override();        // legal in both C++98 and C++11\n  …                       // (with the same meaning)\n};\nThat’s all there is to say about override, but it’s not all there is to say about member\nfunction reference qualifiers. I promised I’d provide more information on them later,\nand now it’s later.\nIf we want to write a function that accepts only lvalue arguments, we declare a non-\nconst lvalue reference parameter:\nvoid doSomething(Widget& w);      // accepts only lvalue Widgets\nIf we want to write a function that accepts only rvalue arguments, we declare an\nrvalue reference parameter:\nvoid doSomething(Widget&& w);     // accepts only rvalue Widgets\nMember function reference qualifiers simply make it possible to draw the same dis‐\ntinction for the object on which a member function is invoked, i.e., *this. It’s pre‐\ncisely analogous to the const at the end of a member function declaration, which\nindicates that the object on which the member function is invoked (i.e., *this) is\nconst.\nThe need for reference-qualified member functions is not common, but it can arise.\nFor example, suppose our Widget class has a std::vector data member, and we\noffer an accessor function that gives clients direct access to it:\nclass Widget {\npublic:\nItem 12 \n| \n83\nwww.it-ebooks.info\n",
      "content_length": 2101,
      "extraction_method": "Direct"
    },
    {
      "page_number": 102,
      "chapter": null,
      "content": "  using DataType = std::vector<double>;      // see Item 9 for\n  …                                          // info on \"using\"\n  DataType& data() { return values; }\n  …\nprivate:\n  DataType values;\n};\nThis is hardly the most encapsulated design that’s seen the light of day, but set that\naside and consider what happens in this client code:\nWidget w;\n…\nauto vals1 = w.data();               // copy w.values into vals1\nThe return type of Widget::data is an lvalue reference (a std::vector<double>&,\nto be precise), and because lvalue references are defined to be lvalues, we’re initializ‐\ning vals1 from an lvalue. vals1 is thus copy constructed from w.values, just as the\ncomment says.\nNow suppose we have a factory function that creates Widgets,\nWidget makeWidget();\nand we want to initialize a variable with the std::vector inside the Widget returned\nfrom makeWidget:\nauto vals2 = makeWidget().data();    // copy values inside the\n                                     // Widget into vals2\nAgain, Widgets::data returns an lvalue reference, and, again, the lvalue reference is\nan lvalue, so, again, our new object (vals2) is copy constructed from values inside\nthe Widget. This time, though, the Widget is the temporary object returned from\nmakeWidget (i.e., an rvalue), so copying the std::vector inside it is a waste of time.\nIt’d be preferable to move it, but, because data is returning an lvalue reference, the\nrules of C++ require that compilers generate code for a copy. (There’s some wiggle\nroom for optimization through what is known as the “as if rule,” but you’d be foolish\nto rely on your compilers finding a way to take advantage of it.)\nWhat’s needed is a way to specify that when data is invoked on an rvalue Widget, the\nresult should also be an rvalue. Using reference qualifiers to overload data for lvalue\nand rvalue Widgets makes that possible:\n84 \n| \nItem 12\nwww.it-ebooks.info\n",
      "content_length": 1896,
      "extraction_method": "Direct"
    },
    {
      "page_number": 103,
      "chapter": null,
      "content": "class Widget {\npublic:\n  using DataType = std::vector<double>;\n  …\n  DataType& data() &                // for lvalue Widgets, \n  { return values; }                // return lvalue\n  DataType data() &&                // for rvalue Widgets,\n  { return std::move(values); }     // return rvalue\n  …\nprivate:\n  DataType values;\n};\nNotice the differing return types from the data overloads. The lvalue reference over‐\nload returns an lvalue reference (i.e., an lvalue), and the rvalue reference overload\nreturns a temporary object (i.e., an rvalue). This means that client code now behaves\nas we’d like:\nauto vals1 = w.data();             // calls lvalue overload for\n                                   // Widget::data, copy-\n                                   // constructs vals1\nauto vals2 = makeWidget().data();  // calls rvalue overload for\n                                   // Widget::data, move-\n                                   // constructs vals2\nThis is certainly nice, but don’t let the warm glow of this happy ending distract you\nfrom the true point of this Item. That point is that whenever you declare a function in\na derived class that’s meant to override a virtual function in a base class, be sure to\ndeclare that function override.\nThings to Remember\n• Declare overriding functions override.\n• Member function reference qualifiers make it possible to treat lvalue and\nrvalue objects (*this) differently.\nItem 12 \n| \n85\nwww.it-ebooks.info\n",
      "content_length": 1453,
      "extraction_method": "Direct"
    },
    {
      "page_number": 104,
      "chapter": null,
      "content": "Item 13: Prefer const_iterators to iterators.\nconst_iterators are the STL equivalent of pointers-to-const. They point to values\nthat may not be modified. The standard practice of using const whenever possible\ndictates that you should use const_iterators any time you need an iterator, yet\nhave no need to modify what the iterator points to.\nThat’s as true for C++98 as for C++11, but in C++98, const_iterators had only\nhalfhearted support. It wasn’t that easy to create them, and once you had one, the\nways you could use it were limited. For example, suppose you want to search a\nstd::vector<int> for the first occurrence of 1983 (the year “C++” replaced “C with\nClasses” as the name of the programming language), then insert the value 1998 (the\nyear the first ISO C++ Standard was adopted) at that location. If there’s no 1983 in\nthe vector, the insertion should go at the end of the vector. Using iterators in\nC++98, that was easy:\nstd::vector<int> values;\n…\nstd::vector<int>::iterator it =\n  std::find(values.begin(),values.end(), 1983);\nvalues.insert(it, 1998);\nBut iterators aren’t really the proper choice here, because this code never modifies\nwhat an iterator points to. Revising the code to use const_iterators should be\ntrivial, but in C++98, it was anything but. Here’s one approach that’s conceptually\nsound, though still not correct:\ntypedef std::vector<int>::iterator IterT;             // type-\ntypedef std::vector<int>::const_iterator ConstIterT;  // defs\nstd::vector<int> values;\n…\nConstIterT ci =\n  std::find(static_cast<ConstIterT>(values.begin()),  // cast\n            static_cast<ConstIterT>(values.end()),    // cast\n            1983);\nvalues.insert(static_cast<IterT>(ci), 1998);    // may not\n                                                // compile; see\n                                                // below\n86 \n| \nItem 13\nwww.it-ebooks.info\n",
      "content_length": 1872,
      "extraction_method": "Direct"
    },
    {
      "page_number": 105,
      "chapter": null,
      "content": "The typedefs aren’t required, of course, but they make the casts in the code easier to\nwrite. (If you’re wondering why I’m showing typedefs instead of following the\nadvice of Item 9 to use alias declarations, it’s because this example shows C++98\ncode, and alias declarations are a feature new to C++11.)\nThe casts in the call to std::find are present because values is a non-const con‐\ntainer and in C++98, there was no simple way to get a const_iterator from a non-\nconst container. The casts aren’t strictly necessary, because it was possible to get\nconst_iterators in other ways (e.g., you could bind values to a reference-to-const\nvariable, then use that variable in place of values in your code), but one way or\nanother, the process of getting const_iterators to elements of a non-const con‐\ntainer involved some amount of contorting.\nOnce you had the const_iterators, matters often got worse, because in C++98,\nlocations for insertions (and erasures) could be specified only by iterators.\nconst_iterators weren’t acceptable. That’s why, in the code above, I cast the\nconst_iterator (that I was so careful to get from std::find) into an iterator:\npassing a const_iterator to insert wouldn’t compile.\nTo be honest, the code I’ve shown might not compile, either, because there’s no\nportable conversion from a const_iterator to an iterator, not even with a\nstatic_cast. Even the semantic sledgehammer known as reinterpret_cast can’t\ndo the job. (That’s not a C++98 restriction. It’s true in C++11, too. const_iterators\nsimply don’t convert to iterators, no matter how much it might seem like they\nshould.) There are some portable ways to generate iterators that point where\nconst_iterators do, but they’re not obvious, not universally applicable, and not\nworth discussing in this book. Besides, I hope that by now my point is clear:\nconst_iterators were so much trouble in C++98, they were rarely worth the\nbother. At the end of the day, developers don’t use const whenever possible, they use\nit whenever practical, and in C++98, const_iterators just weren’t very practical.\nAll that changed in C++11. Now const_iterators are both easy to get and easy to\nuse. The container member functions cbegin and cend produce const_iterators,\neven for non-const containers, and STL member functions that use iterators to iden‐\ntify positions (e.g., insert and erase) actually use const_iterators. Revising the\noriginal C++98 code that uses iterators to use const_iterators in C++11 is truly\ntrivial:\nstd::vector<int> values;                           // as before\n…\nauto it =                                          // use cbegin\nItem 13 \n| \n87\nwww.it-ebooks.info\n",
      "content_length": 2657,
      "extraction_method": "Direct"
    },
    {
      "page_number": 106,
      "chapter": null,
      "content": "  std::find(values.cbegin(),values.cend(), 1983);  // and cend\nvalues.insert(it, 1998);\nNow that’s code using const_iterators that’s practical!\nAbout the only situation in which C++11’s support for const_iterators comes up a\nbit short is when you want to write maximally generic library code. Such code takes\ninto account that some containers and container-like data structures offer begin and\nend (plus cbegin, cend, rbegin, etc.) as non-member functions, rather than mem‐\nbers. This is the case for built-in arrays, for example, and it’s also the case for some\nthird-party libraries with interfaces consisting only of free functions. Maximally\ngeneric code thus uses non-member functions rather than assuming the existence of\nmember versions.\nFor example, we could generalize the code we’ve been working with into a findAnd\nInsert template as follows:\ntemplate<typename C, typename V>\nvoid findAndInsert(C& container,          // in container, find\n                   const V& targetVal,    // first occurrence\n                   const V& insertVal)    // of targetVal, then\n{                                         // insert insertVal\n  using std::cbegin;                      // there\n  using std::cend;\n  auto it = std::find(cbegin(container),  // non-member cbegin\n                      cend(container),    // non-member cend\n                      targetVal);\n  container.insert(it, insertVal);\n}\nThis works fine in C++14, but, sadly, not in C++11. Through an oversight during\nstandardization, C++11 added the non-member functions begin and end, but it\nfailed to add cbegin, cend, rbegin, rend, crbegin, and crend. C++14 rectifies that\noversight.\nIf you’re using C++11, you want to write maximally generic code, and none of the\nlibraries you’re using provides the missing templates for non-member cbegin and\nfriends, you can throw your own implementations together with ease. For example,\nhere’s an implementation of non-member cbegin:\ntemplate <class C>\nauto cbegin(const C& container)->decltype(std::begin(container))\n{\n88 \n| \nItem 13\nwww.it-ebooks.info\n",
      "content_length": 2063,
      "extraction_method": "Direct"
    },
    {
      "page_number": 107,
      "chapter": null,
      "content": "  return std::begin(container);         // see explanation below\n}\nYou’re surprised to see that non-member cbegin doesn’t call member cbegin, aren’t\nyou? So was I. But follow the logic. This cbegin template accepts any type of argu‐\nment representing a container-like data structure, C, and it accesses this argument\nthrough its reference-to-const parameter, container. If C is a conventional con‐\ntainer type (e.g., a std::vector<int>), container will be a reference to a const\nversion of that container (e.g., a const std::vector<int>&). Invoking the non-\nmember begin function (provided by C++11) on a const container yields a\nconst_iterator, and that iterator is what this template returns. The advantage of\nimplementing things this way is that it works even for containers that offer a begin\nmember function (which, for containers, is what C++11’s non-member begin calls),\nbut fail to offer a cbegin member. You can thus use this non-member cbegin on\ncontainers that directly support only begin.\nThis template also works if C is a built-in array type. In that case, container becomes\na reference to a const array. C++11 provides a specialized version of non-member\nbegin for arrays that returns a pointer to the array’s first element. The elements of a\nconst array are const, so the pointer that non-member begin returns for a const\narray is a pointer-to-const, and a pointer-to-const is, in fact, a const_iterator for\nan array. (For insight into how a template can be specialized for built-in arrays, con‐\nsult Item 1’s discussion of type deduction in templates that take reference parameters\nto arrays.)\nBut back to basics. The point of this Item is to encourage you to use const_itera\ntors whenever you can. The fundamental motivation—using const whenever it’s\nmeaningful—predates C++11, but in C++98, it simply wasn’t practical when working\nwith iterators. In C++11, it’s eminently practical, and C++14 tidies up the few bits of\nunfinished business that C++11 left behind.\nThings to Remember\n• Prefer const_iterators to iterators.\n• In maximally generic code, prefer non-member versions of begin, end,\nrbegin, etc., over their member function counterparts.\nItem 13 \n| \n89\nwww.it-ebooks.info\n",
      "content_length": 2200,
      "extraction_method": "Direct"
    },
    {
      "page_number": 108,
      "chapter": null,
      "content": "Item 14: Declare functions noexcept if they won’t emit\nexceptions.\nIn C++98, exception specifications were rather temperamental beasts. You had to\nsummarize the exception types a function might emit, so if the function’s implemen‐\ntation was modified, the exception specification might require revision, too. Chang‐\ning an exception specification could break client code, because callers might be\ndependent on the original exception specification. Compilers typically offered no\nhelp in maintaining consistency among function implementations, exception specifi‐\ncations, and client code. Most programmers ultimately decided that C++98 exception\nspecifications weren’t worth the trouble.\nDuring work on C++11, a consensus emerged that the truly meaningful information\nabout a function’s exception-emitting behavior was whether it had any. Black or\nwhite, either a function might emit an exception or it guaranteed that it wouldn’t.\nThis maybe-or-never dichotomy forms the basis of C++11’s exception specifications,\nwhich essentially replace C++98’s. (C++98-style exception specifications remain\nvalid, but they’re deprecated.) In C++11, unconditional noexcept is for functions\nthat guarantee they won’t emit exceptions.\nWhether a function should be so declared is a matter of interface design. The\nexception-emitting behavior of a function is of key interest to clients. Callers can\nquery a function’s noexcept status, and the results of such a query can affect the\nexception safety or efficiency of the calling code. As such, whether a function is\nnoexcept is as important a piece of information as whether a member function is\nconst. Failure to declare a function noexcept when you know that it won’t emit an\nexception is simply poor interface specification.\nBut there’s an additional incentive to apply noexcept to functions that won’t pro‐\nduce exceptions: it permits compilers to generate better object code. To understand\nwhy, it helps to examine the difference between the C++98 and C++11 ways of saying\nthat a function won’t emit exceptions. Consider a function f that promises callers\nthey’ll never receive an exception. The two ways of expressing that are:\nint f(int x) throw();     // no exceptions from f: C++98 style\nint f(int x) noexcept;    // no exceptions from f: C++11 style\nIf, at runtime, an exception leaves f, f’s exception specification is violated. With the\nC++98 exception specification, the call stack is unwound to f’s caller, and, after some\nactions not relevant here, program execution is terminated. With the C++11 excep‐\ntion specification, runtime behavior is slightly different: the stack is only possibly\nunwound before program execution is terminated.\n90 \n| \nItem 14\nwww.it-ebooks.info\n",
      "content_length": 2720,
      "extraction_method": "Direct"
    },
    {
      "page_number": 109,
      "chapter": null,
      "content": "The difference between unwinding the call stack and possibly unwinding it has a sur‐\nprisingly large impact on code generation. In a noexcept function, optimizers need\nnot keep the runtime stack in an unwindable state if an exception would propagate\nout of the function, nor must they ensure that objects in a noexcept function are\ndestroyed in the inverse order of construction should an exception leave the function.\nFunctions with “throw()” exception specifications lack such optimization flexibility,\nas do functions with no exception specification at all. The situation can be summar‐\nized this way:\nRetType function(params) noexcept;     // most optimizable\nRetType function(params) throw();      // less optimizable\nRetType function(params);              // less optimizable\nThis alone is sufficient reason to declare functions noexcept whenever you know\nthey won’t produce exceptions.\nFor some functions, the case is even stronger. The move operations are the preemi‐\nnent example. Suppose you have a C++98 code base making use of a std::vec\ntor<Widget>. Widgets are added to the std::vector from time to time via\npush_back:\nstd::vector<Widget> vw;\n…\nWidget w;\n…                        // work with w\nvw.push_back(w);         // add w to vw\n…\nAssume this code works fine, and you have no interest in modifying it for C++11.\nHowever, you do want to take advantage of the fact that C++11’s move semantics can\nimprove the performance of legacy code when move-enabled types are involved. You\ntherefore ensure that Widget has move operations, either by writing them yourself or\nby seeing to it that the conditions for their automatic generation are fulfilled (see\nItem 17).\nWhen a new element is added to a std::vector, it’s possible that the std::vector\nlacks space for it, i.e., that the std::vector’s size is equal to its capacity. When that\nhappens, the std::vector allocates a new, larger, chunk of memory to hold its\nItem 14 \n| \n91\nwww.it-ebooks.info\n",
      "content_length": 1960,
      "extraction_method": "Direct"
    },
    {
      "page_number": 110,
      "chapter": null,
      "content": "3 The \nchecking \nis \ntypically \nrather \nroundabout. \nFunctions \nlike \nstd::vector::push_back \ncall\nstd::move_if_noexcept, a variation of std::move that conditionally casts to an rvalue (see Item 23),\ndepending on whether the type’s move constructor is noexcept. In turn, std::move_if_noexcept consults\nstd::is_nothrow_move_constructible, and the value of this type trait (see Item 9) is set by compilers,\nbased on whether the move constructor has a noexcept (or throw()) designation.\nelements, and it transfers the elements from the existing chunk of memory to the new\none. In C++98, the transfer was accomplished by copying each element from the old\nmemory to the new memory, then destroying the objects in the old memory. This\napproach enabled push_back to offer the strong exception safety guarantee: if an\nexception was thrown during the copying of the elements, the state of the std::vec\ntor remained unchanged, because none of the elements in the old memory were\ndestroyed until all elements had been successfully copied into the new memory.\nIn C++11, a natural optimization would be to replace the copying of std::vector\nelements with moves. Unfortunately, doing this runs the risk of violating\npush_back’s exception safety guarantee. If n elements have been moved from the old\nmemory and an exception is thrown moving element n+1, the push_back operation\ncan’t run to completion. But the original std::vector has been modified: n of its\nelements have been moved from. Restoring their original state may not be possible,\nbecause attempting to move each object back into the original memory may itself\nyield an exception.\nThis is a serious problem, because the behavior of legacy code could depend on\npush_back’s strong exception safety guarantee. Therefore, C++11 implementations\ncan’t silently replace copy operations inside push_back with moves unless it’s known\nthat the move operations won’t emit exceptions. In that case, having moves replace\ncopies would be safe, and the only side effect would be improved performance.\nstd::vector::push_back takes advantage of this “move if you can, but copy if you\nmust” strategy, and it’s not the only function in the Standard Library that does. Other\nfunctions sporting the strong exception safety guarantee in C++98 (e.g., std::vec\ntor::reserve, std::deque::insert, etc.) behave the same way. All these functions\nreplace calls to copy operations in C++98 with calls to move operations in C++11\nonly if the move operations are known to not emit exceptions. But how can a func‐\ntion know if a move operation won’t produce an exception? The answer is obvious: it\nchecks to see if the operation  is declared noexcept.3\nswap functions comprise another case where noexcept is particularly desirable. swap\nis a key component of many STL algorithm implementations, and it’s commonly\nemployed in copy assignment operators, too. Its widespread use renders the opti‐\nmizations that noexcept affords especially worthwhile. Interestingly, whether swaps\nin the Standard Library are noexcept is sometimes dependent on whether user-\n92 \n| \nItem 14\nwww.it-ebooks.info\n",
      "content_length": 3103,
      "extraction_method": "Direct"
    },
    {
      "page_number": 111,
      "chapter": null,
      "content": "defined swaps are noexcept. For example, the declarations for the Standard Library’s\nswaps for arrays and std::pair are:\ntemplate <class T, size_t N>\nvoid swap(T (&a)[N],                                    // see\n          T (&b)[N]) noexcept(noexcept(swap(*a, *b)));  // below\ntemplate <class T1, class T2>\nstruct pair {\n  …\n  void swap(pair& p) noexcept(noexcept(swap(first, p.first)) &&\n                              noexcept(swap(second, p.second)));\n  …\n};\nThese functions are conditionally noexcept: whether they are noexcept depends on\nwhether the expressions inside the noexcept clauses are noexcept. Given two arrays\nof Widget, for example, swapping them is noexcept only if swapping individual ele‐\nments in the arrays is noexcept, i.e., if swap for Widget is noexcept. The author of\nWidget’s swap thus determines whether swapping arrays of Widget is noexcept.\nThat, in turn, determines whether other swaps, such as the one for arrays of arrays of\nWidget, are noexcept. Similarly, whether swapping two std::pair objects contain‐\ning Widgets is noexcept depends on whether swap for Widgets is noexcept. The\nfact that swapping higher-level data structures can generally be noexcept only if\nswapping their lower-level constituents is noexcept should motivate you to offer\nnoexcept swap functions whenever you can.\nBy now, I hope you’re excited about the optimization opportunities that noexcept\naffords. Alas, I must temper your enthusiasm. Optimization is important, but cor‐\nrectness is more important. I noted at the beginning of this Item that noexcept is\npart of a function’s interface, so you should declare a function noexcept only if you\nare willing to commit to a noexcept implementation over the long term. If you\ndeclare a function noexcept and later regret that decision, your options are bleak.\nYou can remove noexcept from the function’s declaration (i.e., change its interface),\nthus running the risk of breaking client code. You can change the implementation\nsuch that an exception could escape, yet keep the original (now incorrect) exception\nspecification. If you do that, your program will be terminated if an exception tries to\nleave the function. Or you can resign yourself to your existing implementation, aban‐\ndoning whatever kindled your desire to change the implementation in the first place.\nNone of these options is appealing.\nThe fact of the matter is that most functions are exception-neutral. Such functions\nthrow no exceptions themselves, but functions they call might emit one. When that\nItem 14 \n| \n93\nwww.it-ebooks.info\n",
      "content_length": 2562,
      "extraction_method": "Direct"
    },
    {
      "page_number": 112,
      "chapter": null,
      "content": "4 The interface specifications for move operations on containers in the Standard Library lack noexcept. How‐\never, implementers are permitted to strengthen exception specifications for Standard Library functions, and,\nin practice, it is common for at least some container move operations to be declared noexcept. That practice\nexemplifies this Item’s advice. Having found that it’s possible to write container move operations such that\nexceptions aren’t thrown, implementers often declare the operations noexcept, even though the Standard\ndoes not require them to do so.\nhappens, the exception-neutral function allows the emitted exception to pass through\non its way to a handler further up the call chain. Exception-neutral functions are\nnever noexcept, because they may emit such “just passing through” exceptions. Most\nfunctions, therefore, quite properly lack the noexcept designation.\nSome functions, however, have natural implementations that emit no exceptions, and\nfor a few more—notably the move operations and swap—being noexcept can have\nsuch a significant payoff, it’s worth implementing them in a noexcept manner if at\nall possible.4 When you can honestly say that a function should never emit excep‐\ntions, you should definitely declare it noexcept.\nPlease note that I said some functions have natural noexcept implementations.\nTwisting a function’s implementation to permit a noexcept declaration is the tail\nwagging the dog. Is putting the cart before the horse. Is not seeing the forest for the\ntrees. Is…choose your favorite metaphor. If a straightforward function implementa‐\ntion might yield exceptions (e.g., by invoking a function that might throw), the hoops\nyou’ll jump through to hide that from callers (e.g., catching all exceptions and replac‐\ning them with status codes or special return values) will not only complicate your\nfunction’s implementation, it will typically complicate code at call sites, too. For\nexample, callers may have to check for status codes or special return values. The run‐\ntime cost of those complications (e.g., extra branches, larger functions that put more\npressure on instruction caches, etc.) could exceed any speedup you’d hope to achieve\nvia noexcept, plus you’d be saddled with source code that’s more difficult to com‐\nprehend and maintain. That’d be poor software engineering.\nFor some functions, being noexcept is so important, they’re that way by default. In\nC++98, it was considered bad style to permit the memory deallocation functions (i.e.,\noperator delete and operator delete[]) and destructors to emit exceptions, and\nin C++11, this style rule has been all but upgraded to a language rule. By default, all\nmemory deallocation functions and all destructors—both user-defined and compiler-\ngenerated—are implicitly noexcept. There’s thus no need to declare them noexcept.\n(Doing so doesn’t hurt anything, it’s just unconventional.) The only time a destructor\nis not implicitly noexcept is when a data member of the class (including inherited\nmembers and those contained inside other data members) is of a type that expressly\nstates that its destructor may emit exceptions (e.g., declares it “noexcept(false)”).\nSuch destructors are uncommon. There are none in the Standard Library, and if the\n94 \n| \nItem 14\nwww.it-ebooks.info\n",
      "content_length": 3296,
      "extraction_method": "Direct"
    },
    {
      "page_number": 113,
      "chapter": null,
      "content": "5 “Regardless of the state of the program” and “no constraints” doesn’t legitimize programs whose behavior is\nalready undefined. For example, std::vector::size has a wide contract, but that doesn’t require that it\nbehave reasonably if you invoke it on a random chunk of memory that you’ve cast to a std::vector. The\nresult of the cast is undefined, so there are no behavioral guarantees for the program containing the cast.\ndestructor for an object being used by the Standard Library (e.g., because it’s in a\ncontainer or was passed to an algorithm) emits an exception, the behavior of the pro‐\ngram is undefined.\nIt’s worth noting that some library interface designers distinguish functions with\nwide contracts from those with narrow contracts. A function with a wide contract has\nno preconditions. Such a function may be called regardless of the state of the pro‐\ngram, and it imposes no constraints on the arguments that callers pass it.5 Functions\nwith wide contracts never exhibit undefined behavior.\nFunctions without wide contracts have narrow contracts. For such functions, if a pre‐\ncondition is violated, results are undefined.\nIf you’re writing a function with a wide contract and you know it won’t emit excep‐\ntions, following the advice of this Item and declaring it noexcept is easy. For func‐\ntions with narrow contracts, the situation is trickier. For example, suppose you’re\nwriting a function f taking a std::string parameter, and suppose f’s natural imple‐\nmentation never yields an exception. That suggests that f should be declared noex\ncept.\nNow suppose that f has a precondition: the length of its std::string parameter\ndoesn’t exceed 32 characters. If f were to be called with a std::string whose length\nis greater than 32, behavior would be undefined, because a precondition violation by\ndefinition results in undefined behavior. f is under no obligation to check this pre‐\ncondition, because functions may assume that their preconditions are satisfied. (Call‐\ners are responsible for ensuring that such assumptions are valid.) Even with a\nprecondition, then, declaring f noexcept seems  appropriate:\nvoid f(const std::string& s) noexcept;    // precondition:\n                                          // s.length() <= 32\nBut suppose that f’s implementer chooses to check for precondition violations.\nChecking isn’t required, but it’s also not forbidden, and checking the precondition\ncould be useful, e.g., during system testing. Debugging an exception that’s been\nthrown is generally easier than trying to track down the cause of undefined behavior.\nBut how should a precondition violation be reported such that a test harness or a cli‐\nent error handler could detect it? A straightforward approach would be to throw a\n“precondition was violated” exception, but if f is declared noexcept, that would be\nimpossible; throwing an exception would lead to program termination. For this rea‐\nItem 14 \n| \n95\nwww.it-ebooks.info\n",
      "content_length": 2947,
      "extraction_method": "Direct"
    },
    {
      "page_number": 114,
      "chapter": null,
      "content": "son, library designers who distinguish wide from narrow contracts generally reserve\nnoexcept for functions with wide contracts.\nAs a final point, let me elaborate on my earlier observation that compilers typically\noffer no help in identifying inconsistencies between function implementations and\ntheir exception specifications. Consider this code, which is perfectly legal:\nvoid setup();           // functions defined elsewhere\nvoid cleanup();\nvoid doWork() noexcept\n{\n  setup();              // set up work to be done\n  …                     // do the actual work\n  cleanup();            // perform cleanup actions\n}\nHere, doWork is declared noexcept, even though it calls the non-noexcept functions\nsetup and cleanup. This seems contradictory, but it could be that setup and\ncleanup document that they never emit exceptions, even though they’re not declared\nthat way. There could be good reasons for their non-noexcept declarations. For\nexample, they might be part of a library written in C. (Even functions from the\nC Standard Library that have been moved into the std namespace lack exception\nspecifications, e.g., std::strlen isn’t declared noexcept.) Or they could be part of a\nC++98 library that decided not to use C++98 exception specifications and hasn’t yet\nbeen revised for C++11.\nBecause there are legitimate reasons for noexcept functions to rely on code lacking\nthe noexcept guarantee, C++ permits such code, and compilers generally don’t issue\nwarnings about it.\nThings to Remember\n• noexcept is part of a function’s interface, and that means that callers may\ndepend on it.\n• noexcept functions are more optimizable than non-noexcept functions.\n• noexcept is particularly valuable for the move operations, swap, memory\ndeallocation functions, and destructors.\n• Most functions are exception-neutral rather than noexcept.\n96 \n| \nItem 14\nwww.it-ebooks.info\n",
      "content_length": 1871,
      "extraction_method": "Direct"
    },
    {
      "page_number": 115,
      "chapter": null,
      "content": "Item 15: Use constexpr whenever possible.\nIf there were an award for the most confusing new word in C++11, constexpr would\nprobably win it. When applied to objects, it’s essentially a beefed-up form of const,\nbut when applied to functions, it has a quite different meaning. Cutting through the\nconfusion is worth the trouble, because when constexpr corresponds to what you\nwant to express, you definitely want to use it.\nConceptually, constexpr indicates a value that’s not only constant, it’s known dur‐\ning compilation. The concept is only part of the story, though, because when con\nstexpr is applied to functions, things are more nuanced than this suggests. Lest I\nruin the surprise ending, for now I’ll just say that you can’t assume that the results of\nconstexpr functions are const, nor can you take for granted that their values are\nknown during compilation. Perhaps most intriguingly, these things are features. It’s\ngood that constexpr functions need not produce results that are const or known\nduring compilation!\nBut let’s begin with constexpr objects. Such objects are, in fact, const, and they do,\nin fact, have values that are known at compile time. (Technically, their values are\ndetermined during translation, and translation consists not just of compilation but\nalso of linking. Unless you write compilers or linkers for C++, however, this has no\neffect on you, so you can blithely program as if the values of constexpr objects were\ndetermined during compilation.)\nValues known during compilation are privileged. They may be placed in read-only\nmemory, for example, and, especially for developers of embedded systems, this can\nbe a feature of considerable importance. Of broader applicability is that integral val‐\nues that are constant and known during compilation can be used in contexts where\nC++ requires an integral constant expression. Such contexts include specification of\narray sizes, integral template arguments (including lengths of std::array objects),\nenumerator values, alignment specifiers, and more. If you want to use a variable for\nthese kinds of things, you certainly want to declare it constexpr, because then com‐\npilers will ensure that it has a compile-time value:\nint sz;                             // non-constexpr variable\n…\nconstexpr auto arraySize1 = sz;     // error! sz's value not\n                                    // known at compilation\nstd::array<int, sz> data1;          // error! same problem\nconstexpr auto arraySize2 = 10;     // fine, 10 is a\nItem 15 \n| \n97\nwww.it-ebooks.info\n",
      "content_length": 2537,
      "extraction_method": "Direct"
    },
    {
      "page_number": 116,
      "chapter": null,
      "content": "                                    // compile-time constant\nstd::array<int, arraySize2> data2;  // fine, arraySize2\n                                    // is constexpr\nNote that const doesn’t offer the same guarantee as constexpr, because const\nobjects need not be initialized with values known during compilation:\nint sz;                             // as before\n…\nconst auto arraySize = sz;          // fine, arraySize is\n                                    // const copy of sz\nstd::array<int, arraySize> data;    // error! arraySize's value\n                                    // not known at compilation\nSimply put, all constexpr objects are const, but not all const objects are con\nstexpr. If you want compilers to guarantee that a variable has a value that can be\nused in contexts requiring compile-time constants, the tool to reach for is con\nstexpr, not const.\nUsage scenarios for constexpr objects become more interesting when constexpr\nfunctions are involved. Such functions produce compile-time constants when they\nare called with compile-time constants. If they’re called with values not known until\nruntime, they produce runtime values. This may sound as if you don’t know what\nthey’ll do, but that’s the wrong way to think about it. The right way to view it is this:\n• constexpr functions can be used in contexts that demand compile-time con‐\nstants. If the values of the arguments you pass to a constexpr function in such a\ncontext are known during compilation, the result will be computed during\ncompilation. If any of the arguments’ values is not known during compilation,\nyour code will be rejected.\n• When a constexpr function is called with one or more values that are not\nknown during compilation, it acts like a normal function, computing its result at\nruntime. This means you don’t need two functions to perform the same opera‐\ntion, one for compile-time constants and one for all other values. The constexpr\nfunction does it all.\nSuppose we need a data structure to hold the results of an experiment that can be run\nin a variety of ways. For example, the lighting level can be high, low, or off during the\ncourse of the experiment, as can the fan speed and the temperature, etc. If there are n\nenvironmental conditions relevant to the experiment, each of which has three possi‐\n98 \n| \nItem 15\nwww.it-ebooks.info\n",
      "content_length": 2337,
      "extraction_method": "Direct"
    },
    {
      "page_number": 117,
      "chapter": null,
      "content": "ble states, the number of combinations is 3n. Storing experimental results for all com‐\nbinations of conditions thus requires a data structure with enough room for 3n values.\nAssuming each result is an int and that n is known (or can be computed) during\ncompilation, a std::array could be a reasonable data structure choice. But we’d\nneed a way to compute 3n during compilation. The C++ Standard Library provides\nstd::pow, which is the mathematical functionality we need, but, for our purposes,\nthere are two problems with it. First, std::pow works on floating-point types, and we\nneed an integral result. Second, std::pow isn’t constexpr (i.e., isn’t guaranteed to\nreturn a compile-time result when called with compile-time values), so we can’t use it\nto specify a std::array’s size.\nFortunately, we can write the pow we need. I’ll show how to do that in a moment, but\nfirst let’s look at how it could be declared and used:\nconstexpr                              // pow's a constexpr func\nint pow(int base, int exp) noexcept    // that never throws\n{\n  …                                    // impl is below\n}\nconstexpr auto numConds = 5;                 // # of conditions\nstd::array<int, pow(3, numConds)> results;   // results has\n                                             // 3^numConds\n                                             // elements\nRecall that the constexpr in front of pow doesn’t say that pow returns a const value,\nit says that if base and exp are compile-time constants, pow’s result may be used as a\ncompile-time constant. If base and/or exp are not compile-time constants, pow’s\nresult will be computed at runtime. That means that pow can not only be called to do\nthings like compile-time-compute the size of a std::array, it can also be called in\nruntime contexts such as this:\nauto base = readFromDB(\"base\");       // get these values\nauto exp = readFromDB(\"exponent\");    // at runtime\nauto baseToExp = pow(base, exp);      // call pow function\n                                      // at runtime\nBecause constexpr functions must be able to return compile-time results when\ncalled with compile-time values, restrictions are imposed on their implementations.\nThe restrictions differ between C++11 and C++14.\nIn C++11, constexpr functions may contain no more than a single executable state‐\nment: a return. That sounds more limiting than it is, because two tricks can be used\nItem 15 \n| \n99\nwww.it-ebooks.info\n",
      "content_length": 2435,
      "extraction_method": "Direct"
    },
    {
      "page_number": 118,
      "chapter": null,
      "content": "to extend the expressiveness of constexpr functions beyond what you might think.\nFirst, the conditional “?:” operator can be used in place of if-else statements, and\nsecond, recursion can be used instead of loops. pow can therefore be implemented\nlike this:\nconstexpr int pow(int base, int exp) noexcept\n{\n  return (exp == 0 ? 1 : base * pow(base, exp - 1));\n}\nThis works, but it’s hard to imagine that anybody except a hard-core functional pro‐\ngrammer would consider it pretty. In C++14, the restrictions on constexpr func‐\ntions are substantially looser, so the following implementation becomes possible:\nconstexpr int pow(int base, int exp) noexcept       // C++14\n{\n  auto result = 1;\n  for (int i = 0; i < exp; ++i) result *= base;\n  return result;\n}\nconstexpr functions are limited to taking and returning literal types, which essen‐\ntially means types that can have values determined during compilation. In C++11, all\nbuilt-in types except void qualify, but user-defined types may be literal, too, because\nconstructors and other member functions may be constexpr:\nclass Point {\npublic:\n  constexpr Point(double xVal = 0, double yVal = 0) noexcept\n  : x(xVal), y(yVal)\n  {}\n  constexpr double xValue() const noexcept { return x; }\n  constexpr double yValue() const noexcept { return y; }\n  void setX(double newX) noexcept { x = newX; }\n  void setY(double newY) noexcept { y = newY; }\nprivate:\n  double x, y;\n};\nHere, the Point constructor can be declared constexpr, because if the arguments\npassed to it are known during compilation, the value of the data members of the con‐\n100 \n| \nItem 15\nwww.it-ebooks.info\n",
      "content_length": 1618,
      "extraction_method": "Direct"
    },
    {
      "page_number": 119,
      "chapter": null,
      "content": "6 Because Point::xValue returns double, the type of mid.xValue() * 10 is also double. Floating-point types\ncan’t be used to instantiate templates or to specify enumerator values, but they can be used as part of larger\nexpressions that yield integral types. For example, static_cast<int>(mid.xValue() * 10) could be used to\ninstantiate a template or to specify an enumerator value.\nstructed Point can also be known during compilation. Points so initialized could\nthus be constexpr:\nconstexpr Point p1(9.4, 27.7);      // fine, \"runs\" constexpr\n                                    // ctor during compilation\nconstexpr Point p2(28.8, 5.3);      // also fine\nSimilarly, the getters xValue and yValue can be constexpr, because if they’re\ninvoked on a Point object with a value known during compilation (e.g., a constexpr\nPoint object), the values of the data members x and y can be known during compila‐\ntion. That makes it possible to write constexpr functions that call Point’s getters\nand to initialize constexpr objects with the results of such functions:\nconstexpr\nPoint midpoint(const Point& p1, const Point& p2) noexcept\n{\n  return { (p1.xValue() + p2.xValue()) / 2,    // call constexpr\n           (p1.yValue() + p2.yValue()) / 2 };  // member funcs\n}\nconstexpr auto mid = midpoint(p1, p2);     // init constexpr\n                                           // object w/result of\n                                           // constexpr function\nThis is very exciting. It means that the object mid, though its initialization involves\ncalls to constructors, getters, and a non-member function, can be created in read-\nonly memory! It means you could use an expression like mid.xValue() * 10 in an\nargument to a template or in an expression specifying the value of an enumerator!6 It\nmeans that the traditionally fairly strict line between work done during compilation\nand work done at runtime begins to blur, and some computations traditionally done\nat runtime can migrate to compile time. The more code taking part in the migration,\nthe faster your software will run. (Compilation may take longer, however.)\nIn C++11, two restrictions prevent Point’s member functions setX and setY from\nbeing declared constexpr. First, they modify the object they operate on, and in\nC++11, constexpr member functions are implicitly const. Second, they have void\nreturn types, and void isn’t a literal type in C++11. Both these restrictions are lifted\nin C++14, so in C++14, even Point’s setters can be constexpr:\nItem 15 \n| \n101\nwww.it-ebooks.info\n",
      "content_length": 2532,
      "extraction_method": "Direct"
    },
    {
      "page_number": 120,
      "chapter": null,
      "content": "class Point {\npublic:\n  …\n  constexpr void setX(double newX) noexcept     // C++14\n  { x = newX; }\n  constexpr void setY(double newY) noexcept     // C++14\n  { y = newY; }\n  …\n};\nThat makes it possible to write functions like this:\n// return reflection of p with respect to the origin (C++14)\nconstexpr Point reflection(const Point& p) noexcept\n{\n  Point result;                       // create non-const Point\n  result.setX(-p.xValue());           // set its x and y values\n  result.setY(-p.yValue());\n  return result;                      // return copy of it\n}\nClient code could look like this:\nconstexpr Point p1(9.4, 27.7);        // as above\nconstexpr Point p2(28.8, 5.3);\nconstexpr auto mid = midpoint(p1, p2);\nconstexpr auto reflectedMid =         // reflectedMid's value is\n  reflection(mid);                    // (-19.1 -16.5) and known\n                                      // during compilation\nThe advice of this Item is to use constexpr whenever possible, and by now I hope it’s\nclear why: both constexpr objects and constexpr functions can be employed in a\nwider range of contexts than non-constexpr objects and functions. By using con\nstexpr whenever possible, you maximize the range of situations in which your\nobjects and functions may be used.\nIt’s important to note that constexpr is part of an object’s or function’s interface.\nconstexpr proclaims “I can be used in a context where C++ requires a constant\nexpression.” If you declare an object or function constexpr, clients may use it in\n102 \n| \nItem 15\nwww.it-ebooks.info\n",
      "content_length": 1546,
      "extraction_method": "Direct"
    },
    {
      "page_number": 121,
      "chapter": null,
      "content": "such contexts. If you later decide that your use of constexpr was a mistake and you\nremove it, you may cause arbitrarily large amounts of client code to stop compiling.\n(The simple act of adding I/O to a function for debugging or performance tuning\ncould lead to such a problem, because I/O statements are generally not permitted in\nconstexpr functions.) Part of “whenever possible” in “Use constexpr whenever\npossible” is your willingness to make a long-term commitment to the constraints it\nimposes on the objects and functions you apply it to.\nThings to Remember\n• constexpr objects are const and are initialized with values known during\ncompilation.\n• constexpr functions can produce compile-time results when called with\narguments whose values are known during compilation.\n• constexpr objects and functions may be used in a wider range of contexts\nthan non-constexpr objects and functions.\n• constexpr is part of an object’s or function’s interface.\nItem 16: Make const member functions thread safe.\nIf we’re working in a mathematical domain, we might find it convenient to have a\nclass representing polynomials. Within this class, it would probably be useful to have\na function to compute the root(s) of a polynomial, i.e., values where the polynomial\nevaluates to zero. Such a function would not modify the polynomial, so it’d be natural\nto  declare it const:\nclass Polynomial {\npublic:\n  using RootsType =          // data structure holding values\n    std::vector<double>;     // where polynomial evals to zero\n  …                          // (see Item 9 for info on \"using\")\n  RootsType roots() const;\n  …\n};\nComputing the roots of a polynomial can be expensive, so we don’t want to do it if\nwe don’t have to. And if we do have to do it, we certainly don’t want to do it more\nthan once. We’ll thus cache the root(s) of the polynomial if we have to compute\nItem 15 \n| \n103\nwww.it-ebooks.info\n",
      "content_length": 1901,
      "extraction_method": "Direct"
    },
    {
      "page_number": 122,
      "chapter": null,
      "content": "them, and we’ll implement roots to return the cached value. Here’s the basic\napproach:\nclass Polynomial {\npublic:\n  using RootsType = std::vector<double>;\n  RootsType roots() const\n  {\n    if (!rootsAreValid) {            // if cache not valid\n      …                              // compute roots,\n                                     // store them in rootVals\n      rootsAreValid = true;\n    }\n    return rootVals;\n  }\nprivate:\n  mutable bool rootsAreValid{ false };    // see Item 7 for info\n  mutable RootsType rootVals{};           // on initializers\n};\nConceptually, roots doesn’t change the Polynomial object on which it operates, but,\nas part of its caching activity, it may need to modify rootVals and rootsAreValid.\nThat’s a classic use case for mutable, and that’s why it’s part of the declarations for\nthese data members.\nImagine now that two threads simultaneously call roots on a Polynomial object:\nPolynomial p;\n…\n/*-----  Thread 1  ----- */     /*-------  Thread 2  ------- */\nauto rootsOfP = p.roots();      auto valsGivingZero = p.roots();\nThis client code is perfectly reasonable. roots is a const member function, and that\nmeans it represents a read operation. Having multiple threads perform a read opera‐\ntion without synchronization is safe. At least it’s supposed to be. In this case, it’s not,\nbecause inside roots, one or both of these threads might try to modify the data\nmembers rootsAreValid and rootVals. That means that this code could have dif‐\n104 \n| \nItem 16\nwww.it-ebooks.info\n",
      "content_length": 1512,
      "extraction_method": "Direct"
    },
    {
      "page_number": 123,
      "chapter": null,
      "content": "ferent threads reading and writing the same memory without synchronization, and\nthat’s the definition of a data race. This code has undefined behavior.\nThe problem is that roots is declared const, but it’s not thread safe. The const dec‐\nlaration is as correct in C++11 as it would be in C++98 (retrieving the roots of a poly‐\nnomial doesn’t change the value of the polynomial), so what requires rectification is\nthe lack of thread safety.\nThe easiest way to address the issue is the usual one: employ a mutex:\nclass Polynomial {\npublic:\n  using RootsType = std::vector<double>;\n  RootsType roots() const\n  {\n    std::lock_guard<std::mutex> g(m);     // lock mutex\n    if (!rootsAreValid) {                 // if cache not valid\n      …                                   // compute/store roots\n      rootsAreValid = true;\n    }\n    return rootVals;\n  }                                       // unlock mutex\nprivate:\n  mutable std::mutex m;\n  mutable bool rootsAreValid{ false };\n  mutable RootsType rootVals{};\n};\nThe std::mutex m is declared mutable, because locking and unlocking it are non-\nconst member functions, and within roots (a const member function), m would\notherwise be considered a const object.\nIt’s worth noting that because std::mutex is a move-only type (i.e., a type that can be\nmoved, but not copied), a side effect of adding m to Polynomial is that Polynomial\nloses the ability to be copied. It can still be moved, however.\nIn some situations, a mutex is overkill. For example, if all you’re doing is counting\nhow many times a member function is called, a std::atomic counter (i.e, one where\nother threads are guaranteed to see its operations occur indivisibly—see Item 40) will\noften be a less expensive way to go. (Whether it actually is less expensive depends on\nItem 16 \n| \n105\nwww.it-ebooks.info\n",
      "content_length": 1822,
      "extraction_method": "Direct"
    },
    {
      "page_number": 124,
      "chapter": null,
      "content": "the hardware you’re running on and the implementation of mutexes in your Stan‐\ndard Library.) Here’s how you can employ a std::atomic to count calls:\nclass Point {                                // 2D point\npublic:\n  …\n  double distanceFromOrigin() const noexcept     // see Item 14\n  {                                              // for noexcept\n    ++callCount;                             // atomic increment\n    return std::sqrt((x * x) + (y * y));\n  }\nprivate:\n  mutable std::atomic<unsigned> callCount{ 0 };\n  double x, y;\n};\nLike std::mutexes, std::atomics are move-only types, so the existence of call\nCount in Point means that Point is also move-only.\nBecause operations on std::atomic variables are often less expensive than mutex\nacquisition and release, you may be tempted to lean on std::atomics more heavily\nthan you should. For example, in a class caching an expensive-to-compute int, you\nmight try to use a pair of std::atomic variables instead of a mutex:\nclass Widget {\npublic:\n  …\n  int magicValue() const\n  {\n    if (cacheValid) return cachedValue;\n    else {\n      auto val1 = expensiveComputation1();\n      auto val2 = expensiveComputation2();\n      cachedValue = val1 + val2;               // uh oh, part 1\n      cacheValid = true;                       // uh oh, part 2\n      return cachedValue;\n    }\n  }\nprivate:\n106 \n| \nItem 16\nwww.it-ebooks.info\n",
      "content_length": 1375,
      "extraction_method": "Direct"
    },
    {
      "page_number": 125,
      "chapter": null,
      "content": "  mutable std::atomic<bool> cacheValid{ false };\n  mutable std::atomic<int> cachedValue;\n};\nThis will work, but sometimes it will work a lot harder than it should. Consider:\n• A thread calls Widget::magicValue, sees cacheValid as false, performs the\ntwo expensive computations, and assigns their sum to cachedValue.\n• At that point, a second thread calls Widget::magicValue, also sees cacheValid\nas false, and thus carries out the same expensive computations that the first\nthread has just finished. (This “second thread” may in fact be several other\nthreads.)\nSuch behavior is contrary to the goal of caching. Reversing the order of the assign‐\nments to cachedValue and CacheValid eliminates that problem, but the result is\neven worse:\nclass Widget {\npublic:\n  …\n  int magicValue() const\n  {\n    if (cacheValid) return cachedValue;\n    else {\n      auto val1 = expensiveComputation1();\n      auto val2 = expensiveComputation2();\n      cacheValid = true;                        // uh oh, part 1\n      return cachedValue = val1 + val2;         // uh oh, part 2\n    }\n  }\n  …\n};\nImagine that cacheValid is false, and then:\n• One thread calls Widget::magicValue and executes through the point where\ncacheValid is set to true.\n• At that moment, a second thread calls Widget::magicValue and checks cache\nValid. Seeing it true, the thread returns cachedValue, even though the first\nItem 16 \n| \n107\nwww.it-ebooks.info\n",
      "content_length": 1411,
      "extraction_method": "Direct"
    },
    {
      "page_number": 126,
      "chapter": null,
      "content": "thread has not yet made an assignment to it. The returned value is therefore\nincorrect.\nThere’s a lesson here. For a single variable or memory location requiring synchroni‐\nzation, use of a std::atomic is adequate, but once you get to two or more variables\nor memory locations that require manipulation as a unit, you should reach for a\nmutex. For Widget::magicValue, that would look like this:\nclass Widget {\npublic:\n  …\n  int magicValue() const\n  {\n    std::lock_guard<std::mutex> guard(m);   // lock m\n    if (cacheValid) return cachedValue;\n    else {\n      auto val1 = expensiveComputation1();\n      auto val2 = expensiveComputation2();\n      cachedValue = val1 + val2;\n      cacheValid = true;\n      return cachedValue;\n    }\n  }                                         // unlock m\n  …\nprivate:\n  mutable std::mutex m;\n  mutable int cachedValue;                  // no longer atomic\n  mutable bool cacheValid{ false };         // no longer atomic\n};\nNow, this Item is predicated on the assumption that multiple threads may simultane‐\nously execute a const member function on an object. If you’re writing a const mem‐\nber function where that’s not the case—where you can guarantee that there will never\nbe more than one thread executing that member function on an object—the thread\nsafety of the function is immaterial. For example, it’s unimportant whether member\nfunctions of classes designed for exclusively single-threaded use are thread safe. In\nsuch cases, you can avoid the costs associated with mutexes and std::atomics, as\nwell as the side effect of their rendering the classes containing them move-only. How‐\never, such threading-free scenarios are increasingly uncommon, and they’re likely to\nbecome rarer still. The safe bet is that const member functions will be subject to con‐\n108 \n| \nItem 16\nwww.it-ebooks.info\n",
      "content_length": 1832,
      "extraction_method": "Direct"
    },
    {
      "page_number": 127,
      "chapter": null,
      "content": "current execution, and that’s why you should ensure that your const member func‐\ntions are thread safe.\n \nThings to Remember\n• Make const member functions thread safe unless you’re certain they’ll never\nbe used in a concurrent context.\n• Use of std::atomic variables may offer better performance than a mutex, but\nthey’re suited for manipulation of only a single variable or memory location.\nItem 17: Understand special member function\ngeneration.\nIn official C++ parlance, the special member functions are the ones that C++ is willing\nto generate on its own. C++98 has four such functions: the default constructor, the\ndestructor, the copy constructor, and the copy assignment operator. There’s fine\nprint, of course. These functions are generated only if they’re needed, i.e., if some\ncode uses them without their being expressly declared in the class. A default con‐\nstructor is generated only if the class declares no constructors at all. (This prevents\ncompilers from creating a default constructor for a class where you’ve specified that\nconstructor arguments are required.) Generated special member functions are\nimplicitly public and inline, and they’re nonvirtual unless the function in question\nis a destructor in a derived class inheriting from a base class with a virtual destructor.\nIn that case, the compiler-generated destructor for the derived class is also virtual.\nBut you already know these things. Yes, yes, ancient history: Mesopotamia, the Shang\ndynasty, FORTRAN, C++98. But times have changed, and the rules for special mem‐\nber function generation in C++ have changed with them. It’s important to be aware\nof the new rules, because few things are as central to effective C++ programming as\nknowing when compilers silently insert member functions into your classes.\nAs of C++11, the special member functions club has two more inductees: the move\nconstructor and the move assignment operator. Their signatures are:\nclass Widget {\npublic:\n  …\n  Widget(Widget&& rhs);              // move constructor\n  Widget& operator=(Widget&& rhs);   // move assignment operator\n  …\n};\nItem 16 \n| \n109\nwww.it-ebooks.info\n",
      "content_length": 2128,
      "extraction_method": "Direct"
    },
    {
      "page_number": 128,
      "chapter": null,
      "content": "The rules governing their generation and behavior are analogous to those for their\ncopying siblings. The move operations are generated only if they’re needed, and if\nthey are generated, they perform “memberwise moves” on the non-static data mem‐\nbers of the class. That means that the move constructor move-constructs each non-\nstatic data member of the class from the corresponding member of its parameter rhs,\nand the move assignment operator move-assigns each non-static data member from\nits parameter. The move constructor also move-constructs its base class parts (if there\nare any), and the move assignment operator move-assigns its base class parts.\nNow, when I refer to a move operation move-constructing or move-assigning a data\nmember or base class, there is no guarantee that a move will actually take place.\n“Memberwise moves” are, in reality, more like memberwise move requests, because\ntypes that aren’t move-enabled (i.e., that offer no special support for move operations,\ne.g., most C++98 legacy classes) will be “moved” via their copy operations. The heart\nof each memberwise “move” is application of std::move to the object to be moved\nfrom, and the result is used during function overload resolution to determine\nwhether a move or a copy should be performed. Item 23 covers this process in detail.\nFor this Item, simply remember that a memberwise move consists of move opera‐\ntions on data members and base classes that support move operations, but a copy\noperation for those that don’t.\nAs is the case with the copy operations, the move operations aren’t generated if you\ndeclare them yourself. However, the precise conditions under which they are gener‐\nated differ a bit from those for the copy operations.\nThe two copy operations are independent: declaring one doesn’t prevent compilers\nfrom generating the other. So if you declare a copy constructor, but no copy assign‐\nment operator, then write code that requires copy assignment, compilers will gener‐\nate the copy assignment operator for you. Similarly, if you declare a copy assignment\noperator, but no copy constructor, yet your code requires copy construction, compil‐\ners will generate the copy constructor for you. That was true in C++98, and it’s still\ntrue in C++11.\nThe two move operations are not independent. If you declare either, that prevents\ncompilers from generating the other. The rationale is that if you declare, say, a move\nconstructor for your class, you’re indicating that there’s something about how move\nconstruction should be implemented that’s different from the default memberwise\nmove that compilers would generate. And if there’s something wrong with member‐\nwise move construction, there’d probably be something wrong with memberwise\nmove assignment, too. So declaring a move constructor prevents a move assignment\noperator from being generated, and declaring a move assignment operator prevents\ncompilers from generating a move constructor.\nFurthermore, move operations won’t be generated for any class that explicitly\ndeclares a copy operation. The justification is that declaring a copy operation (con‐\n110 \n| \nItem 17\nwww.it-ebooks.info\n",
      "content_length": 3149,
      "extraction_method": "Direct"
    },
    {
      "page_number": 129,
      "chapter": null,
      "content": "struction or assignment) indicates that the normal approach to copying an object\n(memberwise copy) isn’t appropriate for the class, and compilers figure that if mem‐\nberwise copy isn’t appropriate for the copy operations, memberwise move probably\nisn’t appropriate for the move operations.\nThis goes in the other direction, too. Declaring a move operation (construction or\nassignment) in a class causes compilers to disable the copy operations. (The copy\noperations are disabled by deleting them—see Item 11). After all, if memberwise\nmove isn’t the proper way to move an object, there’s no reason to expect that mem‐\nberwise copy is the proper way to copy it. This may sound like it could break C++98\ncode, because the conditions under which the copy operations are enabled are more\nconstrained in C++11 than in C++98, but this is not the case. C++98 code can’t have\nmove operations, because there was no such thing as “moving” objects in C++98. The\nonly way a legacy class can have user-declared move operations is if they were added\nfor C++11, and classes that are modified to take advantage of move semantics have to\nplay by the C++11 rules for special member function generation.\nPerhaps you’ve heard of a guideline known as the Rule of Three. The Rule of Three\nstates that if you declare any of a copy constructor, copy assignment operator, or\ndestructor, you should declare all three. It grew out of the observation that the need\nto take over the meaning of a copy operation almost always stemmed from the class\nperforming some kind of resource management, and that almost always implied that\n(1) whatever resource management was being done in one copy operation probably\nneeded to be done in the other copy operation and (2) the class destructor would also\nbe participating in management of the resource (usually releasing it). The classic\nresource to be managed was memory, and this is why all Standard Library classes that\nmanage memory (e.g., the STL containers that perform dynamic memory manage‐\nment) all declare “the big three”: both copy operations and a destructor. \nA consequence of the Rule of Three is that the presence of a user-declared destructor\nindicates that simple memberwise copy is unlikely to be appropriate for the copying\noperations in the class. That, in turn, suggests that if a class declares a destructor, the\ncopy operations probably shouldn’t be automatically generated, because they\nwouldn’t do the right thing. At the time C++98 was adopted, the significance of this\nline of reasoning was not fully appreciated, so in C++98, the existence of a user-\ndeclared destructor had no impact on compilers’ willingness to generate copy opera‐\ntions. That continues to be the case in C++11, but only because restricting the\nconditions under which the copy operations are generated would break too much\nlegacy code.\nThe reasoning behind the Rule of Three remains valid, however, and that, combined\nwith the observation that declaration of a copy operation precludes the implicit gen‐\neration of the move operations, motivates the fact that C++11 does not generate\nmove operations for a class with a user-declared destructor.\nItem 17 \n| \n111\nwww.it-ebooks.info\n",
      "content_length": 3189,
      "extraction_method": "Direct"
    },
    {
      "page_number": 130,
      "chapter": null,
      "content": "So move operations are generated for classes (when needed) only if these three things\nare true:\n• No copy operations are declared in the class.\n• No move operations are declared in the class.\n• No destructor is declared in the class.\nAt some point, analogous rules may be extended to the copy operations, because\nC++11 deprecates the automatic generation of copy operations for classes declaring\ncopy operations or a destructor. This means that if you have code that depends on\nthe generation of copy operations in classes declaring a destructor or one of the copy\noperations, you should consider upgrading these classes to eliminate the dependence.\nProvided the behavior of the compiler-generated functions is correct (i.e, if member‐\nwise copying of the class’s non-static data members is what you want), your job is\neasy, because C++11’s “= default” lets you say that explicitly:\nclass Widget {\npublic:\n  …\n  ~Widget();                             // user-declared dtor\n  …                                      // default copy ctor\n  Widget(const Widget&) = default;       // behavior is OK\n  Widget&                                // default copy assign\n    operator=(const Widget&) = default;  // behavior is OK\n  …\n};\nThis approach is often useful in polymorphic base classes, i.e., classes defining inter‐\nfaces through which derived class objects are manipulated. Polymorphic base classes\nnormally have virtual destructors, because if they don’t, some operations (e.g., the use\nof delete or typeid on a derived class object through a base class pointer or refer‐\nence) yield undefined or misleading results. Unless a class inherits a destructor that’s\nalready virtual, the only way to make a destructor virtual is to explicitly declare it that\nway. Often, the default implementation would be correct, and “= default” is a good\nway to express that. However, a user-declared destructor suppresses generation of the\nmove operations, so if movability is to be supported, “= default” often finds a sec‐\nond application. Declaring the move operations disables the copy operations, so if\ncopyability is also desired, one more round of “= default” does the job:\nclass Base {\npublic:\n  virtual ~Base() = default;                // make dtor virtual\n112 \n| \nItem 17\nwww.it-ebooks.info\n",
      "content_length": 2283,
      "extraction_method": "Direct"
    },
    {
      "page_number": 131,
      "chapter": null,
      "content": "  Base(Base&&) = default;                   // support moving\n  Base& operator=(Base&&) = default;\n  Base(const Base&) = default;              // support copying\n  Base& operator=(const Base&) = default;\n  …\n};\nIn fact, even if you have a class where compilers are willing to generate the copy and\nmove operations and where the generated functions would behave as you want, you\nmay choose to adopt a policy of declaring them yourself and using “= default” for\ntheir definitions. It’s more work, but it makes your intentions clearer, and it can help\nyou sidestep some fairly subtle bugs. For example, suppose you have a class repre‐\nsenting a string table, i.e., a data structure that permits fast lookups of string values\nvia an integer ID:\nclass StringTable {\npublic:\n  StringTable() {}\n  …                 // functions for insertion, erasure, lookup,\n                    // etc., but no copy/move/dtor functionality\nprivate:\n  std::map<int, std::string> values;\n};\nAssuming that the class declares no copy operations, no move operations, and no\ndestructor, compilers will automatically generate these functions if they are used.\nThat’s very convenient.\nBut suppose that sometime later, it’s decided that logging the default construction\nand the destruction of such objects would be useful. Adding that functionality is easy:\nclass StringTable {\npublic:\n  StringTable()\n  { makeLogEntry(\"Creating StringTable object\"); }     // added\n  \n  ~StringTable()                                       // also\n  { makeLogEntry(\"Destroying StringTable object\"); }   // added\n  …                                     // other funcs as before\nItem 17 \n| \n113\nwww.it-ebooks.info\n",
      "content_length": 1665,
      "extraction_method": "Direct"
    },
    {
      "page_number": 132,
      "chapter": null,
      "content": "private:\n  std::map<int, std::string> values;    // as before\n};\nThis looks reasonable, but declaring a destructor has a potentially significant side\neffect: it prevents the move operations from being generated. However, creation of\nthe class’s copy operations is unaffected. The code is therefore likely to compile, run,\nand pass its functional testing. That includes testing its move functionality, because\neven though this class is no longer move-enabled, requests to move it will compile\nand run. Such requests will, as noted earlier in this Item, cause copies to be made.\nWhich means that code “moving” StringTable objects actually copies them,\ni.e., copies the underlying std::map<int, std::string> objects. And copying a std\n::map<int, std::string> is likely to be orders of magnitude slower than moving it.\nThe simple act of adding a destructor to the class could thereby have introduced a\nsignificant performance problem! Had the copy and move operations been explicitly\ndefined using “= default”, the problem would not have arisen.\nNow, having endured my endless blathering about the rules governing the copy and\nmove operations in C++11, you may wonder when I’ll turn my attention to the two\nother special member functions, the default constructor and the destructor. That\ntime is now, but only for this sentence, because almost nothing has changed for these\nmember functions: the rules in C++11 are nearly the same as in C++98.\nThe C++11 rules governing the special member functions are thus:\n• Default constructor: Same rules as C++98. Generated only if the class contains\nno user-declared constructors.\n• Destructor: Essentially same rules as C++98; sole difference is that destructors\nare noexcept by default (see Item 14). As in C++98, virtual only if a base class\ndestructor is virtual.\n• Copy constructor: Same runtime behavior as C++98: memberwise copy con‐\nstruction of non-static data members. Generated only if the class lacks a user-\ndeclared copy constructor. Deleted if the class declares a move operation.\nGeneration of this function in a class with a user-declared copy assignment oper‐\nator or destructor is deprecated.\n• Copy assignment operator: Same runtime behavior as C++98: memberwise\ncopy assignment of non-static data members. Generated only if the class lacks a\nuser-declared copy assignment operator. Deleted if the class declares a move\noperation. Generation of this function in a class with a user-declared copy con‐\nstructor or destructor is deprecated.\n114 \n| \nItem 17\nwww.it-ebooks.info\n",
      "content_length": 2530,
      "extraction_method": "Direct"
    },
    {
      "page_number": 133,
      "chapter": null,
      "content": "• Move constructor and move assignment operator: Each performs memberwise\nmoving of non-static data members. Generated only if the class contains no user-\ndeclared copy operations, move operations, or destructor.\nNote that there’s nothing in the rules about the existence of a member function tem‐\nplate preventing compilers from generating the special member functions. That\nmeans that if Widget looks like this,\nclass Widget {\n  …\n  template<typename T>                // construct Widget\n  Widget(const T& rhs);               // from anything\n  template<typename T>                // assign Widget\n  Widget& operator=(const T& rhs);    // from anything\n  …\n};\ncompilers will still generate copy and move operations for Widget (assuming the\nusual conditions governing their generation are fulfilled), even though these tem‐\nplates could be instantiated to produce the signatures for the copy constructor and\ncopy assignment operator. (That would be the case when T is Widget.) In all likeli‐\nhood, this will strike you as an edge case barely worth acknowledging, but there’s a\nreason I’m mentioning it. Item 26 demonstrates that it can have important conse‐\nquences.\nThings to Remember\n• The special member functions are those compilers may generate on their own:\ndefault constructor, destructor, copy operations, and move operations.\n• Move operations are generated only for classes lacking explicitly declared\nmove operations, copy operations, and a destructor.\n• The copy constructor is generated only for classes lacking an explicitly\ndeclared copy constructor, and it’s deleted if a move operation is declared.\nThe copy assignment operator is generated only for classes lacking an explic‐\nitly declared copy assignment operator, and it’s deleted if a move operation is\ndeclared. Generation of the copy operations in classes with an explicitly\ndeclared destructor is deprecated.\n• Member function templates never suppress generation of special member\nfunctions.\nItem 17 \n| \n115\nwww.it-ebooks.info\n",
      "content_length": 2003,
      "extraction_method": "Direct"
    },
    {
      "page_number": 134,
      "chapter": null,
      "content": "www.it-ebooks.info\n",
      "content_length": 19,
      "extraction_method": "Direct"
    },
    {
      "page_number": 135,
      "chapter": null,
      "content": "CHAPTER 4\nSmart Pointers\nPoets and songwriters have a thing about love. And sometimes about counting. Occa‐\nsionally both. Inspired by the rather different takes on love and counting by Elizabeth\nBarrett Browning (“How do I love thee? Let me count the ways.”) and Paul Simon\n(“There must be 50 ways to leave your lover.”), we might try to enumerate the rea‐\nsons why a raw pointer is hard to love:\n1. Its declaration doesn’t indicate whether it points to a single object or to an array.\n2. Its declaration reveals nothing about whether you should destroy what it points\nto when you’re done using it, i.e., if the pointer owns the thing it points to.\n3. If you determine that you should destroy what the pointer points to, there’s no\nway to tell how. Should you use delete, or is there a different destruction mech‐\nanism (e.g., a dedicated destruction function the pointer should be passed to)?\n4. If you manage to find out that delete is the way to go, Reason 1 means it may\nnot be possible to know whether to use the single-object form (“delete”) or the\narray form (“delete []”). If you use the wrong form, results are undefined.\n5. Assuming you ascertain that the pointer owns what it points to and you discover\nhow to destroy it, it’s difficult to ensure that you perform the destruction exactly\nonce along every path in your code (including those due to exceptions). Missing a\npath leads to resource leaks, and doing the destruction more than once leads to\nundefined behavior.\n6. There’s typically no way to tell if the pointer dangles, i.e., points to memory that\nno longer holds the object the pointer is supposed to point to. Dangling pointers\narise when objects are destroyed while pointers still point to them.\n117\nwww.it-ebooks.info\n",
      "content_length": 1744,
      "extraction_method": "Direct"
    },
    {
      "page_number": 136,
      "chapter": null,
      "content": "Raw pointers are powerful tools, to be sure, but decades of experience have demon‐\nstrated that with only the slightest lapse in concentration or discipline, these tools can\nturn on their ostensible masters.\nSmart pointers are one way to address these issues. Smart pointers are wrappers\naround raw pointers that act much like the raw pointers they wrap, but that avoid\nmany of their pitfalls. You should therefore prefer smart pointers to raw pointers.\nSmart pointers can do virtually everything raw pointers can, but with far fewer\nopportunities for error.\nThere are four smart pointers in C++11: std::auto_ptr, std::unique_ptr,\nstd::shared_ptr, and std::weak_ptr. All are designed to help manage the life‐\ntimes of dynamically allocated objects, i.e., to avoid resource leaks by ensuring that\nsuch objects are destroyed in the appropriate manner at the appropriate time (includ‐\ning in the event of exceptions).\nstd::auto_ptr is a deprecated leftover from C++98. It was an attempt to standard‐\nize what later became C++11’s std::unique_ptr. Doing the job right required move\nsemantics, but C++98 didn’t have them. As a workaround, std::auto_ptr co-opted\nits copy operations for moves. This led to surprising code (copying a std::auto_ptr\nsets it to null!) and frustrating usage restrictions (e.g., it’s not possible to store\nstd::auto_ptrs in containers).\nstd::unique_ptr does everything std::auto_ptr does, plus more. It does it as effi‐\nciently, and it does it without warping what it means to copy an object. It’s better\nthan std::auto_ptr in every way. The only legitimate use case for std::auto_ptr\nis a need to compile code with C++98 compilers. Unless you have that constraint,\nyou should replace std::auto_ptr with std::unique_ptr and never look back.\nThe smart pointer APIs are remarkably varied. About the only functionality common\nto all is default construction. Because comprehensive references for these APIs are\nwidely available, I’ll focus my discussions on information that’s often missing from\nAPI overviews, e.g., noteworthy use cases, runtime cost analyses, etc. Mastering such\ninformation can be the difference between merely using these smart pointers and\nusing them effectively.\nItem 18: Use std::unique_ptr for exclusive-ownership\nresource management.\nWhen you reach for a smart pointer, std::unique_ptr should generally be the one\nclosest at hand. It’s reasonable to assume that, by default, std::unique_ptrs are the\nsame size as raw pointers, and for most operations (including dereferencing), they\nexecute exactly the same instructions. This means you can use them even in situa‐\n118 \n| \nItem 17\nwww.it-ebooks.info\n",
      "content_length": 2644,
      "extraction_method": "Direct"
    },
    {
      "page_number": 137,
      "chapter": null,
      "content": "class Investment { … };\nclass Stock:\n  public Investment { … };\nclass Bond:\n  public Investment { … };\nclass RealEstate:\n  public Investment { … };\nInvestment\nBond\nStock\nRealEstate\ntions where memory and cycles are tight. If a raw pointer is small enough and fast\nenough for you, a std::unique_ptr almost certainly is, too.\nstd::unique_ptr embodies exclusive ownership semantics. A non-null std::\nunique_ptr always owns what it points to. Moving a std::unique_ptr transfers\nownership from the source pointer to the destination pointer. (The source pointer is\nset to null.) Copying a std::unique_ptr isn’t allowed, because if you could copy a\nstd::unique_ptr, you’d end up with two std::unique_ptrs to the same resource,\neach thinking it owned (and should therefore destroy) that resource.\nstd::unique_ptr is thus a move-only type. Upon destruction, a non-null\nstd::unique_ptr destroys its resource. By default, resource destruction is accom‐\nplished by applying delete to the raw pointer inside the std::unique_ptr.\nA common use for std::unique_ptr is as a factory function return type for objects\nin a hierarchy. Suppose we have a hierarchy for types of investments (e.g., stocks,\nbonds, real estate, etc.) with a base class Investment.\nA factory function for such a hierarchy typically allocates an object on the heap and\nreturns a pointer to it, with the caller being responsible for deleting the object when\nit’s no longer needed. That’s a perfect match for std::unique_ptr, because the\ncaller acquires responsibility for the resource returned by the factory (i.e., exclusive\nownership of it), and the std::unique_ptr automatically deletes what it points to\nwhen the std::unique_ptr is destroyed. A factory function for the Investment\nhierarchy could be declared like this:\ntemplate<typename... Ts>              // return std::unique_ptr\nstd::unique_ptr<Investment>           // to an object created\nmakeInvestment(Ts&&... params);       // from the given args\nCallers could use the returned std::unique_ptr in a single scope as follows,\n{\n  …\nItem 18 \n| \n119\nwww.it-ebooks.info\n",
      "content_length": 2083,
      "extraction_method": "Direct"
    },
    {
      "page_number": 138,
      "chapter": null,
      "content": "1 There are a few exceptions to this rule. Most stem from abnormal program termination. If an exception prop‐\nagates out of a thread’s primary function (e.g., main, for the program’s initial thread) or if a noexcept specifi‐\ncation is violated (see Item 14), local objects may not be destroyed, and if std::abort or an exit function\n(i.e., std::_Exit, std::exit, or std::quick_exit) is called, they definitely won’t be.\n  auto pInvestment =              // pInvestment is of type\n    makeInvestment( arguments );  // std::unique_ptr<Investment>\n  …\n}                                 // destroy *pInvestment\nbut they could also use it in ownership-migration scenarios, such as when the\nstd::unique_ptr returned from the factory is moved into a container, the container\nelement is subsequently moved into a data member of an object, and that object is\nlater destroyed. When that happens, the object’s std::unique_ptr data member\nwould also be destroyed, and its destruction would cause the resource returned from\nthe factory to be destroyed. If the ownership chain got interrupted due to an excep‐\ntion or other atypical control flow (e.g., early function return or break from a loop),\nthe std::unique_ptr owning the managed resource would eventually have its\ndestructor called,1 and the resource it was managing would thereby be destroyed.\nBy default, that destruction would take place via delete, but, during construction,\nstd::unique_ptr objects can be configured to use custom deleters: arbitrary func‐\ntions (or function objects, including those arising from lambda expressions) to be\ninvoked when it’s time for their resources to be destroyed. If the object created by\nmakeInvestment shouldn’t be directly deleted, but instead should first have a log\nentry written, makeInvestment could be implemented as follows. (An explanation\nfollows the code, so don’t worry if you see something whose motivation is less than\nobvious.)\nauto delInvmt = [](Investment* pInvestment)       // custom\n                {                                 // deleter\n                  makeLogEntry(pInvestment);      // (a lambda\n                  delete pInvestment;             // expression)\n                };\ntemplate<typename... Ts>                          // revised\nstd::unique_ptr<Investment, decltype(delInvmt)>   // return type\nmakeInvestment(Ts&&... params)\n{\n  std::unique_ptr<Investment, decltype(delInvmt)> // ptr to be\n    pInv(nullptr, delInvmt);                      // returned\n120 \n| \nItem 18\nwww.it-ebooks.info\n",
      "content_length": 2515,
      "extraction_method": "Direct"
    },
    {
      "page_number": 139,
      "chapter": null,
      "content": "  if ( /* a Stock object should be created */ )\n  {\n    pInv.reset(new Stock(std::forward<Ts>(params)...));\n  }\n  else if ( /* a Bond object should be created */ )\n  {\n    pInv.reset(new Bond(std::forward<Ts>(params)...));\n  }\n  else if ( /* a RealEstate object should be created */ )\n  {\n    pInv.reset(new RealEstate(std::forward<Ts>(params)...));\n  }\n  return pInv;\n}\nIn a moment, I’ll explain how this works, but first consider how things look if you’re\na caller. Assuming you store the result of the makeInvestment call in an auto vari‐\nable, you frolic in blissful ignorance of the fact that the resource you’re using requires\nspecial treatment during deletion. In fact, you veritably bathe in bliss, because the use\nof std::unique_ptr means you need not concern yourself with when the resource\nshould be destroyed, much less ensure that the destruction happens exactly once\nalong every path through the program. std::unique_ptr takes care of all those\nthings automatically. From a client’s perspective, makeInvestment’s interface is\nsweet.\nThe implementation is pretty nice, too, once you understand the following:\n• delInvmt is the custom deleter for the object returned from makeInvestment.\nAll custom deletion functions accept a raw pointer to the object to be destroyed,\nthen do what is necessary to destroy that object. In this case, the action is to call\nmakeLogEntry and then apply delete. Using a lambda expression to create\ndelInvmt is convenient, but, as we’ll see shortly, it’s also more efficient than\nwriting a conventional function.\n• When a custom deleter is to be used, its type must be specified as the second type\nargument to std::unique_ptr. In this case, that’s the type of delInvmt, and\nthat’s why the return type of makeInvestment is std::unique_ptr<Invest\nment, decltype(delInvmt)>. (For information about decltype, see Item 3.)\n• The basic strategy of makeInvestment is to create a null std::unique_ptr,\nmake it point to an object of the appropriate type, and then return it. To asso‐\nciate the custom deleter delInvmt with pInv, we pass that as its second construc‐\ntor argument.\nItem 18 \n| \n121\nwww.it-ebooks.info\n",
      "content_length": 2147,
      "extraction_method": "Direct"
    },
    {
      "page_number": 140,
      "chapter": null,
      "content": "• Attempting to assign a raw pointer (e.g., from new) to a std::unique_ptr won’t\ncompile, because it would constitute an implicit conversion from a raw to a\nsmart pointer. Such implicit conversions can be problematic, so C++11’s smart\npointers prohibit them. That’s why reset is used to have pInv assume owner‐\nship of the object created via new.\n• With each use of new, we use std::forward to perfect-forward the arguments\npassed to makeInvestment (see Item 25). This makes all the information pro‐\nvided by callers available to the constructors of the objects being created.\n• The custom deleter takes a parameter of type Investment*. Regardless of the\nactual type of object created inside makeInvestment (i.e., Stock, Bond, or Real\nEstate), it will ultimately be deleted inside the lambda expression as an Invest\nment* object. This means we’ll be deleting a derived class object via a base class\npointer. For that to work, the base class—Investment—must have a virtual \ndestructor:\nclass Investment {\npublic:\n  …                                             // essential\n  virtual ~Investment();                        // design\n  …                                             // component!\n};\nIn C++14, the existence of function return type deduction (see Item 3) means that\nmakeInvestment could be implemented in this simpler and more encapsulated fash‐\nion:\ntemplate<typename... Ts>\nauto makeInvestment(Ts&&... params)              // C++14\n{\n  auto delInvmt = [](Investment* pInvestment)    // this is now\n                  {                              // inside\n                    makeLogEntry(pInvestment);   // make-\n                    delete pInvestment;          // Investment\n                  };\n  std::unique_ptr<Investment, decltype(delInvmt)>   // as\n    pInv(nullptr, delInvmt);                        // before\n  if ( … )                                          // as before\n  {\n    pInv.reset(new Stock(std::forward<Ts>(params)...));\n  }\n  else if ( … )                                     // as before\n122 \n| \nItem 18\nwww.it-ebooks.info\n",
      "content_length": 2062,
      "extraction_method": "Direct"
    },
    {
      "page_number": 141,
      "chapter": null,
      "content": "  {\n    pInv.reset(new Bond(std::forward<Ts>(params)...));\n  }\n  else if ( … )                                     // as before\n  {\n    pInv.reset(new RealEstate(std::forward<Ts>(params)...));\n  }\n  return pInv;                                      // as before\n}\nI remarked earlier that, when using the default deleter (i.e., delete), you can reason‐\nably assume that std::unique_ptr objects are the same size as raw pointers. When\ncustom deleters enter the picture, this may no longer be the case. Deleters that are\nfunction pointers generally cause the size of a std::unique_ptr to grow from one\nword to two. For deleters that are function objects, the change in size depends on\nhow much state is stored in the function object. Stateless function objects (e.g., from\nlambda expressions with no captures) incur no size penalty, and this means that\nwhen a custom deleter can be implemented as either a function or a captureless\nlambda expression, the lambda is preferable:\nauto delInvmt1 = [](Investment* pInvestment)      // custom\n                 {                                // deleter\n                   makeLogEntry(pInvestment);     // as\n                   delete pInvestment;            // stateless\n                 };                               // lambda\ntemplate<typename... Ts>                          // return type\nstd::unique_ptr<Investment, decltype(delInvmt1)>  // has size of\nmakeInvestment(Ts&&... args);                     // Investment*\nvoid delInvmt2(Investment* pInvestment)           // custom\n{                                                 // deleter\n  makeLogEntry(pInvestment);                      // as function\n  delete pInvestment;\n}\ntemplate<typename... Ts>                 // return type has\nstd::unique_ptr<Investment,              // size of Investment*\n                void (*)(Investment*)>   // plus at least size\nmakeInvestment(Ts&&... params);          // of function pointer!\nFunction object deleters with extensive state can yield std::unique_ptr objects of\nsignificant size. If you find that a custom deleter makes your std::unique_ptrs\nunacceptably large, you probably need to change your design.\nItem 18 \n| \n123\nwww.it-ebooks.info\n",
      "content_length": 2190,
      "extraction_method": "Direct"
    },
    {
      "page_number": 142,
      "chapter": null,
      "content": "Factory functions are not the only common use case for std::unique_ptrs. They’re\neven more popular as a mechanism for implementing the Pimpl Idiom. The code for\nthat isn’t complicated, but in some cases it’s less than straightforward, so I’ll refer you\nto Item 22, which is dedicated to the topic.\nstd::unique_ptr comes in two forms, one for individual objects (std::\nunique_ptr<T>) and one for arrays (std::unique_ptr<T[]>). As a result, there’s\nnever any ambiguity about what kind of entity a std::unique_ptr points to. The\nstd::unique_ptr API is designed to match the form you’re using. For example,\nthere’s no indexing operator (operator[]) for the single-object form, while the array\nform lacks dereferencing operators (operator* and operator->).\nThe existence of std::unique_ptr for arrays should be of only intellectual interest\nto you, because std::array, std::vector, and std::string are virtually always\nbetter data structure choices than raw arrays. About the only situation I can conceive\nof when a std::unique_ptr<T[]> would make sense would be when you’re using a\nC-like API that returns a raw pointer to a heap array that you assume ownership of.\nstd::unique_ptr is the C++11 way to express exclusive ownership, but one of its\nmost attractive features is that it easily and efficiently converts to a std::\nshared_ptr:\nstd::shared_ptr<Investment> sp =    // converts std::unique_ptr\n  makeInvestment( arguments );      // to std::shared_ptr\nThis is a key part of why std::unique_ptr is so well suited as a factory function\nreturn type. Factory functions can’t know whether callers will want to use exclusive-\nownership semantics for the object they return or whether shared ownership (i.e.,\nstd::shared_ptr) would be more appropriate. By returning a std::unique_ptr,\nfactories provide callers with the most efficient smart pointer, but they don’t hinder\ncallers from replacing it with its more flexible sibling. (For information about\nstd::shared_ptr, proceed to Item 19.)\nThings to Remember\n• std::unique_ptr is a small, fast, move-only smart pointer for managing\nresources with exclusive-ownership semantics.\n• By default, resource destruction takes place via delete, but custom deleters\ncan be specified. Stateful deleters and function pointers as deleters increase the\nsize of std::unique_ptr objects.\n• Converting a std::unique_ptr to a std::shared_ptr is easy.\n124 \n| \nItem 18\nwww.it-ebooks.info\n",
      "content_length": 2416,
      "extraction_method": "Direct"
    },
    {
      "page_number": 143,
      "chapter": null,
      "content": "Item 19: Use std::shared_ptr for shared-ownership\nresource management.\nProgrammers using languages with garbage collection point and laugh at what C++\nprogrammers go through to prevent resource leaks. “How primitive!” they jeer.\n“Didn’t you get the memo from Lisp in the 1960s? Machines should manage resource\nlifetimes, not humans.” C++ developers roll their eyes. “You mean the memo where\nthe only resource is memory and the timing of resource reclamation is nondetermin‐\nistic? We prefer the generality and predictability of destructors, thank you.” But our\nbravado is part bluster. Garbage collection really is convenient, and manual lifetime\nmanagement really can seem akin to constructing a mnemonic memory circuit using\nstone knives and bear skins.  Why can’t we have the best of both worlds: a system that\nworks automatically (like garbage collection), yet applies to all resources and has pre‐\ndictable timing (like destructors)?\nstd::shared_ptr is the C++11 way of binding these worlds together. An object\naccessed via std::shared_ptrs has its lifetime managed by those pointers through\nshared ownership. No specific std::shared_ptr owns the object. Instead, all\nstd::shared_ptrs pointing to it collaborate to ensure its destruction at the point\nwhere it’s no longer needed. When the last std::shared_ptr pointing to an object\nstops pointing there (e.g., because the std::shared_ptr is destroyed or made to\npoint to a different object), that std::shared_ptr destroys the object it points to. As\nwith garbage collection, clients need not concern themselves with managing the life‐\ntime of pointed-to objects, but as with destructors, the timing of the objects’ destruc‐\ntion is deterministic.\nA std::shared_ptr can tell whether it’s the last one pointing to a resource by con‐\nsulting the resource’s reference count, a value associated with the resource that keeps\ntrack of how many std::shared_ptrs point to it. std::shared_ptr constructors\nincrement this count (usually—see below), std::shared_ptr destructors decrement\nit, and copy assignment operators do both. (If sp1 and sp2 are std::shared_ptrs to\ndifferent objects, the assignment “sp1 = sp2;” modifies sp1 such that it points to the\nobject pointed to by sp2. The net effect of the assignment is that the reference count\nfor the object originally pointed to by sp1 is decremented, while that for the object\npointed to by sp2 is incremented.) If a std::shared_ptr sees a reference count of\nzero after performing a decrement, no more std::shared_ptrs point to the\nresource, so the std::shared_ptr destroys it.\nThe existence of the reference count has performance implications:\nItem 19 \n| \n125\nwww.it-ebooks.info\n",
      "content_length": 2677,
      "extraction_method": "Direct"
    },
    {
      "page_number": 144,
      "chapter": null,
      "content": "2 This implementation is not required by the Standard, but every Standard Library implementation I’m familiar\nwith employs it.\n• std::shared_ptrs are twice the size of a raw pointer, because they internally\ncontain a raw pointer to the resource as well as a raw pointer to the resource’s\nreference count.2\n• Memory for the reference count must be dynamically allocated. Conceptually,\nthe reference count is associated with the object being pointed to, but pointed-to\nobjects know nothing about this. They thus have no place to store a reference\ncount. (A pleasant implication is that any object—even those of built-in types—\nmay be managed by std::shared_ptrs.) Item 21 explains that the cost of the\ndynamic allocation is avoided when the std::shared_ptr is created by\nstd::make_shared, but there are situations where std::make_shared can’t be\nused. Either way, the reference count is stored as dynamically allocated data.\n• Increments and decrements of the reference count must be atomic, because\nthere can be simultaneous readers and writers in different threads. For example,\na std::shared_ptr pointing to a resource in one thread could be executing its\ndestructor (hence decrementing the reference count for the resource it points to),\nwhile, in a different thread, a std::shared_ptr to the same object could be\ncopied (and therefore incrementing the same reference count). Atomic opera‐\ntions are typically slower than non-atomic operations, so even though reference\ncounts are usually only a word in size, you should assume that reading and writ‐\ning them is comparatively costly.\nDid I pique your curiosity when I wrote that std::shared_ptr constructors only\n“usually” increment the reference count for the object they point to? Creating a\nstd::shared_ptr pointing to an object always yields one more std::shared_ptr\npointing to that object, so why mustn’t we always increment the reference count?\nMove construction, that’s why. Move-constructing a std::shared_ptr from\nanother std::shared_ptr sets the source std::shared_ptr to null, and that means\nthat the old std::shared_ptr stops pointing to the resource at the moment the new\nstd::shared_ptr starts. As a result, no reference count manipulation is required.\nMoving std::shared_ptrs is therefore faster than copying them: copying requires\nincrementing the reference count, but moving doesn’t. This is as true for assignment\nas for construction, so move construction is faster than copy construction, and move\nassignment is faster than copy assignment.\nLike std::unique_ptr (see Item 18), std::shared_ptr uses delete as its default\nresource-destruction \nmechanism, \nbut \nit \nalso \nsupports \ncustom \ndeleters.\nThe design of this support differs from that for std::unique_ptr, however. For\n126 \n| \nItem 19\nwww.it-ebooks.info\n",
      "content_length": 2784,
      "extraction_method": "Direct"
    },
    {
      "page_number": 145,
      "chapter": null,
      "content": "std::unique_ptr, the type of the deleter is part of the type of the smart pointer. For\nstd::shared_ptr, it’s not:\nauto loggingDel = [](Widget *pw)        // custom deleter\n                  {                     // (as in Item 18)\n                    makeLogEntry(pw);\n                    delete pw;\n                  };\nstd::unique_ptr<                        // deleter type is\n  Widget, decltype(loggingDel)          // part of ptr type\n  > upw(new Widget, loggingDel);\nstd::shared_ptr<Widget>                 // deleter type is not\n  spw(new Widget, loggingDel);          // part of ptr type\nThe std::shared_ptr design is more flexible. Consider two std::shared_ptr\n<Widget>s, each with a custom deleter of a different type (e.g., because the custom\ndeleters are specified via lambda expressions):\nauto customDeleter1 = [](Widget *pw) { … };    // custom deleters,\nauto customDeleter2 = [](Widget *pw) { … };    // each with a\n                                               // different type\nstd::shared_ptr<Widget> pw1(new Widget, customDeleter1);\nstd::shared_ptr<Widget> pw2(new Widget, customDeleter2);\nBecause pw1 and pw2 have the same type, they can be placed in a container of objects\nof that type:\nstd::vector<std::shared_ptr<Widget>> vpw{ pw1, pw2 };\nThey could also be assigned to one another, and they could each be passed to a func‐\ntion taking a parameter of type std::shared_ptr<Widget>. None of these things\ncan be done with std::unique_ptrs that differ in the types of their custom deleters,\nbecause the type of the custom deleter would affect the type of the std::unique_ptr.\nIn another difference from std::unique_ptr, specifying a custom deleter doesn’t\nchange the size of a std::shared_ptr object. Regardless of deleter, a\nstd::shared_ptr object is two pointers in size. That’s great news, but it should\nmake you vaguely uneasy. Custom deleters can be function objects, and function\nobjects can contain arbitrary amounts of data. That means they can be arbitrarily\nlarge. How can a std::shared_ptr refer to a deleter of arbitrary size without using\nany more memory?\nItem 19 \n| \n127\nwww.it-ebooks.info\n",
      "content_length": 2124,
      "extraction_method": "Direct"
    },
    {
      "page_number": 146,
      "chapter": null,
      "content": "It can’t. It may have to use more memory. However, that memory isn’t part of the\nstd::shared_ptr object. It’s on the heap or, if the creator of the std::shared_ptr\ntook advantage of std::shared_ptr support for custom allocators, it’s wherever the\nmemory managed by the allocator is located. I remarked earlier that a\nstd::shared_ptr object contains a pointer to the reference count for the object it\npoints to. That’s true, but it’s a bit misleading, because the reference count is part of a\nlarger data structure known as the control block. There’s a control block for each\nobject managed by std::shared_ptrs. The control block contains, in addition to the\nreference count, a copy of the custom deleter, if one has been specified. If a custom\nallocator was specified, the control block contains a copy of that, too. The control\nblock may also contain additional data, including, as Item 21 explains, a secondary\nreference count known as the weak count, but we’ll ignore such data in this Item. We\ncan envision the memory associated with a std::shared_ptr<T> object as looking\nlike this:\nPtr to T\nT Object\nReference Count\nWeak Count\nOther Data\n(e.g., custom deleter,\nallocator, etc.)\nControl Block\nPtr to Control Block\nstd::shared_ptr<T>\nAn object’s control block is set up by the function creating the first\nstd::shared_ptr to the object. At least that’s what’s supposed to happen. In gen‐\neral, it’s impossible for a function creating a std::shared_ptr to an object to know\nwhether some other std::shared_ptr already points to that object, so the following\nrules for control block creation are used:\n• std::make_shared (see Item 21) always creates a control block. It manufac‐\ntures a new object to point to, so there is certainly no control block for that\nobject at the time std::make_shared is called.\n• A control block is created when a std::shared_ptr is constructed from a\nunique-ownership pointer (i.e., a std::unique_ptr or std::auto_ptr).\nUnique-ownership pointers don’t use control blocks, so there should be no con‐\ntrol block for the pointed-to object. (As part of its construction, the\nstd::shared_ptr assumes ownership of the pointed-to object, so the unique-\nownership pointer is set to null.)\n128 \n| \nItem 19\nwww.it-ebooks.info\n",
      "content_length": 2245,
      "extraction_method": "Direct"
    },
    {
      "page_number": 147,
      "chapter": null,
      "content": "• When a std::shared_ptr constructor is called with a raw pointer, it creates a\ncontrol block. If you wanted to create a std::shared_ptr from an object that\nalready had a control block, you’d presumably pass a std::shared_ptr or a\nstd::weak_ptr (see Item 20) as a constructor argument, not a raw pointer.\nstd::shared_ptr constructors taking std::shared_ptrs or std::weak_ptrs\nas constructor arguments don’t create new control blocks, because they can rely\non the smart pointers passed to them to point to any necessary control blocks.\nA consequence of these rules is that constructing more than one std::shared_ptr\nfrom a single raw pointer gives you a complimentary ride on the particle accelerator\nof undefined behavior, because the pointed-to object will have multiple control\nblocks. Multiple control blocks means multiple reference counts, and multiple refer‐\nence counts means the object will be destroyed multiple times (once for each refer‐\nence count). That means that code like this is bad, bad, bad:\nauto pw = new Widget;                          // pw is raw ptr\n…\nstd::shared_ptr<Widget> spw1(pw, loggingDel);  // create control\n                                               // block for *pw\n…\nstd::shared_ptr<Widget> spw2(pw, loggingDel);  // create 2nd\n                                               // control block\n                                               // for *pw!\nThe creation of the raw pointer pw to a dynamically allocated object is bad, because it\nruns contrary to the advice behind this entire chapter: to prefer smart pointers to raw\npointers. (If you’ve forgotten the motivation for that advice, refresh your memory on\npage 115.) But set that aside. The line creating pw is a stylistic abomination, but at\nleast it doesn’t cause undefined program behavior.\nNow, the constructor for spw1 is called with a raw pointer, so it creates a control\nblock (and thereby a reference count) for what’s pointed to. In this case, that’s *pw\n(i.e., the object pointed to by pw). In and of itself, that’s okay, but the constructor for\nspw2 is called with the same raw pointer, so it also creates a control block (hence a\nreference count) for *pw. *pw thus has two reference counts, each of which will even‐\ntually become zero, and that will ultimately lead to an attempt to destroy *pw twice.\nThe second destruction is responsible for the undefined behavior.\nThere are at least two lessons regarding std::shared_ptr use here. First, try to\navoid passing raw pointers to a std::shared_ptr constructor. The usual alternative\nis to use std::make_shared (see Item 21), but in the example above, we’re using cus‐\nItem 19 \n| \n129\nwww.it-ebooks.info\n",
      "content_length": 2662,
      "extraction_method": "Direct"
    },
    {
      "page_number": 148,
      "chapter": null,
      "content": "tom deleters, and that’s not possible with std::make_shared. Second, if you must\npass a raw pointer to a std::shared_ptr constructor, pass the result of new directly\ninstead of going through a raw pointer variable. If the first part of the code above\nwere rewritten like this,\nstd::shared_ptr<Widget> spw1(new Widget,    // direct use of new\n                             loggingDel);\nit’d be a lot less tempting to create a second std::shared_ptr from the same raw\npointer. Instead, the author of the code creating spw2 would naturally use spw1 as an\ninitialization argument (i.e., would call the std::shared_ptr copy constructor), and\nthat would pose no problem whatsoever:\nstd::shared_ptr<Widget> spw2(spw1);     // spw2 uses same\n                                        // control block as spw1\nAn especially surprising way that using raw pointer variables as std::shared_ptr\nconstructor arguments can lead to multiple control blocks involves the this pointer.\nSuppose our program uses std::shared_ptrs to manage Widget objects, and we\nhave a data structure that keeps track of Widgets that have been processed:\nstd::vector<std::shared_ptr<Widget>> processedWidgets;\nFurther suppose that Widget has a member function that does the processing:\nclass Widget {\npublic:\n  …\n  void process();\n  …\n};\nHere’s a reasonable-looking approach for Widget::process:\nvoid Widget::process()\n{\n  …                                       // process the Widget\n  processedWidgets.emplace_back(this);    // add it to list of\n}                                         // processed Widgets;\n                                          // this is wrong!\nThe comment about this being wrong says it all—or at least most of it. (The part\nthat’s wrong is the passing of this, not the use of emplace_back. If you’re not famil‐\niar with emplace_back, see Item 42.) This code will compile, but it’s passing a raw\npointer (this) to a container of std::shared_ptrs. The std::shared_ptr thus\nconstructed will create a new control block for the pointed-to Widget (*this). That\n130 \n| \nItem 19\nwww.it-ebooks.info\n",
      "content_length": 2079,
      "extraction_method": "Direct"
    },
    {
      "page_number": 149,
      "chapter": null,
      "content": "doesn’t sound harmful until you realize that if there are std::shared_ptrs outside\nthe member function that already point to that Widget, it’s game, set, and match for\nundefined behavior.\nThe std::shared_ptr API includes a facility for just this kind of situation. It has\nprobably the oddest of all names in the Standard C++ Library: std::\nenable_shared_from_this. That’s a template for a base class you inherit from if\nyou want a class managed by std::shared_ptrs to be able to safely create a\nstd::shared_ptr from a this pointer. In our example, Widget would inherit from\nstd::enable_shared_from_this as follows:\nclass Widget: public std::enable_shared_from_this<Widget> {\npublic:\n  …\n  void process();\n  …\n};\nAs I said, std::enable_shared_from_this is a base class template. Its type parame‐\nter is always the name of the class being derived, so Widget inherits from\nstd::enable_shared_from_this<Widget>. If the idea of a derived class inheriting\nfrom a base class templatized on the derived class makes your head hurt, try not to\nthink about it. The code is completely legal, and the design pattern behind it is so well\nestablished, it has a standard name, albeit one that’s almost as odd as\nstd::enable_shared_from_this. The name is The Curiously Recurring Template\nPattern (CRTP). If you’d like to learn more about it, unleash your search engine,\nbecause here we need to get back to std::enable_shared_from_this.\nstd::enable_shared_from_this defines a member function that creates a\nstd::shared_ptr to the current object, but it does it without duplicating control\nblocks. The member function is shared_from_this, and you use it in member func‐\ntions whenever you want a std::shared_ptr that points to the same object as the\nthis pointer. Here’s a safe implementation of Widget::process:\nvoid Widget::process()\n{\n  // as before, process the Widget\n  …\n  // add std::shared_ptr to current object to processedWidgets\n  processedWidgets.emplace_back(shared_from_this());\n}\nItem 19 \n| \n131\nwww.it-ebooks.info\n",
      "content_length": 2011,
      "extraction_method": "Direct"
    },
    {
      "page_number": 150,
      "chapter": null,
      "content": "Internally, shared_from_this looks up the control block for the current object, and\nit creates a new std::shared_ptr that refers to that control block. The design relies\non the current object having an associated control block. For that to be the case, there\nmust be an existing std::shared_ptr (e.g., one outside the member function calling\nshared_from_this) that points to the current object. If no such std::shared_ptr\nexists (i.e., if the current object has no associated control block), behavior is unde‐\nfined, although shared_from_this typically throws an exception.\nTo prevent clients from calling member functions that invoke shared_from_this\nbefore a std::shared_ptr points to the object, classes inheriting from\nstd::enable_shared_from_this often declare their constructors private and\nhave clients create objects by calling factory functions that return std::\nshared_ptrs. Widget, for example, could look like this: \nclass Widget: public std::enable_shared_from_this<Widget> {\npublic:\n  // factory function that perfect-forwards args\n  // to a private ctor\n  template<typename... Ts>\n  static std::shared_ptr<Widget> create(Ts&&... params);\n  …\n  void process();             // as before\n  …\nprivate:\n  …                           // ctors\n};\nBy now, you may only dimly recall that our discussion of control blocks was motiva‐\nted by a desire to understand the costs associated with std::shared_ptrs. Now that\nwe understand how to avoid creating too many control blocks, let’s return to the\noriginal topic.\nA control block is typically only a few words in size, although custom deleters and\nallocators may make it larger. The usual control block implementation is more\nsophisticated than you might expect. It makes use of inheritance, and there’s even a\nvirtual function. (It’s used to ensure that the pointed-to object is properly destroyed.)\nThat means that using std::shared_ptrs also incurs the cost of the machinery for\nthe virtual function used by the control block.\nHaving read about dynamically allocated control blocks, arbitrarily large deleters and\nallocators, virtual function machinery, and atomic reference count manipulations,\nyour enthusiasm for std::shared_ptrs may have waned somewhat. That’s fine.\n132 \n| \nItem 19\nwww.it-ebooks.info\n",
      "content_length": 2264,
      "extraction_method": "Direct"
    },
    {
      "page_number": 151,
      "chapter": null,
      "content": "They’re not the best solution to every resource management problem. But for the\nfunctionality they provide, std::shared_ptrs exact a very reasonable cost. Under\ntypical conditions, where the default deleter and default allocator are used and where\nthe std::shared_ptr is created by std::make_shared, the control block is only\nabout three words in size, and its allocation is essentially free. (It’s incorporated into\nthe memory allocation for the object being pointed to. For details, see Item 21.)\nDereferencing a std::shared_ptr is no more expensive than dereferencing a raw\npointer. Performing an operation requiring a reference count manipulation (e.g.,\ncopy construction or copy assignment, destruction) entails one or two atomic opera‐\ntions, but these operations typically map to individual machine instructions, so\nalthough they may be expensive compared to non-atomic instructions, they’re still\njust single instructions. The virtual function machinery in the control block is gener‐\nally used only once per object managed by std::shared_ptrs: when the object is\ndestroyed.\nIn exchange for these rather modest costs, you get automatic lifetime management of\ndynamically allocated resources. Most of the time, using std::shared_ptr is vastly\npreferable to trying to manage the lifetime of an object with shared ownership by\nhand. If you find yourself doubting whether you can afford use of std::shared_ptr,\nreconsider whether you really need shared ownership. If exclusive ownership will do\nor even may do, std::unique_ptr is a better choice. Its performance profile is close\nto that for raw pointers, and “upgrading” from std::unique_ptr to std::\nshared_ptr is easy, because a std::shared_ptr can be created from a std::\nunique_ptr.\nThe reverse is not true. Once you’ve turned lifetime management of a resource over\nto a std::shared_ptr, there’s no changing your mind. Even if the reference count is\none, you can’t reclaim ownership of the resource in order to, say, have a\nstd::unique_ptr manage it. The ownership contract between a resource and the\nstd::shared_ptrs that point to it is of the ’til-death-do-us-part variety. No divorce,\nno annulment, no dispensations.\nSomething else std::shared_ptrs can’t do is work with arrays. In yet another dif‐\nference from std::unique_ptr, std::shared_ptr has an API that’s designed only\nfor pointers to single objects. There’s no std::shared_ptr<T[]>. From time to\ntime, “clever” programmers stumble on the idea of using a std::shared_ptr<T> to\npoint to an array, specifying a custom deleter to perform an array delete (i.e., delete\n[]). This can be made to compile, but it’s a horrible idea. For one thing,\nstd::shared_ptr offers no operator[], so indexing into the array requires awk‐\nward expressions based on pointer arithmetic. For another, std::shared_ptr sup‐\nports derived-to-base pointer conversions that make sense for single objects, but that\nopen holes in the type system when applied to arrays. (For this reason, the\nItem 19 \n| \n133\nwww.it-ebooks.info\n",
      "content_length": 3017,
      "extraction_method": "Direct"
    },
    {
      "page_number": 152,
      "chapter": null,
      "content": "std::unique_ptr<T[]> API prohibits such conversions.) Most importantly, given\nthe variety of C++11 alternatives to built-in arrays (e.g., std::array, std::vector,\nstd::string), declaring a smart pointer to a dumb array is almost always a sign of\nbad design.\nThings to Remember\n• std::shared_ptrs offer convenience approaching that of garbage collection\nfor the shared lifetime management of arbitrary resources.\n• Compared to std::unique_ptr, std::shared_ptr objects are typically\ntwice as big, incur overhead for control blocks, and require atomic reference\ncount manipulations.\n• Default resource destruction is via delete, but custom deleters are supported.\nThe type of the deleter has no effect on the type of the std::shared_ptr.\n• Avoid creating std::shared_ptrs from variables of raw pointer type.\nItem 20: Use std::weak_ptr for std::shared_ptr-\nlike pointers that can dangle.\nParadoxically, it can be convenient to have a smart pointer that acts like a\nstd::shared_ptr (see Item 19), but that doesn’t participate in the shared ownership\nof the pointed-to resource. In other words, a pointer like std::shared_ptr that\ndoesn’t affect an object’s reference count. This kind of smart pointer has to contend\nwith a problem unknown to std::shared_ptrs: the possibility that what it points to\nhas been destroyed. A truly smart pointer would deal with this problem by tracking\nwhen it dangles, i.e., when the object it is supposed to point to no longer exists. That’s\nprecisely the kind of smart pointer std::weak_ptr is. \nYou may be wondering how a std::weak_ptr could be useful. You’ll probably won‐\nder even more when you examine the std::weak_ptr API. It looks anything but\nsmart. std::weak_ptrs can’t be dereferenced, nor can they be tested for nullness.\nThat’s because std::weak_ptr isn’t a standalone smart pointer. It’s an augmentation\nof std::shared_ptr.\nThe relationship begins at birth. std::weak_ptrs are typically created from\nstd::shared_ptrs. They point to the same place as the std::shared_ptrs initializ‐\ning them, but they don’t affect the reference count of the object they point to:\nauto spw =                       // after spw is constructed,\n  std::make_shared<Widget>();    // the pointed-to Widget's\n134 \n| \nItem 19\nwww.it-ebooks.info\n",
      "content_length": 2260,
      "extraction_method": "Direct"
    },
    {
      "page_number": 153,
      "chapter": null,
      "content": "                                 // ref count (RC) is 1. (See\n                                 // Item 21 for info on\n                                 // std::make_shared.)\n…\nstd::weak_ptr<Widget> wpw(spw);  // wpw points to same Widget\n                                 // as spw. RC remains 1\n…\nspw = nullptr;                   // RC goes to 0, and the\n                                 // Widget is destroyed.\n                                 // wpw now dangles\nstd::weak_ptrs that dangle are said to have expired. You can test for this directly,\nif (wpw.expired()) …             // if wpw doesn't point\n                                 // to an object…\nbut often what you desire is a check to see if a std::weak_ptr has expired and, if it\nhasn’t (i.e., if it’s not dangling), to access the object it points to. This is easier desired\nthan done. Because std::weak_ptrs lack dereferencing operations, there’s no way to\nwrite the code. Even if there were, separating the check and the dereference would\nintroduce a race condition: between the call to expired and the dereferencing action,\nanother thread might reassign or destroy the last std::shared_ptr pointing to the\nobject, thus causing that object to be destroyed. In that case, your dereference would\nyield undefined behavior.\nWhat you need is an atomic operation that checks to see if the std::weak_ptr has\nexpired and, if not, gives you access to the object it points to. This is done by creating\na std::shared_ptr from the std::weak_ptr. The operation comes in two forms,\ndepending on what you’d like to have happen if the std::weak_ptr has expired\nwhen you try to create a std::shared_ptr from it. One form is std::\nweak_ptr::lock, which returns a std::shared_ptr. The std::shared_ptr is null\nif the std::weak_ptr has expired:\nstd::shared_ptr<Widget> spw1 = wpw.lock();  // if wpw's expired,\n                                            // spw1 is null\nauto spw2 = wpw.lock();                     // same as above,\n                                            // but uses auto\nThe other form is the std::shared_ptr constructor taking a std::weak_ptr as an\nargument. In this case, if the std::weak_ptr has expired, an exception is thrown:\nstd::shared_ptr<Widget> spw3(wpw);    // if wpw's expired,\n                                      // throw std::bad_weak_ptr\nItem 20 \n| \n135\nwww.it-ebooks.info\n",
      "content_length": 2355,
      "extraction_method": "Direct"
    },
    {
      "page_number": 154,
      "chapter": null,
      "content": "But you’re probably still wondering about how std::weak_ptrs can be useful. Con‐\nsider a factory function that produces smart pointers to read-only objects based on a\nunique ID. In accord with Item 18’s advice regarding factory function return types, it\nreturns a std::unique_ptr:\nstd::unique_ptr<const Widget> loadWidget(WidgetID id);\nIf loadWidget is an expensive call (e.g., because it performs file or database I/O) and\nit’s common for IDs to be used repeatedly, a reasonable optimization would be to\nwrite a function that does what loadWidget does, but also caches its results. Clogging\nthe cache with every Widget that has ever been requested can lead to performance\nproblems of its own, however, so another reasonable optimization would be to\ndestroy cached Widgets when they’re no longer in use.\nFor this caching factory function, a std::unique_ptr return type is not a good fit.\nCallers should certainly receive smart pointers to cached objects, and callers should\ncertainly determine the lifetime of those objects, but the cache needs a pointer to the\nobjects, too. The cache’s pointers need to be able to detect when they dangle, because\nwhen factory clients are finished using an object returned by the factory, that object\nwill be destroyed, and the corresponding cache entry will dangle. The cached pointers\nshould therefore be std::weak_ptrs—pointers that can detect when they dangle.\nThat means that the factory’s return type should be a std::shared_ptr, because\nstd::weak_ptrs can detect when they dangle only when an object’s lifetime is man‐\naged by std::shared_ptrs.\nHere’s a quick-and-dirty implementation of a caching version of loadWidget:\nstd::shared_ptr<const Widget> fastLoadWidget(WidgetID id)\n{\n  static std::unordered_map<WidgetID,\n                            std::weak_ptr<const Widget>> cache;\n  auto objPtr = cache[id].lock();   // objPtr is std::shared_ptr\n                                    // to cached object (or null\n                                    // if object's not in cache)\n  if (!objPtr) {                    // if not in cache,\n    objPtr = loadWidget(id);        // load it\n    cache[id] = objPtr;             // cache it\n  }\n  return objPtr;\n}\n136 \n| \nItem 20\nwww.it-ebooks.info\n",
      "content_length": 2229,
      "extraction_method": "Direct"
    },
    {
      "page_number": 155,
      "chapter": null,
      "content": "This implementation employs one of C++11’s hash table containers (std::unor\ndered_map), though it doesn’t show the WidgetID hashing and equality-comparison\nfunctions that would also have to be present.\nThe implementation of fastLoadWidget ignores the fact that the cache may accu‐\nmulate expired std::weak_ptrs corresponding to Widgets that are no longer in use\n(and have therefore been destroyed). The implementation can be refined, but rather\nthan spend time on an issue that lends no additional insight into std::weak_ptrs,\nlet’s consider a second use case: the Observer design pattern. The primary compo‐\nnents of this pattern are subjects (objects whose state may change) and observers\n(objects to be notified when state changes occur). In most implementations, each\nsubject contains a data member holding pointers to its observers. That makes it easy\nfor subjects to issue state change notifications. Subjects have no interest in control‐\nling the lifetime of their observers (i.e., when they’re destroyed), but they have a great\ninterest in making sure that if an observer gets destroyed, subjects don’t try to subse‐\nquently access it. A reasonable design is for each subject to hold a container of\nstd::weak_ptrs to its observers, thus making it possible for the subject to determine\nwhether a pointer dangles before using it.\nAs a final example of std::weak_ptr’s utility, consider a data structure with objects\nA, B, and C in it, where A and C share ownership of B and therefore hold\nstd::shared_ptrs to it:\nA\nB\nC\nstd::shared_ptr\nstd::shared_ptr\nSuppose it’d be useful to also have a pointer from B back to A. What kind of pointer\nshould this be?\nA\nB\nC\nstd::shared_ptr\n???\nstd::shared_ptr\nThere are three choices:\n• A raw pointer. With this approach, if A is destroyed, but C continues to point to\nB, B will contain a pointer to A that will dangle. B won’t be able to detect that, so B\nmay inadvertently dereference the dangling pointer. That would yield undefined\nbehavior.\n• A std::shared_ptr. In this design, A and B contain std::shared_ptrs to each\nother. The resulting std::shared_ptr cycle (A points to B and B points to A) will\nItem 20 \n| \n137\nwww.it-ebooks.info\n",
      "content_length": 2181,
      "extraction_method": "Direct"
    },
    {
      "page_number": 156,
      "chapter": null,
      "content": "prevent both A and B from being destroyed. Even if A and B are unreachable from\nother program data structures (e.g., because C no longer points to B), each will\nhave a reference count of one. If that happens, A and B will have been leaked, for\nall practical purposes: it will be impossible for the program to access them, yet\ntheir resources will never be reclaimed.\n• A std::weak_ptr. This avoids both problems above. If A is destroyed, B’s\npointer back to it will dangle, but B will be able to detect that. Furthermore,\nthough A and B will point to one another, B’s pointer won’t affect A’s reference\ncount, hence can’t keep A from being destroyed when std::shared_ptrs no\nlonger point to it.\nUsing std::weak_ptr is clearly the best of these choices. However, it’s worth noting\nthat the need to employ std::weak_ptrs to break prospective cycles of std::\nshared_ptrs is not terribly common. In strictly hierarchal data structures such as\ntrees, child nodes are typically owned only by their parents. When a parent node is\ndestroyed, its child nodes should be destroyed, too. Links from parents to children\nare thus generally best represented by std::unique_ptrs. Back-links from children\nto parents can be safely implemented as raw pointers, because a child node should\nnever have a lifetime longer than its parent. There’s thus no risk of a child node\ndereferencing a dangling parent pointer.\nOf course, not all pointer-based data structures are strictly hierarchical, and when\nthat’s the case, as well as in situations such as caching and the implementation of lists\nof observers, it’s nice to know that std::weak_ptr stands at the ready.\nFrom an efficiency perspective, the std::weak_ptr story is essentially the same as\nthat for std::shared_ptr. std::weak_ptr objects are the same size as std::\nshared_ptr objects, they make use of the same control blocks as std::\nshared_ptrs (see Item 19), and operations such as construction, destruction, and\nassignment involve atomic reference count manipulations. That probably surprises\nyou, because I wrote at the beginning of this Item that std::weak_ptrs don’t partici‐\npate in reference counting. Except that’s not quite what I wrote. What I wrote was\nthat std::weak_ptrs don’t participate in the shared ownership of objects and hence\ndon’t affect the pointed-to object’s reference count. There’s actually a second reference\ncount in the control block, and it’s this second reference count that std::weak_ptrs\nmanipulate. For details, continue on to Item 21.\n138 \n| \nItem 20\nwww.it-ebooks.info\n",
      "content_length": 2543,
      "extraction_method": "Direct"
    },
    {
      "page_number": 157,
      "chapter": null,
      "content": "3 To create a full-featured make_unique with the smallest effort possible, search for the standardization docu‐\nment that gave rise to it, then copy the implementation you’ll find there. The document you want is N3656 by\nStephan T. Lavavej, dated 2013-04-18.\nThings to Remember\n• Use std::weak_ptr for std::shared_ptr-like pointers that can dangle.\n• Potential use cases for std::weak_ptr include caching, observer lists, and the\nprevention of std::shared_ptr cycles.\nItem 21: Prefer std::make_unique and\nstd::make_shared to direct use of new.\nLet’s begin by leveling the playing field for std::make_unique and std::\nmake_shared. std::make_shared is part of C++11, but, sadly, std::make_\nunique isn’t. It joined the Standard Library as of C++14. If you’re using C++11,\nnever fear, because a basic version of std::make_unique is easy to write yourself.\nHere, look:\ntemplate<typename T, typename... Ts>\nstd::unique_ptr<T> make_unique(Ts&&... params)\n{\n  return std::unique_ptr<T>(new T(std::forward<Ts>(params)...));\n}\nAs you can see, make_unique just perfect-forwards its parameters to the constructor\nof the object being created, constructs a std::unique_ptr from the raw pointer new\nproduces, and returns the std::unique_ptr so created. This form of the function\ndoesn’t support arrays or custom deleters (see Item 18), but it demonstrates that with\nonly a little effort, you can create make_unique if you need to.3 Just remember not to\nput your version in namespace std, because you won’t want it to clash with a vendor-\nprovided version when you upgrade to a C++14 Standard Library implementation.\nstd::make_unique and std::make_shared are two of the three make functions:\nfunctions that take an arbitrary set of arguments, perfect-forward them to the con‐\nstructor for a dynamically allocated object, and return a smart pointer to that object.\nThe \nthird \nmake \nfunction \nis \nstd::allocate_shared. \nIt \nacts \njust \nlike\nstd::make_shared, except its first argument is an allocator object to be used for the\ndynamic memory allocation.\nItem 21 \n| \n139\nwww.it-ebooks.info\n",
      "content_length": 2072,
      "extraction_method": "Direct"
    },
    {
      "page_number": 158,
      "chapter": null,
      "content": "Even the most trivial comparison of smart pointer creation using and not using a\nmake function reveals the first reason why using such functions is preferable. Con‐\nsider:\nauto upw1(std::make_unique<Widget>());      // with make func\nstd::unique_ptr<Widget> upw2(new Widget);   // without make func\nauto spw1(std::make_shared<Widget>());      // with make func\nstd::shared_ptr<Widget> spw2(new Widget);   // without make func\nI’ve highlighted the essential difference: the versions using new repeat the type being\ncreated, but the make functions don’t. Repeating types runs afoul of a key tenet of\nsoftware engineering: code duplication should be avoided. Duplication in source\ncode increases compilation times, can lead to bloated object code, and generally ren‐\nders a code base more difficult to work with. It often evolves into inconsistent code,\nand inconsistency in a code base often leads to bugs. Besides, typing something twice\ntakes more effort than typing it once, and who’s not a fan of reducing their typing\nburden?\nThe second reason to prefer make functions has to do with exception safety. Suppose\nwe have a function to process a Widget in accord with some priority:\nvoid processWidget(std::shared_ptr<Widget> spw, int priority);\nPassing the std::shared_ptr by value may look suspicious, but Item 41 explains\nthat if processWidget always makes a copy of the std::shared_ptr (e.g., by storing\nit in a data structure tracking Widgets that have been processed), this can be a rea‐\nsonable design choice.\nNow suppose we have a function to compute the relevant priority,\nint computePriority();\nand we use that in a call to processWidget that uses new instead of\nstd::make_shared:\nprocessWidget(std::shared_ptr<Widget>(new Widget),  // potential\n              computePriority());                   // resource\n                                                    // leak!\nAs the comment indicates, this code could leak the Widget conjured up by new. But\nhow? Both the calling code and the called function are using std::shared_ptrs, and\nstd::shared_ptrs are designed to prevent resource leaks. They automatically\n140 \n| \nItem 21\nwww.it-ebooks.info\n",
      "content_length": 2156,
      "extraction_method": "Direct"
    },
    {
      "page_number": 159,
      "chapter": null,
      "content": "destroy what they point to when the last std::shared_ptr pointing there goes away.\nIf everybody is using std::shared_ptrs everywhere, how can this code leak?\nThe answer has to do with compilers’ translation of source code into object code. At\nruntime, the arguments for a function must be evaluated before the function can be\ninvoked, so in the call to processWidget, the following things must occur before\nprocessWidget can begin execution:\n• The expression “new Widget” must be evaluated, i.e., a Widget must be created\non the heap.\n• The constructor for the std::shared_ptr<Widget> responsible for managing\nthe pointer produced by new must be executed.\n• computePriority must run.\nCompilers are not required to generate code that executes them in this order. “new\nWidget” must be executed before the std::shared_ptr constructor may be called,\nbecause the result of that new is used as an argument to that constructor, but compute\nPriority may be executed before those calls, after them, or, crucially, between them.\nThat is, compilers may emit code to execute the operations in this order:\n1. Perform “new Widget”.\n2. Execute computePriority.\n3. Run std::shared_ptr constructor.\nIf such code is generated and, at runtime, computePriority produces an exception,\nthe dynamically allocated Widget from Step 1 will be leaked, because it will never be\nstored in the std::shared_ptr that’s supposed to start managing it in Step 3.\nUsing std::make_shared avoids this problem. Calling code would look like this:\nprocessWidget(std::make_shared<Widget>(),   // no potential\n              computePriority());           // resource leak\nAt runtime, either std::make_shared or computePriority will be called first. If it’s\nstd::make_shared, the raw pointer to the dynamically allocated Widget is safely\nstored in the returned std::shared_ptr before computePriority is called. If compu\ntePriority then yields an exception, the std::shared_ptr destructor will see to it\nthat the Widget it owns is destroyed. And if computePriority is called first and\nyields an exception, std::make_shared will not be invoked, and there will hence be\nno dynamically allocated Widget to worry about.\nItem 21 \n| \n141\nwww.it-ebooks.info\n",
      "content_length": 2205,
      "extraction_method": "Direct"
    },
    {
      "page_number": 160,
      "chapter": null,
      "content": "If we replace std::shared_ptr and std::make_shared with std::unique_ptr and\nstd::make_unique, exactly the same reasoning applies. Using std::make_unique\ninstead of new is thus just as important in writing exception-safe code as using\nstd::make_shared.\nA special feature of std::make_shared (compared to direct use of new) is improved\nefficiency. Using std::make_shared allows compilers to generate smaller, faster\ncode that employs leaner data structures. Consider the following direct use of new:\nstd::shared_ptr<Widget> spw(new Widget);\nIt’s obvious that this code entails a memory allocation, but it actually performs two.\nItem 19 explains that every std::shared_ptr points to a control block containing,\namong other things, the reference count for the pointed-to object. Memory for this\ncontrol block is allocated in the std::shared_ptr constructor. Direct use of new,\nthen, requires one memory allocation for the Widget and a second allocation for the\ncontrol block.\nIf std::make_shared is used instead,\nauto spw = std::make_shared<Widget>();\none allocation suffices. That’s because std::make_shared allocates a single chunk of\nmemory to hold both the Widget object and the control block. This optimization\nreduces the static size of the program, because the code contains only one memory\nallocation call, and it increases the speed of the executable code, because memory is\nallocated only once. Furthermore, using std::make_shared obviates the need for\nsome of the bookkeeping information in the control block, potentially reducing the\ntotal memory footprint for the program.\nThe efficiency analysis for std::make_shared is equally applicable to std::allo\ncate_shared, so the performance advantages of std::make_shared extend to that\nfunction, as well.\nThe arguments for preferring make functions over direct use of new are strong ones.\nDespite their software engineering, exception safety, and efficiency advantages, how‐\never, this Item’s guidance is to prefer the make functions, not to rely on them exclu‐\nsively. That’s because there are circumstances where they can’t or shouldn’t be used.\nFor example, none of the make functions permit the specification of custom deleters\n(see Items 18 and 19), but both std::unique_ptr and std::shared_ptr have con‐\nstructors that do. Given a custom deleter for a Widget,\nauto widgetDeleter = [](Widget* pw) { … };\ncreating a smart pointer using it is straightforward using new:\n142 \n| \nItem 21\nwww.it-ebooks.info\n",
      "content_length": 2462,
      "extraction_method": "Direct"
    },
    {
      "page_number": 161,
      "chapter": null,
      "content": "std::unique_ptr<Widget, decltype(widgetDeleter)>\n  upw(new Widget, widgetDeleter);\nstd::shared_ptr<Widget> spw(new Widget, widgetDeleter);\nThere’s no way to do the same thing with a make function.\nA second limitation of make functions stems from a syntactic detail of their imple‐\nmentations. Item 7 explains that when creating an object whose type overloads con‐\nstructors both with and without std::initializer_list parameters, creating the\nobject using braces prefers the std::initializer_list constructor, while creating\nthe object using parentheses calls the non-std::initializer_list constructor.\nThe make functions perfect-forward their parameters to an object’s constructor, but\ndo they do so using parentheses or using braces? For some types, the answer to this\nquestion makes a big difference. For example, in these calls,\nauto upv = std::make_unique<std::vector<int>>(10, 20);\nauto spv = std::make_shared<std::vector<int>>(10, 20);\ndo the resulting smart pointers point to std::vectors with 10 elements, each of\nvalue 20, or to std::vectors with two elements, one with value 10 and the other\nwith value 20? Or is the result indeterminate?\nThe good news is that it’s not indeterminate: both calls create std::vectors of size\n10 with all values set to 20. That means that within the make functions, the perfect\nforwarding code uses parentheses, not braces. The bad news is that if you want to\nconstruct your pointed-to object using a braced initializer, you must use new directly.\nUsing a make function would require the ability to perfect-forward a braced initial‐\nizer, but, as Item 30 explains, braced initializers can’t be perfect-forwarded. However,\nItem 30 also describes a workaround: use auto type deduction to create a std::ini\ntializer_list object from a braced initializer (see Item 2), then pass the auto-\ncreated object through the make function:\n// create std::initializer_list\nauto initList = { 10, 20 };\n// create std::vector using std::initializer_list ctor\nauto spv = std::make_shared<std::vector<int>>(initList);\nFor std::unique_ptr, these two scenarios (custom deleters and braced initializers)\nare the only ones where its make functions are problematic. For std::shared_ptr\nand its make functions, there are two more. Both are edge cases, but some developers\nlive on the edge, and you may be one of them.\nItem 21 \n| \n143\nwww.it-ebooks.info\n",
      "content_length": 2370,
      "extraction_method": "Direct"
    },
    {
      "page_number": 162,
      "chapter": null,
      "content": "4 In practice, the value of the weak count isn’t always equal to the number of std::weak_ptrs referring to the\ncontrol block, because library implementers have found ways to slip additional information into the weak\ncount that facilitate better code generation. For purposes of this Item, we’ll ignore this and assume that the\nweak count’s value is the number of std::weak_ptrs referring to the control block.\nSome classes define their own versions of operator new and operator delete. The\npresence of these functions implies that the global memory allocation and dealloca‐\ntion routines for objects of these types are inappropriate. Often, class-specific rou‐\ntines are designed only to allocate and deallocate chunks of memory of precisely the\nsize of objects of the class, e.g., operator new and operator delete for class Widget\nare often designed only to handle allocation and deallocation of chunks of memory of\nexactly size sizeof(Widget). Such routines are a poor fit for std::shared_ptr’s\nsupport for custom allocation (via std::allocate_shared) and deallocation (via\ncustom deleters), because the amount of memory that std::allocate_shared\nrequests isn’t the size of the dynamically allocated object, it’s the size of that object\nplus the size of a control block. Consequently, using make functions to create objects\nof types with class-specific versions of operator new and operator delete is typi‐\ncally a poor idea.\nThe size and speed advantages of std::make_shared vis-à-vis direct use of new stem\nfrom std::shared_ptr’s control block being placed in the same chunk of memory\nas the managed object. When that object’s reference count goes to zero, the object is\ndestroyed (i.e., its destructor is called). However, the memory it occupies can’t be\nreleased until the control block has also been destroyed, because the same chunk of\ndynamically allocated memory contains both.\nAs I noted, the control block contains bookkeeping information beyond just the ref‐\nerence count itself. The reference count tracks how many std::shared_ptrs refer to\nthe control block, but the control block contains a second reference count, one that\ntallies how many std::weak_ptrs refer to the control block. This second reference\ncount is known as the weak count.4 When a std::weak_ptr checks to see if it has\nexpired (see Item 19), it does so by examining the reference count (not the weak\ncount) in the control block that it refers to. If the reference count is zero (i.e., if the\npointed-to object has no std::shared_ptrs referring to it and has thus been\ndestroyed), the std::weak_ptr has expired. Otherwise, it hasn’t.\nAs long as std::weak_ptrs refer to a control block (i.e., the weak count is greater\nthan zero), that control block must continue to exist. And as long as a control block\nexists, the memory containing it must remain allocated. The memory allocated by a\nstd::shared_ptr make function, then, can’t be deallocated until the last\nstd::shared_ptr and the last std::weak_ptr referring to it have been destroyed.\n144 \n| \nItem 21\nwww.it-ebooks.info\n",
      "content_length": 3056,
      "extraction_method": "Direct"
    },
    {
      "page_number": 163,
      "chapter": null,
      "content": "If the object type is quite large and the time between destruction of the last\nstd::shared_ptr and the last std::weak_ptr is significant, a lag can occur between\nwhen an object is destroyed and when the memory it occupied is freed:\nclass ReallyBigType { … };\nauto pBigObj =                          // create very large\n  std::make_shared<ReallyBigType>();    // object via\n                                        // std::make_shared\n…            // create std::shared_ptrs and std::weak_ptrs to\n             // large object, use them to work with it\n…            // final std::shared_ptr to object destroyed here,\n             // but std::weak_ptrs to it remain\n…            // during this period, memory formerly occupied\n             // by large object remains allocated\n…            // final std::weak_ptr to object destroyed here;\n             // memory for control block and object is released\nWith a direct use of new, the memory for the ReallyBigType object can be released\nas soon as the last std::shared_ptr to it is destroyed:\nclass ReallyBigType { … };              // as before\nstd::shared_ptr<ReallyBigType> pBigObj(new ReallyBigType);\n                                        // create very large\n                                        // object via new\n…            // as before, create std::shared_ptrs and\n             // std::weak_ptrs to object, use them with it\n…            // final std::shared_ptr to object destroyed here,\n             // but std::weak_ptrs to it remain;\n             // memory for object is deallocated\n…            // during this period, only memory for the\n             // control block remains allocated\n…            // final std::weak_ptr to object destroyed here;\n             // memory for control block is released\nShould you find yourself in a situation where use of std::make_shared is impossible\nor inappropriate, you’ll want to guard yourself against the kind of exception-safety\nItem 21 \n| \n145\nwww.it-ebooks.info\n",
      "content_length": 1968,
      "extraction_method": "Direct"
    },
    {
      "page_number": 164,
      "chapter": null,
      "content": "problems we saw earlier. The best way to do that is to make sure that when you use\nnew directly, you immediately pass the result to a smart pointer constructor in a\nstatement that does nothing else. This prevents compilers from generating code that\ncould emit an exception between the use of new and invocation of the constructor for\nthe smart pointer that will manage the newed object.\nAs an example, consider a minor revision to the exception-unsafe call to the process\nWidget function we examined earlier. This time, we’ll specify a custom deleter:\nvoid processWidget(std::shared_ptr<Widget> spw,  // as before\n                   int priority);\nvoid cusDel(Widget *ptr);                        // custom\n                                                 // deleter\nHere’s the exception-unsafe call:\nprocessWidget(                                   // as before,\n  std::shared_ptr<Widget>(new Widget, cusDel),   // potential\n  computePriority()                              // resource\n);                                               // leak!\nRecall: if computePriority is called after “new Widget” but before the\nstd::shared_ptr constructor, and if computePriority yields an exception, the\ndynamically allocated Widget will be leaked.\nHere the use of a custom deleter precludes use of std::make_shared, so the way to\navoid the problem is to put the allocation of the Widget and the construction of the\nstd::shared_ptr into their own statement, then call processWidget with the\nresulting std::shared_ptr. Here’s the essence of the technique, though, as we’ll see\nin a moment, we can tweak it to improve its performance:\nstd::shared_ptr<Widget> spw(new Widget, cusDel);\nprocessWidget(spw, computePriority());     // correct, but not\n                                           // optimal; see below\nThis works, because a std::shared_ptr assumes ownership of the raw pointer\npassed to its constructor, even if that constructor yields an exception. In this example,\nif spw’s constructor throws an exception (e.g., due to an inability to dynamically allo‐\ncate memory for a control block), it’s still guaranteed that cusDel will be invoked on\nthe pointer resulting from “new Widget”.\nThe minor performance hitch is that in the exception-unsafe call, we’re passing an\nrvalue to processWidget,\n146 \n| \nItem 21\nwww.it-ebooks.info\n",
      "content_length": 2324,
      "extraction_method": "Direct"
    },
    {
      "page_number": 165,
      "chapter": null,
      "content": "processWidget(\n  std::shared_ptr<Widget>(new Widget, cusDel),  // arg is rvalue\n  computePriority()\n);\nbut in the exception-safe call, we’re passing an lvalue:\nprocessWidget(spw, computePriority());          // arg is lvalue\nBecause processWidget’s std::shared_ptr parameter is passed by value, construc‐\ntion from an rvalue entails only a move, while construction from an lvalue requires a\ncopy. For std::shared_ptr, the difference can be significant, because copying a\nstd::shared_ptr requires an atomic increment of its reference count, while moving\na std::shared_ptr requires no reference count manipulation at all. For the\nexception-safe code to achieve the level of performance of the exception-unsafe code,\nwe need to apply std::move to spw to turn it into an rvalue (see Item 23):\nprocessWidget(std::move(spw),            // both efficient and\n              computePriority());        // exception safe\nThat’s interesting and worth knowing, but it’s also typically irrelevant, because you’ll\nrarely have a reason not to use a make function. And unless you have a compelling\nreason for doing otherwise, using a make function is what you should do.\nThings to Remember\n• Compared to direct use of new, make functions eliminate source code duplica‐\ntion, improve exception safety, and, for std::make_shared and std::allo\ncate_shared, generate code that’s smaller and faster.\n• Situations where use of make functions is inappropriate include the need to\nspecify custom deleters and a desire to pass braced initializers.\n• For std::shared_ptrs, additional situations where make functions may be\nill-advised include (1) classes with custom memory management and (2) sys‐\ntems with memory concerns, very large objects, and std::weak_ptrs that\noutlive the corresponding std::shared_ptrs.\nItem 22: When using the Pimpl Idiom, define special\nmember functions in the implementation file.\nIf you’ve ever had to combat excessive build times, you’re familiar with the Pimpl\n(“pointer to implementation”) Idiom. That’s the technique whereby you replace the\ndata members of a class with a pointer to an implementation class (or struct), put the\nItem 21 \n| \n147\nwww.it-ebooks.info\n",
      "content_length": 2171,
      "extraction_method": "Direct"
    },
    {
      "page_number": 166,
      "chapter": null,
      "content": "data members that used to be in the primary class into the implementation class, and\naccess those data members indirectly through the pointer. For example, suppose\nWidget looks like  this:\nclass Widget {                     // in header \"widget.h\"\npublic:\n  Widget();\n  …\nprivate:\n  std::string name;\n  std::vector<double> data;\n  Gadget g1, g2, g3;               // Gadget is some user-\n};                                 // defined type\nBecause Widget’s data members are of types std::string, std::vector, and\nGadget, headers for those types must be present for Widget to compile, and that\nmeans that Widget clients must #include <string>, <vector>, and gadget.h.\nThose headers increase the compilation time for Widget clients, plus they make those\nclients dependent on the contents of the headers. If a header’s content changes,\nWidget clients must recompile. The standard headers <string> and <vector> don’t\nchange very often, but it could be that gadget.h is subject to frequent revision.\nApplying the Pimpl Idiom in C++98 could have Widget replace its data members\nwith a raw pointer to a struct that has been declared, but not defined:\nclass Widget {                 // still in header \"widget.h\"\npublic:\n  Widget();\n  ~Widget();                   // dtor is needed—see below\n  …\nprivate:\n  struct Impl;                 // declare implementation struct\n  Impl *pImpl;                 // and pointer to it\n};\nBecause Widget no longer mentions the types std::string, std::vector, and\nGadget, Widget clients no longer need to #include the headers for these types. That\nspeeds compilation, and it also means that if something in these headers changes,\nWidget clients are unaffected.\nA type that has been declared, but not defined, is known as an incomplete type.\nWidget::Impl is such a type. There are very few things you can do with an incom‐\nplete type, but declaring a pointer to it is one of them. The Pimpl Idiom takes advan‐\ntage of that.\n148 \n| \nItem 22\nwww.it-ebooks.info\n",
      "content_length": 1983,
      "extraction_method": "Direct"
    },
    {
      "page_number": 167,
      "chapter": null,
      "content": "Part 1 of the Pimpl Idiom is the declaration of a data member that’s a pointer to an\nincomplete type. Part 2 is the dynamic allocation and deallocation of the object that\nholds the data members that used to be in the original class. The allocation and deal‐\nlocation code goes in the implementation file, e.g., for Widget, in widget.cpp:\n#include \"widget.h\"            // in impl. file \"widget.cpp\"\n#include \"gadget.h\"\n#include <string>\n#include <vector>\nstruct Widget::Impl {          // definition of Widget::Impl\n  std::string name;            // with data members formerly\n  std::vector<double> data;    // in Widget\n  Gadget g1, g2, g3;\n};\nWidget::Widget()               // allocate data members for\n: pImpl(new Impl)              // this Widget object\n{}\nWidget::~Widget()              // destroy data members for\n{ delete pImpl; }              // this object\nHere I’m showing #include directives to make clear that the overall dependencies on\nthe headers for std::string, std::vector, and Gadget continue to exist. However,\nthese dependencies have been moved from widget.h (which is visible to and used by\nWidget clients) to widget.cpp (which is visible to and used only by the Widget\nimplementer). I’ve also highlighted the code that dynamically allocates and deallo‐\ncates the Impl object. The need to deallocate this object when a Widget is destroyed\nis what necessitates the Widget destructor.\nBut I’ve shown you C++98 code, and that reeks of a bygone millennium. It uses raw\npointers and raw new and raw delete and it’s all just so…raw. This chapter is built\non the idea that smart pointers are preferable to raw pointers, and if what we want is\nto dynamically allocate a Widget::Impl object inside the Widget constructor and\nhave it destroyed at the same time the Widget is, std::unique_ptr (see Item 18) is\nprecisely the tool we need. Replacing the raw pImpl pointer with a std::unique_ptr\nyields this code for the header file,\nclass Widget {                      // in \"widget.h\"\npublic:\n  Widget();\n  …\nprivate:\nItem 22 \n| \n149\nwww.it-ebooks.info\n",
      "content_length": 2063,
      "extraction_method": "Direct"
    },
    {
      "page_number": 168,
      "chapter": null,
      "content": "  struct Impl; \n  std::unique_ptr<Impl> pImpl;      // use smart pointer\n};                                  // instead of raw pointer\nand this for the implementation file:\n#include \"widget.h\"                 // in \"widget.cpp\"\n#include \"gadget.h\"\n#include <string>\n#include <vector>\nstruct Widget::Impl {               // as before\n  std::string name;\n  std::vector<double> data;\n  Gadget g1, g2, g3;\n};\nWidget::Widget()                    // per Item 21, create\n: pImpl(std::make_unique<Impl>())   // std::unique_ptr\n{}                                  // via std::make_unique\nYou’ll note that the Widget destructor is no longer present. That’s because we have\nno code to put into it. std::unique_ptr automatically deletes what it points to when\nit (the std::unique_ptr) is destroyed, so we need not delete anything ourselves.\nThat’s one of the attractions of smart pointers: they eliminate the need for us to sully\nour hands with manual resource release.\nThis code compiles, but, alas, the most trivial client use doesn’t:\n#include \"widget.h\"\nWidget w;                           // error!\nThe error message you receive depends on the compiler you’re using, but the text\ngenerally mentions something about applying sizeof or delete to an incomplete\ntype. Those operations aren’t among the things you can do with such types.\nThis apparent failure of the Pimpl Idiom using std::unique_ptrs is alarming,\nbecause (1) std::unique_ptr is advertised as supporting incomplete types, and (2)\nthe Pimpl Idiom is one of std::unique_ptrs most common use cases. Fortunately,\ngetting the code to work is easy. All that’s required is a basic understanding of the\ncause of the problem.\nThe issue arises due to the code that’s generated when w is destroyed (e.g., goes out of\nscope). At that point, its destructor is called. In the class definition using\nstd::unique_ptr, we didn’t declare a destructor, because we didn’t have any code to\nput into it. In accord with the usual rules for compiler-generated special member\n150 \n| \nItem 22\nwww.it-ebooks.info\n",
      "content_length": 2041,
      "extraction_method": "Direct"
    },
    {
      "page_number": 169,
      "chapter": null,
      "content": "functions (see Item 17), the compiler generates a destructor for us. Within that\ndestructor, the compiler inserts code to call the destructor for Widget’s data member\npImpl. pImpl is a std::unique_ptr<Widget::Impl>, i.e., a std::unique_ptr\nusing the default deleter. The default deleter is a function that uses delete on the raw\npointer inside the std::unique_ptr. Prior to using delete, however, implementa‐\ntions typically have the default deleter employ C++11’s static_assert to ensure \nthat the raw pointer doesn’t point to an incomplete type. When the compiler gener‐\nates code for the destruction of the Widget w, then, it generally encounters a\nstatic_assert that fails, and that’s usually what leads to the error message. This\nmessage is associated with the point where w is destroyed, because Widget’s destruc‐\ntor, like all compiler-generated special member functions, is implicitly inline. The\nmessage itself often refers to the line where w is created, because it’s the source code\nexplicitly creating the object that leads to its later implicit destruction.\nTo fix the problem, you just need to make sure that at the point where the code to\ndestroy the std::unique_ptr<Widget::Impl> is generated, Widget::Impl is a\ncomplete type. The type becomes complete when its definition has been seen, and\nWidget::Impl is defined inside widget.cpp. The key to successful compilation,\nthen, is to have the compiler see the body of Widget’s destructor (i.e., the place where\nthe compiler will generate code to destroy the std::unique_ptr data member) only\ninside widget.cpp after Widget::Impl has been defined.\nArranging for that is simple. Declare Widget’s destructor in widget.h, but don’t\ndefine it there:\nclass Widget {                     // as before, in \"widget.h\"\npublic:\n  Widget();\n  ~Widget();                       // declaration only\n  …\nprivate:                           // as before\n  struct Impl;\n  std::unique_ptr<Impl> pImpl;\n};\nDefine it in widget.cpp after Widget::Impl has been defined:\n#include \"widget.h\"                // as before, in \"widget.cpp\"\n#include \"gadget.h\"\n#include <string>\n#include <vector>\n  struct Widget::Impl {            // as before, definition of\nItem 22 \n| \n151\nwww.it-ebooks.info\n",
      "content_length": 2228,
      "extraction_method": "Direct"
    },
    {
      "page_number": 170,
      "chapter": null,
      "content": "  std::string name;                // Widget::Impl\n  std::vector<double> data;\n  Gadget g1, g2, g3;\n};\nWidget::Widget()                   // as before\n: pImpl(std::make_unique<Impl>())\n{}\nWidget::~Widget()                  // ~Widget definition\n{}\nThis works well, and it requires the least typing, but if you want to emphasize that the\ncompiler-generated destructor would do the right thing—that the only reason you\ndeclared it was to cause its definition to be generated in Widget’s implementation\nfile, you can define the destructor body with “= default”:\nWidget::~Widget() = default;       // same effect as above\nClasses using the Pimpl Idiom are natural candidates for move support, because\ncompiler-generated move operations do exactly what’s desired: perform a move on\nthe underlying std::unique_ptr. As Item 17 explains, the declaration of a destruc‐\ntor in Widget prevents compilers from generating the move operations, so if you\nwant move support, you must declare the functions yourself. Given that the\ncompiler-generated versions would behave correctly, you’re likely to be tempted to\nimplement them as follows:\nclass Widget {                                 // still in\npublic:                                        // \"widget.h\"\n  Widget();\n  ~Widget();\n  Widget(Widget&& rhs) = default;              // right idea,\n  Widget& operator=(Widget&& rhs) = default;   // wrong code!\n \n  …\nprivate:                                       // as before\n  struct Impl;\n  std::unique_ptr<Impl> pImpl;\n};\nThis approach leads to the same kind of problem as declaring the class without a\ndestructor, and for the same fundamental reason. The compiler-generated move\nassignment operator needs to destroy the object pointed to by pImpl before reassign‐\ning it, but in the Widget header file, pImpl points to an incomplete type. The situa‐\n152 \n| \nItem 22\nwww.it-ebooks.info\n",
      "content_length": 1873,
      "extraction_method": "Direct"
    },
    {
      "page_number": 171,
      "chapter": null,
      "content": "tion is different for the move constructor. The problem there is that compilers\ntypically generate code to destroy pImpl in the event that an exception arises inside\nthe move constructor, and destroying pImpl requires that Impl be complete.\nBecause the problem is the same as before, so is the fix—move the definition of the\nmove operations into the implementation file:\nclass Widget {                       // still in \"widget.h\"\npublic:\n  Widget();\n  ~Widget();\n  Widget(Widget&& rhs);              // declarations\n  Widget& operator=(Widget&& rhs);   // only\n  …\nprivate:                             // as before\n  struct Impl;\n  std::unique_ptr<Impl> pImpl;\n};\n#include <string>                    // as before,\n…                                    // in \"widget.cpp\"\nstruct Widget::Impl { … };           // as before\nWidget::Widget()                     // as before\n: pImpl(std::make_unique<Impl>())\n{}\nWidget::~Widget() = default;         // as before\nWidget::Widget(Widget&& rhs) = default;              // defini-\nWidget& Widget::operator=(Widget&& rhs) = default;   // tions\nThe Pimpl Idiom is a way to reduce compilation dependencies between a class’s\nimplementation and the class’s clients, but, conceptually, use of the idiom doesn’t\nchange what the class represents. The original Widget class contained std::string,\nstd::vector, and Gadget data members, and, assuming that Gadgets, like\nstd::strings and std::vectors, can be copied, it would make sense for Widget to\nsupport the copy operations. We have to write these functions ourselves, because (1)\ncompilers won’t generate copy operations for classes with move-only types like\nstd::unique_ptr and (2) even if they did, the generated functions would copy only\nItem 22 \n| \n153\nwww.it-ebooks.info\n",
      "content_length": 1762,
      "extraction_method": "Direct"
    },
    {
      "page_number": 172,
      "chapter": null,
      "content": "the std::unique_ptr (i.e., perform a shallow copy), and we want to copy what the\npointer points to (i.e., perform a deep copy).\nIn a ritual that is by now familiar, we declare the functions in the header file and\nimplement them in the implementation file:\nclass Widget {                         // still in \"widget.h\"\npublic:\n  …                                    // other funcs, as before\n  Widget(const Widget& rhs);              // declarations\n  Widget& operator=(const Widget& rhs);   // only\nprivate:                                  // as before\n  struct Impl;\n  std::unique_ptr<Impl> pImpl;\n};\n#include \"widget.h\"                  // as before,\n…                                    // in \"widget.cpp\"\nstruct Widget::Impl { … };           // as before\nWidget::~Widget() = default;         // other funcs, as before\nWidget::Widget(const Widget& rhs)              // copy ctor\n: pImpl(std::make_unique<Impl>(*rhs.pImpl))\n{}\nWidget& Widget::operator=(const Widget& rhs)   // copy operator=\n{\n  *pImpl = *rhs.pImpl;\n  return *this;\n}\nBoth function implementations are conventional. In each case, we simply copy the\nfields of the Impl struct from the source object (rhs) to the destination object\n(*this). Rather than copy the fields one by one, we take advantage of the fact that\ncompilers will create the copy operations for Impl, and these operations will copy\neach field automatically. We thus implement Widget’s copy operations by calling\nWidget::Impl’s compiler-generated copy operations. In the copy constructor, note\nthat we still follow the advice of Item 21 to prefer use of std::make_unique over\ndirect use of new.\n154 \n| \nItem 22\nwww.it-ebooks.info\n",
      "content_length": 1664,
      "extraction_method": "Direct"
    },
    {
      "page_number": 173,
      "chapter": null,
      "content": "For purposes of implementing the Pimpl Idiom, std::unique_ptr is the smart\npointer to use, because the pImpl pointer inside an object (e.g., inside a Widget) has\nexclusive ownership of the corresponding implementation object (e.g., the\nWidget::Impl object). Still, it’s interesting to note that if we were to use\nstd::shared_ptr instead of std::unique_ptr for pImpl, we’d find that the advice\nof this Item no longer applied. There’d be no need to declare a destructor in Widget,\nand without a user-declared destructor, compilers would happily generate the move\noperations, which would do exactly what we’d want them to. That is, given this code\nin widget.h,\nclass Widget {                     // in \"widget.h\"\npublic:\n  Widget();\n  …                                // no declarations for dtor\n                                   // or move operations\nprivate:\n  struct Impl; \n  std::shared_ptr<Impl> pImpl;     // std::shared_ptr\n};                                 // instead of std::unique_ptr\nand this client code that #includes widget.h,\nWidget w1;\nauto w2(std::move(w1));            // move-construct w2\nw1 = std::move(w2);                // move-assign w1\neverything would compile and run as we’d hope: w1 would be default constructed, its\nvalue would be moved into w2, that value would be moved back into w1, and then\nboth w1 and w2 would be destroyed (thus causing the pointed-to Widget::Impl\nobject to be destroyed).\nThe difference in behavior between std::unique_ptr and std::shared_ptr for\npImpl pointers stems from the differing ways these smart pointers support custom\ndeleters. For std::unique_ptr, the type of the deleter is part of the type of the smart\npointer, and this makes it possible for compilers to generate smaller runtime data\nstructures and faster runtime code. A consequence of this greater efficiency is that\npointed-to types must be complete when compiler-generated special functions (e.g.,\ndestructors or move operations) are used. For std::shared_ptr, the type of the\ndeleter is not part of the type of the smart pointer. This necessitates larger runtime\ndata structures and somewhat slower code, but pointed-to types need not be com‐\nplete when compiler-generated special functions are employed.\nItem 22 \n| \n155\nwww.it-ebooks.info\n",
      "content_length": 2262,
      "extraction_method": "Direct"
    },
    {
      "page_number": 174,
      "chapter": null,
      "content": "For the Pimpl Idiom, there’s not really a trade-off between the characteristics of\nstd::unique_ptr and std::shared_ptr, because the relationship between classes\nlike Widget and classes like Widget::Impl is exclusive ownership, and that makes\nstd::unique_ptr the proper tool for the job. Nevertheless, it’s worth knowing that\nin \nother \nsituations—situations \nwhere \nshared \nownership \nexists \n(and\nstd::shared_ptr is hence a fitting design choice), there’s no need to jump through\nthe function-definition hoops that use of std::unique_ptr entails.\nThings to Remember\n• The Pimpl Idiom decreases build times by reducing compilation dependencies\nbetween class clients and class implementations.\n• For std::unique_ptr pImpl pointers, declare special member functions in\nthe class header, but implement them in the implementation file. Do this even\nif the default function implementations are acceptable.\n• The above advice applies to std::unique_ptr, but not to std::shared_ptr.\n156 \n| \nItem 22\nwww.it-ebooks.info\n",
      "content_length": 1011,
      "extraction_method": "Direct"
    },
    {
      "page_number": 175,
      "chapter": null,
      "content": "CHAPTER 5\nRvalue References, Move Semantics,\nand Perfect Forwarding\nWhen you first learn about them, move semantics and perfect forwarding seem\npretty straightforward:\n• Move semantics makes it possible for compilers to replace expensive copying\noperations with less expensive moves. In the same way that copy constructors\nand copy assignment operators give you control over what it means to copy\nobjects, move constructors and move assignment operators offer control over the\nsemantics of moving. Move semantics also enables the creation of move-only\ntypes, such as std::unique_ptr, std::future, and std::thread.\n• Perfect forwarding makes it possible to write function templates that take arbi‐\ntrary arguments and forward them to other functions such that the target func‐\ntions receive exactly the same arguments as were passed to the forwarding\nfunctions.\nRvalue references are the glue that ties these two rather disparate features together.\nThey’re the underlying language mechanism that makes both move semantics and\nperfect forwarding possible.\nThe more experience you have with these features, the more you realize that your ini‐\ntial impression was based on only the metaphorical tip of the proverbial iceberg. The\nworld of move semantics, perfect forwarding, and rvalue references is more nuanced\nthan it appears. std::move doesn’t move anything, for example, and perfect forward‐\ning is imperfect. Move operations aren’t always cheaper than copying; when they are,\nthey’re not always as cheap as you’d expect; and they’re not always called in a context\nwhere moving is valid. The construct “type&&” doesn’t always represent an rvalue\nreference.\n157\nwww.it-ebooks.info\n",
      "content_length": 1681,
      "extraction_method": "Direct"
    },
    {
      "page_number": 176,
      "chapter": null,
      "content": "No matter how far you dig into these features, it can seem that there’s always more to\nuncover. Fortunately, there is a limit to their depths. This chapter will take you to the\nbedrock. Once you arrive, this part of C++11 will make a lot more sense. You’ll know\nthe usage conventions for std::move and std::forward, for example. You’ll be\ncomfortable with the ambiguous nature of “type&&”. You’ll understand the reasons\nfor the surprisingly varied behavioral profiles of move operations. All those pieces\nwill fall into place. At that point, you’ll be back where you started, because move\nsemantics, perfect forwarding, and rvalue references will once again seem pretty\nstraightforward. But this time, they’ll stay that way.\nIn the Items in this chapter, it’s especially important to bear in mind that a parameter\nis always an lvalue, even if its type is an rvalue reference. That is, given\nvoid f(Widget&& w);\nthe parameter w is an lvalue, even though its type is rvalue-reference-to-Widget. (If\nthis surprises you, please review the overview of lvalues and rvalues that begins on\npage 2.)\nItem 23: Understand std::move and std::forward.\nIt’s useful to approach std::move and std::forward in terms of what they don’t do.\nstd::move doesn’t move anything. std::forward doesn’t forward anything. At run‐\ntime, neither does anything at all. They generate no executable code. Not a single\nbyte.\nstd::move and std::forward are merely functions (actually function templates)\nthat perform casts. std::move unconditionally casts its argument to an rvalue, while\nstd::forward performs this cast only if a particular condition is fulfilled. That’s it.\nThe explanation leads to a new set of questions, but, fundamentally, that’s the com‐\nplete story.\nTo make the story more concrete, here’s a sample implementation of std::move in\nC++11. It’s not fully conforming to the details of the Standard, but it’s very close.\ntemplate<typename T>                       // in namespace std\ntypename remove_reference<T>::type&&\nmove(T&& param)\n{\n  using ReturnType =                       // alias declaration;\n    typename remove_reference<T>::type&&;  // see Item 9\n  return static_cast<ReturnType>(param);\n}\n158 \n| \nItem 22\nwww.it-ebooks.info\n",
      "content_length": 2224,
      "extraction_method": "Direct"
    },
    {
      "page_number": 177,
      "chapter": null,
      "content": "I’ve highlighted two parts of the code for you. One is the name of the function,\nbecause the return type specification is rather noisy, and I don’t want you to lose your\nbearings in the din. The other is the cast that comprises the essence of the function.\nAs you can see, std::move takes a reference to an object (a universal reference, to be\nprecise—see Item 24) and it returns a reference to the same object.\nThe “&&” part of the function’s return type implies that std::move returns an rvalue\nreference, but, as Item 28 explains, if the type T happens to be an lvalue reference, T&&\nwould become an lvalue reference. To prevent this from happening, the type trait (see\nItem 9) std::remove_reference is applied to T, thus ensuring that “&&” is applied\nto a type that isn’t a reference. That guarantees that std::move truly returns an\nrvalue reference, and that’s important, because rvalue references returned from func‐\ntions are rvalues. Thus, std::move casts its argument to an rvalue, and that’s all it\ndoes.\nAs an aside, std::move can be implemented with less fuss in C++14. Thanks to func‐\ntion return type deduction (see Item 3) and to the Standard Library’s alias template\nstd::remove_reference_t (see Item 9), std::move can be written this way:\ntemplate<typename T>                          // C++14; still in\ndecltype(auto) move(T&& param)                // namespace std\n{\n  using ReturnType = remove_reference_t<T>&&;\n  return static_cast<ReturnType>(param);\n}\nEasier on the eyes, no?\nBecause std::move does nothing but cast its argument to an rvalue, there have been\nsuggestions that a better name for it might have been something like rvalue_cast.\nBe that as it may, the name we have is std::move, so it’s important to remember\nwhat std::move does and doesn’t do. It does cast. It doesn’t move.\nOf course, rvalues are candidates for moving, so applying std::move to an object\ntells the compiler that the object is eligible to be moved from. That’s why std::move\nhas the name it does: to make it easy to designate objects that may be moved from.\nIn truth, rvalues are only usually candidates for moving. Suppose you’re writing a\nclass representing annotations. The class’s constructor takes a std::string parame‐\nter comprising the annotation, and it copies the parameter to a data member. Flush\nwith the information in Item 41, you declare a by-value parameter:\nclass Annotation {\npublic:\n  explicit Annotation(std::string text);  // param to be copied,\nItem 23 \n| \n159\nwww.it-ebooks.info\n",
      "content_length": 2505,
      "extraction_method": "Direct"
    },
    {
      "page_number": 178,
      "chapter": null,
      "content": "  …                                       // so per Item 41,\n};                                        // pass by value\nBut Annotation’s constructor needs only to read text’s value. It doesn’t need to\nmodify it. In accord with the time-honored tradition of using const whenever possi‐\nble, you revise your declaration such that text is const:\nclass Annotation {\npublic:\n  explicit Annotation(const std::string text)\n  …\n};\nTo avoid paying for a copy operation when copying text into a data member, you\nremain true to the advice of Item 41 and apply std::move to text, thus producing\nan rvalue:\nclass Annotation {\npublic:\n  explicit Annotation(const std::string text)\n  : value(std::move(text))  // \"move\" text into value; this code\n  { … }                     // doesn't do what it seems to!\n  \n  …\nprivate:\n  std::string value;\n};\nThis code compiles. This code links. This code runs. This code sets the data member\nvalue to the content of text. The only thing separating this code from a perfect real‐\nization of your vision is that text is not moved into value, it’s copied. Sure, text is\ncast to an rvalue by std::move, but text is declared to be a const std::string, so\nbefore the cast, text is an lvalue const std::string, and the result of the cast is an\nrvalue const std::string, but throughout it all, the constness remains.\nConsider the effect that has when compilers have to determine which std::string\nconstructor to call. There are two possibilities:\nclass string {            // std::string is actually a \npublic:                   // typedef for std::basic_string<char>\n  …\n  string(const string& rhs);    // copy ctor\n  string(string&& rhs);         // move ctor\n  …\n};\n160 \n| \nItem 23\nwww.it-ebooks.info\n",
      "content_length": 1720,
      "extraction_method": "Direct"
    },
    {
      "page_number": 179,
      "chapter": null,
      "content": "In the Annotation constructor’s member initialization list, the result of\nstd::move(text) is an rvalue of type const std::string. That rvalue can’t be\npassed to std::string’s move constructor, because the move constructor takes an\nrvalue reference to a non-const std::string. The rvalue can, however, be passed to\nthe copy constructor, because an lvalue-reference-to-const is permitted to bind to a\nconst rvalue. The member initialization therefore invokes the copy constructor in\nstd::string, even though text has been cast to an rvalue! Such behavior is essential\nto maintaining const-correctness. Moving a value out of an object generally modifies\nthe object, so the language should not permit const objects to be passed to functions\n(such as move constructors) that could modify them.\nThere are two lessons to be drawn from this example. First, don’t declare objects\nconst if you want to be able to move from them. Move requests on const objects are\nsilently transformed into copy operations. Second, std::move not only doesn’t\nactually move anything, it doesn’t even guarantee that the object it’s casting will be\neligible to be moved. The only thing you know for sure about the result of applying\nstd::move to an object is that it’s an rvalue.\nThe story for std::forward is similar to that for std::move, but whereas\nstd::move unconditionally casts its argument to an rvalue, std::forward does it\nonly under certain conditions. std::forward is a conditional cast. To understand\nwhen it casts and when it doesn’t, recall how std::forward is typically used. The\nmost common scenario is a function template taking a universal reference parameter\nthat is to be passed to another function:\nvoid process(const Widget& lvalArg);     // process lvalues\nvoid process(Widget&& rvalArg);          // process rvalues\ntemplate<typename T>                     // template that passes\nvoid logAndProcess(T&& param)            // param to process\n{\n  auto now =                             // get current time\n    std::chrono::system_clock::now();\n  makeLogEntry(\"Calling 'process'\", now);\n  process(std::forward<T>(param));\n}\nConsider two calls to logAndProcess, one with an lvalue, the other with an rvalue:\nWidget w;\nlogAndProcess(w);                  // call with lvalue\nlogAndProcess(std::move(w));       // call with rvalue\nItem 23 \n| \n161\nwww.it-ebooks.info\n",
      "content_length": 2355,
      "extraction_method": "Direct"
    },
    {
      "page_number": 180,
      "chapter": null,
      "content": "Inside logAndProcess, the parameter param is passed to the function process. pro\ncess is overloaded for lvalues and rvalues. When we call logAndProcess with an\nlvalue, we naturally expect that lvalue to be forwarded to process as an lvalue, and\nwhen we call logAndProcess with an rvalue, we expect the rvalue overload of pro\ncess to be invoked.\nBut param, like all function parameters, is an lvalue. Every call to process inside\nlogAndProcess will thus want to invoke the lvalue overload for process. To prevent\nthis, we need a mechanism for param to be cast to an rvalue if and only if the argu‐\nment with which param was initialized—the argument passed to logAndProcess—\nwas an rvalue. This is precisely what std::forward does. That’s why std::forward\nis a conditional cast: it casts to an rvalue only if its argument was initialized with an\nrvalue.\nYou may wonder how std::forward can know whether its argument was initialized\nwith an rvalue. In the code above, for example, how can std::forward tell whether\nparam was initialized with an lvalue or an rvalue? The brief answer is that that infor‐\nmation is encoded in logAndProcess’s template parameter T. That parameter is\npassed to std::forward, which recovers the encoded information. For details on\nexactly how that works, consult Item 28.\nGiven that both std::move and std::forward boil down to casts, the only differ‐\nence being that std::move always casts, while std::forward only sometimes does,\nyou might ask whether we can dispense with std::move and just use std::forward\neverywhere. From a purely technical perspective, the answer is yes: std::forward\ncan do it all. std::move isn’t necessary. Of course, neither function is really neces‐\nsary, because we could write casts everywhere, but I hope we agree that that would be,\nwell, yucky.\nstd::move’s attractions are convenience, reduced likelihood of error, and greater\nclarity. Consider a class where we want to track how many times the move construc‐\ntor is called. A static counter that’s incremented during move construction is all we\nneed. Assuming the only non-static data in the class is a std::string, here’s the\nconventional way (i.e., using std::move) to implement the move constructor:\nclass Widget {\npublic:\n  Widget(Widget&& rhs)\n  : s(std::move(rhs.s))\n  { ++moveCtorCalls; }\n  …\n162 \n| \nItem 23\nwww.it-ebooks.info\n",
      "content_length": 2345,
      "extraction_method": "Direct"
    },
    {
      "page_number": 181,
      "chapter": null,
      "content": "private:\n  static std::size_t moveCtorCalls;\n  std::string s;\n};\nTo implement the same behavior with std::forward, the code would look like this:\nclass Widget {\npublic:\n  Widget(Widget&& rhs)                      // unconventional,\n  : s(std::forward<std::string>(rhs.s))     // undesirable\n  { ++moveCtorCalls; }                      // implementation\n  …\n};\nNote first that std::move requires only a function argument (rhs.s), while\nstd::forward requires both a function argument (rhs.s) and a template type argu‐\nment (std::string). Then note that the type we pass to std::forward should be a\nnon-reference, because that’s the convention for encoding that the argument being\npassed is an rvalue (see Item 28). Together, this means that std::move requires less\ntyping than std::forward, and it spares us the trouble of passing a type argument\nthat encodes that the argument we’re passing is an rvalue. It also eliminates the possi‐\nbility of our passing an incorrect type (e.g., std::string&, which would result in the\ndata member s being copy constructed instead of move constructed).\nMore importantly, the use of std::move conveys an unconditional cast to an rvalue,\nwhile the use of std::forward indicates a cast to an rvalue only for references to\nwhich rvalues have been bound. Those are two very different actions. The first one\ntypically sets up a move, while the second one just passes—forwards—an object to\nanother function in a way that retains its original lvalueness or rvalueness. Because\nthese actions are so different, it’s good that we have two different functions (and\nfunction names) to distinguish them.\nThings to Remember\n• std::move performs an unconditional cast to an rvalue. In and of itself, it\ndoesn’t move anything.\n• std::forward casts its argument to an rvalue only if that argument is bound\nto an rvalue.\n• Neither std::move nor std::forward do anything at runtime.\nItem 23 \n| \n163\nwww.it-ebooks.info\n",
      "content_length": 1933,
      "extraction_method": "Direct"
    },
    {
      "page_number": 182,
      "chapter": null,
      "content": "1 Item 25 explains that universal references should almost always have std::forward applied to them, and as\nthis book goes to press, some members of the C++ community have started referring to universal references\nas forwarding references.\nItem 24: Distinguish universal references from rvalue\nreferences.\nIt’s been said that the truth shall set you free, but under the right circumstances, a\nwell-chosen lie can be equally liberating. This Item is such a lie. Because we’re dealing\nwith software, however, let’s eschew the word “lie” and instead say that this Item\ncomprises an “abstraction.”  \nTo declare an rvalue reference to some type T, you write T&&. It thus seems reason‐\nable to assume that if you see “T&&” in source code, you’re looking at an rvalue refer‐\nence. Alas, it’s not quite that simple:\nvoid f(Widget&& param);             // rvalue reference\nWidget&& var1 = Widget();           // rvalue reference\nauto&& var2 = var1;                 // not rvalue reference\ntemplate<typename T>\nvoid f(std::vector<T>&& param);     // rvalue reference\ntemplate<typename T>\nvoid f(T&& param);                  // not rvalue reference\nIn fact, “T&&” has two different meanings. One is rvalue reference, of course. Such\nreferences behave exactly the way you expect: they bind only to rvalues, and their pri‐\nmary raison d’être is to identify objects that may be moved from.\nThe other meaning for “T&&” is either rvalue reference or lvalue reference. Such refer‐\nences look like rvalue references in the source code (i.e., “T&&”), but they can behave\nas if they were lvalue references (i.e., “T&”). Their dual nature permits them to bind to\nrvalues (like rvalue references) as well as lvalues (like lvalue references). Furthermore,\nthey can bind to const or non-const objects, to volatile or non-volatile objects,\neven to objects that are both const and volatile. They can bind to virtually any‐\nthing. Such unprecedentedly flexible references deserve a name of their own. I call\nthem universal references.1\nUniversal references arise in two contexts. The most common is function template\nparameters, such as this example from the sample code above:\n164 \n| \nItem 24\nwww.it-ebooks.info\n",
      "content_length": 2186,
      "extraction_method": "Direct"
    },
    {
      "page_number": 183,
      "chapter": null,
      "content": "template<typename T>\nvoid f(T&& param);             // param is a universal reference\nThe second context is auto declarations, including this one from the sample code\nabove:\nauto&& var2 = var1;            // var2 is a universal reference\nWhat these contexts have in common is the presence of type deduction. In the tem‐\nplate f, the type of param is being deduced, and in the declaration for var2, var2’s\ntype is being deduced. Compare that with the following examples (also from the sam‐\nple code above), where type deduction is missing. If you see “T&&” without type\ndeduction, you’re looking at an rvalue reference:\nvoid f(Widget&& param);        // no type deduction;\n                               // param is an rvalue reference\nWidget&& var1 = Widget();      // no type deduction;\n                               // var1 is an rvalue reference\nBecause universal references are references, they must be initialized. The initializer\nfor a universal reference determines whether it represents an rvalue reference or an\nlvalue reference. If the initializer is an rvalue, the universal reference corresponds to\nan rvalue reference. If the initializer is an lvalue, the universal reference corresponds\nto an lvalue reference. For universal references that are function parameters, the ini‐\ntializer is provided at the call site:\ntemplate<typename T>\nvoid f(T&& param);     // param is a universal reference\nWidget w;\nf(w);                  // lvalue passed to f; param's type is\n                       // Widget& (i.e., an lvalue reference)\nf(std::move(w));       // rvalue passed to f; param's type is\n                       // Widget&& (i.e., an rvalue reference)\nFor a reference to be universal, type deduction is necessary, but it’s not sufficient. The\nform of the reference declaration must also be correct, and that form is quite con‐\nstrained. It must be precisely “T&&”. Look again at this example from the sample code\nwe saw earlier:\ntemplate<typename T>\nvoid f(std::vector<T>&& param);  // param is an rvalue reference\nWhen f is invoked, the type T will be deduced (unless the caller explicitly specifies it,\nan edge case we’ll not concern ourselves with). But the form of param’s type declara‐\nItem 24 \n| \n165\nwww.it-ebooks.info\n",
      "content_length": 2240,
      "extraction_method": "Direct"
    },
    {
      "page_number": 184,
      "chapter": null,
      "content": "tion isn’t “T&&”, it’s “std::vector<T>&&”. That rules out the possibility that param is\na universal reference. param is therefore an rvalue reference, something that your\ncompilers will be happy to confirm for you if you try to pass an lvalue to f:\nstd::vector<int> v;\nf(v);                             // error! can't bind lvalue to\n                                  // rvalue reference\nEven the simple presence of a const qualifier is enough to disqualify a reference from\nbeing universal:\ntemplate<typename T>\nvoid f(const T&& param);         // param is an rvalue reference\nIf you’re in a template and you see a function parameter of type “T&&”, you might\nthink you can assume that it’s a universal reference. You can’t. That’s because being\nin a template doesn’t guarantee the presence of type deduction. Consider this\npush_back member function in std::vector:\ntemplate<class T, class Allocator = allocator<T>>  // from C++\nclass vector {                                     // Standards\npublic:\n  void push_back(T&& x);\n  …\n};\npush_back’s parameter certainly has the right form for a universal reference, but\nthere’s no type deduction in this case. That’s because push_back can’t exist without a\nparticular vector instantiation for it to be part of, and the type of that instantiation\nfully determines the declaration for push_back. That is, saying\nstd::vector<Widget> v;\ncauses the std::vector template to be instantiated as follows:\nclass vector<Widget, allocator<Widget>> {\npublic:\n  void push_back(Widget&& x);               // rvalue reference\n  …\n};\nNow you can see clearly that push_back employs no type deduction. This push_back\nfor vector<T> (there are two—the function is overloaded) always declares a parame‐\nter of type rvalue-reference-to-T.\nIn contrast, the conceptually similar emplace_back member function in std::vec\ntor does employ type deduction:\n166 \n| \nItem 24\nwww.it-ebooks.info\n",
      "content_length": 1907,
      "extraction_method": "Direct"
    },
    {
      "page_number": 185,
      "chapter": null,
      "content": "template<class T, class Allocator = allocator<T>>  // still from\nclass vector {                                     // C++\npublic:                                            // Standards\n  template <class... Args>\n  void emplace_back(Args&&... args);\n  …\n};\nHere, the type parameter Args is independent of vector’s type parameter T, so Args\nmust be deduced each time emplace_back is called. (Okay, Args is really a parameter\npack, not a type parameter, but for purposes of this discussion, we can treat it as if it\nwere a type parameter.)\nThe fact that emplace_back’s type parameter is named Args, yet it’s still a universal\nreference, reinforces my earlier comment that it’s the form of a universal reference\nthat must be “T&&”. There’s no requirement that you use the name T. For example,\nthe following template takes a universal reference, because the form (“type&&”) is\nright, and param’s type will be deduced (again, excluding the corner case where the\ncaller explicitly specifies the type):\ntemplate<typename MyTemplateType>         // param is a\nvoid someFunc(MyTemplateType&& param);    // universal reference\nI remarked earlier that auto variables can also be universal references. To be more\nprecise, variables declared with the type auto&& are universal references, because type\ndeduction takes place and they have the correct form (“T&&”). auto universal refer‐\nences are not as common as universal references used for function template parame‐\nters, but they do crop up from time to time in C++11. They crop up a lot more in\nC++14, because C++14 lambda expressions may declare auto&& parameters. For\nexample, if you wanted to write a C++14 lambda to record the time taken in an arbi‐\ntrary function invocation, you could do this:\nauto timeFuncInvocation =\n  [](auto&& func, auto&&... params)               // C++14\n  {\n    start timer;\n    std::forward<decltype(func)>(func)(           // invoke func\n      std::forward<decltype(params)>(params)...   // on params\n      );                              \n    stop timer and record elapsed time;\n  };\nIf your reaction to the “std::forward<decltype(blah blah blah)>” code inside\nthe lambda is, “What the…?!”, that probably just means you haven’t yet read Item 33.\nDon’t worry about it. The important thing in this Item is the auto&& parameters that\nItem 24 \n| \n167\nwww.it-ebooks.info\n",
      "content_length": 2343,
      "extraction_method": "Direct"
    },
    {
      "page_number": 186,
      "chapter": null,
      "content": "the lambda declares. func is a universal reference that can be bound to any callable\nobject, lvalue or rvalue. args is zero or more universal references (i.e., a universal ref‐\nerence parameter pack) that can be bound to any number of objects of arbitrary\ntypes. The result, thanks to auto universal references, is that timeFuncInvocation\ncan time pretty much any function execution. (For information on the difference\nbetween “any” and “pretty much any,” turn to Item 30.)\nBear in mind that this entire Item—the foundation of universal references—is a lie…\ner, an “abstraction.” The underlying truth is known as reference collapsing, a topic to\nwhich Item 28 is dedicated. But the truth doesn’t make the abstraction any less useful.\nDistinguishing between rvalue references and universal references will help you read\nsource code more accurately (“Does that T&& I’m looking at bind to rvalues only or to\neverything?”), and it will avoid ambiguities when you communicate with your collea‐\ngues (“I’m using a universal reference here, not an rvalue reference…”). It will also\nallow you to make sense of Items 25 and 26, which rely on the distinction. So\nembrace the abstraction. Revel in it. Just as Newton’s laws of motion (which are tech‐\nnically incorrect) are typically just as useful as and easier to apply than Einstein’s\ntheory of general relativity (“the truth”), so is the notion of universal references nor‐\nmally preferable to working through the details of reference collapsing.\nThings to Remember\n• If a function template parameter has type T&& for a deduced type T, or if an\nobject is declared using auto&&, the parameter or object is a universal refer‐\nence.\n• If the form of the type declaration isn’t precisely type&&, or if type deduction\ndoes not occur, type&& denotes an rvalue reference.\n• Universal references correspond to rvalue references if they’re initialized with\nrvalues. They correspond to lvalue references if they’re initialized with lval‐\nues.  \nItem 25: Use std::move on rvalue references,\nstd::forward on universal references.\nRvalue references bind only to objects that are candidates for moving. If you have an\nrvalue reference parameter, you know that the object it’s bound to may be moved:\nclass Widget {\n  Widget(Widget&& rhs);        // rhs definitely refers to an\n168 \n| \nItem 24\nwww.it-ebooks.info\n",
      "content_length": 2340,
      "extraction_method": "Direct"
    },
    {
      "page_number": 187,
      "chapter": null,
      "content": "  …                            // object eligible for moving\n};\nThat being the case, you’ll want to pass such objects to other functions in a way that\npermits those functions to take advantage of the object’s rvalueness. The way to do\nthat is to cast parameters bound to such objects to rvalues. As Item 23 explains, that’s\nnot only what std::move does, it’s what it was created for:\nclass Widget {\npublic:\n  Widget(Widget&& rhs)               // rhs is rvalue reference\n  : name(std::move(rhs.name)),\n    p(std::move(rhs.p))\n    { … }\n  …\nprivate:\n  std::string name;\n  std::shared_ptr<SomeDataStructure> p;\n};\nA universal reference, on the other hand (see Item 24), might be bound to an object\nthat’s eligible for moving. Universal references should be cast to rvalues only if they\nwere initialized with rvalues. Item 23 explains that this is precisely what std::for\nward does:\nclass Widget {\npublic:\n  template<typename T>\n  void setName(T&& newName)               // newName is\n  { name = std::forward<T>(newName); }    // universal reference\n  …\n};\nIn short, rvalue references should be unconditionally cast to rvalues (via std::move)\nwhen forwarding them to other functions, because they’re always bound to rvalues,\nand universal references should be conditionally cast to rvalues (via std::forward)\nwhen forwarding them, because they’re only sometimes bound to rvalues.\nItem 23 explains that using std::forward on rvalue references can be made to\nexhibit the proper behavior, but the source code is wordy, error-prone, and unidio‐\nmatic, so you should avoid using std::forward with rvalue references. Even worse is\nthe idea of using std::move with universal references, because that can have the\neffect of unexpectedly modifying lvalues (e.g., local variables):\nItem 25 \n| \n169\nwww.it-ebooks.info\n",
      "content_length": 1804,
      "extraction_method": "Direct"
    },
    {
      "page_number": 188,
      "chapter": null,
      "content": "class Widget {\npublic:\n  template<typename T>\n  void setName(T&& newName)         // universal reference\n  { name = std::move(newName); }    // compiles, but is\n  …                                 // bad, bad, bad!\nprivate:\n  std::string name;\n  std::shared_ptr<SomeDataStructure> p;\n};\nstd::string getWidgetName();        // factory function\nWidget w;\nauto n = getWidgetName();           // n is local variable\nw.setName(n);                       // moves n into w!\n…                                   // n's value now unknown\nHere, the local variable n is passed to w.setName, which the caller can be forgiven for\nassuming is a read-only operation on n. But because setName internally uses\nstd::move to unconditionally cast its reference parameter to an rvalue, n’s value will\nbe moved into w.name, and n will come back from the call to setName with an unspe‐\ncified value. That’s the kind of behavior that can drive callers to despair—possibly to\nviolence.\nYou might argue that setName shouldn’t have declared its parameter to be a univer‐\nsal reference. Such references can’t be const (see Item 24), yet setName surely\nshouldn’t modify its parameter. You might point out that if setName had simply been\noverloaded for const lvalues and for rvalues, the whole problem could have been\navoided. Like this:\nclass Widget {\npublic:\n  void setName(const std::string& newName)      // set from\n  { name = newName; }                           // const lvalue\n  void setName(std::string&& newName)           // set from\n  { name = std::move(newName); }                // rvalue\n  …\n};\n170 \n| \nItem 25\nwww.it-ebooks.info\n",
      "content_length": 1614,
      "extraction_method": "Direct"
    },
    {
      "page_number": 189,
      "chapter": null,
      "content": "That would certainly work in this case, but there are drawbacks. First, it’s more\nsource code to write and maintain (two functions instead of a single template). Sec‐\nond, it can be less efficient. For example, consider this use of setName:\nw.setName(\"Adela Novak\");\nWith the version of setName taking a universal reference, the string literal \"Adela\nNovak\" would be passed to setName, where it would be conveyed to the assignment\noperator for the std::string inside w. w’s name data member would thus be assigned\ndirectly from the string literal; no temporary std::string objects would arise. With\nthe overloaded versions of setName, however, a temporary std::string object\nwould be created for setName’s parameter to bind to, and this temporary\nstd::string would then be moved into w’s data member. A call to setName would\nthus entail execution of one std::string constructor (to create the temporary), one\nstd::string move assignment operator (to move newName into w.name), and one\nstd::string destructor (to destroy the temporary). That’s almost certainly a more\nexpensive execution sequence than invoking only the std::string assignment oper‐\nator taking a const char* pointer. The additional cost is likely to vary from imple‐\nmentation to implementation, and whether that cost is worth worrying about will\nvary from application to application and library to library, but the fact is that replac‐\ning a template taking a universal reference with a pair of functions overloaded on\nlvalue references and rvalue references is likely to incur a runtime cost in some cases.\nIf we generalize the example such that Widget’s data member may be of an arbitrary\ntype (rather than knowing that it’s std::string), the performance gap can widen\nconsiderably, because not all types are as cheap to move as std::string (see\nItem 29).\nThe most serious problem with overloading on lvalues and rvalues, however, isn’t the\nvolume or idiomaticity of the source code, nor is it the code’s runtime performance.\nIt’s the poor scalability of the design. Widget::setName takes only one parameter, so\nonly two overloads are necessary, but for functions taking more parameters, each of\nwhich could be an lvalue or an rvalue, the number of overloads grows geometrically:\nn parameters necessitates 2n overloads. And that’s not the worst of it. Some functions\n—function templates, actually—take an unlimited number of parameters, each of\nwhich could be an lvalue or rvalue. The poster children for such functions are\nstd::make_shared, and, as of C++14, std::make_unique (see Item 21). Check out\nthe declarations of their most commonly used overloads:\ntemplate<class T, class... Args>                 // from C++11\nshared_ptr<T> make_shared(Args&&... args);       // Standard\ntemplate<class T, class... Args>                 // from C++14\nunique_ptr<T> make_unique(Args&&... args);       // Standard\nItem 25 \n| \n171\nwww.it-ebooks.info\n",
      "content_length": 2910,
      "extraction_method": "Direct"
    },
    {
      "page_number": 190,
      "chapter": null,
      "content": "For functions like these, overloading on lvalues and rvalues is not an option: univer‐\nsal references are the only way to go. And inside such functions, I assure you,\nstd::forward is applied to the universal reference parameters when they’re passed\nto other functions. Which is exactly what you should do.\nWell, usually. Eventually. But not necessarily initially. In some cases, you’ll want to\nuse the object bound to an rvalue reference or a universal reference more than once\nin a single function, and you’ll want to make sure that it’s not moved from until\nyou’re otherwise done with it. In that case, you’ll want to apply std::move (for rvalue\nreferences) or std::forward (for universal references) to only the final use of the\nreference. For example:\ntemplate<typename T>                       // text is\nvoid setSignText(T&& text)                 // univ. reference\n{\n  sign.setText(text);                      // use text, but\n                                           // don't modify it\n  auto now =                               // get current time\n    std::chrono::system_clock::now();\n    \n  signHistory.add(now,\n                  std::forward<T>(text));  // conditionally cast\n}                                          // text to rvalue\nHere, we want to make sure that text’s value doesn’t get changed by sign.setText,\nbecause we want to use that value when we call signHistory.add. Ergo the use of\nstd::forward on only the final use of the universal reference.\nFor std::move, the same thinking applies (i.e., apply std::move to an rvalue refer‐\nence the last time it’s used), but it’s important to note that in rare cases, you’ll want to\ncall std::move_if_noexcept instead of std::move. To learn when and why, consult\nItem 14.\nIf you’re in a function that returns by value, and you’re returning an object bound to\nan rvalue reference or a universal reference, you’ll want to apply std::move or\nstd::forward when you return the reference. To see why, consider an operator+\nfunction to add two matrices together, where the left-hand matrix is known to be an\nrvalue (and can hence have its storage reused to hold the sum of the matrices):\nMatrix                                        // by-value return\noperator+(Matrix&& lhs, const Matrix& rhs)\n{\n  lhs += rhs;\n172 \n| \nItem 25\nwww.it-ebooks.info\n",
      "content_length": 2310,
      "extraction_method": "Direct"
    },
    {
      "page_number": 191,
      "chapter": null,
      "content": "  return std::move(lhs);                      // move lhs into\n}                                             // return value\nBy casting lhs to an rvalue in the return statement (via std::move), lhs will be\nmoved into the function’s return value location. If the call to std::move were omit‐\nted,\nMatrix                                        // as above\noperator+(Matrix&& lhs, const Matrix& rhs)\n{\n  lhs += rhs;\n  return lhs;                                 // copy lhs into\n}                                             // return value\nthe fact that lhs is an lvalue would force compilers to instead copy it into the return\nvalue location. Assuming that the Matrix type supports move construction, which is\nmore efficient than copy construction, using std::move in the return statement\nyields more efficient code.\nIf Matrix does not support moving, casting it to an rvalue won’t hurt, because the\nrvalue will simply be copied by Matrix’s copy constructor (see Item 23). If Matrix is\nlater revised to support moving, operator+ will automatically benefit the next time it\nis compiled. That being the case, there’s nothing to be lost (and possibly much to be\ngained) by applying std::move to rvalue references being returned from functions\nthat return by value.\nThe situation is similar for universal references and std::forward. Consider a func‐\ntion template reduceAndCopy that takes a possibly unreduced Fraction object,\nreduces it, and then returns a copy of the reduced value. If the original object is an\nrvalue, its value should be moved into the return value (thus avoiding the expense of\nmaking a copy), but if the original is an lvalue, an actual copy must be created.\nHence:\ntemplate<typename T>         \nFraction                           // by-value return\nreduceAndCopy(T&& frac)            // universal reference param\n{\n  frac.reduce();\n  return std::forward<T>(frac);    // move rvalue into return\n}                                  // value, copy lvalue\nIf the call to std::forward were omitted, frac would be unconditionally copied into\nreduceAndCopy’s return value.\nSome programmers take the information above and try to extend it to situations\nwhere it doesn’t apply. “If using std::move on an rvalue reference parameter being\nItem 25 \n| \n173\nwww.it-ebooks.info\n",
      "content_length": 2282,
      "extraction_method": "Direct"
    },
    {
      "page_number": 192,
      "chapter": null,
      "content": "2 Eligible local objects include most local variables (such as w inside makeWidget) as well as temporary objects\ncreated as part of a return statement. Function parameters don’t qualify. Some people draw a distinction\nbetween application of the RVO to named and unnamed (i.e., temporary) local objects, limiting the term\nRVO to unnamed objects and calling its application to named objects the named return value optimization\n(NRVO).\ncopied into a return value turns a copy construction into a move construction,” they\nreason, “I can perform the same optimization on local variables that I’m returning.”\nIn other words, they figure that given a function returning a local variable by value,\nsuch as this,\nWidget makeWidget()        // \"Copying\" version of makeWidget\n{\n  Widget w;                // local variable\n  …                        // configure w\n  return w;                // \"copy\" w into return value\n}\nthey can “optimize” it by turning the “copy” into a move:\nWidget makeWidget()        // Moving version of makeWidget\n{\n  Widget w;\n  …\n  return std::move(w);     // move w into return value\n}                          // (don't do this!)\nMy liberal use of quotation marks should tip you off that this line of reasoning is\nflawed. But why is it flawed?\nIt’s flawed, because the Standardization Committee is way ahead of such program‐\nmers when it comes to this kind of optimization. It was recognized long ago that the\n“copying” version of makeWidget can avoid the need to copy the local variable w by\nconstructing it in the memory alloted for the function’s return value. This is known\nas the return value optimization (RVO), and it’s been expressly blessed by the C++\nStandard for as long as there’s been one.\nWording such a blessing is finicky business, because you want to permit such copy\nelision only in places where it won’t affect the observable behavior of the software.\nParaphrasing the legalistic (arguably toxic) prose of the Standard, this particular\nblessing says that compilers may elide the copying (or moving) of a local object2 in a\nfunction that returns by value if (1) the type of the local object is the same as that\nreturned by the function and (2) the local object is what’s being returned. With that\nin mind, look again at the “copying” version of makeWidget:\n174 \n| \nItem 25\nwww.it-ebooks.info\n",
      "content_length": 2331,
      "extraction_method": "Direct"
    },
    {
      "page_number": 193,
      "chapter": null,
      "content": "Widget makeWidget()        // \"Copying\" version of makeWidget\n{\n  Widget w;\n  …\n  return w;                // \"copy\" w into return value\n}\nBoth conditions are fulfilled here, and you can trust me when I tell you that for this\ncode, every decent C++ compiler will employ the RVO to avoid copying w. That\nmeans that the “copying” version of makeWidget doesn’t, in fact, copy anything.\nThe moving version of makeWidget does just what its name says it does (assuming\nWidget offers a move constructor): it moves the contents of w into makeWidget’s\nreturn value location. But why don’t compilers use the RVO to eliminate the move,\nagain constructing w in the memory alloted for the function’s return value? The\nanswer is simple: they can’t. Condition (2) stipulates that the RVO may be performed\nonly if what’s being returned is a local object, but that’s not what the moving version\nof makeWidget is doing. Look again at its return statement:\nreturn std::move(w);\nWhat’s being returned here isn’t the local object w, it’s a reference to w—the result of\nstd::move(w). Returning a reference to a local object doesn’t satisfy the conditions\nrequired for the RVO, so compilers must move w into the function’s return value\nlocation. Developers trying to help their compilers optimize by applying std::move\nto a local variable that’s being returned are actually limiting the optimization options\navailable to their compilers!\nBut the RVO is an optimization. Compilers aren’t required to elide copy and move\noperations, even when they’re permitted to. Maybe you’re paranoid, and you worry\nthat your compilers will punish you with copy operations, just because they can. Or\nperhaps you’re insightful enough to recognize that there are cases where the RVO is\ndifficult for compilers to implement, e.g., when different control paths in a function\nreturn different local variables. (Compilers would have to generate code to construct\nthe appropriate local variable in the memory allotted for the function’s return value,\nbut how could compilers determine which local variable would be appropriate?) If so,\nyou might be willing to pay the price of a move as insurance against the cost of a\ncopy. That is, you might still think it’s reasonable to apply std::move to a local\nobject you’re returning, simply because you’d rest easy knowing you’d never pay for a\ncopy.\nIn that case, applying std::move to a local object would still be a bad idea. The part\nof the Standard blessing the RVO goes on to say that if the conditions for the RVO\nare met, but compilers choose not to perform copy elision, the object being returned\nmust be treated as an rvalue. In effect, the Standard requires that when the RVO is\nItem 25 \n| \n175\nwww.it-ebooks.info\n",
      "content_length": 2722,
      "extraction_method": "Direct"
    },
    {
      "page_number": 194,
      "chapter": null,
      "content": "permitted, either copy elision takes place or std::move is implicitly applied to local\nobjects being returned. So in the “copying” version of makeWidget,\nWidget makeWidget()        // as before\n{\n  Widget w;\n  …\n  return w;\n}\ncompilers must either elide the copying of w or they must treat the function as if it\nwere written like this:\nWidget makeWidget()\n{\n  Widget w;\n  …\n  return std::move(w);     // treat w as rvalue, because\n}                          // no copy elision was performed\nThe situation is similar for by-value function parameters. They’re not eligible for\ncopy elision with respect to their function’s return value, but compilers must treat\nthem as rvalues if they’re returned. As a result, if your source code looks like this,\nWidget makeWidget(Widget w)       // by-value parameter of same\n{                                 // type as function's return\n  …\n  return w;\n}\ncompilers must treat it as if it had been written this way:\nWidget makeWidget(Widget w)\n{\n  …\n  return std::move(w);            // treat w as rvalue\n}\nThis means that if you use std::move on a local object being returned from a func‐\ntion that’s returning by value, you can’t help your compilers (they have to treat the\nlocal object as an rvalue if they don’t perform copy elision), but you can certainly hin‐\nder them (by precluding the RVO). There are situations where applying std::move\nto a local variable can be a reasonable thing to do (i.e., when you’re passing it to a\nfunction and you know you won’t be using the variable any longer), but as part of a\nreturn statement that would otherwise qualify for the RVO or that returns a by-\nvalue parameter isn’t among them.\n176 \n| \nItem 25\nwww.it-ebooks.info\n",
      "content_length": 1702,
      "extraction_method": "Direct"
    },
    {
      "page_number": 195,
      "chapter": null,
      "content": "Things to Remember\n• Apply std::move to rvalue references and std::forward to universal refer‐\nences the last time each is used.\n• Do the same thing for rvalue references and universal references being\nreturned from functions that return by value.\n• Never apply std::move or std::forward to local objects if they would other‐\nwise be eligible for the return value optimization.\nItem 26: Avoid overloading on universal references.\nSuppose you need to write a function that takes a name as a parameter, logs the cur‐\nrent date and time, then adds the name to a global data structure. You might come up\nwith a function that looks something like this:\nstd::multiset<std::string> names;     // global data structure\nvoid logAndAdd(const std::string& name)\n{\n  auto now =                          // get current time\n    std::chrono::system_clock::now();\n  log(now, \"logAndAdd\");              // make log entry\n  names.emplace(name);                // add name to global data\n}                                     // structure; see Item 42\n                                      // for info on emplace\nThis isn’t unreasonable code, but it’s not as efficient as it could be. Consider three\npotential calls:\nstd::string petName(\"Darla\");\nlogAndAdd(petName);                   // pass lvalue std::string\nlogAndAdd(std::string(\"Persephone\")); // pass rvalue std::string\nlogAndAdd(\"Patty Dog\");               // pass string literal\nIn the first call, logAndAdd’s parameter name is bound to the variable petName.\nWithin logAndAdd, name is ultimately passed to names.emplace. Because name is an\nlvalue, it is copied into names. There’s no way to avoid that copy, because an lvalue\n(petName) was passed into logAndAdd.\nItem 25 \n| \n177\nwww.it-ebooks.info\n",
      "content_length": 1739,
      "extraction_method": "Direct"
    },
    {
      "page_number": 196,
      "chapter": null,
      "content": "In the second call, the parameter name is bound to an rvalue (the temporary\nstd::string explicitly created from \"Persephone\"). name itself is an lvalue, so it’s\ncopied into names, but we recognize that, in principle, its value could be moved into\nnames. In this call, we pay for a copy, but we should be able to get by with only a\nmove.\nIn the third call, the parameter name is again bound to an rvalue, but this time it’s to a\ntemporary std::string that’s implicitly created from \"Patty Dog\". As in the sec‐\nond call, name is copied into names, but in this case, the argument originally passed to\nlogAndAdd was a string literal. Had that string literal been passed directly to\nemplace, there would have been no need to create a temporary std::string at all.\nInstead, emplace would have used the string literal to create the std::string object\ndirectly inside the std::multiset. In this third call, then, we’re paying to copy a\nstd::string, yet there’s really no reason to pay even for a move, much less a copy.\nWe can eliminate the inefficiencies in the second and third calls by rewriting\nlogAndAdd to take a universal reference (see Item 24) and, in accord with Item 25,\nstd::forwarding this reference to emplace. The results speak for themselves:\ntemplate<typename T>\nvoid logAndAdd(T&& name)\n{\n  auto now = std::chrono::system_clock::now();\n  log(now, \"logAndAdd\");\n  names.emplace(std::forward<T>(name));\n}\nstd::string petName(\"Darla\");          // as before\nlogAndAdd(petName);                    // as before, copy\n                                       // lvalue into multiset\nlogAndAdd(std::string(\"Persephone\"));  // move rvalue instead\n                                       // of copying it\nlogAndAdd(\"Patty Dog\");                // create std::string\n                                       // in multiset instead\n                                       // of copying a temporary\n                                       // std::string\nHurray, optimal efficiency!\nWere this the end of the story, we could stop here and proudly retire, but I haven’t\ntold you that clients don’t always have direct access to the names that logAndAdd\n178 \n| \nItem 26\nwww.it-ebooks.info\n",
      "content_length": 2176,
      "extraction_method": "Direct"
    },
    {
      "page_number": 197,
      "chapter": null,
      "content": "requires. Some clients have only an index that logAndAdd uses to look up the corre‐\nsponding name in a table. To support such clients, logAndAdd is overloaded:\nstd::string nameFromIdx(int idx);      // return name\n                                       // corresponding to idx\nvoid logAndAdd(int idx)                // new overload\n{\n  auto now = std::chrono::system_clock::now();\n  log(now, \"logAndAdd\");\n  names.emplace(nameFromIdx(idx));\n}\nResolution of calls to the two overloads works as expected:\nstd::string petName(\"Darla\");          // as before\nlogAndAdd(petName);                    // as before, these\nlogAndAdd(std::string(\"Persephone\"));  // calls all invoke\nlogAndAdd(\"Patty Dog\");                // the T&& overload\nlogAndAdd(22);                         // calls int overload\nActually, resolution works as expected only if you don’t expect too much. Suppose a\nclient has a short holding an index and passes that to logAndAdd:\nshort nameIdx;\n…                                      // give nameIdx a value\nlogAndAdd(nameIdx);                    // error!\nThe comment on the last line isn’t terribly illuminating, so let me explain what hap‐\npens here.\nThere are two logAndAdd overloads. The one taking a universal reference can deduce\nT to be short, thus yielding an exact match. The overload with an int parameter can\nmatch the short argument only with a promotion. Per the normal overload resolu‐\ntion rules, an exact match beats a match with a promotion, so the universal reference\noverload is invoked.\nWithin that overload, the parameter name is bound to the short that’s passed in.\nname is then std::forwarded to the emplace member function on names (a\nstd::multiset<std::string>), which, in turn, dutifully forwards it to the\nstd::string constructor. There is no constructor for std::string that takes a\nshort, so the std::string constructor call inside the call to multiset::emplace\nItem 26 \n| \n179\nwww.it-ebooks.info\n",
      "content_length": 1940,
      "extraction_method": "Direct"
    },
    {
      "page_number": 198,
      "chapter": null,
      "content": "inside the call to logAndAdd fails. All because the universal reference overload was a\nbetter match for a short argument than an int.\nFunctions taking universal references are the greediest functions in C++. They\ninstantiate to create exact matches for almost any type of argument. (The few kinds of\narguments where this isn’t the case are described in Item 30.) This is why combining\noverloading and universal references is almost always a bad idea: the universal refer‐\nence overload vacuums up far more argument types than the developer doing the\noverloading generally expects.\nAn easy way to topple into this pit is to write a perfect forwarding constructor. A\nsmall modification to the logAndAdd example demonstrates the problem. Instead of\nwriting a free function that can take either a std::string or an index that can be\nused to look up a std::string, imagine a class Person with constructors that do the\nsame  thing:\nclass Person {\npublic:\n  template<typename T>         \n  explicit Person(T&& n)           // perfect forwarding ctor;\n  : name(std::forward<T>(n)) {}    // initializes data member\n  explicit Person(int idx)         // int ctor\n  : name(nameFromIdx(idx)) {}\n  …\nprivate:\n  std::string name;\n};\nAs was the case with logAndAdd, passing an integral type other than int (e.g.,\nstd::size_t, short, long, etc.) will call the universal reference constructor over‐\nload instead of the int overload, and that will lead to compilation failures. The prob‐\nlem here is much worse, however, because there’s more overloading present in\nPerson than meets the eye. Item 17 explains that under the appropriate conditions,\nC++ will generate both copy and move constructors, and this is true even if the class\ncontains a templatized constructor that could be instantiated to produce the signa‐\nture of the copy or move constructor. If the copy and move constructors for Person\nare thus generated, Person will effectively look like this:\nclass Person {\npublic:\n  template<typename T>              // perfect forwarding ctor\n  explicit Person(T&& n)\n  : name(std::forward<T>(n)) {}\n180 \n| \nItem 26\nwww.it-ebooks.info\n",
      "content_length": 2121,
      "extraction_method": "Direct"
    },
    {
      "page_number": 199,
      "chapter": null,
      "content": "  explicit Person(int idx);         // int ctor\n  Person(const Person& rhs);        // copy ctor\n                                    // (compiler-generated)\n  Person(Person&& rhs);             // move ctor\n  …                                 // (compiler-generated)\n};\nThis leads to behavior that’s intuitive only if you’ve spent so much time around com‐\npilers and compiler-writers, you’ve forgotten what it’s like to be human:\nPerson p(\"Nancy\");\nauto cloneOfP(p);                   // create new Person from p;\n                                    // this won't compile!\nHere we’re trying to create a Person from another Person, which seems like about as\nobvious a case for copy construction as one can get. (p’s an lvalue, so we can banish\nany thoughts we might have about the “copying” being accomplished through a move\noperation.) But this code won’t call the copy constructor. It will call the perfect-\nforwarding constructor. That function will then try to initialize Person’s\nstd::string data member with a Person object (p). std::string having no con‐\nstructor taking a Person, your compilers will throw up their hands in exasperation,\npossibly punishing you with long and incomprehensible error messages as an expres‐\nsion of their displeasure.\n“Why,” you might wonder, “does the perfect-forwarding constructor get called\ninstead of the copy constructor? We’re initializing a Person with another Person!”\nIndeed we are, but compilers are sworn to uphold the rules of C++, and the rules of\nrelevance here are the ones governing the resolution of calls to overloaded functions.\nCompilers reason as follows. cloneOfP is being initialized with a non-const lvalue\n(p), and that means that the templatized constructor can be instantiated to take a\nnon-const lvalue of type Person. After such instantiation, the Person class looks like\nthis:\nclass Person {\npublic:\n  explicit Person(Person& n)             // instantiated from\n  : name(std::forward<Person&>(n)) {}    // perfect-forwarding\n                                         // template\n  explicit Person(int idx);              // as before\nItem 26 \n| \n181\nwww.it-ebooks.info\n",
      "content_length": 2134,
      "extraction_method": "Direct"
    },
    {
      "page_number": 200,
      "chapter": null,
      "content": "  Person(const Person& rhs);             // copy ctor\n  …                                      // (compiler-generated)\n};\nIn the statement,\nauto cloneOfP(p);\np could be passed to either the copy constructor or the instantiated template. Calling\nthe copy constructor would require adding const to p to match the copy construc‐\ntor’s parameter’s type, but calling the instantiated template requires no such addition.\nThe overload generated from the template is thus a better match, so compilers do\nwhat they’re designed to do: generate a call to the better-matching function. “Copy‐\ning” non-const lvalues of type Person is thus handled by the perfect-forwarding\nconstructor, not the copy constructor.\nIf we change the example slightly so that the object to be copied is const, we hear an\nentirely different tune:\nconst Person cp(\"Nancy\");     // object is now const\nauto cloneOfP(cp);            // calls copy constructor!\nBecause the object to be copied is now const, it’s an exact match for the parameter\ntaken by the copy constructor. The templatized constructor can be instantiated to\nhave the same signature,\nclass Person {\npublic:\n  explicit Person(const Person& n);      // instantiated from\n                                         // template\n  Person(const Person& rhs);             // copy ctor\n                                         // (compiler-generated)\n  …\n};\nbut this doesn’t matter, because one of the overload-resolution rules in C++ is that in\nsituations where a template instantiation and a non-template function (i.e., a “nor‐\nmal” function) are equally good matches for a function call, the normal function is\npreferred. The copy constructor (a normal function) thereby trumps an instantiated\ntemplate with the same signature.\n182 \n| \nItem 26\nwww.it-ebooks.info\n",
      "content_length": 1786,
      "extraction_method": "Direct"
    },
    {
      "page_number": 201,
      "chapter": null,
      "content": "(If you’re wondering why compilers generate a copy constructor when they could\ninstantiate a templatized constructor to get the signature that the copy constructor\nwould have, review Item 17.)\nThe interaction among perfect-forwarding constructors and compiler-generated\ncopy and move operations develops even more wrinkles when inheritance enters the\npicture. In particular, the conventional implementations of derived class copy and\nmove operations behave quite surprisingly. Here, take a look:\nclass SpecialPerson: public Person {\npublic:\n  SpecialPerson(const SpecialPerson& rhs)  // copy ctor; calls\n  : Person(rhs)                            // base class\n  { … }                                    // forwarding ctor!\n  SpecialPerson(SpecialPerson&& rhs)       // move ctor; calls\n  : Person(std::move(rhs))                 // base class\n  { … }                                    // forwarding ctor!\n};\nAs the comments indicate, the derived class copy and move constructors don’t call\ntheir base class’s copy and move constructors, they call the base class’s perfect-\nforwarding constructor! To understand why, note that the derived class functions are\nusing arguments of type SpecialPerson to pass to their base class, then work\nthrough the template instantiation and overload-resolution consequences for the\nconstructors in class Person. Ultimately, the code won’t compile, because there’s no\nstd::string constructor taking a SpecialPerson.\nI hope that by now I’ve convinced you that overloading on universal reference\nparameters is something you should avoid if at all possible. But if overloading on uni‐\nversal references is a bad idea, what do you do if you need a function that forwards\nmost argument types, yet needs to treat some argument types in a special fashion?\nThat egg can be unscrambled in a number of ways. So many, in fact, that I’ve devoted\nan entire Item to them. It’s Item 27. The next Item. Keep reading, you’ll bump right\ninto it.\nThings to Remember\n• Overloading on universal references almost always leads to the universal refer‐\nence overload being called more frequently than expected.\n• Perfect-forwarding constructors are especially problematic, because they’re\ntypically better matches than copy constructors for non-const lvalues, and\nthey can hijack derived class calls to base class copy and move constructors.\nItem 26 \n| \n183\nwww.it-ebooks.info\n",
      "content_length": 2387,
      "extraction_method": "Direct"
    },
    {
      "page_number": 202,
      "chapter": null,
      "content": "Item 27: Familiarize yourself with alternatives to\noverloading on universal references.\nItem 26 explains that overloading on universal references can lead to a variety of\nproblems, both for freestanding and for member functions (especially constructors).\nYet it also gives examples where such overloading could be useful. If only it would\nbehave the way we’d like! This Item explores ways to achieve the desired behavior,\neither through designs that avoid overloading on universal references or by employ‐\ning them in ways that constrain the types of arguments they can match.\nThe discussion that follows builds on the examples introduced in Item 26. If you\nhaven’t read that Item recently, you’ll want to review it before continuing.\nAbandon overloading\nThe first example in Item 26, logAndAdd, is representative of the many functions that\ncan avoid the drawbacks of overloading on universal references by simply using dif‐\nferent names for the would-be overloads. The two logAndAdd overloads, for example,\ncould be broken into logAndAddName and logAndAddNameIdx. Alas, this approach\nwon’t work for the second example we considered, the Person constructor, because\nconstructor names are fixed by the language. Besides, who wants to give up overload‐\ning?\nPass by const T&\nAn alternative is to revert to C++98 and replace pass-by-universal-reference with\npass-by-lvalue-reference-to-const. In fact, that’s the first approach Item 26 considers\n(shown on page 175). The drawback is that the design isn’t as efficient as we’d prefer.\nKnowing what we now know about the interaction of universal references and over‐\nloading, giving up some efficiency to keep things simple might be a more attractive\ntrade-off than it initially appeared.\nPass by value\nAn approach that often allows you to dial up performance without any increase in\ncomplexity is to replace pass-by-reference parameters with, counterintuitively, pass\nby value. The design adheres to the advice in Item 41 to consider passing objects by\nvalue when you know you’ll copy them, so I’ll defer to that Item for a detailed discus‐\nsion of how things work and how efficient they are. Here, I’ll just show how the tech‐\nnique could be used in the Person example:\nclass Person {\npublic:\n  explicit Person(std::string n) // replaces T&& ctor; see\n184 \n| \nItem 27\nwww.it-ebooks.info\n",
      "content_length": 2334,
      "extraction_method": "Direct"
    },
    {
      "page_number": 203,
      "chapter": null,
      "content": "  : name(std::move(n)) {}        // Item 41 for use of std::move\n  \n  explicit Person(int idx)       // as before\n  : name(nameFromIdx(idx)) {}\n  …\nprivate:\n  std::string name;\n};\nBecause there’s no std::string constructor taking only an integer, all int and int-\nlike arguments to a Person constructor (e.g., std::size_t, short, long) get fun‐\nneled to the int overload. Similarly, all arguments of type std::string (and things\nfrom which std::strings can be created, e.g., literals such as \"Ruth\") get passed to\nthe constructor taking a std::string. There are thus no surprises for callers. You\ncould argue, I suppose, that some people might be surprised that using 0 or NULL to\nindicate a null pointer would invoke the int overload, but such people should be\nreferred to Item 8 and required to read it repeatedly until the thought of using 0 or\nNULL as a null pointer makes them recoil.\nUse Tag dispatch\nNeither pass by lvalue-reference-to-const nor pass by value offers support for perfect\nforwarding. If the motivation for the use of a universal reference is perfect forward‐\ning, we have to use a universal reference; there’s no other choice. Yet we don’t want\nto abandon overloading. So if we don’t give up overloading and we don’t give up uni‐\nversal references, how can we avoid overloading on universal references?\nIt’s actually not that hard. Calls to overloaded functions are resolved by looking at all\nthe parameters of all the overloads as well as all the arguments at the call site, then\nchoosing the function with the best overall match—taking into account all parame‐\nter/argument combinations. A universal reference parameter generally provides an\nexact match for whatever’s passed in, but if the universal reference is part of a param‐\neter list containing other parameters that are not universal references, sufficiently\npoor matches on the non-universal reference parameters can knock an overload with\na universal reference out of the running. That’s the basis behind the tag dispatch\napproach, and an example will make the foregoing description easier to understand.\nWe’ll apply tag dispatch to the logAndAdd example on page 177. Here’s the code for\nthat example, lest you get sidetracked looking it up:\nstd::multiset<std::string> names;      // global data structure\ntemplate<typename T>                   // make log entry and add\nItem 27 \n| \n185\nwww.it-ebooks.info\n",
      "content_length": 2390,
      "extraction_method": "Direct"
    },
    {
      "page_number": 204,
      "chapter": null,
      "content": "void logAndAdd(T&& name)               // name to data structure\n{\n  auto now = std::chrono::system_clock::now();\n  log(now, \"logAndAdd\");\n  names.emplace(std::forward<T>(name));\n}\nBy itself, this function works fine, but were we to introduce the overload taking an\nint that’s used to look up objects by index, we’d be back in the troubled land of\nItem 26. The goal of this Item is to avoid that. Rather than adding the overload, we’ll\nreimplement logAndAdd to delegate to two other functions, one for integral values\nand one for everything else. logAndAdd itself will accept all argument types, both\nintegral and non-integral.\nThe two functions doing the real work will be named logAndAddImpl, i.e., we’ll use\noverloading. One of the functions will take a universal reference. So we’ll have both\noverloading and universal references. But each function will also take a second\nparameter, one that indicates whether the argument being passed is integral. This\nsecond parameter is what will prevent us from tumbling into the morass described in\nItem 26, because we’ll arrange it so that the second parameter will be the factor that\ndetermines which overload is selected.\nYes, I know, “Blah, blah, blah. Stop talking and show me the code!” No problem.\nHere’s an almost-correct version of the updated logAndAdd:\ntemplate<typename T>\nvoid logAndAdd(T&& name)\n{\n  logAndAddImpl(std::forward<T>(name),\n                std::is_integral<T>());     // not quite correct\n}\nThis function forwards its parameter to logAndAddImpl, but it also passes an argu‐\nment indicating whether that parameter’s type (T) is integral. At least, that’s what it’s\nsupposed to do. For integral arguments that are rvalues, it’s also what it does. But, as\nItem 28 explains, if an lvalue argument is passed to the universal reference name, the\ntype deduced for T will be an lvalue reference. So if an lvalue of type int is passed to\nlogAndAdd, T will be deduced to be int&. That’s not an integral type, because refer‐\nences aren’t integral types. That means that std::is_integral<T> will be false for\nany lvalue argument, even if the argument really does represent an integral value.\nRecognizing the problem is tantamount to solving it, because the ever-handy Stan‐\ndard C++ Library has a type trait (see Item 9), std::remove_reference, that does\nboth what its name suggests and what we need: remove any reference qualifiers from\na type. The proper way to write logAndAdd is therefore:\n186 \n| \nItem 27\nwww.it-ebooks.info\n",
      "content_length": 2488,
      "extraction_method": "Direct"
    },
    {
      "page_number": 205,
      "chapter": null,
      "content": "template<typename T>\nvoid logAndAdd(T&& name)\n{\n  logAndAddImpl(\n    std::forward<T>(name),\n    std::is_integral<typename std::remove_reference<T>::type>()\n  );\n}\nThis does the trick. (In C++14, you can save a few keystrokes by using\nstd::remove_reference_t<T> in place of the highlighted text. For details, see\nItem 9.)\nWith that taken care of, we can shift our attention to the function being called,\nlogAndAddImpl. There are two overloads, and the first is applicable only to non-\nintegral types (i.e., to types where std::is_integral<typename std::remove_ref\nerence<T>::type> is false):\ntemplate<typename T>                             // non-integral\nvoid logAndAddImpl(T&& name, std::false_type)    // argument:\n{                                                // add it to\n  auto now = std::chrono::system_clock::now();   // global data\n  log(now, \"logAndAdd\");                         // structure\n  names.emplace(std::forward<T>(name));\n}\nThis is straightforward code, once you understand the mechanics behind the high‐\nlighted parameter. Conceptually, logAndAdd passes a boolean to logAndAddImpl\nindicating whether an integral type was passed to logAndAdd, but true and false\nare runtime values, and we need to use overload resolution—a compile-time phenom‐\nenon—to choose the correct logAndAddImpl overload. That means we need a type\nthat corresponds to true and a different type that corresponds to false. This need is\ncommon enough that the Standard Library provides what is required under the\nnames std::true_type and std::false_type. The argument passed to logAndAd\ndImpl by logAndAdd is an object of a type that inherits from std::true_type if T is\nintegral and from std::false_type if T is not integral. The net result is that this\nlogAndAddImpl overload is a viable candidate for the call in logAndAdd only if T is\nnot an integral type.\nThe second overload covers the opposite case: when T is an integral type. In that\nevent, logAndAddImpl simply finds the name corresponding to the passed-in index\nand passes that name back to logAndAdd:\nstd::string nameFromIdx(int idx);             // as in Item 26\nItem 27 \n| \n187\nwww.it-ebooks.info\n",
      "content_length": 2155,
      "extraction_method": "Direct"
    },
    {
      "page_number": 206,
      "chapter": null,
      "content": "void logAndAddImpl(int idx, std::true_type)   // integral\n{                                             // argument: look\n  logAndAdd(nameFromIdx(idx));                // up name and\n}                                             // call logAndAdd\n                                              // with it\nBy having logAndAddImpl for an index look up the corresponding name and pass it\nto logAndAdd (from where it will be std::forwarded to the other logAndAddImpl\noverload), we avoid the need to put the logging code in both logAndAddImpl over‐\nloads.\nIn this design, the types std::true_type and std::false_type are “tags” whose\nonly purpose is to force overload resolution to go the way we want. Notice that we\ndon’t even name those parameters. They serve no purpose at runtime, and in fact we\nhope that compilers will recognize that the tag parameters are unused and will opti‐\nmize them out of the program’s execution image. (Some compilers do, at least some\nof the time.) The call to the overloaded implementation functions inside logAndAdd\n“dispatches” the work to the correct overload by causing the proper tag object to be\ncreated. Hence the name for this design: tag dispatch. It’s a standard building block of\ntemplate metaprogramming, and the more you look at code inside contemporary\nC++ libraries, the more often you’ll encounter it.\nFor our purposes, what’s important about tag dispatch is less how it works and more\nhow it permits us to combine universal references and overloading without the prob‐\nlems described in Item 26. The dispatching function—logAndAdd—takes an uncon‐\nstrained universal reference parameter, but this function is not overloaded. The\nimplementation functions—logAndAddImpl—are overloaded, and one takes a uni‐\nversal reference parameter, but resolution of calls to these functions depends not just\non the universal reference parameter, but also on the tag parameter, and the tag val‐\nues are designed so that no more than one overload will be a viable match. As a\nresult, it’s the tag that determines which overload gets called. The fact that the univer‐\nsal reference parameter will always generate an exact match for its argument is imma‐\nterial.\nConstraining templates that take universal references\nA keystone of tag dispatch is the existence of a single (unoverloaded) function as the\nclient API. This single function dispatches the work to be done to the implementa‐\ntion functions. Creating an unoverloaded dispatch function is usually easy, but the\nsecond problem case Item 26 considers, that of a perfect-forwarding constructor for\nthe Person class (shown on page 178), is an exception. Compilers may generate copy\nand move constructors themselves, so even if you write only one constructor and use\ntag dispatch within it, some constructor calls may be handled by compiler-generated\nfunctions that bypass the tag dispatch system.\n188 \n| \nItem 27\nwww.it-ebooks.info\n",
      "content_length": 2912,
      "extraction_method": "Direct"
    },
    {
      "page_number": 207,
      "chapter": null,
      "content": "In truth, the real problem is not that the compiler-generated functions sometimes\nbypass the tag dispatch design, it’s that they don’t always pass it by. You virtually\nalways want the copy constructor for a class to handle requests to copy lvalues of that\ntype, but, as Item 26 demonstrates, providing a constructor taking a universal refer‐\nence causes the universal reference constructor (rather than the copy constructor) to\nbe called when copying non-const lvalues. That Item also explains that when a base\nclass declares a perfect-forwarding constructor, that constructor will typically be\ncalled when derived classes implement their copy and move constructors in the con‐\nventional fashion, even though the correct behavior is for the base class’s copy and\nmove constructors to be invoked.\nFor situations like these, where an overloaded function taking a universal reference is\ngreedier than you want, yet not greedy enough to act as a single dispatch function, tag\ndispatch is not the droid you’re looking for. You need a different technique, one that\nlets you rachet down the conditions under which the function template that the uni‐\nversal reference is part of is permitted to be employed. What you need, my friend, is\nstd::enable_if.\nstd::enable_if gives you a way to force compilers to behave as if a particular tem‐\nplate didn’t exist. Such templates are said to be disabled. By default, all templates are\nenabled, but a template using std::enable_if is enabled only if the condition speci‐\nfied by std::enable_if is satisfied. In our case, we’d like to enable the Person\nperfect-forwarding constructor only if the type being passed isn’t Person. If the type\nbeing passed is Person, we want to disable the perfect-forwarding constructor (i.e.,\ncause compilers to ignore it), because that will cause the class’s copy or move con‐\nstructor to handle the call, which is what we want when a Person object is initialized\nwith another Person.\nThe way to express that idea isn’t particularly difficult, but the syntax is off-putting,\nespecially if you’ve never seen it before, so I’ll ease you into it. There’s some boiler‐\nplate that goes around the condition part of std::enable_if, so we’ll start with that.\nHere’s the declaration for the perfect-forwarding constructor in Person, showing\nonly as much of the std::enable_if as is required simply to use it. I’m showing\nonly the declaration for this constructor, because the use of std::enable_if has no\neffect on the function’s implementation. The implementation remains the same as in\nItem 26.\nclass Person {\npublic:\n  template<typename T,\n           typename = typename std::enable_if<condition>::type>\n  explicit Person(T&& n);\n  …\nItem 27 \n| \n189\nwww.it-ebooks.info\n",
      "content_length": 2729,
      "extraction_method": "Direct"
    },
    {
      "page_number": 208,
      "chapter": null,
      "content": "};\nTo understand exactly what’s going on in the highlighted text, I must regretfully sug‐\ngest that you consult other sources, because the details take a while to explain, and\nthere’s just not enough space for it in this book. (During your research, look into\n“SFINAE” as well as std::enable_if, because SFINAE is the technology that makes\nstd::enable_if work.) Here, I want to focus on expression of the condition that\nwill control whether this constructor is enabled.\nThe condition we want to specify is that T isn’t Person, i.e., that the templatized con‐\nstructor should be enabled only if T is a type other than Person. Thanks to a type\ntrait that determines whether two types are the same (std::is_same), it would seem\nthat the condition we want is !std::is_same<Person, T>::value. (Notice the “!”\nat the beginning of the expression. We want for Person and T to not be the same.)\nThis is close to what we need, but it’s not quite correct, because, as Item 28 explains,\nthe type deduced for a universal reference initialized with an lvalue is always an\nlvalue reference. That means that for code like this,\nPerson p(\"Nancy\");\nauto cloneOfP(p);          // initialize from lvalue\nthe type T in the universal constructor will be deduced to be Person&. The types Per\nson and Person& are not the same, and the result of std::is_same will reflect that:\nstd::is_same<Person, Person&>::value is false.\nIf we think more precisely about what we mean when we say that the templatized\nconstructor in Person should be enabled only if T isn’t Person, we’ll realize that\nwhen we’re looking at T, we want to ignore\n• Whether it’s a reference. For the purpose of determining whether the universal\nreference constructor should be enabled, the types Person, Person&, and Per\nson&& are all the same as Person.\n• Whether it’s const or volatile. As far as we’re concerned, a const Person and\na volatile Person and a const volatile Person are all the same as a Person.\nThis means we need a way to strip any references, consts, and volatiles from T\nbefore checking to see if that type is the same as Person. Once again, the Standard\nLibrary gives us what we need in the form of a type trait. That trait is std::decay.\nstd::decay<T>::type is the same as T, except that references and cv-qualifiers (i.e.,\nconst or volatile qualifiers) are removed. (I’m fudging the truth here, because\nstd::decay, as its name suggests, also turns array and function types into pointers\n190 \n| \nItem 27\nwww.it-ebooks.info\n",
      "content_length": 2485,
      "extraction_method": "Direct"
    },
    {
      "page_number": 209,
      "chapter": null,
      "content": "(see Item 1), but for purposes of this discussion, std::decay behaves as I’ve\ndescribed.) The condition we want to control whether our constructor is enabled,\nthen, is\n!std::is_same<Person, typename std::decay<T>::type>::value\ni.e., Person is not the same type as T, ignoring any references or cv-qualifiers. (As\nItem 9 explains, the “typename” in front of std::decay is required, because the type\nstd::decay<T>::type depends on the template parameter T.)\nInserting this condition into the std::enable_if boilerplate above, plus formatting\nthe result to make it easier to see how the pieces fit together, yields this declaration\nfor Person’s perfect-forwarding constructor:\nclass Person {\npublic:\n  template<\n    typename T,\n    typename = typename std::enable_if<\n                 !std::is_same<Person,\n                               typename std::decay<T>::type\n                              >::value\n               >::type\n  >\n  explicit Person(T&& n);\n  …\n};\nIf you’ve never seen anything like this before, count your blessings. There’s a reason I\nsaved this design for last. When you can use one of the other mechanisms to avoid\nmixing universal references and overloading (and you almost always can), you\nshould. Still, once you get used to the functional syntax and the proliferation of angle\nbrackets, it’s not that bad. Furthermore, this gives you the behavior you’ve been striv‐\ning for. Given the declaration above, constructing a Person from another Person—\nlvalue or rvalue, const or non-const, volatile or non-volatile—will never\ninvoke the constructor taking a universal reference.\nSuccess, right? We’re done!\nUm, no. Belay that celebration. There’s still one loose end from Item 26 that contin‐\nues to flap about. We need to tie it down.\nSuppose a class derived from Person implements the copy and move operations in\nthe conventional manner:\nItem 27 \n| \n191\nwww.it-ebooks.info\n",
      "content_length": 1893,
      "extraction_method": "Direct"
    },
    {
      "page_number": 210,
      "chapter": null,
      "content": "class SpecialPerson: public Person {\npublic:\n  SpecialPerson(const SpecialPerson& rhs)  // copy ctor; calls\n  : Person(rhs)                            // base class\n  { … }                                    // forwarding ctor!\n  SpecialPerson(SpecialPerson&& rhs)       // move ctor; calls\n  : Person(std::move(rhs))                 // base class\n  { … }                                    // forwarding ctor!\n  …\n};\nThis is the same code I showed in Item 26 (on page 206), including the comments,\nwhich, alas, remain accurate. When we copy or move a SpecialPerson object, we\nexpect to copy or move its base class parts using the base class’s copy and move con‐\nstructors, but in these functions, we’re passing SpecialPerson objects to the base\nclass’s constructors, and because SpecialPerson isn’t the same as Person (not even\nafter application of std::decay), the universal reference constructor in the base class\nis enabled, and it happily instantiates to perform an exact match for a SpecialPer\nson argument. This exact match is better than the derived-to-base conversions that\nwould be necessary to bind the SpecialPerson objects to the Person parameters in\nPerson’s copy and move constructors, so with the code we have now, copying and\nmoving SpecialPerson objects would use the Person perfect-forwarding construc‐\ntor to copy or move their base class parts! It’s déjà Item 26 all over again.\nThe derived class is just following the normal rules for implementing derived class\ncopy and move constructors, so the fix for this problem is in the base class and, in\nparticular, in the condition that controls whether Person’s universal reference con‐\nstructor is enabled. We now realize that we don’t want to enable the templatized con‐\nstructor for any argument type other than Person, we want to enable it for any\nargument type other than Person or a type derived from Person. Pesky inheritance!\nYou should not be surprised to hear that among the standard type traits is one that\ndetermines whether one type is derived from another. It’s called std::is_base_of.\nstd::is_base_of<T1, T2>::value is true if T2 is derived from T1. Types are con‐\nsidered to be derived from themselves, so std::is_base_of<T, T>::value is true.\nThis is handy, because we want to revise our condition controlling Person’s perfect-\nforwarding constructor such that the constructor is enabled only if the type T, after\nstripping it of references and cv-qualifiers, is neither Person nor a class derived from\nPerson. Using std::is_base_of instead of std::is_same gives us what we need:\n192 \n| \nItem 27\nwww.it-ebooks.info\n",
      "content_length": 2599,
      "extraction_method": "Direct"
    },
    {
      "page_number": 211,
      "chapter": null,
      "content": "class Person {\npublic:\n  template<\n    typename T,\n    typename = typename std::enable_if<\n                 !std::is_base_of<Person,\n                                  typename std::decay<T>::type\n                                 >::value\n               >::type\n  >\n  explicit Person(T&& n);\n  …\n};\nNow we’re finally done. Provided we’re writing the code in C++11, that is. If we’re\nusing C++14, this code will still work, but we can employ alias templates for\nstd::enable_if and std::decay to get rid of the “typename” and “::type” cruft,\nthus yielding this somewhat more palatable code:\nclass Person {                                     // C++14\npublic:\n  template<\n    typename T,\n    typename = std::enable_if_t<               // less code here\n                 !std::is_base_of<Person,\n                                  std::decay_t<T>  // and here\n                                 >::value\n               >                                   // and here\n  >\n  explicit Person(T&& n);\n  …\n};\nOkay, I admit it: I lied. We’re still not done. But we’re close. Tantalizingly close.\nHonest.\nWe’ve seen how to use std::enable_if to selectively disable Person’s universal ref‐\nerence constructor for argument types we want to have handled by the class’s copy\nand move constructors, but we haven’t yet seen how to apply it to distinguish integral\nand non-integral arguments. That was, after all, our original goal; the constructor\nambiguity problem was just something we got dragged into along the way.\nItem 27 \n| \n193\nwww.it-ebooks.info\n",
      "content_length": 1534,
      "extraction_method": "Direct"
    },
    {
      "page_number": 212,
      "chapter": null,
      "content": "All we need to do—and I really do mean that this is everything—is (1) add a Person\nconstructor overload to handle integral arguments and (2) further constrain the\ntemplatized constructor so that it’s disabled for such arguments. Pour these ingredi‐\nents into the pot with everything else we’ve discussed, simmer over a low flame, and\nsavor the aroma of success:\nclass Person {\npublic:\n  template<\n    typename T,\n    typename = std::enable_if_t<\n      !std::is_base_of<Person, std::decay_t<T>>::value\n      &&\n      !std::is_integral<std::remove_reference_t<T>>::value\n    >\n  > \n  explicit Person(T&& n)        // ctor for std::strings and\n  : name(std::forward<T>(n))    // args convertible to\n  { … }                         // std::strings\n  explicit Person(int idx)      // ctor for integral args\n  : name(nameFromIdx(idx))\n  { … }\n  …                             // copy and move ctors, etc.\nprivate:\n  std::string name;\n};\nVoilà! A thing of beauty! Well, okay, the beauty is perhaps most pronounced for\nthose with something of a template metaprogramming fetish, but the fact remains\nthat this approach not only gets the job done, it does it with unique aplomb. Because\nit uses perfect forwarding, it offers maximal efficiency, and because it controls the\ncombination of universal references and overloading rather than forbidding it, this\ntechnique can be applied in circumstances (such as constructors) where overloading\nis unavoidable.\nTrade-offs\nThe first three techniques considered in this Item—abandoning overloading, passing\nby const T&, and passing by value—specify a type for each parameter in the func‐\ntion(s) to be called. The last two techniques—tag dispatch and constraining template\neligibility—use perfect forwarding, hence don’t specify types for the parameters. This\nfundamental decision—to specify a type or not—has consequences.\n194 \n| \nItem 27\nwww.it-ebooks.info\n",
      "content_length": 1891,
      "extraction_method": "Direct"
    },
    {
      "page_number": 213,
      "chapter": null,
      "content": "As a rule, perfect forwarding is more efficient, because it avoids the creation of tem‐\nporary objects solely for the purpose of conforming to the type of a parameter decla‐\nration. In the case of the Person constructor, perfect forwarding permits a string\nliteral such as \"Nancy\" to be forwarded to the constructor for the std::string\ninside Person, whereas techniques not using perfect forwarding must create a tem‐\nporary std::string object from the string literal to satisfy the parameter specifica‐\ntion for the Person constructor.\nBut perfect forwarding has drawbacks. One is that some kinds of arguments can’t be\nperfect-forwarded, even though they can be passed to functions taking specific types.\nItem 30 explores these perfect forwarding failure cases.\nA second issue is the comprehensibility of error messages when clients pass invalid\narguments. Suppose, for example, a client creating a Person object passes a string lit‐\neral made up of char16_ts (a type introduced in C++11 to represent 16-bit charac‐\nters) instead of chars (which is what a std::string consists of):\nPerson p(u\"Konrad Zuse\");   // \"Konrad Zuse\" consists of\n                            // characters of type const char16_t\nWith the first three approaches examined in this Item, compilers will see that the\navailable constructors take either int or std::string, and they’ll produce a more or\nless straightforward error message explaining that there’s no conversion from const\nchar16_t[12] to int or std::string.\nWith an approach based on perfect forwarding, however, the array of const\nchar16_ts gets bound to the constructor’s parameter without complaint. From there\nit’s forwarded to the constructor of Person’s std::string data member, and it’s\nonly at that point that the mismatch between what the caller passed in (a const\nchar16_t array) and what’s required (any type acceptable to the std::string con‐\nstructor) is discovered. The resulting error message is likely to be, er, impressive.\nWith one of the compilers I use, it’s more than 160 lines long.\nIn this example, the universal reference is forwarded only once (from the Person\nconstructor to the std::string constructor), but the more complex the system, the\nmore likely that a universal reference is forwarded through several layers of function\ncalls before finally arriving at a site that determines whether the argument type(s) are\nacceptable. The more times the universal reference is forwarded, the more baffling\nthe error message may be when something goes wrong. Many developers find that\nthis issue alone is grounds to reserve universal reference parameters for interfaces\nwhere performance is a foremost concern.\nIn the case of Person, we know that the forwarding function’s universal reference\nparameter is supposed to be an initializer for a std::string, so we can use a\nItem 27 \n| \n195\nwww.it-ebooks.info\n",
      "content_length": 2861,
      "extraction_method": "Direct"
    },
    {
      "page_number": 214,
      "chapter": null,
      "content": "static_assert to verify that it can play that role. The std::is_constructible\ntype trait performs a compile-time test to determine whether an object of one type\ncan be constructed from an object (or set of objects) of a different type (or set of\ntypes), so the assertion is easy to write:\nclass Person {\npublic:\n  template<                                 // as before\n    typename T,\n    typename = std::enable_if_t<\n      !std::is_base_of<Person, std::decay_t<T>>::value\n      &&\n      !std::is_integral<std::remove_reference_t<T>>::value\n    >\n  >\n  explicit Person(T&& n)\n  : name(std::forward<T>(n))\n  {\n    // assert that a std::string can be created from a T object\n    static_assert(\n      std::is_constructible<std::string, T>::value,\n      \"Parameter n can't be used to construct a std::string\"\n   );\n   …                    // the usual ctor work goes here\n  }\n  …                     // remainder of Person class (as before)\n};\nThis causes the specified error message to be produced if client code tries to create a\nPerson from a type that can’t be used to construct a std::string. Unfortunately, in\nthis example the static_assert is in the body of the constructor, but the forward‐\ning code, being part of the member initialization list, precedes it. With the compilers\nI use, the result is that the nice, readable message arising from the static_assert\nappears only after the usual error messages (up to 160-plus lines of them) have been\nemitted.\n \n196 \n| \nItem 27\nwww.it-ebooks.info\n",
      "content_length": 1498,
      "extraction_method": "Direct"
    },
    {
      "page_number": 215,
      "chapter": null,
      "content": "Things to Remember\n• Alternatives to the combination of universal references and overloading\ninclude the use of distinct function names, passing parameters by lvalue-\nreference-to-const, passing parameters by value, and using tag dispatch.\n• Constraining templates via std::enable_if permits the use of universal ref‐\nerences and overloading together, but it controls the conditions under which\ncompilers may use the universal reference overloads.\n• Universal reference parameters often have efficiency advantages, but they typ‐\nically have usability disadvantages.\nItem 28: Understand reference collapsing.\nItem 23 remarks that when an argument is passed to a template function, the type\ndeduced for the template parameter encodes whether the argument is an lvalue or an\nrvalue. The Item fails to mention that this happens only when the argument is used\nto initialize a parameter that’s a universal reference, but there’s a good reason for the\nomission: universal references aren’t introduced until Item 24. Together, these obser‐\nvations about universal references and lvalue/rvalue encoding mean that for this tem‐\nplate,\ntemplate<typename T>\nvoid func(T&& param);\nthe deduced template parameter T will encode whether the argument passed to param\nwas an lvalue or an rvalue.\nThe encoding mechanism is simple. When an lvalue is passed as an argument, T is\ndeduced to be an lvalue reference. When an rvalue is passed, T is deduced to be a\nnon-reference. (Note the asymmetry: lvalues are encoded as lvalue references, but\nrvalues are encoded as non-references.) Hence:\nWidget widgetFactory();     // function returning rvalue\nWidget w;                   // a variable (an lvalue)\nfunc(w);                    // call func with lvalue; T deduced\n                            // to be Widget&\nfunc(widgetFactory());      // call func with rvalue; T deduced\n                            // to be Widget\nItem 27 \n| \n197\nwww.it-ebooks.info\n",
      "content_length": 1932,
      "extraction_method": "Direct"
    },
    {
      "page_number": 216,
      "chapter": null,
      "content": "In both calls to func, a Widget is passed, yet because one Widget is an lvalue and one\nis an rvalue, different types are deduced for the template parameter T. This, as we\nshall soon see, is what determines whether universal references become rvalue refer‐\nences or lvalue references, and it’s also the underlying mechanism through which\nstd::forward does its work.\nBefore we can look more closely at std::forward and universal references, we must\nnote that references to references are illegal in C++. Should you try to declare one,\nyour compilers will reprimand you:\nint x;\n…\nauto& & rx = x;   // error! can't declare reference to reference\nBut consider what happens when an lvalue is passed to a function template taking a\nuniversal reference:\ntemplate<typename T>\nvoid func(T&& param);    // as before\nfunc(w);                 // invoke func with lvalue;\n                         // T deduced as Widget&\nIf we take the type deduced for T (i.e., Widget&) and use it to instantiate the template,\nwe get this:\nvoid func(Widget& && param);\nA reference to a reference! And yet compilers issue no protest. We know from\nItem 24 that because the universal reference param is being initialized with an lvalue,\nparam’s type is supposed to be an lvalue reference, but how does the compiler get\nfrom the result of taking the deduced type for T and substituting it into the template\nto the following, which is the ultimate function signature?\nvoid func(Widget& param);\nThe answer is reference collapsing. Yes, you are forbidden from declaring references\nto references, but compilers may produce them in particular contexts, template\ninstantiation being among them. When compilers generate references to references,\nreference collapsing dictates what happens next.\nThere are two kinds of references (lvalue and rvalue), so there are four possible\nreference-reference combinations (lvalue to lvalue, lvalue to rvalue, rvalue to lvalue,\nand rvalue to rvalue). If a reference to a reference arises in a context where this is per‐\nmitted (e.g., during template instantiation), the references collapse to a single refer‐\nence according to this rule:\n198 \n| \nItem 28\nwww.it-ebooks.info\n",
      "content_length": 2169,
      "extraction_method": "Direct"
    },
    {
      "page_number": 217,
      "chapter": null,
      "content": "If either reference is an lvalue reference, the result is an lvalue reference.\nOtherwise (i.e., if both are rvalue references) the result is an rvalue refer‐\nence.\nIn our example above, substitution of the deduced type Widget& into the template\nfunc yields an rvalue reference to an lvalue reference, and the reference-collapsing\nrule tells us that the result is an lvalue reference.\nReference collapsing is a key part of what makes std::forward work. As explained\nin Item 25, std::forward is applied to universal reference parameters, so a common\nuse case looks like this:\ntemplate<typename T>\nvoid f(T&& fParam)\n{\n  …                                    // do some work\n  someFunc(std::forward<T>(fParam));   // forward fParam to\n}                                      // someFunc\nBecause fParam is a universal reference, we know that the type parameter T will\nencode whether the argument passed to f (i.e., the expression used to initialize\nfParam) was an lvalue or an rvalue. std::forward’s job is to cast fParam (an lvalue)\nto an rvalue if and only if T encodes that the argument passed to f was an rvalue, i.e.,\nif T is a non-reference type.\nHere’s how std::forward can be implemented to do that:\ntemplate<typename T>                                // in\nT&& forward(typename                                // namespace\n              remove_reference<T>::type& param)     // std\n{\n  return static_cast<T&&>(param);\n}\nThis isn’t quite Standards-conformant (I’ve omitted a few interface details), but the\ndifferences are irrelevant for the purpose of understanding how std::forward\nbehaves.\nSuppose that the argument passed to f is an lvalue of type Widget. T will be deduced\nas Widget&, and the call to std::forward will instantiate as std::forward\n<Widget&>. Plugging Widget& into the std::forward implementation yields this:\nItem 28 \n| \n199\nwww.it-ebooks.info\n",
      "content_length": 1866,
      "extraction_method": "Direct"
    },
    {
      "page_number": 218,
      "chapter": null,
      "content": "Widget& && forward(typename\n                     remove_reference<Widget&>::type& param)\n{ return static_cast<Widget& &&>(param); }\nThe type trait std::remove_reference<Widget&>::type yields Widget (see\nItem 9), so std::forward becomes:\nWidget& && forward(Widget& param)\n{ return static_cast<Widget& &&>(param); }\nReference collapsing is also applied to the return type and the cast, and the result is\nthe final version of std::forward for the call:\nWidget& forward(Widget& param)                  // still in\n{ return static_cast<Widget&>(param);  }        // namespace std\nAs you can see, when an lvalue argument is passed to the function template f,\nstd::forward is instantiated to take and return an lvalue reference. The cast inside\nstd::forward does nothing, because param’s type is already Widget&, so casting it to\nWidget& has no effect. An lvalue argument passed to std::forward will thus return\nan lvalue reference. By definition, lvalue references are lvalues, so passing an lvalue to\nstd::forward causes an lvalue to be returned, just like it’s supposed to.\nNow suppose that the argument passed to f is an rvalue of type Widget. In this case,\nthe deduced type for f’s type parameter T will simply be Widget. The call inside f to\nstd::forward will thus be to std::forward<Widget>. Substituting Widget for T in\nthe std::forward implementation gives this:\nWidget&& forward(typename\n                   remove_reference<Widget>::type& param)\n{ return static_cast<Widget&&>(param); }\nApplying std::remove_reference to the non-reference type Widget yields the\nsame type it started with (Widget), so std::forward becomes this:\nWidget&& forward(Widget& param)\n{ return static_cast<Widget&&>(param); }\nThere are no references to references here, so there’s no reference collapsing, and this\nis the final instantiated version of std::forward for the call.\nRvalue references returned from functions are defined to be rvalues, so in this case,\nstd::forward will turn f’s parameter fParam (an lvalue) into an rvalue. The end\nresult is that an rvalue argument passed to f will be forwarded to someFunc as an\nrvalue, which is precisely what is supposed to happen.\n200 \n| \nItem 28\nwww.it-ebooks.info\n",
      "content_length": 2195,
      "extraction_method": "Direct"
    },
    {
      "page_number": 219,
      "chapter": null,
      "content": "In C++14, the existence of std::remove_reference_t makes it possible to imple‐\nment std::forward a bit more concisely:\ntemplate<typename T>                         // C++14; still in\nT&& forward(remove_reference_t<T>& param)    // namespace std\n{\n  return static_cast<T&&>(param);\n}\nReference collapsing occurs in four contexts. The first and most common is template\ninstantiation. The second is type generation for auto variables. The details are essen‐\ntially the same as for templates, because type deduction for auto variables is essen‐\ntially the same as type deduction for templates (see Item 2). Consider again this\nexample from earlier in the Item:\ntemplate<typename T>\nvoid func(T&& param);\nWidget widgetFactory();     // function returning rvalue\nWidget w;                   // a variable (an lvalue)\nfunc(w);                    // call func with lvalue; T deduced\n                            // to be Widget&\nfunc(widgetFactory());      // call func with rvalue; T deduced\n                            // to be Widget\nThis can be mimicked in auto form. The declaration\nauto&& w1 = w;\ninitializes w1 with an lvalue, thus deducing the type Widget& for auto. Plugging\nWidget& in for auto in the declaration for w1 yields this reference-to-reference code,\nWidget& && w1 = w;\nwhich, after reference collapsing, becomes\nWidget& w1 = w;\nAs a result, w1 is an lvalue reference.\nOn the other hand, this declaration,\nauto&& w2 = widgetFactory();\ninitializes w2 with an rvalue, causing the non-reference type Widget to be deduced for\nauto. Substituting Widget for auto gives us this:\nItem 28 \n| \n201\nwww.it-ebooks.info\n",
      "content_length": 1618,
      "extraction_method": "Direct"
    },
    {
      "page_number": 220,
      "chapter": null,
      "content": "Widget&& w2 = widgetFactory();\nThere are no references to references here, so we’re done; w2 is an rvalue reference.\nWe’re now in a position to truly understand the universal references introduced in\nItem 24. A universal reference isn’t a new kind of reference, it’s actually an rvalue ref‐\nerence in a context where two conditions are satisfied:\n• Type deduction distinguishes lvalues from rvalues. Lvalues of type T are\ndeduced to have type T&, while rvalues of type T yield T as their deduced type.\n• Reference collapsing occurs.\nThe concept of universal references is useful, because it frees you from having to rec‐\nognize the existence of reference collapsing contexts, to mentally deduce different\ntypes for lvalues and rvalues, and to apply the reference collapsing rule after mentally\nsubstituting the deduced types into the contexts in which they occur.\nI said there were four such contexts, but we’ve discussed only two: template instantia‐\ntion and auto type generation. The third is the generation and use of typedefs and\nalias declarations (see Item 9). If, during creation or evaluation of a typedef, refer‐\nences to references arise, reference collapsing intervenes to eliminate them. For\nexample, suppose we have a Widget class template with an embedded typedef for an\nrvalue reference type,\ntemplate<typename T>\nclass Widget {\npublic:\n  typedef T&& RvalueRefToT;\n  …\n};\nand suppose we instantiate Widget with an lvalue reference type:\nWidget<int&> w;\nSubstituting int& for T in the Widget template gives us the following typedef:\ntypedef int& && RvalueRefToT;\nReference collapsing reduces it to this,\ntypedef int& RvalueRefToT;\nwhich makes clear that the name we chose for the typedef is perhaps not as descrip‐\ntive as we’d hoped: RvalueRefToT is a typedef for an lvalue reference when Widget\nis instantiated with an lvalue reference type.\n202 \n| \nItem 28\nwww.it-ebooks.info\n",
      "content_length": 1894,
      "extraction_method": "Direct"
    },
    {
      "page_number": 221,
      "chapter": null,
      "content": "The final context in which reference collapsing takes place is uses of decltype. If,\nduring analysis of a type involving decltype, a reference to a reference arises, refer‐\nence collapsing will kick in to eliminate it. (For information about decltype, see\nItem 3.)\nThings to Remember\n• Reference collapsing occurs in four contexts: template instantiation, auto type\ngeneration, creation and use of typedefs and alias declarations, and\ndecltype.\n• When compilers generate a reference to a reference in a reference collapsing\ncontext, the result becomes a single reference. If either of the original refer‐\nences is an lvalue reference, the result is an lvalue reference. Otherwise it’s an\nrvalue reference.\n• Universal references are rvalue references in contexts where type deduction\ndistinguishes lvalues from rvalues and where reference collapsing occurs.\nItem 29: Assume that move operations are not present,\nnot cheap, and not used.\nMove semantics is arguably the premier feature of C++11. “Moving containers is now\nas cheap as copying pointers!” you’re likely to hear, and “Copying temporary objects\nis now so efficient, coding to avoid it is tantamount to premature optimization!” Such\nsentiments are easy to understand. Move semantics is truly an important feature. It\ndoesn’t just allow compilers to replace expensive copy operations with comparatively\ncheap moves, it actually requires that they do so (when the proper conditions are ful‐\nfilled). Take your C++98 code base, recompile with a C++11-conformant compiler\nand Standard Library, and—shazam!—your software runs faster.\nMove semantics can really pull that off, and that grants the feature an aura worthy of\nlegend. Legends, however, are generally the result of exaggeration. The purpose of\nthis Item is to keep your expectations grounded.\nLet’s begin with the observation that many types fail to support move semantics. The\nentire C++98 Standard Library was overhauled for C++11 to add move operations\nfor types where moving could be implemented faster than copying, and the imple‐\nmentation of the library components was revised to take advantage of these opera‐\ntions, but chances are that you’re working with a code base that has not been\ncompletely revised to take advantage of C++11. For types in your applications (or in\nthe libraries you use) where no modifications for C++11 have been made, the exis‐\nItem 28 \n| \n203\nwww.it-ebooks.info\n",
      "content_length": 2412,
      "extraction_method": "Direct"
    },
    {
      "page_number": 222,
      "chapter": null,
      "content": "std::vector<Widget> vw1;\n// put data into vw1\n…\n// move vw1 into vw2. Runs in\n// constant time. Only ptrs\n// in vw1 and vw2 are modified\nauto vw2 = std::move(vw1);\nvw1\nvw1\nnull\nvw2\nWidgets\nWidgets\ntence of move support in your compilers is likely to do you little good. True, C++11\nis willing to generate move operations for classes that lack them, but that happens\nonly for classes declaring no copy operations, move operations, or destructors (see\nItem 17). Data members or base classes of types that have disabled moving (e.g., by\ndeleting the move operations—see Item 11) will also suppress compiler-generated\nmove operations. For types without explicit support for moving and that don’t qual‐\nify for compiler-generated move operations, there is no reason to expect C++11 to\ndeliver any kind of performance improvement over C++98.\nEven types with explicit move support may not benefit as much as you’d hope. All\ncontainers in the standard C++11 library support moving, for example, but it would\nbe a mistake to assume that moving all containers is cheap. For some containers, this\nis because there’s no truly cheap way to move their contents. For others, it’s because\nthe truly cheap move operations the containers offer come with caveats the container\nelements can’t satisfy.\nConsider std::array, a new container in C++11. std::array is essentially a built-\nin array with an STL interface. This is fundamentally different from the other stan‐\ndard containers, each of which stores its contents on the heap. Objects of such\ncontainer types hold (as data members), conceptually, only a pointer to the heap\nmemory storing the contents of the container. (The reality is more complex, but for\npurposes of this analysis, the differences are not important.) The existence of this\npointer makes it possible to move the contents of an entire container in constant\ntime: just copy the pointer to the container’s contents from the source container to\nthe target, and set the source’s pointer to null:\nstd::array objects lack such a pointer, because the data for a std::array’s con‐\ntents are stored directly in the std::array object:\n204 \n| \nItem 29\nwww.it-ebooks.info\n",
      "content_length": 2164,
      "extraction_method": "Direct"
    },
    {
      "page_number": 223,
      "chapter": null,
      "content": "std::array<Widget, 10000> aw1;\n// put data into aw1\n…\n// move aw1 into aw2. Runs in\n// linear time. All elements in\n// aw1 are moved into aw2\nauto aw2 = std::move(aw1);\naw1\nWidgets\naw1\nWidgets (moved from)\naw2\nWidgets (moved to)\nNote that the elements in aw1 are moved into aw2. Assuming that Widget is a type\nwhere moving is faster than copying, moving a std::array of Widget will be faster\nthan copying the same std::array. So std::array certainly offers move support.\nYet both moving and copying a std::array have linear-time computational com‐\nplexity, because each element in the container must be copied or moved. This is far\nfrom the “moving a container is now as cheap as assigning a couple of pointers”\nclaim that one sometimes hears.\nOn the other hand, std::string offers constant-time moves and linear-time copies.\nThat makes it sound like moving is faster than copying, but that may not be the case.\nMany string implementations employ the small string optimization (SSO). With the\nSSO, “small” strings (e.g., those with a capacity of no more than 15 characters) are\nstored in a buffer within the std::string object; no heap-allocated storage is used.\nMoving small strings using an SSO-based implementation is no faster than copying\nthem, because the copy-only-a-pointer trick that generally underlies the performance\nadvantage of moves over copies isn’t applicable.\nThe motivation for the SSO is extensive evidence that short strings are the norm for\nmany applications. Using an internal buffer to store the contents of such strings elim‐\ninates the need to dynamically allocate memory for them, and that’s typically an effi‐\nciency win. An implication of the win, however, is that moves are no faster than\ncopies, though one could just as well take a glass-half-full approach and say that for\nsuch strings, copying is no slower than moving.\nEven for types supporting speedy move operations, some seemingly sure-fire move\nsituations can end up making copies. Item 14 explains that some container opera‐\ntions in the Standard Library offer the strong exception safety guarantee and that to\nensure that legacy C++98 code dependent on that guarantee isn’t broken when\nupgrading to C++11, the underlying copy operations may be replaced with move\noperations only if the move operations are known to not throw. A consequence is\nthat even if a type offers move operations that are more efficient than the corre‐\nItem 29 \n| \n205\nwww.it-ebooks.info\n",
      "content_length": 2452,
      "extraction_method": "Direct"
    },
    {
      "page_number": 224,
      "chapter": null,
      "content": "sponding copy operations, and even if, at a particular point in the code, a move oper‐\nation would generally be appropriate (e.g., if the source object is an rvalue), compilers\nmight still be forced to invoke a copy operation because the corresponding move\noperation isn’t declared noexcept.\nThere are thus several scenarios in which C++11’s move semantics do you no good:\n• No move operations: The object to be moved from fails to offer move opera‐\ntions. The move request therefore becomes a copy request.\n• Move not faster: The object to be moved from has move operations that are no\nfaster than its copy operations.\n• Move not usable: The context in which the moving would take place requires a\nmove operation that emits no exceptions, but that operation isn’t declared noex\ncept.\nIt’s worth mentioning, too, another scenario where move semantics offers no effi‐\nciency gain:\n• Source object is lvalue: With very few exceptions (see e.g., Item 25) only rvalues\nmay be used as the source of a move operation.\nBut the title of this Item is to assume that move operations are not present, not cheap,\nand not used. This is typically the case in generic code, e.g., when writing templates,\nbecause you don’t know all the types you’re working with. In such circumstances, you\nmust be as conservative about copying objects as you were in C++98—before move\nsemantics existed. This is also the case for “unstable” code, i.e., code where the char‐\nacteristics of the types being used are subject to relatively frequent modification.\nOften, however, you know the types your code uses, and you can rely on their charac‐\nteristics not changing (e.g., whether they support inexpensive move operations).\nWhen that’s the case, you don’t need to make assumptions. You can simply look up\nthe move support details for the types you’re using. If those types offer cheap move\noperations, and if you’re using objects in contexts where those move operations will\nbe invoked, you can safely rely on move semantics to replace copy operations with\ntheir less expensive move counterparts.\nThings to Remember\n• Assume that move operations are not present, not cheap, and not used.\n• In code with known types or support for move semantics, there is no need for\nassumptions.\n206 \n| \nItem 29\nwww.it-ebooks.info\n",
      "content_length": 2284,
      "extraction_method": "Direct"
    },
    {
      "page_number": 225,
      "chapter": null,
      "content": "Item 30: Familiarize yourself with perfect forwarding\nfailure cases.\nOne of the features most prominently emblazoned on the C++11 box is perfect for‐\nwarding. Perfect forwarding. It’s perfect! Alas, tear the box open, and you’ll find that\nthere’s “perfect” (the ideal), and then there’s “perfect” (the reality). C++11’s perfect\nforwarding is very good, but it achieves true perfection only if you’re willing to over‐\nlook an epsilon or two. This Item is devoted to familiarizing you with the epsilons.\nBefore embarking on our epsilon exploration, it’s worthwhile to review what’s meant\nby “perfect forwarding.” “Forwarding” just means that one function passes—forwards\n—its parameters to another function. The goal is for the second function (the one\nbeing forwarded to) to receive the same objects that the first function (the one doing\nthe forwarding) received. That rules out by-value parameters, because they’re copies\nof what the original caller passed in. We want the forwarded-to function to be able to\nwork with the originally-passed-in objects. Pointer parameters are also ruled out,\nbecause we don’t want to force callers to pass pointers. When it comes to general-\npurpose forwarding, we’ll be dealing with parameters that are references.\nPerfect forwarding means we don’t just forward objects, we also forward their salient\ncharacteristics: their types, whether they’re lvalues or rvalues, and whether they’re\nconst or volatile. In conjunction with the observation that we’ll be dealing with\nreference parameters, this implies that we’ll be using universal references (see\nItem 24), because only universal reference parameters encode information about the\nlvalueness and rvalueness of the arguments that are passed to them.\nLet’s assume we have some function f, and we’d like to write a function (in truth, a\nfunction template) that forwards to it. The core of what we need looks like this:\ntemplate<typename T>\nvoid fwd(T&& param)                  // accept any argument\n{\n  f(std::forward<T>(param));         // forward it to f\n}\nForwarding functions are, by their nature, generic. The fwd template, for example,\naccepts any type of argument, and it forwards whatever it gets. A logical extension of\nthis genericity is for forwarding functions to be not just templates, but variadic tem‐\nplates, thus accepting any number of arguments. The variadic form for fwd looks like\nthis:\ntemplate<typename... Ts>\nvoid fwd(Ts&&... params)             // accept any arguments\n{\nItem 30 \n| \n207\nwww.it-ebooks.info\n",
      "content_length": 2516,
      "extraction_method": "Direct"
    },
    {
      "page_number": 226,
      "chapter": null,
      "content": "  f(std::forward<Ts>(params)...);    // forward them to f\n}\nThis is the form you’ll see in, among other places, the standard containers’ emplace‐\nment functions (see Item 42) and the smart pointer factory functions,\nstd::make_shared and std::make_unique (see Item 21).\nGiven our target function f and our forwarding function fwd, perfect forwarding fails\nif calling f with a particular argument does one thing, but calling fwd with the same\nargument does something different:\nf( expression );      // if this does one thing,\nfwd( expression );    // but this does something else, fwd fails\n                      // to perfectly forward expression to f\nSeveral kinds of arguments lead to this kind of failure. Knowing what they are and\nhow to work around them is important, so let’s tour the kinds of arguments that can’t\nbe perfect-forwarded.\nBraced initializers\nSuppose f is declared like this:\nvoid f(const std::vector<int>& v);\nIn that case, calling f with a braced initializer compiles,\nf({ 1, 2, 3 });       // fine, \"{1, 2, 3}\" implicitly\n                      // converted to std::vector<int>\nbut passing the same braced initializer to fwd doesn’t compile:\nfwd({ 1, 2, 3 });     // error! doesn't compile\nThat’s because the use of a braced initializer is a perfect forwarding failure case.\nAll such failure cases have the same cause. In a direct call to f (such as f({ 1, 2,\n3 })), compilers see the arguments passed at the call site, and they see the types of the\nparameters declared by f. They compare the arguments at the call site to the parame‐\nter declarations to see if they’re compatible, and, if necessary, they perform implicit\nconversions to make the call succeed. In the example above, they generate a tempo‐\nrary std::vector<int> object from { 1, 2, 3 } so that f’s parameter v has a\nstd::vector<int> object to bind to.\nWhen calling f indirectly through the forwarding function template fwd, compilers\nno longer compare the arguments passed at fwd’s call site to the parameter declara‐\ntions in f. Instead, they deduce the types of the arguments being passed to fwd, and\n208 \n| \nItem 30\nwww.it-ebooks.info\n",
      "content_length": 2126,
      "extraction_method": "Direct"
    },
    {
      "page_number": 227,
      "chapter": null,
      "content": "they compare the deduced types to f’s parameter declarations. Perfect forwarding\nfails when either of the following occurs:\n• Compilers are unable to deduce a type for one or more of fwd’s parameters. In\nthis case, the code fails to compile.\n• Compilers deduce the “wrong” type for one or more of fwd’s parameters. Here,\n“wrong” could mean that fwd’s instantiation won’t compile with the types that\nwere deduced, but it could also mean that the call to f using fwd’s deduced types\nbehaves differently from a direct call to f with the arguments that were passed to\nfwd. One source of such divergent behavior would be if f were an overloaded\nfunction name, and, due to “incorrect” type deduction, the overload of f called\ninside fwd were different from the overload that would be invoked if f were\ncalled directly.\nIn the “fwd({ 1, 2, 3 })” call above, the problem is that passing a braced initializer\nto a function template parameter that’s not declared to be a std::initial\nizer_list is decreed to be, as the Standard puts it, a “non-deduced context.” In\nplain English, that means that compilers are forbidden from deducing a type for the\nexpression { 1, 2, 3 } in the call to fwd, because fwd’s parameter isn’t declared to be\na std::initializer_list. Being prevented from deducing a type for fwd’s parame‐\nter, compilers must understandably reject the call.\nInterestingly, Item 2 explains that type deduction succeeds for auto variables initial‐\nized with a braced initializer. Such variables are deemed to be std::initial\nizer_list objects, and this affords a simple workaround for cases where the type the\nforwarding function should deduce is a std::initializer_list—declare a local\nvariable using auto, then pass the local variable to the forwarding function:\nauto il = { 1, 2, 3 };     // il's type deduced to be\n                           // std::initializer_list<int>\nfwd(il);                   // fine, perfect-forwards il to f\n0 or NULL as null pointers\nItem 8 explains that when you try to pass 0 or NULL as a null pointer to a template,\ntype deduction goes awry, deducing an integral type (typically int) instead of a\npointer type for the argument you pass. The result is that neither 0 nor NULL can be\nperfect-forwarded as a null pointer. The fix is easy, however: pass nullptr instead of\n0 or NULL. For details, consult Item 8.\nItem 30 \n| \n209\nwww.it-ebooks.info\n",
      "content_length": 2376,
      "extraction_method": "Direct"
    },
    {
      "page_number": 228,
      "chapter": null,
      "content": "Declaration-only integral static const data members\nAs a general rule, there’s no need to define integral static const data members in\nclasses; declarations alone suffice. That’s because compilers perform const propaga‐\ntion on such members’ values, thus eliminating the need to set aside memory for\nthem. For example, consider this code:\nclass Widget {\npublic:\n  static const std::size_t MinVals = 28; // MinVals' declaration\n  …\n};\n…                                        // no defn. for MinVals\nstd::vector<int> widgetData;\nwidgetData.reserve(Widget::MinVals);     // use of MinVals\nHere, we’re using Widget::MinVals (henceforth simply MinVals) to specify widget\nData’s initial capacity, even though MinVals lacks a definition. Compilers work\naround the missing definition (as they are required to do) by plopping the value 28\ninto all places where MinVals is mentioned. The fact that no storage has been set\naside for MinVals’ value is unproblematic. If MinVals’ address were to be taken (e.g.,\nif somebody created a pointer to MinVals), then MinVals would require storage (so\nthat the pointer had something to point to), and the code above, though it would\ncompile, would fail at link-time until a definition for MinVals was provided.\nWith that in mind, imagine that f (the function fwd forwards its argument to) is\ndeclared like this:\nvoid f(std::size_t val);\nCalling f with MinVals is fine, because compilers will just replace MinVals with its\nvalue:\nf(Widget::MinVals);         // fine, treated as \"f(28)\"\nAlas, things may not go so smoothly if we try to call f through fwd:\nfwd(Widget::MinVals);       // error! shouldn't link\nThis code will compile, but it shouldn’t link. If that reminds you of what happens if\nwe write code that takes MinVals’ address, that’s good, because the underlying prob‐\nlem is the same.\nAlthough nothing in the source code takes MinVals’ address, fwd’s parameter is a\nuniversal reference, and references, in the code generated by compilers, are usually\ntreated like pointers. In the program’s underlying binary code (and on the hardware),\n210 \n| \nItem 30\nwww.it-ebooks.info\n",
      "content_length": 2112,
      "extraction_method": "Direct"
    },
    {
      "page_number": 229,
      "chapter": null,
      "content": "pointers and references are essentially the same thing. At this level, there’s truth to\nthe adage that references are simply pointers that are automatically dereferenced.\nThat being the case, passing MinVals by reference is effectively the same as passing it\nby pointer, and as such, there has to be some memory for the pointer to point to.\nPassing integral static const data members by reference, then, generally requires\nthat they be defined, and that requirement can cause code using perfect forwarding to\nfail where the equivalent code without perfect forwarding succeeds.\nBut perhaps you noticed the weasel words I sprinkled through the preceding discus‐\nsion. The code “shouldn’t” link. References are “usually” treated like pointers. Passing\nintegral static const data members by reference “generally” requires that they be\ndefined. It’s almost like I know something I don’t really want to tell you…\nThat’s because I do. According to the Standard, passing MinVals by reference\nrequires that it be defined. But not all implementations enforce this requirement. So,\ndepending on your compilers and linkers, you may find that you can perfect-forward\nintegral static const data members that haven’t been defined. If you do, congratu‐\nlations, but there is no reason to expect such code to port. To make it portable, sim‐\nply provide a definition for the integral static const data member in question. For\nMinVals, that’d look like this:\nconst std::size_t Widget::MinVals;     // in Widget's .cpp file\nNote that the definition doesn’t repeat the initializer (28, in the case of MinVals).\nDon’t stress over this detail, however. If you forget and provide the initializer in both\nplaces, your compilers will complain, thus reminding you to specify it only once.\nOverloaded function names and template names\nSuppose our function f (the one we keep wanting to forward arguments to via fwd)\ncan have its behavior customized by passing it a function that does some of its work.\nAssuming this function takes and returns ints, f could be declared like this:\nvoid f(int (*pf)(int));         // pf = \"processing function\"\nIt’s worth noting that f could also be declared using a simpler non-pointer syntax.\nSuch a declaration would look like this, though it’d have the same meaning as the\ndeclaration above:\nvoid f(int pf(int));            // declares same f as above\nEither way, now suppose we have an overloaded function, processVal:\nint processVal(int value);\nint processVal(int value, int priority);\nWe can pass processVal to f,\nItem 30 \n| \n211\nwww.it-ebooks.info\n",
      "content_length": 2559,
      "extraction_method": "Direct"
    },
    {
      "page_number": 230,
      "chapter": null,
      "content": "f(processVal);                  // fine\nbut it’s something of a surprise that we can. f demands a pointer to a function as its\nargument, but processVal isn’t a function pointer or even a function, it’s the name\nof two different functions. However, compilers know which processVal they need:\nthe one matching f’s parameter type. They thus choose the processVal taking one\nint, and they pass that function’s address to f.\nWhat makes this work is that f’s declaration lets compilers figure out which version\nof processVal is required. fwd, however, being a function template, doesn’t have any\ninformation about what type it needs, and that makes it impossible for compilers to\ndetermine which overload should be passed:\nfwd(processVal);            // error! which processVal?\nprocessVal alone has no type. Without a type, there can be no type deduction, and\nwithout type deduction, we’re left with another perfect forwarding failure case.\nThe same problem arises if we try to use a function template instead of (or in addi‐\ntion to) an overloaded function name. A function template doesn’t represent one\nfunction, it represents many functions:\ntemplate<typename T>\nT workOnVal(T param)        // template for processing values\n{ … }\nfwd(workOnVal);             // error! which workOnVal\n                            // instantiation?\nThe way to get a perfect-forwarding function like fwd to accept an overloaded func‐\ntion name or a template name is to manually specify the overload or instantiation\nyou want to have forwarded. For example, you can create a function pointer of the\nsame type as f’s parameter, initialize that pointer with processVal or workOnVal\n(thus causing the proper version of processVal to be selected or the proper instan‐\ntiation of workOnVal to be generated), and pass the pointer to fwd:\nusing ProcessFuncType =                        // make typedef;\n  int (*)(int);                                // see Item 9\nProcessFuncType processValPtr = processVal;    // specify needed\n                                               // signature for\n                                               // processVal\nfwd(processValPtr);                            // fine\nfwd(static_cast<ProcessFuncType>(workOnVal));  // also fine\n212 \n| \nItem 30\nwww.it-ebooks.info\n",
      "content_length": 2276,
      "extraction_method": "Direct"
    },
    {
      "page_number": 231,
      "chapter": null,
      "content": "3 This assumes that bitfields are laid out lsb (least significant bit) to msb (most significant bit). C++ doesn’t\nguarantee that, but compilers often provide a mechanism that allows programmers to control bitfield layout.\nOf course, this requires that you know the type of function pointer that fwd is for‐\nwarding to. It’s not unreasonable to assume that a perfect-forwarding function will\ndocument that. After all, perfect-forwarding functions are designed to accept any‐\nthing, so if there’s no documentation telling you what to pass, how would you know?\nBitfields\nThe final failure case for perfect forwarding is when a bitfield is used as a function\nargument. To see what this means in practice, observe that an IPv4 header can be\nmodeled as follows:3\nstruct IPv4Header {\n  std::uint32_t version:4,\n                IHL:4,\n                DSCP:6,\n                ECN:2,\n                totalLength:16;\n  …\n};\nIf our long-suffering function f (the perennial target of our forwarding function fwd)\nis declared to take a std::size_t parameter, calling it with, say, the totalLength\nfield of an IPv4Header object compiles without fuss:\nvoid f(std::size_t sz);        // function to call\nIPv4Header h;\n…\nf(h.totalLength);              // fine\nTrying to forward h.totalLength to f via fwd, however, is a different story:\nfwd(h.totalLength);            // error!\nThe problem is that fwd’s parameter is a reference, and h.totalLength is a non-\nconst bitfield. That may not sound so bad, but the C++ Standard condemns the\ncombination in unusually clear prose: “A non-const reference shall not be bound to\na bit-field.” There’s an excellent reason for the prohibition. Bitfields may consist of\narbitrary parts of machine words (e.g., bits 3-5 of a 32-bit int), but there’s no way to\ndirectly address such things. I mentioned earlier that references and pointers are the\nsame thing at the hardware level, and just as there’s no way to create a pointer to\nItem 30 \n| \n213\nwww.it-ebooks.info\n",
      "content_length": 1983,
      "extraction_method": "Direct"
    },
    {
      "page_number": 232,
      "chapter": null,
      "content": "arbitrary bits (C++ dictates that the smallest thing you can point to is a char), there’s\nno way to bind a reference to arbitrary bits, either.\nWorking around the impossibility of perfect-forwarding a bitfield is easy, once you\nrealize that any function that accepts a bitfield as an argument will receive a copy of\nthe bitfield’s value. After all, no function can bind a reference to a bitfield, nor can\nany function accept pointers to bitfields, because pointers to bitfields don’t exist. The\nonly kinds of parameters to which a bitfield can be passed are by-value parameters\nand, interestingly, references-to-const. In the case of by-value parameters, the called\nfunction obviously receives a copy of the value in the bitfield, and it turns out that in\nthe case of a reference-to-const parameter, the Standard requires that the reference\nactually bind to a copy of the bitfield’s value that’s stored in an object of some stan‐\ndard integral type (e.g., int). References-to-const don’t bind to bitfields, they bind\nto “normal” objects into which the values of the bitfields have been copied.\nThe key to passing a bitfield into a perfect-forwarding function, then, is to take\nadvantage of the fact that the forwarded-to function will always receive a copy of the\nbitfield’s value. You can thus make a copy yourself and call the forwarding function\nwith the copy. In the case of our example with IPv4Header, this code would do the\ntrick:\n// copy bitfield value; see Item 6 for info on init. form\nauto length = static_cast<std::uint16_t>(h.totalLength);\nfwd(length);                        // forward the copy\nUpshot\nIn most cases, perfect forwarding works exactly as advertised. You rarely have to\nthink about it. But when it doesn’t work—when reasonable-looking code fails to\ncompile or, worse, compiles, but doesn’t behave the way you anticipate—it’s impor‐\ntant to know about perfect forwarding’s imperfections. Equally important is knowing\nhow to work around them. In most cases, this is straightforward. \nThings to Remember\n• Perfect forwarding fails when template type deduction fails or when it deduces\nthe wrong type.\n• The kinds of arguments that lead to perfect forwarding failure are braced ini‐\ntializers, null pointers expressed as 0 or NULL, declaration-only integral const\nstatic data members, template and overloaded function names, and bitfields.\n214 \n| \nItem 30\nwww.it-ebooks.info\n",
      "content_length": 2399,
      "extraction_method": "Direct"
    },
    {
      "page_number": 233,
      "chapter": null,
      "content": "CHAPTER 6\nLambda Expressions\nLambda expressions—lambdas—are a game changer in C++ programming. That’s\nsomewhat surprising, because they bring no new expressive power to the language.\nEverything a lambda can do is something you can do by hand with a bit more typing.\nBut lambdas are such a convenient way to create function objects, the impact on day-\nto-day C++ software development is enormous. Without lambdas, the STL “_if”\nalgorithms (e.g., std::find_if, std::remove_if, std::count_if, etc.) tend to be\nemployed with only the most trivial predicates, but when lambdas are available, use\nof these algorithms with nontrivial conditions blossoms. The same is true of algo‐\nrithms that can be customized with comparison functions (e.g., std::sort,\nstd::nth_element, std::lower_bound, etc.). Outside the STL, lambdas make it\npossible \nto \nquickly \ncreate \ncustom \ndeleters \nfor \nstd::unique_ptr \nand\nstd::shared_ptr (see Items 18 and 19), and they make the specification of predi‐\ncates for condition variables in the threading API equally straightforward (see\nItem 39). Beyond the Standard Library, lambdas facilitate the on-the-fly specification\nof callback functions, interface adaption functions, and context-specific functions for\none-off calls. Lambdas really make C++ a more pleasant programming language.\nThe vocabulary associated with lambdas can be confusing. Here’s a brief refresher:\n• A lambda expression is just that: an expression. It’s part of the source code. In\nstd::find_if(container.begin(), container.end(),\n             [](int val) { return 0 < val && val < 10; });\nthe highlighted expression is the lambda.\n• A closure is the runtime object created by a lambda. Depending on the capture\nmode, closures hold copies of or references to the captured data. In the call to\n215\nwww.it-ebooks.info\n",
      "content_length": 1813,
      "extraction_method": "Direct"
    },
    {
      "page_number": 234,
      "chapter": null,
      "content": "std::find_if above, the closure is the object that’s passed at runtime as the\nthird argument to std::find_if.\n• A closure class is a class from which a closure is instantiated. Each lambda causes\ncompilers to generate a unique closure class. The statements inside a lambda\nbecome executable instructions in the member functions of its closure class.\nA lambda is often used to create a closure that’s used only as an argument to a func‐\ntion. That’s the case in the call to std::find_if above. However, closures may gen‐\nerally be copied, so it’s usually possible to have multiple closures of a closure type\ncorresponding to a single lambda. For example, in the following code,\n{\n  int x;                                 // x is local variable\n  …\n  auto c1 =                              // c1 is copy of the\n    [x](int y) { return x * y > 55; };   // closure produced\n                                         // by the lambda\n  auto c2 = c1;                          // c2 is copy of c1\n  auto c3 = c2;                          // c3 is copy of c2\n  …\n}\nc1, c2, and c3 are all copies of the closure produced by the lambda.\nInformally, it’s perfectly acceptable to blur the lines between lambdas, closures, and\nclosure classes. But in the Items that follow, it’s often important to distinguish what\nexists during compilation (lambdas and closure classes), what exists at runtime (clo‐\nsures), and how they relate to one another.\nItem 31: Avoid default capture modes.\nThere are two default capture modes in C++11: by-reference and by-value. Default\nby-reference capture can lead to dangling references. Default by-value capture lures\nyou into thinking you’re immune to that problem (you’re not), and it lulls you into\nthinking your closures are self-contained (they may not be).\nThat’s the executive summary for this Item. If you’re more engineer than executive,\nyou’ll want some meat on those bones, so let’s start with the danger of default by-\nreference capture.\n216 \n| \nItem 30\nwww.it-ebooks.info\n",
      "content_length": 2001,
      "extraction_method": "Direct"
    },
    {
      "page_number": 235,
      "chapter": null,
      "content": "A by-reference capture causes a closure to contain a reference to a local variable or to\na parameter that’s available in the scope where the lambda is defined. If the lifetime\nof a closure created from that lambda exceeds the lifetime of the local variable or\nparameter, the reference in the closure will dangle. For example, suppose we have a\ncontainer of filtering functions, each of which takes an int and returns a bool indi‐\ncating whether a passed-in value satisfies the filter:\nusing FilterContainer =                     // see Item 9 for\n  std::vector<std::function<bool(int)>>;    // \"using\", Item 2\n                                            // for std::function\nFilterContainer filters;                    // filtering funcs\nWe could add a filter for multiples of 5 like this:\nfilters.emplace_back(                       // see Item 42 for\n  [](int value) { return value % 5 == 0; }  // info on\n);                                          // emplace_back\nHowever, it may be that we need to compute the divisor at runtime, i.e., we can’t just\nhard-code 5 into the lambda. So adding the filter might look more like this:\nvoid addDivisorFilter()\n{\n  auto calc1 = computeSomeValue1();\n  auto calc2 = computeSomeValue2();\n  auto divisor = computeDivisor(calc1, calc2);\n  filters.emplace_back(                              // danger!\n    [&](int value) { return value % divisor == 0; }  // ref to\n  );                                                 // divisor\n}                                                    // will\n                                                     // dangle!\nThis code is a problem waiting to happen. The lambda refers to the local variable\ndivisor, but that variable ceases to exist when addDivisorFilter returns. That’s\nimmediately after filters.emplace_back returns, so the function that’s added to\nfilters is essentially dead on arrival. Using that filter yields undefined behavior\nfrom virtually the moment it’s created.\nNow, the same problem would exist if divisor’s by-reference capture were explicit,\nfilters.emplace_back(\n  [&divisor](int value)                // danger! ref to\n  { return value % divisor == 0; }     // divisor will\n);                                     // still dangle!\nItem 31 \n| \n217\nwww.it-ebooks.info\n",
      "content_length": 2268,
      "extraction_method": "Direct"
    },
    {
      "page_number": 236,
      "chapter": null,
      "content": "but with an explicit capture, it’s easier to see that the viability of the lambda is depen‐\ndent on divisor’s lifetime. Also, writing out the name, “divisor,” reminds us to\nensure that divisor lives at least as long as the lambda’s closures. That’s a more spe‐\ncific memory jog than the general “make sure nothing dangles” admonition that\n“[&]” conveys.\nIf you know that a closure will be used immediately (e.g., by being passed to an STL\nalgorithm) and won’t be copied, there is no risk that references it holds will outlive\nthe local variables and parameters in the environment where its lambda is created. In\nthat case, you might argue, there’s no risk of dangling references, hence no reason to\navoid a default by-reference capture mode. For example, our filtering lambda might\nbe used only as an argument to C++11’s std::all_of, which returns whether all ele‐\nments in a range satisfy a condition:\ntemplate<typename C>\nvoid workWithContainer(const C& container)\n{\n  auto calc1 = computeSomeValue1();             // as above\n  auto calc2 = computeSomeValue2();             // as above\n  auto divisor = computeDivisor(calc1, calc2);  // as above\n  using ContElemT = typename C::value_type;     // type of\n                                                // elements in\n                                                // container\n  using std::begin;                             // for\n  using std::end;                               // genericity;\n                                                // see Item 13\n  if (std::all_of(                              // if all values\n        begin(container), end(container),       // in container\n        [&](const ContElemT& value)             // are multiples\n        { return value % divisor == 0; })       // of divisor...\n      ) {\n    …                                           // they are...\n  } else {\n    …                                           // at least one\n  }                                             // isn't...\n}\nIt’s true, this is safe, but its safety is somewhat precarious. If the lambda were found\nto be useful in other contexts (e.g., as a function to be added to the filters con‐\ntainer) and was copy-and-pasted into a context where its closure could outlive divi\n218 \n| \nItem 31\nwww.it-ebooks.info\n",
      "content_length": 2274,
      "extraction_method": "Direct"
    },
    {
      "page_number": 237,
      "chapter": null,
      "content": "sor, you’d be back in dangle-city, and there’d be nothing in the capture clause to\nspecifically remind you to perform lifetime analysis on divisor.\nLong-term, it’s simply better software engineering to explicitly list the local variables\nand parameters that a lambda depends on.\nBy the way, the ability to use auto in C++14 lambda parameter specifications means\nthat the code above can be simplified in C++14. The ContElemT typedef can be elimi‐\nnated, and the if condition can be revised as follows:\nif (std::all_of(begin(container), end(container),\n                [&](const auto& value)                // C++14\n                { return value % divisor == 0; }))\nOne way to solve our problem with divisor would be a default by-value capture\nmode. That is, we could add the lambda to filters as follows:\nfilters.emplace_back(                                 // now\n  [=](int value) { return value % divisor == 0; }     // divisor\n);                                                    // can't\n                                                      // dangle\nThis suffices for this example, but, in general, default by-value capture isn’t the anti-\ndangling elixir you might imagine. The problem is that if you capture a pointer by\nvalue, you copy the pointer into the closures arising from the lambda, but you don’t\nprevent code outside the lambda from deleteing the pointer and causing your\ncopies to dangle.\n“That could never happen!” you protest. “Having read Chapter 4, I worship at the\nhouse of smart pointers. Only loser C++98 programmers use raw pointers and\ndelete.” That may be true, but it’s irrelevant because you do, in fact, use raw point‐\ners, and they can, in fact, be deleted out from under you. It’s just that in your\nmodern C++ programming style, there’s often little sign of it in the source code.\nSuppose one of the things Widgets can do is add entries to the container  of filters:\nclass Widget {\npublic:\n  …                                  // ctors, etc.\n  void addFilter() const;            // add an entry to filters\nprivate:\n  int divisor;                       // used in Widget's filter\n};\nWidget::addFilter could be defined like this:\nItem 31 \n| \n219\nwww.it-ebooks.info\n",
      "content_length": 2199,
      "extraction_method": "Direct"
    },
    {
      "page_number": 238,
      "chapter": null,
      "content": "void Widget::addFilter() const\n{\n  filters.emplace_back(\n    [=](int value) { return value % divisor == 0; }\n  );\n}\nTo the blissfully uninitiated, this looks like safe code. The lambda is dependent on\ndivisor, but the default by-value capture mode ensures that divisor is copied into\nany closures arising from the lambda, right?\nWrong. Completely wrong. Horribly wrong. Fatally wrong.\nCaptures apply only to non-static local variables (including parameters) visible in\nthe scope where the lambda is created. In the body of Widget::addFilter, divisor\nis not a local variable, it’s a data member of the Widget class. It can’t be captured. Yet\nif the default capture mode is eliminated, the code won’t compile:\nvoid Widget::addFilter() const\n{\n  filters.emplace_back(                             // error!\n    [](int value) { return value % divisor == 0; }  // divisor\n  );                                                // not\n}                                                   // available\nFurthermore, if an attempt is made to explicitly capture divisor (either by value or\nby reference—it doesn’t matter), the capture won’t compile, because divisor isn’t a\nlocal variable or a parameter:\nvoid Widget::addFilter() const\n{\n  filters.emplace_back(\n    [divisor](int value)                // error! no local\n    { return value % divisor == 0; }    // divisor to capture\n  );\n}\nSo if the default by-value capture clause isn’t capturing divisor, yet without the\ndefault by-value capture clause, the code won’t compile, what’s going on?\nThe explanation hinges on the implicit use of a raw pointer: this. Every non-static\nmember function has a this pointer, and you use that pointer every time you men‐\ntion a data member of the class. Inside any Widget member function, for example,\ncompilers internally replace uses of divisor with this->divisor. In the version of\nWidget::addFilter with a default by-value capture,\n220 \n| \nItem 31\nwww.it-ebooks.info\n",
      "content_length": 1947,
      "extraction_method": "Direct"
    },
    {
      "page_number": 239,
      "chapter": null,
      "content": "void Widget::addFilter() const\n{\n  filters.emplace_back(\n    [=](int value) { return value % divisor == 0; }\n  );\n}\nwhat’s being captured is the Widget’s this pointer, not divisor. Compilers treat the\ncode as if it had been written as follows:\nvoid Widget::addFilter() const\n{\n  auto currentObjectPtr = this;\n  \n  filters.emplace_back(\n    [currentObjectPtr](int value)\n    { return value % currentObjectPtr->divisor == 0; }\n  );\n}\nUnderstanding this is tantamount to understanding that the viability of the closures\narising from this lambda is tied to the lifetime of the Widget whose this pointer they\ncontain a copy of. In particular, consider this code, which, in accord with Chapter 4,\nuses pointers of only the smart variety:\nusing FilterContainer =                     // as before\n  std::vector<std::function<bool(int)>>;\nFilterContainer filters;                    // as before\nvoid doSomeWork()\n{\n  auto pw =                       // create Widget; see\n    std::make_unique<Widget>();   // Item 21 for\n                                  // std::make_unique\n  pw->addFilter();                // add filter that uses\n                                  // Widget::divisor\n  …\n}                                 // destroy Widget; filters\n                                  // now holds dangling pointer!\nWhen a call is made to doSomeWork, a filter is created that depends on the Widget\nobject produced by std::make_unique, i.e., a filter that contains a copy of a pointer\nto that Widget—the Widget’s this pointer. This filter is added to filters, but when\ndoSomeWork finishes, the Widget is destroyed by the std::unique_ptr managing its\nItem 31 \n| \n221\nwww.it-ebooks.info\n",
      "content_length": 1675,
      "extraction_method": "Direct"
    },
    {
      "page_number": 240,
      "chapter": null,
      "content": "lifetime (see Item 18). From that point on, filters contains an entry with a dangling\npointer.\nThis particular problem can be solved by making a local copy of the data member\nyou want to capture and then capturing the copy:\nvoid Widget::addFilter() const\n{\n  auto divisorCopy = divisor;                // copy data member\n  filters.emplace_back(\n    [divisorCopy](int value)                 // capture the copy\n    { return value % divisorCopy == 0; }     // use the copy\n  );\n}\nTo be honest, if you take this approach, default by-value capture will work, too,\nvoid Widget::addFilter() const\n{\n  auto divisorCopy = divisor;                // copy data member\n  filters.emplace_back(\n    [=](int value)                           // capture the copy\n    { return value % divisorCopy == 0; }     // use the copy\n  );\n}\nbut why tempt fate? A default capture mode is what made it possible to accidentally\ncapture this when you thought you were capturing divisor in the first place.\nIn C++14, a better way to capture a data member is to use generalized lambda cap‐\nture (see Item 32):\nvoid Widget::addFilter() const\n{\n  filters.emplace_back(               // C++14:\n    [divisor = divisor](int value)    // copy divisor to closure\n    { return value % divisor == 0; }  // use the copy\n  );\n}\nThere’s no such thing as a default capture mode for a generalized lambda capture,\nhowever, so even in C++14, the advice of this Item—to avoid default capture modes\n—stands.\nAn additional drawback to default by-value captures is that they can suggest that the\ncorresponding closures are self-contained and insulated from changes to data outside\n222 \n| \nItem 31\nwww.it-ebooks.info\n",
      "content_length": 1665,
      "extraction_method": "Direct"
    },
    {
      "page_number": 241,
      "chapter": null,
      "content": "the closures. In general, that’s not true, because lambdas may be dependent not just\non local variables and parameters (which may be captured), but also on objects with\nstatic storage duration. Such objects are defined at global or namespace scope or are\ndeclared static inside classes, functions, or files. These objects can be used inside\nlambdas, but they can’t be captured. Yet specification of a default by-value capture\nmode can lend the impression that they are. Consider this revised version of the add\nDivisorFilter function we saw earlier:\nvoid addDivisorFilter()\n{\n  static auto calc1 = computeSomeValue1();      // now static\n  static auto calc2 = computeSomeValue2();      // now static\n  static auto divisor =                         // now static\n    computeDivisor(calc1, calc2);\n  filters.emplace_back(\n    [=](int value)                     // captures nothing!\n    { return value % divisor == 0; }   // refers to above static\n  );\n  ++divisor;                           // modify divisor\n}\nA casual reader of this code could be forgiven for seeing “[=]” and thinking, “Okay,\nthe lambda makes a copy of all the objects it uses and is therefore self-contained.” But\nit’s not self-contained. This lambda doesn’t use any non-static local variables, so\nnothing is captured. Rather, the code for the lambda refers to the static variable\ndivisor. When, at the end of each invocation of addDivisorFilter, divisor is\nincremented, any lambdas that have been added to filters via this function will\nexhibit new behavior (corresponding to the new value of divisor). Practically speak‐\ning, this lambda captures divisor by reference, a direct contradiction to what the\ndefault by-value capture clause seems to imply. If you stay away from default by-\nvalue capture clauses, you eliminate the risk of your code being misread in this way.\nThings to Remember\n• Default by-reference capture can lead to dangling references.\n• Default by-value capture is susceptible to dangling pointers (especially this),\nand it misleadingly suggests that lambdas are self-contained.\nItem 31 \n| \n223\nwww.it-ebooks.info\n",
      "content_length": 2105,
      "extraction_method": "Direct"
    },
    {
      "page_number": 242,
      "chapter": null,
      "content": "Item 32: Use init capture to move objects into closures.\nSometimes neither by-value capture nor by-reference capture is what you want. If\nyou have a move-only object (e.g., a std::unique_ptr or a std::future) that you\nwant to get into a closure, C++11 offers no way to do it. If you have an object that’s\nexpensive to copy but cheap to move (e.g., most containers in the Standard Library),\nand you’d like to get that object into a closure, you’d much rather move it than copy\nit. Again, however, C++11 gives you no way to accomplish that.\nBut that’s C++11. C++14 is a different story. It offers direct support for moving\nobjects into closures. If your compilers are C++14-compliant, rejoice and read on. If\nyou’re still working with C++11 compilers, you should rejoice and read on, too,\nbecause there are ways to approximate move capture in C++11.\nThe absence of move capture was recognized as a shortcoming even as C++11 was\nadopted. The straightforward remedy would have been to add it in C++14, but the\nStandardization Committee chose a different path. They introduced a new capture\nmechanism that’s so flexible, capture-by-move is only one of the tricks it can per‐\nform. The new capability is called init capture. It can do virtually everything the\nC++11 capture forms can do, plus more. The one thing you can’t express with an init\ncapture is a default capture mode, but Item 31 explains that you should stay away\nfrom those, anyway. (For situations covered by C++11 captures, init capture’s syntax\nis a bit wordier, so in cases where a C++11 capture gets the job done, it’s perfectly\nreasonable to use it.)\nUsing an init capture makes it possible for you to specify\n1. the name of a data member in the closure class generated from the lambda and\n2. an expression initializing that data member.\nHere’s how you can use init capture to move a std::unique_ptr into a closure:\nclass Widget {                          // some useful type\npublic:\n  …\n  bool isValidated() const;\n  bool isProcessed() const;\n  bool isArchived() const;\nprivate:\n  …\n};\n224 \n| \nItem 32\nwww.it-ebooks.info\n",
      "content_length": 2085,
      "extraction_method": "Direct"
    },
    {
      "page_number": 243,
      "chapter": null,
      "content": "auto pw = std::make_unique<Widget>();   // create Widget; see\n                                        // Item 21 for info on\n                                        // std::make_unique\n…                                       // configure *pw\nauto func = [pw = std::move(pw)]               // init data mbr\n            { return pw->isValidated()         // in closure w/\n                     && pw->isArchived(); };   // std::move(pw)\nThe highlighted text comprises the init capture. To the left of the “=” is the name of\nthe data member in the closure class you’re specifying, and to the right is the initializ‐\ning expression. Interestingly, the scope on the left of the “=” is different from the\nscope on the right. The scope on the left is that of the closure class. The scope on the\nright is the same as where the lambda is being defined. In the example above, the\nname pw on the left of the “=” refers to a data member in the closure class, while the\nname pw on the right refers to the object declared above the lambda, i.e., the variable\ninitialized by the call to std::make_unique. So “pw = std::move(pw)” means “create\na data member pw in the closure, and initialize that data member with the result of\napplying std::move to the local variable pw.”\nAs usual, code in the body of the lambda is in the scope of the closure class, so uses of\npw there refer to the closure class data member.\nThe comment “configure *pw” in this example indicates that after the Widget is cre‐\nated by std::make_unique and before the std::unique_ptr to that Widget is cap‐\ntured by the lambda, the Widget is modified in some way. If no such configuration is\nnecessary, i.e., if the Widget created by std::make_unique is in a state suitable to be\ncaptured by the lambda, the local variable pw is unnecessary, because the closure\nclass’s data member can be directly initialized by std::make_unique:\nauto func = [pw = std::make_unique<Widget>()]  // init data mbr\n            { return pw->isValidated()         // in closure w/\n                     && pw->isArchived(); };   // result of call\n                                               // to make_unique\nThis should make clear that the C++14 notion of “capture” is considerably general‐\nized from C++11, because in C++11, it’s not possible to capture the result of an\nexpression. As a result, another name for init capture is generalized lambda capture.\nBut what if one or more of the compilers you use lacks support for C++14’s init cap‐\nture? How can you accomplish move capture in a language lacking support for move\ncapture?\nItem 32 \n| \n225\nwww.it-ebooks.info\n",
      "content_length": 2601,
      "extraction_method": "Direct"
    },
    {
      "page_number": 244,
      "chapter": null,
      "content": "Remember that a lambda expression is simply a way to cause a class to be generated\nand an object of that type to be created. There is nothing you can do with a lambda\nthat you can’t do by hand. The example C++14 code we just saw, for example, can be\nwritten in C++11 like this:\nclass IsValAndArch {                         // \"is validated\npublic:                                      // and archived\"\n  using DataType = std::unique_ptr<Widget>;\n  explicit IsValAndArch(DataType&& ptr)      // Item 25 explains\n  : pw(std::move(ptr)) {}                    // use of std::move\n  bool operator()() const\n  { return pw->isValidated() && pw->isArchived(); }\nprivate:\n  DataType pw;\n};\nauto func = IsValAndArch(std::make_unique<Widget>());\nThat’s more work than writing the lambda, but it doesn’t change the fact that if you\nwant a class in C++11 that supports move-initialization of its data members, the only\nthing between you and your desire is a bit of time with your keyboard.\nIf you want to stick with lambdas (and given their convenience, you probably do),\nmove capture can be emulated in C++11 by\n1. moving the object to be captured into a function object produced by\nstd::bind and\n2. giving the lambda a reference to the “captured” object.\nIf you’re familiar with std::bind, the code is pretty straightforward. If you’re not\nfamiliar with std::bind, the code takes a little getting used to, but it’s worth the\ntrouble.\nSuppose you’d like to create a local std::vector, put an appropriate set of values\ninto it, then move it into a closure. In C++14, this is easy:\nstd::vector<double> data;                 // object to be moved\n                                          // into closure\n…                                         // populate data\nauto func = [data = std::move(data)]      // C++14 init capture\n            { /* uses of data */ };\n226 \n| \nItem 32\nwww.it-ebooks.info\n",
      "content_length": 1884,
      "extraction_method": "Direct"
    },
    {
      "page_number": 245,
      "chapter": null,
      "content": "I’ve highlighted key parts of this code: the type of object you want to move\n(std::vector<double>), the name of that object (data), and the initializing expres‐\nsion for the init capture (std::move(data)). The C++11 equivalent is as follows,\nwhere I’ve highlighted the same key things:\nstd::vector<double> data;                 // as above\n…                                         // as above\nauto func =\n  std::bind(                              // C++11 emulation\n    [](const std::vector<double>& data)   // of init capture\n    { /* uses of data */ },\n    std::move(data)\n  );\nLike lambda expressions, std::bind produces function objects. I call function\nobjects returned by std::bind bind objects. The first argument to std::bind is a\ncallable object. Subsequent arguments represent values to be passed to that object.\nA bind object contains copies of all the arguments passed to std::bind. For each\nlvalue argument, the corresponding object in the bind object is copy constructed. For\neach rvalue, it’s move constructed. In this example, the second argument is an rvalue\n(the result of std::move—see Item 23), so data is move constructed into the bind\nobject. This move construction is the crux of move capture emulation, because mov‐\ning an rvalue into a bind object is how we work around the inability to move an\nrvalue into a C++11 closure.\nWhen a bind object is “called” (i.e., its function call operator is invoked) the argu‐\nments it stores are passed to the callable object originally passed to std::bind. In\nthis example, that means that when func (the bind object) is called, the move-\nconstructed copy of data inside func is passed as an argument to the lambda that\nwas passed to std::bind.\nThis lambda is the same as the lambda we’d use in C++14, except a parameter, data,\nhas been added to correspond to our pseudo-move-captured object. This parameter\nis an lvalue reference to the copy of data in the bind object. (It’s not an rvalue refer‐\nence, because although the expression used to initialize the copy of data\n(“std::move(data)”) is an rvalue, the copy of data itself is an lvalue.) Uses of data\ninside the lambda will thus operate on the move-constructed copy of data inside the\nbind object.\nBy default, the operator() member function inside the closure class generated from\na lambda is const. That has the effect of rendering all data members in the closure\nItem 32 \n| \n227\nwww.it-ebooks.info\n",
      "content_length": 2419,
      "extraction_method": "Direct"
    },
    {
      "page_number": 246,
      "chapter": null,
      "content": "const within the body of the lambda. The move-constructed copy of data inside the\nbind object is not const, however, so to prevent that copy of data from being modi‐\nfied inside the lambda, the lambda’s parameter is declared reference-to-const. If the\nlambda were declared mutable, operator() in its closure class would not be\ndeclared const, and it would be appropriate to omit const in the lambda’s parame‐\nter declaration:\nauto func =\n  std::bind(                               // C++11 emulation\n    [](std::vector<double>& data) mutable  // of init capture\n    { /* uses of data */ },                // for mutable lambda\n    std::move(data)\n  );\nBecause a bind object stores copies of all the arguments passed to std::bind, the\nbind object in our example contains a copy of the closure produced by the lambda\nthat is its first argument. The lifetime of the closure is therefore the same as the life‐\ntime of the bind object. That’s important, because it means that as long as the closure\nexists, the bind object containing the pseudo-move-captured object exists, too.\nIf this is your first exposure to std::bind, you may need to consult your favorite\nC++11 reference before all the details of the foregoing discussion fall into place. Even\nif that’s the case, these fundamental points should be clear:\n• It’s not possible to move-construct an object into a C++11 closure, but it is possi‐\nble to move-construct an object into a C++11 bind object.\n• Emulating move-capture in C++11 consists of move-constructing an object into\na bind object, then passing the move-constructed object to the lambda by refer‐\nence.\n• Because the lifetime of the bind object is the same as that of the closure, it’s pos‐\nsible to treat objects in the bind object as if they were in the closure.\nAs a second example of using std::bind to emulate move capture, here’s the C++14\ncode we saw earlier to create a std::unique_ptr in a closure:\nauto func = [pw = std::make_unique<Widget>()]    // as before,\n            { return pw->isValidated()           // create pw\n                     && pw->isArchived(); };     // in closure\nAnd here’s the C++11 emulation:\nauto func = std::bind(\n              [](const std::unique_ptr<Widget>& pw)\n              { return pw->isValidated()\n                     && pw->isArchived(); },\n228 \n| \nItem 32\nwww.it-ebooks.info\n",
      "content_length": 2339,
      "extraction_method": "Direct"
    },
    {
      "page_number": 247,
      "chapter": null,
      "content": "              std::make_unique<Widget>()\n            );\nIt’s ironic that I’m showing how to use std::bind to work around limitations in\nC++11 lambdas, because in Item 34, I advocate the use of lambdas over std::bind.\nHowever, that Item explains that there are some cases in C++11 where std::bind\ncan be useful, and this is one of them. (In C++14, features such as init capture and\nauto parameters eliminate those cases.)\nThings to Remember\n• Use C++14’s init capture to move objects into closures.\n• In C++11, emulate init capture via hand-written classes or std::bind.\nItem 33: Use decltype on auto&& parameters to\nstd::forward them.\nOne of the most exciting features of C++14 is generic lambdas—lambdas that use\nauto in their parameter specifications. The implementation of this feature is straight‐\nforward: operator() in the lambda’s closure class is a template. Given this lambda,\nfor example,\nauto f = [](auto x){ return func(normalize(x)); };\nthe closure class’s function call operator looks like this:\nclass SomeCompilerGeneratedClassName {\npublic:\n  template<typename T>                   // see Item 3 for \n  auto operator()(T x) const             // auto return type\n  { return func(normalize(x)); }\n  …                                      // other closure class\n};                                       // functionality\nIn this example, the only thing the lambda does with its parameter x is forward it to\nnormalize. If normalize treats lvalues differently from rvalues, this lambda isn’t\nwritten properly, because it always passes an lvalue (the parameter x) to normalize,\neven if the argument that was passed to the lambda was an rvalue.\nThe correct way to write the lambda is to have it perfect-forward x to normalize.\nDoing that requires two changes to the code. First, x has to become a universal refer‐\nItem 32 \n| \n229\nwww.it-ebooks.info\n",
      "content_length": 1857,
      "extraction_method": "Direct"
    },
    {
      "page_number": 248,
      "chapter": null,
      "content": "ence (see Item 24), and second, it has to be passed to normalize via std::forward\n(see Item 25). In concept, these are trivial modifications:\nauto f = [](auto&& x)\n         { return func(normalize(std::forward<???>(x))); };\nBetween concept and realization, however, is the question of what type to pass to\nstd::forward, i.e., to determine what should go where I’ve written ??? above.\nNormally, when you employ perfect forwarding, you’re in a template function taking\na type parameter T, so you just write std::forward<T>. In the generic lambda,\nthough, there’s no type parameter T available to you. There is a T in the templatized\noperator() inside the closure class generated by the lambda, but it’s not possible to\nrefer to it from the lambda, so it does you no good.\nItem 28 explains that if an lvalue argument is passed to a universal reference parame‐\nter, the type of that parameter becomes an lvalue reference. If an rvalue is passed, the\nparameter becomes an rvalue reference. This means that in our lambda, we can\ndetermine whether the argument passed was an lvalue or an rvalue by inspecting the\ntype of the parameter x. decltype gives us a way to do that (see Item 3). If an lvalue\nwas passed in, decltype(x) will produce a type that’s an lvalue reference. If an\nrvalue was passed, decltype(x) will produce an rvalue reference type.\nItem 28 also explains that when calling std::forward, convention dictates that the\ntype argument be an lvalue reference to indicate an lvalue and a non-reference to\nindicate an rvalue. In our lambda, if x is bound to an lvalue, decltype(x) will yield\nan lvalue reference. That conforms to convention. However, if x is bound to an\nrvalue, decltype(x) will yield an rvalue reference instead of the customary non-\nreference.\nBut look at the sample C++14 implementation for std::forward from Item 28:\ntemplate<typename T>                         // in namespace\nT&& forward(remove_reference_t<T>& param)    // std\n{\n  return static_cast<T&&>(param);\n}\nIf client code wants to perfect-forward an rvalue of type Widget, it normally instanti‐\nates std::forward with the type Widget (i.e, a non-reference type), and the\nstd::forward template yields this function:\nWidget&& forward(Widget& param)            // instantiation of\n{                                          // std::forward when\n  return static_cast<Widget&&>(param);     // T is Widget\n}\n230 \n| \nItem 33\nwww.it-ebooks.info\n",
      "content_length": 2422,
      "extraction_method": "Direct"
    },
    {
      "page_number": 249,
      "chapter": null,
      "content": "But consider what would happen if the client code wanted to perfect-forward the\nsame rvalue of type Widget, but instead of following the convention of specifying T to\nbe a non-reference type, it specified it to be an rvalue reference. That is, consider\nwhat would happen if T were specified to be Widget&&. After initial instantiation of\nstd::forward and application of std::remove_reference_t, but before reference\ncollapsing (once again, see Item 28), std::forward would look like this:\nWidget&& && forward(Widget& param)         // instantiation of\n{                                          // std::forward when\n  return static_cast<Widget&& &&>(param);  // T is Widget&&\n}                                          // (before reference-\n                                           // collapsing)\nApplying the reference-collapsing rule that an rvalue reference to an rvalue reference\nbecomes a single rvalue reference, this instantiation emerges:\nWidget&& forward(Widget& param)            // instantiation of\n{                                          // std::forward when\n  return static_cast<Widget&&>(param);     // T is Widget&&\n}                                          // (after reference-\n                                           // collapsing)\nIf you compare this instantiation with the one that results when std::forward is\ncalled with T set to Widget, you’ll see that they’re identical. That means that instanti‐\nating std::forward with an rvalue reference type yields the same result as instantiat‐\ning it with a non-reference type.\nThat’s wonderful news, because decltype(x) yields an rvalue reference type when\nan rvalue is passed as an argument to our lambda’s parameter x. We established\nabove that when an lvalue is passed to our lambda, decltype(x) yields the custom‐\nary type to pass to std::forward, and now we realize that for rvalues, decltype(x)\nyields a type to pass to std::forward that’s not conventional, but that nevertheless\nyields the same outcome as the conventional type. So for both lvalues and rvalues,\npassing decltype(x) to std::forward gives us the result we want. Our perfect-\nforwarding lambda can therefore be written like this:\nauto f =\n  [](auto&& param)\n  {\n    return\n      func(normalize(std::forward<decltype(param)>(param)));\n  };\nFrom there, it’s just a hop, skip, and six dots to a perfect-forwarding lambda that\naccepts not just a single parameter, but any number of parameters, because C++14\nlambdas can also be variadic:\nItem 33 \n| \n231\nwww.it-ebooks.info\n",
      "content_length": 2513,
      "extraction_method": "Direct"
    },
    {
      "page_number": 250,
      "chapter": null,
      "content": "auto f =\n  [](auto&&... params)\n  {\n    return\n    func(normalize(std::forward<decltype(params)>(params)...));\n  };\nThings to Remember\n• Use decltype on auto&& parameters to std::forward them.\nItem 34: Prefer lambdas to std::bind.\nstd::bind is the C++11 successor to C++98’s std::bind1st and std::bind2nd,\nbut, informally, it’s been part of the Standard Library since 2005. That’s when the\nStandardization Committee adopted a document known as TR1, which included\nbind’s specification. (In TR1, bind was in a different namespace, so it was\nstd::tr1::bind, not std::bind, and a few interface details were different.) This\nhistory means that some programmers have a decade or more of experience using\nstd::bind. If you’re one of them, you may be reluctant to abandon a tool that’s\nserved you well. That’s understandable, but in this case, change is good, because in\nC++11, lambdas are almost always a better choice than std::bind. As of C++14, the\ncase for lambdas isn’t just stronger, it’s downright ironclad.\nThis Item assumes that you’re familiar with std::bind. If you’re not, you’ll want to\nacquire a basic understanding before continuing. Such an understanding is worth‐\nwhile in any case, because you never know when you might encounter uses of\nstd::bind in a code base you have to read or maintain.\nAs in Item 32, I refer to the function objects returned from std::bind as bind\nobjects.\nThe most important reason to prefer lambdas over std::bind is that lambdas are\nmore readable. Suppose, for example, we have a function to set up an audible alarm:\n// typedef for a point in time (see Item 9 for syntax)\nusing Time = std::chrono::steady_clock::time_point;\n// see Item 10 for \"enum class\"\nenum class Sound { Beep, Siren, Whistle };\n// typedef for a length of time\n232 \n| \nItem 33\nwww.it-ebooks.info\n",
      "content_length": 1805,
      "extraction_method": "Direct"
    },
    {
      "page_number": 251,
      "chapter": null,
      "content": "using Duration = std::chrono::steady_clock::duration;\n// at time t, make sound s for duration d\nvoid setAlarm(Time t, Sound s, Duration d);\nFurther suppose that at some point in the program, we’ve determined we’ll want an\nalarm that will go off an hour after it’s set and that will stay on for 30 seconds. The\nalarm sound, however, remains undecided. We can write a lambda that revises\nsetAlarm’s interface so that only a sound needs to be specified:\n// setSoundL (\"L\" for \"lambda\") is a function object allowing a\n// sound to be specified for a 30-sec alarm to go off an hour\n// after it's set\nauto setSoundL =                             \n  [](Sound s)\n  {\n    // make std::chrono components available w/o qualification\n    using namespace std::chrono;\n    setAlarm(steady_clock::now() + hours(1),  // alarm to go off\n             s,                               // in an hour for\n             seconds(30));                    // 30 seconds\n  };\nI’ve highlighted the call to setAlarm inside the lambda. This is a normal-looking\nfunction call, and even a reader with little lambda experience can see that the param‐\neter s passed to the lambda is passed as an argument to setAlarm.\nWe can streamline this code in C++14 by availing ourselves of the standard suffixes\nfor seconds (s), milliseconds (ms), hours (h), etc., that build on C++11’s support for\nuser-defined literals. These suffixes are implemented in the std::literals name‐\nspace, so the above code can be rewritten as follows:\nauto setSoundL =                             \n  [](Sound s)\n  {\n    using namespace std::chrono;\n    using namespace std::literals;         // for C++14 suffixes\n    setAlarm(steady_clock::now() + 1h,     // C++14, but\n             s,                            // same meaning\n             30s);                         // as above\n  };\nItem 34 \n| \n233\nwww.it-ebooks.info\n",
      "content_length": 1863,
      "extraction_method": "Direct"
    },
    {
      "page_number": 252,
      "chapter": null,
      "content": "Our first attempt to write the corresponding std::bind call is below. It has an error\nthat we’ll fix in a moment, but the correct code is more complicated, and even this\nsimplified version brings out some important issues:\nusing namespace std::chrono;           // as above\nusing namespace std::literals;\nusing namespace std::placeholders;     // needed for use of \"_1\"\nauto setSoundB =                       // \"B\" for \"bind\"\n  std::bind(setAlarm,\n            steady_clock::now() + 1h,  // incorrect! see below\n            _1,\n            30s);\nI’d like to highlight the call to setAlarm here as I did in the lambda, but there’s no\ncall to highlight. Readers of this code simply have to know that calling setSoundB\ninvokes setAlarm with the time and duration specified in the call to std::bind. To\nthe uninitiated, the placeholder “_1” is essentially magic, but even readers in the\nknow have to mentally map from the number in that placeholder to its position in the\nstd::bind parameter list in order to understand that the first argument in a call to\nsetSoundB is passed as the second argument to setAlarm. The type of this argument\nis not identified in the call to std::bind, so readers have to consult the setAlarm\ndeclaration to determine what kind of argument to pass to setSoundB.\nBut, as I said, the code isn’t quite right. In the lambda, it’s clear that the expression\n“steady_clock::now() + 1h” is an argument to setAlarm. It will be evaluated when\nsetAlarm is called. That makes sense: we want the alarm to go off an hour after\ninvoking setAlarm. In the std::bind call, however, “steady_clock::now() + 1h”\nis passed as an argument to std::bind, not to setAlarm. That means that the\nexpression will be evaluated when std::bind is called, and the time resulting from\nthat expression will be stored inside the resulting bind object. As a consequence, the\nalarm will be set to go off an hour after the call to std::bind, not an hour after the\ncall to setAlarm!\nFixing the problem requires telling std::bind to defer evaluation of the expression\nuntil setAlarm is called, and the way to do that is to nest a second call to std::bind\ninside the first one:\nauto setSoundB =\n  std::bind(setAlarm,\n            std::bind(std::plus<>(), steady_clock::now(), 1h),\n            _1,\n            30s);\n234 \n| \nItem 34\nwww.it-ebooks.info\n",
      "content_length": 2332,
      "extraction_method": "Direct"
    },
    {
      "page_number": 253,
      "chapter": null,
      "content": "If you’re familiar with the std::plus template from C++98, you may be surprised to\nsee that in this code, no type is specified between the angle brackets, i.e., the code\ncontains “std::plus<>”, not “std::plus<type>”. In C++14, the template type\nargument for the standard operator templates can generally be omitted, so there’s no\nneed to provide it here. C++11 offers no such feature, so the C++11 std::bind\nequivalent to the lambda is:\nusing namespace std::chrono;                   // as above\nusing namespace std::placeholders;\nauto setSoundB =\n  std::bind(setAlarm,\n            std::bind(std::plus<steady_clock::time_point>(),\n                      steady_clock::now(),\n                      hours(1)),\n            _1,\n            seconds(30));\nIf, at this point, the lambda’s not looking a lot more attractive, you should probably\nhave your eyesight checked.\nWhen setAlarm is overloaded, a new issue arises. Suppose there’s an overload taking\na fourth parameter specifying the alarm volume:\nenum class Volume { Normal, Loud, LoudPlusPlus };\nvoid setAlarm(Time t, Sound s, Duration d, Volume v);\nThe lambda continues to work as before, because overload resolution chooses the\nthree-argument version of setAlarm:\nauto setSoundL =                               // same as before\n  [](Sound s)\n  {\n    using namespace std::chrono;\n    setAlarm(steady_clock::now() + 1h,         // fine, calls\n             s,                                // 3-arg version\n             30s);                             // of setAlarm\n  };\nThe std::bind call, on the other hand, now fails to compile:\nauto setSoundB =                               // error! which\n  std::bind(setAlarm,                          // setAlarm?\n            std::bind(std::plus<>(),\n                      steady_clock::now(),\nItem 34 \n| \n235\nwww.it-ebooks.info\n",
      "content_length": 1824,
      "extraction_method": "Direct"
    },
    {
      "page_number": 254,
      "chapter": null,
      "content": "                      1h),\n            _1,\n            30s);\nThe problem is that compilers have no way to determine which of the two setAlarm\nfunctions they should pass to std::bind. All they have is a function name, and the\nname alone is ambiguous.\nTo get the std::bind call to compile, setAlarm must be cast to the proper function\npointer type:\nusing SetAlarm3ParamType = void(*)(Time t, Sound s, Duration d);\nauto setSoundB =                                        // now\n  std::bind(static_cast<SetAlarm3ParamType>(setAlarm),  // okay\n            std::bind(std::plus<>(),\n                      steady_clock::now(),\n                      1h),\n            _1,\n            30s);\nBut this brings up another difference between lambdas and std::bind. Inside the\nfunction call operator for setSoundL (i.e., the function call operator of the lambda’s\nclosure class), the call to setAlarm is a normal function invocation that can be\ninlined by compilers in the usual fashion:\nsetSoundL(Sound::Siren);      // body of setAlarm may\n                              // well be inlined here\nThe call to std::bind, however, passes a function pointer to setAlarm, and that\nmeans that inside the function call operator for setSoundB (i.e., the function call\noperator for the bind object), the call to setAlarm takes place through a function\npointer. Compilers are less likely to inline function calls through function pointers,\nand that means that calls to setAlarm through setSoundB are less likely to be fully\ninlined than those through setSoundL:\nsetSoundB(Sound::Siren);      // body of setAlarm is less\n                              // likely to be inlined here\nIt’s thus possible that using lambdas generates faster code than using std::bind.\nThe setAlarm example involves only a simple function call. If you want to do any‐\nthing more complicated, the scales tip even further in favor of lambdas. For example,\nconsider this C++14 lambda, which returns whether its argument is between a mini‐\nmum value (lowVal) and a maximum value (highVal), where lowVal and highVal\nare local variables:\n236 \n| \nItem 34\nwww.it-ebooks.info\n",
      "content_length": 2115,
      "extraction_method": "Direct"
    },
    {
      "page_number": 255,
      "chapter": null,
      "content": "auto betweenL =\n  [lowVal, highVal]\n  (const auto& val)                          // C++14\n  { return lowVal <= val && val <= highVal; };\nstd::bind can express the same thing, but the construct is an example of job secu‐\nrity through code obscurity:\nusing namespace std::placeholders;           // as above\nauto betweenB =\n  std::bind(std::logical_and<>(),            // C++14\n              std::bind(std::less_equal<>(), lowVal, _1),\n              std::bind(std::less_equal<>(), _1, highVal));\nIn C++11, we’d have to specify the types we wanted to compare, and the std::bind\ncall would then look like this:\nauto betweenB =                              // C++11 version\n  std::bind(std::logical_and<bool>(),\n              std::bind(std::less_equal<int>(), lowVal, _1),\n              std::bind(std::less_equal<int>(), _1, highVal));\nOf course, in C++11, the lambda couldn’t take an auto parameter, so it’d have to\ncommit to a type, too:\nauto betweenL =                              // C++11 version\n  [lowVal, highVal]\n  (int val)\n  { return lowVal <= val && val <= highVal; };\nEither way, I hope we can agree that the lambda version is not just shorter, but also\nmore comprehensible and maintainable.\nEarlier, I remarked that for those with little std::bind experience, its placeholders\n(e.g., _1, _2, etc.) are essentially magic. But it’s not just the behavior of the placehold‐\ners that’s opaque. Suppose we have a function to create compressed copies of\nWidgets,\nenum class CompLevel { Low, Normal, High };  // compression\n                                             // level\nWidget compress(const Widget& w,             // make compressed\n                CompLevel lev);              // copy of w\nand we want to create a function object that allows us to specify how much a particu‐\nlar Widget w should be compressed. This use of std::bind will create such an object:\nItem 34 \n| \n237\nwww.it-ebooks.info\n",
      "content_length": 1907,
      "extraction_method": "Direct"
    },
    {
      "page_number": 256,
      "chapter": null,
      "content": "1 std::bind always copies its arguments, but callers can achieve the effect of having an argument stored by\nreference by applying std::ref to it. The result of\n    auto compressRateB = std::bind(compress, std::ref(w), _1);\nis that compressRateB acts as if it holds a reference to w, rather than a copy.\nWidget w;\nusing namespace std::placeholders;\nauto compressRateB = std::bind(compress, w, _1);\nNow, when we pass w to std::bind, it has to be stored for the later call to compress.\nIt’s stored inside the object compressRateB, but how is it stored—by value or by ref‐\nerence? It makes a difference, because if w is modified between the call to std::bind\nand a call to compressRateB, storing w by reference will reflect the changes, while\nstoring it by value won’t.\nThe answer is that it’s stored by value,1 but the only way to know that is to memorize\nhow std::bind works; there’s no sign of it in the call to std::bind. Contrast that\nwith a lambda approach, where whether w is captured by value or by reference is\nexplicit:\nauto compressRateL =                         // w is captured by\n  [w](CompLevel lev)                         // value; lev is\n  { return compress(w, lev); };              // passed by value\nEqually explicit is how parameters are passed to the lambda. Here, it’s clear that the\nparameter lev is passed by value. Hence:\ncompressRateL(CompLevel::High);              // arg is passed\n                                             // by value\nBut in the call to the object resulting from std::bind, how is the argument passed?\ncompressRateB(CompLevel::High);              // how is arg\n                                             // passed?\nAgain, the only way to know is to memorize how std::bind works. (The answer is\nthat all arguments passed to bind objects are passed by reference, because the func‐\ntion call operator for such objects uses perfect forwarding.)\nCompared to lambdas, then, code using std::bind is less readable, less expressive,\nand possibly less efficient. In C++14, there are no reasonable use cases for\nstd::bind. In C++11, however, std::bind can be justified in two constrained situa‐\ntions:\n238 \n| \nItem 34\nwww.it-ebooks.info\n",
      "content_length": 2174,
      "extraction_method": "Direct"
    },
    {
      "page_number": 257,
      "chapter": null,
      "content": "• Move capture. C++11 lambdas don’t offer move capture, but it can be emulated\nthrough a combination of a lambda and std::bind. For details, consult Item 32,\nwhich also explains that in C++14, lambdas’ support for init capture eliminates\nthe need for the emulation.\n• Polymorphic function objects. Because the function call operator on a bind\nobject uses perfect forwarding, it can accept arguments of any type (modulo the\nrestrictions on perfect forwarding described in Item 30). This can be useful when\nyou want to bind an object with a templatized function call operator. For exam‐\nple, given this class,\nclass PolyWidget {\npublic:\n    template<typename T>\n    void operator()(const T& param);\n    …\n};\nstd::bind can bind a PolyWidget as follows:\nPolyWidget pw;\nauto boundPW = std::bind(pw, _1);\nboundPW can then be called with different types of  arguments:\nboundPW(1930);              // pass int to\n                            // PolyWidget::operator()\nboundPW(nullptr);           // pass nullptr to\n                            // PolyWidget::operator()\nboundPW(\"Rosebud\");         // pass string literal to\n                            // PolyWidget::operator()\nThere is no way to do this with a C++11 lambda. In C++14, however, it’s easily\nachieved via a lambda with an auto parameter:\nauto boundPW = [pw](const auto& param)    // C++14\n               { pw(param); };\nThese are edge cases, of course, and they’re transient edge cases at that, because com‐\npilers supporting C++14 lambdas are increasingly common.\nWhen bind was unofficially added to C++ in 2005, it was a big improvement over its\n1998 predecessors. The addition of lambda support to C++11 rendered std::bind\nall but obsolete, however, and as of C++14, there are just no good use cases for it.\nItem 34 \n| \n239\nwww.it-ebooks.info\n",
      "content_length": 1801,
      "extraction_method": "Direct"
    },
    {
      "page_number": 258,
      "chapter": null,
      "content": "Things to Remember\n• Lambdas are more readable, more expressive, and may be more efficient than\nusing std::bind.\n• In C++11 only, std::bind may be useful for implementing move capture or\nfor binding objects with templatized function call operators.\n240 \n| \nItem 34\nwww.it-ebooks.info\n",
      "content_length": 284,
      "extraction_method": "Direct"
    },
    {
      "page_number": 259,
      "chapter": null,
      "content": "CHAPTER 7\nThe Concurrency API\nOne of C++11’s great triumphs is the incorporation of concurrency into the language\nand library. Programmers familiar with other threading APIs (e.g., pthreads or Win‐\ndows threads) are sometimes surprised at the comparatively Spartan feature set that\nC++ offers, but that’s because a great deal of C++’s support for concurrency is in the\nform of constraints on compiler-writers. The resulting language assurances mean\nthat for the first time in C++’s history, programmers can write multithreaded pro‐\ngrams with standard behavior across all platforms. This establishes a solid foundation\non which expressive libraries can be built, and the concurrency elements of the Stan‐\ndard Library (tasks, futures, threads, mutexes, condition variables, atomic objects,\nand more) are merely the beginning of what is sure to become an increasingly rich set\nof tools for the development of concurrent C++ software.\nIn the Items that follow, bear in mind that the Standard Library has two templates for\nfutures: std::future and std::shared_future. In many cases, the distinction is\nnot important, so I often simply talk about futures, by which I mean both kinds.\nItem 35: Prefer task-based programming to thread-\nbased.\nIf you want to run a function doAsyncWork asynchronously, you have two basic\nchoices. You can create a std::thread and run doAsyncWork on it, thus employing\na thread-based approach:\nint doAsyncWork();\nstd::thread t(doAsyncWork);\nOr you can pass doAsyncWork to std::async, a strategy known as task-based:\n241\nwww.it-ebooks.info\n",
      "content_length": 1564,
      "extraction_method": "Direct"
    },
    {
      "page_number": 260,
      "chapter": null,
      "content": "1 Assuming you have one. Some embedded systems don’t.\nauto fut = std::async(doAsyncWork);        // \"fut\" for \"future\"\nIn such calls, the function object passed to std::async (e.g., doAsyncWork) is con‐\nsidered a task.\nThe task-based approach is typically superior to its thread-based counterpart, and the\ntiny amount of code we’ve seen already demonstrates some reasons why. Here,\ndoAsyncWork produces a return value, which we can reasonably assume the code\ninvoking doAsyncWork is interested in. With the thread-based invocation, there’s no\nstraightforward way to get access to it. With the task-based approach, it’s easy,\nbecause the future returned from std::async offers the get function. The get func‐\ntion is even more important if doAsyncWork emits an exception, because get pro‐\nvides access to that, too. With the thread-based approach, if doAsyncWork throws, the\nprogram dies (via a call to std::terminate).\nA more fundamental difference between thread-based and task-based programming\nis the higher level of abstraction that task-based embodies. It frees you from the\ndetails of thread management, an observation that reminds me that I need to summa‐\nrize the three meanings of “thread” in concurrent C++ software:\n• Hardware threads are the threads that actually perform computation. Contempo‐\nrary machine architectures offer one or more hardware threads per CPU core.\n• Software threads (also known as OS threads or system threads) are the threads\nthat the operating system1 manages across all processes and schedules for execu‐\ntion on hardware threads. It’s typically possible to create more software threads\nthan hardware threads, because when a software thread is blocked (e.g., on I/O or\nwaiting for a mutex or condition variable), throughput can be improved by exe‐\ncuting other, unblocked, threads.\n• std::threads are objects in a C++ process that act as handles to underlying\nsoftware threads. Some std::thread objects represent “null” handles, i.e., corre‐\nspond to no software thread, because they’re in a default-constructed state\n(hence have no function to execute), have been moved from (the moved-to\nstd::thread then acts as the handle to the underlying software thread), have\nbeen joined (the function they were to run has finished), or have been detached\n(the connection between them and their underlying software thread has been\nsevered).\nSoftware threads are a limited resource. If you try to create more than the system can\nprovide, a std::system_error exception is thrown. This is true even if the function\nyou want to run can’t throw. For example, even if doAsyncWork is noexcept,\n242 \n| \nItem 35\nwww.it-ebooks.info\n",
      "content_length": 2652,
      "extraction_method": "Direct"
    },
    {
      "page_number": 261,
      "chapter": null,
      "content": "int doAsyncWork() noexcept;          // see Item 14 for noexcept\nthis statement could result in an exception:\nstd::thread t(doAsyncWork);          // throws if no more\n                                     // threads are available\nWell-written software must somehow deal with this possibility, but how? One\napproach is to run doAsyncWork on the current thread, but that could lead to unbal‐\nanced loads and, if the current thread is a GUI thread, responsiveness issues. Another\noption is to wait for some existing software threads to complete and then try to create\na new std::thread again, but it’s possible that the existing threads are waiting for an\naction that doAsyncWork is supposed to perform (e.g., produce a result or notify a\ncondition variable).\nEven if you don’t run out of threads, you can have trouble with oversubscription.\nThat’s when there are more ready-to-run (i.e., unblocked) software threads than\nhardware threads. When that happens, the thread scheduler (typically part of the OS)\ntime-slices the software threads on the hardware. When one thread’s time-slice is fin‐\nished and another’s begins, a context switch is performed. Such context switches\nincrease the overall thread management overhead of the system, and they can be par‐\nticularly costly when the hardware thread on which a software thread is scheduled is\non a different core than was the case for the software thread during its last time-slice.\nIn that case, (1) the CPU caches are typically cold for that software thread (i.e., they\ncontain little data and few instructions useful to it) and (2) the running of the “new”\nsoftware thread on that core “pollutes” the CPU caches for “old” threads that had\nbeen running on that core and are likely to be scheduled to run there again.\nAvoiding oversubscription is difficult, because the optimal ratio of software to hard‐\nware threads depends on how often the software threads are runnable, and that can\nchange dynamically, e.g., when a program goes from an I/O-heavy region to a\ncomputation-heavy region. The best ratio of software to hardware threads is also\ndependent on the cost of context switches and how effectively the software threads\nuse the CPU caches. Furthermore, the number of hardware threads and the details of\nthe CPU caches (e.g., how large they are and their relative speeds) depend on the\nmachine architecture, so even if you tune your application to avoid oversubscription\n(while still keeping the hardware busy) on one platform, there’s no guarantee that\nyour solution will work well on other kinds of machines.\nYour life will be easier if you dump these problems on somebody else, and using\nstd::async does exactly that:\nauto fut = std::async(doAsyncWork);   // onus of thread mgmt is\n                                      // on implementer of\n                                      // the Standard Library\nItem 35 \n| \n243\nwww.it-ebooks.info\n",
      "content_length": 2896,
      "extraction_method": "Direct"
    },
    {
      "page_number": 262,
      "chapter": null,
      "content": "This call shifts the thread management responsibility to the implementer of the C++\nStandard Library. For example, the likelihood of receiving an out-of-threads excep‐\ntion is significantly reduced, because this call will probably never yield one. “How can\nthat be?” you might wonder. “If I ask for more software threads than the system can\nprovide, why does it matter whether I do it by creating std::threads or by calling\nstd::async?” It matters, because std::async, when called in this form (i.e., with\nthe default launch policy—see Item 36), doesn’t guarantee that it will create a new\nsoftware thread. Rather, it permits the scheduler to arrange for the specified function\n(in this example, doAsyncWork) to be run on the thread requesting doAsyncWork’s\nresult (i.e., on the thread calling get or wait on fut), and reasonable schedulers take\nadvantage of that freedom if the system is oversubscribed or is out of threads.\nIf you pulled this “run it on the thread needing the result” trick yourself, I remarked\nthat it could lead to load-balancing issues, and those issues don’t go away simply\nbecause it’s std::async and the runtime scheduler that confront them instead of\nyou. When it comes to load balancing, however, the runtime scheduler is likely to\nhave a more comprehensive picture of what’s happening on the machine than you\ndo, because it manages the threads from all processes, not just the one your code is\nrunning in.\nWith std::async, responsiveness on a GUI thread can still be problematic, because\nthe scheduler has no way of knowing which of your threads has tight responsiveness\nrequirements. In that case, you’ll want to pass the std::launch::async launch pol‐\nicy to std::async. That will ensure that the function you want to run really executes\non a different thread (see Item 36).\nState-of-the-art thread schedulers employ system-wide thread pools to avoid over‐\nsubscription, and they improve load balancing across hardware cores through work-\nstealing algorithms. The C++ Standard does not require the use of thread pools or\nwork-stealing, and, to be honest, there are some technical aspects of the C++11 con‐\ncurrency specification that make it more difficult to employ them than we’d like.\nNevertheless, some vendors take advantage of this technology in their Standard\nLibrary implementations, and it’s reasonable to expect that progress will continue in\nthis area. If you take a task-based approach to your concurrent programming, you\nautomatically reap the benefits of such technology as it becomes more widespread. If,\non the other hand, you program directly with std::threads, you assume the burden\nof dealing with thread exhaustion, oversubscription, and load balancing yourself, not\nto mention how your solutions to these problems mesh with the solutions imple‐\nmented in programs running in other processes on the same machine.\nCompared to thread-based programming, a task-based design spares you the travails\nof manual thread management, and it provides a natural way to examine the results\nof asynchronously executed functions (i.e., return values or exceptions). Neverthe‐\n244 \n| \nItem 35\nwww.it-ebooks.info\n",
      "content_length": 3146,
      "extraction_method": "Direct"
    },
    {
      "page_number": 263,
      "chapter": null,
      "content": "less, there are some situations where using threads directly may be appropriate. They\ninclude:\n• You need access to the API of the underlying threading implementation. The\nC++ concurrency API is typically implemented using a lower-level platform-\nspecific API, usually pthreads or Windows’ Threads. Those APIs are currently\nricher than what C++ offers. (For example, C++ has no notion of thread priori‐\nties or affinities.) To provide access to the API of the underlying threading\nimplementation, std::thread objects typically offer the native_handle mem‐\nber function. There is no counterpart to this functionality for std::futures (i.e.,\nfor what std::async returns).\n• You need to and are able to optimize thread usage for your application. This\ncould be the case, for example, if you’re developing server software with a known\nexecution profile that will be deployed as the only significant process on a\nmachine with fixed hardware characteristics.\n• You need to implement threading technology beyond the C++ concurrency\nAPI, e.g., thread pools on platforms where your C++ implementations don’t\noffer them.\nThese are uncommon cases, however. Most of the time, you should choose task-\nbased designs instead of programming with threads.\nThings to Remember\n• The std::thread API offers no direct way to get return values from asyn‐\nchronously run functions, and if those functions throw, the program is termi‐\nnated.\n• Thread-based programming calls for manual management of thread exhaus‐\ntion, oversubscription, load balancing, and adaptation to new platforms.\n• Task-based programming via std::async with the default launch policy han‐\ndles most of these issues for you.\nItem 36: Specify std::launch::async if\nasynchronicity is essential.\nWhen you call std::async to execute a function (or other callable object), you’re\ngenerally intending to run the function asynchronously. But that’s not necessarily\nwhat you’re asking std::async to do. You’re really requesting that the function be\nrun in accord with a std::async launch policy. There are two standard policies, each\nItem 35 \n| \n245\nwww.it-ebooks.info\n",
      "content_length": 2111,
      "extraction_method": "Direct"
    },
    {
      "page_number": 264,
      "chapter": null,
      "content": "2 This is a simplification. What matters isn’t the future on which get or wait is invoked, it’s the shared state to\nwhich the future refers. (Item 38 discusses the relationship between futures and shared states.) Because\nstd::futures support moving and can also be used to construct std::shared_futures, and because\nstd::shared_futures can be copied, the future object referring to the shared state arising from the call to\nstd::async to which f was passed is likely to be different from the one returned by std::async. That’s a\nmouthful, however, so it’s common to fudge the truth and simply talk about invoking get or wait on the\nfuture returned from std::async.\nrepresented by an enumerator in the std::launch scoped enum. (See Item 10 for\ninformation on scoped enums.) Assuming a function f is passed to std::async for\nexecution,\n• The std::launch::async launch policy means that f must be run asynchro‐\nnously, i.e., on a different thread.\n• The std::launch::deferred launch policy means that f may run only when\nget or wait is called on the future returned by std::async.2 That is, f’s execu‐\ntion is deferred until such a call is made. When get or wait is invoked, f will\nexecute synchronously, i.e., the caller will block until f finishes running. If nei‐\nther get nor wait is called, f will never run.\nPerhaps surprisingly, std::async’s default launch policy—the one it uses if you\ndon’t expressly specify one—is neither of these. Rather, it’s these or-ed together. The\nfollowing two calls have exactly the same meaning:\nauto fut1 = std::async(f);                     // run f using\n                                               // default launch\n                                               // policy\nauto fut2 = std::async(std::launch::async |    // run f either\n                       std::launch::deferred,  // async or\n                       f);                     // deferred\nThe default policy thus permits f to be run either asynchronously or synchronously.\nAs Item 35 points out, this flexibility permits std::async and the thread-\nmanagement components of the Standard Library to assume responsibility for thread\ncreation and destruction, avoidance of oversubscription, and load balancing. That’s\namong the things that make concurrent programming with std::async so conve‐\nnient.\nBut using std::async with the default launch policy has some interesting implica‐\ntions. Given a thread t executing this statement,\nauto fut = std::async(f);   // run f using default launch policy\n246 \n| \nItem 36\nwww.it-ebooks.info\n",
      "content_length": 2535,
      "extraction_method": "Direct"
    },
    {
      "page_number": 265,
      "chapter": null,
      "content": "• It’s not possible to predict whether f will run concurrently with t, because f\nmight be scheduled to run deferred.\n• It’s not possible to predict whether f runs on a thread different from the\nthread invoking get or wait on fut. If that thread is t, the implication is that\nit’s not possible to predict whether f runs on a thread different from t.\n• It may not be possible to predict whether f runs at all, because it may not be\npossible to guarantee that get or wait will be called on fut along every path\nthrough the program.\nThe default launch policy’s scheduling flexibility often mixes poorly with the use of\nthread_local variables, because it means that if f reads or writes such thread-local\nstorage (TLS), it’s not possible to predict which thread’s variables will be accessed:\nauto fut = std::async(f);        // TLS for f possibly for\n                                 // independent thread, but\n                                 // possibly for thread\n                                 // invoking get or wait on fut\nIt also affects wait-based loops using timeouts, because calling wait_for or\nwait_until on a task (see Item 35) that’s deferred yields the value\nstd::launch::deferred. This means that the following loop, which looks like it\nshould eventually terminate, may, in reality, run forever:\nusing namespace std::literals;        // for C++14 duration\n                                      // suffixes; see Item 34\nvoid f()                              // f sleeps for 1 second,\n{                                     // then returns\n  std::this_thread::sleep_for(1s);\n}\nauto fut = std::async(f);             // run f asynchronously\n                                      // (conceptually)\nwhile (fut.wait_for(100ms) !=         // loop until f has\n       std::future_status::ready)     // finished running...\n{                                     // which may never happen!\n  …\n}\nItem 36 \n| \n247\nwww.it-ebooks.info\n",
      "content_length": 1930,
      "extraction_method": "Direct"
    },
    {
      "page_number": 266,
      "chapter": null,
      "content": "If f runs concurrently with the thread calling std::async (i.e., if the launch policy\nchosen for f is std::launch::async), there’s no problem here (assuming f\neventually finishes), but if f is deferred, fut.wait_for will always return std::\nfuture_status::deferred. That will never be equal to std::future_status::\nready, so the loop will never terminate.\nThis kind of bug is easy to overlook during development and unit testing, because it\nmay manifest itself only under heavy loads. Those are the conditions that push the\nmachine towards oversubscription or thread exhaustion, and that’s when a task may\nbe most likely to be deferred. After all, if the hardware isn’t threatened by oversub‐\nscription or thread exhaustion, there’s no reason for the runtime system not to sched‐\nule the task for concurrent execution.\nThe fix is simple: just check the future corresponding to the std::async call to see\nwhether the task is deferred, and, if so, avoid entering the timeout-based loop.\nUnfortunately, there’s no direct way to ask a future whether its task is deferred.\nInstead, you have to call a timeout-based function—a function such as wait_for. In\nthis case, you don’t really want to wait for anything, you just want to see if the return\nvalue is std::future_status::deferred, so stifle your mild disbelief at the neces‐\nsary circumlocution and call wait_for with a zero timeout:\nauto fut = std::async(f);                  // as above\nif (fut.wait_for(0s) ==                    // if task is\n    std::future_status::deferred)          // deferred...\n{\n                        // ...use wait or get on fut\n  …                     // to call f synchronously\n} else {                // task isn't deferred\n  while (fut.wait_for(100ms) !=            // infinite loop not\n         std::future_status::ready) {      // possible (assuming\n                                           // f finishes)\n    …                  // task is neither deferred nor ready,\n                       // so do concurrent work until it's ready\n  }\n  …                    // fut is ready\n}\n248 \n| \nItem 36\nwww.it-ebooks.info\n",
      "content_length": 2100,
      "extraction_method": "Direct"
    },
    {
      "page_number": 267,
      "chapter": null,
      "content": "The upshot of these various considerations is that using std::async with the default\nlaunch policy for a task is fine as long as the following conditions are fulfilled:\n• The task need not run concurrently with the thread calling get or wait.\n• It doesn’t matter which thread’s thread_local variables are read or written.\n• Either there’s a guarantee that get or wait will be called on the future returned\nby std::async or it’s acceptable that the task may never execute.\n• Code using wait_for or wait_until takes the possibility of deferred status into\naccount.\nIf any of these conditions fails to hold, you probably want to guarantee that\nstd::async will schedule the task for truly asynchronous execution. The way to do\nthat is to pass std::launch::async as the first argument when you make the call:\nauto fut = std::async(std::launch::async, f);  // launch f\n                                               // asynchronously\nIn fact, having a function that acts like std::async, but that automatically uses\nstd::launch::async as the launch policy, is a convenient tool to have around, so\nit’s nice that it’s easy to write. Here’s the C++11 version:\ntemplate<typename F, typename... Ts>\ninline\nstd::future<typename std::result_of<F(Ts...)>::type>\nreallyAsync(F&& f, Ts&&... params)       // return future\n{                                        // for asynchronous\n  return std::async(std::launch::async,  // call to f(params...)\n                    std::forward<F>(f),\n                    std::forward<Ts>(params)...);\n}\nThis function receives a callable object f and zero or more parameters params and\nperfect-forwards them (see Item 25) to std::async, passing std::launch::async\nas the launch policy. Like std::async, it returns a std::future for the result of\ninvoking f on params. Determining the type of that result is easy, because the type\ntrait std::result_of gives it to you. (See Item 9 for general information on type\ntraits.)\nreallyAsync is used just like std::async:\nauto fut = reallyAsync(f);         // run f asynchronously;\n                                   // throw if std::async\n                                   // would throw\nItem 36 \n| \n249\nwww.it-ebooks.info\n",
      "content_length": 2187,
      "extraction_method": "Direct"
    },
    {
      "page_number": 268,
      "chapter": null,
      "content": "In C++14, the ability to deduce reallyAsync’s return type streamlines the function\ndeclaration:\ntemplate<typename F, typename... Ts>\ninline\nauto                                           // C++14\nreallyAsync(F&& f, Ts&&... params)\n{\n  return std::async(std::launch::async,\n                    std::forward<F>(f),\n                    std::forward<Ts>(params)...);\n}\nThis version makes it crystal clear that reallyAsync does nothing but invoke\nstd::async with the std::launch::async launch policy.\nThings to Remember\n• The default launch policy for std::async permits both asynchronous and\nsynchronous task execution.\n• This flexibility leads to uncertainty when accessing thread_locals, implies\nthat the task may never execute, and affects program logic for timeout-based\nwait calls.\n• Specify std::launch::async if asynchronous task execution is essential.\nItem 37: Make std::threads unjoinable on all paths.\nEvery std::thread object is in one of two states: joinable or unjoinable. A joinable\nstd::thread corresponds to an underlying asynchronous thread of execution that is\nor could be running. A std::thread corresponding to an underlying thread that’s\nblocked or waiting to be scheduled is joinable, for example. std::thread objects cor‐\nresponding to underlying threads that have run to completion are also considered\njoinable.\nAn unjoinable std::thread is what you’d expect: a std::thread that’s not joinable.\nUnjoinable std::thread objects include:\n• Default-constructed std::threads. Such std::threads have no function to\nexecute, hence don’t correspond to an underlying thread of execution.\n250 \n| \nItem 36\nwww.it-ebooks.info\n",
      "content_length": 1635,
      "extraction_method": "Direct"
    },
    {
      "page_number": 269,
      "chapter": null,
      "content": "• std::thread objects that have been moved from. The result of a move is that\nthe underlying thread of execution a std::thread used to correspond to (if any)\nnow corresponds to a different std::thread.\n• std::threads that have been joined. After a join, the std::thread object no\nlonger corresponds to the underlying thread of execution that has finished run‐\nning.\n• std::threads that have been detached. A detach severs the connection\nbetween a std::thread object and the underlying thread of execution it corre‐\nsponds to.\nOne reason a std::thread’s joinability is important is that if the destructor for a\njoinable thread is invoked, execution of the program is terminated. For example, sup‐\npose we have a function doWork that takes a filtering function, filter, and a maxi‐\nmum value, maxVal, as parameters. doWork checks to make sure that all conditions\nnecessary for its computation are satisfied, then performs the computation with all\nthe values between 0 and maxVal that pass the filter. If it’s time-consuming to do the\nfiltering and it’s also time-consuming to determine whether doWork’s conditions are\nsatisfied, it would be reasonable to do those two things concurrently.\nOur preference would be to employ a task-based design for this (see Item 35), but\nlet’s assume we’d like to set the priority of the thread doing the filtering. Item 35\nexplains that that requires use of the thread’s native handle, and that’s accessible only\nthrough the std::thread API; the task-based API (i.e., futures) doesn’t provide it.\nOur approach will therefore be based on threads, not tasks.\nWe could come up with code like this:\nconstexpr auto tenMillion = 10000000;         // see Item 15\n                                              // for constexpr\nbool doWork(std::function<bool(int)> filter,  // returns whether\n            int maxVal = tenMillion)          // computation was\n{                                             // performed; see\n                                              // Item 2 for\n                                              // std::function\n  std::vector<int> goodVals;                  // values that\n                                              // satisfy filter\n  std::thread t([&filter, maxVal, &goodVals]  // populate\n                {                             // goodVals\n                  for (auto i = 0; i <= maxVal; ++i)\n                   { if (filter(i)) goodVals.push_back(i); }\nItem 37 \n| \n251\nwww.it-ebooks.info\n",
      "content_length": 2458,
      "extraction_method": "Direct"
    },
    {
      "page_number": 270,
      "chapter": null,
      "content": "                });\n  auto nh = t.native_handle();                // use t's native\n  …                                           // handle to set\n                                              // t's priority\n  if (conditionsAreSatisfied()) {\n    t.join();                                 // let t finish\n    performComputation(goodVals);\n    return true;                              // computation was\n  }                                           // performed\n  return false;                               // computation was\n}                                             // not performed\nBefore I explain why this code is problematic, I’ll remark that tenMillion’s initializ‐\ning value can be made more readable in C++14 by taking advantage of C++14’s abil‐\nity to use an apostrophe as a digit separator:\nconstexpr auto tenMillion = 10'000'000;       // C++14\nI’ll also remark that setting t’s priority after it has started running is a bit like closing\nthe proverbial barn door after the equally proverbial horse has bolted. A better design\nwould be to start t in a suspended state (thus making it possible to adjust its priority\nbefore it does any computation), but I don’t want to distract you with that code. If\nyou’re more distracted by the code’s absence, turn to Item 39, because it shows how\nto start threads suspended.\nBut back to doWork. If conditionsAreSatisfied() returns true, all is well, but if it\nreturns false or throws an exception, the std::thread object t will be joinable\nwhen its destructor is called at the end of doWork. That would cause program execu‐\ntion to be terminated.\nYou might wonder why the std::thread destructor behaves this way. It’s because\nthe two other obvious options are arguably worse. They are:\n• An implicit join. In this case, a std::thread’s destructor would wait for its\nunderlying asynchronous thread of execution to complete. That sounds reason‐\nable, but it could lead to performance anomalies that would be difficult to track\ndown. For example, it would be counterintuitive that doWork would wait for its\nfilter to be applied to all values if conditionsAreSatisfied() had already\nreturned false.\n• An implicit detach. In this case, a std::thread’s destructor would sever the\nconnection between the std::thread object and its underlying thread of execu‐\ntion. The underlying thread would continue to run. This sounds no less reason‐\n252 \n| \nItem 37\nwww.it-ebooks.info\n",
      "content_length": 2422,
      "extraction_method": "Direct"
    },
    {
      "page_number": 271,
      "chapter": null,
      "content": "able than the join approach, but the debugging problems it can lead to are\nworse. In doWork, for example, goodVals is a local variable that is captured by\nreference. It’s also modified inside the lambda (via the call to push_back). Sup‐\npose, then, that while the lambda is running asynchronously, conditionsAreSa\ntisfied() returns false. In that case, doWork would return, and its local\nvariables (including goodVals) would be destroyed. Its stack frame would be\npopped, and execution of its thread would continue at doWork’s call site.\nStatements following that call site would, at some point, make additional func‐\ntion calls, and at least one such call would probably end up using some or all of\nthe memory that had once been occupied by the doWork stack frame. Let’s call\nsuch a function f. While f was running, the lambda that doWork initiated would\nstill be running asynchronously. That lambda could call push_back on the stack\nmemory that used to be goodVals but that is now somewhere inside f’s stack\nframe. Such a call would modify the memory that used to be goodVals, and that\nmeans that from f’s perspective, the content of memory in its stack frame could\nspontaneously change! Imagine the fun you’d have debugging that.\nThe Standardization Committee decided that the consequences of destroying a joina‐\nble thread were sufficiently dire that they essentially banned it (by specifying that\ndestruction of a joinable thread causes program termination).\nThis puts the onus on you to ensure that if you use a std::thread object, it’s made\nunjoinable on every path out of the scope in which it’s defined. But covering every\npath can be complicated. It includes flowing off the end of the scope as well as jump‐\ning out via a return, continue, break, goto or exception. That can be a lot of paths.\nAny time you want to perform some action along every path out of a block, the nor‐\nmal approach is to put that action in the destructor of a local object. Such objects are\nknown as RAII objects, and the classes they come from are known as RAII classes.\n(RAII itself stands for “Resource Acquisition Is Initialization,” although the crux of\nthe technique is destruction, not initialization). RAII classes are common in the Stan‐\ndard Library. Examples include the STL containers (each container’s destructor\ndestroys the container’s contents and releases its memory), the standard smart point‐\ners (Items 18–20 explain that std::unique_ptr’s destructor invokes its deleter on\nthe object it points to, and the destructors in std::shared_ptr and std::weak_ptr\ndecrement reference counts), std::fstream objects (their destructors close the files\nthey correspond to), and many more. And yet there is no standard RAII class for\nstd::thread objects, perhaps because the Standardization Committee, having rejec‐\nted both join and detach as default options, simply didn’t know what such a class\nshould do. \nItem 37 \n| \n253\nwww.it-ebooks.info\n",
      "content_length": 2938,
      "extraction_method": "Direct"
    },
    {
      "page_number": 272,
      "chapter": null,
      "content": "Fortunately, it’s not difficult to write one yourself. For example, the following class\nallows callers to specify whether join or detach should be called when a Threa\ndRAII object (an RAII object for a std::thread) is destroyed:\nclass ThreadRAII {\npublic:\n  enum class DtorAction { join, detach };    // see Item 10 for\n                                             // enum class info\n  ThreadRAII(std::thread&& t, DtorAction a)  // in dtor, take\n  : action(a), t(std::move(t)) {}            // action a on t\n  \n  ~ThreadRAII()\n  {                                          // see below for\n    if (t.joinable()) {                      // joinability test\n      if (action == DtorAction::join) {\n        t.join();\n      } else {\n        t.detach();\n      }\n      \n    }\n  }\n  std::thread& get() { return t; }           // see below\nprivate:\n  DtorAction action;\n  std::thread t;\n};\nI hope this code is largely self-explanatory, but the following points may be helpful:\n• The constructor accepts only std::thread rvalues, because we want to move the\npassed-in std::thread into the ThreadRAII object. (Recall that std::thread\nobjects aren’t copyable.)\n• The parameter order in the constructor is designed to be intuitive to callers\n(specifying the std::thread first and the destructor action second makes more\nsense than vice versa), but the member initialization list is designed to match the\norder of the data members’ declarations. That order puts the std::thread object\nlast. In this class, the order makes no difference, but in general, it’s possible for\nthe initialization of one data member to depend on another, and because\nstd::thread objects may start running a function immediately after they are\n254 \n| \nItem 37\nwww.it-ebooks.info\n",
      "content_length": 1739,
      "extraction_method": "Direct"
    },
    {
      "page_number": 273,
      "chapter": null,
      "content": "initialized, it’s a good habit to declare them last in a class. That guarantees that at\nthe time they are constructed, all the data members that precede them have\nalready been initialized and can therefore be safely accessed by the asynchro‐\nnously running thread that corresponds to the std::thread data member.\n• ThreadRAII offers a get function to provide access to the underlying\nstd::thread object. This is analogous to the get functions offered by the stan‐\ndard smart pointer classes that give access to their underlying raw pointers. Pro‐\nviding get avoids the need for ThreadRAII to replicate the full std::thread\ninterface, and it also means that ThreadRAII objects can be used in contexts\nwhere std::thread objects are required.\n• Before the ThreadRAII destructor invokes a member function on the\nstd::thread object t, it checks to make sure that t is joinable. This is necessary,\nbecause invoking join or detach on an unjoinable thread yields undefined\nbehavior. It’s possible that a client constructed a std::thread, created a\nThreadRAII object from it, used get to acquire access to t, and then did a move\nfrom t or called join or detach on it. Each of those actions would render t\nunjoinable.\nIf you’re worried that in this code,\nif (t.joinable()) {\n  if (action == DtorAction::join) {\n    t.join();\n  } else {\n    t.detach();\n  }\n}\na race exists, because between execution of t.joinable() and invocation of\njoin or detach, another thread could render t unjoinable, your intuition is\ncommendable, but your fears are unfounded. A std::thread object can change\nstate from joinable to unjoinable only through a member function call, e.g., join,\ndetach, or a move operation. At the time a ThreadRAII object’s destructor is\ninvoked, no other thread should be making member function calls on that object.\nIf there are simultaneous calls, there is certainly a race, but it isn’t inside the\ndestructor, it’s in the client code that is trying to invoke two member functions\n(the destructor and something else) on one object at the same time. In general,\nsimultaneous member function calls on a single object are safe only if all are to\nconst member functions (see Item 16).\nEmploying ThreadRAII in our doWork example would look like this:\nItem 37 \n| \n255\nwww.it-ebooks.info\n",
      "content_length": 2280,
      "extraction_method": "Direct"
    },
    {
      "page_number": 274,
      "chapter": null,
      "content": "bool doWork(std::function<bool(int)> filter,  // as before\n            int maxVal = tenMillion)\n{\n  std::vector<int> goodVals;                  // as before\n  ThreadRAII t(                               // use RAII object\n    std::thread([&filter, maxVal, &goodVals]\n                {                             \n                  for (auto i = 0; i <= maxVal; ++i)\n                    { if (filter(i)) goodVals.push_back(i); }\n                }),\n                ThreadRAII::DtorAction::join  // RAII action\n  );\n  auto nh = t.get().native_handle();\n  …\n  if (conditionsAreSatisfied()) {\n    t.get().join();\n    performComputation(goodVals);\n    return true;\n  }\n  return false;\n}\nIn this case, we’ve chosen to do a join on the asynchronously running thread in the\nThreadRAII destructor, because, as we saw earlier, doing a detach could lead to\nsome truly nightmarish debugging. We also saw earlier that doing a join could lead\nto performance anomalies (that, to be frank, could also be unpleasant to debug), but\ngiven a choice between undefined behavior (which detach would get us), program\ntermination (which use of a raw std::thread would yield), or performance anoma‐\nlies, performance anomalies seems like the best of a bad lot.\nAlas, Item 39 demonstrates that using ThreadRAII to perform a join on\nstd::thread destruction can sometimes lead not just to a performance anomaly, but\nto a hung program. The “proper” solution to these kinds of problems would be to\ncommunicate to the asynchronously running lambda that we no longer need its work\nand that it should return early, but there’s no support in C++11 for interruptible\n256 \n| \nItem 37\nwww.it-ebooks.info\n",
      "content_length": 1667,
      "extraction_method": "Direct"
    },
    {
      "page_number": 275,
      "chapter": null,
      "content": "3 You’ll find a nice treatment in Anthony Williams’ C++ Concurrency in Action (Manning Publications, 2012),\nsection 9.2.\nthreads. They can be implemented by hand, but that’s a topic beyond the scope of\nthis  book.3\nItem 17 explains that because ThreadRAII declares a destructor, there will be no\ncompiler-generated move operations, but there is no reason ThreadRAII objects\nshouldn’t be movable. If compilers were to generate these functions, the functions\nwould do the right thing, so explicitly requesting their creation isappropriate:\nclass ThreadRAII {\npublic:\n  enum class DtorAction { join, detach };           // as before\n  ThreadRAII(std::thread&& t, DtorAction a)         // as before\n  : action(a), t(std::move(t)) {}\n  ~ThreadRAII()\n  {\n    …                                               // as before\n  }\n  ThreadRAII(ThreadRAII&&) = default;               // support\n  ThreadRAII& operator=(ThreadRAII&&) = default;    // moving\n  std::thread& get() { return t; }                  // as before\nprivate:                                            // as before\n  DtorAction action;\n  std::thread t;\n};\nThings to Remember\n• Make std::threads unjoinable on all paths.\n• join-on-destruction can lead to difficult-to-debug performance anomalies.\n• detach-on-destruction can lead to difficult-to-debug undefined behavior.\n• Declare std::thread objects last in lists of data members.\nItem 37 \n| \n257\nwww.it-ebooks.info\n",
      "content_length": 1425,
      "extraction_method": "Direct"
    },
    {
      "page_number": 276,
      "chapter": null,
      "content": "4 Item 39 explains that the kind of communications channel associated with a future can be employed for other\npurposes. For this Item, however, we’ll consider only its use as a mechanism for a callee to convey its result to\na caller.\nItem 38: Be aware of varying thread handle destructor\nbehavior.\nItem 37 explains that a joinable std::thread corresponds to an underlying system\nthread of execution. A future for a non-deferred task (see Item 36) has a similar rela‐\ntionship to a system thread. As such, both std::thread objects and future objects\ncan be thought of as handles to system threads.\nFrom this perspective, it’s interesting that std::threads and futures have such dif‐\nferent behaviors in their destructors. As noted in Item 37, destruction of a joinable\nstd::thread terminates your program, because the two obvious alternatives—an\nimplicit join and an implicit detach—were considered worse choices. Yet the\ndestructor for a future sometimes behaves as if it did an implicit join, sometimes as\nif it did an implicit detach, and sometimes neither. It never causes program termina‐\ntion. This thread handle behavioral bouillabaisse deserves closer examination.\nWe’ll begin with the observation that a future is one end of a communications chan‐\nnel through which a callee transmits a result to a caller.4 The callee (usually running\nasynchronously) writes the result of its computation into the communications chan‐\nnel (typically via a std::promise object), and the caller reads that result using a\nfuture. You can think of it as follows, where the dashed arrow shows the flow of\ninformation from callee to caller:\nCaller\nfuture\nCallee\n(typically)\nstd::promise\nBut where is the callee’s result stored? The callee could finish before the caller invokes\nget on a corresponding future, so the result can’t be stored in the callee’s\nstd::promise. That object, being local to the callee, would be destroyed when the\ncallee finished.\nThe result can’t be stored in the caller’s future, either, because (among other reasons)\na std::future may be used to create a std::shared_future (thus transferring\nownership of the callee’s result from the std::future to the std::shared_future),\nwhich may then be copied many times after the original std::future is destroyed.\nGiven that not all result types can be copied (i.e., move-only types) and that the result\n258 \n| \nItem 38\nwww.it-ebooks.info\n",
      "content_length": 2393,
      "extraction_method": "Direct"
    },
    {
      "page_number": 277,
      "chapter": null,
      "content": "must live at least as long as the last future referring to it, which of the potentially\nmany futures corresponding to the callee should be the one to contain its result?\nBecause neither objects associated with the callee nor objects associated with the\ncaller are suitable places to store the callee’s result, it’s stored in a location outside\nboth. This location is known as the shared state. The shared state is typically repre‐\nsented by a heap-based object, but its type, interface, and implementation are not\nspecified by the Standard. Standard Library authors are free to implement shared\nstates in any way they like.\nWe can envision the relationship among the callee, the caller, and the shared state as\nfollows, where dashed arrows once again represent the flow of information:\nCaller\nCallee’s\nResult\nShared State\nfuture\nCallee\n(typically)\nstd::promise\nThe existence of the shared state is important, because the behavior of a future’s\ndestructor—the topic of this Item—is determined by the shared state associated with\nthe future. In particular,\n• The destructor for the last future referring to a shared state for a non-\ndeferred task launched via std::async blocks until the task completes. In\nessence, the destructor for such a future does an implicit join on the thread on\nwhich the asynchronously executing task is running.\n• The destructor for all other futures simply destroys the future object. For\nasynchronously running tasks, this is akin to an implicit detach on the underly‐\ning thread. For deferred tasks for which this is the final future, it means that the\ndeferred task will never run.\nThese rules sound more complicated than they are. What we’re really dealing with is\na simple “normal” behavior and one lone exception to it. The normal behavior is that\na future’s destructor destroys the future object. That’s it. It doesn’t join with any‐\nthing, it doesn’t detach from anything, it doesn’t run anything. It just destroys the\nfuture’s data members. (Well, actually, it does one more thing. It decrements the ref‐\nerence count inside the shared state that’s manipulated by both the futures referring\nto it and the callee’s std::promise. This reference count makes it possible for the\nlibrary to know when the shared state can be destroyed. For general information\nabout reference counting, see Item 19.)\nThe exception to this normal behavior arises only for a future for which all of the fol‐\nlowing apply:\nItem 38 \n| \n259\nwww.it-ebooks.info\n",
      "content_length": 2469,
      "extraction_method": "Direct"
    },
    {
      "page_number": 278,
      "chapter": null,
      "content": "• It refers to a shared state that was created due to a call to std::async.\n• The task’s launch policy is std::launch::async (see Item 36), either because\nthat was chosen by the runtime system or because it was specified in the call to\nstd::async.\n• The future is the last future referring to the shared state. For std::futures,\nthis will always be the case. For std::shared_futures, if other std::shared_\nfutures refer to the same shared state as the future being destroyed, the future\nbeing destroyed follows the normal behavior (i.e., it simply destroys its data\nmembers).\nOnly when all of these conditions are fulfilled does a future’s destructor exhibit spe‐\ncial behavior, and that behavior is to block until the asynchronously running task\ncompletes. Practically speaking, this amounts to an implicit join with the thread\nrunning the std::async-created task.\nIt’s common to hear this exception to normal future destructor behavior summarized\nas “Futures from std::async block in their destructors.” To a first approximation,\nthat’s correct, but sometimes you need more than a first approximation. Now you\nknow the truth in all its glory and wonder.\nYour wonder may take a different form. It may be of the “I wonder why there’s a spe‐\ncial rule for shared states for non-deferred tasks that are launched by std::async”\nvariety. It’s a reasonable question. From what I can tell, the Standardization Commit‐\ntee wanted to avoid the problems associated with an implicit detach (see Item 37),\nbut they didn’t want to adopt as radical a policy as mandatory program termination\n(as they did for joinable std::threads—again, see Item 37), so they compromised\non an implicit join. The decision was not without controversy, and there was serious\ntalk about abandoning this behavior for C++14. In the end, no change was made, so\nthe behavior of destructors for futures is consistent in C++11 and C++14.\nThe API for futures offers no way to determine whether a future refers to a shared\nstate arising from a call to std::async, so given an arbitrary future object, it’s not\npossible to know whether it will block in its destructor waiting for an asynchronously\nrunning task to finish. This has some interesting implications:\n// this container might block in its dtor, because one or more\n// contained futures could refer to a shared state for a non-\n// deferred task launched via std::async\nstd::vector<std::future<void>> futs;   // see Item 39 for info\n                                       // on std::future<void>\nclass Widget {                         // Widget objects might\npublic:                                // block in their dtors\n260 \n| \nItem 38\nwww.it-ebooks.info\n",
      "content_length": 2673,
      "extraction_method": "Direct"
    },
    {
      "page_number": 279,
      "chapter": null,
      "content": "  …\nprivate:\n  std::shared_future<double> fut;\n};\nOf course, if you have a way of knowing that a given future does not satisfy the condi‐\ntions that trigger the special destructor behavior (e.g., due to program logic), you’re\nassured that that future won’t block in its destructor. For example, only shared states\narising from calls to std::async qualify for the special behavior, but there are other\nways that shared states get created. One is the use of std::packaged_task. A\nstd::packaged_task object prepares a function (or other callable object) for asyn‐\nchronous execution by wrapping it such that its result is put into a shared state. A\nfuture referring to that shared state can then be obtained via std::packaged_task’s\nget_future function:\nint calcValue();                      // func to run\nstd::packaged_task<int()>             // wrap calcValue so it\n  pt(calcValue);                      // can run asynchronously\nauto fut = pt.get_future();           // get future for pt\nAt this point, we know that the future fut doesn’t refer to a shared state created by a\ncall to std::async, so its destructor will behave normally.\nOnce created, the std::packaged_task pt can be run on a thread. (It could be run\nvia a call to std::async, too, but if you want to run a task using std::async, there’s\nlittle reason to create a std::packaged_task, because std::async does everything\nstd::packaged_task does before it schedules the task for execution.)\nstd::packaged_tasks aren’t copyable, so when pt is passed to the std::thread\nconstructor, it must be cast to an rvalue (via std::move—see Item 23):\nstd::thread t(std::move(pt));         // run pt on t\nThis example lends some insight into the normal behavior for future destructors, but\nit’s easier to see if the statements are put together inside a block:\n{                                     // begin block\n  std::packaged_task<int()>\n    pt(calcValue);\n  auto fut = pt.get_future();\nItem 38 \n| \n261\nwww.it-ebooks.info\n",
      "content_length": 1976,
      "extraction_method": "Direct"
    },
    {
      "page_number": 280,
      "chapter": null,
      "content": "  std::thread t(std::move(pt));\n  …                                   // see below\n}                                     // end block\nThe most interesting code here is the “…” that follows creation of the std::thread\nobject t and precedes the end of the block. What makes it interesting is what can\nhappen to t inside the “…” region. There are three basic possibilities:\n• Nothing happens to t. In this case, t will be joinable at the end of the scope.\nThat will cause the program to be terminated (see Item 37).\n• A join is done on t. In this case, there would be no need for fut to block in its\ndestructor, because the join is already present in the calling code.\n• A detach is done on t. In this case, there would be no need for fut to detach in\nits destructor, because the calling code already does that.\nIn other words, when you have a future corresponding to a shared state that arose\ndue to a std::packaged_task, there’s usually no need to adopt a special destruction\npolicy, because the decision among termination, joining, or detaching will be made in\nthe code that manipulates the std::thread on which the std::packaged_task is\ntypically run.\nThings to Remember\n• Future destructors normally just destroy the future’s data members.\n• The final future referring to a shared state for a non-deferred task launched\nvia std::async blocks until the task completes.\nItem 39: Consider void futures for one-shot event\ncommunication.\nSometimes it’s useful for a task to tell a second, asynchronously running task that a\nparticular event has occurred, because the second task can’t proceed until the event\nhas taken place. Perhaps a data structure has been initialized, a stage of computation\nhas been completed, or a significant sensor value has been detected. When that’s the\ncase, what’s the best way for this kind of inter-thread communication to take place?\nAn obvious approach is to use a condition variable (condvar). If we call the task that\ndetects the condition the detecting task and the task reacting to the condition the\n262 \n| \nItem 38\nwww.it-ebooks.info\n",
      "content_length": 2069,
      "extraction_method": "Direct"
    },
    {
      "page_number": 281,
      "chapter": null,
      "content": "reacting task, the strategy is simple: the reacting task waits on a condition variable,\nand the detecting thread notifies that condvar when the event occurs. Given\nstd::condition_variable cv;             // condvar for event\nstd::mutex m;                           // mutex for use with cv\nthe code in the detecting task is as simple as simple can be:\n…                                       // detect event\ncv.notify_one();                        // tell reacting task\nIf there were multiple reacting tasks to be notified, it would be appropriate to replace\nnotify_one with notify_all, but for now, we’ll assume there’s only one reacting\ntask.\nThe code for the reacting task is a bit more complicated, because before calling wait\non the condvar, it must lock a mutex through a std::unique_lock object. (Locking\na mutex before waiting on a condition variable is typical for threading libraries. The\nneed to lock the mutex through a std::unique_lock object is simply part of the\nC++11 API.) Here’s the conceptual approach:\n…                                      // prepare to react\n{                                      // open critical section\n  std::unique_lock<std::mutex> lk(m);  // lock mutex\n  cv.wait(lk);                         // wait for notify;\n                                       // this isn't correct!\n  …                                    // react to event\n                                       // (m is locked)\n}                                      // close crit. section;\n                                       // unlock m via lk's dtor\n…                                      // continue reacting\n                                       // (m now unlocked)\nThe first issue with this approach is what’s sometimes termed a code smell: even if the\ncode works, something doesn’t seem quite right. In this case, the odor emanates from\nthe need to use a mutex. Mutexes are used to control access to shared data, but it’s\nentirely possible that the detecting and reacting tasks have no need for such media‐\ntion. For example, the detecting task might be responsible for initializing a global\ndata structure, then turning it over to the reacting task for use. If the detecting task\nItem 39 \n| \n263\nwww.it-ebooks.info\n",
      "content_length": 2231,
      "extraction_method": "Direct"
    },
    {
      "page_number": 282,
      "chapter": null,
      "content": "never accesses the data structure after initializing it, and if the reacting task never\naccesses it before the detecting task indicates that it’s ready, the two tasks will stay out\nof each other’s way through program logic. There will be no need for a mutex. The\nfact that the condvar approach requires one leaves behind the unsettling aroma of\nsuspect design.\nEven if you look past that, there are two other problems you should definitely pay\nattention to:\n• If the detecting task notifies the condvar before the reacting task waits, the\nreacting task will hang. In order for notification of a condvar to wake another\ntask, the other task must be waiting on that condvar. If the detecting task hap‐\npens to execute the notification before the reacting task executes the wait, the\nreacting task will miss the notification, and it will wait forever.\n• The wait statement fails to account for spurious wakeups. A fact of life in\nthreading APIs (in many languages—not just C++) is that code waiting on a con‐\ndition variable may be awakened even if the condvar wasn’t notified. Such awak‐\nenings are known as spurious wakeups. Proper code deals with them by\nconfirming that the condition being waited for has truly occurred, and it does\nthis as its first action after waking. The C++ condvar API makes this exception‐\nally easy, because it permits a lambda (or other function object) that tests for the\nwaited-for condition to be passed to wait. That is, the wait call in the reacting\ntask could be written like this:\ncv.wait(lk,\n        []{ return whether the event has occurred; });\nTaking advantage of this capability requires that the reacting task be able to\ndetermine whether the condition it’s waiting for is true. But in the scenario we’ve\nbeen considering, the condition it’s waiting for is the occurrence of an event that\nthe detecting thread is responsible for recognizing. The reacting thread may have\nno way of determining whether the event it’s waiting for has taken place. That’s\nwhy it’s waiting on a condition variable!\nThere are many situations where having tasks communicate using a condvar is a\ngood fit for the problem at hand, but this doesn’t seem to be one of them.\nFor many developers, the next trick in their bag is a shared boolean flag. The flag is\ninitially false. When the detecting thread recognizes the event it’s looking for, it sets\nthe flag:\nstd::atomic<bool> flag(false);      // shared flag; see\n                                    // Item 40 for std::atomic\n…                                   // detect event\n264 \n| \nItem 39\nwww.it-ebooks.info\n",
      "content_length": 2580,
      "extraction_method": "Direct"
    },
    {
      "page_number": 283,
      "chapter": null,
      "content": "flag = true;                        // tell reacting task\nFor its part, the reacting thread simply polls the flag. When it sees that the flag is set,\nit knows that the event it’s been waiting for has occurred:\n…                                   // prepare to react\nwhile (!flag);                      // wait for event\n…                                   // react to event\nThis approach suffers from none of the drawbacks of the condvar-based design.\nThere’s no need for a mutex, no problem if the detecting task sets the flag before the\nreacting task starts polling, and nothing akin to a spurious wakeup. Good, good,\ngood.\nLess good is the cost of polling in the reacting task. During the time the task is wait‐\ning for the flag to be set, the task is essentially blocked, yet it’s still running. As such,\nit occupies a hardware thread that another task might be able to make use of, it incurs\nthe cost of a context switch each time it starts or completes its time-slice, and it could\nkeep a core running that might otherwise be shut down to save power. A truly\nblocked task would do none of these things. That’s an advantage of the condvar-\nbased approach, because a task in a wait call is truly blocked.\nIt’s common to combine the condvar and flag-based designs. A flag indicates whether\nthe event of interest has occurred, but access to the flag is synchronized by a mutex.\nBecause the mutex prevents concurrent access to the flag, there is, as Item 40\nexplains, no need for the flag to be std::atomic; a simple bool will do. The detect‐\ning task would then look like this:\nstd::condition_variable cv;           // as before\nstd::mutex m;\nbool flag(false);                     // not std::atomic\n…                                     // detect event\n{\n  std::lock_guard<std::mutex> g(m);   // lock m via g's ctor\n  flag = true;                        // tell reacting task\n                                      // (part 1)\n}                                     // unlock m via g's dtor\nItem 39 \n| \n265\nwww.it-ebooks.info\n",
      "content_length": 2027,
      "extraction_method": "Direct"
    },
    {
      "page_number": 284,
      "chapter": null,
      "content": "cv.notify_one();                      // tell reacting task\n                                      // (part 2)\nAnd here’s the reacting task:\n…                                      // prepare to react\n{                                      // as before\n  std::unique_lock<std::mutex> lk(m);  // as before\n  cv.wait(lk, [] { return flag; });    // use lambda to avoid\n                                       // spurious wakeups\n  …                                    // react to event\n                                       // (m is locked)\n}\n…                                      // continue reacting\n                                       // (m now unlocked)\nThis approach avoids the problems we’ve discussed. It works regardless of whether\nthe reacting task waits before the detecting task notifies, it works in the presence of\nspurious wakeups, and it doesn’t require polling. Yet an odor remains, because the\ndetecting task communicates with the reacting task in a very curious fashion. Notify‐\ning the condition variable tells the reacting task that the event it’s been waiting for\nhas probably occurred, but the reacting task must check the flag to be sure. Setting\nthe flag tells the reacting task that the event has definitely occurred, but the detecting\ntask still has to notify the condition variable so that the reacting task will awaken and\ncheck the flag. The approach works, but it doesn’t seem terribly clean.\nAn alternative is to avoid condition variables, mutexes, and flags by having the react‐\ning task wait on a future that’s set by the detecting task. This may seem like an odd\nidea. After all, Item 38 explains that a future represents the receiving end of a com‐\nmunications channel from a callee to a (typically asynchronous) caller, and here\nthere’s no callee-caller relationship between the detecting and reacting tasks. How‐\never, Item 38 also notes that a communications channel whose transmitting end is a\nstd::promise and whose receiving end is a future can be used for more than just\ncallee-caller communication. Such a communications channel can be used in any sit‐\nuation where you need to transmit information from one place in your program to\nanother. In this case, we’ll use it to transmit information from the detecting task to\nthe reacting task, and the information we’ll convey will be that the event of interest\nhas taken place.\nThe design is simple. The detecting task has a std::promise object (i.e., the writing\nend of the communications channel), and the reacting task has a corresponding\n266 \n| \nItem 39\nwww.it-ebooks.info\n",
      "content_length": 2566,
      "extraction_method": "Direct"
    },
    {
      "page_number": 285,
      "chapter": null,
      "content": "future. When the detecting task sees that the event it’s looking for has occurred, it sets\nthe std::promise (i.e., writes into the communications channel). Meanwhile, the\nreacting task waits on its future. That wait blocks the reacting task until the\nstd::promise has been set.\nNow, both std::promise and futures (i.e., std::future and std::shared_future)\nare templates that require a type parameter. That parameter indicates the type of data\nto be transmitted through the communications channel. In our case, however, there’s\nno data to be conveyed. The only thing of interest to the reacting task is that its future\nhas been set. What we need for the std::promise and future templates is a type that\nindicates that no data is to be conveyed across the communications channel. That\ntype is void. The detecting task will thus use a std::promise<void>, and the react‐\ning task a std::future<void> or std::shared_future<void>. The detecting task\nwill set its std::promise<void> when the event of interest occurs, and the reacting\ntask will wait on its future. Even though the reacting task won’t receive any data\nfrom the detecting task, the communications channel will permit the reacting task to\nknow when the detecting task has “written” its void data by calling set_value on its\nstd::promise.\nSo given\nstd::promise<void> p;               // promise for\n                                    // communications channel\nthe detecting task’s code is trivial,\n…                                   // detect event\np.set_value();                      // tell reacting task\nand the reacting task’s code is equally simple:\n…                                   // prepare to react\np.get_future().wait();              // wait on future\n                                    // corresponding to p\n…                                   // react to event\nLike the approach using a flag, this design requires no mutex, works regardless of\nwhether the detecting task sets its std::promise before the reacting task waits, and\nis immune to spurious wakeups. (Only condition variables are susceptible to that\nproblem.) Like the condvar-based approach, the reacting task is truly blocked after\nmaking the wait call, so it consumes no system resources while waiting. Perfect,\nright?\nItem 39 \n| \n267\nwww.it-ebooks.info\n",
      "content_length": 2291,
      "extraction_method": "Direct"
    },
    {
      "page_number": 286,
      "chapter": null,
      "content": "Not exactly. Sure, a future-based approach skirts those shoals, but there are other\nhazards to worry about. For example, Item 38 explains that between a std::promise\nand a future is a shared state, and shared states are typically dynamically allocated.\nYou should therefore assume that this design incurs the cost of heap-based allocation\nand deallocation.\nPerhaps more importantly, a std::promise may be set only once. The communica‐\ntions channel between a std::promise and a future is a one-shot mechanism: it can’t\nbe used repeatedly. This is a notable difference from the condvar- and flag-based\ndesigns, both of which can be used to communicate multiple times. (A condvar can\nbe repeatedly notified, and a flag can always be cleared and set again.)\nThe one-shot restriction isn’t as limiting as you might think. Suppose you’d like to\ncreate a system thread in a suspended state. That is, you’d like to get all the overhead\nassociated with thread creation out of the way so that when you’re ready to execute\nsomething on the thread, the normal thread-creation latency will be avoided. Or you\nmight want to create a suspended thread so that you could configure it before letting\nit run. Such configuration might include things like setting its priority or core affin‐\nity. The C++ concurrency API offers no way to do those things, but std::thread\nobjects offer the native_handle member function, the result of which is intended to\ngive you access to the platform’s underlying threading API (usually POSIX threads or\nWindows threads). The lower-level API often makes it possible to configure thread\ncharacteristics such as priority and affinity.\nAssuming you want to suspend a thread only once (after creation, but before it’s run‐\nning its thread function), a design using a void future is a reasonable choice. Here’s\nthe essence of the technique:\nstd::promise<void> p;\nvoid react();                        // func for reacting task\nvoid detect()                        // func for detecting task\n{\n  std::thread t([]                   // create thread\n                {\n                  p.get_future().wait();     // suspend t until\n                  react();                   // future is set\n                });\n  …                                  // here, t is suspended\n                                     // prior to call to react\n  p.set_value();                     // unsuspend t (and thus\n                                     // call react)\n268 \n| \nItem 39\nwww.it-ebooks.info\n",
      "content_length": 2494,
      "extraction_method": "Direct"
    },
    {
      "page_number": 287,
      "chapter": null,
      "content": "5 A reasonable place to begin researching the matter is my 24 December 2013 blog post at The View From Aris‐\nteia, “ThreadRAII + Thread Suspension = Trouble?”\n  …                                  // do additional work\n  t.join();                          // make t unjoinable\n}                                    // (see Item 37)\nBecause it’s important that t become unjoinable on all paths out of detect, use of an\nRAII class like Item 37’s ThreadRAII seems like it would be advisable. Code like this\ncomes to mind:\nvoid detect()\n{\n  ThreadRAII tr(                          // use RAII object\n    std::thread([]\n                {                       \n                  p.get_future().wait();\n                  react();\n                }),\n    ThreadRAII::DtorAction::join          // risky! (see below)\n  );\n  …                                       // thread inside tr\n                                          // is suspended here\n  p.set_value();                          // unsuspend thread\n                                          // inside tr\n  …\n}\nThis looks safer than it is. The problem is that if in the first “…” region (the one with\nthe “thread inside tr is suspended here” comment), an exception is emitted,\nset_value will never be called on p. That means that the call to wait inside the\nlambda will never return. That, in turn, means that the thread running the lambda\nwill never finish, and that’s a problem, because the RAII object tr has been config‐\nured to perform a join on that thread in tr’s destructor. In other words, if an excep‐\ntion is emitted from the first “…” region of code, this function will hang, because tr’s\ndestructor will never complete.\nThere are ways to address this problem, but I’ll leave them in the form of the hal‐\nlowed exercise for the reader.5 Here, I’d like to show how the original code (i.e., not\nusing ThreadRAII) can be extended to suspend and then unsuspend not just one\nItem 39 \n| \n269\nwww.it-ebooks.info\n",
      "content_length": 1965,
      "extraction_method": "Direct"
    },
    {
      "page_number": 288,
      "chapter": null,
      "content": "reacting task, but many. It’s a simple generalization, because the key is to use\nstd::shared_futures instead of a std::future in the react code. Once you know\nthat the std::future’s share member function transfers ownership of its shared\nstate to the std::shared_future object produced by share, the code nearly writes\nitself. The only subtlety is that each reacting thread needs its own copy of the\nstd::shared_future that refers to the shared state, so the std::shared_future\nobtained from share is captured by value by the lambdas running on the reacting\nthreads:\nstd::promise<void> p;                // as before\nvoid detect()                        // now for multiple\n{                                    // reacting tasks\n  auto sf = p.get_future().share();  // sf's type is\n                                     // std::shared_future<void>\n  std::vector<std::thread> vt;              // container for\n                                            // reacting threads\n  for (int i = 0; i < threadsToRun; ++i) {\n    vt.emplace_back([sf]{ sf.wait();        // wait on local\n                          react(); });      // copy of sf; see\n  }                                         // Item 42 for info\n                                            // on emplace_back\n  …                                  // detect hangs if\n                                     // this \"…\" code throws!\n  p.set_value();                     // unsuspend all threads\n  …\n  for (auto& t : vt) {               // make all threads\n    t.join();                        // unjoinable; see Item 2\n  }                                  // for info on \"auto&\"\n}\nThe fact that a design using futures can achieve this effect is noteworthy, and that’s\nwhy you should consider it for one-shot event communication.\n270 \n| \nItem 39\nwww.it-ebooks.info\n",
      "content_length": 1815,
      "extraction_method": "Direct"
    },
    {
      "page_number": 289,
      "chapter": null,
      "content": "Things to Remember\n• For simple event communication, condvar-based designs require a superflu‐\nous mutex, impose constraints on the relative progress of detecting and react‐\ning tasks, and require reacting tasks to verify that the event has taken place.\n• Designs employing a flag avoid those problems, but are based on polling, not\nblocking.\n• A condvar and flag can be used together, but the resulting communications\nmechanism is somewhat stilted.\n• Using std::promises and futures dodges these issues, but the approach uses\nheap memory for shared states, and it’s limited to one-shot communication.\nItem 40: Use std::atomic for concurrency, volatile\nfor special memory.\nPoor volatile. So misunderstood. It shouldn’t even be in this chapter, because it has\nnothing to do with concurrent programming. But in other programming languages\n(e.g., Java and C#), it is useful for such programming, and even in C++, some compil‐\ners have imbued volatile with semantics that render it applicable to concurrent\nsoftware (but only when compiled with those compilers). It’s thus worthwhile to dis‐\ncuss volatile in a chapter on concurrency if for no other reason than to dispel the\nconfusion surrounding it.\nThe C++ feature that programmers sometimes confuse volatile with—the feature\nthat definitely does belong in this chapter—is the std::atomic template. Instantia‐\ntions \nof \nthis \ntemplate \n(e.g., \nstd::atomic<int>, \nstd::atomic<bool>,\nstd::atomic<Widget*>, etc.) offer operations that are guaranteed to be seen as\natomic by other threads. Once a std::atomic object has been constructed, opera‐\ntions on it behave as if they were inside a mutex-protected critical section, but the\noperations are generally implemented using special machine instructions that are\nmore efficient than would be the case if a mutex were employed.\nConsider this code using std::atomic:\nstd::atomic<int> ai(0);    // initialize ai to 0\nai = 10;                   // atomically set ai to 10\nstd::cout << ai;           // atomically read ai's value\n++ai;                      // atomically increment ai to 11\nItem 39 \n| \n271\nwww.it-ebooks.info\n",
      "content_length": 2115,
      "extraction_method": "Direct"
    },
    {
      "page_number": 290,
      "chapter": null,
      "content": "--ai;                      // atomically decrement ai to 10\nDuring execution of these statements, other threads reading ai may see only values\nof 0, 10, or 11. No other values are possible (assuming, of course, that this is the only\nthread modifying ai).\nTwo aspects of this example are worth noting. First, in the “std::cout << ai;” state‐\nment, the fact that ai is a std::atomic guarantees only that the read of ai is atomic.\nThere is no guarantee that the entire statement proceeds atomically. Between the\ntime ai’s value is read and operator<< is invoked to write it to the standard output,\nanother thread may have modified ai’s value. That has no effect on the behavior of\nthe statement, because operator<< for ints uses a by-value parameter for the int to\noutput (the outputted value will therefore be the one that was read from ai), but it’s\nimportant to understand that what’s atomic in that statement is nothing more than\nthe read of ai.\nThe second noteworthy aspect of the example is the behavior of the last two state‐\nments—the increment and decrement of ai. These are each read-modify-write\n(RMW) operations, yet they execute atomically. This is one of the nicest characteris‐\ntics of the std::atomic types: once a std::atomic object has been constructed, all\nmember functions on it, including those comprising RMW operations, are guaran‐\nteed to be seen by other threads as atomic.\nIn contrast, the corresponding code using volatile guarantees virtually nothing in a\nmultithreaded context:\nvolatile int vi(0);        // initialize vi to 0\nvi = 10;                   // set vi to 10\nstd::cout << vi;           // read vi's value\n++vi;                      // increment vi to 11\n--vi;                      // decrement vi to 10\nDuring execution of this code, if other threads are reading the value of vi, they may\nsee anything, e.g, -12, 68, 4090727—anything! Such code would have undefined\nbehavior, because these statements modify vi, so if other threads are reading vi at\nthe same time, there are simultaneous readers and writers of memory that’s neither\nstd::atomic nor protected by a mutex, and that’s the definition of a data race.\n272 \n| \nItem 40\nwww.it-ebooks.info\n",
      "content_length": 2185,
      "extraction_method": "Direct"
    },
    {
      "page_number": 291,
      "chapter": null,
      "content": "As a concrete example of how the behavior of std::atomics and volatiles can dif‐\nfer in a multithreaded program, consider a simple counter of each type that’s incre‐\nmented by multiple threads. We’ll initialize each to 0:\nstd::atomic<int> ac(0);    // \"atomic counter\"\nvolatile int vc(0);        // \"volatile counter\"\nWe’ll then increment each counter one time in two simultaneously running threads:\n/*-----  Thread 1  ----- */     /*-------  Thread 2  ------- */\n         ++ac;                             ++ac;\n         ++vc;                             ++vc;\nWhen both threads have finished, ac’s value (i.e., the value of the std::atomic)\nmust be 2, because each increment occurs as an indivisible operation. vc’s value, on\nthe other hand, need not be 2, because its increments may not occur atomically. Each\nincrement consists of reading vc’s value, incrementing the value that was read, and\nwriting the result back into vc. But these three operations are not guaranteed to pro‐\nceed atomically for volatile objects, so it’s possible that the component parts of the\ntwo increments of vc are interleaved as follows:\n1. Thread 1 reads vc’s value, which is 0.\n2. Thread 2 reads vc’s value, which is still 0.\n3. Thread 1 increments the 0 it read to 1, then writes that value into vc.\n4. Thread 2 increments the 0 it read to 1, then writes that value into vc.\nvc’s final value is therefore 1, even though it was incremented twice.\nThis is not the only possible outcome. vc’s final value is, in general, not predictable,\nbecause vc is involved in a data race, and the Standard’s decree that data races cause\nundefined behavior means that compilers may generate code to do literally anything.\nCompilers don’t use this leeway to be malicious, of course. Rather, they perform opti‐\nmizations that would be valid in programs without data races, and these optimiza‐\ntions yield unexpected and unpredictable behavior in programs where races are\npresent.\nThe use of RMW operations isn’t the only situation where std::atomics comprise a\nconcurrency success story and volatiles suffer failure. Suppose one task computes\nan important value needed by a second task. When the first task has computed the\nvalue, it must communicate this to the second task. Item 39 explains that one way for\nthe first task to communicate the availability of the desired value to the second task is\nItem 40 \n| \n273\nwww.it-ebooks.info\n",
      "content_length": 2402,
      "extraction_method": "Direct"
    },
    {
      "page_number": 292,
      "chapter": null,
      "content": "6 This is true only for std::atomics using sequential consistency, which is both the default and the only consis‐\ntency model for std::atomic objects that use the syntax shown in this book. C++11 also supports consis‐\ntency models with more flexible code-reordering rules. Such weak (aka relaxed) models make it possible to\ncreate software that runs faster on some hardware architectures, but the use of such models yields software\nthat is much more difficult to get right, to understand, and to maintain. Subtle errors in code using relaxed\natomics is not uncommon, even for experts, so you should stick to sequential consistency if at all possible.\nby using a std::atomic<bool>. Code in the task computing the value would look\nsomething like this:\nstd::atomic<bool> valAvailable(false);\nauto imptValue = computeImportantValue();  // compute value\nvalAvailable = true;                       // tell other task\n                                           // it's available\nAs humans reading this code, we know it’s crucial that the assignment to imptValue\ntake place before the assignment to valAvailable, but all compilers see is a pair of\nassignments to independent variables. As a general rule, compilers are permitted to\nreorder such unrelated assignments. That is, given this sequence of assignments\n(where a, b, x, and y correspond to independent variables),\na = b;\nx = y;\ncompilers may generally reorder them as follows:\nx = y;\na = b;\nEven if compilers don’t reorder them, the underlying hardware might do it (or might\nmake it seem to other cores as if it had), because that can sometimes make the code\nrun faster.\nHowever, the use of std::atomics imposes restrictions on how code can be reor‐\ndered, and one such restriction is that no code that, in the source code, precedes a\nwrite of a std::atomic variable may take place (or appear to other cores to take\nplace) afterwards.6 That means that in our code,\nauto imptValue = computeImportantValue();  // compute value\nvalAvailable = true;                       // tell other task\n                                           // it's available\nnot only must compilers retain the order of the assignments to imptValue and\nvalAvailable, they must generate code that ensures that the underlying hardware\n274 \n| \nItem 40\nwww.it-ebooks.info\n",
      "content_length": 2290,
      "extraction_method": "Direct"
    },
    {
      "page_number": 293,
      "chapter": null,
      "content": "does, too. As a result, declaring valAvailable as std::atomic ensures that our crit‐\nical ordering requirement—imptValue must be seen by all threads to change no later\nthan valAvailable does—is maintained.\nDeclaring valAvailable as volatile doesn’t impose the same code reordering\nrestrictions:\nvolatile bool valAvailable(false);\nauto imptValue = computeImportantValue();\nvalAvailable = true;  // other threads might see this assignment\n                      // before the one to imptValue!\nHere, compilers might flip the order of the assignments to imptValue and valAvail\nable, and even if they don’t, they might fail to generate machine code that would\nprevent the underlying hardware from making it possible for code on other cores to\nsee valAvailable change before imptValue.\nThese two issues—no guarantee of operation atomicity and insufficient restrictions\non code reordering—explain why volatile’s not useful for concurrent program‐\nming, but it doesn’t explain what it is useful for. In a nutshell, it’s for telling compilers\nthat they’re dealing with memory that doesn’t behave normally.\n“Normal” memory has the characteristic that if you write a value to a memory loca‐\ntion, the value remains there until something overwrites it. So if I have a normal int,\nint x;\nand a compiler sees the following sequence of operations on it,\nauto y = x;           // read x\ny = x;                // read x again\nthe compiler can optimize the generated code by eliminating the assignment to y,\nbecause it’s redundant with y’s initialization.\nNormal memory also has the characteristic that if you write a value to a memory\nlocation, never read it, and then write to that memory location again, the first write\ncan be eliminated, because it was never used. So given these two adjacent statements,\nx = 10;               // write x\nx = 20;               // write x again\ncompilers can eliminate the first one. That means that if we have this in the source\ncode,\nauto y = x;           // read x\ny = x;                // read x again\nItem 40 \n| \n275\nwww.it-ebooks.info\n",
      "content_length": 2059,
      "extraction_method": "Direct"
    },
    {
      "page_number": 294,
      "chapter": null,
      "content": "x = 10;               // write x\nx = 20;               // write x again\ncompilers can treat it as if it had been written like this:\nauto y = x;           // read x\nx = 20;               // write x\nLest you wonder who’d write code that performs these kinds of redundant reads and\nsuperfluous writes (technically known as redundant loads and dead stores), the\nanswer is that humans don’t write it directly—at least we hope they don’t. However,\nafter compilers take reasonable-looking source code and perform template instantia‐\ntion, inlining, and various common kinds of reordering optimizations, it’s not\nuncommon for the result to have redundant loads and dead stores that compilers can\nget rid of.\nSuch optimizations are valid only if memory behaves normally. “Special” memory\ndoesn’t. Probably the most common kind of special memory is memory used for\nmemory-mapped I/O. Locations in such memory actually communicate with periph‐\nerals, e.g., external sensors or displays, printers, network ports, etc. rather than read‐\ning or writing normal memory (i.e., RAM). In such a context, consider again the code\nwith seemingly redundant reads:\nauto y = x;           // read x\ny = x;                // read x again\nIf x corresponds to, say, the value reported by a temperature sensor, the second read\nof x is not redundant, because the temperature may have changed between the first\nand second reads.\nIt’s a similar situation for seemingly superfluous writes. In this code, for example,\nx = 10;               // write x\nx = 20;               // write x again\nif x corresponds to the control port for a radio transmitter, it could be that the code is\nissuing commands to the radio, and the value 10 corresponds to a different command\nfrom the value 20. Optimizing out the first assignment would change the sequence of\ncommands sent to the radio.\nvolatile is the way we tell compilers that we’re dealing with special memory. Its\nmeaning to compilers is “Don’t perform any optimizations on operations on this\nmemory.” So if x corresponds to special memory, it’d be declared volatile:\nvolatile int x;\nConsider the effect that has on our original code sequence:\n276 \n| \nItem 40\nwww.it-ebooks.info\n",
      "content_length": 2188,
      "extraction_method": "Direct"
    },
    {
      "page_number": 295,
      "chapter": null,
      "content": "7 y’s type is auto-deduced, so it uses the rules described in Item 2. Those rules dictate that for the declaration of\nnon-reference non-pointer types (which is the case for y), const and volatile qualifiers are dropped. y’s\ntype is therefore simply int. This means that redundant reads of and writes to y can be eliminated. In the\nexample, compilers must perform both the initialization of and the assignment to y, because x is volatile,\nso the second read of x might yield a different value from the first one.\nauto y = x;           // read x\ny = x;                // read x again (can't be optimized away)\nx = 10;               // write x (can't be optimized away)\nx = 20;               // write x again\nThis is precisely what we want if x is memory-mapped (or has been mapped to a\nmemory location shared across processes, etc.).\nPop quiz! In that last piece of code, what is y’s type: int or volatile int?7\nThe fact that seemingly redundant loads and dead stores must be preserved when\ndealing with special memory explains, by the way, why std::atomics are unsuitable\nfor this kind of work. Compilers are permitted to eliminate such redundant opera‐\ntions on std::atomics. The code isn’t written quite the same way it is for vola\ntiles, but if we overlook that for a moment and focus on what compilers are\npermitted to do, we can say that, conceptually, compilers may take this,\nstd::atomic<int> x;\nauto y = x;           // conceptually read x (see below)\ny = x;                // conceptually read x again (see below)\nx = 10;               // write x\nx = 20;               // write x again\nand optimize it to this:\nauto y = x;           // conceptually read x (see below)\nx = 20;               // write x\nFor special memory, this is clearly unacceptable behavior.\nNow, as it happens, neither of these two statements will compile when x is\nstd::atomic:\nauto y = x;           // error!\ny = x;                // error!\nThat’s because the copy operations for std::atomic are deleted (see Item 11). And\nwith good reason. Consider what would happen if the initialization of y with x com‐\nItem 40 \n| \n277\nwww.it-ebooks.info\n",
      "content_length": 2121,
      "extraction_method": "Direct"
    },
    {
      "page_number": 296,
      "chapter": null,
      "content": "piled. Because x is std::atomic, y’s type would be deduced to be std::atomic, too\n(see Item 2). I remarked earlier that one of the best things about std::atomics is\nthat all their operations are atomic, but in order for the copy construction of y from x\nto be atomic, compilers would have to generate code to read x and write y in a single\natomic operation. Hardware generally can’t do that, so copy construction isn’t sup‐\nported for std::atomic types. Copy assignment is deleted for the same reason,\nwhich is why the assignment from x to y won’t compile. (The move operations aren’t\nexplicitly declared in std::atomic, so, per the rules for compiler-generated special\nfunctions described in Item 17, std::atomic offers neither move construction nor\nmove assignment.)\nIt’s possible to get the value of x into y, but it requires use of std::atomic’s member\nfunctions load and store. The load member function reads a std::atomic’s value\natomically, while the store member function writes it atomically. To initialize y with\nx, followed by putting x’s value in y, the code must be written like this:\nstd::atomic<int> y(x.load());     // read x\ny.store(x.load());                // read x again\nThis compiles, but the fact that reading x (via x.load()) is a separate function call\nfrom initializing or storing to y makes clear that there is no reason to expect either\nstatement as a whole to execute as a single atomic operation.\nGiven that code, compilers could “optimize” it by storing x’s value in a register\ninstead of reading it twice:\nregister = x.load();              // read x into register\nstd::atomic<int> y(register);     // init y with register value\ny.store(register);                // store register value into y\nThe result, as you can see, reads from x only once, and that’s the kind of optimization\nthat must be avoided when dealing with special memory. (The optimization isn’t per‐\nmitted for volatile variables.)\nThe situation should thus be clear:\n• std::atomic is useful for concurrent programming, but not for accessing spe‐\ncial memory.\n• volatile is useful for accessing special memory, but not for concurrent pro‐\ngramming.\n278 \n| \nItem 40\nwww.it-ebooks.info\n",
      "content_length": 2181,
      "extraction_method": "Direct"
    },
    {
      "page_number": 297,
      "chapter": null,
      "content": "Because std::atomic and volatile serve different purposes, they can even be used\ntogether:\nvolatile std::atomic<int> vai;    // operations on vai are\n                                  // atomic and can't be\n                                  // optimized away\nThis could be useful if vai corresponded to a memory-mapped I/O location that was\nconcurrently accessed by multiple threads.\nAs a final note, some developers prefer to use std::atomic’s load and store mem‐\nber functions even when they’re not required, because it makes explicit in the source\ncode that the variables involved aren’t “normal.” Emphasizing that fact isn’t unrea‐\nsonable. Accessing a std::atomic is typically much slower than accessing a non-\nstd::atomic, and we’ve already seen that the use of std::atomics prevents\ncompilers from performing certain kinds of code reorderings that would otherwise\nbe permitted. Calling out loads and stores of std::atomics can therefore help iden‐\ntify potential scalability chokepoints. From a correctness perspective, not seeing a call\nto store on a variable meant to communicate information to other threads (e.g., a\nflag indicating the availability of data) could mean that the variable wasn’t declared\nstd::atomic when it should have been.\nThis is largely a style issue, however, and as such is quite different from the choice\nbetween std::atomic and volatile.\nThings to Remember\n• std::atomic is for data accessed from multiple threads without using\nmutexes. It’s a tool for writing concurrent software.\n• volatile is for memory where reads and writes should not be optimized\naway. It’s a tool for working with special memory.\nItem 40 \n| \n279\nwww.it-ebooks.info\n",
      "content_length": 1675,
      "extraction_method": "Direct"
    },
    {
      "page_number": 298,
      "chapter": null,
      "content": "www.it-ebooks.info\n",
      "content_length": 19,
      "extraction_method": "Direct"
    },
    {
      "page_number": 299,
      "chapter": null,
      "content": "1 In this Item, to “copy” a parameter generally means to use it as the source of a copy or move operation. Recall\non page 2 that C++ has no terminology to distinguish a copy made by a copy operation from one made by a\nmove operation.\nCHAPTER 8\nTweaks\nFor every general technique or feature in C++, there are circumstances where it’s rea‐\nsonable to use it, and there are circumstances where it’s not. Describing when it\nmakes sense to use a general technique or feature is usually fairly straightforward, but\nthis chapter covers two exceptions. The general technique is pass by value, and the\ngeneral feature is emplacement. The decision about when to employ them is affected\nby so many factors, the best advice I can offer is to consider their use. Nevertheless,\nboth are important players in effective modern C++ programming, and the Items\nthat follow provide the information you’ll need to determine whether using them is\nappropriate for your software.\nItem 41: Consider pass by value for copyable parameters\nthat are cheap to move and always copied.\nSome function parameters are intended to be copied.1 For example, a member func‐\ntion addName might copy its parameter into a private container. For efficiency, such a\nfunction should copy lvalue arguments, but move rvalue arguments:\nclass Widget {\npublic:\n  void addName(const std::string& newName)    // take lvalue;\n  { names.push_back(newName); }               // copy it\n  void addName(std::string&& newName)         // take rvalue;\n281\nwww.it-ebooks.info\n",
      "content_length": 1515,
      "extraction_method": "Direct"
    },
    {
      "page_number": 300,
      "chapter": null,
      "content": "  { names.push_back(std::move(newName)); }    // move it; see\n  …                                           // Item 25 for use\n                                              // of std::move\nprivate:\n  std::vector<std::string> names;\n};\nThis works, but it requires writing two functions that do essentially the same thing.\nThat chafes a bit: two functions to declare, two functions to implement, two func‐\ntions to document, two functions to maintain. Ugh.\nFurthermore, there will be two functions in the object code—something you might\ncare about if you’re concerned about your program’s footprint. In this case, both\nfunctions will probably be inlined, and that’s likely to eliminate any bloat issues\nrelated to the existence of two functions, but if these functions aren’t inlined every‐\nwhere, you really will get two functions in your object code.\nAn alternative approach is to make addName a function template taking a universal\nreference (see Item 24):\nclass Widget {\npublic:\n  template<typename T>                          // take lvalues\n  void addName(T&& newName)                     // and rvalues;\n  {                                             // copy lvalues,\n    names.push_back(std::forward<T>(newName));  // move rvalues;\n  }                                             // see Item 25\n                                                // for use of\n  …                                             // std::forward\n};\nThis reduces the source code you have to deal with, but the use of universal refer‐\nences leads to other complications. As a template, addName’s implementation must\ntypically be in a header file. It may yield several functions in object code, because it\nnot only instantiates differently for lvalues and rvalues, it also instantiates differently\nfor std::string and types that are convertible to std::string (see Item 25). At the\nsame time, there are argument types that can’t be passed by universal reference (see\nItem 30), and if clients pass improper argument types, compiler error messages can\nbe intimidating (see Item 27).\nWouldn’t it be nice if there were a way to write functions like addName such that lval‐\nues were copied, rvalues were moved, there was only one function to deal with (in\nboth source and object code), and the idiosyncrasies of universal references were\navoided? As it happens, there is. All you have to do is abandon one of the first rules\nyou probably learned as a C++ programmer. That rule was to avoid passing objects of\n282 \n| \nItem 41\nwww.it-ebooks.info\n",
      "content_length": 2518,
      "extraction_method": "Direct"
    },
    {
      "page_number": 301,
      "chapter": null,
      "content": "user-defined types by value. For parameters like newName in functions like addName,\npass by value may be an entirely reasonable strategy.\nBefore we discuss why pass-by-value may be a good fit for newName and addName,\nlet’s see how it would be implemented:\nclass Widget {\npublic:\n  void addName(std::string newName)           // take lvalue or\n  { names.push_back(std::move(newName)); }    // rvalue; move it\n  …\n};\nThe only non-obvious part of this code is the application of std::move to the param‐\neter newName. Typically, std::move is used with rvalue references, but in this case,\nwe know that (1) newName is a completely independent object from whatever the\ncaller passed in, so changing newName won’t affect callers and (2) this is the final use\nof newName, so moving from it won’t have any impact on the rest of the function.\nThe fact that there’s only one addName function explains how we avoid code duplica‐\ntion, both in the source code and the object code. We’re not using a universal refer‐\nence, so this approach doesn’t lead to bloated header files, odd failure cases, or\nconfounding error messages. But what about the efficiency of this design? We’re\npassing by value. Isn’t that expensive?\nIn C++98, it was a reasonable bet that it was. No matter what callers passed in, the\nparameter newName would be created by copy construction. In C++11, however, add\nName will be copy constructed only for lvalues. For rvalues, it will be move construc‐\nted. Here, look:\nWidget w;\n…\nstd::string name(\"Bart\");\nw.addName(name);                 // call addName with lvalue\n…\nw.addName(name + \"Jenne\");       // call addName with rvalue\n                                 // (see below)\nItem 41 \n| \n283\nwww.it-ebooks.info\n",
      "content_length": 1720,
      "extraction_method": "Direct"
    },
    {
      "page_number": 302,
      "chapter": null,
      "content": "In the first call to addName (when name is passed), the parameter newName is initial‐\nized with an lvalue. newName is thus copy constructed, just like it would be in C++98.\nIn the second call, newName is initialized with the std::string object resulting from\na call to operator+ for std::string (i.e., the append operation). That object is an\nrvalue, and newName is therefore move constructed.\nLvalues are thus copied, and rvalues are moved, just like we want. Neat, huh?\nIt is neat, but there are some caveats you need to keep in mind. Doing that will be\neasier if we recap the three versions of addName we’ve considered:\nclass Widget {                                  // Approach 1:\npublic:                                         // overload for\n  void addName(const std::string& newName)      // lvalues and\n  { names.push_back(newName); }                 // rvalues\n  void addName(std::string&& newName)\n  { names.push_back(std::move(newName)); }\n  …\nprivate:\n  std::vector<std::string> names;\n};\nclass Widget {                                  // Approach 2:\npublic:                                         // use universal\n  template<typename T>                          // reference\n  void addName(T&& newName)\n  { names.push_back(std::forward<T>(newName)); }\n  …\n};\nclass Widget {                                  // Approach 3:\npublic:                                         // pass by value\n  void addName(std::string newName)\n  { names.push_back(std::move(newName)); }\n  …\n};\nI refer to the first two versions as the “by-reference approaches,” because they’re both\nbased on passing their parameters by reference.\n284 \n| \nItem 41\nwww.it-ebooks.info\n",
      "content_length": 1662,
      "extraction_method": "Direct"
    },
    {
      "page_number": 303,
      "chapter": null,
      "content": "Here are the two calling scenarios we’ve examined:\nWidget w;\n…\nstd::string name(\"Bart\");\nw.addName(name);                       // pass lvalue\n…\nw.addName(name + \"Jenne\");             // pass rvalue\nNow consider the cost, in terms of copy and move operations, of adding a name to a\nWidget for the two calling scenarios and each of the three addName implementations\nwe’ve discussed. The accounting will largely ignore the possibility of compilers opti‐\nmizing copy and move operations away, because such optimizations are context- and\ncompiler-dependent and, in practice, don’t change the essence of the analysis.\n• Overloading: Regardless of whether an lvalue or an rvalue is passed, the caller’s\nargument is bound to a reference called newName. That costs nothing, in terms of\ncopy and move operations. In the lvalue overload, newName is copied into\nWidget::names. In the rvalue overload, it’s moved. Cost summary: one copy for\nlvalues, one move for rvalues.\n• Using a universal reference: As with overloading, the caller’s argument is bound\nto the reference newName. This is a no-cost operation. Due to the use of\nstd::forward, lvalue std::string arguments are copied into Widget::names,\nwhile rvalue std::string arguments are moved. The cost summary for\nstd::string arguments is the same as with overloading: one copy for lvalues,\none move for rvalues.\nItem 25 explains that if a caller passes an argument of a type other than\nstd::string, it will be forwarded to a std::string constructor, and that could\ncause as few as zero std::string copy or move operations to be performed.\nFunctions taking universal references can thus be uniquely efficient. However,\nthat doesn’t affect the analysis in this Item, so we’ll keep things simple by assum‐\ning that callers always pass std::string arguments.\n• Passing by value: Regardless of whether an lvalue or an rvalue is passed, the\nparameter newName must be constructed. If an lvalue is passed, this costs a copy\nconstruction. If an rvalue is passed, it costs a move construction. In the body of\nthe function, newName is unconditionally moved into Widget::names. The cost\nsummary is thus one copy plus one move for lvalues, and two moves for rvalues.\nCompared to the by-reference approaches, that’s one extra move for both lvalues\nand rvalues.\nItem 41 \n| \n285\nwww.it-ebooks.info\n",
      "content_length": 2326,
      "extraction_method": "Direct"
    },
    {
      "page_number": 304,
      "chapter": null,
      "content": "2 Sentences like this are why it’d be nice to have terminology that distinguishes copies made via copy opera‐\ntions from copies made via move operations.\nLook again at this Item’s title:\nConsider pass by value for copyable parameters that are cheap to move\nand always copied.\nIt’s worded the way it is for a reason. Four reasons, in fact:\n1. You should only consider using pass by value. Yes, it requires writing only one\nfunction. Yes, it generates only one function in the object code. Yes, it avoids the\nissues associated with universal references. But it has a higher cost than the alter‐\nnatives, and, as we’ll see below, in some cases, there are expenses we haven’t yet\ndiscussed.\n2. Consider pass by value only for copyable parameters. Parameters failing this test\nmust have move-only types, because if they’re not copyable, yet the function\nalways makes a copy, the copy must be created via the move constructor.2 Recall\nthat the advantage of pass by value over overloading is that with pass by value,\nonly one function has to be written. But for move-only types, there is no need to\nprovide an overload for lvalue arguments, because copying an lvalue entails call‐\ning the copy constructor, and the copy constructor for move-only types is dis‐\nabled. That means that only rvalue arguments need to be supported, and in that\ncase, the “overloading” solution requires only one overload: the one taking an\nrvalue reference.\nConsider a class with a std::unique_ptr<std::string> data member and a\nsetter for it. std::unique_ptr is a move-only type, so the “overloading”\napproach to its setter consists of a single function:\nclass Widget {\npublic:\n  …\n  void setPtr(std::unique_ptr<std::string>&& ptr)\n  { p = std::move(ptr); }\nprivate:\n  std::unique_ptr<std::string> p;\n};\nA caller might use it this way:\n286 \n| \nItem 41\nwww.it-ebooks.info\n",
      "content_length": 1843,
      "extraction_method": "Direct"
    },
    {
      "page_number": 305,
      "chapter": null,
      "content": "Widget w;\n…\nw.setPtr(std::make_unique<std::string>(\"Modern C++\"));\nHere \nthe \nrvalue \nstd::unique_ptr<std::string> \nreturned \nfrom\nstd::make_unique (see Item 21) is passed by rvalue reference to setPtr, where\nit’s moved into the data member p. The total cost is one move.\nIf setPtr were to take its parameter by value,\nclass Widget {\npublic:\n  …\n  void setPtr(std::unique_ptr<std::string> ptr)\n  { p = std::move(ptr); }\n  …\n};\nthe same call would move construct the parameter ptr, and ptr would then be\nmove assigned into the data member p. The total cost would thus be two moves\n—twice that of the “overloading” approach.\n3. Pass by value is worth considering only for parameters that are cheap to move.\nWhen moves are cheap, the cost of an extra one may be acceptable, but when\nthey’re not, performing an unnecessary move is analogous to performing an\nunnecessary copy, and the importance of avoiding unnecessary copy operations\nis what led to the C++98 rule about avoiding pass by value in the first place!\n4. You should consider pass by value only for parameters that are always copied. To\nsee why this is important, suppose that before copying its parameter into the\nnames container, addName checks to see if the new name is too short or too long.\nIf it is, the request to add the name is ignored. A pass-by-value implementation\ncould be written like this:\nclass Widget {\npublic:\n  void addName(std::string newName)\n  {\n    if ((newName.length() >= minLen) &&\n        (newName.length() <= maxLen))\n      {\n        names.push_back(std::move(newName));\n      }\n  }\nItem 41 \n| \n287\nwww.it-ebooks.info\n",
      "content_length": 1603,
      "extraction_method": "Direct"
    },
    {
      "page_number": 306,
      "chapter": null,
      "content": "  …\nprivate:\n  std::vector<std::string> names;\n};\nThis function incurs the cost of constructing and destroying newName, even if\nnothing is added to names. That’s a price the by-reference approaches wouldn’t\nbe asked to pay.\nEven when you’re dealing with a function performing an unconditional copy on a\ncopyable type that’s cheap to move, there are times when pass by value may not be\nappropriate. That’s because a function can copy a parameter in two ways: via con‐\nstruction (i.e., copy construction or move construction) and via assignment (i.e., copy\nassignment or move assignment). addName uses construction: its parameter newName\nis passed to vector::push_back, and inside that function, newName is copy con‐\nstructed into a new element created at the end of the std::vector. For functions\nthat use construction to copy their parameter, the analysis we saw earlier is complete:\nusing pass by value incurs the cost of an extra move for both lvalue and rvalue argu‐\nments.\nWhen a parameter is copied using assignment, the situation is more complicated.\nSuppose, for example, we have a class representing passwords. Because passwords\ncan be changed, we provide a setter function, changeTo. Using a pass-by-value strat‐\negy, we could implement Password like this:\nclass Password {\npublic:\n  explicit Password(std::string pwd)     // pass by value\n  : text(std::move(pwd)) {}              // construct text\n  void changeTo(std::string newPwd)      // pass by value\n  { text = std::move(newPwd); }          // assign text\n  …\nprivate:\n  std::string text;                      // text of password\n};\nStoring the password as plain text will whip your software security SWAT team into a\nfrenzy, but ignore that and consider this code:\n288 \n| \nItem 41\nwww.it-ebooks.info\n",
      "content_length": 1767,
      "extraction_method": "Direct"
    },
    {
      "page_number": 307,
      "chapter": null,
      "content": "std::string initPwd(\"Supercalifragilisticexpialidocious\");\nPassword p(initPwd);\nThere are no suprises here: p.text is constructed with the given password, and using\npass by value in the constructor incurs the cost of a std::string move construction\nthat would not be necessary if overloading or perfect forwarding were employed. All\nis well.\nA user of this program may not be as sanguine about the password, however, because\n“Supercalifragilisticexpialidocious” is found in many dictionaries. He or she may\ntherefore take actions that lead to code equivalent to the following being executed:\nstd::string newPassword = \"Beware the Jabberwock\";\np.changeTo(newPassword);\nWhether the new password is better than the old one is debatable, but that’s the user’s\nproblem. Ours is that changeTo’s use of assignment to copy the parameter newPwd\nprobably causes that function’s pass-by-value strategy to explode in cost.\nThe argument passed to changeTo is an lvalue (newPassword), so when the parame‐\nter newPwd is constructed, it’s the std::string copy constructor that’s called. That\nconstructor allocates memory to hold the new password. newPwd is then move-\nassigned to text, which causes the memory already held by text to be deallocated.\nThere are thus two dynamic memory management actions within changeTo: one to\nallocate memory for the new password, and one to deallocate the memory for the old\npassword.\nBut in this case, the old password (“Supercalifragilisticexpialidocious”) is longer than\nthe new one (“Beware the Jabberwock”), so there’s no need to allocate or deallocate\nanything. If the overloading approach were used, it’s likely that none would take \nplace:\nclass Password {\npublic:\n  …\n  void changeTo(const std::string& newPwd)      // the overload\n  {                                             // for lvalues\n    text = newPwd;           // can reuse text's memory if\n                             // text.capacity() >= newPwd.size()\n  }\n  …\nItem 41 \n| \n289\nwww.it-ebooks.info\n",
      "content_length": 1990,
      "extraction_method": "Direct"
    },
    {
      "page_number": 308,
      "chapter": null,
      "content": "private:\n  std::string text;                             // as above\n};\nIn this scenario, the cost of pass by value includes an extra memory allocation and\ndeallocation—costs that are likely to exceed that of a std::string move operation\nby orders of magnitude.\nInterestingly, if the old password were shorter than the new one, it would typically be\nimpossible to avoid an allocation-deallocation pair during the assignment, and in\nthat case, pass by value would run at about the same speed as pass by reference. The\ncost of assignment-based parameter copying can thus depend on the values of the\nobjects participating in the assignment! This kind of analysis applies to any parame‐\nter type that holds values in dynamically allocated memory. Not all types qualify, but\nmany—including std::string and std::vector—do.\nThis potential cost increase generally applies only when lvalue arguments are passed,\nbecause the need to perform memory allocation and deallocation typically occurs\nonly when true copy operations (i.e., not moves) are performed. For rvalue argu‐\nments, moves almost always suffice.\nThe upshot is that the extra cost of pass by value for functions that copy a parameter\nusing assignment depends on the type being passed, the ratio of lvalue to rvalue argu‐\nments, whether the type uses dynamically allocated memory, and, if so, the imple‐\nmentation of that type’s assignment operators and the likelihood that the memory\nassociated with the assignment target is at least as large as the memory associated\nwith the assignment source. For std::string, it also depends on whether the imple‐\nmentation uses the small string optimization (SSO—see Item 29) and, if so, whether\nthe values being assigned fit in the SSO buffer.\nSo, as I said, when parameters are copied via assignment, analyzing the cost of pass\nby value is complicated. Usually, the most practical approach is to adopt a “guilty\nuntil proven innocent” policy, whereby you use overloading or universal references\ninstead of pass by value unless it’s been demonstrated that pass by value yields\nacceptably efficient code for the parameter type you need.\nNow, for software that must be as fast as possible, pass by value may not be a viable\nstrategy, because avoiding even cheap moves can be important. Moreover, it’s not\nalways clear how many moves will take place. In the Widget::addName example, pass\nby value incurs only a single extra move operation, but suppose that Widget::add\nName called Widget::validateName, and this function also passed by value. (Pre‐\nsumably it has a reason for always copying its parameter, e.g., to store it in a data\nstructure of all values it validates.) And suppose that validateName called a third\nfunction that also passed by value…\n290 \n| \nItem 41\nwww.it-ebooks.info\n",
      "content_length": 2779,
      "extraction_method": "Direct"
    },
    {
      "page_number": 309,
      "chapter": null,
      "content": "You can see where this is headed. When there are chains of function calls, each of\nwhich employs pass by value because “it costs only one inexpensive move,” the cost\nfor the entire chain of calls may not be something you can tolerate. Using by-\nreference parameter passing, chains of calls don’t incur this kind of accumulated\noverhead.\nAn issue unrelated to performance, but still worth keeping in mind, is that pass by\nvalue, unlike pass by reference, is susceptible to the slicing problem. This is well-trod\nC++98 ground, so I won’t dwell on it, but if you have a function that is designed to\naccept a parameter of a base class type or any type derived from it, you don’t want to\ndeclare a pass-by-value parameter of that type, because you’ll “slice off” the derived-\nclass characteristics of any derived type object that may be passed in:\nclass Widget { … };                          // base class\nclass SpecialWidget: public Widget { … };    // derived class\nvoid processWidget(Widget w);   // func for any kind of Widget,\n                                // including derived types;\n…                               // suffers from slicing problem\nSpecialWidget sw;\n…\nprocessWidget(sw);              // processWidget sees a\n                                // Widget, not a SpecialWidget!\nIf you’re not familiar with the slicing problem, search engines and the Internet are\nyour friends; there’s lots of information available. You’ll find that the existence of the\nslicing problem is another reason (on top of the efficiency hit) why pass by value has\na shady reputation in C++98. There are good reasons why one of the first things you\nprobably learned about C++ programming was to avoid passing objects of user-\ndefined types by value.\nC++11 doesn’t fundamentally change the C++98 wisdom regarding pass by value. In\ngeneral, pass by value still entails a performance hit you’d prefer to avoid, and pass by\nvalue can still lead to the slicing problem. What’s new in C++11 is the distinction\nbetween lvalue and rvalue arguments. Implementing functions that take advantage of\nmove semantics for rvalues of copyable types requires either overloading or using\nuniversal references, both of which have drawbacks. For the special case of copyable,\ncheap-to-move types passed to functions that always copy them and where slicing is\nnot a concern, pass by value can offer an easy-to-implement alternative that’s nearly\nas efficient as its pass-by-reference competitors, but avoids their disadvantages.\nItem 41 \n| \n291\nwww.it-ebooks.info\n",
      "content_length": 2532,
      "extraction_method": "Direct"
    },
    {
      "page_number": 310,
      "chapter": null,
      "content": "Things to Remember\n• For copyable, cheap-to-move parameters that are always copied, pass by value\nmay be nearly as efficient as pass by reference, it’s easier to implement, and it\ncan generate less object code.\n• Copying parameters via construction may be significantly more expensive\nthan copying them via assignment.\n• Pass by value is subject to the slicing problem, so it’s typically inappropriate\nfor base class parameter types.\nItem 42: Consider emplacement instead of insertion.\nIf you have a container holding, say, std::strings, it seems logical that when you\nadd a new element via an insertion function (i.e., insert, push_front, push_back,\nor, for std::forward_list, insert_after), the type of element you’ll pass to the\nfunction will be std::string. After all, that’s what the container has in it.\nLogical though this may be, it’s not always true. Consider this code:\nstd::vector<std::string> vs;         // container of std::string\nvs.push_back(\"xyzzy\");               // add string literal\nHere, the container holds std::strings, but what you have in hand—what you’re\nactually trying to push_back—is a string literal, i.e., a sequence of characters inside\nquotes. A string literal is not a std::string, and that means that the argument\nyou’re passing to push_back is not of the type held by the container.\npush_back for std::vector is overloaded for lvalues and rvalues as follows:\ntemplate <class T,                           // from the C++11\n          class Allocator = allocator<T>>    // Standard\nclass vector {\npublic:\n  …\n  void push_back(const T& x);                // insert lvalue\n  void push_back(T&& x);                     // insert rvalue\n  …\n};\nIn the call\nvs.push_back(\"xyzzy\");\n292 \n| \nItem 41\nwww.it-ebooks.info\n",
      "content_length": 1744,
      "extraction_method": "Direct"
    },
    {
      "page_number": 311,
      "chapter": null,
      "content": "compilers see a mismatch between the type of the argument (const char[6]) and the\ntype of the parameter taken by push_back (a reference to a std::string). They\naddress the mismatch by generating code to create a temporary std::string object\nfrom the string literal, and they pass that temporary object to push_back. In other\nwords, they treat the call as if it had been written like this:\nvs.push_back(std::string(\"xyzzy\"));  // create temp. std::string\n                                     // and pass it to push_back\nThe code compiles and runs, and everybody goes home happy. Everybody except the\nperformance freaks, that is, because the performance freaks recognize that this code\nisn’t as efficient as it should be.\nTo create a new element in a container of std::strings, they understand, a\nstd::string constructor is going to have to be called, but the code above doesn’t\nmake just one constructor call. It makes two. And it calls the std::string destruc‐\ntor, too. Here’s what happens at runtime in the call to push_back:\n1. A temporary std::string object is created from the string literal \"xyzzy\". This\nobject has no name; we’ll call it temp. Construction of temp is the first\nstd::string construction. Because it’s a temporary object, temp is an rvalue.\n2. temp is passed to the rvalue overload for push_back, where it’s bound to the\nrvalue reference parameter x. A copy of x is then constructed in the memory for\nthe std::vector. This construction—the second one—is what actually creates a\nnew object inside the std::vector. (The constructor that’s used to copy x into\nthe std::vector is the move constructor, because x, being an rvalue reference,\ngets cast to an rvalue before it’s copied. For information about the casting of\nrvalue reference parameters to rvalues, see Item 25.)\n3. Immediately after push_back returns, temp is destroyed, thus calling the\nstd::string destructor.\nThe performance freaks can’t help but notice that if there were a way to take the\nstring literal and pass it directly to the code in step 2 that constructs the std::string\nobject inside the std::vector, we could avoid constructing and destroying temp.\nThat would be maximally efficient, and even the performance freaks could content‐\nedly decamp.\nBecause you’re a C++ programmer, there’s an above-average chance you’re a perfor‐\nmance freak. If you’re not, you’re still probably sympathetic to their point of view. (If\nyou’re not at all interested in performance, shouldn’t you be in the Python room\ndown the hall?) So I’m pleased to tell you that there is a way to do exactly what is\nItem 42 \n| \n293\nwww.it-ebooks.info\n",
      "content_length": 2612,
      "extraction_method": "Direct"
    },
    {
      "page_number": 312,
      "chapter": null,
      "content": "needed for maximal efficiency in the call to push_back. It’s to not call push_back.\npush_back is the wrong function. The function you want is emplace_back.\nemplace_back does exactly what we desire: it uses whatever arguments are passed to\nit to construct a std::string directly inside the std::vector. No temporaries are\ninvolved:\nvs.emplace_back(\"xyzzy\");   // construct std::string inside\n                            // vs directly from \"xyzzy\"\nemplace_back uses perfect forwarding, so, as long as you don’t bump into one of\nperfect forwarding’s limitations (see Item 30), you can pass any number of arguments\nof any combination of types through emplace_back. For example, if you’d like to\ncreate a std::string in vs via the std::string constructor taking a character and\na repeat count, this would do it:\nvs.emplace_back(50, 'x');   // insert std::string consisting\n                            // of 50 'x' characters\nemplace_back is available for every standard container that supports push_back.\nSimilarly, \nevery \nstandard \ncontainer \nthat \nsupports \npush_front \nsupports\nemplace_front. And every standard container that supports insert (which is all\nbut std::forward_list and std::array) supports emplace. The associative con‐\ntainers offer emplace_hint to complement their insert functions that take a “hint”\niterator, and std::forward_list has emplace_after to match its insert_after.\nWhat makes it possible for emplacement functions to outperform insertion functions\nis their more flexible interface. Insertion functions take objects to be inserted, while\nemplacement functions take constructor arguments for objects to be inserted. This dif‐\nference permits emplacement functions to avoid the creation and destruction of tem‐\nporary objects that insertion functions can necessitate.\nBecause an argument of the type held by the container can be passed to an emplace‐\nment function (the argument thus causes the function to perform copy or move con‐\nstruction), emplacement can be used even when an insertion function would require\nno temporary. In that case, insertion and emplacement do essentially the same thing.\nFor example, given\nstd::string queenOfDisco(\"Donna Summer\");\nboth of the following calls are valid, and both have the same net effect on the con‐\ntainer:\nvs.push_back(queenOfDisco);       // copy-construct queenOfDisco\n                                  // at end of vs\nvs.emplace_back(queenOfDisco);    // ditto\n294 \n| \nItem 42\nwww.it-ebooks.info\n",
      "content_length": 2473,
      "extraction_method": "Direct"
    },
    {
      "page_number": 313,
      "chapter": null,
      "content": "Emplacement functions can thus do everything insertion functions can. They some‐\ntimes do it more efficiently, and, at least in theory, they should never do it less effi‐\nciently. So why not use them all the time?\nBecause, as the saying goes, in theory, there’s no difference between theory and prac‐\ntice, but in practice, there is. With current implementations of the Standard Library,\nthere are situations where, as expected, emplacement outperforms insertion, but,\nsadly, there are also situations where the insertion functions run faster. Such situa‐\ntions are not easy to characterize, because they depend on the types of arguments\nbeing passed, the containers being used, the locations in the containers where inser‐\ntion or emplacement is requested, the exception safety of the contained types’ con‐\nstructors, and, for containers where duplicate values are prohibited (i.e., std::set,\nstd::map, std::unordered_set, std::unordered_map), whether the value to be\nadded is already in the container. The usual performance-tuning advice thus applies:\nto determine whether emplacement or insertion runs faster, benchmark them both.\nThat’s not very satisfying, of course, so you’ll be pleased to learn that there’s a heuris‐\ntic that can help you identify situations where emplacement functions are most likely\nto be worthwhile. If all the following are true, emplacement will almost certainly out‐\nperform insertion:\n• The value being added is constructed into the container, not assigned.  The\nexample that opened this Item (adding a std::string with the value \"xyzzy\" to\na std::vector vs) showed the value being added to the end of vs—to a place\nwhere no object yet existed. The new value therefore had to be constructed into\nthe std::vector. If we revise the example such that the new std::string goes\ninto a location already occupied by an object, it’s a different story. Consider:\nstd::vector<std::string> vs;         // as before\n…                                    // add elements to vs\nvs.emplace(vs.begin(), \"xyzzy\");     // add \"xyzzy\" to\n                                     // beginning of vs\nFor this code, few implementations will construct the added std::string into\nthe memory occupied by vs[0]. Instead, they’ll move-assign the value into place.\nBut move assignment requires an object to move from, and that means that a\ntemporary object will need to be created to be the source of the move. Because\nthe primary advantage of emplacement over insertion is that temporary objects\nare neither created nor destroyed, when the value being added is put into the\ncontainer via assignment, emplacement’s edge tends to disappear.\nAlas, whether adding a value to a container is accomplished by construction or\nassignment is generally up to the implementer. But, again, heuristics can help.\nItem 42 \n| \n295\nwww.it-ebooks.info\n",
      "content_length": 2835,
      "extraction_method": "Direct"
    },
    {
      "page_number": 314,
      "chapter": null,
      "content": "Node-based containers virtually always use construction to add new values, and\nmost standard containers are node-based. The only ones that aren’t are\nstd::vector, std::deque, and std::string. (std::array isn’t, either, but it\ndoesn’t support insertion or emplacement, so it’s not relevant here.) Within the\nnon-node-based containers, you can rely on emplace_back to use construction\ninstead of assignment to get a new value into place, and for std::deque, the\nsame is true of emplace_front.\n• The argument type(s) being passed differ from the type held by the container.\nAgain, emplacement’s advantage over insertion generally stems from the fact that\nits interface doesn’t require creation and destruction of a temporary object when\nthe argument(s) passed are of a type other than that held by the container. When\nan object of type T is to be added to a container<T>, there’s no reason to expect\nemplacement to run faster than insertion, because no temporary needs to be cre‐\nated to satisfy the insertion interface.\n• The container is unlikely to reject the new value as a duplicate. This means\nthat the container either permits duplicates or that most of the values you add\nwill be unique. The reason this matters is that in order to detect whether a value\nis already in the container, emplacement implementations typically create a node\nwith the new value so that they can compare the value of this node with existing\ncontainer nodes. If the value to be added isn’t in the container, the node is linked\nin. However, if the value is already present, the emplacement is aborted and the\nnode is destroyed, meaning that the cost of its construction and destruction was\nwasted. Such nodes are created for emplacement functions more often than for\ninsertion functions.\nThe following calls from earlier in this Item satisfy all the criteria above. They also\nrun faster than the corresponding calls to push_back.\nvs.emplace_back(\"xyzzy\");   // construct new value at end of\n                            // container; don't pass the type in\n                            // container; don't use container\n                            // rejecting duplicates\nvs.emplace_back(50, 'x');   // ditto\nWhen deciding whether to use emplacement functions, two other issues are worth\nkeeping in mind. The first regards resource management. Suppose you have a con‐\ntainer of std::shared_ptr<Widget>s,\nstd::list<std::shared_ptr<Widget>> ptrs;\nand you want to add a std::shared_ptr that should be released via a custom deleter\n(see Item 19). Item 21 explains that you should use std::make_shared to create\n296 \n| \nItem 42\nwww.it-ebooks.info\n",
      "content_length": 2619,
      "extraction_method": "Direct"
    },
    {
      "page_number": 315,
      "chapter": null,
      "content": "std::shared_ptrs whenever you can, but it also concedes that there are situations\nwhere you can’t. One such situation is when you want to specify a custom deleter. In\nthat case, you must use new directly to get the raw pointer to be managed by the\nstd::shared_ptr.\nIf the custom deleter is this function,\nvoid killWidget(Widget* pWidget);\nthe code using an insertion function could look like this:\nptrs.push_back(std::shared_ptr<Widget>(new Widget, killWidget));\nIt could also look like this, though the meaning would be the same:\nptrs.push_back({ new Widget, killWidget });\nEither way, a temporary std::shared_ptr would be constructed before calling\npush_back. push_back’s parameter is a reference to a std::shared_ptr, so there\nhas to be a std::shared_ptr for this parameter to refer to.\nThe creation of the temporary std::shared_ptr is what emplace_back would\navoid, but in this case, that temporary is worth far more than it costs. Consider the\nfollowing potential sequence of events:\n1. In either call above, a temporary std::shared_ptr<Widget> object is construc‐\nted to hold the raw pointer resulting from “new Widget”. Call this object temp.\n2. push_back takes temp by reference. During allocation of a list node to hold a\ncopy of temp, an out-of-memory exception gets thrown.\n3. As the exception propagates out of push_back, temp is destroyed. Being the sole\nstd::shared_ptr referring to the Widget it’s managing, it automatically relea‐\nses that Widget, in this case by calling killWidget.\nEven though an exception occurred, nothing leaks: the Widget created via “new\nWidget” in the call to push_back is released in the destructor of the\nstd::shared_ptr that was created to manage it (temp). Life is good.\nNow consider what happens if emplace_back is called instead of push_back:\nptrs.emplace_back(new Widget, killWidget);\n1. The raw pointer resulting from “new Widget” is perfect-forwarded to the point\ninside emplace_back where a list node is to be allocated. That allocation fails,\nand an out-of-memory exception is thrown.\nItem 42 \n| \n297\nwww.it-ebooks.info\n",
      "content_length": 2072,
      "extraction_method": "Direct"
    },
    {
      "page_number": 316,
      "chapter": null,
      "content": "2. As the exception propagates out of emplace_back, the raw pointer that was the\nonly way to get at the Widget on the heap is lost. That Widget (and any resources\nit owns) is leaked.\nIn this scenario, life is not good, and the fault doesn’t lie with std::shared_ptr. The\nsame kind of problem can arise through the use of std::unique_ptr with a custom\ndeleter. Fundamentally, the effectiveness of resource-managing classes like\nstd::shared_ptr and std::unique_ptr is predicated on resources (such as raw\npointers from new) being immediately passed to constructors for resource-managing\nobjects. The fact that functions like std::make_shared and std::make_unique\nautomate this is one of the reasons they’re so important.\nIn calls to the insertion functions of containers holding resource-managing objects\n(e.g., std::list<std::shared_ptr<Widget>>), the functions’ parameter types gen‐\nerally ensure that nothing gets between acquisition of a resource (e.g., use of new) and\nconstruction of the object managing the resource. In the emplacement functions,\nperfect-forwarding defers the creation of the resource-managing objects until they\ncan be constructed in the container’s memory, and that opens a window during\nwhich exceptions can lead to resource leaks. All standard containers are susceptible\nto this problem. When working with containers of resource-managing objects, you\nmust take care to ensure that if you choose an emplacement function over its inser‐\ntion counterpart, you’re not paying for improved code efficiency with diminished\nexception safety.\nFrankly, you shouldn’t be passing expressions like “new Widget” to emplace_back or\npush_back or most any other function, anyway, because, as Item 21 explains, this\nleads to the possibility of exception safety problems of the kind we just examined.\nClosing the door requires taking the pointer from “new Widget” and turning it over\nto a resource-managing object in a standalone statement, then passing that object as\nan rvalue to the function you originally wanted to pass “new Widget” to. (Item 21\ncovers this technique in more detail.) The code using push_back should therefore be\nwritten more like this:\nstd::shared_ptr<Widget> spw(new Widget,    // create Widget and\n                            killWidget);   // have spw manage it\nptrs.push_back(std::move(spw));            // add spw as rvalue\nThe emplace_back version is similar:\nstd::shared_ptr<Widget> spw(new Widget, killWidget);\nptrs.emplace_back(std::move(spw));\nEither way, the approach incurs the cost of creating and destroying spw. Given that\nthe motivation for choosing emplacement over insertion is to avoid the cost of a tem‐\n298 \n| \nItem 42\nwww.it-ebooks.info\n",
      "content_length": 2689,
      "extraction_method": "Direct"
    },
    {
      "page_number": 317,
      "chapter": null,
      "content": "porary object of the type held by the container, yet that’s conceptually what spw is,\nemplacement functions are unlikely to outperform insertion functions when you’re\nadding resource-managing objects to a container and you follow the proper practice\nof ensuring that nothing can intervene between acquiring a resource and turning it\nover to a resource-managing object.\n A second noteworthy aspect of emplacement functions is their interaction with\nexplicit constructors. In honor of C++11’s support for regular expressions, sup‐\npose you create a container of regular expression objects:\nstd::vector<std::regex> regexes;\nDistracted by your colleagues’ quarreling over the ideal number of times per day to\ncheck one’s Facebook account, you accidentally write the following seemingly mean‐\ningless code:\nregexes.emplace_back(nullptr);    // add nullptr to container\n                                  // of regexes?\nYou don’t notice the error as you type it, and your compilers accept the code without\ncomplaint, so you end up wasting a bunch of time debugging. At some point, you\ndiscover that you have inserted a null pointer into your container of regular expres‐\nsions. But how is that possible? Pointers aren’t regular expressions, and if you tried to\ndo something like this,\nstd::regex r = nullptr;           // error! won't compile\ncompilers would reject your code. Interestingly, they would also reject it if you called\npush_back instead of emplace_back:\nregexes.push_back(nullptr);       // error! won't compile\nThe curious behavior you’re experiencing stems from the fact that std::regex\nobjects can be constructed from character strings. That’s what makes useful code like\nthis legal:\nstd::regex upperCaseWord(\"[A-Z]+\");\nCreation of a std::regex from a character string can exact a comparatively large\nruntime cost, so, to minimize the likelihood that such an expense will be incurred\nunintentionally, the std::regex constructor taking a const char* pointer is\nexplicit. That’s why these lines don’t compile:\nstd::regex r = nullptr;           // error! won't compile\nregexes.push_back(nullptr);       // error! won't compile\nIn both cases, we’re requesting an implicit conversion from a pointer to a\nstd::regex, and the explicitness of that constructor prevents such conversions.\nItem 42 \n| \n299\nwww.it-ebooks.info\n",
      "content_length": 2323,
      "extraction_method": "Direct"
    },
    {
      "page_number": 318,
      "chapter": null,
      "content": "In the call to emplace_back, however, we’re not claiming to pass a std::regex\nobject. Instead, we’re passing a constructor argument for a std::regex object. That’s\nnot considered an implicit conversion request. Rather, it’s viewed as if you’d written\nthis code:\nstd::regex r(nullptr);           // compiles\nIf the laconic comment “compiles” suggests a lack of enthusiasm, that’s good, because\nthis code, though it will compile, has undefined behavior. The std::regex construc‐\ntor taking a const char* pointer requires that the pointed-to string comprise a valid\nregular expression, and the null pointer fails that requirement. If you write and com‐\npile such code, the best you can hope for is that it crashes at runtime. If you’re not so\nlucky, you and your debugger could be in for a special bonding experience.\nSetting aside push_back, emplace_back, and bonding for a moment, notice how\nthese very similar initialization syntaxes yield different results:\nstd::regex r1 = nullptr;         // error! won't compile\nstd::regex r2(nullptr);          // compiles\nIn the official terminology of the Standard, the syntax used to initialize r1 (employ‐\ning the equals sign) corresponds to what is known as copy initialization. In contrast,\nthe syntax used to initialize r2 (with the parentheses, although braces may be used\ninstead) yields what is called direct initialization. Copy initialization is not permitted\nto use explicit constructors. Direct initialization is. That’s why the line initializing\nr1 doesn’t compile, but the line initializing r2 does.\nBut back to push_back and emplace_back and, more generally, the insertion func‐\ntions versus the emplacement functions. Emplacement functions use direct initializa‐\ntion, which means they may use explicit constructors. Insertion functions employ\ncopy initialization, so they can’t. Hence:\nregexes.emplace_back(nullptr);  // compiles. Direct init permits\n                                // use of explicit std::regex\n                                // ctor taking a pointer\nregexes.push_back(nullptr);     // error! copy init forbids\n                                // use of that ctor\nThe lesson to take away is that when you use an emplacement function, be especially\ncareful to make sure you’re passing the correct arguments, because even explicit\nconstructors will be considered by compilers as they try to find a way to interpret\nyour code as valid.\n300 \n| \nItem 42\nwww.it-ebooks.info\n",
      "content_length": 2443,
      "extraction_method": "Direct"
    },
    {
      "page_number": 319,
      "chapter": null,
      "content": "Things to Remember\n• In principle, emplacement functions should sometimes be more efficient than\ntheir insertion counterparts, and they should never be less efficient.\n• In practice, they’re most likely to be faster when (1) the value being added is\nconstructed into the container, not assigned; (2) the argument type(s) passed\ndiffer from the type held by the container; and (3) the container won’t reject\nthe value being added due to it being a duplicate.\n• Emplacement functions may perform type conversions that would be rejected\nby insertion functions.\nItem 42 \n| \n301\nwww.it-ebooks.info\n",
      "content_length": 593,
      "extraction_method": "Direct"
    },
    {
      "page_number": 320,
      "chapter": null,
      "content": "www.it-ebooks.info\n",
      "content_length": 19,
      "extraction_method": "Direct"
    },
    {
      "page_number": 321,
      "chapter": null,
      "content": "Index\nSymbols\n&&, meanings of, 164\n0 (zero)\noverloading and, 59\ntemplates and, 60\ntype of, 58\n= (equals sign), assignment vs. initialization, 50\n=default, 112, 152, 257\n=delete (see deleted functions)\nA\nAbrahams, David, xiv\n\"Adventure\", allusion to, 295\nAlexandrescu, Andrei, xiii\nalias declarations\nalias templates and, 63-65\ndefinition of, 63\nreference collapsing and, 202\nvs. typedefs, 63-65\nalias templates, 63\nallusions\nto \"Adventure\", 295\nto \"Citizen Kane\", 239\nto \"Jabberwocky\", 289\nto \"Mary Poppins\", 289\nto \"Star Trek\", 125\nto \"Star Wars\", 189\nto \"The Hitchhiker's Guide to the Galaxy\",\n30\nto Dave Barry, 33\nto John 8:32, 164\napostrophe, as digit separator, 252\narguments, bound and unbound, 238\narray\narguments, 15-17\ndecay, definition of, 15\nparameters, 16\nreference to, 16\nsize, deducing, 16\nauto, 37-48\nadvantages of, 38-41\nbraced initializers and, 21-23\ncode readability and, 42\nmaintenance and, 42\nproxy classes and, 43-46\nrefactoring and, 42\nreference collapsing and, 201\nreturn type deduction and braced initializ‐\ners and, 21-23\nstd::initializer_list and, 21\ntrailing return types and, 25\ntype deduction, 18-23\nuniversal references and, 167\nvs. std::function for function objects, 39\nB\nback pointers, 138\nBarry, Dave, allusion to, 33\nbasic guarantee, definition of, 4\nBecker, Thomas, xiv\nbig three, the, 111\nbitfield arguments, 214\nboolean flags and event communication, 264\nBoost.TypeIndex, 34-35\nbraced initialization, 50-55\nauto and, 21-23\ndefinition of, 50\nperfect forwarding and, 208-209\n303\nwww.it-ebooks.info\n",
      "content_length": 1534,
      "extraction_method": "Direct"
    },
    {
      "page_number": 322,
      "chapter": null,
      "content": "return type deduction and, 23\nstd::initializer_lists and, 52-54\nBrowning, Elizabeth Barrett, 117\nby-reference captures, 217-219\nby-value capture\npointers and, 219\nproblems with, 219-223\nstd::move and, 283\nby-value parameters, std::move and, 283\nC\nC with Classes, 86\n\"C++ Concurrency in Action\" (book), 257\nC++03, definition of, 2\nC++11, definition of, 2\nC++14, definition of, 2\nC++98\ndefinition of, 2\nexception specifications, 90\nc++filt, 32\ncaching factory function, 136\ncallable objects, definition of, 5\ncaptures\nby-reference, 217\nby-value, 219\ndefault modes, 216-223\nthis pointer and, 220-222\ncasts\nconditional vs. unconditional, 161\nstd::move vs. std::forward, 158\ncbegin, 87\ncend, 87\nCheng, Rachel, xiv\n\"Citizen Kane\", allusion to, 239\nclass templates, definition of, 5\nclosures\nclosure class, definition of, 216\ncopies of, 216\ndefinition of, 5, 216\ncode examples (see example classes/templates;\nexample functions/templates)\ncode reordering\nstd::atomic and, 273\nvolatile and, 275\ncode smells, 263\ncompiler warnings, 81\nnoexcept and, 96\nvirtual function overriding and, 81\ncondition variables\nevent communication and, 262-266\nspurious wakeups and, 264\ntiming dependencies and, 264\ncondvar (see condition variables)\nconst\nconst member functions and thread safety,\n103-109\nconst propagation, definition of, 210\nconst T&&, 166\npointers and type deduction, 14\nvs. constexpr, 98\nconstexpr, 97-103\nconstexpr functions, 98-102\nrestrictions on, 99-102\nruntime arguments and, 99\nconstexpr objects, 97-98\ninterface design and, 102\nvs. const, 98\nconstructors\nconstructor calls, braces vs. parentheses,\n52-55\nexplicit, 299-300\nuniversal references and, 180-183, 188-194\nconst_iterators\nconverting to iterators, 87\nvs. iterators, 86-89\ncontextual keywords, definition of, 83\ncontracts, wide vs. narrow, 95\ncontrol blocks, 128-132\ndefinition of, 128\nsize of, 132\nstd::shared_ptr and, 129\ncopy elision, definition of, 174\ncopy of an object, definition of, 4\ncopy operations\nautomatic generation of, 112\ndefaulting, 113-114\ndefinition of, 3\nfor classes declaring copy operations or\ndtor, 112\nfor std::atomic, 277\nimplicit\nin classes declaring move operations,\n111\nPimpl Idiom and, 153-154\nrelationship to destructor and resource\nmanagement, 111\nvia construction vs. assignment, 288-290\n304 \n| \nIndex\nwww.it-ebooks.info\n",
      "content_length": 2308,
      "extraction_method": "Direct"
    },
    {
      "page_number": 323,
      "chapter": null,
      "content": "CRTP (Curiously Recurring Template Pattern),\n131\nctor (see constructor)\nCuriously Recurring Template Pattern (CRTP),\n131\ncustom deleters, definition of, 120\nD\ndangling pointer, definition of, 134\ndangling references, 217\ndead stores, definition of, 276\nDealtry, William, xiv\ndeclarations, definition of, 5\ndecltype, 23-30\nauto&& parameters in lambdas and,\n229-232\ndecltype(auto) and, 26\nreference collapsing and, 203\nreturn expressions and, 29\ntreatment of names vs. treatment of expres‐\nsions, 28\ndeduced types, viewing, 30-35\ndeduction, type (see type deduction)\ndeep copy, definition of, 154\ndefault capture modes, 216-223\ndefault launch policy, 246-249\nthread-local storage and, 247\ndefaulted dtor, 152\ndefaulted member functions, 112\ndefaulted virtual destructors, 112\ndefinition of terms\nalias template, 63\nalias templates, 63\narray decay, 15\nbasic guarantee, 4\nbraced initialization, 50\nC++03, 2\nC++11, 2\nC++14, 2\nC++98, 2\ncallable object, 5\nclass template, 5\nclosure, 5, 216\nclosure class, 216\ncode smell, 263\nconst propagation, 210\ncontextual keyword, 83\ncontrol block, 128\ncopy of an object, 4\ncopy operation, 3\nCRTP (Curiously Recurring Template Pat‐\ntern), 131\nctor, 6\ncustom deleter, 120\ndangling pointer, 134\ndead stores, 276\ndeclaration, 5\ndeep copy, 154\ndefinition, 5\ndeleted function, 75\ndependent type, 64\ndeprecated feature, 6\ndisabled templates, 189\ndtor, 6\nenabled templates, 189\nexception safe, 4\nexception-neutral, 93\nexclusive ownership, 119\nexpired std::weak_ptr, 135\nfunction argument, 4\nfunction objects, 5\nfunction parameter, 4\nfunction signature, 6\ngeneralized lambda capture, 225\ngeneric lambdas, 229\nhardware thread, 242\nincomplete type, 148\ninit capture, 224\nintegral constant expression, 97\ninterruptible thread, 256\njoinable std::thread, 250\nlambda, 5, 215\nlambda expression, 215\nlhs, 3\nliteral types, 100\nlvalue, 2\nmake function, 139\nmemory-mapped I/O, 276\nmost vexing parse, 51\nmove operation, 3\nmove semantic, 157\nmove-only type, 105, 119\nnamed return value optimization (NRVO),\n174\nnarrow contracts, 95-96\nnarrowing conversions, 51\nnon-dependent type, 64\nIndex \n| \n305\nwww.it-ebooks.info\n",
      "content_length": 2126,
      "extraction_method": "Direct"
    },
    {
      "page_number": 324,
      "chapter": null,
      "content": "NRVO (named return value optimization),\n174\noverride, 79\noversubscription, 243\nparameter forwarding, 207\nperfect forwarding, 4, 157, 207\nPimpl Idiom, 147\nRAII classes, 253\nRAII object, 253\nRAII objects, 253\nraw pointer, 6\nredundant loads, 276\nreference collapsing, 198\nreference count, 125\nreference qualifier, 80\nrelaxed memory consistency, 274\nresource ownership, 117\nreturn value optimization (RVO), 174\nrhs, 3\nRule of Three, 111\nrvalue, 2\nRVO (return value optimization), 174\nscoped enums, 67\nsequential memory consistency, 274\nshallow copy, 154\nshared ownership, 125\nshared state, 259\nsmall string optimization (SSO), 205\nsmart pointers, 6\nsoftware threads, 242\nspecial member functions, 109\nspurious wakeups, 264\nstatic storage duration, 222\nstrong guarantee, 4\ntag dispatch, 188\ntask-based programming, 241\ntemplate class, 5\ntemplate function, 5\nthread local storage (TLS), 247\nthread-based programming, 241\ntrailing return type, 25\ntranslation, 97\nundefined behavior, 6\nuniform initialization, 50\nunjoinable std::thread, 250\nunscoped enum, 67\nunscoped enums, 67\nweak count, 144\nweak memory consistency, 274\nwide contracts, 95-96\nWidget, 3\ndefinitions of terms\nalias declarations, 63\ncopy elision, 174\ndefinitions, definition of, 5\ndeleted functions, 74-79\ndefinition of, 75\nvs. private and undefined ones, 74-79\ndeleters\ncustom, 142\nstd::unique_ptr vs. std::shared_ptr, 126, 155\ndeleting non-member functions, 76-77\ndeleting template instantiations, 77-78\ndependent type, definition of, 64\ndeprecated features\nautomatic copy operation generation, 112\nC++98-style exception specifications, 90\ndefinition of, 6\nstd::auto_ptr, 118\ndestructor\ndefaulted, 112, 152\nrelationship to copy operations and\nresource management, 111\ndigit separators, apostrophes as, 252\ndisabled templates, definition of, 189\ndtor (see destructor)\nDziubinski, Matt P., xiv\nE\nEinstein's theory of general relativity, 168\nellipses, narrow vs. wide, 3\nemplacement\nconstruction vs. assignment and, 295\nemplacement functions, 293-300\nexception safety and, 296-299\nexplicit constructors and, 299-300\nheuristic for use of, 295-296\nperfect forwarding and, 294\nvs. insertion, 292-301\nenabled templates, definition of, 189\nenums\ncompilation dependencies and, 70\nenum classes (see scoped enums)\nforward declaring, 69-71\nimplicit conversions and, 68\nscoped vs. unscoped, 67\nstd::get and, 71-73\nstd::tuples and, 71-73\n306 \n| \nIndex\nwww.it-ebooks.info\n",
      "content_length": 2417,
      "extraction_method": "Direct"
    },
    {
      "page_number": 325,
      "chapter": null,
      "content": "underlying type for, 69-71\nequals sign (=), assignment vs. initialization, 50\nerrata list for this book, 7\nerror messages, universal reference and, 195\nevent communication\nboolean flags, 264\ncondition variables and, 262\ncost and efficiency of polling, 265\nfuture as mechanism for, 266-270\nexample classes/templates\n(see also std::)\nBase, 79-82, 112\nBond, 119\nDerived, 79, 81-82\nInvestment, 119, 122\nIPv4Header, 213\nIsValAndArch, 226\nMyAllocList, 64\nMyAllocList<Wine>, 65\nPassword, 288-290\nPerson, 180-182, 184, 189, 191, 193, 196\nPoint, 24, 100, 101, 106\nPolynomial, 103-105\nPolyWidget, 239\nRealEstate, 119\nReallyBigType, 145\nSomeCompilerGeneratedClassName, 229\nSpecialPerson, 183, 192\nSpecialWidget, 291\nstd::add_lvalue_reference, 66\nstd::basic_ios, 75\nstd::get, 257\nstd::pair, 93\nstd::remove_const, 66\nstd::remove_reference, 66\nstd::string, 160\nstd::vector, 24, 166, 292\nstd::vector<bool>, 46\nStock, 119\nStringTable, 113\nstruct Point, 24\nTD, 31\nThreadRAII, 254, 257\nWarning, 83\nWidget, 3, 5, 50, 52, 64, 78, 80, 83, 106-108,\n109, 112, 115, 130-132, 148-155, 162,\n168-170, 202, 210, 219, 224, 260,\n281-288, 291\nWidget::Impl, 150-153\nWidget::processPointer, 78\nWine, 65\nexample functions/templates\n(see also std::)\naddDivisorFilter, 217, 223\narraySize, 16\nauthAndAccess, 25-28, 26-27\nBase::Base, 113\nBase::doWork, 79\nBase::mf1, 81-82\nBase::mf2, 81-82\nBase::mf3, 81-82\nBase::mf4, 81-82\nBase::operator=, 113\nBase::~Base, 112\ncalcEpsilon, 47\ncalcValue, 261\ncbegin, 88\ncleanup, 96\ncompress, 237\ncomputerPriority, 140\ncontinueProcessing, 70\ncreateInitList, 23\ncreateVec, 32, 35\ncusDel, 146\ndelInvmt2, 123\nDerived::doWork, 79\nDerived::mf1, 81-82\nDerived::mf2, 81-82\nDerived::mf3, 81-82\nDerived::mf4, 81-82\ndetect, 268, 270\ndoAsyncWork, 241-242\ndoSomething, 83\ndoSomeWork, 57, 221\ndoWork, 96, 251, 255\ndwim, 37-38\nf, 10-16, 18, 22-23, 32, 34, 59, 90, 95,\n164-166, 199, 208, 247\nf1, 17, 29, 60\nf2, 17, 29, 60\nf3, 60\nfastLoadWidget, 136\nfeatures, 43\nfindAndInsert, 88\nfunc, 5, 39, 197-198, 201\nfunc_for_cx, 19\nfunc_for_rx, 19\nfunc_for_x, 19\nIndex \n| \n307\nwww.it-ebooks.info\n",
      "content_length": 2065,
      "extraction_method": "Direct"
    },
    {
      "page_number": 326,
      "chapter": null,
      "content": "fwd, 207\nInvestment::~Investment, 122\nisLucky, 76\nIsValAndArch::IsValAndArch, 226\nIsValAndArch::operator(), 226\nkillWidget, 297\nloadWidget, 136\nlockAndCall, 61\nlogAndAdd, 177-179, 186-187\nlogAndAddImpl, 187-188\nlogAndProcess, 161\nmakeInvestment, 119-120, 122-123\nmakeStringDeque, 27\nmakeWidget, 80, 84, 174-176\nmidpoint, 101\nmyFunc, 16\nnameFromIdx, 179\noperator+, 3, 172-173\nPassword::changeTo, 288-289\nPassword::Password, 288\nPerson::Person, 180-182, 184, 189, 191,\n193-194, 196\nPoint::distanceFromOrigin, 106\nPoint::Point, 100\nPoint::setX, 100-101\nPoint::setY, 100\nPoint::xValue, 100\nPoint::yValue, 100-101\nPolynomial::roots, 103-105\nPolyWidget::operator(), 239\npow, 99-100\nprimeFactors, 68\nprocess, 130, 132, 161\nprocessPointer, 77, 78\nprocessPointer<char>, 77\nprocessPointer<const char>, 77\nprocessPointer<const void>, 77\nprocessPointer<void>, 78\nprocessVal, 211\nprocessVals, 3\nprocessWidget, 146\nreact, 268\nreallyAsync, 249\nreduceAndCopy, 173\nreflection, 102\nsetAlarm, 233, 235\nsetSignText, 172\nsetup, 96\nSomeCompilerGeneratedClassName::oper‐\nator(), 229\nsomeFunc, 4, 17, 20, 167\nSpecialPerson::SpecialPerson, 183, 192\nSpecialWidget::processWidget, 291\nstd::add_lvalue_reference, 66\nstd::basic_ios::basic_ios, 75, 160\nstd::basic_ios::operator=, 75, 160\nstd::forward, 199-201, 230\nstd::get, 257\nstd::make_shared, 139-147, 171\nstd::make_unique, 139-147, 171\nstd::move, 158\nstd::pair::swap, 93\nstd::remove_const, 66\nstd::remove_reference, 66\nstd::swap, 93\nstd::vector::emplace_back, 167\nstd::vector::operator[], 24, 24\nstd::vector::push_back, 166, 292\nstd::vector<bool>::operator[], 46\nStringTable::StringTable, 113\nStringTable::~StringTable, 113\nThreadRAII::get, 254, 257\nThreadRAII::operator=, 257\nThreadRAII::ThreadRAII, 254, 257\nThreadRAII::~ThreadRAII, 254, 257\ntoUType, 73\nWarning::override, 83\nWidget::addFilter, 219-222\nWidget::addName, 281-284\nWidget::create, 132\nWidget::data, 83-85\nWidget::doWork, 80\nWidget::isArchived, 224\nWidget::isProcessed, 224\nWidget::isValidated, 224\nWidget::magicValue, 106-108\nWidget::operator float, 53\nWidget::operator=, 109, 112, 115, 152-154\nWidget::process, 130-131\nWidget::processPointer<char>, 77\nWidget::processPointer<void>, 77\nWidget::processWidget, 140\nWidget::setName, 169-170\nWidget::setPtr, 286\nWidget::Widget, 3, 52-55, 109, 112, 115,\n148-155, 162, 168-169\nWidget::~Widget, 112, 148, 151\n308 \n| \nIndex\nwww.it-ebooks.info\n",
      "content_length": 2375,
      "extraction_method": "Direct"
    },
    {
      "page_number": 327,
      "chapter": null,
      "content": "widgetFactory, 201\nworkOnVal, 212\nworkWithContainer, 218\nexample structs (see example classes/templates)\nexception safety\nalternatives to std::make_shared, 145-147,\n298\ndefinition of, 4\nemplacement and, 296-299\nmake functions and, 140, 298\nexception specifications, 90\nexception-neutral, definition of, 93\nexclusive ownership, definition of, 119\nexpired std::weak_ptr, 135\nexplicit constructors, insertion functions and,\n299\nexplicitly typed initializer idiom, 43-48\nF\nFacebook, 299\nfeminine manifestation of the divine (see\nUrbano, Nancy L.)\nFernandes, Martinho, xiv\nfinal keyword, 83\nFioravante, Matthew, xiv\nforwarding (see perfect forwarding)\nforwarding references, 164\nFrench, gratuitous use of, 164, 194\nFriesen, Stanley, xiii\nfunction\narguments, definition of, 4\nconditionally noexcept, 93\ndecay, 17\ndefaulted (see defaulted member functions)\ndeleted, 74-79\ngreediest in C++, 180\nmember, 87\nmember reference qualifiers and, 83-85\nmember templates, 115\nmember, defaulted, 112\nnames, overloaded, 211-213\nnon-member, 88\nobjects, definition of, 5\nparameters, definition of, 4\npointer parameter syntaxes, 211\nprivate and undefined, 74\nreturn type deduction, 25-26\nsignature, definition of, 6\nuniversal references and, 180\nG\ngeneralized lambda capture, definition of, 225\ngeneric code, move operations and, 206\ngeneric lambdas\ndefinition of, 229\noperator() in, 229\ngratuitous swipe at Python, 293\ngratuitous use\nof French, 164, 194\nof Yiddish, 82\ngreediest functions in C++, 180\nGrimm, Rainer, xiv\nH\nHalbersma, Rein, xiv\nhardware threads, definition of, 242\nhighlighting in this book, 3\nHinnant, Howard, xiv\n\"Hitchhiker's Guide to the Galaxy, The\", allu‐\nsion to, 30\nHuchley, Benjamin, xiv\nI\nimplicit copy operations, in classes declaring\nmove operations, 111\nimplicit generation of special member func‐\ntions, 109-115\nincomplete type, definition of, 148\nindeterminate destructor behavior for futures,\n260\ninference, type (see type deduction)\ninit capture, 224-229\ndefinition of, 224\ninitialization\nbraced, 50\norder with std::thread data members, 254\nsyntaxes for, 49\nuniform, 50\ninlining, in lambdas vs. std::bind, 236\ninsertion\nexplicit constructors and, 300\nvs. emplacement, 292-301\nintegral constant expression, definition of, 97\ninterface design\nconstexpr and, 102\nexception specifications and, 90\nwide vs. narrow contracts, 95\ninterruptible threads, definition of, 256\nIndex \n| \n309\nwww.it-ebooks.info\n",
      "content_length": 2409,
      "extraction_method": "Direct"
    },
    {
      "page_number": 328,
      "chapter": null,
      "content": "J\n\"Jabberwocky\", allusion to, 289\nJohn 8:32, allusion to, 164\njoinability, testing std::threads for, 255\njoinable std::threads\ndefinition of, 250\ndestruction of, 251-253\ntesting for joinability, 255\nK\nKaminski, Tomasz, xiv\nKarpov, Andrey, xiv\nkeywords, contextual, 83\nKirby-Green,Tom, xiv\nKohl, Nate, xiv\nKreuzer, Gerhard, xiv, xv\nKrügler, Daniel, xiii\nL\nlambdas\nauto&& parameters and decltype in,\n229-232\nbound and unbound arguments and, 238\nby-reference captures and, 217-219\nby-value capture, drawbacks of, 219-223\nby-value capture, pointers and, 219\ncreating closures with, 216\ndangling references and, 217-219\ndefault capture modes and, 216-223\ndefinition of, 5, 215\nexpressive power of, 215\ngeneric, 229\nimplicit capture of the this pointer, 220-222\ninit capture, 224-229\ninlining and, 236\nlambda capture and objects of static storage\nduration, 222\nmove capture and, 238\noverloading and, 235\npolymorphic function objects and, 239\nvariadic, 231\nvs. std::bind, 232-240\nbound arguments, treatment of, 238\ninlining and, 236\nmove capture and, 239\npolymorphic functions objects and, 239\nreadability and, 232-236\nunbound arguments, treatment of, 238\nLavavej, Stephan T., xiii, 139\nlegacy types, move operations and, 203\nlhs, definition of, 3\nLiber, Nevin “:-)”, xiv\nliteral types, definition of, 100\nload balancing, 244\nlocal variables\nby-value return and, 173-176\nwhen not destroyed, 120\nlvalues, definition of, 2\nM\nMaher, Michael, xv\nmake functions\navoiding code duplication and, 140\ncustom deleters and, 142\ndefinition of, 139\nexception safety and, 140-142, 298\nparentheses vs. braces, 143\n\"Mary Poppins\", allusion to, 289\nMatthews, Hubert, xiv\nmemory\nconsistency models, 274\nmemory-mapped I/O, definition of, 276\nMerkle, Bernhard, xiii\nMesopotamia, 109\n\"Modern C++ Design\" (book), xiii\nmost vexing parse, definition of, 51\nmove capture, 224\nemulation with std::bind, 226-229, 239\nlambdas and, 239\nmove operations\ndefaulting, 113-114\ndefinition of, 3\ngeneric code and, 206\nimplicitly generated, 109-112\nlegacy types and, 203\nPimpl Idiom and, 152-153\nstd::array and, 204\nstd::shared_ptr and, 126\nstd::string and, 205\nstrong guarantee and, 205\ntemplates and, 206\nmove operations and\nmove semantics, definition of, 157\nmove-enabled types, 110\nmove-only type, definition of, 105, 119\n310 \n| \nIndex\nwww.it-ebooks.info\n",
      "content_length": 2315,
      "extraction_method": "Direct"
    },
    {
      "page_number": 329,
      "chapter": null,
      "content": "N\nnamed return value optimization (NRVO), 174\nnarrow contracts, definition of, 95-96\nnarrow ellipsis, 3\nnarrowing conversions, definition of, 51\nNeedham, Bradley E., xiv, xv\nNeri, Cassio, xiv\nNewton's laws of motion, 168\nNiebler, Eric, xiv\nNikitin, Alexey A., xiv\nnoexcept, 90-96\ncompiler warnings and, 96\nconditional, 93\ndeallocation functions and, 94\ndestructors and, 94\nfunction interfaces and, 93\nmove operations and, 91-92\noperator delete and, 94\noptimization and, 90-93\nstrong guarantee and, 92\nswap functions and, 92-93\nnon-dependent type, definition of, 64\nnon-member functions, 88\ndeleting, 76\nNovak, Adela, 171\nNRVO (named return value optimization), 174\nNULL\noverloading and, 59\ntemplates and, 60\nnullptr\noverloading and, 59\ntemplates and, 60-62\ntype of, 59\nvs. 0 and NULL, 58-62\nO\nobjects\n() vs. {} for creation of, 49-58\ndestruction of, 120\noperator templates, type arguments and, 235\noperator(), in generic lambdas, 229\noperator[], return type of, 24, 46\nOrr, Roger, xiv\nOS threads, definition of, 242\noverloading\nalternatives to, 184-197\nlambdas and, 235\npointer and integral types, 59\nscalability of, 171\nuniversal references and, 171, 177-197\noverride, 79-85\nas keyword, 83\nrequirements for overriding, 79-81\nvirtual functions and, 79-85\noversubscription, definition of, 243\n\"Overview of the New C++\" (book), xiii\nP\nparameters\nforwarding, definition of, 207\nof rvalue reference type, 2\nParent, Sean, xiv\npass by value, 281-292\nefficiency of, 283-291\nslicing problem and, 291\nperfect forwarding\n(see also universal references)\nconstructors, 180-183, 188-194\ncopying objects and, 180-183\ninheritance and, 183, 191-193\ndefinition of, 4, 157, 207\nemplacement and, 294\nfailure cases, 207-214\nbitfields, 213\nbraced initializers, 208\ndeclaration-only integral static const\ndata members, 210-211\noverloaded function/template names,\n211\nstd::bind and, 238\nPimpl Idiom, 147-156\ncompilation time and, 148\ncopy operations and, 153-154\ndefinition of, 147\nmove operations and, 152-153\nstd::shared_ptr and, 155-156\nstd::unique_ptr and, 149\npolling, cost/efficiency of, 265\npolymorphic function objects, 239\nprivate and undefined functions, vs. deleted\nfunctions, 74\nproxy class, 45-46\nPython, gratuitous swipe at, 293\nR\nraces, testing for std::thread joinability and, 255\nRAII classes\ndefinition of, 253\nIndex \n| \n311\nwww.it-ebooks.info\n",
      "content_length": 2339,
      "extraction_method": "Direct"
    },
    {
      "page_number": 330,
      "chapter": null,
      "content": "for std::thread objects, 269\nRAII objects, definition of, 253\nraw pointers\nas back pointers, 138\ndefinition of, 6\ndisadvantages of, 117\nread-modify-write (RMW) operations, 272\nstd::atomic and, 272\nvolatile and, 272\nredundant loads, definition of, 276\nreference collapsing, 197-203\nalias declarations and, 202\nauto and, 201\ncontexts for, 201-203\ndecltype and, 203\nrules for, 199\ntypedefs and, 202\nreference count, definition of, 125\nreference counting control blocks (see control\nblocks)\nreference qualifiers\ndefinition of, 80\non member functions, 83-85\nreferences\ndangling, 217\nforwarding, 164\nin binary code, 210\nto arrays, 16\nto references, illegality of, 198\nrelaxed memory consistency, 274\nreporting bugs and suggesting improvements, 6\nResource Acquisition is Initialization (see\nRAII)\nresource management\ncopy operations and destructor and, 111\ndeletion and, 126\nresource ownership, definition of, 117\nreturn value optimization (RVO), 174-176\nrhs, definition of, 3\nRMW (read-modify-write) operations, 272\nRule of Three, definition of, 111\nrvalue references\ndefinition of, 2\nfinal use of, 172\nparameters, 2\npassing to std::forward, 231-232\nvs. universal references, 164-168\nrvalue_cast, 159\nRVO (see return value optimization)\nS\nSchober, Hendrik, xiii\nscoped enums\ndefinition of, 67\nvs. unscoped enums, 67-74\nsequential consistency, definition of, 274\nSFINAE technology, 190\nshallow copy, definition of, 154\nshared ownership, definition of, 125\nshared state\ndefinition of, 259\nfuture destructor behavior and, 259\nreference count in, 259\nshared_from_this, 131\nSimon, Paul, 117\nslicing problem, 291\nsmall string optimization (SSO), 205, 290\nsmart pointers, 117-156\ndangling pointers and, 134\ndefinition of, 6, 118\nexclusive-ownership resource management\nand, 118\nvs. raw pointers, 117\nsoftware threads, definition of, 242\nspecial member functions\ndefinition of, 109\nimplicit generation of, 109-115\nmember function templates and, 115\n\"special\" memory, 275-277\nspurious wakeups, definition of, 264\nSSO (small string optimization), 205, 290\n\"Star Trek\", allusion to, 125\n\"Star Wars\", allusion to, 189\nstatic storage duration, definition of, 222\nstatic_assert, 151, 196\nstd::add_lvalue_reference, 66\nstd::add_lvalue_reference_t, 66\nstd::allocate_shared\nand classes with custom memory manage‐\nment and, 144\nefficiency of, 142\nstd::all_of, 218\nstd::array, move operations and, 204\nstd::async, 243\ndefault launch policy, 246-249\ndestructors for futures from, 259\nlaunch policy, 245\nlaunch policy and thread-local storage,\n247-248\n312 \n| \nIndex\nwww.it-ebooks.info\n",
      "content_length": 2558,
      "extraction_method": "Direct"
    },
    {
      "page_number": 331,
      "chapter": null,
      "content": "launch policy and timeout-based loops, 247\nstd::packaged_task and, 261\nstd::atomic\ncode reordering and, 273\ncopy operations and, 277\nmultiple variables and transactions and,\n106-108\nRMW operations and, 272\nuse with volatile, 279\nvs. volatile, 271-279\nstd::auto_ptr, 118\nstd::basic_ios, 75\nstd::basic_ios::basic_ios, 75\nstd::basic_ios::operator=, 75\nstd::bind\nbound and unbound arguments and, 238\ninlining and, 236\nmove capture and, 238\nmove capture emulation and, 226-229\noverloading and, 235\nperfect forwarding and, 238\npolymorphic function objects and, 239\nreadability and, 232-236\nvs. lambdas, 232-240\nstd::cbegin, 88\nstd::cend, 88\nstd::crbegin, 88\nstd::crend, 88\nstd::decay, 190\nstd::enable_if, 189-194\nstd::enable_shared_from_this, 131-132\nstd::false_type, 187\nstd::forward, 161-162, 199-201\nby-value return and, 172-176\ncasts and, 158\npassing rvalue references to, 231\nreplacing std::move with, 162\nuniversal references and, 168-173\nstd::function, 39-40\nstd::future<void>, 267\nstd::initializer_lists, braced initializers and, 52\nstd::is_base_of, 192\nstd::is_constructible, 195\nstd::is_nothrow_move_constructible, 92\nstd::is_same, 190-191\nstd::launch::async, 246\nautomating use as launch policy, 249\nstd::launch::deferred, 246\ntimeout-based loops and, 247\nstd::literals, 233\nstd::make_shared, 139-147, 171\n(see also make functions)\nalternatives to, 298\nclasses with custom memory management\nand, 144\nefficiency of, 142\nlarge objects and, 144-145\nstd::make_unique, 139-147, 171\n(see also make functions)\nstd::move, 158-161\nby-value parameters and, 283\nby-value return and, 172-176\ncasts and, 158\nconst objects and, 159-161\nreplacing with std::forward, 162-163\nrvalue references and, 168-173\nuniversal references and, 169\nstd::move_if_noexcept, 92\nstd::nullptr_t, 59\nstd::operator, 160\nstd::operator=, 75\nstd::operator[], 24, 46\nstd::packaged_task, 261-262\nstd::async and, 261\nstd::pair, 93\nstd::pair::swap, 93\nstd::plus, 235\nstd::promise, 258\nsetting, 266\nstd::promise<void>, 267\nstd::rbegin, 88\nstd::ref, 238\nstd::remove_const, 66\nstd::remove_const_t, 66\nstd::remove_reference, 66\nstd::remove_reference_t, 66\nstd::rend, 88\nstd::result_of, 249\nstd::shared_future<void>, 267\nstd::shared_ptr, 125-134\narrays and, 133\nconstruction from raw pointer, 129-132\nconstruction from this, 130-132\nconversion from std::unique_ptr, 124\ncreating from std::weak_ptr, 135\ncycles and, 137\ndeleters and, 126\nvs. std::unique_ptr deleters, 155\nIndex \n| \n313\nwww.it-ebooks.info\n",
      "content_length": 2461,
      "extraction_method": "Direct"
    },
    {
      "page_number": 332,
      "chapter": null,
      "content": "efficiency of, 125, 133\nmove operations and, 126\nmultiple control blocks and, 129\nsize of, 126\nvs. std::weak_ptr, 134\nstd::string, move operations and, 205\nstd::swap, 93\nstd::system_error, 242\nstd::threads\nas data members, member initialization\norder and, 254\ndestroying joinable, 251-253\nimplicit join or detach, 252\njoinable vs. unjoinable, 250\nRAII class for, 253-257, 269\nstd::true_type, 187\nstd::unique_ptr, 118-124\nconversion to std::shared_ptr, 124\ndeleters and, 120-123, 126\nvs. std::shared_ptr deleters, 155\nefficiency of, 118\nfactory functions and, 119-123\nfor arrays, 124\nsize of, 123\nstd::vector, 24, 166, 292\nstd::vector constructors, 56\nstd::vector::emplace_back, 167\nstd::vector::push_back, 166, 292\nstd::vector<bool>, 43-46\nstd::vector<bool>::operator[], 46\nstd::vector<bool>::reference, 43-45\nstd::weak_ptr, 134-139\ncaching and, 136\nconstruction of std::shared_ptr with, 135\ncycles and, 137\nefficiency of, 138\nexpired, 135\nobserver design pattern and, 137\nvs. std::shared_ptr, 134\nSteagall, Bob, xiv\nStewart, Rob, xiv\nstrong guarantee\ndefinition of, 4\nmove operations and, 205\nnoexcept and, 91\nSummer, Donna, 294\nSupercalifragilisticexpialidocious, 289\nSutter, Herb, xiv\nsystem threads, 242\nT\nT&&, meanings of, 164\ntag dispatch, 185-188\ntask-based programming, definition of, 241\ntasks\nload balancing and, 244\nquerying for deferred status, 248\nvs. threads, 241-245\ntemplate\nalias templates, 63-65\naliases, 63\nclasses, definition of, 5\ndisabled vs. enabled, 189\nfunctions, definition of, 5\ninstantiations, deleting, 77\nmove operations and, 206\nnames, perfect forwarding and, 211\nparentheses vs. braces in, 57\nstandard operators and type arguments for,\n235\ntype deduction, 9-18\narray arguments and, 15-17\nfor pass by value, 14-15\nfor pointer and reference types, 11-14\nfor universal references, 13-14\nfunction arguments and, 17\nvs. auto type deduction, 18-19\nterminology and conventions, 2-6\ntesting std::threads for joinability, 255\n\"The Hitchhiker's Guide to the Galaxy\", allu‐\nsion to, 30\n\"The View from Aristeia\" (blog), xv, 269\nthread handle destructor behavior, 258-262\nthread local storage (TLS), definition of, 247\nthread-based programming, definition of, 241\nthreads\ndestruction, 252\nexhaustion, 243\nfunction return values and, 242\nhardware, 242\nimplicit join or detach, 252\njoinable vs. unjoinable, 250\nOS threads, 242\nsetting priority/affinity, 245, 252, 268\nsoftware, 242\nsuspending, 268-270\nsystem threads, 242\ntesting for joinability, 255\nvs. tasks, 241-245\n314 \n| \nIndex\nwww.it-ebooks.info\n",
      "content_length": 2520,
      "extraction_method": "Direct"
    },
    {
      "page_number": 333,
      "chapter": null,
      "content": "thread_local variables, 247\ntime suffixes, 233\ntimeout-based loops, 247\nTLS (see thread-local storage)\ntranslation, definition of, 97\ntype arguments, operator templates and, 235\ntype deduction\n(see also template, type deduction)\nfor auto, 18-23\nemplace_back and, 166\nuniversal references and, 165\ntype inference (see type deduction)\ntype traits, 66-67\ntype transformations, 66\ntypedefs, reference collapsing and, 202\ntypeid and viewing deduced types, 31-33\ntypename\ndependent type and, 64\nnon-dependent type and, 64\nvs. class for template parameters, 3\ntypes, testing for equality, 190\nU\nundefined behavior, definition of, 6\nundefined template to elicit compiler error\nmessages, 31\nuniform initialization, 50\nuniversal references\n(see also perfect forwarding)\nadvantages over overloading, 171\nalternatives to overloading on, 183-197\nauto and, 167\nconstructors and, 180-183, 188-194\nefficiency and, 178\nerror messages and, 195-196\nfinal use of, 172\ngreedy functions and, 180\ninitializers and, 165\nlvalue/rvalue encoding, 197\nnames of, 167\noverloading and, 177-197\nreal meaning of, 202\nstd::move and, 169\nsyntactic form of, 165\ntype deduction and, 165\nvs. rvalue references, 164-168\nunjoinable std::threads, definition of, 250\nunscoped enums\ndefinition of, 67\nvs. scoped enums, 67-74\nUrbano, Nancy L. (see feminine manifestation\nof the divine)\nV\nVandewoestyn, Bart, xiv\nvariadic lambdas, 231\n\"View from Aristeia, The\" (blog), xv, 269\nvirtual functions, override and, 79-85\nvoid future, 267\nvolatile\ncode reordering and, 275\ndead stores and, 276\nredundant loads and, 276\nRMW operations and, 272\n\"special\" memory and, 275-277\nuse with std::atomic, 279\nvs. std::atomic, 271-279\nW\nWakely, Jonathan, xiv\nwarnings, compiler (see compiler warnings)\nWatkins, Damien, xiv\nweak count, definition of, 144\nweak memory consistency, 274\nwide contracts, definition of, 95-96\nwide ellipsis, 3\nWidget, definition of, 3\nWilliams, Anthony, xiii, 257\nWilliams, Ashley Morgan, xv\nWilliams, Emyr, xv\nWinkler, Fredrik, xiv\nWinterberg, Michael, xiv\nY\nYiddish, gratuitous use of, 82\nZ\nZolman, Leor, xiii, xiv\nZuse, Konrad, 195\nIndex \n| \n315\nwww.it-ebooks.info\n",
      "content_length": 2133,
      "extraction_method": "Direct"
    },
    {
      "page_number": 334,
      "chapter": null,
      "content": "About the Author\nScott Meyers is one of the world’s foremost experts on C++. A sought-after trainer,\nconsultant, and conference presenter, his Effective C++ books (Effective C++, More\nEffective C++, and Effective STL) have set the bar for C++ programming guidance for\nmore than 20 years. He has a Ph.D. in computer science from Brown University. His\nwebsite is aristeia.com.\nColophon\nThe animal on the cover of Effective Modern C++ is a Rose-crowned fruit dove (Ptili‐\nnopus regina). This species of dove also goes by the names pink-capped fruit dove or\nSwainson’s fruit dove. It is distinguished by its striking plumage: grey head and\nbreast, orange belly, whitish throat, yellow-orange iris, and grey green bill and feet.\nDistributed in lowland rainforests in eastern Australia, monsoon forests in northern\nAustralia, and the Lesser Sunda Islands and Maluku Islands of Indonesia, the Rose-\ncrowned fruit dove’s diet consists of various fruits like figs (which it swallows whole),\npalms, and vines. Camphor Laurel, a large evergreen tree, is another food source for\nthe fruit dove. They feed—in pairs, small parties, or singly—in rainforest canopies,\nusually in the morning or late afternoon. To hydrate, they get water from leaves or\ndew, not from the ground.\nThe fruit dove is considered vulnerable in New South Wales due to rainforest clear‐\ning and fragmentation, logging, weeds, fire regime–altered habitats, and the removal\nof Laurel Camphor without adequate alternatives.\nMany of the animals on O’Reilly covers are endangered; all of them are important to\nthe world. To learn more about how you can help, go to animals.oreilly.com.\nThe cover image is from Wood’s Illustrated Natural History, bird volume. The cover\nfonts are URW Typewriter and Guardian Sans. The text font is Adobe Minion Pro;\nthe heading font is Adobe Myriad Condensed; and the code font is Dalton Maag’s\nUbuntu Mono.\nwww.it-ebooks.info\n",
      "content_length": 1913,
      "extraction_method": "Direct"
    }
  ],
  "enrichment": {
    "version": "1.0.0",
    "generated_by": "generate_chapter_metadata.py",
    "contains": [
      "keywords",
      "concepts",
      "summary"
    ]
  }
}