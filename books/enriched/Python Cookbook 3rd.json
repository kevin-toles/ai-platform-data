{
  "metadata": {
    "title": "Python Cookbook 3rd",
    "source_file": "Python Cookbook 3rd_metadata.json"
  },
  "chapters": [
    {
      "chapter_number": 1,
      "title": "Data Structures and Algorithms",
      "start_page": 1,
      "end_page": 60,
      "summary": "Recipes for Mastering Python 3\nIf you need help writing programs in Python 3, or want to update David Beazley, an independent\nolder Python 2 code, this book is just the ticket.\npractical recipes written and tested with Python 3.3, this unique programming courses for\nthe Python E.\ncovering the core Python language as well as tasks common to a created several open-source\nEach recipe contains code Python packages.\nO’Reilly books may be purchased for educational, business, or sales promotional use.\nKeeping the Last N Items                                                                                           5\nFinding the Largest or Smallest N Items                                                                 7\nMapping Keys to Multiple Values in a Dictionary                                               11\nDetermining the Most Frequently Occurring Items in a Sequence                20\nSorting a List of Dictionaries by a Common Key                                              21\nCreating New Iteration Patterns with Generators                                             115\nIterating Over the Index-Value Pairs of a Sequence                                        127\nIterating on Items in Separate Containers                                                        131\nReading and Writing Text Data                                                                            141\nWriting Functions That Accept Any Number of Arguments                           217\nReturning Multiple Values from a Function                                                       221\nReplacing Single Method Classes with Functions                                              231\nCreating a New Kind of Class or Instance Attribute                                         264\nDisassembling Python Byte Code                                                                      392\nMaking Separate Directories of Code Import Under a Common\nCreating a New Python Environment                                                             432\nWriting an Extension Function That Operates on Arrays                              609\nCalling Python from C                                                                                        619\nMixing Threads from C and Python                                                                 625\nConverting C Strings to Python                                                                       653\nReading File-Like Objects from C                                                                   659\nat the time of this writing (2013), most working Python programmers continue to use\nAll of the recipes have been written and tested with Python 3.3 without\nrecipes will only work with Python 3.3 and above.\nbut the ultimate goal is to write a book of recipes based on the most modern tools and\ncode in Python 3 or those who hope to modernize existing code.\nAn online search for Python recipes returns literally thousands of useful recipes\nRather than attempting to seek out Python 3-specific recipes, the topics of this book are\nwho wants to write their code in a modern style.\nPython.\nmany of the recipes aim to illustrate features that are new to Python 3 and more likely\nThis book is aimed at more experienced Python programmers who are looking to\nknows how to use search engines and Python’s excellent online documentation.\nThis is not a book designed for beginners trying to learn Python for the first time.\nmanual (e.g., quickly looking up the functions in a specific module).\nsuch as variable or function names, databases, data types, environment variables,\nShows text that should be replaced with user-supplied values or by values deter‐\nOnline Code Examples\nAlmost all of the code examples in this book are available online at http://github.com/\nUsing Code Examples\nexamples, you may use the code in this book in your programs and documentation.\nFor example, writing a program that uses several chunks of code from this\nof example code from this book into your product’s documentation does require per‐\nFor example: Python Cookbook, 3rd edition, by David\nIf you feel your use of code examples falls outside fair use or the permission given here,\nSafari Books Online offers a range of product mixes and pricing programs for organi‐\nWe have a web page for this book, where we list errata, examples, and any additional\nbook was derived from content I developed teaching Python-related training classes\nleast, I’d like to thank the Python community for their continued support and putting\nMost of all, I’d like to thank the Python\nPython provides a variety of useful built-in data structures, such as lists, sets, and dic‐\nYou have an N-element tuple or sequence that you would like to unpack into a collection\nAny sequence (or iterable) can be unpacked into variables using a simple assignment\n>>> name, shares, price, date = data\n>>> name, shares, price, (year, mon, day) = data\nValueError: need more than 2 values to unpack\nUnpacking actually works with any object that happens to be iterable, not just tuples or\nThis includes strings, files, iterators, and generators.\n>>> a, b, c, d, e = s\nWhen unpacking, you may sometimes want to discard certain values.\nPython has no\n>>> _, shares, price, _ = data\nAs another use case, suppose you have user records that consist of a name and email\n>>> record = ('Dave', 'dave@example.com', '773-555-1212', '847-555-1212')\nThus, any code that uses\nFor example, perhaps a sequence of tagged tuples:\nStar unpacking can also be useful when combined with certain kinds of string processing\nSometimes you might want to unpack values and throw them away.\nFor example, if you have a list, you can easily split it into head\n>>> items = [1, 10, 7, 4, 5, 9]\nOne could imagine writing functions that perform such splitting in order to carry out\n>>> def sum(items):\n>>> sum(items)\nKeeping the Last N Items\nYou want to keep a limited history of the last few items seen during iteration or during\nfollowing code performs a simple text match on a sequence of lines and yields the\nKeeping the Last N Items \n# Example use on a file\nWhen writing code to search for items, it is common to use a generator function in‐\nfrom the code that uses the results.\nWhen new items are added and\nAlthough you could manually perform such operations on a list (e.g., appending, de‐\nAdding or popping items from either end of a queue has O(1) complexity.\na list where inserting or removing items from the front of the list is O(N).\nFinding the Largest or Smallest N Items\nYou want to make a list of the largest or smallest N items in a collection.\nBoth functions also accept a key parameter that allows them to be used with more\ncheap = heapq.nsmallest(3, portfolio, key=lambda s: s['price'])\nexpensive = heapq.nlargest(3, portfolio, key=lambda s: s['price'])\nIf you are looking for the N smallest or largest items and N is small compared to the\nFinding the Largest or Smallest N Items \nthe covers, they work by first converting the data into a list where items are ordered as\nThe most important feature of a heap is that heap[0] is always the smallest item.\nover, subsequent items can be easily found using the heapq.heappop() method, which\npops off the first item and replaces it with the next smallest item (an operation that\nthree smallest items, you would do this:\nor largest item (N=1), it is faster to use min() and max().\nuse sorted(items)[:N] or sorted(items)[-N:]).\nAlthough it’s not necessary to use this recipe, the implementation of a heap is an inter‐\nYou want to implement a queue that sorts items by a given priority and always returns\nthe item with the highest priority on each pop operation.\nThe following class uses the heapq module to implement a simple priority queue:\ndef push(self, item, priority):\nheapq.heappush(self._queue, (-priority, self._index, item))\n>>> class Item:\nreturn 'Item({!r})'.format(self.name)\n>>> q.push(Item('foo'), 1)\n>>> q.push(Item('bar'), 5)\n>>> q.push(Item('spam'), 4)\n>>> q.push(Item('grok'), 1)\nItem('bar')\nItem('spam')\nItem('foo')\nItem('grok')\nObserve how the first pop() operation returned the item with the highest priority.\nobserve how the two items with the same priority (foo and grok) were returned in the\nThe core of this recipe concerns the use of the heapq module.\npush() and heapq.heappop() insert and remove items from a list _queue in a way such\nthat the first item in the list has the smallest priority (as discussed in Recipe 1.4).\nheappop() method always returns the “smallest” item, so that is the key to making the\nN) complexity where N is the number of items in the heap, they are fairly efficient even\nfor fairly large values of N.\nIn this recipe, the queue consists of tuples of the form (-priority, index, item).\npriority value is negated to get the queue to sort items from highest priority to lowest\nvalue.\nThe role of the index variable is to properly order items with the same priority level.\nBy keeping a constantly increasing index, the items will be sorted according to the order\nthe comparison operations work for items that have the same priority level.\nTo elaborate on that, instances of Item in the example can’t be ordered.\n>>> a = Item('foo')\n>>> b = Item('bar')\nIf you make (priority, item) tuples, they can be compared as long as the priorities\n>>> a = (1, Item('foo'))\n>>> b = (5, Item('bar'))\n>>> c = (1, Item('grok'))\nBy introducing the extra index and making (priority, index, item) tuples, you avoid\nthis problem entirely since no two tuples will ever have the same value for index (and\nPython never bothers to compare the remaining tuple values once the result of com‐\n>>> a = (1, 0, Item('foo'))\n>>> b = (5, 1, Item('bar'))\n>>> c = (1, 2, Item('grok'))\nIf you want to use this queue for communication between threads, you need to add\nSee Recipe 12.3 for an example of how to do this.\nMapping Keys to Multiple Values in a Dictionary\nYou want to make a dictionary that maps keys to more than one value (a so-called\nA dictionary is a mapping where each key is mapped to a single value.\nmap keys to multiple values, you need to store the multiple values in another container\nFor example, you might make dictionaries like this:\nThe choice of whether or not to use lists or sets depends on intended use.\nUse a list if\nyou want to preserve the insertion order of the items.\nUse a set if you want to eliminate\nTo easily construct such dictionaries, you can use defaultdict in the collections\nyou can simply focus on adding items.\nMapping Keys to Multiple Values in a Dictionary \nkeys accessed later on (even if they aren’t currently found in the dictionary).\nwant this behavior, you might use setdefault() on an ordinary dictionary instead.\ntion the fact that it always creates a new instance of the initial value on each invocation\n(the empty list [] in the example).\ncode that looks like this:\nfor key, value in pairs:\nif key not in d:\nd[key] = []\nd[key].append(value)\nfor key, value in pairs:\nd[key].append(value)\nThis recipe is strongly related to the problem of grouping records together in data pro‐\nSee Recipe 1.15 for an example.\nYou want to create a dictionary, and you also want to control the order of items when\nTo control the order of items in a dictionary, you can use an OrderedDict from the\nfor key in d:\nprint(key, d[key])\nAn OrderedDict can be particularly useful when you want to build a mapping that you\nFor example, if you want\nAn OrderedDict internally maintains a doubly linked list that orders the keys according\nWhen a new item is first inserted, it is placed at the end of this list.\nstructure involving a large number of OrderedDict instances (e.g., reading 100,000 lines\nof a CSV file into a list of OrderedDict instances), you would need to study the re‐\nYou want to perform various calculations (e.g., minimum value, maximum value, sort‐\ning, etc.) on a dictionary of data.\nConsider a dictionary that maps stock names to prices:\nIn order to perform useful calculations on the dictionary contents, it is often useful to\ninvert the keys and values of the dictionary using zip().\nmin_price = min(zip(prices.values(), prices.keys()))\nmax_price = max(zip(prices.values(), prices.keys()))\nSimilarly, to rank the data, use zip() with sorted(), as in the following:\nprices_sorted = sorted(zip(prices.values(), prices.keys()))\nFor example, the following code is an error:\nprices_and_names = zip(prices.values(), prices.keys())\nprint(max(prices_and_names))   # ValueError: max() arg is an empty sequence\nIf you try to perform common data reductions on a dictionary, you’ll find that they only\nprocess the keys, not the values.\nlation involving the dictionary values.\nmin(prices.values())  # Returns 10.75\nmax(prices.values())  # Returns 612.78\nFor example, you may want\nto know information about the corresponding keys (e.g., which stock has the lowest\nYou can get the key corresponding to the min or max value if you supply a key function\nmin(prices, key=lambda k: prices[k])  # Returns 'FB'\nmax(prices, key=lambda k: prices[k])  # Returns 'AAPL'\nHowever, to get the minimum value, you’ll need to perform an extra lookup step.\nmin_value = prices[min(prices, key=lambda k: prices[k])]\nsequence of (value, key) pairs.\nvalue element is compared first, followed by the key.\nthat you want and allows reductions and sorting to be easily performed on the dictionary\nIt should be noted that in calculations involving (value, key) pairs, the key will be\nvalue.\nor largest key will be returned if there happen to be duplicate values.\n>>> min(zip(prices.values(), prices.keys()))\n>>> max(zip(prices.values(), prices.keys()))\nYou have two dictionaries and want to find out what they might have in common (same\nkeys, same values, etc.).\nTo find out what the two dictionaries have in common, simply perform common set\noperations using the keys() or items() methods.\n# Find keys in common\na.keys() & b.keys()   # { 'x', 'y' }\n# Find keys in a that are not in b\n# Find (key,value) pairs in common\na.items() & b.items() # { ('y', 2) }\nexample, suppose you want to make a new dictionary with selected keys removed.\nis some sample code using a dictionary comprehension:\n# Make a new dictionary with certain keys removed\nA dictionary is a mapping between a set of keys and values.\nThe keys() method of a\ndictionary returns a keys-view object that exposes the keys.\nkeys views is that they also support common set operations such as unions, intersections,\nThus, if you need to perform common set operations with dictionary\nkeys, you can often just use the keys-view objects directly without first converting them\nThe items() method of a dictionary returns an items-view object consisting of (key,\noperations such as finding out which key-value pairs two dictionaries have in common.\nAlthough similar, the values() method of a dictionary does not support the set oper‐\nIn part, this is due to the fact that unlike keys, the items\nYou want to eliminate the duplicate values in a sequence, but preserve the order of the\nIf the values in the sequence are hashable, the problem can be easily solved using a set\ndef dedupe(items):\nif item not in seen:\nyield item\nHere is an example of how to use your function:\nThis only works if the items in the sequence are hashable.\ndef dedupe(items, key=None):\nval = item if key is None else key(item)\nyield item\nHere, the purpose of the key argument is to specify a function that converts sequence\n>>> list(dedupe(a, key=lambda d: (d['x'],d['y'])))\n>>> list(dedupe(a, key=lambda d: d['x']))\nvalue of a single field or attribute or a larger data structure.\nThe use of a generator function in this recipe reflects the fact that you might want the\nFor example, if you want to read a file, eliminating duplicate lines, you could simply\nThe specification of a key function mimics similar functionality in built-in functions\nSuppose you have some code that is pulling specific data fields out of a record string\nAs a general rule, writing code with a lot of hardcoded index values leads to a readability\nFor example, if you come back to the code a year later, you’ll\n>>> items = [0, 1, 2, 3, 4, 5, 6]\n>>> items[2:4]\n>>> items[a]\n>>> items[a] = [10,11]\n>>> items\n>>> items\nThis returns a tuple (start, stop, step) where all values have\nYou have a sequence of items, and you’d like to determine the most frequently occurring\nitems in the sequence.\nAs input, Counter objects can be fed any sequence of hashable input items.\ncovers, a Counter is a dictionary that maps the items to the number of occurrences.\nIf you want to increment the count manually, simply use addition:\nSorting a List of Dictionaries by a Common Key\nYou have a list of dictionaries and you would like to sort the entries according to one\nor more of the dictionary values.\nSorting a List of Dictionaries by a Common Key \nSorting this type of structure is easy using the operator module’s itemgetter function.\nand you receive the following data structure in return:\ndictionaries.\nrows_by_fname = sorted(rows, key=itemgetter('fname'))\nrows_by_uid = sorted(rows, key=itemgetter('uid'))\nThe itemgetter() function can also accept multiple keys.\nFor example, this code\nrows_by_lfname = sorted(rows, key=itemgetter('lname','fname'))\nIn this example, rows is passed to the built-in sorted() function, which accepts a key‐\nword argument key.\nfrom rows as input and returns a value that will be used as the basis for sorting.\nThe operator.itemgetter() function takes as arguments the lookup indices used to\nextract the desired values from the records in rows.\nIt can be a dictionary key name, a\nnumeric list element, or any value that can be fed to an object’s __getitem__() method.\nThis can be useful if you want to simultaneously sort on multiple\nrows_by_fname = sorted(rows, key=lambda r: r['fname'])\nrows_by_lfname = sorted(rows, key=lambda r: (r['lname'],r['fname']))\n>>> min(rows, key=itemgetter('uid'))\n>>> max(rows, key=itemgetter('uid'))\nYou want to sort objects of the same class, but they don’t natively support comparison\nThe built-in sorted() function takes a key argument that can be passed a callable that\nwill return some value in the object that sorted will use to compare the objects.\nexample, if you have a sequence of User instances in your application, and you want to\n>>> sorted(users, key=lambda u: u.user_id)\n>>> sorted(users, key=attrgetter('user_id'))\nthe use of operator.itemgetter() for dictionaries (see Recipe 1.13).\nby_name = sorted(users, key=attrgetter('last_name', 'first_name'))\nYou have a sequence of dictionaries or instances and you want to iterate over the data\nin groups based on the value of a particular field, such as date.\nThe itertools.groupby() function is particularly useful for grouping data together\nTo illustrate, suppose you have the following list of dictionaries:\nNow suppose you want to iterate over the data in chunks grouped by date.\nsort by the desired field (in this case, date) and then use itertools.groupby():\nrows.sort(key=itemgetter('date'))\nfor date, items in groupby(rows, key=itemgetter('date')):\nfor i in items:\nof identical values (or values returned by the given key function).\nreturns the value along with an iterator that produces all of the items in a group with\nthe same value.\nAn important preliminary step is sorting the data according to the field of interest.\ngroupby() only examines consecutive items, failing to sort first won’t group the records\nIf your goal is to simply group the data together by dates into a large data structure that\nrows_by_date = defaultdict(list)\nThis allows the records for each date to be accessed easily like this:\nFor this latter example, it’s not necessary to sort the records first.\nconcern, it may be faster to do this than to first sort the records and iterate using\nYou have data inside of a sequence, and need to extract values or reduce the sequence\nThe easiest way to filter sequence data is often to use a list comprehension.\nto produce the filtered values iteratively.\nfunction and use the built-in filter() function.\nvalues = ['1', '2', '-3', '-', '4', 'N/A', '5']\nivals = list(filter(is_int, values))\nfilter() creates an iterator, so if you want to create a list of results, make sure you also\nuse list() as shown.\nitems in the iterable where the corresponding element in the selector is True.\nbe useful if you’re trying to apply the results of filtering one sequence to another related\nFor example, suppose you have the following two columns of data:\nNow suppose you want to make a list of all addresses where the corresponding count\nThe key here is to first create a sequence of Booleans that indicates which elements\nThe compress() function then picks out the items corre‐\nLike filter(), compress() normally returns an iterator.\nThus, you need to use list()\nYou want to make a dictionary that is a subset of another dictionary.\n# Make a dictionary of all prices over 200\np1 = { key:value for key, value in prices.items() if value > 200 }\n# Make a dictionary of tech stocks\np2 = { key:value for key,value in prices.items() if key in tech_names }\nby creating a sequence of tuples and passing them to the dict() function.\np1 = dict((key, value) for key, value in prices.items() if value > 200)\na bit faster (over twice as fast when tested on the prices dictionary used in the example).\n# Make a dictionary of tech stocks\nYou have code that accesses list or tuple elements by position, but this makes the code\nmethod that returns a subclass of the standard Python tuple type.\nAlthough an instance of a namedtuple looks like a normal class instance, it is inter‐\nA major use case for named tuples is decoupling your code from the position of the\nReferences to positional elements often make the code a bit less expressive and more\nsequence in the example already contained such instances.\nOne possible use of a namedtuple is as a replacement for a dictionary, which requires\nThus, if you are building large data structures involving dictionaries,\ntuple containing the default values and then use _replace() to create new instances\nwith values replaced.\nStock = namedtuple('Stock', ['name', 'shares', 'price', 'date', 'time'])\n# Function to convert a dictionary to a Stock\nHere is an example of how this code would work:\nStock(name='ACME', shares=100, price=123.45, date=None, time=None)\n>>> b = {'name': 'ACME', 'shares': 100, 'price': 123.45, 'date': '12/17/2012'}\nStock(name='ACME', shares=100, price=123.45, date='12/17/2012', time=None)\nA very elegant way to combine a data reduction and a transformation is to use a \nFor example, if you want to calculate the sum of\nprint('There be python!')\nprint('Sorry, no python.')\nFor example, if you didn’t use a generator expression, you\nthe data iteratively and is therefore much more memory-efficient.\nCertain reduction functions such as min() and max() accept a key argument that might\nmin_shares = min(portfolio, key=lambda s: s['shares'])\nYou have multiple dictionaries or mappings that you want to logically combine into a\nsingle mapping to perform certain operations, such as looking up values or checking\nNow suppose you want to perform lookups where you have to check both dictionaries\nprint(c['x'])      # Outputs 1  (from a)\nprint(c['y'])      # Outputs 2  (from b)\n>>> list(c.keys())\n>>> list(c.values())\nIf there are duplicate keys, the values from the first mapping get used.\nc['z'] in the example would always refer to the value in dictionary a, not the va",
      "keywords": [
        "Data Structures",
        "Data",
        "Python",
        "Items",
        "Key",
        "Sequence",
        "List",
        "Dictionary",
        "code",
        "Structures and Algorithms",
        "Structures",
        "Function",
        "Python Cookbook",
        "User",
        "Keys"
      ],
      "concepts": [
        "python",
        "items",
        "data",
        "values",
        "useful",
        "uses",
        "keys",
        "key",
        "functions",
        "function"
      ],
      "similar_chapters": [
        {
          "book": "Python Cookbook 3rd",
          "chapter": 5,
          "title": "",
          "score": 0.582,
          "base_score": 0.432,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Python Cookbook 3rd",
          "chapter": 3,
          "title": "",
          "score": 0.5,
          "base_score": 0.35,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Python Cookbook 3rd",
          "chapter": 6,
          "title": "",
          "score": 0.5,
          "base_score": 0.5,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Python Cookbook 3rd",
          "chapter": 4,
          "title": "",
          "score": 0.489,
          "base_score": 0.339,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Python Cookbook 3rd",
          "chapter": 14,
          "title": "",
          "score": 0.386,
          "base_score": 0.386,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "key",
          "items",
          "prices",
          "keys",
          "dictionary"
        ],
        "semantic": [],
        "merged": [
          "key",
          "items",
          "prices",
          "keys",
          "dictionary"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.3858863204766031,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:08:10.208552+00:00"
      }
    },
    {
      "chapter_number": 2,
      "title": "Strings and Text",
      "start_page": 61,
      "end_page": 120,
      "summary": "If you’re going to perform a lot of matches using the same pattern, it usually pays to\n>>> if datepat.match(text1):\n>>> if datepat.match(text2):\nmatch() always tries to find the match at the start of a string.\nIf you want to search text\nfor all occurrences of a pattern, use the findall() method instead.\n>>> text = 'Today is 11/27/2012.\n>>> datepat.findall(text)\nCapture groups often simplify subsequent processing of the matched text because the\nMatching and Searching for Text Patterns \n>>> text\n>>> datepat.findall(text)\nThe findall() method searches the text and finds all matches, returning them as a list.\nIf you want to find matches iteratively, use the finditer() method instead.\n>>> for m in datepat.finditer(text):\nHowever, this recipe illustrates the absolute basics of using the re module to match and\nsearch for text.\nre.compile() and then using methods such as match(), findall(), or finditer().\nWhen specifying patterns, it is relatively common to use raw strings such as\nSuch strings leave the backslash character uninterpreted,\nwhich can be useful in the context of regular expressions.\nOtherwise, you need to use\nBe aware that the match() method only checks the beginning of a string.\nIf you want an exact match, make sure the pattern includes the end-marker ($), as in\nChapter 2: Strings and Text\nLast, if you’re just doing a simple text matching/searching operation, you can often skip\nthe compilation step and use module-level functions in the re module instead.\n>>> re.findall(r'(\\d+)/(\\d+)/(\\d+)', text)\nBe aware, though, that if you’re going to perform a lot of matching or searching, it usually\npays to compile the pattern first and use it over and over again.\nSearching and Replacing Text\nYou want to search for and replace a text pattern in a string.\nFor simple literal patterns, use the str.replace() method.\n>>> text.replace('yeah', 'yep')\nFor more complicated patterns, use the sub() functions/methods in the re module.\n>>> text = 'Today is 11/27/2012.\n>>> re.sub(r'(\\d+)/(\\d+)/(\\d+)', r'\\3-\\1-\\2', text)\nSearching and Replacing Text \n>>> datepat.sub(r'\\3-\\1-\\2', text)\n>>> datepat.sub(change_date, text)\nAs input, the argument to the substitution callback is a match object, as returned by \nmatch() or find().\nUse the .group() method to extract specific parts of the match.\nfunction should return the replacement text.\nreplacement text, use re.subn() instead.\n>>> newtext, n = datepat.subn(r'\\3-\\1-\\2', text)\nThere isn’t much more to regular expression search and replace than the sub() method\nSearching and Replacing Case-Insensitive Text\nYou need to search for and possibly replace text in a case-insensitive manner.\nChapter 2: Strings and Text\nTo perform case-insensitive text operations, you need to use the re module and supply\n>>> text = 'UPPER PYTHON, lower python, Mixed Python'\n>>> re.findall('python', text, flags=re.IGNORECASE)\n>>> re.sub('python', 'snake', text, flags=re.IGNORECASE)\nThe last example reveals a limitation that replacing text won’t match the case of the\nmatched text.\nIf you need to fix this, you might have to use a support function, as in the\ntext = m.group()\nif text.isupper():\nelif text.islower():\nelif text[0].isupper():\nHere is an example of using this last function:\n>>> re.sub('python', matchcase('snake'), text, flags=re.IGNORECASE)\nMatch\nYou’re trying to match a text pattern using regular expressions, but it is identifying the\nlongest possible matches of a pattern.\nSpecifying a Regular Expression for the Shortest Match \nThis problem often arises in patterns that try to match text enclosed inside a pair of\nstarting and ending delimiters (e.g., a quoted string).\n>>> text1 = 'Computer says \"no.\"'\n>>> str_pat.findall(text1)\n>>> str_pat.findall(text2)\nIn this example, the pattern r'\\\"(.*)\\\"' is attempting to match text enclosed inside\nHowever, the * operator in a regular expression is greedy, so matching is based\nThus, in the second example involving text2, it\nincorrectly matches the two quoted strings.\n>>> str_pat.findall(text2)\nIn a pattern, the dot matches any\ntext (such as a quote), matching will try to find the longest possible match to the pattern.\nYou’re trying to match a block of text using a regular expression, but you need the match\nChapter 2: Strings and Text\nThis problem typically arises in patterns that use the dot (.) to match any character but\nare trying to match C-style comments:\n>>> text1 = '/* this is a comment */'\n>>> text2 = '''/* this is a\n>>> comment.findall(text1)\n>>> comment.findall(text2)\n>>> comment.findall(text2)\npurposes of matching, but that group is not captured separately or numbered).\nThe re.compile() function accepts a flag, re.DOTALL, which is useful here.\nin a regular expression match all characters, including newlines.\n>>> comment.findall(text2)\nworking with extremely complicated patterns or a mix of separate regular expressions\nIf given a choice, it’s usually better to define your regular expression pattern\nNormalizing Unicode Text to a Standard\nYou’re working with Unicode strings, but need to make sure that all of the strings have\norder to fix this, you should first normalize the text into a standard representation using\nChapter 2: Strings and Text\nThe first argument to normalize() specifies how you want the string normalized.\nmeans that characters should be fully composed (i.e., use a single code point if possible).\nNFD means that characters should be fully decomposed with the use of combining char‐\nNormalization is an important part of any code that needs to ensure that it processes\nUnicode text in a sane and consistent way.\nNormalization can also be an important part of sanitizing and filtering text.\nsuppose you want to remove all diacritical marks from some text (possibly for the pur‐\nNormalizing Unicode Text to a Standard Representation \nWorking with Unicode Characters in Regular\nYou are using regular expressions to process text, but are concerned about the handling\nFor example, \\d already matches any unicode digit\n>>> num.match('123')\n<_sre.SRE_Match object at 0x101234030>\nIf you need to include specific Unicode characters in patterns, you can use the usual\nis a regex that matches all characters in a few different Arabic code pages:\nWhen performing matching and searching operations, it’s a good idea to normalize and\npossibly sanitize all text to a standard form first (see Recipe 2.9).\nChapter 2: Strings and Text\nStripping Unwanted Characters from Strings\nmiddle of a text string.\nstring.\nFor example, you can use them to get rid of whitespace, remove\nBe aware that stripping does not apply to any text in the middle of a string.\nStripping Unwanted Characters from Strings \nnique, such as using the replace() method or a regular expression substitution.\nIt is often the case that you want to combine string stripping operations with some other\narea where a generator expression can be useful.\nHere, the expression lines = (line.strip() for line in f) acts as a kind of data\nnext recipe on sanitizing strings for further details.\nSanitizing and Cleaning Up Text\ninvolving text parsing and data handling.\nstring functions (e.g., str.upper() and str.lower()) to convert text to a standard case.\nChapter 2: Strings and Text\nYou can also normalize text using unicode\nexample, you want to eliminate whole ranges of characters or strip diacritical marks.\nIn this last example, a dictionary mapping every Unicode combining character to None\nSanitizing and Cleaning Up Text \nYet another technique for cleaning up text involves I/O decoding and encoding func‐\nHere the normalization process decomposed the original text into characters along with\nA major issue with sanitizing text can be runtime performance.\nclean up whitespace, you could use code like this:\nOn the other hand, the translate() method is very fast if you need to perform any\nChapter 2: Strings and Text\nAlthough the focus of this recipe has been text, similar techniques can be applied to\nbytes, including simple replacements, translation, and regular expressions.\nAligning Text Strings\nYou need to format text with some sort of alignment applied.\n>>> text = 'Hello World'\n>>> text.ljust(20)\n>>> text.rjust(20)\n>>> text.center(20)\nAll of these methods accept an optional &&65.180&&fill character as well.\n>>> text.rjust(20,'=')\n>>> text.center(20,'*')\nAll you need to do is use\n>>> format(text, '>20')\n>>> format(text, '<20')\n>>> format(text, '^20')\n>>> format(text, '=>20s')\nAligning Text Strings \n>>> format(text, '*^20s')\nvalues.\nOne benefit of format() is that it is not specific to strings.\nIt works with any value,\nFor instance, you can use it with numbers:\n>>> format(x, '>10')\n>>> format(x, '^10.2f')\nIn older code, you will also see the % operator used to format text.\n>>> '%-20s' % text\n>>> '%20s' % text\nHowever, in new code, you should probably prefer the use of the format() function or\ncenter() method of strings in that it works with any kind of object.\nCombining and Concatenating Strings\nYou want to combine many small strings together into a larger string.\nto combine them is to use the join() method.\nChapter 2: Strings and Text\nas a method on strings.\nfrom any number of different data sequences (e.g., lists, tuples, dicts, files, sets, or gen‐\nSo you just specify the separator string that you want and use\nthe join() method on it to glue text fragments together.\nIf you’re only combining a few strings, using + usually works well enough:\nThe + operator also works fine as a substitute for more complicated string formatting\n>>> print('{} {}'.format(a,b))\n>>> print(a + ' ' + b)\nIf you’re trying to combine string literals together in source code, you can simply place\nJoining strings together might not seem advanced enough to warrant an entire recipe,\nThe most important thing to know is that using the + operator to join a lot of strings\nIn particular, you never want to write code that joins strings together like this:\nCombining and Concatenating Strings \noperation creates a new string object.\nprint(a + ':' + b + ':' + c)       # Ugly\nprint(':'.join([a, b, c]))         # Still ugly\nMixing I/O operations and string concatenation is something that might require study\nIf the two strings are small, the first version might offer much better performance due\nLast, but not least, if you’re writing code that is building output from lots of small strings,\nChapter 2: Strings and Text\ntext = ''.join(sample())\nYou want to create a string in which embedded variable names are substituted with a\nstring representation of a variable’s value.\nPython has no direct support for simply substituting variable values in strings.\nthis feature can be approximated using the format() method of strings.\nAlternatively, if the values to be substituted are truly found in variables, you can use the\nNow use this class to wrap the inputs to format_map():\ndef sub(text):\nreturn text.format_map(safesub(sys._getframe(1).f_locals))\nChapter 2: Strings and Text\nsee string formatting like this:\nYou may also see the use of template strings:\n>>> import string\n>>> s = string.Template('$name has $n messages.')\nalso get all of the features related to string formatting (alignment, padding, numerical\nformatting, etc.), which is simply not possible with alternatives such as Template string\nwould see the missing values appearing in the resulting string (potentially useful for\nThe sub() function uses sys._getframe(1) to return the stack frame of the caller.\never, for utility functions such as a string substitution feature, it can be useful.\nReformatting Text to a Fixed Number of Columns\nYou have long strings that you want to reformat so that they fill a user-specified number\nUse the textwrap module to reformat text for output.\nChapter 2: Strings and Text\nThe textwrap module is a straightforward way to clean up text for printing—especially\nHandling HTML and XML Entities in Text\ncorresponding text.\nAlternatively, you need to produce text, but escape certain charac‐\nIf you are producing text, replacing special characters such as < or > is relatively easy if\nyou use the html.escape() function.\nIf you’re trying to emit text as ASCII and want to embed character code entities for non-\nASCII characters, you can use the errors='xmlcharrefreplace' argument to various\nHandling HTML and XML Entities in Text \nTo replace entities in text, a different approach is needed.\nIf, for some reason, you’ve received bare text with some entities in it and you want them\nor other basic string formatting features.\nIf you need to process text in the other direction, various utility functions, such as\nrelated to replacing entities in the input text for you.\nTokenizing Text\nYou have a string that you want to parse left to right into a stream of tokens.\nSuppose you have a string of text such as this:\ntext = 'foo = 23 + 42 * 10'\nChapter 2: Strings and Text\nTo tokenize the string, you need to do more than merely match patterns.\nNUM  = r'(?P<NUM>\\d+)'\nmaster_pat = re.compile('|'.join([NAME, NUM, PLUS, TIMES, EQ, WS]))\nNext, to tokenize, use the little-known scanner() method of pattern objects.\nmethod creates a scanner object in which repeated calls to match() step through the\nsupplied text one match at a time.\n<_sre.SRE_Match object at 0x100677738>\n<_sre.SRE_Match object at 0x100677738>\n<_sre.SRE_Match object at 0x100677738>\n<_sre.SRE_Match object at 0x100677738>\n<_sre.SRE_Match object at 0x100677738>\nTokenizing Text \nToken = namedtuple('Token', ['type','value'])\ndef generate_tokens(pat, text):\nscanner = pat.scanner(text)\n# Example use\n# Token(type='NAME', value='foo')\n# Token(type='WS', value=' ')\n# Token(type='EQ', value='=')\n# Token(type='WS', value=' ')\n# Token(type='NUM', value='42')\nfunctions or use a generator expression.\ntokens = (tok for tok in generate_tokens(master_pat, text)\nTokenizing is often the first step for more advanced kinds of text parsing and handling.\nTo use the scanning technique shown, there are a few important details to keep in mind.\nFirst, you must make sure that you identify every possible text sequence that might\nIf any nonmatching text is found,\nWhen matching, re\nChapter 2: Strings and Text\nThe second pattern is wrong because it would match the text <= as the token LT followed\n#  Token(type='PRINT', value='print')\n#  Token(type='NAME', value='er')\nYou need to parse text according to a set of grammar rules and perform actions or build\nIn this problem, we’re focused on the problem of parsing text according to a particular\nparsing is that you try to match the input text to the grammar by making various sub‐\nFrom there, parsing involves trying to match the grammar to input tokens by making\nexpr ::= NUM { (*|/) factor }* { (+|-) term }*\nexpr ::= NUM + factor { (*|/) factor }* { (+|-) term }*\nexpr ::= NUM + NUM { (*|/) factor}* { (+|-) term }*\nat the input and trying to match it to grammar rules.\ntor }*) disappear when it’s determined that they can’t match the next token.\ncessful parse, the entire righthand side is expanded completely to match the input token\nChapter 2: Strings and Text\nNUM    = r'(?P<NUM>\\d+)'\nToken = collections.namedtuple('Token', ['type','value'])\ndef generate_tokens(text):\nscanner = master_pat.scanner(text)\nUse the ._accept() method\nmethod to exactly match and discard the next token on on the input\ndef parse(self,text):\nself.tokens = generate_tokens(text)\nreturn self.expr()\n'Test and consume the next token if it matches toktype'\n'Consume next token if it matches toktype or raise SyntaxError'\ndef expr(self):\ndef term(self):\nreturn int(self.tok.value)\nChapter 2: Strings and Text\nreturn self.expr()\ndef expr(self):\ndef term(self):\nreturn int(self.tok.value)\nTo start, you take every grammar rule and you turn it into a function or method.\ndef expr(self):\nChapter 2: Strings and Text\ndef term(self):\ngrammar rule, consuming tokens in the process.\nnext token and check for an exact match.\nIf it doesn’t match, it’s a syntax error.\n_expect() method in this recipe is used to perform these steps.\nto check the next token for each possibility and advance only if a match is made.\nversion of the _expect() method in that it will advance if a match is made, but if\n• For grammar rules where there are repeated parts (e.g., such as in the rule expr ::=\n• Once an entire grammar rule has been consumed, each method returns some kind\nample, in the expression evaluator, return values will represent partial results of the\nTo do it, you might try to use the items() method like this:\nChapter 2: Strings and Text\n# Token processing functions\nprint('Bad character: {!r}'.format(t.value[0]))\ndef p_expr_term(p):\ndef p_term_factor(p):\nwrite regular expressions for the tokens and high-level handling functions that execute\nwhen various grammar rules are matched.\nPerforming Text Operations on Byte Strings\nYou want to perform common text operations (e.g., stripping, searching, and replace‐\nment) on byte strings.\nByte strings already support most of the same built-in operations as text strings.\nChapter 2: Strings and Text\n>>> data = b'Hello World'\nSuch operations also work with byte arrays.\n>>> data = bytearray(b'Hello World')\nYou can apply regular expression pattern matching to byte strings, but the patterns\nreturn _compile(pattern, flags).split(string, maxsplit)\nTypeError: can't use a string pattern on a bytes-like object\n>>> re.split(b'[:,]',data)     # Notice: pattern as bytes\nFor the most part, almost all of the operations available on text strings will work on byte\nstrings.\nbyte strings produces integers, not individual characters.\n>>> a = 'Hello World'     # Text string\n>>> b = b'Hello World'    # Byte string\nPerforming Text Operations on Byte Strings \nSecond, byte strings don’t provide a nice string representation and don’t print cleanly\nunless first decoded into a text string.\nSimilarly, there are no string formatting operations available to byte strings.\nIf you want to do any kind of formatting applied to byte strings, it should be done using\nnormal text strings and encoding.\nFinally, you need to be aware that using a byte string can change the semantics of certain\nname encoded as bytes instead of a text string, it usually disables filename encoding/\n>>> os.listdir('.')          # Text string (names are decoded)\nChapter 2: Strings and Text\n>>> os.listdir(b'.')         # Byte string (names left as bytes)\nNotice in the last part of this example how giving a byte string as the directory name\nAs a final comment, some programmers might be inclined to use byte strings as an\nalternative to text strings due to a possible performance improvement.\ntrue that manipulating bytes tends to be slightly more efficient than text (due to the\nYou’ll often find that byte strings don’t play well with a lot of other parts\nFrankly, if you’re working with text, use\nnormal text strings in your program, not byte strings.\nPerforming Text Operations on Byte Strings \nPerforming mathematical calculations with integers and floating-point numbers is easy\nHowever, if you need to perform calculations with fractions, arrays, or dates\nYou want to round a floating-point number to a fixed number of decimal places.\nFor simple rounding, use the built-in round(value, ndigits) function.\nDon’t confuse rounding with formatting a value for output.\noutput a numerical value with a certain number of decimal places, you don’t typically\nneed to use round().\n>>> format(x, '0.2f')\n>>> format(x, '0.3f')\n>>> 'value is {:0.3f}'.format(x)\n'value is 1.235'\nportant (e.g., in financial applications, perhaps), consider the use of the decimal module,\nYou need to perform accurate calculations with decimal numbers, and don’t want the\nIf you want more accuracy (and are willing to give up some performance), you can use\n>>> print(a + b)\nAt first glance, it might look a little weird (i.e., specifying numbers as strings).\nIf you print them or use them in string formatting func‐\n>>> print(a / b)\nprint(a / b)\nprint(a / b)\nNewcomers to Python might be inclined to use the decimal module to work around\ncommon to use the normal floating-point type.\nfaster—something that’s important if you’re performing a large number of calculations.\nAll of this said, the main use of the decimal module is in programs involving things\nYou need to format a number for output, controlling the number of digits, alignment,\nTo format a single number for output, use the built-in format() function.\n>>> format(x, '0.2f')\n>>> format(x, '>10.1f')\n>>> format(x, '<10.1f')\n>>> format(x, '^10.1f')\n>>> format(x, ',')\n>>> format(x, '0,.1f')\nIf you want to use exponential notation, change the f to an e or E, depending on the\n>>> format(x, 'e')\n>>> format(x, '0.2E')\nformat codes are also used in the .format() method of strings.\n>>> 'The value is {:0,.2f}'.format(x)\n'The value is 1,234.57'\n>>> format(x, '0.1f')\n>>> format(-x, '0.1f')\nFormatting of values with a thousands separator is not locale aware.\nswap separator characters using the translate() method of strings.\nIn a lot of Python code, numbers are formatted using the % operator.\nported when using the % operator to format numbers.\nTo convert an integer into a binary, octal, or hexadecimal text string, use the bin(),\nAlternatively, you can use the format() function if you don’t want the 0b, 0o, or 0x\n>>> format(x, 'b')\n>>> format(x, 'o')\n>>> format(x, 'b')\nFor example, to show a 32-bit value, use the following:\n>>> format(2**32 + x, 'b')\nTo convert integer strings in different bases, simply use the int() function with an\nYou have a byte string and you need to unpack it into an integer value.\nyou need to convert a large integer back into a byte string.\nSuppose your program needs to work with a 16-element byte string that holds a 128-\nTo interpret the bytes as an integer, use int.from_bytes(), and specify the byte ordering\nTo convert a large integer value back into a byte string, use the int.to_bytes() method,\nConverting large integer values to and from byte strings is not a common operation.\nIf you are writing code that needs to pull such values out of a data record, you might\nmake up the integer value are listed from the least to most significant or the other way\nIf you try to pack an integer into a byte string, but it won’t fit, you’ll get an error.\ncan use the int.bit_length() method to determine how many bits are required to\nPerforming Complex-Valued Math\nyou just need to perform some calculations using complex numbers.\nTo perform additional complex-valued functions such as sines, cosines, or square roots,\nuse the cmath module:\nMost of Python’s math-related modules are aware of complex values.\nyou use numpy, it is straightforward to make arrays of complex values and perform\nPython’s standard mathematical functions do not produce complex values by default,\nPerforming Complex-Valued Math \nIf you want complex numbers to be produced as a result, you have to explicitly use cmath\nYou need to create or test for the floating-point values of infinity, negative infinity, or\nPython has no special syntax to represent these special floating-point values, but they\nTo test for the presence of these values, use the math.isinf() and math.isnan() func‐\nFor more detailed information about these special floating-point values, you should\nBecause of this, the only safe way to test for a NaN value is to use math.isnan(), as\n>>> print(a + b)\n>>> print(a * b)\nYou need to perform calculations on large numerical datasets, such as arrays or grids.\nFor any heavy computation involving arrays, use the NumPy library.\nillustrating important behavioral differences between lists and NumPy arrays:\nThese are replacements for similar functions normally found in the math module.\nelements one at a time and performing calculations using functions in the math module.\nThat said, it’s still possible to accomplish useful things with NumPy by starting with\nOne note about usage is that it is relatively common to use the statement import numpy\nYou need to perform matrix and linear algebra operations, such as matrix multiplication,\nFor example, to pick a random item out of a sequence, use random.choice():\n>>> values = [1, 2, 3, 4, 5, 6]\nIf you simply want to shuffle items in a sequence in place, use random.shuffle():\n>>> values\n>>> values",
      "keywords": [
        "text",
        "strings",
        "Text Strings",
        "Byte Strings",
        "string",
        "num",
        "match",
        "format",
        "PYTHON",
        "world",
        "Token",
        "regular expression",
        "method",
        "Strings and Text",
        "numbers"
      ],
      "concepts": [
        "text",
        "string",
        "strings",
        "matches",
        "match",
        "values",
        "important",
        "useful",
        "uses",
        "character"
      ],
      "similar_chapters": [
        {
          "book": "Python Cookbook 3rd",
          "chapter": 3,
          "title": "",
          "score": 0.491,
          "base_score": 0.341,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Python Cookbook 3rd",
          "chapter": 5,
          "title": "",
          "score": 0.407,
          "base_score": 0.257,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Python Cookbook 3rd",
          "chapter": 1,
          "title": "",
          "score": 0.382,
          "base_score": 0.232,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Python Cookbook 3rd",
          "chapter": 4,
          "title": "",
          "score": 0.38,
          "base_score": 0.23,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "text",
          "strings",
          "match",
          "token",
          "string"
        ],
        "semantic": [],
        "merged": [
          "text",
          "strings",
          "match",
          "token",
          "string"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.21424330916419176,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:08:10.208582+00:00"
      }
    },
    {
      "chapter_number": 3,
      "title": "Numbers, Dates, and Times",
      "start_page": 121,
      "end_page": 160,
      "summary": "You have code that needs to perform simple time conversions, like days to seconds,\nTo perform conversions and arithmetic involving different units of time, use the date\n>>> from datetime import timedelta\nIf you need to represent specific dates and times, create datetime instances and use the\nChapter 3: Numbers, Dates, and Times\nFor most basic date and time manipulation problems, the datetime module will suffice.\nIf you need to perform more complex date manipulations, such as dealing with time\nFile \"<stdin>\", line 1, in <module>\n>>> # Time between two dates\nYou want a general solution for finding a date for the last occurrence of a day of the\nPython’s datetime module has utility functions and classes to help perform calculations\ndef get_previous_byday(dayname, start_date=None):\nif start_date is None:\nstart_date = datetime.today()\nday_num = start_date.weekday()\ntarget_date = start_date - timedelta(days=days_ago)\nThe optional start_date can be supplied using another datetime instance.\nChapter 3: Numbers, Dates, and Times\nThis recipe works by mapping the start date and the target date to their numeric position\nfrom the start date by subtracting an appropriate timedelta instance.\nYou have some code that needs to loop over each date in the current month, and want\nLooping over the dates doesn’t require building a list of all the dates ahead of time.\ncan just calculate the starting and stopping date in the range, then use datetime.time\nHere’s a function that takes any datetime object, and returns a tuple containing the first\nfrom datetime import datetime, date, timedelta\ndef get_month_range(start_date=None):\nif start_date is None:\nstart_date = date.today().replace(day=1)\n_, days_in_month = calendar.monthrange(start_date.year, start_date.month)\nend_date = start_date + timedelta(days=days_in_month)\nreturn (start_date, end_date)\nThis recipe works by first calculating a date correponding to the first day of the month.\nA quick way to do this is to use the replace() method of a date or datetime object to\nOnce the number of days in the month is known, the ending date is calculated by adding\nan appropriate timedelta to the starting date.\nexample, timedelta instances can be used to increment the date.\nChapter 3: Numbers, Dates, and Times\nIdeally, it would be nice to create a function that works like the built-in range() function,\nbut for dates.\ndef date_range(start, stop, step):\n>>> for d in date_range(datetime(2012, 9, 1), datetime(2012,10,1),\nFor example, let’s say you have some code that generates a datetime object, but you need\n>>> nice_z = datetime.strftime(z, '%A %B %d, %Y')\nWhen tested, this function runs over seven times faster than datetime.strptime().\nManipulating Dates Involving Time Zones\nFor almost any problem involving time zones, you should use the pytz module.\nA major use of pytz is in localizing simple dates created with the datetime library.\nexample, here is how you would represent a date in Chicago time:\nChapter 3: Numbers, Dates, and Times\nOnce the date has been localized, it can be converted to other time zones.\n>>> from datetime import timedelta\nhandling is to convert all dates to UTC time and to use that for all internal storage and\nManipulating Dates Involving Time Zones \nyou want to output the date in localized time, just convert it to the appropriate time\nChapter 3: Numbers, Dates, and Times\nIterators and Generators\nIteration is one of Python’s strongest features.\niteration as a way to process items in a sequence.\nis possible, such as creating your own iterator objects, applying useful iteration patterns\nin the itertools module, making generator functions, and so forth.\nto address common problems involving iteration.\nManually Consuming an Iterator\nYou need to process items in an iterable, but for whatever reason, you can’t or don’t want\nTo manually consume an iterable, use the next() function and write your code to catch\nline = next(f)\nprint(line, end='')\nNormally, StopIteration is used to signal the end of iteration.\nline = next(f, None)\nif line is None:\nprint(line, end='')\nIn most cases, the for statement is used to consume an iterable.\nand then, a problem calls for more precise control over the underlying iteration mech‐\ning iteration:\n>>> # Get the iterator\n>>> it = iter(items)     # Invokes items.__iter__()\n>>> # Run the iterator\nSubsequent recipes in this chapter expand on iteration techniques, and knowledge of\nthe basic iterator protocol is assumed.\nDelegating Iteration\niterable.\nYou would like to make iteration work with your new container.\nTypically, all you need to do is define an __iter__() method that delegates iteration to\nChapter 4: Iterators and Generators\ndef __iter__(self):\nreturn iter(self._children)\nIn this code, the __iter__() method simply forwards the iteration request to the in‐\nPython’s iterator protocol requires __iter__() to return a special iterator object that\nimplements a __next__() method to carry out the actual iteration.\nis iterating over the contents of another container, you don’t really need to worry about\nAll you need to do is to forward the iteration\nThe use of the iter() function here is a bit of a shortcut that cleans up the code.\niter(s)\nsimply returns the underlying iterator by calling s.__iter__(), much in the same way\nCreating New Iteration Patterns with Generators\nYou want to implement a custom iteration pattern that’s different than the usual built-\nCreating New Iteration Patterns with Generators \nIf you want to implement a new kind of iteration pattern, define it using a generator\nTo use such a function, you iterate over it using a for loop or use it with some other\nfunction that consumes an iterable (e.g., sum(), list(), etc.).\na normal function, a generator only runs in response to iteration.\nChapter 4: Iterators and Generators\n>>> # Run to next yield (iteration stops)\ncarried out in iteration.\nOnce a generator function returns, iteration stops.\nthe for statement that’s usually used to iterate takes care of these details, so you don’t\nImplementing the Iterator Protocol\nYou are building custom objects on which you would like to support iteration, but would\nlike an easy way to implement the iterator protocol.\nBy far, the easiest way to implement iteration on an object is to use a generator function.\nwant to implement an iterator that traverses nodes in a depth-first pattern.\ndef __iter__(self):\nreturn iter(self._children)\nImplementing the Iterator Protocol \nitself and then iterates over each child yielding the items produced by the child’s\nPython’s iterator protocol requires __iter__() to return a special iterator object that\nmethod using an associated iterator class:\ndef __iter__(self):\nreturn iter(self._children)\nChapter 4: Iterators and Generators\ndef __init__(self, start_node):\nself._children_iter = None\nself._child_iter = None\ndef __iter__(self):\n# Return myself if just started; create an iterator for children\nif self._children_iter is None:\nself._children_iter = iter(self._node)\nelif self._child_iter:\nnextchild = next(self._child_iter)\nself._child_iter = None\n# Advance to the next child and start its iteration\nself._child_iter = next(self._children_iter).depth_first()\nthe iteration process.\nyour iterator as a generator and be done with it.\nIterating in Reverse\nYou want to iterate in reverse over a sequence.\nUse the built-in reversed() function.\nIterating in Reverse \nReversed iteration only works if the object in question has a size that can be determined\nfor line in reversed(list(f)):\nprint(line, end='')\nBe aware that turning an iterable into a list as shown could consume a lot of memory\nMany programmers don’t realize that reversed iteration can be customized on user-\n# Forward iterator\ndef __iter__(self):\n# Reverse iterator\nDefining a reversed iterator makes the code much more efficient, as it’s no longer nec‐\nessary to pull the data into a list and iterate in reverse on the list.\nYou would like to define a generator function, but it involves extra state that you would\nChapter 4: Iterators and Generators\nimplement it as a class, putting the generator function code in the __iter__() method.\ndef __init__(self, lines, histlen=3):\ndef __iter__(self):\nyield line\nTo use this class, you would treat it like a normal generator function.\nThis can lead to rather complicated code if the generator function needs to in‐\nDefining your generator in the __iter__() method doesn’t change anything about how\n>>> next(lines)\nTypeError: 'linehistory' object is not an iterator\n>>> # Call iter() first, then start iterating\n>>> it = iter(lines)\nTaking a Slice of an Iterator\nYou want to take a slice of data produced by an iterator, but the normal slicing operator\nThe itertools.islice() function is perfectly suited for taking slices of iterators and\nChapter 4: Iterators and Generators\nIterators and generators can’t normally be sliced, because no information is known about\nThe result of islice() is an iterator\nIt’s important to emphasize that islice() will consume data on the supplied iterator.\nSince iterators can’t be rewound, that is something to consider.\nSkipping the First Part of an Iterable\nYou want to iterate over items in an iterable, but the first few items aren’t of interest and\nTo use it, you supply a function and an\niterable.\nThe returned iterator discards the first items in the sequence as long as the\nTo illustrate, suppose you are reading a file that starts with a series of comment lines.\nfor line in f:\nprint(line, end='')\nSkipping the First Part of an Iterable \nprint(line, end='')\nThis example is based on skipping the first items according to a test function.\nhappen to know the exact number of items you want to skip, then you can use iter\n>>> items = ['a', 'b', 'c', 1, 4, 10, 15]\nline = next(f, '')\nwhile line:\nprint(line, end='')\nline = next(f, None)\nDiscarding the first part of an iterable is also slightly different than simply filtering all\nChapter 4: Iterators and Generators\nprint(line, end='')\nlines throughout the entire file.\nLast, but not least, it should be emphasized that this recipe works with all iterables,\nIterating Over All Possible Combinations or\nYou want to iterate over all of the possible combinations or permutations of a collection\n>>> items = ['a', 'b', 'c']\nIterating Over All Possible Combinations or Permutations \nUse itertools.combinations() to produce a sequence of combinations of items taken\nChapter 4: Iterators and Generators\nwith seemingly complicated iteration problems, it always pays to look at itertools first.\nIterating Over the Index-Value Pairs of a Sequence\nYou want to iterate over a sequence, but would like to keep track of which element of\nFor printing output with canonical line numbers (where you typically start the num‐\nThis case is especially useful for tracking line numbers in files should you want to use\nIterating Over the Index-Value Pairs of a Sequence \nSo, if you want to map words in a file to the lines in which\nfor line in f:\niterator that returns successive tuples consisting of a counter and the value returned by\nChapter 4: Iterators and Generators\nIterating Over Multiple Sequences Simultaneously\nYou want to iterate over the items contained in more than one sequence at a time.\nTo iterate over more than one sequence simultaneously, use the zip() function.\nzip(a, b) works by creating an iterator that produces tuples (x, y) where x is taken\nIteration stops whenever one of the input sequences is\nIterating Over Multiple Sequences Simultaneously \nLast, but not least, it’s important to emphasize that zip() creates an iterator as a result.\nIf you need the paired values stored in a list, use the list() function.\nChapter 4: Iterators and Generators\nIterating on Items in Separate Containers\niterables as input, and returns an iterator that effectively masks the fact that you’re really\n# Iterate over all items\nIterating on Items in Separate Containers \nitertools.chain() accepts one or more iterables as arguments.\nating an iterator that successively consumes and returns the items produced by each of\nthe supplied iterables you provided.\nthan first combining the sequences and iterating.\nwhen the iterables in question are of different types.\nYou want to process data iteratively in the style of a data processing pipeline (similar to\nGenerator functions are a good way to implement processing pipelines.\nSuppose each file contains lines of data like this:\nChapter 4: Iterators and Generators\nTo process these files, you could define a collection of small generator functions that\nOpen a sequence of filenames one at a time producing a file object.\nThe file is closed immediately when proceeding to the next iteration.\ndef gen_concatenate(iterators):\nChain a sequence of iterators together into a single sequence.\nfor it in iterators:\nyield line\nexample, to find all log lines that contain the word python, you would just do this:\nlines = gen_concatenate(files)\nprint(line)\nlines = gen_concatenate(files)\npipeline that is consuming it with iteration.\nIn fact, due to the iterative\nquires that all of the chained iterables be specified as arguments.\nparticular recipe, doing that would involve a statement such as lines = iter\nSince that generator is producing a sequence of open files that are immediately\nChapter 4: Iterators and Generators\nclosed in the next iteration step, chain() can’t be used.\nAlso appearing in the gen_concatenate() function is the use of yield from to delegate\nThis is easily solved by writing a recursive generator function involving a yield from\nfrom collections import Iterable\nif isinstance(x, Iterable) and not isinstance(x, ignore_types):\nIn the code, the isinstance(x, Iterable) simply checks to see if an item is iterable.\nnore_types) is there to prevent strings and bytes from being interpreted as iterables\nThe yield from statement is a nice shortcut to use if you ever want to write generators\nIf you don’t use it, you need to write code that\nif isinstance(x, Iterable) and not isinstance(x, ignore_types):\nIterating in Sorted Order Over Merged Sorted\nIterables\nYou have a collection of sorted sequences and you want to iterate over a sorted sequence\nChapter 4: Iterators and Generators\nThe iterative nature of heapq.merge means that it never reads any of the supplied se‐\nIterating in Sorted Order Over Merged Sorted Iterables \nReplacing Infinite while Loops with an Iterator\nYou have code that uses a while loop to iteratively process data because it involves a\nfunction or some kind of unusual test condition that doesn’t fall into the usual iteration\nSuch code can often be replaced using iter(), as follows:\nfor chunk in iter(lambda: s.recv(CHUNKSIZE), b''):\n>>> for chunk in iter(lambda: f.read(10), ''):\nA little-known feature of the built-in iter() function is that it optionally accepts a zero-\ncreates an iterator that repeatedly calls the supplied callable over and over again until it\nChapter 4: Iterators and Generators\ninto a single iter() call.\nReplacing Infinite while Loops with an Iterator \nYou need to read or write text data, possibly in different text encodings such as ASCII,\nUse the open() function with mode rt to read a text file.\n# Iterate over the lines of the file\nfor line in f:\nSimilarly, to write a text file, use open() with mode wt to write a file, clearing and\nprint(line1, file=f)\nprint(line2, file=f)\nTo append to the end of an existing file, use open() with mode at.",
      "keywords": [
        "date",
        "line",
        "items",
        "iterator",
        "generator function",
        "Node",
        "time",
        "function",
        "generator",
        "datetime",
        "data",
        "iter"
      ],
      "concepts": [
        "iteration",
        "iterating",
        "iterate",
        "line",
        "time",
        "printing",
        "function",
        "functionality",
        "functions",
        "date"
      ],
      "similar_chapters": [
        {
          "book": "Python Cookbook 3rd",
          "chapter": 1,
          "title": "",
          "score": 0.5,
          "base_score": 0.35,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Python Cookbook 3rd",
          "chapter": 2,
          "title": "",
          "score": 0.491,
          "base_score": 0.341,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Python Cookbook 3rd",
          "chapter": 5,
          "title": "",
          "score": 0.381,
          "base_score": 0.231,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Python Cookbook 3rd",
          "chapter": 4,
          "title": "",
          "score": 0.308,
          "base_score": 0.158,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "iterator",
          "iteration",
          "datetime",
          "iterators",
          "iter"
        ],
        "semantic": [],
        "merged": [
          "iterator",
          "iteration",
          "datetime",
          "iterators",
          "iter"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.2721636213639111,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:08:10.208601+00:00"
      }
    },
    {
      "chapter_number": 4,
      "title": "Iterators and Generators",
      "start_page": 161,
      "end_page": 200,
      "summary": "with open('somefile.txt', 'rt', newline='') as f:\ncontents of a Windows-encoded text file containing the raw data hello world!\\r\\n:\n>>> f = open('hello.txt', 'rt')\n>>> f.read()\nA final issue concerns possible encoding errors in text files.\ntext file, you might encounter an encoding or decoding error.\n>>> f = open('sample.txt', 'rt', encoding='ascii')\n>>> f.read()\nFile \"<stdin>\", line 1, in <module>\nFile \"/usr/local/lib/python3.3/encodings/ascii.py\", line 26, in decode\nIf you get this error, it usually means that you’re not reading the file in the correct\nand check that you’re doing it right (e.g., reading data as UTF-8 instead of Latin-1 or\n>>> f = open('sample.txt', 'rt', encoding='ascii', errors='replace')\n>>> f.read()\nReading and Writing Text Data \nPrinting to a File\nYou want to redirect the output of the print() function to a file.\nUse the file keyword argument to print(), like this:\nwith open('somefile.txt', 'rt') as f:\nprint('Hello World!', file=f)\nThere’s not much more to printing to a file other than this.\nfile is opened in text mode.\nPrinting will fail if the underlying file is in binary mode.\nYou want to output data using print(), but you also want to change the separator\nChapter 5: Files and I/O\nFile \"<stdin>\", line 1, in <module>\nReading and Writing Binary Data\nYou need to read or write binary data, such as that found in images, sound files, and so\nReading and Writing Binary Data \nUse the open() function with mode rb or wb to read or write binary data.\n# Read the entire file as a single byte string\ndata = f.read()\n# Write binary data to a file\nf.write(b'Hello World')\nWhen reading binary, it is important to stress that all data returned will be in the form\nSimilarly, when writing, you must supply data in the\nWhen reading binary data, the subtle semantic differences between byte strings and text\nChapter 5: Files and I/O\nIf you ever need to read or write text from a binary-mode file, make sure you remember\ndata = f.read(16)\nf.write(text.encode('utf-8'))\nwith open('data.bin','wb') as f:\nMany objects also allow binary data to be directly read into their underlying memory\n>>> with open('data.bin', 'rb') as f:\nSee Recipe 5.9 for another example of reading binary data\nWriting to a File That Doesn’t Already Exist\nYou want to write data to a file, but only if it doesn’t already exist on the filesystem.\nWriting to a File That Doesn’t Already Exist \nf.write('Hello\\n')\nf.write('Hello\\n')\nFile \"<stdin>\", line 1, in <module>\nIf the file is binary mode, use mode xb instead of xt.\nwhen writing files (i.e., accidentally overwriting an existing file).\nis to first test for the file like this:\nf.write('Hello\\n')\nprint('File already exists!')\nFile already exists!\nYou want to feed a text or binary string to code that’s been written to operate on file-\nChapter 5: Files and I/O\nUse the io.StringIO() and io.BytesIO() classes to create file-like objects that operate\n>>> print('This is a test', file=s)\ndata, use the io.BytesIO class instead.\n>>> s.write(b'binary data')\nb'binary data'\ncreate a file-like object containing test data that’s fed into a function that would otherwise\nwork with a normal file.\nYou need to read or write data in a file with gzip or bz2 compression.\nThe gzip and bz2 modules make it easy to work with such files.\nto read compressed files as text, do this:\ntext = f.read()\ntext = f.read()\nSimilarly, to write compressed data, do this:\nf.write(text)\nf.write(text)\nAs shown, all I/O will use text and perform Unicode encoding/decoding.\nto work with binary data instead, use a file mode of rb or wb.\nFor the most part, reading or writing compressed data is straightforward.\naware that choosing the correct file mode is critically important.\nf.write(text)\non top of an existing file opened in binary mode.\nChapter 5: Files and I/O\nThis allows the gzip and bz2 modules to work with various file-like objects such as\nInstead of iterating over a file by lines, you want to iterate over a collection of fixed-\nwith open('somefile.data', 'rb') as f:\nrecords = iter(partial(f.read, RECORD_SIZE), b'')\nnumber of bytes from a file each time it’s called.\nwhen a file is read but the end of file has been reached.\nLast, but not least, the solution shows the file being opened in binary mode.\nFor text files, reading\nReading Binary Data into a Mutable Buffer\nYou want to read binary data directly into a mutable buffer without any intermediate\nPerhaps you want to mutate the data in-place and write it back out to a file.\nTo read data into a mutable array, use the readinto() method of files.\nwith open(filename, 'rb') as f:\n>>> # Write a sample file\nf.write(b'Hello World')\nThe readinto() method of files can be used to fill any preallocated array with data.\nFor example, if you are reading a binary file\nChapter 5: Files and I/O\nMemory Mapping Binary Files\nYou want to memory map a binary file into a mutable byte array, possibly for random\nUse the mmap module to memory map files.\nopen a file and memory map it in a portable manner:\nMemory Mapping Binary Files \nTo use this function, you would need to have a file already created and filled with data.\nHere is an example of how you could initially create a file and expand it to a desired\n>>> with open('data', 'wb') as f:\nf.write(b'\\x00')\n>>> with open('data', 'rb') as f:\nprint(f.read(11))\nBy default, the memory_map() function shown opens a file for both reading and writing.\nAny modifications made to the data are copied back to the original file.\nChapter 5: Files and I/O\nthe original file, use mmap.ACCESS_COPY:\naccessing the contents of a file.\nFor example, instead of opening a file and performing\nfile and access the data using slicing operations.\nAs you access different regions, those portions of the file will be read and\nHowever, parts of the file that are never\nIf more than one Python interpreter memory maps the same file, the resulting mmap\nread/write data simultaneously, and changes made to the data in one interpreter will\nMemory Mapping Binary Files \nTo manipulate pathnames, use the functions in the os.path module.\n'data.csv'\nFor any manipulation of filenames, you should use the os.path module instead of trying\nChapter 5: Files and I/O\nConsult the documentation for more functions related to file testing, symbolic\nTesting for the Existence of a File\nYou need to test whether or not a file or directory exists.\nUse the os.path module to test for the existence of a file or directory.\n>>> # Is a regular file\n>>> # Get the file linked to\nIf you need to get metadata (e.g., the file size or modification date), that is also available\nTesting for the Existence of a File \nFile testing is a straightforward operation using os.path.\nFile \"<stdin>\", line 1, in <module>\nFile \"/usr/local/lib/python3.3/genericpath.py\", line 49, in getsize\nYou want to get a list of the files contained in a directory on the filesystem.\nUse the os.listdir() function to obtain a list of files in a directory:\nThis will give you the raw directory listing, including all files, subdirectories, symbolic\n# Get all regular files\nChapter 5: Files and I/O\nIf you want to get additional metadata, such as file sizes, modification dates,\nand so forth, you either need to use additional functions in the os.path module or use\n# Get file sizes and modification dates\nfile_metadata = [(name, os.stat(name)) for name in pyfiles]\nYou want to perform file I/O operations using raw filenames that have not been decoded\n>>> # Wrte a file using a unicode filename\n>>> # Open file with raw filename\n>>> with open(b'jalapen\\xcc\\x83o.txt') as f:\nprint(f.read())\nwhen byte strings are supplied to file-related functions, such as open() and os.list\nChapter 5: Files and I/O\nprograms that work with a lot of files.\nlowing files to be created without proper filename encoding.\n>>> files = os.listdir('.')\n>>> files\n>>> for name in files:\nFile \"<stdin>\", line 2, in <module>\n>>> for name in files:\n>>> for name in files:\nChapter 5: Files and I/O\nOpen File\nYou want to add or change the Unicode encoding of an already open file without closing\nIf you want to add Unicode encoding/decoding to an already existing file object that’s\ntext = f.read()\nIf you want to change the encoding of an already open text-mode file, use its detach()\nsimple example involving a text file:\nAdding or Changing the Encoding of an Already Open File \n>>> f = open('sample.txt','w')\nIn this example, io.TextIOWrapper is a text-handling layer that encodes and decodes\nUnicode, io.BufferedWriter is a buffered I/O layer that handles binary data, and \n>>> f = io.TextIOWrapper(f.buffer, encoding='latin-1')\n>>> f.write('Hello')\nFile \"<stdin>\", line 1, in <module>\nValueError: I/O operation on closed file.\nfile in the process.\n>>> f = open('sample.txt', 'w')\n>>> f.write('hello')\nFile \"<stdin>\", line 1, in <module>\n>>> f = io.TextIOWrapper(b, encoding='latin-1')\nChapter 5: Files and I/O\nWriting Bytes to a Text File\nYou want to write raw bytes to a file opened in text mode.\nSimply write the byte data to the files underlying buffer.\nFile \"<stdin>\", line 1, in <module>\nSimilarly, binary data can be read from a text file by reading from its buffer attribute\nencoding/decoding layer on top of a buffered binary-mode file.\nactually needs to dump binary data to standard output, you can use the technique shown\nWriting Bytes to a Text File \nWrapping an Existing File Descriptor As a File Object\nYou have an integer file descriptor correponding to an already open I/O channel on the\noperating system (e.g., file, pipe, socket, etc.), and you want to wrap a higher-level\nPython file object around it.\nA file descriptor is different than a normal open file in that it is simply an integer handle\nhappen to have such a file descriptor, you can wrap a Python file object around it using\n# Open a low-level file descriptor\nf.write('hello world\\n')\nWhen the high-level file object is closed or destroyed, the underlying file descriptor will\n# Create a file object, but don't close underlying fd when done\nfor putting a file-like interface on an existing I/O channel that was opened in a different\n# Make text-mode file wrappers for socket reading/writing\nChapter 5: Files and I/O\n# Echo lines back to the client using file I/O\ntrying to put a file-like interface on a socket and need your code to be cross platform,\nfile().\nYou can also use this to make a kind of alias that allows an already open file to be used\ncould create a file object that allows you to emit binary data on stdout (which is normally\n# Create a binary-mode file for stdout\nMaking Temporary Files and Directories\nYou need to create a temporary file or directory for use when your program executes.\nAfterward, you possibly want the file or directory to be destroyed.\nMaking Temporary Files and Directories \nunnamed temporary file, use tempfile.TemporaryFile:\n# Read/write to the file\nf.write('Hello World\\n')\nf.write('Testing\\n')\ndata = f.read()\nOr, if you prefer, you can also use the file like this:\n# Use the temporary file\n# File is destroyed\nThe first argument to TemporaryFile() is the file mode, which is usually w+t for text\nuseful here since closing the file to change modes would actually destroy it.\nFile() additionally accepts the same arguments as the built-in open() function.\nFile() instead.\nprint('filename is:', f.name)\nHere, the f.name attribute of the opened file contains the filename of the temporary file.\nThis can be useful if it needs to be given to some other code that needs to open the file.\nChapter 5: Files and I/O\nprint('filename is:', f.name)\nare probably the most convenient way to work with temporary files and directories,\nfiles and directories.\nthe mkstemp() function simply returns a raw OS file descriptor and leaves it up to you\nSimilarly, it’s up to you to clean up the files if you want.\nAll of the temporary-file-related functions allow you to override this directory as well\nMaking Temporary Files and Directories \nYou want to read and write data over a serial port, typically to interact with some kind\nnication ports such as “COM0” and “COM1.” Once open, you can read and write data\nyour code to use bytes instead of text (or perform proper text encoding/decoding as\nChapter 5: Files and I/O\nThe most common approach for serializing data is to use the pickle module.\nan object to a file, you do this:\ndata = ...\npickle.dump(data, f)\ns = pickle.dumps(data)\n# Restore from a file\ndata = pickle.load(f)\nIt simply works with most Python data types and instances of user-defined\npickle is a Python-specific self-describing data encoding.\nYou can pickle functions, classes, and instances, but the resulting data only encodes\nChapter 5: Files and I/O\npickle is not a particularly efficient encoding for large data structures such as binary\nfile or using a more standardized encoding, such as HDF5 (supported by third-party\ndata encoding, such as XML, CSV, or JSON.\nChapter 5: Files and I/O\nData Encoding and Processing\nkinds of common encodings, such as CSV files, JSON, XML, and binary packed records.\nReading and Writing CSV Data\nYou want to read or write data encoded as a CSV file.\nFor most kinds of CSV data, use the csv library.\nstock market data in a file named stocks.csv like this:\nwith open('stocks.csv') as f:\nwith open('stock.csv') as f:\nAnother alternative is to read the data as a sequence of dictionaries instead.\nwith open('stocks.csv') as f:\nTo write CSV data, you also use the csv module but create a writer object.\nwith open('stocks.csv','w') as f:\nChapter 6: Data Encoding and Processing\nwith open('stocks.csv','w') as f:\nwith open('stocks.csv') as f:\nFor example, if you want to read tab-delimited data instead, use this:\nIf you’re reading CSV data and converting it into named tuples, you need to be a little\nFor example, a CSV file could have a header\nReading and Writing CSV Data \nwith open('stock.csv') as f:\nIt’s also important to emphasize that csv does not try to interpret the data or convert it\ndata:\nwith open('stocks.csv') as f:\nwith open('stocks.csv') as f:\nthe real world, it’s common for CSV files to have missing values, corrupted data, and\ndas.read_csv() function that will load CSV data into a DataFrame object.\nChapter 6: Data Encoding and Processing\nReading and Writing JSON Data\nYou want to read or write data encoded as JSON (JavaScript Object Notation).\nThe json module provides an easy way to encode and decode data in JSON.\ndata = {\nHere is how you turn a JSON-encoded string back into a Python data structure:\nIf you are working with files instead of strings, you can alternatively use json.dump()\nand json.load() to encode and decode JSON data.\n# Writing JSON data\nwith open('data.json', 'w') as f:\njson.dump(data, f)\n# Reading data back\nwith open('data.json', 'r') as f:\ndata = json.load(f)\nReading and Writing JSON Data \nChapter 6: Data Encoding and Processing\nNormally, JSON decoding will create dicts or lists from the supplied data.\nFor example, here is how you would decode JSON data, preserving its\n>>> data = json.loads(s, object_pairs_hook=OrderedDict)\n>>> data\n>>> data = json.loads(s, object_hook=JSONObject)\n>>> data.name\nIn this last example, the dictionary created by decoding the JSON data is passed as a\n>>> print(json.dumps(data))\n>>> print(json.dumps(data, indent=4))\nReading and Writing JSON Data \n>>> print(json.dumps(data, sort_keys=True))\nFile \"<stdin>\", line 1, in <module>\nFile \"/usr/local/lib/python3.3/json/__init__.py\", line 226, in dumps\nFile \"/usr/local/lib/python3.3/json/encoder.py\", line 187, in encode\nFile \"/usr/local/lib/python3.3/json/encoder.py\", line 245, in iterencode\nFile \"/usr/local/lib/python3.3/json/encoder.py\", line 169, in default\nChapter 6: Data Encoding and Processing",
      "keywords": [
        "file",
        "data",
        "open",
        "Writing JSON Data",
        "Binary Data",
        "encoding",
        "Python file object",
        "JSON Data",
        "Open file",
        "CSV Data",
        "file object",
        "Python",
        "Writing Binary Data",
        "csv",
        "text file"
      ],
      "concepts": [
        "files",
        "data",
        "encode",
        "encodings",
        "important",
        "imported",
        "python",
        "read",
        "filename",
        "printing"
      ],
      "similar_chapters": [
        {
          "book": "Python Cookbook 3rd",
          "chapter": 5,
          "title": "",
          "score": 0.57,
          "base_score": 0.42,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Python Cookbook 3rd",
          "chapter": 1,
          "title": "",
          "score": 0.489,
          "base_score": 0.339,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Python Cookbook 3rd",
          "chapter": 2,
          "title": "",
          "score": 0.38,
          "base_score": 0.23,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Python Cookbook 3rd",
          "chapter": 14,
          "title": "",
          "score": 0.354,
          "base_score": 0.354,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Python Cookbook 3rd",
          "chapter": 15,
          "title": "",
          "score": 0.341,
          "base_score": 0.341,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "file",
          "json",
          "files",
          "csv",
          "binary"
        ],
        "semantic": [],
        "merged": [
          "file",
          "json",
          "files",
          "csv",
          "binary"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.30269197421589694,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:08:10.208617+00:00"
      }
    },
    {
      "chapter_number": 5,
      "title": "Files and I/O",
      "start_page": 201,
      "end_page": 240,
      "summary": "Here is an example of how these functions are used:\nParsing Simple XML Data\nYou would like to extract data from a simple XML document.\nThe xml.etree.ElementTree module can be used to extract data from simple XML\nfrom xml.etree.ElementTree import parse\nu = urlopen('http://planet.python.org/rss20.xml')\nParsing Simple XML Data \nhttp://holdenweb.blogspot.com/2012/11/python-for-data-analysis.html\nhttp://jugad2.blogspot.com/2012/11/the-python-data-model.html\nhttp://www.pythondiary.com/blog/Nov.18,2012/been-...-object-databases.html\nWorking with data encoded as XML is commonplace in many applications.\nXML widely used as a format for exchanging data on the Internet, it is a common format\nfor storing application data (e.g., word processing, music libraries, etc.).\nIn many cases, when XML is simply being used to store data, the document structure\n<title>Steve Holden: Python for Data Analysis</title>\n<guid>http://holdenweb.blogspot.com/...-data-analysis.html</guid>\n<link>http://holdenweb.blogspot.com/...-data-analysis.html</link>\nChapter 6: Data Encoding and Processing\n<title>Vasudev Ram: The Python Data model (for v2 and v3)</title>\n<guid>http://jugad2.blogspot.com/...-data-model.html</guid>\n<link>http://jugad2.blogspot.com/...-data-model.html</link>\nThe xml.etree.ElementTree.parse() function parses the entire XML document into\nfindtext() to search for specific XML elements.\nThe arguments to these functions are\ndoc represents the top of the document (the top-level “rss” element).\nEach element represented by the ElementTree module has a few essential attributes and\n<xml.etree.ElementTree.ElementTree object at 0x101339510>\nParsing Simple XML Data \nParsing Huge XML Files Incrementally\nYou need to extract data from a huge XML document using as little memory as possible.\nmentally process huge XML files using a very small memory footprint:\nTo test the function, you now need to find a large XML file to work with.\nfind such files on government and open data websites.\nconsists of more than 100,000 rows of data, which are encoded like this:\nChapter 6: Data Encoding and Processing\nSuppose you want to write a script that ranks ZIP codes by the number of pothole\nTo do it, you could write code like this:\nfrom xml.etree.ElementTree import parse\ndoc = parse('potholes.xml')\nParsing Huge XML Files Incrementally \nThe only problem with this script is that it reads and parses the entire XML file into\ndata = parse_and_remove('potholes.xml', 'row/row')\nfor pothole in data:\nparse() method allows incremental processing of XML documents.\nresulting XML element.\n>>> data = iterparse('potholes.xml',('start','end'))\n>>> next(data)\n>>> next(data)\n>>> next(data)\n>>> next(data)\n>>> next(data)\n>>> next(data)\n>>> next(data)\nother data (e.g., child elements).\nend events are created when an element is completed.\nAlthough not shown in this recipe, start-ns and end-ns events are used to handle XML\nChapter 6: Data Encoding and Processing\nIn this recipe, the start and end events are used to manage stacks of elements and tags.\nto the parse_and_remove() function.\nYet, it is still possible to write code that processes the XML data in a\nsion of code that reads the entire document into memory first runs approximately twice\nYou want to take the data in a Python dictionary and turn it into XML.\nAlthough the xml.etree.ElementTree library is commonly used for parsing, it can also\nbe used to create XML documents.\nfrom xml.etree.ElementTree import Element\ndef dict_to_xml(tag, d):\nTurn a simple dict of key/value pairs into XML\nelem = Element(tag)\nto a byte string using the tostring() function in xml.etree.ElementTree.\nIf you want to attach attributes to an element, use its set() method:\nWhen creating XML, you might be inclined to just make strings instead.\ndef dict_to_xml_str(tag, d):\nTurn a simple dict of key/value pairs into XML\n>>> dict_to_xml_str('item',d)\nChapter 6: Data Encoding and Processing\n>>> e = dict_to_xml('item',d)\ncan use the escape() and unescape() functions in xml.sax.saxutils.\nYou want to read an XML document, make changes to it, and then write it back out as\nThe xml.etree.ElementTree module makes it easy to perform such tasks.\nHere is an example of using ElementTree to read it and make changes to the structure:\n>>> from xml.etree.ElementTree import parse, Element\n>>> doc = parse('pred.xml')\n>>> e = Element('spam')\nThe result of these operations is a new XML file that looks like this:\nChapter 6: Data Encoding and Processing\nModifying the structure of an XML document is straightforward, but you must re‐\nIf you need to make new elements, use the Element class, as shown in this recipe’s\nParsing XML Documents with Namespaces\nYou need to parse an XML document, but it’s using XML namespaces.\nConsider a document that uses namespaces like this:\nParsing XML Documents with Namespaces \n<Element '{http://www.w3.org/1999/xhtml}html' at 0x1007767e0>\n>>> doc.findtext('content/{http://www.w3.org/1999/xhtml}html/head/title')\n>>> doc.findtext('content/{http://www.w3.org/1999/xhtml}html/'\nreturn path.format_map(self.namespaces)\nTo use this class, you do the following:\n<Element '{http://www.w3.org/1999/xhtml}html' at 0x1007767e0>\nParsing XML documents that contain namespaces can be messy.\nscope of namespace processing if you’re willing to use the iterparse() function instead.\nChapter 6: Data Encoding and Processing\nend <Element '{http://www.w3.org/1999/xhtml}title' at 0x1011131b0>\nend <Element '{http://www.w3.org/1999/xhtml}head' at 0x1011130a8>\nend <Element '{http://www.w3.org/1999/xhtml}h1' at 0x101113310>\nend <Element '{http://www.w3.org/1999/xhtml}body' at 0x101113260>\nend <Element '{http://www.w3.org/1999/xhtml}html' at 0x10110df70>\nAs a final note, if the text you are parsing makes use of namespaces in addition to other\nA standard way to represent rows of data in Python is as a sequence of tuples.\ninput or output data is represented by a tuple.\nTo do anything with the data, you next create a cursor.\nTo insert a sequence of rows into the data, use a statement like this:\nChapter 6: Data Encoding and Processing\nOne complication is the mapping of data from the database into Python types.\nYou should never use Python string formatting operators (e.g., %) or the .for\nIf the values provided to such formatting operators\nIf you simply need to decode or encode a raw string of hex digits, use the binascii\nSimilar functionality can also be found in the base64 module.\nChapter 6: Data Encoding and Processing\nYou need to decode or encode binary data using Base64 encoding.\n>>> # Some byte data\nBase64 encoding is only meant to be used on byte-oriented data such as byte strings and\nare mixing Base64-encoded data with Unicode text, you may have to perform an extra\nReading and Writing Binary Arrays of Structures\nYou want to read or write data encoded as a binary array of uniform structures into\nTo work with binary data, use the struct module.\nHere is an example of code that writes\na list of Python tuples out to a binary file, encoding each tuple as a structure using\ndef write_records(records, format, f):\nWrite a sequence of tuples to a binary file of structures.\nrecord_struct = Struct(format)\nf.write(record_struct.pack(*r))\nwith open('data.b', 'wb') as f:\ngoing to read the file incrementally in chunks, you can write code such as this:\ndef read_records(format, f):\nrecord_struct = Struct(format)\nchunks = iter(lambda: f.read(record_struct.size), b'')\nreturn (record_struct.unpack(chunk) for chunk in chunks)\nwith open('data.b','rb') as f:\nIf you want to read the file entirely into a byte string with a single read and convert it\ndef unpack_records(format, data):\nrecord_struct = Struct(format)\nreturn (record_struct.unpack_from(data, offset)\nfor offset in range(0, len(data), record_struct.size))\nChapter 6: Data Encoding and Processing\nwith open('data.b', 'rb') as f:\ndata = f.read()\nfor rec in unpack_records('<idd', data):\nFor programs that must encode and decode binary data, it is common to use the struct\nTo declare a new structure, simply create an instance of Struct such as:\nStructures are always defined using a set of structure codes such as i, d, f, and so forth\nThese codes correspond to specific binary data types\nThe size attribute contains the size of the structure in bytes,\npack and unpack data.\n>>> record_struct.size\n>>> record_struct.unpack(_)\nReading and Writing Binary Arrays of Structures \nstance, the format code is only specified once and all of the useful operations are grouped\nThe code for reading binary structures involves a number of interesting, yet elegant\nIn the read_records() function, iter() is being used to make\na user-supplied callable (e.g., lambda: f.read(record_struct.size)) until it returns\na specified value (e.g., b), at which point iteration stops.\n>>> f = open('data.b', 'rb')\n>>> chunks = iter(lambda: f.read(20), b'')\ndef read_records(format, f):\nrecord_struct = Struct(format)\nchk = f.read(record_struct.size)\nyield record_struct.unpack(chk)\nIn the unpack_records() function, a different approach using the unpack_from()\nunpack_from() is a useful method for extracting binary data from a\ndef unpack_records(format, data):\nrecord_struct = Struct(format)\nreturn (record_struct.unpack(data[offset:offset + record_struct.size])\nfor offset in range(0, len(data), record_struct.size))\nChapter 6: Data Encoding and Processing\nwork, as it performs various offset calculations, copies data, and makes small slice ob‐\nIf you’re going to be unpacking a lot of structures from a large byte string you’ve\nUnpacking records is one place where you might want to use namedtuple objects from\nwith open('data.p', 'rb') as f:\nIf you’re writing a program that needs to work with a large amount of binary data, you\ninto a list of tuples, you could read it into a structured array, like this:\n>>> f = open('data.b', 'rb')\nLast, but not least, if you’re faced with the task of reading binary data in some known\nfile format (i.e., image formats, shape files, HDF5, etc.), check to see if a Python module\nYou need to read complicated binary-encoded data that contains a collection of nested\nReading Nested and Variable-Sized Binary Structures \nThe struct module can be used to decode and encode almost any kind of binary data\ndata structure representing a collection of points that make up a series of polygons:\nNow suppose this data was to be encoded into a binary file where the file started with\nFile code (0x1234, little endian)\nTo write this file, you can use Python code like this:\nChapter 6: Data Encoding and Processing\nsize = len(poly) * struct.calcsize('<dd')\nf.write(struct.pack('<i', size+4))\nf.write(struct.pack('<dd', *pt))\n# Call it with our polygon data\nTo read the resulting data back, you can write very similar looking code using the \nstruct.unpack() function, reversing the operations performed during writing.\ndef read_polys(filename):\nfile_code, min_x, min_y, max_x, max_y, num_polys = \\\npbytes, = struct.unpack('<i', f.read(4))\npt = struct.unpack('<dd', f.read(16))\nAlthough this code works, it’s also a rather messy mix of small reads, struct unpacking,\nIn the remainder of this recipe, a rather advanced solution for interpreting binary data\nspecification of the file format, and to simply have the details of reading and unpacking\nFirst, when reading binary data, it is common for the file to contain headers and other\ndata structures.\nAlthough the struct module can unpack this data into a tuple, another\nReading Nested and Variable-Sized Binary Structures \ndef __init__(self, format, offset):\nr =  struct.unpack_from(self.format,\nclass Structure:\nThis code uses a descriptor to represent each structure field.\na struct-compatible format code along with a byte offset into an underlying memory\nIn the __get__() method, the struct.unpack_from() function is used to unpack\nThe Structure class just serves as a base class that accepts some byte data and stores it\nUsing this code, you can now define a structure as a high-level class that mirrors the\nHere is an example of using this class to read the header from the polygon data written\n>>> phead.file_code == 0x1234\nChapter 6: Data Encoding and Processing\nand requires the user to specify a lot of low-level detail (e.g., repeated uses of Struct\nStructure class:\nsetattr(self, 'struct_size', offset)\nreturn cls(f.read(cls.struct_size))\nUsing this new Structure class, you can now write a structure definition like this:\n('<i', 'file_code'),\nReading Nested and Variable-Sized Binary Structures \nmethod also makes it easier to read the data from a file without knowing any details\nabout the size or structure of the data.\n>>> phead.file_code == 0x1234\nFor example, suppose you want to support nested binary structures.\ndef __init__(self, name, struct_type, offset):\ndata = instance._buffer[self.offset:\nself.offset+self.struct_type.struct_size]\nresult = self.struct_type(data)\nChapter 6: Data Encoding and Processing\noffset += format.struct_size\nsetattr(self, 'struct_size', offset)\nIn this code, the NestedStruct descriptor is used to overlay another structure definition\nUsing this new formulation, you can start to write code like this:\nclass Point(Structure):\n('<i', 'file_code'),\n>>> phead.file_code == 0x1234\nReading Nested and Variable-Sized Binary Structures \nOne way to handle this is to write a class that simply represents a chunk of binary data\ndef from_file(cls, f, size_fmt, includes_size=True):\nsz, = struct.unpack(size_fmt, sz_bytes)\ndef iter_as(self, code):\nsize = code.struct_size\ndata = self._buffer[off:off+size]\nyield code(data)\nThe SizedRecord.from_file() class method is a utility for reading a size-prefixed\nchunk of data from a file, which is common in many file formats.\nstructure format code containing the encoding of the size, which is expected to be in\nThe optional includes_size argument specifies whether the number of bytes\nHere’s an example of how you would use this code to\nChapter 6: Data Encoding and Processing\ndo that, use the iter_as() method, which accepts a structure format code or Struc\nReading Nested and Variable-Sized Binary Structures \nclass Point(Structure):\n('<i', 'file_code'),\ndef read_polys(filename):\na memoryview of the supplied byte data and does nothing else.\nField descriptor that stores the associated structure format code and byte offset into\nChapter 6: Data Encoding and Processing\nmetaclass is to make it extremely easy for a user to specify a structure format with a\n_fields_ = [ ('>i', 'file_code'),    # Big endian\ndata.\nRecipe 8.13 for a closely related recipe that uses descriptors to build a type system.\nsimilar support for defining data structures, nesting of data structures, and similar\nReading Nested and Variable-Sized Binary Structures \nCreation Date                      74055  non-null values\nCompletion Date                    72154  non-null values\nNumber of Premises with Rats       65752  non-null values\nZIP Code                           73584  non-null values\nX Coordinate                       74043  non-null values\nY Coordinate                       74043  non-null values\nLongitude                          74043  non-null values\nChapter 6: Data Encoding and Processing\n>>> crew_dispatched['ZIP Code'].value_counts()[:10]\nChapter 6: Data Encoding and Processing\nTopics include default arguments, functions that take any number of\ntricky control flow and data passing problems involving callback functions are\nWriting Functions That Accept Any Number of\nYou want to write a function that accepts any number of input arguments.\nTo write a function that accepts any number of positional arguments, use a * argument.\nTo accept any number of keyword arguments, use an argument that starts with **.\ndef make_element(name, value, **attrs):\nelement = '<{name}{attrs}>{value}</{name}>'.format(\nreturn element\nmake_element('item', 'Albatross', size='large', quantity=6)\nmake_element('p', '<spam>')\narguments, use * and ** together.\nWith this function, all of the positional arguments are placed into a tuple args, and all\ndef a(x, *args, y):\ndef b(x, *args, y, **kwargs):\nWriting Functions That Only Accept Keyword\nYou want a function to only accept certain arguments by keyword.\nThis technique can also be used to specify keyword arguments for functions that accept\nHelp on function recv in module __main__:\nWriting Functions That Only Accept Keyword Arguments \nthey can be used to inject arguments into functions that make use of the *args and\nFunction argument annotations can be a useful way to give programmers hints about\nreturn x + y\nHowever, they might give useful hints to others reading the source code\nAlthough you can attach any kind of object to a function as an annotation (e.g., numbers,\n{'y': <class 'int'>, 'return': <class 'int'>, 'x': <class 'int'>}\nReturning Multiple Values from a Function\nYou want to return multiple values from a function.\nTo return multiple values from a function, simply return a tuple.\nAlthough it looks like myfun() returns multiple values, a tuple is actually being created.\nWhen calling functions that return a tuple, it is common to assign the result to multiple\nReturning Multiple Values from a Function \nYou want to define a function or method where one or more of the arguments are\nvalues in the definition and make sure that default arguments appear last.\nuse None as the default and write code like this:\nIf, instead of providing a default value, you want to write code that merely tests whether\nan optional argument was given an interesting value or not, use this idiom:\ndef spam(a, b=_no_value):\nif b is _no_value:\nprint('No b value supplied')\nNo b value supplied",
      "keywords": [
        "Data",
        "Data Encoding",
        "XML",
        "Simple XML Data",
        "element",
        "binary data",
        "XML Data",
        "structure",
        "struct",
        "code",
        "Python data structure",
        "function",
        "Python",
        "Encoding",
        "Encoding and Processing"
      ],
      "concepts": [
        "data",
        "values",
        "elements",
        "element",
        "functions",
        "functionality",
        "xml",
        "structure",
        "structured",
        "classes"
      ],
      "similar_chapters": [
        {
          "book": "Python Cookbook 3rd",
          "chapter": 1,
          "title": "",
          "score": 0.582,
          "base_score": 0.432,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Python Cookbook 3rd",
          "chapter": 4,
          "title": "",
          "score": 0.57,
          "base_score": 0.42,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Python Cookbook 3rd",
          "chapter": 10,
          "title": "",
          "score": 0.492,
          "base_score": 0.492,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Python Cookbook 3rd",
          "chapter": 2,
          "title": "",
          "score": 0.407,
          "base_score": 0.257,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Python Cookbook 3rd",
          "chapter": 3,
          "title": "",
          "score": 0.381,
          "base_score": 0.231,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "xml",
          "struct",
          "record_struct",
          "binary",
          "offset"
        ],
        "semantic": [],
        "merged": [
          "xml",
          "struct",
          "record_struct",
          "binary",
          "offset"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.34546406040759337,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:08:10.208664+00:00"
      }
    },
    {
      "chapter_number": 6,
      "title": "Data Encoding and Processing",
      "start_page": 241,
      "end_page": 280,
      "summary": "Defining functions with default arguments is easy, but there is a bit more to it than meets\nFirst, the values assigned as a default are bound only once at the time of function defi‐\n>>> def spam(a, b=x):\nThis is because the default value was fixed at function definition time.\nDefining Functions with Default Arguments \ncommon base class for almost all objects in Python.\nYou need to supply a short callback function for use with an operation such as sort(),\nbut you don’t want to write a separate one-line function using the def statement.\nAlthough lambda allows you to define a simple function, its use is highly restricted.\ncallback functions.\nYou’ve defined an anonymous function using lambda, but you also need to capture the\nThe problem here is that the value of x used in the lambda expression is a free variable\nIf you want an anonymous function to capture a value at the point of definition and\ntries to be just a little bit too clever with the use of lambda functions.\nkind and expecting the lambda functions to remember the iteration variable at the time\nNotice how all functions think that n has the last value during iteration.\nAs you can see, the functions now capture the value of n at the time of definition.\nYou have a callable that you would like to use with some other Python code, possibly as\na callback function or handler, but it takes too many arguments and causes an exception\nIf you need to reduce the number of arguments to a function, you should use func\nThe partial() function allows you to assign fixed values to one or\ndef spam(a, b, c, d):\nNow consider the use of partial() to fix certain argument values:\nwith the arguments given to partial(), and passes everything to the original function.\nYou could use the following function to compute the distance between two\ncustomize sorting, but it only works with functions that take a single argument (thus,\nnatures of callback functions used in other libraries.\ncallback function that accepts both the result and an optional logging argument:\np.apply_async(add, (3, 4), callback=partial(output_result, log=log))\nWhen supplying the callback function using apply_async(), the extra logging argu‐\nit simply invokes the callback function with a single value.\ndef handle(self):\nHowever, suppose you want to give the EchoHandler class an __init__() method that\ndef __init__(self, *args, ack, **kwargs):\ndef handle(self):\nto resolve using partial()—just use it to supply the value of the ack argument, like\nIn this example, the specification of the ack argument in the __init__() method might\nThe functionality of partial() is sometimes replaced with a lambda expression.\np.apply_async(add, (3, 4), callback=lambda result: output_result(result,log))\nReplacing Single Method Classes with Functions\nYou have a class that only defines a single method besides __init__().\nsimplify your code, you would much rather just have a simple function.\nIn many cases, single-method classes can be turned into functions using closures.\ndef __init__(self, template):\ndef open(self, **kwargs):\nreturn urlopen(self.template.format_map(kwargs))\n# Example use.\nThe class could be replaced with a much simpler function:\n# Example use\nIn many cases, the only reason you might have a single-method class is to store addi‐\ntional state for use in the method.\nclass is to hold the template value someplace so that it can be used in the open() method.\nSimply stated, a closure is just a function, but with an extra environment of the variables\nremembers the value of the template argument, and uses it in subsequent calls.\nReplacing Single Method Classes with Functions \nthan the alternative of turning your function into a full-fledged class.\nCarrying Extra State with Callback Functions\nYou’re writing code that relies on the use of callback functions (e.g., event handlers,\ncompletion callbacks, etc.), but you want to have the callback function carry extra state\nfor use inside the callback function.\nThis recipe pertains to the use of callback functions that are found in many libraries\nfor the purposes of testing, define the following function, which invokes a callback:\ndef apply_async(func, args, *, callback):\n>>> apply_async(add, (2, 3), callback=print_result)\n>>> apply_async(add, ('hello', 'world'), callback=print_result)\nAs you will notice, the print_result() function only accepts a single argument, which\nOne way to carry extra information in a callback is to use a bound-method instead of\nFor example, this class keeps an internal sequence number that is\ndef __init__(self):\ndef handler(self, result):\nprint('[{}] Got: {}'.format(self.sequence, result))\nTo use this class, you would create an instance and use the bound method handler as\nAs an alternative to a class, you can also use a closure to capture state.\nFor a coroutine, you would use its send() method as the callback, like this:\nCarrying Extra State with Callback Functions \ndef __init__(self):\nPart of the issue is that the callback function is often disconnected from the code\nwant the callback function to continue with a procedure involving multiple steps, you\nThe last technique involving partial() is useful if all you need to do is pass extra values\n>>> apply_async(add, (2, 3), callback=lambda r: handler(r, seq))\nInlining Callback Functions\nYou’re writing code that uses callback functions, but you’re concerned about the pro‐\nCallback functions can be inlined into a function using generators and coroutines.\nillustrate, suppose you have a function that performs work and invokes a callback as\ndef apply_async(func, args, *, callback):\nNow take a look at the following supporting code, which involves an Async class and\nclass Async:\ndef __init__(self, func, args):\nInlining Callback Functions \napply_async(a.func, a.args, callback=result_queue.put)\nThis recipe will really test your knowledge of callback functions, generators, and control\nply_async() function illustrates the essential parts of executing the callback, although\nfunction emit a value and suspend.\nfunction.\nof this calculation is that instead of using a normal callback function, the callback is set\nmight happen depends on the precise implementation of the apply_async() function.\nInlining Callback Functions \nYou would like to extend a closure with functions that allow the inner variables to be\nthe closure as function attributes.\n# Closure function\ndef set_n(value):\n# Attach as function attributes\nmake it possible to write functions that change inner variables.\ntributes allow the accessor methods to be attached to the closure function in a straight‐\nforward manner where they work a lot like instance methods (even though no class is\nclass.\ndef __init__(self, locals=None):\ndef __len__(self):\n# Example use\nInterestingly, this code runs a bit faster than using a normal class definition.\ndef __init__(self):\ndef push(self, item):\ndef pop(self):\nreturn self.items.pop()\ndef __len__(self):\nreturn len(self.items)\nproperties, descriptors, or class methods don’t work.\nClasses and Objects\ndef __init__(self, x, y):\ndef __repr__(self):\nreturn 'Pair({0.x!r}, {0.y!r})'.format(self)\ndef __str__(self):\nreturn '({0.x!s}, {0.y!s})'.format(self)\nThe __repr__() method returns the code representation of an instance, and is usually\nThe built-in repr() function returns\nprint() functions.\nThe use of format() in the solution might look a little funny, but the format code {0.x}\nthe instance self:\ndef __repr__(self):\nreturn 'Pair({0.x!r}, {0.y!r})'.format(self)\ndef __repr__(self):\nreturn 'Pair(%r, %r)' % (self.x, self.y)\nYou want an object to support customized formatting through the format() function\nTo customize string formatting, define the __format__() method on a class.\ndef __init__(self, year, month, day):\ndef __format__(self, code):\nreturn fmt.format(d=self)\nInstances of the Date class now support formatting operations such as the following:\nto the class itself.\nFor example, consider the following class,\ndef __init__(self, address, family=AF_INET, type=SOCK_STREAM):\ndef __enter__(self):\nreturn self.sock\n__exit__() method can choose to use the exception information in some way or to\ndef __init__(self, address, family=AF_INET, type=SOCK_STREAM):\nself.connections = []\ndef __enter__(self):\n# Example use\nthe memory footprint of instances by adding the __slots__ attribute to the class defi‐\ndef __init__(self, year, month, day):\nand methods.\nclass A:\ndef __init__(self):\ndef public_method(self):\ndef _internal_method(self):\nfunctions.\nYou may also encounter the use of two leading underscores (__) on names within class\nclass B:\ndef __init__(self):\ndef __private_method(self):\ndef public_method(self):\nself.__private_method()\nSpecifically, the private attributes in the preceding class get renamed to _B__pri\nclass C(B):\ndef __init__(self):\ndef __private_method(self):\nclass B.\nexample, this code defines a property that adds simple type checking to an attribute:\nclass Person:\ndef __init__(self, first_name):\nself.first_name = first_name\ndef first_name(self):\nreturn self._first_name\n# Setter function\ndef first_name(self, value):\nself._first_name = value\ndef first_name(self):\nIn the preceding code, there are three related methods, all of which must have the same\nThe first method is a getter function, and establishes first_name as being a\nThe other two methods attach optional setter and deleter functions to the\nwhy the __init__() method sets self.first_name instead of self._first_name.\nBy setting self.first_name, the set operation uses the setter method (as\nProperties can also be defined for existing get and set methods.\nclass Person:\ndef __init__(self, first_name):\nself.set_first_name(first_name)\ndef get_first_name(self):\nreturn self._first_name\n# Setter function\ndef set_first_name(self, value):\nself._first_name = value\ndef del_first_name(self):\n# Make a property from existing get/set methods\na class with a property, you can find the raw methods in the fget, fset, and fdel\nclass Person:\ndef __init__(self, first_name):\nself.first_name = name\ndef first_name(self):\nreturn self._first_name\ndef first_name(self, value):\nself._first_name = value\ndef __init__(self, radius):\ndef area(self):\ndef perimeter(self):\nHere, the use of properties results in a very uniform instance interface in that radius,\nattributes and method calls.\ntually may want to directly use getter and setter functions.\nFor example, perhaps a Python class is going to be\n(as a normal method call) rather than a property that implicitly makes such calls.\nclass Person:\ndef __init__(self, first_name, last_name):\nself.first_name = first_name\nself.last_name = last_name\ndef first_name(self):\nreturn self._first_name\ndef first_name(self, value):\nself._first_name = value\ndef last_name(self):\nreturn self._last_name\ndef last_name(self, value):\nself._last_name = value\nCalling a Method on a Parent Class\nYou want to invoke a method in a parent class in place of a method that has been\nTo call a method in a parent (or superclass), use the super() function.\nclass A:\ndef spam(self):\nclass B(A):\ndef spam(self):\nA very common use of super() is in the handling of the __init__() method to make\nclass A:\ndef __init__(self):\nself.x = 0\nclass B(A):\ndef __init__(self):\nAnother common use of super() is in code that overrides any of Python’s special meth‐\ndef __init__(self, obj):\ndef __getattr__(self, name):\ndef __setattr__(self, name, value):\nsetattr(self._obj, name, value)\nCorrect use of the super() function is actually one of the most poorly understood\ndef __init__(self):\ndef __init__(self):\nBase.__init__(self)\ndef __init__(self):\ndef __init__(self):\nBase.__init__(self)\nclass B(Base):\ndef __init__(self):\nBase.__init__(self)\nclass C(A,B):\ndef __init__(self):\nA.__init__(self)\nB.__init__(self)\nIf you run this code, you’ll see that the Base.__init__() method gets invoked twice, as\nCalling a Method on a Parent Class \nother hand, you change the code to use super(), it all works:\ndef __init__(self):\ndef __init__(self):\nclass B(Base):\ndef __init__(self):\nclass C(A,B):\ndef __init__(self):\nWhen you use this new version, you’ll find that each __init__() method only gets\nTo implement inheritance, Python starts with the leftmost class and works its way left-\nWhen you use the super() function, Python continues its search starting with the next\nAs long as every redefined method consistently uses super() and\nparent of a class next in the MRO and that you can even use it in a class with no direct\nFor example, consider this class:\nclass A:\ndef spam(self):\nIf you try to use this class, you’ll find that it’s completely broken:\n>>> class B:\ndef spam(self):\n>>> class C(A,B):\nCalling a Method on a Parent Class \nHere you see that the use of super().spam() in class A has, in fact, called the spam()\n<class 'object'>)\ntripped up if it tries to invoke a method on a class that’s not a direct parent.\nWithin a subclass, you want to extend the functionality of a property defined in a parent\nclass.\nclass Person:\ndef __init__(self, name):\nself.name = name\ndef name(self):\nreturn self._name\n# Setter function\ndef name(self, value):\nself._name = value\n# Deleter function\ndef name(self):\nHere is an example of a class that inherits from Person and extends the name property\ndef name(self):\ndef name(self, value):\nsuper(SubPerson, SubPerson).name.__set__(self, value)\ndef name(self):\nHere is an example of the new class in use:\nIf you only want to extend one of the methods of a property, use code such as the\ndef name(self):\nOr, alternatively, for just the setter, use this code:\ndef name(self, value):\nsuper(SubPerson, SubPerson).name.__set__(self, value)\nto the fact that a property is defined as a collection of getter, setter, and deleter methods,\nIn the first example, all of the property methods are redefined together.\nPerson, SubPerson).name.__set__(self, value) in the setter function is no mis‐\nthrough the __set__() method of the previously defined name property.\nonly way to get to this method is to access it as a class variable instead of an instance\nIf you only want to redefine one of the methods, it’s not enough to use @property by\ndef name(self):\nIf you try the resulting code, you’ll find that the setter function disappears entirely:\nself.name = name\ndef name(self):",
      "keywords": [
        "function",
        "callback functions",
        "functions",
        "init",
        "method",
        "callback",
        "code",
        "result",
        "property",
        "function def",
        "super",
        "Python",
        "async",
        "def spam"
      ],
      "concepts": [
        "function",
        "functionality",
        "classes",
        "methods",
        "codes",
        "values",
        "attributes",
        "useful",
        "uses",
        "returned"
      ],
      "similar_chapters": [
        {
          "book": "Python Cookbook 3rd",
          "chapter": 1,
          "title": "",
          "score": 0.5,
          "base_score": 0.5,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Python Cookbook 3rd",
          "chapter": 15,
          "title": "",
          "score": 0.401,
          "base_score": 0.401,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Python Cookbook 3rd",
          "chapter": 8,
          "title": "",
          "score": 0.375,
          "base_score": 0.375,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Python Cookbook 3rd",
          "chapter": 7,
          "title": "",
          "score": 0.363,
          "base_score": 0.363,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Python Cookbook 3rd",
          "chapter": 4,
          "title": "",
          "score": 0.309,
          "base_score": 0.309,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "def",
          "callback",
          "class",
          "__init__",
          "__init__ self"
        ],
        "semantic": [],
        "merged": [
          "def",
          "callback",
          "class",
          "__init__",
          "__init__ self"
        ]
      },
      "topic_id": null,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.33262303960555717,
        "topic_boost": 0.0,
        "timestamp": "2025-12-17T23:08:10.208680+00:00"
      }
    },
    {
      "chapter_number": 7,
      "title": "Functions",
      "start_page": 281,
      "end_page": 320,
      "summary": "If you don’t know which base class defined a property,\nclass String:\ndef __init__(self, name):\nself.name = name\ndef __get__(self, instance, cls):\nreturn instance.__dict__[self.name]\ndef __set__(self, instance, value):\ninstance.__dict__[self.name] = value\n# A class with a descriptor\nclass Person:\ndef __init__(self, name):\nself.name = name\ndef name(self):\ndef name(self, value):\nsuper(SubPerson, SubPerson).name.__set__(self, value)\ndef name(self):\nCreating a New Kind of Class or Instance Attribute\nin the form of a descriptor class.\nclass Integer:\ndef __init__(self, name):\nself.name = name\ndef __get__(self, instance, cls):\nreturn instance.__dict__[self.name]\ndef __set__(self, instance, value):\ninstance.__dict__[self.name] = value\ndef __delete__(self, instance):\nA descriptor is a class that implements the three core attribute access operations (get,\nTo use a descriptor, instances of the descriptor are placed into a class definition as class\nclass Point:\ndef __init__(self, x, y):\nOne confusion with descriptors is that they can only be defined at the class level, not\nclass Point:\nCreating a New Kind of Class or Instance Attribute \ndef __init__(self, x, y):\nMust be a class variable\nclass Integer:\ndef __get__(self, instance, cls):\nreturn instance.__dict__[self.name]\nbetween instance variables and class variables.\nIf a descriptor is accessed as a class vari‐\nan example, here is some more advanced descriptor-based code involving a class\nclass Typed:\ndef __init__(self, name, expected_type):\nself.name = name\ndef __get__(self, instance, cls):\nreturn instance.__dict__[self.name]\ndef __set__(self, instance, value):\nif not isinstance(value, self.expected_type):\nraise TypeError('Expected ' + str(self.expected_type))\ninstance.__dict__[self.name] = value\ndef __delete__(self, instance):\n# Class decorator that applies it to selected attributes\n# Attach a Typed descriptor to the class\nclass Stock:\ndef __init__(self, name, shares, price):\nself.name = name\nwant to customize the access of a single attribute of a specific class.\nAn efficient way to define a lazy attribute is through the use of a descriptor class, such\nclass lazyproperty:\ndef __init__(self, func):\ndef __get__(self, instance, cls):\nvalue = self.func(instance)\nsetattr(instance, self.func.__name__, value)\nTo utilize this code, you would use it in a class such as the following:\nclass Circle:\ndef __init__(self, radius):\nAs shown in other recipes (e.g., Recipe 8.9), when a descriptor is placed into a class\nThe lazyproperty class exploits this by having the __get__() method store the com‐\nsetattr(self, name, value)\nfunction defined in a common base class.\nclass Structure:\n# Class variable that specifies expected fields\ndef __init__(self, *args):\n# Example class definitions\nclass Stock(Structure):\nclass Point(Structure):\nIf you use the resulting classes, you’ll find that they are easy to construct.\nclass Structure:\ndef __init__(self, *args, **kwargs):\nclass Stock(Structure):\nclass Structure:\n# Class variable that specifies expected fields\ndef __init__(self, *args, **kwargs):\nclass Stock(Structure):\nclass Stock:\ndef __init__(self, name, shares, price):\nself.name = name\nclass Point:\ndef __init__(self, x, y):\nclass Circle:\ndef __init__(self, radius):\nclass Structure:\n# Class variable that specifies expected fields\ndef __init__(self, *args):\ntures of IDEs. If a user asks for help on a specific class, the required arguments aren’t\nclass Stock(Structure)\ndef init_fromlocals(self):\nclass Stock:\ndef __init__(self, name, shares, price):\nDefining an Interface or Abstract Base Class\nTo define an abstract base class, use the abc module.\ndef write(self, data):\ndef write(self, data):\nA major use of abstract base classes is in code that wants to enforce an expected pro‐\nFor example, one way to view the IStream base class is as a high-\nbase class (ABC), but ABCs allow other classes to be registered as implementing the\nIt should be noted that @abstractmethod can also be applied to static methods, class\ndef name(self):\ndef name(self, value):\nDefining an Interface or Abstract Base Class \nThe following code illustrates the use of descriptors to implement a system type and\n# Base class.\nclass Descriptor:\ndef __init__(self, name=None, **opts):\nself.name = name\nsetattr(self, key, value)\ndef __set__(self, instance, value):\ninstance.__dict__[self.name] = value\nclass Typed(Descriptor):\ndef __set__(self, instance, value):\nif not isinstance(value, self.expected_type):\nraise TypeError('expected ' + str(self.expected_type))\nclass Unsigned(Descriptor):\ndef __set__(self, instance, value):\nclass MaxSized(Descriptor):\ndef __init__(self, name=None, **opts):\ndef __set__(self, instance, value):\nif len(value) >= self.size:\nclass Integer(Typed):\nclass Float(Typed):\nclass String(Typed):\nUsing these type objects, it is now possible to define a class such as this:\nclass Stock:\ndef __init__(self, name, shares, price):\nself.name = name\nraise TypeError('expected ' + str(self.expected_type))\nTypeError: expected <class 'float'>\nin classes.\nOne approach is to use a class decorator, like this:\nclass Stock:\ndef __init__(self, name, shares, price):\nself.name = name\nclass checkedmeta(type):\nfor key, value in methods.items():\ndef __init__(self, name, shares, price):\nself.name = name\nclasses, the use of super(), class decorators, and metaclasses.\nFirst, in the Descriptor base class, you will notice that there is a __set__() method,\nThe overall design of the various descriptor classes is based on mixin classes.\nscriptor classes derived from Typed.\nclass for MaxSized looks for its required attribute in opts, but simply passes it along to\nthe Descriptor base class, which actually sets it.\nThe definitions of the various type classes such as Integer, Float, and String illustrate\na useful technique of using class variables to customize an implementation.\nThe use of a class decorator or metaclass is often useful for simplifying the specification\nclass Point:\nThe code for the class decorator and metaclass simply scan the class dictionary looking\nOf all the approaches, the class decorator solution may provide the most flexibility and\nclasses, multiple inheritance, and tricky use of the super() function.\nnative formulation of this recipe that uses class decorators:\n# Base class.\nclass Descriptor:\ndef __init__(self, name=None, **opts):\nself.name = name\nsetattr(self, key, value)\ndef __set__(self, instance, value):\ninstance.__dict__[self.name] = value\ndef __set__(self, instance, value):\nsuper_set(self, instance, value)\ndef __set__(self, instance, value):\nsuper_set(self, instance, value)\ndef __init__(self, name=None, **opts):\ndef __set__(self, instance, value):\nif len(value) >= self.size:\nsuper_set(self, instance, value)\nclass Integer(Descriptor):\nclass UnsignedInteger(Integer):\nclass Float(Descriptor):\nclass String(Descriptor):\nFor example, a simple timing test of setting a typed attribute reveals that the class\nYou want to implement a custom class that mimics the behavior of a common built-in\nThe collections library defines a variety of abstract base classes that are extremely\nuseful when implementing custom container classes.\nyour class to support iteration.\nclass A(collections.Iterable):\nTypeError: Can't instantiate abstract class A with abstract methods __iter__\nTo fix this error, simply give the class the required __iter__() method and implement\nclasses to see what methods need to be implemented to make a custom container with\nTypeError: Can't instantiate abstract class Sequence with abstract methods \\\nHere is a simple example of a class that implements the preceding methods to create a\nclass SortedItems(collections.Sequence):\ndef __init__(self, initial=None):\ndef __len__(self):\ndef add(self, item):\nHere’s an example of using this class:\nInheriting from one of the abstract base classes in collections ensures that your cus‐\nMany of the abstract base classes in collections also provide default implementations\nclass Items(collections.MutableSequence):\ndef __init__(self, initial=None):\ndef __setitem__(self, index, value):\nself._items[index] = value\ndef insert(self, index, value):\nself._items.insert(index, value)\ndef __len__(self):\nThis recipe only provides a brief glimpse into Python’s abstract class functionality.\nclasses.\nclass A:\ndef spam(self, x):\nclass B:\ndef __init__(self):\nself._a = A()\ndef spam(self, x):\nreturn self._a.spam(x)\nclass A:\ndef spam(self, x):\nclass B:\ndef __init__(self):\nself._a = A()\n# Expose all of the methods defined on class A\nclass Proxy:\ndef __init__(self, obj):\ndef __setattr__(self, name, value):\nTo use this proxy class, you simply wrap it around another instance.\nclass Spam:\ndef __init__(self, x):\nclass A:\ndef spam(self, x):\nclass B(A):\ndef spam(self, x):\nclass A:\ndef spam(self, x):\nclass B:\ndef __init__(self):\nself._a = A()\ndef spam(self, x):\nsider this class:\nclass ListLike:\ndef __init__(self):\nclass ListLike:\ndef __init__(self):\ndef __len__(self):\ndef __setitem__(self, index, value):\nself._items[index] = value\nDefining More Than One Constructor in a Class\nYou’re writing a class, but you want users to be able to create instances in more than the\nTo define a class with more than one constructor, you should use a class method.\nclass Date:\ndef __init__(self, year, month, day):\nDefining More Than One Constructor in a Class \nOne of the primary uses of class methods is to define alternate constructors, as shown\nA critical feature of a class method is that it receives the class as the first\nYou will notice that this class is used within the method to create and\nIt is extremely subtle, but this aspect of class methods makes\nclass NewDate(Date):\nWhen defining a class with multiple constructors, you should make the __init__()\nInstead of defining a separate class method, you might be inclined to implement the\nclass Date:\ndef __init__(self, *args):\n# Class method version\nof a class.\nFor example, consider this class:\nclass Date:\ndef __init__(self, year, month, day):\na class method that’s been defined as an alternate constructor.\nclass shown, someone might define an alternate constructor today() as follows:\nclass Date:\ndef __init__(self, year, month, day):\nOtherwise, the code will break if the class uses\nExtending Classes with Mixins\nHowever, the classes where\nThus, you can’t just attach the methods to a common base class.\nFor example, maybe a library provides a basic set of classes\nHere are a set of mixin classes\nclass LoggedMappingMixin:\ndef __getitem__(self, key):\ndef __setitem__(self, key, value):\ndef __delitem__(self, key):\nclass SetOnceMappingMixin:\ndef __setitem__(self, key, value):\nclass StringKeysMappingMixin:\ndef __setitem__(self, key, value):\nThese classes, by themselves, are useless.\nExtending Classes with Mixins \nIn the example, you will notice that the mixins are combined with other existing classes\nclasses all work together to provide the desired functionality.\nclasses in this recipe work by themselves.\nThey have to be mixed with another class that\nSecond, mixin classes typically have no state of their own.\nIf you are thinking about defining a mixin class that has an __init__() method and\nerly invokes the __init__() method of other classes that are mixed in.\nother classes.\nIf the __init__() of the mixin class took any arguments of its\nExtending Classes with Mixins \nclass RestrictKeysMixin:\ndef __init__(self, *args, _restrict_key_type, **kwargs):\ndef __setitem__(self, key, value):\nraise TypeError('Keys must be ' + str(self.__restrict_key_type))\nHere is an example that shows how this class might be used:\nraise TypeError('Keys must be ' + str(self.__restrict_key_type))\nTypeError: Keys must be <class 'str'>\nrestrict_key_type that is provided to the mixin class.\nclasses.\nIn the solution, the classes redefine certain critical methods, such as\nUsing super() delegates to the next class on the method\nHowever, in a class definition such as this:\nthe use of super() in LoggedMappingMixin delegates to the next class over in the mul‐\nAn alternative implementation of mixins involves the use of class decorators.\ndef __getitem__(self, key):\nreturn cls_getitem(self, key)\ndef __setitem__(self, key, value):\nreturn cls_setitem(self, key, value)\ndef __delitem__(self, key):\nreturn cls_delitem(self, key)\nThis function is applied as a decorator to a class definition.\nclass definition to replace certain methods.\nFurther details about class decorators can\nSee Recipe 8.13 for an advanced recipe involving both mixins and class decorators.\nclass Connection:\ndef __init__(self):\ndef read(self):\ndef write(self, data):\nclass Connection:\ndef __init__(self):\n# Delegate to the state class\ndef read(self):\ndef write(self, data):\n# Connection state base class\nclass ConnectionState:\nHere is an interactive session that illustrates the use of these classes:\nindividual states into their own classes.\nIt might look a little weird, but each state is implemented by a class with static methods,\non a decision to not store any instance data in the different state classes themselves.\nof states under a common base class is mostly there to help organize the code and to\nraised in base class methods is just there to make sure that subclasses provide an im‐\nan abstract base class, as described in Recipe 8.12.\n__class__ attribute of instances.\nclass Connection:\ndef __init__(self):\nself.__class__ = newstate\ndef read(self):",
      "keywords": [
        "Classes",
        "instance",
        "class Stock",
        "init",
        "base class",
        "descriptor",
        "expected",
        "self.",
        "type",
        "key",
        "methods",
        "Abstract Base Class",
        "Objects",
        "Attribute",
        "attribute class Integer"
      ],
      "concepts": [
        "classes",
        "method",
        "instance",
        "attribute",
        "value",
        "descriptor",
        "implementation",
        "implement",
        "implementations",
        "passed"
      ],
      "similar_chapters": [
        {
          "book": "Python Cookbook 3rd",
          "chapter": 8,
          "title": "",
          "score": 0.77,
          "base_score": 0.62,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Python Cookbook 3rd",
          "chapter": 9,
          "title": "",
          "score": 0.657,
          "base_score": 0.507,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Python Cookbook 3rd",
          "chapter": 11,
          "title": "",
          "score": 0.496,
          "base_score": 0.346,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Python Cookbook 3rd",
          "chapter": 12,
          "title": "",
          "score": 0.387,
          "base_score": 0.237,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Python Cookbook 3rd",
          "chapter": 6,
          "title": "",
          "score": 0.363,
          "base_score": 0.363,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "class",
          "def",
          "def __init__",
          "__init__ self",
          "__init__"
        ],
        "semantic": [],
        "merged": [
          "class",
          "def",
          "def __init__",
          "__init__ self",
          "__init__"
        ]
      },
      "topic_id": 1,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.33409769853162957,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:08:10.208707+00:00"
      }
    },
    {
      "chapter_number": 8,
      "title": "Classes and Objects",
      "start_page": 321,
      "end_page": 380,
      "summary": "def write(self, data):\ndef open(self):\ndef close(self):\ndef read(self):\ndef write(self, data):\ndef open(self):\ndef close(self):\ndef read(self):\ndef write(self, data):\ndef open(self):\ndef close(self):\n__class__ attribute.\nclass State:\ndef __init__(self):\ndef action(self, x):\nclass State:\ndef __init__(self):\ndef new_state(self, state):\nself.__class__ = state\ndef action(self, x):\ndef action(self, x):\nChapter 8: Classes and Objects\ndef action(self, x):\ndef action(self, x):\nclass Point:\ndef __init__(self, x, y):\ndef __repr__(self):\ndef distance(self, x, y):\nself argument.\nChapter 8: Classes and Objects\nclass Node:\nclass UnaryOperator(Node):\ndef __init__(self, operand):\nclass BinaryOperator(Node):\ndef __init__(self, left, right):\nclass Add(BinaryOperator):\nclass Number(Node):\ndef __init__(self, value):\nThese classes would then be used to build up nested data structures, like this:\ndef visit(self, node):\ndef generic_visit(self, node):\nraise RuntimeError('No {} method'.format('visit_' + type(node).__name__))\nTo use this class, a programmer inherits from it and implements various methods of the\ndef visit_Number(self, node):\ndef visit_Add(self, node):\nreturn self.visit(node.left) + self.visit(node.right)\ndef visit_Sub(self, node):\nreturn self.visit(node.left) - self.visit(node.right)\ndef visit_Mul(self, node):\nreturn self.visit(node.left) * self.visit(node.right)\ndef visit_Div(self, node):\nreturn self.visit(node.left) / self.visit(node.right)\ndef visit_Negate(self, node):\nHere is an example of how you would use this class using the previously generated\nAs a completely different example, here is a class that translates an expression into\ndef generate_code(self, node):\nself.visit(node)\nreturn self.instructions\ndef visit_Number(self, node):\nself.instructions.append(('PUSH', node.value))\nChapter 8: Classes and Objects\ndef binop(self, node, instruction):\nself.visit(node.left)\nself.visit(node.right)\ndef visit_Add(self, node):\nself.binop(node, 'ADD')\ndef visit_Sub(self, node):\nself.binop(node, 'SUB')\ndef visit_Mul(self, node):\ndef visit_Div(self, node):\ndef unaryop(self, node, instruction):\nself.visit(node.operand)\ndef visit_Negate(self, node):\nHere is an example of this class in action:\nThat is, in this recipe, none of the various Node classes provide any implementation that\nThe second major idea of this recipe is in the implementation of the visitor class itself.\ndef visit(self, node):\nreturn self.visit_Number(node)\nreturn self.visit_Add(node)\nreturn self.visit_Sub(node)\ndef visit_Add(self, node):\nreturn self.visit(node.left) + self.visit(node.right)\nThis recursion is what makes the visitor class traverse the entire data structure.\nFor example, if you are writing an HTTP framework, you might have classes that do a\ndef handle(self, request):\ndef do_GET(self, request):\ndef do_POST(self, request):\ndef do_HEAD(self, request):\nChapter 8: Classes and Objects\nIn Recipe 8.21, a visitor class was presented.\nclass Node:\ndef visit(self, node):\ndef _visit(self, node):\ndef generic_visit(self, node):\nraise RuntimeError('No {} method'.format('visit_' + type(node).__name__))\nIf you use this class, you’ll find that it still works with existing code that might have used\nclass UnaryOperator(Node):\ndef __init__(self, operand):\nclass BinaryOperator(Node):\ndef __init__(self, left, right):\nclass Add(BinaryOperator):\nclass Number(Node):\ndef __init__(self, value):\ndef visit_Number(self, node):\ndef visit_Add(self, node):\nreturn self.visit(node.left) + self.visit(node.right)\nChapter 8: Classes and Objects\ndef visit_Sub(self, node):\nreturn self.visit(node.left) - self.visit(node.right)\ndef visit_Mul(self, node):\nreturn self.visit(node.left) * self.visit(node.right)\ndef visit_Div(self, node):\nreturn self.visit(node.left) / self.visit(node.right)\ndef visit_Negate(self, node):\nreturn -self.visit(node.operand)\nreturn self.visit(node.left) + self.visit(node.right)\ndef visit_Number(self, node):\ndef visit_Add(self, node):\ndef visit_Sub(self, node):\ndef visit_Mul(self, node):\ndef visit_Div(self, node):\ndef visit_Negate(self, node):\ndef visit_Add(self, node):\nChapter 8: Classes and Objects\nvalue = self.visit(node.left)\nit_Name() method for that node.\nIn this recipe, if the value produced by a yield statement is a non-Node type,\nexecuting method, where it would show up as the return value from a yield statement.\nThis means that you can’t use a Node as a return value to be propagated.\nexample, possibly by introducing another class into the mix, like this:\nclass Visit:\ndef __init__(self, node):\nself.node = node\ndef visit(self, node):\nstack.append(self._visit(stack.pop().node))\nChapter 8: Classes and Objects\ndef _visit(self, node):\ndef generic_visit(self, node):\nraise RuntimeError('No {} method'.format('visit_' + type(node).__name__))\ndef visit_Add(self, node):\ndef visit_Sub(self, node):\nclass Node:\ndef __init__(self, value):\ndef __repr__(self):\nreturn 'Node({!r:})'.format(self.value)\ndef parent(self):\ndef parent(self, node):\nself._parent = weakref.ref(node)\ndef add_child(self, child):\nclass Data:\ndef __del__(self):\n# Node class involving a cycle\nclass Node:\ndef __init__(self):\nChapter 8: Classes and Objects\ndef add_child(self, child):\nclass Data:\ndef __del__(self):\n# Node class involving a cycle\nclass Node:\ndef __init__(self):\ndef __del__(self):\ndef add_child(self, child):\nChapter 8: Classes and Objects\nPython classes can support comparison by implementing a special method for each\nmethod in the classes.\nit, you decorate a class with it, and define __eq__() and one other comparison method\nclass Room:\nself.name = name\nclass House:\ndef __init__(self, name, style):\nself.name = name\ndef add_room(self, room):\ndef __str__(self):\ndef __eq__(self, other):\ndef __lt__(self, other):\nHere, the House class has been decorated with @total_ordering.\nIf you’ve written the code to make a class support all of the basic comparison operators,\nclass House:\ndef __eq__(self, other):\ndef __lt__(self, other):\nChapter 8: Classes and Objects\nWhen creating instances of a class, you want to return a cached reference to a previous\nthat there is only one instance of a class created for a set of input arguments.\nfrom the class itself.\nclass Spam:\ndef __init__(self, name):\nself.name = name\nclass as follows:\nclass Spam:\ncls._spam_cache[name] = self\nreturn self\ndef __init__(self, name):\nself.name = name\nChapter 8: Classes and Objects\nfactory function that’s decoupled from the original class definition.\nthis up is to put the caching code into a separate manager class and glue things together\ndef __init__(self):\ndef get_spam(self, name):\nif name not in self._cache:\nself._cache[name] = s\ns = self._cache[name]\ndef clear(self):\nclass Spam:\ndef __init__(self, name):\nself.name = name\nclasses) and attached to the Spam class as a replacement for the default caching imple‐\nmight give the class a name starting with an underscore, such as _Spam, which at least\nSpam instances directly, you can make __init__() raise an exception and use a class\nclass Spam:\ndef __init__(self, *args, **kwargs):\nself.name = name\nTo use this, you modify the caching code to use Spam._new() to create instances instead\ndef __init__(self):\ndef get_spam(self, name):\nif name not in self._cache:\nChapter 8: Classes and Objects\nself._cache[name] = s\ns = self._cache[name]\nthe Spam class, it’s probably best to not overthink the problem.\nthe name or defining a class method constructor is usually enough for programmers to\na nutshell, metaprogramming is about creating functions and classes whose main goal\nfeatures for this include decorators, class decorators, and metaclasses.\nYou want to put a wrapper layer around a function that adds extra processing (e.g.,\nIf you ever need to wrap a function with extra code, define a decorator function.\nHere is an example of using the decorator:\nA decorator is a function that accepts a function as input and returns a new function as\nclass A:\nclass B:\n# Equivalent definition of a class method\nThe code inside a decorator typically involves creating a new function that accepts any\narguments using *args and **kwargs, as shown with the wrapper() function in this\nnewly created function wrapper is returned as a result and takes the place of the original\nreturn value of the function being wrapped.\nThe return value of a decorator is\nFor example, the use of the decorator\nDecorators\nYou’ve written a decorator, but when you apply it to a function, important metadata\ndecorator from the functools library to the underlying wrapper function.\nPreserving Function Metadata When Writing Decorators \nHere is an example of using the decorator and examining the resulting function meta‐\nuse @wraps, you’ll find that the decorated function loses all sorts of useful information.\nAn important feature of the @wraps decorator is that it makes the wrapped function\nThe presence of the __wrapped__ attribute also makes decorated functions properly\nA decorator has been applied to a function, but you want to “undo” it, gaining access to\nGaining direct access to the unwrapped function behind a decorator can be useful for\nrecipe only works if the implementation of a decorator properly copies metadata using\nIf multiple decorators have been applied to a function, the behavior of accessing __wrap\ndef decorator1(func):\nprint('Decorator 1')\ndef decorator2(func):\nprint('Decorator 2')\n@decorator1\n@decorator2\nHere is what happens when you call the decorated function and the original function\nDecorator 1\nDecorator 2\nIn particular, the built-in decorators @staticmethod and @class\nDefining a Decorator That Takes Arguments\nYou want to write a decorator function that takes arguments.\nto write a decorator that adds logging to a function, but allows the user to specify the\nAdd logging to a function.\ndef decorate(func):\nreturn decorate\navailable to the inner functions of the decorator.\nThe inner function decorate() accepts\nWriting a decorator that takes arguments is tricky because of the underlying calling\nDefining a Decorator That Takes Arguments \ndecorator taking arguments.\nYou want to write a decorator function that wraps a function, but has user adjustable\n# Utility decorator to attach a function as an attribute of obj\nAdd logging to a function.\ndef decorate(func):\nreturn decorate\nAlthough it’s not shown, accessor functions to return the value of various settings could\nhad another decorator applied on top (such as the @timethis example), it would shadow\ndecorators defined as classes, as shown in Recipe 9.9.\nYou would like to write a single decorator that can be used without arguments, such as\n@decorator, or with optional arguments, such as @decorator(x,y,z).\nHere is a variant of the logging code shown in Recipe 9.5 that defines such a decorator:\nDefining a Decorator That Takes an Optional Argument \nusing decorators, most programmers are used to applying them without any arguments\ndecorators get applied to functions and their calling conventions.\nIn this case, the function to be wrapped is simply passed to logged as the first argument.\nThus, in the solution, the first argument of logged() is the function being wrapped.\nFor a decorator taking arguments such as this:\nto return a function that accepts the function and wraps it (see Recipe 9.5).\nDecorator\nYou want to optionally enforce type checking of function arguments as a kind of asser‐\ntype contracts on the input arguments to a function.\nEnforcing Type Checking on a Function Using a Decorator \nTypeError: Argument y must be <class 'int'>\ndef decorate(func):\nreturn decorate\nTypeError: Argument z must be <class 'int'>\nThis recipe is an advanced decorator example that introduces a number of important\nFirst, one aspect of decorators is that they only get applied once, at the time of function\nTo do this, simply have your decorator function return the function unwrapped.\nIn the solution, the following code fragment returns the function unmodified if the\ndef decorate(func):\nwith the argument signature of the function being wrapped.\nIn the first part of our decorator, we use the bind_partial() method of signatures to\nEnforcing Type Checking on a Function Using a Decorator \nthe argument names to the supplied values in the same order as the function signature.\nIn the actual wrapper function made by the decorator, the sig.bind() method is used.\nTypeError: Argument items must be <class 'list'>\nA final point of design discussion might be the use of decorator arguments versus func‐\nFor example, why not write the decorator to look at annotations like\nDefining Decorators As Part of a Class\nYou want to define a decorator inside a class definition and apply it to other functions\nDefining a decorator inside a class is straightforward, but you first need to sort out the\ninstance or a class method.\nclass A:\n# Decorator as an instance method\ndef decorator1(self, func):\nprint('Decorator 1')\n# Decorator as a class method\ndef decorator2(cls, func):\nprint('Decorator 2')\nHere is an example of how the two decorators would be applied:\nDefining Decorators As Part of a Class \n@a.decorator1\n# As a class method\n@A.decorator2\nis applied from the class A.\nDefining decorators in a class might look odd at first glance, but there are examples of\nclass with getter(), setter(), and deleter() methods that each act as a decorator.\n# Apply decorator methods\ndef first_name(self):\nreturn self._first_name\ndef first_name(self, value):\nself._first_name = value\nThe key reason why it’s defined in this way is that the various decorator methods are\nA common confusion when writing decorators in classes is getting tripped up by the\nproper use of the extra self or cls arguments in the decorator code itself.\nprovide a self or cls argument (since they’re part of a class), the wrapper function\nwrapper() function created in both decorators doesn’t include a self argument.\nA final subtle facet of having decorators defined in a class concerns their potential use\nFor example, suppose you want to apply one of the decorators defined\nin class A to methods defined in a subclass B.\nclass B(A):\n@A.decorator2\ndef bar(self):\nIn particular, the decorator in question has to be defined as a class method and you have\nsuch as @B.decorator2, because at the time of method definition, class B has not yet\nDefining Decorators As Classes\nYou want to wrap functions with a decorator, but the result is going to be a callable\nYou need your decorator to work both inside and outside class definitions.\nTo define a decorator as an instance, you need to make sure it implements the\nFor example, this code defines a class that puts a\ndef __init__(self, func):\nwraps(func)(self)\ndef __call__(self, *args, **kwargs):\nreturn self.__wrapped__(*args, **kwargs)\ndef __get__(self, instance, cls):\nreturn self\nreturn types.MethodType(self, instance)\nDefining Decorators As Classes \nTo use this class, you use it like a normal decorator, either inside or outside of a class:\nclass Spam:\ndef bar(self, x):\nprint(self, x)\nDefining a decorator as a class is usually straightforward.\nthings happen when you try to invoke decorated instance methods.\nThe reason it breaks is that whenever functions implementing methods are looked up\nin a class, their __get__() method is invoked as part of the descriptor protocol, which\nmethod object (which ultimately supplies the self argument to the method).\n>>> def grok(self, x):\non a class, the instance argument to __get__() is set to None and the Profiled instance\nDefining Decorators As Classes \nApplying Decorators to Class and Static Methods\nYou want to apply a decorator to a class or static method.\nApplying decorators to class and static methods is straightforward, but make sure that\n# Class illustrating application of the decorator to different kinds of methods\nclass Spam:\ndef instance_method(self, n):\nprint(self, n)\ndef class_method(cls, n):\nThe resulting class and static methods should operate normally, but have the extra\n>>> Spam.class_method(1000000)\n<class '__main__.Spam'> 1000000\nclass Spam:\nThus, if you try to use them like functions in another decorator, the decorator\nOne situation where this recipe is of critical importance is in defining class and static\nmethods in abstract base classes, as described in Recipe 8.12.\nto define an abstract class method, you can use this code:\nApplying Decorators to Class and Static Methods \nWriting Decorators That Add Arguments to Wrapped\nYou want to write a decorator that adds an extra argument to the calling signature of\nHere is an example of how the decorator works:\nAdding arguments to the signature of wrapped functions is not the most common ex‐\nthe arguments of the function being wrapped.\ndecorator was applied to a function that already had a debug argument, then it would\nWriting Decorators That Add Arguments to Wrapped Functions \nUsing Decorators to Patch Class Definitions\nThis might be a perfect use for a class decorator.\nFor example, here is a class decorator\ndef new_getattribute(self, name):\n# Attach to the class and return\nclass A:\ndef __init__(self,x):\ndef spam(self):\nHere is what happens if you try to use the class in the solution:\nClass decorators can often be used as a straightforward alternative to other more ad‐\nUsing Decorators to Patch Class Definitions \ndef __getattribute__(self, name):\ndef __init__(self,x):\ndef spam(self):\nsome sense, the class decorator solution is much more direct in how it operates, and it\nIf you are applying multiple class decorators to a class, the application order might\nFor example, a decorator that replaces a method with an entirely new imple‐\nSee Recipe 8.13 for another example of class decorators in action.\nAs Python programmers know, if you define a class, you call it like a function to create\nclass Spam:\ndef __init__(self, name):\nself.name = name\nclass NoInstances(type):\ndef __call__(self, *args, **kwargs):\nclass Spam(metaclass=NoInstances):\nNow, suppose you want to implement the singleton pattern (i.e., a class where only one\nclass Singleton(type):\ndef __init__(self, *args, **kwargs):\nself.__instance = None\ndef __call__(self, *args, **kwargs):\nif self.__instance is None:\nreturn self.__instance\nreturn self.__instance\nclass Spam(metaclass=Singleton):\ndef __init__(self):\nclass Cached(type):\ndef __init__(self, *args, **kwargs):\ndef __call__(self, *args):\nreturn self.__cache[args]\nclass Spam(metaclass=Cached):\ndef __init__(self, name):\nself.name = name\nHere’s an example showing the behavior of this class:\nyou didn’t use a metaclass, you might have to hide the classes behind some kind of extra\nclass _Spam:\ndef __init__(self):\nreturn _spam_instance\nreturn _spam_instance\nCapturing Class Attribute Definition Order\nclass Typed:\ndef __init__(self, name=None):\nself._name = name\ndef __set__(self, instance, value):\nif not isinstance(value, self._expected_type):\ninstance.__dict__[self._name] = value\nclass Integer(Typed):\nclass Float(Typed):\nclass String(Typed):\n# Metaclass that uses an OrderedDict for class body\nCapturing Class Attribute Definition Order \nclass OrderedMeta(type):\nused by methods of the class in various ways.\nFor example, here is a simple class that\nuses the ordering to implement a method for serializing the instance data as a line of\ndef as_csv(self):\ndef __init__(self, name, shares, price):\nself.name = name\nHere is an interactive session illustrating the use of the Stock class in the example:\nThis method is invoked immediately at the start of a class def‐\nuse when processing the class body.\ndef __init__(self, clsname):\ndef __setitem__(self, name, value):\nif name in self:\nclass OrderedMeta(type):\nHere’s what happens if you use this metaclass and make a class with duplicate entries:\ndef spam(self):\ndef spam(self):\nCapturing Class Attribute Definition Order \nwhen making the final class object.\nFor instance, in an object relational mapper, classes might be written in\nYou want to define a metaclass that allows class definitions to supply optional argu‐\nkeyword argument in the class statement.\nFor example, with abstract base classes:\ndef read(self, maxsize=None):\ndef write(self, data):\nclass Spam(metaclass=MyMeta, debug=True, synchronize=True):",
      "keywords": [
        "Spam",
        "decorator",
        "Node",
        "def spam",
        "def visit",
        "class Spam",
        "function",
        "def add",
        "Add",
        "Method",
        "recipe",
        "visit",
        "def wrapper",
        "class method",
        "arguments"
      ],
      "concepts": [
        "classes",
        "decorator",
        "decorate",
        "decorated",
        "decoration",
        "function",
        "functions",
        "functionality",
        "nodes",
        "methods"
      ],
      "similar_chapters": [
        {
          "book": "Python Cookbook 3rd",
          "chapter": 7,
          "title": "",
          "score": 0.77,
          "base_score": 0.62,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Python Cookbook 3rd",
          "chapter": 9,
          "title": "",
          "score": 0.659,
          "base_score": 0.509,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Python Cookbook 3rd",
          "chapter": 12,
          "title": "",
          "score": 0.52,
          "base_score": 0.37,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Python Cookbook 3rd",
          "chapter": 11,
          "title": "",
          "score": 0.48,
          "base_score": 0.33,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Python Cookbook 3rd",
          "chapter": 6,
          "title": "",
          "score": 0.375,
          "base_score": 0.375,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "node",
          "def",
          "class",
          "decorator",
          "self node"
        ],
        "semantic": [],
        "merged": [
          "node",
          "def",
          "class",
          "decorator",
          "self node"
        ]
      },
      "topic_id": 1,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.35780183136777327,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:08:10.208725+00:00"
      }
    },
    {
      "chapter_number": 9,
      "title": "Metaprogramming",
      "start_page": 381,
      "end_page": 440,
      "summary": "__prepare__(), __new__(), and __init__() methods using keyword-only arguments,\nclass MyMeta(type):\ndef __init__(self, name, bases, ns, *, debug=False, synchronize=False):\nThe __prepare__() method is called first and used to create the class\nclass Spam(metaclass=MyMeta):\n__prepare__() method, which runs prior to processing any statements in the class body.\nClass variables, on the other hand, would only be accessible in the __new__() and\nYou’ve written a function or method that uses *args and **kwargs, so that it can be\nuse the signature features found in the inspect module.\nTwo classes, Signature and\n>>> from inspect import Signature, Parameter\nFile \"/usr/local/lib/python3.3/inspect.py\", line 1972, in _bind\nFile \"/usr/local/lib/python3.3/inspect.py\", line 1961, in _bind\nFile \"/usr/local/lib/python3.3/inspect.py\", line 1985, in _bind\nfrom inspect import Signature, Parameter\ndef __init__(self, *args, **kwargs):\nbound_values = self.__signature__.bind(*args, **kwargs)\nHere is an example of how the Stock class works:\nfrom inspect import Signature, Parameter\nclass StructureMeta(type):\ndef __init__(self, *args, **kwargs):\nbound_values = self.__signature__.bind(*args, **kwargs)\nIf you do this, code that uses the inspect module\nEnforcing Coding Conventions in Classes\nIf you want to monitor the definition of classes, you can often do it by defining a\nclass MyMeta(type):\ndef __new__(self, clsname, bases, clsdict):\nclass MyMeta(type):\ndef __init__(self, clsname, bases, clsdict):\nEnforcing Coding Conventions in Classes \nTo use a metaclass, you would generally incorporate it into a top-level base class from\nclass B(Root):\nthe definition of all classes under it.\nclass NoMixedCaseMeta(type):\ndef foo_bar(self):      # Ok\nclass B(Root):\ndef fooBar(self):       # TypeError\nfrom inspect import signature\nimport logging\nclass MatchSignaturesMeta(type):\ndef __init__(self, clsname, bases, clsdict):\ndef foo(self, x, y):\ndef spam(self, x, *, z):\n# Class with redefined methods, but slightly different signatures\nclass B(A):\ndef foo(self, a, b):\ndef spam(self,x,z):\n(self, x, y) != (self, a, b)\nFor example, code that\nIn large object-oriented programs, it can sometimes be useful to put class definitions\nThe metaclass can observe class definitions and be\nEnforcing Coding Conventions in Classes \nwant to work with the resulting class.\nis typically used when a metaclass wants to alter the class definition in some way (by\na class has been created, and is useful if you want to write code that works with the fully\nformed class object.\nThis only works once the class instance has been\nThe last example also illustrates the use of Python’s function signature objects.\nLast, but not least, the line of code that uses super(self, self) is not a typo.\nworking with a metaclass, it’s important to realize that the self is actually a class object.\nYou’re writing code that ultimately needs to create a new class object.\nabout emitting emit class source code to a string and using a function such as exec()\nYou can use the function types.new_class() to instantiate new class objects.\nneed to do is provide the name of the class, tuple of parent classes, keyword arguments,\n# Example of making a class manually from parts\ndef __init__(self, name, shares, price):\nself.name = name\ndef cost(self):\n# Make a class\nimport types\nStock = types.new_class('Stock', (), {}, lambda ns: ns.update(cls_dict))\nThis makes a normal class object that works just like you expect:\ntypes.new_class().\nWhenever a class is defined, its __module__ attribute contains the\nIf the class you want to create involves a different metaclass, it would be specified in the\nthird argument to types.new_class().\n>>> Stock = types.new_class('Stock', (), {'metaclass': abc.ABCMeta},\n<class '__main__.Stock'>\nFor example, a class\nclass Spam(Base, debug=True, typecheck=False):\nSpam = types.new_class('Spam', (Base,),\nThe fourth argument to new_class() is the most mysterious, but it is a function that\nBeing able to manufacture new class objects can be useful in certain contexts.\n<class '__main__.Stock'>\nimport types\nimport sys\n# Make a __new__ function and add to the class dict\n# Make the class\ncls = types.new_class(classname, (tuple,), {},\nThe following example shows how the preceding code works:\nBy using types.new_class() instead, you ensure\nfunction that’s given as the fourth argument to types.new_class() receives the map‐\nIf you only want to carry out the preparation step, use types.prepare_class().\nimport types\nmetaclass, kwargs, ns = types.prepare_class('Stock', (), {'metaclass': type})\nYou want to initialize parts of a class definition once at the time a class is defined, not\nPerforming initialization or setup actions at the time of class definition is a classic use\nHere is an example that uses this idea to create classes similar to named tuples from the\nclass StructTupleMeta(type):\nThis code allows simple tuple-based data structures to be defined, like this:\nIn this recipe, the StructTupleMeta class takes the listing of attribute names in the\n_fields class attribute and turns them into property methods that access a particular\nThe __init__() method in StructTupleMeta is only called once for each class that is\nThe cls argument is the class that has just been defined.\nis using the _fields class variable to take the newly defined class and add some new\n__new__() method in that class is responsible for making new instances.\ncalling signature of tuples so that we can create instances with code that uses a normal-\nabout how Python classes are defined, how instances are created, and the points at which\ndifferent methods of metaclasses and classes are invoked.\nclass Spam:\ndef bar(self, x:int, y:int):\ndef bar(self, s:str, n:int = 0):\nimport types\nclass MultiMethod:\ndef __init__(self, name):\nself._methods = {}\nself.__name__ = name\ndef register(self, meth):\nif name == 'self':\nself._methods[tuple(types)] = meth\nself._methods[tuple(types)] = meth\ndef __call__(self, *args):\nCall a method based on type signature of the arguments\nmeth = self._methods.get(types, None)\ndef __get__(self, instance, cls):\nDescriptor method needed to make calls work in a class\nreturn types.MethodType(self, instance)\nreturn self\ndef __setitem__(self, key, value):\nclass MultipleMeta(type):\nTo use this class, you write code like this:\nclass Spam(metaclass=MultipleMeta):\ndef bar(self, x:int, y:int):\ndef bar(self, s:str, n:int = 0):\nimport time\nclass Date(metaclass=MultipleMeta):\ndef __init__(self, year: int, month:int, day:int):\ndef __init__(self):\nTypeError: No matching method for types (<class 'int'>, <class 'str'>)\nuses its __prepare__() method to supply a custom class dictionary as an instance of\nThis method builds a type tuple from all of the arguments except self, looks\nis required to make MultiMethod instances operate correctly inside class definitions.\n>>> b.__self__\nclass A:\nclass B(A):\nclass C:\nclass Spam(metaclass=MultipleMeta):\ndef foo(self, x:A):\ndef foo(self, x:C):\nTypeError: No matching method for types (<class '__main__.B'>,)\nimport types\nclass multimethod:\ndef __init__(self, func):\nself._methods = {}\ndef match(self, *types):\nself._methods[types[:len(types) - n]] = func\nreturn self\ndef __call__(self, *args):\nmeth = self._methods.get(types, None)\nreturn self._default(*args)\ndef __get__(self, instance, cls):\nreturn types.MethodType(self, instance)\nreturn self\nTo use the decorator version, you would write code like this:\nclass Spam:\ndef bar(self, *args):\ndef bar(self, x, y):\ndef bar(self, s, n = 0):\nYou are writing classes where you are repeatedly having to define property methods that\nConsider a simple class where attributes are being wrapped by property methods:\ndef __init__(self, name ,age):\nself.name = name\ndef name(self):\nreturn self._name\ndef name(self, value):\nself._name = value\ndef age(self):\nreturn self._age\ndef age(self, value):\nself._age = value\ndef prop(self):\ndef prop(self, value):\ndef __init__(self, name, age):\nself.name = name\nThis recipe illustrates an important feature of inner function or closures—namely, their\nuse in writing code that works a lot like a macro.\nthis example may look a little weird, but it’s really just generating the property code for\nclass definition itself.\ndef __init__(self, name, age):\nself.name = name\nHere the code is starting to look a lot like some of the type system descriptor code shown\nimport time\nIn the timethis() function, all of the code prior to the yield executes as the __en\nimport time\ndef __init__(self, label):\ndef __enter__(self):\nThus, if the code in exec() makes any kind of modification,\nYou want to write programs that parse and analyze Python source code.\nMost programmers know that Python can evaluate or execute source code provided in\nHowever, the ast module can be used to compile Python source code into an abstract\n>>> import ast\n<_ast.Module object at 0x100747390>\nclass that implements various visit_NodeName() methods where NodeName() matches\nimport ast\ndef __init__(self):\nself.loaded = set()\ndef visit_Name(self, node):\n# Some Python code\ncode = '''\nof just blindly passing some fragment of code into a function like exec(), you could\nalso write tools that look at the entire source code for a module and perform some sort\naccessed names into the body of a function by reparsing the function body’s source code,\nrewriting the AST, and recreating the function’s code object:\nimport ast\ndef __init__(self, lowered_names):\ndef visit_FunctionDef(self, node):\nThe decorator rewrites the source code of the countdown() function to look like this:\nThe dis module can be used to output a disassembly of any Python function.\nIf you ever want to interpret this code yourself, you would need to use some of the\nIronically, there is no function in the dis module that makes it easy for you to process\nTo use this function, you would use code like this:\n<code object add at 0x1007beed0, file \"<stdin>\", line 1>\n>>> c.co_code\n>>> # Make a completely new code object with bogus byte code\n>>> import types\n<code object add at 0x10069fe40, file \"<stdin>\", line 1>\nModules and Packages\nModules and packages are the core of any large project, and the Python installation\nand packages, such as how to organize packages, splitting large modules into multiple\nfiles, and creating namespace packages.\nMaking a Hierarchical Package of Modules\nYou want to organize your code into a package consisting of a hierarchical collection of\nmodules.\nsystem and make sure that every directory defines an __init__.py file.\nDefining a hierarchy of modules is as easy as making a directory structure on the file‐\nThe purpose of the __init__.py files is to include optional initialization code\nstatement import graphics, the file graphics/__init__.py will be imported and form\nimported prior to the final import of the graphics/formats/jpg.py file.\nFor example, an __init__.py file can\nFor such a file, a user merely has to use a single import graphics.formats instead of\nOther common uses of __init__.py include consolidating definitions from multiple files\nAstute programmers will notice that Python 3.3 still seems to perform package imports\nYou want precise control over the symbols that are exported from a module or package\nwhen a user uses the from module import * statement.\nChapter 10: Modules and Packages\nAlthough the use of from module import * is strongly discouraged, it still sees frequent\nuse in modules that define a large number of names.\nImporting Package Submodules Using Relative\nYou have code organized as a package and want to import a submodule from one of the\nother package submodules without hardcoding the package name into the import\nTo import modules of a package from other modules in the same package, use a package-\nImporting Package Submodules Using Relative Names \nIf the module mypackage.A.spam wants to import the module grok located in the same\ndirectory, it should include an import statement like this:\nimport grok\nIf the same module wants to import the module B.bar located in a different directory,\nit can use an import statement like this:\nfrom ..B import bar\nBoth of the import statements shown operate relative to the location of the spam.py file\nInside packages, imports involving modules in the same package can either use fully\ntop-level package name into your source code.\nthe code around.\nChapter 10: Modules and Packages\nAlthough it looks like you could navigate the filesystem using a relative import, they are\nFinally, it should be noted that relative imports only work for modules that are located\n% python3 mypackage/A/spam.py      # Relative imports fail\n% python3 -m mypackage.A.spam      # Relative imports work\nFor more background on relative package imports, see PEP 328.\nSplitting a Module into Multiple Files\nYou have a module that you would like to split into multiple files.\nlike to do it without breaking existing code by keeping the separate files unified as a\nA program module can be split into separate files by turning it into a package.\nclass A:\ndef spam(self):\nclass B(A):\ndef bar(self):\nSuppose you want to split mymodule.py into two files, one for each class definition.\nSplitting a Module into Multiple Files \nIn the a.py file, put this code:\nclass A:\ndef spam(self):\nIn the b.py file, put this code:\nfrom .a import A\nclass B(A):\ndef bar(self):\nfrom .a import A\nmodule:\ncode base, you could just break everything up into separate files and make users use a\nlot of import statements like this:\nChapter 10: Modules and Packages\nfrom mymodule import A, B\nThe key to doing this is to create a package directory and to use the\nFor instance, in this recipe, class B needs to access class A as a base class.\nPackage-relative imports are used throughout the recipe to avoid hardcoding the top-\nlevel module name into the source code.\n__init__.py file imports all of the required subcomponents all at once.\nfrom .a import A\nIn this version, classes A and B have been replaced by functions that load the desired\nSplitting a Module into Multiple Files \nFor a real-world example of lazy loading, look at the source code for multiprocessing/\nMaking Separate Directories of Code Import Under a\nEach part is organized as a directory of files, like a package.\nEssentially, the problem here is that you would like to define a top-level Python package\nlike a normal Python package, but you omit __init__.py files in the directories where\ndirectories of Python code like this:\nthere is no __init__.py file in either directory.\nmodule path and try some imports:\n>>> import sys\n>>> sys.path.extend(['foo-package', 'bar-package'])\n>>> import spam.blah\n>>> import spam.grok\nyou can import either spam.blah or spam.grok.\nChapter 10: Modules and Packages\nThe key to making a namespace package is to make sure there are no __init__.py files\n__init__.py file causes an interesting thing to happen on package import.\nA special namespace package module is then\n>>> import spam\nThe directories on __path__ are used when locating further package subcomponents\n(e.g., when importing spam.grok or spam.blah).\nAn important feature of namespace packages is that anyone can extend the namespace\nwith their own code.\nFor example, suppose you made your own directory of code like\nIf you added your directory of code to sys.path along with the other packages, it would\n>>> import spam.custom\n>>> import spam.grok\n>>> import spam.blah\nAttributeError: 'module' object has no attribute '__file__'\nMaking Separate Directories of Code Import Under a Common Namespace \n<module 'spam' (namespace)>\nYou want to reload an already loaded module because you’ve made changes to its source.\n>>> import spam\n<module 'spam' from './spam.py'>\nlying dictionary and refreshes it by re-executing the module’s source code.\nments such as from module import name.\n>>> import spam\n>>> from spam import grok\nChapter 10: Modules and Packages\nWithout quitting Python, go edit the source code to spam.py so that the function grok()\n<module 'spam' from './spam.py'>\ncode.\ndirectory and add a __main__.py file.\nThis technique also works if you package all of your code up into a zip file.\nCreating a directory or zip file and adding a __main__.py file is one possible way to\ncode isn’t meant to be used as a standard library module that’s installed into the Python\nFor example, if the code was\nYour package includes a datafile that your code needs to read.\nit, use the following code:\nChapter 10: Modules and Packages\nTo read a datafile, you might be inclined to write code that uses built-in I/O functions,\nSince each module includes a __file__ variable with the full path, it’s not im‐\nargument is the relative name of the file within the package.\nYou have Python code that can’t be imported because it’s not located in a directory listed\nYou would like to add new directories to Python’s path, but don’t want to\n>>> import sys\nThis .pth file needs to be placed into one of Python’s site-packages directories, which are\nimport sys\nimport sys\nThe site-packages directories are the locations where third-party modules and packages\nChapter 10: Modules and Packages\nImporting Modules Using a Name Given in a String\nYou have the name of a module that you would like to import, but it’s being held in a\nUse the importlib.import_module() function to manually import a module or part of\n>>> math = importlib.import_module('math')\n>>> mod = importlib.import_module('urllib.request')\nimport_module simply performs the same steps as import, but returns the resulting\nIf you are working with packages, import_module() can also be used to perform relative\nimports.\nimport b'\nb = importlib.import_module('.b', __package__)\nThe problem of manually importing modules with import_module() most commonly\narises when writing code that manipulates or wraps around modules in some way.\nkind where you need to load a module by name and perform patches to the loaded code.\nIn older code, you will sometimes see the built-in __import__() function used to per‐\nAlthough this works, importlib.import_module() is usually easier to\nSee Recipe 10.11 for an advanced example of customizing the import process.\nImporting Modules Using a Name Given in a String \nYou would like to customize Python’s import statement so that it can transparently load\nmain goal is actually to take a deep dive into the inner workings of Python’s import\nAt the core of this recipe is a desire to extend the functionality of the import statement.\nmaking the following directory of Python code:\nin each file so you can test them and see output when they’re imported.\nChapter 10: Modules and Packages\nThe first approach to loading a remote module is to create an explicit loading function\nimport sys\ndef load_module(url):\ncode = compile(source, url, 'exec')\nLoading Modules from a Remote Machine Using Import Hooks \nThis function merely downloads the source code, compiles it into a code object using\ncompile(), and executes it in the dictionary of a newly created module object.\n>>> fib = load_module('http://localhost:15000/fib.py')\n>>> spam = load_module('http://localhost:15000/spam.py')\nimport statement, and extending the code to support more advanced constructs, such\ncreate what’s known as a meta path importer.\nimport sys\nimport logging\ndef handle_starttag(self, tag, attrs):\nChapter 10: Modules and Packages\ndef __init__(self, baseurl):\ndef find_module(self, fullname, path=None):\nlog.debug('find_module: fullname=%r, path=%r', fullname, path)\nif not path[0].startswith(self._baseurl):\nlog.debug('find_module: trying package %r', fullname)\n# Attempt to load the package (which accesses __init__.py)\nloader.load_module(fullname)\nlog.debug('find_module: package %r loaded', fullname)\nlog.debug('find_module: package failed.\nreturn self._loaders[baseurl]\nLoading Modules from a Remote Machine Using Import Hooks \ndef invalidate_caches(self):\ndef __init__(self, baseurl):\ndef module_repr(self, module):\nreturn '<urlmodule %r from %r>' % (module.__name__, module.__file__)\ndef load_module(self, fullname):\ncode = self.get_code(fullname)\nmod.__file__ = self.get_filename(fullname)\ndef get_code(self, fullname):\nreturn compile(src, self.get_filename(fullname), 'exec')\ndef get_data(self, path):\ndef get_filename(self, fullname):\nreturn self._baseurl + '/' + fullname.split('.')[-1] + '.py'\ndef get_source(self, fullname):\nreturn self._source_cache[filename]\nChapter 10: Modules and Packages\ndef is_package(self, fullname):\ndef load_module(self, fullname):\nmod.__path__ = [ self._baseurl ]\ndef get_filename(self, fullname):\nreturn self._baseurl + '/' + '__init__.py'\ndef is_package(self, fullname):\n>>> import fib\n>>> # Load the importer and retry (it works)\n>>> import fib\n>>> import spam\nLoading Modules from a Remote Machine Using Import Hooks \nWhenever modules are imported, the\nfinders in sys.meta_path are consulted in order to locate the module.\nWhen imports are made, the module name is compared against\nused to load source code from the remote machine and create the resulting module\nclass and support functions to urlimport.py:\n# Path finder class for a URL\ndef __init__(self, baseurl):\ndef find_loader(self, fullname):\n# Attempt to load the package (which accesses __init__.py)\nloader.load_module(fullname)\nlog.debug('find_loader: package %r loaded', fullname)\nChapter 10: Modules and Packages\nlog.debug('find_loader: module %r found', fullname)\nreturn (self._loader, [])\nlog.debug('find_loader: module %r not found', fullname)\ndef invalidate_caches(self):\nsys.path_importer_cache.clear()\nsys.path_importer_cache.clear()\nTo use this path-based finder, you simply add URLs to sys.path.\n>>> import fib\n>>> # Imports still fail (not on path)\nLoading Modules from a Remote Machine Using Import Hooks \n>>> import fib\n>>> import sys\n>>> import fib\nthat finder is used to try to load modules for that entry on sys.path.\nIt should be noted that the remotely imported modules work exactly like any other\nmodule.\nmodule, package, and import mechanism is one of the most complicated parts of the\nChapter 10: Modules and Packages\nFirst, if you want to create a new module object, you use the imp.new_module() function.\n>>> m = imp.new_module('spam')\n<module 'spam'>\nModule objects usually have a few expected attributes, including __file__ (the name\nof the file that the module was loaded from) and __package__ (the name of the enclosing\n>>> import sys\n>>> m = sys.modules.setdefault('spam', imp.new_module('spam'))\n<module 'spam'>\nSince creating modules is easy, it is straightforward to write simple functions, such as\nthe load_module() function in the first part of this recipe.\nimports.\ndirectories, looking for __init__.py files, executing those files, setting up paths, etc.).\nLoading Modules from a Remote Machine Using Import Hooks \nfinder objects on sys.meta_path and invokes their find_module() method in order to\n>>> class Finder:\ndef find_module(self, fullname, path):\n>>> import sys\n>>> import types\nNotice how the find_module() method is being triggered on every import.\nthe path argument in this method is to handle packages.\nWhen packages are imported,\nit is a list of the directories that are found in the package’s __path__ attribute.\nChapter 10: Modules and Packages",
      "keywords": [
        "module",
        "code",
        "Package",
        "init",
        "Python",
        "File",
        "function",
        "source code",
        "Load",
        "method",
        "Spam",
        "Signature"
      ],
      "concepts": [
        "classes",
        "important",
        "imported",
        "code",
        "coding",
        "module",
        "packages",
        "function",
        "functions",
        "functionality"
      ],
      "similar_chapters": [
        {
          "book": "Python Cookbook 3rd",
          "chapter": 8,
          "title": "",
          "score": 0.659,
          "base_score": 0.509,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Python Cookbook 3rd",
          "chapter": 7,
          "title": "",
          "score": 0.657,
          "base_score": 0.507,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Python Cookbook 3rd",
          "chapter": 12,
          "title": "",
          "score": 0.514,
          "base_score": 0.364,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Python Cookbook 3rd",
          "chapter": 11,
          "title": "",
          "score": 0.438,
          "base_score": 0.288,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Python Cookbook 3rd",
          "chapter": 14,
          "title": "",
          "score": 0.421,
          "base_score": 0.421,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "import",
          "package",
          "class",
          "def",
          "spam"
        ],
        "semantic": [],
        "merged": [
          "import",
          "package",
          "class",
          "def",
          "spam"
        ]
      },
      "topic_id": 1,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.36844468711743905,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:08:10.208744+00:00"
      }
    },
    {
      "chapter_number": 10,
      "title": "Modules and Packages",
      "start_page": 441,
      "end_page": 480,
      "summary": "Looking for xml.etree.ElementPath ['/usr/local/lib/python3.3/xml/etree']\nThe placement of the finder on sys.meta_path is critical.\n>>> sys.meta_path.append(Finder())\n>>> import urllib.request\nare imported:\n>>> import fib\n>>> import xml.superfast\nLooking for xml.superfast ['/usr/local/lib/python3.3/xml']\nof sys.meta_path, where it serves as a kind of importer of last resort.\nmodule name can’t be located by any of the other import mechanisms, it gets handled\nvalue presented in the path argument needs to be checked to see if it starts with the URL\nAdditional handling of packages is found in the UrlPackageLoader class.\nrather than importing the package name, tries to load the underlying __init__.py file.\nIt also sets the module __path__ attribute.\nbe passed to subsequent find_module() calls when loading package submodules.\nThe path-based import hook is an extension of these ideas, but based on a somewhat\nAs you know, sys.path is a list of directories where Python looks\nLoading Modules from a Remote Machine Using Import Hooks \n>>> import sys\nEach entry in sys.path is additionally attached to a finder object.\nfinders by looking at sys.path_importer_cache:\n>>> pprint(sys.path_importer_cache)\n'/usr/local/lib/python3.3/site-packages': FileFinder('...python3.3/site-packages'),\nsys.path_importer_cache tends to be much larger than sys.path because it records\nries of packages which usually aren’t included on sys.path.\nTo execute import fib, the directories on sys.path are checked in order.\ndirectory, the name fib is presented to the associated finder found in sys.path_im\ndef find_loader(self, name):\n>>> import sys\n>>> # Add a \"debug\" entry to the importer cache\n>>> sys.path_importer_cache['debug'] = Finder()\n>>> # Add a \"debug\" directory to sys.path\n>>> import threading\nChapter 10: Modules and Packages\ndebug as the first entry on sys.path.\nOn all subsequent imports, you see your finder\nThe population of sys.path_importer_cache is controlled by a list of functions stored\nin sys.path_hooks.\nchecking function to sys.path_hooks:\n>>> sys.path_importer_cache.clear()\n>>> def check_path(path):\n>>> sys.path_hooks.insert(0, check_path)\n>>> import fib\nChecking /Users/beazley/.local/lib/python3.3/site-packages\nChecking /usr/local/lib/python3.3/site-packages\nAs you can see, the check_path() function is being invoked for every entry on\nsys.path.\n(checking just moves to the next function on sys.path_hooks).\nUsing this knowledge of how sys.path is processed, you can install a custom path\nchecking function that looks for filename patterns, such as URLs. For instance:\n>>> def check_url(path):\n>>> sys.path.append('http://localhost:15000')\n>>> sys.path_hooks[0] = check_url\n>>> import fib\nLoading Modules from a Remote Machine Using Import Hooks \n>>> # Notice installation of Finder in sys.path_importer_cache\n>>> sys.path_importer_cache['http://localhost:15000']\npath checking function has been installed that looks for URLs in sys.path.\nsys.path_importer_cache.\nthrough that part of sys.path will try to use your custom finder.\nPackage handling with a path-based importer is somewhat tricky, and relates to the\nFor a normal package, find_loader() returns a tuple (loader, path) where loader\nis the loader instance that will import the package (and execute __init__.py) and path\nis a list of the directories that will make up the initial setting of the package’s __path__\ncuted import grok, the path returned by find_loader() would be [ 'http://local\n(None, path) where path is a list of directories that would have made up the package’s\nnism moves on to check further directories on sys.path.\nAll packages contain an internal path setting, which can be\nChapter 10: Modules and Packages\nAs mentioned, the setting of __path__ is controlled by the return value of the find_load\nfunctions in sys.path_hooks.\ntries in __path__ are checked by the handle_url() function.\nof UrlPathFinder to be created and added to sys.path_importer_cache.\nIf your implementation of a finder involves the use of other modules (e.g., urllib.re\nquest), there is a possibility that those modules will attempt to make further imports\ncode ensures that the finder doesn’t respond to any import requests while it’s in the\nwant the URL importers to reread the list of links, possibly for the purpose of being able\nImporters installed using sys.meta_path are free to\nmodule/package handling.\nof sys.path.\nBecause of the connection to sys.path, modules loaded with such exten‐\nLoading Modules from a Remote Machine Using Import Hooks \n>>> import logging\n>>> import urlimport\n>>> import fib\n>>> import sys\n>>> sys.path.append('http://localhost:15000')\n>>> import fib\nPatching Modules on Import\nYou want to patch or apply decorators to functions in an existing module.\nonly want to do it if the module actually gets imported and used elsewhere.\nChapter 10: Modules and Packages\nimport importlib\nimport sys\n_post_import_hooks = defaultdict(list)\ndef find_module(self, fullname, path=None):\ndef __init__(self, finder):\ndef load_module(self, fullname):\nimportlib.import_module(fullname)\nfor func in _post_import_hooks[fullname]:\nreturn module\ndef when_imported(fullname):\n_post_import_hooks[fullname].append(func)\nTo use this code, you use the when_imported() decorator.\n>>> @when_imported('threading')\n>>> import threading\nPatching Modules on Import \nFirst, the role of the @when_imported decorator is to register handler functions that get\ntriggered on import.\nlist in the _post_import_hooks dictionary.\nTo trigger the pending actions in _post_import_hooks after module import, the Post\nImportFinder class is installed as the first item in sys.meta_path.\nRecipe 10.11, sys.meta_path contains a list of finder objects that are consulted in order\ngated to the other finders on sys.meta_path.\nfunction imp.import_module() is called recursively in the PostImportLoader class.\nThis is what causes the import request to pass\nto the other finders on sys.meta_path.\nChapter 10: Modules and Packages\nAfter a module has been loaded with imp.import_module(), all handlers currently reg‐\nistered in _post_import_hooks are called with the newly loaded module as an argument.\nYou simply write a handler function that’s decorated with @when_imported()\nthe post import handler function doesn’t get triggered again (all the more reason to not\nsys.modules and redo the import, you’ll see the handler trigger again.\nMore information about post-import hooks can be found in PEP 369 .\nInstalling Packages Just for Yourself\nAlternatively, perhaps you just want to install a package\nas ~/.local/lib/python3.3/site-packages.\npython3 setup.py install --user\nInstalling Packages Just for Yourself \nfound in a location such as /usr/local/lib/python3.3/site-packages.\nCreating a New Python Environment\nYou want to create a new Python environment in which you can install modules and\n>>> import sys\nChapter 10: Modules and Packages\n'/Users/beazley/Spam/lib/python3.3/site-packages']\nA key feature of this interpreter is that its site-packages directory has been set to the\nbe installed here, not in the normal system site-packages directory.\nAs you can see in the example, the sys.path variable\ncontains directories from the normal system Python, but the site-packages directory has\nWith a new virtual environment, the next step is often to install a package manager,\nThis should install the packages into the newly created site-packages directory.\nAlthough a virtual environment might look like a copy of the Python installation, it\nIf you would like to include already installed packages as part of a virtual environ‐\nment, create the environment using the --system-site-packages option.\nFor example, a typical library package might look\nTo make the package something that you can distribute, first write a setup.py file that\nthe Python Package Index.\nChapter 10: Modules and Packages\nFor pure Python code, writing a plain setup.py file is usually straightforward.\nservices and using Python to implement networked services as a server.\nYou need to access various services via HTTP as a client.\nFor simple things, it’s usually easy enough to use the urllib.request module.\nexample, to send a simple HTTP GET request to a remote service, do something like this:\nfrom urllib import request, parse\nIf you need to send the query parameters in the request body using a POST method,\nfrom urllib import request, parse\nfrom urllib import request, parse\nFor example, here is equivalent requests code for the\nimport requests\nresp = requests.post(url, data=parms, headers=headers)\nA notable feature of requests is how it returns the resulting response content from a\nimport requests\nresp = requests.head('http://www.python.org/index.html')\nHere is a requests example that executes a login into the Python Package index using\nimport requests\nresp = requests.get('http://pypi.python.org/pypi?:action=login',\nHere is an example of using requests to pass HTTP cookies from one request to the\nimport requests\nresp1 = requests.get(url)\nimport requests\nFor really simple HTTP client code, using the built-in urllib module is usually fine.\nThis is where a third-party module, such as requests,\nlike requests, you might have to implement your code using the low-level http.cli\nFor example, this code shows how to execute a HEAD request:\nfrom http.client import HTTPConnection\nauthenticates to the Python package index:\nimport urllib.request\nr = urllib.request.Request('http://pypi.python.org/pypi?:action=login')\n>>> import requests\nattempts (i.e., don’t try to learn how to write an HTTP authentication client by logging\nYou want to implement a server that communicates with clients using the TCP Internet\nAn easy way to create a TCP server is to use the socketserver library.\ndef handle(self):\nprint('Got connection from', self.client_address)\nmsg = self.request.recv(8192)\nself.request.send(msg)\nIn this code, you define a special handler class that implements a handle() method for\nservicing client connections.\nThe request attribute is the underlying client socket and\nTo test the server, run it and then open a separate Python process that connects to it:\n>>> from socket import socket, AF_INET, SOCK_STREAM\nexample that uses the StreamRequestHandler base class to put a file-like interface on\ndef handle(self):\nprint('Got connection from', self.client_address)\n# self.wfile is a file-like object for writing\nsocketserver makes it relatively easy to create simple TCP servers.\non each client connection.\nThe socket option shown is actually a very common setting that allows the server to\nimport socket\ndef handle(self):\nprint('Got connection from', self.client_address)\n# self.wfile is a file-like object for writing\nFinally, it should be noted that most of Python’s higher-level networking modules (e.g.,\nit is also not difficult to implement servers directly using the socket library as well.\nis a simple example of directly programming a server with Sockets:\nfrom socket import socket, AF_INET, SOCK_STREAM\ndef echo_handler(address, client_sock):\ndef echo_server(address, backlog=5):\nYou want to implement a server that communicates with clients using the UDP Internet\nAs with TCP, UDP servers are also easy to create using the socketserver library.\nexample, here is a simple time server:\nimport time\ndef handle(self):\nprint('Got connection from', self.client_address)\n# Get message and client socket\nmsg, sock = self.request\nsock.sendto(resp.encode('ascii'), self.client_address)\nAs before, you define a special handler class that implements a handle() method for\nservicing client connections.\nTo test the server, run it and then open a separate Python process that sends messages\n>>> from socket import socket, AF_INET, SOCK_DGRAM\nA typical UDP server receives an incoming datagram (message) along with a client\nIf the server is to respond, it sends a datagram back to the client.\nGiven that there is no underlying connection, UDP servers are often much easier to\nImplementing a UDP server directly using sockets is also not difficult.\nfrom socket import socket, AF_INET, SOCK_DGRAM\nimport time\ndef time_server(address):\n>>> import ipaddress\nThe ipaddress module has classes for representing IP addresses, networks, and inter‐\nnetwork-related modules, such as the socket library.\n>>> from socket import socket, AF_INET, SOCK_STREAM\nimport cgi\ndef __call__(self, environ, start_response):\nhandler = self.pathmap.get((method,path), notfound_404)\nreturn handler(environ, start_response)\ndef register(self, method, path, function):\nself.pathmap[method.lower(), path] = function\nimport time\ndef hello_world(environ, start_response):\nfrom wsgiref.simple_server import make_server\nFor implementing a simple REST interface, it is often easy enough to base your code on\nimport cgi\nenviron['REQUEST_METHOD'] is the type of re‐\nfrom the request and puts them into a dictionary-like object for later use.\ndef __call__(self, environ, start_response)\nWhen a request arrives, the method and path are extracted and\nNobody likes to work with code that is a tangled mess of print() functions, XML, and\nFinally, an important part of using WSGI is that nothing in the implementation is spe‐\nfrom wsgiref.simple_server import make_server\nThis will create a simple server that you can use to see if your implementation works.\nYou want an easy way to execute functions or methods in Python programs running on\nHere is an example of a simple server that implements a simple key-\nfrom xmlrpc.server import SimpleXMLRPCServer\ndef __init__(self, address):\nself._serv = SimpleXMLRPCServer(address, allow_none=True)\nfor name in self._rpc_methods_:\nself._serv.register_function(getattr(self, name))\ndef get(self, name):\nreturn self._data[name]\ndef set(self, name, value):\nreturn name in self._data\ndef keys(self):\nreturn list(self._data)\ndef serve_forever(self):\nHere is how you would access the server remotely from a client:\n>>> from xmlrpc.client import ServerProxy\nXML-RPC can be an extremely easy way to set up a simple remote procedure call service.\nAll you need to do is create a server instance, register functions with it using the regis\nrecipe packages it up into a class to put all of the code together, but there is no such\nFor example, you could create a server by trying something like this:\nfrom xmlrpc.server import SimpleXMLRPCServer\nHere is a simple example of writing an echo server:\nfrom multiprocessing.connection import Listener\nimport traceback\ndef echo_server(address, authkey):\nHere is a simple example of a client connecting to the server and sending various\n>>> from multiprocessing.connection import Client\nTo create a connection using a UNIX domain socket, simply change the address\nTo create a connection using a Windows named pipe, use a filename such as this:\nYou want to implement simple remote procedure call (RPC) on top of a message passing\nRPC is easy to implement by encoding function requests, arguments, and return values\nexample of a simple RPC handler that could be incorporated into a server:\nimport pickle\nself._functions = { }\ndef register_function(self, func):\ndef handle_connection(self, connection):\nr = self._functions[func_name](*args,**kwargs)\nTo use this handler, you need to add it into a messaging server.\nRPC server:\nfrom multiprocessing.connection import Listener\ndef rpc_server(handler, address, authkey):\nt = Thread(target=handler.handle_connection, args=(client,))\nrpc_server(handler, ('localhost', 17000), authkey=b'peekaboo')\nTo access the server from a remote client, you need to create a corresponding RPC proxy\nimport pickle\ndef __init__(self, connection):\nself._connection = connection\nself._connection.send(pickle.dumps((name, args, kwargs)))\nresult = pickle.loads(self._connection.recv())\nTo use the proxy, you wrap it around a connection to the server.\n>>> from multiprocessing.connection import Client\nwants to call a remote function, such as foo(1, 2, z=3), the proxy class creates a tuple\nample, if you want to implement RPC over ZeroMQ, just replace the connection objects\nimport json\nself._functions = { }\ndef register_function(self, func):\ndef handle_connection(self, connection):\nr = self._functions[func_name](*args,**kwargs)\nimport json\ndef __init__(self, connection):\nself._connection = connection\nself._connection.send(json.dumps((name, args, kwargs)))\nresult = json.loads(self._connection.recv())\nFor another example of an RPC implementation, it can be useful to look at the imple‐\nYou want a simple way to authenticate the clients connecting to servers in a distributed\nimport hmac\ndef client_authenticate(connection, secret_key):\nsecret_key is a key known only to both client/server.\ndef server_authenticate(connection, secret_key):\nRequest client authentication.\nThe general idea is that upon connection, the server presents the client with a message\nThe client and server both\nThe client sends its computed digest back to the server, where it is\nFor example, with sockets, the server code might look something like this:\nfrom socket import socket, AF_INET, SOCK_STREAM\ndef echo_handler(client_sock):\nif not server_authenticate(client_sock, secret_key):",
      "keywords": [
        "module",
        "server",
        "client",
        "Web Programming",
        "path",
        "packages",
        "Python",
        "connection",
        "simple",
        "import requests",
        "socket",
        "sys.path",
        "request"
      ],
      "concepts": [
        "imports",
        "important",
        "packages",
        "packaging",
        "connection",
        "connections",
        "connects",
        "modules",
        "requested",
        "request"
      ],
      "similar_chapters": [
        {
          "book": "Python Cookbook 3rd",
          "chapter": 5,
          "title": "",
          "score": 0.492,
          "base_score": 0.492,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Python Cookbook 3rd",
          "chapter": 9,
          "title": "",
          "score": 0.372,
          "base_score": 0.372,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Python Cookbook 3rd",
          "chapter": 14,
          "title": "",
          "score": 0.363,
          "base_score": 0.363,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Python Cookbook 3rd",
          "chapter": 15,
          "title": "",
          "score": 0.35,
          "base_score": 0.35,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Python Cookbook 3rd",
          "chapter": 1,
          "title": "",
          "score": 0.315,
          "base_score": 0.315,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "import",
          "sys",
          "server",
          "path",
          "packages"
        ],
        "semantic": [],
        "merged": [
          "import",
          "sys",
          "server",
          "path",
          "packages"
        ]
      },
      "topic_id": null,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.3365950844388168,
        "topic_boost": 0.0,
        "timestamp": "2025-12-17T23:08:10.208760+00:00"
      }
    },
    {
      "chapter_number": 11,
      "title": "Network and Web Programming",
      "start_page": 481,
      "end_page": 520,
      "summary": "msg = client_sock.recv(8192)\nYou want to implement a network service involving sockets where servers and clients\nserver certificate to connecting clients:\nCERTFILE = 'server_cert.pem' # Server certificate (given to client)\nHere’s an interactive session that shows how to connect to the server as a client.\nclient requires the server to present its certificate and verifies it:\nFirst, for servers, SSL can be added through the use of a mixin class like this:\nMixin class that adds support for SSL to existing servers based\ndef __init__(self, *args,\ndef get_request(self):\nexample of defining an XML-RPC server that operates over SSL:\ndef __init__(self, *args, **kwargs):\nself._data = {}\ndef get(self, name):\nreturn self._data[name]\ndef set(self, name, value):\nself._data[name] = value\ndef delete(self, name):\ndel self._data[name]\ndef exists(self, name):\nreturn name in self._data\ndef keys(self):\nreturn list(self._data)\ndef serve_forever(self):\nTo use this server, you can connect using the normal xmlrpc.client module.\nOne complicated issue with SSL clients is performing extra steps to verify the server\ndef __init__(self, cafile, certfile=None, keyfile=None):\ndef make_connection(self, host):\ns = super().make_connection((host, {'context': self._ssl_context}))\nAs shown, the server presents a certificate to the client and the client verifies it.\nIf the server wants to verify the client, change the\nTo verify server certificates, clients maintain a file con‐\nFor the purposes of this recipe, you can create what’s known as a self-signed certificate.\nIn server-related code, both the private key and certificate file will be presented to the\nput a copy of the server’s certificate on the client machine and use that as a means for\nDuring connection, the server will present its certificate, and then you’ll\nOnce a connection is established, you can use the send_handle() and recv_handle()\nsend_handle(out_p, client.fileno(), worker_pid)\nThe server process opens a socket and waits for client connections.\nthe server receives a connection, it sends the resulting socket file descriptor to the worker\nIf you connect to the running server using Telnet or a similar tool, here is an example\nThe most important part of this example is the fact that the client socket accepted in the\nFor example, you could implement the server and worker\ndef server(work_address, port):\n# Now run a TCP/IP server and send clients to worker\nfrom multiprocessing.connection import Client\ndef worker(server_address):\nserv = Client(server_address, authkey=b'peekaboo')\nwith socket(AF_INET, SOCK_STREAM, fileno=fd) as client:\nprint('Usage: worker.py server_address', file=sys.stderr)\ndifferent implementation of the server that shows how to pass descriptors using sockets:\ndef server(work_address, port):\n# Now run a TCP/IP server and send clients to worker\ndef worker(server_address):\nprint('Usage: worker.py server_address', file=sys.stderr)\ndef fileno(self):\ndef wants_to_receive(self):\ndef handle_receive(self):\ndef wants_to_send(self):\ndef handle_send(self):\ndef __init__(self, address):\nself.sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\nself.sock.bind(address)\ndef fileno(self):\nreturn self.sock.fileno()\ndef wants_to_receive(self):\ndef handle_receive(self):\nmsg, addr = self.sock.recvfrom(1)\ndef handle_receive(self):\nmsg, addr = self.sock.recvfrom(8192)\nself.sock.sendto(msg, addr)\ndef __init__(self, address, client_handler, handler_list):\nself.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\nself.sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, True)\nself.sock.bind(address)\nself.sock.listen(1)\nself.client_handler = client_handler\ndef fileno(self):\nreturn self.sock.fileno()\ndef wants_to_receive(self):\ndef handle_receive(self):\nclient, addr = self.sock.accept()\ndef __init__(self, sock, handler_list):\nself.sock = sock\ndef fileno(self):\nreturn self.sock.fileno()\ndef close(self):\nself.sock.close()\ndef wants_to_send(self):\ndef handle_send(self):\nnsent = self.sock.send(self.outgoing)\ndef wants_to_receive(self):\ndef handle_receive(self):\ndata = self.sock.recv(8192)\nself.close()\nself.outgoing.extend(data)\nsimultaneous connections without ever using threads or processes.\nout to a separate thread or process.\nHowever, coordinating threads and processes with\ndef __init__(self, nworkers):\nself.signal_done_sock, self.done_sock = socket.socketpair()\nself.signal_done_sock = socket.socket(socket.AF_INET,\nself.signal_done_sock.connect(server.getsockname())\nself.done_sock, _ = server.accept()\ndef fileno(self):\nreturn self.done_sock.fileno()\n# Callback that executes when the thread is done\ndef _complete(self, callback, r):\nself.signal_done_sock.send(b'x')\n# Run a function in a thread pool\ndef run(self, func, args=(), kwargs={},*,callback):\ndef wants_to_receive(self):\ndef handle_receive(self):\nself.done_sock.recv(1)\ncompleted by the thread pool, it executes the _complete() method in the class.\nHere is a simple server that shows how to use the thread pool to carry out a long-running\ndef handle_receive(self):\nmsg, addr = self.sock.recvfrom(128)\npool.run(fib, (n,), callback=lambda r: self.respond(r, addr))\ndef respond(self, result, addr):\nTo test the program, first create a server and client program connected over a socket.\nuncommon to write programs that need to send/receive large chunks of data.\nnetwork-related functions aren’t able to send or receive huge blocks of data entirely all\nIn this form, the view can be passed to socket-related functions, such as sock.send()\nFor example, sock.send() sends data directly from memory\nStarting and Stopping Threads\nYou want to create and destroy threads for concurrent execution of code.\n# Code to execute in an independent thread\n# Create and launch a thread\nfrom threading import Thread\nt = Thread(target=countdown, args=(10,))\nWhen you create a thread instance, it doesn’t start executing until you invoke its start()\nOnce started, threads run\nYou can query a thread instance to see\nYou can also request to join with a thread, which waits for it to terminate:\nThe interpreter remains running until all threads terminate.\nFor long-running threads\nor background tasks that run forever, you should consider making the thread daemonic.\nt = Thread(target=countdown, args=(10,), daemon=True)\nmain thread terminates.\nthreads.\nFor example, there are no operations to terminate a thread, signal a thread,\nIf you want to be able to terminate threads, the thread must be programmed to poll for\nFor example, you might put your thread in a class such as this:\ndef __init__(self):\nself._running = True\ndef terminate(self):\nself._running = False\ndef run(self, n):\nwhile self._running and n > 0:\nt = Thread(target=c.run, args=(10,))\nFor example, a thread blocked indefinitely on an I/O operation\nto carefully program thread to utilize timeout loops.\ndef terminate(self):\nself._running = False\ndef run(self, sock):\nwhile self._running:\nDue to a global interpreter lock (GIL), Python threads are restricted to an execution\nSometimes you will see threads defined via inheritance from the Thread class.\nfrom threading import Thread\nclass CountdownThread(Thread):\ndef __init__(self, n):\nself.n = 0\ndef run(self):\nwhile self.n > 0:\nStarting and Stopping Threads \nprint('T-minus', self.n)\nself.n -= 1\nthreading library.\nThat is, you can only use the resulting code in the context of threads,\non threading.\ncontexts that may or may not involve threads.\nneutral to the actual means of concurrency (threads, processes, etc.).\nDetermining If a Thread Has Started\nYou’ve launched a thread, but want to know when it actually starts running.\nA key feature of threads is that they execute independently and nondeterministically.\nThis can present a tricky synchronization problem if other threads in the program need\nTo solve such problems, use the Event object from the threading\nEvent instances are similar to a “sticky” flag that allows threads to wait for something\nIf the event is unset and a thread waits on the\nA thread that sets the event\nwill wake up all of the threads that happen to be waiting (if any).\nIf a thread waits on an\nHere is some sample code that uses an Event to coordinate the startup of a thread:\nfrom threading import Thread, Event\n# Code to execute in an independent thread\n# Launch the thread and pass the startup event\nt = Thread(target=countdown, args=(10,started_evt))\n# Wait for the thread to start\nthread wait until the countdown() function has first printed the startup message.\nThat is, you create an event, threads\nit will execute before a released thread cycles back to wait on the event again).\nIf a thread is going to repeatedly signal an event over and over, you’re probably better\nimport threading\ndef __init__(self, interval):\nself._cv = threading.Condition()\ndef start(self):\nt = threading.Thread(target=self.run)\nDetermining If a Thread Has Started \ndef run(self):\nRun the timer and notify waiting threads after each interval\ndef wait_for_tick(self):\nthreading.Thread(target=countdown, args=(10,)).start()\nthreading.Thread(target=countup, args=(5,)).start()\nA critical feature of Event objects is that they wake all waiting threads.\na program where you only want to wake up a single waiting thread, it is probably better\n# Worker thread\n# Create some threads\nsema = threading.Semaphore(0)\nt = threading.Thread(target=worker, args=(n, sema,))\nIf you run this, a pool of threads will start, but nothing happens because they’re all\nWriting code that involves a lot of tricky synchronization between threads is likely to\nCommunicating Between Threads\nYou have multiple threads in your program and you want to safely communicate or\nPerhaps the safest way to send data from one thread to another is to use a Queue from\nTo do this, you create a Queue instance that is shared by the threads.\nThreads then use put() or get() operations to add or remove items from the queue.\nfrom threading import Thread\n# A thread that produces data\nCommunicating Between Threads \n# A thread that consumes data\n# Create the shared queue and launch both threads\nt1 = Thread(target=consumer, args=(q,))\nt2 = Thread(target=producer, args=(q,))\nas many threads as you wish.\nfrom threading import Thread\n# A thread that produces data\n# A thread that consumes data\nAlthough queues are the most common thread communication mechanism, you can\nFor example, here is how you might build a thread-safe priority queue, as\nimport threading\ndef __init__(self):\nself._queue = []\nself._cv = threading.Condition()\ndef put(self, item, priority):\ndef get(self):\nwhile len(self._queue) == 0:\nreturn heapq.heappop(self._queue)[-1]\nThread communication with a queue is a one-way and nondeterministic process.\nfrom threading import Thread\n# A thread that produces data\n# A thread that consumes data\nCommunicating Between Threads \n# Create the shared queue and launch both threads\nt1 = Thread(target=consumer, args=(q,))\nt2 = Thread(target=producer, args=(q,))\nfrom threading import Thread, Event\n# A thread that produces data\n# A thread that consumes data\nWriting threaded programs based on simple queuing is often a good way to maintain\nOne caution with thread queues is that putting an item in a queue doesn’t make a copy\nthreads.\nfrom threading import Thread\n# A thread that produces data\n# A thread that consumes data\nbetween communicating threads is a much harder problem than it seems.\nCommunicating Between Threads \nA timeout is useful if you’re trying to make consumer threads periodically give up on\nthe queue is empty, but in the time that has elapsed since making the call, another thread\nYour program uses threads and you want to lock critical sections of code to avoid race\nTo make mutable objects safe to use by multiple threads, use Lock objects in the thread\nimport threading\nA counter object that can be shared by multiple threads.\ndef __init__(self, initial_value = 0):\nself._value_lock = threading.Lock()\ndef incr(self,delta=1):\nwith self._value_lock:\ndef decr(self,delta=1):\nwith self._value_lock:\none thread is allowed to execute the block of statements under the with statement at a\nin threaded programs can result in randomly corrupted data and bizarre behavior\nimport threading\nA counter object that can be shared by multiple threads.\ndef __init__(self, initial_value = 0):\nself._value_lock = threading.Lock()\ndef incr(self,delta=1):\nself._value_lock.acquire()\nself._value_lock.release()\ndef decr(self,delta=1):\nself._value_lock.acquire()\nself._value_lock.release()\nsuch that each thread is only allowed to acquire one lock at a time.\nobject is a lock that can be acquired multiple times by the same thread.\nas a “monitor.” With this kind of locking, only one thread is allowed to use an entire\nfunction or the methods of a class while the lock is held.\nimport threading\nA counter object that can be shared by multiple threads.\n_lock = threading.RLock()\ndef __init__(self, initial_value = 0):\ndef incr(self,delta=1):\ndef decr(self,delta=1):\nIn this variant of the code, there is just a single class-level lock shared by all instances\none thread is allowed to be using the methods of the class at once.\nit may cause more lock contention in programs that use a large number of threads and\nthreads or throttling.\nfrom threading import Semaphore\n# At most, five threads allowed to run at once\nYou’re writing a multithreaded program where threads need to acquire more than one\nIn multithreaded programs, a common source of deadlock is due to threads that attempt\nFor instance, if a thread acquires the first lock, but\nthen blocks trying to acquire the second lock, that thread can potentially block the\nprogress of other threads and make the program freeze.\nimport threading\n# Thread-local state to stored information on locks already acquired\ndef acquire(*locks):\nthe acquire() function whenever you want to work with one or more locks.\nimport threading\nx_lock = threading.Lock()\ny_lock = threading.Lock()\ndef thread_1():\nprint('Thread-1')\ndef thread_2():\nprint('Thread-2')\nThe solution uses thread-local storage to solve a subtle problem with detecting potential\nimport threading\nx_lock = threading.Lock()\ny_lock = threading.Lock()\ndef thread_1():\nprint('Thread-1')\ndef thread_2():\nprint('Thread-2')\nIf you run this version of the program, one of the threads will crash with an exception\nself.run()\nFile \"/usr/local/lib/python3.3/threading.py\", line 596, in run\nFile \"deadlock.py\", line 49, in thread_1\nThis crash is caused by the fact that each thread remembers the locks it has already\nThe issue of deadlock is a well-known problem with programs involving threads (as\nlong as you can ensure that threads can hold only one lock at a time, your program will",
      "keywords": [
        "thread",
        "server",
        "data",
        "threading import Thread",
        "self.",
        "lock",
        "socket",
        "SSL",
        "client",
        "import Thread",
        "event",
        "Queue",
        "Return True",
        "data def"
      ],
      "concepts": [
        "threads",
        "lock",
        "client",
        "servers",
        "important",
        "classes",
        "data",
        "socket",
        "programming",
        "programs"
      ],
      "similar_chapters": [
        {
          "book": "Python Cookbook 3rd",
          "chapter": 7,
          "title": "",
          "score": 0.496,
          "base_score": 0.346,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Python Cookbook 3rd",
          "chapter": 8,
          "title": "",
          "score": 0.48,
          "base_score": 0.33,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Python Cookbook 3rd",
          "chapter": 9,
          "title": "",
          "score": 0.438,
          "base_score": 0.288,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Python Cookbook 3rd",
          "chapter": 12,
          "title": "",
          "score": 0.411,
          "base_score": 0.261,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Python Cookbook 3rd",
          "chapter": 15,
          "title": "",
          "score": 0.322,
          "base_score": 0.322,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "thread",
          "threads",
          "threading",
          "def",
          "server"
        ],
        "semantic": [],
        "merged": [
          "thread",
          "threads",
          "threading",
          "def",
          "server"
        ]
      },
      "topic_id": 1,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.29677760015413207,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:08:10.208774+00:00"
      }
    },
    {
      "chapter_number": 12,
      "title": "Concurrency",
      "start_page": 521,
      "end_page": 560,
      "summary": "As threads run, they periodically reset the timer, and as\nAs a final example, a classic thread deadlock problem is the so-called “dining philoso‐\nthread and each chopstick represents a lock.\nimport threading\n# The philosopher thread\nprint(threading.currentThread(), 'eating')\nchopsticks = [threading.Lock() for n in range(NSTICKS)]\nYou need to store state that’s specific to the currently executing thread and not visible\nto other threads.\nthe currently executing thread.\nTo do this, create a thread-local storage object using\nthreading.local().\nexecuting thread and no others.\nAs an interesting practical example of using thread-local storage, consider the LazyCon\nmodified version that safely works with multiple threads:\nimport threading\ndef __init__(self, address, family=AF_INET, type=SOCK_STREAM):\nself.type = SOCK_STREAM\nself.local = threading.local()\ndef __enter__(self):\nif hasattr(self.local, 'sock'):\nself.local.sock = socket(self.family, self.type)\nself.local.sock.connect(self.address)\nreturn self.local.sock\ndef __exit__(self, exc_ty, exc_val, tb):\nself.local.sock.close()\ndel self.local.sock\nIn this code, carefully observe the use of the self.local attribute.\ninstance of threading.local().\nstored as self.local.sock.\ns.send(b'Host: www.python.org\\r\\n')\nThe reason it works is that each thread actually creates its own dedicated socket con‐\nnection (stored as self.local.sock).\nThus, when the different threads perform socket\nCreating and manipulating thread-specific state is not a problem that often arises in\neveryone because chaos would ensue if multiple threads ever started reading and writing\nIn this recipe, the use of threading.local() makes the LazyConnection class support\none connection per thread, as opposed to one connection for the entire process.\ndictionary for each thread.\nThe fact that each thread uses\nCreating a Thread Pool\nYou want to create a pool of worker threads for serving clients or performing other kinds\nCreating a Thread Pool \nHere is an example of a simple TCP server that uses a thread-pool to serve\nIf you want to manually create your own thread pool, it’s usually easy enough to do it\nfrom threading import Thread\nt = Thread(target=echo_client, args=(q,))\nto get data back from the worker thread.\nfrom threading import Thread\nCreating a Thread Pool \nt = Thread(target=echo_client, args=(client_sock, client_addr))\nattack on the server that makes it create so many threads that your program runs out\nusing a pre-initialized thread pool, you can carefully put an upper limit on the amount\nYou might be concerned with the effect of creating a large number of threads.\nmodern systems should have no trouble creating pools of a few thousand threads.\nMoreover, having a thousand threads just sitting around waiting for work isn’t going to\nhave much, if any, impact on the performance of other code (a sleeping thread does just\nGenerally, you only want to use thread pools for I/O-bound\nOne possible concern with creating large thread pools might be memory use.\nample, if you create 2,000 threads on OS X, the system shows the Python process using\nWhen creating a thread, the operating system reserves a region of virtual memory to\nmight find the Python process is using far less real memory (e.g., for 2,000 threads, only\nyou can dial it down using the threading.stack_size() function.\nimport threading\nIf you add this call and repeat the experiment of creating 2,000 threads, you’ll find that\nYou have a program that performs a lot of CPU-intensive work, and you want to make\nWork to be submitted to a pool must be defined in a function.\nresults = map(work, data)\nresults = pool.map(work, data)\nAlternatively, you can manually submit single tasks using the pool.submit() method:\n# Example of submitting work to the pool\nfuture_result = pool.submit(work, arg)\nfuture_result = pool.submit(work, arg)\nAlthough process pools can be easy to use, there are a number of important consider‐\n• Process pools are created by calling the fork() system call on Unix.\n• Great care should be made when combining process pools and programs that use\nthreads.\nto the creation of any threads (e.g., create the pool in the main thread at program\nAlthough Python fully supports thread programming, parts of the C implementation\nof the interpreter are not entirely thread safe to a level of allowing fully concurrent\n(GIL) that only allows one Python thread to execute at any given time.\nusing more than one thread only runs on a single CPU).\nIf your program is mostly doing I/O, such as network communication, threads\nIn fact, you can create thousands of Python threads with barely a con‐\nModern operating systems have no trouble running with that many threads, so\nA CPU-bound program might be using threads to manage a graphical user interface, a\nFirst, if you are working entirely in Python, you can use the multi\nprocessing module to create a process pool and use it like a co-processor.\nsuppose you have the following thread code:\ndef some_work(args):\n# A thread that calls the above function\ndef some_thread():\nHere’s how you would modify the code to use a pool:\ndef some_work(args):\n# A thread that calls the above function\ndef some_thread():\nr = pool.apply(some_work, (args))\nThis example with a pool works around the GIL using a neat trick.\nWhenever a thread\nhands the work to a separate Python interpreter running in a different process.\nthe thread is waiting for the result, it releases the GIL.\nPython, and have the C code release the GIL while it’s working.\n// Threaded C code\nIf you are going to use a process pool as a workaround, be aware that doing so involves\nwork, the operation to be performed needs to be contained within a Python function\nAnother subtle aspect of pools is that mixing threads and process pools together can be\ntogether, it is often best to create the process pool as a singleton at program startup,\nThreads will then use the same process pool for all\nto make sure the C code operates independently of Python.\nDefining an Actor Task\nan actor is a concurrently executing task that simply acts upon messages sent to it.\nActors are straightforward to define using a combination of a thread and a queue.\nfrom threading import Thread, Event\ndef __init__(self):\nself._mailbox = Queue()\ndef send(self, msg):\nSend a message to the actor\nself._mailbox.put(msg)\ndef recv(self):\nmsg = self._mailbox.get()\ndef close(self):\nself.send(ActorExit)\ndef start(self):\nself._terminated = Event()\nt = Thread(target=self._bootstrap)\nDefining an Actor Task \ndef _bootstrap(self):\nself.run()\nself._terminated.set()\ndef join(self):\nself._terminated.wait()\ndef run(self):\nmsg = self.recv()\ndef run(self):\nmsg = self.recv()\nIn this example, Actor instances are things that you simply send a message to using\nit off to an internal thread that runs to process the received messages.\ndefining the run() method to implement their custom processing.\ndef print_actor():\ndef run(self):\ndef do_A(self, x):\ndef do_B(self, x, y):\nfrom threading import Event\ndef __init__(self):\nself._result = None\ndef set_result(self, value):\nself._result = value\nDefining an Actor Task \nself._evt.set()\ndef result(self):\nself._evt.wait()\nreturn self._result\ndef submit(self, func, *args, **kwargs):\nself.send((func, args, kwargs, r))\ndef run(self):\nfunc, args, kwargs, r = self.recv()\nFor example, the send() method of an actor-like object could be programmed to trans‐\nYou have a program based on communicating threads and want them to implement\nof directly sending a message from one task to another, a message is sent to the exchange\ndef __init__(self):\nself._subscribers = set()\ndef attach(self, task):\nself._subscribers.add(task)\ndef detach(self, task):\nself._subscribers.remove(task)\ndef send(self, msg):\nfor subscriber in self._subscribers:\nHere is a simple example that shows how to use an exchange:\n# Example of a task.\nclass Task:\ndef send(self, msg):\n# Examples of subscribing tasks to it\n# Example of sending messages\nThe concept of tasks or threads sending messages to one another (often via queues) is\ncommunicating threads.\nto decouple various tasks in the program.\ndef __init__(self):\nself.count = 0\ndef send(self, msg):\nself.count += 1\nprint('msg[{}]: {!r}'.format(self.count, msg))\ndef __init__(self):\nself._subscribers = set()\ndef attach(self, task):\nself._subscribers.add(task)\ndef detach(self, task):\nself._subscribers.remove(task)\ndef subscribe(self, *tasks):\nself.attach(task)\nself.detach(task)\ndef send(self, msg):\nfor subscriber in self._subscribers:\nFor example, exchanges could implement an entire collection of message channels\ninto distributed computing applications (e.g., routing messages to tasks on different\nUsing Generators As an Alternative to Threads\nsystem threads.\nthe following code that implements a simple task scheduler:\ndef __init__(self):\nself._task_queue = deque()\ndef new_task(self, task):\nself._task_queue.append(task)\ndef run(self):\nRun until there are no more tasks\nwhile self._task_queue:\ntask = self._task_queue.popleft()\nnext(task)\nself._task_queue.append(task)\nIn this code, the TaskScheduler class runs a collection of generators in a round-robin\nGenerator functions are the tasks and the yield statement is how tasks signal\nInstead, you might use generators to replace the use of threads\nUsing Generators As an Alternative to Threads \nThe following code illustrates the use of generators to implement a thread-free version\ndef __init__(self):\nself._actors = { }          # Mapping of names to actors\nself._msg_queue = deque()   # Message queue\ndef new_actor(self, name, actor):\nself._msg_queue.append((actor,None))\nself._actors[name] = actor\ndef send(self, name, msg):\nactor = self._actors.get(name)\nself._msg_queue.append((actor,msg))\ndef run(self):\nwhile self._msg_queue:\nactor, msg = self._msg_queue.popleft()\nHere is an advanced example showing the use of generators to implement a concurrent\ndef handle_yield(self, sched, task):\ndef handle_resume(self, sched, task):\ndef __init__(self):\nself._numtasks = 0       # Total num of tasks\nself._ready = deque()    # Tasks ready to run\nself._read_waiting = {}  # Tasks waiting to read\nself._write_waiting = {} # Tasks waiting to write\ndef _iopoll(self):\nself._write_waiting,[])\nevt, task = self._read_waiting.pop(r)\nevt.handle_resume(self, task)\nevt, task = self._write_waiting.pop(w)\nevt.handle_resume(self, task)\ndef new(self,task):\nUsing Generators As an Alternative to Threads \nself._ready.append((task, None))\nself._numtasks += 1\ndef add_ready(self, task, msg=None):\nAppend an already started task to the ready queue.\nmsg is what to send into the task when it resumes.\nself._ready.append((task, msg))\ndef _read_wait(self, fileno, evt, task):\nself._read_waiting[fileno] = (evt, task)\ndef _write_wait(self, fileno, evt, task):\nself._write_waiting[fileno] = (evt, task)\ndef run(self):\nwhile self._numtasks:\nif not self._ready:\nself._iopoll()\ntask, msg = self._ready.popleft()\nr = task.send(msg)\nr.handle_yield(self, task)\nself._numtasks -= 1\ndef __init__(self, sock, nbytes):\nself.sock = sock\ndef handle_yield(self, sched, task):\nsched._read_wait(self.sock.fileno(), self, task)\ndef handle_resume(self, sched, task):\ndata = self.sock.recv(self.nbytes)\nsched.add_ready(task, data)\ndef __init__(self, sock, data):\nself.sock = sock\nself.data = data\ndef handle_yield(self, sched, task):\nsched._write_wait(self.sock.fileno(), self, task)\ndef handle_resume(self, sched, task):\nnsent = self.sock.send(self.data)\ndef __init__(self, sock):\nself.sock = sock\ndef handle_yield(self, sched, task):\nsched._read_wait(self.sock.fileno(), self, task)\ndef handle_resume(self, sched, task):\nr = self.sock.accept()\nsched.add_ready(task, r)\n# Wrapper around a socket object for use with yield\ndef __init__(self, sock):\nself._sock = sock\ndef recv(self, maxbytes):\nreturn ReadSocket(self._sock, maxbytes)\ndef send(self, data):\nreturn WriteSocket(self._sock, data)\ndef accept(self):\nreturn AcceptSocket(self._sock)\ndef __getattr__(self, name):\nreturn getattr(self._sock, name)\ndef __init__(self,addr,sched):\nself.sched = sched\nsched.new(self.server_loop(addr))\ndef server_loop(self,addr):\nUsing Generators As an Alternative to Threads \nself.sched.new(self.client_handler(Socket(c)))\ndef client_handler(self,client):\nThere is a queue of tasks ready to\nrun and there are waiting areas for tasks sleeping for I/O.\nmoving tasks between the ready queue and the I/O waiting area.\ndata = f.send(result)\nIf a generator function has just started, sending in a value\nA task scheduler might use this to com‐\nthis, your only real option is to delegate the operation to a separate thread or process\nnot been written to work well with generator-based threading.\nPolling Multiple Thread Queues\nYou have a collection of thread queues, and you would like to be able to poll them for\nPolling Multiple Thread Queues \ndef __init__(self):\nself._putsocket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\nself._putsocket.connect(server.getsockname())\ndef fileno(self):\nreturn self._getsocket.fileno()\ndef put(self, item):\nself._putsocket.send(b'x')\ndef get(self):\nimport threading\nThe problem of polling non-file-like objects, such as queues, is often a lot trickier than\nto write code that cycles through the queues and uses a timer, like this:\nPolling Multiple Thread Queues \nand queues at the same time, you might have to use code like this:\nYou would like to write a program that runs as a proper daemon process on Unix or\nThe following code shows how to define a daemon process along\nprint(os.getpid(),file=f)\nsys.stdout.write('Daemon started with pid {}\\n'.format(os.getpid()))\nprint('Usage: {} [start|stop]'.format(sys.argv[0]), file=sys.stderr)\nprint(e, file=sys.stderr)\nprint('Not running', file=sys.stderr)\nprint('Unknown command {!r}'.format(sys.argv[1]), file=sys.stderr)\nTo launch the daemon, the user would use a command like this:\nDaemon processes run entirely in the background, so the command returns immedi‐\nThis recipe defines a function daemonize() that should be called at program startup to\nmake the program run as a daemon.\nmakes the daemon process give up the ability to acquire a new controlling terminal and\na file for later use by other programs.\nYou want your program to terminate by printing a message to standard error and re‐\nThis will cause the supplied message to be printed to sys.stderr and the program to\nNamely, to terminate a program, you might be inclined to write code like this:\nbash % python3 search.py -v -p spam --pat=eggs foo.txt bar.txt -o results\nbash % python3 search.py -v -p spam --pat=eggs foo.txt bar.txt -o results \\",
      "keywords": [
        "Task",
        "thread",
        "self.",
        "Python",
        "SOCK",
        "Multiple Thread Queues",
        "work",
        "GIL",
        "client",
        "Pool",
        "Actor",
        "msg",
        "result",
        "yield"
      ],
      "concepts": [
        "threads",
        "tasks",
        "important",
        "function",
        "functions",
        "prints",
        "file",
        "data",
        "program",
        "programming"
      ],
      "similar_chapters": [
        {
          "book": "Python Cookbook 3rd",
          "chapter": 8,
          "title": "",
          "score": 0.52,
          "base_score": 0.37,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Python Cookbook 3rd",
          "chapter": 9,
          "title": "",
          "score": 0.514,
          "base_score": 0.364,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Python Cookbook 3rd",
          "chapter": 11,
          "title": "",
          "score": 0.411,
          "base_score": 0.261,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Python Cookbook 3rd",
          "chapter": 7,
          "title": "",
          "score": 0.387,
          "base_score": 0.237,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Python Cookbook 3rd",
          "chapter": 15,
          "title": "",
          "score": 0.332,
          "base_score": 0.332,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "task",
          "thread",
          "def",
          "threads",
          "pool"
        ],
        "semantic": [],
        "merged": [
          "task",
          "thread",
          "def",
          "threads",
          "pool"
        ]
      },
      "topic_id": 1,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.28515580735334023,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:08:10.208789+00:00"
      }
    },
    {
      "chapter_number": 13,
      "title": "Utility Scripting and System Administration",
      "start_page": 561,
      "end_page": 600,
      "summary": "the options you want to support it using the add_argument() method.\nbeing used to make a list of filenames in the example:\nhelp='output file')\nFinally, the following argument specification takes a value, but checks it against a set of\nFor example,\nmay also encounter code that uses the optparse library to parse options.\nUse the os.get_terminal_size() function to do this:\nYou want to execute an external command and collect its output as a Python string.\nUse the subprocess.check_output() function.\nFor example:\nFor example:\nIf the executed command returns a nonzero exit code, an exception is raised.\nan example of catching errors and getting the output created along with the exit code:\nboth standard output and error collected, use the stderr argument:\nIf you need to execute a command with a timeout, use the timeout argument:\nuseful if you’re trying to get Python to execute a complicated shell command involving\nFor example:\nThe check_output() function is the easiest way to execute an external command and\nFor example:\nthis is a test\nYou need to copy or move files and directories around, but you don’t want to do it by\nThe shutil module has portable implementations of functions for copying files and\nFor example:\n# Copy files, but preserve metadata (cp -p src dst)\nThe arguments to these functions are all strings supplying file or directory names.\ndef ignore_pyc_files(dirname, filenames):\nshutil.copytree(src, dst, ignore=ignore_pyc_files)\nFor example:\nUsing shutil to copy files and directories is mostly straightforward.\ncaution concerning file metadata is that functions such as copy2() only make a best\nwant to use a function like shutil.copytree() to perform system backups.\nWhen working with filenames, make sure you use the functions in os.path for the\nFor example:\nexample, in the process of copying, the function might encounter broken symbolic links,\n# msg is error message from exception\nFor example:\nThe second argument to make_archive() is the desired output format.\nFor example:\nPython has other library modules for dealing with the low-level details of various archive\nThe functions have a variety of additional options for logging, dryruns, file permissions,\nYou need to write a script that involves finding files, like a file renaming script or a log\nTo search for files, use the os.walk() function, supplying it with the top-level directory.\nHere is an example of a function that finds a specific filename and prints out the full\nif name in files:\nTo illustrate, here is a function that prints out all of the files that have a recent modifi‐\nfor path, dirs, files in os.walk(top):\nfor name in files:\nfunction using various features of the os, os.path, glob, and similar modules.\nReading Configuration Files\nYou want to read configuration files written in the common .ini configuration file\nThe configparser module can be used to read configuration files.\nyou have this configuration file:\nlog_errors=true\n>>> cfg.getboolean('debug','log_errors')\nFor example:\n>>> cfg.set('debug','log_errors','False')\nlog_errors = False\nWithin each config file, values are grouped into different\nThere are several notable differences between a config file and using a Python source\nReading Configuration Files \nFor example:\nlog_errors = true\nlog_errors = TRUE\nlog_errors = 1\nPerhaps the most significant difference between a config file and Python code is that,\nunlike scripts, configuration files are not executed in a top-down manner.\nFor example, in this part of the config file, it doesn’t matter that the prefix variable is\na user made their own configuration file that looked like this:\nprefix=/Users/beazley/test\nlog_errors=False\nexample:\n'/Users/beazley/test'\n'/Users/beazley/test/lib'\n>>> cfg.getboolean('debug', 'log_errors')\n'/Users/beazley/test/lib'\nmight find in an .ini file used by other programs (e.g., applications on Windows).\nYou want scripts and simple programs to write diagnostic information to log files.\nThe easiest way to add logging to simple programs is to use the logging module.\nexample:\nimport logging\n# Configure the logging system\nlevel=logging.ERROR\n# Example logging calls (insert into your program)\nlogging.error(\"Couldn't find %r\", item)\nlogging.info('Opening file %r, mode=%r', filename, mode)\nThe five logging calls (critical(), error(), warning(), info(), debug()) represent\nThe argument to each logging operation is a message string followed by zero or more\nWhen making the final log message, the % operator is used to format the\nIf you run this program, the contents of the file app.log will be as follows:\nFor example:\nAs shown, the logging configuration is hardcoded directly into the program.\nto configure it from a configuration file, change the basicConfig() call to the following:\nimport logging\nimport logging.config\n# Configure the logging system\nNow make a configuration file logconfig.ini that looks like this:\nfor the logging module, this solution is quite sufficient for simple programs and scripts.\ncalls, and your program will generate logging output.\nIf you want the logging messages to route to standard error instead of a file, don’t supply\nIf you later need to change the configuration of the logging module, you need to obtain\nFor example:\nIt must be emphasized that this recipe only shows a basic use of the logging module.\nYou would like to add a logging capability to a library, but don’t want it to interfere with\nprograms that don’t use logging.\nFor libraries that want to perform logging, you should create a dedicated logger object,\nimport logging\n# Example function (for testing)\nFor example:\nHowever, if the logging system gets configured, log messages will start to appear.\nexample:\n>>> import logging\nlibrary code that tries to configure the logging system on its own or which makes as‐\nThus, if the library is used and logging is never configured, no messages or warnings\n>>> import logging\n>>> logging.basicConfig(level=logging.ERROR)\nHere, the root logger has been configured to only output messages at the ERROR level or\nThe ability to change the logging settings for a single module like this can be a useful\nchange the level for the one module where you want more output.\nThe “Logging HOWTO” has more information about configuring the logging module\nThe time module contains various functions for performing timing-related functions.\nFor example:\nHere is an example that\nThis recipe provides a simple yet very useful class for making timing measurements and\ncontrast, the time.perf_counter() function always uses the highest-resolution timer\nFor example:\nYou want to place some limits on the memory or CPU use of a program running on\nFor example:\nWith a memory limit in place, programs will start generating MemoryError exceptions\nFor example, when tested, it works on Linux but not on OS X.\nFor example:\nover how the page gets opened, you can use one of the following functions:\nIf you want to open a page in a specific browser, you can use the webbrowser.get()\nFor example:\nTesting, Debugging, and Exceptions\nyour code before Python executes it makes testing a critical part of development.\ngoal of this chapter is to discuss some common problems related to testing, debugging,\nand exception handling.\nTesting Output Sent to stdout\nwrite a test for your code to prove that, given the proper input, the proper output is\nUsing the unittest.mock module’s patch() function, it’s pretty simple to mock out\nConsider, as an example, the following function in a module mymodule:\nThe built-in print function, by default, sends output to sys.stdout.\nUsing the unittest.mock module’s patch()\nmethod makes it convenient to replace objects only within the context of a running test,\ntest code for mymodule:\nfrom unittest.mock import patch\ndef test_url_gets_to_stdout(self):\nThe urlprint() function takes three arguments, and the test starts by setting up dummy\nTo run the test, the unittest.mock.patch() function is used as a context manager to\nChapter 14: Testing, Debugging, and Exceptions\nPatching Objects in Unit Tests\nYou’re writing unit tests and need to apply patches to selected objects in order to make\nassertions about how they were used in the test (e.g., assertions about being called with\nThe unittest.mock.patch() function can be used to help with this problem.\nfrom unittest.mock import patch\nimport example\ndef test1(x, mock_func):\nexample.func(x)       # Uses patched example.func\nexample.func(x)      # Uses patched example.func\nFor example:\ndef test1(mock1, mock2, mock3):\ndef test2():\nPatching Objects in Unit Tests \nFor example:\nFor example:\nFile \"<stdin>\", line 1, in <module>\nFile \".../unittest/mock.py\", line 726, in assert_called_with\nChapter 14: Testing, Debugging, and Exceptions\nNormally, this function uses urlopen() to go fetch data off the Web and parse it.\nfrom unittest.mock import patch\nimport example\nclass Tests(unittest.TestCase):\n@patch('example.urlopen', return_value=sample_data)\ndef test_dowprices(self, mock_urlopen):\nPatching Objects in Unit Tests \nIn this example, the urlopen() function in the example module is replaced with a mock\nAn important but subtle facet of this test is the patching of example.urlopen instead of\nWhen you are making patches, you have to use the names\nas they are used in the code being tested.\nSince the example code uses from urllib.re\nTesting for Exceptional Conditions in Unit Tests\nYou want to write a unit test that cleanly tests if an exception is raised.\nTo test for exceptions, use the assertRaises() method.\nFor example, if you want to test\nthat a function raised a ValueError exception, use this code:\ndef test_bad_int(self):\nIf you need to test the exception’s value in some way, then a different approach is needed.\nFor example:\ndef test_file_not_found(self):\nChapter 14: Testing, Debugging, and Exceptions\nexception.\ndef test_bad_int(self):\nas that when no exception is raised at all.\ndef test_bad_int(self):\nvalue of the exception object that’s created.\nsertRaisesRegex() method, which allows you to test for an exception and perform a\nFor example:\ndef test_bad_int(self):\ndef test_bad_int(self):\nTesting for Exceptional Conditions in Unit Tests \nThis form can be useful if your test involves multiple steps (e.g., setup) besides that of\nLogging Test Output to a File\nYou want the results of running unit tests written to a file instead of printed to standard\nlike this at the bottom of your testing file:\nThis makes the test file executable, and prints the results of running tests to standard\nThe interesting thing about this recipe is not so much the task of getting test results\nAt a basic level, the unittest module works by first assembling a test suite.\nThis test\nsuite consists of the different testing methods you defined.\nChapter 14: Testing, Debugging, and Exceptions\nModule() is one of several methods it defines to gather tests.\nmodule for TestCase classes and extracts test methods from them.\nused to pull test methods from an individual class that inherits from TestCase.\nThe TextTestRunner class is an example of a test runner class.\nthis class is to execute the tests contained in a test suite.\nThis class is the same test runner\nlow-level configuration, including an output file and an elevated verbosity level.\ntomize how tests execute, you could make custom test runner classes that emulate the\nThe unittest module has decorators that can be applied to selected test methods to\nFor example:\nclass Tests(unittest.TestCase):\ndef test_0(self):\n@unittest.skip('skipped test')\ndef test_1(self):\ndef test_2(self):\ndef test_3(self):\ndef test_4(self):\nThe skip() decorator can be used to skip over a test that you don’t want to run at all.\nskipIf() and skipUnless() can be a useful way to write tests that only apply to certain\nThe decorators for skipping methods can also be applied to entire testing classes.\nHandling Multiple Exceptions\nYou have a piece of code that can throw any of several different exceptions, and you\nneed to account for all of the potential exceptions that could be raised without creating\nChapter 14: Testing, Debugging, and Exceptions\nIf you can handle different exceptions all using a single block of code, they can be\nlisted exceptions occurs.\nIf, on the other hand, you need to handle one of the exceptions\nFor such exceptions, you\nlogger.error('File not found')\nHandling Multiple Exceptions \nIn this example, the e variable holds an instance of the raised OSError.\nyou need to inspect the exception further, such as processing it based on the value of an\nFile \"<stdin>\", line 1, in <module>\nprint('File not found')\n(<class 'FileNotFoundError'>, <class 'OSError'>, <class 'Exception'>,\nCatching All Exceptions\nYou want to write code that catches all exceptions.\nTo catch all exceptions, write an exception handler for Exception, as shown here:\nChapter 14: Testing, Debugging, and Exceptions\nexcept Exception as e:\nlog('Reason:', e)       # Important!\nIf you also want to catch those exceptions, change Exception to BaseException.\nBecause of this, if you choose to catch all exceptions, it is absolutely critical to log or\nreport the actual reason for the exception somewhere (e.g., log file, error message print‐\nexcept Exception:\nexcept Exception as e:\nCatching All Exceptions \nHowever, if you must catch all exceptions, just make sure you give good di‐\nCreating Custom Exceptions\nYou’re building an application and would like to wrap lower-level exceptions with cus‐\nCreating new exceptions is easy—just define them as classes that inherit from Excep\nexceptions like this:\nclass NetworkError(Exception):\nUsers could then use these exceptions in the normal way.\nCustom exception classes should almost always inherit from the built-in Exception\nclass, or inherit from some locally defined base exception that itself inherits from Ex\nAlthough all exceptions also derive from BaseException, you should not use\nthis as a base class for new exceptions.\nTherefore, catching these exceptions is not the\nChapter 14: Testing, Debugging, and Exceptions\nHaving custom exceptions in your application and using them as shown makes your\ndifferent classes of exceptions together.\nException, make sure you always call Exception.__init__() with all of the passed\nclass CustomError(Exception):\nlibraries and parts of Python expect all exceptions to have the .args attribute, so if you\nbuilt-in RuntimeError exception, and notice how any number of arguments can be used\nCreating Custom Exceptions \nFor more information on creating your own exceptions, see the Python documentation.\nRaising an Exception in Response to Another\nException\nYou want to raise an exception in response to catching a different exception, but want\nTo chain exceptions, use the raise from statement instead of a simple raise statement.\n>>> def example():\nraise RuntimeError('A parsing error occurred') from e...\nFile \"<stdin>\", line 3, in example\nFile \"<stdin>\", line 1, in <module>\nFile \"<stdin>\", line 5, in example\nattribute of the exception object to follow the exception chain should you wish.\nChapter 14: Testing, Debugging, and Exceptions\n>>> def example2():\nFile \"<stdin>\", line 3, in example2\nFile \"<stdin>\", line 1, in <module>\nFile \"<stdin>\", line 5, in example2\nIn this example, you get information about both exceptions, but the interpretation is a\nIn this case, the NameError exception is raised as the result of a program‐\nattribute of an exception is not set.\nexception.\nIf, for some reason, you want to suppress chaining, use raise from None:\n>>> def example3():\nFile \"<stdin>\", line 1, in <module>\nFile \"<stdin>\", line 5, in example3\nRaising an Exception in Response to Another Exception \nIn designing code, you should give careful attention to use of the raise statement inside\nIf you write your code in the following style, you still get a chained exception, but it’s\nWhen you use raise from, you’re making it clear that you meant to raise the second\nexception.\nResist the urge to suppress exception information, as shown in the last example.\nYou caught an exception in an except block, but now you want to reraise it.\nSimply use the raise statement all by itself.\n>>> def example():\nChapter 14: Testing, Debugging, and Exceptions",
      "keywords": [
        "exception",
        "exceptions",
        "file",
        "def test",
        "logging",
        "output",
        "System Administration",
        "Utility Scripting",
        "function",
        "module",
        "Unit Tests",
        "system"
      ],
      "concepts": [
        "tested",
        "exception",
        "exceptions",
        "exceptional",
        "file",
        "logging",
        "log",
        "classes",
        "examples",
        "important"
      ],
      "similar_chapters": [
        {
          "book": "Python Cookbook 3rd",
          "chapter": 14,
          "title": "",
          "score": 0.736,
          "base_score": 0.586,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Python Cookbook 3rd",
          "chapter": 15,
          "title": "",
          "score": 0.422,
          "base_score": 0.422,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Python Cookbook 3rd",
          "chapter": 1,
          "title": "",
          "score": 0.337,
          "base_score": 0.337,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Python Cookbook 3rd",
          "chapter": 4,
          "title": "",
          "score": 0.325,
          "base_score": 0.325,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Python Cookbook 3rd",
          "chapter": 5,
          "title": "",
          "score": 0.3,
          "base_score": 0.3,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "exceptions",
          "exception",
          "logging",
          "file",
          "tests"
        ],
        "semantic": [],
        "merged": [
          "exceptions",
          "exception",
          "logging",
          "file",
          "tests"
        ]
      },
      "topic_id": 2,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.32950184787285103,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:08:10.208807+00:00"
      }
    },
    {
      "chapter_number": 14,
      "title": "Testing, Debugging, and Exceptions",
      "start_page": 601,
      "end_page": 640,
      "summary": "To have your program issue a warning message, use the warnings.warn() function.\ndef func(x, y, logfile=None, debug=False):\nbash % python3 -W all example.py\nbash % python3 -W error example.py\nFile \"example.py\", line 10, in <module>\nFile \"example.py\", line 5, in func\nyou can can use the warnings.simplefilter() function to control output, as just\nIf your program is crashing with an exception, running your program as python3 -i\nsomeprogram.py can be a useful tool for simply looking around.\n# sample.py\nbash % python3 -i sample.py\nFile \"sample.py\", line 6, in <module>\nFile \"sample.py\", line 4, in func\n> sample.py(4)func()\nsample.py(6)<module>()\n> sample.py(4)func()\nA common use of the debugger is to inspect variables inside a function that has crashed.\nIf you simply want to time your whole program, it’s usually easy enough to use something\nbash % time python3 someprogram.py\nbash % python3 -m cProfile someprogram.py\n1    0.036    0.036   16.077   16.077 someprogram.py:4(<module>)\n1    0.227    0.227    0.438    0.438 png.py:163(<module>)\nFor example, you may already know that your code spends most of its time in a few\nTo use this decorator, you simply place it in front of a function definition to get timings\nFor studying the performance of small code fragments, the timeit module can be useful.\nextreme solutions, such as C extensions or a just-in-time (JIT) compiler.\nUse functions\ncode defined in a function.\nmake the program run faster, simply put the scripting statements in a function:\nimport as well as making selected use of bound methods.\nInstead of using math.sqrt(), the code uses\ndef __init__(self, x, y):\nreturn self._y\ngrams in another programming language to use getter/setter functions, that doesn’t\nBuilt-in data types such as strings, tuples, lists, sets, and dicts are all implemented in C,\nFor example, someone might write code like this:\nIt can sometimes make Python programs run an\nNumba is a dynamic compiler where you annotate selected Python functions\nC Extensions\nThis chapter looks at the problem of accessing C code from Python.\nbuilt-in libraries are written in C, and accessing C is an important part of making Python\nwith the problem of porting extension code from Python 2 to 3.\nAlthough Python provides an extensive C programming API, there are actually many\nof C code along with some representative examples of how to work with the code.\nHere is the C code we will work with in most of the recipes:\n/* sample.c */_method\nint in_mandel(double x0, double y0, int n) {\n/* A C data structure */\ndouble x,y;\n/* Function involving a C data structure */\nThis code contains a number of different C programming features.\nThe divide() function is an example\nof a C function returning multiple values, one through a pointer argument.\nfunction performs a data reduction across a C array.\nThe Point and distance() function\nsample.c, that definitions are found in a file named sample.h and that it has been com‐\npiled into a library libsample that can be linked to other C code.\nIt is assumed that if you’re working with C code, you’ve already figured that out.\nChapter 15: C Extensions\nAccessing C Code Using ctypes\nYou have a small number of C functions that have been compiled into a shared library\nYou would like to call these functions purely from Python without having to\nwrite additional C code or using a third-party extension tool.\nFor small problems involving C code, it is often easy enough to use the ctypes module\nsure the C code you want to access has been compiled into a shared library that is\ndirectory as the sample.py file shown next.\nTo access the resulting library, you make a Python module that wraps around it, such\n# sample.py\ngcd.argtypes = (ctypes.c_int, ctypes.c_int)\ngcd.restype = ctypes.c_int\nin_mandel.argtypes = (ctypes.c_double, ctypes.c_double, ctypes.c_int)\nin_mandel.restype = ctypes.c_int\n_divide.argtypes = (ctypes.c_int, ctypes.c_int, ctypes.POINTER(ctypes.c_int))\n_divide.restype = ctypes.c_int\nrem = ctypes.c_int()\nAccessing C Code Using ctypes \nreturn ctypes.cast(ptr, ctypes.POINTER(ctypes.c_double))\nval = ((ctypes.c_double)*len(param))(*param)\nreturn param.ctypes.data_as(ctypes.POINTER(ctypes.c_double))\n_avg.argtypes = (DoubleArray, ctypes.c_int)\n_avg.restype = ctypes.c_double\n_fields_ = [('x', ctypes.c_double),\n('y', ctypes.c_double)]\ndistance.restype = ctypes.c_double\nIf all goes well, you should be able to load the module and use the resulting C functions.\nChapter 15: C Extensions\n>>> p1 = sample.Point(1,2)\n>>> p2 = sample.Point(4,5)\nconcerns the overall packaging of C and Python code together.\nto access C code that you have compiled yourself, you will need to make sure that the\nshared library gets placed in a location where the sample.py module can find it.\npossibility is to put the resulting .so file in the same directory as the supporting Python\nbe able to use the ctypes.util.find_library() function.\nAgain, ctypes won’t work at all if it can’t locate the library with the C code.\nOnce you know where the C library is located, you use ctypes.cdll.LoadLibrary()\nAccessing C Code Using ctypes \nin_mandel.argtypes = (ctypes.c_double, ctypes.c_double, ctypes.c_int)\nin_mandel.restype = ctypes.c_int\nfunction, and .restype is the return type.\nc_double, c_int, c_short, c_float, etc.) that represent common C data types.\ning the type signatures is critical if you want to make Python pass the right kinds of\nA somewhat tricky part of using ctypes is that the original C code may use idioms that\nThe divide() function is a good example because it returns\n>>> divide.argtypes = (ctypes.c_int, ctypes.c_int, ctypes.POINTER(ctypes.c_int))\nctypes.ArgumentError: argument 3: <class 'TypeError'>: expected LP_c_int\n>>> x = ctypes.c_int()\nHere an instance of a ctypes.c_int is created and passed in as the pointer object.\na normal Python integer, a c_int object can be mutated.\nChapter 15: C Extensions\nFor cases where the C calling convention is “un-Pythonic,” it is common to write a small\nIn the solution, this code makes the divide() function return the\n_divide.argtypes = (ctypes.c_int, ctypes.c_int, ctypes.POINTER(ctypes.c_int))\n_divide.restype = ctypes.c_int\nrem = ctypes.c_int()\nThe underlying C code expects\nand narrow it down to a compatible ctypes object (a pointer to a ctypes.c_double, in\n>>> a = (ctypes.c_double * len(nums))(*nums)\n<__main__.c_double_Array_3 object at 0x10069cd40>\nAccessing C Code Using ctypes \n>>> ctypes.cast(ptr, ctypes.POINTER(ctypes.c_double))\n<__main__.LP_c_double object at 0x10069cd40>\nshown, the function can accept a variety of different array-like inputs:\nThe last part of this recipe shows how to work with a simple C structure.\n_fields_ = [('x', ctypes.c_double),\n('y', ctypes.c_double)]\nOnce defined, you can use the class in type signatures as well as in code that needs to\n>>> p1 = sample.Point(1,2)\n>>> p2 = sample.Point(4,5)\naccessing a few C functions from Python.\nChapter 15: C Extensions\nsame functionality, but uses C syntax and supports more advanced kinds of C code.\nWriting a Simple C Extension Module\nYou want to write a simple C extension module directly using Python’s extension API\nFor simple C code, it is straightforward to make a handcrafted extension module.\npreliminary step, you probably want to make sure your C code has a proper header file.\nextern int in_mandel(double x0, double y0, int n);\ndouble x,y;\nWriting a Simple C Extension Module \nWith that assumption, here is a sample extension module that illustrates the basics of\nwriting extension functions:\nstatic PyObject *py_gcd(PyObject *self, PyObject *args) {\nint x, y, result;\nresult = gcd(x,y);\nreturn Py_BuildValue(\"i\", result);\nstatic PyObject *py_in_mandel(PyObject *self, PyObject *args) {\ndouble x0, y0;\nif (!PyArg_ParseTuple(args, \"ddi\", &x0, &y0, &n)) {\nresult = in_mandel(x0,y0,n);\nreturn Py_BuildValue(\"i\", result);\nstatic PyObject *py_divide(PyObject *self, PyObject *args) {\nChapter 15: C Extensions\n\"sample\",           /* name of module */\n/* Module initialization function */\nFor building the extension module, create a setup.py file that looks like this:\nNow, to build the resulting library, simply use python3 buildlib.py build_ext --\nbash % python3 setup.py build_ext --inplace\n-I/usr/local/include/python3.3m -c pysample.c\nbe able to start importing it as a module:\nWriting a Simple C Extension Module \nPython’s C extension API is large, and repeating all of it here is simply not practical.\nFirst, in extension modules, functions that you write are all typically written with a\nstatic PyObject *py_func(PyObject *self, PyObject *args) {\nPyObject is the C data type that represents any Python object.\nextension function is a C function that receives a tuple of Python objects (in PyObject\n*args) and returns a new Python object as a result.\nThe self argument to the function\nis unused for simple extension functions, but comes into play should you want to define\nnew classes or object types in C (e.g., if the extension function were a method of a class,\nThe PyArg_ParseTuple() function is used to convert values from Python to a C rep‐\nThe Py_BuildValue() function is used to create Python objects from C data types.\nIn the extension functions, it is\nused to return results back to Python.\nfor py_divide(), an example showing the return of a tuple is shown.\nChapter 15: C Extensions\nreturn Py_BuildValue(\"d\", 3.4);     // Return a double\nreturn Py_BuildValue(\"s\", \"Hello\"); // Null-terminated UTF-8 string\nreturn Py_BuildValue(\"(ii)\", 3, 4); // Tuple (3, 4)\nNear the bottom of any extension module, you will find a function table such as the\nThis table lists C functions, the names to use\nThe final function PyInit_sample() is the module initialization function that executes\nwhen the module is first imported.\nwith C functions than what is shown here (in fact, the C API contains well over 500\nfunctions in it).\nWriting an Extension Function That Operates on\nYou want to write a C extension function that operates on contiguous arrays of data, as\nmight be created by the array module or libraries like NumPy. However, you would like\nyour function to be general purpose and not specific to any one array library.\nTo receive and process arrays in a portable manner, you should write code that uses the\nHere is an example of a handwritten C extension function that receives\narray data and calls the avg(double *buf, int len) function from this chapter’s in‐\nstatic PyObject *py_avg(PyObject *self, PyObject *args) {\nWriting an Extension Function That Operates on Arrays \n/* Pass the raw buffer and size to the C function */\nreturn Py_BuildValue(\"d\", result);\nHere is an example that shows how this extension function works:\nChapter 15: C Extensions\nPassing array objects to C functions might be one of the most common things you would\nwant to do with a extension function.\nThe key to this code is the PyBuffer_GetBuffer() function.\nFor arrays, byte strings, and other similar objects, a Py_buffer structure is filled with\nThis is the same code that the struct module uses when encoding binary values.\nmodule and might include multiple items in the case of arrays containing C structures.\nOnce we have verified the underlying buffer information, we simply pass it to the C\nfunction, which treats it as a normal C array.\nThis is how the function\nis able to work with arrays created by the array module or by numpy.\nWriting an Extension Function That Operates on Arrays \nManaging Opaque Pointers in C Extension Modules\nYou have an extension module that needs to handle a pointer to a C data structure, but\nConsider this fragment of C code from our sample code:\ndouble x,y;\nHere is an example of extension code that wraps the Point structure and distance()\nfunction using capsules:\n/* Destructor function for points */\nstatic PyObject *PyPoint_FromPoint(Point *p, int must_free) {\nstatic PyObject *py_Point(PyObject *self, PyObject *args) {\nChapter 15: C Extensions\ndouble x,y;\nstatic PyObject *py_distance(PyObject *self, PyObject *args) {\nreturn Py_BuildValue(\"d\", result);\nUsing these functions from Python looks like this:\n>>> p1 = sample.Point(2,3)\n>>> p2 = sample.Point(4,5)\nCapsules are similar to a typed C pointer.\nManaging Opaque Pointers in C Extension Modules \nIn any extension functions, we’ll use these func‐\nthese two functions.\nWhen working with certain kinds of C code, ownership issues can be difficult\nCapsules are a sensible solution to interfacing with certain kinds of C code involving\nDefining and Exporting C APIs from Extension\nYou have a C extension module that internally defines a variety of useful functions that\nyou would like to export as a public C API for use elsewhere.\nfunctions inside other extension modules, but don’t know how to link them together,\nThis recipe focuses on the code written to handle Point objects, which were presented\nIf you recall, that C code included some utility functions like this:\n/* Destructor function for points */\nChapter 15: C Extensions\nstatic PyObject *PyPoint_FromPoint(Point *p, int must_free) {\nPoint_FromPoint() functions as an API that other extension modules could use and\nlink to (e.g., if you have other extensions that also want to use the wrapped Point\nstatic int import_sample(void) {\n_point_api = (_PointAPIMethods *) PyCapsule_Import(\"sample._point_api\",0);\nreturn (_point_api != NULL) ?\nDefining and Exporting C APIs from Extension Modules \nThe most important feature here is the _PointAPIMethods table of function pointers.\n/* Destructor function for points */\nstatic PyObject *PyPoint_FromPoint(Point *p, int free) {\n/* Module initialization function */\nPyObject *py_point_api;\n/* Add the Point C API functions */\npy_point_api = PyCapsule_New((void *) &_point_api, \"sample._point_api\", NULL);\nif (py_point_api) {\nPyModule_AddObject(m, \"_point_api\", py_point_api);\nChapter 15: C Extensions\nFinally, here is an example of a new extension module that loads and uses these API\nfunctions:\n/* An extension function that uses the exported API */\nstatic PyObject *print_point(PyObject *self, PyObject *args) {\nreturn Py_BuildValue(\"\");\n\"A module that imports an API\",  /* Doc string (may be NULL) */\n/* Module initialization function */\n/* Import sample, loading its API functions */\nDefining and Exporting C APIs from Extension Modules \nthe libraries or code from the other module.\nIf it all works, you’ll find that your new extension function works perfectly with the C\nAPI functions defined in the other module:\n>>> p1 = sample.Point(2,3)\nIn this case, the defining module populates a structure of function pointers, creates\na capsule that points to it, and saves the capsule in a module-level attribute (e.g., sam\nOther modules can be programmed to pick up this attribute when imported and extract\n(e.g., sample._point_api), and it will find the capsule and extract the pointer all in one\nThere are some C programming tricks involved in making exported functions look\nChapter 15: C Extensions\nbeen defined to transparently dispatch the API functions through the method table.\nyou didn’t want to use this recipe as shown, you might be able to cross-link modules\ncommon API functions into a shared library and making sure that all extension modules\nFurther information about providing C APIs for extension modules can be found in the\nCalling Python from C\nYou want to safely execute a Python callable from C and return a result back to C.\nexample, perhaps you are writing C code that wants to use a Python function as a\nCalling Python from C is mostly straightforward, but involves a number of tricky parts.\nThe following C code shows an example of how to do it safely:\n/* Execute func(x,y) in the Python interpreter.\narguments and return result of the function must\ndouble call_func(PyObject *func, double x, double y) {\nCalling Python from C \nargs = Py_BuildValue(\"(dd)\", x, y);\n/* Call the function */\nTo use this function, you need to have obtained a reference to an existing Python callable\ncallable object passed into an extension module or simply writing C code to extract a\nHere is a simple example that shows calling a function from an embedded Python\nChapter 15: C Extensions\nreturn PyObject_GetAttrString(module, symbol);\n/* Call it using our call_func() code */\nTo build this last example, you’ll need to compile the C and link against the Python\ncc -g embed.c -I/usr/local/include/python3.3m \\\nHere is a slightly different example that shows an extension function that receives a\n/* Extension function for testing the C-Python callback */\nPyObject *py_call_func(PyObject *self, PyObject *args) {\nCalling Python from C \ndouble x, y, result;\nif (!PyArg_ParseTuple(args,\"Odd\", &func,&x,&y)) {\nresult = call_func(func, x, y);\nreturn Py_BuildValue(\"d\", result);\nUsing this extension function, you could test it as follows:\nreturn x+y\nIf you are calling Python from C, the most important thing to keep in mind is that C is\nments, calling the Python function, checking for exceptions, checking types, extracting\ndouble call_func(PyObject *func, double x, double y) {\nAs an aside, handling errors in the C code is something that you will need to carefully\nto be handled in some other manner that makes sense to your C code.\nCalling a function is relatively straightforward—simply use PyObject_Call(), supply‐\nChapter 15: C Extensions",
      "keywords": [
        "point",
        "Python",
        "extension function",
        "return NULL",
        "code",
        "function",
        "Extension Module",
        "extension",
        "module",
        "int",
        "NULL",
        "functions",
        "double",
        "PyObject",
        "Python object"
      ],
      "concepts": [
        "function",
        "functions",
        "functionality",
        "python",
        "module",
        "returning",
        "important",
        "importing",
        "sample",
        "code"
      ],
      "similar_chapters": [
        {
          "book": "Python Cookbook 3rd",
          "chapter": 13,
          "title": "",
          "score": 0.736,
          "base_score": 0.586,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Python Cookbook 3rd",
          "chapter": 15,
          "title": "",
          "score": 0.512,
          "base_score": 0.512,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Python Cookbook 3rd",
          "chapter": 9,
          "title": "",
          "score": 0.421,
          "base_score": 0.421,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Python Cookbook 3rd",
          "chapter": 1,
          "title": "",
          "score": 0.386,
          "base_score": 0.386,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Python Cookbook 3rd",
          "chapter": 10,
          "title": "",
          "score": 0.363,
          "base_score": 0.363,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "ctypes",
          "extension",
          "pyobject",
          "c_int",
          "ctypes c_int"
        ],
        "semantic": [],
        "merged": [
          "ctypes",
          "extension",
          "pyobject",
          "c_int",
          "ctypes c_int"
        ]
      },
      "topic_id": 2,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.3657402118223605,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:08:10.208825+00:00"
      }
    },
    {
      "chapter_number": 15,
      "title": "C Extensions",
      "start_page": 641,
      "end_page": 680,
      "summary": "function call, you need to make sure that you clean up the arguments using Py_DE\nAfter calling the Python function, you must check for the presence of exceptions.\nSince you’re working from C, you really don’t have the exception\nExtracting information from the return value of calling a Python function is typically\nhave to use functions in the Python concrete objects layer.\nchecks for and extracts the value of a Python float using PyFloat_Check() and Py\nCalling Python from C \nA final tricky part of calling into Python from C concerns the management of Python’s\nWhenever Python is accessed from C, you need to make\n/* Code that uses Python C API functions */\nThis is true even if the calling C code is running\nAt this point, the C code is free to\nuse any Python C-API functions that it wants.\nthe code after the fail: lable as serving the same purpose as code in a Python final\nIf you write your C code using all of these conventions including management of the\nChapter 15: C Extensions\nReleasing the GIL in C Extensions\nYou have C extension code in that you want to execute concurrently with other threads\nIn C extension code, the GIL can be released and reacquired by inserting the following\n// Threaded C code.\nMust not use Python API functions\nThe GIL can only safely be released if you can guarantee that no Python C API functions\nwill be executed in the C code.\nin computationally intensive code that performs calculations on C arrays (e.g., in ex‐\nWhile the GIL is released, other Python threads are allowed to execute in the interpreter.\nMixing Threads from C and Python\nYou have a program that involves a mix of C, Python, and threads, but some of the\nthreads are created from C outside the control of the Python interpreter.\ncertain threads utilize functions in the Python C API.\nReleasing the GIL in C Extensions \nIf you’re going to mix C, Python, and threads together, you need to make sure you\nthe following code somewhere in your C code and make sure it’s called prior to creation\nFor any C code that involves Python objects or the Python C API, make sure you prop‐\n/* Use functions in the interpreter */\nIn advanced applications involving C and Python, it is not uncommon to have many\nthings going on at once—possibly involving a mix of a C code, Python code, C threads,\ninitialized and that C code involving the interpreter has the proper GIL management\nIf other code is currently executing, this function will block until that\nChapter 15: C Extensions\nWrapping C Code with Swig\nYou have existing C code that you would like to access as a C extension module.\nSwig operates by parsing C header files and automatically creating extension code.\nuse it, you first need to have a C header file.\nFor example, this header file for our sample\nextern int in_mandel(double x0, double y0, int n);\nPoint(double x, double y) {\nWrapping C Code with Swig \n/* Map the argument pattern (double *a, int n) to arrays */\n%typemap(in) (double *a, int n)(Py_buffer view) {\n/* C declarations to be included in the extension module */\nextern int in_mandel(double x0, double y0, int n);\nbash % swig -python -py3 sample.i\nThe output of swig is two files, sample_wrap.c and sample.py.\nThe sample_wrap.c file is C code that needs to be compiled into a sup‐\nFor example, you create a setup.py file like this:\n['sample_wrap.c'],\nChapter 15: C Extensions\nTo compile and test, run python3 on the setup.py file like this:\n-I/usr/local/include/python3.3m -c sample_wrap.c\nsample_wrap.c: In function ‘SWIG_InitializeModule’:\nsample_wrap.c:3589: warning: statement with no effect\nIf all of this works, you’ll find that you can use the resulting C extension module in a\nSwig is one of the oldest tools for building extension modules, dating back to Python\ntend to have large existing bases of C that they are trying to access using Python as a\nFor instance, a user might have C code containing thou‐\nsands of functions and various data structures that they would like to access from\nPython.\nWrapping C Code with Swig \nThis merely declares the name of the extension module and specifies C header files that\ndirectly into the output code so this is where you put all included files and other defi‐\nThe bottom part of a Swig interface is a listing of C declarations that you want to be\nextern int in_mandel(double x0, double y0, int n);\nto the C code.\nChapter 15: C Extensions\ncustomization is what makes the divide() function return two values:\nInside the typemap is a fragment of C code that tells Swig how\nto convert a Python object into the associated C arguments.\nthe converted values of the C arguments in the typemap pattern (e.g., $1 maps to double\nthe Python C API and the way in which Swig interacts with it.\nNevertheless, if you have a lot of a C code to expose as an extension module, Swig can\na compiler that processes C declarations, but with a powerful pattern matching and\nWrapping C Code with Swig \nWrapping Existing C Code with Cython\nYou want to use Cython to make a Python extension module that wraps around an\nexisting C library.\nhas been compiled into a C library called libsample.\n# Declarations of \"external\" C functions and structures\nThis file serves the same purpose in Cython as a C header file.\ncdef extern from \"sample.h\" declares the required C header file.\nPython interpreter to the underlying C code declared in the csample.pxd file:\n# Import the low-level C declarations\n# Import some functionality from Python and the C stdlib\nChapter 15: C Extensions\n# Create a Point object and return as a capsule\ndef Point(double x,double y):\nbuild the extension module, create a setup.py file that looks like this:\nWrapping Existing C Code with Cython \ncythoning sample.pyx to sample.c\n-I/usr/local/include/python3.3m -c sample.c\nChapter 15: C Extensions\nAt a high level, using Cython is modeled after C.\nThe .pxd files merely contain C defi‐\nnitions (similar to .h files) and the .pyx files contain implementation (similar to a .c file).\nFor example, even though the csample.pxd file declares int gcd(int, int) as a func‐\nThe C data types attached to the\nFile \"sample.pyx\", line 7, in sample.gcd (sample.c:1284)\nIn that file, the function is declared as returning a bint instead of an int.\nWrapping Existing C Code with Cython \nWithin the Cython wrappers, you have the option of declaring C data types in addition\nHere, the rem variable is explicitly declared as a C int variable.\nunderlying divide() function, &rem makes a pointer to it just as in C.\nThe code for the avg() function illustrates some more advanced features of Cython.\nThis is needed to make sure the C avg() receives a pointer\nPython object—only objects and functions declared as cdef can be used.\nThus, in the csample.pxd file, the avg() is declared as double avg(double *, int)\nC library and Python C API:\nChapter 15: C Extensions\nThe function del_Point() and Point() use this functionality to create a capsule object\ndel_Point() as a function that is only accessible from Cython and not Python.\nsule_New(), PyCapsule_GetPointer() are directly from the Python C API and are used\ncdef csample.Point *_c_point\nself._c_point = <csample.Point *> malloc(sizeof(csample.Point))\nself._c_point.x = x\nself._c_point.y = y\nfree(self._c_point)\nreturn self._c_point.x\nself._c_point.x = value\nreturn self._c_point.y\nself._c_point.y = value\nWrapping Existing C Code with Cython \nreturn csample.distance(p1._c_point, p2._c_point)\ncdef csample.Point *_c_point is declaring an instance variable that holds a pointer\nto an underlying Point structure in C.\ncreate and destroy the underlying C structure using malloc() and free() calls.\nproperty x and property y declarations give code that gets and sets the underlying\naccept instances of the Point extension type as arguments, but pass the underlying\npointer to the C function.\nMaking this change, you will find that the code for manipulating Point objects is more\n<sample.Point object at 0x100447288>\n<sample.Point object at 0x1004472a0>\nYou would like to write some high-performance array processing functions to operate\nChapter 15: C Extensions\nAs an example, consider the following code which shows a Cython function for clipping\nTo compile and build the extension, you’ll need a setup.py file such as the following (use\nYou will find that the resulting function clips arrays, and that it works with many dif‐\n>>> c = numpy.zeros_like(b)\n>>> c\n>>> sample.clip(b,-5,5,c)\n>>> c\n>>> min(c)\n>>> max(c)\n>>> timeit('numpy.clip(b,-5,5,c)','from __main__ import b,c,numpy',number=1000)\n>>> timeit('sample.clip(b,-5,5,c)','from __main__ import b,c,sample',\nNumPy version is written in C.\nThe declaration cpdef clip() declares clip() as both a C-level and\nPython-level function.\nIn Cython, this is useful, because it means that the function call\nChapter 15: C Extensions\nWhen writing code that produces a result that is also an array, you should follow the\nbility of creating the output array on the caller and frees the code from having to know\nis relatively easy to create output arrays using functions such as numpy.zeros() or\nIn the implementation of your function, you simply write straightforward looking array\nto the end of the array (like with Python lists).\nwritten C version.\nFor example, perhaps you write the following C function and craft a\ncrafted C extension ran more than 10% slower than the version created by Cython.\nIf you want to write a version of the code that operates on two-dimensional arrays, here\nChapter 15: C Extensions\nto turn it into a Python callable that you can use as an extension function.\ndress of a C function and how to turn it back into a callable object:\n>>> addr = ctypes.cast(lib.sin, ctypes.c_void_p).value\n>>> functype = ctypes.CFUNCTYPE(ctypes.c_double, ctypes.c_double)\nThe resulting object is used like any normal function accessed\nassembly function, obtain a function pointer to it, and turn it into a Python callable:\n>>> foo = ctypes.CFUNCTYPE(ctypes.c_double, ctypes.c_double, ctypes.c_double)(ptr)\nPassing NULL-Terminated Strings to C Libraries\nYou are writing an extension module that needs to pass a NULL-terminated string to a\nC library.\nHowever, you’re not entirely sure how to do it with Python’s Unicode string\nMany C libraries include functions that operate on NULL-terminated strings declared\nConsider the following C function that we will use for the purposes of\nChapter 15: C Extensions\nprint_chars(\"Hello\");   // Outputs: 48 65 6c 6c 6f\nFor calling such a C function from Python, you have a few choices.\nrestrict it to only operate on bytes using \"y\" conversion code to PyArg_ParseTuple()\nstatic PyObject *py_print_chars(PyObject *self, PyObject *args) {\nIf you want to pass Unicode strings instead, use the \"s\" format code to PyArg_Parse\nstatic PyObject *py_print_chars(PyObject *self, PyObject *args) {\nPassing NULL-Terminated Strings to C Libraries \n53 70 69 63 79 20 4a 61 6c 61 70 65 c3 b1 6f\nseTuple(), the following code samples show how you can check and extract a suitable\nchar * reference, from both a bytes and string object:\nChapter 15: C Extensions\nstrings since Python has no such requirement.\nhave to work with legacy C code that presents no other option.\n>>> print_chars(s)     # Passing string\n53 70 69 63 79 20 4a 61 6c 61 70 65 c3 b1 6f\nIf this growth in memory use is a concern, you should rewrite your C extension code\nto use the PyUnicode_AsUTF8String() function like this:\nstatic PyObject *py_print_chars(PyObject *self, PyObject *args) {\n53 70 69 63 79 20 4a 61 6c 61 70 65 c3 b1 6f\nPassing NULL-Terminated Strings to C Libraries \nIf you are trying to pass NULL-terminated strings to functions wrapped via ctypes, be\n>>> print_chars.argtypes = (ctypes.c_char_p,)\n48 65 6c 6c 6f\nIf you want to pass a string instead of bytes, you need to perform a manual UTF-8\nyou decide to use them to pass strings to C code.\nPassing Unicode Strings to C Libraries\nYou are writing an extension module that needs to pass a Python string to a C library\nby C libraries.\nFor the purposes of illustration, here are two C functions that operate on string data\nChapter 15: C Extensions\nFor the byte-oriented function print_chars(), you need to convert Python strings into\nHere is a sample extension function that does\nstatic PyObject *py_print_chars(PyObject *self, PyObject *args) {\nFor library functions that work with the machine native wchar_t type, you can write\nextension code such as this:\n53 70 69 63 79 20 4a 61 6c 61 70 65 c3 b1 6f\n53 70 69 63 79 20 4a 61 6c 61 70 65 f1 6f\nPassing Unicode Strings to C Libraries \nCarefully observe how the byte-oriented function print_chars() is receiving UTF-8\nencoded data, whereas print_wchars() is receiving the Unicode code point values.\nBefore considering this recipe, you should first study the nature of the C library that\nFor many C libraries, it might make more sense to pass bytes instead\nstatic PyObject *py_print_chars(PyObject *self, PyObject *args) {\nIf you decide that you still want to pass strings, you need to know that Python 3 uses an\nadaptable string representation that is not entirely straightforward to map directly to C\nto present string data to C, some kind of conversion is almost always necessary.\n53 70 69 63 79 20 4a 61 6c 61 70 65 c3 b1 6f\n53 70 69 63 79 20 4a 61 6c 61 70 65 f1 6f\nChapter 15: C Extensions\nstatic PyObject *py_print_chars(PyObject *self, PyObject *args) {\nthe Unicode data into a temporary array, pass it to the C library function, and then\nThat buffer is passed to C and then released\nPassing Unicode Strings to C Libraries \nIf, for some reason you know that the C library takes the data in a different byte encoding\nstatic PyObject *py_print_chars(PyObject *self, PyObject *args) {\nPy_UCS4 ch = PyUnicode_READ(kind, data, n);\nIn this code, the PyUnicode_KIND() and PyUnicode_DATA() macros are related to the\nA few final words: when passing Unicode strings from Python to C, you should probably\nChapter 15: C Extensions\nConverting C Strings to Python\nYou want to convert strings from C to Python bytes or a string object.\nFor C strings represented as a pair char *, int, you must decide whether or not you\nchar *s;     /* Pointer to C string data */\nPyObject *obj = Py_BuildValue(\"y#\", s, len);\nIf you want to create a Unicode string and you know that s points to data encoded as\nPyObject *obj = PyUnicode_Decode(s, len, \"encoding\", \"errors\");\nto be raw Unicode code points which are directly converted to Python.\nConverting C Strings to Python \nConversion of strings from C to Python follow the same principles as I/O.\ndata from C must be explicitly decoded into a string according to some codec.\nor the data is binary, you’re probably best off encoding the string as bytes instead.\nWhen making an object, Python always copies the string data you provide.\nit’s up to you to release the C string afterward (if required).\nWorking with C Strings of Dubious Encoding\nYou are converting strings back and forth between C and Python, but the C encoding\nFor example, perhaps the C data is supposed to be\nYou would like to write code that can handle\nmalformed data in a graceful way that doesn’t crash Python or destroy the string data\nHere is some C data and a function that illustrates the nature of this problem:\nIn this code, the string sdata contains a mix of UTF-8 and malformed data.\nless, if a user calls print_chars(sdata, slen) in C, it works fine.\nNow suppose you want to convert the contents of sdata into a Python string.\nsuppose you want to later pass that string to the print_chars() function through an\nChapter 15: C Extensions\n/* Return the C string back to Python */\n/* Wrapper for the print_chars() function */\nstatic PyObject *py_print_chars(PyObject *self, PyObject *args) {\nIf you try these functions from Python, here’s what happens:\nCareful observation will reveal that the malformed string got encoded into a Python\nstring without errors, and that when passed back into C, it turned back into a byte string\nthat exactly encoded the same bytes as the original C string.\nNamely, the fact that C strings in extensions might not follow the\nthat some malformed C data would pass to Python.\nA good example might be C strings\nWorking with C Strings of Dubious Encoding \nto pass from C to Python and back into C without any data loss.\nyour code will be much more reliable if it uses proper encodings.\nChapter 15: C Extensions\nAs a final note, many of Python’s system-oriented functions, especially those related to\nPassing Filenames to C Extensions\nYou need to pass filenames to C library functions, but need to make sure the filename\nTo write an extension function that receives a filename, use code such as this:\nIf you already have a PyObject * that you want to convert as a filename, use code such\nPassing Filenames to C Extensions \nIf you need to return a filename back to Python, use the following code:\n/* Turn a filename into a Python object */\nIf you use this recipe in your extension code, filenames will be handled in a manner that\nPassing Open Files to C Extensions\nYou have an open file object in Python, but need to pass it to C extension code that will\nPyObject *fobj;     /* File object (already obtained somehow) */\nOnce you have the descriptor, it can be passed to various low-level C functions that\nIf you need to convert an integer file descriptor back into a Python object, use\nChapter 15: C Extensions\nIf you are passing file objects from Python to C, there are a few tricky issues to be\nPrior to passing any kind of file descriptor to C, you should first flush the I/O buffers\nIf a file descriptor is passed to C, but still used in Python,\nyou need to make sure C doesn’t accidentally close the file.\nis being turned into a Python file object, you need to be clear about who is responsible\nIf you need to make a different kind of file object such as a FILE * object from the C\nthe I/O stack (one from Python’s io module and one from C stdio).\nas fclose() in C could also inadvertently close the file for further use in Python.\na choice, you should probably make extension code work with the low-level integer file\nReading File-Like Objects from C\nYou want to write C extension code that consumes data from any Python file-like object\nTo consume data on a file-like object, you need to repeatedly invoke its read() method\nHere is a sample C extension function that merely consumes all of the data on a file-like\nReading File-Like Objects from C \n/* Consume a \"file-like\" object and write bytes to stdout */\nstatic PyObject *py_consume_file(PyObject *self, PyObject *args) {\n/* Encode Unicode as Bytes for C */\nChapter 15: C Extensions\nTo test the code, try making a file-like object such as a StringIO instance and pass it in:\nThus, you can’t use normal C library functions to access it.\nneed to use Python’s C API to manipulate the file-like object much like you would in\nPython.\nmode and decode the resulting text into a bytes encoding that can be used by C.\nReading File-Like Objects from C \nmethod of the file-like object, convert data into an appropriate Python object (bytes or\nfor C extensions.\nConsuming an Iterable from C\nYou want to write C extension code that consumes items from any iterable object such\nHere is a sample C extension function that shows how to consume the items on an\nChapter 15: C Extensions",
      "keywords": [
        "Python",
        "return NULL",
        "code",
        "point",
        "PyObject",
        "extension code",
        "extension",
        "int",
        "NULL",
        "double",
        "function",
        "file",
        "Python object",
        "string",
        "data"
      ],
      "concepts": [
        "function",
        "functions",
        "functionality",
        "python",
        "code",
        "file",
        "strings",
        "string",
        "data",
        "bytes"
      ],
      "similar_chapters": [
        {
          "book": "Python Cookbook 3rd",
          "chapter": 14,
          "title": "",
          "score": 0.512,
          "base_score": 0.512,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Python Cookbook 3rd",
          "chapter": 13,
          "title": "",
          "score": 0.422,
          "base_score": 0.422,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Python Cookbook 3rd",
          "chapter": 9,
          "title": "",
          "score": 0.413,
          "base_score": 0.413,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Python Cookbook 3rd",
          "chapter": 6,
          "title": "",
          "score": 0.401,
          "base_score": 0.401,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Python Cookbook 3rd",
          "chapter": 1,
          "title": "",
          "score": 0.383,
          "base_score": 0.383,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "pyobject",
          "extensions",
          "extension",
          "15 extensions",
          "chapter 15"
        ],
        "semantic": [],
        "merged": [
          "pyobject",
          "extensions",
          "extension",
          "15 extensions",
          "chapter 15"
        ]
      },
      "topic_id": null,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.37868529612122,
        "topic_boost": 0.0,
        "timestamp": "2025-12-17T23:08:10.208843+00:00"
      }
    }
  ],
  "total_chapters": 15,
  "enrichment_provenance": {
    "taxonomy_id": "none",
    "taxonomy_version": "none",
    "taxonomy_path": "none",
    "taxonomy_checksum": "sha256:none",
    "source_metadata_file": "Python Cookbook 3rd_metadata.json",
    "enrichment_date": "2025-12-17T23:08:10.214696+00:00",
    "enrichment_method": "msep",
    "model_version": "ai-agents-msep-v1",
    "processing_time_ms": 4157.371336001233,
    "total_similar_chapters": 73
  }
}