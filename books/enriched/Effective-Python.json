{
  "metadata": {
    "title": "Effective-Python",
    "source_file": "Effective-Python_metadata.json"
  },
  "chapters": [
    {
      "chapter_number": 1,
      "title": "Segment 1 (pages 2-9)",
      "start_page": 2,
      "end_page": 9,
      "summary": "Praise for Effective Python\nThis new edition, updated and expanded for Python 3, is a \ntreasure trove of practical Python programming wisdom that can benefit pro-\n—Wes McKinney, Creator of Python Pandas project, Director of Ursa Labs\nfull advantage of the unique features Python has to offer.\nPython for nearly twenty years and I still learned a bunch of useful tricks, espe-\ncially around newer features introduced by Python 3.\nEffective Python is crammed \nthey talk about Pythonic code.”\n“I’ve been programming in Python for years and thought I knew it pretty well.\nto improve my Python code to make it faster (e.g., using bisect to search sorted \n(e.g., unpacking with starred expressions), and more Pythonic (e.g., using zip to \nup to speed on Python 3 features, such as the walrus operator, f-strings, and the \n“Now that Python 3 has finally become the standard version of Python, it’s \nBrett Slatkin returns with a second edition of Effective Python \nwith a huge new list of Python idioms and straightforward recommendations, \n3.8 that we’ll all want to use as we finally leave Python 2 behind.\nlay out an enormous list of tips regarding new Python 3 syntaxes and concepts \none Python book this year...’ contest.\nThe second edition updates the advice for Python 3, and it’s fantastic!\nI’ve been using Python for almost 20 years, and I learned something new every \nThe advice given in this book will serve anyone well.”\nupdated Effective Python makes a consensus view of what’s ‘Pythonic’ available to \n—Brandon Rhodes, Author of python-patterns.guide\nEffective Python\nEffective Python\n90 SPECIFIC WAYS TO WRITE BETTER PYTHON\nWhere those designations appear in this \nbook, and the publisher was aware of a trademark claim, the designations have \nChapter 1: Pythonic Thinking ",
      "keywords": [
        "Python",
        "Effective Python",
        "Python Pandas project",
        "Effective Python makes",
        "updated Effective Python",
        "blank Effective Python",
        "Python Pandas",
        "Effective",
        "edition",
        "practical Python programming",
        "Python programming wisdom",
        "unique features Python",
        "book",
        "advice",
        "Brett Slatkin"
      ],
      "concepts": [
        "python",
        "pythonic",
        "editor",
        "sales",
        "advice",
        "programming",
        "programs",
        "features",
        "lists",
        "edition"
      ],
      "similar_chapters": [
        {
          "book": "Effective-Python",
          "chapter": 3,
          "title": "",
          "score": 0.744,
          "base_score": 0.594,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 39,
          "title": "",
          "score": 0.595,
          "base_score": 0.445,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 2,
          "title": "",
          "score": 0.547,
          "base_score": 0.547,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 30,
          "title": "",
          "score": 0.513,
          "base_score": 0.513,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 9,
          "title": "",
          "score": 0.495,
          "base_score": 0.495,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "python",
          "effective",
          "effective python",
          "edition",
          "features"
        ],
        "semantic": [],
        "merged": [
          "python",
          "effective",
          "effective python",
          "edition",
          "features"
        ]
      },
      "topic_id": 3,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.32636875206705285,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:03.223457+00:00"
      }
    },
    {
      "chapter_number": 2,
      "title": "Segment 2 (pages 10-18)",
      "start_page": 10,
      "end_page": 18,
      "summary": "Chapter 1 Pythonic Thinking \nItem 1: Know Which Version of Python You’re Using \nItem 3: Know the Differences Between bytes and str \nItem 5:  Write Helper Functions Instead of \nItem 8: Use zip to Process Iterators in Parallel \nItem 9: Avoid else Blocks After for and while Loops \nItem 11: Know How to Slice Sequences \nItem 16:  Prefer get Over in and KeyError to \nItem 18:  Know How to Construct Key-Dependent \nItem 19:  Never Unpack More Than Three Variables \nItem 23:  Provide Optional Behavior with Keyword Arguments \nItem 24:  Use None and Docstrings to Specify \nItem 27:  Use Comprehensions Instead of map and filter \nItem 29:  Avoid Repeated Work in Comprehensions by Using \nItem 30:  Consider Generators Instead of Returning Lists \nItem 31: Be Defensive When Iterating Over Arguments \nItem 32:  Consider Generator Expressions for Large List \nItem 36:  Consider itertools for Working with Iterators \nItem 37:  Compose Classes Instead of Nesting \nItem 38:  Accept Functions Instead of Classes for \nItem 39:  Use @classmethod Polymorphism to \nItem 41:  Consider Composing Functionality \nItem 44:  Use Plain Attributes Instead of Setter and \nItem 45:  Consider @property Instead of \nItem 46:  Use Descriptors for Reusable @property Methods \nItem 47:  Use __getattr__, __getattribute__, and \nItem 50: Annotate Class Attributes with __set_name__ \nItem 51:  Prefer Class Decorators Over Metaclasses for \nItem 52: Use subprocess to Manage Child Processes \nItem 53:  Use Threads for Blocking I/O, Avoid for Parallelism \nItem 54: Use Lock to Prevent Data Races in Threads \nItem 55:  Use Queue to Coordinate Work Between Threads \nItem 56:  Know How to Recognize When Concurrency \nItem 58:  Understand How Using Queue for \nItem 59:  Consider ThreadPoolExecutor When Threads \nItem 64:  Consider concurrent.futures for True Parallelism \nItem 67: Use datetime Instead of time for Local Clocks \nItem 69: Use decimal When Precision Is Paramount \nItem 73: Know How to Use heapq for Priority Queues \nItem 75: Use repr Strings for Debugging Output \nItem 78:  Use Mocks to Test Code with \nItem 80: Consider Interactive Debugging with pdb \nItem 81:  Use tracemalloc to Understand Memory \nItem 82: Know Where to Find Community-Built Modules \nItem 83:  Use Virtual Environments for Isolated and \nItem 84:  Write Docstrings for Every Function, \nItem 85:  Use Packages to Organize Modules and \nItem 86:  Consider Module-Scoped Code to \nItem 89:  Consider warnings to Refactor and Migrate Usage \nthe best way to use Python.\nEach chapter in this book contains a broad but related set of items.\nEach item \nItems include advice on what to \nItems reference each other to make it easier to fill in the \n(see Item 1: “Know Which Version of Python You’re Using”), up to and \nChapter 1: Pythonic Thinking\nPython can also be used \nThis chapter covers how to best utilize Python in these subtly \ncovers how to use Python to optimize your programs to maximize ",
      "keywords": [
        "Item",
        "Python",
        "chapter covers",
        "Prefer",
        "Avoid",
        "Generators",
        "Attributes",
        "Classes",
        "Python programs",
        "Prefer Multiple Assignment",
        "Functions",
        "book",
        "Comprehensions",
        "Covers",
        "Prefer Public Attributes"
      ],
      "concepts": [
        "item",
        "useful",
        "pythonic",
        "python",
        "consider",
        "classes",
        "prefer",
        "functions",
        "function",
        "functionality"
      ],
      "similar_chapters": [
        {
          "book": "Effective-Python",
          "chapter": 9,
          "title": "",
          "score": 0.782,
          "base_score": 0.632,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 43,
          "title": "",
          "score": 0.679,
          "base_score": 0.529,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 14,
          "title": "",
          "score": 0.592,
          "base_score": 0.592,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 1,
          "title": "",
          "score": 0.547,
          "base_score": 0.547,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 40,
          "title": "",
          "score": 0.535,
          "base_score": 0.535,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "item",
          "consider",
          "know",
          "covers",
          "chapter"
        ],
        "semantic": [],
        "merged": [
          "item",
          "consider",
          "know",
          "covers",
          "chapter"
        ]
      },
      "topic_id": 4,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.41577049457250526,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:03.223533+00:00"
      }
    },
    {
      "chapter_number": 3,
      "title": "Segment 3 (pages 19-26)",
      "start_page": 19,
      "end_page": 26,
      "summary": "I take some artistic license with the Python style guide in order to \nor terminal output: what you see when running the Python program \nand are preceded by a >>> line (the Python interactive prompt).\nidea is that you could type the code snippets into a Python shell and \ngrams besides the normal Python interpreter.\nThanks \nThanks to all of the translators who made the book \nThanks to the wonderful Python programmers I’ve known and \nusing Python to manage Google’s enormous fleet of servers.\nPythonic Thinking\nOver the years, the Python community has come to use the adjective \nPythonic to describe code that follows a particular style.\nThe Pythonic \nyour interpreter to read The Zen of Python.)\nProgrammers familiar with other languages may try to write Python \nthat can be expressed in Python.\nbest—the Pythonic—way to do the most common things in Python.\nItem 1: Know Which Version of Python You’re Using\nof Python 3.7 (released in June 2018).\nexamples in the syntax of Python 3.8 (released in October 2019) to \nbook does not cover Python 2.\nHowever, the default meaning of python on the \nbut it can sometimes be an alias for even older versions, like python2.6 \nor python2.5.\nTo find out exactly which version of Python you’re using, \n$ python --version\nPython 2.7.10\nChapter 1 Pythonic Thinking\nPython 3 is usually available under the name python3:\n$ python3 --version\nPython 3.8.0\nYou can also figure out the version of Python you’re using at runtime \nPython 3 includes \nible with and focused on Python 3.\nPython 3 for all your Python projects.\nUsing Python 2 after that date is a liability because it \na Python 2 codebase, you should consider using helpful tools like 2to3 \n(preinstalled with Python) and six (available as a community pack-\nhelp you make the transition to Python 3.\n✦ Python 3 is the most up-to-date and well-supported version of \nPython, and you should use it for your projects.\n✦ Be sure that the command-line executable for running Python on \nthe style guide for how to format Python code.\nwrite Python code any way you want, as long as it has valid syntax.\nSharing a common style with other Python \nPEP 8 provides a wealth of details about how to write clear Python \nIt continues to be updated as the Python language evolves.\nIt’s worth reading the whole guide online (https://www.python.org/\nIn Python, whitespace is syntactically significant.\nPython program-",
      "keywords": [
        "Python",
        "Python code",
        "code",
        "book",
        "write Python code",
        "style guide",
        "Python style guide",
        "Python programmers",
        "style",
        "write Python",
        "Python program",
        "format Python code",
        "clear Python code",
        "code snippets",
        "guide"
      ],
      "concepts": [
        "pythonic",
        "thanks",
        "styles",
        "editor",
        "output",
        "program",
        "programming",
        "code",
        "write",
        "writing"
      ],
      "similar_chapters": [
        {
          "book": "Effective-Python",
          "chapter": 1,
          "title": "",
          "score": 0.744,
          "base_score": 0.594,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 39,
          "title": "",
          "score": 0.593,
          "base_score": 0.443,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 2,
          "title": "",
          "score": 0.426,
          "base_score": 0.426,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 41,
          "title": "",
          "score": 0.411,
          "base_score": 0.411,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 30,
          "title": "",
          "score": 0.394,
          "base_score": 0.394,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "python",
          "guide",
          "style",
          "python code",
          "version python"
        ],
        "semantic": [],
        "merged": [
          "python",
          "guide",
          "style",
          "python code",
          "version python"
        ]
      },
      "topic_id": 3,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.29754993528453566,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:03.223574+00:00"
      }
    },
    {
      "chapter_number": 4,
      "title": "Segment 4 (pages 27-34)",
      "start_page": 27,
      "end_page": 34,
      "summary": "Item 3: Know the Differences Between bytes and str \nItem 3: Know the Differences Between bytes and str\ndata: bytes and str.\nInstances of str contain Unicode code points that represent textual \nImportantly, str instances do not have an associated binary encod-\ning, and bytes instances do not have an associated text encoding.\nconvert Unicode data to binary data, you must call the encode method \nWhen you’re writing Python programs, it’s important to do encoding \nof your program should use the str type containing Unicode data \nThe first function takes a bytes or str instance and always returns \ndef to_str(bytes_or_str):\nif isinstance(bytes_or_str, bytes):\nvalue = bytes_or_str.decode('utf-8')\nvalue = bytes_or_str\nreturn value  # Instance of str\nItem 3: Know the Differences Between bytes and str \nprint(repr(to_str(b'foo')))\nThe second function takes a bytes or str instance and always returns \na bytes:\ndef to_bytes(bytes_or_str):\nif isinstance(bytes_or_str, str):\nvalue = bytes_or_str.encode('utf-8')\nvalue = bytes_or_str\nreturn value  # Instance of bytes\nprint(repr(to_bytes(b'foo')))\nUnicode strings in Python.\nThe first issue is that bytes and str seem to work the same way, but \nBy using the + operator, you can add bytes to bytes and str to str, \nBut you can’t add str instances to bytes instances:\nTypeError: can't concat str to bytes\nNor can you add bytes instances to str instances:\nTypeError: can only concatenate str (not \"bytes\") to str\nBy using binary operators, you can compare bytes to bytes and str to \nBut you can’t compare a str instance to a bytes instance:\nNor can you compare a bytes instance to a str instance:\nComparing bytes and str instances for equality will always evaluate \nThe % operator works with format strings for each type, respectively:\nBut you can’t pass a str instance to a bytes format string because \nPython doesn’t know what binary text encoding to use:\nprint(b'red %s' % 'blue')\n¯implements __bytes__, not 'str'\nItem 3: Know the Differences Between bytes and str \nYou can pass a bytes instance to a str format string using the \nprint('red %s' % b'blue')\nrepr Strings for Debugging Output”) on the bytes instance and sub-\nTypeError: write() argument must be str, not bytes\nmode, write operations expect str instances containing Unicode data \ninstead of bytes instances containing binary data.\nit uses the system’s default text encoding to interpret binary data \nusing the bytes.encode (for writing) and str.decode (for reading) \nbinary data in the file was actually meant to be a string encoded as \nwith open('data.bin', 'r', encoding='cp1252') as f:\nbytes.\n✦ bytes contains sequences of 8-bit values, and str contains \nUTF-8-encoded strings, Unicode code points, etc).\n✦ bytes and str instances can’t be used together with operators (like \n✦ If you want to read or write binary data to/from a file, always open \n✦ If you want to read or write Unicode data to/from a file, be care-\nFormat Strings and str.format\nPython has four different ways of formatting strings that are built \nThe most common way to format a string in Python is by using the \nare new to Python start with C-style format strings because they’re \nThere are four problems with C-style format strings in Python.",
      "keywords": [
        "bytes",
        "str",
        "Python",
        "str instances",
        "data",
        "Unicode data",
        "Unicode",
        "Instances",
        "bytes instances",
        "format",
        "binary",
        "binary data",
        "encoding",
        "Item",
        "Unicode strings"
      ],
      "concepts": [
        "format",
        "formatting",
        "encoding",
        "encode",
        "pythonic",
        "python",
        "bytes",
        "uses",
        "code",
        "imports"
      ],
      "similar_chapters": [
        {
          "book": "Effective-Python",
          "chapter": 36,
          "title": "",
          "score": 0.691,
          "base_score": 0.541,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 2,
          "title": "",
          "score": 0.465,
          "base_score": 0.465,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 20,
          "title": "",
          "score": 0.432,
          "base_score": 0.432,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 5,
          "title": "",
          "score": 0.417,
          "base_score": 0.417,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 14,
          "title": "",
          "score": 0.416,
          "base_score": 0.416,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "bytes",
          "str",
          "bytes str",
          "unicode",
          "binary"
        ],
        "semantic": [],
        "merged": [
          "bytes",
          "str",
          "bytes str",
          "unicode",
          "binary"
        ]
      },
      "topic_id": 6,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.3143355978176459,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:03.223611+00:00"
      }
    },
    {
      "chapter_number": 5,
      "title": "Segment 5 (pages 35-42)",
      "start_page": 35,
      "end_page": 42,
      "summary": "formatted = '%-10s = %.2f' % (key, value)\nprint(formatted)\nchanging the format string results in the same error:\nThe second problem with C-style formatting expressions is that they \nvalues before formatting them into a string—and this is an extremely \nNow, I make a few modifications to the values that I’m formatting \nThe third problem with formatting expressions is that if you want \nto use the same value in a format string multiple times, you have to \nformatted = template % (name, name)\nprint(formatted)\nsmall modifications to the values being formatted.\nprint(formatted)\nkeys from the dictionary are matched with format specifiers with the \nchange the order of values on the right side of the formatting expres-\nUsing dictionaries in formatting expressions also solves problem #3 \nHowever, dictionary format strings introduce and exacerbate other \nUsing dictionaries in formatting expressions also increases verbosity, \nwhich is problem #4 with C-style formatting expressions in Python.\nprint(formatted)\none line per value to use in formatting:\nformatted = template % menu\nprint(formatted)\nformat string and the lines of the dictionary.\nmake small modifications to any of the values before formatting.\nexpressive than the old C-style format strings that use the % operator.\nformat values:\nprint(formatted)\nprint('*', formatted, '*')\nYou can use this functionality to format multiple values together \nBy default the placeholders in the format string are replaced by the \nformatted = '{} = {}'.format(key, value)\nprint(formatted)\nformatted = '{:<10} = {:.2f}'.format(key, value)\nprint(formatted)\nwill be passed to the format built-in function along with the value \n(format(value, '.2f') in the example above).\nthe __format__ special method.\nWith C-style format strings, you need to escape the % character (by \nformatted = '{1} = {0}'.format(key, value)\nprint(formatted)\nthe format string without the need to pass the value to the format \nSee {0} cook.'.format(name)\nprint(formatted)\nto make small modifications to values before formatting them.\nnew_style = '#{}: {:<10s} = {}'.format(\nthe str.format method, such as using combinations of dictionary keys \nprint(formatted)\nusing dictionaries in C-style formatting expressions to the new style \nold_formatted = template % {\nthe dictionary and a few characters in the format specifiers, but it’s \nlimiting that it undermines the value of the format method from str \nInterpolated Format Strings\nyou to prefix format strings with an f character, which is similar to \nF-strings take the expressiveness of format strings to the extreme, \ndancy of providing keys and values to be formatted.\nformatted = f'{key} = {value}'\nprint(formatted)\nthe str.format method:\nformatted = f'{key!r:<10} = {value:.2f}'\nprint(formatted)\nFormatting with f-strings is shorter than using C-style format strings ",
      "keywords": [
        "format",
        "format strings",
        "C-style format strings",
        "formatted",
        "C-style formatting expressions",
        "key",
        "format method",
        "C-style format",
        "formatting expressions",
        "Interpolated Format Strings",
        "format specifiers",
        "strings",
        "soup",
        "string",
        "C-style formatting"
      ],
      "concepts": [
        "formatted",
        "strings",
        "key",
        "keys",
        "value",
        "multiple",
        "pythonic",
        "python",
        "printed",
        "problem"
      ],
      "similar_chapters": [
        {
          "book": "Effective-Python",
          "chapter": 6,
          "title": "",
          "score": 0.572,
          "base_score": 0.572,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 10,
          "title": "",
          "score": 0.477,
          "base_score": 0.477,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 14,
          "title": "",
          "score": 0.475,
          "base_score": 0.475,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 2,
          "title": "",
          "score": 0.435,
          "base_score": 0.435,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 4,
          "title": "",
          "score": 0.417,
          "base_score": 0.417,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "format",
          "formatted",
          "print formatted",
          "formatting",
          "format strings"
        ],
        "semantic": [],
        "merged": [
          "format",
          "formatted",
          "print formatted",
          "formatting",
          "format strings"
        ]
      },
      "topic_id": null,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.2839810165809858,
        "topic_boost": 0.0,
        "timestamp": "2025-12-17T23:07:03.223646+00:00"
      }
    },
    {
      "chapter_number": 6,
      "title": "Segment 6 (pages 43-50)",
      "start_page": 43,
      "end_page": 50,
      "summary": "f_string = f'{key:<10} = {value:.2f}'\nc_tuple  = '%-10s = %.2f' % (key, value)\nstr_args = '{:<10} = {:.2f}'.format(key, value)\nstr_kw   = '{key:<10} = {value:.2f}'.format(key=key,\nc_dict   = '%(key)-10s = %(value).2f' % {'key': key,\nassert c_tuple == c_dict == f_string\nF-strings also enable you to put a full Python expression within the \nmodifications to the values being formatted with concise syntax.\nf_string = f'#{i+1}: {item.title():<10s} = {round(count)}'\nOr, if it’s clearer, you can split an f-string over multiple lines by rely-\nItem 5: Write Helper Functions Instead of Complex Expressions \nf'{item.title():<10s} = '\nPython expressions may also appear within the format specifier \nby using a variable instead of hard-coding it in the format string:\nby f-strings makes them the best built-in option for Python pro-\nAny time you find yourself needing to format values into \n✦ F-strings are a new syntax for formatting values into strings that \nPython’s pithy syntax makes it easy to write single-line expressions \nmy_values = parse_qs('red=5&blue=0&green=',\nprint(repr(my_values))\nSome query string parameters may have multiple values, some may \nprint('Red:     ', my_values.get('red'))\nprint('Green:   ', my_values.get('green'))\nprint('Opacity: ', my_values.get('opacity'))\nIt’d be nice if a default value of 0 were assigned when a parameter isn’t \nred = my_values.get('red', [''])[0] or 0\ngreen = my_values.get('green', [''])[0] or 0\nThe red case works because the key is present in the my_values dictio-\nThe value is a list with one member: the string '5'.\nItem 5: Write Helper Functions Instead of Complex Expressions \nThe green case works because the value in the my_values dictionary is \nThe opacity case works because the value in the my_values dictionary \nThe default value in this case is a list with one member: an empty \nred = int(my_values.get('red', [''])[0] or 0)\nred_str = my_values.get('red', [''])\ngreen_str = my_values.get('green', [''])\ndef get_first_int(values, key, default=0):\nfound = values.get(key, [''])\ngreen = get_first_int(my_values, 'green')\n✦ Python’s syntax makes it easy to write single-line expressions that \nItem 6:  Prefer Multiple Assignment Unpacking Over \nitems = tuple(snack_calories.items())\nprint(items)\n(('chips', 140), ('popcorn', 80), ('nuts', 190))\nThe values in tuples can be accessed through numerical indexes:\nfirst = item[0]\nItem 6: Prefer Multiple Assignment Unpacking Over Indexing \nOnce a tuple is created, you can’t modify it by assigning a new value \nPython also has syntax for unpacking, which allows for assigning \nmultiple values in a single statement.\nvalues, you can assign it to a tuple of two variable names:\nfirst, second = item  # Unpacking\nprint(f'Favorite {type1} is {name1} with {cals1} calories')\nprint(f'Favorite {type2} is {name2} with {cals2} calories')\nprint(f'Favorite {type3} is {name3} with {cals3} calories')\neven be used to swap values in place without the need to create tem-\nHowever, with unpacking syntax, it’s possible to swap indexes in a \nItem 6: Prefer Multiple Assignment Unpacking Over Indexing \nof the assignment (a[i-1], a[i]) is used to receive that tuple value \nitem = snacks[i]\nname = item[0]\ncalories = item[1]\nprint(f'#{i+1}: {name} has {calories} calories')",
      "keywords": [
        "item",
        "C-style format strings",
        "green",
        "string",
        "calories",
        "Unpacking",
        "Expressions",
        "red",
        "Prefer Multiple Assignment",
        "Python",
        "Write Helper Functions",
        "Multiple Assignment Unpacking",
        "Helper Functions",
        "multiple",
        "key"
      ],
      "concepts": [
        "item",
        "value",
        "pythonic",
        "expressions",
        "expressiveness",
        "string",
        "strings",
        "unpacking",
        "line",
        "indexing"
      ],
      "similar_chapters": [
        {
          "book": "Effective-Python",
          "chapter": 14,
          "title": "",
          "score": 0.676,
          "base_score": 0.526,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 5,
          "title": "",
          "score": 0.572,
          "base_score": 0.572,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 7,
          "title": "",
          "score": 0.56,
          "base_score": 0.41,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 10,
          "title": "",
          "score": 0.52,
          "base_score": 0.52,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 2,
          "title": "",
          "score": 0.481,
          "base_score": 0.481,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "my_values",
          "green",
          "red",
          "key",
          "calories"
        ],
        "semantic": [],
        "merged": [
          "my_values",
          "green",
          "red",
          "key",
          "calories"
        ]
      },
      "topic_id": 5,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.2769164581668954,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:03.223688+00:00"
      }
    },
    {
      "chapter_number": 7,
      "title": "Segment 7 (pages 51-58)",
      "start_page": 51,
      "end_page": 58,
      "summary": "✦ Python has special syntax called unpacking for assigning multiple \nThe range built-in function is useful for loops that iterate over a set of \nflavor_list = ['vanilla', 'chocolate', 'pecan', 'strawberry']\nOften, you’ll want to iterate over a list and also know the index of \nflavor_list or range.\nenumerate wraps any iterator with a lazy generator (see Item 30: \npairs of the loop index and the next value from the given iterator.\nit = enumerate(flavor_list)\nstatement (see Item 6: “Prefer Multiple Assignment Unpacking Over \nfor i, flavor in enumerate(flavor_list):\nfor i, flavor in enumerate(flavor_list, 1):\n✦ enumerate provides concise syntax for looping over an iterator and \ngetting the index of each item from the iterator as you go.\n✦ Prefer enumerate instead of looping over a range and indexing into a \nItem 8: Use zip to Process Iterators in Parallel\nprint(counts)\nlist by their indexes.\nTo iterate over both lists in parallel, I can iterate \nover the length of the names source list:\nindexes into names and counts make the code hard to read.\nItem 8: Use zip to Process Iterators in Parallel \nTo make this code clearer, Python provides the zip built-in function.\nzip wraps two or more iterators with a lazy generator.\ncode is much cleaner than the code for indexing into multiple lists:\nfor name, count in zip(names, counts):\nzip consumes the iterators it wraps one item at a time, which means \nHowever, beware of zip’s behavior when the input iterators are of \nRunning zip on the two input lists \nfor name, count in zip(names, counts):\nIf you don’t expect the lengths of the lists passed to zip to \nfor name, count in itertools.zip_longest(names, counts):\n✦ The zip built-in function can be used to iterate over multiple itera-\n✦ zip truncates its output silently to the shortest iterator if you supply \n✦ Use the zip_longest function from the itertools built-in mod-\nule if you want to use zip on iterators of unequal lengths without \nItem 9: Avoid else Blocks After for and while Loops\na loop’s repeated interior block:\nprint('Loop', i)\nprint('Else block!')\nLoop 0\nLoop 1\nLoop 2\nSurprisingly, the else block runs immediately after the loop finishes.\nItem 9: Avoid else Blocks After for and while Loops \nUsing a break statement in a loop actually skips the else block:\nprint('Loop', i)\nprint('Else block!')\nLoop 0\nLoop 1\nAnother surprise is that the else block runs immediately if you loop \nprint('For Else block!')\nThe else block also runs when while loops are initially False:\nprint('While Else block!')\nThe rationale for these behaviors is that else blocks after loops are \ncoprime because the loop doesn’t encounter a break:\nprint('Not coprime')\nprint('Coprime')\nYou should avoid using else blocks after loops entirely.\nfollow for and while loop interior blocks.\n✦ The else block after a loop runs only if the loop body did not encoun-\n✦ Avoid using else blocks after loops because their behavior isn’t ",
      "keywords": [
        "Item",
        "loop",
        "block",
        "list",
        "count",
        "zip",
        "flavor",
        "enumerate",
        "Python",
        "range",
        "Prefer enumerate",
        "coprime",
        "Multiple Assignment Unpacking",
        "Prefer Multiple Assignment",
        "Pythonic Thinking"
      ],
      "concepts": [
        "loops",
        "item",
        "code",
        "counting",
        "list",
        "names",
        "enumerate",
        "iterate",
        "iterating",
        "assignment"
      ],
      "similar_chapters": [
        {
          "book": "Effective-Python",
          "chapter": 14,
          "title": "",
          "score": 0.715,
          "base_score": 0.565,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 8,
          "title": "",
          "score": 0.595,
          "base_score": 0.595,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 6,
          "title": "",
          "score": 0.56,
          "base_score": 0.41,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 2,
          "title": "",
          "score": 0.499,
          "base_score": 0.499,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 9,
          "title": "",
          "score": 0.49,
          "base_score": 0.49,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "loop",
          "zip",
          "block",
          "enumerate",
          "loops"
        ],
        "semantic": [],
        "merged": [
          "loop",
          "zip",
          "block",
          "enumerate",
          "loops"
        ]
      },
      "topic_id": 5,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.2828981234272723,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:03.223724+00:00"
      }
    },
    {
      "chapter_number": 8,
      "title": "Segment 8 (pages 59-69)",
      "start_page": 59,
      "end_page": 69,
      "summary": "def make_lemonade(count):\ncount = fresh_fruit.get('lemon', 0)\nif count:\nmake_lemonade(count)\nif count := fresh_fruit.get('lemon', 0):\nmake_lemonade(count)\nItem 10: Prevent Repetition with Assignment Expressions \ndef make_cider(count):\ncount = fresh_fruit.get('apple', 0)\nif count >= 4:\nmake_cider(count)\nassignment of count puts distracting emphasis on that variable.\nif (count := fresh_fruit.get('apple', 0)) >= 4:\nmake_cider(count)\ndef slice_bananas(count):\ndef make_smoothies(count):\ncount = fresh_fruit.get('banana', 0)\nif count >= 2:\npieces = slice_bananas(count)\ncount = fresh_fruit.get('banana', 0)\nif count >= 2:\npieces = slice_bananas(count)\nif (count := fresh_fruit.get('banana', 0)) >= 2:\npieces = slice_bananas(count)\nItem 10: Prevent Repetition with Assignment Expressions \nif (count := fresh_fruit.get('banana', 0)) >= 2:\npieces = slice_bananas(count)\ncount = fresh_fruit.get('banana', 0)\nif count >= 2:\npieces = slice_bananas(count)\ncount = fresh_fruit.get('apple', 0)\nif count >= 4:\nto_enjoy = make_cider(count)\ncount = fresh_fruit.get('lemon', 0)\nif count:\nto_enjoy = make_lemonade(count)\nif (count := fresh_fruit.get('banana', 0)) >= 2:\npieces = slice_bananas(count)\nelif (count := fresh_fruit.get('apple', 0)) >= 4:\nto_enjoy = make_cider(count)\nelif count := fresh_fruit.get('lemon', 0):\nto_enjoy = make_lemonade(count)\nThe version that uses assignment expressions is only five lines shorter \ndef make_juice(fruit, count):\nfor fruit, count in fresh_fruit.items():\nbatch = make_juice(fruit, count)\nanother at the end of the loop to replenish the list of delivered fruit.\nItem 10: Prevent Repetition with Assignment Expressions \nfor fruit, count in fresh_fruit.items():\nbatch = make_juice(fruit, count)\nfor fruit, count in fresh_fruit.items():\nbatch = make_juice(fruit, count)\nsider using assignment expressions in order to improve readability.\n✦ Assignment expressions use the walrus operator (:=) to both assign \nclearly by using assignment expressions.\nPython includes syntax for slicing sequences into pieces.\nSlicing \nThe simplest uses for slicing are the built-in types list, str, and \na = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h']\nAll but ends: ['b', 'c', 'd', 'e', 'f', 'g']\nWhen slicing from the start of a list, you should leave out the zero \nWhen slicing to the end of a list, you should leave out the final index \na[:]      # ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h']\nThe result of slicing a list is a whole new list.\nslicing won’t affect the original list:\nNo change: ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h']\nWhen used in assignments, slices replace the specified range \na, b = c[:2]; see Item 6: “Prefer Multiple Assignment Unpacking \nOver Indexing”), the lengths of slice assignments don’t need to be the \nThe values before and after the assigned slice will be preserved.\nBefore  ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h']\nIf you leave out both the start and the end indexes when slicing, you \nIf you assign to a slice with no start or end indexes, you replace the \nprint('After b ', b)      # Same list, so same contents as a\n✦ Slicing is forgiving of start or end indexes that are out of bounds, \nwhich means it’s easy to express slices on the front or back bound-\n✦ Assigning to a list slice replaces that range in the original sequence ",
      "keywords": [
        "count",
        "Assignment Expressions",
        "list",
        "make",
        "fresh",
        "assignment",
        "fruit",
        "pieces",
        "slicing",
        "Expressions",
        "slice",
        "Item",
        "Python",
        "fruit.get",
        "count variable"
      ],
      "concepts": [
        "list",
        "item",
        "count",
        "slices",
        "slicing",
        "assign",
        "assignments",
        "expressions",
        "express",
        "pieces"
      ],
      "similar_chapters": [
        {
          "book": "Effective-Python",
          "chapter": 7,
          "title": "",
          "score": 0.595,
          "base_score": 0.595,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 14,
          "title": "",
          "score": 0.555,
          "base_score": 0.555,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 21,
          "title": "",
          "score": 0.504,
          "base_score": 0.504,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 9,
          "title": "",
          "score": 0.488,
          "base_score": 0.488,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 2,
          "title": "",
          "score": 0.45,
          "base_score": 0.45,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "count",
          "fresh_fruit",
          "count fresh_fruit",
          "fruit",
          "count count"
        ],
        "semantic": [],
        "merged": [
          "count",
          "fresh_fruit",
          "count fresh_fruit",
          "fruit",
          "count count"
        ]
      },
      "topic_id": null,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.3113616581079791,
        "topic_boost": 0.0,
        "timestamp": "2025-12-17T23:07:03.223761+00:00"
      }
    },
    {
      "chapter_number": 9,
      "title": "Segment 9 (pages 70-82)",
      "start_page": 70,
      "end_page": 82,
      "summary": "Item 12: Avoid Striding and Slicing in a Single Expression \nwith start or end indexes, consider using one assignment for striding \n✦ Prefer using positive stride values in slices without start or end \nItem 13: Prefer Catch-All Unpacking Over Slicing\nOne limitation of basic unpacking (see Item 6: “Prefer Multiple Assign-\nWhen I try to take the first two items of the list with basic unpack-\ncar_ages_descending = sorted(car_ages, reverse=True)\nItem 13: Prefer Catch-All Unpacking Over Slicing \nNewcomers to Python often rely on indexing and slicing (see Item 11: \nBut it is possible to use multiple starred expressions in an unpacking \nno leftover items from the sequence being unpacked, the catch-all \nItem 13: Prefer Catch-All Unpacking Over Slicing \nFor example, here I unpack the values from iterating over a range \nto just assign to a static list that matches the unpacking pattern \nBut with the addition of starred expressions, the value of unpack-\n✦ Unpacking assignments may use a starred expression to catch all \nItem 14:  Sort by Complex Criteria Using the key \nThe list built-in type provides a sort method for ordering the items \nBy default, sort will \norder a list’s contents by the natural ascending order of the items.\nFor example, here I sort a list of integers from smallest to largest:\nnumbers.sort()\nThe sort method works for nearly all built-in types (strings, floats, \nWhat does sort do with \nItem 14: Sort by Complex Criteria Using the key Parameter \ntools = [\nSorting objects of this type doesn’t work because the sort method \ntools.sort()\n'Tool'\nto Use heapq for Priority Queues” for an example) to make sort work \nOften there’s an attribute on the object that you’d like to use for sort-\nTo support this use case, the sort method accepts a key param-\nsingle argument, which is an item from the list that is being sorted.\n(i.e., with a natural ordering) to use in place of an item for sorting \neter that enables me to sort the list of Tool objects alphabetically by \ntools.sort(key=lambda x: x.name)\nSorted:   [Tool('chisel',      0.25),\nI can just as easily define another lambda function to sort by weight \nand pass it as the key parameter to the sort method:\ntools.sort(key=lambda x: x.weight)\nprint('By weight:', tools)\ntion to do transformations on the values before sorting.\nhere I apply the lower method to each item in a list of place names to \nplaces.sort()\nplaces.sort(key=lambda x: x.lower())\nSometimes you may need to use multiple criteria for sorting.\nexample, say that I have a list of power tools and I want to sort them \nItem 14: Sort by Complex Criteria Using the key Parameter \nthe sort method.\nto sort the list of power tools first by weight and then by name.\nbutes that I want to sort on in order of priority:\npower_tools.sort(key=lambda x: (x.weight, x.name))\nprint(power_tools)\nparameter to the sort method, it will affect both criteria in the tuple \npower_tools.sort(key=lambda x: (x.weight, x.name),\nprint(power_tools)\nFor numerical values it’s possible to mix sorting directions by using \nthe values in the returned tuple, effectively reversing its sort order \nHere, I use this approach to sort by \npower_tools.sort(key=lambda x: (-x.weight, x.name))\nprint(power_tools)\npower_tools.sort(key=lambda x: (x.weight, -x.name),\nThe sort method of the list type will preserve the order of the input \nlist when the key function returns values that are equal to each \nThis means that I can call sort multiple times on the same \nsort ordering of weight descending and name ascending as I did above \npower_tools.sort(key=lambda x: x.name)   # Name ascending\npower_tools.sort(key=lambda x: x.weight, # Weight descending\nprint(power_tools)\nItem 14: Sort by Complex Criteria Using the key Parameter \npower_tools.sort(key=lambda x: x.name)\nprint(power_tools)\nWhen the second sort call by weight descending is made, it sees that \nThis causes the sort \nmethod to put both items into the final result list in the same order \npower_tools.sort(key=lambda x: x.weight,\nprint(power_tools)\nneed to make sure that you execute the sorts in the opposite sequence \nthe sort order to be by weight descending and then by name ascend-\ning, so I had to do the name sort first, followed by the weight sort.\nand using unary negation to mix sort orders, is simpler to read and \nI recommend only using multiple calls to sort if \n✦ The sort method of the list type can be used to rearrange a list’s \n✦ The sort method doesn’t work for objects unless they define a natu-\n✦ The key parameter of the sort method can be used to supply a \nhelper function that returns the value to use for sorting in place of \neach item from the list.\nused to reverse individual sort orders for types that allow it.\n✦ For types that can’t be negated, you can combine many sorting cri-\nteria together by calling the sort method multiple times using dif-\nferent key functions and reverse values, in the order of lowest rank \nWhen I created the dictionary the keys were in the order 'cat', 'dog', \nbut when I printed it the keys were in the reverse order 'dog', 'cat'.\nItem 15: Be Cautious When Relying on dict Insertion Ordering \non iteration order, including keys, values, items, and popitem, would \nprint(list(baby_names.keys()))\nprint(list(baby_names.values()))\nprint(list(baby_names.items()))\nprint(list(baby_names.keys()))\nprint(list(baby_names.values()))\nprint(list(baby_names.items()))\nprint(baby_names.popitem())  # Last item inserted",
      "keywords": [
        "Tool",
        "Sort",
        "list",
        "Item",
        "key",
        "sort method",
        "Unpacking",
        "Python",
        "order",
        "key Parameter",
        "key function",
        "method",
        "weight",
        "descending",
        "power"
      ],
      "concepts": [
        "sorted",
        "printed",
        "orders",
        "ordering",
        "item",
        "tools",
        "multiple",
        "lists",
        "value",
        "unpacking"
      ],
      "similar_chapters": [
        {
          "book": "Effective-Python",
          "chapter": 2,
          "title": "",
          "score": 0.782,
          "base_score": 0.632,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 43,
          "title": "",
          "score": 0.61,
          "base_score": 0.46,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 20,
          "title": "",
          "score": 0.515,
          "base_score": 0.515,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 14,
          "title": "",
          "score": 0.496,
          "base_score": 0.496,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 1,
          "title": "",
          "score": 0.495,
          "base_score": 0.495,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "sort",
          "sort method",
          "power_tools",
          "key",
          "weight"
        ],
        "semantic": [],
        "merged": [
          "sort",
          "sort method",
          "power_tools",
          "key",
          "weight"
        ]
      },
      "topic_id": 4,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.36544377703131,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:03.223805+00:00"
      }
    },
    {
      "chapter_number": 10,
      "title": "Segment 10 (pages 83-98)",
      "start_page": 83,
      "end_page": 98,
      "summary": "for key, value in kwargs.items():\nprint('%s = %s' % (key, value))\nfor key, value in kwargs.items():\nprint(f'{key} = {value}')\nClasses also use the dict type for their instance dictionaries.\nfor key, value in a.__dict__.items():\nprint('%s = %s' % (key, value))\nfor key, value in a.__dict__.items():\nprint(f'{key} = {value}')\nnames = list(votes.keys())\nnames.sort(key=votes.get, reverse=True)\nfirst key must be the winner:\ncollections.abc built-in module to define a new dictionary-like class \ndef __getitem__(self, key):\nreturn self.data[key]\ndef __setitem__(self, key, value):\nself.data[key] = value\ndef __delitem__(self, key):\ndel self.data[key]\nkeys = list(self.data.keys())\nkeys.sort()\nvalue passed to get_winner is a dict instance and not a MutableMapping \nwith dictionary-like behavior (see Item 90: “Consider Static Analysis \ndef populate_ranks(votes: Dict[str, int],\nnames = list(votes.keys())\nnames.sort(key=votes.get, reverse=True)\nItem 16: Prefer get Over in and KeyError to Handle Missing Dictionary Keys 65\ninstance’s contents will occur in the same order in which the keys \n✦ Python makes it easy to define objects that act like dictionaries but \nfor the dict type at runtime, or require dict values using type anno-\nMissing Dictionary Keys\nies are accessing, assigning, and deleting keys and their associated \nTo increment the counter for a new vote, I need to see if the key exists, \ninsert the key with a default counter value of zero if it’s missing, and \nThis requires accessing the key \nif key in counters:\ncount = counters[key]\ncounters[key] = count + 1\ndictionaries raise a KeyError exception when you try to get the value \ncount = counters[key]\ncounters[key] = count + 1\nThis flow of fetching a key that exists or returning a default value \nis so common that the dict built-in type provides the get method to \ncount = counters.get(key, 0)\ncounters[key] = count + 1\nif key not in counters:\ncounters[key] = 0\ncounters[key] += 1\nif key in counters:\ncounters[key] += 1\ncounters[key] = 1\nItem 16: Prefer get Over in and KeyError to Handle Missing Dictionary Keys 67\ncounters[key] += 1\ncounters[key] = 1\nThus, for a dictionary with simple types, using the get method is the \nWhat if the values of the dictionary are a more complex type, like a \ning a list of names with each key:\nkey = 'brioche'\nif key in votes:\nnames = votes[key]\nvotes[key] = names = []\nRelying on the in expression requires two accesses if the key is pres-\nent, or one access and one assignment if the key is missing.\nvalue for each key can be assigned blindly to the default value of an \nempty list if the key doesn’t already exist.\nstatement (votes[key] = names = []) populates the key in one line \nthe dictionary value is a list.\nThis approach requires one key access \nif the key is present, or one key access and one assignment if it’s \nnames = votes[key]\nvotes[key] = names = []\nSimilarly, you can use the get method to fetch a list value when the \nkey is present, or do one fetch and one assignment if the key isn’t \nnames = votes.get(key)\nvotes[key] = names = []\nif (names := votes.get(key)) is None:\nvotes[key] = names = []\nThe dict type also provides the setdefault method to help shorten \nsetdefault tries to fetch the value of a key \nIf the key isn’t present, the method assigns that key \nAnd then the method returns the value \nfor that key: either the originally present value or the newly inserted \nnames = votes.setdefault(key, [])\nItem 16: Prefer get Over in and KeyError to Handle Missing Dictionary Keys 69\nsetdefault is assigned directly into the dictionary when the key is \nkey = 'foo'\ndata.setdefault(key, value)\ning a new default value for each key I access with setdefault.\nvalues instead of lists of who voted: Why not also use the setdefault \ncount = counters.setdefault(key, 0)\ncounters[key] = count + 1\nalways need to assign the key in the dictionary to a new value \nwhereas using setdefault requires one access and two assignments.\nshortest way to handle missing dictionary keys, such as when the \nsetdefault to Handle Missing Items in Internal State”).\n✦ There are four common ways to detect and handle missing keys \n✦ The get method is best for dictionaries that contain basic types \n✦ When the setdefault method of dict seems like the best fit for your \nvariety of ways to handle missing keys (see Item 16: “Prefer get Over \nin and KeyError to Handle Missing Dictionary Keys”).\nI can use the setdefault method to add new cities to the sets, whether \nvisits.setdefault('France', set()).add('Arles')  # Short\nvalue when a key doesn’t exist.\nthat will return the default value to use each time a key is missing \n(an example of Item 38: “Accept Functions Instead of Classes for Sim-\nassume that accessing any key in the data dictionary will always \ntions (see Item 18: “Know How to Construct Key-Dependent Default \nValues with __missing__,” Item 43: “Inherit from collections.abc for \ntial keys, then you should prefer using a defaultdict instance from \n✦ If a dictionary of arbitrary keys is passed to you, and you don’t con-\nItem 18: Know How to Construct Key-Dependent Default Values \nItem 18:  Know How to Construct Key-Dependent \nThe built-in dict type’s setdefault method results in shorter code \nwhen handling missing keys in some specific circumstances (see Item \n16: “Prefer get Over in and KeyError to Handle Missing Dictionary \n(see Item 17: “Prefer defaultdict Over setdefault to Handle Missing \nand checking for the presence of keys using the get method and an \nWhen the file handle already exists in the dictionary, this code makes \nexist, the dictionary is accessed once by get, and then it is assigned \nfor other  dictionary-like implementations; see Item 43: “Inherit from \nhelper function that defaultdict calls doesn’t know which specific key \nItem 18: Know How to Construct Key-Dependent Default Values \ndling missing keys.\ndef __missing__(self, key):\nvalue = open_picture(key)\nself[key] = value\nWhen the pictures[path] dictionary access finds that the path key \nisn’t present in the dictionary, the __missing__ method is called.\nmethod must create the new default value for the key, insert it into \n✦ The setdefault method of dict is a bad fit when creating the default \non the key being accessed.\nin order to construct default values that must know which key was ",
      "keywords": [
        "key",
        "Missing Dictionary Keys",
        "Handle Missing Dictionary",
        "Handle Missing Items",
        "Item",
        "Handle Missing",
        "dictionary",
        "dict",
        "Dictionary Keys",
        "handle missing keys",
        "ranks",
        "Missing",
        "keys",
        "dict type",
        "Missing Dictionary"
      ],
      "concepts": [
        "keys",
        "types",
        "typed",
        "typing",
        "item",
        "classes",
        "values",
        "dictionaries",
        "dictionary",
        "vote"
      ],
      "similar_chapters": [
        {
          "book": "Effective-Python",
          "chapter": 17,
          "title": "",
          "score": 0.743,
          "base_score": 0.593,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 21,
          "title": "",
          "score": 0.59,
          "base_score": 0.44,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 34,
          "title": "",
          "score": 0.55,
          "base_score": 0.4,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 6,
          "title": "",
          "score": 0.52,
          "base_score": 0.52,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 5,
          "title": "",
          "score": 0.477,
          "base_score": 0.477,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "key",
          "missing",
          "dictionary",
          "keys",
          "counters"
        ],
        "semantic": [],
        "merged": [
          "key",
          "missing",
          "dictionary",
          "keys",
          "counters"
        ]
      },
      "topic_id": 2,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.2892361198233884,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:03.223854+00:00"
      }
    },
    {
      "chapter_number": 11,
      "title": "Segment 11 (pages 99-114)",
      "start_page": 99,
      "end_page": 114,
      "summary": "Functions\nfunction.\nItem 19:  Never Unpack More Than Three Variables \nWhen Functions Return Multiple Values\ntions to seemingly return more than one value.\nfunction that appears to return two values:\nminimum, maximum = get_stats(lengths)  # Two return values\nThe way this works is that multiple values are returned together in a \nThe calling code then unpacks the returned tuple by \nhow an unpacking statement and multiple-return function work the \ndef my_function():\nreturn 1, 2\nfirst, second = my_function()\nMultiple return values can also be received by starred expressions for \nItem 19: Never Unpack More Than Three Return Values \nfunction to also calculate these statistics and return them in the \nreturn minimum, maximum, average, median, count\nFirst, all the return values \nUsing a large number of return values is extremely error \nSecond, the line that calls the function and unpacks the values is \nables when unpacking the multiple return values from a function.\nThese could be individual values from a three-tuple, two variables \nneed to unpack more return values than that, you’re better off defin-\nfunction return an instance of that instead.\n✦ You can have functions return multiple values by putting them in a \n✦ Multiple return values from a function can also be unpacked by \nItem 20: Prefer Raising Exceptions to Returning None\nmers to give special meaning to the return value of None.\nFor example, say I want a helper function \nreturn None\nCode using this function can interpret the return value accordingly:\nItem 20: Prefer Raising Exceptions to Returning None \nIf the denominator is not zero, the function returns zero.\nproblem is that a zero return value can cause issues when you evalu-\nonly looking for None (see Item 5: “Write Helper Functions Instead of \nThis misinterpretation of a False-equivalent return value is a common \nreturning None from a function like careful_divide is error prone.\nThe first way is to split the return value into a two-tuple (see Item 19: \n“Never Unpack More Than Three Variables When Functions Return \nCallers of this function have to unpack the tuple.\nThe caller no longer requires a condition on the return value of the \nfunction.\nInstead, it can assume that the return value is always \nYou can specify that a function’s return value will \nItem 21: Know How Closures Interact with Variable Scope \n✦ Functions that return None to indicate special meaning are error \n✦ Raise exceptions to indicate special situations instead of returning \n✦ Type annotations can be used to make it clear that a function will \nnever return the value None, even in special situations.\nA common way to do this is to pass a helper function as the key argu-\nThe helper’s return value will \nbe used as the value for sorting each item in the list.\ndef sort_priority(values, group):\nvalues.sort(key=helper)\nThis function works for simple inputs:\nnumbers = [8, 3, 1, 2, 5, 4, 7, 6]\nsort_priority(numbers, group)\nprint(numbers)\n■Python supports closures—that is, functions that refer to variables \nfunction is able to access the group argument for sort_priority.\narguments to other functions, compare them in expressions and \na closure function as the key argument.\nThis is why the return \nvalue from the helper closure causes the sort order to have two \nIt’d be nice if this function returned whether higher-priority items \nfunction for deciding which group each number is in.\nthe function can return the flag value after it’s been modified by the \ndef sort_priority2(numbers, group):\nreturn found\nItem 21: Know How Closures Interact with Variable Scope \nI can run the function on the same inputs as before:\nfound = sort_priority2(numbers, group)\nprint(numbers)\nThe sorted results are correct, which means items from group were \n1. The current function’s scope.\n2. Any enclosing scopes (such as other containing functions).\n4. The built-in scope (that contains functions like len and str).\nAssigning a value to a variable works differently.\nnewly defined variable is the function that contains the assignment.\nThis assignment behavior explains the wrong return value of the \nsort_priority2 function.\ndef sort_priority2(numbers, group):\nreturn found\nprevents local variables in a function from polluting the containing \nOtherwise, every assignment within a function would put \nHere, I define the same function again, now using nonlocal:\ndef sort_priority3(numbers, group):\nreturn found\ntion against using nonlocal for anything beyond simple functions.\neasier to read (see Item 38: “Accept Functions Instead of Classes for \nItem 22: Reduce Visual Noise with Variable Positional Arguments \n✦ Closure functions can refer to variables from any of the scopes in \nfunctions.\nItem 22:  Reduce Visual Noise with Variable Positional \nAccepting a variable number of positional arguments can make a \nof arguments, I would need a function that takes a message and a \ndef log(message, values):\nMy numbers are: 1, 2\ndef log(message, *values):  # The only difference\nMy numbers are: 1, 2\nfunction like log, I can do this by using the * operator.\nPython to pass items from the sequence as positional arguments to \nthe function:\nturned into a tuple before they are passed to a function.\nthat if the caller of a function uses the * operator on a generator, it \nItem 22: Reduce Visual Noise with Variable Positional Arguments \n*args is ideal for function calls that pass many literals or variable \narguments to a function in the future without migrating every caller.\ndef log(sequence, message, *values):\nkeyword-only arguments when you want to extend functions that \n✦ Functions can accept a variable number of positional arguments by \n✦ You can use the items from a sequence as the positional arguments \nfor a function with the * operator.\n✦ Adding new positional parameters to functions that accept *args \narguments by position when calling a function:\nreturn number % divisor\nAll normal arguments to Python functions can also be passed by \ncall a function like remainder, you can do this by using the ** opera-\nthe corresponding keyword arguments of the function:\n'number': 20,\narguments in the function call, as long as no argument is repeated:\n'number': 20,\nfor key, value in kwargs.items():",
      "keywords": [
        "function",
        "Item",
        "Functions",
        "Functions Return Multiple",
        "numbers",
        "Python",
        "arguments",
        "Positional Arguments",
        "variable",
        "Variable Positional Arguments",
        "Functions Return",
        "Scope",
        "Variables",
        "argument",
        "result"
      ],
      "concepts": [
        "functions",
        "function",
        "item",
        "numbers",
        "returned",
        "variables",
        "variable",
        "argument",
        "arguments",
        "scope"
      ],
      "similar_chapters": [
        {
          "book": "Effective-Python",
          "chapter": 14,
          "title": "",
          "score": 0.517,
          "base_score": 0.517,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 9,
          "title": "",
          "score": 0.491,
          "base_score": 0.491,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 13,
          "title": "",
          "score": 0.455,
          "base_score": 0.455,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 15,
          "title": "",
          "score": 0.426,
          "base_score": 0.426,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 8,
          "title": "",
          "score": 0.413,
          "base_score": 0.413,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "return",
          "function",
          "arguments",
          "return value",
          "group"
        ],
        "semantic": [],
        "merged": [
          "return",
          "function",
          "arguments",
          "return value",
          "group"
        ]
      },
      "topic_id": null,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.34129775463783363,
        "topic_boost": 0.0,
        "timestamp": "2025-12-17T23:07:03.223897+00:00"
      }
    },
    {
      "chapter_number": 12,
      "title": "Segment 12 (pages 115-125)",
      "start_page": 115,
      "end_page": 125,
      "summary": "The flexibility of keyword arguments provides three significant \nThe first benefit is that keyword arguments make the function call \nwith keyword arguments, number=20 and divisor=7 make it immedi-\nThe second benefit of keyword arguments is that they can have \ndefault values specified in the function definition.\nprovide this behavior in the same function by adding an argument for \ndef flow_rate(weight_diff, time_diff, period):\nThe problem is that now I need to specify the period argument every \ntime I call the function, even in the common case of flow rate per sec-\nItem 23: Provide Optional Behavior with Keyword Arguments \nTo make this less noisy, I can give the period argument a default \ndef flow_rate(weight_diff, time_diff, period=1):\nThe period argument is now optional:\nThe third reason to use keyword arguments is that they provide a \nThe default argument value for units_per_kg is 1, which makes the \nspecify the new keyword argument to see the new behavior:\nProviding backward compatibility using optional keyword arguments \nSupplying optional arguments positionally can be confusing because \npractice is to always specify optional arguments using the keyword \nnames and never pass them as positional arguments.\n✦ Function arguments can be specified by position or by keyword.\n✦ Keywords make it clear what the purpose of each argument is when \nit would be confusing with only positional arguments.\n✦ Keyword arguments with default values make it easy to add new \n✦ Optional keyword arguments should always be passed by keyword \nDefault Arguments\nSometimes you need to use a non-static type as a keyword  argument’s \nI want the message to include the time when the function was \narguments are reevaluated each time the function is called:\nA default argument value is evaluated only once per module \nItem 24: Specify Dynamic Default Arguments in Docstrings \nUsing None for default argument values is especially important when \ndecode because default argument values are evaluated only once (at \nThe fix is to set the keyword argument default value to None and then \nItem 25: Clarity with Keyword-Only and Positional-Only Arguments \nargument is marked as having an Optional value that is a datetime.\n✦ A default argument value is evaluated only once: during function \n✦ Use None as the default value for any keyword argument that has a \n✦ Using None to represent keyword argument default values also \nPositional-Only Arguments\nPassing arguments by keyword is a powerful feature of Python func-\nThe flexibility of keyword arguments enables you to write \nOther times, I want to ignore OverflowError exceptions and return \nean arguments that control the exception-ignoring behavior.\nreadability of this code is to use keyword arguments.\nThen, callers can use keyword arguments to specify which of the \nresult = safe_division_b(1.0, 10**500, ignore_overflow=True)\nThe problem is, since these keyword arguments are optional behavior, \nthere’s nothing forcing callers to use keyword arguments for clarity.\nthe old way with positional arguments:\narguments.\nThese arguments can only be supplied by keyword, never \nHere, I redefine the safe_division function to accept keyword-only \narguments.\nof positional arguments and the beginning of keyword-only \narguments:\ndef safe_division_c(number, divisor, *,  # Changed\nNow, calling the function with positional arguments for the keyword \nTypeError: safe_division_c() takes 2 positional arguments but 4 \nBut keyword arguments and their default values will work as expected \nresult = safe_division_c(1.0, 0, ignore_zero_division=True)\nItem 25: Clarity with Keyword-Only and Positional-Only Arguments \nthis function: Callers may specify the first two required arguments \ning callers that specified the number or divisor arguments using \nTypeError: safe_division_c() got an unexpected keyword argument \narguments.\nThese arguments can be supplied only by position and \nnever by keyword (the opposite of the keyword-only arguments \nHere, I redefine the safe_division function to use positional-only \narguments for the first two required parameters.\nI can verify that this function works when the required arguments \nTypeError: safe_division_d() got some positional-only arguments \n¯passed as keyword arguments: 'numerator, denominator'\nNow, I can be sure that the first two required positional arguments \nin the definition of the safe_division_d function are decoupled from \nOne notable consequence of keyword- and positional-only arguments \nthe default for all function arguments in Python).\nanother optional parameter to safe_division that allows callers to \nItem 25: Clarity with Keyword-Only and Positional-Only Arguments \n✦ Keyword-only arguments force callers to supply certain arguments \nKeyword-only arguments are defined after a \n✦ Positional-only arguments ensure that callers can’t supply \nPositional-only arguments are defined before a single / in the argu-\nmay be supplied by position or keyword, which is the default for \ncan access and modify input arguments, return values, and raised \nFor example, say that I want to print the arguments and return value ",
      "keywords": [
        "arguments",
        "keyword arguments",
        "default",
        "keyword",
        "argument",
        "function",
        "division",
        "safe",
        "Positional-Only Arguments",
        "diff",
        "default argument",
        "keyword argument default",
        "Dynamic Default Arguments",
        "optional keyword arguments",
        "time"
      ],
      "concepts": [
        "argument",
        "functions",
        "function",
        "functionality",
        "returned",
        "item",
        "defaults",
        "result",
        "optional",
        "positional"
      ],
      "similar_chapters": [
        {
          "book": "Effective-Python",
          "chapter": 42,
          "title": "",
          "score": 0.441,
          "base_score": 0.441,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 2,
          "title": "",
          "score": 0.4,
          "base_score": 0.4,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 11,
          "title": "",
          "score": 0.399,
          "base_score": 0.399,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 9,
          "title": "",
          "score": 0.391,
          "base_score": 0.391,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 21,
          "title": "",
          "score": 0.378,
          "base_score": 0.378,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "arguments",
          "keyword",
          "keyword arguments",
          "positional arguments",
          "argument"
        ],
        "semantic": [],
        "merged": [
          "arguments",
          "keyword",
          "keyword arguments",
          "positional arguments",
          "argument"
        ]
      },
      "topic_id": null,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.3030006119645567,
        "topic_boost": 0.0,
        "timestamp": "2025-12-17T23:07:03.223932+00:00"
      }
    },
    {
      "chapter_number": 13,
      "title": "Segment 13 (pages 126-133)",
      "start_page": 126,
      "end_page": 133,
      "summary": "Item 26: Define Function Decorators with functools.wraps \nthrough all parameters to the wrapped function:\nI can apply this decorator to a function by using the @ symbol:\nThe decorated function runs the wrapper code before and after \nfibonacci(4)\nfibonacci((0,), {}) -> 0\nprint(fibonacci)\n<function trace.<locals>.wrapper at 0x108955dc0>\nThe trace function returns the \nThe wrapper function is what’s \nFor example, the help built-in function is useless when called on the \ndecorated fibonacci function.\nHelp on function wrapper in module __main__:\nItem 26: Define Function Decorators with functools.wraps \nNow, running the help function produces the expected result, even \nthough the function is decorated:\nHelp on function fibonacci in module __main__:\nBeyond these examples, Python functions have many other standard \n✦ Decorators in Python are syntax to allow one function to modify \nComprehensions \nfunction.\nThe result of a call to a generator function can be used any-\nItem 27:  Use Comprehensions Instead of map \nThese expressions are called list comprehensions.\nin a list.\nWith a list comprehension, I can achieve the same outcome by specify-\nsquares = [x**2 for x in a]  # List comprehension\nUnless you’re applying a single-argument function, list comprehen-\nsions are also clearer than the map built-in function for simple cases.\nmap requires the creation of a lambda function for the computation, \nUnlike map, list comprehensions let you easily filter items from the \nthe list comprehension after the loop:\nThe filter built-in function can be used along with map to achieve the \n✦ List comprehensions are clearer than the map and filter built-in \n✦ List comprehensions allow you to easily skip items from the input \nlist, a behavior that map doesn’t support without help from filter.\nBeyond basic usage (see Item 27: “Use Comprehensions Instead of map \nand filter”), comprehensions support multiple levels of looping.\nexample, say that I want to simplify a matrix (a list containing other \nHere, I do this with a list \nloops in a comprehension.\nIf this comprehension included another loop, it would get so long that \nmy_lists = [\nflat = [x for sublist1 in my_lists\nthan the three-level-list comprehension:\nComprehensions support multiple if conditions.\nsay that I want to filter a list of numbers to only even values greater \nThese two list comprehensions are equivalent:\nExpressing this with a list comprehension does not require a lot of ",
      "keywords": [
        "fibonacci",
        "Function",
        "list",
        "Comprehensions",
        "Variable Positional Arguments",
        "list comprehensions",
        "Define Function Decorators",
        "Item",
        "wrapper",
        "Reduce Visual Noise",
        "map",
        "filter",
        "decorator",
        "squares",
        "Visual Noise"
      ],
      "concepts": [
        "comprehensions",
        "comprehension",
        "function",
        "functions",
        "list",
        "item",
        "prints",
        "loops",
        "filter",
        "filtered"
      ],
      "similar_chapters": [
        {
          "book": "Effective-Python",
          "chapter": 24,
          "title": "",
          "score": 0.706,
          "base_score": 0.556,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 18,
          "title": "",
          "score": 0.654,
          "base_score": 0.504,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 16,
          "title": "",
          "score": 0.654,
          "base_score": 0.504,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 19,
          "title": "",
          "score": 0.534,
          "base_score": 0.384,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 22,
          "title": "",
          "score": 0.519,
          "base_score": 0.369,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "comprehensions",
          "list",
          "function",
          "map",
          "comprehension"
        ],
        "semantic": [],
        "merged": [
          "comprehensions",
          "list",
          "function",
          "map",
          "comprehension"
        ]
      },
      "topic_id": 1,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.31232058835751014,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:03.223979+00:00"
      }
    },
    {
      "chapter_number": 14,
      "title": "Segment 14 (pages 134-147)",
      "start_page": 134,
      "end_page": 147,
      "summary": "helper function (see Item 30: “Consider Generators Instead of Return-\nexpression for a comprehension.\ncomprehension’s value expression:\nresult = {name: tenth for name, count in stock.items()\nfor count in stock.values():  # Leaks loop variable\nprint(f'Last item of {list(stock.values())} is {count}')\nator expressions (see Item 32: “Consider Generator Expressions for \ngenerator expressions to reuse the value from one condition else-\na comprehension or generator expression’s condition, you should \nItem 30:  Consider Generators Instead of Returning \nis to return a list of items.\nItem 30: Consider Generators Instead of Returning Lists \nThere is one line for creating the result list and another \nGenerators \nare produced by functions that use yield expressions.\ngenerator function that produces the same results as before:\ndef index_words_iter(text):\nWhen called, a generator function does not actually run but instead \nimmediately returns an iterator.\nfunction, the iterator advances the generator to its next yield expres-\nEach value passed to yield by the generator is returned by the \niterator to the caller:\nit = index_words_iter(address)\nThe index_words_iter function is significantly easier to read because \ntor returned by the generator to a list by passing it to the list built-in \nfunction if necessary (see Item 32: “Consider Generator Expressions \nresult = list(index_words_iter(address))\nFor example, here I define a generator that streams input from \nresults (see Item 36: “Consider itertools for Working with Iterators \nprint(list(results))\nItem 31: Be Defensive When Iterating Over Arguments \nmust be aware that the iterators returned are stateful and can’t be \nreused (see Item 31: “Be Defensive When Iterating Over Arguments”).\nfunction return a list of accumulated results.\n✦ The iterator returned by a generator produces the set of values \npassed to yield expressions within the generator function’s body.\nItem 31: Be Defensive When Iterating Over Arguments\nimportant to iterate over that list multiple times.\nTo do this, I need a normalization function that sums the inputs to \nThis function works as expected when given a list of visits:\nrequirements (see Item 30: “Consider Generators Instead of Returning \nSurprisingly, calling normalize on the read_visits generator’s return \nThis behavior occurs because an iterator produces its results only \nIf you iterate over an iterator or a generator that has \nalready exhausted iterator.\nfunctions can’t tell the difference between an iterator that has no out-\nput and an iterator that had output and is now exhausted.\nTo solve this problem, you can explicitly exhaust an input iterator and \nYou can then iterate over \nsame function as before, but it defensively copies the input iterator:\nnumbers_copy = list(numbers)  # Copy the iterator\nItem 31: Be Defensive When Iterating Over Arguments \nNow the function works correctly on the read_visits generator’s \nThe problem with this approach is that the copy of the input iterator’s \nCopying the iterator could cause \ntion that returns a new iterator each time it’s called:\ndef normalize_func(get_iter):\nfor value in get_iter():  # New iterator\nthe generator and produces a new iterator each time:\ncontainer class that implements the iterator protocol.\nThe iterator protocol is how Python for loops and related expressions \nThe iter built-in \nfunction calls the foo.__iter__ special method in turn.\nThe __iter__ \nmethod must return an iterator object (which itself implements the \nnext built-in function on the iterator object until it’s exhausted (indi-\nas a generator.\nHere, I define an iterable container class that reads \ndef __iter__(self):\nnormalize the numbers also calls __iter__ to allocate a second iter-\njust iterators.\nto the iter built-in function, iter returns the iterator itself.\ntrast, when a container type is passed to iter, a new iterator object is \nItem 31: Be Defensive When Iterating Over Arguments \niterated over:\nif isinstance(numbers, Iterator):  # Another way to check\nthe full input iterator, as with the normalize_copy function above, but \nyou also need to iterate over the input data multiple times.\nThe function raises an exception if the input is an iterator rather than \nit = iter(visits)\n✦ Beware of functions and methods that iterate over input argu-\nIf these arguments are iterators, you may see \n✦ Python’s iterator protocol defines how containers and iterators inter-\nact with the iter and next built-in functions, for loops, and related \n✦ You can easily define your own iterable container type by imple-\nmenting the __iter__ method as a generator.\n✦ You can detect that a value is an iterator (instead of a container) \nif calling iter on it produces the same value as what you passed \nItem 32:  Consider Generator Expressions for Large \nThe problem with list comprehensions (see Item 27: “Use Comprehen-\ninstances containing one item for each value in input sequences.\nItem 32: Consider Generator Expressions for Large List Comprehensions \na generalization of list comprehensions and generators.\nGenerator \nInstead, generator expressions evaluate to an iterator that yields \none item at a time from the expression.\nYou create a generator expression by putting list-comprehension-like \nHere, I use a generator expression \nThe returned iterator can be advanced one step at a time to produce \nthe next output from the generator expression, as needed (using \nHere, I take the iterator returned by the gen-\nerator expression above and use it as the input for another generator \noperating on a large stream of input, generator expressions are a \nThe only gotcha is that the iterators returned by gener-\niterators more than once (see Item 31: “Be Defensive When Iterating \n✦ List comprehensions can cause problems for large inputs by using \n✦ Generator expressions avoid memory issues by producing outputs \none at a time as iterators.\n✦ Generator expressions can be composed by passing the iterator from \none generator expression into the for subexpression of another.\nItem 33: Compose Multiple Generators with yield from\nlems (see Item 31: “Be Defensive When Iterating Over Arguments”).",
      "keywords": [
        "Generator Expressions",
        "Generator",
        "Item",
        "List Comprehensions",
        "Large List Comprehensions",
        "iterator",
        "list",
        "Comprehensions",
        "Expressions",
        "function",
        "result",
        "batches",
        "iter",
        "generator function",
        "Comprehensions and Generators"
      ],
      "concepts": [
        "iterating",
        "iterate",
        "iteration",
        "result",
        "lists",
        "expressions",
        "expression",
        "function",
        "functions",
        "functionality"
      ],
      "similar_chapters": [
        {
          "book": "Effective-Python",
          "chapter": 7,
          "title": "",
          "score": 0.715,
          "base_score": 0.565,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 6,
          "title": "",
          "score": 0.676,
          "base_score": 0.526,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 2,
          "title": "",
          "score": 0.592,
          "base_score": 0.592,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 16,
          "title": "",
          "score": 0.568,
          "base_score": 0.568,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 15,
          "title": "",
          "score": 0.557,
          "base_score": 0.557,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "iterator",
          "generator",
          "generator expressions",
          "list",
          "iter"
        ],
        "semantic": [],
        "merged": [
          "iterator",
          "generator",
          "generator expressions",
          "list",
          "iter"
        ]
      },
      "topic_id": 5,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.3831906305440534,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:03.224021+00:00"
      }
    },
    {
      "chapter_number": 15,
      "title": "Segment 15 (pages 148-156)",
      "start_page": 148,
      "end_page": 156,
      "summary": "Item 33: Compose Multiple Generators with yield from \nthis by calling a generator for each step of the animation, iterating \nover each generator in turn, and then yielding the deltas from all of \nyield delta\nyield delta\nyield delta\nsingle animation generator:\nThis advanced generator feature allows you to yield all values from \nyield from move(4, 5.0)\nyield from move(2, 3.0)\nyield i\nyield i\nItem 34: Avoid Injecting Data into Generators with send \n✦ The yield from expression allows you to compose multiple nested \nnested generators and yielding their outputs.\nyield expressions provide generator functions with a simple way to \nHere, I use a function to generate an approx-\ndef wave(amplitude, steps):\nyield output\niterating over the wave generator:\nulate the amplitude on each iteration of the generator.\nPython generators support the send method, which upgrades yield \nprovide streaming inputs to a generator at the same time it’s yielding \nNormally, when iterating a generator, the value of the yield \ndef my_generator():\nit = iter(my_generator())\noutput = next(it)       # Get first generator output\nItem 34: Avoid Injecting Data into Generators with send \nnext(it)            # Run generator until it exits\nWhen I call the send method instead of iterating the generator with a \nthe value of the yield expression when the generator is resumed.\never, when the generator first starts, a yield expression has not been \nit = iter(my_generator())\noutput = it.send(None)  # Get first generator output\nit.send('hello!')   # Send value into the generator\nthe wave generator to save the amplitude returned by the yield expres-\nsion and use it to calculate the next generated output:\namplitude = yield output  # Receive next amplitude\namplitude into the wave_modulating generator on each iteration.\nfirst input to send must be None, since a yield expression would not \noutput = it.send(amplitude)\namplitude wasn’t received by the generator until after the initial yield \nway to implement this behavior is by composing multiple generators \nMultiple Generators with yield from”).\nyield from wave(7.0, 3)\nItem 34: Avoid Injecting Data into Generators with send \nyield from wave(2.0, 4)\nyield from wave(10.0, 5)\nmay expect it to also work properly along with the generator send \nthe wave_modulating generator together:\nyield from wave_modulating(3)\nyield from wave_modulating(4)\nyield from wave_modulating(5)\nWhen each yield from expression finishes iterating over a nested gen-\ninitial amplitude from a generator send method call.\nparent generator to output a None value when it transitions between \nchild generators.\ndef wave_cascading(amplitude_it, steps):\nyield output\nI can pass the same iterator into each of the generator functions that \ndef complex_wave_cascading(amplitude_it):\nyield from wave_cascading(amplitude_it, 3)\nyield from wave_cascading(amplitude_it, 4)\nyield from wave_cascading(amplitude_it, 5)\nNow, I can run the composed generator by simply passing in an itera-\nit = complex_wave_cascading(iter(amplitudes))\na generator function).\n✦ The send method can be used to inject data into a generator by giv-\n✦ Using send with yield from expressions may cause surprising \ngenerator output.\n✦ Providing an input iterator to a set of composed generators is a bet-\nple Generators with yield from”) and the send method (see Item 34: ",
      "keywords": [
        "output",
        "generator",
        "yield",
        "delta",
        "Avoid Injecting Data",
        "wave",
        "amplitude",
        "Item",
        "send",
        "yield expression",
        "Avoid Injecting",
        "Injecting Data",
        "run",
        "generator output",
        "expression"
      ],
      "concepts": [
        "generators",
        "generate",
        "generated",
        "outputs",
        "yield",
        "amplitude",
        "send",
        "wave",
        "run",
        "runs"
      ],
      "similar_chapters": [
        {
          "book": "Effective-Python",
          "chapter": 16,
          "title": "",
          "score": 0.559,
          "base_score": 0.559,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 14,
          "title": "",
          "score": 0.557,
          "base_score": 0.557,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 7,
          "title": "",
          "score": 0.452,
          "base_score": 0.452,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 2,
          "title": "",
          "score": 0.442,
          "base_score": 0.442,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 11,
          "title": "",
          "score": 0.426,
          "base_score": 0.426,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "yield",
          "generator",
          "send",
          "amplitude",
          "generators"
        ],
        "semantic": [],
        "merged": [
          "yield",
          "generator",
          "send",
          "amplitude",
          "generators"
        ]
      },
      "topic_id": null,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.2929381949623241,
        "topic_boost": 0.0,
        "timestamp": "2025-12-17T23:07:03.224070+00:00"
      }
    },
    {
      "chapter_number": 16,
      "title": "Segment 16 (pages 157-164)",
      "start_page": 157,
      "end_page": 164,
      "summary": "generator feature is the throw method for re-raising Exception \ninstances within generator functions.\nprint(it.throw(MyError('test error')))\nWhen you call throw, the generator function may catch the injected \nItem 35: Avoid Causing State Transitions in Generators with throw \nprint(it.throw(MyError('test error')))\nthis behavior by defining a generator that relies on the throw method:\nclass Reset(Exception):\nIn this code, whenever the Reset exception is raised by the yield \ntimer generator, which injects exceptions with throw to cause resets, \ncurrent = it.throw(Reset())\nstateful closure (see Item 38: “Accept Functions Instead of Classes for \nSimple Interfaces”) using an iterable container object (see Item 31: “Be \ndef __iter__(self):\nItem 35: Avoid Causing State Transitions in Generators with throw \nfor current in timer:\ntimer.reset()\nan iterable class if you need this type of exceptional behavior.\n✦ A better way to provide exceptional behavior in generators is to use \na class that implements the __iter__ method along with methods to \nItem 36:  Consider itertools for Working with Iterators \nThe itertools built-in module contains a large number of functions \nthat are useful for organizing and interacting with iterators (see Item \n30: “Consider Generators Instead of Returning Lists” and Item 31: “Be \nThe itertools built-in module includes a number of functions for \niterator:\nUse repeat to output a single value forever, or use the second param-\nUse cycle to repeat an iterator’s items forever:\nItem 36: Consider itertools for Working with Iterators and Generators \nit1, it2, it3 = itertools.tee(['first', 'second'], 3)\nThis variant of the zip built-in function (see Item 8: “Use zip to \nProcess Iterators in Parallel”) returns a placeholder value when an \nnormal = list(zip(keys, values))\nit = itertools.zip_longest(keys, values, fillvalue='nope')\nFiltering Items from an Iterator\nThe itertools built-in module includes a number of functions for fil-\ntering items from an iterator.\nfirst_five = itertools.islice(values, 5)\nmiddle_odds = itertools.islice(values, 2, 8, 2)\ntakewhile returns items from an iterator until a predicate function \nit = itertools.takewhile(less_than_seven, values)\niterator until the predicate function returns True for the first time:\nit = itertools.dropwhile(less_than_seven, values)\nItem 36: Consider itertools for Working with Iterators and Generators \nreturns all items from an iterator where a predicate function returns \nprint('Filter:      ', list(filter_result))\nfilter_false_result = itertools.filterfalse(evens, values)\nprint('Filter false:', list(filter_false_result))\nProducing Combinations of Items from Iterators\nThe itertools built-in module includes a number of functions for \nproducing combinations of items from iterators.\naccumulate folds an item from the iterator into a running value by \nsum_reduce = itertools.accumulate(values)\nmodulo_reduce = itertools.accumulate(values, sum_modulo_20)",
      "keywords": [
        "ticks remaining",
        "Item",
        "ticks",
        "yield",
        "remaining",
        "Generators",
        "Iterators",
        "list",
        "Generators generator feature",
        "throw",
        "Reset",
        "function",
        "yield expression",
        "timer",
        "Exception"
      ],
      "concepts": [
        "iterating",
        "iteration",
        "value",
        "item",
        "exception",
        "exceptions",
        "exceptional",
        "lists",
        "resets",
        "functions"
      ],
      "similar_chapters": [
        {
          "book": "Effective-Python",
          "chapter": 18,
          "title": "",
          "score": 0.682,
          "base_score": 0.532,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 13,
          "title": "",
          "score": 0.654,
          "base_score": 0.504,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 32,
          "title": "",
          "score": 0.63,
          "base_score": 0.48,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 19,
          "title": "",
          "score": 0.586,
          "base_score": 0.436,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 22,
          "title": "",
          "score": 0.574,
          "base_score": 0.424,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "itertools",
          "throw",
          "generators",
          "iterator",
          "iterators"
        ],
        "semantic": [],
        "merged": [
          "itertools",
          "throw",
          "generators",
          "iterator",
          "iterators"
        ]
      },
      "topic_id": 1,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.3704504930492908,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:03.224112+00:00"
      }
    },
    {
      "chapter_number": 17,
      "title": "Segment 17 (pages 165-174)",
      "start_page": 165,
      "end_page": 174,
      "summary": "Classes and \nI can define a class to store the names in a dictionary instead of using \nself._grades = {}\nself._grades[name] = []\ndef report_grade(self, name, score):\nself._grades[name].append(score)\ndef average_grade(self, name):\ngrades = self._grades[name]\na list of grades by subject, not just overall.\nthe _grades dictionary to map student names (its keys) to yet another \n(its keys) to a list of grades (its values).\nself._grades[name] = defaultdict(list)  # Inner dict\nreport_grade \ndef report_grade(self, name, subject, grade):\nby_subject = self._grades[name]\ngrade_list = by_subject[subject]\ndef average_grade(self, name):\nby_subject = self._grades[name]\nItem 37: Compose Classes Instead of Nesting Built-in Types \nfor grades in by_subject.values():\ntrack the weight of each score toward the overall grade in the class \ndictionary; instead of mapping subjects (its keys) to a list of grades \nself._grades = {}\nself._grades[name] = defaultdict(list)\ndef report_grade(self, name, subject, score, weight):\nby_subject = self._grades[name]\ngrade_list = by_subject[subject]\ngrade_list.append((score, weight))\nAlthough the changes to report_grade seem simple—just make the \ndef average_grade(self, name):\nby_subject = self._grades[name]\nbuilt-in types like dictionaries, tuples, sets, and lists to a hierarchy of \nclasses.\nweighted grades, so the complexity of creating classes seemed unwar-\na single grade.\nHere, I use the tuple of (score, weight) to track grades in \ngrades = []\ntotal = sum(score * weight for score, weight in grades)\naverage_grade = total / total_weight\ngrades = []\ntotal = sum(score * weight for score, weight, _ in grades)\naverage_grade = total / total_weight\nclasses:\nGrade = namedtuple('Grade', ('score', 'weight'))\nItem 37: Compose Classes Instead of Nesting Built-in Types \nclasses.\nNext, I can write a class to represent a single subject that contains a \nset of grades:\nclass Subject:\nself._grades = []\ndef report_grade(self, score, weight):\nself._grades.append(Grade(score, weight))\ndef average_grade(self):\nfor grade in self._grades:\ntotal += grade.score * grade.weight\ntotal_weight += grade.weight\nThen, I write a class to represent a set of subjects that are being stud-\nclass Student:\nItem 37: Compose Classes Instead of Nesting Built-in Types \ndef average_grade(self):\ntotal += subject.average_grade()",
      "keywords": [
        "Albert Einstein",
        "grade",
        "Albert",
        "Albert Einstein book.report",
        "Subexpressions in Comprehensions",
        "Classes",
        "Einstein",
        "weight",
        "Albert Einstein math",
        "total",
        "Cartesian product",
        "subject",
        "self.",
        "score",
        "Isaac Newton"
      ],
      "concepts": [
        "classes",
        "grades",
        "dictionaries",
        "items",
        "book",
        "subject",
        "list",
        "types",
        "writing",
        "write"
      ],
      "similar_chapters": [
        {
          "book": "Effective-Python",
          "chapter": 10,
          "title": "",
          "score": 0.743,
          "base_score": 0.593,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 21,
          "title": "",
          "score": 0.738,
          "base_score": 0.588,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 34,
          "title": "",
          "score": 0.542,
          "base_score": 0.392,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 2,
          "title": "",
          "score": 0.501,
          "base_score": 0.501,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 19,
          "title": "",
          "score": 0.451,
          "base_score": 0.451,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "_grades",
          "score",
          "self _grades",
          "grades",
          "weight"
        ],
        "semantic": [],
        "merged": [
          "_grades",
          "score",
          "self _grades",
          "grades",
          "weight"
        ]
      },
      "topic_id": 2,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.32694422057262734,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:03.224150+00:00"
      }
    },
    {
      "chapter_number": 18,
      "title": "Segment 18 (pages 175-187)",
      "start_page": 175,
      "end_page": 187,
      "summary": "Chapter 5 Classes and Interfaces\nItem 38:  Accept Functions Instead of Classes for \nabstract class.\nthan classes.\nFunctions work as hooks because Python has first-class \nItem 38: Accept Functions Instead of Classes for Simple Interfaces \nhelper function that uses such a closure as the default value hook:\nChapter 5 Classes and Interfaces\nis to define a small class that encapsulates the state you want to \nclass CountMissing:\nBut in Python, thanks to first-class functions, you can reference \nUsing a helper class like this to provide the behavior of a stateful \npurpose of the CountMissing class is.\ndefaultdict, the class is a mystery.\nTo clarify this situation, Python allows classes to define the __call__ \nclass BetterCountMissing:\n__call__ method indicates that a class’s instances will be used some-\nfor the class’s primary behavior.\nof the class is to act as a stateful closure.\n✦ References to functions and methods in Python are first class, \n✦ The __call__ special method enables instances of a class to be \nclass that provides the __call__ method instead of defining a state-\nIn Python, not only do objects support polymorphism, but classes do \nThis means that many classes \nChapter 5 Classes and Interfaces\nI want a common class to represent the input data.\nsuch a class with a read method that must be defined by subclasses:\nclass InputData:\nclass PathInputData(InputData):\nclass Worker:\ndef __init__(self, input_data):\nclass LineCountWorker(Worker):\nChapter 5 Classes and Interfaces\nThe best way to solve this problem is with class method polymor-\nfor InputData.read, except that it’s for whole classes instead of their \nclass GenericInputData:\nclass PathInputData(GenericInputData):\nGenericWorker class.\nHere, I use the input_class parameter, which \nclass GenericWorker:\ndef __init__(self, input_data):\ndef create_workers(cls, input_class, config):\nfor input_data in input_class.generate_inputs(config):\nChapter 5 Classes and Interfaces\nNote that the call to input_class.generate_inputs above is the \nclass LineCountWorker(GenericWorker):\ndef mapreduce(worker_class, input_class, config):\nworkers = worker_class.create_workers(input_class, config)\n✦ Python only supports a single constructor per class: the __init__ \n✦ Use @classmethod to define alternative constructors for your classes.\n✦ Use class method polymorphism to provide generic ways to build \nItem 40: Initialize Parent Classes with super\nis to directly call the parent class’s __init__ method with the child \nclass MyBaseClass:\ndef __init__(self, value):\nItem 40: Initialize Parent Classes with super \nclass MyChildClass(MyBaseClass):\nFor example, here I define two parent classes that operate \nclass TimesTwo:\nclass PlusFive:\nThis class defines its parent classes in one ordering:\nclass OneWay(MyBaseClass, TimesTwo, PlusFive):\ndef __init__(self, value):\nMyBaseClass.__init__(self, value)\nAnd constructing it produces a result that matches the parent class \nclass AnotherWay(MyBaseClass, PlusFive, TimesTwo):\ndef __init__(self, value):\nMyBaseClass.__init__(self, value)\nChapter 5 Classes and Interfaces\nwhich means this class’s behavior doesn’t match the order of the par-\nbase classes and the __init__ calls is hard to spot, which makes this \nI define two child classes that inherit from MyBaseClass:\nclass TimesSeven(MyBaseClass):\ndef __init__(self, value):\nMyBaseClass.__init__(self, value)\nclass PlusNine(MyBaseClass):\ndef __init__(self, value):\nMyBaseClass.__init__(self, value)\nThen, I define a child class that inherits from both of these classes, \ndef __init__(self, value):\nTimesSeven.__init__(self, value)\nPlusNine.__init__(self, value)\nThe call to the second parent class’s constructor, PlusNine.__init__, \ncauses self.value to be reset back to 5 when MyBaseClass.__init__ gets \nItem 40: Initialize Parent Classes with super \nHere, I create a diamond-shaped class hierarchy again, but this time \nI use super to initialize the parent class:\nclass TimesSevenCorrect(MyBaseClass):\ndef __init__(self, value):\nclass PlusNineCorrect(MyBaseClass):\ndef __init__(self, value):\nThe other parent classes are run in the order specified in \nthe class statement:\ndef __init__(self, value):\nMRO defines for this class.\nThe MRO ordering is available on a class \nChapter 5 Classes and Interfaces\n<class '__main__.MyBaseClass'>\n<class 'object'>\ntheir __init__ functions were called.\nclass ExplicitTrisect(MyBaseClass):\ndef __init__(self, value):\nsuper(ExplicitTrisect, self).__init__(value)\nparameters (__class__ and self) for you when super is called with \nclass AutomaticTrisect(MyBaseClass):\ndef __init__(self, value):\nsuper(__class__, self).__init__(value)\nclass ImplicitTrisect(MyBaseClass):\ndef __init__(self, value):",
      "keywords": [
        "init",
        "Classes",
        "function",
        "Item",
        "data",
        "Parent Classes",
        "Python",
        "method",
        "Functions",
        "workers",
        "key",
        "input",
        "parent class",
        "Interfaces",
        "result"
      ],
      "concepts": [
        "classes",
        "method",
        "functions",
        "function",
        "functionality",
        "value",
        "item",
        "worker",
        "result",
        "python"
      ],
      "similar_chapters": [
        {
          "book": "Effective-Python",
          "chapter": 32,
          "title": "",
          "score": 0.702,
          "base_score": 0.552,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 16,
          "title": "",
          "score": 0.682,
          "base_score": 0.532,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 13,
          "title": "",
          "score": 0.654,
          "base_score": 0.504,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 22,
          "title": "",
          "score": 0.651,
          "base_score": 0.501,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 24,
          "title": "",
          "score": 0.622,
          "base_score": 0.472,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "class",
          "__init__",
          "mybaseclass",
          "self value",
          "__init__ self"
        ],
        "semantic": [],
        "merged": [
          "class",
          "__init__",
          "mybaseclass",
          "self value",
          "__init__ self"
        ]
      },
      "topic_id": 1,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.3610754721268696,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:03.224192+00:00"
      }
    },
    {
      "chapter_number": 19,
      "title": "Segment 19 (pages 188-197)",
      "start_page": 188,
      "end_page": 197,
      "summary": "Item 41: Consider Composing Functionality with Mix-in Classes \nparent classes.\nMix-in Classes\nA mix-in is a class that \nMix-in classes don’t define their own instance attributes nor \nall my classes?\nclass ToDictMixin:\noutput[key] = self._traverse(key, value)\ndef _traverse(self, key, value):\nreturn value.to_dict()\nreturn self._traverse_dict(value)\nreturn [self._traverse(key, i) for i in value]\nreturn self._traverse_dict(value.__dict__)\nHere, I define an example class that uses the mix-in to make a dictio-\ndef __init__(self, value, left=None, right=None):\nself.value = value\n{'value': 10,\nItem 41: Consider Composing Functionality with Mix-in Classes \ndef __init__(self, value, left=None,\ndef _traverse(self, key, value):\n{'value': 10,\nclass that has an attribute of type BinaryTreeWithParent to automati-\ndef __init__(self, name, tree_with_parent):\nself.name = name\nmix-in that provides generic JSON serialization for any class.\nthis by assuming that a class provides a to_dict method (which may \nor may not be provided by the ToDictMixin class):\nclass JsonMixin:\nItem 41: Consider Composing Functionality with Mix-in Classes \nSerializing these classes to and from JSON is simple.\nWhen you use mix-ins like this, it’s fine if the class you apply \n✦ Mix-ins can include instance methods or class methods, depending \nIn Python, there are only two types of visibility for a class’s attributes: \nself.__private_field = 10\ndef get_private_field(self):\nreturn self.__private_field\nPrivate fields are specified by prefixing an attribute’s name with a \nHowever, directly accessing private fields from outside the class raises \nClass methods also have access to private attributes because they are \nclass MyOtherObject:\nself.__private_field = 71\nreturn instance.__private_field\nAs you’d expect with private fields, a subclass can’t access its parent \nclass’s private fields:\nclass MyParentObject:\nself.__private_field = 71\ndef get_private_field(self):\nreturn self.__private_field\nattribute access to use the name _MyChildObject__private_field \nvalue of Python trying to prevent private attribute access otherwise?\nclass MyStringClass:\ndef __init__(self, value):\nself.__value = value\ndef get_value(self):\nreturn str(self.__value)\ndef get_value(self):\nreturn int(self._MyStringClass__value)\nHere, the MyIntegerSubclass class’s immediate parent, MyStringClass, \ndef __init__(self, value):\nself.__value = value\ndef get_value(self):\nreturn self.__value\ndef get_value(self):\ndef get_value(self):\nreturn int(self._MyStringClass__value)  # Not updated\nThe __value attribute is now assigned in the MyBaseClass parent class, \nence self._MyStringClass__value to break in MyIntegerSubclass:\nclass MyStringClass:\ndef __init__(self, value):\nself._value = value\noccurs when a child class unwittingly defines an attribute that was \nalready defined by its parent class:\nself._value = 5\nreturn self._value\nself._value = 'hello'  # Conflicts\nissue occurring, you can use a private attribute in the parent class \nclasses:\nself.__value = 5       # Double underscore\nreturn self.__value    # Double underscore\nself._value = 'hello'  # OK!",
      "keywords": [
        "Private",
        "Classes",
        "Mix-in Classes",
        "init",
        "self.",
        "parent",
        "field",
        "attribute",
        "Mix-in",
        "dict",
        "private attribute",
        "Item",
        "Private fields",
        "Python",
        "return self."
      ],
      "concepts": [
        "classes",
        "value",
        "attribute",
        "python",
        "method",
        "item",
        "private",
        "returns",
        "functionality",
        "function"
      ],
      "similar_chapters": [
        {
          "book": "Effective-Python",
          "chapter": 24,
          "title": "",
          "score": 0.72,
          "base_score": 0.57,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 22,
          "title": "",
          "score": 0.628,
          "base_score": 0.478,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 32,
          "title": "",
          "score": 0.587,
          "base_score": 0.437,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 18,
          "title": "",
          "score": 0.586,
          "base_score": 0.436,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 16,
          "title": "",
          "score": 0.586,
          "base_score": 0.436,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "self",
          "private",
          "mix",
          "class",
          "value"
        ],
        "semantic": [],
        "merged": [
          "self",
          "private",
          "mix",
          "class",
          "value"
        ]
      },
      "topic_id": 1,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.3147547163804779,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:03.224229+00:00"
      }
    },
    {
      "chapter_number": 20,
      "title": "Segment 20 (pages 198-208)",
      "start_page": 198,
      "end_page": 208,
      "summary": "Much of programming in Python is defining classes that contain data \nclass is a container of some kind, encapsulating attributes and func-\nPython also provides built-in container types for \nWhen you’re designing classes for simple use cases like sequences, \nit’s natural to want to subclass Python’s built-in list type directly.\nclass FrequencyList(list):\ntree class:\ndef __init__(self, value, left=None, right=None):\nHow do you make this class act like a sequence type?\nTo make the BinaryNode class act like a sequence, you can provide \nif self.left is not None:\ndef __getitem__(self, index):\nverse the tree with the left and right attributes:\nprint('LRR is', tree.left.right.right.value)\nclass SequenceNode(IndexableNode):\nPython programmer would expect to see on a sequence like list or \ncollections.abc module defines a set of abstract base classes that \nprovide all of the typical methods for each container type.\nsubclass from these abstract base classes and forget to implement \nclass BadType(Sequence):\nclass BetterNode(SequenceNode, Sequence):\n✦ Inherit directly from Python’s container types (like list or dict) for \ndefined in collections.abc to ensure that your classes match \nmetaclasses let you intercept Python’s class statement and provide \nspecial behavior each time a class is defined.\nItem 44:  Use Plain Attributes Instead of Setter and \ntry to implement explicit getter and setter methods in their classes:\ndef __init__(self, ohms):\nself._ohms = ohms\ndef get_ohms(self):\nreturn self._ohms\ndef set_ohms(self, ohms):\nself._ohms = ohms\nprint('Before:', r0.get_ohms())\nr0.set_ohms(10e3)\nprint('After: ', r0.get_ohms())\nclass Resistor:\ndef __init__(self, ohms):\nself.ohms = ohms\ndef __init__(self, ohms):\nItem 44: Use Plain Attributes Instead of Setter and Getter Methods \ndef voltage(self):\nself.current = self._voltage / self.ohms\nmethod, which in turn will update the current attribute of the object \nclass that ensures all resistance values are above zero ohms:\nclass BoundedResistance(Resistor):\ndef __init__(self, ohms):\ndef ohms(self):\nreturn self._ohms\ndef ohms(self, ohms):\nself._ohms = ohms\nResistor.__init__, which assigns self.ohms = -5.\ncauses the @ohms.setter method from BoundedResistance to be called, \nI can even use @property to make attributes from parent classes \ndef __init__(self, ohms):\ndef ohms(self):\nreturn self._ohms\ndef ohms(self, ohms):\nif hasattr(self, '_ohms'):\nself._ohms = ohms\nWhen you use @property methods to implement setters and getters, \nple, don’t set other attributes in getter property methods:\ndef ohms(self):\nItem 44: Use Plain Attributes Instead of Setter and Getter Methods \nself.voltage = self._ohms * self.current\nreturn self._ohms\ndef ohms(self, ohms):\nself._ohms = ohms\nSetting other attributes in getter property methods leads to extremely \nUsers of a class will expect its attributes to be like \n✦ Define new class interfaces using simple public attributes and avoid \ndefining setter and getter methods.\n✦ Use @property to define special behavior when attributes are \n@property methods.",
      "keywords": [
        "ohms",
        "Python",
        "methods",
        "Custom Container Types",
        "Container Types",
        "attributes",
        "tree",
        "Item",
        "property",
        "self.",
        "Container",
        "Custom Container",
        "Getter Methods",
        "classes",
        "init"
      ],
      "concepts": [
        "methods",
        "tree",
        "ohms",
        "attributes",
        "python",
        "pythonic",
        "uses",
        "define",
        "defined",
        "objects"
      ],
      "similar_chapters": [
        {
          "book": "Effective-Python",
          "chapter": 2,
          "title": "",
          "score": 0.533,
          "base_score": 0.533,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 9,
          "title": "",
          "score": 0.515,
          "base_score": 0.515,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 32,
          "title": "",
          "score": 0.47,
          "base_score": 0.47,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 19,
          "title": "",
          "score": 0.468,
          "base_score": 0.468,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 18,
          "title": "",
          "score": 0.453,
          "base_score": 0.453,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "ohms",
          "self",
          "self ohms",
          "ohms self",
          "self _ohms"
        ],
        "semantic": [],
        "merged": [
          "ohms",
          "self",
          "self ohms",
          "ohms self",
          "self _ohms"
        ]
      },
      "topic_id": null,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.3431072528947631,
        "topic_boost": 0.0,
        "timestamp": "2025-12-17T23:07:03.224268+00:00"
      }
    },
    {
      "chapter_number": 21,
      "title": "Segment 21 (pages 209-217)",
      "start_page": 209,
      "end_page": 217,
      "summary": "class Bucket:\nself.quota = 0\nreturn f'Bucket(quota={self.quota})'\nbucket.quota = 0\nbucket.quota += amount\nif bucket.quota - amount < 0:\nbucket.quota -= amount\nTo use this class, first I fill the bucket up:\nBucket(quota=100)\nBucket(quota=1)\nBucket(quota=1)\nself.max_quota = 0\nself.quota_consumed = 0\ndef quota(self):\ndef quota(self, amount):\nself.quota_consumed = 0\nself.max_quota = 0\nself.max_quota = amount\nself.quota_consumed += delta\n✦ Use @property to give existing instance attributes new functionality.\nself._grade = 0\ndef grade(self):\nreturn self._grade\ndef grade(self, value):\n'Grade must be between 0 and 100')\nself._grade = value\nself._writing_grade = 0\nself._math_grade = 0\n'Grade must be between 0 and 100')\ndef writing_grade(self):\nreturn self._writing_grade\ndef writing_grade(self, value):\nself._check_grade(value)\nself._writing_grade = value\ndef math_grade(self):\nreturn self._math_grade\ndef math_grade(self, value):\nself._check_grade(value)\nself._math_grade = value\nwrite the @property boilerplate and _check_grade method over and \nHere, I define a new class called Exam with class attributes that are \nGrade instances.\nThe Grade class implements the descriptor protocol:\nclass Grade:\ndef __set__(self, instance, value):\n# Class attributes\nexam.writing_grade = 40\nexam.writing_grade\nattribute named writing_grade, Python falls back to the Exam class’s \nKnowing this behavior and how I used @property for grade validation \nclass Grade:\ndef __set__(self, instance, value):\n'Grade must be between 0 and 100')\nfirst_exam.writing_grade = 82\nprint('Writing', first_exam.writing_grade)\nsecond_exam.writing_grade = 75\nprint(f'Second {second_exam.writing_grade} is right')\nprint(f'First  {first_exam.writing_grade} is wrong; '\nThe problem is that a single Grade instance is shared across all Exam \ninstances for the class attribute writing_grade.\nThe Grade instance for \nTo solve this, I need the Grade class to keep track of its value for each \nclass Grade:\nreturn self._values.get(instance, 0)\ndef __set__(self, instance, value):\n'Grade must be between 0 and 100')\nclass Grade:\ndef __set__(self, instance, value):\nfirst_exam.writing_grade = 82\nsecond_exam.writing_grade = 75\nprint(f'First  {first_exam.writing_grade} is right')\nprint(f'Second {second_exam.writing_grade} is right')",
      "keywords": [
        "grade",
        "exam",
        "quota",
        "bucket",
        "Attributes",
        "property",
        "instance",
        "Item",
        "Exam instance",
        "class Exam",
        "self.",
        "class Grade",
        "Refactoring Attributes",
        "writing",
        "Attributes class Exam"
      ],
      "concepts": [
        "classes",
        "attributes",
        "property",
        "exam",
        "grade",
        "useful",
        "instance",
        "value",
        "python",
        "data"
      ],
      "similar_chapters": [
        {
          "book": "Effective-Python",
          "chapter": 17,
          "title": "",
          "score": 0.738,
          "base_score": 0.588,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 10,
          "title": "",
          "score": 0.59,
          "base_score": 0.44,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 34,
          "title": "",
          "score": 0.546,
          "base_score": 0.396,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 8,
          "title": "",
          "score": 0.504,
          "base_score": 0.504,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 19,
          "title": "",
          "score": 0.443,
          "base_score": 0.443,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "grade",
          "self",
          "writing_grade",
          "quota",
          "bucket"
        ],
        "semantic": [],
        "merged": [
          "grade",
          "self",
          "writing_grade",
          "quota",
          "bucket"
        ]
      },
      "topic_id": 2,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.323414315128519,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:03.224306+00:00"
      }
    },
    {
      "chapter_number": 22,
      "title": "Segment 22 (pages 218-231)",
      "start_page": 218,
      "end_page": 231,
      "summary": "your own descriptor classes.\nIf a class defines __getattr__, that \nmethod is called every time an attribute can’t be found in an object’s \nclass LazyRecord:\nclass’s implementation of __getattr__ in order to fetch the real \n* Called __getattr__('foo'), populating instance dictionary\nclass ValidatingRecord:\nclass MissingPropertyRecord:\n* Called __getattr__('foo'), populating instance dictionary\nclasses that implement __getattribute__ have that method called \nclass SavingRecord:\ndata.foo = 5\ndata.foo = 7\ncalled on every attribute access for an object, even when you may not \nclass BrokenDictionaryRecord:\ncauses __getattribute__ to run again, which accesses self._data \nclass DictionaryRecord:\nby using methods from super() (i.e., the object class) to access \nclass was defined correctly.\nods, or have strict relationships between class attributes.\nOften a class’s validation code runs in the __init__ method, when an \nobject of the class’s type is constructed at runtime (see Item 44: “Use \ncase, a metaclass receives the contents of associated class statements \nclass Meta(type):\ndef __new__(meta, name, bases, class_dict):\nprint(class_dict)\nreturn type.__new__(meta, name, bases, class_dict)\nclass MyClass(metaclass=Meta):\nclass MySubclass(MyClass):\nThe metaclass has access to the name of the class, the parent classes \nit inherits from (bases), and all the class attributes that were defined \nin the class’s body.\nAll classes inherit from object, so it’s not explicitly \n* Running <class '__main__.Meta'>.__new__ for MyClass\n* Running <class '__main__.Meta'>.__new__ for MySubclass\nBases: (<class '__main__.MyClass'>,)\ndate all of the parameters of an associated class before it’s defined.\nusing it in the base class of my polygon class hierarchy.\nimportant not to apply the same validation to the base class:\nclass ValidatePolygon(type):\ndef __new__(meta, name, bases, class_dict):\n# Only validate subclasses of the Polygon class\nif class_dict['sides'] < 3:\nreturn type.__new__(meta, name, bases, class_dict)\nclass Polygon(metaclass=ValidatePolygon):\nclass Triangle(Polygon):\nclass Rectangle(Polygon):\nclass Nonagon(Polygon):\nrunning when I define such a class (unless it’s defined in a dynam-\nprint('Before class')\nclass Line(Polygon):\nprint('After class')\nBefore class\nfied syntax—the __init_subclass__ special class method—for achiev-\nclass BetterPolygon:\nhaving to go into the class’s dictionary with class_dict['sides'].\nprint('Before class')\nprint('After class')\nBefore class\nis that you can only specify a single metaclass per class definition.\nclass ValidateFilled(type):\ndef __new__(meta, name, bases, class_dict):\n# Only validate subclasses of the Filled class\nif class_dict['color'] not in ('red', 'green'):\nreturn type.__new__(meta, name, bases, class_dict)\nclass Filled(metaclass=ValidateFilled):\nclass RedPentagon(Filled, Polygon):\nclass ValidatePolygon(type):\ndef __new__(meta, name, bases, class_dict):\n# Only validate non-root classes\nif not class_dict.get('is_root'):\nif class_dict['sides'] < 3:\nreturn type.__new__(meta, name, bases, class_dict)\nclass Polygon(metaclass=ValidatePolygon):\ndef __new__(meta, name, bases, class_dict):\n# Only validate non-root classes\nif not class_dict.get('is_root'):\nif class_dict['color'] not in ('red', 'green'):\nreturn super().__new__(meta, name, bases, class_dict)\nclass FilledPolygon(Polygon, metaclass=ValidateFilledPolygon):\nclass GreenPentagon(FilledPolygon):\npose of class validation like this (similar to mix-ins; see Item 41: \nThe __init_subclass__ special class method can also be used to \nIt can be defined by multiple levels of a class \nHere, I define a class to represent \nregion fill color that can be composed with the BetterPolygon class \nclass Filled:\nI can inherit from both classes to define a new class.\nBoth classes call \nclass RedTriangle(Filled, Polygon):\nprint('Before class')\nclass BlueLine(Filled, Polygon):\nprint('After class')\nBefore class\nprint('Before class')\nclass BeigeSquare(Filled, Polygon):\nprint('After class')\nBefore class\nclass Top:\nclass Left(Top):\nclass Right(Top):\nclass Bottom(Left, Right):\nTop for <class '__main__.Left'>\nTop for <class '__main__.Right'>\nTop for <class '__main__.Bottom'>\nRight for <class '__main__.Bottom'>\nLeft for <class '__main__.Bottom'>\n✦ The __new__ method of metaclasses is run after the class state-\n✦ Metaclasses can be used to inspect or modify a class after it’s \n✦ Be sure to call super().__init_subclass__ from within your class’s \nof classes and multiple inheritance.\nItem 49:  Register Class Existence with ",
      "keywords": [
        "foo",
        "called",
        "getattribute",
        "init",
        "polygon",
        "Attributes",
        "sides",
        "dict",
        "subclass",
        "Python",
        "getattr",
        "Item",
        "data",
        "Metaclasses",
        "super"
      ],
      "concepts": [
        "classes",
        "attributes",
        "data",
        "sides",
        "validation",
        "validate",
        "validating",
        "polygon",
        "access",
        "accessing"
      ],
      "similar_chapters": [
        {
          "book": "Effective-Python",
          "chapter": 24,
          "title": "",
          "score": 0.735,
          "base_score": 0.585,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 32,
          "title": "",
          "score": 0.681,
          "base_score": 0.531,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 18,
          "title": "",
          "score": 0.651,
          "base_score": 0.501,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 19,
          "title": "",
          "score": 0.628,
          "base_score": 0.478,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 23,
          "title": "",
          "score": 0.627,
          "base_score": 0.477,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "class",
          "class_dict",
          "polygon",
          "meta",
          "__new__"
        ],
        "semantic": [],
        "merged": [
          "class",
          "class_dict",
          "polygon",
          "meta",
          "__new__"
        ]
      },
      "topic_id": 1,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.31569605888661234,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:03.224344+00:00"
      }
    },
    {
      "chapter_number": 23,
      "title": "Segment 23 (pages 232-240)",
      "start_page": 232,
      "end_page": 240,
      "summary": "Item 49: Register Class Existence with __init_subclass__ \nclass Serializable:\nThis class makes it easy to serialize simple, immutable data struc-\nclass Point2D(Serializable):\nHere, I define another class that can deserialize \nthe data from its Serializable parent class:\nclass BetterPoint2D(Deserializable):\nTo do this, I can include the serialized object’s class name in the \nclass BetterSerializable:\n'class': self.__class__.__name__,\nname = self.__class__.__name__\nclasses passed to register_class:\ndef register_class(target_class):\nname = params['class']\ntarget_class = registry[name]\nreturn target_class(*params['args'])\nregister_class for every class I may want to deserialize in the future:\nclass EvenBetterPoint2D(BetterSerializable):\nregister_class(EvenBetterPoint2D)\nknow which class it contains:\nSerialized: {\"class\": \"EvenBetterPoint2D\", \"args\": [5, 3]}\nregister_class:\nclass Point3D(BetterSerializable):\n# Forgot to call register_class!\nalize an instance of a class I forgot to register:\nItem 49: Register Class Existence with __init_subclass__ \nBetterSerializable and ensure that register_class is called in all \nMetaclasses enable this by intercepting the class statement \nclass Meta(type):\ndef __new__(meta, name, bases, class_dict):\nregister_class(cls)\nclass RegisteredSerializable(BetterSerializable,\nthat the call to register_class happened and deserialize will always \nclass Vector3D(RegisteredSerializable):\nSerialized: {\"class\": \"Vector3D\", \"args\": [10, -7, 3]}\nAn even better approach is to use the __init_subclass__ special class \nclass BetterRegisteredSerializable(BetterSerializable):\nregister_class(cls)\nclass Vector1D(BetterRegisteredSerializable):\nSerialized: {\"class\": \"Vector1D\", \"args\": [6]}\nBy using __init_subclass__ (or metaclasses) for class registration, \nbase class is subclassed in a program.\n✦ Using metaclasses for class registration helps you avoid errors by \nItem 49: Register Class Existence with __init_subclass__ \ncontaining class.\nclass Field:\nDefining the class representing a row requires supplying the data-\nclass Customer:\n# Class attributes\nUsing the class is simple.\nBut the class definition seems redundant.\nname of the field for the class on the left ('field_name =').\nclass Customer:\ninstance to know upfront which class attribute it will be assigned to.\nclass Meta(type):\ndef __new__(meta, name, bases, class_dict):\nfor key, value in class_dict.items():\nHere, I define a base class that uses the metaclass.\nAll classes repre-\nclass DatabaseRow(metaclass=Meta):\nclass Field:\nBy using the metaclass, the new DatabaseRow base class, and the new \nField descriptor, the class definition for a database row no longer has \nclass BetterCustomer(DatabaseRow):\nThe trouble with this approach is that you can’t use the Field class for \nclass BrokenCustomer:\nevery descriptor instance when its containing class is defined.\nclass Field:\n# Called on class creation for each descriptor\ninherit from a specific parent class or having to use a metaclass:\nclass FixedCustomer:",
      "keywords": [
        "Field",
        "init",
        "json class Serializable",
        "class Field",
        "instance",
        "data",
        "Register Class Existence",
        "Annotate Class Attributes",
        "Field descriptor",
        "Register",
        "Class Attributes",
        "Serialized",
        "args",
        "Item",
        "Metaclasses"
      ],
      "concepts": [
        "classes",
        "field",
        "data",
        "requires",
        "requirements",
        "item",
        "point",
        "instance",
        "serialized",
        "serialization"
      ],
      "similar_chapters": [
        {
          "book": "Effective-Python",
          "chapter": 32,
          "title": "",
          "score": 0.719,
          "base_score": 0.569,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 24,
          "title": "",
          "score": 0.707,
          "base_score": 0.557,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 22,
          "title": "",
          "score": 0.627,
          "base_score": 0.477,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 19,
          "title": "",
          "score": 0.578,
          "base_score": 0.428,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 18,
          "title": "",
          "score": 0.559,
          "base_score": 0.409,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "class",
          "register_class",
          "field",
          "betterserializable",
          "register"
        ],
        "semantic": [],
        "merged": [
          "class",
          "register_class",
          "field",
          "betterserializable",
          "register"
        ]
      },
      "topic_id": 1,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.26399487767534596,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:03.224379+00:00"
      }
    },
    {
      "chapter_number": 24,
      "title": "Segment 24 (pages 241-248)",
      "start_page": 241,
      "end_page": 248,
      "summary": "✦ Metaclasses enable you to modify a class’s attributes before the \nclass is fully defined.\nItem 51:  Prefer Class Decorators Over Metaclasses for \nComposable Class Extensions\nAlthough metaclasses allow you to customize class creation in multi-\nand Item 49: “Register Class Existence with __init_subclass__”), they \nFor example, say that I want to decorate all of the methods of a class \nif hasattr(func, 'tracing'):  # Only decorate once\nItem 51: Prefer Class Decorators Over Metaclasses \nclass TraceDict(dict):\nan instance of the class:\nthat I wanted to decorate with @trace_func.\ncally decorate all methods of a class.\ntrace_func decorator:\ntrace_types = (\nclass TraceMeta(type):\ndef __new__(meta, name, bases, class_dict):\nklass = super().__new__(meta, name, bases, class_dict)\nNow, I can declare my dict subclass by using the TraceMeta metaclass \nclass TraceDict(dict, metaclass=TraceMeta):\n__new__((<class '__main__.TraceDict'>, [('hi', 1)]), {}) -> {}\nclass OtherMeta(type):\nclass SimpleDict(dict, metaclass=OtherMeta):\nclass TraceDict(SimpleDict, metaclass=TraceMeta):\nclass TraceMeta(type):\nclass OtherMeta(TraceMeta):\nclass SimpleDict(dict, metaclass=OtherMeta):\nclass TraceDict(SimpleDict, metaclass=TraceMeta):\nItem 51: Prefer Class Decorators Over Metaclasses \n__new__((<class '__main__.TraceDict'>, [('hi', 1)]), {}) -> {}\nthe class that’s being modified.\nTo solve this problem, Python supports class decorators.\nClass \ndef my_class_decorator(klass):\n@my_class_decorator\nclass MyClass:\n<class '__main__.MyClass'>\nI can implement a class decorator to apply trace_func to all methods \nand functions of a class by moving the core of the TraceMeta.__new__ \nclass TraceDict(dict):\n__new__((<class '__main__.TraceDict'>, [('hi', 1)]), {}) -> {}\nClass decorators also work when the class being decorated already \nclass OtherMeta(type):\nclass TraceDict(dict, metaclass=OtherMeta):\n__new__((<class '__main__.TraceDict'>, [('hi', 1)]), {}) -> {}\nItem 51: Prefer Class Decorators Over Metaclasses \nto Use heapq for Priority Queues” for a useful class decorator called \n✦ A class decorator is a simple function that receives a class instance \nas a parameter and returns either a new class or a modified version \nof the original class.\n✦ Class decorators are useful when you want to modify every method \n✦ Metaclasses can’t be composed together easily, while many class \ndecorators can be used to extend the same class without conflicts.\nWithin a single program, concurrency is a tool that makes it easier ",
      "keywords": [
        "Class Decorators",
        "Prefer Class Decorators",
        "trace",
        "dict",
        "Metaclasses",
        "class TraceDict",
        "TraceDict",
        "Item",
        "Decorators",
        "exist",
        "Prefer Class",
        "metaclass",
        "trace class TraceDict",
        "pass class TraceDict",
        "pass class"
      ],
      "concepts": [
        "classes",
        "types",
        "concurrency",
        "concurrent",
        "item",
        "program",
        "python",
        "decorators",
        "decorate",
        "decorated"
      ],
      "similar_chapters": [
        {
          "book": "Effective-Python",
          "chapter": 22,
          "title": "",
          "score": 0.735,
          "base_score": 0.585,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 19,
          "title": "",
          "score": 0.72,
          "base_score": 0.57,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 23,
          "title": "",
          "score": 0.707,
          "base_score": 0.557,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 13,
          "title": "",
          "score": 0.706,
          "base_score": 0.556,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 18,
          "title": "",
          "score": 0.622,
          "base_score": 0.472,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "class",
          "tracedict",
          "class tracedict",
          "decorators",
          "class decorators"
        ],
        "semantic": [],
        "merged": [
          "class",
          "tracedict",
          "class tracedict",
          "decorators",
          "class decorators"
        ]
      },
      "topic_id": 1,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.3162520303856446,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:03.224415+00:00"
      }
    },
    {
      "chapter_number": 25,
      "title": "Segment 25 (pages 249-264)",
      "start_page": 249,
      "end_page": 264,
      "summary": "Item 52: Use subprocess to Manage Child Processes\nPython has battle-hardened libraries for running and managing child \nChild processes started by Python are able to run in parallel, enabling \nbe CPU bound (see Item 53: “Use Threads for Blocking I/O, Avoid for \nPython has many ways to run subprocesses (e.g., os.popen, os.exec*), \nRunning a child process with subprocess \nHere, I use the module’s run convenience function to start a \ninstead of the run function, I can poll child process status periodically \nwhile Python does other work:\nItem 52: Use subprocess to Manage Child Processes \nprocess to run many child processes in parallel.\nYou can also pipe data from a Python program into a subprocess and \ndef run_encrypt(data):\nproc = run_encrypt(data)\nThe child processes run in parallel and consume their input.\nencrypt_proc = run_encrypt(data)\nhash_proc = run_hash(encrypt_proc.stdout)\nItem 52: Use subprocess to Manage Child Processes \n✦ Use the subprocess module to run child processes and manage their \n✦ Child processes run in parallel with the Python interpreter, enabling \nItem 53:  Use Threads for Blocking I/O, Avoid for \nruns a Python program in two steps.\nwhile the Python program executes.\none thread takes control of a program by interrupting another thread.\nin languages like C++ or Java, having multiple threads of execution \nItem 53: Use Threads for Blocking I/O, Avoid for Parallelism \nAlthough Python supports multiple threads of execution, the GIL \nmeans that when you reach for threads to do parallel computation \nUsing multiple threads to do this computation would make sense in \nthread for doing the same computation as before:\nfrom threading import Thread\nclass FactorizeThread(Thread):\ndef run(self):\nThen, I start a thread for each number to factorize in parallel:\nthreads = []\nthread = FactorizeThread(number)\nthread.start()\nthreads.append(thread)\nFinally, I wait for all of the threads to finish:\nfor thread in threads:\nthread.join()\nWith one thread per number, you might expect less than a 4x speedup \nperformance of these threads to be worse when there are multiple \ndon’t work with the standard Thread class (see Item 64: “Consider \nthreads at all?\nFirst, multiple threads make it easy for a program to seem like it’s \nWith threads, you can leave it to Python to run your func-\nfairness between Python threads of execution, even though only one \nThe second reason Python supports threads is to deal with blocking \nItem 53: Use Threads for Blocking I/O, Avoid for Parallelism \nA Python program uses system calls to ask the computer’s  operating \nThreads help handle blocking I/O by insulating a program from the \nMy program’s main thread of \nit’s time to consider moving your system calls to threads.\nseparate threads.\nthread to do whatever computation is required:\nthreads = []\nthread.start()\nthreads.append(thread)\nWith the threads started, here I do some work to calculate the next \nhelicopter move before waiting for the system call threads to finish:\nfor thread in threads:\nthread.join()\nall the system calls will run in parallel from multiple Python threads \nThis works because Python threads release the GIL just before \nUsing threads is the simplest way to do blocking I/O in parallel with \n✦ Python threads can’t run in parallel on multiple CPU cores because \nItem 54: Use Lock to Prevent Data Races in Threads \n✦ Python threads are still useful despite the GIL because they provide \n✦ Use Python threads to make multiple system calls in parallel.\nItem 54: Use Lock to Prevent Data Races in Threads\n“Use Threads for Blocking I/O, Avoid for Parallelism”), many new \nalready  preventing Python threads from running on multiple CPU \nAlthough only one Python thread runs at a time, a thread’s opera-\naccess the same objects from multiple threads simultaneously.\nImagine that each sensor has its own worker thread because reading \nment, the worker thread increments the counter up to a maximum \nHere, I run one worker thread for each sensor in parallel and wait for \nfrom threading import Thread\nthreads = []\nthread = Thread(target=worker,\nthread.start()\nfor thread in threads:\nthread.join()\ninterpreter thread can run at a time?\nThe Python interpreter enforces fairness between all of the threads \nTo do this, Python suspends a thread as it’s running and resumes \nanother thread in turn.\nwhen Python will suspend your threads.\nA thread can even be paused \nequivalent to this statement from the perspective of the worker thread:\nItem 54: Use Lock to Prevent Data Races in Threads \nPython threads incrementing the counter can be suspended between \n# Running in Thread A\n# Context switch to Thread B\nThread B interrupted thread A before it had completely finished.\nThread B ran and finished, but then thread A resumed mid-execution, \noverwriting all of thread B’s progress in incrementing the counter.\ncorruption, Python includes a robust set of tools in the threading \nvalue against simultaneous accesses from multiple threads.\nthread will be able to acquire the lock at a time.\nfrom threading import Lock\nNow, I run the worker threads as before but use a LockingCounter \nthread = Thread(target=worker,\nthread.start()\nfor thread in threads:\nthread.join()\nresponsible for protecting against data races between the threads in \n✦ Use the Lock class from the threading built-in module to enforce \nyour program’s invariants between multiple threads.\nItem 55:  Use Queue to Coordinate Work Between \nThreads\nPython programs that do many things concurrently often need to \nItem 55: Use Queue to Coordinate Work Between Threads \n(see Item 53: “Use Threads for Blocking I/O, Avoid for Parallelism”).\nqueue (see Item 54: “Use Lock to Prevent Data Races in Threads” to \nunderstand the importance of thread safety in Python; see Item 71: \nfrom threading import Lock\nHere, I represent each phase of the pipeline as a Python thread that \ntakes work from one queue like this, runs a function on it, and puts \nfrom threading import Thread\nclass Worker(Thread):\ndef run(self):\nitem = self.in_queue.get()\nItem 55: Use Queue to Coordinate Work Between Threads \nthreads = [\nI can start the threads and then inject a bunch of work into the first \nfor thread in threads:\nthread.start()\nthe threads polling their input queues for new work.\nprocessed = len(done_queue.items)\nProcessed 1000 items after polling 3035 times\nthreads waste CPU time doing nothing useful; they’re constantly rais-\nworker thread that it’s time to exit.",
      "keywords": [
        "Python threads",
        "Threads",
        "Python",
        "Child Processes",
        "Python thread runs",
        "Item",
        "multiple Python threads",
        "Child",
        "Python interpreter thread",
        "multiple threads",
        "Python interpreter",
        "worker thread",
        "lock",
        "run",
        "Python program"
      ],
      "concepts": [
        "threads",
        "item",
        "processes",
        "process",
        "processing",
        "time",
        "python",
        "working",
        "running",
        "run"
      ],
      "similar_chapters": [
        {
          "book": "Effective-Python",
          "chapter": 30,
          "title": "",
          "score": 0.707,
          "base_score": 0.557,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 26,
          "title": "",
          "score": 0.643,
          "base_score": 0.493,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 27,
          "title": "",
          "score": 0.635,
          "base_score": 0.485,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 38,
          "title": "",
          "score": 0.618,
          "base_score": 0.468,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 28,
          "title": "",
          "score": 0.597,
          "base_score": 0.447,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "thread",
          "threads",
          "python",
          "threads thread",
          "child"
        ],
        "semantic": [],
        "merged": [
          "thread",
          "threads",
          "python",
          "threads thread",
          "child"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.29012946867669526,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:03.224450+00:00"
      }
    },
    {
      "chapter_number": 26,
      "title": "Segment 26 (pages 265-274)",
      "start_page": 265,
      "end_page": 274,
      "summary": "but the second phase makes slow progress, then the queue connecting \nQueue to the Rescue\nthread that waits for some input data on a queue:\nmy_queue = Queue()\nmy_queue.get()              # Runs after put() below\nis put on the Queue instance and the get method has something to \nmy_queue.put(object())          # Runs before get() above\nItem 55: Use Queue to Coordinate Work Between Threads \nconsuming a queue:\nmy_queue.get()              # Runs second\nmy_queue.get()              # Runs fourth\nqueue before the consumer thread ever calls get.\nBut the Queue size \nThis means the producer adding items to the queue will have \nto wait for the consumer thread to call get at least once before the \nqueue:\nmy_queue.put(object())          # Runs first\nmy_queue.put(object())          # Runs third\nThe Queue class can also track the progress of work using the \nThis lets you wait for a phase’s input queue to \nwith the done_queue above).\nthread that calls task_done when it finishes working on an item:\nin_queue = Queue()\nwork = in_queue.get()       # Runs second\nin_queue.task_done()        # Runs third\nThe producer can just wait for the in_queue to finish by calling \njoin on the Queue instance.\nin_queue.put(object())         # Runs first\nin_queue.join()                # Runs fourth\na close method that adds a special sentinel item to the queue that \nclass ClosableQueue(Queue):\nItem 55: Use Queue to Coordinate Work Between Threads \nwork on the queue (see Item 31: “Be Defensive When Iterating Over \ndef __init__(self, func, in_queue, out_queue):\nself.in_queue = in_queue\nself.out_queue = out_queue\nfor item in self.in_queue:\nself.out_queue.put(result)\ndownload_queue = ClosableQueue()\nresize_queue = ClosableQueue()\nupload_queue = ClosableQueue()\ndone_queue = ClosableQueue()\nqueue of the first phase:\ndownload_queue.put(object())\ndownload_queue.close()\nFinally, I wait for the work to finish by joining the queues that con-\nto stop by closing its input queue.\ndownload_queue.join()\nresize_queue.close()\nresize_queue.join()\nupload_queue.close()\nupload_queue.join()\nprint(done_queue.qsize(), 'items finished')\nis by calling close on each input queue once per consuming thread, \ndef stop_threads(closable_queue, threads):\nclosable_queue.join()\nItem 55: Use Queue to Coordinate Work Between Threads \ncess into the top of the pipeline, joining queues and threads along the \ndownload_queue = ClosableQueue()\nresize_queue = ClosableQueue()\nupload_queue = ClosableQueue()\ndone_queue = ClosableQueue()\ndownload_queue.put(object())\nstop_threads(download_queue, download_threads)\nstop_threads(resize_queue, resize_threads)\nstop_threads(upload_queue, upload_threads)\nprint(done_queue.qsize(), 'items finished')\nAlthough Queue works well in this case of a linear pipeline, there \n✦ The Queue class has all the facilities you need to build robust \ndef get(self, y, x):\ndef set(self, y, x, state):\nself.rows[y % self.height][x % self.width] = state\ndef count_neighbors(y, x, get):\ndef game_logic(state, neighbors):\nFinally, I can define a function that progresses the whole grid of cells \nstep_cell(y, x, grid.get, next_grid.set)\ndef game_logic(state, neighbors):",
      "keywords": [
        "queue",
        "Threads",
        "consumer",
        "grid",
        "producer",
        "item",
        "consumer thread",
        "state",
        "Runs",
        "alive",
        "Game",
        "Queue class",
        "input queue",
        "queue def run",
        "Concurrency"
      ],
      "concepts": [
        "queue",
        "grid",
        "item",
        "state",
        "thread",
        "work",
        "classes",
        "functionality",
        "functions",
        "function"
      ],
      "similar_chapters": [
        {
          "book": "Effective-Python",
          "chapter": 27,
          "title": "",
          "score": 0.754,
          "base_score": 0.604,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 29,
          "title": "",
          "score": 0.716,
          "base_score": 0.566,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 28,
          "title": "",
          "score": 0.67,
          "base_score": 0.52,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 25,
          "title": "",
          "score": 0.643,
          "base_score": 0.493,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 35,
          "title": "",
          "score": 0.595,
          "base_score": 0.445,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "queue",
          "closablequeue",
          "in_queue",
          "my_queue",
          "download_queue"
        ],
        "semantic": [],
        "merged": [
          "queue",
          "closablequeue",
          "in_queue",
          "my_queue",
          "download_queue"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.3000150822391172,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:03.224485+00:00"
      }
    },
    {
      "chapter_number": 27,
      "title": "Segment 27 (pages 275-289)",
      "start_page": 275,
      "end_page": 289,
      "summary": "Game of Life example program (Item 57: “Avoid Creating New Thread \nQueue for Concurrency Requires Refactoring,” Item 59: “Consider \nThreadPoolExecutor When Threads Are Necessary for Concurrency,” \nand Item 60: “Achieve Highly Concurrent I/O with Coroutines”).\nItem 57:  Avoid Creating New Thread Instances for \nI/O in Python (see Item 53: “Use Threads for Blocking I/O, Avoid for \nItem 57: Avoid Creating New Thread Instances for On-demand Fan-out \nTo begin, threads \nfrom threading import Lock\nthread for each call to step_cell.\nThe threads will run in parallel and \ndef simulate_threaded(grid):\nthreads = []\nthread.start()  # Fan out\nfor thread in threads:\nthread.join()       # Fan in\nthe LockingGrid and simulate_threaded implementations:\ngrid = simulate_threaded(grid)  # Changed\nthreads.\n■The Thread instances require special tools to coordinate with \nThis complexity makes threaded code more difficult to extend and \nthread.\nRunning a thread per concurrent activity just won’t work.\nI can test what this would do by running a Thread instance pointed at \nItem 57: Avoid Creating New Thread Instances for On-demand Fan-out \nthread = Thread(target=game_logic, args=(ALIVE, 3))\nthread.start()\nthread.join()\nException in thread Thread-226:\nItem 59: “Consider ThreadPoolExecutor When Threads Are Necessary \nfor Concurrency”, and Item 60: “Achieve Highly Concurrent I/O with \n✦ Threads do not provide a built-in way to raise exceptions back in \nthe code that started a thread or that is waiting for one to finish, \nItem 58: Using Queue for Concurrency Requires Refactoring \nItem 58:  Understand How Using Queue for Concurrency \nIn the previous item (see Item 57: “Avoid Creating New Thread \nThread to solve the parallel I/O problem in the Game of Life example \nThe next approach to try is to implement a threaded pipeline using \nworker threads upfront and have them do parallelized I/O as needed.\ncating to and from the worker threads that execute the game_logic \nI can start multiple threads that will consume items from the \nThese threads will run concurrently, allowing for parallel \nclass StoppableWorker(Thread):\ndef game_logic_thread(item):\ny, x, state, neighbors = item\nthreads = []\nthread = StoppableWorker(\ngame_logic_thread, in_queue, out_queue)\nthread.start()\ning items from out_queue until it’s empty causes fan-in:\ndef simulate_pipeline(grid, in_queue, out_queue):\nin_queue.put((y, x, state, neighbors))  # Fan out\nfor item in out_queue:                          # Fan in\ny, x, next_state = item\nnext_grid.set(y, x, next_state)\nsimulate_pipeline function, which means I can use the  single-threaded \nThis code is also easier to debug than the Thread approach used \nsimulate_pipeline(Grid(1, 1), in_queue, out_queue)\nItem 58: Using Queue for Concurrency Requires Refactoring \nfor thread in threads:\nfor thread in threads:\nthread.join()\nsimulate_threaded approach from the previous item.\nber of threads running game_logic_thread—upfront based on my \nin worker threads, propagate them on a Queue, and then re-raise \nthem in the main thread.\npipeline that runs count_neighbors in a thread.\nthat exceptions propagate correctly between the worker threads and \nthe main thread.\nto ensure safe synchronization between the worker threads (see Item \nItem 57: “Avoid Creating New Thread Instances for On-demand Fan-\ndef count_neighbors_thread(item):\ny, x, state, get = item\ndef game_logic_thread(item):\ny, x, state, neighbors = item\nthreads = []\nItem 58: Using Queue for Concurrency Requires Refactoring \nthread = StoppableWorker(\ncount_neighbors_thread, in_queue, logic_queue)\nthread.start()\nthread = StoppableWorker(\ngame_logic_thread, logic_queue, out_queue)\nthread.start()\nitem = (y, x, state, grid.get)\nin_queue.put(item)          # Fan out\nfor item in out_queue:              # Fan in\ny, x, next_state = item\nnext_grid.set(y, x, next_state)\nfor thread in threads:\nfor thread in threads:\nfor thread in threads:\nthread.join()\nusing Queue is a better approach than using Thread instances on their \nby Python (see Item 59: “Consider ThreadPoolExecutor When Threads \n✦ Using Queue instances with a fixed number of worker threads \nimproves the scalability of fan-out and fan-in using threads.\nItem 58: Using Queue for Concurrency Requires Refactoring \nItem 59:  Consider ThreadPoolExecutor When Threads \n(see Item 57: “Avoid Creating New Thread Instances for On-demand \nallel I/O problem from the Game of Life example (see Item 56: “Know \nInstead of starting a new Thread instance for each Grid square, I can \nseparate thread.\nItem 59: Consider ThreadPoolExecutor When Threads Are Necessary \nrefactoring, easily avoiding the cost of thread startup each time fan-\nblow-up issues of using threads directly, it also limits I/O parallel-\nItem 60:  Achieve Highly Concurrent I/O with ",
      "keywords": [
        "Thread",
        "Concurrency Requires Refactoring",
        "Item",
        "Queue",
        "Thread Instances",
        "grid",
        "Concurrency",
        "Concurrency Requires",
        "ALIVE",
        "game",
        "state",
        "logic",
        "neighbors",
        "Requires Refactoring",
        "Avoid Creating"
      ],
      "concepts": [
        "thread",
        "items",
        "grid",
        "queue",
        "state",
        "concurrency",
        "concurrent",
        "classes",
        "fan",
        "fanning"
      ],
      "similar_chapters": [
        {
          "book": "Effective-Python",
          "chapter": 28,
          "title": "",
          "score": 0.832,
          "base_score": 0.682,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 26,
          "title": "",
          "score": 0.754,
          "base_score": 0.604,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 30,
          "title": "",
          "score": 0.643,
          "base_score": 0.493,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 25,
          "title": "",
          "score": 0.635,
          "base_score": 0.485,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 29,
          "title": "",
          "score": 0.61,
          "base_score": 0.46,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "thread",
          "threads",
          "fan",
          "item",
          "concurrency"
        ],
        "semantic": [],
        "merged": [
          "thread",
          "threads",
          "fan",
          "item",
          "concurrency"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.2577008157017259,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:03.224518+00:00"
      }
    },
    {
      "chapter_number": 28,
      "title": "Segment 28 (pages 290-298)",
      "start_page": 290,
      "end_page": 298,
      "summary": "Item 60: Achieve Highly Concurrent I/O with Coroutines \n“Avoid Creating New Thread Instances for On-demand Fan-out,” Item \nPython addresses the need for highly concurrent I/O with coroutines.\nThe cost of starting a coroutine is a function call.\nthreads, coroutines are independent functions that can consume \npowering coroutines is the event loop, which can do highly concurrent \nallow for I/O to occur within the game_logic function while overcom-\ncoroutine by defining it using async def instead of def.\nasync def game_logic(state, neighbors):\nThe simulate function also needs to become a coroutine:\nThe coroutine version of the simulate function requires some \nit returns a coroutine instance that can be used with an await \nItem 60: Achieve Highly Concurrent I/O with Coroutines \nrun the step_cell coroutines concurrently and resume execution \nsimulate coroutine in an event loop and carry out its dependent I/O:\nasync def game_logic(state, neighbors):\nItem 61: Know How to Port Threaded I/O to asyncio \n✦ Coroutines can use fan-out and fan-in in order to parallelize I/O, \nItem 61: Know How to Port Threaded I/O to asyncio\nusing blocking I/O and threads (see Item 53: “Use Threads for Block-\ndef __init__(self, connection):\nself.connection = connection\ndef send(self, command):\nself.connection.send(data)\ndef receive(self):\nThe server is implemented as a class that handles one connection at a \ndef __init__(self, *args):\nself._clear_state(None, None)\ndef _clear_state(self, lower, upper):\nself.secret = None\nself.guesses = []\ndef loop(self):\nwhile command := self.receive():\nself.set_params(parts)\nself.send_number()\nself.receive_report(parts)\ndef set_params(self, parts):\nself._clear_state(lower, upper)\ndef next_guess(self):\nif self.secret is not None:\nreturn self.secret\nguess = random.randint(self.lower, self.upper)\nif guess not in self.guesses:\ndef send_number(self):\nguess = self.next_guess()\nself.guesses.append(guess)\nself.send(format(guess))\ndef receive_report(self, parts):\nlast = self.guesses[-1]\nItem 61: Know How to Port Threaded I/O to asyncio \nself.secret = last\ndef __init__(self, *args):\nself._clear_state()\ndef _clear_state(self):\nself.secret = None\nself.last_distance = None\ndef session(self, lower, upper, secret):\nself.send(f'PARAMS {lower} {upper}')\nself._clear_state()\nself.send('PARAMS 0 -1')\ndef request_numbers(self, count):\nself.send('NUMBER')\ndata = self.receive()\nif self.last_distance == 0:\ndef report_outcome(self, number):\nnew_distance = math.fabs(number - self.secret)\nself.send(f'REPORT {decision}')\nI can run the server by having one thread listen on a socket and \nItem 61: Know How to Port Threaded I/O to asyncio ",
      "keywords": [
        "Item",
        "Coroutines",
        "ALIVE",
        "State",
        "Achieve Highly Concurrent",
        "Grid",
        "Highly Concurrent",
        "Port Threaded",
        "async def",
        "async",
        "server",
        "await",
        "function",
        "Thread",
        "neighbors"
      ],
      "concepts": [
        "thread",
        "functions",
        "function",
        "grid",
        "item",
        "classes",
        "state",
        "connection",
        "connections",
        "command"
      ],
      "similar_chapters": [
        {
          "book": "Effective-Python",
          "chapter": 27,
          "title": "",
          "score": 0.832,
          "base_score": 0.682,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 26,
          "title": "",
          "score": 0.67,
          "base_score": 0.52,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 29,
          "title": "",
          "score": 0.654,
          "base_score": 0.504,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 30,
          "title": "",
          "score": 0.63,
          "base_score": 0.48,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 25,
          "title": "",
          "score": 0.597,
          "base_score": 0.447,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "self",
          "def",
          "coroutines",
          "secret",
          "self secret"
        ],
        "semantic": [],
        "merged": [
          "self",
          "def",
          "coroutines",
          "secret",
          "self secret"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.3026408229643624,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:03.224553+00:00"
      }
    },
    {
      "chapter_number": 29,
      "title": "Segment 29 (pages 299-314)",
      "start_page": 299,
      "end_page": 314,
      "summary": "The client runs in the main thread and returns the results of the \ndef run_client(address):\ndef __init__(self, reader, writer):             # Changed\nasync def send(self, command):\nself.writer.write(data)                     # Changed\nasync def receive(self):\nline = await self.reader.readline()         # Changed\nasync def loop(self):                           # Changed\nItem 61: Know How to Port Threaded I/O to asyncio \nwhile command := await self.receive():      # Changed\nawait self.send_number()            # Changed\nasync def send_number(self):                    # Changed\nThe first command method for the client requires a few async and await \nasync def session(self, lower, upper, secret):  # Changed\nawait self.send('PARAMS 0 -1')          # Changed\nasync def request_numbers(self, count):         # Changed\nawait self.send('NUMBER')               # Changed\ndata = await self.receive()             # Changed\nasync def report_outcome(self, number):         # Changed\nawait self.send(f'REPORT {decision}')       # Changed\nto use the asyncio built-in module and its start_server function:\nasync def handle_async_connection(reader, writer):\nasync def run_async_server(address):\nThe run_client function that initiates the game requires changes on \nItem 61: Know How to Port Threaded I/O to asyncio \nlines in the function that require interaction with coroutines need to \nasync def run_async_client(address):\nstreams = await asyncio.open_connection(*address)   # New\nWhat’s most interesting about run_async_client is that I didn’t have \nI use the asyncio.create_task function to \nenqueue the server for execution on the event loop so that it runs in \nserver = run_async_server(address)\nresults = await run_async_client(address)\nasyncio.run(main_async())\nItem 61: Know How to Port Threaded I/O to asyncio \nasyncio Event Loop to Maximize Responsiveness”).\ning code that uses threads and blocking I/O over to coroutines and \nItem 62:  Mix Threads and Coroutines to Ease the \nover to use asyncio with coroutines.\nneed threads to be able to run coroutines, and you need coroutines to \nItem 62: Mix Threads and Coroutines to Ease the Transition to asyncio \nWhen the input file handle is closed, the worker thread exits:\ndef tail_file(handle, interval, write_func):\ndef run_threads(handles, interval, output_path):\nGiven a set of input paths and an output path, I can call run_threads \nrun_threads(handles, 0.1, output_path)\nI incrementally convert this code to use asyncio and coroutines \n1. Change a top function to use async def instead of def.\nloop—to use asyncio.run_in_executor instead.\nasyncio.run_coroutine_threadsafe function).\n4. Try to eliminate get_event_loop and run_in_executor calls by \nHere, I apply steps 1–3 to the run_threads function:\nasync def run_tasks_mixed(handles, interval, output_path):\nasync def write_async(data):\nfuture = asyncio.run_coroutine_threadsafe(\ntask = loop.run_in_executor(\nThe run_in_executor method instructs the event loop to run a given \nout corresponding await expressions, the run_tasks_mixed coroutine \nThen, the asyncio.gather function along with an await expression \nfans in the tail_file threads until they all complete (see Item 56: \nItem 62: Mix Threads and Coroutines to Ease the Transition to asyncio \nby using asyncio.run_coroutine_threadsafe.\ncase—and have it execute in the event loop from the main thread (or \nthreads together and ensures that all writes to the output file are only \ndone by the event loop in the main thread.\nI use the asyncio.run \nfunction to start the coroutine and run the main event loop:\nasyncio.run(run_tasks_mixed(handles, 0.1, output_path))\nNow, I can apply step 4 to the run_tasks_mixed function by moving \nasync def tail_async(handle, interval, write_func):\nline = await loop.run_in_executor(\nget_event_loop and run_in_executor down the stack and out of the \nasync def run_tasks(handles, interval, output_path):\nasync def write_async(data):\ncoro = tail_async(handle, interval, write_async)\nasyncio.run(run_tasks(handles, 0.1, output_path))\ncoroutine versions and run the event loop instead of implement-\nTo run that coroutine until it finishes, I need to \nItem 62: Mix Threads and Coroutines to Ease the Transition to asyncio \ncreate an event loop for each tail_file worker thread and then call \nthread and drive the event loop until the tail_async coroutine exits, \ndef tail_file(handle, interval, write_func):\nloop = asyncio.new_event_loop()\nasync def write_async(data):\ncoro = tail_async(handle, interval, write_async)\nI can verify that everything works as expected by calling run_threads \nrun_threads(handles, 0.1, output_path)\nthe run_threads function to a coroutine.\n(see Item 63: “Avoid Blocking the asyncio Event Loop to Maximize \n✦ The awaitable run_in_executor method of the asyncio event \nloop enables coroutines to run synchronous functions in \n✦ The run_until_complete method of the asyncio event loop enables \nsynchronous code to run a coroutine until it finishes.\nasyncio.run_coroutine_threadsafe function provides the same \nItem 63: Avoid Blocking the asyncio Event Loop \nItem 63:  Avoid Blocking the asyncio Event Loop to \n(see Item 62: “Mix Threads and Coroutines to Ease the Transition to \nasync def run_tasks(handles, interval, output_path):\nasync def write_async(data):\ncoro = tail_async(handle, interval, write_async)\nfor the output file handle happen in the main event loop.\nparameter to the asyncio.run function.\nasync def slow_coroutine():\nasyncio.run(slow_coroutine(), debug=True)\neverything required to write to the output file using its own event \ndef __init__(self, output_path):\nself.loop = asyncio.new_event_loop()\ndef run(self):\nasyncio.set_event_loop(self.loop)\nself.loop.run_forever()\nself.loop.run_until_complete(asyncio.sleep(0))\nCoroutines in other threads can directly call and await on the write \nasync def real_write(self, data):\nself.output.write(data)\nasync def write(self, data):\nfuture = asyncio.run_coroutine_threadsafe(\nasync def real_stop(self):\nasync def stop(self):\nfuture = asyncio.run_coroutine_threadsafe(\nwithout slowing down the main event loop thread:\nasync def __aenter__(self):\nawait loop.run_in_executor(None, self.start)\nasync def __aexit__(self, *_):\nning slow system calls in the main event loop thread:\nasync def tail_async(handle, interval, write_func):\nasync def run_fully_async(handles, interval, output_path):\ncoro = tail_async(handle, interval, output.write)\nItem 63: Avoid Blocking the asyncio Event Loop ",
      "keywords": [
        "async def",
        "async",
        "event loop",
        "Item",
        "Changed async def",
        "asyncio Event Loop",
        "threads",
        "changed",
        "loop",
        "run",
        "async def run",
        "output",
        "await",
        "event",
        "coroutines"
      ],
      "concepts": [
        "asyncio",
        "thread",
        "function",
        "functionality",
        "functions",
        "await",
        "changed",
        "changes",
        "async",
        "handling"
      ],
      "similar_chapters": [
        {
          "book": "Effective-Python",
          "chapter": 26,
          "title": "",
          "score": 0.716,
          "base_score": 0.566,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 28,
          "title": "",
          "score": 0.654,
          "base_score": 0.504,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 27,
          "title": "",
          "score": 0.61,
          "base_score": 0.46,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 25,
          "title": "",
          "score": 0.57,
          "base_score": 0.42,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 30,
          "title": "",
          "score": 0.544,
          "base_score": 0.394,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "asyncio",
          "async",
          "async def",
          "loop",
          "event"
        ],
        "semantic": [],
        "merged": [
          "asyncio",
          "async",
          "async def",
          "loop",
          "event"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.2753079287387964,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:03.224587+00:00"
      }
    },
    {
      "chapter_number": 30,
      "title": "Segment 30 (pages 315-323)",
      "start_page": 315,
      "end_page": 323,
      "summary": "At some point in writing Python programs, you may hit the perfor-\nUnfortunately, Python’s global interpreter lock (GIL) prevents true \nparallelism in threads (see Item 53: “Use Threads for Blocking I/O, \nmodule, using the C language.\nand can run faster than Python, eliminating the need for parallelism \ndent of the Python interpreter that run in parallel and utilize multiple \nunderstandable in Python can become verbose and complicated in C.\nItem 64: Consider concurrent.futures for True Parallelism \nis equivalent to the original Python code and that no bugs have been \ntem of C-extension modules in the Python community that speed up \nOptimized Python programs usually don’t have \ninvestment in Python to solve difficult computational problems.\nconcurrent.futures built-in module, may be exactly what you need \nlize multiple CPU cores in parallel by running additional interpreters \nsive with Python and utilize multiple CPU cores.\nresults = list(map(my_module.gcd, NUMBERS))\nRunning this code on multiple Python threads will yield no speed \nimprovement because the GIL prevents Python from using multiple \nusing the concurrent.futures module with its ThreadPoolExecutor \nclass and two worker threads (to match the number of CPU cores on \nresults = list(pool.map(my_module.gcd, NUMBERS))\nwith the ProcessPoolExecutor from the concurrent.futures module, \n# run_parallel.py\nresults = list(pool.map(my_module.gcd, NUMBERS))\n1. It takes each item from the numbers input data to map.\n2. It serializes the item into binary data by using the pickle module \n3. It copies the serialized data from the main interpreter process to \nItem 64: Consider concurrent.futures for True Parallelism \n4. It deserializes the data back into Python objects, using pickle in \n5. It imports the Python module containing the gcd function.\n6. It runs the function on the input data in parallel with other child \n9. It deserializes the binary data back into Python objects in the \nprogram through parallelization.\nof a single process shared between Python threads.\nclass to run isolated, high-leverage functions in threads.\n✦ Moving CPU bottlenecks to C-extension modules can be an effective \nPython code.\n✦ The multiprocessing module provides powerful tools that can paral-\nlelize certain types of Python computation with minimal effort.\nconcurrent.futures built-in module and its simple ProcessPoolExecutor \nItem 64: Consider concurrent.futures for True Parallelism \nOnce you’ve written a useful Python program, the next step is to \nPython has \nbuilt-in features and modules that aid in hardening your  programs so \nyou’re implementing Python programs that handle a non-trivial \nLuckily, Python includes many of the algorithms and data structures \nItem 65:  Take Advantage of Each Block in try/except\nduring exception handling in Python.\ntionality of try, except, else, and finally blocks.\nUse try/finally when you want exceptions to propagate up but also \nwant to run cleanup code even when exceptions occur.\nusage of try/finally is for reliably closing file handles (see Item 66: \ndef try_finally_example(filename):\nhandle.close()        # Always runs after try block\nthe calling code, but the close method of handle in the finally block \ndata = try_finally_example(filename)\nYou must call open before the try block because exceptions that occur \ntry_finally_example('does_not_exist.txt')\nthe try block doesn’t raise an exception, the else block runs.\nelse block helps you minimize the amount of code in the try block, ",
      "keywords": [
        "Python",
        "True Parallelism",
        "multiple CPU cores",
        "CPU cores",
        "Parallelism",
        "Item",
        "module",
        "Python programs",
        "CPU",
        "multiple CPU",
        "data",
        "code",
        "threads",
        "Python threads",
        "Python code"
      ],
      "concepts": [
        "python",
        "module",
        "item",
        "data",
        "run",
        "running",
        "runs",
        "computers",
        "computationally",
        "program"
      ],
      "similar_chapters": [
        {
          "book": "Effective-Python",
          "chapter": 25,
          "title": "",
          "score": 0.707,
          "base_score": 0.557,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 33,
          "title": "",
          "score": 0.68,
          "base_score": 0.53,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 27,
          "title": "",
          "score": 0.643,
          "base_score": 0.493,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 28,
          "title": "",
          "score": 0.63,
          "base_score": 0.48,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 26,
          "title": "",
          "score": 0.59,
          "base_score": 0.44,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "python",
          "cpu",
          "futures",
          "concurrent futures",
          "block"
        ],
        "semantic": [],
        "merged": [
          "python",
          "cpu",
          "futures",
          "concurrent futures",
          "block"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.31491019140602833,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:03.224622+00:00"
      }
    },
    {
      "chapter_number": 31,
      "title": "Segment 31 (pages 324-335)",
      "start_page": 324,
      "end_page": 335,
      "summary": "Item 65: Take Advantage of Each Block in try/except/else/finally \nprint('* Loading JSON data')\nresult_dict = json.loads(data)  # May raise ValueError\nprint('* Handling ValueError')\nIn the successful case, the JSON data is decoded in the try block, \nHere, the try block is used to read the file and process it; the \nexcept block is used to handle exceptions from the try block that are \nprint('* Loading JSON data')\nop = json.loads(data)   # May raise ValueError\nIn the successful case, the try, else, and finally blocks run:\nIf the calculation is invalid, the try, except, and finally blocks run, \nIf the JSON data was invalid, the try block runs and raises an excep-\ntion, the finally block runs, and then the exception is propagated up \nItem 65: Take Advantage of Each Block in try/except/else/finally \ndivide_json function at the same time that my hard drive runs out of \nresult data, the finally block still ran and closed the file handle as \n✦ The try/finally compound statement lets you run cleanup code \nregardless of whether exceptions were raised in the try block.\nin with statements to indicate that the indented code block runs only \nlevel before running the code in the with block and reduces the log-\nNow, I can call the same logging function again but in the \nThis time, all of the debug messages are \nprinted to the screen during the with block.\nning outside the with block won’t print debug messages:\nopen returns a file handle for the as target of with, and it closes the \nthe file handle every time.\nbecause the logging severity level is set low enough in the with block \nwon’t print anything because the default logging severity level for the \nlogging.debug('This will not print')\nAfter the with statement exits, calling debug logging methods on the \nLogger named 'my-log' will not print anything because the default \nlogging.debug('This will not print')\n✦ The with statement allows you to reuse logic from try/finally blocks \nItem 67: Use datetime Instead of time for Local Clocks\nCoordinated Universal Time (UTC) is the standard, time-zone- \nyourself converting time between UTC and local clocks for the sake of \nItem 67: Use datetime Instead of time for Local Clocks \nPython provides two ways of accomplishing time zone conversions.\nThe old way, using the time built-in module, is terribly error prone.\nYou should be acquainted with both time and datetime to thoroughly \nunderstand why datetime is the best choice and time should be \nThe time Module\nThe localtime function from the time built-in module lets you convert \nTime in my case).\nThis local time can be printed in human-readable \nimport time\nlocal_tuple = time.localtime(now)\ntime_str = time.strftime(time_format, local_tuple)\nprint(time_str)\nin human-readable local time and converting it to UTC time.\ndo this by using the strptime function to parse the time string, and \nthen calling mktime to convert local time to a UNIX timestamp:\nutc_now = time.mktime(time_tuple)\nHow do you convert local time in one time zone to local time in \nanother time zone?\nues from the time, localtime, and strptime functions to do time zone \nTime zones change all the time \nthe time zone changes automatically.\nPython lets you use these time \nzones through the time module if your platform supports it.\nplatforms, such as Windows, some time zone functionality isn’t avail-\nable from time at all.\nFor example, here I parse a departure time from \nprint(time_str)\nassume that other time zones known to my computer will work.\nthe time module unreliable in Python.\nThe time module fails to consis-\ntently work properly for multiple local times.\nusing the time module for this purpose.\nIf you must use time, use it \nonly to convert between UTC and the host computer’s local time.\nThe second option for representing times in Python is the datetime \nLike the time module, \ndatetime can be used to convert from the current time in UTC to local \ntime.\nHere, I convert the present time in UTC to my computer’s local time, \nThe datetime module can also easily convert a local time back to a \ntime_str = '2019-03-16 15:14:35'\nnow = datetime.strptime(time_str, time_format)\nutc_now = time.mktime(time_tuple)\nUnlike the time module, the datetime module has facilities for reli-\nably converting from one local time to another local time.\ndatetime only provides the machinery for time zone operations with \nis missing time zone definitions besides UTC.\npytz contains a full database of every time zone \nTo use pytz effectively, you should always convert local times to UTC \nThen, convert to local times as a final step.\nFor example, here I convert a New York City flight arrival time to a \nnyc_dt_naive = datetime.strptime(arrival_nyc, time_format)\nItem 67: Use datetime Instead of time for Local Clocks \ntime:\nJust as easily, I can convert it to the local time in Nepal:\n✦ Avoid using the time module for translating between different time \nmodule to reliably convert between times in different time zones.\n✦ Always represent time in UTC and do conversions to local time as ",
      "keywords": [
        "Loading JSON data",
        "time",
        "Loading JSON",
        "local time",
        "JSON data",
        "JSON",
        "Block",
        "UTC",
        "time zone",
        "data",
        "time Module",
        "local",
        "module",
        "Item",
        "finally"
      ],
      "concepts": [
        "time",
        "printed",
        "function",
        "functions",
        "functionality",
        "data",
        "utc",
        "logging",
        "log",
        "handling"
      ],
      "similar_chapters": [
        {
          "book": "Effective-Python",
          "chapter": 38,
          "title": "",
          "score": 0.557,
          "base_score": 0.407,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 25,
          "title": "",
          "score": 0.481,
          "base_score": 0.331,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 26,
          "title": "",
          "score": 0.474,
          "base_score": 0.324,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 35,
          "title": "",
          "score": 0.469,
          "base_score": 0.319,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 30,
          "title": "",
          "score": 0.461,
          "base_score": 0.311,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "time",
          "local",
          "local time",
          "block",
          "zone"
        ],
        "semantic": [],
        "merged": [
          "time",
          "local",
          "local time",
          "block",
          "zone"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.2721099554988337,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:03.224658+00:00"
      }
    },
    {
      "chapter_number": 32,
      "title": "Segment 32 (pages 336-344)",
      "start_page": 336,
      "end_page": 344,
      "summary": "For example, say that I want to use a Python object to represent the \nclass GameState:\nstate = GameState()\nthe GameState object to a file:\npickle.dump(state, f)\nGameState object as if it had never been serialized:\nstate_after = pickle.load(f)\nthe GameState class\nclass GameState:\nSerializing the new version of the GameState class using pickle will \nstate = GameState()\nserialized = pickle.dumps(state)\nstate_after = pickle.loads(serialized)\nwith the new definition of the GameState class:\nstate_after = pickle.load(f)\nthe returned object is an instance of the new GameState class:\nThis behavior is a byproduct of the way the pickle module works.\nprimary use case is making object serialization easy.\nuse of pickle moves beyond trivial usage, the module’s functionality \nfor serializing and deserializing Python objects, allowing you to con-\nclass GameState:\ndef __init__(self, level=0, lives=4, points=0):\nTo use this constructor for pickling, I define a helper function that \ndef pickle_game_state(game_state):\nkwargs = game_state.__dict__\nreturn unpickle_game_state, (kwargs,)\nNow, I need to define the unpickle_game_state helper.\ntion takes serialized data and parameters from pickle_game_state \ndef unpickle_game_state(kwargs):\ncopyreg.pickle(GameState, pickle_game_state)\nstate = GameState()\nstate.points += 1000\nserialized = pickle.dumps(state)\nstate_after = pickle.loads(serialized)\nclass GameState:\ndef __init__(self, level=0, lives=4, points=0, magic=5):\nBut unlike before, deserializing an old GameState object will result in \nunpickle_game_state calls the GameState constructor directly instead \nThis causes old game state \nstate_after = pickle.loads(serialized)\nAfter:  {'level': 0, 'lives': 4, 'points': 1000, 'magic': 5}\nfine the GameState class to no longer have a lives field:\nclass GameState:\ndef __init__(self, level=0, points=0, magic=5):\nbe passed to the GameState constructor by the unpickle_game_state \npickling a new GameState object:\ndef pickle_game_state(game_state):\nkwargs = game_state.__dict__\nreturn unpickle_game_state, (kwargs,)\ndef unpickle_game_state(kwargs):\ncopyreg.pickle(GameState, pickle_game_state)\nstate_after = pickle.loads(serialized)\nunpickle_game_state function.\nHere, I rename the GameState class to BetterGameState and remove \ndef __init__(self, level=0, points=0, magic=5):\nAttempting to deserialize an old GameState object now fails because \nobject’s class is encoded in the pickled data:\nfor the function to use for unpickling an object.\ncopyreg.pickle(BetterGameState, pickle_game_state)\nunpickle_game_state is encoded in the serialized data instead of \nserialized = pickle.dumps(state)\n¯\\x94\\x8c\\x13unpickle_game_state\\x94\\x93\\x94}\\x94(\\x8c\nwhich the unpickle_game_state function is present.\n✦ The pickle built-in module is useful only for serializing and deseri-\n✦ Deserializing previously pickled objects may break if the classes \n✦ Use the copyreg built-in module with pickle to ensure backward \nThe solution is to use the Decimal class from the decimal built-in mod-\nThe Decimal class provides fixed point math of 28 decimal places \ncost = rate * seconds / Decimal(60)\nsmall_cost = rate * seconds / Decimal(60)\nLuckily, the Decimal class has a built-in function for rounding to \nrounded = small_cost.quantize(Decimal('0.01'),",
      "keywords": [
        "state",
        "decimal",
        "GameState",
        "game",
        "GameState object",
        "pickle",
        "GameState class",
        "object",
        "points",
        "level",
        "serialized",
        "lives",
        "Decimal class",
        "module",
        "Python"
      ],
      "concepts": [
        "pickle",
        "pickling",
        "serializing",
        "serialize",
        "decimal",
        "points",
        "state",
        "classes",
        "object",
        "function"
      ],
      "similar_chapters": [
        {
          "book": "Effective-Python",
          "chapter": 23,
          "title": "",
          "score": 0.719,
          "base_score": 0.569,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 18,
          "title": "",
          "score": 0.702,
          "base_score": 0.552,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 22,
          "title": "",
          "score": 0.681,
          "base_score": 0.531,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 16,
          "title": "",
          "score": 0.63,
          "base_score": 0.48,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 24,
          "title": "",
          "score": 0.614,
          "base_score": 0.464,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "gamestate",
          "pickle",
          "unpickle_game_state",
          "serialized",
          "decimal"
        ],
        "semantic": [],
        "merged": [
          "gamestate",
          "pickle",
          "unpickle_game_state",
          "serialized",
          "decimal"
        ]
      },
      "topic_id": 1,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.3493031178538266,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:03.224700+00:00"
      }
    },
    {
      "chapter_number": 33,
      "title": "Segment 33 (pages 345-356)",
      "start_page": 345,
      "end_page": 356,
      "summary": "Item 70: Profile Before Optimizing\nprovides a built-in profiler for determining which parts of a program \nHere, I define a function that sorts a list of data using \ninefficient version of the insert_value function that does a linear scan \nItem 70: Profile Before Optimizing \nTo profile insertion_sort and insert_value, I create a data set of ran-\ndom numbers and define a test function to pass to the profiler:\nthe performance of your program while it’s being profiled.\nWhen profiling a Python program, be sure that what you’re measuring is the \nthe test function through it using the runcall method:\n20003 function calls in 1.320 seconds\n■ncalls: The number of calls to the function during the profiling \nexcluding time spent executing other functions it calls.\nfunction each time it is called, excluding time spent executing \nother functions it calls.\nfunction, including time spent in all other functions it calls.\nfunction each time it is called, including time spent in all other \nfunctions it calls.\nuse of CPU in my test is the cumulative time spent in the insert_value \nfunction.\nThe new function is much faster, with a cumulative time spent \nfunction:\nItem 70: Profile Before Optimizing \n30003 function calls in 0.017 seconds\nfunction is called by many different parts of your program.\nFor example, here the my_utility function is called repeatedly by two \ndifferent functions in the program:\n20242 function calls in 0.118 seconds\nThe my_utility function is clearly the source of most execution time, \nof each function:\nThis profiler statistics table shows functions called on the left and \nFunction                                was called by...\nProfiling.md:172(second_func)           <-      20    0.000    0.001  main.py:176(my_program)\n✦ It’s important to profile Python programs before optimizing because \nto profile a tree of function calls in isolation.\nItem 71: Prefer deque for Producer–Consumer Queues\nqueue is used when one function gathers values to process and \nItem 71: Prefer deque for Producer–Consumer Queues \nconsumer queue.\nI also define a placeholder function for receiving a single email, pre-\nThe producing function receives emails and enqueues them to be con-\nThis function uses the append method on the \nlist to add new messages to the end of the queue so they are pro-\ndef produce_emails(queue):\nqueue.append(email)  # Producer\nThe consuming function does something useful with the emails.\nfunction calls pop(0) on the queue, which removes the very first item \nfrom the beginning of the queue, the consumer ensures that the items \ndef consume_one_email(queue):\nif not queue:\nemail = queue.pop(0)  # Consumer\nkeep_running function returns False (see Item 60: “Achieve Highly \ndef loop(queue, keep_running):\nproduce_emails(queue)\nconsume_one_email(queue)\nthroughput at the cost of end-to-end latency (see Item 55: “Use Queue \nTo analyze the performance of using list as a FIFO queue, I can \nqueue using the append method of list (matching the producer func-\ndef print_results(count, tests):\ndef list_append_benchmark(count):\ndef run(queue):\nqueue.append(i)\nRunning this benchmark function with different levels of cardinality \ncomparison = list_append_benchmark(count)\nItem 71: Prefer deque for Producer–Consumer Queues \nitems from the beginning of the queue (matching the consumer func-\ndef list_pop_benchmark(count):\nreturn list(range(count))\ndef run(queue):\nwhile queue:\nqueue.pop(0)\nI can similarly run this benchmark for queues of different sizes to see \ncomparison = list_pop_benchmark(count)\na list with pop(0) scales quadratically as the length of the queue \nI need to call pop(0) for every item in the list, and thus I end up \nqueue.\nstay the same as it was when using a list for the queue.\nlist.pop method call in consume_one_email must change to call the \nmethod must be called with a deque instance instead of a list.\ndef consume_one_email(queue):\nif not queue:\nemail = queue.popleft()  # Consumer\nperformance (matching the producer function’s usage) has stayed \ndef deque_append_benchmark(count):\nItem 71: Prefer deque for Producer–Consumer Queues \ndef run(queue):\nqueue.append(i)\nthe consumer function’s usage of deque:\ndef run(queue):\nwhile queue:\n✦ The list type can be used as a FIFO queue by having the producer \ncall append to add items and the consumer call pop(0) to receive \nItem 71: Prefer deque for Producer–Consumer Queues ",
      "keywords": [
        "time Count",
        "count",
        "time",
        "function",
        "queue",
        "data size",
        "data",
        "list",
        "Consumer Queues",
        "Performance",
        "size",
        "Consumer",
        "Item",
        "program",
        "Python"
      ],
      "concepts": [
        "function",
        "functions",
        "queues",
        "times",
        "profile",
        "profiled",
        "item",
        "returns",
        "count",
        "emails"
      ],
      "similar_chapters": [
        {
          "book": "Effective-Python",
          "chapter": 30,
          "title": "",
          "score": 0.68,
          "base_score": 0.53,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 38,
          "title": "",
          "score": 0.564,
          "base_score": 0.414,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 25,
          "title": "",
          "score": 0.54,
          "base_score": 0.39,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 35,
          "title": "",
          "score": 0.523,
          "base_score": 0.373,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 29,
          "title": "",
          "score": 0.477,
          "base_score": 0.327,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "queue",
          "consumer",
          "function",
          "producer",
          "queue queue"
        ],
        "semantic": [],
        "merged": [
          "queue",
          "consumer",
          "function",
          "producer",
          "queue queue"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.27931818654582813,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:03.224735+00:00"
      }
    },
    {
      "chapter_number": 34,
      "title": "Segment 34 (pages 357-368)",
      "start_page": 357,
      "end_page": 368,
      "summary": "✦ Searching sorted data contained in a list takes linear time using \nItem 73: Know How to Use heapq for Priority Queues\nbooks.\nThere are people returning their borrowed books on time.\nbooks.\nclass Book:\nItem 73: Know How to Use heapq for Priority Queues \nlist and sorting it by due_date each time a new Book is added:\ndef add_book(queue, book):\nqueue.append(book)\nqueue = []\nadd_book(queue, Book('Don Quixote', '2019-06-07'))\nadd_book(queue, Book('Frankenstein', '2019-06-05'))\nadd_book(queue, Book('Les Misérables', '2019-06-08'))\nadd_book(queue, Book('War and Peace', '2019-06-03'))\nIf I can assume that the queue of borrowed books is always in sorted \noverdue book, if any, and remove it from the queue:\ndef next_overdue_book(queue, now):\nif queue:\nbook = queue[-1]\nif book.due_date < now:\nreturn book\nfound = next_overdue_book(queue, now)\nfound = next_overdue_book(queue, now)\nIf a book is returned before the due date, I can remove the scheduled \nreminder message by removing the Book from the list:\ndef return_book(queue, book):\nqueue.remove(book)\nqueue = []\nadd_book(queue, book)\nreturn_book(queue, book)\nnext_overdue_book(queue, now)\nIf I have len(queue) books to add, and the \nbooks \nwhile queue:\nqueue scales superlinearly as the number of books being borrowed \nItem 73: Know How to Use heapq for Priority Queues \nWhen a book is returned before the due date, I need to do a linear \nscan in order to find the book in the queue and remove it.\na book causes all subsequent items in the list to be shifted back \ndef list_return_benchmark(count):\nqueue = list(range(count))\ndef run(queue, to_return):\ncomparison = list_return_benchmark(count)\nHere, I reimplement the add_book function using the heapq module.\nThe queue is still a plain list.\nthe queue:\ndef add_book(queue, book):\nheappush(queue, book)\nqueue = []\nadd_book(queue, Book('Little Women', '2019-06-05'))\nadd_book(queue, Book('The Time Machine', '2019-05-30'))\nThe heapq module requires items in the priority queue to be compa-\nItem 73: Know How to Use heapq for Priority Queues \nclass Book:\nNow, I can add books to the priority queue by using the heapq.heappush \nqueue = []\nadd_book(queue, Book('Pride and Prejudice', '2019-06-01'))\nadd_book(queue, Book('The Time Machine', '2019-05-30'))\nadd_book(queue, Book('Crime and Punishment', '2019-06-06'))\nadd_book(queue, Book('Wuthering Heights', '2019-06-12'))\nAlternatively, I can create a list with all of the books in any order and \nqueue = [\nqueue = [\nTo check for overdue books, I inspect the first element in the list \ndef next_overdue_book(queue, now):\nif queue:\nbook = queue[0]           # Most overdue first\nif book.due_date < now:\nheappop(queue)        # Remove the overdue book\nreturn book\nNow, I can find and remove overdue books in order until there are \nbook = next_overdue_book(queue, now)\nbook = next_overdue_book(queue, now)\nnext_overdue_book(queue, now)\nItem 73: Know How to Use heapq for Priority Queues \nwhile queue:\nqueue \nbook from the priority queue until its due date.\nbe the first item in the list, and I can simply ignore the book if it’s \nclass Book:\nany book that’s already been returned:\ndef next_overdue_book(queue, now):\nwhile queue:\nbook = queue[0]\nif book.returned:\nif book.due_date < now:\nreturn book\nThis approach makes the return_book function extremely fast \ndef return_book(queue, book):\nbook.returned = True\nAlthough the queue \nItem 73: Know How to Use heapq for Priority Queues ",
      "keywords": [
        "book",
        "queue",
        "count",
        "list",
        "Item",
        "time",
        "priority queue",
        "add",
        "overdue",
        "time Count",
        "data",
        "overdue books",
        "index",
        "Priority",
        "date"
      ],
      "concepts": [
        "queues",
        "books",
        "returns",
        "item",
        "function",
        "functions",
        "functionality",
        "list",
        "index",
        "data"
      ],
      "similar_chapters": [
        {
          "book": "Effective-Python",
          "chapter": 10,
          "title": "",
          "score": 0.55,
          "base_score": 0.4,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 21,
          "title": "",
          "score": 0.546,
          "base_score": 0.396,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 17,
          "title": "",
          "score": 0.542,
          "base_score": 0.392,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 26,
          "title": "",
          "score": 0.452,
          "base_score": 0.452,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 8,
          "title": "",
          "score": 0.391,
          "base_score": 0.391,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "queue",
          "book",
          "queue book",
          "add_book",
          "add_book queue"
        ],
        "semantic": [],
        "merged": [
          "queue",
          "book",
          "queue book",
          "add_book",
          "add_book queue"
        ]
      },
      "topic_id": 2,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.25073313444690193,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:03.224779+00:00"
      }
    },
    {
      "chapter_number": 35,
      "title": "Segment 35 (pages 369-376)",
      "start_page": 369,
      "end_page": 376,
      "summary": "to download the video data in advance.\nprogram, I can implement this by requesting a chunk of data from the \n# Returns the byte offset in the video data\ndef request_chunk(video_id, byte_offset, size):\n# Returns size bytes of video_id's data from the offset\nbyte_offset = timecode_to_index(video_id, timecode)\nvideo_data = request_chunk(video_id, byte_offset, size)\nof video data?\nchunk is extracted from gigabytes of video data that’s cached in mem-\nvideo_data = ...\n# bytes containing data for video_id\nchunk = video_data[byte_offset:byte_offset + size]\ntors: how much time it takes to slice the 20 MB video chunk from \nvideo_data, and how much time the socket takes to transmit that \ndata to the client.\nstand the performance characteristics of slicing bytes instances this \nchunk = video_data[byte_offset:byte_offset + size]\nIt took roughly 5 milliseconds to extract the 20 MB slice of data to \n5  milliseconds = 200 clients requesting new chunks in parallel, which \nproblem is that slicing a bytes instance causes the underlying data to \nA better way to write this code is by using Python’s built-in memoryview \nPython runtime and C extensions to access the underlying data \nbuffers that are behind objects like bytes instances.\nmemoryview instance without copying the underlying data.\nate a memoryview wrapping a bytes instance and inspect a slice of it:\nview = memoryview(data)\nprint('Data in view:   ', chunk.tobytes())\nprint('Underlying data:', chunk.obj)\nData in view:    b'haircut'\nvideo_view = memoryview(video_data)\nchunk = video_view[byte_offset:byte_offset + size]\nsome clients are sending live video streams to the server in order to \nlatest video data from the user in a cache that other clients can read \nHere’s what the implementation of reading 1 MB of new data \nchunk = socket.recv(size)\nvideo_view = memoryview(video_cache)\nbefore = video_view[:byte_offset]\nafter = video_view[byte_offset + size:]\nThe socket.recv method returns a bytes instance.\nnew data with the existing cache at the current byte_offset by using \nchunk = socket.recv(size)\nbefore = video_view[:byte_offset]\nafter = video_view[byte_offset + size:]\nIt takes 33 milliseconds to receive 1 MB and update the video cache.\nclients streaming in video data this way.\nA better way to write this code is to use Python’s built-in bytearray \nThe bytearray type is like a mutable version of bytes that allows for \nsuch a memoryview, the resulting object can be used to assign data to a \nback together after data was received from the client:\nwrite_view[:] = b'-10 bytes-'\nRawIOBase.readinto, use the buffer protocol to receive or read data \nwith a memoryview slice to receive data into an underlying bytearray \nwrite_view = memoryview(video_array)\nchunk = write_view[byte_offset:byte_offset + size]\nsocket.recv_into(chunk)\nchunk = write_view[byte_offset:byte_offset + size]\nsocket.recv_into(chunk)\n✦ The bytearray built-in type provides a mutable bytes-like type \nthat can be used for zero-copy data reads with functions like \n✦ A memoryview can wrap a bytearray, allowing for received data to be ",
      "keywords": [
        "video",
        "data",
        "video data",
        "chunk",
        "byte",
        "Python",
        "memoryview",
        "size",
        "Item",
        "offset",
        "view",
        "underlying data",
        "bytearray",
        "Performance",
        "run"
      ],
      "concepts": [
        "chunk",
        "bytes",
        "memoryview",
        "size",
        "items",
        "type",
        "typing",
        "uses",
        "buffer",
        "program"
      ],
      "similar_chapters": [
        {
          "book": "Effective-Python",
          "chapter": 26,
          "title": "",
          "score": 0.595,
          "base_score": 0.445,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 33,
          "title": "",
          "score": 0.523,
          "base_score": 0.373,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 29,
          "title": "",
          "score": 0.486,
          "base_score": 0.336,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 30,
          "title": "",
          "score": 0.477,
          "base_score": 0.327,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 31,
          "title": "",
          "score": 0.469,
          "base_score": 0.319,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "byte_offset",
          "chunk",
          "data",
          "video",
          "memoryview"
        ],
        "semantic": [],
        "merged": [
          "byte_offset",
          "chunk",
          "data",
          "video",
          "memoryview"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.2212497380655682,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:03.224811+00:00"
      }
    },
    {
      "chapter_number": 36,
      "title": "Segment 36 (pages 377-390)",
      "start_page": 377,
      "end_page": 390,
      "summary": "■Calling the str function before passing the value to print\nprint(str(my_value))\nprint(my_value.__str__())\ncontains tests for each behavior that I expect:\n# utils_test.py\ndef test_to_str_bytes(self):\ndef test_to_str_str(self):\ndef test_failing(self):\nThen, I run the test file using the Python command line.\ntwo of the test methods pass and one fails, with a helpful error mes-\n$ python3 utils_test.py\nFile \"utils_test.py\", line 15, in test_failing\nRan 3 tests in 0.002s\nTests are organized into TestCase subclasses.\nEach test case is a \nmethod beginning with the word test.\nIf a test method runs without \ntest fails, the TestCase subclass continues running the other test \nmethods so you can get a full picture of how all your tests are doing \n$ python3 utils_test.py UtilsTestCase.test_to_str_bytes\nRan 1 test in 0.000s\nI have the same test case written with and without using a helper \n# assert_test.py\ndef test_assert_helper(self):\ndef test_assert_statement(self):\n$ python3 assert_test.py\nFAIL: test_assert_helper (__main__.AssertTestCase)\nFile \"assert_test.py\", line 16, in test_assert_helper\nFAIL: test_assert_statement (__main__.AssertTestCase)\nFile \"assert_test.py\", line 11, in test_assert_statement\nRan 2 tests in 0.001s\n# utils_error_test.py\ndef test_to_str_bad(self):\ndef test_to_str_bad_encoding(self):\nTestCase subclasses to make your tests more readable.\nbe run as if they’re test cases.\ntion methods, these custom test helpers often use the fail method to \nI define a custom test helper method for verifying the behavior of a \n# helper_test.py\ndef verify_complex_case(self, values, expected):\ntest_it = zip(expect_it, found_it)\nfor i, (expect, found) in enumerate(test_it):\ndef test_wrong_lengths(self):\ndef test_wrong_results(self):\nThe helper method makes the test cases short and readable, and the \n$ python3 helper_test.py\nFAIL: test_wrong_lengths (__main__.HelperTestCase)\nFile \"helper_test.py\", line 43, in test_wrong_lengths\nFile \"helper_test.py\", line 34, in verify_complex_case\nFAIL: test_wrong_results (__main__.HelperTestCase)\nFile \"helper_test.py\", line 52, in test_wrong_results\nFile \"helper_test.py\", line 24, in verify_complex_case\nRan 2 tests in 0.002s\nI usually define one TestCase subclass for each set of related tests.\nI often create one TestCase subclass for test-\nallows the test method to continue testing other cases even after one \ntest methods).\nTo show this, here I define an example data-driven test:\n# data_driven_test.py\ndef test_good(self):\ndef test_bad(self):\nThe 'no error' test case fails, printing a helpful error message, but \nall of the other cases are still tested and confirmed to pass:\n$ python3 data_driven_test.py\nFAIL: test_good (__main__.DataDrivenTestCase) [no error]\nRan 2 tests in 0.001s\n✦ You can create tests by subclassing the TestCase class from the \nTest methods on TestCase classes must start with \nthe word test.\nas assertEqual, to confirm expected behaviors in your tests instead \nItem 77: Isolate Tests from Each Other \n✦ Consider writing data-driven tests using the subTest helper method \nItem 77:  Isolate Tests from Each Other with setUp, \ntest methods can be run; this is sometimes called the test harness.\ntest method, respectively, so you can ensure that each test runs in \n# environment_test.py\nself.test_dir = TemporaryDirectory()\nself.test_dir.cleanup()\ndef test_modify_file(self):\nwith open(self.test_path / 'data.bin', 'w') as f:\nrun your integration tests.\ntest methods run without repeating that initialization.\n# integration_test.py\nprint('* Test setup')\nprint('* Test clean-up')\ndef test_end_to_end1(self):\nprint('* Test 1')\ndef test_end_to_end2(self):\nprint('* Test 2')\n$ python3 integration_test.py \n* Test setup\n* Test 1\nItem 78: Use Mocks to Test Code with Complex Dependencies \n* Test clean-up\n.* Test setup\n* Test 2\n* Test clean-up\nRan 2 tests in 0.000s\nintegration tests (for modules that interact with each other).\n✦ Use the setUp and tearDown methods to make sure your tests are \nmodule-level functions to manage any test harnesses you need for \nthe entire lifetime of a test module and all of the TestCase classes ",
      "keywords": [
        "Verify Related Behaviors",
        "TestCase",
        "def test",
        "Item",
        "str",
        "main",
        "TestCase Subclasses",
        "test methods",
        "Debugging",
        "Related Behaviors",
        "Verify Related",
        "test.py",
        "Debugging def test",
        "Python",
        "method"
      ],
      "concepts": [
        "tested",
        "python",
        "printing",
        "classes",
        "value",
        "method",
        "data",
        "fails",
        "item",
        "strings"
      ],
      "similar_chapters": [
        {
          "book": "Effective-Python",
          "chapter": 4,
          "title": "",
          "score": 0.691,
          "base_score": 0.541,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 16,
          "title": "",
          "score": 0.49,
          "base_score": 0.49,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 38,
          "title": "",
          "score": 0.477,
          "base_score": 0.477,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 18,
          "title": "",
          "score": 0.448,
          "base_score": 0.448,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 37,
          "title": "",
          "score": 0.436,
          "base_score": 0.436,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "test",
          "py",
          "tests",
          "testcase",
          "self"
        ],
        "semantic": [],
        "merged": [
          "test",
          "py",
          "tests",
          "testcase",
          "self"
        ]
      },
      "topic_id": 6,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.3510909567672242,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:03.224854+00:00"
      }
    },
    {
      "chapter_number": 37,
      "title": "Segment 37 (pages 391-402)",
      "start_page": 391,
      "end_page": 402,
      "summary": "get_animals(database, 'Meerkat')\nA better approach is to mock out the database.\nget_animals function without actually connecting to the database:\nmock = Mock(spec=get_animals)\nmock.return_value = expected\nThe Mock class creates a mock function.\nof the mock is the value to return when it is called.\nItem 78: Use Mocks to Test Code with Complex Dependencies \nOnce it’s created, I can call the mock, get its return value, and ver-\nthe mock to do anything; all I care about is that the database param-\nresult = mock(database, 'Meerkat')\nthe code that called the mock provided the correct arguments?\nthis, the Mock class provides the assert_called_once_with method, \nmock.assert_called_once_with(database, 'Meerkat')\nmock.assert_called_once_with(database, 'Giraffe')\nI can also use the assert_called_with method of Mock to \nmock = Mock(spec=get_animals)\nmock('database 1', 'Rabbit')\nmock('database 2', 'Bison')\nmock('database 3', 'Meerkat')\nmock.assert_called_with(ANY, 'Meerkat')\nmock = Mock(spec=get_animals)\nresult = mock(database, 'Meerkat')\nanimals at the zoo, given a set of database-interacting functions:\ndef feed_animal(database, name, when):\nItem 78: Use Mocks to Test Code with Complex Dependencies \nfeed_animal(database, name, now)\nAnd I need to mock out feed_animal to \nThe question is: Even if I know how to create these mock functions \nbeing tested to use the mock dependent functions instead of the \nfeeding_timedelta = food_func(database, species)\nanimals = animals_func(database, species)\nTo test this function, I need to create all of the Mock instances upfront \nnow_func = Mock(spec=datetime.utcnow)\nfood_func = Mock(spec=get_food_period)\nanimals_func = Mock(spec=get_animals)\nfeed_func = Mock(spec=feed_animal)\nThen, I can run the test by passing the mocks into the do_rounds \ndatabase,\nfood_func.assert_called_once_with(database, 'Meerkat')\nanimals_func.assert_called_once_with(database, 'Meerkat')\ncall(database, 'Spot', now_func.return_value),\ncall(database, 'Fluffy', now_func.return_value),\nI don’t verify the parameters to the datetime.utcnow mock or how many \nItem 78: Use Mocks to Test Code with Complex Dependencies \nunittest.mock.call helper and the assert_has_calls method.\nThe unittest.mock.patch family of functions makes \nFor example, here I override get_animals to be a mock using \nfrom unittest.mock import patch\nI need to mock out the current time returned by the datetime.utcnow \ndatetime.utcnow mock and use patch for all of the other mocks:\npatch.multiple function to create many mocks and set their \nnow_func = Mock(spec=datetime.utcnow)\nItem 79: Encapsulate Dependencies to Facilitate Mocking and Testing \nresult = do_rounds(database, 'Meerkat', utcnow=now_func)\nfood_func.assert_called_once_with(database, 'Meerkat')\nanimals_func.assert_called_once_with(database, 'Meerkat')\ncall(database, 'Spot', now_func.return_value),\ncall(database, 'Fluffy', now_func.return_value),\nMocks are useful in tests when \ncode being tested and how dependent functions were called by that \ncode, using the Mock.assert_called_once_with family of methods.\nfunctions can be used to inject mocks into the code being tested.\nMocking and Testing\nIn the previous item (see Item 78: “Use Mocks to Test Code with \nsuch as a database.\nating mocks and writing tests.\ndatabase.feed_animal(name, now)\nneed to use unittest.mock.patch to inject the mock into the code \nItem 79: Encapsulate Dependencies to Facilitate Mocking and Testing \nThe Mock \nclass returns a mock object for any attribute name that is accessed.\ndatabase = Mock(spec=ZooDatabase)\nprint(database.feed_animal)\ndatabase.feed_animal()\ndatabase.feed_animal.assert_any_call()\n<Mock name='mock.feed_animal' id='4384773408'>\nnow_func = Mock(spec=datetime.utcnow)\ndatabase = Mock(spec=ZooDatabase)\ndatabase.get_food_period.return_value = timedelta(hours=3)\ndatabase.get_animals.return_value = [\ndatabase.get_animals.assert_called_once_with('Meerkat')\ndatabase.feed_animal.assert_has_calls(\nDATABASE = None\nif DATABASE is None:\nNow, I can inject the mock ZooDatabase using patch, run the test, and \nI’m not using a mock datetime.utcnow \nfrom unittest.mock import patch\nDATABASE.get_food_period.return_value = timedelta(hours=3)\nDATABASE.get_animals.return_value = [\n✦ When unit tests require a lot of repeated boilerplate to set up mocks, \nclasses by returning a new mock, which can act as a mock method, \nmock dependencies in tests.",
      "keywords": [
        "database",
        "mocks",
        "animals",
        "Meerkat",
        "Item",
        "Mock class",
        "function",
        "Code",
        "datetime",
        "mock object",
        "food",
        "species",
        "functions"
      ],
      "concepts": [
        "mocks",
        "animals",
        "function",
        "functions",
        "functionality",
        "patch",
        "item",
        "classes",
        "expected",
        "expectations"
      ],
      "similar_chapters": [
        {
          "book": "Effective-Python",
          "chapter": 36,
          "title": "",
          "score": 0.436,
          "base_score": 0.436,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 22,
          "title": "",
          "score": 0.359,
          "base_score": 0.359,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 41,
          "title": "",
          "score": 0.336,
          "base_score": 0.336,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 16,
          "title": "",
          "score": 0.328,
          "base_score": 0.328,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 11,
          "title": "",
          "score": 0.31,
          "base_score": 0.31,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "mock",
          "database",
          "meerkat",
          "mock spec",
          "database meerkat"
        ],
        "semantic": [],
        "merged": [
          "mock",
          "database",
          "meerkat",
          "mock spec",
          "database meerkat"
        ]
      },
      "topic_id": null,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.22671282814429128,
        "topic_boost": 0.0,
        "timestamp": "2025-12-17T23:07:03.224885+00:00"
      }
    },
    {
      "chapter_number": 38,
      "title": "Segment 38 (pages 403-410)",
      "start_page": 403,
      "end_page": 410,
      "summary": "The debugger lets you inspect program state, print local \nvariables, and step through a Python program one statement at a time.\nIn most other programming languages, you use a debugger by spec-\nthe debugger is by modifying your program to directly initiate the \nprogram in order to run the debugger and starting it normally.\nbreakpoint()  # Start the debugger here\nAs soon as the breakpoint function runs, the program pauses its exe-\n$ python3 always_breakpoint.py \n> always_breakpoint.py(12)compute_rmse()\nmodules, inspect global state, construct new objects, run the help \nThree very useful commands make inspecting the running program \nhigher levels of the program that led to the breakpoint.\ndebugger commands to control the program’s execution in different \n■step: Run the program until the next line of execution in the pro-\nnext line of execution includes calling a function, the debugger \n■next: Run the program until the next line of execution in the \n■return: Run the program until the current function returns, and \n■continue: Continue running the program until the next break-\nThe breakpoint function can be called anywhere in a program.\nWhen I run the program and it enters the debugger, I can confirm \n$ python3 conditional_breakpoint.py \n> conditional_breakpoint.py(14)compute_rmse()\nThis enables you to debug a program after it’s \nI use the command line python3 -m pdb -c continue <program path> \nto run the program under control of the pdb module.\ncommand tells pdb to get the program started immediately.\nrunning, the program hits a problem and automatically enters the \ninteractive debugger, at which point I can inspect the program state:\n$ python3 -m pdb -c continue postmortem_breakpoint.py \nFile \".../pdb.py\", line 1697, in main\nFile \".../pdb.py\", line 1566, in _runscript\nFile \".../bdb.py\", line 585, in run\nFile \"postmortem_breakpoint.py\", line 4, in <module>\nFile \"postmortem_breakpoint.py\", line 16, in compute_rmse\n> postmortem_breakpoint.py(16)compute_rmse()\nfunction of the pdb module (which is often done in a single line as \nFile \"my_module.py\", line 17, in compute_stddev\nFile \"my_module.py\", line 13, in compute_variance\nest directly in your program by calling the breakpoint built-in \ninspect and modify the state of a running program.\n✦ pdb shell commands let you precisely control program execution \n✦ The pdb module can be used for debug exceptions after they \nhappen in independent Python programs (using python -m pdb -c \ncontinue <program path>) or the interactive Python interpreter (using \nworry about allocating or deallocating memory in their programs.\nHowever, in practice, programs eventually do run out of mem-\nwhere a Python program is using or leaking memory proves to be a \nThe first way to debug memory usage is to ask the gc built-in module \nItem 81: Use tracemalloc to Understand Memory Usage and Leaks \nwhere your program’s memory is being used.\n# waste_memory.py\nThen, I run a program that uses the gc built-in module to print out \n<waste_memory.MyObject object at 0x10390aeb8>\n<waste_memory.MyObject object at 0x10390af28>\nHere, I use this approach to print out the top three memory usage \nx = waste_memory.run()                     # Usage to debug\nwhich objects are dominating my program’s memory usage and where \nmemory usage in the program:\nFile \"waste_memory.py\", line 17\nFile \"waste_memory.py\", line 10\nFile \"waste_memory.py\", line 5\n✦ It can be difficult to understand how Python programs use and leak \nItem 81: Use tracemalloc to Understand Memory Usage and Leaks ",
      "keywords": [
        "program",
        "Python",
        "pdb",
        "debugger",
        "Memory",
        "err",
        "Memory Usage",
        "line",
        "Python program",
        "function",
        "objects",
        "waste",
        "run",
        "compute",
        "Understand Memory Usage"
      ],
      "concepts": [
        "program",
        "programming",
        "python",
        "pdb",
        "run",
        "running",
        "runs",
        "file",
        "memory",
        "objects"
      ],
      "similar_chapters": [
        {
          "book": "Effective-Python",
          "chapter": 25,
          "title": "",
          "score": 0.618,
          "base_score": 0.468,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 33,
          "title": "",
          "score": 0.564,
          "base_score": 0.414,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 30,
          "title": "",
          "score": 0.561,
          "base_score": 0.411,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 31,
          "title": "",
          "score": 0.557,
          "base_score": 0.407,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 28,
          "title": "",
          "score": 0.543,
          "base_score": 0.393,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "program",
          "py",
          "debugger",
          "memory",
          "pdb"
        ],
        "semantic": [],
        "merged": [
          "program",
          "py",
          "debugger",
          "memory",
          "pdb"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.33206369879197023,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:03.224925+00:00"
      }
    },
    {
      "chapter_number": 39,
      "title": "Segment 39 (pages 411-419)",
      "start_page": 411,
      "end_page": 419,
      "summary": "Collaborating with others on Python programs requires being \nTo use the Package Index, you need to use the command-line tool pip \npython3 -m pip to ensure that packages are installed for the correct \nUsing pip to install a new module is simple.\nexample, here I install the pytz module that I use elsewhere in this \n$ python3 -m pip install pytz\nInstalling collected packages: pytz\nYou can also create your own PyPI packages to share with the Python \npackages that are built and maintained by the Python community.\n✦ pip is the command-line tool you can use to install packages \nvarious packages from the Python community (see Item 82: “Know \nning the python3 -m pip command-line tool to install packages like \nThe problem is that, by default, pip installs new packages in a global \nthat the packages you install depend on.\nwhat the Sphinx package depends on after installing it by asking pip:\n$ python3 -m pip show Sphinx\nItem 83: Use Virtual Environments for Isolated Dependencies \nLocation: /usr/local/lib/python3.8/site-packages\n$ python3 -m pip show flask\nLocation: /usr/local/lib/python3.8/site-packages\nwith python3 -m pip install --upgrade Jinja2, you may find that Sphinx \nglobal version of a module installed at a time.\nassume the worst: that the versions of Python and global packages \nSince Python 3.4, pip and the venv \ntion (accessible with python -m venv).\nvenv allows you to create isolated versions of the Python environment.\nthe tool, it’s important to note the meaning of the python3 command \n$ which python3\n$ python3 --version\nPython 3.8.0\nworks because I already have the pytz package installed as a global \n$ python3 -c 'import pytz'\nNow, I use venv to create a new virtual environment called myproject.\n$ python3 -m venv myproject\nTo start using the virtual environment, I use the source command \nAfter activation, the path to the python3  command-line tool has moved \n(myproject)$ which python3\n/tmp/myproject/bin/python3\npython3 to version 3.9, my virtual environment will still explicitly \nThe virtual environment I created with venv starts with no packages \ninstalled except for pip and setuptools.\n(myproject)$ python3 -c 'import pytz'\nI can use the pip command-line tool to install the pytz module into \n(myproject)$ python3 -m pip install pytz\nItem 83: Use Virtual Environments for Isolated Dependencies \nInstalling collected packages: pytz\n(myproject)$ python3 -c 'import pytz'\n(myproject)$ which python3\n/tmp/myproject/bin/python3\n$ which python3\nOnce you are in a virtual environment, you can continue installing \nI can use the python3 -m pip freeze \n(myproject)$ python3 -m pip freeze > requirements.txt\n$ python3 -m venv otherproject\nThe new environment will have no extra packages installed:\n(otherproject)$ python3 -m pip list\nI can install all of the packages from the first environment by  running \npython3 -m pip install on the requirements.txt that I generated with \nthe python3 -m pip freeze command:\n(otherproject)$ python3 -m pip install -r /tmp/myproject/\ninstalls all of the packages required to reproduce the first environ-\n(otherproject)$ python3 -m pip list\nItem 83: Use Virtual Environments for Isolated Dependencies \ntool, are hard-coded to the environment’s install directory.\ning a virtual environment directory, just use python3 -m pip freeze \n✦ Virtual environments allow you to use pip to install many differ-\n✦ Virtual environments are created with python -m venv, enabled with \npython3 -m pip freeze.\npython3 -m pip install -r requirements.txt.",
      "keywords": [
        "virtual environment",
        "Python",
        "environment",
        "Virtual",
        "Python Package Index",
        "pip",
        "packages",
        "version",
        "myproject",
        "install",
        "Item",
        "Python environment",
        "Python community",
        "pip install",
        "Python Package"
      ],
      "concepts": [
        "packages",
        "packaging",
        "python",
        "version",
        "versions",
        "dependencies",
        "depend",
        "dependency",
        "install",
        "environments"
      ],
      "similar_chapters": [
        {
          "book": "Effective-Python",
          "chapter": 1,
          "title": "",
          "score": 0.595,
          "base_score": 0.445,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 3,
          "title": "",
          "score": 0.593,
          "base_score": 0.443,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 41,
          "title": "",
          "score": 0.474,
          "base_score": 0.474,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 30,
          "title": "",
          "score": 0.385,
          "base_score": 0.385,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 25,
          "title": "",
          "score": 0.311,
          "base_score": 0.311,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "pip",
          "python3",
          "install",
          "python3 pip",
          "packages"
        ],
        "semantic": [],
        "merged": [
          "pip",
          "python3",
          "install",
          "python3 pip",
          "packages"
        ]
      },
      "topic_id": 3,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.21757195862525977,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:03.225005+00:00"
      }
    },
    {
      "chapter_number": 40,
      "title": "Segment 40 (pages 420-428)",
      "start_page": 420,
      "end_page": 428,
      "summary": "Item 84: Write Docstrings for Every Function, Class, and Module \nDocstrings can be attached to functions, classes, and modules.\nYou can inspect functions, classes, and modules to \nDocumenting Modules\nThe goal of this docstring is to introduce the module and its \nThe module docstring is also a jumping-off point where you can high-\nlight important classes and functions found in the module.\nHere’s an example of a module docstring:\nThis module provides easy ways to determine when words you've\nIf the module is a command-line utility, the module docstring is also \nthe same pattern as the module-level docstring.\nimportant details of the class’s operation.\nImportant public attributes and methods of the class should be high-\nHere’s an example of a class docstring:\nItem 84: Write Docstrings for Every Function, Class, and Module \nDocumenting Functions\nEach public function and method should have a docstring.\nlows the same pattern as the docstrings for modules and classes.\nHere’s an example of a function docstring:\nThere are also some special cases in writing docstrings for functions \nfrom typing import Container, List\nItem 85: Use Packages to Organize Modules and Provide Stable APIs \n✦ Write documentation for every module, class, method, and function \n✦ For modules: Introduce the contents of a module and any important \n✦ For classes: Document behavior, important attributes, and subclass \nbehavior in the docstring following the class statement.\n✦ For functions and methods: Document every argument, returned \nvalue, raised exception, and other behaviors in the docstring follow-\nItem 85:  Use Packages to Organize Modules and \nYou’ll separate functionality into various modules \nPackages are modules that \ncontain other modules.\nPython files in that directory will be available for import, using a path \nTo import the utils module, I use the absolute module name that \nfrom mypackage import utils\nThe functionality provided by packages has two primary purposes in \nThe first use of packages is to help divide your modules into separate \nhere’s a program that imports attributes from two modules with the \nfrom analysis.utils import log_base2_bucket\nfrom frontend.utils import stringify\nwant to use the inspect function from both the analysis.utils and \nthe frontend.utils modules.\nfrom analysis.utils import inspect\nfrom frontend.utils import inspect  # Overwrites!\nItem 85: Use Packages to Organize Modules and Provide Stable APIs \nThe solution is to use the as clause of the import statement to rename \nfrom analysis.utils import inspect as analysis_inspect\nfrom frontend.utils import inspect as frontend_inspect\nimport statement, including entire modules.\nple above, this means I’d use basic import statements instead of \nimport from:\nimport analysis.utils\nimport frontend.utils\nThe second use of packages in Python is to provide strict, stable APIs \nthe __all__ special attribute of a module or package.\nWhen consuming code executes from foo import *, \ning underscore—are imported (see Item 42: “Prefer Public Attributes \nHere, I define the models module of \nI also define a utils module in mypackage to perform operations on the \nmodels import Projectile\nattributes that are available on the mypackage module.\ndownstream consumers to always import directly from mypackage \ninstead of importing from mypackage.models or mypackage.utils.\ncontents of the mypackage module when it’s imported.\nspecify an explicit API for mypackage by limiting what you import into \nI can expose the public interface of mypackage by simply import-\nmodels import *\nutils import *\nHere’s a consumer of the API that directly imports from mypackage \nfrom mypackage import *\nNotably, internal-only functions like mypackage.utils._dot_product \nThis whole approach works great when it’s important to provide an \nyour own modules, the functionality of __all__ is probably unneces-\nItem 85: Use Packages to Organize Modules and Provide Stable APIs \nIf a module has multiple import * statements, \nnames within the containing module.\nThe safest approach is to avoid import * in your code and explicitly ",
      "keywords": [
        "Module",
        "Item",
        "Provide Stable APIs",
        "Python",
        "Function",
        "docstring",
        "Stable APIs",
        "module docstring",
        "functions",
        "API",
        "Packages",
        "provide",
        "mypackage",
        "Organize Modules",
        "Python provides packages"
      ],
      "concepts": [
        "importance",
        "important",
        "imports",
        "module",
        "documenting",
        "classes",
        "words",
        "function",
        "functions",
        "functionality"
      ],
      "similar_chapters": [
        {
          "book": "Effective-Python",
          "chapter": 2,
          "title": "",
          "score": 0.535,
          "base_score": 0.535,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 43,
          "title": "",
          "score": 0.516,
          "base_score": 0.516,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 41,
          "title": "",
          "score": 0.481,
          "base_score": 0.481,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 13,
          "title": "",
          "score": 0.396,
          "base_score": 0.396,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 32,
          "title": "",
          "score": 0.395,
          "base_score": 0.395,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "utils",
          "import",
          "mypackage",
          "docstring",
          "modules"
        ],
        "semantic": [],
        "merged": [
          "utils",
          "import",
          "mypackage",
          "docstring",
          "modules"
        ]
      },
      "topic_id": null,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.291159705076676,
        "topic_boost": 0.0,
        "timestamp": "2025-12-17T23:07:03.225043+00:00"
      }
    },
    {
      "chapter_number": 41,
      "title": "Segment 41 (pages 429-441)",
      "start_page": 429,
      "end_page": 441,
      "summary": "✦ Packages in Python are modules that contain other modules.\n✦ You can provide an explicit API for a module by listing its publicly \nItem 86:  Consider Module-Scoped Code to Configure \nmy program’s code, I need to run a server container, the database \nItem 86: Consider Module-Scoped Code to Configure Enviornments \nOther modules in my program can then import the __main__ \nmodule and use the value of TESTING to decide how they define their \nThe key behavior to notice here is that code running in module \nmodule will define names.\nbefore defining top-level constructs in a module:\nmy module definitions.\n✦ You can tailor a module’s contents to different deployment environ-\nItem 87:  Define a Root Exception to Insulate Callers \nWhen you’re defining a module’s API, the exceptions you raise are \n# my_module.py\nby providing a root Exception in my module and having all other \nexceptions raised by that module inherit from the root exception:\n# my_module.py\nclass Error(Exception):\n\"\"\"Base-class for all exceptions raised by this module.\"\"\"\nHaving a root exception in a module makes it easy for consumers of \nan API to catch all of the exceptions that were raised deliberately.\nexcept my_module.Error:\nItem 87: Define a Root Exception to Insulate Callers from APIs \nFile \".../example.py\", line 3, in <module>\nFile \".../my_module.py\", line 10, in determine_weight\nthe insulating except block that catches my module’s root exception.\nexcept my_module.InvalidDensityError:\nexcept my_module.Error:\nFile \".../example.py\", line 3, in <module>\nFile \".../my_module.py\", line 12, in determine_weight\nfind bugs in an API module’s code.\nexceptions that I define within my module’s hierarchy, then all other \ntypes of exceptions raised by my module must be the ones that I didn’t \ners from bugs in my API module’s code.\nmodule’s implementation that needs to be fixed.\nexcept my_module.InvalidDensityError:\nexcept my_module.Error:\nlogging.exception('Bug in the API code!')\nFile \".../example.py\", line 3, in <module>\nFile \".../my_module.py\", line 14, in determine_weight\n# my_module.py\nItem 87: Define a Root Exception to Insulate Callers from APIs \nexcept my_module.NegativeDensityError:\nexcept my_module.InvalidDensityError:\nexcept my_module.Error:\nlogging.exception('Bug in the API code!')\n# my_module.py\nclass Error(Exception):\n\"\"\"Base-class for all exceptions raised by this module.\"\"\"\n✦ Defining root exceptions for modules allows API consumers to \n✦ Catching root exceptions can help you find bugs in code that \n✦ Catching the Python Exception base class can help you find bugs in \ninterdependence between modules.\nThe problem is that the app module that contains the prefs object \nimport dialog\nIf I try to import the app module from my \nFile \".../main.py\", line 17, in <module>\nFile \".../app.py\", line 17, in <module>\nimport dialog\nFile \".../dialog.py\", line 23, in <module>\nAttributeError: partially initialized module 'app' has no \nWhen a module is imported, here’s what Python \n2. Loads the code from the module and ensures that it compiles\n5. Runs the code in the module object to define its contents\nmodule aren’t defined until the code for those attributes has executed \nBut the module can be loaded with the import state-\nIn the example above, the app module imports dialog before defin-\nThen, the dialog module imports app.\nmodule is empty (from step 4).\nboth app and dialog can import the same utility module and avoid \nimport the dialog module toward the bottom of the app module, after \nthe app module’s other contents have run, the AttributeError goes \nThis works because, when the dialog module is loaded late, its recur-\nThis makes your module’s dependencies clear to new readers of \nIt also ensures that any module you depend on is in scope \nand available to all the code in your module.\nchanges in the ordering of your code to break the module entirely.\nImport, Configure, Run\nI can have my modules only \nThen, I have each module provide a \nconfigure function that I call once all other modules have finished \nimporting.\nThe purpose of configure is to prepare each module’s state \nby accessing the attributes of other modules.\nall modules have been imported (step 5 is complete), so all attributes \nHere, I redefine the dialog module to only access the prefs object \nI also redefine the app module to not run activities on import:\nimport dialog\nimport dialog\ntinct phases within a module can also make your code harder to read \nis called a dynamic import because the module import happens while \nand initializing its modules.\nHere, I redefine the dialog module to use a dynamic import.\ndialog.show function imports the app module at runtime instead of \nthe dialog module importing app at initialization time:\nThe app module can now be the same as it was in the original exam-\nimport dialog\nchanges to the way the modules are defined and imported.\nmodule.\n✦ Circular dependencies happen when two modules must call into \nmutual dependencies into a separate module at the bottom of the \ndependency between modules while minimizing refactoring and ",
      "keywords": [
        "module",
        "API",
        "Exception",
        "exceptions",
        "dialog",
        "Root Exception",
        "code",
        "API code",
        "dialog module",
        "API module",
        "app module",
        "import dialog",
        "density",
        "Break Circular Dependencies",
        "weight"
      ],
      "concepts": [
        "modules",
        "imports",
        "exception",
        "exceptions",
        "classes",
        "configure",
        "configuration",
        "configurations",
        "dependencies",
        "dependency"
      ],
      "similar_chapters": [
        {
          "book": "Effective-Python",
          "chapter": 40,
          "title": "",
          "score": 0.481,
          "base_score": 0.481,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 39,
          "title": "",
          "score": 0.474,
          "base_score": 0.474,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 16,
          "title": "",
          "score": 0.472,
          "base_score": 0.472,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 36,
          "title": "",
          "score": 0.426,
          "base_score": 0.426,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 18,
          "title": "",
          "score": 0.423,
          "base_score": 0.423,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "module",
          "dialog",
          "app",
          "my_module",
          "app module"
        ],
        "semantic": [],
        "merged": [
          "module",
          "dialog",
          "app",
          "my_module",
          "app module"
        ]
      },
      "topic_id": null,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.3099217692636319,
        "topic_boost": 0.0,
        "timestamp": "2025-12-17T23:07:03.225081+00:00"
      }
    },
    {
      "chapter_number": 42,
      "title": "Segment 42 (pages 442-451)",
      "start_page": 442,
      "end_page": 451,
      "summary": "Item 89: Consider warnings to Refactor and Migrate Usage \ndef convert(value, units):\ndef localize(value, units):\ntime_units='hours',\ndistance_units='miles'):\nprint(f'{distance} {distance_units}')\ntime_units='seconds')\nIt seems like requiring units to be specified for this function is a much \nFor this purpose, Python provides the built-in warnings module.\nUsing warnings is a programmatic way to inform other programmers \nException to Insulate Callers from APIs”), warnings are all about \nI can modify print_distance to issue warnings when the optional \nimport warnings\nspeed_units=None,\ntime_units=None,\ndistance_units=None):\nif speed_units is None:\nwarnings.warn(\n'speed_units required', DeprecationWarning)\nif time_units is None:\nwarnings.warn(\n'time_units required', DeprecationWarning)\ntime_units = 'hours'\nif distance_units is None:\nwarnings.warn(\n'distance_units required', DeprecationWarning)\ndistance_units = 'miles'\nprint(f'{distance} {distance_units}')\nI can verify that this code issues a warning by calling the function \nput from the warnings module:\nItem 89: Consider warnings to Refactor and Migrate Usage \ntime_units='seconds')\n.../example.py:97: DeprecationWarning: distance_units required\nwarnings.warn(\nAdding warnings to this function required quite a lot of repetitive boil-\nAlso, the warning message \nas the cause of the warning.\nfunctions that can issue warnings on behalf of other code, reducing \nHere, I define a helper function that warns if an optional \nwarnings.warn(\nspeed_units=None,\ntime_units=None,\ndistance_units=None):\ndistance_units = require(\nprint(f'{distance} {distance_units}')\ntime_units='seconds')\n.../example.py:174: DeprecationWarning: distance_units will be \nwhen a warning is encountered.\nOne option is to make all warnings \nbecome errors, which raises the warning as an exception instead of \nwarnings.simplefilter('error')\nwarnings.warn('This usage is deprecated',\n$ python -W error example_test.py \nwarnings.warn('This might raise an exception!')\nItem 89: Consider warnings to Refactor and Migrate Usage \nwarnings module to ignore the error by using the simplefilter and \nwarnings for all the details):\nwarnings.warn('This will not be printed to stderr')\nwarnings to cause errors because they might crash the program at a \n'py.warnings' logger:\n'%(asctime)-15s WARNING] %(message)s')\nlogger = logging.getLogger('py.warnings')\nwarnings.resetwarnings()\nwarnings.simplefilter('default')\nwarnings.warn('This will go to the logs output')\n2019-06-11 19:48:19,132 WARNING] .../example.py:227: \nwarnings.warn('This will go to the logs output')\nUsing logging to capture warnings ensures that any error reporting \nof important warnings in production.\nAPI library maintainers should also write unit tests to verify that \nassert len(found_warnings) == 1\nassert str(single_warning.message) == (\nassert single_warning.category == DeprecationWarning\n✦ The warnings module can be used to notify callers of your API about \n✦ Raise warnings as errors by using the -W error command-line argu-\n✦ In production, you can replicate warnings into the logging module \nwarnings at runtime.\n✦ It’s useful to write tests for the warnings that your code generates to \ntions of static analysis tools for Python that use typing.\nReturn value types are specified with -> type \n.../example.py:6: error: Name 'value' is not defined",
      "keywords": [
        "units",
        "distance",
        "warnings",
        "speed",
        "Item",
        "Python",
        "duration",
        "norm",
        "time",
        "API",
        "code",
        "function",
        "arguments",
        "type",
        "error"
      ],
      "concepts": [
        "warnings",
        "typing",
        "type",
        "error",
        "value",
        "item",
        "function",
        "functions",
        "units",
        "logging"
      ],
      "similar_chapters": [
        {
          "book": "Effective-Python",
          "chapter": 12,
          "title": "",
          "score": 0.441,
          "base_score": 0.441,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 41,
          "title": "",
          "score": 0.397,
          "base_score": 0.397,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 9,
          "title": "",
          "score": 0.358,
          "base_score": 0.358,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 36,
          "title": "",
          "score": 0.347,
          "base_score": 0.347,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 18,
          "title": "",
          "score": 0.344,
          "base_score": 0.344,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "warnings",
          "distance_units",
          "warn",
          "warnings warn",
          "time_units"
        ],
        "semantic": [],
        "merged": [
          "warnings",
          "distance_units",
          "warn",
          "warnings warn",
          "time_units"
        ]
      },
      "topic_id": null,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.28097595967796574,
        "topic_boost": 0.0,
        "timestamp": "2025-12-17T23:07:03.225117+00:00"
      }
    },
    {
      "chapter_number": 43,
      "title": "Segment 43 (pages 452-461)",
      "start_page": 452,
      "end_page": 461,
      "summary": "87–88\nin comprehensions, 112–114\n__call__ method, 154–155\n__init__ method, 160–164\nsubclasses), 73–75\ndescriptors versus, 190–195\n186–189\nattributes, 214–218\ndynamic default values, 93–96\npositional-only, 96–101\nin comprehensions, 110–114\n87–88\nannotating, 214–218\n181–185\nrefactoring, 186–189\n6–7\navoiding, 289–292\nthreads, 230–235\n413–418\n379–384\n145–148\nbytearray built-in type, 346–351\nversus, 5–10\n48–52\ninstances, 5–10\n226–230\n413–418\nbuilt-in types versus, 145–148\ndecorators, 218–224\ndocumentation, 398–399\n151–155\n160–164\n169–174\nrefactoring to, 148–151\n413–418\ndynamic import, 417–418\n415–416\n389–390\ndocumentation, 396–401\nfrom, 174–178\n110–114\n121–122\n107–109\n109–110\n252–256\nusing Queue class for, 257–263\n264–266\nwith threads, 230–235\nwhen to use, 248–252\n292–297\nenvironments, 406–408\n390–396\nmodule, 174–178\n282–288\n11–21\n174–178\n379–384\n319–322\nclass decorators, 218–224\nfunction decorators, 101–104\ndynamic, 93–96\n315–316\n__missing__ method, 73–75\nmethods, 70–72\nexpressions, 65–70\nversus, 70–72\nconflicts, 390–396\nencapsulating, 375–379\nconfiguring, 406–408\ndecorator, 190–195\nmodule, 312–319\n207–208\nmethods, 70–72\nexpressions, 65–70\n13–15\n108–109\n93–96\nwriting, 396–401\nfor classes, 398–399\nfor functions, 399–400\nfor modules, 397–398\n400–401\ndynamic default arguments, 93–96\ndynamic import, 417–418\n375–379\nbuilt-in function versus, 28–30\n299–304\nversus, 80–82\nhelper functions versus, 21–24\nwith Queue class, 257–263\n264–265\nwith Queue class, 257–263\n264–265\n326–334\ninstances, 9–10\n107–109\nwith statements versus, 304–308\n326–334\n32–35\nformat built-in function, 15–19\n11–21\n15–19\n19–21\n11–15\nC-style strings versus, 11–21\nstr.format method versus, 15–19\n83–86\ndecorators, 101–104\ndocumentation, 399–400\n93–96\nexceptions versus, 80–82",
      "keywords": [
        "Cautious When Relying",
        "type",
        "versus",
        "type hints",
        "built-in module",
        "method",
        "built-in",
        "Static Analysis",
        "type annotations",
        "versus str instances",
        "module",
        "method versus",
        "built-in types versus",
        "bytes versus str",
        "arguments"
      ],
      "concepts": [
        "types",
        "typing",
        "classes",
        "value",
        "method",
        "module",
        "built",
        "functionality",
        "function",
        "functions"
      ],
      "similar_chapters": [
        {
          "book": "Effective-Python",
          "chapter": 2,
          "title": "",
          "score": 0.679,
          "base_score": 0.529,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 44,
          "title": "",
          "score": 0.632,
          "base_score": 0.632,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 9,
          "title": "",
          "score": 0.61,
          "base_score": 0.46,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 40,
          "title": "",
          "score": 0.516,
          "base_score": 0.516,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 22,
          "title": "",
          "score": 0.433,
          "base_score": 0.433,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "versus",
          "96",
          "418",
          "93",
          "93 96"
        ],
        "semantic": [],
        "merged": [
          "versus",
          "96",
          "418",
          "93",
          "93 96"
        ]
      },
      "topic_id": 4,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.30310162283182435,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:07:03.225177+00:00"
      }
    },
    {
      "chapter_number": 44,
      "title": "Segment 44 (pages 462-467)",
      "start_page": 462,
      "end_page": 467,
      "summary": "96–101\n86–89\n123–126\n155–160\n181–185\nversus, 21–24\n174–178\n207–208\n58–65\nusing threads for, 230–235\n121–122\n139–140\n140–141\n137–138\nmethods, 70–72\nexpressions, 65–70\n384–387\n121–122\nversus, 114–116\n48–52\n334–336\n235–238\nfunctions, 28–30\n107–109\nmethods, 70–72\nexpressions, 65–70\n375–379\n415–416\n401–406\n77–80\n292–297\n248–252\n235–238\nversus, 145–148\n93–96\n155–160\n322–326\n401–406\n401–406\nmodule, 292–297\n226–230\n13–15\n326–334\n322–326\n238–247\n228–229\n257–263\n86–89\n354–357\nversus, 169–174\nprocesses, 226–230\n326–334\nversus, 169–174\n389–390\nPython 2, 1–2\nPython 3, 1–2\n389–390\n238–247\n28–30\nto classes, 148–151\n354–357\n114–116\nexceptions versus, 80–82\n190–195\n304–308\n299–304\n304–308\nclass, 319–322\n48–52\nclasses, 168–169\n312–319\n68–70\ndefaultdict method versus, 70–72\n181–185\n365–367\n248–252\n48–52\n58–65\n334–336\nversus, 5–10\n11–21\n19–21\n11–15\n109–110\n226–230\n365–367\n357–365\n375–379\n357–365\n282–288\n264–266\n132–136\n384–387\nstrings, 13–15\n24–28\n55–56\n6–7\nindexing versus, 24–28\n32–35\nfor classes, 398–399\nfor modules, 397–398",
      "keywords": [
        "built-in module",
        "versus",
        "built-in",
        "method",
        "built-in function",
        "module",
        "asyncio built-in module",
        "method versus",
        "built-in function versus",
        "versus setdefault methods",
        "function",
        "zip built-in function",
        "attributes versus",
        "pickle built-in module",
        "unpacking versus"
      ],
      "concepts": [
        "method",
        "module",
        "classes",
        "built",
        "function",
        "functions",
        "index",
        "arguments",
        "typing",
        "type"
      ],
      "similar_chapters": [
        {
          "book": "Effective-Python",
          "chapter": 43,
          "title": "",
          "score": 0.632,
          "base_score": 0.632,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 16,
          "title": "",
          "score": 0.424,
          "base_score": 0.424,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 2,
          "title": "",
          "score": 0.408,
          "base_score": 0.408,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 38,
          "title": "",
          "score": 0.407,
          "base_score": 0.407,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Effective-Python",
          "chapter": 27,
          "title": "",
          "score": 0.401,
          "base_score": 0.401,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "versus",
          "70",
          "365",
          "238",
          "357"
        ],
        "semantic": [],
        "merged": [
          "versus",
          "70",
          "365",
          "238",
          "357"
        ]
      },
      "topic_id": null,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.30198884944557397,
        "topic_boost": 0.0,
        "timestamp": "2025-12-17T23:07:03.225214+00:00"
      }
    }
  ],
  "total_chapters": 44,
  "enrichment_provenance": {
    "taxonomy_id": "none",
    "taxonomy_version": "none",
    "taxonomy_path": "none",
    "taxonomy_checksum": "sha256:none",
    "source_metadata_file": "Effective-Python_metadata.json",
    "enrichment_date": "2025-12-17T23:07:03.237263+00:00",
    "enrichment_method": "msep",
    "model_version": "ai-agents-msep-v1",
    "processing_time_ms": 4253.369876998477,
    "total_similar_chapters": 220
  }
}